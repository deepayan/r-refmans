<!DOCTYPE html><html lang="en-US"><head><title>Help for package exametrika</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {exametrika}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AlphaCoefficient'><p>Alpha Coefficient</p></a></li>
<li><a href='#AlphaIfDel'><p>Alpha Coefficient if Item removed</p></a></li>
<li><a href='#asymprior'><p>Prior distribution function with guessing parameter</p></a></li>
<li><a href='#Biclustering'><p>Biclustering and Ranklustering Analysis</p></a></li>
<li><a href='#BINET'><p>Bicluster Network Model</p></a></li>
<li><a href='#BiserialCorrelation'><p>Biserial Correlation</p></a></li>
<li><a href='#BitRespPtn'><p>Binary pattern maker</p></a></li>
<li><a href='#BNM'><p>Bayesian Network Model</p></a></li>
<li><a href='#calcFitIndices'><p>calc Fit Indices</p></a></li>
<li><a href='#CCRR'><p>Conditional Correct Response Rate</p></a></li>
<li><a href='#crr'><p>Correct Response Rate</p></a></li>
<li><a href='#CSR'><p>Conditional Selection Rate</p></a></li>
<li><a href='#CTT'><p>Classical Test Theory</p></a></li>
<li><a href='#dataFormat'><p>dataFormat</p></a></li>
<li><a href='#Dimensionality'><p>Dimensionality</p></a></li>
<li><a href='#generate_category_labels'><p>Generate category labels for response data</p></a></li>
<li><a href='#generate_start_values'><p>generate start values for optimize</p></a></li>
<li><a href='#GRM'><p>Graded Response Model (GRM)</p></a></li>
<li><a href='#grm_cumprob'><p>cumulative probability of GRM</p></a></li>
<li><a href='#grm_iif'><p>Item Information Function for GRM</p></a></li>
<li><a href='#grm_prob'><p>Probability function for GRM</p></a></li>
<li><a href='#IIF2PLM'><p>IIF for 2PLM</p></a></li>
<li><a href='#IIF3PLM'><p>IIF for 3PLM</p></a></li>
<li><a href='#InterItemAnalysis'><p>Inter-Item Analysis for Psychometric Data</p></a></li>
<li><a href='#IRM'><p>Infinite Relational Model</p></a></li>
<li><a href='#IRT'><p>Estimating Item parameters using EM algorithm</p></a></li>
<li><a href='#ITBiserial'><p>Item-Total Biserial Correlation</p></a></li>
<li><a href='#ItemEntropy'><p>Item Entropy</p></a></li>
<li><a href='#ItemFit'><p>Model Fit Functions for Items</p></a></li>
<li><a href='#ItemInformationFunc'><p>IIF for 4PLM</p></a></li>
<li><a href='#ItemLift'><p>Item Lift</p></a></li>
<li><a href='#ItemOdds'><p>Item Odds</p></a></li>
<li><a href='#ItemReport'><p>Generate Item Report for Non-Binary Test Data</p></a></li>
<li><a href='#ItemStatistics'><p>Simple Item Statistics</p></a></li>
<li><a href='#ItemThreshold'><p>Item Threshold</p></a></li>
<li><a href='#ItemTotalCorr'><p>Item-Total Correlation</p></a></li>
<li><a href='#J12S5000'><p>J12S5000</p></a></li>
<li><a href='#J15S3810'><p>J15S3810</p></a></li>
<li><a href='#J15S500'><p>J15S500</p></a></li>
<li><a href='#J20S400'><p>J20S400</p></a></li>
<li><a href='#J35S5000'><p>J35S5000</p></a></li>
<li><a href='#J35S515'><p>J35S515</p></a></li>
<li><a href='#J50S100'><p>J50S100</p></a></li>
<li><a href='#J5S10'><p>J5S10</p></a></li>
<li><a href='#J5S1000'><p>J5S1000</p></a></li>
<li><a href='#Jacobian_grm'><p>Jacobian function for GRM</p></a></li>
<li><a href='#JCRR'><p>Joint Correct Response Rate</p></a></li>
<li><a href='#JointSampleSize'><p>Joint Sample Size</p></a></li>
<li><a href='#JSR'><p>Joint Selection Rate</p></a></li>
<li><a href='#LCA'><p>Latent Class Analysis</p></a></li>
<li><a href='#LD_param_est'><p>LDparam set</p></a></li>
<li><a href='#LDB'><p>Local Dependence Biclustering</p></a></li>
<li><a href='#LDLRA'><p>Local Dependence Latent Rank Analysis</p></a></li>
<li><a href='#log_lik_grm'><p>log_lik function for grm</p></a></li>
<li><a href='#LogisticModel'><p>Four-Parameter Logistic Model</p></a></li>
<li><a href='#longdataFormat'><p>Long Format Data Conversion</p></a></li>
<li><a href='#LRA'><p>Latent Rank Analysis</p></a></li>
<li><a href='#maxParents_penalty'><p>Utility function for searching DAG</p></a></li>
<li><a href='#MutualInformation'><p>Mutual Information</p></a></li>
<li><a href='#nrs'><p>Number Right Score</p></a></li>
<li><a href='#objective_function_IRT'><p>Log-likelihood function used in the Maximization Step (M-Step).</p></a></li>
<li><a href='#OmegaCoefficient'><p>Omega Coefficient</p></a></li>
<li><a href='#params_to_target_jac'><p>parameter transformation params_to_target</p></a></li>
<li><a href='#passage'><p>Passage Rate of Student</p></a></li>
<li><a href='#percentile'><p>Student Percentile Ranks</p></a></li>
<li><a href='#PhiCoefficient'><p>Phi-Coefficient</p></a></li>
<li><a href='#plot.exametrika'><p>Plot Method for Objects of Class &quot;exametrika&quot;</p></a></li>
<li><a href='#polychoric'><p>Polychoric Correlation</p></a></li>
<li><a href='#polychoric_likelihood'><p>Calculate Polychoric Correlation Likelihood</p></a></li>
<li><a href='#PolychoricCorrelationMatrix'><p>Polychoric Correlation Matrix</p></a></li>
<li><a href='#polyserial'><p>Polyserial Correlation</p></a></li>
<li><a href='#print.exametrika'><p>Print Method for Exametrika Objects</p></a></li>
<li><a href='#PSD_item_params'><p>internal functions for PSD of Item parameters</p></a></li>
<li><a href='#qBiNormal'><p>bivariate normal CDF</p></a></li>
<li><a href='#RaschModel'><p>Rasch Model</p></a></li>
<li><a href='#response_type_error'><p>Generate Error Message for Invalid Response Type</p></a></li>
<li><a href='#score_function_with_Jacobian'><p>score function for grm</p></a></li>
<li><a href='#ScoreReport'><p>Generate Score Report for Non-Binary Test Data</p></a></li>
<li><a href='#slopeprior'><p>Prior distribution function with respect to the slope.</p></a></li>
<li><a href='#softmax'><p>softmax function</p></a></li>
<li><a href='#sscore'><p>Standardized Score</p></a></li>
<li><a href='#stanine'><p>Stanine Scores</p></a></li>
<li><a href='#StrLearningGA_BNM'><p>Structure Learning for BNM by simple GA</p></a></li>
<li><a href='#StrLearningPBIL_BNM'><p>Structure Learning for BNM by PBIL</p></a></li>
<li><a href='#StrLearningPBIL_LDLRA'><p>Structure Learning for LDLRA by PBIL algorithm</p></a></li>
<li><a href='#StudentAnalysis'><p>StudentAnalysis</p></a></li>
<li><a href='#target_to_params_jac'><p>parameter transformation target_to_params</p></a></li>
<li><a href='#TestFit'><p>Model Fit Functions for test whole</p></a></li>
<li><a href='#TestFitSaturated'><p>Model Fit Functions for saturated model</p></a></li>
<li><a href='#TestInformationFunc'><p>TIF for IRT</p></a></li>
<li><a href='#TestResponseFunc'><p>TRF for IRT</p></a></li>
<li><a href='#TestStatistics'><p>Simple Test Statistics</p></a></li>
<li><a href='#tetrachoric'><p>Tetrachoric Correlation</p></a></li>
<li><a href='#TetrachoricCorrelationMatrix'><p>Tetrachoric Correlation Matrix</p></a></li>
<li><a href='#ThreePLM'><p>Three-Parameter Logistic Model</p></a></li>
<li><a href='#TwoPLM'><p>Two-Parameter Logistic Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Test Theory Analysis and Biclustering</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements comprehensive test data engineering methods as described in 
    Shojima (2022, ISBN:978-9811699856). Provides statistical techniques for 
    engineering and processing test data: Classical Test Theory (CTT) with 
    reliability coefficients for continuous ability assessment; Item Response 
    Theory (IRT) including Rasch, 2PL, and 3PL models with item/test information 
    functions; Latent Class Analysis (LCA) for nominal clustering; Latent Rank 
    Analysis (LRA) for ordinal clustering with automatic determination of cluster 
    numbers; Biclustering methods including infinite relational models for 
    simultaneous clustering of examinees and items without predefined cluster 
    numbers; and Bayesian Network Models (BNM) for visualizing inter-item 
    dependencies. Features local dependence analysis through LRA and biclustering, 
    parameter estimation, dimensionality assessment, and network structure 
    visualization for educational, psychological, and social science research.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>BuildVignettes:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://kosugitti.github.io/exametrika/">https://kosugitti.github.io/exametrika/</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0), mvtnorm, igraph</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-09 04:59:57 UTC; napier3</td>
</tr>
<tr>
<td>Author:</td>
<td>Koji Kosugi <a href="https://orcid.org/0000-0001-5816-0099"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Koji Kosugi &lt;kosugitti@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-09 05:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='AlphaCoefficient'>Alpha Coefficient</h2><span id='topic+AlphaCoefficient'></span>

<h3>Description</h3>

<p>This function computes Tau-Equivalent Measurement, also known as Cronbach's alpha coefficient, for a given data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AlphaCoefficient(x, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AlphaCoefficient_+3A_x">x</code></td>
<td>
<p>This should be a data matrix or a Covariance/Phi/Tetrachoric matrix.</p>
</td></tr>
<tr><td><code id="AlphaCoefficient_+3A_na">na</code></td>
<td>
<p>This parameter identifies the numbers or characters that should be treated as missing values when 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="AlphaCoefficient_+3A_z">Z</code></td>
<td>
<p>This parameter represents a missing indicator matrix. It is only needed if 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="AlphaCoefficient_+3A_w">w</code></td>
<td>
<p>This parameter is an item weight vector. It is only required if 'x' is a data matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For a correlation/covariance matrix input, returns a single numeric value
representing the alpha coefficient. For a data matrix input, returns a list with
three components:
</p>

<dl>
<dt>AlphaCov</dt><dd><p>Alpha coefficient calculated from covariance matrix</p>
</dd>
<dt>AlphaPhi</dt><dd><p>Alpha coefficient calculated from phi coefficient matrix</p>
</dd>
<dt>AlphaTetrachoric</dt><dd><p>Alpha coefficient calculated from tetrachoric correlation matrix</p>
</dd>
</dl>



<h3>References</h3>

<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of a test. Psychometrika, 16,297–334.
</p>

<hr>
<h2 id='AlphaIfDel'>Alpha Coefficient if Item removed</h2><span id='topic+AlphaIfDel'></span>

<h3>Description</h3>

<p>This function returns the alpha coefficient when the specified item is excluded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AlphaIfDel(x, delItem = NULL, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AlphaIfDel_+3A_x">x</code></td>
<td>
<p>This should be a data matrix or a Covariance/Phi/Tetrachoric matrix.</p>
</td></tr>
<tr><td><code id="AlphaIfDel_+3A_delitem">delItem</code></td>
<td>
<p>Specify the item to be deleted. If NULL, calculations are performed for all cases.</p>
</td></tr>
<tr><td><code id="AlphaIfDel_+3A_na">na</code></td>
<td>
<p>This parameter identifies the numbers or characters that should be treated as missing values when 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="AlphaIfDel_+3A_z">Z</code></td>
<td>
<p>This parameter represents a missing indicator matrix. It is only needed if 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="AlphaIfDel_+3A_w">w</code></td>
<td>
<p>This parameter is an item weight vector. It is only required if 'x' is a data matrix.</p>
</td></tr>
</table>

<hr>
<h2 id='asymprior'>Prior distribution function with guessing parameter</h2><span id='topic+asymprior'></span>

<h3>Description</h3>

<p>Prior distribution function with guessing parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asymprior(c, alp, bet)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asymprior_+3A_c">c</code></td>
<td>
<p>guessing parameter</p>
</td></tr>
<tr><td><code id="asymprior_+3A_alp">alp</code></td>
<td>
<p>prior to be set</p>
</td></tr>
<tr><td><code id="asymprior_+3A_bet">bet</code></td>
<td>
<p>prior to be set</p>
</td></tr>
</table>

<hr>
<h2 id='Biclustering'>Biclustering and Ranklustering Analysis</h2><span id='topic+Biclustering'></span>

<h3>Description</h3>

<p>Performs biclustering, ranklustering, or their confirmatory variants on binary response data.
These methods simultaneously cluster both examinees and items into homogeneous groups
(or ordered ranks for ranklustering). The analysis reveals latent structures and patterns
in the data by creating a matrix with rows and columns arranged to highlight block structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Biclustering(
  U,
  ncls = 2,
  nfld = 2,
  Z = NULL,
  w = NULL,
  na = NULL,
  method = "B",
  conf = NULL,
  mic = FALSE,
  maxiter = 100,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Biclustering_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_ncls">ncls</code></td>
<td>
<p>Number of latent classes/ranks to identify (between 2 and 20).</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_nfld">nfld</code></td>
<td>
<p>Number of latent fields (item clusters) to identify.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_method">method</code></td>
<td>
<p>Analysis method to use (character string):
</p>

<ul>
<li><p> &quot;B&quot; or &quot;Biclustering&quot;: Standard biclustering (default)
</p>
</li>
<li><p> &quot;R&quot; or &quot;Ranklustering&quot;: Ranklustering with ordered class structure
</p>
</li></ul>
</td></tr>
<tr><td><code id="Biclustering_+3A_conf">conf</code></td>
<td>
<p>Confirmatory parameter for pre-specified field assignments. Can be either:
</p>

<ul>
<li><p> A vector with items and corresponding fields in sequence
</p>
</li>
<li><p> A field membership profile matrix (items × fields) with 0/1 values
</p>
</li>
<li><p> NULL (default) for exploratory analysis where field memberships are estimated
</p>
</li></ul>
</td></tr>
<tr><td><code id="Biclustering_+3A_mic">mic</code></td>
<td>
<p>Logical; if TRUE, forces Field Reference Profiles to be monotonically
increasing. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of EM algorithm iterations. Default is 100.</p>
</td></tr>
<tr><td><code id="Biclustering_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, displays progress during estimation. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Biclustering simultaneously clusters both rows (examinees) and columns (items) of a data matrix.
Unlike traditional clustering that groups either rows or columns, biclustering identifies
submatrices with similar patterns. Ranklustering is a variant that imposes an ordinal
structure on the classes, making it suitable for proficiency scaling.
</p>
<p>The algorithm uses an Expectation-Maximization approach to iteratively estimate:
</p>

<ol>
<li><p> Field membership of items (which items belong to which fields)
</p>
</li>
<li><p> Class/rank membership of examinees (which examinees belong to which classes)
</p>
</li>
<li><p> Field Reference Profiles (probability patterns for each field-class combination)
</p>
</li></ol>

<p>The confirmatory option allows for pre-specified field assignments, which is useful
when there is prior knowledge about item groupings or for testing hypothesized structures.
</p>


<h3>Value</h3>

<p>An object of class &quot;exametrika&quot; and &quot;Biclustering&quot; containing:
</p>

<dl>
<dt>model</dt><dd><p>Model type indicator (1 for biclustering, 2 for ranklustering)</p>
</dd>
<dt>mic</dt><dd><p>Logical value indicating whether monotonicity constraint was applied</p>
</dd>
<dt>testlength</dt><dd><p>Number of items in the test</p>
</dd>
<dt>nobs</dt><dd><p>Number of examinees in the dataset</p>
</dd>
<dt>Nclass</dt><dd><p>Number of latent classes/ranks specified</p>
</dd>
<dt>Nfield</dt><dd><p>Number of latent fields specified</p>
</dd>
<dt>N_Cycle</dt><dd><p>Number of EM iterations performed</p>
</dd>
<dt>LFD</dt><dd><p>Latent Field Distribution - counts of items assigned to each field</p>
</dd>
<dt>LRD/LCD</dt><dd><p>Latent Rank/Class Distribution - counts of examinees assigned to each class/rank</p>
</dd>
<dt>FRP</dt><dd><p>Field Reference Profile matrix - probability of correct response for each field-class combination</p>
</dd>
<dt>FRPIndex</dt><dd><p>Field Reference Profile indices including location parameters, slope parameters, and monotonicity indices</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile - expected score for examinees in each class/rank</p>
</dd>
<dt>CMD/RMD</dt><dd><p>Class/Rank Membership Distribution - sum of membership probabilities across examinees</p>
</dd>
<dt>FieldMembership</dt><dd><p>Matrix showing the probabilities of each item belonging to each field</p>
</dd>
<dt>ClassMembership</dt><dd><p>Matrix showing the probabilities of each examinee belonging to each class/rank</p>
</dd>
<dt>SmoothedMembership</dt><dd><p>Matrix of smoothed class membership probabilities after filtering</p>
</dd>
<dt>FieldEstimated</dt><dd><p>Vector of the most likely field assignments for each item</p>
</dd>
<dt>ClassEstimated</dt><dd><p>Vector of the most likely class/rank assignments for each examinee</p>
</dd>
<dt>Students</dt><dd><p>Data frame containing membership probabilities and classification information for each examinee</p>
</dd>
<dt>FieldAnalysis</dt><dd><p>Matrix showing field analysis results with item-level information</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Model fit indices for evaluating the quality of the clustering solution</p>
</dd>
<dt>SOACflg</dt><dd><p>Logical flag indicating whether Strongly Ordinal Alignment Condition is satisfied</p>
</dd>
<dt>WOACflg</dt><dd><p>Logical flag indicating whether Weakly Ordinal Alignment Condition is satisfied</p>
</dd>
</dl>



<h3>References</h3>

<p>Shojima, K. (2012). Biclustering of binary data matrices using bilinear models.
Behaviormetrika, 39(2), 161-178.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Perform Biclustering with Binary method (B)
# Analyze data with 5 fields and 6 classes
result.Bi &lt;- Biclustering(J35S515, nfld = 5, ncls = 6, method = "B")

# Perform Biclustering with Rank method (R)
# Store results for further analysis and visualization
result.Rank &lt;- Biclustering(J35S515, nfld = 5, ncls = 6, method = "R")

# Display the Bicluster Reference Matrix (BRM) as a heatmap
plot(result.Rank, type = "Array")

# Plot Field Reference Profiles (FRP) in a 2x3 grid
# Shows the probability patterns for each field
plot(result.Rank, type = "FRP", nc = 2, nr = 3)

# Plot Rank Membership Profiles (RMP) for students 1-9 in a 3x3 grid
# Shows posterior probability distribution of rank membership
plot(result.Rank, type = "RMP", students = 1:9, nc = 3, nr = 3)

# Example of confirmatory analysis with pre-specified fields
# Assign items 1-10 to field 1, 11-20 to field 2, etc.
field_assignments &lt;- c(rep(1, 10), rep(2, 10), rep(3, 15))
result.Conf &lt;- Biclustering(J35S515, nfld = 3, ncls = 5, conf = field_assignments)


</code></pre>

<hr>
<h2 id='BINET'>Bicluster Network Model</h2><span id='topic+BINET'></span>

<h3>Description</h3>

<p>Bicluster Network Model: BINET is a model that combines the Bayesian
network model and Biclustering. BINET is very similar to LDB and LDR.
The most significant difference is that in LDB, the nodes represent
the fields, whereas in BINET, they represent the class. BINET
explores the local dependency structure among latent classes at each
latent field, where each field is a locus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BINET(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  conf = NULL,
  ncls = NULL,
  nfld = NULL,
  g_list = NULL,
  adj_list = NULL,
  adj_file = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BINET_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="BINET_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="BINET_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="BINET_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="BINET_+3A_conf">conf</code></td>
<td>
<p>For the confirmatory parameter, you can input either a vector with
items and corresponding fields in sequence, or a field membership profile
matrix. In the case of the former, the field membership profile matrix will be generated internally.
When providing a membership profile matrix, it needs to be either matrix or data.frame.
The number of fields(nfld) will be overwrite to the number of columns of this matrix.</p>
</td></tr>
<tr><td><code id="BINET_+3A_ncls">ncls</code></td>
<td>
<p>number of classes</p>
</td></tr>
<tr><td><code id="BINET_+3A_nfld">nfld</code></td>
<td>
<p>number of fields</p>
</td></tr>
<tr><td><code id="BINET_+3A_g_list">g_list</code></td>
<td>
<p>A list compiling graph-type objects for each rank/class.</p>
</td></tr>
<tr><td><code id="BINET_+3A_adj_list">adj_list</code></td>
<td>
<p>A list compiling matrix-type adjacency matrices for each rank/class.</p>
</td></tr>
<tr><td><code id="BINET_+3A_adj_file">adj_file</code></td>
<td>
<p>A file detailing the relationships of the graph for each rank/class,
listed in the order of starting point, ending point, and rank(class).</p>
</td></tr>
<tr><td><code id="BINET_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>Nclass</dt><dd><p>Optimal number of classes.</p>
</dd>
<dt>Nfield</dt><dd><p>Optimal number of fields.</p>
</dd>
<dt>crr</dt><dd><p>Correct Response Rate</p>
</dd>
<dt>ItemLabel</dt><dd><p>Label of Items</p>
</dd>
<dt>FieldLabel</dt><dd><p>Label of Fields</p>
</dd>
<dt>all_adj</dt><dd><p>Integrated Adjacency matrix used to plot graph.</p>
</dd>
<dt>all_g</dt><dd><p>Integrated graph object used to plot graph.see also
<a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>adj_list</dt><dd><p>List of Adjacency matrix used in the model</p>
</dd>
<dt>params</dt><dd><p>A list of the estimated conditional probabilities.
It indicates which path was obtained from which parent node(class) to
which child node(class), held by <code>parent</code>, <code>child</code>, and <code>field</code>. The item
Items contained in the field is in <code>fld</code>. Named <code>chap</code> includes the
conditional correct response answer rate of the child node, while <code>pap</code>
contains the pass rate of the parent node.</p>
</dd>
<dt>PSRP</dt><dd><p>Response pattern by the students belonging to the parent
classes of Class c. A more comprehensible arrangement of <code>params.</code></p>
</dd>
<dt>LCD</dt><dd><p>Latent Class Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>LFD</dt><dd><p>Latent Field Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>CMD</dt><dd><p>Class Membership Distribution.</p>
</dd>
<dt>FRP</dt><dd><p>Marginal bicluster reference matrix.</p>
</dd>
<dt>FRPIndex</dt><dd><p>Index of FFP includes the item location parameters B and Beta,
the slope parameters A and Alpha, and the monotonicity indices C and Gamma.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile</p>
</dd>
<dt>LDPSR</dt><dd><p>A rearranged set of parameters for output. It includes
the field the items contained within that field, and the conditional
correct response rate of parent nodes(class) and child node(class).</p>
</dd>
<dt>FieldEstimated</dt><dd><p>Given vector which correspondence between items
and the fields.</p>
</dd>
<dt>Students</dt><dd><p>Rank Membership Profile matrix.The s-th row vector of <code class="reqn">\hat{M}_R</code>, <code class="reqn">\hat{m}_R</code>, is the
rank membership profile of Student s, namely the posterior probability distribution representing the student's
belonging to the respective latent classes. </p>
</dd>
<dt>NextStage</dt><dd><p>The next class that easiest for students to move to,
its membership probability, class-up odds, and the field required for
more.</p>
</dd>
<dt>MG_FitIndices</dt><dd><p>Multigroup as Null model.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>SM_FitIndices</dt><dd><p>Saturated Model as Null model.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Example: Bicluster Network Model (BINET)
# BINET combines Bayesian network model and Biclustering to explore
# local dependency structure among latent classes at each field

# Create field configuration vector based on field assignments
conf &lt;- c(
  1, 5, 5, 5, 9, 9, 6, 6, 6, 6, 2, 7, 7, 11, 11, 7, 7,
  12, 12, 12, 2, 2, 3, 3, 4, 4, 4, 8, 8, 12, 1, 1, 6, 10, 10
)

# Create edge data for network structure between classes
edges_data &lt;- data.frame(
  "From Class (Parent) &gt;&gt;&gt;" = c(
    1, 2, 3, 4, 5, 7, 2, 4, 6, 8, 10, 6, 6, 11, 8, 9, 12
  ),
  "&gt;&gt;&gt; To Class (Child)" = c(
    2, 4, 5, 5, 6, 11, 3, 7, 9, 12, 12, 10, 8, 12, 12, 11, 13
  ),
  "At Field (Locus)" = c(
    1, 2, 2, 3, 4, 4, 5, 5, 5, 5, 5, 7, 8, 8, 9, 9, 12
  )
)

# Save edge data to temporary CSV file
tmp_file &lt;- tempfile(fileext = ".csv")
write.csv(edges_data, file = tmp_file, row.names = FALSE)

# Fit Bicluster Network Model
result.BINET &lt;- BINET(
  J35S515,
  ncls = 13, # Maximum class number from edges (13)
  nfld = 12, # Maximum field number from conf (12)
  conf = conf, # Field configuration vector
  adj_file = tmp_file # Path to the CSV file
)

# Clean up temporary file
unlink(tmp_file)

# Display model results
print(result.BINET)

# Visualize different aspects of the model
plot(result.BINET, type = "Array") # Show bicluster structure
plot(result.BINET, type = "TRP") # Test Response Profile
plot(result.BINET, type = "LRD") # Latent Rank Distribution
plot(result.BINET,
  type = "RMP", # Rank Membership Profiles
  students = 1:9, nc = 3, nr = 3
)
plot(result.BINET,
  type = "FRP", # Field Reference Profiles
  nc = 3, nr = 2
)
plot(result.BINET,
  type = "LDPSR", # Locally Dependent Passing Student Rates
  nc = 3, nr = 2
)

</code></pre>

<hr>
<h2 id='BiserialCorrelation'>Biserial Correlation</h2><span id='topic+BiserialCorrelation'></span>

<h3>Description</h3>

<p>A biserial correlation is a correlation between dichotomous-ordinal and
continuous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BiserialCorrelation(i, t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BiserialCorrelation_+3A_i">i</code></td>
<td>
<p>i is a dichotomous-ordinal variable (0/1). x and y can also be the other way around.</p>
</td></tr>
<tr><td><code id="BiserialCorrelation_+3A_t">t</code></td>
<td>
<p>t is a continuous variable. x and y can also be the other way around.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The biserial correlation coefficient between the two variables.
</p>

<hr>
<h2 id='BitRespPtn'>Binary pattern maker</h2><span id='topic+BitRespPtn'></span>

<h3>Description</h3>

<p>Binary pattern maker
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BitRespPtn(n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BitRespPtn_+3A_n">n</code></td>
<td>
<p>decimal numbers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>if n &lt;- 1, return 0,1
if n &lt;- 2, return 00,01,10,11
and so on.
</p>


<h3>Value</h3>

<p>binary patterns
</p>

<hr>
<h2 id='BNM'>Bayesian Network Model</h2><span id='topic+BNM'></span>

<h3>Description</h3>

<p>performs Bayesian Network Model with specified graph structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BNM(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  g = NULL,
  adj_file = NULL,
  adj_matrix = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BNM_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="BNM_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="BNM_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="BNM_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="BNM_+3A_g">g</code></td>
<td>
<p>Specify a graph object suitable for the igraph class.</p>
</td></tr>
<tr><td><code id="BNM_+3A_adj_file">adj_file</code></td>
<td>
<p>specify CSV file where the graph structure is specified.</p>
</td></tr>
<tr><td><code id="BNM_+3A_adj_matrix">adj_matrix</code></td>
<td>
<p>specify adjacency matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a Bayesian network analysis on the relationships
between items. This corresponds to Chapter 8 of the text. It uses the igraph
package for graph visualization and checking the adjacency matrix.
You need to provide either a graph object or a CSV file where the graph
structure is specified.
</p>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>crr</dt><dd><p>correct response ratio</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>adj</dt><dd><p>Adjacency matrix</p>
</dd></dl>
<p>\
</p>
<dl>
<dt>param</dt><dd><p>Learned Parameters</p>
</dd>
<dt>CCRR_table</dt><dd><p>Correct Response Rate tables</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Create a Directed Acyclic Graph (DAG) structure for item relationships
# Each row represents a directed edge from one item to another
DAG &lt;-
  matrix(
    c(
      "Item01", "Item02", # Item01 influences Item02
      "Item02", "Item03", # Item02 influences Item03
      "Item02", "Item04", # Item02 influences Item04
      "Item03", "Item05", # Item03 influences Item05
      "Item04", "Item05" # Item04 influences Item05
    ),
    ncol = 2, byrow = TRUE
  )

# Convert the DAG matrix to an igraph object for network analysis
g &lt;- igraph::graph_from_data_frame(DAG)
g

# Create adjacency matrix from the graph
# Shows direct connections between items (1 for connection, 0 for no connection)
adj_mat &lt;- as.matrix(igraph::as_adjacency_matrix(g))
print(adj_mat)

# Fit Bayesian Network Model using the specified adjacency matrix
# Analyzes probabilistic relationships between items based on the graph structure
result.BNM &lt;- BNM(J5S10, adj_matrix = adj_mat)
result.BNM


</code></pre>

<hr>
<h2 id='calcFitIndices'>calc Fit Indices</h2><span id='topic+calcFitIndices'></span>

<h3>Description</h3>

<p>A general function that returns the model fit indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFitIndices(chi_A, chi_B, df_A, df_B, nobs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcFitIndices_+3A_chi_a">chi_A</code></td>
<td>
<p>chi-squares for this model</p>
</td></tr>
<tr><td><code id="calcFitIndices_+3A_chi_b">chi_B</code></td>
<td>
<p>chi-squares for compared model</p>
</td></tr>
<tr><td><code id="calcFitIndices_+3A_df_a">df_A</code></td>
<td>
<p>degrees of freedom for this model</p>
</td></tr>
<tr><td><code id="calcFitIndices_+3A_df_b">df_B</code></td>
<td>
<p>degrees of freedom for compared model</p>
</td></tr>
<tr><td><code id="calcFitIndices_+3A_nobs">nobs</code></td>
<td>
<p>number of observations for Information criteria</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>NFI</dt><dd><p>Normed Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RFI</dt><dd><p>Relative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>IFI</dt><dd><p>Incremental Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>TLI</dt><dd><p>Tucker-Lewis Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>CFI</dt><dd><p>Comparative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RMSEA</dt><dd><p>Root Mean Square Error of Approximation. Smaller values closer to 0.0 indicate a better fit.</p>
</dd>
<dt>AIC</dt><dd><p>Akaike Information Criterion. A lower value indicates a better fit.</p>
</dd>
<dt>CAIC</dt><dd><p>Consistent AIC.A lower value indicates a better fit.</p>
</dd>
<dt>BIC</dt><dd><p>Bayesian Information Criterion. A lower value indicates a better fit.</p>
</dd>
</dl>


<hr>
<h2 id='CCRR'>Conditional Correct Response Rate</h2><span id='topic+CCRR'></span><span id='topic+CCRR.default'></span><span id='topic+CCRR.binary'></span><span id='topic+CCRR.nominal'></span>

<h3>Description</h3>

<p>The conditional correct response rate (CCRR) represents the ratio of the students
who passed Item C (consequent item) to those who passed Item A (antecedent item).
This function is applicable only to binary response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCRR(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
CCRR(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
CCRR(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'nominal'
CCRR(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CCRR_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="CCRR_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="CCRR_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="CCRR_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of conditional correct response rates with exametrika class.
Each element (i,j) represents the probability of correctly answering item j
given that item i was answered correctly.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate CCRR using sample dataset J5S10
CCRR(J5S10)
</code></pre>

<hr>
<h2 id='crr'>Correct Response Rate</h2><span id='topic+crr'></span><span id='topic+crr.default'></span><span id='topic+crr.binary'></span>

<h3>Description</h3>

<p>The correct response rate (CRR) is one of the most basic and important
statistics for item analysis. This is an index of item difficulty and
a measure of how many students out of those who tried an item correctly
responded to it. This function is applicable only to binary response data.
</p>
<p>The CRR for each item is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">p_j = \frac{\sum_{i=1}^n z_{ij}u_{ij}}{\sum_{i=1}^n z_{ij}}</code>
</p>

<p>where <code class="reqn">z_{ij}</code> is the missing indicator and <code class="reqn">u_{ij}</code> is the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crr(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
crr(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
crr(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crr_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="crr_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="crr_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="crr_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of weighted correct response rates for each item.
Values range from 0 to 1, where higher values indicate easier items
(more students answered correctly).
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simple binary data
U &lt;- matrix(c(1, 0, 1, 1, 0, 1), ncol = 2)
crr(U)

# using sample datasaet
crr(J15S500)
</code></pre>

<hr>
<h2 id='CSR'>Conditional Selection Rate</h2><span id='topic+CSR'></span>

<h3>Description</h3>

<p>Calculate the Conditional Selection Rate (CSR) for polytomous data.
CSR measures the proportion of respondents who selected a specific category
in item K, given that they selected a particular category in item J.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CSR(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CSR_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="CSR_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="CSR_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="CSR_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a nested list structure CSR, where <code>CSR[[j]][[k]]</code> contains
a matrix of conditional probabilities. In this matrix, the element at row l and
column m represents P(K=m|J=l), which is the probability of selecting category m
for item K, given that category l was selected for item J.
</p>
<p>Mathematically, for each cell (l,m) in the <code>CSR[[j]][[k]]</code> matrix:
<code>CSR[[j]][[k]][l,m] = P(Item K = category m | Item J = category l)</code>
</p>
<p>This is calculated as the number of respondents who selected both category l for
item J and category m for item K, divided by the total number of respondents who
selected category l for item J.
</p>


<h3>Value</h3>

<p>A list of Joint Selection Rate matrices for each item pair.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate CSR using sample dataset J5S1000
CSR(J5S1000)

# Extract the conditional selection rates from item 1 to item 2
csr_1_2 &lt;- CSR(J5S1000)[[1]][[2]]
# This shows the probability of selecting each category in item 2
# given that a specific category was selected in item 1
</code></pre>

<hr>
<h2 id='CTT'>Classical Test Theory</h2><span id='topic+CTT'></span>

<h3>Description</h3>

<p>This function calculates the overall alpha and omega coefficients for
the given data matrix. It also computes the alpha coefficient for
each item, assuming that item is excluded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CTT(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CTT_+3A_u">U</code></td>
<td>
<p>U is a data matrix of the type matrix or data.frame.</p>
</td></tr>
<tr><td><code id="CTT_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="CTT_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="CTT_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of class c(&quot;exametrika&quot;, &quot;CTT&quot;) containing two data frames:
</p>

<dl>
<dt>Reliability</dt><dd><p>A data frame with overall reliability coefficients
(Alpha and Omega) calculated using different correlation matrices
(Covariance, Phi, and Tetrachoric)</p>
</dd>
<dt>ReliabilityExcludingItem</dt><dd><p>A data frame showing alpha coefficients
when each item is excluded, calculated using different correlation matrices</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# using sample dataset
CTT(J15S500)

</code></pre>

<hr>
<h2 id='dataFormat'>dataFormat</h2><span id='topic+dataFormat'></span>

<h3>Description</h3>

<p>This function serves the role of formatting the data prior to the analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataFormat(
  data,
  na = NULL,
  id = 1,
  Z = NULL,
  w = NULL,
  response.type = NULL,
  CA = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dataFormat_+3A_data">data</code></td>
<td>
<p>is a data matrix of the type matrix or data.frame.</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_id">id</code></td>
<td>
<p>id indicates the column number containing the examinee ID. The default is 1.
If no ID column is specified or if the specified column contains response data,
sequential IDs (&quot;Student1&quot;, &quot;Student2&quot;, etc.) will be generated and all columns
will be treated as response data.</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_response.type">response.type</code></td>
<td>
<p>Character string specifying the type of response data:
&quot;binary&quot; for dichotomous data,
&quot;ordinal&quot; for ordered polytomous data,
&quot;rated&quot; for polytomous data with correct answers,
&quot;nominal&quot; for unordered polytomous data.
If NULL (default), the type is automatically detected.</p>
</td></tr>
<tr><td><code id="dataFormat_+3A_ca">CA</code></td>
<td>
<p>A numeric vector specifying the correct answers for rated polytomous data.
Required when response.type is &quot;rated&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>U</dt><dd><p>For binary response data. A matrix with rows representing the sample size and columns
representing the number of items, where elements are either 0 or 1. <code class="reqn">u_{ij}=1</code> indicates
that student i correctly answered item j, while <code class="reqn">u_{ij}=0</code> means that student i answered
item j incorrectly.</p>
</dd>
<dt>Q</dt><dd><p>For polytomous response data. A matrix with rows representing the sample size and columns
representing the number of items, where elements are non-negative integers. When input data is
in factor format, the factor levels are converted to consecutive integers starting from 1.</p>
</dd>
<dt>ID</dt><dd><p>The ID label given by the designated column or function.</p>
</dd>
<dt>ItemLabel</dt><dd><p>The item names given by the provided column names or function.</p>
</dd>
<dt>Z</dt><dd><p>Missing indicator matrix. <code class="reqn">z_{ij}=1</code> indicates that item j is presented to Student i,
while <code class="reqn">z_{ij}=0</code> indicates item j is NOT presented to Student i.
If the data contains NA values, -1 is assigned.</p>
</dd>
<dt>w</dt><dd><p>Item weight vector</p>
</dd>
<dt>response.type</dt><dd><p>Character string indicating the type of response data:
&quot;binary&quot;, &quot;ordinal&quot;, &quot;rated&quot;, or &quot;nominal&quot;</p>
</dd>
<dt>CategoryLabel</dt><dd><p>List containing the original factor labels when polytomous responses
are provided as factors. NULL if no factor data is present.</p>
</dd>
<dt>categories</dt><dd><p>Numeric vector containing the number of response categories for each item.</p>
</dd>
<dt>CA</dt><dd><p>For rated polytomous data, a numeric vector of correct answers. NULL for other types.</p>
</dd>
</dl>


<hr>
<h2 id='Dimensionality'>Dimensionality</h2><span id='topic+Dimensionality'></span><span id='topic+Dimensionality.default'></span><span id='topic+Dimensionality.binary'></span><span id='topic+Dimensionality.rated'></span><span id='topic+Dimensionality.ordinal'></span>

<h3>Description</h3>

<p>The dimensionality is the number of components
the test is measuring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dimensionality(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
Dimensionality(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
Dimensionality(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'rated'
Dimensionality(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
Dimensionality(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Dimensionality_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="Dimensionality_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="Dimensionality_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="Dimensionality_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of class c(&quot;exametrika&quot;, &quot;Dimensionality&quot;) containing:
</p>

<dl>
<dt>Component</dt><dd><p>Sequence of component numbers</p>
</dd>
<dt>Eigenvalue</dt><dd><p>Eigenvalues of the tetrachoric correlation matrix</p>
</dd>
<dt>PerOfVar</dt><dd><p>Percentage of variance explained by each component</p>
</dd>
<dt>CumOfPer</dt><dd><p>Cumulative percentage of variance explained</p>
</dd>
</dl>


<hr>
<h2 id='generate_category_labels'>Generate category labels for response data</h2><span id='topic+generate_category_labels'></span>

<h3>Description</h3>

<p>Generate category labels for response data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_category_labels(data_column, item_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_category_labels_+3A_data_column">data_column</code></td>
<td>
<p>A vector containing response data for a single item</p>
</td></tr>
<tr><td><code id="generate_category_labels_+3A_item_name">item_name</code></td>
<td>
<p>Character string of the item name</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the input is a factor, returns its levels.
Otherwise, generates labels in the format &quot;Item name-Category-N&quot;
</p>


<h3>Value</h3>

<p>A character vector of category labels
</p>

<hr>
<h2 id='generate_start_values'>generate start values for optimize</h2><span id='topic+generate_start_values'></span>

<h3>Description</h3>

<p>generate start values for optimize
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_start_values(tmp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_start_values_+3A_tmp">tmp</code></td>
<td>
<p>dataset</p>
</td></tr>
</table>

<hr>
<h2 id='GRM'>Graded Response Model (GRM)</h2><span id='topic+GRM'></span>

<h3>Description</h3>

<p>Implements Samejima's (1969) Graded Response Model (GRM), which is an Item Response Theory
model for ordered categorical response data. The model estimates discrimination parameters
and category threshold parameters for each item. It is widely used in psychological measurement,
educational assessment, and other fields that deal with multi-step rating scales.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GRM(U, na = NULL, Z = NULL, w = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GRM_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class using the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="GRM_+3A_na">na</code></td>
<td>
<p>Specifies numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="GRM_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. 1 indicates observed values, 0 indicates missing values.</p>
</td></tr>
<tr><td><code id="GRM_+3A_w">w</code></td>
<td>
<p>Item weight vector</p>
</td></tr>
<tr><td><code id="GRM_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, shows progress of iterations (default: TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class &quot;exametrika&quot; and &quot;GRM&quot; containing the following elements:
</p>

<dl>
<dt>testlength</dt><dd><p>Length of the test (number of items)</p>
</dd>
<dt>nobs</dt><dd><p>Sample size (number of rows in the dataset)</p>
</dd>
<dt>params</dt><dd><p>Matrix containing the estimated item parameters</p>
</dd>
<dt>EAP</dt><dd><p>Ability parameters of examinees estimated by EAP method</p>
</dd>
<dt>MAP</dt><dd><p>Ability parameters of examinees estimated by MAP method</p>
</dd>
<dt>PSD</dt><dd><p>Posterior standard deviation of the ability parameters</p>
</dd>
<dt>ItemFitIndices</dt><dd><p>Fit indices for each item. See also <code><a href="#topic+ItemFit">ItemFit</a></code></p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit indices for the test. See also <code><a href="#topic+TestFit">TestFit</a></code></p>
</dd>
</dl>



<h3>References</h3>

<p>Samejima, F. (1969). Estimation of latent ability using a response pattern of graded scores.
Psychometrika Monograph Supplement, 34(4, Pt. 2), 1-100.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Apply GRM to example data
result &lt;- GRM(J5S1000)
print(result)
plot(result, type = "IRF")
plot(result, type = "IIF")
plot(result, type = "TIF")

</code></pre>

<hr>
<h2 id='grm_cumprob'>cumulative probability of GRM</h2><span id='topic+grm_cumprob'></span>

<h3>Description</h3>

<p>cumulative probability of GRM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grm_cumprob(theta, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grm_cumprob_+3A_theta">theta</code></td>
<td>
<p>latent score of subject</p>
</td></tr>
<tr><td><code id="grm_cumprob_+3A_a">a</code></td>
<td>
<p>discriminant parameter of IRF</p>
</td></tr>
<tr><td><code id="grm_cumprob_+3A_b">b</code></td>
<td>
<p>difficulty parameter of IRF</p>
</td></tr>
</table>

<hr>
<h2 id='grm_iif'>Item Information Function for GRM</h2><span id='topic+grm_iif'></span>

<h3>Description</h3>

<p>Calculates the value of the Item Information Function for the Graded Response Model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grm_iif(theta, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grm_iif_+3A_theta">theta</code></td>
<td>
<p>Latent trait value of the subject</p>
</td></tr>
<tr><td><code id="grm_iif_+3A_a">a</code></td>
<td>
<p>Discrimination parameter of IRF</p>
</td></tr>
<tr><td><code id="grm_iif_+3A_b">b</code></td>
<td>
<p>Vector of difficulty parameters (thresholds) of IRF</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of the Item Information Function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example for an item with 3 categories
a &lt;- 1.5
b &lt;- c(-1.0, 1.0)
thetas &lt;- seq(-3, 3, by = 0.1)
info &lt;- sapply(thetas, function(t) grm_iif(t, a, b))
plot(thetas, info, type = "l", xlab = "Theta", ylab = "Information")

## End(Not run)
</code></pre>

<hr>
<h2 id='grm_prob'>Probability function for GRM</h2><span id='topic+grm_prob'></span>

<h3>Description</h3>

<p>Calculates the probability of selecting each category given a latent trait value and item parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grm_prob(theta, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grm_prob_+3A_theta">theta</code></td>
<td>
<p>Latent trait value of the subject</p>
</td></tr>
<tr><td><code id="grm_prob_+3A_a">a</code></td>
<td>
<p>Discrimination parameter of IRF</p>
</td></tr>
<tr><td><code id="grm_prob_+3A_b">b</code></td>
<td>
<p>Vector of difficulty parameters (thresholds) of IRF</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of category selection probabilities
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example for an item with 3 categories
a &lt;- 1.5
b &lt;- c(-1.0, 1.0)
theta &lt;- 0
grm_prob(theta, a, b)

## End(Not run)
</code></pre>

<hr>
<h2 id='IIF2PLM'>IIF for 2PLM</h2><span id='topic+IIF2PLM'></span>

<h3>Description</h3>

<p>Item Information Function for 2PLM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IIF2PLM(a, b, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IIF2PLM_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="IIF2PLM_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="IIF2PLM_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector representing the item information at each ability
level theta. The information is calculated as:
<code class="reqn">I(\theta) = a^2P(\theta)(1-P(\theta))</code>
</p>

<hr>
<h2 id='IIF3PLM'>IIF for 3PLM</h2><span id='topic+IIF3PLM'></span>

<h3>Description</h3>

<p>Item Information Function for 3PLM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IIF3PLM(a, b, c, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IIF3PLM_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="IIF3PLM_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="IIF3PLM_+3A_c">c</code></td>
<td>
<p>lower asymptote parameter</p>
</td></tr>
<tr><td><code id="IIF3PLM_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector representing the item information at each ability
level theta. The information is calculated as:
<code class="reqn">I(\theta) = \frac{a^2(1-P(\theta))(P(\theta)-c)^2}{(1-c)^2P(\theta)}</code>
</p>

<hr>
<h2 id='InterItemAnalysis'>Inter-Item Analysis for Psychometric Data</h2><span id='topic+InterItemAnalysis'></span>

<h3>Description</h3>

<p>Calculates various relationship metrics between pairs of items in test data. This analysis
helps identify item interdependencies, content overlaps, and potential local dependence.
For binary data, metrics include joint response rates, conditional probabilities,
and several correlation measures. For ordinal/rated data, appropriate correlation
measures are calculated.
</p>
<p>The following metrics are calculated for binary data:
</p>

<ul>
<li><p> JSS: Joint Sample Size - number of examinees responding to both items
</p>
</li>
<li><p> JCRR: Joint Correct Response Rate - proportion of examinees answering both items correctly
</p>
</li>
<li><p> CCRR: Conditional Correct Response Rate - probability of answering one item correctly
given a correct response to another item
</p>
</li>
<li><p> IL: Item Lift - ratio of joint correct response rate to the product of marginal rates
</p>
</li>
<li><p> MI: Mutual Information - measure of mutual dependence between items
</p>
</li>
<li><p> Phi: Phi Coefficient - correlation coefficient for binary variables
</p>
</li>
<li><p> Tetrachoric: Tetrachoric Correlation - estimate of Pearson correlation for underlying
continuous variables
</p>
</li></ul>

<p>For ordinal/rated data, the function calculates:
</p>

<ul>
<li><p> JSS: Joint Sample Size
</p>
</li>
<li><p> JSR: Joint Selection Rate
</p>
</li>
<li><p> CSR: Conditional Selection Rate
</p>
</li>
<li><p> MI: Mutual Information
</p>
</li>
<li><p> Polychoric: Polychoric Correlation - extension of tetrachoric correlation for ordinal data
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>InterItemAnalysis(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="InterItemAnalysis_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="InterItemAnalysis_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="InterItemAnalysis_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="InterItemAnalysis_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function automatically detects the data type and applies appropriate analysis methods:
</p>

<ul>
<li><p> For binary data: Calculates tetrachoric correlations and related statistics
</p>
</li>
<li><p> For ordinal/rated data: Calculates polychoric correlations and related statistics
</p>
</li>
<li><p> For nominal data: Returns an error (not supported)
</p>
</li></ul>

<p>Inter-item analysis is useful for:
</p>

<ul>
<li><p> Identifying groups of highly related items
</p>
</li>
<li><p> Detecting local dependence between items
</p>
</li>
<li><p> Evaluating test dimensionality
</p>
</li>
<li><p> Informing item selection and test construction
</p>
</li></ul>



<h3>Value</h3>

<p>For binary data, an object of class &quot;exametrika&quot; and &quot;IIAnalysis&quot; containing:
</p>

<dl>
<dt>JSS</dt><dd><p>Joint Sample Size matrix - N(i,j) shows number of examinees who responded to both items i and j</p>
</dd>
<dt>JCRR</dt><dd><p>Joint Correct Response Rate matrix - P(Xi=1, Xj=1) shows probability of correct responses to both items</p>
</dd>
<dt>CCRR</dt><dd><p>Conditional Correct Response Rate matrix - P(Xi=1|Xj=1) shows probability of correct response to item i
given correct response to item j</p>
</dd>
<dt>IL</dt><dd><p>Item Lift matrix - P(Xi=1, Xj=1)/(P(Xi=1)*P(Xj=1)) measures association strength</p>
</dd>
<dt>MI</dt><dd><p>Mutual Information matrix - measures information shared between items</p>
</dd>
<dt>Phi</dt><dd><p>Phi Coefficient matrix - correlation coefficient between binary variables</p>
</dd>
<dt>Tetrachoric</dt><dd><p>Tetrachoric Correlation matrix - correlation between underlying continuous variables</p>
</dd>
</dl>

<p>For ordinal/rated data, an object of class &quot;exametrika&quot; and &quot;IIAnalysis.ordinal&quot; containing:
</p>

<dl>
<dt>JSS</dt><dd><p>Joint Sample Size matrix</p>
</dd>
<dt>JSR</dt><dd><p>Joint Selection Rate matrix - frequencies of joint category selections</p>
</dd>
<dt>CSR</dt><dd><p>Conditional Selection Rate matrix - probabilities of response categories conditional on other items</p>
</dd>
<dt>MI</dt><dd><p>Mutual Information matrix</p>
</dd>
<dt>Polychoric</dt><dd><p>Polychoric Correlation matrix - correlations between underlying continuous variables</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+dataFormat">dataFormat</a></code> for data preparation, <code><a href="#topic+CTT">CTT</a></code> for
Classical Test Theory analysis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Basic usage with binary data
ii_analysis &lt;- InterItemAnalysis(J15S500)

# View joint sample sizes
head(ii_analysis$JSS)

# View tetrachoric correlations
head(ii_analysis$Tetrachoric)

# Find pairs of items with high mutual information (potential local dependence)
high_MI &lt;- which(ii_analysis$MI &gt; 0.2 &amp; upper.tri(ii_analysis$MI), arr.ind = TRUE)
if (nrow(high_MI) &gt; 0) {
  print("Item pairs with high mutual information:")
  print(high_MI)
}

# Example with ordinal data
ordinal_analysis &lt;- InterItemAnalysis(J15S3810)

# View polychoric correlations for ordinal data
head(ordinal_analysis$Polychoric)


</code></pre>

<hr>
<h2 id='IRM'>Infinite Relational Model</h2><span id='topic+IRM'></span>

<h3>Description</h3>

<p>The purpose of this method is to find
the optimal number of classes C, and optimal number of
fields F. It can be found in a single run of the analysis, but
it takes a long computation time when the sample size S is large.
In addition, this method incorporates the Chinese restaurant process
and Gibbs sampling. In detail, See Section 7.8 in Shojima(2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRM(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  gamma_c = 1,
  gamma_f = 1,
  max_iter = 100,
  stable_limit = 5,
  minSize = 20,
  EM_limit = 20,
  seed = 123,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IRM_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="IRM_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="IRM_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="IRM_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="IRM_+3A_gamma_c">gamma_c</code></td>
<td>
<p><code class="reqn">\gamma_C</code> is the hyperparameter of the CRP and represents the
attractiveness of a new Class. As <code class="reqn">\gamma_C</code> increases, the student is more likely
to be seated at a vacant class. The default is 1.</p>
</td></tr>
<tr><td><code id="IRM_+3A_gamma_f">gamma_f</code></td>
<td>
<p><code class="reqn">\gamma_F</code> is the hyperparameter of the CRP and represents the
attractiveness of a new Field. The greater this value it more likely to be classified
in the new field. The default is 1.</p>
</td></tr>
<tr><td><code id="IRM_+3A_max_iter">max_iter</code></td>
<td>
<p>A maximum iteration number of IRM process. The default is 100.</p>
</td></tr>
<tr><td><code id="IRM_+3A_stable_limit">stable_limit</code></td>
<td>
<p>The IRM process exits the loop when the FRM stabilizes and no longer
changes significantly. This option sets the maximum number of stable iterations,
with a default of 5.</p>
</td></tr>
<tr><td><code id="IRM_+3A_minsize">minSize</code></td>
<td>
<p>A value used for readjusting the number of classes.If the size of each
class is less than <code>minSize</code>, the number of classes will be reduced. Note that this
under limit of size is not used for either all correct or all incorrect class.</p>
</td></tr>
<tr><td><code id="IRM_+3A_em_limit">EM_limit</code></td>
<td>
<p>After IRM process, resizing the number of classes process will starts.
This process using EM algorithm,<code>EM_limit</code> is the maximum number of iteration with
default of 20.</p>
</td></tr>
<tr><td><code id="IRM_+3A_seed">seed</code></td>
<td>
<p>seed value for random numbers.</p>
</td></tr>
<tr><td><code id="IRM_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>Nclass</dt><dd><p>Optimal number of classes.</p>
</dd>
<dt>Nfield</dt><dd><p>Optimal number of fields.</p>
</dd>
<dt>BRM</dt><dd><p>Bicluster Reference Matrix</p>
</dd>
<dt>FRP</dt><dd><p>Field Reference Profile</p>
</dd>
<dt>FRPIndex</dt><dd><p>Index of FFP includes the item location parameters B and Beta,
the slope parameters A and Alpha, and the monotonicity indices C and Gamma.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile</p>
</dd>
<dt>FMP</dt><dd><p>Field Membership Profile</p>
</dd>
<dt>Students</dt><dd><p>Rank Membership Profile matrix.The s-th row vector of <code class="reqn">\hat{M}_R</code>, <code class="reqn">\hat{m}_R</code>, is the
rank membership profile of Student s, namely the posterior probability distribution representing the student's
belonging to the respective latent classes. It also includes the rank with the maximum estimated membership probability,
as well as the rank-up odds and rank-down odds.</p>
</dd>
<dt>LRD</dt><dd><p>Latent Rank Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>LFD</dt><dd><p>Latent Field Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>RMD</dt><dd><p>Rank Membership Distribution.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Fit an Infinite Relational Model (IRM) to determine optimal number of classes and fields
# gamma_c and gamma_f are concentration parameters for the Chinese Restaurant Process
result.IRM &lt;- IRM(J35S515, gamma_c = 1, gamma_f = 1, verbose = TRUE)

# Display the Bicluster Reference Matrix (BRM) as a heatmap
# Shows the discovered clustering structure of items and students
plot(result.IRM, type = "Array")

# Plot Field Reference Profiles (FRP) in a 3-column grid
# Shows the probability patterns for each automatically determined field
plot(result.IRM, type = "FRP", nc = 3)

# Plot Test Reference Profile (TRP)
# Shows the overall response pattern across all fields
plot(result.IRM, type = "TRP")


</code></pre>

<hr>
<h2 id='IRT'>Estimating Item parameters using EM algorithm</h2><span id='topic+IRT'></span>

<h3>Description</h3>

<p>A function for estimating item parameters using the EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IRT(U, model = 2, na = NULL, Z = NULL, w = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IRT_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="IRT_+3A_model">model</code></td>
<td>
<p>This argument takes the number of item parameters to be
estimated in the logistic model. It is limited to values 2, 3, or 4.</p>
</td></tr>
<tr><td><code id="IRT_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="IRT_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="IRT_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="IRT_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, shows progress of iterations (default: TRUE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Apply the 2, 3, and 4 parameter logistic models to estimate the item and subject populations.
The 4PL model can be described as follows.
</p>
<p style="text-align: center;"><code class="reqn">P(\theta,a_j,b_j,c_j,d_j)= c_j + \frac{d_j -c_j}{1+exp\{-a_j(\theta - b_j)\}}</code>
</p>

<p><code class="reqn">a_j, b_j, c_j</code>, and <code class="reqn">d_j</code> are parameters related to item j, and are parameters that
adjust the logistic curve.
<code class="reqn">a_j</code> is called the slope parameter, <code class="reqn">b_j</code> is the location, <code class="reqn">c_j</code> is the lower asymptote,
and <code class="reqn">d_j</code> is the upper asymptote parameter.
The model includes lower models, and among the 4PL models, the case where <code class="reqn">d=1</code> is the 3PL model,
and among the 3PL models, the case where <code class="reqn">c=0</code> is the 2PL model.
</p>


<h3>Value</h3>


<dl>
<dt>model</dt><dd><p>number of item parameters you set.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>params</dt><dd><p>Matrix containing the estimated item parameters</p>
</dd>
<dt>Q3mat</dt><dd><p>Q3-matrix developed by Yen(1984)</p>
</dd>
<dt>itemPSD</dt><dd><p>Posterior standard deviation of the item parameters</p>
</dd>
<dt>ability</dt><dd><p>Estimated parameters of students ability</p>
</dd>
<dt>ItemFitIndices</dt><dd><p>Fit index for each item.See also <code><a href="#topic+ItemFit">ItemFit</a></code></p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <code><a href="#topic+TestFit">TestFit</a></code></p>
</dd>
</dl>



<h3>References</h3>

<p>Yen, W. M. (1984) Applied Psychological Measurement, 8, 125-145.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Fit a 3-parameter IRT model to the sample dataset
result.IRT &lt;- IRT(J15S500, model = 3)

# Display the first few rows of estimated student abilities
head(result.IRT$ability)

# Plot Item Response Function (IRF) for items 1-6 in a 2x3 grid
plot(result.IRT, type = "IRF", items = 1:6, nc = 2, nr = 3)

# Plot Item Information Function (IIF) for items 1-6 in a 2x3 grid
plot(result.IRT, type = "IIF", items = 1:6, nc = 2, nr = 3)

# Plot the Test Information Function (TIF) for all items
plot(result.IRT, type = "TIF")

</code></pre>

<hr>
<h2 id='ITBiserial'>Item-Total Biserial Correlation</h2><span id='topic+ITBiserial'></span><span id='topic+ITBiserial.default'></span><span id='topic+ITBiserial.binary'></span>

<h3>Description</h3>

<p>The Item-Total Biserial Correlation computes the biserial correlation
between each item and the total score. This function is applicable only
to binary response data.
</p>
<p>This correlation provides a measure of item discrimination, indicating how well
each item distinguishes between high and low performing examinees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ITBiserial(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ITBiserial(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ITBiserial(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ITBiserial_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ITBiserial_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ITBiserial_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ITBiserial_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of item-total biserial correlations. Values range
from -1 to 1, where:
</p>

<ul>
<li><p> Values near 1: Strong positive discrimination
</p>
</li>
<li><p> Values near 0: No discrimination
</p>
</li>
<li><p> Negative values: Potential item problems
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>The biserial correlation is generally preferred over the point-biserial
correlation when the dichotomization is artificial (i.e., when the underlying
trait is continuous).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
ITBiserial(J15S500)
</code></pre>

<hr>
<h2 id='ItemEntropy'>Item Entropy</h2><span id='topic+ItemEntropy'></span><span id='topic+ItemEntropy.default'></span><span id='topic+ItemEntropy.binary'></span><span id='topic+ItemEntropy.ordinal'></span>

<h3>Description</h3>

<p>The item entropy is an indicator of the variability or randomness
of the responses. This function is applicable only to binary response data.
</p>
<p>The entropy value represents the uncertainty or information content of the
response pattern for each item, measured in bits. Maximum entropy (1 bit)
occurs when correct and incorrect responses are equally likely (p = 0.5).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemEntropy(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ItemEntropy(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemEntropy(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
ItemEntropy(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemEntropy_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemEntropy_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemEntropy_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemEntropy_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The item entropy is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">e_j = -p_j\log_2p_j-(1-p_j)\log_2(1-p_j)</code>
</p>

<p>where <code class="reqn">p_j</code> is the correct response rate for item j.
</p>
<p>The entropy value has the following properties:
</p>

<ul>
<li><p> Maximum value of 1 bit when p = 0.5 (most uncertainty)
</p>
</li>
<li><p> Minimum value of 0 bits when p = 0 or 1 (no uncertainty)
</p>
</li>
<li><p> Higher values indicate more balanced response patterns
</p>
</li>
<li><p> Lower values indicate more predictable response patterns
</p>
</li></ul>



<h3>Value</h3>

<p>A numeric vector of entropy values for each item, measured in bits.
Values range from 0 to 1, where:
</p>

<ul>
<li><p> 1: maximum uncertainty (p = 0.5)
</p>
</li>
<li><p> 0: complete certainty (p = 0 or 1)
</p>
</li>
<li><p> Values near 1 indicate items with balanced response patterns
</p>
</li>
<li><p> Values near 0 indicate items with extreme response patterns
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
ItemEntropy(J5S10)
</code></pre>

<hr>
<h2 id='ItemFit'>Model Fit Functions for Items</h2><span id='topic+ItemFit'></span>

<h3>Description</h3>

<p>A general function that returns the model fit indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemFit(U, Z, ell_A, nparam)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemFit_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="ItemFit_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="ItemFit_+3A_ell_a">ell_A</code></td>
<td>
<p>log likelihood of this model</p>
</td></tr>
<tr><td><code id="ItemFit_+3A_nparam">nparam</code></td>
<td>
<p>number of parameters for this model</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>model_log_like</dt><dd><p>log likelihood of analysis model</p>
</dd>
<dt>bench_log_like</dt><dd><p>log likelihood of benchmark model</p>
</dd>
<dt>null_log_like</dt><dd><p>log likelihood of null model</p>
</dd>
<dt>model_Chi_sq</dt><dd><p>Chi-Square statistics for analysis model</p>
</dd>
<dt>null_Chi_sq</dt><dd><p>Chi-Square statistics for null model</p>
</dd>
<dt>model_df</dt><dd><p>degrees of freedom of analysis model</p>
</dd>
<dt>null_df</dt><dd><p>degrees of freedom of null model</p>
</dd>
<dt>NFI</dt><dd><p>Normed Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RFI</dt><dd><p>Relative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>IFI</dt><dd><p>Incremental Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>TLI</dt><dd><p>Tucker-Lewis Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>CFI</dt><dd><p>Comparative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RMSEA</dt><dd><p>Root Mean Square Error of Approximation. Smaller values closer to 0.0 indicate a better fit.</p>
</dd>
<dt>AIC</dt><dd><p>Akaike Information Criterion. A lower value indicates a better fit.</p>
</dd>
<dt>CAIC</dt><dd><p>Consistent AIC.A lower value indicates a better fit.</p>
</dd>
<dt>BIC</dt><dd><p>Bayesian Information Criterion. A lower value indicates a better fit.</p>
</dd>
</dl>


<hr>
<h2 id='ItemInformationFunc'>IIF for 4PLM</h2><span id='topic+ItemInformationFunc'></span>

<h3>Description</h3>

<p>Item Information Function for 4PLM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemInformationFunc(a = 1, b, c = 0, d = 1, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemInformationFunc_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="ItemInformationFunc_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="ItemInformationFunc_+3A_c">c</code></td>
<td>
<p>lower asymptote parameter</p>
</td></tr>
<tr><td><code id="ItemInformationFunc_+3A_d">d</code></td>
<td>
<p>upper asymptote parameter</p>
</td></tr>
<tr><td><code id="ItemInformationFunc_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector representing the item information at each ability
level theta. The information is calculated based on the first derivative of
the log-likelihood of the 4PL model with respect to theta.
</p>

<hr>
<h2 id='ItemLift'>Item Lift</h2><span id='topic+ItemLift'></span><span id='topic+ItemLift.default'></span><span id='topic+ItemLift.binary'></span>

<h3>Description</h3>

<p>The lift is a commonly used index in a POS data analysis.
The item lift of Item k to Item j is defined as follow:
<code class="reqn"> l_{jk} = \frac{p_{k\mid j}}{p_k} </code>
This function is applicable only to binary response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemLift(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ItemLift(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemLift(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemLift_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemLift_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemLift_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemLift_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of item lift values with exametrika class.
Each element (j,k) represents the lift value of item k given item j,
which indicates how much more likely item k is to be correct given that
item j was answered correctly.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>References</h3>

<p>Brin, S., Motwani, R., Ullman, J., &amp; Tsur, S. (1997). Dynamic itemset counting and
implication rules for market basket data. In Proceedings of ACM SIGMOD International Conference
on Management of Data (pp. 255–264). https://dl.acm.org/doi/10.1145/253262.253325
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate ItemLift using sample dataset J5S10
ItemLift(J5S10)
</code></pre>

<hr>
<h2 id='ItemOdds'>Item Odds</h2><span id='topic+ItemOdds'></span><span id='topic+ItemOdds.default'></span><span id='topic+ItemOdds.binary'></span>

<h3>Description</h3>

<p>Item Odds are defined as the ratio of Correct Response Rate to
Incorrect Response Rate:
</p>
<p style="text-align: center;"><code class="reqn">O_j = \frac{p_j}{1-p_j}</code>
</p>

<p>where <code class="reqn">p_j</code> is the correct response rate for item j.
This function is applicable only to binary response data.
</p>
<p>The odds value represents how many times more likely a correct response is
compared to an incorrect response. For example, an odds of 2 means students
are twice as likely to answer correctly as incorrectly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemOdds(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ItemOdds(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemOdds(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemOdds_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemOdds_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemOdds_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemOdds_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of odds values for each item. Values range from 0 to infinity,
where:
</p>

<ul>
<li><p> odds &gt; 1: correct response more likely than incorrect
</p>
</li>
<li><p> odds = 1: equally likely
</p>
</li>
<li><p> odds &lt; 1: incorrect response more likely than correct
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
ItemOdds(J5S10)
</code></pre>

<hr>
<h2 id='ItemReport'>Generate Item Report for Non-Binary Test Data</h2><span id='topic+ItemReport'></span>

<h3>Description</h3>

<p>Calculates item-level statistics for non-binary test data, including response rates,
basic descriptive statistics, and item-total correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemReport(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemReport_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemReport_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values</p>
</td></tr>
<tr><td><code id="ItemReport_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemReport_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended for non-binary (ordinal or rated) response data. It provides
detailed statistics for each item in the test, focusing on response patterns and
the relationship between individual items and overall test performance.
If binary data is provided, an error message will be displayed.
</p>


<h3>Value</h3>

<p>An object of class &quot;exametrika&quot; and &quot;QitemStatistics&quot; containing:
</p>

<dl>
<dt>ItemLabel</dt><dd><p>Labels identifying each item</p>
</dd>
<dt>Obs</dt><dd><p>Number of valid responses for each item</p>
</dd>
<dt>ObsRatio</dt><dd><p>Proportion of valid responses for each item (range: 0-1)</p>
</dd>
<dt>ItemMean</dt><dd><p>Mean score of each item</p>
</dd>
<dt>ItemSD</dt><dd><p>Standard deviation of each item score</p>
</dd>
<dt>ItemCORR</dt><dd><p>Item-total correlation coefficients - correlation between
item scores and total test scores</p>
</dd>
<dt>ItemCORR_R</dt><dd><p>Corrected item-total correlation coefficients - correlation between
item scores and total test scores excluding the target item</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate item report for sample ordinal data
item_stats &lt;- ItemReport(J15S3810)

# View first few rows of the item report
head(item_stats)

# Example with rated data including custom missing value indicator
item_stats2 &lt;- ItemReport(J35S5000, na = -99)


</code></pre>

<hr>
<h2 id='ItemStatistics'>Simple Item Statistics</h2><span id='topic+ItemStatistics'></span><span id='topic+ItemStatistics.default'></span><span id='topic+ItemStatistics.binary'></span><span id='topic+ItemStatistics.ordinal'></span>

<h3>Description</h3>

<p>This function calculates statistics for each item, with different metrics available
depending on the data type (binary, ordinal, or rated).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemStatistics(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ItemStatistics(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemStatistics(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
ItemStatistics(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemStatistics_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemStatistics_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemStatistics_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemStatistics_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For binary data:
</p>

<dl>
<dt>ItemLabel</dt><dd><p>Label identifying each item</p>
</dd>
<dt>NR</dt><dd><p>Number of Respondents for each item</p>
</dd>
<dt>CRR</dt><dd><p>Correct Response Rate denoted as $p_j$.</p>
</dd>
<dt>ODDs</dt><dd><p>Item Odds is the ratio of the correct response rate to the incorrect response rate.
Defined as <code class="reqn">o_j = \frac{p_j}{1-p_j}</code></p>
</dd>
<dt>Threshold</dt><dd><p>Item Threshold is a measure of difficulty based on a standard normal distribution.</p>
</dd>
<dt>Entropy</dt><dd><p>Item Entropy is an indicator of the variability or randomness of the responses.
Defined as <code class="reqn">e_j=-p_j \log_2 p_j - (1-p_j)\log_2(1-p_j)</code></p>
</dd>
<dt>ITCrr</dt><dd><p>Item-total Correlation is a Pearson's correlation of an item with the Number-Right score.</p>
</dd>
</dl>

<p>For ordinal polytomous data:
</p>

<dl>
<dt>ItemLabel</dt><dd><p>Label identifying each item</p>
</dd>
<dt>NR</dt><dd><p>Number of Respondents for each item</p>
</dd>
<dt>Threshold</dt><dd><p>Matrix of threshold values for each item's category boundaries, based on
a standard normal distribution. For an item with K categories, there are K-1 thresholds.</p>
</dd>
<dt>Entropy</dt><dd><p>Item Entropy calculated using the category probabilities. Unlike binary data,
this is calculated using the formula <code class="reqn">e_j = -\sum_{k=1}^{K_j} p_{jk} \log_{K_j} p_{jk}</code>,
where <code class="reqn">K_j</code> is the number of categories for item j.</p>
</dd>
<dt>ITCrr</dt><dd><p>Item-total Correlation calculated using polyserial correlation, which
accounts for the ordinal nature of the item responses and the continuous total score.</p>
</dd>
</dl>



<h3>Note</h3>

<p>For rated data, the function processes the data as binary, with each response
being compared to the correct answer to determine correctness.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset(binary)
ItemStatistics(J15S500)
</code></pre>

<hr>
<h2 id='ItemThreshold'>Item Threshold</h2><span id='topic+ItemThreshold'></span><span id='topic+ItemThreshold.binary'></span><span id='topic+ItemThreshold.ordinal'></span>

<h3>Description</h3>

<p>Item threshold is a measure of difficulty based on a standard normal distribution.
This function is applicable only to binary response data.
</p>
<p>The threshold is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">\tau_j = \Phi^{-1}(1-p_j)</code>
</p>

<p>where <code class="reqn">\Phi^{-1}</code> is the inverse standard normal distribution function
and <code class="reqn">p_j</code> is the correct response rate for item j.
</p>
<p>Higher threshold values indicate more difficult items, as they represent the
point on the standard normal scale above which examinees tend to answer incorrectly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemThreshold(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemThreshold(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
ItemThreshold(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemThreshold_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemThreshold_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemThreshold_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemThreshold_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of threshold values for each item on the standard normal scale.
Typical values range from about -3 to 3, where:
</p>

<ul>
<li><p> Positive values indicate difficult items
</p>
</li>
<li><p> Zero indicates items of medium difficulty (50% correct)
</p>
</li>
<li><p> Negative values indicate easy items
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
ItemThreshold(J5S10)
</code></pre>

<hr>
<h2 id='ItemTotalCorr'>Item-Total Correlation</h2><span id='topic+ItemTotalCorr'></span><span id='topic+ItemTotalCorr.default'></span><span id='topic+ItemTotalCorr.binary'></span><span id='topic+ItemTotalCorr.ordinal'></span>

<h3>Description</h3>

<p>Item-Total correlation (ITC) is a Pearson's correlation of an item with
the Number-Right Score (NRS) or total score. This function is applicable
only to binary response data.
</p>
<p>The ITC is a measure of item discrimination, indicating how well an item
distinguishes between high and low performing examinees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemTotalCorr(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
ItemTotalCorr(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
ItemTotalCorr(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
ItemTotalCorr(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemTotalCorr_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ItemTotalCorr_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="ItemTotalCorr_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ItemTotalCorr_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation is calculated between:
</p>

<ul>
<li><p> Each item's responses (0 or 1)
</p>
</li>
<li><p> The total test score (sum of correct responses)
</p>
</li></ul>

<p>Higher positive correlations indicate items that better discriminate between
high and low ability examinees.
</p>


<h3>Value</h3>

<p>A numeric vector of item-total correlations. Values typically range
from -1 to 1, where:
</p>

<ul>
<li><p> Values near 1: Strong positive discrimination
</p>
</li>
<li><p> Values near 0: No discrimination
</p>
</li>
<li><p> Negative values: Potential item problems (lower ability students
performing better than higher ability students)
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>Values below 0.2 might indicate problematic items that should be reviewed.
Values above 0.3 are generally considered acceptable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
ItemTotalCorr(J15S500)

</code></pre>

<hr>
<h2 id='J12S5000'>J12S5000</h2><span id='topic+J12S5000'></span>

<h3>Description</h3>

<p>A binary response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J12S5000
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 5000 students and 12 items containing binary (0/1) responses
</p>


<h3>Source</h3>

<p><a href="http://sh0j1ma.stars.ne.jp/exmk/">http://sh0j1ma.stars.ne.jp/exmk/</a>
</p>

<hr>
<h2 id='J15S3810'>J15S3810</h2><span id='topic+J15S3810'></span>

<h3>Description</h3>

<p>A ordinal response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J15S3810
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 3810 students and 15 items containing nominal responses with 4 categories
</p>

<hr>
<h2 id='J15S500'>J15S500</h2><span id='topic+J15S500'></span>

<h3>Description</h3>

<p>A binary response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J15S500
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 500 students and 15 items containing binary (0/1) responses
</p>


<h3>Source</h3>

<p><a href="http://sh0j1ma.stars.ne.jp/exmk/">http://sh0j1ma.stars.ne.jp/exmk/</a>
</p>

<hr>
<h2 id='J20S400'>J20S400</h2><span id='topic+J20S400'></span>

<h3>Description</h3>

<p>A binary response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J20S400
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 400 students and 20 items containing binary (0/1) responses
</p>


<h3>Source</h3>

<p><a href="http://sh0j1ma.stars.ne.jp/exmk/">http://sh0j1ma.stars.ne.jp/exmk/</a>
</p>

<hr>
<h2 id='J35S5000'>J35S5000</h2><span id='topic+J35S5000'></span>

<h3>Description</h3>

<p>A rated response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J35S5000
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 5000 students and 35 items containing polytomous responses with correct answers
</p>

<hr>
<h2 id='J35S515'>J35S515</h2><span id='topic+J35S515'></span>

<h3>Description</h3>

<p>A binary response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J35S515
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 515 students and 35 items containing binary (0/1) responses
</p>


<h3>Source</h3>

<p><a href="http://sh0j1ma.stars.ne.jp/exmk/">http://sh0j1ma.stars.ne.jp/exmk/</a>
</p>

<hr>
<h2 id='J50S100'>J50S100</h2><span id='topic+J50S100'></span>

<h3>Description</h3>

<p>A simulated binary dataset for test analysis. This is a synthetic dataset
generated using random number generation for demonstration and testing purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J50S100
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 100 students and 50 items containing binary responses
</p>

<hr>
<h2 id='J5S10'>J5S10</h2><span id='topic+J5S10'></span>

<h3>Description</h3>

<p>A binary response dataset for test analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J5S10
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 5 students and 10 items containing binary (0/1) responses
</p>


<h3>Source</h3>

<p><a href="http://sh0j1ma.stars.ne.jp/exmk/">http://sh0j1ma.stars.ne.jp/exmk/</a>
</p>

<hr>
<h2 id='J5S1000'>J5S1000</h2><span id='topic+J5S1000'></span>

<h3>Description</h3>

<p>A simulated ordinal dataset for test analysis. This is a synthetic dataset
generated using random number generation for demonstration and testing purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J5S1000
</code></pre>


<h3>Format</h3>

<p>An exametrika class object with 1000 students and 5 items containing ordinal responses
</p>

<hr>
<h2 id='Jacobian_grm'>Jacobian function for GRM</h2><span id='topic+Jacobian_grm'></span>

<h3>Description</h3>

<p>Jacobian function for GRM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jacobian_grm(target, nitems, ncat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jacobian_grm_+3A_target">target</code></td>
<td>
<p>target vector</p>
</td></tr>
<tr><td><code id="Jacobian_grm_+3A_nitems">nitems</code></td>
<td>
<p>number of items</p>
</td></tr>
<tr><td><code id="Jacobian_grm_+3A_ncat">ncat</code></td>
<td>
<p>number of categories for each items</p>
</td></tr>
</table>

<hr>
<h2 id='JCRR'>Joint Correct Response Rate</h2><span id='topic+JCRR'></span><span id='topic+JCRR.default'></span><span id='topic+JCRR.binary'></span><span id='topic+JCRR.nominal'></span>

<h3>Description</h3>

<p>The joint correct response rate (JCRR) is the rate of students who passed
both items. This function is applicable only to binary response data.
For non-binary data, it will automatically redirect to the JSR function
with an appropriate message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JCRR(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
JCRR(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
JCRR(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'nominal'
JCRR(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="JCRR_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="JCRR_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="JCRR_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="JCRR_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of joint correct response rates with exametrika class.
Each element (i,j) represents the proportion of students who correctly
answered both items i and j.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate JCRR using sample dataset J5S10
JCRR(J5S10)
</code></pre>

<hr>
<h2 id='JointSampleSize'>Joint Sample Size</h2><span id='topic+JointSampleSize'></span><span id='topic+JointSampleSize.default'></span><span id='topic+JointSampleSize.binary'></span>

<h3>Description</h3>

<p>The joint sample size is a matrix whose elements are the number of
individuals who responded to each pair of items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JointSampleSize(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
JointSampleSize(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
JointSampleSize(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="JointSampleSize_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="JointSampleSize_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="JointSampleSize_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="JointSampleSize_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of class c(&quot;exametrika&quot;, &quot;matrix&quot;) where each element (i,j)
represents the number of students who responded to both item i and item j. The
diagonal elements represent the total number of responses for each item.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>

<hr>
<h2 id='JSR'>Joint Selection Rate</h2><span id='topic+JSR'></span>

<h3>Description</h3>

<p>Calculate the Joint Selection Rate (JSR) for polytomous data.
JSR measures the proportion of respondents who selected specific category
combinations between pairs of items. For each pair of items (j,k),
it returns a contingency table showing the joint probability of selecting
each category combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JSR(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="JSR_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="JSR_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="JSR_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="JSR_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of Joint Selection Rate matrices for each item pair.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate JCRR using sample dataset J5S1000
JSR(J5S1000)
</code></pre>

<hr>
<h2 id='LCA'>Latent Class Analysis</h2><span id='topic+LCA'></span>

<h3>Description</h3>

<p>Performs Latent Class Analysis (LCA) on binary response data using the Expectation-Maximization (EM) algorithm.
LCA identifies unobserved (latent) subgroups of examinees with similar response patterns,
and estimates both the class characteristics and individual membership probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LCA(U, ncls = 2, na = NULL, Z = NULL, w = NULL, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LCA_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="LCA_+3A_ncls">ncls</code></td>
<td>
<p>Number of latent classes to identify (between 2 and 20). Default is 2.</p>
</td></tr>
<tr><td><code id="LCA_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="LCA_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="LCA_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
<tr><td><code id="LCA_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of EM algorithm iterations. Default is 100.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Latent Class Analysis is a statistical method for identifying unobserved subgroups within
a population based on observed response patterns. It assumes that examinees belong to one
of several distinct latent classes, and that the probability of a correct response to each
item depends on class membership.
</p>
<p>The algorithm proceeds by:
</p>

<ol>
<li><p> Initializing class reference probabilities
</p>
</li>
<li><p> Computing posterior class membership probabilities for each examinee (E-step)
</p>
</li>
<li><p> Re-estimating class reference probabilities based on these memberships (M-step)
</p>
</li>
<li><p> Iterating until convergence or reaching the maximum number of iterations
</p>
</li></ol>

<p>Unlike Item Response Theory (IRT), LCA treats latent variables as categorical rather than
continuous, identifying distinct profiles rather than positions on a continuum.
</p>


<h3>Value</h3>

<p>An object of class &quot;exametrika&quot; and &quot;LCA&quot; containing:
</p>

<dl>
<dt>testlength</dt><dd><p>Length of the test (number of items).</p>
</dd>
<dt>nobs</dt><dd><p>Sample size (number of rows in the dataset).</p>
</dd>
<dt>Nclass</dt><dd><p>Number of latent classes specified.</p>
</dd>
<dt>N_Cycle</dt><dd><p>Number of EM algorithm iterations performed.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile vector showing expected scores for each latent class.
Calculated as the column sum of the estimated class reference matrix.</p>
</dd>
<dt>LCD</dt><dd><p>Latent Class Distribution vector showing the number of examinees assigned to each latent class.</p>
</dd>
<dt>CMD</dt><dd><p>Class Membership Distribution vector showing the sum of membership probabilities for each latent class.</p>
</dd>
<dt>Students</dt><dd><p>Class Membership Profile matrix showing the posterior probability of each examinee
belonging to each latent class. The last column (&quot;Estimate&quot;) indicates the most likely class assignment.</p>
</dd>
<dt>IRP</dt><dd><p>Item Reference Profile matrix where each row represents an item and each column
represents a latent class. Values indicate the probability of a correct response
for members of that class.</p>
</dd>
<dt>ItemFitIndices</dt><dd><p>Fit indices for each item. See also <code><a href="#topic+ItemFit">ItemFit</a></code>.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit indices for the test. See also <code><a href="#topic+TestFit">TestFit</a></code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Goodman, L. A. (1974). Exploratory latent structure analysis using both identifiable and
unidentifiable models. Biometrika, 61(2), 215-231.
</p>
<p>Lazarsfeld, P. F., &amp; Henry, N. W. (1968). Latent structure analysis.
Boston: Houghton Mifflin.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Fit a Latent Class Analysis model with 5 classes to the sample dataset
result.LCA &lt;- LCA(J15S500, ncls = 5)

# Display the first few rows of student class membership probabilities
head(result.LCA$Students)

# Plot Item Response Profiles (IRP) for items 1-6 in a 2x3 grid
# Shows probability of correct response for each item across classes
plot(result.LCA, type = "IRP", items = 1:6, nc = 2, nr = 3)

# Plot Class Membership Probabilities (CMP) for students 1-9 in a 3x3 grid
# Shows probability distribution of class membership for each student
plot(result.LCA, type = "CMP", students = 1:9, nc = 3, nr = 3)

# Plot Test Response Profile (TRP) showing expected scores for each class
plot(result.LCA, type = "TRP")

# Plot Latent Class Distribution (LCD) showing class sizes
plot(result.LCA, type = "LCD")

# Compare models with different numbers of classes
# (In practice, you might try more class counts)
lca2 &lt;- LCA(J15S500, ncls = 2)
lca3 &lt;- LCA(J15S500, ncls = 3)
lca4 &lt;- LCA(J15S500, ncls = 4)
lca5 &lt;- LCA(J15S500, ncls = 5)

# Compare BIC values to select optimal number of classes
# (Lower BIC indicates better fit)
data.frame(
  Classes = 2:5,
  BIC = c(
    lca2$TestFitIndices$BIC,
    lca3$TestFitIndices$BIC,
    lca4$TestFitIndices$BIC,
    lca5$TestFitIndices$BIC
  )
)


</code></pre>

<hr>
<h2 id='LD_param_est'>LDparam set</h2><span id='topic+LD_param_est'></span>

<h3>Description</h3>

<p>A function that extracts only the estimation of graph parameters
after the rank estimation is completed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LD_param_est(tmp, adj_list, classRefMat, ncls, smoothpost)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LD_param_est_+3A_tmp">tmp</code></td>
<td>
<p>tmp</p>
</td></tr>
<tr><td><code id="LD_param_est_+3A_adj_list">adj_list</code></td>
<td>
<p>adj_list</p>
</td></tr>
<tr><td><code id="LD_param_est_+3A_classrefmat">classRefMat</code></td>
<td>
<p>values returned from emclus</p>
</td></tr>
<tr><td><code id="LD_param_est_+3A_ncls">ncls</code></td>
<td>
<p>ncls</p>
</td></tr>
<tr><td><code id="LD_param_est_+3A_smoothpost">smoothpost</code></td>
<td>
<p>smoothpost</p>
</td></tr>
</table>

<hr>
<h2 id='LDB'>Local Dependence Biclustering</h2><span id='topic+LDB'></span>

<h3>Description</h3>

<p>Latent dependence Biclustering, which incorporates biclustering and a Bayesian
network model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDB(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  ncls = 2,
  method = "R",
  conf = NULL,
  g_list = NULL,
  adj_list = NULL,
  adj_file = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LDB_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="LDB_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="LDB_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="LDB_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="LDB_+3A_ncls">ncls</code></td>
<td>
<p>number of latent class(rank). The default is 2.</p>
</td></tr>
<tr><td><code id="LDB_+3A_method">method</code></td>
<td>
<p>specify the model to analyze the data.Local dependence latent
class model is set to &quot;C&quot;, latent rank model is set &quot;R&quot;. The default is &quot;R&quot;.</p>
</td></tr>
<tr><td><code id="LDB_+3A_conf">conf</code></td>
<td>
<p>For the confirmatory parameter, you can input either a vector with
items and corresponding fields in sequence, or a field membership profile
matrix. In the case of the former, the field membership profile matrix will be generated internally.
When providing a membership profile matrix, it needs to be either matrix or data.frame.
The number of fields(nfld) will be overwrite to the number of columns of this matrix.</p>
</td></tr>
<tr><td><code id="LDB_+3A_g_list">g_list</code></td>
<td>
<p>A list compiling graph-type objects for each rank/class.</p>
</td></tr>
<tr><td><code id="LDB_+3A_adj_list">adj_list</code></td>
<td>
<p>A list compiling matrix-type adjacency matrices for each rank/class.</p>
</td></tr>
<tr><td><code id="LDB_+3A_adj_file">adj_file</code></td>
<td>
<p>A file detailing the relationships of the graph for each rank/class,
listed in the order of starting point, ending point, and rank(class).</p>
</td></tr>
<tr><td><code id="LDB_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>Nclass</dt><dd><p>Optimal number of classes.</p>
</dd>
<dt>Nfield</dt><dd><p>Optimal number of fields.</p>
</dd>
<dt>crr</dt><dd><p>Correct Response Rate</p>
</dd>
<dt>ItemLabel</dt><dd><p>Label of Items</p>
</dd>
<dt>FieldLabel</dt><dd><p>Label of Fields</p>
</dd>
<dt>adj_list</dt><dd><p>List of Adjacency matrix used in the model</p>
</dd>
<dt>g_list</dt><dd><p>List of graph object used in the model</p>
</dd>
<dt>IRP</dt><dd><p>List of Estimated Parameters. This object is three-dimensional
PIRP array, where each dimension represents the number of rank,number
of field, and Dmax. Dmax denotes the maximum number of correct response
patterns for each field.</p>
</dd>
<dt>LFD</dt><dd><p>Latent Field Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>LRD</dt><dd><p>Latent Rank Distribution. see also <a href="#topic+plot.exametrika">plot.exametrika</a></p>
</dd>
<dt>FRP</dt><dd><p>Marginal Field Reference Matrix</p>
</dd>
<dt>FRPIndex</dt><dd><p>Index of FFP includes the item location parameters B and Beta,
the slope parameters A and Alpha, and the monotonicity indices C and Gamma.</p>
</dd>
<dt>CCRR_table</dt><dd><p>This table is a rearrangement of IRP into a data.frame
format for output, consisting of combinations of rank ,field and PIRP.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile</p>
</dd>
<dt>RMD</dt><dd><p>Rank Membership Distribution.</p>
</dd>
<dt>FieldEstimated</dt><dd><p>Given vector which correspondence between items
and the fields.</p>
</dd>
<dt>ClassEstimated</dt><dd><p>An index indicating which class a student belongs
to, estimated by confirmatory Ranklustering.</p>
</dd>
<dt>Students</dt><dd><p>Rank Membership Profile matrix.The s-th row vector of <code class="reqn">\hat{M}_R</code>, <code class="reqn">\hat{m}_R</code>, is the
rank membership profile of Student s, namely the posterior probability distribution representing the student's
belonging to the respective latent classes. It also includes the rank with the maximum estimated membership probability,
as well as the rank-up odds and rank-down odds.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Example: Latent Dirichlet Bayesian Network model
# Create field configuration vector based on field assignments
conf &lt;- c(
  1, 6, 6, 8, 9, 9, 4, 7, 7, 7, 5, 8, 9, 10, 10, 9, 9,
  10, 10, 10, 2, 2, 3, 3, 5, 5, 6, 9, 9, 10, 1, 1, 7, 9, 10
)

# Create edge data for the network structure between fields
edges_data &lt;- data.frame(
  "From Field (Parent) &gt;&gt;&gt;" = c(
    6, 4, 5, 1, 1, 4, # Class/Rank 2
    3, 4, 6, 2, 4, 4, # Class/Rank 3
    3, 6, 4, 1, # Class/Rank 4
    7, 9, 6, 7 # Class/Rank 5
  ),
  "&gt;&gt;&gt; To Field (Child)" = c(
    8, 7, 8, 7, 2, 5, # Class/Rank 2
    5, 8, 8, 4, 6, 7, # Class/Rank 3
    5, 8, 5, 8, # Class/Rank 4
    10, 10, 8, 9 # Class/Rank 5
  ),
  "At Class/Rank (Locus)" = c(
    2, 2, 2, 2, 2, 2, # Class/Rank 2
    3, 3, 3, 3, 3, 3, # Class/Rank 3
    4, 4, 4, 4, # Class/Rank 4
    5, 5, 5, 5 # Class/Rank 5
  )
)

# Save edge data to temporary CSV file
tmp_file &lt;- tempfile(fileext = ".csv")
write.csv(edges_data, file = tmp_file, row.names = FALSE)

# Fit Latent Dirichlet Bayesian Network model
result.LDB &lt;- LDB(
  U = J35S515,
  ncls = 5, # Number of latent classes
  conf = conf, # Field configuration vector
  adj_file = tmp_file # Path to the CSV file
)

# Clean up temporary file
unlink(tmp_file)

# Display model results
print(result.LDB)

# Visualize different aspects of the model
plot(result.LDB, type = "Array") # Show bicluster structure
plot(result.LDB, type = "TRP") # Test Response Profile
plot(result.LDB, type = "LRD") # Latent Rank Distribution
plot(result.LDB,
  type = "RMP", # Rank Membership Profiles
  students = 1:9, nc = 3, nr = 3
)
plot(result.LDB,
  type = "FRP", # Field Reference Profiles
  nc = 3, nr = 2
)
# Field PIRP Profile showing correct answer counts for each rank and field
plot(result.LDB, type = "FieldPIRP")

</code></pre>

<hr>
<h2 id='LDLRA'>Local Dependence Latent Rank Analysis</h2><span id='topic+LDLRA'></span>

<h3>Description</h3>

<p>performs local dependence latent lank analysis(LD_LRA) by Shojima(2011)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDLRA(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  ncls = 2,
  method = "R",
  g_list = NULL,
  adj_list = NULL,
  adj_file = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LDLRA_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_ncls">ncls</code></td>
<td>
<p>number of latent class(rank). The default is 2.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_method">method</code></td>
<td>
<p>specify the model to analyze the data.Local dependence latent
class model is set to &quot;C&quot;, latent rank model is set &quot;R&quot;. The default is &quot;R&quot;.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_g_list">g_list</code></td>
<td>
<p>A list compiling graph-type objects for each rank/class.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_adj_list">adj_list</code></td>
<td>
<p>A list compiling matrix-type adjacency matrices for each rank/class.</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_adj_file">adj_file</code></td>
<td>
<p>A file detailing the relationships of the graph for each rank/class,
listed in the order of starting point, ending point, and rank(class).</p>
</td></tr>
<tr><td><code id="LDLRA_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended to perform LD-LRA. LD-LRA is an analysis that
combines LRA and BNM, and it is used to analyze the network structure among
items in the latent rank. In this function, structural learning is not
performed, so you need to provide item graphs for each rank as separate files.
The file format for this is plain text CSV that includes edges (From, To) and
rank numbers.
</p>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>crr</dt><dd><p>correct response ratio</p>
</dd>
<dt>adj_list</dt><dd><p>adjacency matrix list</p>
</dd>
<dt>g_list</dt><dd><p>graph list</p>
</dd>
<dt>referenceMatrix</dt><dd><p>Learned Parameters.A three-dimensional array of patterns where
item x rank x pattern.</p>
</dd>
<dt>IRP</dt><dd><p>Marginal Item Reference Matrix</p>
</dd>
<dt>IRPIndex</dt><dd><p>IRP Indices which include Alpha, Beta, Gamma.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile matrix.</p>
</dd>
<dt>LRD</dt><dd><p>latent Rank/Class Distribution</p>
</dd>
<dt>RMD</dt><dd><p>Rank/Class Membership Distribution</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>Estimation_table</dt><dd><p>Estimated parameters tables.</p>
</dd>
<dt>CCRR_table</dt><dd><p>Correct Response Rate tables</p>
</dd>
<dt>Studens</dt><dd><p>Student information. It includes estimated class
membership, probability of class membership, RUO, and RDO.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Create sample DAG structure with different rank levels
# Format: From, To, Rank
DAG_dat &lt;- matrix(c(
  "From", "To", "Rank",
  "Item01", "Item02", "1", # Simple structure for Rank 1
  "Item01", "Item02", "2", # More complex structure for Rank 2
  "Item02", "Item03", "2",
  "Item01", "Item02", "3", # Additional connections for Rank 3
  "Item02", "Item03", "3",
  "Item03", "Item04", "3"
), ncol = 3, byrow = TRUE)

# Method 1: Directly use graph and adjacency lists
g_list &lt;- list()
adj_list &lt;- list()

for (i in 1:3) {
  adj_R &lt;- DAG_dat[DAG_dat[, 3] == as.character(i), 1:2, drop = FALSE]
  g_tmp &lt;- igraph::graph_from_data_frame(
    d = data.frame(
      From = adj_R[, 1],
      To = adj_R[, 2]
    ),
    directed = TRUE
  )
  adj_tmp &lt;- igraph::as_adjacency_matrix(g_tmp)
  g_list[[i]] &lt;- g_tmp
  adj_list[[i]] &lt;- adj_tmp
}

# Fit Local Dependence Latent Rank Analysis
result.LDLRA1 &lt;- LDLRA(J12S5000,
  ncls = 3,
  g_list = g_list,
  adj_list = adj_list
)

# Plot Item Reference Profiles (IRP) in a 4x3 grid
# Shows the probability patterns of correct responses for each item across ranks
plot(result.LDLRA1, type = "IRP", nc = 4, nr = 3)

# Plot Test Reference Profile (TRP)
# Displays the overall pattern of correct response probabilities across ranks
plot(result.LDLRA1, type = "TRP")

# Plot Latent Rank Distribution (LRD)
# Shows the distribution of students across different ranks
plot(result.LDLRA1, type = "LRD")


</code></pre>

<hr>
<h2 id='log_lik_grm'>log_lik function for grm</h2><span id='topic+log_lik_grm'></span>

<h3>Description</h3>

<p>log_lik function for grm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_lik_grm(target, dat, verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_lik_grm_+3A_target">target</code></td>
<td>
<p>target vector</p>
</td></tr>
<tr><td><code id="log_lik_grm_+3A_dat">dat</code></td>
<td>
<p>data set</p>
</td></tr>
</table>

<hr>
<h2 id='LogisticModel'>Four-Parameter Logistic Model</h2><span id='topic+LogisticModel'></span>

<h3>Description</h3>

<p>The four-parameter logistic model is a model where one additional
parameter d, called the upper asymptote parameter, is added to the
3PLM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogisticModel(a = 1, b, c = 0, d = 1, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LogisticModel_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="LogisticModel_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="LogisticModel_+3A_c">c</code></td>
<td>
<p>lower asymptote parameter</p>
</td></tr>
<tr><td><code id="LogisticModel_+3A_d">d</code></td>
<td>
<p>upper asymptote parameter</p>
</td></tr>
<tr><td><code id="LogisticModel_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of probabilities between c and d, representing
the probability of a correct response given the ability level theta. The probability
is calculated using the formula: <code class="reqn">P(\theta) = c + \frac{(d-c)}{1 + e^{-a(\theta-b)}}</code>
</p>

<hr>
<h2 id='longdataFormat'>Long Format Data Conversion</h2><span id='topic+longdataFormat'></span>

<h3>Description</h3>

<p>A function to reshape long data into a dataset suitable for exametrika.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>longdataFormat(
  data,
  na = NULL,
  Sid = NULL,
  Qid = NULL,
  Resp = NULL,
  w = NULL,
  response.type = NULL,
  CA = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="longdataFormat_+3A_data">data</code></td>
<td>
<p>is a data matrix of the type matrix or data.frame. This must
contain at least three columns to identify the student, the item, and
the response. Additionally, it can include a column for the weight of
the items.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_sid">Sid</code></td>
<td>
<p>Specify the column number containing the student ID label vector.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_qid">Qid</code></td>
<td>
<p>Specify the column number containing the Question label vector.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_resp">Resp</code></td>
<td>
<p>Specify the column number containing the Response value vector.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_w">w</code></td>
<td>
<p>Specify the column number containing the weight vector.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_response.type">response.type</code></td>
<td>
<p>Character string specifying the type of response data:
&quot;binary&quot; for dichotomous data,
&quot;ordinal&quot; for ordered polytomous data,
&quot;rated&quot; for polytomous data with correct answers,
&quot;nominal&quot; for unordered polytomous data.
If NULL (default), the type is automatically detected.</p>
</td></tr>
<tr><td><code id="longdataFormat_+3A_ca">CA</code></td>
<td>
<p>A numeric vector specifying the correct answers for rated polytomous data.
Required when response.type is &quot;rated&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>U</dt><dd><p>For binary response data. A matrix with rows representing the sample size and columns
representing the number of items, where elements are either 0 or 1. <code class="reqn">u_{ij}=1</code> indicates
that student i correctly answered item j, while <code class="reqn">u_{ij}=0</code> means that student i answered
item j incorrectly.</p>
</dd>
<dt>Q</dt><dd><p>For polytomous response data. A matrix with rows representing the sample size and columns
representing the number of items, where elements are non-negative integers. When input data is
in factor format, the factor levels are converted to consecutive integers starting from 1.</p>
</dd>
<dt>ID</dt><dd><p>The ID label given by the designated column or function.</p>
</dd>
<dt>ItemLabel</dt><dd><p>The item names given by the provided column names or function.</p>
</dd>
<dt>Z</dt><dd><p>Missing indicator matrix. <code class="reqn">z_{ij}=1</code> indicates that item j is presented to Student i,
while <code class="reqn">z_{ij}=0</code> indicates item j is NOT presented to Student i.</p>
</dd>
<dt>w</dt><dd><p>Item weight vector</p>
</dd>
<dt>response.type</dt><dd><p>Character string indicating the type of response data:
&quot;binary&quot;, &quot;ordinal&quot;, &quot;rated&quot;, or &quot;nominal&quot;</p>
</dd>
<dt>CategoryLabel</dt><dd><p>List containing the original factor labels when polytomous responses
are provided as factors. NULL if no factor data is present.</p>
</dd>
<dt>categories</dt><dd><p>Numeric vector containing the number of response categories for each item.</p>
</dd>
<dt>CA</dt><dd><p>For rated polytomous data, a numeric vector of correct answers. NULL for other types.</p>
</dd>
</dl>


<hr>
<h2 id='LRA'>Latent Rank Analysis</h2><span id='topic+LRA'></span><span id='topic+LRA.default'></span><span id='topic+LRA.binary'></span><span id='topic+LRA.ordinal'></span><span id='topic+LRA.rated'></span>

<h3>Description</h3>

<p>A general function for estimating Latent Rank Analysis across different response types.
This function automatically dispatches to the appropriate method based on the response type:
</p>

<ul>
<li><p> For binary data (<code>LRA.binary</code>): Analysis using either SOM or GTM method
</p>
</li>
<li><p> For ordinal data (<code>LRA.ordinal</code>): Analysis using the GTM method with category thresholds
</p>
</li>
<li><p> For rated data (<code>LRA.rated</code>): Analysis using the GTM method with rating categories
</p>
</li></ul>

<p>Latent Rank Analysis identifies underlying rank structures in test data and assigns
examinees to these ranks based on their response patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRA(U, ...)

## Default S3 method:
LRA(U, na = NULL, Z = Z, w = w, ...)

## S3 method for class 'binary'
LRA(
  U,
  nrank = 2,
  method = "GTM",
  mic = FALSE,
  maxiter = 100,
  BIC.check = FALSE,
  seed = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'ordinal'
LRA(
  U,
  nrank = 2,
  mic = FALSE,
  maxiter = 100,
  trapezoidal = 0,
  eps = 1e-04,
  verbose = TRUE,
  ...
)

## S3 method for class 'rated'
LRA(
  U,
  nrank = 2,
  mic = FALSE,
  maxiter = 100,
  trapezoidal = 0,
  eps = 1e-04,
  minFreqRatio = 0,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRA_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="LRA_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to specific methods.</p>
</td></tr>
<tr><td><code id="LRA_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="LRA_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. 1 indicates observed values, 0 indicates missing values.</p>
</td></tr>
<tr><td><code id="LRA_+3A_w">w</code></td>
<td>
<p>Item weight vector.</p>
</td></tr>
<tr><td><code id="LRA_+3A_nrank">nrank</code></td>
<td>
<p>Number of latent ranks to estimate. Must be between 2 and 20.</p>
</td></tr>
<tr><td><code id="LRA_+3A_method">method</code></td>
<td>
<p>For binary data only. Either &quot;SOM&quot; (Self-Organizing Maps) or &quot;GTM&quot; (Gaussian Topographic Mapping). Default is &quot;GTM&quot;.</p>
</td></tr>
<tr><td><code id="LRA_+3A_mic">mic</code></td>
<td>
<p>Logical; if TRUE, forces Item Reference Profiles to be monotonically increasing. Default is FALSE.</p>
</td></tr>
<tr><td><code id="LRA_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for estimation. Default is 100.</p>
</td></tr>
<tr><td><code id="LRA_+3A_bic.check">BIC.check</code></td>
<td>
<p>For binary data with SOM method only. If TRUE, convergence is checked using BIC values. Default is FALSE.</p>
</td></tr>
<tr><td><code id="LRA_+3A_seed">seed</code></td>
<td>
<p>For binary data with SOM method only. Random seed for reproducibility.</p>
</td></tr>
<tr><td><code id="LRA_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if TRUE, displays detailed progress during estimation. Default is TRUE.</p>
</td></tr>
<tr><td><code id="LRA_+3A_trapezoidal">trapezoidal</code></td>
<td>
<p>Specifies the height of both tails when using a trapezoidal
prior distribution. Must be less than 1/nrank. The default value is 0, which
results in a uniform prior distribution.</p>
</td></tr>
<tr><td><code id="LRA_+3A_eps">eps</code></td>
<td>
<p>Convergence threshold for parameter updates. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="LRA_+3A_minfreqratio">minFreqRatio</code></td>
<td>
<p>Minimum frequency ratio for response categories (default = 0).
Categories with occurrence rates below this threshold will be excluded from analysis.
For example, if set to 0.1, response categories that appear in less than 10% of
responses for an item will be omitted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class &quot;exametrika&quot; and the specific subclass (e.g., &quot;LRA&quot;, &quot;LRAordinal&quot;, &quot;LRArated&quot;)
containing the following common elements:
</p>

<dl>
<dt>testlength</dt><dd><p>Length of the test (number of items).</p>
</dd>
<dt>nobs</dt><dd><p>Sample size (number of rows in the dataset).</p>
</dd>
<dt>Nrank</dt><dd><p>Number of latent ranks specified.</p>
</dd>
<dt>N_Cycle</dt><dd><p>Number of EM algorithm iterations performed.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile vector showing expected scores at each rank.</p>
</dd>
<dt>LRD</dt><dd><p>Latent Rank Distribution vector showing the number of examinees at each rank.</p>
</dd>
<dt>RMD</dt><dd><p>Rank Membership Distribution vector showing the sum of probabilities for each rank.</p>
</dd>
<dt>Students</dt><dd><p>Rank Membership Profile matrix showing the posterior probabilities of
examinees belonging to each rank, along with their estimated ranks and odds ratios.</p>
</dd>
<dt>ItemFitIndices</dt><dd><p>Fit indices for each item. See also <code><a href="#topic+ItemFit">ItemFit</a></code>.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit indices for the test. See also <code><a href="#topic+TestFit">TestFit</a></code>.</p>
</dd>
</dl>

<p>Each subclass returns additional specific elements, detailed in their respective documentation.
</p>
<p>For binary data (<code>LRA.binary</code>), the returned list additionally includes:
</p>

<dl>
<dt>IRP</dt><dd><p>Item Reference Profile matrix showing the probability of correct response for each item across different ranks.</p>
</dd>
<dt>IRPIndex</dt><dd><p>Item Response Profile indices including the location parameters B and Beta,
slope parameters A and Alpha, and monotonicity indices C and Gamma.</p>
</dd>
</dl>

<p>For ordinal data (<code>LRA.ordinal</code>), the returned list additionally includes:
</p>

<dl>
<dt>ScoreReport</dt><dd><p>Descriptive statistics of test performance, including sample size,
test length, central tendency, variability, distribution characteristics, and reliability.</p>
</dd>
<dt>ItemReport</dt><dd><p>Basic statistics for each item including category proportions and item-total correlations.</p>
</dd>
<dt>ICBR</dt><dd><p>Item Category Boundary Reference matrix showing cumulative probabilities for rank-category combinations.</p>
</dd>
<dt>ICRP</dt><dd><p>Item Category Reference Profile matrix showing probability of response in each category by rank.</p>
</dd>
<dt>ScoreRankCorr</dt><dd><p>Spearman's correlation between test scores and estimated ranks.</p>
</dd>
<dt>RankQuantCorr</dt><dd><p>Spearman's correlation between estimated ranks and quantile groups.</p>
</dd>
<dt>ScoreRank</dt><dd><p>Contingency table of raw scores by estimated ranks.</p>
</dd>
<dt>ScoreMembership</dt><dd><p>Expected rank memberships for each raw score.</p>
</dd>
<dt>RankQuantile</dt><dd><p>Cross-tabulation of rank frequencies and quantile groups.</p>
</dd>
<dt>MembQuantile</dt><dd><p>Cross-tabulation of rank membership probabilities and quantile groups.</p>
</dd>
<dt>CatQuant</dt><dd><p>Response patterns across item categories and quantile groups.</p>
</dd>
</dl>

<p>For rated data (<code>LRA.rated</code>), the returned list additionally includes:
</p>

<dl>
<dt>ScoreReport</dt><dd><p>Descriptive statistics of test performance, including sample size,
test length, central tendency, variability, distribution characteristics, and reliability.</p>
</dd>
<dt>ItemReport</dt><dd><p>Basic statistics for each item including category proportions and item-total correlations.</p>
</dd>
<dt>ICRP</dt><dd><p>Item Category Reference Profile matrix showing probability of response in each category by rank.</p>
</dd>
<dt>ScoreRankCorr</dt><dd><p>Spearman's correlation between test scores and estimated ranks.</p>
</dd>
<dt>RankQuantCorr</dt><dd><p>Spearman's correlation between estimated ranks and quantile groups.</p>
</dd>
<dt>ScoreRank</dt><dd><p>Contingency table of raw scores by estimated ranks.</p>
</dd>
<dt>ScoreMembership</dt><dd><p>Expected rank memberships for each raw score.</p>
</dd>
<dt>RankQuantile</dt><dd><p>Cross-tabulation of rank frequencies and quantile groups.</p>
</dd>
<dt>MembQuantile</dt><dd><p>Cross-tabulation of rank membership probabilities and quantile groups.</p>
</dd>
<dt>ItemQuantileRef</dt><dd><p>Reference values for each item across quantile groups.</p>
</dd>
<dt>CatQuant</dt><dd><p>Response patterns across item categories and quantile groups.</p>
</dd>
</dl>



<h3>Binary Data Method</h3>

<p><code>LRA.binary</code> analyzes dichotomous (0/1) response data using either Self-Organizing Maps (SOM)
or Gaussian Topographic Mapping (GTM).
</p>


<h3>Ordinal Data Method</h3>

<p><code>LRA.ordinal</code> analyzes ordered categorical data with multiple thresholds,
such as Likert-scale responses or graded items.
</p>


<h3>Rated Data Method</h3>

<p><code>LRA.rated</code> analyzes data with ratings assigned to each response, such as
partially-credited items or preference scales where response categories have different weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.exametrika">plot.exametrika</a></code> for visualizing LRA results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Binary data example
# Fit a Latent Rank Analysis model with 6 ranks to binary data
result.LRA &lt;- LRA(J15S500, nrank = 6)

# Display the first few rows of student rank membership profiles
head(result.LRA$Students)

# Plot Item Reference Profiles (IRP) for the first 6 items
plot(result.LRA, type = "IRP", items = 1:6, nc = 2, nr = 3)

# Plot Test Reference Profile (TRP) showing expected scores at each rank
plot(result.LRA, type = "TRP")



# Ordinal data example
# Fit a Latent Rank Analysis model with 3 ranks to ordinal data
result.LRAord &lt;- LRA(J15S3810, nrank = 3, mic = TRUE)

# Plot score distributions
plot(result.LRAord, type = "ScoreFreq")
plot(result.LRAord, type = "ScoreRank")

# Plot category response patterns for items 1-6
plot(result.LRAord, type = "ICBR", items = 1:6, nc = 3, nr = 2)
plot(result.LRAord, type = "ICRP", items = 1:6, nc = 3, nr = 2)



# Rated data example
# Fit a Latent Rank Analysis model with 10 ranks to rated data
result.LRArated &lt;- LRA(J35S5000, nrank = 10, mic = TRUE)

# Plot score distributions
plot(result.LRArated, type = "ScoreFreq")
plot(result.LRArated, type = "ScoreRank")

# Plot category response patterns for items 1-6
plot(result.LRArated, type = "ICRP", items = 1:6, nc = 3, nr = 2)


</code></pre>

<hr>
<h2 id='maxParents_penalty'>Utility function for searching DAG</h2><span id='topic+maxParents_penalty'></span>

<h3>Description</h3>

<p>Function to limit the number of parent nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxParents_penalty(vec, testlength, maxParents)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maxParents_penalty_+3A_vec">vec</code></td>
<td>
<p>gene Vector corresponding to the upper triangular of the adjacency matrix</p>
</td></tr>
<tr><td><code id="maxParents_penalty_+3A_testlength">testlength</code></td>
<td>
<p>test length. In this context it means a number of nodes.</p>
</td></tr>
<tr><td><code id="maxParents_penalty_+3A_maxparents">maxParents</code></td>
<td>
<p>Upper limit of number of nodes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When generating an adjacency matrix using GA, the number of edges coming
from a single node should be limited to 2 or 3. This is because if
there are too many edges, it becomes difficult to interpret in practical
applications. This function works to adjust the sampling of the randomly
generated adjacency matrix so that the column sum of the upper triangular
elements fits within the set limit.
</p>

<hr>
<h2 id='MutualInformation'>Mutual Information</h2><span id='topic+MutualInformation'></span><span id='topic+MutualInformation.default'></span><span id='topic+MutualInformation.binary'></span><span id='topic+MutualInformation.ordinal'></span>

<h3>Description</h3>

<p>Mutual Information is a measure that represents the degree of interdependence
between two items. This function is applicable to both binary and polytomous response data.
The measure is calculated using the joint probability distribution of responses
between item pairs and their marginal probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MutualInformation(U, na = NULL, Z = NULL, w = NULL, base = 2)

## Default S3 method:
MutualInformation(U, na = NULL, Z = NULL, w = NULL, base = 2)

## S3 method for class 'binary'
MutualInformation(U, na = NULL, Z = NULL, w = NULL, base = 2)

## S3 method for class 'ordinal'
MutualInformation(U, na = NULL, Z = NULL, w = NULL, base = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MutualInformation_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="MutualInformation_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="MutualInformation_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="MutualInformation_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
<tr><td><code id="MutualInformation_+3A_base">base</code></td>
<td>
<p>The base for the logarithm. Default is 2. For polytomous data,
you can use &quot;V&quot; to set the base to min(rows, columns), &quot;e&quot; for natural logarithm (base e),
or any other number to use that specific base.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For binary data, the following formula is used:
</p>
<p style="text-align: center;"><code class="reqn">
MI_{jk} = p_{00} \log_2 \frac{p_{00}}{(1-p_j)(1-p_k)} + p_{01} \log_2 \frac{p_{01}}{(1-p_j)p_k}
 + p_{10} \log_2 \frac{p_{10}}{p_j(1-p_k)} + p_{11} \log_2 \frac{p_{11}}{p_jp_k}
</code>
</p>

<p>Where:
</p>

<ul>
<li> <p><code class="reqn">p_{00}</code> is the joint probability of incorrect responses to both items j and k
</p>
</li>
<li> <p><code class="reqn">p_{01}</code> is the joint probability of incorrect response to item j and correct to item k
</p>
</li>
<li> <p><code class="reqn">p_{10}</code> is the joint probability of correct response to item j and incorrect to item k
</p>
</li>
<li> <p><code class="reqn">p_{11}</code> is the joint probability of correct responses to both items j and k
</p>
</li></ul>

<p>For polytomous data, the following formula is used:
</p>
<p style="text-align: center;"><code class="reqn">MI_{jk} = \sum_{j=1}^{C_j}\sum_{k=1}^{C_k}p_{jk}\log \frac{p_{jk}}{p_{j.}p_{.k}}</code>
</p>

<p>The base of the logarithm can be the number of rows, number of columns, min(rows, columns),
base-10 logarithm, natural logarithm (e), etc.
</p>


<h3>Value</h3>

<p>A matrix of mutual information values with exametrika class.
Each element (i,j) represents the mutual information between items i and j,
measured in bits. Higher values indicate stronger interdependence between items.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate Mutual Information using sample dataset J15S500
MutualInformation(J15S500)
</code></pre>

<hr>
<h2 id='nrs'>Number Right Score</h2><span id='topic+nrs'></span><span id='topic+nrs.default'></span><span id='topic+nrs.binary'></span>

<h3>Description</h3>

<p>The Number-Right Score (NRS) function calculates the weighted sum of correct
responses for each examinee. This function is applicable only to binary
response data.
</p>
<p>For each examinee, the score is computed as:
</p>
<p style="text-align: center;"><code class="reqn">NRS_i = \sum_{j=1}^J z_{ij}u_{ij}w_j</code>
</p>

<p>where:
</p>

<ul>
<li> <p><code class="reqn">z_{ij}</code> is the missing response indicator (0/1)
</p>
</li>
<li> <p><code class="reqn">u_{ij}</code> is the response (0/1)
</p>
</li>
<li> <p><code class="reqn">w_j</code> is the item weight
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>nrs(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
nrs(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
nrs(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nrs_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="nrs_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="nrs_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="nrs_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the Number-Right Score for each examinee.
The score represents the weighted sum of correct answers, where:
</p>

<ul>
<li><p> Maximum score is the sum of all item weights
</p>
</li>
<li><p> Minimum score is 0
</p>
</li>
<li><p> Missing responses do not contribute to the score
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
nrs(J15S500)
</code></pre>

<hr>
<h2 id='objective_function_IRT'>Log-likelihood function used in the Maximization Step (M-Step).</h2><span id='topic+objective_function_IRT'></span>

<h3>Description</h3>

<p>Log-likelihood function used in the Maximization Step (M-Step).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>objective_function_IRT(lambda, model, qjtrue, qjfalse, quadrature)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="objective_function_IRT_+3A_lambda">lambda</code></td>
<td>
<p>item parameter vector</p>
</td></tr>
<tr><td><code id="objective_function_IRT_+3A_model">model</code></td>
<td>
<p>2,3,or 4 PL</p>
</td></tr>
<tr><td><code id="objective_function_IRT_+3A_qjtrue">qjtrue</code></td>
<td>
<p>correct resp pattern</p>
</td></tr>
<tr><td><code id="objective_function_IRT_+3A_qjfalse">qjfalse</code></td>
<td>
<p>incorrect resp pattern</p>
</td></tr>
<tr><td><code id="objective_function_IRT_+3A_quadrature">quadrature</code></td>
<td>
<p>Pattern of a segmented normal distribution.</p>
</td></tr>
</table>

<hr>
<h2 id='OmegaCoefficient'>Omega Coefficient</h2><span id='topic+OmegaCoefficient'></span>

<h3>Description</h3>

<p>This function computes Tau-Congeneric Measurement, also known as McDonald's tau coefficient, for a given data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OmegaCoefficient(x, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OmegaCoefficient_+3A_x">x</code></td>
<td>
<p>This should be a data matrix or a Covariance/Phi/Tetrachoric matrix.</p>
</td></tr>
<tr><td><code id="OmegaCoefficient_+3A_na">na</code></td>
<td>
<p>This parameter identifies the numbers or characters that should be treated as missing values when 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="OmegaCoefficient_+3A_z">Z</code></td>
<td>
<p>This parameter represents a missing indicator matrix. It is only needed if 'x' is a data matrix.</p>
</td></tr>
<tr><td><code id="OmegaCoefficient_+3A_w">w</code></td>
<td>
<p>This parameter is an item weight vector. It is only required if 'x' is a data matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For a correlation/covariance matrix input, returns a single numeric value
representing the omega coefficient. For a data matrix input, returns a list with
three components:
</p>

<dl>
<dt>OmegaCov</dt><dd><p>Omega coefficient calculated from covariance matrix</p>
</dd>
<dt>OmegaPhi</dt><dd><p>Omega coefficient calculated from phi coefficient matrix</p>
</dd>
<dt>OmegaTetrachoric</dt><dd><p>Omega coefficient calculated from tetrachoric correlation matrix</p>
</dd>
</dl>



<h3>References</h3>

<p>McDonald, R. P. (1999). Test theory: A unified treatment. Erlbaum.
</p>

<hr>
<h2 id='params_to_target_jac'>parameter transformation params_to_target</h2><span id='topic+params_to_target_jac'></span>

<h3>Description</h3>

<p>parameter transformation params_to_target
</p>


<h3>Usage</h3>

<pre><code class='language-R'>params_to_target_jac(a_vec, b_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="params_to_target_jac_+3A_a_vec">a_vec</code></td>
<td>
<p>vector of descriminant parameters</p>
</td></tr>
<tr><td><code id="params_to_target_jac_+3A_b_list">b_list</code></td>
<td>
<p>lists of difficuluty parameter vec</p>
</td></tr>
</table>

<hr>
<h2 id='passage'>Passage Rate of Student</h2><span id='topic+passage'></span><span id='topic+passage.default'></span><span id='topic+passage.binary'></span>

<h3>Description</h3>

<p>The Passage Rate for each student is calculated as their Number-Right Score (NRS)
divided by the number of items presented to them. This function is applicable
only to binary response data.
</p>
<p>The passage rate is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">P_i = \frac{\sum_{j=1}^J z_{ij}u_{ij}w_j}{\sum_{j=1}^J z_{ij}}</code>
</p>

<p>where:
</p>

<ul>
<li> <p><code class="reqn">z_{ij}</code> is the missing response indicator (0/1)
</p>
</li>
<li> <p><code class="reqn">u_{ij}</code> is the response (0/1)
</p>
</li>
<li> <p><code class="reqn">w_j</code> is the item weight
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>passage(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
passage(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
passage(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="passage_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="passage_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="passage_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="passage_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the passage rate for each student.
Values range from 0 to 1 (or maximum weight) where:
</p>

<ul>
<li><p> 1: Perfect score on all attempted items
</p>
</li>
<li><p> 0: No correct answers
</p>
</li>
<li><p> NA: No items attempted
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>The passage rate accounts for missing responses by only considering items that
were actually presented to each student. This provides a fair comparison
between students who attempted different numbers of items.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
passage(J15S500)

</code></pre>

<hr>
<h2 id='percentile'>Student Percentile Ranks</h2><span id='topic+percentile'></span><span id='topic+percentile.default'></span><span id='topic+percentile.binary'></span>

<h3>Description</h3>

<p>The percentile function calculates each student's relative standing in the group,
expressed as a percentile rank (1-100). This function is applicable only to
binary response data.
</p>
<p>The percentile rank indicates the percentage of scores in the distribution
that fall below a given score. For example, a percentile rank of 75 means
the student performed better than 75% of the group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentile(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
percentile(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
percentile(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="percentile_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="percentile_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="percentile_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="percentile_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of percentile ranks (1-100) for each student, where:
</p>

<ul>
<li><p> 100: Highest performing student(s)
</p>
</li>
<li><p> 50: Median performance
</p>
</li>
<li><p> 1: Lowest performing student(s)
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>Percentile ranks are calculated using the empirical cumulative distribution
function of standardized scores. Tied scores receive the same percentile rank.
The values are rounded up to the nearest integer to provide ranks from 1 to 100.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
percentile(J5S10)

</code></pre>

<hr>
<h2 id='PhiCoefficient'>Phi-Coefficient</h2><span id='topic+PhiCoefficient'></span><span id='topic+PhiCoefficient.default'></span><span id='topic+PhiCoefficient.binary'></span>

<h3>Description</h3>

<p>The phi coefficient is the Pearson's product moment correlation coefficient
between two binary items. This function is applicable only to binary response data.
The coefficient ranges from -1 to 1, where 1 indicates perfect positive correlation,
-1 indicates perfect negative correlation, and 0 indicates no correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PhiCoefficient(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
PhiCoefficient(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
PhiCoefficient(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PhiCoefficient_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="PhiCoefficient_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="PhiCoefficient_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="PhiCoefficient_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of phi coefficients with exametrika class.
Each element (i,j) represents the phi coefficient between items i and j.
The matrix is symmetric with ones on the diagonal.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
# Calculate Phi-Coefficient using sample dataset J15S500
PhiCoefficient(J15S500)
</code></pre>

<hr>
<h2 id='plot.exametrika'>Plot Method for Objects of Class &quot;exametrika&quot;</h2><span id='topic+plot.exametrika'></span>

<h3>Description</h3>

<p>Creates visualizations for objects with class &quot;exametrika&quot;.
The calculation results of the exametrika package have an exametrika class attribute,
along with the specific analysis model class (IRT, GRM, LCA, LRA, Biclustering, IRM, LDLRA, LDB,
BINET). Each model has its own compatible plot types, accessible by specifying the 'type' parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'exametrika'
plot(
  x,
  type = c("IRF", "TRF", "IIF", "TIF", "IIC", "ICC", "TIC", "IRP", "TRP", "LCD", "CMP",
    "FRP", "RMP", "LRD", "Array", "CRV", "RRV", "FieldPIRP", "LDPSR", "ScoreFreq",
    "ScoreRank", "ICRP", "ICBR"),
  items = NULL,
  students = NULL,
  nc = 1,
  nr = 1,
  overlay = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.exametrika_+3A_x">x</code></td>
<td>
<p>An object of class &quot;exametrika&quot;</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_type">type</code></td>
<td>
<p>Character string specifying the plot type. Available types vary by model:
</p>

<dl>
<dt>IRF, ICC</dt><dd><p>Item Response Function. Also known as 'ICC' (Item Characteristic Curve).</p>
</dd>
<dt>TRF</dt><dd><p>Test Response Function.</p>
</dd>
<dt>IIF, IIC</dt><dd><p>Item Information Function. Also known as 'IIC' (Item Information Curve).</p>
</dd>
<dt>TIF, TIC</dt><dd><p>Test Information Function. Also known as 'TIC' (Test Information Curve).</p>
</dd>
<dt>IRP</dt><dd><p>Item Reference Profile. Line graph with items and latent classes/ranks
on the horizontal axis, and membership probability on the vertical axis.</p>
</dd>
<dt>CRV, RRV</dt><dd><p>Class/Rank Reference Vector. Plots correct answer rates for each class or rank,
with fields on the horizontal axis and correct answer rates on the vertical axis.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile. Shows latent classes/ranks on the horizontal axis,
displaying members per class/rank as a bar graph and expected test scores as a line graph.</p>
</dd>
<dt>LCD</dt><dd><p>Latent Class Distribution. Displays latent classes on the horizontal axis,
showing members per class as a bar graph and cumulative membership probability as a line.</p>
</dd>
<dt>LRD</dt><dd><p>Latent Rank Distribution. Similar to LCD but with ranks instead of classes on the horizontal axis.</p>
</dd>
<dt>CMP</dt><dd><p>Class Membership Profile. Line graph showing class membership probabilities of students.</p>
</dd>
<dt>RMP</dt><dd><p>Rank Membership Profile. Similar to CMP but with ranks instead of classes.</p>
</dd>
<dt>ScoreFreq</dt><dd><p>Frequency polygon of score distribution with rank thresholds.</p>
</dd>
<dt>ScoreRank</dt><dd><p>Heatmap of score membership probabilities for each rank.</p>
</dd>
<dt>ICRP</dt><dd><p>Visualizes ranks (x-axis) versus category response probabilities (y-axis).</p>
</dd>
<dt>ICBR</dt><dd><p>Visualizes ranks (x-axis) versus cumulative category probabilities (y-axis).</p>
</dd>
<dt>FRP</dt><dd><p>Field Reference Profile. Shows correspondence between fields and latent classes/ranks.</p>
</dd>
<dt>Array</dt><dd><p>Array plot for Biclustering/Ranklustering. Colored matrix cells where darker cells
indicate larger values.</p>
</dd>
<dt>FieldPIRP</dt><dd><p>Shows correct response rates by number of correct answers in parent fields.
Only available for LDB model.</p>
</dd>
<dt>LDPSR</dt><dd><p>Latent Dependence Passing Student Rate. Compares passing rates of parent and child classes.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_items">items</code></td>
<td>
<p>Numeric vector specifying which items to plot. If NULL, all items are included.
When type is &quot;IIF&quot;/&quot;IIC&quot;, specifying 0 will produce a TIF/TIC for the entire test.</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_students">students</code></td>
<td>
<p>Numeric vector specifying which students to plot. If NULL, all students are included.</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_nc">nc</code></td>
<td>
<p>Integer specifying the number of columns for multiple plots. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_nr">nr</code></td>
<td>
<p>Integer specifying the number of rows for multiple plots. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_overlay">overlay</code></td>
<td>
<p>Logical. If TRUE, elements such as IRFs will be overlaid on a single plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.exametrika_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each model class supports specific plot types:
</p>

<dl>
<dt>IRT</dt><dd><p>Supports &quot;IRF&quot;/&quot;ICC&quot;, &quot;TRF&quot;, &quot;IIF&quot;/&quot;IIC&quot;, &quot;TIF&quot;/&quot;TIC&quot;</p>
</dd>
<dt>GRM</dt><dd><p>Supports &quot;IRF&quot;/&quot;ICC&quot;, &quot;IIF&quot;/&quot;IIC&quot;, &quot;TIF&quot;/&quot;TIC&quot;</p>
</dd>
<dt>LCA</dt><dd><p>Supports &quot;IRP&quot;, &quot;FRP&quot;, &quot;TRP&quot;, &quot;LCD&quot;, &quot;CMP&quot;</p>
</dd>
<dt>LRA</dt><dd><p>Supports &quot;IRP&quot;, &quot;FRP&quot;, &quot;TRP&quot;, &quot;LRD&quot;, &quot;RMP&quot;</p>
</dd>
<dt>LRAordinal</dt><dd><p>Supports &quot;ScoreFreq&quot;, &quot;ScoreRank&quot;, &quot;ICRP&quot;, &quot;ICBR&quot;, &quot;RMP&quot;</p>
</dd>
<dt>LRArated</dt><dd><p>Supports &quot;ScoreFreq&quot;, &quot;ScoreRank&quot;, &quot;ICRP&quot;, &quot;RMP&quot;</p>
</dd>
<dt>Biclustering</dt><dd><p>Supports &quot;FRP&quot;, &quot;TRP&quot;, &quot;LCD&quot;, &quot;LRD&quot;, &quot;CMP&quot;, &quot;RMP&quot;, &quot;CRV&quot;, &quot;RRV&quot;, &quot;Array&quot;</p>
</dd>
<dt>IRM</dt><dd><p>Supports &quot;FRP&quot;, &quot;TRP&quot;, &quot;Array&quot;</p>
</dd>
<dt>LDLRA</dt><dd><p>Supports &quot;IRP&quot;, &quot;TRP&quot;, &quot;LRD&quot;, &quot;RMP&quot;</p>
</dd>
<dt>LDB</dt><dd><p>Supports &quot;FRP&quot;, &quot;TRP&quot;, &quot;LRD&quot;, &quot;RMP&quot;, &quot;Array&quot;, &quot;FieldPIRP&quot;</p>
</dd>
<dt>BINET</dt><dd><p>Supports &quot;FRP&quot;, &quot;TRP&quot;, &quot;LRD&quot;, &quot;RMP&quot;, &quot;Array&quot;, &quot;LDPSR&quot;</p>
</dd>
</dl>



<h3>Value</h3>

<p>Produces visualizations based on the model class and specified type:
</p>

<dl>
<dt>IRT models</dt><dd><p>IRF (Item Response Function), TRF (Test Response Function),
IIF (Item Information Function), TIF (Test Information Function)</p>
</dd>
<dt>LCA/LRA models</dt><dd><p>IRP (Item Reference Profile), TRP (Test Reference Profile),
LCD/LRD (Latent Class/Rank Distribution), CMP/RMP (Class/Rank Membership Profile)</p>
</dd>
<dt>Biclustering/IRM models</dt><dd><p>Array plots showing clustering patterns, FRP, TRP, etc.</p>
</dd>
<dt>LDLRA/LDB/BINET models</dt><dd><p>Network and profile plots specific to each model</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# IRT model example
irt_result &lt;- exametrika::IRT(U)
plot(irt_result, type = "IRF", items = 1:5)
plot(irt_result, type = "TIF")

# LCA model example
lca_result &lt;- exametrika::LCA(U)
plot(lca_result, type = "IRP")
plot(lca_result, type = "LCD")

## End(Not run)

</code></pre>

<hr>
<h2 id='polychoric'>Polychoric Correlation</h2><span id='topic+polychoric'></span>

<h3>Description</h3>

<p>Calculate the polychoric correlation coefficient between two polytomous (categorical ordinal) variables.
Polychoric correlation estimates the correlation between two theorized normally distributed
continuous latent variables from two observed ordinal variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polychoric(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="polychoric_+3A_x">x</code></td>
<td>
<p>A polytomous vector (categorical ordinal variable)</p>
</td></tr>
<tr><td><code id="polychoric_+3A_y">y</code></td>
<td>
<p>A polytomous vector (categorical ordinal variable)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function handles missing values (coded as -1 or NA) using pairwise deletion.
The estimation uses maximum likelihood approach with Brent's method for optimization.
</p>


<h3>Value</h3>

<p>The polychoric correlation coefficient between x and y
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example with simulated data
set.seed(123)
x &lt;- sample(1:5, 100, replace = TRUE)
y &lt;- sample(1:4, 100, replace = TRUE)
polychoric(x, y)

</code></pre>

<hr>
<h2 id='polychoric_likelihood'>Calculate Polychoric Correlation Likelihood</h2><span id='topic+polychoric_likelihood'></span>

<h3>Description</h3>

<p>Calculates the negative log-likelihood for estimating polychoric correlation
from a contingency table of two ordinal variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polychoric_likelihood(rho, mat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="polychoric_likelihood_+3A_rho">rho</code></td>
<td>
<p>Numeric value between -1 and 1, the correlation coefficient</p>
</td></tr>
<tr><td><code id="polychoric_likelihood_+3A_mat">mat</code></td>
<td>
<p>A contingency table matrix for two ordinal variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function estimates thresholds from the marginal distributions and
calculates the expected probabilities based on a bivariate normal distribution.
It then computes the log-likelihood by comparing observed and expected frequencies.
</p>


<h3>Value</h3>

<p>The negative log-likelihood value for the given correlation coefficient
</p>

<hr>
<h2 id='PolychoricCorrelationMatrix'>Polychoric Correlation Matrix</h2><span id='topic+PolychoricCorrelationMatrix'></span><span id='topic+PolychoricCorrelationMatrix.default'></span><span id='topic+PolychoricCorrelationMatrix.ordinal'></span>

<h3>Description</h3>

<p>Polychoric Correlation Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PolychoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
PolychoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
PolychoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PolychoricCorrelationMatrix_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="PolychoricCorrelationMatrix_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="PolychoricCorrelationMatrix_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="PolychoricCorrelationMatrix_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of polychoric correlations with exametrika class.
Each element (i,j) represents the polychoric correlation between items i and j.
The matrix is symmetric with ones on the diagonal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example code
PolychoricCorrelationMatrix(J5S1000)

</code></pre>

<hr>
<h2 id='polyserial'>Polyserial Correlation</h2><span id='topic+polyserial'></span>

<h3>Description</h3>

<p>Calculates the polyserial correlation coefficient between a continuous variable and an ordinal variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polyserial(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="polyserial_+3A_x">x</code></td>
<td>
<p>A numeric vector representing the continuous variable.</p>
</td></tr>
<tr><td><code id="polyserial_+3A_y">y</code></td>
<td>
<p>A numeric vector representing the ordinal variable (must be integer values).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements Olsson et al.'s ad hoc method for estimating the polyserial correlation
coefficient. The method assumes that the continuous variable follows a normal distribution and
that the ordinal variable is derived from an underlying continuous normal variable through
thresholds.
</p>


<h3>Value</h3>

<p>A numeric value representing the estimated polyserial correlation coefficient.
</p>


<h3>References</h3>

<p>U.Olsson, F.Drasgow, and N.Dorans (1982).
The polyserial correlation coefficient. Psychometrika, 47,337-347.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 300
x &lt;- rnorm(n)
y &lt;- sample(1:5, size = n, replace = TRUE)
polyserial(x, y)
</code></pre>

<hr>
<h2 id='print.exametrika'>Print Method for Exametrika Objects</h2><span id='topic+print.exametrika'></span>

<h3>Description</h3>

<p>S3 method for printing objects of class &quot;exametrika&quot;. This function formats and displays
appropriate summary information based on the specific subclass of the exametrika object.
Different types of analysis results (IRT, LCA, network models, etc.) are presented
with customized formatting to highlight the most relevant information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'exametrika'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.exametrika_+3A_x">x</code></td>
<td>
<p>An object of class &quot;exametrika&quot; with various possible subclasses</p>
</td></tr>
<tr><td><code id="print.exametrika_+3A_digits">digits</code></td>
<td>
<p>Integer indicating the number of decimal places to display. Default is 3.</p>
</td></tr>
<tr><td><code id="print.exametrika_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to print methods (not currently used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function identifies the specific subclass of the exametrika object and tailors the
output accordingly. For most analysis types, the function displays:
</p>

<ul>
<li><p> Basic model description and parameters
</p>
</li>
<li><p> Estimation results (e.g., item parameters, latent class profiles)
</p>
</li>
<li><p> Model fit statistics and diagnostics
</p>
</li>
<li><p> Visual representations where appropriate (e.g., graphs for network models, scree plots
for dimensionality analysis)
</p>
</li></ul>

<p>When printing network-based models (LDLRA, LDB, BINET), this function visualizes
the network structure using graphs, which can help in interpreting complex relationships
between items or latent variables.
</p>


<h3>Value</h3>

<p>Prints a formatted summary of the exametrika object to the console, with content
varying by object subclass:
</p>

<dl>
<dt>TestStatistics</dt><dd><p>Basic descriptive statistics of the test</p>
</dd>
<dt>Dimensionality</dt><dd><p>Eigenvalue analysis results with scree plot</p>
</dd>
<dt>ItemStatistics</dt><dd><p>Item-level statistics and psychometric properties</p>
</dd>
<dt>QitemStatistics</dt><dd><p>Item statistics for polytomous items</p>
</dd>
<dt>exametrikaData</dt><dd><p>Data structure details including response patterns and weights</p>
</dd>
<dt>IIAnalysis</dt><dd><p>Item-item relationship measures (tetrachoric correlations, etc.)</p>
</dd>
<dt>CTT</dt><dd><p>Classical Test Theory reliability measures</p>
</dd>
<dt>IRT/GRM</dt><dd><p>Item parameters, ability estimates, and fit indices</p>
</dd>
<dt>LCA/LRA</dt><dd><p>Class/Rank profiles, distribution information, and model fit statistics</p>
</dd>
<dt>Biclustering/IRM</dt><dd><p>Cluster profiles, field distributions, and model diagnostics</p>
</dd>
<dt>LDLRA/LDB/BINET</dt><dd><p>Network visualizations, parameter estimates, and conditional probabilities</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Print IRT analysis results with 4 decimal places
result &lt;- IRT(J15S500)
print(result, digits = 4)

# Print Latent Class Analysis results
result_lca &lt;- LCA(J15S500, ncls = 3)
print(result_lca)


</code></pre>

<hr>
<h2 id='PSD_item_params'>internal functions for PSD of Item parameters</h2><span id='topic+PSD_item_params'></span>

<h3>Description</h3>

<p>internal functions for PSD of Item parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PSD_item_params(model, Lambda, quadrature, marginal_posttheta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PSD_item_params_+3A_model">model</code></td>
<td>
<p>2,3,or 4PL</p>
</td></tr>
<tr><td><code id="PSD_item_params_+3A_lambda">Lambda</code></td>
<td>
<p>item parameters Matrix</p>
</td></tr>
<tr><td><code id="PSD_item_params_+3A_quadrature">quadrature</code></td>
<td>
<p>quads</p>
</td></tr>
<tr><td><code id="PSD_item_params_+3A_marginal_posttheta">marginal_posttheta</code></td>
<td>
<p>marginal post theta</p>
</td></tr>
</table>

<hr>
<h2 id='qBiNormal'>bivariate normal CDF</h2><span id='topic+qBiNormal'></span>

<h3>Description</h3>

<p>Calculates the cumulative distribution function (CDF) of a bivariate normal distribution.
This function computes P(X &lt;= a, Y &lt;= b) where X and Y follow a bivariate normal
distribution with correlation coefficient rho.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qBiNormal(a, b, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qBiNormal_+3A_a">a</code></td>
<td>
<p>Numeric value, the upper limit for the first variable.</p>
</td></tr>
<tr><td><code id="qBiNormal_+3A_b">b</code></td>
<td>
<p>Numeric value, the upper limit for the second variable.</p>
</td></tr>
<tr><td><code id="qBiNormal_+3A_rho">rho</code></td>
<td>
<p>Numeric value between -1 and 1, the correlation coefficient.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation uses numerical integration with Gauss-Legendre quadrature
for accurate computation. Special cases for infinite bounds are handled separately.
</p>


<h3>Value</h3>

<p>The probability P(X &lt;= a, Y &lt;= b), a value between 0 and 1.
</p>

<hr>
<h2 id='RaschModel'>Rasch Model</h2><span id='topic+RaschModel'></span>

<h3>Description</h3>

<p>The one-parameter logistic model is a model with only one parameter b.
This model is a 2PLM model in which a is constrained to 1.
This model is also called the Rasch model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RaschModel(b, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaschModel_+3A_b">b</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="RaschModel_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of probabilities between 0 and 1, representing
the probability of a correct response given the ability level theta. The probability
is calculated using the formula: <code class="reqn">P(\theta) = \frac{1}{1 + e^{-(\theta-b)}}</code>
</p>

<hr>
<h2 id='response_type_error'>Generate Error Message for Invalid Response Type</h2><span id='topic+response_type_error'></span>

<h3>Description</h3>

<p>Internal function to generate standardized error messages when a function
is called with an incompatible response type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response_type_error(response_type, fun_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="response_type_error_+3A_response_type">response_type</code></td>
<td>
<p>character. One of &quot;binary&quot;, &quot;rated&quot;, &quot;ordinal&quot;, or &quot;nominal&quot;</p>
</td></tr>
<tr><td><code id="response_type_error_+3A_fun_name">fun_name</code></td>
<td>
<p>character. Name of the calling function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Never returns; always stops with an error message
</p>

<hr>
<h2 id='score_function_with_Jacobian'>score function for grm</h2><span id='topic+score_function_with_Jacobian'></span>

<h3>Description</h3>

<p>score function for grm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score_function_with_Jacobian(target, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="score_function_with_Jacobian_+3A_target">target</code></td>
<td>
<p>target vector</p>
</td></tr>
<tr><td><code id="score_function_with_Jacobian_+3A_dat">dat</code></td>
<td>
<p>data set</p>
</td></tr>
</table>

<hr>
<h2 id='ScoreReport'>Generate Score Report for Non-Binary Test Data</h2><span id='topic+ScoreReport'></span>

<h3>Description</h3>

<p>Calculates comprehensive descriptive statistics for a test, including measures of
central tendency, variability, distribution shape, and reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScoreReport(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ScoreReport_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="ScoreReport_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values</p>
</td></tr>
<tr><td><code id="ScoreReport_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="ScoreReport_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended for non-binary (ordinal or rated) response data. It calculates
descriptive statistics for the overall test performance. If binary data is provided,
an error message will be displayed.
</p>


<h3>Value</h3>

<p>An object of class &quot;exametrika&quot; and &quot;TestStatistics&quot; containing:
</p>

<dl>
<dt>TestLength</dt><dd><p>Number of items included in the test</p>
</dd>
<dt>SampleSize</dt><dd><p>Number of examinees (rows) in the dataset</p>
</dd>
<dt>Mean</dt><dd><p>Average score across all examinees</p>
</dd>
<dt>Median</dt><dd><p>Median score</p>
</dd>
<dt>SD</dt><dd><p>Standard deviation of test scores</p>
</dd>
<dt>Variance</dt><dd><p>Variance of test scores</p>
</dd>
<dt>Skewness</dt><dd><p>Skewness of the score distribution (measure of asymmetry)</p>
</dd>
<dt>Kurtosis</dt><dd><p>Kurtosis of the score distribution (measure of tail extremity)</p>
</dd>
<dt>Min</dt><dd><p>Minimum score obtained</p>
</dd>
<dt>Max</dt><dd><p>Maximum score obtained</p>
</dd>
<dt>Range</dt><dd><p>Difference between maximum and minimum scores</p>
</dd>
<dt>Alpha</dt><dd><p>Cronbach's alpha coefficient, a measure of internal consistency reliability</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate score report for sample ordinal data
ScoreReport(J15S3810)

# Example with rated data
ScoreReport(J35S5000)


</code></pre>

<hr>
<h2 id='slopeprior'>Prior distribution function with respect to the slope.</h2><span id='topic+slopeprior'></span>

<h3>Description</h3>

<p>Prior distribution function with respect to the slope.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slopeprior(a, m, s, const = 1e-15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slopeprior_+3A_a">a</code></td>
<td>
<p>slope coefficient</p>
</td></tr>
<tr><td><code id="slopeprior_+3A_m">m</code></td>
<td>
<p>prior parameter to be set</p>
</td></tr>
<tr><td><code id="slopeprior_+3A_s">s</code></td>
<td>
<p>prior parameter to be set</p>
</td></tr>
<tr><td><code id="slopeprior_+3A_const">const</code></td>
<td>
<p>A very small constant</p>
</td></tr>
</table>

<hr>
<h2 id='softmax'>softmax function</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>to avoid overflow
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>

<hr>
<h2 id='sscore'>Standardized Score</h2><span id='topic+sscore'></span><span id='topic+sscore.default'></span><span id='topic+sscore.binary'></span>

<h3>Description</h3>

<p>The standardized score (z-score) indicates how far a student's performance
deviates from the mean in units of standard deviation. This function is
applicable only to binary response data.
</p>
<p>The score is calculated by standardizing the passage rates:
</p>
<p style="text-align: center;"><code class="reqn">Z_i = \frac{r_i - \bar{r}}{\sigma_r}</code>
</p>

<p>where:
</p>

<ul>
<li> <p><code class="reqn">r_i</code> is student i's passage rate
</p>
</li>
<li> <p><code class="reqn">\bar{r}</code> is the mean passage rate
</p>
</li>
<li> <p><code class="reqn">\sigma_r</code> is the standard deviation of passage rates
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sscore(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
sscore(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
sscore(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sscore_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="sscore_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="sscore_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="sscore_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of standardized scores for each student. The scores follow
a standard normal distribution with:
</p>

<ul>
<li><p> Mean = 0
</p>
</li>
<li><p> Standard deviation = 1
</p>
</li>
<li><p> Approximately 68% of scores between -1 and 1
</p>
</li>
<li><p> Approximately 95% of scores between -2 and 2
</p>
</li>
<li><p> Approximately 99% of scores between -3 and 3
</p>
</li></ul>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>The standardization allows for comparing student performance across different
tests or groups. A positive score indicates above-average performance, while
a negative score indicates below-average performance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
sscore(J5S10)
</code></pre>

<hr>
<h2 id='stanine'>Stanine Scores</h2><span id='topic+stanine'></span><span id='topic+stanine.default'></span><span id='topic+stanine.binary'></span>

<h3>Description</h3>

<p>The Stanine (Standard Nine) scoring system divides students into nine groups
based on a normalized distribution. This function is applicable only to
binary response data.
</p>
<p>These groups correspond to the following percentile ranges:
</p>

<ul>
<li><p> Stanine 1: lowest 4% (percentiles 1-4)
</p>
</li>
<li><p> Stanine 2: next 7% (percentiles 5-11)
</p>
</li>
<li><p> Stanine 3: next 12% (percentiles 12-23)
</p>
</li>
<li><p> Stanine 4: next 17% (percentiles 24-40)
</p>
</li>
<li><p> Stanine 5: middle 20% (percentiles 41-60)
</p>
</li>
<li><p> Stanine 6: next 17% (percentiles 61-77)
</p>
</li>
<li><p> Stanine 7: next 12% (percentiles 78-89)
</p>
</li>
<li><p> Stanine 8: next 7% (percentiles 90-96)
</p>
</li>
<li><p> Stanine 9: highest 4% (percentiles 97-100)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>stanine(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
stanine(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
stanine(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stanine_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="stanine_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="stanine_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="stanine_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing two elements:
</p>

<dl>
<dt>stanine</dt><dd><p>The score boundaries for each stanine level</p>
</dd>
<dt>stanineScore</dt><dd><p>The stanine score (1-9) for each student</p>
</dd>
</dl>



<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>
<p>Stanine scores provide a normalized scale with:
</p>

<ul>
<li><p> Mean = 5
</p>
</li>
<li><p> Standard deviation = 2
</p>
</li>
<li><p> Scores range from 1 to 9
</p>
</li>
<li><p> Score of 5 represents average performance
</p>
</li></ul>



<h3>References</h3>

<p>Angoff, W. H. (1984). Scales, norms, and equivalent scores. Educational Testing Service.
(Reprint of chapter in R. L. Thorndike (Ed.) (1971) Educational Measurement (2nd Ed.).
American Council on Education.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result &lt;- stanine(J15S500)
# View score boundaries
result$stanine
# View individual scores
result$stanineScore

</code></pre>

<hr>
<h2 id='StrLearningGA_BNM'>Structure Learning for BNM by simple GA</h2><span id='topic+StrLearningGA_BNM'></span>

<h3>Description</h3>

<p>Generating a DAG from data using a genetic algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrLearningGA_BNM(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  seed = 123,
  population = 20,
  Rs = 0.5,
  Rm = 0.005,
  maxParents = 2,
  maxGeneration = 100,
  successiveLimit = 5,
  crossover = 0,
  elitism = 0,
  filename = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="StrLearningGA_BNM_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_seed">seed</code></td>
<td>
<p>seed for random.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_population">population</code></td>
<td>
<p>Population size. The default is 20</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_rs">Rs</code></td>
<td>
<p>Survival Rate. The default is 0.5</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_rm">Rm</code></td>
<td>
<p>Mutation Rate. The default is 0.005</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_maxparents">maxParents</code></td>
<td>
<p>Maximum number of edges emanating from a single node. The default is 2.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_maxgeneration">maxGeneration</code></td>
<td>
<p>Maximum number of generations.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_successivelimit">successiveLimit</code></td>
<td>
<p>Termination conditions. If the optimal individual does not change
for this number of generations, it is considered to have converged.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_crossover">crossover</code></td>
<td>
<p>Configure crossover using numerical values. Specify 0 for uniform
crossover, where bits are randomly copied from both parents. Choose 1 for single-point
crossover with one crossover point, and 2 for two-point crossover with two crossover points.
The default is 0.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_elitism">elitism</code></td>
<td>
<p>Number of elites that remain without crossover when transitioning to
the next generation.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_filename">filename</code></td>
<td>
<p>Specify the filename when saving the generated adjacency matrix in CSV format.
The default is null, and no output is written to the file.</p>
</td></tr>
<tr><td><code id="StrLearningGA_BNM_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates a DAG from data using a genetic algorithm.
Depending on the size of the data and the settings, the computation may
take a significant amount of computational time. For details on the
settings or algorithm, see Shojima(2022), section 8.5
</p>


<h3>Value</h3>


<dl>
<dt>adj</dt><dd><p>Optimal adjacency matrix</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>crr</dt><dd><p>correct response ratio</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>adj</dt><dd><p>Adjacency matrix</p>
</dd>
<dt>param</dt><dd><p>Learned Parameters</p>
</dd>
<dt>CCRR_table</dt><dd><p>Correct Response Rate tables</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Perform Structure Learning for Bayesian Network Model using Genetic Algorithm
# Parameters are set for balanced exploration and computational efficiency
StrLearningGA_BNM(J5S10,
  population = 20, # Size of population in each generation
  Rs = 0.5, # 50% survival rate for next generation
  Rm = 0.002, # 0.2% mutation rate for genetic diversity
  maxParents = 2, # Maximum of 2 parent nodes per item
  maxGeneration = 100, # Maximum number of evolutionary steps
  crossover = 2, # Use two-point crossover method
  elitism = 2 # Keep 2 best solutions in each generation
)

</code></pre>

<hr>
<h2 id='StrLearningPBIL_BNM'>Structure Learning for BNM by PBIL</h2><span id='topic+StrLearningPBIL_BNM'></span>

<h3>Description</h3>

<p>Generating a DAG from data using a Population-Based Incremental Learning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrLearningPBIL_BNM(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  seed = 123,
  population = 20,
  Rs = 0.5,
  Rm = 0.002,
  maxParents = 2,
  maxGeneration = 100,
  successiveLimit = 5,
  elitism = 0,
  alpha = 0.05,
  estimate = 1,
  filename = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="StrLearningPBIL_BNM_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_seed">seed</code></td>
<td>
<p>seed for random.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_population">population</code></td>
<td>
<p>Population size. The default is 20</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_rs">Rs</code></td>
<td>
<p>Survival Rate. The default is 0.5</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_rm">Rm</code></td>
<td>
<p>Mutation Rate. The default is 0.002</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_maxparents">maxParents</code></td>
<td>
<p>Maximum number of edges emanating from a single node. The default is 2.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_maxgeneration">maxGeneration</code></td>
<td>
<p>Maximum number of generations.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_successivelimit">successiveLimit</code></td>
<td>
<p>Termination conditions. If the optimal individual does not change
for this number of generations, it is considered to have converged.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_elitism">elitism</code></td>
<td>
<p>Number of elites that remain without crossover when transitioning to
the next generation.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_alpha">alpha</code></td>
<td>
<p>Learning rate. The default is 0.05</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_estimate">estimate</code></td>
<td>
<p>In PBIL for estimating the adjacency matrix, specify by number from the
following four methods: 1. Optimal adjacency matrix, 2. Rounded average of individuals in
the last generation, 3. Rounded average of survivors in the last generation, 4. Rounded
generational gene of the last generation. The default is 1.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_filename">filename</code></td>
<td>
<p>Specify the filename when saving the generated adjacency matrix in CSV format.
The default is null, and no output is written to the file.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_BNM_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs structural learning using the Population-Based
Incremental Learning model(PBIL) proposed by Fukuda et al.(2014) within
the genetic algorithm framework. Instead of learning the adjacency matrix
itself, the 'genes of genes' that generate the adjacency matrix are updated
with each generation. For more details, please refer to Fukuda(2014) and Section
8.5.2 of the text(Shojima,2022).
</p>


<h3>Value</h3>


<dl>
<dt>adj</dt><dd><p>Optimal adjacency matrix</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>crr</dt><dd><p>correct response ratio</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>param</dt><dd><p>Learned Parameters</p>
</dd>
<dt>CCRR_table</dt><dd><p>Correct Response Rate tables</p>
</dd>
</dl>



<h3>References</h3>

<p>Fukuda, S., Yamanaka, Y., &amp; Yoshihiro, T. (2014). A Probability-based evolutionary
algorithm with mutations to learn Bayesian networks. International Journal of Artificial
Intelligence and Interactive Multimedia, 3, 7–13. DOI: 10.9781/ijimai.2014.311
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Perform Structure Learning for Bayesian Network Model using PBIL
# (Population-Based Incremental Learning)
StrLearningPBIL_BNM(J5S10,
  population = 20, # Size of population in each generation
  Rs = 0.5, # 50% survival rate for next generation
  Rm = 0.005, # 0.5% mutation rate for genetic diversity
  maxParents = 2, # Maximum of 2 parent nodes per item
  alpha = 0.05, # Learning rate for probability update
  estimate = 4 # Use rounded generational gene method
)

</code></pre>

<hr>
<h2 id='StrLearningPBIL_LDLRA'>Structure Learning for LDLRA by PBIL algorithm</h2><span id='topic+StrLearningPBIL_LDLRA'></span>

<h3>Description</h3>

<p>Generating DAG list from data using Population-Based Incremental learning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrLearningPBIL_LDLRA(
  U,
  Z = NULL,
  w = NULL,
  na = NULL,
  seed = 123,
  ncls = 2,
  method = "R",
  population = 20,
  Rs = 0.5,
  Rm = 0.002,
  maxParents = 2,
  maxGeneration = 100,
  successiveLimit = 5,
  elitism = 0,
  alpha = 0.05,
  estimate = 1,
  filename = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_seed">seed</code></td>
<td>
<p>seed for random.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_ncls">ncls</code></td>
<td>
<p>number of latent class(rank). The default is 2.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_method">method</code></td>
<td>
<p>specify the model to analyze the data.Local dependence latent
class model is set to &quot;C&quot;, latent rank model is set &quot;R&quot;. The default is &quot;R&quot;.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_population">population</code></td>
<td>
<p>Population size. The default is 20</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_rs">Rs</code></td>
<td>
<p>Survival Rate. The default is 0.5</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_rm">Rm</code></td>
<td>
<p>Mutation Rate. The default is 0.002</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_maxparents">maxParents</code></td>
<td>
<p>Maximum number of edges emanating from a single node. The default is 2.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_maxgeneration">maxGeneration</code></td>
<td>
<p>Maximum number of generations.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_successivelimit">successiveLimit</code></td>
<td>
<p>Termination conditions. If the optimal individual does not change
for this number of generations, it is considered to have converged.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_elitism">elitism</code></td>
<td>
<p>Number of elites that remain without crossover when transitioning to
the next generation.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_alpha">alpha</code></td>
<td>
<p>Learning rate. The default is 0.05</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_estimate">estimate</code></td>
<td>
<p>In PBIL for estimating the adjacency matrix, specify by number from the
following four methods: 1. Optimal adjacency matrix, 2. Rounded average of individuals in
the last generation, 3. Rounded average of survivors in the last generation, 4. Rounded
generational gene of the last generation. The default is 1.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_filename">filename</code></td>
<td>
<p>Specify the filename when saving the generated adjacency matrix in CSV format.
The default is null, and no output is written to the file.</p>
</td></tr>
<tr><td><code id="StrLearningPBIL_LDLRA_+3A_verbose">verbose</code></td>
<td>
<p>verbose output Flag. default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs structural learning for each classes by using
the Population-Based Incremental Learning model(PBIL) proposed by
Fukuda et al.(2014) within the genetic algorithm framework.
Instead of learning the adjacency matrix itself, the 'genes of genes'
that generate the adjacency matrix are updated with each generation.
For more details, please refer to Fukuda(2014) and Section
9.4.3 of the text(Shojima,2022).
</p>


<h3>Value</h3>


<dl>
<dt>nobs</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>testlength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>crr</dt><dd><p>correct response ratio</p>
</dd>
<dt>adj_list</dt><dd><p>adjacency matrix list</p>
</dd>
<dt>g_list</dt><dd><p>graph list</p>
</dd>
<dt>referenceMatrix</dt><dd><p>Learned Parameters.A three-dimensional array of patterns where
item x rank x pattern.</p>
</dd>
<dt>IRP</dt><dd><p>Marginal Item Reference Matrix</p>
</dd>
<dt>IRPIndex</dt><dd><p>IRP Indices which include Alpha, Beta, Gamma.</p>
</dd>
<dt>TRP</dt><dd><p>Test Reference Profile matrix.</p>
</dd>
<dt>LRD</dt><dd><p>latent Rank/Class Distribution</p>
</dd>
<dt>RMD</dt><dd><p>Rank/Class Membership Distribution</p>
</dd>
<dt>TestFitIndices</dt><dd><p>Overall fit index for the test.See also <a href="#topic+TestFit">TestFit</a></p>
</dd>
<dt>Estimation_table</dt><dd><p>Estimated parameters tables.</p>
</dd>
<dt>CCRR_table</dt><dd><p>Correct Response Rate tables</p>
</dd>
<dt>Studens</dt><dd><p>Student information. It includes estimated class
membership, probability of class membership, RUO, and RDO.</p>
</dd>
</dl>



<h3>References</h3>

<p>Fukuda, S., Yamanaka, Y., &amp; Yoshihiro, T. (2014). A Probability-based evolutionary
algorithm with mutations to learn Bayesian networks. International Journal of Artificial
Intelligence and Interactive Multimedia, 3, 7–13. DOI: 10.9781/ijimai.2014.311
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Perform Structure Learning for LDLRA using PBIL algorithm
# This process may take considerable time due to evolutionary optimization
result.LDLRA.PBIL &lt;- StrLearningPBIL_LDLRA(J35S515,
  seed = 123, # Set random seed for reproducibility
  ncls = 5, # Number of latent ranks
  maxGeneration = 10,
  method = "R", # Use rank model (vs. class model)
  elitism = 1, # Keep best solution in each generation
  successiveLimit = 15 # Convergence criterion
)

# Examine the learned network structure
# Plot Item Response Profiles showing item patterns across ranks
plot(result.LDLRA.PBIL, type = "IRP", nc = 4, nr = 3)

# Plot Test Response Profile showing overall response patterns
plot(result.LDLRA.PBIL, type = "TRP")

# Plot Latent Rank Distribution showing student distribution
plot(result.LDLRA.PBIL, type = "LRD")

</code></pre>

<hr>
<h2 id='StudentAnalysis'>StudentAnalysis</h2><span id='topic+StudentAnalysis'></span>

<h3>Description</h3>

<p>The StudentAnalysis function returns descriptive statistics for each individual student.
Specifically, it provides the number of responses, the number of correct answers,
the passage rate, the standardized score, the percentile, and the stanine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StudentAnalysis(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="StudentAnalysis_+3A_u">U</code></td>
<td>
<p>U is a data matrix of the type matrix or data.frame.</p>
</td></tr>
<tr><td><code id="StudentAnalysis_+3A_na">na</code></td>
<td>
<p>na argument specifies the numbers or characters to be treated as missing values.
</p>

<ul>
<li><p> ID: Student identifier
</p>
</li>
<li><p> NR: Number of responses
</p>
</li>
<li><p> NRS: Number-right score (total correct answers)
</p>
</li>
<li><p> PR: Passage rate (proportion correct)
</p>
</li>
<li><p> SS: Standardized score (z-score)
</p>
</li>
<li><p> Percentile: Student's percentile rank
</p>
</li>
<li><p> Stanine: Student's stanine score (1-9)
</p>
</li></ul>
</td></tr>
<tr><td><code id="StudentAnalysis_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="StudentAnalysis_+3A_w">w</code></td>
<td>
<p>w is item weight vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame containing the following columns for each student:
</p>

<ul>
<li><p> ID: Student identifier
</p>
</li>
<li><p> NR: Number of responses
</p>
</li>
<li><p> NRS: Number-right score (total correct answers)
</p>
</li>
<li><p> PR: Passage rate (proportion correct)
</p>
</li>
<li><p> SS: Standardized score (z-score)
</p>
</li>
<li><p> Percentile: Student's percentile rank
</p>
</li>
<li><p> Stanine: Student's stanine score (1-9)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># using sample dataset
StudentAnalysis(J15S500)
</code></pre>

<hr>
<h2 id='target_to_params_jac'>parameter transformation target_to_params</h2><span id='topic+target_to_params_jac'></span>

<h3>Description</h3>

<p>parameter transformation target_to_params
</p>


<h3>Usage</h3>

<pre><code class='language-R'>target_to_params_jac(target, nitems, ncat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="target_to_params_jac_+3A_target">target</code></td>
<td>
<p>optimize target vector</p>
</td></tr>
<tr><td><code id="target_to_params_jac_+3A_nitems">nitems</code></td>
<td>
<p>number of items</p>
</td></tr>
<tr><td><code id="target_to_params_jac_+3A_ncat">ncat</code></td>
<td>
<p>number of categories for each items</p>
</td></tr>
</table>

<hr>
<h2 id='TestFit'>Model Fit Functions for test whole</h2><span id='topic+TestFit'></span>

<h3>Description</h3>

<p>A general function that returns the model fit indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestFit(U, Z, ell_A, nparam)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TestFit_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="TestFit_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="TestFit_+3A_ell_a">ell_A</code></td>
<td>
<p>log likelihood of this model</p>
</td></tr>
<tr><td><code id="TestFit_+3A_nparam">nparam</code></td>
<td>
<p>number of parameters for this model</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>model_log_like</dt><dd><p>log likelihood of analysis model</p>
</dd>
<dt>bench_log_like</dt><dd><p>log likelihood of benchmark model</p>
</dd>
<dt>null_log_like</dt><dd><p>log likelihood of null model</p>
</dd>
<dt>model_Chi_sq</dt><dd><p>Chi-Square statistics for analysis model</p>
</dd>
<dt>null_Chi_sq</dt><dd><p>Chi-Square statistics for null model</p>
</dd>
<dt>model_df</dt><dd><p>degrees of freedom of analysis model</p>
</dd>
<dt>null_df</dt><dd><p>degrees of freedom of null model</p>
</dd>
<dt>NFI</dt><dd><p>Normed Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RFI</dt><dd><p>Relative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>IFI</dt><dd><p>Incremental Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>TLI</dt><dd><p>Tucker-Lewis Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>CFI</dt><dd><p>Comparative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RMSEA</dt><dd><p>Root Mean Square Error of Approximation. Smaller values closer to 0.0 indicate a better fit.</p>
</dd>
<dt>AIC</dt><dd><p>Akaike Information Criterion. A lower value indicates a better fit.</p>
</dd>
<dt>CAIC</dt><dd><p>Consistent AIC.A lower value indicates a better fit.</p>
</dd>
<dt>BIC</dt><dd><p>Bayesian Information Criterion. A lower value indicates a better fit.</p>
</dd>
</dl>


<hr>
<h2 id='TestFitSaturated'>Model Fit Functions for saturated model</h2><span id='topic+TestFitSaturated'></span>

<h3>Description</h3>

<p>A general function that returns the model fit indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestFitSaturated(U, Z, ell_A, nparam)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TestFitSaturated_+3A_u">U</code></td>
<td>
<p>U is either a data class of exametrika, or raw data. When raw data is given,
it is converted to the exametrika class with the <a href="#topic+dataFormat">dataFormat</a> function.</p>
</td></tr>
<tr><td><code id="TestFitSaturated_+3A_z">Z</code></td>
<td>
<p>Z is a missing indicator matrix of the type matrix or data.frame</p>
</td></tr>
<tr><td><code id="TestFitSaturated_+3A_ell_a">ell_A</code></td>
<td>
<p>log likelihood of this model</p>
</td></tr>
<tr><td><code id="TestFitSaturated_+3A_nparam">nparam</code></td>
<td>
<p>number of parameters for this model</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>model_log_like</dt><dd><p>log likelihood of analysis model</p>
</dd>
<dt>bench_log_like</dt><dd><p>log likelihood of benchmark model</p>
</dd>
<dt>null_log_like</dt><dd><p>log likelihood of null model</p>
</dd>
<dt>model_Chi_sq</dt><dd><p>Chi-Square statistics for analysis model</p>
</dd>
<dt>null_Chi_sq</dt><dd><p>Chi-Square statistics for null model</p>
</dd>
<dt>model_df</dt><dd><p>degrees of freedom of analysis model</p>
</dd>
<dt>null_df</dt><dd><p>degrees of freedom of null model</p>
</dd>
<dt>NFI</dt><dd><p>Normed Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RFI</dt><dd><p>Relative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>IFI</dt><dd><p>Incremental Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>TLI</dt><dd><p>Tucker-Lewis Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>CFI</dt><dd><p>Comparative Fit Index. Lager values closer to 1.0 indicate a better fit.</p>
</dd>
<dt>RMSEA</dt><dd><p>Root Mean Square Error of Approximation. Smaller values closer to 0.0 indicate a better fit.</p>
</dd>
<dt>AIC</dt><dd><p>Akaike Information Criterion. A lower value indicates a better fit.</p>
</dd>
<dt>CAIC</dt><dd><p>Consistent AIC.A lower value indicates a better fit.</p>
</dd>
<dt>BIC</dt><dd><p>Bayesian Information Criterion. A lower value indicates a better fit.</p>
</dd>
</dl>


<hr>
<h2 id='TestInformationFunc'>TIF for IRT</h2><span id='topic+TestInformationFunc'></span>

<h3>Description</h3>

<p>Test Information Function for 4PLM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestInformationFunc(params, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TestInformationFunc_+3A_params">params</code></td>
<td>
<p>parameter matrix</p>
</td></tr>
<tr><td><code id="TestInformationFunc_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector representing the test information at each ability
level theta. The test information is the sum of item information functions for
all items in the test: <code class="reqn">I_{test}(\theta) = \sum_{j=1}^n I_j(\theta)</code>
</p>

<hr>
<h2 id='TestResponseFunc'>TRF for IRT</h2><span id='topic+TestResponseFunc'></span>

<h3>Description</h3>

<p>Calculates the expected score across all items on a test for a given ability level (theta)
using Item Response Theory. The Test Response Function (TRF) is essentially the sum of
the Item Characteristic Curves (ICCs) for all items in the test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestResponseFunc(params, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TestResponseFunc_+3A_params">params</code></td>
<td>
<p>parameter matrix</p>
</td></tr>
<tr><td><code id="TestResponseFunc_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Test Response Function computes the expected total score for an examinee with a given
ability level (theta) across all items in the test. For each item, the function uses the
logistic model with parameters a (discrimination), b (difficulty), c (guessing), and
d (upper asymptote).
</p>


<h3>Value</h3>

<p>A numeric vector with the same length as theta, containing the expected total score
for each ability level.
</p>

<hr>
<h2 id='TestStatistics'>Simple Test Statistics</h2><span id='topic+TestStatistics'></span><span id='topic+TestStatistics.default'></span><span id='topic+TestStatistics.binary'></span><span id='topic+TestStatistics.ordinal'></span>

<h3>Description</h3>

<p>Calculates descriptive statistics for test scores, providing a comprehensive
summary of central tendency, variability, and distribution shape.
Different statistics are calculated based on the data type (binary, ordinal, rated, or nominal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestStatistics(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
TestStatistics(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
TestStatistics(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'ordinal'
TestStatistics(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TestStatistics_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="TestStatistics_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="TestStatistics_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="TestStatistics_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object depends on the data type:
</p>
<p>For binary data, a list of class c(&quot;exametrika&quot;, &quot;TestStatistics&quot;) containing:
</p>

<dl>
<dt>TestLength</dt><dd><p>Length of the test. The number of items included in the test.</p>
</dd>
<dt>SampleSize</dt><dd><p>Sample size. The number of rows in the dataset.</p>
</dd>
<dt>Mean</dt><dd><p>Average number of correct answers.</p>
</dd>
<dt>SEofMean</dt><dd><p>Standard error of mean.</p>
</dd>
<dt>Variance</dt><dd><p>Variance of test scores.</p>
</dd>
<dt>SD</dt><dd><p>Standard Deviation of test scores.</p>
</dd>
<dt>Skewness</dt><dd><p>Skewness of score distribution (measure of asymmetry).</p>
</dd>
<dt>Kurtosis</dt><dd><p>Kurtosis of score distribution (measure of tail extremity).</p>
</dd>
<dt>Min</dt><dd><p>Minimum score.</p>
</dd>
<dt>Max</dt><dd><p>Maximum score.</p>
</dd>
<dt>Range</dt><dd><p>Range of scores (Max - Min).</p>
</dd>
<dt>Q1</dt><dd><p>First quartile. Same as the 25th percentile.</p>
</dd>
<dt>Median</dt><dd><p>Median. Same as the 50th percentile.</p>
</dd>
<dt>Q3</dt><dd><p>Third quartile. Same as the 75th percentile.</p>
</dd>
<dt>IQR</dt><dd><p>Interquartile range. Calculated by subtracting Q1 from Q3.</p>
</dd>
<dt>Stanine</dt><dd><p>Stanine score boundaries, see <code><a href="#topic+stanine">stanine</a></code>.</p>
</dd>
</dl>

<p>For ordinal and rated data, the function calls <code><a href="#topic+ScoreReport">ScoreReport</a></code> and returns
its result. See <code><a href="#topic+ScoreReport">ScoreReport</a></code> for details of the returned object.
</p>
<p>For nominal data, an error is returned as this function does not support nominal data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Basic usage
stats &lt;- TestStatistics(J15S500)
print(stats)

# Extract specific statistics
cat("Mean score:", stats$Mean, "\n")
cat("Standard deviation:", stats$SD, "\n")

# View score distribution summary
summary_stats &lt;- data.frame(
  Min = stats$Min,
  Q1 = stats$Q1,
  Median = stats$Median,
  Mean = stats$Mean,
  Q3 = stats$Q3,
  Max = stats$Max
)
print(summary_stats)
</code></pre>

<hr>
<h2 id='tetrachoric'>Tetrachoric Correlation</h2><span id='topic+tetrachoric'></span>

<h3>Description</h3>

<p>Tetrachoric Correlation is superior to the phi coefficient as a measure of the
relation of an item pair. See Divgi, 1979; Olsson, 1979;Harris, 1988.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tetrachoric(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tetrachoric_+3A_x">x</code></td>
<td>
<p>binary vector x</p>
</td></tr>
<tr><td><code id="tetrachoric_+3A_y">y</code></td>
<td>
<p>binary vector y</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single numeric value of class &quot;exametrika&quot; representing the
tetrachoric correlation coefficient between the two binary variables. The value
ranges from -1 to 1, where:
</p>

<ul>
<li><p> 1 indicates perfect positive correlation
</p>
</li>
<li><p> -1 indicates perfect negative correlation
</p>
</li>
<li><p> 0 indicates no correlation
</p>
</li></ul>



<h3>References</h3>

<p>Divgi, D. R. (1979). Calculation of the tetrachoric correlation coefficient.
Psychometrika, 44, 169–172.
</p>
<p>Olsson, U. (1979). Maximum likelihood estimation of the polychoric correlation
coefficient. Psychometrika,44, 443–460.
</p>
<p>Harris, B. (1988). Tetrachoric correlation coefficient. In L. Kotz, &amp; N. L. Johnson
(Eds.), Encyclopedia of statistical sciences (Vol. 9, pp. 223–225). Wiley.
</p>

<hr>
<h2 id='TetrachoricCorrelationMatrix'>Tetrachoric Correlation Matrix</h2><span id='topic+TetrachoricCorrelationMatrix'></span><span id='topic+TetrachoricCorrelationMatrix.default'></span><span id='topic+TetrachoricCorrelationMatrix.binary'></span>

<h3>Description</h3>

<p>Calculates the matrix of tetrachoric correlations between all pairs of items.
Tetrachoric Correlation is superior to the phi coefficient as a measure of the
relation of an item pair. This function is applicable only to binary response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TetrachoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)

## Default S3 method:
TetrachoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)

## S3 method for class 'binary'
TetrachoricCorrelationMatrix(U, na = NULL, Z = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TetrachoricCorrelationMatrix_+3A_u">U</code></td>
<td>
<p>Either an object of class &quot;exametrika&quot; or raw data. When raw data is given,
it is converted to the exametrika class with the <code><a href="#topic+dataFormat">dataFormat</a></code> function.</p>
</td></tr>
<tr><td><code id="TetrachoricCorrelationMatrix_+3A_na">na</code></td>
<td>
<p>Values to be treated as missing values.</p>
</td></tr>
<tr><td><code id="TetrachoricCorrelationMatrix_+3A_z">Z</code></td>
<td>
<p>Missing indicator matrix of type matrix or data.frame. Values of 1 indicate
observed responses, while 0 indicates missing data.</p>
</td></tr>
<tr><td><code id="TetrachoricCorrelationMatrix_+3A_w">w</code></td>
<td>
<p>Item weight vector specifying the relative importance of each item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of tetrachoric correlations with exametrika class.
Each element (i,j) represents the tetrachoric correlation between items i and j.
The matrix is symmetric with ones on the diagonal.
</p>


<h3>Note</h3>

<p>This function is implemented using a binary data compatibility wrapper and
will raise an error if used with polytomous data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example code
TetrachoricCorrelationMatrix(J15S500)

</code></pre>

<hr>
<h2 id='ThreePLM'>Three-Parameter Logistic Model</h2><span id='topic+ThreePLM'></span>

<h3>Description</h3>

<p>The three-parameter logistic model is a model where the lower
asymptote parameter c is added to the 2PLM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ThreePLM(a, b, c, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ThreePLM_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="ThreePLM_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="ThreePLM_+3A_c">c</code></td>
<td>
<p>lower asymptote parameter</p>
</td></tr>
<tr><td><code id="ThreePLM_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of probabilities between c and 1, representing
the probability of a correct response given the ability level theta. The probability
is calculated using the formula: <code class="reqn">P(\theta) = c + \frac{1-c}{1 + e^{-a(\theta-b)}}</code>
</p>

<hr>
<h2 id='TwoPLM'>Two-Parameter Logistic Model</h2><span id='topic+TwoPLM'></span>

<h3>Description</h3>

<p>The two-parameter logistic model is a classic model that defines
the probability of a student with ability theta successfully
answering item j, using both a slope parameter and a
location parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TwoPLM(a, b, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TwoPLM_+3A_a">a</code></td>
<td>
<p>slope parameter</p>
</td></tr>
<tr><td><code id="TwoPLM_+3A_b">b</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="TwoPLM_+3A_theta">theta</code></td>
<td>
<p>ability parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of probabilities between 0 and 1, representing
the probability of a correct response given the ability level theta. The probability
is calculated using the formula: <code class="reqn">P(\theta) = \frac{1}{1 + e^{-a(\theta-b)}}</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
