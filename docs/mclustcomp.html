<!DOCTYPE html><html><head><title>Help for package mclustcomp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mclustcomp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mclustcomp-package'><p>Measures for Comparing Clusterings</p></a></li>
<li><a href='#get.commsize'><p>Compute community size of a clustering</p></a></li>
<li><a href='#get.confusion'><p>Compute confusion matrix</p></a></li>
<li><a href='#get.pair'><p>Comembership matrix of size <code>(2-by-2)</code></p></a></li>
<li><a href='#get.probs'><p>Compute confusion matrix</p></a></li>
<li><a href='#mclustcomp'><p>Measures for Comparing Clusterings</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Measures for Comparing Clusters</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Given a set of data points, a clustering is defined as a disjoint partition
    where each pair of sets in a partition has no overlapping elements. 
    This package provides 25 methods that play a role somewhat similar to 
    distance or metric that measures similarity of two clusterings - or partitions.
    For a more detailed description, see Meila, M. (2005) &lt;<a href="https://doi.org/10.1145%2F1102351.1102424">doi:10.1145/1102351.1102424</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, Rdpack</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-06-12 06:23:48 UTC; kisung</td>
</tr>
<tr>
<td>Author:</td>
<td>Kisung You [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kisung You &lt;kisungyou@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-06-13 04:40:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='mclustcomp-package'>Measures for Comparing Clusterings</h2><span id='topic+mclustcomp-package'></span>

<h3>Description</h3>

<p>Given a set of data points <code class="reqn">D</code>, a clustering <code class="reqn">C = (C_1,C_2,...,C_k)</code> is
a partition where each pair of sets <code class="reqn">C_i</code> and <code class="reqn">C_j</code> has no overlapping
elements. <span class="pkg">mclustcomp</span> package provides a collection of methods that play a
role similar to <em>distance</em> or <em>metric</em>
in that measures similarity of two clusterings (or,
partitions) <code class="reqn">C</code> and <code class="reqn">C'</code>. For a more detailed description,
see Meila, M. (2005) &lt;doi:10.1145/1102351.1102424&gt;.
</p>

<hr>
<h2 id='get.commsize'>Compute community size of a clustering</h2><span id='topic+get.commsize'></span>

<h3>Description</h3>

<p>Compute community size of a clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.commsize(x, ux)
</code></pre>

<hr>
<h2 id='get.confusion'>Compute confusion matrix</h2><span id='topic+get.confusion'></span>

<h3>Description</h3>

<p>Compute confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.confusion(x, y, ux, uy)
</code></pre>

<hr>
<h2 id='get.pair'>Comembership matrix of size <code>(2-by-2)</code></h2><span id='topic+get.pair'></span>

<h3>Description</h3>

<p>Comembership matrix of size <code>(2-by-2)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.pair(x, y)
</code></pre>

<hr>
<h2 id='get.probs'>Compute confusion matrix</h2><span id='topic+get.probs'></span>

<h3>Description</h3>

<p>Compute confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.probs(confmat, scx, scy, n, threps)
</code></pre>

<hr>
<h2 id='mclustcomp'>Measures for Comparing Clusterings</h2><span id='topic+mclustcomp'></span>

<h3>Description</h3>

<p>Given two partitions or clusterings <code class="reqn">C_1</code> and <code class="reqn">C_2</code>, it returns community comparison scores
corresponding with a set of designated methods. Note that two label vectors should be
of same length having either numeric or factor type. Currently we have 3 classes of methods
depending on methodological philosophy behind each. See below for the taxonomy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustcomp(x, y, types = "all", tversky.param = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustcomp_+3A_x">x</code>, <code id="mclustcomp_+3A_y">y</code></td>
<td>
<p>vectors of clustering labels</p>
</td></tr>
<tr><td><code id="mclustcomp_+3A_types">types</code></td>
<td>
<p><code>"all"</code> for returning scores for every available measure.
Either a single score name or a vector of score names can be supplied. See the section
for the list of the methods for details.</p>
</td></tr>
<tr><td><code id="mclustcomp_+3A_tversky.param">tversky.param</code></td>
<td>
<p>a list of parameters for Tversky index; <code>alpha</code> and <code>beta</code> for
weight parameters, and <code>sym</code>, a logical where <code>FALSE</code> stands for original method, <code>TRUE</code>
for a revised variant to symmetrize the score. Default (alpha,beta)=(1,1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame with columns <code>types</code> and corresponding <code>scores</code>.
</p>


<h3>Category 1. Counting Pairs</h3>


<table>
<tr>
 <td style="text-align: center;">
TYPE </td><td style="text-align: left;"> FULL NAME </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'adjrand'</code>  </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Rand_index">Adjusted Rand index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'chisq'</code>    </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Chi-squared_test">Chi-Squared Coefficient</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'fmi'</code>      </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Fowlkes-Mallows_index">Fowlkes-Mallows index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'jaccard'</code>  </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'mirkin'</code>   </td><td style="text-align: left;"> Mirkin Metric, or Equivalence Mismatch Distance. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'overlap'</code>  </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Overlap_coefficient">Overlap Coefficient</a>, or Szymkiewicz-Simpson coefficient.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'pd'</code>       </td><td style="text-align: left;"> Partition Difference.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'rand'</code>     </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Rand_index">Rand Index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'sdc'</code>      </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Sorensen-Dice_coefficient">Sørensen–Dice Coefficient</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'smc'</code>      </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Simple_matching_coefficient">Simple Matching Coefficient</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'tanimoto'</code> </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Jaccard_index">Tanimoto index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'tversky'</code>  </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Tversky_index">Tversky index</a>.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'wallace1'</code> </td><td style="text-align: left;"> Wallace Criterion Type 1.</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'wallace2'</code> </td><td style="text-align: left;"> Wallace Criterion Type 2.
</td>
</tr>

</table>

<p>Note that Tanimoto Coefficient and Dice's coefficient are special cases with (alpha,beta) = (1,1) and (0.5,0.5), respectively.
</p>


<h3>Category 2. Set Overlaps/Matching</h3>


<table>
<tr>
 <td style="text-align: center;">
TYPE </td><td style="text-align: left;"> FULL NAME </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'f'</code>   </td><td style="text-align: left;"> F-Measure. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'mhm'</code> </td><td style="text-align: left;"> Meila-Heckerman Measure. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'mmm'</code> </td><td style="text-align: left;"> Maximum-Match Measure. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'vdm'</code> </td><td style="text-align: left;"> Van Dongen Measure.
</td>
</tr>

</table>



<h3>Category 3. Information Theory</h3>


<table>
<tr>
 <td style="text-align: center;">
TYPE </td><td style="text-align: left;"> FULL NAME </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'jent'</code> </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Joint_entropy">Joint Entropy</a> </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'mi'</code>   </td><td style="text-align: left;"> Mutual Information. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'nmi1'</code> </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Mutual_information">Normalized Mutual Information</a> by Strehl and Ghosh. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'nmi2'</code> </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Mutual_information">Normalized Mutual Information</a> by Fred and Jain. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'nmi3'</code> </td><td style="text-align: left;"> Normalized Mutual Information by Danon et al. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'nvi'</code>  </td><td style="text-align: left;"> Normalized Variation of Information. </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>'vi'</code>   </td><td style="text-align: left;"> <a href="https://en.wikipedia.org/wiki/Variation_of_information">Variation of Information</a>.
</td>
</tr>

</table>



<h3>References</h3>

<p>Strehl A, Ghosh J (2003).
&ldquo;Cluster Ensembles — a Knowledge Reuse Framework for Combining Multiple Partitions.&rdquo;
<em>J. Mach. Learn. Res.</em>, <b>3</b>, 583&ndash;617.
ISSN 1532-4435.
</p>
<p>Meilă M (2007).
&ldquo;Comparing clusterings—an information based distance.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>98</b>(5), 873&ndash;895.
ISSN 0047259X.
</p>
<p>Meilă M (2003).
&ldquo;Comparing Clusterings by the Variation of Information.&rdquo;
In Goos G, Hartmanis J, van Leeuwen J, Schölkopf B, Warmuth MK (eds.), <em>Learning Theory and Kernel Machines</em>, volume 2777, 173&ndash;187.
Springer Berlin Heidelberg, Berlin, Heidelberg.
ISBN 978-3-540-40720-1 978-3-540-45167-9.
</p>
<p>Wagner S, Wagner D (2007).
&ldquo;Comparing Clusterings – An Overview.&rdquo;
Technical Report 2006-04, Department of Informatics.
</p>
<p>Albatineh AN, Niewiadomska-Bugaj M, Mihalko D (2006).
&ldquo;On Similarity Indices and Correction for Chance Agreement.&rdquo;
<em>Journal of Classification</em>, <b>23</b>(2), 301&ndash;313.
ISSN 0176-4268, 1432-1343.
</p>
<p>Mirkin B (2001).
&ldquo;Eleven Ways to Look at the Chi-Squared Coefficient for Contingency Tables.&rdquo;
<em>The American Statistician</em>, <b>55</b>(2), 111&ndash;120.
ISSN 0003-1305, 1537-2731.
</p>
<p>Rand WM (1971).
&ldquo;Objective Criteria for the Evaluation of Clustering Methods.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>66</b>(336), 846.
ISSN 01621459.
</p>
<p>Kuncheva LI, Hadjitodorov ST (2004).
&ldquo;Using diversity in cluster ensembles.&rdquo;
In <em>Proceedings of the IEEE International Conference on Systems, Man and Cybernetics</em>, volume 2, 1214&ndash;1219.
ISBN 978-0-7803-8567-2.
</p>
<p>Fowlkes EB, Mallows CL (1983).
&ldquo;A Method for Comparing Two Hierarchical Clusterings.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>78</b>(383), 553&ndash;569.
ISSN 0162-1459, 1537-274X.
</p>
<p>Dongen S (2000).
&ldquo;Performance Criteria for Graph Clustering and Markov Cluster Experiments.&rdquo;
CWI (Centre for Mathematics and Computer Science), Amsterdam, The Netherlands, The Netherlands.
</p>
<p>Jaccard P (1912).
&ldquo;THE DISTRIBUTION OF THE FLORA IN THE ALPINE ZONE.1.&rdquo;
<em>New Phytologist</em>, <b>11</b>(2), 37&ndash;50.
ISSN 0028-646X, 1469-8137.
</p>
<p>Li T, Ogihara M, Ma S (2010).
&ldquo;On combining multiple clusterings: an overview and a new perspective.&rdquo;
<em>Applied Intelligence</em>, <b>33</b>(2), 207&ndash;219.
ISSN 0924-669X, 1573-7497.
</p>
<p>Larsen B, Aone C (1999).
&ldquo;Fast and effective text mining using linear-time document clustering.&rdquo;
In <em>Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 16&ndash;22.
ISBN 978-1-58113-143-7.
</p>
<p>Meilă M, Heckerman D (2001).
&ldquo;An Experimental Comparison of Model-Based Clustering Methods.&rdquo;
<em>Machine Learning</em>, <b>42</b>(1), 9&ndash;29.
ISSN 1573-0565.
</p>
<p>Cover TM, Thomas JA (2006).
<em>Elements of information theory</em>, 2nd ed edition.
Wiley-Interscience, Hoboken, N.J.
ISBN 978-0-471-24195-9, OCLC: ocm59879802.
</p>
<p>Ana LNF, Jain AK (2003).
&ldquo;Robust data clustering.&rdquo;
In <em>2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</em>, volume 2, II&ndash;128&ndash;II&ndash;133.
ISBN 978-0-7695-1900-5.
</p>
<p>Wallace DL (1983).
&ldquo;Comment.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>78</b>(383), 569&ndash;576.
ISSN 0162-1459, 1537-274X.
</p>
<p>Simpson GG (1943).
&ldquo;Mammals and the nature of continents.&rdquo;
<em>American Journal of Science</em>, <b>241</b>, 1&ndash;31.
</p>
<p>Dice LR (1945).
&ldquo;Measures of the Amount of Ecologic Association Between Species.&rdquo;
<em>Ecology</em>, <b>26</b>(3), 297&ndash;302.
ISSN 00129658.
</p>
<p>Segaran T (2007).
<em>Programming collective intelligence: building smart web 2.0 applications</em>, 1st ed edition.
O'Reilly, Beijing ; Sebastapol [CA].
ISBN 978-0-596-52932-1, OCLC: ocn166886837.
</p>
<p>Tversky A (1977).
&ldquo;Features of similarity.&rdquo;
<em>Psychological Review</em>, <b>84</b>(4), 327&ndash;352.
ISSN 0033-295X.
</p>
<p>Danon L, Díaz-Guilera A, Duch J, Arenas A (2005).
&ldquo;Comparing community structure identification.&rdquo;
<em>Journal of Statistical Mechanics: Theory and Experiment</em>, <b>2005</b>(09), P09008&ndash;P09008.
ISSN 1742-5468.
</p>
<p>Lancichinetti A, Fortunato S, Kertész J (2009).
&ldquo;Detecting the overlapping and hierarchical community structure in complex networks.&rdquo;
<em>New Journal of Physics</em>, <b>11</b>(3), 033015.
ISSN 1367-2630.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1. compare two identical clusterings
x = sample(1:5,20,replace=TRUE) # label from 1 to 5, 10 elements
y = x                           # set two labels x and y equal
mclustcomp(x,y)                 # show all results

## example 2. selection of a few methods
z = sample(1:4,20,replace=TRUE)           # generate a non-trivial clustering
cmethods = c("jaccard","tanimoto","rand") # select 3 methods
mclustcomp(x,z,types=cmethods)            # test with the selected scores

## example 3. tversky.param
tparam = list()                           # create an empty list
tparam$alpha = 2
tparam$beta  = 3
tparam$sym   = TRUE
mclustcomp(x,z,types="tversky")           # default set as Tanimoto case.
mclustcomp(x,z,types="tversky",tversky.param=tparam)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
