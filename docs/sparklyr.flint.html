<!DOCTYPE html><html><head><title>Help for package sparklyr.flint</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sparklyr.flint}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#asof_future_left_join'><p>Temporal future left join</p></a></li>
<li><a href='#asof_join'><p>Temporal join</p></a></li>
<li><a href='#asof_left_join'><p>Temporal left join</p></a></li>
<li><a href='#collect.ts_rdd'><p>Collect data from a TimeSeriesRDD</p></a></li>
<li><a href='#from_rdd'><p>Construct a TimeSeriesRDD from a Spark RDD of rows</p></a></li>
<li><a href='#from_sdf'><p>Construct a TimeSeriesRDD from a Spark DataFrame</p></a></li>
<li><a href='#init'><p>Dependencies and initialization procedures</p></a></li>
<li><a href='#ols_regression'><p>OLS regression</p></a></li>
<li><a href='#sdf_utils'><p>Utility functions for importing a Spark data frame into a TimeSeriesRDD</p></a></li>
<li><a href='#spark_connection'><p>Retrieve Spark connection associated with an R object</p></a></li>
<li><a href='#spark_connection.ts_rdd'><p>Retrieve Spark connection associated with an R object</p></a></li>
<li><a href='#spark_dataframe'><p>Retrieve a Spark DataFrame</p></a></li>
<li><a href='#spark_dataframe.ts_rdd'><p>Retrieve a Spark DataFrame</p></a></li>
<li><a href='#spark_jobj'><p>Retrieve a Spark JVM Object Reference</p></a></li>
<li><a href='#spark_jobj.ts_rdd'><p>Retrieve a Spark JVM Object Reference</p></a></li>
<li><a href='#summarize_avg'><p>Average summarizer</p></a></li>
<li><a href='#summarize_corr'><p>Correlation summarizer</p></a></li>
<li><a href='#summarize_corr2'><p>Pairwise correlation summarizer</p></a></li>
<li><a href='#summarize_count'><p>Count summarizer</p></a></li>
<li><a href='#summarize_covar'><p>Covariance summarizer</p></a></li>
<li><a href='#summarize_dot_product'><p>Dot product summarizer</p></a></li>
<li><a href='#summarize_ema_half_life'><p>EMA half-life summarizer</p></a></li>
<li><a href='#summarize_ewma'><p>Exponential weighted moving average summarizer</p></a></li>
<li><a href='#summarize_geometric_mean'><p>Geometric mean summarizer</p></a></li>
<li><a href='#summarize_kurtosis'><p>Kurtosis summarizer</p></a></li>
<li><a href='#summarize_max'><p>Maximum value summarizer</p></a></li>
<li><a href='#summarize_min'><p>Minimum value summarizer</p></a></li>
<li><a href='#summarize_nth_central_moment'><p>N-th central moment summarizer</p></a></li>
<li><a href='#summarize_nth_moment'><p>N-th moment summarizer</p></a></li>
<li><a href='#summarize_product'><p>Product summarizer</p></a></li>
<li><a href='#summarize_quantile'><p>Quantile summarizer</p></a></li>
<li><a href='#summarize_skewness'><p>Skewness summarizer</p></a></li>
<li><a href='#summarize_stddev'><p>Standard deviation summarizer</p></a></li>
<li><a href='#summarize_sum'><p>Sum summarizer</p></a></li>
<li><a href='#summarize_var'><p>Variance summarizer</p></a></li>
<li><a href='#summarize_weighted_avg'><p>Weighted average summarizer</p></a></li>
<li><a href='#summarize_weighted_corr'><p>Pearson weighted correlation summarizer</p></a></li>
<li><a href='#summarize_weighted_covar'><p>Weighted covariance summarizer</p></a></li>
<li><a href='#summarize_z_score'><p>Z-score summarizer</p></a></li>
<li><a href='#summarizers'><p>Wrapper functions for commonly used summarizer functions</p></a></li>
<li><a href='#to_sdf'><p>Export data from TimeSeriesRDD to a Spark dataframe</p></a></li>
<li><a href='#try_spark_connect'><p>Attempt to establish a Spark connection</p></a></li>
<li><a href='#ts_rdd_builder'><p>TimeSeriesRDD builder object</p></a></li>
<li><a href='#window_exprs'><p>Time window specifications</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparklyr Extension for 'Flint'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Edgar Ruiz &lt;edgar@rstudio.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This sparklyr extension makes 'Flint' time series
    library functionalities (<a href="https://github.com/twosigma/flint">https://github.com/twosigma/flint</a>) easily
    accessible through R.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td>&lt;<a href="https://github.com/r-spark/sparklyr.flint&amp;gt;">https://github.com/r-spark/sparklyr.flint&gt;</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-spark/sparklyr.flint/issues">https://github.com/r-spark/sparklyr.flint/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dbplyr, dplyr, rlang, sparklyr (&ge; 1.3)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, tibble</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Spark: 2.x or above</td>
</tr>
<tr>
<td>Collate:</td>
<td>'imports.R' 'globals.R' 'sdf_utils.R' 'asof_join.R' 'init.R'
'window_exprs.R' 'summarizers.R' 'ols_regression.R'
'reexports.R' 'utils.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-10 15:59:43 UTC; yitaoli</td>
</tr>
<tr>
<td>Author:</td>
<td>Yitao Li <a href="https://orcid.org/0000-0002-1261-905X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Edgar Ruiz [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-11 08:50:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='asof_future_left_join'>Temporal future left join</h2><span id='topic+asof_future_left_join'></span>

<h3>Description</h3>

<p>Perform left-outer join on 2 'TimeSeriesRDD's based on inexact timestamp
matches, where each record from 'left' with timestamp 't' matches the
record from 'right' having the most recent timestamp at or after 't' if
'strict_lookahead' is FALSE (default) or having the most recent timestamp
strictly after 't' if 'strict_lookahead' is TRUE.
Notice this is equivalent to 'asof_join()' with 'direction' = &quot;&gt;=&quot; if
'strict_lookahead' is FALSE (default) or direction '&gt;' if
'strict_lookahead' is TRUE.
See <code><a href="#topic+asof_join">asof_join</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asof_future_left_join(
  left,
  right,
  tol = "0ms",
  key_columns = list(),
  left_prefix = NULL,
  right_prefix = NULL,
  strict_lookahead = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asof_future_left_join_+3A_left">left</code></td>
<td>
<p>The left 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_right">right</code></td>
<td>
<p>The right 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_tol">tol</code></td>
<td>
<p>A character vector specifying a time duration (e.g., &quot;0ns&quot;, &quot;5ms&quot;,
&quot;5s&quot;, &quot;1d&quot;, etc) as the tolerance for absolute difference in timestamp values
between each record from 'left' and its matching record from 'right'.
By default, 'tol' is &quot;0ns&quot;, which means a record from 'left' will only be
matched with a record from 'right' if both contain the exact same timestamps.</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_key_columns">key_columns</code></td>
<td>
<p>Columns to be used as the matching key among records from
'left' and 'right': if non-empty, then in addition to matching criteria
imposed by timestamps, a record from 'left' will only match one from the
'right' only if they also have equal values in all key columns.</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_left_prefix">left_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'left' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_right_prefix">right_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'right' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
<tr><td><code id="asof_future_left_join_+3A_strict_lookahead">strict_lookahead</code></td>
<td>
<p>Whether each record from 'left' with timestamp 't'
should match record from 'right' with the smallest timestamp strictly
greater than 't' (default: FALSE)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Temporal join functions: 
<code><a href="#topic+asof_join">asof_join</a>()</code>,
<code><a href="#topic+asof_left_join">asof_left_join</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")
if (!is.null(sc)) {
  ts_1 &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10))) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_2 &lt;- copy_to(sc, tibble::tibble(t = seq(10) + 1, v = seq(10) + 1L)) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  future_left_join_ts &lt;- asof_future_left_join(ts_1, ts_2, tol = "1s")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='asof_join'>Temporal join</h2><span id='topic+asof_join'></span>

<h3>Description</h3>

<p>Perform left-outer join on 2 'TimeSeriesRDD's based on inexact timestamp
matches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asof_join(
  left,
  right,
  tol = "0ms",
  direction = c("&gt;=", "&lt;=", "&lt;"),
  key_columns = list(),
  left_prefix = NULL,
  right_prefix = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asof_join_+3A_left">left</code></td>
<td>
<p>The left 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_join_+3A_right">right</code></td>
<td>
<p>The right 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_join_+3A_tol">tol</code></td>
<td>
<p>A character vector specifying a time duration (e.g., &quot;0ns&quot;, &quot;5ms&quot;,
&quot;5s&quot;, &quot;1d&quot;, etc) as the tolerance for absolute difference in timestamp values
between each record from 'left' and its matching record from 'right'.
By default, 'tol' is &quot;0ns&quot;, which means a record from 'left' will only be
matched with a record from 'right' if both contain the exact same timestamps.</p>
</td></tr>
<tr><td><code id="asof_join_+3A_direction">direction</code></td>
<td>
<p>Specifies the temporal direction of the join, must be one
of &quot;&gt;=&quot;, &quot;&lt;=&quot;, or &quot;&lt;&quot;.
If direction is &quot;&gt;=&quot;, then each record from 'left' with timestamp 'tl'
gets joined with a record from 'right' having the largest/most recent
timestamp 'tr' such that 'tl' &gt;= 'tr' and 'tl' - 'tr' &lt;= 'tol' (or
equivalently, 0 &lt;= 'tl' - 'tr' &lt;= 'tol').
If direction is &quot;&lt;=&quot;, then each record from 'left' with timestamp 'tl'
gets joined with a record from 'right' having the smallest/least recent
timestamp 'tr' such that 'tl' &lt;= 'tr' and 'tr' - 'tl' &lt;= 'tol' (or
equivalently, '0 &lt;= 'tr' - 'tl' &lt;= 'tol').
If direction is &quot;&lt;&quot;, then each record from 'left' with timestamp 'tl'
gets joined with a record from 'right' having the smallest/least recent
timestamp 'tr' such that 'tr' &gt; 'tl' and 'tr' - 'tl' &lt;= 'tol' (or
equivalently, 0 &lt; 'tr' - 'tl' &lt;= 'tol').</p>
</td></tr>
<tr><td><code id="asof_join_+3A_key_columns">key_columns</code></td>
<td>
<p>Columns to be used as the matching key among records from
'left' and 'right': if non-empty, then in addition to matching criteria
imposed by timestamps, a record from 'left' will only match one from the
'right' only if they also have equal values in all key columns.</p>
</td></tr>
<tr><td><code id="asof_join_+3A_left_prefix">left_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'left' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
<tr><td><code id="asof_join_+3A_right_prefix">right_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'right' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Temporal join functions: 
<code><a href="#topic+asof_future_left_join">asof_future_left_join</a>()</code>,
<code><a href="#topic+asof_left_join">asof_left_join</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")
if (!is.null(sc)) {
  ts_1 &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10))) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_2 &lt;- copy_to(sc, tibble::tibble(t = seq(10) + 1, v = seq(10) + 1L)) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  future_left_join_ts &lt;- asof_join(ts_1, ts_2, tol = "1s", direction = "&lt;=")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='asof_left_join'>Temporal left join</h2><span id='topic+asof_left_join'></span>

<h3>Description</h3>

<p>Perform left-outer join on 2 'TimeSeriesRDD's based on inexact timestamp
matches, where each record from 'left' with timestamp 't' matches the
record from 'right' having the most recent timestamp at or before 't'.
Notice this is equivalent to 'asof_join()' with 'direction' = &quot;&lt;=&quot;.
See <code><a href="#topic+asof_join">asof_join</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asof_left_join(
  left,
  right,
  tol = "0ms",
  key_columns = list(),
  left_prefix = NULL,
  right_prefix = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asof_left_join_+3A_left">left</code></td>
<td>
<p>The left 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_left_join_+3A_right">right</code></td>
<td>
<p>The right 'TimeSeriesRDD'</p>
</td></tr>
<tr><td><code id="asof_left_join_+3A_tol">tol</code></td>
<td>
<p>A character vector specifying a time duration (e.g., &quot;0ns&quot;, &quot;5ms&quot;,
&quot;5s&quot;, &quot;1d&quot;, etc) as the tolerance for absolute difference in timestamp values
between each record from 'left' and its matching record from 'right'.
By default, 'tol' is &quot;0ns&quot;, which means a record from 'left' will only be
matched with a record from 'right' if both contain the exact same timestamps.</p>
</td></tr>
<tr><td><code id="asof_left_join_+3A_key_columns">key_columns</code></td>
<td>
<p>Columns to be used as the matching key among records from
'left' and 'right': if non-empty, then in addition to matching criteria
imposed by timestamps, a record from 'left' will only match one from the
'right' only if they also have equal values in all key columns.</p>
</td></tr>
<tr><td><code id="asof_left_join_+3A_left_prefix">left_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'left' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
<tr><td><code id="asof_left_join_+3A_right_prefix">right_prefix</code></td>
<td>
<p>A string to prepend to all columns from 'right' after the
join (usually for disambiguation purposes if 'left' and 'right' contain
overlapping column names).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Temporal join functions: 
<code><a href="#topic+asof_future_left_join">asof_future_left_join</a>()</code>,
<code><a href="#topic+asof_join">asof_join</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")
if (!is.null(sc)) {
  ts_1 &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10))) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_2 &lt;- copy_to(sc, tibble::tibble(t = seq(10) + 1, v = seq(10) + 1L)) %&gt;%
    from_sdf(is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  left_join_ts &lt;- asof_left_join(ts_1, ts_2, tol = "1s")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='collect.ts_rdd'>Collect data from a TimeSeriesRDD</h2><span id='topic+collect.ts_rdd'></span>

<h3>Description</h3>

<p>Collect data from a TimeSeriesRDD into a R data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ts_rdd'
collect(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collect.ts_rdd_+3A_x">x</code></td>
<td>
<p>A com.twosigma.flint.timeseries.TimeSeriesRDD object</p>
</td></tr>
<tr><td><code id="collect.ts_rdd_+3A_...">...</code></td>
<td>
<p>Additional arguments to 'sdf_collect()'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A R data frame containing the same time series data the input
TimeSeriesRDD contains
</p>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- from_sdf(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  df &lt;- ts %&gt;% collect()
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='from_rdd'>Construct a TimeSeriesRDD from a Spark RDD of rows</h2><span id='topic+from_rdd'></span><span id='topic+fromRDD'></span>

<h3>Description</h3>

<p>Construct a TimeSeriesRDD containing time series data from a Spark RDD of rows
</p>


<h3>Usage</h3>

<pre><code class='language-R'>from_rdd(
  rdd,
  schema,
  is_sorted = FALSE,
  time_unit = .sparklyr.flint.globals$kValidTimeUnits,
  time_column = .sparklyr.flint.globals$kDefaultTimeColumn
)

fromRDD(
  rdd,
  schema,
  is_sorted = FALSE,
  time_unit = .sparklyr.flint.globals$kValidTimeUnits,
  time_column = .sparklyr.flint.globals$kDefaultTimeColumn
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="from_rdd_+3A_rdd">rdd</code></td>
<td>
<p>A Spark RDD[Row] object containing time series data</p>
</td></tr>
<tr><td><code id="from_rdd_+3A_schema">schema</code></td>
<td>
<p>A Spark StructType object containing schema of the time series
data</p>
</td></tr>
<tr><td><code id="from_rdd_+3A_is_sorted">is_sorted</code></td>
<td>
<p>Whether the rows being imported are already sorted by time</p>
</td></tr>
<tr><td><code id="from_rdd_+3A_time_unit">time_unit</code></td>
<td>
<p>Time unit of the time column (must be one of the following
values: &quot;NANOSECONDS&quot;, &quot;MICROSECONDS&quot;, &quot;MILLISECONDS&quot;, &quot;SECONDS&quot;,
&quot;MINUTES&quot;, &quot;HOURS&quot;, &quot;DAYS&quot;</p>
</td></tr>
<tr><td><code id="from_rdd_+3A_time_column">time_column</code></td>
<td>
<p>Name of the time column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD useable by the Flint time series library
</p>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>
<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  rdd &lt;- spark_dataframe(sdf) %&gt;% invoke("rdd")
  schema &lt;- spark_dataframe(sdf) %&gt;% invoke("schema")
  ts &lt;- from_rdd(
    rdd, schema,
    is_sorted = TRUE, time_unit = "SECONDS", time_column = "t"
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='from_sdf'>Construct a TimeSeriesRDD from a Spark DataFrame</h2><span id='topic+from_sdf'></span><span id='topic+fromSDF'></span>

<h3>Description</h3>

<p>Construct a TimeSeriesRDD containing time series data from a Spark DataFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>from_sdf(
  sdf,
  is_sorted = FALSE,
  time_unit = .sparklyr.flint.globals$kValidTimeUnits,
  time_column = .sparklyr.flint.globals$kDefaultTimeColumn
)

fromSDF(
  sdf,
  is_sorted = FALSE,
  time_unit = .sparklyr.flint.globals$kValidTimeUnits,
  time_column = .sparklyr.flint.globals$kDefaultTimeColumn
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="from_sdf_+3A_sdf">sdf</code></td>
<td>
<p>A Spark DataFrame object</p>
</td></tr>
<tr><td><code id="from_sdf_+3A_is_sorted">is_sorted</code></td>
<td>
<p>Whether the rows being imported are already sorted by time</p>
</td></tr>
<tr><td><code id="from_sdf_+3A_time_unit">time_unit</code></td>
<td>
<p>Time unit of the time column (must be one of the following
values: &quot;NANOSECONDS&quot;, &quot;MICROSECONDS&quot;, &quot;MILLISECONDS&quot;, &quot;SECONDS&quot;,
&quot;MINUTES&quot;, &quot;HOURS&quot;, &quot;DAYS&quot;</p>
</td></tr>
<tr><td><code id="from_sdf_+3A_time_column">time_column</code></td>
<td>
<p>Name of the time column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD useable by the Flint time series library
</p>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>
<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- from_sdf(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='init'>Dependencies and initialization procedures</h2><span id='topic+init'></span>

<h3>Description</h3>

<p>Functions in this file specify all runtime dependencies of sparklyr.flint
and package-wide constants in '.sparklyr.flint.globals'.
</p>

<hr>
<h2 id='ols_regression'>OLS regression</h2><span id='topic+ols_regression'></span>

<h3>Description</h3>

<p>Ordinary least squares regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols_regression(
  ts_rdd,
  formula,
  weight = NULL,
  has_intercept = TRUE,
  ignore_const_vars = FALSE,
  const_var_threshold = 1e-12
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ols_regression_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD containing dependent and independent variables</p>
</td></tr>
<tr><td><code id="ols_regression_+3A_formula">formula</code></td>
<td>
<p>An object of class &quot;formula&quot; (or one that can be coerced
to that class) which symbolically describes the model to be fitted, with
the left-hand-side being the column name of the dependent variable, and
the right-hand-side being column name(s) of independent variable(s)
delimited by '+', e.g., 'mpg ~ hp + weight + am' for predicting 'mpg' based
on 'hp', 'weight' and 'am'</p>
</td></tr>
<tr><td><code id="ols_regression_+3A_weight">weight</code></td>
<td>
<p>Name of the weight column if performing a weighted OLS
regression, or NULL if otherwise. Default: NULL.</p>
</td></tr>
<tr><td><code id="ols_regression_+3A_has_intercept">has_intercept</code></td>
<td>
<p>Whether to include an intercept term (default: TRUE).
If FALSE, then the resulting regression plane will always pass through the
origin.</p>
</td></tr>
<tr><td><code id="ols_regression_+3A_ignore_const_vars">ignore_const_vars</code></td>
<td>
<p>Whether to ignore independent variables that are
constant or nearly constant based on const_threshold (default: FALSE).
If TRUE, the scalar fields of regression result are the same as if the
constant variables are not included as independent variables. The output
beta, tStat, stdErr columns will still have the same dimension number of
elements as the number of independent variables. However, entries
corresponding to independent variables that are considered constant will
have 0.0 for beta and stdErr; and Double.NaN for tStat.
If FALSE and at least one independent variable is considered constant, the
regression will output Double.NaN for all values. Note that if there are
multiple independent variables that can be considered constant and if the
resulting model should have an intercept term, then it is recommended to
set both ignore_const_vars and has_intercept to TRUE.</p>
</td></tr>
<tr><td><code id="ols_regression_+3A_const_var_threshold">const_var_threshold</code></td>
<td>
<p>Consider an independent variable 'x' as constant
if ((number of observations) * variance(x)) is less than this value.
Default: 1e-12.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeries RDD with the following schema:
* - &quot;samples&quot;: [[LongType]], the number of samples
* - &quot;beta&quot;: [[ArrayType]] of [[DoubleType]], beta without the intercept
component
* - &quot;intercept&quot;: [[DoubleType]], the intercept
* - &quot;hasIntercept&quot;: [[BooleanType]], whether the model has an intercept
term
* - &quot;stdErr_intercept&quot;: [[DoubleType]], the standard error of the intercept
* - &quot;stdErr_beta&quot;: [[ArrayType]] of [[DoubleType]], the standard error of
beta
* - &quot;rSquared&quot;: [[DoubleType]], the r-squared statistics
* - &quot;r&quot;: [[DoubleType]], the squared root of r-squared statistics
* - &quot;tStat_intercept&quot;: [[DoubleType]], the t-stats of the intercept
* - &quot;tStat_beta&quot;: [[ArrayType]] of [[DoubleType]], the t-stats of beta
* - &quot;logLikelihood&quot;: [[DoubleType]], the log-likelihood of the data given
the fitted betas
* - &quot;akaikeIC&quot;: [[DoubleType]], the Akaike information criterion
* - &quot;bayesIC&quot;: [[DoubleType]], the Bayes information criterion
* - &quot;cond&quot;: [[DoubleType]], the condition number of the Gram matrix X^TX
where X is the matrix formed by row vectors of independent variables
(including a constant entry corresponding to the intercept if
'has_intercept' is TRUE)
* - &quot;const_columns&quot;: [[ArrayType]] of [[StringType]], the list of
independent variables that are considered constants
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  mtcars_sdf &lt;- copy_to(sc, mtcars, overwrite = TRUE) %&gt;%
    dplyr::mutate(time = 0L)
  mtcars_ts &lt;- from_sdf(mtcars_sdf, is_sorted = TRUE, time_unit = "SECONDS")
  model &lt;- ols_regression(
    mtcars_ts, mpg ~ cyl + disp + hp + drat + wt + vs + am + gear + carb
  ) %&gt;%
      collect()
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='sdf_utils'>Utility functions for importing a Spark data frame into a TimeSeriesRDD</h2><span id='topic+sdf_utils'></span>

<h3>Description</h3>

<p>These functions provide an interface for specifying how a Spark data frame
should be imported into a TimeSeriesRDD (e.g., which column represents time,
whether rows are already ordered by time, and time unit being used, etc)
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdf_utils_+3A_sc">sc</code></td>
<td>
<p>Spark connection</p>
</td></tr>
<tr><td><code id="sdf_utils_+3A_is_sorted">is_sorted</code></td>
<td>
<p>Whether the rows being imported are already sorted by time</p>
</td></tr>
<tr><td><code id="sdf_utils_+3A_time_unit">time_unit</code></td>
<td>
<p>Time unit of the time column (must be one of the following
values: &quot;NANOSECONDS&quot;, &quot;MICROSECONDS&quot;, &quot;MILLISECONDS&quot;, &quot;SECONDS&quot;,
&quot;MINUTES&quot;, &quot;HOURS&quot;, &quot;DAYS&quot;</p>
</td></tr>
<tr><td><code id="sdf_utils_+3A_time_column">time_column</code></td>
<td>
<p>Name of the time column</p>
</td></tr>
</table>

<hr>
<h2 id='spark_connection'>Retrieve Spark connection associated with an R object</h2><span id='topic+spark_connection'></span>

<h3>Description</h3>

<p>See <code><a href="sparklyr.html#topic+spark_connection">spark_connection</a></code> for more details.
</p>

<hr>
<h2 id='spark_connection.ts_rdd'>Retrieve Spark connection associated with an R object</h2><span id='topic+spark_connection.ts_rdd'></span>

<h3>Description</h3>

<p>See <code><a href="sparklyr.html#topic+spark_connection">spark_connection</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ts_rdd'
spark_connection(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spark_connection.ts_rdd_+3A_x">x</code></td>
<td>
<p>An R object from which a 'spark_connection' can be obtained.</p>
</td></tr>
<tr><td><code id="spark_connection.ts_rdd_+3A_...">...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  print(spark_connection(ts))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='spark_dataframe'>Retrieve a Spark DataFrame</h2><span id='topic+spark_dataframe'></span>

<h3>Description</h3>

<p>See <code><a href="sparklyr.html#topic+spark_dataframe">spark_dataframe</a></code> for more details.
</p>

<hr>
<h2 id='spark_dataframe.ts_rdd'>Retrieve a Spark DataFrame</h2><span id='topic+spark_dataframe.ts_rdd'></span>

<h3>Description</h3>

<p>Retrieve a Spark DataFrame from a TimeSeriesRDD object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ts_rdd'
spark_dataframe(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spark_dataframe.ts_rdd_+3A_x">x</code></td>
<td>
<p>An R object wrapping, or containing, a Spark DataFrame.</p>
</td></tr>
<tr><td><code id="spark_dataframe.ts_rdd_+3A_...">...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- from_sdf(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  print(ts %&gt;% spark_dataframe())
  print(sdf %&gt;% spark_dataframe()) # the former should contain the same set of
                                   # rows as the latter does, modulo possible
                                   # difference in types of timestamp columns
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='spark_jobj'>Retrieve a Spark JVM Object Reference</h2><span id='topic+spark_jobj'></span>

<h3>Description</h3>

<p>See <code><a href="sparklyr.html#topic+spark_jobj">spark_jobj</a></code> for more details.
</p>

<hr>
<h2 id='spark_jobj.ts_rdd'>Retrieve a Spark JVM Object Reference</h2><span id='topic+spark_jobj.ts_rdd'></span>

<h3>Description</h3>

<p>See <code><a href="sparklyr.html#topic+spark_jobj">spark_jobj</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ts_rdd'
spark_jobj(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spark_jobj.ts_rdd_+3A_x">x</code></td>
<td>
<p>An R object containing, or wrapping, a 'spark_jobj'.</p>
</td></tr>
<tr><td><code id="spark_jobj.ts_rdd_+3A_...">...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  print(spark_jobj(ts))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_avg'>Average summarizer</h2><span id='topic+summarize_avg'></span>

<h3>Description</h3>

<p>Compute moving average of 'column' and store results in a new column named
'&lt;column&gt;_mean'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_avg(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_avg_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_avg_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_avg_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_avg_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_avg &lt;- summarize_avg(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_corr'>Correlation summarizer</h2><span id='topic+summarize_corr'></span>

<h3>Description</h3>

<p>Compute pairwise correations among the list of columns specified and store
results in new columns named with the following pattern:
'&lt;column1&gt;_&lt;column2&gt;_correlation' and '&lt;column1&gt;_&lt;column2&gt;_correlationTStat',
where column1 and column2 are names of any 2 distinct columns
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_corr(ts_rdd, columns, key_columns = list(), incremental = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_corr_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_corr_+3A_columns">columns</code></td>
<td>
<p>A list of column names</p>
</td></tr>
<tr><td><code id="summarize_corr_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_corr_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = rnorm(10), v = rnorm(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_corr &lt;- summarize_corr(ts, columns = c("u", "v"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_corr2'>Pairwise correlation summarizer</h2><span id='topic+summarize_corr2'></span>

<h3>Description</h3>

<p>Compute pairwise correations for all possible pairs of columns such that the
first column of each pair is one of 'xcolumns' and the second column of each
pair is one of 'ycolumns', storing results in new columns named with the
following pattern:
'&lt;column1&gt;_&lt;column2&gt;_correlation' and '&lt;column1&gt;_&lt;column2&gt;_correlationTStat'
for each pair of columns (column1, column2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_corr2(
  ts_rdd,
  xcolumns,
  ycolumns,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_corr2_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_corr2_+3A_xcolumns">xcolumns</code></td>
<td>
<p>A list of column names</p>
</td></tr>
<tr><td><code id="summarize_corr2_+3A_ycolumns">ycolumns</code></td>
<td>
<p>A list of column names disjoint from xcolumns</p>
</td></tr>
<tr><td><code id="summarize_corr2_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_corr2_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(
    sc,
    tibble::tibble(t = seq(10), x1 = rnorm(10), x2 = rnorm(10), y1 = rnorm(10), y2 = rnorm(10))
  )
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_corr2 &lt;- summarize_corr2(ts, xcolumns = c("x1", "x2"), ycolumns = c("y1", "y2"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_count'>Count summarizer</h2><span id='topic+summarize_count'></span>

<h3>Description</h3>

<p>Count the total number of records if no column is specified, or the number of
non-null values within the specified column within each time window or within
each group of records with identical timestamps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_count(ts_rdd, column = NULL, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_count_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_count_+3A_column">column</code></td>
<td>
<p>If not NULL, then report the number of values in the column
specified that are not NULL or NaN within each time window or group of records
with identical timestamps, and store the counts in a new column named
'&lt;column&gt;_count'.
Otherwise the number of records within each time window or group of records with
identical timestamps is reported, and stored in a column named 'count'.</p>
</td></tr>
<tr><td><code id="summarize_count_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_count_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_count &lt;- summarize_count(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_covar'>Covariance summarizer</h2><span id='topic+summarize_covar'></span>

<h3>Description</h3>

<p>Compute covariance between values from 'xcolumn' and 'ycolumn' within each time
window or within each group of records with identical timestamps, and store results
in a new column named '&lt;xcolumn&gt;_&lt;ycolumn&gt;_covariance'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_covar(ts_rdd, xcolumn, ycolumn, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_covar_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_covar_+3A_xcolumn">xcolumn</code></td>
<td>
<p>Column representing the first random variable</p>
</td></tr>
<tr><td><code id="summarize_covar_+3A_ycolumn">ycolumn</code></td>
<td>
<p>Column representing the second random variable</p>
</td></tr>
<tr><td><code id="summarize_covar_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_covar_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = rnorm(10), v = rnorm(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_covar &lt;- summarize_covar(ts, xcolumn = "u", ycolumn = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_dot_product'>Dot product summarizer</h2><span id='topic+summarize_dot_product'></span>

<h3>Description</h3>

<p>Compute dot product of values from 'xcolumn' and 'ycolumn' within a moving
time window or within each group of records with identical timestamps and store
results in a new column named '&lt;xcolumn&gt;_&lt;ycolumn&gt;_dotProduct'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_dot_product(
  ts_rdd,
  xcolumn,
  ycolumn,
  window = NULL,
  key_columns = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_dot_product_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_dot_product_+3A_xcolumn">xcolumn</code></td>
<td>
<p>Name of the first column</p>
</td></tr>
<tr><td><code id="summarize_dot_product_+3A_ycolumn">ycolumn</code></td>
<td>
<p>Name of the second column</p>
</td></tr>
<tr><td><code id="summarize_dot_product_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_dot_product_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10, 1, -1), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_dot_product &lt;- summarize_dot_product(ts, xcolumn = "u", ycolumn = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_ema_half_life'>EMA half-life summarizer</h2><span id='topic+summarize_ema_half_life'></span>

<h3>Description</h3>

<p>Calculate the exponential moving average of a time series using the half-
life specified and store the result in a new column named '&lt;column&gt;_ema'
See https://github.com/twosigma/flint/blob/master/doc/ema.md for details on
different EMA implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_ema_half_life(
  ts_rdd,
  column,
  half_life_duration,
  window = NULL,
  time_column = "time",
  interpolation = c("previous", "linear", "current"),
  convention = c("legacy", "convolution", "core"),
  key_columns = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_ema_half_life_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_half_life_duration">half_life_duration</code></td>
<td>
<p>A time duration specified in string form (e.g.,
&quot;1d&quot;, &quot;1h&quot;, &quot;15m&quot;, etc) representing the half-life duration</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize the EMA of 'column' within the time
interval of [t - 1h, t] for each timestamp 't', 'in_future(&quot;5s&quot;)' to
summarize EMA of 'column' within the time interval of [t, t + 5s] for each
timestamp 't'), or 'NULL' to summarize EMA of 'column' within the time
interval of (-inf, t] for each timestamp 't'</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_time_column">time_column</code></td>
<td>
<p>Name of the column containing timestamps (default: &quot;time&quot;)</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_interpolation">interpolation</code></td>
<td>
<p>Method used for interpolating values between two
consecutive data points, must be one of &quot;previous&quot;, &quot;linear&quot;, and
&quot;current&quot; (default: &quot;previous&quot;). See
https://github.com/twosigma/flint/blob/master/doc/ema.md for details on
different interpolation methods.</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_convention">convention</code></td>
<td>
<p>Convolution convention, must be one of &quot;convolution&quot;,
&quot;core&quot;, and &quot;legacy&quot; (default: &quot;legacy&quot;). See
https://github.com/twosigma/flint/blob/master/doc/ema.md for details.</p>
</td></tr>
<tr><td><code id="summarize_ema_half_life_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  price_sdf &lt;- copy_to(
    sc,
    data.frame(time = seq(1000), price = rnorm(1000))
  )
  ts &lt;- fromSDF(price_sdf, is_sorted = TRUE, time_unit = "SECONDS")
  ts_ema &lt;- summarize_ema_half_life(
    ts,
    column = "price",
    half_life_duration = "100s"
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_ewma'>Exponential weighted moving average summarizer</h2><span id='topic+summarize_ewma'></span>

<h3>Description</h3>

<p>Compute exponential weighted moving average (EWMA) of 'column' and store
results in a new column named '&lt;column&gt;_ewma'
At time t[n], the i-th value x[i] with timestamp t[i] will have a weighted
value of [weight(i, n) * x[i]], where weight(i, n) is determined by both
'alpha' and 'smoothing_duration'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_ewma(
  ts_rdd,
  column,
  alpha = 0.05,
  smoothing_duration = "1d",
  time_column = "time",
  convention = c("core", "legacy"),
  key_columns = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_ewma_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_alpha">alpha</code></td>
<td>
<p>A smoothing factor between 0 and 1 (default: 0.05) &ndash; a higher
alpha discounts older observations faster</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_smoothing_duration">smoothing_duration</code></td>
<td>
<p>A time duration specified in string form (e.g.,
&quot;1d&quot;, &quot;1h&quot;, &quot;15m&quot;, etc) or &quot;constant&quot;.
The weight applied to a past observation from time t[p] at time t[n] is
jointly determined by 'alpha' and 'smoothing_duration'.
</p>
<p>If 'smoothing_duration' is a fixed time duration such as &quot;1d&quot;, then
weight(p, n) = (1 - alpha) ^ [(t[n] - t[p]) / smoothing_duration]
</p>
<p>If 'smoothing_duration' is &quot;constant&quot;, then
weight(p, n) = (1 - alpha) ^ (n - p)
(i.e., this option assumes the difference between consecutive timestamps
is equal to some constant 'diff', and 'smoothing_duration' is effectively
also equal to 'diff', so that t[n] - t[p] = (n - p) * diff and
weight(p, n) = (1 - alpha) ^ [(t[n] - t[p]) / smoothing_duration] =
(1 - alpha) ^ [(n - p) * diff / diff] = (1 - alpha) ^ (n - p))</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_time_column">time_column</code></td>
<td>
<p>Name of the column containing timestamps (default: &quot;time&quot;)</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_convention">convention</code></td>
<td>
<p>One of &quot;core&quot; or &quot;legacy&quot; (default: &quot;core&quot;)
</p>
<p>If 'convention' is &quot;core&quot;, then the output will be weighted sum of all
observations divided by the sum of all weight coefficients (see
https://github.com/twosigma/flint/blob/master/doc/ema.md#core).
</p>
<p>If 'convention' is &quot;legacy&quot;, then the output will simply be the weighted
sum of all observations, without being normalized by the sum of all weight
coefficients (see
https://github.com/twosigma/flint/blob/master/doc/ema.md#legacy).</p>
</td></tr>
<tr><td><code id="summarize_ewma_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  price_sdf &lt;- copy_to(
    sc,
    data.frame(
      time = ceiling(seq(12) / 2),
      price = seq(12) / 2,
      id = rep(c(3L, 7L), 6)
    )
  )
  ts &lt;- fromSDF(price_sdf, is_sorted = TRUE, time_unit = "DAYS")
  ts_ewma &lt;- summarize_ewma(
    ts,
    column = "price",
    smoothing_duration = "1d",
    key_columns = "id"
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_geometric_mean'>Geometric mean summarizer</h2><span id='topic+summarize_geometric_mean'></span>

<h3>Description</h3>

<p>Compute geometric mean of values from 'column' within a moving time window or
within each group of records with identical timestamps and store results in a
new column named '&lt;column&gt;_geometricMean'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_geometric_mean(
  ts_rdd,
  column,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_geometric_mean_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_geometric_mean_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_geometric_mean_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_geometric_mean_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10, 1, -1)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_geometric_mean &lt;- summarize_geometric_mean(ts, column = "u")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_kurtosis'>Kurtosis summarizer</h2><span id='topic+summarize_kurtosis'></span>

<h3>Description</h3>

<p>Compute the excess kurtosis (fourth standardized moment minus 3) of 'column'
and store the result in a new column named '&lt;column&gt;_kurtosis'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_kurtosis(ts_rdd, column, key_columns = list(), incremental = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_kurtosis_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_kurtosis_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_kurtosis_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_kurtosis_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  price_sdf &lt;- copy_to(
    sc,
    data.frame(
      time = ceiling(seq(12) / 2),
      price = seq(12) / 2,
      id = rep(c(3L, 7L), 6)
    )
  )
  ts &lt;- fromSDF(price_sdf, is_sorted = TRUE, time_unit = "DAYS")
  ts_kurtosis &lt;- summarize_kurtosis(ts, column = "price")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_max'>Maximum value summarizer</h2><span id='topic+summarize_max'></span>

<h3>Description</h3>

<p>Find maximum value among values from 'column' within each time window or
within each group of records with identical timestamps, and store results in a
new column named '&lt;column&gt;_max'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_max(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_max_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_max_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_max_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_max_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_max &lt;- summarize_max(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_min'>Minimum value summarizer</h2><span id='topic+summarize_min'></span>

<h3>Description</h3>

<p>Find minimum value among values from 'column' within each time window or
within each group of records with identical timestamps, and store results in a
new column named '&lt;column&gt;_min'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_min(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_min_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_min_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_min_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_min_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_min &lt;- summarize_min(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_nth_central_moment'>N-th central moment summarizer</h2><span id='topic+summarize_nth_central_moment'></span>

<h3>Description</h3>

<p>Compute n-th central moment of the column specified and store result in a
new column named '&lt;column&gt;_&lt;n&gt;thCentralMoment'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_nth_central_moment(
  ts_rdd,
  column,
  n,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_nth_central_moment_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_nth_central_moment_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_nth_central_moment_+3A_n">n</code></td>
<td>
<p>The order of moment to calculate</p>
</td></tr>
<tr><td><code id="summarize_nth_central_moment_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_nth_central_moment_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = rnorm(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_4th_central_moment &lt;- summarize_nth_central_moment(ts, column = "v", n = 4L)
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_nth_moment'>N-th moment summarizer</h2><span id='topic+summarize_nth_moment'></span>

<h3>Description</h3>

<p>Compute n-th moment of the column specified and store result in a new column
named '&lt;column&gt;_&lt;n&gt;thMoment'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_nth_moment(
  ts_rdd,
  column,
  n,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_nth_moment_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_nth_moment_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_nth_moment_+3A_n">n</code></td>
<td>
<p>The order of moment to calculate</p>
</td></tr>
<tr><td><code id="summarize_nth_moment_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_nth_moment_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = rnorm(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_4th_moment &lt;- summarize_nth_moment(ts, column = "v", n = 4L)
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_product'>Product summarizer</h2><span id='topic+summarize_product'></span>

<h3>Description</h3>

<p>Compute product of values from the given column within a moving time window
new column named '&lt;column&gt;_product'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_product(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_product_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_product_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_product_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_product_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_product &lt;- summarize_product(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_quantile'>Quantile summarizer</h2><span id='topic+summarize_quantile'></span>

<h3>Description</h3>

<p>Compute quantiles of 'column' within each time window or within each group of
records with identical time-stamps, and store results in new columns named
'&lt;column&gt;_&lt;quantile value&gt;quantile'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_quantile(ts_rdd, column, p, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_quantile_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_quantile_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_quantile_+3A_p">p</code></td>
<td>
<p>List of quantile probabilities</p>
</td></tr>
<tr><td><code id="summarize_quantile_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_quantile_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_quantile &lt;- summarize_quantile(
    ts, column = "v", p = c(0.5, 0.75, 0.99), window = in_past("3s")
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_skewness'>Skewness summarizer</h2><span id='topic+summarize_skewness'></span>

<h3>Description</h3>

<p>Compute skewness (third standardized moment) of 'column' and store the result
in a new column named '&lt;column&gt;_skewness'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_skewness(ts_rdd, column, key_columns = list(), incremental = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_skewness_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_skewness_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_skewness_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_skewness_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  price_sdf &lt;- copy_to(
    sc,
    data.frame(
      time = ceiling(seq(12) / 2),
      price = seq(12) / 2,
      id = rep(c(3L, 7L), 6)
    )
  )
  ts &lt;- fromSDF(price_sdf, is_sorted = TRUE, time_unit = "DAYS")
  ts_skewness &lt;- summarize_skewness(ts, column = "price")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_stddev'>Standard deviation summarizer</h2><span id='topic+summarize_stddev'></span>

<h3>Description</h3>

<p>Compute unbiased (i.e., Bessel's correction is applied) sample standard
deviation of values from 'column' within each time window or within each
group of records with identical timestamps, and store results in a new column
named '&lt;column&gt;_stddev'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_stddev(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_stddev_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_stddev_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_stddev_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_stddev_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_stddev &lt;- summarize_stddev(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_sum'>Sum summarizer</h2><span id='topic+summarize_sum'></span>

<h3>Description</h3>

<p>Compute moving sums on the column specified and store results in a new column
named '&lt;column&gt;_sum'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_sum(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_sum_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_sum_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_sum_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_sum_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_sum &lt;- summarize_sum(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_var'>Variance summarizer</h2><span id='topic+summarize_var'></span>

<h3>Description</h3>

<p>Compute variance of values from 'column' within each time window or within
each group of records with identical timestamps, and store results in a new column
named &lsquo;&lt;column&gt;_variance', with Bessel&rsquo;s correction applied to the results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_var(ts_rdd, column, window = NULL, key_columns = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_var_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_var_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_var_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_var_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_var &lt;- summarize_var(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_weighted_avg'>Weighted average summarizer</h2><span id='topic+summarize_weighted_avg'></span>

<h3>Description</h3>

<p>Compute moving weighted average, weighted standard deviation, weighted t-
stat, and observation count with the column and weight column specified and
store results in new columns named '&lt;column&gt;_&lt;weighted_column&gt;_mean',
'&lt;column&gt;_&lt;weighted_column&gt;_weightedStandardDeviation',
'&lt;column&gt;_&lt;weighted_column&gt;_weightedTStat', and
'&lt;column&gt;_&lt;weighted_column&gt;_observationCount',
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_weighted_avg(
  ts_rdd,
  column,
  weight_column,
  window = NULL,
  key_columns = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_weighted_avg_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_weighted_avg_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_weighted_avg_+3A_weight_column">weight_column</code></td>
<td>
<p>Column specifying relative weight of each data point</p>
</td></tr>
<tr><td><code id="summarize_weighted_avg_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_weighted_avg_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10), w = seq(1, 0.1, -0.1)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_weighted_avg &lt;- summarize_weighted_avg(
    ts,
    column = "v", weight_column = "w", window = in_past("3s")
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_weighted_corr'>Pearson weighted correlation summarizer</h2><span id='topic+summarize_weighted_corr'></span>

<h3>Description</h3>

<p>Compute Pearson weighted correlation between 'xcolumn' and 'ycolumn' weighted
by 'weight_column' and store result in a new columns named
'&lt;xcolumn&gt;_&lt;ycolumn&gt;_&lt;weight_column&gt;_weightedCorrelation'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_weighted_corr(
  ts_rdd,
  xcolumn,
  ycolumn,
  weight_column,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_weighted_corr_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_weighted_corr_+3A_xcolumn">xcolumn</code></td>
<td>
<p>Column representing the first random variable</p>
</td></tr>
<tr><td><code id="summarize_weighted_corr_+3A_ycolumn">ycolumn</code></td>
<td>
<p>Column representing the second random variable</p>
</td></tr>
<tr><td><code id="summarize_weighted_corr_+3A_weight_column">weight_column</code></td>
<td>
<p>Column specifying relative weight of each data point</p>
</td></tr>
<tr><td><code id="summarize_weighted_corr_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_weighted_corr_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), x = rnorm(10), y = rnorm(10), w = 1.1^seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_weighted_corr &lt;- summarize_weighted_corr(ts, xcolumn = "x", ycolumn = "y", weight_column = "w")
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_weighted_covar'>Weighted covariance summarizer</h2><span id='topic+summarize_weighted_covar'></span>

<h3>Description</h3>

<p>Compute unbiased weighted covariance between values from 'xcolumn' and
'ycolumn' within each time window or within each group of records with identical
timestamps, using values from 'weight_column' as relative weights, and store
results in a new column named
'&lt;xcolumn&gt;_&lt;ycolumn&gt;_&lt;weight_column&gt;_weightedCovariance'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_weighted_covar(
  ts_rdd,
  xcolumn,
  ycolumn,
  weight_column,
  window = NULL,
  key_columns = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_weighted_covar_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_weighted_covar_+3A_xcolumn">xcolumn</code></td>
<td>
<p>Column representing the first random variable</p>
</td></tr>
<tr><td><code id="summarize_weighted_covar_+3A_ycolumn">ycolumn</code></td>
<td>
<p>Column representing the second random variable</p>
</td></tr>
<tr><td><code id="summarize_weighted_covar_+3A_weight_column">weight_column</code></td>
<td>
<p>Column specifying relative weight of each data point</p>
</td></tr>
<tr><td><code id="summarize_weighted_covar_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarize_weighted_covar_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_z_score">summarize_z_score</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), u = rnorm(10), v = rnorm(10), w = 1.1^seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_weighted_covar &lt;- summarize_weighted_covar(
    ts,
    xcolumn = "u", ycolumn = "v", weight_column = "w", window = in_past("3s")
  )
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarize_z_score'>Z-score summarizer</h2><span id='topic+summarize_z_score'></span>

<h3>Description</h3>

<p>Compute z-score of value(s) in the column specified, with respect to the
sample mean and standard deviation observed so far, with the option for out-
of-sample calculation, and store result in a new column named
'&lt;column&gt;_zScore'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_z_score(
  ts_rdd,
  column,
  include_current_observation = FALSE,
  key_columns = list(),
  incremental = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_z_score_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarize_z_score_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarize_z_score_+3A_include_current_observation">include_current_observation</code></td>
<td>
<p>If true, then use unbiased sample standard
deviation with current observation in z-score calculation, otherwise use
unbiased sample standard deviation excluding current observation</p>
</td></tr>
<tr><td><code id="summarize_z_score_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarize_z_score_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A TimeSeriesRDD containing the summarized result
</p>


<h3>See Also</h3>

<p>Other summarizers: 
<code><a href="#topic+ols_regression">ols_regression</a>()</code>,
<code><a href="#topic+summarize_avg">summarize_avg</a>()</code>,
<code><a href="#topic+summarize_corr2">summarize_corr2</a>()</code>,
<code><a href="#topic+summarize_corr">summarize_corr</a>()</code>,
<code><a href="#topic+summarize_count">summarize_count</a>()</code>,
<code><a href="#topic+summarize_covar">summarize_covar</a>()</code>,
<code><a href="#topic+summarize_dot_product">summarize_dot_product</a>()</code>,
<code><a href="#topic+summarize_ema_half_life">summarize_ema_half_life</a>()</code>,
<code><a href="#topic+summarize_ewma">summarize_ewma</a>()</code>,
<code><a href="#topic+summarize_geometric_mean">summarize_geometric_mean</a>()</code>,
<code><a href="#topic+summarize_kurtosis">summarize_kurtosis</a>()</code>,
<code><a href="#topic+summarize_max">summarize_max</a>()</code>,
<code><a href="#topic+summarize_min">summarize_min</a>()</code>,
<code><a href="#topic+summarize_nth_central_moment">summarize_nth_central_moment</a>()</code>,
<code><a href="#topic+summarize_nth_moment">summarize_nth_moment</a>()</code>,
<code><a href="#topic+summarize_product">summarize_product</a>()</code>,
<code><a href="#topic+summarize_quantile">summarize_quantile</a>()</code>,
<code><a href="#topic+summarize_skewness">summarize_skewness</a>()</code>,
<code><a href="#topic+summarize_stddev">summarize_stddev</a>()</code>,
<code><a href="#topic+summarize_sum">summarize_sum</a>()</code>,
<code><a href="#topic+summarize_var">summarize_var</a>()</code>,
<code><a href="#topic+summarize_weighted_avg">summarize_weighted_avg</a>()</code>,
<code><a href="#topic+summarize_weighted_corr">summarize_weighted_corr</a>()</code>,
<code><a href="#topic+summarize_weighted_covar">summarize_weighted_covar</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = rnorm(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_z_score &lt;- summarize_z_score(ts, column = "v", include_current_observation = TRUE)
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='summarizers'>Wrapper functions for commonly used summarizer functions</h2><span id='topic+summarizers'></span>

<h3>Description</h3>

<p>R wrapper functions for commonly used Flint summarizer functionalities such as
sum and count.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarizers_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>Timeseries RDD being summarized</p>
</td></tr>
<tr><td><code id="summarizers_+3A_window">window</code></td>
<td>
<p>Either an R expression specifying time windows to be summarized
(e.g., 'in_past(&quot;1h&quot;)' to summarize data from looking behind 1 hour at
each time point, 'in_future(&quot;5s&quot;)' to summarize data from looking forward
5 seconds at each time point), or 'NULL' to compute aggregate statistics
on records grouped by timestamps</p>
</td></tr>
<tr><td><code id="summarizers_+3A_column">column</code></td>
<td>
<p>Column to be summarized</p>
</td></tr>
<tr><td><code id="summarizers_+3A_key_columns">key_columns</code></td>
<td>
<p>Optional list of columns that will form an equivalence
relation associating each record with the time series it belongs to (i.e.,
any 2 records having equal values in those columns will be associated with
the same time series, and any 2 records having differing values in those
columns are considered to be from 2 separate time series and will therefore
be summarized separately)
By default, 'key_colums' is empty and all records are considered to be part
of a single time series.</p>
</td></tr>
<tr><td><code id="summarizers_+3A_incremental">incremental</code></td>
<td>
<p>If FALSE and 'key_columns' is empty, then apply the
summarizer to all records of 'ts_rdd'.
If FALSE and 'key_columns' is non-empty, then apply the summarizer to all
records within each group determined by 'key_columns'.
If TRUE and 'key_columns' is empty, then for each record in 'ts_rdd',
the summarizer is applied to that record and all records preceding it, and
the summarized result is associated with the timestamp of that record.
If TRUE and 'key_columns' is non-empty, then for each record within a group
of records determined by 1 or more key columns, the summarizer is applied
to that record and all records preceding it within its group, and the
summarized result is associated with the timestamp of that record.</p>
</td></tr>
</table>

<hr>
<h2 id='to_sdf'>Export data from TimeSeriesRDD to a Spark dataframe</h2><span id='topic+to_sdf'></span><span id='topic+toSDF'></span>

<h3>Description</h3>

<p>Construct a Spark dataframe containing time series data from a TimeSeriesRDD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_sdf(ts_rdd)

toSDF(ts_rdd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_sdf_+3A_ts_rdd">ts_rdd</code></td>
<td>
<p>A TimeSeriesRDD object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Spark dataframe containing time series data exported from 'ts_rdd'
</p>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>
<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+ts_rdd_builder">ts_rdd_builder</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- from_sdf(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_avg &lt;- summarize_avg(ts, column = "v", window = in_past("3s"))
  # now export the average values from `ts_avg` back to a Spark dataframe
  # named `sdf_avg`
  sdf_avg &lt;- ts_avg %&gt;% to_sdf()
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

<hr>
<h2 id='try_spark_connect'>Attempt to establish a Spark connection</h2><span id='topic+try_spark_connect'></span>

<h3>Description</h3>

<p>Attempt to connect to Apache Spark and return a Spark connection object upon success
</p>


<h3>Usage</h3>

<pre><code class='language-R'>try_spark_connect(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="try_spark_connect_+3A_...">...</code></td>
<td>
<p>Parameters for sparklyr::spark_connect</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Spark connection object if attempt was successful, or NULL otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
try_spark_connect(master = "local")

</code></pre>

<hr>
<h2 id='ts_rdd_builder'>TimeSeriesRDD builder object</h2><span id='topic+ts_rdd_builder'></span>

<h3>Description</h3>

<p>Builder object containing all required info (i.e., isSorted, timeUnit, and
timeColumn) for importing a Spark data frame into a TimeSeriesRDD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ts_rdd_builder(
  sc,
  is_sorted = FALSE,
  time_unit = .sparklyr.flint.globals$kValidTimeUnits,
  time_column = .sparklyr.flint.globals$kDefaultTimeColumn
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ts_rdd_builder_+3A_sc">sc</code></td>
<td>
<p>Spark connection</p>
</td></tr>
<tr><td><code id="ts_rdd_builder_+3A_is_sorted">is_sorted</code></td>
<td>
<p>Whether the rows being imported are already sorted by time</p>
</td></tr>
<tr><td><code id="ts_rdd_builder_+3A_time_unit">time_unit</code></td>
<td>
<p>Time unit of the time column (must be one of the following
values: &quot;NANOSECONDS&quot;, &quot;MICROSECONDS&quot;, &quot;MILLISECONDS&quot;, &quot;SECONDS&quot;,
&quot;MINUTES&quot;, &quot;HOURS&quot;, &quot;DAYS&quot;</p>
</td></tr>
<tr><td><code id="ts_rdd_builder_+3A_time_column">time_column</code></td>
<td>
<p>Name of the time column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A reusable TimeSeriesRDD builder object
</p>


<h3>See Also</h3>

<p>Other Spark dataframe utility functions: 
<code><a href="#topic+collect.ts_rdd">collect.ts_rdd</a>()</code>,
<code><a href="#topic+from_rdd">from_rdd</a>()</code>,
<code><a href="#topic+from_sdf">from_sdf</a>()</code>,
<code><a href="#topic+spark_connection.ts_rdd">spark_connection.ts_rdd</a>()</code>,
<code><a href="#topic+spark_dataframe.ts_rdd">spark_dataframe.ts_rdd</a>()</code>,
<code><a href="#topic+spark_jobj.ts_rdd">spark_jobj.ts_rdd</a>()</code>,
<code><a href="#topic+to_sdf">to_sdf</a>()</code>
</p>

<hr>
<h2 id='window_exprs'>Time window specifications</h2><span id='topic+window_exprs'></span><span id='topic+in_past'></span><span id='topic+in_future'></span>

<h3>Description</h3>

<p>Functions for specifying commonly used types of time windows, which should
only be used within the context of summarize_* functions (e.g.,
'summarize_count(ts_rdd, in_past(&quot;3s&quot;))'). When passing a time window
specification to some summarize_* function, the Spark connection parameter
('sc') for the time window object will be injected and will be the same Spark
connection the underlying timeseries RDD object is associated with, so, 'sc'
never needs to be specified explicitly.
</p>
<p>Create a sliding time window capuring data within the closed interval of
[current time - duration, current time]
</p>
<p>Create a sliding time window capuring data within the closed interval of
[current time, current time + duration]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>in_past(duration, sc)

in_future(duration, sc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="window_exprs_+3A_duration">duration</code></td>
<td>
<p>String representing length of the time window containing a
number followed by a time unit (e.g., &quot;10s&quot; or &quot;10sec&quot;), where time unit
must be one of the following: &quot;d&quot;, &quot;day&quot;, &quot;h&quot;, &quot;hour&quot;, &quot;min&quot;, &quot;minute&quot;,
&quot;s&quot;, &quot;sec&quot;, &quot;second&quot;, &quot;ms&quot;, &quot;milli&quot;, &quot;millisecond&quot;, &quot;</p>
<p style="text-align: center;"><code class="reqn"> \mu </code>
</p>
<p>s&quot;,
&quot;micro&quot;, &quot;microsecond&quot;, &quot;ns&quot;, &quot;nano&quot;, &quot;nanosecond&quot;</p>
</td></tr>
<tr><td><code id="window_exprs_+3A_sc">sc</code></td>
<td>
<p>Spark connection (does not need to be specified within the context
of 'summarize_*' functions)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time window object useable by the Flint time series library
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_count &lt;- summarize_count(ts, column = "v", window = in_past("3s"))
} else {
  message("Unable to establish a Spark connection!")
}


library(sparklyr)
library(sparklyr.flint)

sc &lt;- try_spark_connect(master = "local")

if (!is.null(sc)) {
  sdf &lt;- copy_to(sc, tibble::tibble(t = seq(10), v = seq(10)))
  ts &lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = "SECONDS", time_column = "t")
  ts_count &lt;- summarize_count(ts, column = "v", window = in_future("3s"))
} else {
  message("Unable to establish a Spark connection!")
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
