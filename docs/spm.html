<!DOCTYPE html><html lang="en"><head><title>Help for package spm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#avi'><p>Averaged variable importance based on random forest</p></a></li>
<li><a href='#cran-comments'>
<p>Note on notes</p></a></li>
<li><a href='#gbmcv'><p>Cross validation, n-fold for generalized boosted regression modeling (gbm)</p></a></li>
<li><a href='#gbmidwcv'><p>Cross validation, n-fold for the hybrid method of generalized boosted</p>
regression modeling and inverse distance weighting (gbmidw)</a></li>
<li><a href='#gbmidwpred'><p>Generate spatial predictions using the hybrid method of generalized boosted regression</p>
modeling and inverse distance weighting (gbmidw)</a></li>
<li><a href='#gbmokcv'><p>Cross validation, n-fold for the hybrid method of generalized boosted</p>
regression modeling and ordinary kriging (gbmok)</a></li>
<li><a href='#gbmokgbmidwcv'><p>Cross validation, n-fold for the average of the hybrid method of generalized</p>
boosted regression modeling and ordinary kriging and the hybrid method of generalized
boosted regression modeling and inverse distance weighting (gbmokgbmidw)</a></li>
<li><a href='#gbmokgbmidwpred'><p>Generate spatial predictions using the average of the hybrid method of</p>
generalized boosted regression modeling and ordinary kriging and the hybrid method of
generalized boosted regression modeling and inverse distance weighting (gbmokgbmidw)</a></li>
<li><a href='#gbmokpred'><p>Generate spatial predictions using the hybrid method of generalized boosted</p>
regression modeling and ordinary kriging (gbmok)</a></li>
<li><a href='#gbmpred'><p>Generate spatial predictions using generalized boosted regression modeling ('gbm')</p></a></li>
<li><a href='#hard'><p>A dataset of seabed hardness in the eastern Joseph Bonaparte Golf, northern Australia marine margin</p></a></li>
<li><a href='#idwcv'><p>Cross validation, n-fold for inverse distance weighting (IDW)</p></a></li>
<li><a href='#idwpred'><p>Generate spatial predictions using inverse distance weighting (IDW)</p></a></li>
<li><a href='#okcv'><p>Cross validation, n-fold for ordinary kriging (OK)</p></a></li>
<li><a href='#okpred'><p>Generate spatial predictions using ordinary kriging (OK)</p></a></li>
<li><a href='#petrel'><p>A dataset of seabed sediments in the Petrel sub-basin in Australia Exclusive Economic Zone</p></a></li>
<li><a href='#petrel.grid'><p>A dataset of grids for producing spatial predictions of seabed sediment content in the Petrel sub-basin in Australia Exclusive Economic Zone</p></a></li>
<li><a href='#pred.acc'><p>Predictive error and accuracy measures for predictive models based on cross-validation</p></a></li>
<li><a href='#RFcv'><p>Cross validation, n-fold for random forest (RF)</p></a></li>
<li><a href='#rfidwcv'><p>Cross validation, n-fold for the hybrid method of random forest and</p>
inverse distance weighting (RFIDW)</a></li>
<li><a href='#rfidwpred'><p>Generate spatial predictions using the hybrid method of random forest and</p>
inverse distance weighting (RFIDW)</a></li>
<li><a href='#rfokcv'><p>Cross validation, n-fold for the hybrid method of random forest and ordinary kriging (RFOK)</p></a></li>
<li><a href='#rfokpred'><p>Generate spatial predictions using the hybrid method of random forest and</p>
ordinary kriging (RFOK)</a></li>
<li><a href='#rfokrfidwcv'><p>Cross validation, n-fold for the average of the hybrid method of random forest and ordinary kriging and the hybrid method of random forest and inverse distance weighting  (RFOKRFIDW)</p></a></li>
<li><a href='#rfokrfidwpred'><p>Generate spatial predictions using the average of the hybrid method of</p>
random forest and ordinary kriging and the hybrid method of random forest and
inverse distance weighting  (RFOKRFIDW)</a></li>
<li><a href='#rfpred'><p>Generate spatial predictions using random forest (RF)</p></a></li>
<li><a href='#rgcv'><p>Cross validation, n-fold for random forest in ranger (RG)</p></a></li>
<li><a href='#rgidwcv'><p>Cross validation, n-fold for the hybrid method of random forest in ranger</p>
and inverse distance weighting (RGIDW)</a></li>
<li><a href='#rgidwpred'><p>Generate spatial predictions using the hybrid method of random forest</p>
in ranger and inverse distance weighting (RGIDW)</a></li>
<li><a href='#rgokcv'><p>Cross validation, n-fold for the hybrid method of random forest in ranger</p>
and ordinary kriging (RGFOK)</a></li>
<li><a href='#rgokpred'><p>Generate spatial predictions using the hybrid method of random forest in</p>
ranger and ordinary kriging (RGOK)</a></li>
<li><a href='#rgokrgidwcv'><p>Cross validation, n-fold for the average of the hybrid method of random</p>
forest in ranger (RG) and ordinary kriging and the hybrid method of RG
and inverse distance weighting  (RGOKRGIDW)</a></li>
<li><a href='#rgokrgidwpred'><p>Generate spatial predictions using the average of the hybrid method of</p>
random forest in ranger (RG) and ordinary kriging and the hybrid method of RG
and inverse distance weighting (RGOKRGIDW)</a></li>
<li><a href='#rgpred'><p>Generate spatial predictions using random forest in ranger (RG)</p></a></li>
<li><a href='#rvi'><p>Relative variable influence based on generalized boosted regression</p>
modeling (gbm)</a></li>
<li><a href='#sponge'><p>A dataset of sponge species richness in the Timor Sea region, northern Australia marine margin</p></a></li>
<li><a href='#sponge.grid'><p>A dataset of predictors for generating sponge species richness in a selected region in the Timor Sea region, northern Australia marine margin</p></a></li>
<li><a href='#sw'><p>A dataset of grids for producing spatial predictions of seabed mud content in the southwest Australia Exclusive Economic Zone</p></a></li>
<li><a href='#swmud'><p>A dataset of seabed mud content in the southwest Australia Exclusive Economic Zone</p></a></li>
<li><a href='#tovecv'><p>Convert error measures to vecv</p></a></li>
<li><a href='#vecv'><p>Variance explained by predictive models based on cross-validation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Spatial Predictive Modeling</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-06</td>
</tr>
<tr>
<td>Description:</td>
<td>Introduction to some novel accurate hybrid methods of geostatistical and machine learning methods for spatial predictive modelling. It contains two commonly used geostatistical methods, two machine learning methods, four hybrid methods and two averaging methods. For each method, two functions are provided. One function is for assessing the predictive errors and accuracy of the method based on cross-validation. The other one is for generating spatial predictions using the method. For details please see: Li, J., Potter, A., Huang, Z., Daniell, J. J. and Heap, A. (2010) &lt;https:www.ga.gov.au/metadata-gateway/metadata/record/gcat_71407&gt;
  Li, J., Heap, A. D., Potter, A., Huang, Z. and Daniell, J. (2011) &lt;<a href="https://doi.org/10.1016%2Fj.csr.2011.05.015">doi:10.1016/j.csr.2011.05.015</a>&gt;
  Li, J., Heap, A. D., Potter, A. and Daniell, J. (2011) &lt;<a href="https://doi.org/10.1016%2Fj.envsoft.2011.07.004">doi:10.1016/j.envsoft.2011.07.004</a>&gt;
  Li, J., Potter, A., Huang, Z. and Heap, A. (2012) &lt;https:www.ga.gov.au/metadata-gateway/metadata/record/74030&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>gstat, sp, randomForest, psy, gbm, biomod2, stats, ranger</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-06 01:57:26 UTC; Jin</td>
</tr>
<tr>
<td>Author:</td>
<td>Jin Li [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jin Li &lt;jinli68@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-06 06:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='avi'>Averaged variable importance based on random forest</h2><span id='topic+avi'></span>

<h3>Description</h3>

<p>This function is to derive an averaged variable importance based
on random forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avi(
  trainx,
  trainy,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  importance = TRUE,
  maxk = c(4),
  nsim = 100,
  corr.threshold = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="avi_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="avi_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="avi_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="avi_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="avi_+3A_importance">importance</code></td>
<td>
<p>imprtance of predictive variables.</p>
</td></tr>
<tr><td><code id="avi_+3A_maxk">maxk</code></td>
<td>
<p>maxk split value. By default, 4 is used.</p>
</td></tr>
<tr><td><code id="avi_+3A_nsim">nsim</code></td>
<td>
<p>iteration number. By default, 100 is used.</p>
</td></tr>
<tr><td><code id="avi_+3A_corr.threshold">corr.threshold</code></td>
<td>
<p>correlation threshold and the defaults value is 0.5.</p>
</td></tr>
<tr><td><code id="avi_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: averaged variable importance
(avi), column number of importance variable in trainx arranged from the most
important to the least important (impvar), names of importance variable
arranged from the most important to the least important (impvar2)
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Smith, S.J., Ellis, N., Pitcher, C.R., 2011. Conditional variable
importance in R package extendedForest.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
set.seed(1234)
avi1 &lt;- avi(petrel[, c(1,2, 6:9)], petrel[, 5], nsim = 10)
avi1

avi1 &lt;- avi(petrel[, c(1), drop = FALSE], petrel[, 5], nsim = 10)
avi1

## End(Not run)

</code></pre>

<hr>
<h2 id='cran-comments'>
Note on notes
</h2><span id='topic+cran-comments'></span>

<h3>Description</h3>

<p>This is my first submission.
</p>
<p>## R CMD check results
0 errors | 0 warnings | 0 notes
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>

<hr>
<h2 id='gbmcv'>Cross validation, n-fold for generalized boosted regression modeling (gbm)</h2><span id='topic+gbmcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for generalized
boosted regression modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmcv(
  trainx,
  trainy,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  n.cores = 6,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. it is also
the number of cross-validation folds to perform within gbm. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="gbmcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv
for categorical data: correct classification rate (ccr.cv) and kappa (kappa.cv)
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013),
rfcv in randomForest and gbm.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Greg Ridgeway with contributions from others (2015). gbm: Generalized
Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)

gbmcv1 &lt;- gbmcv(sponge[, -c(3)], sponge[, 3], cv.fold = 10,
family = "poisson", n.cores=2, predacc = "ALL")
gbmcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
gbmcv1 &lt;- gbmcv(sponge[, -c(3)], sponge[, 3], cv.fold = 10,
family = "poisson",  n.cores=2, predacc = "VEcv")
VEcv [i] &lt;- gbmcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for gbm", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmidwcv'>Cross validation, n-fold for the hybrid method of generalized boosted
regression modeling and inverse distance weighting (gbmidw)</h2><span id='topic+gbmidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of generalized boosted regression modeling and inverse distance
weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmidwcv(
  longlat,
  trainx,
  trainy,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  idp = 2,
  nmax = 12,
  predacc = "VEcv",
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. it is also
the number of cross-validation folds to perform within gbm. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data=FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv
for categorical data: correct classification rate (ccr.cv) and kappa (kappa.cv)
</p>


<h3>Note</h3>

<p>this function is largely based on rf.cv (see Li et al. 2013),
rfcvrandomForest and gbm
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Greg Ridgeway with contributions from others (2015). gbm: Generalized
Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)

gbmidwcv1 &lt;- gbmidwcv(sponge[, c(1,2)], sponge[, -c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "ALL")
gbmidwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
gbmidwcv1 &lt;- gbmidwcv(sponge[, c(1,2)], sponge[, -c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "VEcv")
VEcv [i] &lt;- gbmidwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for gbmidw", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmidwpred'>Generate spatial predictions using the hybrid method of generalized boosted regression
modeling and inverse distance weighting (gbmidw)</h2><span id='topic+gbmidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of generalized boosted regression modeling and inverse distance
weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  idp = 2,
  nmax = 12,
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. it is also
the number of cross-validation folds to perform within gbm. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse and vecv; or vecv
for categorical data: correct classification rate (ccr.cv) and kappa (kappa.cv)
</p>


<h3>Note</h3>

<p>This function is largely based on gbm.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Greg Ridgeway with contributions from others (2015). gbm: Generalized
Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
gbmidwpred1 &lt;- gbmidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
  petrel.grid[, c(1,2)], petrel.grid, family = "gaussian", n.cores=6,
  nmax = 12)
names(gbmidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmokcv'>Cross validation, n-fold for the hybrid method of generalized boosted
regression modeling and ordinary kriging (gbmok)</h2><span id='topic+gbmokcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of generalized boosted regression modeling and ordinary kriging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmokcv(
  longlat,
  trainx,
  trainy,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmokcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. it is also
the number of cross-validation folds to perform within gbm. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmokcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv
for categorical data: correct classification rate (ccr.cv) and kappa (kappa.cv)
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013),
rfcv in randomForest and gbm. When 'A zero or negative range was fitted to
variogram' occurs, to allow gstat running, the range was set to be positive by
using min(vgm1$dist). In this case, caution should be taken in applying this
method, although sometimes it can still outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Greg Ridgeway with contributions from others (2015). gbm: Generalized
Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)

gbmokcv1 &lt;- gbmokcv(sponge[, c(1,2)], sponge[,-c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "ALL")
gbmokcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
gbmokcv1 &lt;- gbmokcv(sponge[, c(1,2)], sponge[, -c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "VEcv")
VEcv [i] &lt;- gbmokcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for gbmok", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmokgbmidwcv'>Cross validation, n-fold for the average of the hybrid method of generalized
boosted regression modeling and ordinary kriging and the hybrid method of generalized
boosted regression modeling and inverse distance weighting (gbmokgbmidw)</h2><span id='topic+gbmokgbmidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the average
of the hybrid method of generalized boosted regression modeling and ordinary
kriging and the hybrid method of generalized boosted regression modeling and
inverse distance weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmokgbmidwcv(
  longlat,
  trainx,
  trainy,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  idp = 2,
  nmaxidw = 12,
  nmaxok = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmokgbmidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. it is also
the number of cross-validation folds to perform within gbm. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgmgstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv
for categorical data: correct classification rate (ccr.cv) and kappa (kappa.cv)
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013),
rfcv in randomForest and gbm.  When 'A zero or negative range was fitted to
variogram' occurs, to allow gstat running, the range was set to be positive by
using min(vgm1$dist). In this case, caution should be taken in applying this
method, although sometimes it can still outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Greg Ridgeway with contributions from others (2015). gbm: Generalized
Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)

gbmokgbmidw1 &lt;- gbmokgbmidwcv(sponge[, c(1,2)], sponge[, -c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "ALL")
gbmokgbmidw1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
gbmokgbmidw1 &lt;- gbmokgbmidwcv(sponge[, c(1,2)], sponge[, -c(3)], sponge[, 3],
cv.fold = 10, family = "poisson", n.cores=2, predacc = "VEcv")
VEcv [i] &lt;- gbmokgbmidw1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for gbmokgbmidw", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmokgbmidwpred'>Generate spatial predictions using the average of the hybrid method of
generalized boosted regression modeling and ordinary kriging and the hybrid method of
generalized boosted regression modeling and inverse distance weighting (gbmokgbmidw)</h2><span id='topic+gbmokgbmidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the average
of the hybrid method of generalized boosted regression modeling and ordinary
kriging and the hybrid method of generalized boosted regression modeling and
inverse distance weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmokgbmidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 0,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  idp = 2,
  nmaxidw = 12,
  nmaxok = 12,
  vgm.args = ("Sph"),
  block = 0,
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmokgbmidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of cross-validation folds to perform within
gbm.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmokgbmidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are the same as the variances of gbmokpred.
</p>


<h3>Note</h3>

<p>This function is largely based on gbm. When 'A zero or negative range
was fitted to variogram' occurs, to allow OK running, the range was set
to be positive by using min(vgm1$dist). In this case, caution should be
taken in applying this method, although sometimes it can still outperform
IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Greg Ridgeway with contributions from others (2015). gbm:
Generalized Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
gbmokgbmidwpred1 &lt;- gbmokgbmidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)],
petrel[, 3], petrel.grid[, c(1,2)], petrel.grid, family = "gaussian",
n.cores=6, nmaxidw = 12, nmaxok = 12, vgm.args = ("Sph"))
names(gbmokgbmidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmokpred'>Generate spatial predictions using the hybrid method of generalized boosted
regression modeling and ordinary kriging (gbmok)</h2><span id='topic+gbmokpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of generalized boosted regression modeling and ordinary kriging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmokpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmokpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of cross-validation folds to perform within
gbm. if &gt; 1, then apply n-fold cross validation; the default is 10, i.e.,
10-fold cross validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmokpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are produced by OK based on the residuals of gbm.
</p>


<h3>Note</h3>

<p>This function is largely based on gbm. When 'A zero or negative range
was fitted to variogram' occurs, to allow OK running, the range was set
to be positive by using min(vgm1$dist). In this case, caution should be
taken in applying this method, although sometimes it can still outperform
IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Greg Ridgeway with contributions from others (2015). gbm:
Generalized Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
gbmokpred1 &lt;- gbmokpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
  petrel.grid[, c(1,2)], petrel.grid, family = "gaussian", n.cores=6,
  nmax = 12, vgm.args = ("Sph"))
names(gbmokpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='gbmpred'>Generate spatial predictions using generalized boosted regression modeling ('gbm')</h2><span id='topic+gbmpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using generalized
boosted regression modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbmpred(
  trainx,
  trainy,
  longlatpredx,
  predx,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbmpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See 'gbm' for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first 'train.fraction * nrows(data)' observations
are used to fit the 'gbm' and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of cross-validation folds to perform within
'gbm'. if &gt; 1, then apply n-fold cross validation; the default is 10, i.e.,
10-fold cross validation that is recommended.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to &lsquo;gbm' then it is the user&rsquo;s
responsibility to resupply the weights to 'gbm.more'. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to 'gbm.more' faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, 'gbm' will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See 'gbm' for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="gbmpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to 'gbm'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Note</h3>

<p>This function is largely based on 'gbm'.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Greg Ridgeway with contributions from others (2015). gbm:
Generalized Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)
data(sponge.grid)
gbmpred1 &lt;- gbmpred(sponge[, -c(3)], sponge[, 3], sponge.grid[, c(1:2)],
sponge.grid, family = "poisson", n.cores=2)
names(gbmpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='hard'>A dataset of seabed hardness in the eastern Joseph Bonaparte Golf, northern Australia marine margin</h2><span id='topic+hard'></span>

<h3>Description</h3>

<p>This dataset contains 137 samples of 17 variables including area surveyed (Area), easting, northing, prock, bathymetry (bathy), backscatter (bs), local Moran I (bathy.moran), plannar curvature (planar.curv), profile curvature (profile.curv), topographic relief (relief), slope (slope), surface area (surface), topographic position index (tpi), homogeneity of backscatter (homogeneity),  local Moran I of backscatter (bs.moran), variance of backscatter (variance) and seabed hardness (hardness).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("hard")</code></pre>


<h3>Format</h3>

<p>A data frame with 137 observations on the following 17 variables.
</p>

<dl>
<dt><code>Area</code></dt><dd><p>a catergorical vector, no unit</p>
</dd>
<dt><code>easting</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>northing</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>prock</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>bathy</code></dt><dd><p>a numeric vector, meter</p>
</dd>
<dt><code>bs</code></dt><dd><p>a numeric vector, dB</p>
</dd>
<dt><code>bathy.moran</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>planar.curv</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>profile.curv</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>relief</code></dt><dd><p>a numeric vector, meter</p>
</dd>
<dt><code>slope</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>surface</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>tpi</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>homogeneity</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>bs.moran</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>variance</code></dt><dd><p>a numeric vector, dB^2</p>
</dd>
<dt><code>hardness</code></dt><dd><p>a catergorical vector, no unit</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please see the source. This dataset was modified by removing 3 samples with missing values from Appendix AA of the book chapter listed in the source.</p>


<h3>Source</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013. Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y. Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.</p>

<hr>
<h2 id='idwcv'>Cross validation, n-fold for inverse distance weighting (IDW)</h2><span id='topic+idwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for inverse
distance weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>idwcv(longlat, trainy, cv.fold = 10, nmax = 12, idp = 2, predacc = "VEcv", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="idwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in longlat.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_nmax">nmax</code></td>
<td>
<p>for a local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="idwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv only.
</p>


<h3>Note</h3>

<p>This function is largely based on rfcv in randomForest and
some functions in library(gstat).
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., 2013. Predictive Modelling Using Random Forest and Its
Hybrid Methods with Geostatistical Techniques in Marine Environmental
Geosciences, In: Christen, P., Kennedy, P., Liu, L., Ong, K.-L., Stranieri,
A., Zhao, Y. (Eds.), The proceedings of the Eleventh Australasian Data
Mining Conference (AusDM 2013), Canberra, Australia, 13-15 November 2013.
Conferences in Research and Practice in Information Technology, Vol. 146.
</p>
<p>A. Liaw and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Pebesma, E.J., 2004. Multivariable geostatistics in S: the gstat
package. Computers &amp; Geosciences, 30: 683-691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sp)
data(swmud)
data(petrel)

idwcv1 &lt;- idwcv(swmud[, c(1,2)], swmud[, 3], nmax = 12, idp = 2)
idwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
idwcv1 &lt;- idwcv(petrel[, c(1,2)], petrel[, 3], nmax = 12, predacc = "VEcv")
VEcv [i] &lt;- idwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for IDW", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd=2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
idwcv1 &lt;- idwcv(swmud[, c(1,2)], swmud[, 3], predacc = "ALL")
measures &lt;- rbind(measures, idwcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for IDW", ylab="VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='idwpred'>Generate spatial predictions using inverse distance weighting (IDW)</h2><span id='topic+idwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using inverse
distance weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>idwpred(longlat, trainy, longlat2, nmax = 12, idp = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="idwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point samples.</p>
</td></tr>
<tr><td><code id="idwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in longlat.</p>
</td></tr>
<tr><td><code id="idwpred_+3A_longlat2">longlat2</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="idwpred_+3A_nmax">nmax</code></td>
<td>
<p>for a local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="idwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="idwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Note</h3>

<p>This function is largely based on library(gstat).
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Pebesma, E.J., 2004. Multivariable geostatistics in S: the gstat
package. Computers &amp; Geosciences, 30: 683-691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sp)
data(swmud)
data(sw)
idwpred1 &lt;- idwpred(swmud[, c(1,2)], swmud[, 3], sw, nmax = 12, idp = 2)
names(idwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='okcv'>Cross validation, n-fold for ordinary kriging (OK)</h2><span id='topic+okcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for ordinary
kriging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>okcv(
  longlat,
  trainy,
  cv.fold = 10,
  nmax = 12,
  transformation = "none",
  delta = 1,
  vgm.args = ("Sph"),
  anis = c(0, 1),
  alpha = 0,
  block = 0,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="okcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples.</p>
</td></tr>
<tr><td><code id="okcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in longlat.</p>
</td></tr>
<tr><td><code id="okcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="okcv_+3A_nmax">nmax</code></td>
<td>
<p>for local kriging: the number of nearest observations that
should be used for a kriging prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="okcv_+3A_transformation">transformation</code></td>
<td>
<p>transform the response variable to normalise the data;
can be &quot;sqrt&quot; for square root, &quot;arcsine&quot; for arcsine, &quot;log&quot; or &quot;none&quot;
for non transformation. By default, &quot;none&quot; is used.</p>
</td></tr>
<tr><td><code id="okcv_+3A_delta">delta</code></td>
<td>
<p>numeric; to avoid log(0) in the log transformation.</p>
</td></tr>
<tr><td><code id="okcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="okcv_+3A_anis">anis</code></td>
<td>
<p>anisotropy parameters: see notes vgm in gstat for details.</p>
</td></tr>
<tr><td><code id="okcv_+3A_alpha">alpha</code></td>
<td>
<p>direction in plane (x,y). see variogram in gstat for details.</p>
</td></tr>
<tr><td><code id="okcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="okcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="okcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv only
</p>


<h3>Note</h3>

<p>This function is largely based on rfcv in randomForest and
some functions in library(gstat).  When 'A zero or negative range was fitted
to variogram' occurs, to allow gstat running, the range was set to be positive by
using min(vgm1$dist). In this case, caution should be taken in applying this
method. If it still occur for okpred function, different method should be
used.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., 2013. Predictive Modelling Using Random Forest and Its
Hybrid Methods with Geostatistical Techniques in Marine Environmental
Geosciences, In: Christen, P., Kennedy, P., Liu, L., Ong, K.-L., Stranieri,
A., Zhao, Y. (Eds.), The proceedings of the Eleventh Australasian Data
Mining Conference (AusDM 2013), Canberra, Australia, 13-15 November 2013.
Conferences in Research and Practice in Information Technology, Vol. 146.
</p>
<p>A. Liaw and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Pebesma, E.J., 2004. Multivariable geostatistics in S: the gstat
package. Computers &amp; Geosciences, 30: 683-691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sp)
data(swmud)
data(petrel)

okcv1 &lt;- okcv(swmud[, c(1,2)], swmud[, 3], nmax = 7, transformation =
"arcsine", vgm.args = ("Sph"), predacc = "VEcv")
okcv1

n &lt;- 20 # number of iterations,60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
okcv1 &lt;- okcv(petrel[, c(1,2)], petrel[, 5], nmax = 12,
transformation = "arcsine", predacc = "VEcv")
VEcv [i] &lt;- okcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for OK", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
okcv1 &lt;- okcv(petrel[, c(1,2)], petrel[, 3], nmax = 12, transformation =
"arcsine", predacc = "ALL")
measures &lt;- rbind(measures, okcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for OK", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='okpred'>Generate spatial predictions using ordinary kriging (OK)</h2><span id='topic+okpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using ordinary
kriging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>okpred(
  longlat,
  trainy,
  longlat2,
  nmax = 12,
  transformation = "none",
  delta = 1,
  vgm.args = ("Sph"),
  anis = c(0, 1),
  alpha = 0,
  block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="okpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples.</p>
</td></tr>
<tr><td><code id="okpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in longlat.</p>
</td></tr>
<tr><td><code id="okpred_+3A_longlat2">longlat2</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="okpred_+3A_nmax">nmax</code></td>
<td>
<p>for local kriging: the number of nearest observations that
should be used for a kriging prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="okpred_+3A_transformation">transformation</code></td>
<td>
<p>transform the response variable to normalise the data;
can be &quot;sqrt&quot; for square root, &quot;arcsine&quot; for arcsine, &quot;log&quot; or &quot;none&quot;
for non transformation. By default, &quot;none&quot; is used.</p>
</td></tr>
<tr><td><code id="okpred_+3A_delta">delta</code></td>
<td>
<p>numeric; to avoid log(0) in the log transformation.</p>
</td></tr>
<tr><td><code id="okpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="okpred_+3A_anis">anis</code></td>
<td>
<p>anisotropy parameters: see notes vgm in gstat for details.</p>
</td></tr>
<tr><td><code id="okpred_+3A_alpha">alpha</code></td>
<td>
<p>direction in plane (x,y). see variogram in gstat for details.</p>
</td></tr>
<tr><td><code id="okpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="okpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Pebesma, E.J., 2004. Multivariable geostatistics in S: the gstat
package. Computers &amp; Geosciences, 30: 683-691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sp)
data(swmud)
data(sw)
okpred1 &lt;- okpred(swmud[, c(1,2)], swmud[, 3], sw, nmax = 7, transformation =
"arcsine", vgm.args = ("Sph"))
names(okpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='petrel'>A dataset of seabed sediments in the Petrel sub-basin in Australia Exclusive Economic Zone</h2><span id='topic+petrel'></span>

<h3>Description</h3>

<p>This dataset contains 237 samples of 9 variables including longitude (long),
latitude (lat), mud content (mud), sand content (sand), gravel content (gravel),
bathymetry (bathy), disttance to coast (dist), seabe relief (relief),
seabed slope (slope).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("petrel")</code></pre>


<h3>Format</h3>

<p>A data frame with 237 observations on the following 9 variables.
</p>

<dl>
<dt><code>long</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>lat</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>mud</code></dt><dd><p>a numeric vector, percentage</p>
</dd>
<dt><code>sand</code></dt><dd><p>a numeric vector, percentage</p>
</dd>
<dt><code>gravel</code></dt><dd><p>a numeric vector, percentage</p>
</dd>
<dt><code>bathy</code></dt><dd><p>a numeric vector, meter bellow sea level</p>
</dd>
<dt><code>dist</code></dt><dd><p>a numeric vector, degree</p>
</dd>
<dt><code>relief</code></dt><dd><p>a numeric vector, meter</p>
</dd>
<dt><code>slope</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please check the reference.</p>


<h3>Source</h3>

<p>Li, J., 2013. Predicting the spatial distribution of seabed gravel content using random forest, spatial interpolation methods and their hybrid methods, The International Congress on Modelling and Simulation (MODSIM) 2013: Adelaide, pp. 394-400.</p>

<hr>
<h2 id='petrel.grid'>A dataset of grids for producing spatial predictions of seabed sediment content in the Petrel sub-basin in Australia Exclusive Economic Zone</h2><span id='topic+petrel.grid'></span>

<h3>Description</h3>

<p>This dataset contains 248675 rows of 6 variables including
longitude (long), latitude (lat), bathymetry (bathy), disttance to coast (dist), seabe relief (relief),
seabed slope (slope).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("petrel")</code></pre>


<h3>Format</h3>

<p>A data frame with 248675 observations on the following 6 variables.
</p>

<dl>
<dt><code>long</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>lat</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>bathy</code></dt><dd><p>a numeric vector, meter bellow sea level</p>
</dd>
<dt><code>dist</code></dt><dd><p>a numeric vector, degree</p>
</dd>
<dt><code>relief</code></dt><dd><p>a numeric vector, meter</p>
</dd>
<dt><code>slope</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please check the reference.</p>


<h3>Source</h3>

<p>Li, J., 2013. Predicting the spatial distribution of seabed gravel content using random forest, spatial interpolation methods and their hybrid methods, The International Congress on Modelling and Simulation (MODSIM) 2013: Adelaide, pp. 394-400.</p>

<hr>
<h2 id='pred.acc'>Predictive error and accuracy measures for predictive models based on cross-validation</h2><span id='topic+pred.acc'></span>

<h3>Description</h3>

<p>This function is used to calculate the mean error (me), mean absolute error
(mae), mean squared error (mse), relative me (rme), relative mae (rmae),
root mse (rmse), relative rmse (rrmse), variance explained by predictive
models based on cross-validation (vecv), and Legates and McCabe's E1 (e1) for numerical data; and
it also calculates correct classification rate (ccr), kappa (kappa), sensitivity (sens), specificity
(spec), and true skill statistic (tss) for categorical data with the observed (obs) data specified
as factor. They are based on the differences between the predicted values for and the observed values
of validation samples for cross-validation. For 0 and 1 data, the observed values need to be specified
as factor in order to use accuracy measures for categorical data. Moreover, sens, spec, tss and rmse are
for categorical data with two levels (e.g. presence and absence data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.acc(obs, pred)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pred.acc_+3A_obs">obs</code></td>
<td>
<p>a vector of observation values of validation samples.</p>
</td></tr>
<tr><td><code id="pred.acc_+3A_pred">pred</code></td>
<td>
<p>a vector of prediction values of predictive models for validation samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1 for numerical data;
ccr, kappa, sens, spec and tss for categorical data with two levels; and
ccr, kappa for categorical data with more than two levels.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., 2016. Assessing spatial predictive models in the environmental sciences: accuracy
measures, data variation and variance explained. Environmental Modelling &amp; Software 80 1-8.
</p>
<p>Li, J., 2017. Assessing the accuracy of predictive models for numerical data: Not r nor r2, why not?
Then what? PLOS ONE 12 (8): e0183250.
</p>
<p>Allouche, O., Tsoar, A., Kadmon, R., 2006. Assessing the accuracy of species distribution models:
prevalence, kappa and true skill statistic (TSS). Journal of Applied Ecology 43 1223-1232.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- sample(1:30, 30)
e &lt;- rnorm(30, 1)
y &lt;- x + e
pred.acc(x, y)

y &lt;- 0.8 * x + e
pred.acc(x, y)

</code></pre>

<hr>
<h2 id='RFcv'>Cross validation, n-fold for random forest (RF)</h2><span id='topic+RFcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for random forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RFcv(
  trainx,
  trainy,
  cv.fold = 10,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  predacc = "ALL",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RFcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="RFcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
for categorical data: correct classification rate (ccr), kappa (kappa), sensitivity (sens),
specificity (spec) and true skill statistic (tss)
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(hard)
data(petrel)

rfcv1 &lt;- RFcv(petrel[, c(1,2, 6:9)], petrel[, 5], predacc = "ALL")
rfcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv(petrel[, c(1,2,6:9)], petrel[, 5], predacc = "VEcv")
VEcv [i] &lt;- rfcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RF", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv(hard[, c(4:6)], hard[, 17])
measures &lt;- rbind(measures, rfcv1$ccr) # for kappa, replace ccr with kappa
}
plot(measures ~ c(1:n), xlab = "Iteration for RF", ylab = "Correct
classification rate  (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfidwcv'>Cross validation, n-fold for the hybrid method of random forest and
inverse distance weighting (RFIDW)</h2><span id='topic+rfidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of random forest and inverse distance weighting (RFIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfidwcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  idp = 2,
  nmax = 12,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rfidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rfidwcv1 &lt;- rfidwcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rfidwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfidwcv1 &lt;- rfidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rfidwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFIDW", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfidwcv1 &lt;- rfidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rfidwcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFIDW", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfidwpred'>Generate spatial predictions using the hybrid method of random forest and
inverse distance weighting (RFIDW)</h2><span id='topic+rfidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of random forest and inverse distance weighting (RFIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  idp = 2,
  nmax = 12,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="rfidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rfidwpred1 &lt;- rfidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
petrel.grid[, c(1,2)], petrel.grid, ntree = 500, idp = 2, nmax = 12)
names(rfidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfokcv'>Cross validation, n-fold for the hybrid method of random forest and ordinary kriging (RFOK)</h2><span id='topic+rfokcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of random forest and ordinary kriging (RFOK).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfokcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfokcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rfokcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.  When 'A zero or negative range was fitted to
variogram' occurs, to allow gstat running, the range was set to be positive by
using min(vgm1$dist). In this case, caution should be taken in applying this
method, although sometimes it can still outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rfokcv1 &lt;- rfokcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rfokcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfokcv1 &lt;- rfokcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rfokcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFOK", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfokcv1 &lt;- rfokcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rfokcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFOK", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfokpred'>Generate spatial predictions using the hybrid method of random forest and
ordinary kriging (RFOK)</h2><span id='topic+rfokpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of random forest and ordinary kriging (RFOK).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfokpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfokpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rfokpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are produced by OK based on the residuals of rf.
</p>


<h3>Note</h3>

<p>This function is largely based rfcv in randomForest.  When 'A zero or
negative range was fitted to variogram' occurs, to allow OK running, the
range was set to be positive by using min(vgm1$dist). In this case, caution
should be taken in applying this method, although sometimes it can still
outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rfokpred1 &lt;- rfokpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
petrel.grid[, c(1,2)], petrel.grid, ntree = 500, nmax = 12, vgm.args =
("Sph"))
names(rfokpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfokrfidwcv'>Cross validation, n-fold for the average of the hybrid method of random forest and ordinary kriging and the hybrid method of random forest and inverse distance weighting  (RFOKRFIDW)</h2><span id='topic+rfokrfidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the average of
the hybrid method of random forest and ordinary kriging and the hybrid
method of random forest and inverse distance weighting  (RFOKRFIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfokrfidwcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  idp = 2,
  nmaxok = 12,
  nmaxidw = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfokrfidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rfokrfidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.  When 'A zero or negative range was fitted to
variogram' occurs, to allow gstat running, the range was set to be positive by
using min(vgm1$dist). In this case, caution should be taken in applying this
method, although sometimes it can still outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rfokrfidwcv1 &lt;- rfokrfidwcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rfokrfidwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfokrfidwcv1 &lt;- rfokrfidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rfokrfidwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFOKRFIDW", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfokrfidwcv1 &lt;- rfokrfidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rfokrfidwcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFOKRFIDW", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfokrfidwpred'>Generate spatial predictions using the average of the hybrid method of
random forest and ordinary kriging and the hybrid method of random forest and
inverse distance weighting  (RFOKRFIDW)</h2><span id='topic+rfokrfidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the average
of the hybrid method of random forest and ordinary kriging and the hybrid
method of random forest and inverse distance weighting  (RFOKRFIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfokrfidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  ntree = 500,
  idp = 2,
  nmaxok = 12,
  nmaxidw = 12,
  vgm.args = ("Sph"),
  block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfokrfidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
locations (i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rfokrfidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are the same as the variances of rfokpred.
</p>


<h3>Note</h3>

<p>This function is largely based rfcv in randomForest.  When 'A zero or
negative range was fitted to variogram' occurs, to allow OK running, the
range was set to be positive by using min(vgm1$dist). In this case, caution
should be taken in applying this method, although sometimes it can still
outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rfokrfidwpred1 &lt;- rfokrfidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)],
petrel[, 3], petrel.grid[, c(1,2)], petrel.grid, ntree = 500, idp = 2,
nmaxok = 12, nmaxidw = 12)
names(rfokrfidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rfpred'>Generate spatial predictions using random forest (RF)</h2><span id='topic+rfpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using random forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfpred(
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rfpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
locations (i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables
for the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rfpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rfpred1 &lt;- rfpred(petrel[, c(1,2, 6:9)], petrel[, 5], petrel.grid[, c(1,2)],
petrel.grid, ntree = 500)
names(rfpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgcv'>Cross validation, n-fold for random forest in ranger (RG)</h2><span id='topic+rgcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for random forest in ranger.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgcv(
  trainx,
  trainy,
  cv.fold = 10,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  num.trees = 500,
  min.node.size = NULL,
  num.threads = NULL,
  verbose = FALSE,
  predacc = "ALL",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables to possibly split at in each node. Default is the
(rounded down) square root of the number variables.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rgcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
for categorical data: correct classification rate (ccr), kappa (kappa), sensitivity (sens),
specificity (spec) and true skill statistic (tss)
</p>


<h3>Note</h3>

<p>This function is largely based on RFcv.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(hard)
data(petrel)

rgcv1 &lt;- rgcv(petrel[, c(1,2, 6:9)], petrel[, 5], predacc = "ALL")
rgcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rgcv1 &lt;- rgcv(petrel[, c(1,2,6:9)], petrel[, 5], predacc = "VEcv")
VEcv [i] &lt;- rgcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RF", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rgcv1 &lt;- rgcv(hard[, c(4:6)], hard[, 17])
measures &lt;- rbind(measures, rgcv1$ccr) # for kappa, replace ccr with kappa
}
plot(measures ~ c(1:n), xlab = "Iteration for RF", ylab = "Correct
classification rate  (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgidwcv'>Cross validation, n-fold for the hybrid method of random forest in ranger
and inverse distance weighting (RGIDW)</h2><span id='topic+rgidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of random forest in ranger and inverse distance weighting (RGIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgidwcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  num.threads = NULL,
  verbose = FALSE,
  idp = 2,
  nmax = 12,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rgidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rfidwcv.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rgidwcv1 &lt;- rgidwcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rgidwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rgidwcv1 &lt;- rgidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rgidwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFIDW", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rgidwcv1 &lt;- rgidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rgidwcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFIDW", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgidwpred'>Generate spatial predictions using the hybrid method of random forest
in ranger and inverse distance weighting (RGIDW)</h2><span id='topic+rgidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of random forest in ranger and inverse distance weighting (RGIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  type = "response",
  num.threads = NULL,
  verbose = FALSE,
  idp = 2,
  nmax = 12,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes' with
default 'response'. See ranger::predict.ranger for details.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used.</p>
</td></tr>
<tr><td><code id="rgidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Note</h3>

<p>This function is largely based on rfidwpred.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rgidwpred1 &lt;- rgidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
petrel.grid[, c(1,2)], petrel.grid, num.trees = 500, idp = 2, nmax = 12)
names(rgidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgokcv'>Cross validation, n-fold for the hybrid method of random forest in ranger
and ordinary kriging (RGFOK)</h2><span id='topic+rgokcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the hybrid
method of random forest in ranger and ordinary kriging (RFOK).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgokcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  num.threads = NULL,
  verbose = FALSE,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgokcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rgokcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rfokcv. When 'A zero or negative range
was fitted to variogram' occurs, to allow gstat running, the range was set to
be positive by using min(vgm1$dist). In this case, caution should be taken in
applying this method, although sometimes it can still outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rgokcv1 &lt;- rgokcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rgokcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rgokcv1 &lt;- rgokcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rgokcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFOK", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rgokcv1 &lt;- rgokcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rgokcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFOK", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgokpred'>Generate spatial predictions using the hybrid method of random forest in
ranger and ordinary kriging (RGOK)</h2><span id='topic+rgokpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the hybrid
method of random forest in ranger and ordinary kriging (RGOK).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgokpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  type = "response",
  num.threads = NULL,
  verbose = FALSE,
  nmax = 12,
  vgm.args = ("Sph"),
  block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgokpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point locations
(i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes' with
default 'response'. See ranger::predict.ranger for details.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_nmax">nmax</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rgokpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are produced by OK based on the residuals of rf.
</p>


<h3>Note</h3>

<p>This function is largely based rfokpred.  When 'A zero or
negative range was fitted to variogram' occurs, to allow OK running, the
range was set to be positive by using min(vgm1$dist). In this case, caution
should be taken in applying this method, although sometimes it can still
outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rgokpred1 &lt;- rgokpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 3],
petrel.grid[, c(1,2)], petrel.grid, num.trees = 500, nmax = 12, vgm.args =
("Sph"))
names(rgokpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgokrgidwcv'>Cross validation, n-fold for the average of the hybrid method of random
forest in ranger (RG) and ordinary kriging and the hybrid method of RG
and inverse distance weighting  (RGOKRGIDW)</h2><span id='topic+rgokrgidwcv'></span>

<h3>Description</h3>

<p>This function is a cross validation function for the average of
the hybrid method of random forest in ranger (RG) and ordinary kriging and the hybrid
method of RG and inverse distance weighting  (RGOKRGIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgokrgidwcv(
  longlat,
  trainx,
  trainy,
  cv.fold = 10,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  num.threads = NULL,
  verbose = FALSE,
  idp = 2,
  nmaxok = 12,
  nmaxidw = 12,
  vgm.args = ("Sph"),
  block = 0,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgokrgidwcv_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_predacc">predacc</code></td>
<td>
<p>can be either &quot;VEcv&quot; for vecv or &quot;ALL&quot; for all measures
in function pred.acc.</p>
</td></tr>
<tr><td><code id="rgokrgidwcv_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
for numerical data: me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv.
</p>


<h3>Note</h3>

<p>This function is largely based on rfokrfidw.  When 'A zero or negative
range was fitted to variogram' occurs, to allow gstat running, the range was
set to be positive by using min(vgm1$dist). In this case, caution should be
taken in applying this method, although sometimes it can still outperform IDW
and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and their
hybrid methods. Pages 394-400  The International Congress on Modelling and
Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)

rgokrgidwcv1 &lt;- rgokrgidwcv(petrel[, c(1,2)], petrel[, c(1,2, 6:9)], petrel[, 5],
predacc = "ALL")
rgokrgidwcv1

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rgokrgidwcv1 &lt;- rgokrgidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "VEcv")
VEcv [i] &lt;- rgokrgidwcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RFOKRFIDW", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 20 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rgokrgidwcv1 &lt;- rgokrgidwcv(petrel[, c(1,2)], petrel[, c(1,2,6:9)], petrel[, 5],
predacc = "ALL")
measures &lt;- rbind(measures, rgokrgidwcv1$vecv)
}
plot(measures ~ c(1:n), xlab = "Iteration for RFOKRFIDW", ylab = "VEcv (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgokrgidwpred'>Generate spatial predictions using the average of the hybrid method of
random forest in ranger (RG) and ordinary kriging and the hybrid method of RG
and inverse distance weighting (RGOKRGIDW)</h2><span id='topic+rgokrgidwpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using the average
of the hybrid method of random forest in ranger (RG) and ordinary kriging and the hybrid
method of RG and inverse distance weighting  (RGOKRGIDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgokrgidwpred(
  longlat,
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = function(p) max(1, floor(sqrt(p))),
  num.trees = 500,
  min.node.size = NULL,
  type = "response",
  num.threads = NULL,
  verbose = FALSE,
  idp = 2,
  nmaxok = 12,
  nmaxidw = 12,
  vgm.args = ("Sph"),
  block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgokrgidwpred_+3A_longlat">longlat</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
samples (i.e., trainx and trainy).</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
locations (i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables for
the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes' with
default 'response'. See ranger::predict.ranger for details.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_idp">idp</code></td>
<td>
<p>numeric; specify the inverse distance weighting power.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_nmaxok">nmaxok</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for OK.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_nmaxidw">nmaxidw</code></td>
<td>
<p>for local predicting: the number of nearest observations that
should be used for a prediction or simulation, where nearest is
defined in terms of the space of the spatial locations. By default, 12
observations are used for IDW.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_vgm.args">vgm.args</code></td>
<td>
<p>arguments for vgm, e.g. variogram model of response
variable and anisotropy parameters. see notes vgm in gstat for details.
By default, &quot;Sph&quot; is used.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_block">block</code></td>
<td>
<p>block size. see krige in gstat for details.</p>
</td></tr>
<tr><td><code id="rgokrgidwpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest or gstat.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude, predictions and variances. The
variances are the same as the variances of rfokpred.
</p>


<h3>Note</h3>

<p>This function is largely based rfokrfidwpred.  When 'A zero or
negative range was fitted to variogram' occurs, to allow OK running, the
range was set to be positive by using min(vgm1$dist). In this case, caution
should be taken in applying this method, although sometimes it can still
outperform IDW and OK.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
rgokrgidwpred1 &lt;- rgokrgidwpred(petrel[, c(1,2)], petrel[, c(1,2, 6:9)],
petrel[, 3], petrel.grid[, c(1,2)], petrel.grid, num.trees = 500, idp = 2,
nmaxok = 12, nmaxidw = 12)
names(rgokrgidwpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rgpred'>Generate spatial predictions using random forest in ranger (RG)</h2><span id='topic+rgpred'></span>

<h3>Description</h3>

<p>This function is to make spatial predictions using random forest
in ranger.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgpred(
  trainx,
  trainy,
  longlatpredx,
  predx,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  num.trees = 500,
  min.node.size = NULL,
  type = "response",
  num.threads = NULL,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgpred_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_longlatpredx">longlatpredx</code></td>
<td>
<p>a dataframe contains longitude and latitude of point
locations (i.e., the centres of grids) to be predicted.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_predx">predx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables
for the grids to be predicted.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables to possibly split at in each node. Default is the
(rounded down) square root of the number variables.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. By default, 500 is used.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Default 1 for classification, 5 for regression.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes' with
default 'response'. See ranger::predict.ranger for details.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_num.threads">num.threads</code></td>
<td>
<p>number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.Default is FALSE.</p>
</td></tr>
<tr><td><code id="rgpred_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of longitude, latitude and predictions.
</p>


<h3>Note</h3>

<p>This function is largely based on rfpred.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation
of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17.
http://dx.doi.org/10.18637/jss.v077.i01.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(petrel)
data(petrel.grid)
set.seed(1234)
rgpred1 &lt;- rgpred(petrel[, c(1,2, 6:9)], petrel[, 5], petrel.grid[, c(1,2)],
petrel.grid, num.trees = 500)
names(rgpred1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rvi'>Relative variable influence based on generalized boosted regression
modeling (gbm)</h2><span id='topic+rvi'></span>

<h3>Description</h3>

<p>This function is to to derive a relative variable influence based
on generalized boosted regression modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rvi(
  trainx,
  trainy,
  var.monotone = rep(0, ncol(trainx)),
  family = "gaussian",
  n.trees = 3000,
  learning.rate = 0.001,
  interaction.depth = 2,
  bag.fraction = 0.5,
  train.fraction = 1,
  n.minobsinnode = 10,
  cv.fold = 10,
  weights = rep(1, nrow(trainx)),
  keep.data = FALSE,
  verbose = TRUE,
  n.cores = 6,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rvi_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictive variables.</p>
</td></tr>
<tr><td><code id="rvi_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="rvi_+3A_var.monotone">var.monotone</code></td>
<td>
<p>an optional vector, the same length as the number of
predictors, indicating which variables have a monotone increasing (+1),
decreasing (-1), or arbitrary (0) relationship with the outcome. By default,
a vector of 0 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_family">family</code></td>
<td>
<p>either a character string specifying the name of the distribution to
use or a list with a component name specifying the distribution and any
additional parameters needed. See gbm for details. By default, &quot;gaussian&quot; is
used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_n.trees">n.trees</code></td>
<td>
<p>the total number of trees to fit. This is equivalent to the
number of iterations and the number of basis functions in the additive
expansion. By default, 3000 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_learning.rate">learning.rate</code></td>
<td>
<p>a shrinkage parameter applied to each tree in the
expansion. Also known as step-size reduction.</p>
</td></tr>
<tr><td><code id="rvi_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>the maximum depth of variable interactions.
1 implies an additive model, 2 implies a model with up to 2-way
interactions, etc. By default, 2 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_bag.fraction">bag.fraction</code></td>
<td>
<p>the fraction of the training set observations randomly
selected to propose the next tree in the expansion. By default, 0.5 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_train.fraction">train.fraction</code></td>
<td>
<p>The first train.fraction * nrows(data) observations
are used to fit the gbm and the remainder are used for computing
out-of-sample estimates of the loss function.</p>
</td></tr>
<tr><td><code id="rvi_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>minimum number of observations in the trees terminal
nodes. Note that this is the actual number of observations not the total
weight. By default, 10 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of cross-validation folds to perform within
gbm. if &gt; 1, then apply n-fold cross validation; the default is 10, i.e.,
10-fold cross validation that is recommended.</p>
</td></tr>
<tr><td><code id="rvi_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process. Must be positive but do not need to be normalized.
If keep.data = FALSE in the initial call to gbm then it is the user's
responsibility to resupply the weights to gbm.more. By default, a vector of
1 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_keep.data">keep.data</code></td>
<td>
<p>a logical variable indicating whether to keep the data and
an index of the data stored with the object. Keeping the data and index
makes subsequent calls to gbm.more faster at the cost of storing an extra
copy of the dataset. By default, 'FALSE' is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, gbm will print out progress and performance
indicators. By default, 'TRUE' is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_n.cores">n.cores</code></td>
<td>
<p>The number of CPU cores to use. See gbm for details. By
default, 6 is used.</p>
</td></tr>
<tr><td><code id="rvi_+3A_...">...</code></td>
<td>
<p>other arguments passed on to gbm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe of variables (var), and
relative influence (rel.inf) arranged from the most influential to the least influential
</p>


<h3>Note</h3>

<p>This function is largely based on gbm.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Greg Ridgeway with contributions from others (2015). gbm:
Generalized Boosted Regression Models. R package version 2.1.1.
https://CRAN.R-project.org/package=gbm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sponge)
set.seed(1234)
rvi1 &lt;- rvi(sponge[, -c(3)], sponge[, 3], family = "poisson", n.cores=2)
names(rvi1)
# The least influence variable
livar &lt;- as.character(rvi1$gbm.rvi$var[dim(sponge[, -3])[2]])
livar

# The least influence variable to be removed from the training dataset
rmvar &lt;- which(names(sponge[, -c(3)]) == livar)
rmvar

## End(Not run)

</code></pre>

<hr>
<h2 id='sponge'>A dataset of sponge species richness in the Timor Sea region, northern Australia marine margin</h2><span id='topic+sponge'></span>

<h3>Description</h3>

<p>This dataset contains 77 samples of 8 variables including longitude (easting), latitude (northing), sponge, topographic position index (tpi3), variance of backscatter (var7), entropy (entro7), backscatter at incidence angle 11 degree (bs11), and backscatter at incidence angle 34 degree (bs34).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("sponge")</code></pre>


<h3>Format</h3>

<p>A data frame with 77 observations on the following 8 variables.
</p>

<dl>
<dt><code>easting</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>northing</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>sponge</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>tpi3</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>var7</code></dt><dd><p>a numeric vector, dB^2</p>
</dd>
<dt><code>entro7</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>bs11</code></dt><dd><p>a numeric vector, dB</p>
</dd>
<dt><code>bs34</code></dt><dd><p>a numeric vector, dB</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please see the source. This dataset was published as an appendix of the paper listed in the source. Where the long and lat were replaced with easting and northing for prediction purpose.</p>


<h3>Source</h3>

<p>Li, J., B. Alvarez, J. Siwabessy, M. Tran, Z. Huang, R. Przeslawski, L. Radke, F. Howard, and S. Nichol. 2017. Application of random forest, generalised linear model and their hybrid methods with geostatistical techniques to count data: Predicting sponge species richness. Environmental Modelling &amp; Software, 97: 112-129</p>

<hr>
<h2 id='sponge.grid'>A dataset of predictors for generating sponge species richness in a selected region in the Timor Sea region, northern Australia marine margin</h2><span id='topic+sponge.grid'></span>

<h3>Description</h3>

<p>This dataset contains 95530 rows of 7 predictive variables including longitude (easting), latitude (northing), topographic position index (tpi3), variance of backscatter (var7), entropy (entro7), backscatter at incidence angle 11 degree (bs11), and backscatter at incidence angle 34 degree (bs34).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("sponge.grid")</code></pre>


<h3>Format</h3>

<p>A data frame with 95530 rows on the following 7 variables.
</p>

<dl>
<dt><code>easting</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>northing</code></dt><dd><p>a numeric vector, m</p>
</dd>
<dt><code>tpi3</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>var7</code></dt><dd><p>a numeric vector, dB^2</p>
</dd>
<dt><code>entro7</code></dt><dd><p>a numeric vector, no unit</p>
</dd>
<dt><code>bs11</code></dt><dd><p>a numeric vector, dB</p>
</dd>
<dt><code>bs34</code></dt><dd><p>a numeric vector, dB</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please see the source. This dataset was used to produce the figure of predictions in the paper listed in the source.</p>


<h3>Source</h3>

<p>Li, J., B. Alvarez, J. Siwabessy, M. Tran, Z. Huang, R. Przeslawski, L. Radke, F. Howard, and S. Nichol. 2017. Application of random forest, generalised linear model and their hybrid methods with geostatistical techniques to count data: Predicting sponge species richness. Environmental Modelling &amp; Software,97: 112-129.</p>

<hr>
<h2 id='sw'>A dataset of grids for producing spatial predictions of seabed mud content in the southwest Australia Exclusive Economic Zone</h2><span id='topic+sw'></span>

<h3>Description</h3>

<p>This dataset contains 500703 rows of 2 variables including
longitude (long), latitude (lat).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("sw")</code></pre>


<h3>Format</h3>

<p>A data frame with 500703 rows on the following 2 variables.
</p>

<dl>
<dt><code>long</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>lat</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please check the source.</p>


<h3>Source</h3>

<p>Li, J., Potter, A., Huang, Z., Daniell, J.J., Heap, A., 2010. Predicting Seabed Mud Content across the Australian Margin: Comparison of Statistical and Mathematical Techniques Using a Simulation Experiment. Geoscience Australia, 2010/11, 146pp.</p>

<hr>
<h2 id='swmud'>A dataset of seabed mud content in the southwest Australia Exclusive Economic Zone</h2><span id='topic+swmud'></span>

<h3>Description</h3>

<p>This dataset contains 177 samples of 3 variables including
longitude (long), latitude (lat), mud content (mud).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("swmud")</code></pre>


<h3>Format</h3>

<p>A data frame with 177 observations on the following 3 variables.
</p>

<dl>
<dt><code>long</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>lat</code></dt><dd><p>a numeric vector, decimal degree</p>
</dd>
<dt><code>mud</code></dt><dd><p>a numeric vector, percentage</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details, please check the source.</p>


<h3>Source</h3>

<p>Li, J., Potter, A., Huang, Z., Daniell, J.J., Heap, A., 2010. Predicting Seabed Mud Content across the Australian Margin: Comparison of Statistical and Mathematical Techniques Using a Simulation Experiment. Geoscience Australia, 2010/11, 146pp.</p>

<hr>
<h2 id='tovecv'>Convert error measures to vecv</h2><span id='topic+tovecv'></span>

<h3>Description</h3>

<p>tovecv can be used to convert existing predictive error measures to vecv.
For the definition of vecv, please see function vecv in library (spm). The error measures considered are
mean square error (mse), root mse (rmse), relative rmse (rrmse), standardised rmse (srmse) and
mean square reduced error (msre).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tovecv(n, mu, s, m, measure = c("mse", "rmse", "rrmse", "srmse", "msre"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tovecv_+3A_n">n</code></td>
<td>
<p>sample number of validation samples.</p>
</td></tr>
<tr><td><code id="tovecv_+3A_mu">mu</code></td>
<td>
<p>mean of validation samples.</p>
</td></tr>
<tr><td><code id="tovecv_+3A_s">s</code></td>
<td>
<p>standard deviation of validation samples.</p>
</td></tr>
<tr><td><code id="tovecv_+3A_m">m</code></td>
<td>
<p>value of an error measure.</p>
</td></tr>
<tr><td><code id="tovecv_+3A_measure">measure</code></td>
<td>
<p>a type of error measure (i.e. &quot;mse&quot;, &quot;rmse&quot;, &quot;rrmse&quot;, &quot;srmse&quot; or &quot;msre&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric number.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., 2016. Assessing spatial predictive models in the environmental sciences: accuracy.
measures, data variation and variance explained. Environmental Modelling &amp; Software 80 1-8.
</p>
<p>Li, J., 2017. Assessing the accuracy of predictive models for numerical data: Not r nor r2, why not?
Then what? PLOS ONE 12 (8): e0183250.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 300
mu &lt;- 15.5
sd &lt;- 8.80
mse &lt;- 50.43
rmse &lt;- sqrt(mse)
rrmse &lt;- rmse / mu * 100
srmse &lt;- rmse / sd
msre &lt;- mse / sd ^ 2
tovecv(n=n, mu=mu, s=sd, m=mse, measure="mse")

tovecv(n=n, mu=mu, s=sd, m=rmse, measure="rmse")

tovecv(n=n, mu=mu, s=sd, m=rrmse, measure="rrmse")

tovecv(n=n, mu=mu, s=sd, m=srmse, measure="srmse")

tovecv(n=n, mu=mu, s=sd, m=msre, measure="msre")

</code></pre>

<hr>
<h2 id='vecv'>Variance explained by predictive models based on cross-validation</h2><span id='topic+vecv'></span>

<h3>Description</h3>

<p>vecv is used to calculate the variance explained by predictive
models based on cross-validation. The vecv is based on the differences between
the predicted values for, and the observed values of, validation samples
for cross-validation. It measures the proportion of variation in the
validation data explained by the predicted values obtained from predictive
models based on cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vecv(obs, pred)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vecv_+3A_obs">obs</code></td>
<td>
<p>observation values of validation samples.</p>
</td></tr>
<tr><td><code id="vecv_+3A_pred">pred</code></td>
<td>
<p>prediction values of predictive models for validation samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric number.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., 2016. Assessing spatial predictive models in the environmental sciences: accuracy.
measures, data variation and variance explained. Environmental Modelling &amp; Software 80 1-8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
x &lt;- sample(1:30, 30)
e &lt;- rnorm(30, 1)
y &lt;- x + e
vecv(x, y)

y &lt;- 0.8 * x + e
vecv(x, y)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
