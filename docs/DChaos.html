<!DOCTYPE html><html><head><title>Help for package DChaos</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DChaos}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#embedding'><p>Provides the delayed-coordinate embedding vectors backwards</p></a></li>
<li><a href='#gauss.sim'><p>Simulates time-series data from the Gauss map</p></a></li>
<li><a href='#henon.sim'><p>Simulates time-series data from the Henon map</p></a></li>
<li><a href='#jacobian.net'><p>Computes the partial derivatives from the best-fitted neural net model</p></a></li>
<li><a href='#logistic.sim'><p>Simulates time-series data from the Logistic map</p></a></li>
<li><a href='#lyapunov'><p>Estimates the Lyapunov exponent through several methods</p></a></li>
<li><a href='#lyapunov.max'><p>Estimates the largest Lyapunov exponent</p></a></li>
<li><a href='#lyapunov.spec'><p>Estimates the Lyapunov exponent spectrum</p></a></li>
<li><a href='#netfit'><p>Fits any standard feedforward neural net model from time-series data</p></a></li>
<li><a href='#rossler.sim'><p>Simulates time-series data from the Rossler system</p></a></li>
<li><a href='#summary.lyapunov'><p>Summary method for a lyapunov object</p></a></li>
<li><a href='#w0.net'><p>Estimates the initial parameter vector of the neural net model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-29</td>
</tr>
<tr>
<td>Title:</td>
<td>Chaotic Time Series Analysis</td>
</tr>
<tr>
<td>Author:</td>
<td>Julio E. Sandubete [aut, cre],
  Lorenzo Escot [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Julio E. Sandubete &lt;jsandube@ucm.es&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>xts, zoo, nnet, pracma, sandwich</td>
</tr>
<tr>
<td>Description:</td>
<td>Chaos theory has been hailed as a revolution of thoughts and attracting ever increasing 
    attention of many scientists from diverse disciplines. Chaotic systems are nonlinear deterministic 
    dynamic systems which can behave like an erratic and apparently random motion. A relevant field
    inside chaos theory and nonlinear time series analysis is the detection of a chaotic behaviour 
    from empirical time series data. One of the main features of chaos is the well known initial value 
    sensitivity property. Methods and techniques related to test the hypothesis of chaos try to quantify 
    the initial value sensitive property estimating the Lyapunov exponents. The DChaos package 
    provides different useful tools and efficient algorithms which test robustly the hypothesis of chaos 
    based on the Lyapunov exponent in order to know if the data generating process behind time series 
    behave chaotically or not.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-29 15:07:29 UTC; julioemilio</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-29 16:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='embedding'>Provides the delayed-coordinate embedding vectors backwards</h2><span id='topic+embedding'></span>

<h3>Description</h3>

<p>This function generates both the uniform and non-uniform embedding vectors backwards using the method of delays from univariate time-series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embedding(x, m = 2, lag = 1, timelapse = c("FIXED", "VARIABLE"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="embedding_+3A_x">x</code></td>
<td>
<p>a <code>vector</code>, a time-series object <code>ts</code> or <code>xts</code>, a <code>data.frame</code>, a <code>data.table</code> or a <code>matrix</code> depending on the method selected in <code>timelapse</code>.</p>
</td></tr>
<tr><td><code id="embedding_+3A_m">m</code></td>
<td>
<p>a non-negative integer denoting the embedding dimension (Default 2).</p>
</td></tr>
<tr><td><code id="embedding_+3A_lag">lag</code></td>
<td>
<p>a non-negative integer denoting the reconstruction delay (Default 1).</p>
</td></tr>
<tr><td><code id="embedding_+3A_timelapse">timelapse</code></td>
<td>
<p>a character denoting if the time-series data are sampled at uniform time-frequency e.g., 1-month, 1-day, 1-hour, 30-min, 5-min, 1-min and so on <code>FIXED</code> or non-uniform time-frequency which are not equally spaced in time <code>VARIABLE</code> (Default <code>FIXED</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The uniform or non-uniform delayed-coordinate embedding vectors backwards by columns from an univariate time-series data considering the parameter set selected by the user. If <code>FIXED</code> has been selected <code>data</code> must be a <code>vector</code> or a time-series object <code>ts</code> or <code>xts</code>. Otherwise <code>VARIABLE</code> has to be specified. In this case <code>data</code> must be a <code>data.frame</code>, a <code>data.table</code> or a <code>matrix</code> with two columns, the date and the univariate time series as a sequence of numerical values, in that order. The date can have the following three classes: <code>POSIXt</code>, <code>Date</code> or <code>Factor</code>. In the latter case the date should come in the following format <code>YMD H:M:OS3</code> considering milliseconds e.g., 20190407 00:00:03.347. If you don't consider milliseconds you must put .000 after the seconds.
</p>


<h3>Note</h3>

<p>Note that a key point to create a suitable reconstruction of the state-space is to fix a criteria in order to estimate the embedding parameters. Researchers usually estimate them using heuristic approaches based on prescriptions proposed by e.g., H.D. Abarbanel (1996) or H. Kantz and T. Schreiber (2004). The main drawbacks of these heuristic approaches are the following: they are not intrinsically statistical; their results are not robust; they lead to estimators whose properties are unknown or largely unexplored; they do not take into account the results of any model fit. The alternative proposed by the statistical approach solves those disadvantages. The statistical approach to state-space reconstruction can be viewed as a best subset selection problem within the nonparametric regression context as argued K.-S. Chan and H. Tong (2001). The DChaos package allows the R users to choose between both methods. By default it uses the statistical approach based on model selection procedures instead of heuristic techniques, see <code>netfit</code> function.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ruelle, D., Takens, F. 1971 On the nature of turbulence. Communications in Mathematical Physics 20(3):167-192.
</p>
<p>Takens, F. 1981 Detecting strange attractors in turbulence. Springer Berlin Heidelberg.
</p>
<p>Abarbanel, H.D. 1996 Analysis of observed chaotic data. Springer.
</p>
<p>Cha, K.-S., Tong, H. 2001 Chaos: a statistical perspective. Springer-Verlag.
</p>
<p>Kantz, H., Schreiber, T. 2004 Nonlinear time series analysis, volume 7. Cambridge university press.
</p>
<p>Huke, J.P., Broomhead, D.S. 2007 Embedding theorems for non-uniformly sampled dynamical systems. Nonlinearity 20(9):205-244.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Provides the uniform delayed-coordinate embedding vectors (Backward)
## data      &lt;- DChaos::embedding(ts, m=5, lag=2, timelapse="FIXED")
## show(head(data, 5))

## Simulates tick-by-tick data (bid price) for Starbucks company
## ts        &lt;- highfrequency::sbux
## show(head(ts, 5))

## Provides the non-uniform delayed-coordinate embedding vectors (Backward)
## data      &lt;- DChaos::embedding(ts, m=3, lag=4, timelapse="VARIABLE")
## show(head(data, 5))
</code></pre>

<hr>
<h2 id='gauss.sim'>Simulates time-series data from the Gauss map</h2><span id='topic+gauss.sim'></span>

<h3>Description</h3>

<p>This function simulates time-series data from the Gauss map considering the parameter set selected by the user. The initial condition is a random number between 0 and 1. Some initial conditions may lead to an unstable system that will tend to infinity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss.sim(
  alpha = 6.2,
  beta = -0.5,
  s = 0,
  x0 = runif(1, 0, 1),
  n = 1000,
  n.start = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gauss.sim_+3A_alpha">alpha</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>alpha</code> (Default 6.2).</p>
</td></tr>
<tr><td><code id="gauss.sim_+3A_beta">beta</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>beta</code> (Default -0.5).</p>
</td></tr>
<tr><td><code id="gauss.sim_+3A_s">s</code></td>
<td>
<p>a non-negative integer denoting the variance value of the error term. If <code class="reqn">s=0</code> gives the standard deterministic map (Default 0).</p>
</td></tr>
<tr><td><code id="gauss.sim_+3A_x0">x0</code></td>
<td>
<p>a non-negative integer denoting the initial condition (Default random number between 0 and 1).</p>
</td></tr>
<tr><td><code id="gauss.sim_+3A_n">n</code></td>
<td>
<p>a non-negative integer denoting the length (Default 1000).</p>
</td></tr>
<tr><td><code id="gauss.sim_+3A_n.start">n.start</code></td>
<td>
<p>a non-negative integer denoting the number of observations that will be discarded to ensure that the values are in the attractor (Default 50).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time-series data object generated from the Gauss map with or without an additive measurement noise term. This dataset could be useful for researchers interested in the field of chaotic dynamic systems and non-linear time series analysis and professors (and students) who teach (learn) courses related to those topics.
</p>


<h3>Note</h3>

<p>This function provides also noisy time-series data from the deterministic gauss map adding an additive measurement noise term if <code class="reqn">s&gt;0</code>. We have added to each time-series data a normal multinomial error term denoted by <code class="reqn">{\varepsilon _t} \sim N\left( {0,s} \right)</code> with different variance values (<code class="reqn">s</code>). In this sense we have considered it appropriate to add a measurement noise term because most real-world observed time-series data are usually noise-contaminated signals, characterised by an erratic and persistent volatility in certain periods and there is almost always a source of noise linked to measurement errors in real-world datasets.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Hilborn, R.C. 2004 Chaos and nonlinear dynamics: an introduction for scientists and engineers. Oxford, Univ. Press, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the deterministic gauss map
## with a chaotic behaviour.
## ts &lt;- gauss.sim(alpha=6.2, beta=-0.5, s=0, n=1000)
##
## Simulates time-series data from the deterministic gauss map
## with a non-chaotic behaviour.
## ts &lt;- gauss.sim(alpha=4.9, beta=-0.58, s=0, n=1000)
</code></pre>

<hr>
<h2 id='henon.sim'>Simulates time-series data from the Henon map</h2><span id='topic+henon.sim'></span>

<h3>Description</h3>

<p>This function simulates time-series data from the Henon map considering the parameter set selected by the user. The initial condition is a random number between -0.5 and 0.5. Some initial conditions may lead to an unstable system that will tend to infinity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>henon.sim(
  a = 1.4,
  b = 0.3,
  s = 0,
  x0 = runif(1, -0.5, 0.5),
  y0 = runif(1, -0.5, 0.5),
  n = 1000,
  n.start = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="henon.sim_+3A_a">a</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>a</code> (Default 1.4).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_b">b</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>b</code> (Default 0.3).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_s">s</code></td>
<td>
<p>a non-negative integer denoting the variance value of the error term. If <code class="reqn">s=0</code> gives the standard deterministic map (Default 0).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_x0">x0</code></td>
<td>
<p>a non-negative integer denoting the initial condition of x-coordinate (Default random number between -0.5 and 0.5).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_y0">y0</code></td>
<td>
<p>a non-negative integer denoting the initial condition of y-coordinate (Default random number between -0.5 and 0.5).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_n">n</code></td>
<td>
<p>a non-negative integer denoting the length (Default 1000).</p>
</td></tr>
<tr><td><code id="henon.sim_+3A_n.start">n.start</code></td>
<td>
<p>a non-negative integer denoting the number of observations that will be discarded to ensure that the values are in the attractor (Default 50).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time-series data object generated from the Henon map with or without an additive measurement noise term. This dataset could be useful for researchers interested in the field of chaotic dynamic systems and non-linear time series analysis and professors (and students) who teach (learn) courses related to those topics.
</p>


<h3>Note</h3>

<p>This function provides also noisy time-series data from the deterministic henon map adding an additive measurement noise term if <code class="reqn">s&gt;0</code>. We have added to each time-series data a normal multinomial error term denoted by <code class="reqn">{\varepsilon _t} \sim N\left( {0,s} \right)</code> with different variance values (<code class="reqn">s</code>). In this sense we have considered it appropriate to add a measurement noise term because most real-world observed time-series data are usually noise-contaminated signals, characterised by an erratic and persistent volatility in certain periods and there is almost always a source of noise linked to measurement errors in real-world datasets.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Hénon, M. 1976 A two-dimensional mapping with a strange attractor. Communications in Mathematical Physics 50(1):69-77.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the deterministic henon map
## with a chaotic behaviour.
ts &lt;- henon.sim(a=1.4, b=0.3, s=0, n=1000)
##
## Simulates time-series data from the deterministic henon map
## with a non-chaotic behaviour.
ts &lt;- henon.sim(a=1.2, b=0.1, s=0, n=1000)
</code></pre>

<hr>
<h2 id='jacobian.net'>Computes the partial derivatives from the best-fitted neural net model</h2><span id='topic+jacobian.net'></span>

<h3>Description</h3>

<p>This function computes analytically the partial derivatives from the best-fitted neural net model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jacobian.net(
  model,
  data,
  m = 1:4,
  lag = 1:1,
  timelapse = c("FIXED", "VARIABLE"),
  h = 2:10,
  w0maxit = 100,
  wtsmaxit = 1e+06,
  pre.white = TRUE,
  trace = 1,
  seed.t = TRUE,
  seed = 56666459
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jacobian.net_+3A_model">model</code></td>
<td>
<p>a neural network model fitted using the <code>netfit</code> function.</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_data">data</code></td>
<td>
<p>a <code>vector</code>, a time-series object <code>ts</code> or <code>xts</code>, a <code>data.frame</code>, a <code>data.table</code> or a <code>matrix</code> depending on the method selected in <code>timelapse</code>.</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_m">m</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the embedding dimension (Default 1:4).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_lag">lag</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the the reconstruction delay (Default 1:1).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_timelapse">timelapse</code></td>
<td>
<p>a character denoting if the time-series data are sampled at uniform time-frequency e.g., 1-month, 1-day, 1-hour, 30-min, 5-min, 1-min and so on <code>FIXED</code> or non-uniform time-frequency which are not equally spaced in time <code>VARIABLE</code> (Default <code>FIXED</code>).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_h">h</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the number of neurones (or nodes) in the single hidden layer (Default 2:10).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_w0maxit">w0maxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the initial parameter vector of the neural net models (Default 100).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_wtsmaxit">wtsmaxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the weights parameter vector of the neural net models (Default 1e6).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_pre.white">pre.white</code></td>
<td>
<p>a logical value denoting if the user wants to use as points to evaluate the partial derivatives the delayed vectors filtered by the neural net model chosen <code>TRUE</code> or not <code>FALSE</code> (Default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_trace">trace</code></td>
<td>
<p>a binary value denoting if the user wants to print the output on the console <code>1</code> or not <code>0</code> (Default 1).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_seed.t">seed.t</code></td>
<td>
<p>a logical value denoting if the user wants to fix the seed <code>TRUE</code> or not <code>FALSE</code> (Default TRUE).</p>
</td></tr>
<tr><td><code id="jacobian.net_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer denoting the value of the seed selected if <code>seed.t = TRUE</code> (Default 56666459).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns several objects considering the parameter set selected by the user. Partial derivatives are calculated analytically from the best-fitted neural net model. It also contains some useful information about the best-fitted feed-forward single hidden layer neural net model saved, the best set of weights found, the fitted values, the residuals obtained or the best embedding parameters set chosen. This function allows the R user uses the data previously obtained from the best-fitted neural network estimated by the <code>netfit</code> function if <code>model</code> is not empty. Otherwise <code>data</code> has to be specified.
</p>


<h3>Note</h3>

<p>The main reason for using neural network models is not to look for the best predictive model but to estimate a model that captures the non-linear time dependence well enough and, additionally, allows us to obtain in an analytical way (instead of numerical) the jacobian functional of the unknown underlying generator system. The estimation of this jacobian or partial derivatives will later allow us to contrast our hypothesis of chaos estimating the Lyapunov exponents.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Eckmann, J.P., Ruelle, D. 1985 Ergodic theory of chaos and strange attractors. Rev Mod Phys 57:617–656.
</p>
<p>Gencay, R., Dechert, W.D. 1992 An algorithm for the n lyapunov exponents of an n-dimensional unknown dynamical system. Physica D 59(1):142–157.
</p>
<p>Shintani, M., Linton, O. 2004 Nonparametric neural network estimation of Lyapunov exponents and a direct test for chaos. Journal of Econometrics 120(1):1-33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Computes analytically the partial derivatives from the best-fitted neural net model
## showed in the netfit example
## model    &lt;- DChaos::netfit(ts, m=1:4, lag=1:3, timelapse="FIXED", h=2:10)
## jacobian &lt;- DChaos::jacobian.net(model=model)
## summary(jacobian)

## Partial derivatives are calculated analytically without setting previously any neural net model
## jacobian &lt;- DChaos::jacobian.net(data=ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10)
## summary(jacobian)
</code></pre>

<hr>
<h2 id='logistic.sim'>Simulates time-series data from the Logistic map</h2><span id='topic+logistic.sim'></span>

<h3>Description</h3>

<p>This function simulates time-series data from the Logistic map considering the parameter set selected by the user. The initial condition is a random number between 0 and 1. Some initial conditions may lead to an unstable system that will tend to infinity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic.sim(a = 4, s = 0, x0 = runif(1, 0, 1), n = 1000, n.start = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistic.sim_+3A_a">a</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>a</code> (Default 4).</p>
</td></tr>
<tr><td><code id="logistic.sim_+3A_s">s</code></td>
<td>
<p>a non-negative integer denoting the variance value of the error term. If <code class="reqn">s=0</code> gives the standard deterministic map (Default 0).</p>
</td></tr>
<tr><td><code id="logistic.sim_+3A_x0">x0</code></td>
<td>
<p>a non-negative integer denoting the initial condition (Default random number between 0 and 1).</p>
</td></tr>
<tr><td><code id="logistic.sim_+3A_n">n</code></td>
<td>
<p>a non-negative integer denoting the length (Default 1000).</p>
</td></tr>
<tr><td><code id="logistic.sim_+3A_n.start">n.start</code></td>
<td>
<p>a non-negative integer denoting the number of observations that will be discarded to ensure that the values are in the attractor (Default 50).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time-series data object generated from the Logistic map with or without an additive measurement noise term. This dataset could be useful for researchers interested in the field of chaotic dynamic systems and non-linear time series analysis and professors (and students) who teach (learn) courses related to those topics.
</p>


<h3>Note</h3>

<p>This function provides also noisy time-series data from the deterministic logistic map adding an additive measurement noise term if <code class="reqn">s&gt;0</code>. We have added to each time-series data a normal multinomial error term denoted by <code class="reqn">{\varepsilon _t} \sim N\left( {0,s} \right)</code> with different variance values (<code class="reqn">s</code>). In this sense we have considered it appropriate to add a measurement noise term because most real-world observed time-series data are usually noise-contaminated signals, characterised by an erratic and persistent volatility in certain periods and there is almost always a source of noise linked to measurement errors in real-world datasets.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>May, R.M. 1976 Simple mathematical models with very complicated dynamics. Nature (261):459-467.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the deterministic logistic map
## with a chaotic behaviour.
## ts &lt;- logistic.sim(a=4, s=0, n=1000)
##
## Simulates time-series data from the deterministic logistic map
## with a non-chaotic behaviour.
## ts &lt;- logistic.sim(a=3.2, s=0, n=1000)
</code></pre>

<hr>
<h2 id='lyapunov'>Estimates the Lyapunov exponent through several methods</h2><span id='topic+lyapunov'></span>

<h3>Description</h3>

<p>This is an all-in-one function. It provides, at the same time, the delayed-coordinate embedding vector (<code>embedding</code>), estimates the best neural net model (<code>netfit</code>), calculates the partial derivatives directly from the chosen neural network model (<code>javcobian.net</code>). Finally, this function estimates both the largest Lyapunov exponent through the Norma-2 procedure (<code>lyapunov.max</code>) and the Lyapunov exponent spectrum through the QR decomposition procedure (<code>lyapunov.spec</code>) taking into account the full sample and three different methods of subsampling by blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lyapunov(
  data,
  m = 1:4,
  lag = 1:1,
  timelapse = c("FIXED", "VARIABLE"),
  h = 2:10,
  w0maxit = 100,
  wtsmaxit = 1e+06,
  pre.white = TRUE,
  lyapmethod = c("SLE", "LLE", "ALL"),
  blocking = c("BOOT", "NOVER", "EQS", "FULL", "ALL"),
  B = 1000,
  trace = 1,
  seed.t = TRUE,
  seed = 56666459,
  doplot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lyapunov_+3A_data">data</code></td>
<td>
<p>a <code>vector</code>, a time-series object <code>ts</code> or <code>xts</code>, a <code>data.frame</code>, a <code>data.table</code> or a <code>matrix</code> depending on the method selected in <code>timelapse</code>.</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_m">m</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the embedding dimension (Default 1:4).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_lag">lag</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the the reconstruction delay (Default 1:1).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_timelapse">timelapse</code></td>
<td>
<p>a character denoting if the time-series data are sampled at uniform time-frequency e.g., 1-month, 1-day, 1-hour, 30-min, 5-min, 1-min and so on <code>FIXED</code> or non-uniform time-frequency which are not equally spaced in time <code>VARIABLE</code> (Default <code>FIXED</code>).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_h">h</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the number of neurones (or nodes) in the single hidden layer (Default 2:10).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_w0maxit">w0maxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the initial parameter vector of the neural net models (Default 100).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_wtsmaxit">wtsmaxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the weights parameter vector of the neural net models (Default 1e6).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_pre.white">pre.white</code></td>
<td>
<p>a logical value denoting if the user wants to use as points to evaluate the partial derivatives the delayed vectors filtered by the neural net model chosen <code>TRUE</code> or not <code>FALSE</code> (Default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_lyapmethod">lyapmethod</code></td>
<td>
<p>a character denoting the procedure chosen to estimate the Lyapunov exponent. If <code>LLE</code> has been selected the function will estimate only the largest Lyapunov exponent through the Norma-2 method. If <code>SLE</code> has been selected the function will estimate the Lyapunov exponent spectrum through the QR decomposition. Otherwise <code>ALL</code> has to be specified. In this case the function will estimate the Lyapunov exponent considering both procedures (Default <code>SLE</code>).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_blocking">blocking</code></td>
<td>
<p>a character denoting the blocking method chosen for figuring out the Lyapunov exponent. Available options are <code>FULL</code> if the user considers the full sample, <code>NOVER</code> if the user considers the non-overlapping sample, <code>EQS</code> if the user considers the equally spaced sample, <code>BOOT</code> if the user considers the bootstrap sample or <code>ALL</code> if the user considers all of them (Default <code>BOOT</code>).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_b">B</code></td>
<td>
<p>a non-negative integer denoting the number of bootstrap iterations (Default 1000).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_trace">trace</code></td>
<td>
<p>a binary value denoting if the user wants to print the output on the console <code>1</code> or not <code>0</code> (Default 1).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_seed.t">seed.t</code></td>
<td>
<p>a logical value denoting if the user wants to fix the seed <code>TRUE</code> or not <code>FALSE</code> (Default TRUE).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer denoting the value of the seed selected if <code>seed.t = TRUE</code> (Default 56666459).</p>
</td></tr>
<tr><td><code id="lyapunov_+3A_doplot">doplot</code></td>
<td>
<p>a logical value denoting if the user wants to draw a plot <code>TRUE</code> or not <code>FALSE</code>. If it is <code>TRUE</code> the evolution of the Lyapunov exponent values are represented for the whole period considering the blocking method chosen by the user. It shows as many graphs as embedding dimensions have been considered (Default <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns several objects considering the parameter set selected by the user. The largest Lyapunov exponent (Norma-2 procedure) and the Lyapunov exponent spectrum (QR decomposition procedure) by each blocking method are estimated. It also contains some useful information about the estimated jacobian, the best-fitted feed-forward single hidden layer neural net model, the best set of weights found, the fitted values, the residuals obtained, the best embedding parameters set chosen, the sample size or the block length considered by each blocking method. This function provides the standard error, the z test value and the p-value for testing the null hypothesis <code class="reqn">H0: \lambda_k &gt; 0 for k = 1,2,3, \ldots, m</code>. Reject the null hypothesis $H_0$ means lack of chaotic behaviour. That is, the data-generating process does not have a chaotic attractor because of it does not show the property of sensitivity to initial conditions.
</p>


<h3>Note</h3>

<p>We have considered it appropriate to incorporate a function that unifies the whole process to make it easier and more intuitive for the R users. The DChaos package provides several ways to figure out robustly the neural net estimator of the k-th Lyapunov exponent. Particularly, there are 8 functions (one for each procedure and blocking method) which estimate the Lyapunov exponents consistently. Hence the DChaos package allows the R users to choose between two different procedures to obtain the neural net estimator of the k-th Lyapunov exponent and four ways of subsampling by blocks: full sample, non-overlapping sample, equally spaced sample and bootstrap sample. The blocking methods what they do is to split the time-series data into several blocks by estimating a Lyapunov exponent for each subsample. If the R users choose the non-overlapping sample (<code>blocking = "NOVER"</code>), the equally spaced sample (<code>blocking = "EQS"</code>) or the bootstrap sample (<code>blocking = "BOOT"</code>) the mean and median values of the Lyapunov exponent for each block or subsample are saved. By default we recommend using the median value as it is more robust to the presence of outliers. Notice that the parameter <code>B</code> will only be considered if the R users choose the bootstrap blocking method.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ellner, S., Gallant, A., McCaffrey, D., Nychka, D. 1991 Convergence rates and data requirements for jacobian-based estimates of lyapunov exponents from data. Physics Letters A 153(6):357-363.
</p>
<p>McCaffrey, D.F., Ellner, S., Gallant, A.R., Nychka, D.W. 1992 Estimating the lyapunov exponent of a chaotic system with nonparametric regression. Journal of the American Statistical Association 87(419):682-695.
</p>
<p>Nychka, D., Ellner, S., Gallant, A.R., McCaffrey, D. 1992 Finding chaos in noisy systems. Journal of the Royal Statistical Society 54(2):399-426.
</p>
<p>Whang, Y.J., Linton, O. 1999 The asymptotic distribution of nonparametric estimates of the lyapunov exponent for stochastic time series. Journal of Econometrics 91(1):1-42.
</p>
<p>Shintani, M., Linton, O. 2004 Nonparametric neural network estimation of Lyapunov exponents and a direct test for chaos. Journal of Econometrics 120(1):1-33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lyapunov.max">lyapunov.max</a></code>, <code><a href="#topic+lyapunov.spec">lyapunov.spec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Provides the Lyapunov exponent spectrum by the QR decomposition procedure considering the
## bootstrap blocking method directly from the Logistic map with chaos simulated.
## exponent &lt;- DChaos::lyapunov(ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10, w0maxit=100,
##                     wtsmaxit=1e6, pre.white=TRUE, lyapmethod="SLE", blocking="ALL",
##                     B=100, trace=1, seed.t=TRUE, seed=56666459, doplot=FALSE))
## summmary(exponent)
</code></pre>

<hr>
<h2 id='lyapunov.max'>Estimates the largest Lyapunov exponent</h2><span id='topic+lyapunov.max'></span>

<h3>Description</h3>

<p>This function estimates the largest Lyapunov exponent through the Norma-2 procedure based on the partial derivatives computed by the <code>jacobian.net</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lyapunov.max(
  data,
  blocking = c("BOOT", "NOVER", "EQS", "FULL"),
  B = 1000,
  doplot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lyapunov.max_+3A_data">data</code></td>
<td>
<p>should be a <code>jacobian</code> object containing the partial derivatives computed by the <code>jacobian.net</code> function.</p>
</td></tr>
<tr><td><code id="lyapunov.max_+3A_blocking">blocking</code></td>
<td>
<p>a character denoting the blocking method chosen for figuring out the largest Lyapunov exponent through the Norma-2 procedure. Available options are <code>FULL</code> if the user considers the full sample, <code>NOVER</code> if the user considers the non-overlapping sample, <code>EQS</code> if the user considers the equally spaced sample or <code>BOOT</code> if the user considers the bootstrap sample (Default <code>BOOT</code>).</p>
</td></tr>
<tr><td><code id="lyapunov.max_+3A_b">B</code></td>
<td>
<p>a non-negative integer denoting the number of bootstrap iterations (Default 1000).</p>
</td></tr>
<tr><td><code id="lyapunov.max_+3A_doplot">doplot</code></td>
<td>
<p>a logical value denoting if the user wants to draw a plot <code>TRUE</code> or not <code>FALSE</code>. If it is <code>TRUE</code> the evolution of the Lyapunov exponent values are represented for the whole period considering the blocking method chosen by the user. It shows as many graphs as embedding dimensions have been considered (Default <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns several objects considering the parameter set selected by the user. The largest Lyapunov exponent considering the Norma-2 procedure by each blocking method are estimated. It also contains some useful information about the estimated jacobian, the best-fitted feed-forward single hidden layer neural net model, the best set of weights found, the fitted values, the residuals obtained, the best embedding parameters set chosen, the sample size or the block length considered by each blocking method. This function provides the standard error, the z test value and the p-value for testing the null hypothesis <code class="reqn">H0: \lambda_k &gt; 0 for k = 1</code> (largest). Reject the null hypothesis $H_0$ means lack of chaotic behaviour. That is, the data-generating process does not have a chaotic attractor because of it does not show the property of sensitivity to initial conditions.
</p>


<h3>Note</h3>

<p>The DChaos package provides several ways to figure out robustly the neural net estimator of the k-th Lyapunov exponent. On the one hand if the R users have previously obtained the partial derivatives from the <code>jacobian.net</code> function they can apply directly the function <code>lyapunov.spec</code> which estimates the Lyapunov exponent spectrum taking into account the QR decomposition procedure. They can also use the function <code>lyapunov.max</code> which estimates only the largest Lyapunov exponent considering the Norma-2 procedure. Hence the DChaos package allows the R users to choose between two different procedures to obtain the neural net estimator of the k-th Lyapunov exponent and four ways of subsampling by blocks: full sample, non-overlapping sample, equally spaced sample and bootstrap sample. The blocking methods what they do is to split the time-series data into several blocks by estimating a Lyapunov exponent for each subsample. If the R users choose the non-overlapping sample (<code>blocking = "NOVER"</code>), the equally spaced sample (<code>blocking = "EQS"</code>) or the bootstrap sample (<code>blocking = "BOOT"</code>) the mean and median values of the Lyapunov exponent for each block or subsample are saved. By default we recommend using the median value as it is more robust to the presence of outliers. Notice that the parameter <code>B</code> will only be considered if the R users choose the bootstrap blocking method.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ellner, S., Gallant, A., McCaffrey, D., Nychka, D. 1991 Convergence rates and data requirements for jacobian-based estimates of lyapunov exponents from data. Physics Letters A 153(6):357-363.
</p>
<p>McCaffrey, D.F., Ellner, S., Gallant, A.R., Nychka, D.W. 1992 Estimating the lyapunov exponent of a chaotic system with nonparametric regression. Journal of the American Statistical Association 87(419):682-695.
</p>
<p>Nychka, D., Ellner, S., Gallant, A.R., McCaffrey, D. 1992 Finding chaos in noisy systems. Journal of the Royal Statistical Society 54(2):399-426.
</p>
<p>Whang, Y.J., Linton, O. 1999 The asymptotic distribution of nonparametric estimates of the lyapunov exponent for stochastic time series. Journal of Econometrics 91(1):1-42.
</p>
<p>Shintani, M., Linton, O. 2004 Nonparametric neural network estimation of Lyapunov exponents and a direct test for chaos. Journal of Econometrics 120(1):1-33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Provides the largest Lyapunov exponent by the Norma-2 procedure considering the
## bootstrap blocking method from the best-fitted neural net model and the partial
## derivatives showed in the jacobian.net example.
## jacobian &lt;- DChaos::jacobian.net(data=ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10)
## summary(jacobian)
## exponent &lt;- DChaos::lyapunov.max(data=jacobian, blocking="BOOT", B=100, doplot=FALSE)
## summary(exponent)
</code></pre>

<hr>
<h2 id='lyapunov.spec'>Estimates the Lyapunov exponent spectrum</h2><span id='topic+lyapunov.spec'></span>

<h3>Description</h3>

<p>This function estimates the Lyapunov exponent spectrum through the QR decomposition procedure based on the partial derivatives computed by the <code>jacobian.net</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lyapunov.spec(
  data,
  blocking = c("BOOT", "NOVER", "EQS", "FULL"),
  B = 1000,
  doplot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lyapunov.spec_+3A_data">data</code></td>
<td>
<p>should be a <code>jacobian</code> object containing the partial derivatives computed by the <code>jacobian.net</code> function.</p>
</td></tr>
<tr><td><code id="lyapunov.spec_+3A_blocking">blocking</code></td>
<td>
<p>a character denoting the blocking method chosen for figuring out the Lyapunov exponent spectrum through the QR decomposition procedure. Available options are <code>FULL</code> if the user considers the full sample, <code>NOVER</code> if the user considers the non-overlapping sample, <code>EQS</code> if the user considers the equally spaced sample or <code>BOOT</code> if the user considers the bootstrap sample (Default <code>BOOT</code>).</p>
</td></tr>
<tr><td><code id="lyapunov.spec_+3A_b">B</code></td>
<td>
<p>a non-negative integer denoting the number of bootstrap iterations (Default 1000).</p>
</td></tr>
<tr><td><code id="lyapunov.spec_+3A_doplot">doplot</code></td>
<td>
<p>a logical value denoting if the user wants to draw a plot <code>TRUE</code> or not <code>FALSE</code>. If it is <code>TRUE</code> the evolution of the Lyapunov exponent values are represented for the whole period considering the blocking method chosen by the user. It shows as many graphs as embedding dimensions have been considered (Default <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns several objects considering the parameter set selected by the user. The Lyapunov exponent spectrum considering the QR decomposition procedure by each blocking method are estimated. It also contains some useful information about the estimated jacobian, the best-fitted feed-forward single hidden layer neural net model, the best set of weights found, the fitted values, the residuals obtained, the best embedding parameters set chosen, the sample size or the block length considered by each blocking method. This function provides the standard error, the z test value and the p-value for testing the null hypothesis <code class="reqn">H0: \lambda_k &gt; 0 for k = 1,2,3, \ldots, m</code> (full spectrum). Reject the null hypothesis $H_0$ means lack of chaotic behaviour. That is, the data-generating process does not have a chaotic attractor because of it does not show the property of sensitivity to initial conditions.
</p>


<h3>Note</h3>

<p>The DChaos package provides several ways to figure out robustly the neural net estimator of the k-th Lyapunov exponent. On the one hand if the R users have previously obtained the partial derivatives from the <code>jacobian.net</code> function they can apply directly the function <code>lyapunov.spec</code> which estimates the Lyapunov exponent spectrum taking into account the QR decomposition procedure. They can also use the function <code>lyapunov.max</code> which estimates only the largest Lyapunov exponent considering the Norma-2 procedure. Hence the DChaos package allows the R users to choose between two different procedures to obtain the neural net estimator of the k-th Lyapunov exponent and four ways of subsampling by blocks: full sample, non-overlapping sample, equally spaced sample and bootstrap sample. The blocking methods what they do is to split the time-series data into several blocks by estimating a Lyapunov exponent for each subsample. If the R users choose the non-overlapping sample (<code>blocking = "NOVER"</code>), the equally spaced sample (<code>blocking = "EQS"</code>) or the bootstrap sample (<code>blocking = "BOOT"</code>) the mean and median values of the Lyapunov exponent for each block or subsample are saved. By default we recommend using the median value as it is more robust to the presence of outliers. Notice that the parameter <code>B</code> will only be considered if the R users choose the bootstrap blocking method.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ellner, S., Gallant, A., McCaffrey, D., Nychka, D. 1991 Convergence rates and data requirements for jacobian-based estimates of lyapunov exponents from data. Physics Letters A 153(6):357-363.
</p>
<p>McCaffrey, D.F., Ellner, S., Gallant, A.R., Nychka, D.W. 1992 Estimating the lyapunov exponent of a chaotic system with nonparametric regression. Journal of the American Statistical Association 87(419):682-695.
</p>
<p>Nychka, D., Ellner, S., Gallant, A.R., McCaffrey, D. 1992 Finding chaos in noisy systems. Journal of the Royal Statistical Society 54(2):399-426.
</p>
<p>Whang, Y.J., Linton, O. 1999 The asymptotic distribution of nonparametric estimates of the lyapunov exponent for stochastic time series. Journal of Econometrics 91(1):1-42.
</p>
<p>Shintani, M., Linton, O. 2004 Nonparametric neural network estimation of Lyapunov exponents and a direct test for chaos. Journal of Econometrics 120(1):1-33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Provides the Lyapunov exponent spectrum by the QR decomposition procedure considering the
## bootstrap blocking method from the best-fitted neural net model and the partial
## derivatives showed in the jacobian.net example.
## jacobian &lt;- DChaos::jacobian.net(data=ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10)
## summary(jacobian)
## exponent &lt;- DChaos::lyapunov.spec(data=jacobian, blocking="BOOT", B=100, doplot=FALSE)
## summary(exponent)
</code></pre>

<hr>
<h2 id='netfit'>Fits any standard feedforward neural net model from time-series data</h2><span id='topic+netfit'></span>

<h3>Description</h3>

<p>This function fits any standard feedforward neural net model from time-series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>netfit(
  serie,
  m = 1:4,
  lag = 1:1,
  timelapse = c("FIXED", "VARIABLE"),
  h = 2:10,
  w0maxit = 100,
  wtsmaxit = 1e+06,
  pre.white = TRUE,
  trace = 1,
  seed.t = TRUE,
  seed = 56666459
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="netfit_+3A_serie">serie</code></td>
<td>
<p>a <code>vector</code>, a time-series object <code>ts</code> or <code>xts</code>, a <code>data.frame</code>, a <code>data.table</code> or a <code>matrix</code> depending on the method selected in <code>timelapse</code>.</p>
</td></tr>
<tr><td><code id="netfit_+3A_m">m</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the embedding dimension (Default 1:4).</p>
</td></tr>
<tr><td><code id="netfit_+3A_lag">lag</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the the reconstruction delay (Default 1:1).</p>
</td></tr>
<tr><td><code id="netfit_+3A_timelapse">timelapse</code></td>
<td>
<p>a character denoting if the time-series data are sampled at uniform time-frequency e.g., 1-month, 1-day, 1-hour, 30-min, 5-min, 1-min and so on <code>FIXED</code> or non-uniform time-frequency which are not equally spaced in time <code>VARIABLE</code> (Default <code>FIXED</code>).</p>
</td></tr>
<tr><td><code id="netfit_+3A_h">h</code></td>
<td>
<p>a non-negative integer denoting a lower and upper bound for the number of neurones (or nodes) in the single hidden layer (Default 2:10).</p>
</td></tr>
<tr><td><code id="netfit_+3A_w0maxit">w0maxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the initial parameter vector of the neural net models (Default 100).</p>
</td></tr>
<tr><td><code id="netfit_+3A_wtsmaxit">wtsmaxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the weights parameter vector of the neural net models (Default 1e6).</p>
</td></tr>
<tr><td><code id="netfit_+3A_pre.white">pre.white</code></td>
<td>
<p>a logical value denoting if the user wants to use as points to evaluate the partial derivatives the delayed vectors filtered by the neural net model chosen <code>TRUE</code> or not <code>FALSE</code> (Default <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="netfit_+3A_trace">trace</code></td>
<td>
<p>a binary value denoting if the user wants to print the output on the console <code>1</code> or not <code>0</code> (Default 1).</p>
</td></tr>
<tr><td><code id="netfit_+3A_seed.t">seed.t</code></td>
<td>
<p>a logical value denoting if the user wants to fix the seed <code>TRUE</code> or not <code>FALSE</code> (Default TRUE).</p>
</td></tr>
<tr><td><code id="netfit_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer denoting the value of the seed selected if <code>seed.t = TRUE</code> (Default 56666459).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns several objects considering the parameter set selected by the user. The best-fitted feed-forward single hidden layer neural net model is saved. It also contains some useful information about the best set of weights found, the fitted values, the residuals obtained or the best embedding parameters set chosen. The best 10 models are displayed on the console. The first column is the neural net number, the second column is the embedding dimension, the third column is the lag or reconstruction delay considered, the fourth column is the number of neurones (or nodes) in the single hidden layer and the fifth column is the Bayesian Information Criterion (BIC) value corresponding to that neural net. Notice that the neural net models are sorted from lowest to highest BIC values.
</p>


<h3>Note</h3>

<p>The process of adjustment to a neural net model often suffers from being trapped in local optima and different initialization strategies should be taken into account. For this reason the function <code>w0.net</code> have been implemented. This function estimates previously the initial parameter vector of the neural net model being able to set the maximum number of iterations that the user wants to obtain setting <code>w0maxit</code>. In addition, by default the neural network estimation is initialized with a fixed seed denoted by <code>seed.t=TRUE</code> with a value equal to <code>seed=56666459</code>. The R user can let the seed be fixed either randomly by <code>seed.t=FALSE</code> or even fix other value of the seed to be able to replicate the results obtained.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ripley, B.D. 1996 Pattern Recognition and Neural Networks. Cambridge.
</p>
<p>Venables, W.N., Ripley, B.D. 2002 Modern Applied Statistics with S. Fourth edition. Springer.
</p>
<p>Hornik, K., Stinchcombe, M., White, H. 1989 Multilayer feedforward networks are universal approximators. Neural Networks 2(5):359-366.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Provides the best-fitted neural network models for certain parameter set
## model    &lt;- DChaos::netfit(ts, m=1:4, lag=1:3, timelapse="FIXED", h=2:10)
## summary(model)
</code></pre>

<hr>
<h2 id='rossler.sim'>Simulates time-series data from the Rossler system</h2><span id='topic+rossler.sim'></span>

<h3>Description</h3>

<p>This function simulates time-series data from the Rossler system considering the parameter set selected by the user. The initial condition is a random number from the normal distribution with mean equal to 0 and variance equal to 1. Some initial conditions may lead to an unstable system that will tend to infinity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rossler.sim(
  a = 0.2,
  b = 0.2,
  c = 5.7,
  s = 0,
  x0 = rnorm(1),
  y0 = rnorm(1),
  z0 = rnorm(1),
  time = seq(0, 100, 0.01),
  n.start = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rossler.sim_+3A_a">a</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>a</code> (Default 0.2).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_b">b</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>b</code> (Default 0.2).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_c">c</code></td>
<td>
<p>a non-negative integer denoting the value of parameter <code>c</code> (Default 5.7).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_s">s</code></td>
<td>
<p>a non-negative integer denoting the variance value of the error term. If <code class="reqn">s=0</code> gives the standard deterministic map (Default 0).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_x0">x0</code></td>
<td>
<p>a non-negative integer denoting the initial condition of x-coordinate (Default random number from the normal distribution).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_y0">y0</code></td>
<td>
<p>a non-negative integer denoting the initial condition of y-coordinate (Default random number from the normal distribution).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_z0">z0</code></td>
<td>
<p>a non-negative integer denoting the initial condition of z-coordinate (Default random number from the normal distribution).</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_time">time</code></td>
<td>
<p>a numeric vector denoting the time-lapse and the time-step (Default time-lapse equal to 10000 with a time-step of 0.01 seconds)</p>
</td></tr>
<tr><td><code id="rossler.sim_+3A_n.start">n.start</code></td>
<td>
<p>a non-negative integer denoting the number of observations that will be discarded to ensure that the values are in the attractor (Default 50).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A time-series data object generated from the Rossler system with or without an additive measurement noise term. This dataset could be useful for researchers interested in the field of chaotic dynamic systems and non-linear time series analysis and professors (and students) who teach (learn) courses related to those topics.
</p>


<h3>Note</h3>

<p>This function provides also noisy time-series data from the deterministic rossler system adding an additive measurement noise term if <code class="reqn">s&gt;0</code>. We have added to each time-series data a normal multinomial error term denoted by <code class="reqn">{\varepsilon _t} \sim N\left( {0,s} \right)</code> with different variance values (<code class="reqn">s</code>). In this sense we have considered it appropriate to add a measurement noise term because most real-world observed time-series data are usually noise-contaminated signals, characterised by an erratic and persistent volatility in certain periods and there is almost always a source of noise linked to measurement errors in real-world datasets. It has been implemented the classical Runge–Kutta method (RK4) in order to generate time-series data from continuous-time dynamical system as the Rossler system.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Rössler, O. 1976 An equation for continuous chaos. Physics Letters A 57(5):397-398.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the deterministic rossler system
## with a chaotic behaviour.
ts &lt;- rossler.sim(a=0.2, b=0.2, c=5.7, s=0, time=seq(0,100,0.1))
##
## Simulates time-series data from the deterministic rossler system
## with a non-chaotic behaviour.
ts &lt;- rossler.sim(a=0.1, b=0.1, c=7, s=0, time=seq(0,100,0.1))
</code></pre>

<hr>
<h2 id='summary.lyapunov'>Summary method for a lyapunov object</h2><span id='topic+summary.lyapunov'></span>

<h3>Description</h3>

<p>summary method for class &quot;lyapunov&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lyapunov'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.lyapunov_+3A_object">object</code></td>
<td>
<p>an object of class <code>"lyapunov"</code> provided by <code><a href="#topic+lyapunov.max">lyapunov.max</a></code>, <code><a href="#topic+lyapunov.spec">lyapunov.spec</a></code> or <code><a href="#topic+lyapunov">lyapunov</a></code> functions.</p>
</td></tr>
<tr><td><code id="summary.lyapunov_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function <code>summary.lyapunov</code> computes and returns a list of summary statistics of the results given in a <code>lyapunov</code> object using the components (list elements) from its argument.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set.seed(34)
## Simulates time-series data from the Logistic map with chaos
## ts        &lt;- DChaos::logistic.sim(n=1000, a=4)
## show(head(ts, 5))

## Summary method for a lyapunov object (only 1 method)
## jacobian &lt;- DChaos::jacobian.net(data=ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10)
## exponent &lt;- DChaos::lyapunov.spec(data=jacobian, blocking="BOOT", B=100, doplot=FALSE)
## summary(exponent)

## Summary method for a lyapunov object (&gt; 1 method)
## exponent &lt;- DChaos::lyapunov(ts, m=3:3, lag=1:1, timelapse="FIXED", h=2:10, w0maxit=100,
##                     wtsmaxit=1e6, pre.white=TRUE, lyapmethod="SLE", blocking="ALL",
##                     B=100, trace=1, seed.t=TRUE, seed=56666459, doplot=FALSE))
## summmary(exponent)
</code></pre>

<hr>
<h2 id='w0.net'>Estimates the initial parameter vector of the neural net model</h2><span id='topic+w0.net'></span>

<h3>Description</h3>

<p>This function estimates the initial parameter vector of the neural net model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w0.net(
  x,
  y,
  m = 2,
  h = 2,
  rangx = 1/max(abs(x)),
  w0maxit = 100,
  seed.t = TRUE,
  seed = 56666459
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w0.net_+3A_x">x</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> denoting the explanatory variables.</p>
</td></tr>
<tr><td><code id="w0.net_+3A_y">y</code></td>
<td>
<p>a <code>vector</code>, a <code>matrix</code> or a <code>data.frame</code> denoting the response variable.</p>
</td></tr>
<tr><td><code id="w0.net_+3A_m">m</code></td>
<td>
<p>a non-negative integer denoting the embedding dimension (Default 2).</p>
</td></tr>
<tr><td><code id="w0.net_+3A_h">h</code></td>
<td>
<p>a non-negative integer denoting the number of neurones (or nodes) in the single hidden layer (Default 2).</p>
</td></tr>
<tr><td><code id="w0.net_+3A_rangx">rangx</code></td>
<td>
<p>a non-negative integer denoting the range of the explanatory variables (Default 1/max(abs(x)).</p>
</td></tr>
<tr><td><code id="w0.net_+3A_w0maxit">w0maxit</code></td>
<td>
<p>a non-negative integer denoting the maximum iterations to estimate the initial parameter vector of the neural net models (Default 100).</p>
</td></tr>
<tr><td><code id="w0.net_+3A_seed.t">seed.t</code></td>
<td>
<p>a logical value denoting if the user wants to fix the seed <code>TRUE</code> or not <code>FALSE</code> (Default TRUE).</p>
</td></tr>
<tr><td><code id="w0.net_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer denoting the value of the seed selected if <code>seed.t = TRUE</code> (Default 56666459).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The optimal initial parameter vector of the neural net model considering the argument set selected by the user.
</p>


<h3>Note</h3>

<p>The process of adjustment to a neural network often suffers from being trapped in local optima and different initialization strategies should be taken into account. For this reason the function <code>w0.net</code> have been implemented. This function estimates previously the initial parameter vector of the neural net model being able to set the maximum number of iterations that the user wants to obtain setting <code>w0maxit</code>. In addition, by default the neural network estimation is initialized with a fixed seed denoted by <code>seed.t=TRUE</code> with a value equal to <code>seed=56666459</code>. The R user can let the seed be fixed either randomly by <code>seed.t=FALSE</code> or even fix other value of the seed to be able to replicate the results obtained.
</p>


<h3>Author(s)</h3>

<p>Julio E. Sandubete, Lorenzo Escot
</p>


<h3>References</h3>

<p>Ripley, B.D. 1996 Pattern Recognition and Neural Networks. Cambridge.
</p>
<p>Venables, W.N., Ripley, B.D. 2002 Modern Applied Statistics with S. Fourth edition. Springer.
</p>
<p>Hornik, K., Stinchcombe, M., White, H. 1989 Multilayer feedforward networks are universal approximators. Neural Networks 2(5):359-366.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
