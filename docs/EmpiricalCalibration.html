<!DOCTYPE html><html lang="en"><head><title>Help for package EmpiricalCalibration</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EmpiricalCalibration}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EmpiricalCalibration-package'><p>EmpiricalCalibration: Routines for Performing Empirical Calibration of Observational Study Estimates</p></a></li>
<li><a href='#calibrateConfidenceInterval'><p>Calibrate confidence intervals</p></a></li>
<li><a href='#calibrateLlr'><p>Calibrate the log likelihood ratio</p></a></li>
<li><a href='#calibrateP'><p>Calibrate the p-value</p></a></li>
<li><a href='#caseControl'><p>Odds ratios from a case-control design</p></a></li>
<li><a href='#cohortMethod'><p>Relative risks from a new-user cohort design</p></a></li>
<li><a href='#compareEase'><p>Compare EASE of correlated sets of estimates</p></a></li>
<li><a href='#computeCvBinomial'><p>Compute critical values for Binomial data</p></a></li>
<li><a href='#computeCvPoisson'><p>Compute critical values for Poisson data</p></a></li>
<li><a href='#computeCvPoissonRegression'><p>Compute critical values for Poisson regression data</p></a></li>
<li><a href='#computeExpectedAbsoluteSystematicError'><p>Compute the expected absolute systematic error</p></a></li>
<li><a href='#computeTraditionalCi'><p>Compute the (traditional) confidence interval</p></a></li>
<li><a href='#computeTraditionalP'><p>Compute the (traditional) p-value</p></a></li>
<li><a href='#convertNullToErrorModel'><p>Convert empirical null distribution to systematic error model</p></a></li>
<li><a href='#evaluateCiCalibration'><p>Evaluate confidence interval calibration</p></a></li>
<li><a href='#fitMcmcNull'><p>Fit the null distribution using MCMC</p></a></li>
<li><a href='#fitNull'><p>Fit the null distribution</p></a></li>
<li><a href='#fitNullNonNormalLl'><p>Fit the null distribution using non-normal log-likelihood approximations</p></a></li>
<li><a href='#fitSystematicErrorModel'><p>Fit a systematic error model</p></a></li>
<li><a href='#grahamReplication'><p>Relative risks from an adjusted new-user cohort design</p></a></li>
<li><a href='#plotCalibration'><p>Create a calibration plot</p></a></li>
<li><a href='#plotCalibrationEffect'><p>Plot the effect of the calibration</p></a></li>
<li><a href='#plotCiCalibration'><p>Create a confidence interval calibration plot</p></a></li>
<li><a href='#plotCiCalibrationEffect'><p>Plot the effect of the CI calibration</p></a></li>
<li><a href='#plotCiCoverage'><p>Create a confidence interval coverage plot</p></a></li>
<li><a href='#plotErrorModel'><p>Plot the systematic error model</p></a></li>
<li><a href='#plotExpectedType1Error'><p>Plot the expected type 1 error as a function of standard error</p></a></li>
<li><a href='#plotForest'><p>Create a forest plot</p></a></li>
<li><a href='#plotMcmcTrace'><p>Plot the MCMC trace</p></a></li>
<li><a href='#plotTrueAndObserved'><p>Plot true and observed values</p></a></li>
<li><a href='#sccs'><p>Incidence rate ratios from Self-Controlled Case Series</p></a></li>
<li><a href='#simulateControls'><p>Simulate (negative) controls</p></a></li>
<li><a href='#simulateMaxSprtData'><p>Simulate survival data for MaxSPRT computation</p></a></li>
<li><a href='#southworthReplication'><p>Relative risks from an unadjusted new-user cohort design</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Routines for Performing Empirical Calibration of Observational
Study Estimates</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-14</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martijn Schuemie &lt;schuemie@ohdsi.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Routines for performing empirical calibration of observational
  study estimates. By using a set of negative control hypotheses we can
  estimate the empirical null distribution of a particular observational
  study setup. This empirical null distribution can be used to compute a
  calibrated p-value, which reflects the probability of observing an
  estimated effect size when the null hypothesis is true taking both random
  and systematic error into account. A similar approach can be used to
  calibrate confidence intervals, using both negative and positive controls. 
  For more details, see Schuemie et al. (2013) &lt;<a href="https://doi.org/10.1002%2Fsim.5925">doi:10.1002/sim.5925</a>&gt; and
  Schuemie et al. (2018) &lt;<a href="https://doi.org/10.1073%2Fpnas.1708282114">doi:10.1073/pnas.1708282114</a>&gt;.</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2 (&ge; 2.0.0), gridExtra, methods, rlang, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, rmarkdown, testthat, Cyclops, survival,
Sequential</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ohdsi.github.io/EmpiricalCalibration/">https://ohdsi.github.io/EmpiricalCalibration/</a>,
<a href="https://github.com/OHDSI/EmpiricalCalibration">https://github.com/OHDSI/EmpiricalCalibration</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/OHDSI/EmpiricalCalibration/issues">https://github.com/OHDSI/EmpiricalCalibration/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-14 15:45:38 UTC; schuemie</td>
</tr>
<tr>
<td>Author:</td>
<td>Martijn Schuemie <a href="https://orcid.org/0000-0002-0817-5361"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Marc Suchard <a href="https://orcid.org/0000-0001-9818-479X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-14 16:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='EmpiricalCalibration-package'>EmpiricalCalibration: Routines for Performing Empirical Calibration of Observational Study Estimates</h2><span id='topic+EmpiricalCalibration'></span><span id='topic+EmpiricalCalibration-package'></span>

<h3>Description</h3>

<p>Routines for performing empirical calibration of observational study estimates. By using a set of negative control hypotheses we can estimate the empirical null distribution of a particular observational study setup. This empirical null distribution can be used to compute a calibrated p-value, which reflects the probability of observing an estimated effect size when the null hypothesis is true taking both random and systematic error into account. A similar approach can be used to calibrate confidence intervals, using both negative and positive controls. For more details, see Schuemie et al. (2013) <a href="https://doi.org/10.1002/sim.5925">doi:10.1002/sim.5925</a> and Schuemie et al. (2018) <a href="https://doi.org/10.1073/pnas.1708282114">doi:10.1073/pnas.1708282114</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Martijn Schuemie <a href="mailto:schuemie@ohdsi.org">schuemie@ohdsi.org</a> (<a href="https://orcid.org/0000-0002-0817-5361">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Marc Suchard (<a href="https://orcid.org/0000-0001-9818-479X">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://ohdsi.github.io/EmpiricalCalibration/">https://ohdsi.github.io/EmpiricalCalibration/</a>
</p>
</li>
<li> <p><a href="https://github.com/OHDSI/EmpiricalCalibration">https://github.com/OHDSI/EmpiricalCalibration</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/OHDSI/EmpiricalCalibration/issues">https://github.com/OHDSI/EmpiricalCalibration/issues</a>
</p>
</li></ul>


<hr>
<h2 id='calibrateConfidenceInterval'>Calibrate confidence intervals</h2><span id='topic+calibrateConfidenceInterval'></span>

<h3>Description</h3>

<p>Calibrate confidence intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateConfidenceInterval(logRr, seLogRr, model, ciWidth = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateConfidenceInterval_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="calibrateConfidenceInterval_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="calibrateConfidenceInterval_+3A_model">model</code></td>
<td>
<p>An object of type <code>systematicErrorModel</code> as created by the
<code><a href="#topic+fitSystematicErrorModel">fitSystematicErrorModel</a></code> function.</p>
</td></tr>
<tr><td><code id="calibrateConfidenceInterval_+3A_ciwidth">ciWidth</code></td>
<td>
<p>The width of the confidence interval. Typically this would be .95, for the 95
percent confidence interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute calibrated confidence intervals based on a model of the systematic error.
</p>


<h3>Value</h3>

<p>A data frame with calibrated confidence intervals and point estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
model &lt;- fitSystematicErrorModel(data$logRr, data$seLogRr, data$trueLogRr)
newData &lt;- simulateControls(n = 15, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
result &lt;- calibrateConfidenceInterval(newData$logRr, newData$seLogRr, model)
result

</code></pre>

<hr>
<h2 id='calibrateLlr'>Calibrate the log likelihood ratio</h2><span id='topic+calibrateLlr'></span>

<h3>Description</h3>

<p><code>calibrateLlr</code> computes calibrated log likelihood ratio using the fitted null distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateLlr(null, likelihoodApproximation, twoSided = FALSE, upper = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateLlr_+3A_null">null</code></td>
<td>
<p>An object of class <code>null</code> created using the <code>fitNull</code> function or an
object of class <code>mcmcNull</code> created using the <code>fitMcmcNull</code> function.</p>
</td></tr>
<tr><td><code id="calibrateLlr_+3A_likelihoodapproximation">likelihoodApproximation</code></td>
<td>
<p>Either a data frame containing normal, skew-normal, or custom parametric likelihood
approximations, or a list of (adaptive) grid likelihood profiles.</p>
</td></tr>
<tr><td><code id="calibrateLlr_+3A_twosided">twoSided</code></td>
<td>
<p>Compute two-sided (TRUE) or one-sided (FALSE) p-value?</p>
</td></tr>
<tr><td><code id="calibrateLlr_+3A_upper">upper</code></td>
<td>
<p>If one-sided: compute p-value for upper (TRUE) or lower (FALSE) bound?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The calibrated log likelihood ratio.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNull(negatives$logRr, negatives$seLogRr)
positive &lt;- sccs[sccs$groundTruth == 1, ]
calibrateLlr(null, positive)

</code></pre>

<hr>
<h2 id='calibrateP'>Calibrate the p-value</h2><span id='topic+calibrateP'></span><span id='topic+calibrateP.null'></span><span id='topic+calibrateP.mcmcNull'></span>

<h3>Description</h3>

<p><code>calibrateP</code> computes calibrated p-values using the fitted null distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrateP(null, logRr, seLogRr, twoSided = TRUE, upper = TRUE, ...)

## S3 method for class 'null'
calibrateP(null, logRr, seLogRr, twoSided = TRUE, upper = TRUE, ...)

## S3 method for class 'mcmcNull'
calibrateP(
  null,
  logRr,
  seLogRr,
  twoSided = TRUE,
  upper = TRUE,
  pValueOnly,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calibrateP_+3A_null">null</code></td>
<td>
<p>An object of class <code>null</code> created using the <code>fitNull</code> function or an
object of class <code>mcmcNull</code> created using the <code>fitMcmcNull</code> function.</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of one or more effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_twosided">twoSided</code></td>
<td>
<p>Compute two-sided (TRUE) or one-sided (FALSE) p-value?</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_upper">upper</code></td>
<td>
<p>If one-sided: compute p-value for upper (TRUE) or lower (FALSE) bound?</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_...">...</code></td>
<td>
<p>Any additional parameters (currently none).</p>
</td></tr>
<tr><td><code id="calibrateP_+3A_pvalueonly">pValueOnly</code></td>
<td>
<p>If true, will return only the calibrated P-value itself, not the credible
interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes a calibrated two-sided p-value as described in Schuemie et al (2014).
</p>


<h3>Value</h3>

<p>The calibrated p-value.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>calibrateP(null)</code>: Computes the calibrated P-value using asymptotic assumptions.
</p>
</li>
<li> <p><code>calibrateP(mcmcNull)</code>: Computes the calibrated P-value and 95 percent credible interval using Markov Chain
Monte Carlo (MCMC).
</p>
</li></ul>


<h3>References</h3>

<p>Schuemie MJ, Ryan PB, Dumouchel W, Suchard MA, Madigan D. Interpreting observational studies: why
empirical calibration is needed to correct p-values. Statistics in Medicine 33(2):209-18,2014
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNull(negatives$logRr, negatives$seLogRr)
positive &lt;- sccs[sccs$groundTruth == 1, ]
calibrateP(null, positive$logRr, positive$seLogRr)

</code></pre>

<hr>
<h2 id='caseControl'>Odds ratios from a case-control design</h2><span id='topic+caseControl'></span>

<h3>Description</h3>

<p>Odds ratios from a case-control design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(caseControl)
</code></pre>


<h3>Format</h3>

<p>A data frame with 47 rows and 4 variables: </p>
 <dl>
<dt>drugName</dt><dd><p>Name of the drug</p>
</dd>
<dt>groundTruth</dt><dd><p>Whether the drug is a positive (1) or negative (0) control</p>
</dd> <dt>logRr</dt><dd><p>The log
of the incidence rate ratio</p>
</dd> <dt>seLogRr</dt><dd><p>The standard error of the log of the incidence rate
ratio</p>
</dd> </dl>



<h3>Details</h3>

<p>A dataset containing the odds ratios (and standard errors) produced using a case-control design.
The outcome is upper GI bleeding, the drug of interest (groundTruth = 1) is sertraline. Also
included are 46 negative control drugs, for which we believe there to be no causal relation with
upper GI bleeding. We used a database of medical records from general practices in the USA, the
General Electric (GE) Centricity database, which contains data on 11.2 million subjects. We
restricted on study period (start of 1990 through November 2003), age requirements (18 years or
older), available time prior to event (180 days), number of controls per case (6), and risk
definition window (30 days following the prescription). Controls were matched on age and sex. Cases
of upper GI bleeding were identified on the basis of the occurrence of ICD-9 diagnosis codes in the
problem list. These codes pertain to esophageal, gastric, duodenal, peptic, and gastrojejunal
ulceration, perforation, and hemorrhage, as well as gastritis and non-specific gastrointestinal
hemorrhage. For more information on this set see Schuemie et al (2014).
</p>


<h3>References</h3>

<p>Schuemie MJ, Ryan PB, Dumouchel W, Suchard MA, Madigan D. Interpreting observational studies: why
empirical calibration is needed to correct p-values. Statistics in Medicine 33(2):209-18,2014
</p>

<hr>
<h2 id='cohortMethod'>Relative risks from a new-user cohort design</h2><span id='topic+cohortMethod'></span>

<h3>Description</h3>

<p>Relative risks from a new-user cohort design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cohortMethod)
</code></pre>


<h3>Format</h3>

<p>A data frame with 31 rows and 4 variables: </p>
 <dl>
<dt>drugName</dt><dd><p>Name of the drug</p>
</dd>
<dt>groundTruth</dt><dd><p>Whether the drug is a positive (1) or negative (0) control</p>
</dd> <dt>logRr</dt><dd><p>The log
of the incidence rate ratio</p>
</dd> <dt>seLogRr</dt><dd><p>The standard error of the log of the incidence rate
ratio</p>
</dd> </dl>



<h3>Details</h3>

<p>A dataset containing the relative risks (and standard errors) produced using a new-user cohort
design. The outcome is acute liver injury, the drug of interest (groundTruth = 1) is Isoniazid Also
included are 30 negative control drugs, for which we believe there to be no causal relation with
acute liver injury. We used the Thomson MarketScan Medicare Supplemental Beneficiaries database,
which contains data on 4.6 million subjects. We selected two groups (cohorts): (1) all subjects
exposed to isoniazid and (2) all subjects having the ailment for which isoniazid is indicated, in
this case tuberculosis, and having received at least one drug that is not known to cause acute
liver injury. We removed all subjects who belonged to both groups and subjects for which less than
180 days of observation time was available prior to their first exposure to the drug in question.
Acute liver injury was identified on the basis of the occurrence of ICD-9-based diagnosis codes
from inpatient and outpatient medical claims and was defined broadly on the basis of codes
associated with hepatic dysfunction, as have been used in prior observational database studies. The
time at risk was defined as the length of exposure + 30 days, and we determined whether subjects
experienced an acute liver injury during their time at risk. Using propensity score stratification,
the cohorts were divided over 20 strata, and an odds ratio over all strata was computed using a
Mantel-Haenszel test. The propensity score was estimated using Bayesian logistic regression using
all available drug, condition, and procedure covariates occurring in the 180 days prior to first
exposure, in addition to age, sex, calendar year of first exposure, Charlson index, number of
drugs, number of visit days, and number of procedures. For more information on this set see
Schuemie et al (2014).
</p>


<h3>References</h3>

<p>Schuemie MJ, Ryan PB, Dumouchel W, Suchard MA, Madigan D. Interpreting observational studies: why
empirical calibration is needed to correct p-values. Statistics in Medicine 33(2):209-18,2014
</p>

<hr>
<h2 id='compareEase'>Compare EASE of correlated sets of estimates</h2><span id='topic+compareEase'></span>

<h3>Description</h3>

<p>Compare EASE of correlated sets of estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareEase(
  logRr1,
  seLogRr1,
  logRr2,
  seLogRr2,
  alpha = 0.05,
  sampleSize = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareEase_+3A_logrr1">logRr1</code></td>
<td>
<p>A numeric vector of effect estimates generated using the first method on the log scale.</p>
</td></tr>
<tr><td><code id="compareEase_+3A_selogrr1">seLogRr1</code></td>
<td>
<p>The standard error of the log of the effect estimates generated using the first method.</p>
</td></tr>
<tr><td><code id="compareEase_+3A_logrr2">logRr2</code></td>
<td>
<p>A numeric vector of effect estimates generated using the second method on the log scale.</p>
</td></tr>
<tr><td><code id="compareEase_+3A_selogrr2">seLogRr2</code></td>
<td>
<p>The standard error of the log of the effect estimates generated using the second method.</p>
</td></tr>
<tr><td><code id="compareEase_+3A_alpha">alpha</code></td>
<td>
<p>The expected type I error for computing confidence intervals and p-values.</p>
</td></tr>
<tr><td><code id="compareEase_+3A_samplesize">sampleSize</code></td>
<td>
<p>The number of samples in the bootstraps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compare the expected absolute systematic error (EASE) of two sets of estimates for the same set of negative controls.
</p>
<p>Important: the two sets of estimates (logRr1 + seLogRr1 and logRr2 + seLogRr2) should be in identical order, so that for
example the first item in each vector corresponds to the same negative control.
</p>


<h3>Value</h3>

<p>A data frame with 4 columns: the point estimate, confidence interval lower bound, and upper bound for the difference
between EASE in the two sets of negative controls, and a p value against the null hypothesis that the EASE is the
same for the two sets.
</p>
<p>The data frame has two attributes: ease1 and ease2, providing the EASE estimates (and confidence intervals) for the
two sets, computed using bootstrapping. Note that these estimates may somewhat different from those generated using
<code><a href="#topic+computeExpectedAbsoluteSystematicError">computeExpectedAbsoluteSystematicError</a></code>, because a different approach is used to compute the confidence
interval. The approach used here will more closely align with the computation of the difference in EASE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate results of first method:
ncs1 &lt;- simulateControls(n = 50)

# Simulate second method to be more biased:
ncs2 &lt;- ncs1
ncs2$logRr &lt;- ncs2$logRr + rnorm(nrow(ncs2), mean = 0.1, sd = 0.1)

delta &lt;- compareEase(
  logRr1 = ncs1$logRr,
  seLogRr1 = ncs1$seLogRr,
  logRr2 = ncs2$logRr,
  seLogRr2 = ncs2$seLogRr
)
delta
attr(delta, "ease1")
attr(delta, "ease2")
</code></pre>

<hr>
<h2 id='computeCvBinomial'>Compute critical values for Binomial data</h2><span id='topic+computeCvBinomial'></span>

<h3>Description</h3>

<p>Obtains critical values for the group and continuous sequential MaxSPRT test with Binomial data,
using a Wald type upper boundary, which is flat with respect to the likelihood ratio function,
and with a pre-specified upper limit on the sample size.
</p>
<p>It is often not possible to select a critical value that corresponds to the exact alpha specified.
Instead, this function will select the least conservative critical value having an alpha below
the one specified, so the sequential analysis is conservative.
</p>
<p>This function is a re-implementation of the <code>CV.Binomial</code> function in the <code>Sequential</code>
package, using Monte-Carlo.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeCvBinomial(
  groupSizes,
  z,
  minimumEvents = 1,
  alpha = 0.05,
  sampleSize = 1e+06,
  nullMean = 0,
  nullSd = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeCvBinomial_+3A_groupsizes">groupSizes</code></td>
<td>
<p>Vector containing the expected number of events under H0 for each test.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_z">z</code></td>
<td>
<p>For a matched case-control analysis, z is the number of controls matched to
each case under the null hypothesis. For a self-controlled analysis, z is the
control time divided by the time at risk.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_minimumevents">minimumEvents</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_alpha">alpha</code></td>
<td>
<p>The significance level, or the type 1 error probability, which is the probability
of rejecting the null hypothesis when it is true.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size for the Monte-Carlo simulations.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_nullmean">nullMean</code></td>
<td>
<p>The mean of the empirical null distribution.</p>
</td></tr>
<tr><td><code id="computeCvBinomial_+3A_nullsd">nullSd</code></td>
<td>
<p>The standard deviation of the empirical null distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The computed critical value. The 'alpha' attribute of the result indicates the selected alpha.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>groupSizes &lt;- rep(1, 10)
computeCvBinomial(groupSizes, z = 4)

</code></pre>

<hr>
<h2 id='computeCvPoisson'>Compute critical values for Poisson data</h2><span id='topic+computeCvPoisson'></span>

<h3>Description</h3>

<p>Obtains critical values for the group and continuous sequential MaxSPRT test with Poisson data,
using a Wald type upper boundary, which is flat with respect to the likelihood ratio function,
and with a pre-specified upper limit on the sample size.
</p>
<p>It is often not possible to select a critical value that corresponds to the exact alpha specified.
Instead, this function will select the least conservative critical value having an alpha below
the one specified, so the sequential analysis is conservative.
</p>
<p>This function is a re-implementation of the <code>CV.Poisson</code> function in the <code>Sequential</code>
package, using Monte-Carlo.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeCvPoisson(
  groupSizes,
  minimumEvents = 1,
  alpha = 0.05,
  sampleSize = 1e+06,
  nullMean = 0,
  nullSd = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeCvPoisson_+3A_groupsizes">groupSizes</code></td>
<td>
<p>Vector containing the expected number of events under H0 for each test.</p>
</td></tr>
<tr><td><code id="computeCvPoisson_+3A_minimumevents">minimumEvents</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected.</p>
</td></tr>
<tr><td><code id="computeCvPoisson_+3A_alpha">alpha</code></td>
<td>
<p>The significance level, or the type 1 error probability, which is the probability
of rejecting the null hypothesis when it is true.</p>
</td></tr>
<tr><td><code id="computeCvPoisson_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size for the Monte-Carlo simulations.</p>
</td></tr>
<tr><td><code id="computeCvPoisson_+3A_nullmean">nullMean</code></td>
<td>
<p>The mean of the empirical null distribution.</p>
</td></tr>
<tr><td><code id="computeCvPoisson_+3A_nullsd">nullSd</code></td>
<td>
<p>The standard deviation of the empirical null distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The computed critical value. The 'alpha' attribute of the result indicates the selected alpha.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>groupSizes &lt;- rep(1, 10)
computeCvPoisson(groupSizes)

</code></pre>

<hr>
<h2 id='computeCvPoissonRegression'>Compute critical values for Poisson regression data</h2><span id='topic+computeCvPoissonRegression'></span>

<h3>Description</h3>

<p>Obtains critical values for the group and continuous sequential MaxSPRT test with Poisson regression data,
using a Wald type upper boundary, which is flat with respect to the likelihood ratio function,
and with a pre-specified upper limit on the sample size.
</p>
<p>It is often not possible to select a critical value that corresponds to the exact alpha specified.
Instead, this function will select the least conservative critical value having an alpha below
the one specified, so the sequential analysis is conservative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeCvPoissonRegression(
  groupSizes,
  z,
  minimumEvents = 1,
  alpha = 0.05,
  sampleSize = 1e+06
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeCvPoissonRegression_+3A_groupsizes">groupSizes</code></td>
<td>
<p>Vector containing the expected number of events under H0 for each test.</p>
</td></tr>
<tr><td><code id="computeCvPoissonRegression_+3A_z">z</code></td>
<td>
<p>The control time divided by the time at risk.</p>
</td></tr>
<tr><td><code id="computeCvPoissonRegression_+3A_minimumevents">minimumEvents</code></td>
<td>
<p>The minimum number of events needed before the null hypothesis can be rejected.</p>
</td></tr>
<tr><td><code id="computeCvPoissonRegression_+3A_alpha">alpha</code></td>
<td>
<p>The significance level, or the type 1 error probability, which is the probability
of rejecting the null hypothesis when it is true.</p>
</td></tr>
<tr><td><code id="computeCvPoissonRegression_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size for the Monte-Carlo simulations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The computed critical value. The 'alpha' attribute of the result indicates the selected alpha.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>groupSizes &lt;- rep(1, 10)
computeCvPoissonRegression(groupSizes, z = 4)

</code></pre>

<hr>
<h2 id='computeExpectedAbsoluteSystematicError'>Compute the expected absolute systematic error</h2><span id='topic+computeExpectedAbsoluteSystematicError'></span>

<h3>Description</h3>

<p>For a random study estimate, what is the expected value of the absolute systematic error?
Provides a single summary value for a null distribution. The expected systematic error of a null
distribution is equal to its mean (mu), and is insensitive to the spread of the null distribution (sigma).
</p>
<p>Taking the absolute value of the expected systematic error we can express both mean and spread of the
estimated null distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeExpectedAbsoluteSystematicError(null, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeExpectedAbsoluteSystematicError_+3A_null">null</code></td>
<td>
<p>An object of class <code>null</code> created using the <code>fitNull</code> function or an
object of class <code>mcmcNull</code> created using the <code>fitMcmcNull</code> function.</p>
</td></tr>
<tr><td><code id="computeExpectedAbsoluteSystematicError_+3A_alpha">alpha</code></td>
<td>
<p>The expected type I error for computing the credible interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected absolute systematic error. If the provided <code>null</code> argument is of type <code>mcmcNull</code>,
the credible interval (defined by <code>alpha</code>) is also returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compareEase">compareEase</a></code> for comparing the expected absolute systematic error of two sets of estimates for the same negative controls.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNull(negatives$logRr, negatives$seLogRr)
computeExpectedAbsoluteSystematicError(null)
</code></pre>

<hr>
<h2 id='computeTraditionalCi'>Compute the (traditional) confidence interval</h2><span id='topic+computeTraditionalCi'></span>

<h3>Description</h3>

<p><code>computeTraditionalCi</code> computes the traditional confidence interval based on the log of the
relative risk and the standard error of the log of the relative risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeTraditionalCi(logRr, seLogRr, ciWidth = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeTraditionalCi_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of one or more effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="computeTraditionalCi_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="computeTraditionalCi_+3A_ciwidth">ciWidth</code></td>
<td>
<p>The width of the confidence interval. Typically this would be .95, for the 95
percent confidence interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The point estimate and confidence interval
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
positive &lt;- sccs[sccs$groundTruth == 1, ]
computeTraditionalCi(positive$logRr, positive$seLogRr)

</code></pre>

<hr>
<h2 id='computeTraditionalP'>Compute the (traditional) p-value</h2><span id='topic+computeTraditionalP'></span>

<h3>Description</h3>

<p><code>computeTraditionalP</code> computes the traditional two-sided p-value based on the log of the
relative risk and the standard error of the log of the relative risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeTraditionalP(logRr, seLogRr, twoSided = TRUE, upper = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computeTraditionalP_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of one or more effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="computeTraditionalP_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="computeTraditionalP_+3A_twosided">twoSided</code></td>
<td>
<p>Compute two-sided (TRUE) or one-sided (FALSE) p-value?</p>
</td></tr>
<tr><td><code id="computeTraditionalP_+3A_upper">upper</code></td>
<td>
<p>If one-sided: compute p-value for upper (TRUE) or lower (FALSE) bound?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The (traditional) p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
positive &lt;- sccs[sccs$groundTruth == 1, ]
computeTraditionalP(positive$logRr, positive$seLogRr)

</code></pre>

<hr>
<h2 id='convertNullToErrorModel'>Convert empirical null distribution to systematic error model</h2><span id='topic+convertNullToErrorModel'></span>

<h3>Description</h3>

<p>This function converts an empirical null distribution, fitted using estimates only for negative controls,
into a systematic error distribution that can be used to calibrate confidence intervals in addition to
p-values.
</p>
<p>Whereas the <code><a href="#topic+fitSystematicErrorModel">fitSystematicErrorModel</a></code> uses positive controls to determine how the error
distribution changes with true effect size, this function requires the user to make an assumption. The
default assumption, <code>meanSlope = 1</code> and <code>sdSlope = 0</code>, specify a belief that the error
distribution is the same for all true effect sizes. In many cases this assumption is likely to be correct,
however, if an estimation method is biased towards the null this assumption will be violated, causing the
calibrated confidence intervals to have lower than nominal coverage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertNullToErrorModel(null, meanSlope = 1, sdSlope = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertNullToErrorModel_+3A_null">null</code></td>
<td>
<p>The empirical null distribution fitted using either the <code><a href="#topic+fitNull">fitNull</a></code>
or the <code><a href="#topic+fitMcmcNull">fitMcmcNull</a></code> function.</p>
</td></tr>
<tr><td><code id="convertNullToErrorModel_+3A_meanslope">meanSlope</code></td>
<td>
<p>The slope for the mean of the error distribution. A slope of 1 means the error
is the same for different values of the true relative risk.</p>
</td></tr>
<tr><td><code id="convertNullToErrorModel_+3A_sdslope">sdSlope</code></td>
<td>
<p>The slope for the log of the standard deviation of the error distribution. A slope
of 0 means the standard deviation is the same for different values of the true
relative risk.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type <code>systematicErrorModel</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNull(negatives$logRr, negatives$seLogRr)
model &lt;- convertNullToErrorModel(null)
positive &lt;- sccs[sccs$groundTruth == 1, ]
calibrateConfidenceInterval(positive$logRr, positive$seLogRr, model)

</code></pre>

<hr>
<h2 id='evaluateCiCalibration'>Evaluate confidence interval calibration</h2><span id='topic+evaluateCiCalibration'></span>

<h3>Description</h3>

<p><code>evaluateCiCalibration</code> performs a leave-one-out cross-validation to evaluate the calibration
confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluateCiCalibration(
  logRr,
  seLogRr,
  trueLogRr,
  strata = as.factor(trueLogRr),
  crossValidationGroup = 1:length(logRr),
  legacy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluateCiCalibration_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="evaluateCiCalibration_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the
standard error = (log(&lt;lower bound 95 percent confidence interval&gt;) -
log(&lt;effect estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="evaluateCiCalibration_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>The true log relative risk.</p>
</td></tr>
<tr><td><code id="evaluateCiCalibration_+3A_strata">strata</code></td>
<td>
<p>Variable used to stratify the plot. Set <code>strata = NULL</code> for no
stratification.</p>
</td></tr>
<tr><td><code id="evaluateCiCalibration_+3A_crossvalidationgroup">crossValidationGroup</code></td>
<td>
<p>What should be the unit for the cross-validation? By default the unit
is a single control, but a different grouping can be provided, for
example linking a negative control to synthetic positive controls
derived from that negative control.</p>
</td></tr>
<tr><td><code id="evaluateCiCalibration_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical calibration is performed using a leave-one-out design: The confidence interval of an
effect is computed by fitting a null using all other controls.
</p>


<h3>Value</h3>

<p>A data frame specifying the coverage per strata (usually true effect size) for a wide range of widths
of the confidence interval. The result also includes the fraction of estimates that was below and above
the confidence interval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
eval &lt;- evaluateCiCalibration(data$logRr, data$seLogRr, data$trueLogRr)

## End(Not run)
</code></pre>

<hr>
<h2 id='fitMcmcNull'>Fit the null distribution using MCMC</h2><span id='topic+fitMcmcNull'></span>

<h3>Description</h3>

<p><code>fitNull</code> fits the null distribution to a set of negative controls using Markov Chain Monte
Carlo (MCMC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitMcmcNull(logRr, seLogRr, iter = 1e+05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitMcmcNull_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="fitMcmcNull_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="fitMcmcNull_+3A_iter">iter</code></td>
<td>
<p>Number of iterations of the MCMC.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an experimental function for computing the 95 percent credible interval of a calibrated
p-value using Markov-Chain Monte Carlo (MCMC).
</p>


<h3>Value</h3>

<p>An object of type <code>mcmcNull</code> containing the mean and standard deviation (both on the log
scale) of the null distribution, as well as the MCMC trace.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitMcmcNull(negatives$logRr, negatives$seLogRr)
null
plotMcmcTrace(null)
positive &lt;- sccs[sccs$groundTruth == 1, ]
calibrateP(null, positive$logRr, positive$seLogRr)

## End(Not run)
</code></pre>

<hr>
<h2 id='fitNull'>Fit the null distribution</h2><span id='topic+fitNull'></span>

<h3>Description</h3>

<p><code>fitNull</code> fits the null distribution to a set of negative controls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitNull(logRr, seLogRr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitNull_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="fitNull_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a Gaussian function to the negative control estimates as described in Schuemie
et al (2014).
</p>


<h3>Value</h3>

<p>An object containing the parameters of the null distribution.
</p>


<h3>References</h3>

<p>Schuemie MJ, Ryan PB, Dumouchel W, Suchard MA, Madigan D. Interpreting observational studies: why
empirical calibration is needed to correct p-values. Statistics in Medicine 33(2):209-18,2014
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNull(negatives$logRr, negatives$seLogRr)
null

</code></pre>

<hr>
<h2 id='fitNullNonNormalLl'>Fit the null distribution using non-normal log-likelihood approximations</h2><span id='topic+fitNullNonNormalLl'></span>

<h3>Description</h3>

<p><code>fitNullNonNormalLl</code> fits the null distribution to a set of negative controls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitNullNonNormalLl(likelihoodApproximations)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitNullNonNormalLl_+3A_likelihoodapproximations">likelihoodApproximations</code></td>
<td>
<p>Either a data frame containing normal, skew-normal, or custom parametric likelihood
approximations, or a list of (adaptive) grid likelihood profiles.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a Gaussian function to the negative control estimates, using non-normal
approximations of the per-negative control log likelihood.
</p>


<h3>Value</h3>

<p>An object containing the parameters of the null distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitNullNonNormalLl(negatives)
null

</code></pre>

<hr>
<h2 id='fitSystematicErrorModel'>Fit a systematic error model</h2><span id='topic+fitSystematicErrorModel'></span>

<h3>Description</h3>

<p>Fit a systematic error model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitSystematicErrorModel(
  logRr,
  seLogRr,
  trueLogRr,
  estimateCovarianceMatrix = FALSE,
  legacy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitSystematicErrorModel_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="fitSystematicErrorModel_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often
the standard error = (log(&lt;lower bound 95 percent confidence
interval&gt;) - log(&lt;effect estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="fitSystematicErrorModel_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>A vector of the true effect sizes.</p>
</td></tr>
<tr><td><code id="fitSystematicErrorModel_+3A_estimatecovariancematrix">estimateCovarianceMatrix</code></td>
<td>
<p>Should a covariance matrix be computed? If so, confidence
intervals for the model parameters will be available.</p>
</td></tr>
<tr><td><code id="fitSystematicErrorModel_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fit a model of the systematic error as a function of true effect size. This model is an extension
of the method for fitting the null distribution. The mean and log(standard deviations) of the error
distributions are assumed to be linear with respect to the true effect size, and each component is
therefore represented by an intercept and a slope.
</p>


<h3>Value</h3>

<p>An object of type <code>systematicErrorModel</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>controls &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
model &lt;- fitSystematicErrorModel(controls$logRr, controls$seLogRr, controls$trueLogRr)
model

</code></pre>

<hr>
<h2 id='grahamReplication'>Relative risks from an adjusted new-user cohort design</h2><span id='topic+grahamReplication'></span>

<h3>Description</h3>

<p>Relative risks from an adjusted new-user cohort design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grahamReplication)
</code></pre>


<h3>Format</h3>

<p>A data frame with 126 rows and 4 variables: </p>
 <dl>
<dt>outcomeName</dt><dd><p>Name of the outcome</p>
</dd>
<dt>trueLogRr</dt><dd><p>The log of the true effect size. Only provided for negative and positive controls,
is NA for the outcome of interest (GI bleeding).</p>
</dd> <dt>logRr</dt><dd><p>The log of the incidence rate ratio</p>
</dd> <dt>seLogRr</dt><dd>
<p>The standard error of the log of the incidence rate ratio</p>
</dd> </dl>



<h3>Details</h3>

<p>A dataset containing the incidence rate ratios (and standard errors) produced using a new-user
cohort design that compares new-users of dabigatran to new-users of warfarin for the outcome of
GI hemorrhage. The dataset includes estimates both for the outcome of interest as well as negative
and positive control outcomes. Subject are required to have 183 days of continuous observation
prior to initiating treatment, be at least 65 years old at index date, and are required to have
no prior exposure to warfarin or dabigatran (or any other novel anticoagulant). Furthermore,
subjects are required to use the treatment for the indication of atrial fibrillation or atrial
flutter, which is enforced by requiring a prior diagnosis of atrial fibrillation or flutter,
and no prior diagnosis of other indications. Propensity scores are generated by fitting a model
for predicting treatment assignment based on baseline patient characteristics, and are used to
perform one-on-one matching. Hazard ratios are estimated through a Cox regression on the matched
population. Time-at-risk is defined as starting on the day after initiating treatment and stopping
when treatment is stopped, when the outcome occurs, or observation time ends, whichever comes first.
The original study (Graham et al 2016) uses the Medicare database. For our replication, we use the
Truven Medicare Supplementary Beneficiaries database. We analyze 15,796 dabigatran-exposed and 15,796
warfarin-exposed subjects. For more information on this set see Schuemie et al (2017).
</p>


<h3>References</h3>

<p>Schuemie MJ, Hripcsak G, Ryan PB, Madigan D, Suchard MA. Empirical confidence interval calibration
for population-level effect estimation studies in observational healthcare data. Proc Natl Acad Sci
U S A. 2018 Mar 13;115(11):2571-2577
</p>
<p>Graham DJ, Reichman ME, Wernecke M, Hsueh YH, Izem R, Southworth MR, Wei Y, Liao J, Goulding MR, Mott K,
Chillarige Y, MaCurdy TE, Worrall C, Kelman JA.  Stroke, Bleeding, and Mortality Risks in Elderly Medicare
Beneficiaries Treated With Dabigatran or Rivaroxaban for Nonvalvular Atrial Fibrillation. JAMA Intern
Med 176(11):1662-1671, 2016
</p>

<hr>
<h2 id='plotCalibration'>Create a calibration plot</h2><span id='topic+plotCalibration'></span>

<h3>Description</h3>

<p><code>plotCalibration</code> creates a plot showing the calibration of our calibration procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCalibration(
  logRr,
  seLogRr,
  useMcmc = FALSE,
  legendPosition = "right",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCalibration_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the
standard error = (log(&lt;lower bound 95 percent confidence interval&gt;) -
log(&lt;effect estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_usemcmc">useMcmc</code></td>
<td>
<p>Use MCMC to estimate the calibrated P-value?</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_legendposition">legendPosition</code></td>
<td>
<p>Where should the legend be positioned? (&quot;none&quot;, &quot;left&quot;, &quot;right&quot;, &quot;bottom&quot;,
&quot;top&quot;)</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'. See
the function <code>ggsave</code> in the ggplot2 package for supported file
formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a calibration plot showing the number of effects with p &lt; alpha for every level of alpha.
The empirical calibration is performed using a leave-one-out design: The p-value of an effect is
computed by fitting a null using all other negative controls. Ideally, the calibration line should
approximate the diagonal. The plot shows both theoretical (traditional) and empirically calibrated
p-values.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
plotCalibration(negatives$logRr, negatives$seLogRr)

</code></pre>

<hr>
<h2 id='plotCalibrationEffect'>Plot the effect of the calibration</h2><span id='topic+plotCalibrationEffect'></span>

<h3>Description</h3>

<p><code>plotCalibrationEffect</code> creates a plot showing the effect of the calibration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCalibrationEffect(
  logRrNegatives,
  seLogRrNegatives,
  logRrPositives = NULL,
  seLogRrPositives = NULL,
  null = NULL,
  alpha = 0.05,
  xLabel = "Relative risk",
  title,
  showCis = FALSE,
  showExpectedAbsoluteSystematicError = FALSE,
  fileName = NULL,
  xLimits = c(0.25, 10),
  yLimits = c(0, 1.5)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCalibrationEffect_+3A_logrrnegatives">logRrNegatives</code></td>
<td>
<p>A numeric vector of effect estimates of the negative controls on the log
scale.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_selogrrnegatives">seLogRrNegatives</code></td>
<td>
<p>The standard error of the log of the effect estimates of the negative
controls.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_logrrpositives">logRrPositives</code></td>
<td>
<p>Optional: A numeric vector of effect estimates of the positive controls on the log
scale.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_selogrrpositives">seLogRrPositives</code></td>
<td>
<p>Optional: The standard error of the log of the effect estimates of the positive
controls.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_null">null</code></td>
<td>
<p>An object representing the fitted null distribution as created by the
<code>fitNull</code> or <code>fitMcmcNull</code> functions. If not provided, a null
will be fitted before plotting.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_alpha">alpha</code></td>
<td>
<p>The alpha for the hypothesis test.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_xlabel">xLabel</code></td>
<td>
<p>The label on the x-axis: the name of the effect estimate.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_showcis">showCis</code></td>
<td>
<p>Show 95 percent credible intervals for the calibrated p = alpha boundary.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_showexpectedabsolutesystematicerror">showExpectedAbsoluteSystematicError</code></td>
<td>
<p>Show the expected absolute systematic error. If <code>null</code> is of
type <code>mcmcNull</code> the 95 percent credible interval will also be shown.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'.
See the function <code>ggsave</code> in the ggplot2 package for supported file
formats.</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_xlimits">xLimits</code></td>
<td>
<p>Vector of length 2 for limits of the plot x axis - defaults to 0.25, 10</p>
</td></tr>
<tr><td><code id="plotCalibrationEffect_+3A_ylimits">yLimits</code></td>
<td>
<p>Vector of length 2 for size limits of the y axis - defaults to 0, 1.5</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a plot with the effect estimate on the x-axis and the standard error on the y-axis.
Negative controls are shown as blue dots, positive controls as yellow diamonds. The area below the
dashed line indicated estimates with p &lt; 0.05. The orange area indicates estimates with calibrated
p &lt; 0.05.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
positive &lt;- sccs[sccs$groundTruth == 1, ]
plotCalibrationEffect(negatives$logRr, negatives$seLogRr, positive$logRr, positive$seLogRr)

</code></pre>

<hr>
<h2 id='plotCiCalibration'>Create a confidence interval calibration plot</h2><span id='topic+plotCiCalibration'></span>

<h3>Description</h3>

<p><code>plotCalibration</code> creates a plot showing the calibration of our confidence interval
calibration procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCiCalibration(
  logRr,
  seLogRr,
  trueLogRr,
  strata = as.factor(trueLogRr),
  crossValidationGroup = 1:length(logRr),
  legacy = FALSE,
  evaluation,
  legendPosition = "top",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCiCalibration_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the
standard error = (log(&lt;lower bound 95 percent confidence interval&gt;) -
log(&lt;effect estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>The true log relative risk.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_strata">strata</code></td>
<td>
<p>Variable used to stratify the plot. Set <code>strata = NULL</code> for no
stratification.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_crossvalidationgroup">crossValidationGroup</code></td>
<td>
<p>What should be the unit for the cross-validation? By default the unit
is a single control, but a different grouping can be provided, for
example linking a negative control to synthetic positive controls
derived from that negative control.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_evaluation">evaluation</code></td>
<td>
<p>A data frame as generated by the <code><a href="#topic+evaluateCiCalibration">evaluateCiCalibration</a></code>
function. If provided, the logRr, seLogRr, trueLogRr, strata, and legacy
arguments will be ignored.</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_legendposition">legendPosition</code></td>
<td>
<p>Where should the legend be positioned? (&quot;none&quot;, &quot;left&quot;, &quot;right&quot;,
&quot;bottom&quot;, &quot;top&quot;).</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotCiCalibration_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example
'plot.png'. See the function <code>ggsave</code> in the ggplot2 package for
supported file formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a calibration plot showing the fraction of effects within the confidence interval. The
empirical calibration is performed using a leave-one-out design: The confidence interval of an
effect is computed by fitting a null using all other controls. Ideally, the calibration line should
approximate the diagonal. The plot shows the coverage for both theoretical (traditional) and
empirically calibrated confidence intervals.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotCiCalibration(data$logRr, data$seLogRr, data$trueLogRr)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotCiCalibrationEffect'>Plot the effect of the CI calibration</h2><span id='topic+plotCiCalibrationEffect'></span>

<h3>Description</h3>

<p>Creates a plot with the effect estimate on the x-axis and the standard error on the y-axis. The plot
is trellised by true effect size. Negative and positive controls are shown as blue dots. The area below the
dashed line indicated estimates that are statistically significant different from the true effect size (p &lt; 0.05).
The orange area indicates estimates with calibrated p &lt; 0.05.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCiCalibrationEffect(
  logRr,
  seLogRr,
  trueLogRr,
  legacy = FALSE,
  model = NULL,
  xLabel = "Relative risk",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCiCalibrationEffect_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>A vector of the true effect sizes.</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_model">model</code></td>
<td>
<p>The fitted systematic error model. If not provided, it will be fitted on the
provided data.</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_xlabel">xLabel</code></td>
<td>
<p>The label on the x-axis: the name of the effect estimate.</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotCiCalibrationEffect_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'. See the
function <code>ggsave</code> in the ggplot2 package for supported file formats.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotCiCalibrationEffect(data$logRr, data$seLogRr, data$trueLogRr)

</code></pre>

<hr>
<h2 id='plotCiCoverage'>Create a confidence interval coverage plot</h2><span id='topic+plotCiCoverage'></span>

<h3>Description</h3>

<p><code>plotCiCoverage</code> creates a plot showing the coverage before and after confidence interval
calibration at various widths of the confidence interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCiCoverage(
  logRr,
  seLogRr,
  trueLogRr,
  strata = as.factor(trueLogRr),
  crossValidationGroup = 1:length(logRr),
  legacy = FALSE,
  evaluation,
  legendPosition = "top",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCiCoverage_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the
standard error = (log(&lt;lower bound 95 percent confidence interval&gt;) -
log(&lt;effect estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>The true log relative risk.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_strata">strata</code></td>
<td>
<p>Variable used to stratify the plot. Set <code>strata = NULL</code> for no
stratification.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_crossvalidationgroup">crossValidationGroup</code></td>
<td>
<p>What should be the unit for the cross-validation? By default the unit
is a single control, but a different grouping can be provided, for
example linking a negative control to synthetic positive controls
derived from that negative control.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_evaluation">evaluation</code></td>
<td>
<p>A data frame as generated by the <code><a href="#topic+evaluateCiCalibration">evaluateCiCalibration</a></code>
function. If provided, the logRr, seLogRr, trueLogRr, strata, and legacy
arguments will be ignored.</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_legendposition">legendPosition</code></td>
<td>
<p>Where should the legend be positioned? (&quot;none&quot;, &quot;left&quot;, &quot;right&quot;,
&quot;bottom&quot;, &quot;top&quot;).</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotCiCoverage_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example
'plot.png'. See the function <code>ggsave</code> in the ggplot2 package for
supported file formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a plot showing the fraction of effects above, within, and below the confidence interval. The
empirical calibration is performed using a leave-one-out design: The confidence interval of an
effect is computed by fitting a null using all other controls. The plot shows the coverage for
both theoretical (traditional) and empirically calibrated confidence intervals.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotCiCoverage(data$logRr, data$seLogRr, data$trueLogRr)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotErrorModel'>Plot the systematic error model</h2><span id='topic+plotErrorModel'></span>

<h3>Description</h3>

<p><code>plotErrorModel</code> creates a plot showing the systematic error model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotErrorModel(
  logRr,
  seLogRr,
  trueLogRr,
  title,
  legacy = FALSE,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotErrorModel_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="plotErrorModel_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the
standard error = (log(&lt;lower bound 95 percent confidence interval&gt;) -
log(&lt;effect estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="plotErrorModel_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>The true log relative risk.</p>
</td></tr>
<tr><td><code id="plotErrorModel_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotErrorModel_+3A_legacy">legacy</code></td>
<td>
<p>If true, a legacy error model will be fitted, meaning standard
deviation is linear on the log scale. If false, standard deviation
is assumed to be simply linear.</p>
</td></tr>
<tr><td><code id="plotErrorModel_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'.
See the function <code>ggsave</code> in the ggplot2 package for supported file
formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a plot with the true effect size on the x-axis, and the mean plus and minus the standard
deviation shown on the y-axis. Also shown are simple error models fitted at each true relative
risk in the input.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotErrorModel(data$logRr, data$seLogRr, data$trueLogRr)
</code></pre>

<hr>
<h2 id='plotExpectedType1Error'>Plot the expected type 1 error as a function of standard error</h2><span id='topic+plotExpectedType1Error'></span>

<h3>Description</h3>

<p><code>plotExpectedType1Error</code> creates a plot showing the expected type 1 error as a function of standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotExpectedType1Error(
  logRrNegatives,
  seLogRrNegatives,
  seLogRrPositives,
  alpha = 0.05,
  null = NULL,
  xLabel = "Relative risk",
  title,
  showCis = FALSE,
  showEffectSizes = FALSE,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotExpectedType1Error_+3A_logrrnegatives">logRrNegatives</code></td>
<td>
<p>A numeric vector of effect estimates of the negative controls on the log
scale.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_selogrrnegatives">seLogRrNegatives</code></td>
<td>
<p>The standard error of the log of the effect estimates of the negative
controls.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_selogrrpositives">seLogRrPositives</code></td>
<td>
<p>The standard error of the log of the effect estimates of the positive
controls.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_alpha">alpha</code></td>
<td>
<p>The alpha (nominal type 1 error) to be used.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_null">null</code></td>
<td>
<p>An object representing the fitted null distribution as created by the
<code>fitNull</code> function. If not provided, a null will be fitted before
plotting.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_xlabel">xLabel</code></td>
<td>
<p>If showing effect sizes, what label should be used for the effect size axis?</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_showcis">showCis</code></td>
<td>
<p>Show 95 percent credible intervals for the expected type 1 error.</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_showeffectsizes">showEffectSizes</code></td>
<td>
<p>Show the expected effect sizes alongside the expected type 1 error?</p>
</td></tr>
<tr><td><code id="plotExpectedType1Error_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'.
See the function <code>ggsave</code> in the ggplot2 package for supported file
formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a plot with the standard error on the x-axis and the expected type 1 error on the y-axis. The
red line indicates the expected type 1 error  given the estimated empirical null distribution if no
calibration is performed. The dashed line indicated the nominal expected type 1 error rate, assuming
the theoretical null distribution.
</p>
<p>If standard errors are provided for non-negative estimates these will be plotted on the red line as
yellow diamonds.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
positive &lt;- sccs[sccs$groundTruth == 1, ]
plotExpectedType1Error(negatives$logRr, negatives$seLogRr, positive$seLogRr)

</code></pre>

<hr>
<h2 id='plotForest'>Create a forest plot</h2><span id='topic+plotForest'></span>

<h3>Description</h3>

<p><code>plotForest</code> creates a forest plot of effect size estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotForest(
  logRr,
  seLogRr,
  names,
  xLabel = "Relative risk",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotForest_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale</p>
</td></tr>
<tr><td><code id="plotForest_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025)</p>
</td></tr>
<tr><td><code id="plotForest_+3A_names">names</code></td>
<td>
<p>A vector containing the names of the drugs or outcomes</p>
</td></tr>
<tr><td><code id="plotForest_+3A_xlabel">xLabel</code></td>
<td>
<p>The label on the x-axis: the name of the effect estimate</p>
</td></tr>
<tr><td><code id="plotForest_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotForest_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'. See the
function <code>ggsave</code> in the ggplot2 package for supported file formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a forest plot of effect size estimates (ratios). Estimates that are significantly different
from 1 (alpha = 0.05) are marked in orange, others are marked in blue.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
plotForest(negatives$logRr, negatives$seLogRr, negatives$drugName)

</code></pre>

<hr>
<h2 id='plotMcmcTrace'>Plot the MCMC trace</h2><span id='topic+plotMcmcTrace'></span>

<h3>Description</h3>

<p>Plot the MCMC trace
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMcmcTrace(mcmcNull, fileName = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMcmcTrace_+3A_mcmcnull">mcmcNull</code></td>
<td>
<p>An object of type <code>mcmcNull</code> as generated using the <code>fitMcmcNull</code>
function.</p>
</td></tr>
<tr><td><code id="plotMcmcTrace_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'. See the
function <code>ggsave</code> in the ggplot2 package for supported file formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plot the trace of the MCMC for diagnostics purposes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sccs)
negatives &lt;- sccs[sccs$groundTruth == 0, ]
null &lt;- fitMcmcNull(negatives$logRr, negatives$seLogRr)
plotMcmcTrace(null)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotTrueAndObserved'>Plot true and observed values</h2><span id='topic+plotTrueAndObserved'></span>

<h3>Description</h3>

<p>Plot true and observed values, for example from a simulation study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTrueAndObserved(
  logRr,
  seLogRr,
  trueLogRr,
  xLabel = "Relative risk",
  title,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotTrueAndObserved_+3A_logrr">logRr</code></td>
<td>
<p>A numeric vector of effect estimates on the log scale.</p>
</td></tr>
<tr><td><code id="plotTrueAndObserved_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the effect estimates. Hint: often the standard
error = (log(&lt;lower bound 95 percent confidence interval&gt;) - log(&lt;effect
estimate&gt;))/qnorm(0.025).</p>
</td></tr>
<tr><td><code id="plotTrueAndObserved_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>A vector of the true effect sizes.</p>
</td></tr>
<tr><td><code id="plotTrueAndObserved_+3A_xlabel">xLabel</code></td>
<td>
<p>The label on the x-axis: the name of the effect estimate.</p>
</td></tr>
<tr><td><code id="plotTrueAndObserved_+3A_title">title</code></td>
<td>
<p>Optional: the main title for the plot</p>
</td></tr>
<tr><td><code id="plotTrueAndObserved_+3A_filename">fileName</code></td>
<td>
<p>Name of the file where the plot should be saved, for example 'plot.png'. See the
function <code>ggsave</code> in the ggplot2 package for supported file formats.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates a forest plot of effect size estimates (ratios). Estimates that are significantly different
from the true value (alpha = 0.05) are marked in orange, others are marked in blue.
</p>


<h3>Value</h3>

<p>A Ggplot object. Use the <code>ggsave</code> function to save to file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotTrueAndObserved(data$logRr, data$seLogRr, data$trueLogRr)

</code></pre>

<hr>
<h2 id='sccs'>Incidence rate ratios from Self-Controlled Case Series</h2><span id='topic+sccs'></span>

<h3>Description</h3>

<p>Incidence rate ratios from Self-Controlled Case Series
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sccs)
</code></pre>


<h3>Format</h3>

<p>A data frame with 46 rows and 4 variables: </p>
 <dl>
<dt>drugName</dt><dd><p>Name of the drug</p>
</dd>
<dt>groundTruth</dt><dd><p>Whether the drug is a positive (1) or negative (0) control</p>
</dd> <dt>logRr</dt><dd><p>The log
of the incidence rate ratio</p>
</dd> <dt>seLogRr</dt><dd><p>The standard error of the log of the incidence rate
ratio</p>
</dd> </dl>



<h3>Details</h3>

<p>A dataset containing the incidence rate ratios (and standard errors) produced using a
Self-Controlled Case Series (SCCS) design. The outcome is upper GI bleeding, the drug of interest
(groundTruth = 1) is sertraline. Also included are 45 negative control drugs, for which we believe
there to be no causal relation with upper GI bleeding. We used a database of medical records from
general practices in the USA, the General Electric (GE) Centricity database, which contains data on
11.2 million subjects. We restricted on study period (start of 1990 through November 2003), age
requirements (18 years or older), available time prior to event (180 days), and risk definition
window (30 days following the prescription). Time 30 days prior to the first prescription was
removed to account for possible contra-indications. Cases of upper GI bleeding were identified on
the basis of the occurrence of ICD-9 diagnosis codes in the problem list. These codes pertain to
esophageal, gastric, duodenal, peptic, and gastrojejunal ulceration, perforation, and hemorrhage,
as well as gastritis and non-specific gastrointestinal hemorrhage. For more information on this set
see Schuemie et al (2014).
</p>


<h3>References</h3>

<p>Schuemie MJ, Ryan PB, Dumouchel W, Suchard MA, Madigan D. Interpreting observational studies: why
empirical calibration is needed to correct p-values. Statistics in Medicine 33(2):209-18,2014
</p>

<hr>
<h2 id='simulateControls'>Simulate (negative) controls</h2><span id='topic+simulateControls'></span>

<h3>Description</h3>

<p>Simulate (negative) controls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateControls(
  n = 50,
  mean = 0,
  sd = 0.1,
  seLogRr = runif(n, min = 0.01, max = 0.2),
  trueLogRr = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateControls_+3A_n">n</code></td>
<td>
<p>Number of controls to simulate.</p>
</td></tr>
<tr><td><code id="simulateControls_+3A_mean">mean</code></td>
<td>
<p>The mean of the error distribution (on the log RR scale).</p>
</td></tr>
<tr><td><code id="simulateControls_+3A_sd">sd</code></td>
<td>
<p>The standard deviation of the error distribution (on the log RR scale).</p>
</td></tr>
<tr><td><code id="simulateControls_+3A_selogrr">seLogRr</code></td>
<td>
<p>The standard error of the log of the relative risk. This is recycled for the
controls. The default is to sample these from a uniform distribution.</p>
</td></tr>
<tr><td><code id="simulateControls_+3A_truelogrr">trueLogRr</code></td>
<td>
<p>The true relative risk (on the log scale) used to generate these controls.  This
is recycled for the controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generate point estimates given known true effect sizes and standard errors
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateControls(n = 50 * 3, mean = 0.25, sd = 0.25, trueLogRr = log(c(1, 2, 4)))
plotTrueAndObserved(data$logRr, data$seLogRr, data$trueLogRr)

</code></pre>

<hr>
<h2 id='simulateMaxSprtData'>Simulate survival data for MaxSPRT computation</h2><span id='topic+simulateMaxSprtData'></span>

<h3>Description</h3>

<p>Simulate survival data for MaxSPRT computation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateMaxSprtData(
  n = 10000,
  pExposure = 0.5,
  backgroundHazard = 0.001,
  tar = 10,
  nullMu = 0.2,
  nullSigma = 0.2,
  maxT = 100,
  looks = 10,
  numberOfNegativeControls = 50,
  numberOfPositiveControls = 1,
  positiveControlEffectSize = 4
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateMaxSprtData_+3A_n">n</code></td>
<td>
<p>Number of subjects.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_pexposure">pExposure</code></td>
<td>
<p>Probability of being in target cohort.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_backgroundhazard">backgroundHazard</code></td>
<td>
<p>Background hazard (risk of the outcome per day).</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_tar">tar</code></td>
<td>
<p>Time at risk for each exposure</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_nullmu">nullMu</code></td>
<td>
<p>Null distribution mean (at log HR scale)</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_nullsigma">nullSigma</code></td>
<td>
<p>Null distribution SD (at log HR scale)</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_maxt">maxT</code></td>
<td>
<p>Maximum time to simulate.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_looks">looks</code></td>
<td>
<p>Number of (evenly spaced) looks at the data.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_numberofnegativecontrols">numberOfNegativeControls</code></td>
<td>
<p>Number of negative controls to simulate.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_numberofpositivecontrols">numberOfPositiveControls</code></td>
<td>
<p>Number of positive controls to simulate.</p>
</td></tr>
<tr><td><code id="simulateMaxSprtData_+3A_positivecontroleffectsize">positiveControlEffectSize</code></td>
<td>
<p>The true effect size of the positive controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulate survival data for negative and positive controls. The data provides multiple looks at data accruing over time, with
each look having more data than the one before. Systematic error for each outcome is drawn from the prespecified null distribution.
</p>
<p>The outcome IDs are assigned sequentially starting at 1, with the first IDs used for the negative controls, and the latter IDs used
for the positive controls.
</p>


<h3>Value</h3>

<p>A data frame with 5 variables: </p>
 <dl>
<dt>time</dt><dd><p>Time from index date to either the event or
end of observation, whichever came first</p>
</dd> <dt>outcome</dt><dd><p>Whether the outcome occurred (1) or not (0)</p>
</dd> <dt>exposure</dt><dd><p>Whether
the subject was exposed (TRUE) or not (FALSE)</p>
</dd> <dt>lookTime</dt><dd><p>The time point when the look occurred. </p>
</dd> <dt>outcomeId</dt><dd><p>A unique
identifier for data corresponding to a single outcome. Lower IDs indicate negative controls, higher IDs indicate the positive control</p>
</dd> </dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- simulateMaxSprtData(n = 1000)
head(data)

</code></pre>

<hr>
<h2 id='southworthReplication'>Relative risks from an unadjusted new-user cohort design</h2><span id='topic+southworthReplication'></span>

<h3>Description</h3>

<p>Relative risks from an unadjusted new-user cohort design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(southworthReplication)
</code></pre>


<h3>Format</h3>

<p>A data frame with 174 rows and 4 variables: </p>
 <dl>
<dt>outcomeName</dt><dd><p>Name of the outcome</p>
</dd>
<dt>trueLogRr</dt><dd><p>The log of the true effect size. Only provided for negative and positive controls,
is NA for the outcome of interest (GI bleeding).</p>
</dd> <dt>logRr</dt><dd><p>The log of the incidence rate ratio</p>
</dd> <dt>seLogRr</dt><dd>
<p>The standard error of the log of the incidence rate ratio</p>
</dd> </dl>



<h3>Details</h3>

<p>A dataset containing the incidence rate ratios (and standard errors) produced using a new-user
cohort design that compares new-users of dabigatran to new-users of warfarin for the outcome of
GI hemorrhage. The dataset includes estimates both for the outcome of interest as well as negative
and positive control outcomes. Subjects are required to have 183 days of continuous observation prior to
initiating treatment, a prior diagnosis of atrial fibrillation, and are required to have no prior
exposure to either dabigatran or warfarin. The study computes an incidence rate ratio without
any adjustment for confounders. Time at risk is defined as the time on the drug. The original
study (Southworth 2013) uses the 'Mini-Sentinel Database'. For our replication, we use the Optum
databases since both databases are US insurance claims databases. We analyzed 5,982
dabigatran-exposed and 19,155 warfarin-exposed subjects. For more information on this set see
Schuemie et al (2017).
</p>


<h3>References</h3>

<p>Schuemie MJ, Hripcsak G, Ryan PB, Madigan D, Suchard MA. Empirical confidence interval calibration
for population-level effect estimation studies in observational healthcare data. Proc Natl Acad Sci
U S A. 2018 Mar 13;115(11):2571-2577
</p>
<p>Southworth MR, Reichman ME, Unger EF. Dabigatran and postmarketing reports of bleeding. N Engl
J Med 368(14):1272-1274, 2013
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
