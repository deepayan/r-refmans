<!DOCTYPE html><html><head><title>Help for package tempted</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tempted}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregate_feature'><p>Aggregate features using feature loadings</p></a></li>
<li><a href='#bernoulli_kernel'><p>Caculate the Bernoulli kernel</p></a></li>
<li><a href='#count_table'><p>OTU read count table from the ECAM data</p></a></li>
<li><a href='#est_test_subject'><p>Estimate subject loading of testing data</p></a></li>
<li><a href='#format_tempted'><p>Format data table into the input of tempted</p></a></li>
<li><a href='#meta_table'><p>Meta data table from the ECAM data</p></a></li>
<li><a href='#plot_feature_summary'><p>Plot nonparametric smoothed mean and error bands of features versus time</p></a></li>
<li><a href='#plot_metafeature'><p>Plot nonparametric smoothed mesan and error bands of meta features versus time</p></a></li>
<li><a href='#plot_time_loading'><p>Plot the temporal loading functions</p></a></li>
<li><a href='#processed_table'><p>Central-log-ratio (clr) transformed OTU table from the ECAM data</p></a></li>
<li><a href='#ratio_feature'><p>Take log ratio of the abundance of top features over bottom features</p></a></li>
<li><a href='#svd_centralize'><p>Remove the mean structure of the temporal tensor</p></a></li>
<li><a href='#tdenoise'><p>Calculate the de-noised temporal tensor</p></a></li>
<li><a href='#tempted'><p>Decomposition of temporal tensor</p></a></li>
<li><a href='#tempted_all'><p>Run all major functions of tempted</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Temporal Tensor Decomposition, a Dimensionality Reduction Tool
for Longitudinal Multivariate Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-1-9</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0), np (&ge; 0.60-17), ggplot2 (&ge; 3.4.0), methods (&ge;
4.2.1)</td>
</tr>
<tr>
<td>Author:</td>
<td>Pixu Shi</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pixu Shi &lt;pixu.shi@duke.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    TEMPoral TEnsor Decomposition (TEMPTED), is a dimension reduction method for multivariate longitudinal data with varying temporal sampling. It formats the data into a temporal tensor and decomposes it into a summation of low-dimensional components, each consisting of a subject loading vector, a feature loading vector, and a continuous temporal loading function. These loadings provide a low-dimensional representation of subjects or samples and can be used to identify features associated with clusters of subjects or samples. TEMPTED provides the flexibility of allowing subjects to have different temporal sampling, so time points do not need to be binned, and missing time points do not need to be imputed.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/pixushi/tempted">https://github.com/pixushi/tempted</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-09 22:17:40 UTC; pixushi</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-11 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregate_feature'>Aggregate features using feature loadings</h2><span id='topic+aggregate_feature'></span>

<h3>Description</h3>

<p>This function aggregate the features into &quot;meta features&quot; by
calculating a weighted summation of the features using feature loading of each component as weights.
It can also aggregate features by using the combination of multiple components by ranking the features
by a linear combination of feature loadings from multiple components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_feature(
  res_tempted,
  mean_svd = NULL,
  datlist,
  pct = 1,
  contrast = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_feature_+3A_res_tempted">res_tempted</code></td>
<td>
<p>Output of <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="aggregate_feature_+3A_mean_svd">mean_svd</code></td>
<td>
<p>Output of <code><a href="#topic+svd_centralize">svd_centralize</a></code>.</p>
</td></tr>
<tr><td><code id="aggregate_feature_+3A_datlist">datlist</code></td>
<td>
<p>Output of <code><a href="#topic+format_tempted">format_tempted</a></code>, the original temporal tensor that will be aggregated.</p>
</td></tr>
<tr><td><code id="aggregate_feature_+3A_pct">pct</code></td>
<td>
<p>The percent of features to aggregate,
features ranked by absolute value of the feature loading of each component.
Default is 1, which means 100% of features are aggregated.
Setting <code>pct=0.01</code> means top 1% of features is aggregated,
where features are ranked in absolute value of feature loading of each component.</p>
</td></tr>
<tr><td><code id="aggregate_feature_+3A_contrast">contrast</code></td>
<td>
<p>A matrix choosing how components are combined,
each column is a contrast of length r and used to calculate the linear combination of
the feature loadings of r components.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of results.
</p>

<dl>
<dt>metafeature_aggregate</dt><dd><p>The meta feature obtained by aggregating the observed temporal tensor. It is a data.frame with four columns: &quot;value&quot; for the meta feature values, &quot;subID&quot; for the subject ID, &quot;timepoint&quot; for the time points, and &quot;PC&quot; indicating which component was used to construct the meta feature.</p>
</dd>
<dt>metafeature_aggregate_est</dt><dd><p>The meta feature obtained by aggregating the denoised temporal tensor. It has the same structure as <code>metafeature_aggregate</code>.</p>
</dd>
<dt>contrast</dt><dd><p>The contrast used to linearly combine the components from input.</p>
</dd>
<dt>toppct</dt><dd><p>A matrix of TRUE/FALSE indicating which features are aggregated in each component and contrast.</p>
</dd>
</dl>



<h3>References</h3>

<p>Shi P, Martino C, Han R, Janssen S, Buck G, Serrano M, Owzar K, Knight R, Shenhav L, Zhang AR. (2023) <em>Time-Informed Dimensionality Reduction for Longitudinal Microbiome Studies</em>. bioRxiv. doi: 10.1101/550749. <a href="https://www.biorxiv.org/content/10.1101/550749">https://www.biorxiv.org/content/10.1101/550749</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Take a subset of the samples so the example runs faster

# Here we are taking samples from the odd months
sub_sample &lt;- rownames(meta_table)[(meta_table$day_of_life%/%12)%%2==1]
count_table_sub &lt;- count_table[sub_sample,]
processed_table_sub &lt;- processed_table[sub_sample,]
meta_table_sub &lt;- meta_table[sub_sample,]

datlist &lt;- format_tempted(count_table_sub,
                          meta_table_sub$day_of_life,
                          meta_table_sub$studyid,
                          pseudo=0.5,
                          transform="clr")

mean_svd &lt;- svd_centralize(datlist, r=1)

res_tempted &lt;- tempted(mean_svd$datlist, r=2, smooth=1e-5)

contrast &lt;- matrix(c(1/2,1), 2, 1)

res_aggregate &lt;- aggregate_feature(res_tempted,
                                   mean_svd,
                                   datlist,
                                   pct=1,
                                   contrast=contrast)

# plot the aggregated features


group &lt;- unique(meta_table[, c("studyid", "delivery")])

plot_metafeature(res_aggregate$metafeature_aggregate, group, bws=30)

</code></pre>

<hr>
<h2 id='bernoulli_kernel'>Caculate the Bernoulli kernel</h2><span id='topic+bernoulli_kernel'></span>

<h3>Description</h3>

<p>This function is used to calculate the kernel matrix for the
RKHS regression that iteratively updates the temporal loading function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bernoulli_kernel(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bernoulli_kernel_+3A_x">x</code>, <code id="bernoulli_kernel_+3A_y">y</code></td>
<td>
<p>Two values between which the Bernoulli kernel is calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The calculated kernel between <code>x</code> and <code>y</code>.
</p>


<h3>References</h3>

<p>Han, R., Shi, P. and Zhang, A.R. (2023) <em>Guaranteed functional tensor singular value decomposition</em>. Journal of the American Statistical Association, pp.1-13. doi: 10.1080/01621459.2022.2153689.
</p>

<hr>
<h2 id='count_table'>OTU read count table from the ECAM data</h2><span id='topic+count_table'></span>

<h3>Description</h3>

<p>OTU read count table from the ECAM data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_table
</code></pre>


<h3>Format</h3>

<p>A data.frame with rows representing samples and matching with data.frame <code>meta_table</code>
and columns representing microbial features (i.e. OTUs). Each entry is a read count.
</p>


<h3>References</h3>

<p>Bokulich, Nicholas A., et al. &quot;Antibiotics, birth mode, and diet shape microbiome maturation during early life.&quot; Science translational medicine 8.343 (2016): 343ra82-343ra82.
</p>

<hr>
<h2 id='est_test_subject'>Estimate subject loading of testing data</h2><span id='topic+est_test_subject'></span>

<h3>Description</h3>

<p>This function estimates the subject loading of the testing data
based on feature and temporal loading from training data,
so that both the testing data and training data have the same dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_test_subject(datlist, res_tempted, mean_svd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_test_subject_+3A_datlist">datlist</code></td>
<td>
<p>Testing data formatted into datlist in the same fashion as the training data.
The same transformation needs to be used for both training and testing data.</p>
</td></tr>
<tr><td><code id="est_test_subject_+3A_res_tempted">res_tempted</code></td>
<td>
<p>Result from <code><a href="#topic+tempted">tempted</a></code> ran on the training data.</p>
</td></tr>
<tr><td><code id="est_test_subject_+3A_mean_svd">mean_svd</code></td>
<td>
<p>Result from <code><a href="#topic+svd_centralize">svd_centralize</a></code> ran on the training data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>estimated subject loading of testing data
</p>


<h3>References</h3>

<p>Shi P, Martino C, Han R, Janssen S, Buck G, Serrano M, Owzar K, Knight R, Shenhav L, Zhang AR. (2023) <em>Time-Informed Dimensionality Reduction for Longitudinal Microbiome Studies</em>. bioRxiv. doi: 10.1101/550749. <a href="https://www.biorxiv.org/content/10.1101/550749">https://www.biorxiv.org/content/10.1101/550749</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Take a subset of the samples so the example runs faster

# Here we are taking samples from the odd months
sub_sample &lt;- rownames(meta_table)[(meta_table$day_of_life%/%12)%%2==1]
count_table_sub &lt;- count_table[sub_sample,]
processed_table_sub &lt;- processed_table[sub_sample,]
meta_table_sub &lt;- meta_table[sub_sample,]

# split the example data into training and testing

id_test &lt;- meta_table_sub$studyid=="2"

count_train &lt;- count_table_sub[!id_test,]
meta_train &lt;- meta_table_sub[!id_test,]

count_test &lt;- count_table_sub[id_test,]
meta_test &lt;- meta_table_sub[id_test,]

# run tempted on training data

datlist_train &lt;- format_tempted(count_train,
                                meta_train$day_of_life,
                                meta_train$studyid,
                                threshold=0.95,
                                pseudo=0.5,
                                transform="clr")

mean_svd_train &lt;- svd_centralize(datlist_train, r=1)

res_tempted_train &lt;- tempted(mean_svd_train$datlist,
r=2, smooth=1e-5)

# get the overlapping features

count_test &lt;- count_test[,rownames(datlist_train[[1]])[-1]]

datlist_test &lt;- format_tempted(count_test,
                               meta_test$day_of_life,
                               meta_test$studyid,
                               threshold=1,
                               pseudo=0.5,
                               transform="clr")

# estimate the subject loading of the testing subject

sub_test &lt;- est_test_subject(datlist_test, res_tempted_train, mean_svd_train)

# train logistic regression classifier on training subjects

metauni &lt;- unique(meta_table_sub[,c("studyid", "delivery")])
rownames(metauni) &lt;- metauni$studyid
Atrain &lt;- as.data.frame(res_tempted_train$A_hat)
Atrain$delivery &lt;- metauni[rownames(Atrain),"delivery"]=="Cesarean"
glm_train &lt;- glm(delivery ~ PC1+PC2,
                 data=Atrain, family=binomial(link="logit"))
summary(glm_train)

# predict the label of testing subject, whose true label is "Cesarean"

predict(glm_train, newdata=as.data.frame(sub_test), type="response")

</code></pre>

<hr>
<h2 id='format_tempted'>Format data table into the input of tempted</h2><span id='topic+format_tempted'></span>

<h3>Description</h3>

<p>This function applies a variety of transformations to the read counts and
format the sample by feature table and meta data into a data list
that can be used as the input of <code><a href="#topic+tempted">tempted</a></code> and <code><a href="#topic+svd_centralize">svd_centralize</a></code>.
For data that are not read counts, or data that are not microbiome data,
the user can apply their desired transformation to the data before formatting into list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_tempted(
  featuretable,
  timepoint,
  subjectID,
  threshold = 0.95,
  pseudo = NULL,
  transform = "clr"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_tempted_+3A_featuretable">featuretable</code></td>
<td>
<p>A sample by feature matrix.</p>
</td></tr>
<tr><td><code id="format_tempted_+3A_timepoint">timepoint</code></td>
<td>
<p>The time stamp of each sample, matched with the rows of <code>featuretable</code>.</p>
</td></tr>
<tr><td><code id="format_tempted_+3A_subjectid">subjectID</code></td>
<td>
<p>The subject ID of each sample, matched with the rows of <code>featuretable</code>.</p>
</td></tr>
<tr><td><code id="format_tempted_+3A_threshold">threshold</code></td>
<td>
<p>A threshold for feature filtering for microbiome data.
Features with zero value percentage &gt; threshold will be excluded. Default is 0.95.</p>
</td></tr>
<tr><td><code id="format_tempted_+3A_pseudo">pseudo</code></td>
<td>
<p>A small number to add to all the counts before
normalizing into proportions and log transformation.
Default is 1/2 of the smallest non-zero value that is specific for each sample.
This pseudo count is added for <code>transform=c("logcomp", "clr", "logit")</code>.</p>
</td></tr>
<tr><td><code id="format_tempted_+3A_transform">transform</code></td>
<td>
<p>The transformation applied to the data.
<code>"logcomp"</code> for log of compositions.
<code>"comp"</code> for compositions.
<code>"ast"</code> for arcsine squared transformation.
<code>"clr"</code> for central log ratio transformation.
<code>"lfb"</code> for log 2 fold change over baseline (first time point) transformation.
<code>"logit"</code> for logit transformation.
<code>"none"</code> for no transformation.
Default <code>transform="clr"</code> is recommended for microbiome data.
For data that are already transformed, use <code>transform="none"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A length n list of matrices as the input of <code><a href="#topic+tempted">tempted</a></code> and <code><a href="#topic+svd_centralize">svd_centralize</a></code>.  Each matrix represents a subject, with columns representing samples from this subject, the first row representing the sampling time points, and the following rows representing the feature values.
</p>


<h3>See Also</h3>

<p>Examples can be found in <code><a href="#topic+tempted">tempted</a></code>.
</p>

<hr>
<h2 id='meta_table'>Meta data table from the ECAM data</h2><span id='topic+meta_table'></span>

<h3>Description</h3>

<p>Meta data table from the ECAM data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meta_table
</code></pre>


<h3>Format</h3>

<p>A data.frame with rows representing samples and matching with data.frame <code>count_table</code> and <code>processed_table</code>
and three columns:
</p>

<dl>
<dt>studyid</dt><dd><p>character denoting the subject ID of the infants.</p>
</dd>
<dt>delivery</dt><dd><p>character denoting the delivery mode of the infants.</p>
</dd>
<dt>day_of_life</dt><dd><p>character denoting the age of infants measured in days when microbiome sample was taken.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bokulich, Nicholas A., et al. &quot;Antibiotics, birth mode, and diet shape microbiome maturation during early life.&quot; Science translational medicine 8.343 (2016): 343ra82-343ra82.
</p>

<hr>
<h2 id='plot_feature_summary'>Plot nonparametric smoothed mean and error bands of features versus time</h2><span id='topic+plot_feature_summary'></span>

<h3>Description</h3>

<p>This is a handy function to plot the smoothed mean and error bands for multiple features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_feature_summary(
  feature_mat,
  time_vec,
  group_vec,
  coverage = 0.95,
  bws = NULL,
  nrow = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_feature_summary_+3A_feature_mat">feature_mat</code></td>
<td>
<p>A sample by feature matrix. Each feature will be plotted separately as a facet.
The features can be original features, meta features, log ratios, or any variables of interest.</p>
</td></tr>
<tr><td><code id="plot_feature_summary_+3A_time_vec">time_vec</code></td>
<td>
<p>A vector of time points matched to the rows of <code>feature_mat</code>.</p>
</td></tr>
<tr><td><code id="plot_feature_summary_+3A_group_vec">group_vec</code></td>
<td>
<p>A vector of factor variable indicating the group membership
of samples matched to the rows of <code>feature_mat</code>.</p>
</td></tr>
<tr><td><code id="plot_feature_summary_+3A_coverage">coverage</code></td>
<td>
<p>The coverage rate for the error band. Default is 0.95.</p>
</td></tr>
<tr><td><code id="plot_feature_summary_+3A_bws">bws</code></td>
<td>
<p>The smoothness parameter for the smoothing lines and error bands.
A larger value means a smoother line.
Default is NULL and calculated by function <code>np::npreg()</code>.</p>
</td></tr>
<tr><td><code id="plot_feature_summary_+3A_nrow">nrow</code></td>
<td>
<p>The number of rows to plot the features used in function <code>ggplot2::facet_wrap()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot the summary of selected features

feat.names &lt;- c("OTU4447072", "OTU4467447")

proportion_table &lt;- count_table/rowSums(count_table)

plot_feature_summary(proportion_table[,feat.names],
                     meta_table$day_of_life,
                     meta_table$delivery,
                     bws=30)
</code></pre>

<hr>
<h2 id='plot_metafeature'>Plot nonparametric smoothed mesan and error bands of meta features versus time</h2><span id='topic+plot_metafeature'></span>

<h3>Description</h3>

<p>This function plot the smoothed mean and error band of meta features
grouped by a factor variable provided by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_metafeature(metafeature, group, coverage = 0.95, bws = NULL, nrow = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_metafeature_+3A_metafeature">metafeature</code></td>
<td>
<p><code>metafeature_ratio</code> from the output of <code><a href="#topic+ratio_feature">ratio_feature</a></code> and
<code><a href="#topic+tempted_all">tempted_all</a></code>,
<code>metafeature_aggregate</code> from the output of
<code><a href="#topic+ratio_feature">ratio_feature</a></code> and <code><a href="#topic+tempted_all">tempted_all</a></code>,
or <code>metafeature_aggregate_est</code> from the output of <code><a href="#topic+ratio_feature">ratio_feature</a></code>.</p>
</td></tr>
<tr><td><code id="plot_metafeature_+3A_group">group</code></td>
<td>
<p>A subject by 2 data.frame with the first column for subject ID and second column for group membership.</p>
</td></tr>
<tr><td><code id="plot_metafeature_+3A_coverage">coverage</code></td>
<td>
<p>The coverage rate for the error band. Default is 0.95.</p>
</td></tr>
<tr><td><code id="plot_metafeature_+3A_bws">bws</code></td>
<td>
<p>The smoothness parameter for the smoothing lines and error bands.
A larger value means a smoother line.
Default is NULL and calculated by function <code>np::npreg()</code>.</p>
</td></tr>
<tr><td><code id="plot_metafeature_+3A_nrow">nrow</code></td>
<td>
<p>The number of rows to plot the features used in function <code>ggplot2::facet_wrap()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>See Also</h3>

<p>Examples can be found in <code><a href="#topic+tempted_all">tempted_all</a></code>, <code><a href="#topic+ratio_feature">ratio_feature</a></code> and <code><a href="#topic+aggregate_feature">aggregate_feature</a></code>.
</p>

<hr>
<h2 id='plot_time_loading'>Plot the temporal loading functions</h2><span id='topic+plot_time_loading'></span>

<h3>Description</h3>

<p>This function uses <code>ggplot2::geom_line()</code> in ggplot2 to plot the temporal loading functions from <code><a href="#topic+tempted">tempted</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_time_loading(res, r = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_time_loading_+3A_res">res</code></td>
<td>
<p>Output of function <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="plot_time_loading_+3A_r">r</code></td>
<td>
<p>The number of components to plot. By default all the components estimated by <code><a href="#topic+tempted">tempted</a></code> will be plotted.</p>
</td></tr>
<tr><td><code id="plot_time_loading_+3A_...">...</code></td>
<td>
<p>Arguments to put in <code>ggplot2::geom_line(aes(...))</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An ggplot2 object.
</p>


<h3>See Also</h3>

<p>Examples can be found in <code><a href="#topic+tempted_all">tempted_all</a></code> and <code><a href="#topic+tempted">tempted</a></code>.
</p>

<hr>
<h2 id='processed_table'>Central-log-ratio (clr) transformed OTU table from the ECAM data</h2><span id='topic+processed_table'></span>

<h3>Description</h3>

<p>Central-log-ratio (clr) transformed OTU table from the ECAM data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processed_table
</code></pre>


<h3>Format</h3>

<p>A data.frame with rows representing samples and matching with data.frame <code>meta_table</code>
and columns representing microbial features (i.e. OTUs).
Entries do not need to be transformed, and will be directly used by <code><a href="#topic+tempted">tempted</a></code>.
This data.frame is used to illustrate how <code><a href="#topic+tempted">tempted</a></code> can be used for
general form of multivariate longitudinal data already preprocessed by user.
</p>


<h3>References</h3>

<p>Bokulich, Nicholas A., et al. &quot;Antibiotics, birth mode, and diet shape microbiome maturation during early life.&quot; Science translational medicine 8.343 (2016): 343ra82-343ra82.
</p>

<hr>
<h2 id='ratio_feature'>Take log ratio of the abundance of top features over bottom features</h2><span id='topic+ratio_feature'></span>

<h3>Description</h3>

<p>Top and bottom ranking features are picked based on feature loadings (and their contrasts).
The log ratio abundance of the top ranking features over the bottom ranking features is produced as the main result.
This function and its result is designed for longitudinal microbiome data,
and may not be meaningful for other type of temporal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratio_feature(
  res_tempted,
  datlist,
  pct = 0.05,
  absolute = FALSE,
  contrast = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ratio_feature_+3A_res_tempted">res_tempted</code></td>
<td>
<p>Output of <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="ratio_feature_+3A_datlist">datlist</code></td>
<td>
<p>Output of <code>format_tempted(, transform="none")</code>, the temporal tensor that include the raw read counts.</p>
</td></tr>
<tr><td><code id="ratio_feature_+3A_pct">pct</code></td>
<td>
<p>The percent of features to sum up. Default is 0.05, i.e. 5%.</p>
</td></tr>
<tr><td><code id="ratio_feature_+3A_absolute">absolute</code></td>
<td>
<p><code>absolute = TRUE</code> means features are ranked by the absolute value of feature loadings,
and the top <code>pct</code> percent of features are picked.
<code>absolute = FALSE</code> means features are ranked by the original value of feature loadings,
and the top and bottom <code>pct</code> percent of features are picked.
Then ratio is taken as the abundance of the features with positive loading
over the abundance of the features with negative loading.</p>
</td></tr>
<tr><td><code id="ratio_feature_+3A_contrast">contrast</code></td>
<td>
<p>A matrix choosing how components are combined,
each column is a contrast of length r and used to calculate the linear combination of
the feature loadings of r components.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of results:
</p>

<dl>
<dt>metafeature_ratio</dt><dd><p>The log ratio abundance of the top over bottom ranking features. It is a data.frame with five columns: &quot;value&quot; for the log ratio values, &quot;subID&quot; for the subject ID, and &quot;timepoint&quot; for the time points, and &quot;PC&quot; indicating which component was used to construct the meta feature.</p>
</dd>
<dt>contrast</dt><dd><p>The contrast used to linearly combine the components from input.</p>
</dd>
<dt>toppct</dt><dd><p>A matrix of TRUE/FALSE indicating which features are ranked top in each component (and contrast) and used as the numerator of the log ratio.</p>
</dd>
<dt>bottompct</dt><dd><p>A matrix of TRUE/FALSE indicating which features are ranked bottom in each component (and contrast) and used as the denominator of the log ratio.</p>
</dd>
</dl>



<h3>References</h3>

<p>Shi P, Martino C, Han R, Janssen S, Buck G, Serrano M, Owzar K, Knight R, Shenhav L, Zhang AR. (2023) <em>Time-Informed Dimensionality Reduction for Longitudinal Microbiome Studies</em>. bioRxiv. doi: 10.1101/550749. <a href="https://www.biorxiv.org/content/10.1101/550749">https://www.biorxiv.org/content/10.1101/550749</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Take a subset of the samples so the example runs faster

# Here we are taking samples from the odd months
sub_sample &lt;- rownames(meta_table)[(meta_table$day_of_life%/%12)%%2==1]
count_table_sub &lt;- count_table[sub_sample,]
processed_table_sub &lt;- processed_table[sub_sample,]
meta_table_sub &lt;- meta_table[sub_sample,]

datlist &lt;- format_tempted(count_table_sub,
                          meta_table_sub$day_of_life,
                          meta_table_sub$studyid,
                          pseudo=0.5,
                          transform="clr")

mean_svd &lt;- svd_centralize(datlist, r=1)

res_tempted &lt;- tempted(mean_svd$datlist, r=2, smooth=1e-5)

datalist_raw &lt;- format_tempted(count_table_sub, meta_table_sub$day_of_life, meta_table_sub$studyid,
transform="none")

contrast &lt;- cbind(c(1,1), c(1,-1))

res_ratio &lt;- ratio_feature(res_tempted, datalist_raw, pct=0.1,
absolute=FALSE, contrast=contrast)

group &lt;- unique(meta_table[, c("studyid", "delivery")])

# plot the log ratios

plot_metafeature(res_ratio$metafeature_ratio, group, bws=30)

</code></pre>

<hr>
<h2 id='svd_centralize'>Remove the mean structure of the temporal tensor</h2><span id='topic+svd_centralize'></span>

<h3>Description</h3>

<p>This function first average the feature value of all time points for each subject to form a subject by feature matrix.
Next, it performs a singular value decomposition of this matrix and construct the matrix's rank-r approximation.
Then, it subtracts this rank-r subject by feature matrix from the temporal tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svd_centralize(datlist, r = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svd_centralize_+3A_datlist">datlist</code></td>
<td>
<p>A length n list of matrices.
Each matrix represents a subject,
with columns representing samples from this subject,
the first row representing the sampling time points,
and the following rows representing the feature values.</p>
</td></tr>
<tr><td><code id="svd_centralize_+3A_r">r</code></td>
<td>
<p>The number of ranks in the mean structure. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of results.
</p>

<dl>
<dt>datlist</dt><dd><p>The new temporal tensor after mean structure is removed.</p>
</dd>
<dt>A_tilde</dt><dd><p>The subject singular vector of the mean structure, a subject by r matrix.</p>
</dd>
<dt>B_tilde</dt><dd><p>The feature singular vector of the mean structure, a feature by r matrix.</p>
</dd>
<dt>lambda_tilde</dt><dd><p>The singular value of the mean structure, a length r vector.</p>
</dd>
</dl>



<h3>References</h3>

<p>Shi P, Martino C, Han R, Janssen S, Buck G, Serrano M, Owzar K, Knight R, Shenhav L, Zhang AR. (2023) <em>Time-Informed Dimensionality Reduction for Longitudinal Microbiome Studies</em>. bioRxiv. doi: 10.1101/550749. <a href="https://www.biorxiv.org/content/10.1101/550749">https://www.biorxiv.org/content/10.1101/550749</a>.
</p>


<h3>See Also</h3>

<p>Examples can be found in <code><a href="#topic+tempted">tempted</a></code>.
</p>

<hr>
<h2 id='tdenoise'>Calculate the de-noised temporal tensor</h2><span id='topic+tdenoise'></span>

<h3>Description</h3>

<p>This function constructs a de-noised version of the temporal tensor
using the low-rank components obtained by <code><a href="#topic+svd_centralize">svd_centralize</a></code> <code><a href="#topic+tempted">tempted</a></code> and uses the loadings to
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tdenoise(res_tempted, mean_svd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tdenoise_+3A_res_tempted">res_tempted</code></td>
<td>
<p>Output of tempted</p>
</td></tr>
<tr><td><code id="tdenoise_+3A_mean_svd">mean_svd</code></td>
<td>
<p>Output of svd_centralize</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The de-noised functional tensor
</p>

<hr>
<h2 id='tempted'>Decomposition of temporal tensor</h2><span id='topic+tempted'></span>

<h3>Description</h3>

<p>This is the main function of tempted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tempted(
  datlist,
  r = 3,
  smooth = 1e-06,
  interval = NULL,
  resolution = 101,
  maxiter = 20,
  epsilon = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tempted_+3A_datlist">datlist</code></td>
<td>
<p>A length n list of matrices.
Each matrix represents a subject,
with columns representing samples from this subject,
the first row representing the sampling time points,
and the following rows representing the feature values.</p>
</td></tr>
<tr><td><code id="tempted_+3A_r">r</code></td>
<td>
<p>Number of components to decompose into, i.e. rank of the CP type decomposition.
Default is set to 3.</p>
</td></tr>
<tr><td><code id="tempted_+3A_smooth">smooth</code></td>
<td>
<p>Smoothing parameter for RKHS norm.
Larger means smoother temporal loading functions. Default is set to be 1e-8.
Value can be adjusted depending on the dataset by checking the smoothness of the estimated temporal loading function in plot.</p>
</td></tr>
<tr><td><code id="tempted_+3A_interval">interval</code></td>
<td>
<p>The range of time points to ran the decomposition for.
Default is set to be the range of all observed time points.
User can set it to be a shorter interval than the observed range.</p>
</td></tr>
<tr><td><code id="tempted_+3A_resolution">resolution</code></td>
<td>
<p>Number of time points to evaluate the value of the temporal loading function.
Default is set to 101. It does not affect the subject or feature loadings.</p>
</td></tr>
<tr><td><code id="tempted_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iteration. Default is 20.</p>
</td></tr>
<tr><td><code id="tempted_+3A_epsilon">epsilon</code></td>
<td>
<p>Convergence criteria for difference between iterations. Default is 1e-4.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimations of the loadings.
</p>

<dl>
<dt>A_hat</dt><dd><p>Subject loading, a subject by r matrix.</p>
</dd>
<dt>B_hat</dt><dd><p>Feature loading, a feature by r matrix.</p>
</dd>
<dt>Phi_hat</dt><dd><p>Temporal loading function, a resolution by r matrix.</p>
</dd>
<dt>time_Phi</dt><dd><p>The time points where the temporal loading function is evaluated.</p>
</dd>
<dt>Lambda</dt><dd><p>Eigen value, a length r vector.</p>
</dd>
<dt>r_square</dt><dd><p>Variance explained by each component. This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using individual components.</p>
</dd>
<dt>accum_r_square</dt><dd><p>Variance explained by the first few components accumulated. This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using the first few components.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># Take a subset of the samples so the example runs faster

# Here we are taking samples from the odd months
sub_sample &lt;- rownames(meta_table)[(meta_table$day_of_life%/%12)%%2==1]
count_table_sub &lt;- count_table[sub_sample,]
processed_table_sub &lt;- processed_table[sub_sample,]
meta_table_sub &lt;- meta_table[sub_sample,]

# for count data from longitudinal microbiome studies

datlist &lt;- format_tempted(count_table_sub,
                          meta_table_sub$day_of_life,
                          meta_table_sub$studyid,
                          pseudo=0.5,
                          transform="clr")

mean_svd &lt;- svd_centralize(datlist, r=1)

res_tempted &lt;- tempted(mean_svd$datlist, r=2, smooth=1e-5)

# for preprocessed data that do not need to be transformed

datlist &lt;- format_tempted(processed_table_sub,
                          meta_table_sub$day_of_life,
                          meta_table_sub$studyid,
                          pseudo=NULL,
                          transform="none")

mean_svd &lt;- svd_centralize(datlist, r=1)

res_tempted &lt;- tempted(mean_svd$datlist, r=2, smooth=1e-5)

# plot the temporal loading

plot_time_loading(res_tempted, r=2)
</code></pre>

<hr>
<h2 id='tempted_all'>Run all major functions of tempted</h2><span id='topic+tempted_all'></span>

<h3>Description</h3>

<p>This function wraps functions <code><a href="#topic+format_tempted">format_tempted</a></code>, <code><a href="#topic+svd_centralize">svd_centralize</a></code>, <code><a href="#topic+tempted">tempted</a></code>,
<code><a href="#topic+ratio_feature">ratio_feature</a></code>, \
and <code><a href="#topic+aggregate_feature">aggregate_feature</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tempted_all(
  featuretable,
  timepoint,
  subjectID,
  threshold = 0.95,
  pseudo = NULL,
  transform = "clr",
  r = 3,
  smooth = 1e-06,
  interval = NULL,
  resolution = 51,
  maxiter = 20,
  epsilon = 1e-04,
  r_svd = 1,
  do_ratio = TRUE,
  pct_ratio = 0.05,
  absolute = FALSE,
  pct_aggregate = 1,
  contrast = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tempted_all_+3A_featuretable">featuretable</code></td>
<td>
<p>A sample by feature matrix. It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_timepoint">timepoint</code></td>
<td>
<p>The time stamp of each sample, matched with the rows of <code>featuretable</code>. It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_subjectid">subjectID</code></td>
<td>
<p>The subject ID of each sample, matched with the rows of <code>featuretable</code>. It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_threshold">threshold</code></td>
<td>
<p>A threshold for feature filtering for microbiome data.
Features with zero value percentage &gt;= threshold will be excluded. Default is 0.95.
It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_pseudo">pseudo</code></td>
<td>
<p>A small number to add to all the counts before
normalizing into proportions and log transformation.
Default is 1/2 of the smallest non-zero value that is specific for each sample.
This pseudo count is added for <code>transform=c("logcomp", "clr", "logit")</code>.
It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_transform">transform</code></td>
<td>
<p>The transformation applied to the data.
<code>"logcomp"</code> for log of compositions.
<code>"comp"</code> for compositions.
<code>"ast"</code> for arcsine squared transformation.
<code>"clr"</code> for central log ratio transformation.
<code>"logit"</code> for logit transformation.
<code>"none"</code> for no transformation.
Default <code>transform="clr"</code> is recommended for microbiome data.
For data that are already transformed, use <code>transform="none"</code>.
It is an input for <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_r">r</code></td>
<td>
<p>Number of components to decompose into, i.e. rank of the CP type decomposition.
Default is set to 3.
It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_smooth">smooth</code></td>
<td>
<p>Smoothing parameter for RKHS norm.
Larger means smoother temporal loading functions. Default is set to be 1e-8.
Value can be adjusted depending on the dataset by checking the smoothness of the estimated temporal loading function in plot.
It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_interval">interval</code></td>
<td>
<p>The range of time points to ran the decomposition for.
Default is set to be the range of all observed time points.
User can set it to be a shorter interval than the observed range.
It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_resolution">resolution</code></td>
<td>
<p>Number of time points to evaluate the value of the temporal loading function.
Default is set to 101. It does not affect the subject or feature loadings. It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iteration. Default is 20. It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_epsilon">epsilon</code></td>
<td>
<p>Convergence criteria for difference between iterations. Default is 1e-4. It is an input for <code><a href="#topic+tempted">tempted</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_r_svd">r_svd</code></td>
<td>
<p>The number of ranks in the mean structure. Default is 1. It is an input for <code><a href="#topic+svd_centralize">svd_centralize</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_do_ratio">do_ratio</code></td>
<td>
<p>Whether to calculate the log ratio of features.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_pct_ratio">pct_ratio</code></td>
<td>
<p>The percent of features to sum up. Default is 0.05, i.e. 5%.
It is an input for <code><a href="#topic+ratio_feature">ratio_feature</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_absolute">absolute</code></td>
<td>
<p><code>absolute = TRUE</code> means features are ranked by the absolute value of feature loadings,
and the top <code>pct_ratio</code> percent of features are picked.
<code>absolute = FALSE</code> means features are ranked by the original value of feature loadings,
and the top and bottom <code>pct_ratio</code> percent of features are picked.
Then ratio is taken as the abundance of the features with positive loading
over the abundance of the features with negative loading.
It is an input for <code><a href="#topic+ratio_feature">ratio_feature</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_pct_aggregate">pct_aggregate</code></td>
<td>
<p>The percent of features to aggregate,
features ranked by absolute value of the feature loading of each component.
Default is 1, which means 100% of features are aggregated.
Setting <code>pct_aggregate=0.01</code> means top 1% of features is aggregated,
where features are ranked in absolute value of feature loading of each component.
It is an input for <code><a href="#topic+aggregate_feature">aggregate_feature</a></code>.</p>
</td></tr>
<tr><td><code id="tempted_all_+3A_contrast">contrast</code></td>
<td>
<p>A matrix choosing how components are combined,
each column is a contrast of length r and used to calculate the linear combination of
the feature loadings of r components.
It is an input for <code><a href="#topic+ratio_feature">ratio_feature</a></code> and It is an input for <code><a href="#topic+aggregate_feature">aggregate_feature</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including all the input and output of functions <code><a href="#topic+format_tempted">format_tempted</a></code>, <code><a href="#topic+svd_centralize">svd_centralize</a></code>, <code><a href="#topic+tempted">tempted</a></code>,
<code><a href="#topic+ratio_feature">ratio_feature</a></code>, and <code><a href="#topic+aggregate_feature">aggregate_feature</a></code>.
</p>

<dl>
<dt>input</dt><dd><p>All the input options of function <code><a href="#topic+tempted_all">tempted_all</a></code>.</p>
</dd>
<dt>datalist_raw</dt><dd><p>Output of <code><a href="#topic+format_tempted">format_tempted</a></code> with option <code>transform="none"</code>.</p>
</dd>
<dt>datlist</dt><dd><p>Output of <code><a href="#topic+format_tempted">format_tempted</a></code>.</p>
</dd>
<dt>mean_svd</dt><dd><p>Output of <code><a href="#topic+svd_centralize">svd_centralize</a></code>.</p>
</dd>
<dt>A_hat</dt><dd><p>Subject loading, a subject by r matrix.</p>
</dd>
<dt>B_hat</dt><dd><p>Feature loading, a feature by r matrix.</p>
</dd>
<dt>Phi_hat</dt><dd><p>Temporal loading function, a resolution by r matrix.</p>
</dd>
<dt>time_Phi</dt><dd><p>The time points where the temporal loading function is evaluated.</p>
</dd>
<dt>Lambda</dt><dd><p>Eigen value, a length r vector.</p>
</dd>
<dt>r_square</dt><dd><p>Variance explained by each component. This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using individual components.</p>
</dd>
<dt>accum_r_square</dt><dd><p>Variance explained by the first few components accumulated. This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using the first few components.</p>
</dd>
<dt>metafeature_ratio</dt><dd><p>The log ratio abundance of the top over bottom ranking features. It is a data.frame with five columns: &quot;value&quot; for the log ratio values, &quot;subID&quot; for the subject ID, and &quot;timepoint&quot; for the time points, and &quot;PC&quot; indicating which component was used to construct the meta feature.</p>
</dd>
<dt>toppct_ratio</dt><dd><p>A matrix of TRUE/FALSE indicating which features are ranked top in each component (and contrast) and used as the numerator of the log ratio.</p>
</dd>
<dt>bottompct_ratio</dt><dd><p>A matrix of TRUE/FALSE indicating which features are ranked bottom in each component (and contrast) and used as the denominator of the log ratio.</p>
</dd>
<dt>metafeature_aggregate</dt><dd><p>The meta feature obtained by aggregating the observed temporal tensor. It is a data.frame with four columns: &quot;value&quot; for the meta feature values, &quot;subID&quot; for the subject ID, &quot;timepoint&quot; for the time points, and &quot;PC&quot; indicating which component was used to construct the meta feature.</p>
</dd>
<dt>toppct_aggregate</dt><dd><p>A matrix of TRUE/FALSE indicating which features are aggregated in each component and contrast.</p>
</dd>
<dt>contrast</dt><dd><p>The contrast used to linearly combine the components from input.</p>
</dd>
</dl>



<h3>References</h3>

<p>Shi P, Martino C, Han R, Janssen S, Buck G, Serrano M, Owzar K, Knight R, Shenhav L, Zhang AR. (2023) <em>Time-Informed Dimensionality Reduction for Longitudinal Microbiome Studies</em>. bioRxiv. doi: 10.1101/550749. <a href="https://www.biorxiv.org/content/10.1101/550749">https://www.biorxiv.org/content/10.1101/550749</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Take a subset of the samples so the example runs faster

# Here we are taking samples from the odd months
sub_sample &lt;- rownames(meta_table)[(meta_table$day_of_life%/%12)%%2==1]
count_table_sub &lt;- count_table[sub_sample,]
processed_table_sub &lt;- processed_table[sub_sample,]
meta_table_sub &lt;- meta_table[sub_sample,]

# for preprocessed data that do not need to be transformed


res.processed &lt;- tempted_all(processed_table_sub,
                             meta_table_sub$day_of_life,
                            meta_table_sub$studyid,
                             threshold=1,
                             transform="none",
                             r=2,
                             smooth=1e-5,
                             do_ratio=FALSE)

# for count data that will have pseudo added and clr transformed

res.count &lt;- tempted_all(count_table_sub,
                         meta_table_sub$day_of_life,
                         meta_table_sub$studyid,
                         threshold=0.95,
                         transform="clr",
                         pseudo=0.5,
                         r=2,
                         smooth=1e-5,
                         pct_ratio=0.1,
                         pct_aggregate=1)

# for proportional data that will have pseudo added and clr transformed

res.proportion &lt;- tempted_all(count_table_sub/rowSums(count_table_sub),
                              meta_table_sub$day_of_life,
                              meta_table_sub$studyid,
                              threshold=0.95,
                              transform="clr",
                              pseudo=NULL,
                              r=2,
                              smooth=1e-5,
                              pct_ratio=0.1,
                              pct_aggregate=1)

# plot the temporal loading and subject trajectories grouped by delivery mode

plot_time_loading(res.proportion, r=2)

group &lt;- unique(meta_table[,c("studyid", "delivery")])

# plot the aggregated features

plot_metafeature(res.proportion$metafeature_aggregate, group, bws=30)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
