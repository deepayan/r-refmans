<!DOCTYPE html><html lang="en"><head><title>Help for package gamlss.lasso</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gamlss.lasso}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gamlss.lasso-package'>
<p>Extra Lasso-Type Additive Terms for GAMLSS</p></a></li>
<li><a href='#gamlss.gnet'>
<p>Support for Function gnet()</p></a></li>
<li><a href='#gamlss.lrs'>
<p>Support for Function lrs()</p></a></li>
<li><a href='#gnet'>
<p>(Adaptive) elastic net in GAMLSS</p></a></li>
<li><a href='#lrs'>
<p>Least angle regression and lasso in GAMLSS</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Description:</td>
<td>Interface for extra high-dimensional smooth functions for Generalized Additive Models for Location Scale and Shape (GAMLSS) including (adaptive) lasso, ridge, elastic net and least angle regression.</td>
</tr>
<tr>
<td>Title:</td>
<td>Extra Lasso-Type Additive Terms for GAMLSS</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-01</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.0), gamlss (&ge; 2.4.0), glmnet, lars, Matrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lattice</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Ziel &lt;florian.ziel@uni-due.de&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.gamlss.com/">https://www.gamlss.com/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-21 08:56:25 UTC; florian</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-21 09:10:02 UTC</td>
</tr>
<tr>
<td>Author:</td>
<td>Florian Ziel [aut, cre],
  Peru Muniain [aut],
  Mikis Stasinopoulos [ctb]</td>
</tr>
</table>
<hr>
<h2 id='gamlss.lasso-package'>
Extra Lasso-Type Additive Terms for GAMLSS
</h2><span id='topic+gamlss.lasso-package'></span><span id='topic+gamlss.lasso'></span>

<h3>Description</h3>

<p>Interface for extra high-dimensional smooth functions for Generalized Additive Models for Location Scale and Shape (GAMLSS) including (adaptive) lasso, ridge, elastic net and least angle regression.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> gamlss.lasso</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Interface for extra high-dimensional smooth functions for Generalized Additive Models for Location Scale and Shape (GAMLSS) including (adaptive) lasso, ridge, elastic net and least angle regression.</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Extra Lasso-Type Additive Terms for GAMLSS</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0-1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-05-01</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.15.0), gamlss (&gt;= 2.4.0), glmnet, lars, Matrix</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> lattice</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person("Florian", "Ziel", role = c("aut", "cre"),
                    email = "florian.ziel@uni-due.de"),
             person("Peru", "Muniain", role = "aut"),
             person("Mikis", "Stasinopoulos", role = "ctb"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Florian Ziel &lt;florian.ziel@uni-due.de&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2 | GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://www.gamlss.com/</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> no</td>
</tr>
<tr>
 <td style="text-align: left;">
Packaged: </td><td style="text-align: left;"> 2021-04-01 06:51:36 UTC; florian</td>
</tr>
<tr>
 <td style="text-align: left;">
Repository: </td><td style="text-align: left;"> CRAN</td>
</tr>
<tr>
 <td style="text-align: left;">
Date/Publication: </td><td style="text-align: left;"> 2021-04-01 06:55:55 UTC</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Florian Ziel [aut, cre],
  Peru Muniain [aut],
  Mikis Stasinopoulos [ctb]</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
gamlss.gnet             Support for Function gnet()
gamlss.lasso-package    Extra Lasso-Type Additive Terms for GAMLSS
gamlss.lrs              Support for Function lrs()
gnet                    (Adaptive) elastic net in GAMLSS
lrs                     Least angle regression and lasso in GAMLSS
</pre>


<h3>Author(s)</h3>

<p>NA
</p>
<p>Maintainer: Florian Ziel &lt;florian.ziel@uni-due.de&gt;
</p>


<h3>References</h3>

<p>R
Rigby, R. A. and  Stasinopoulos D. M. (2005). Generalized additive models for location, scale and shape, (with discussion), 
<em>Appl. Statist.</em>, <b>54</b>, part 3, pp 507-554.
</p>
<p>Rigby R.A., Stasinopoulos D. M., Heller G., and De Bastiani F., (2019) <em>Distributions for Modeling Location, Scale and Shape: Using GAMLSS in R</em>, Chapman and Hall/CRC.
</p>
<p>Stasinopoulos D. M. Rigby R.A. (2007) Generalized additive models for location scale and shape (GAMLSS) in R.
<em>Journal of Statistical Software</em>, Vol. <b>23</b>, Issue 7, Dec 2007, <a href="https://www.jstatsoft.org/v23/i07">https://www.jstatsoft.org/v23/i07</a>.
</p>
<p>Stasinopoulos D. M., Rigby R.A., Heller G., Voudouris V., and De Bastiani F., (2017) <em>Flexible Regression and Smoothing: Using GAMLSS in R</em>, Chapman and Hall/CRC. 
</p>
<p>(see also <a href="https://www.gamlss.com/">https://www.gamlss.com/</a>).
</p>
<p>Efron, B., Hastie, T., Johnstone, I., &amp; Tibshirani, R. (2004). <em>Least angle regression</em>. Annals of statistics, 32(2), 407-499.
</p>
<p>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010). <em>Regularization paths for generalized linear models via coordinate descent</em>. Journal of statistical software, 33(1), 1.
</p>


<h3>See Also</h3>

<p><code><a href="gamlss.html#topic+gamlss">gamlss</a></code>, <code><a href="gamlss.dist.html#topic+gamlss.family">gamlss.family</a></code>, <code><a href="gamlss.add.html#topic+gamlss.add">gamlss.add</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Contructing the data
library(gamlss.lasso)
set.seed(123)
n&lt;- 500
d&lt;- 50
X&lt;- matrix(rnorm(n*d), n,d)
BETA&lt;- cbind( "mu"=rbinom(d,1,.1), "sigma"= rbinom(d,1,.1)*.3)
ysd&lt;- exp(1 + tcrossprod( BETA[,2],X))
data&lt;- cbind(y=as.numeric(rnorm(n, sd=ysd))+t(tcrossprod( BETA[,1],X)), as.data.frame(X))

# Estimating the model with gnet default setting
mod &lt;- gamlss(y~gnet(x.vars=names(data)[-1] ),
              sigma.fo=~gnet(x.vars=names(data)[-1]), data=data, family=NO,
              i.control = glim.control(cyc=1, bf.cyc=1))

# Estimated paramters are available at
rbind(true=BETA[,1],estimate=tail(getSmo(mod, "mu") ,1)[[1]]$beta )## beta for mu
rbind(true=BETA[,2],estimate=tail(getSmo(mod, "sigma") ,1)[[1]]$beta )## beta for sigma
</code></pre>

<hr>
<h2 id='gamlss.gnet'>
Support for Function gnet() 
</h2><span id='topic+gamlss.gnet'></span>

<h3>Description</h3>

<p>This is support for the smoother function gnet() an interface for Tibshirani's <code>glmnet()</code> function.
It is not intended to be called directly by users. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamlss.gnet(x, y, w, xeval = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamlss.gnet_+3A_x">x</code></td>
<td>
<p>the explanatory variables</p>
</td></tr>
<tr><td><code id="gamlss.gnet_+3A_y">y</code></td>
<td>
<p>iterative y variable</p>
</td></tr>
<tr><td><code id="gamlss.gnet_+3A_w">w</code></td>
<td>
<p>iterative weights</p>
</td></tr>
<tr><td><code id="gamlss.gnet_+3A_xeval">xeval</code></td>
<td>
<p>if xeval=TRUE then predicion is used</p>
</td></tr>
<tr><td><code id="gamlss.gnet_+3A_...">...</code></td>
<td>
<p>for extra arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for GAMLSS gnet procedure.</p>


<h3>Author(s)</h3>

<p>Florian Ziel, Peru Muniain and Mikis Stasinopoulos
</p>


<h3>References</h3>

<p>Rigby, R. A. and  Stasinopoulos D. M. (2005). Generalized additive models for location, scale and shape,(with discussion), 
<em>Appl. Statist.</em>, <b>54</b>, part 3, pp 507-554.
</p>
<p>Rigby R.A., Stasinopoulos D. M., Heller G., and De Bastiani F., (2019) <em>Distributions for Modeling Location, Scale and Shape: Using GAMLSS in R</em>, Chapman and Hall/CRC.
</p>
<p>Ripley, B. D. (1996) <em>Pattern Recognition and Neural Networks</em>. Cambridge. 
</p>
<p>Stasinopoulos D. M. Rigby R.A. (2007) Generalized additive models for location scale and shape (GAMLSS) in R.
<em>Journal of Statistical Software</em>, Vol. <b>23</b>, Issue 7, Dec 2007, <a href="https://www.jstatsoft.org/v23/i07">https://www.jstatsoft.org/v23/i07</a>.
</p>
<p>Stasinopoulos D. M., Rigby R.A., Heller G., Voudouris V., and De Bastiani F., (2017) <em>Flexible Regression and Smoothing: Using GAMLSS in R</em>, Chapman and Hall/CRC. 
</p>
<p>(see also <a href="https://www.gamlss.com/">https://www.gamlss.com/</a>).
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics with S</em>. Fourth edition. Springer. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gnet">gnet</a></code></p>

<hr>
<h2 id='gamlss.lrs'>
Support for Function lrs() 
</h2><span id='topic+gamlss.lrs'></span>

<h3>Description</h3>

<p>This is support for the smoother function lrs() an interface for Brad Efron and Trevor Hastie for <code>lars()</code> function.
It is not intended to be called directly by users. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamlss.lrs(x, y, w, xeval = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamlss.lrs_+3A_x">x</code></td>
<td>
<p>the explanatory variables</p>
</td></tr>
<tr><td><code id="gamlss.lrs_+3A_y">y</code></td>
<td>
<p>iterative y variable</p>
</td></tr>
<tr><td><code id="gamlss.lrs_+3A_w">w</code></td>
<td>
<p>iterative weights</p>
</td></tr>
<tr><td><code id="gamlss.lrs_+3A_xeval">xeval</code></td>
<td>
<p>if xeval=TRUE then predicion is used</p>
</td></tr>
<tr><td><code id="gamlss.lrs_+3A_...">...</code></td>
<td>
<p>for extra arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for GAMLSS lrs procedure.</p>


<h3>Author(s)</h3>

<p>Florian Ziel, Peru Muniain and Mikis Stasinopoulos
</p>


<h3>References</h3>

<p>Rigby, R. A. and  Stasinopoulos D. M. (2005). Generalized additive models for location, scale and shape,(with discussion), 
<em>Appl. Statist.</em>, <b>54</b>, part 3, pp 507-554.
</p>
<p>Rigby R.A., Stasinopoulos D. M., Heller G., and De Bastiani F., (2019) <em>Distributions for Modeling Location, Scale and Shape: Using GAMLSS in R</em>, Chapman and Hall/CRC.
</p>
<p>Ripley, B. D. (1996) <em>Pattern Recognition and Neural Networks</em>. Cambridge. 
</p>
<p>Stasinopoulos D. M. Rigby R.A. (2007) Generalized additive models for location scale and shape (GAMLSS) in R.
<em>Journal of Statistical Software</em>, Vol. <b>23</b>, Issue 7, Dec 2007, <a href="https://www.jstatsoft.org/v23/i07">https://www.jstatsoft.org/v23/i07</a>.
</p>
<p>Stasinopoulos D. M., Rigby R.A., Heller G., Voudouris V., and De Bastiani F., (2017) <em>Flexible Regression and Smoothing: Using GAMLSS in R</em>, Chapman and Hall/CRC. 
</p>
<p>(see also <a href="https://www.gamlss.com/">https://www.gamlss.com/</a>).
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics with S</em>. Fourth edition. Springer. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrs">lrs</a></code></p>

<hr>
<h2 id='gnet'>
(Adaptive) elastic net in GAMLSS
</h2><span id='topic+gnet'></span><span id='topic+gnet.control'></span>

<h3>Description</h3>

<p>This function allows estimating the different components of a GAMLSS model (location, shape, scale parameters) using the (adaptive) elastic net (with adaptive lasso as default special case) estimation method via <code>glmnet</code>. This method is appropriate for models with many variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gnet( X = NULL, x.vars = NULL, lambda = NULL, method = c("IC", "CV"), 
  type = c("agg", "sel"), ICpen = c("BIC", "HQC", "AIC"), CVp = 2, 
  k.se = 0, adaptive = 1, epsilon = 1/sqrt(dim(X)[1]), subsets = NULL, 
  sparse = FALSE, control = gnet.control(...), ...) 
gnet.control(family="gaussian", offset = NULL, alpha = 1, nlambda = 100, 
  lambda.min.ratio = 1e-3, standardize = TRUE, intercept = TRUE, thresh = 1e-07,
  dfmax = NULL, pmax = NULL, exclude = NULL, penalty.factor = NULL, lower.limits = -Inf,
  upper.limits = Inf, maxit = 100000, type.gaussian = NULL, type.logistic = "Newton")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gnet_+3A_x">X</code></td>
<td>
<p> The data frame containing the explanatory variables.</p>
</td></tr>
<tr><td><code id="gnet_+3A_x.vars">x.vars</code></td>
<td>
<p> Indicates the name of the variables that must be included as explanatory variables from data the data object of GAMLSS. The explanatory variables must be included by <code>X</code> or by <code>x.vars</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_lambda">lambda</code></td>
<td>
<p> The provided lambda grid. By default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_method">method</code></td>
<td>
<p> The method used to calculate the optimal lambda. If <code>method="IC"</code> information criteria are used, the penalization for the information criterion is selected in <code>ICpen</code>.If <code>method="CV"</code> cross validation resp. sampling is used, the penalization for the cross-validation is selected in <code>CVp</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_type">type</code></td>
<td>
<p> The way to select the optimal lambda across the subsample fits. If <code>type="sel"</code> the optimal lambda is computed by selection. If <code>method="agg"</code> the optimal lambda is computed by aggregation.</p>
</td></tr>
<tr><td><code id="gnet_+3A_icpen">ICpen</code></td>
<td>
<p> The penalization for the information criteria. If <code>ICpen="AIC"</code> or  <code>ICpen=2</code> the optimal lambda is computed by Akaike Information Criterion. If <code>ICpen="BIC"</code> the optimal lambda is computed by Bayesian Information Criterion.If <code>ICpen="HQC"</code> the optimal lambda is computed by Hannan-Quinn Information Criterion.</p>
</td></tr>
<tr><td><code id="gnet_+3A_cvp">CVp</code></td>
<td>
<p> The penalization for the cross-validation, establishes the power of the error term. By default is equal to 2, i.e. squared error.</p>
</td></tr>
<tr><td><code id="gnet_+3A_k.se">k.se</code></td>
<td>
<p> This parameter establishes how many times the standard deviation is summed to the mean to select the optimal lambda. By default is equal to 0.</p>
</td></tr>
<tr><td><code id="gnet_+3A_adaptive">adaptive</code></td>
<td>
<p> This parameter specifies if adaptive lasso shall be used, the default is 1. If <code>NULL</code> then standard lasso is used, otherwise adaptive lasso with penalty weights <code>(abs(beta)+epsilon)^(-adaptive)</code> where <code>beta</code> is chosen from an initial standard lasso estimate and <code>epsilon</code> is specified by the next parameter. Note, estimating standard lasso requires about half of computation time, but adaptive lasso has smaller bias and satiesfies the oracle property.</p>
</td></tr>
<tr><td><code id="gnet_+3A_epsilon">epsilon</code></td>
<td>
<p> This parameter specifies the adaptive lasso penalty weights. The default is <code>1/sqrt(dim(X)[1])</code>. </p>
</td></tr>
<tr><td><code id="gnet_+3A_subsets">subsets</code></td>
<td>
<p> The subsets for cross-validation, information criteria or bootstraping, by default 5 random folds are selected.</p>
</td></tr>
<tr><td><code id="gnet_+3A_sparse">sparse</code></td>
<td>
<p> If sparse converts input matrix for <code>glmnet</code> into a sparse Matrix, may reduces computation time for sparse designs.</p>
</td></tr>
<tr><td><code id="gnet_+3A_control">control</code></td>
<td>
<p>List of further input parameters for glmnet, e.g. alpha for elastic net parameters.</p>
</td></tr>
<tr><td><code id="gnet_+3A_...">...</code></td>
<td>
<p>for extra arguments</p>
</td></tr>
<tr><td><code id="gnet_+3A_family">family</code></td>
<td>
<p>Either a character string representing
one of the built-in families, or else a <code>glm()</code> family object.</p>
</td></tr>
<tr><td><code id="gnet_+3A_offset">offset</code></td>
<td>
<p>A vector of length <code>nobs</code> that is included in the linear
predictor (a <code>nobs x nc</code> matrix for the <code>"multinomial"</code> family).
Useful for the <code>"poisson"</code> family (e.g. log of exposure time), or for
refining a model by starting at a current fit. Default is <code>NULL</code>. If
supplied, then values must also be supplied to the <code>predict</code> function.</p>
</td></tr>
<tr><td><code id="gnet_+3A_alpha">alpha</code></td>
<td>
<p>The elastic net mixing parameter, with <code class="reqn">0\le\alpha\le 1</code>.
The penalty is defined as </p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>
 <p><code>alpha=1</code> is the
lasso penalty, and <code>alpha=0</code> the ridge penalty. Default is lasso.</p>
</td></tr>
<tr><td><code id="gnet_+3A_nlambda">nlambda</code></td>
<td>
<p>Size of the tuning parameter grid, default is 100. It is irrelevant if lambda is explicitly specified.</p>
</td></tr>
<tr><td><code id="gnet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>, the (data derived) entry value (i.e. the smallest value
for which all coefficients are zero). The default is <code>0.001</code>.  A very small value of
<code>lambda.min.ratio</code> will lead to a saturated fit in the <code>nobs &lt;
nvars</code> case. This is undefined for <code>"binomial"</code> and
<code>"multinomial"</code> models, and <code>glmnet</code> will exit gracefully when the
percentage deviance explained is almost 1. It is irrelevant if lambda is explicitly specified.</p>
</td></tr>
<tr><td><code id="gnet_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for <code>X</code> or <code>x.vars</code> variable standardization, prior to
fitting the model sequence. The coefficients are always returned on the
original scale. Default is <code>standardize=TRUE</code> and it is highly recommended.</p>
</td></tr>
<tr><td><code id="gnet_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept(s) be fitted (default=TRUE) or set to zero
(FALSE).</p>
</td></tr>
<tr><td><code id="gnet_+3A_thresh">thresh</code></td>
<td>
<p>Convergence threshold for coordinate descent. Each inner
coordinate-descent loop continues until the maximum change in the objective
after any coefficient update is less than <code>thresh</code> times the null
deviance. Defaults value is <code>1E-7</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_dfmax">dfmax</code></td>
<td>
<p>Limit the maximum number of variables in the model. Useful for
very large <code>nvars</code>, if a partial path is desired.</p>
</td></tr>
<tr><td><code id="gnet_+3A_pmax">pmax</code></td>
<td>
<p>Limit the maximum number of variables ever to be nonzero.</p>
</td></tr>
<tr><td><code id="gnet_+3A_exclude">exclude</code></td>
<td>
<p>Indices of variables to be excluded from the model. Default
is none. Equivalent to an infinite penalty factor (next item).</p>
</td></tr>
<tr><td><code id="gnet_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each
coefficient. This is a number that multiplies <code>lambda</code> to allow
differential shrinkage. Can be 0 for some variables, which implies no
shrinkage, and that variable is always included in the model. Default is 1
for all variables (and implicitly infinity for variables listed in
<code>exclude</code>). Note: the penalty factors are internally rescaled to sum to
nvars, and the lambda sequence will reflect this change.</p>
</td></tr>
<tr><td><code id="gnet_+3A_lower.limits">lower.limits</code></td>
<td>
<p>Vector of lower limits for each coefficient; default
<code>-Inf</code>. Each of these must be non-positive. Can be presented as a
single value (which will then be replicated), else a vector of length
<code>nvars</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_upper.limits">upper.limits</code></td>
<td>
<p>Vector of upper limits for each coefficient; default
<code>Inf</code>. See <code>lower.limits</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of passes over the data for all lambda values;
default is 10^5.</p>
</td></tr>
<tr><td><code id="gnet_+3A_type.gaussian">type.gaussian</code></td>
<td>
<p>Two algorithm types are supported for (only)
<code>family="gaussian"</code>. The default when <code>nvar&lt;500</code> is
<code>type.gaussian="covariance"</code>, and saves all inner-products ever
computed. This can be much faster than <code>type.gaussian="naive"</code>, which
loops through <code>nobs</code> every time an inner-product is computed. The
latter can be far more efficient for <code>nvar &gt;&gt; nobs</code> situations, or when
<code>nvar &gt; 500</code>.</p>
</td></tr>
<tr><td><code id="gnet_+3A_type.logistic">type.logistic</code></td>
<td>
<p>If <code>"Newton"</code> then the exact hessian is used
(default), while <code>"modified.Newton"</code> uses an upper-bound on the
hessian, and can be faster.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation of the lambda is carried out by BIC by default.
If the objective is to predict the model must be defined by <code>x.vars</code>. 
Different types of subsets must be constructed if bootstrapping and aggregation are applied, as in this case observations might be repeated. 
</p>


<h3>Value</h3>

<p>This function returns a smooth object of the GAMLSS model. It contains the estimated parameters and related characteristics for the <code>glmnet</code> component in the GAMLSS model we are estimating.
</p>


<h3>Author(s)</h3>

<p>Florian Ziel, Peru Muniain and Mikis Stasinopoulos
</p>


<h3>References</h3>

<p>Rigby, R. A. and  Stasinopoulos D. M. (2005). Generalized additive models for location, scale, and shape,(with discussion), <em>Appl. Statist.</em>, <b>54</b>, part 3, pp 507-554.
</p>
<p>Rigby, R. A., Stasinopoulos, D. M., Heller, G. Z., and De Bastiani, F. (2019) Distributions for modeling location, scale, and shape: Using GAMLSS in R, Chapman and Hall/CRC. An older version can be found in https://www.gamlss.com/. 
</p>
<p>Stasinopoulos D. M. Rigby R.A. (2007) Generalized additive models for location scale and shape (GAMLSS) in R. <em>Journal of Statistical Software</em>, <b>Vol. 23</b>, Issue 7, Dec 2007, https://www.jstatsoft.org/v23/i07/. 
</p>
<p>Stasinopoulos D. M., Rigby R.A., Heller G., Voudouris V., and De Bastiani F., (2017) Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. 
</p>
<p>Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011) Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent, <em>Journal of Statistical Software</em>, <b>Vol. 39(5)</b>, 1-13, https://www.jstatsoft.org/v39/i05/.
</p>
<p>Tibshirani, Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and Tibshirani, Ryan. (2012) Strong Rules for Discarding Predictors in Lasso-type Problems, <em>JRSSB</em>, <b>Vol. 74(2)</b>, 245-266, https://statweb.stanford.edu/~tibs/ftp/strong.pdf.
</p>
<p>Hastie, T., Tibshirani, Robert and Tibshirani, Ryan. Extended Comparisons of Best Subset Selection, Forward Stepwise Selection, and the Lasso (2017), <em>Stanford Statistics Technical Report</em>, https://arxiv.org/abs/1707.08692.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Contructing the data
library(gamlss.lasso)
set.seed(123)
n&lt;- 500
d&lt;- 50
X&lt;- matrix(rnorm(n*d), n,d)
BETA&lt;- cbind( "mu"=rbinom(d,1,.1), "sigma"= rbinom(d,1,.1)*.3)
ysd&lt;- exp(1 + tcrossprod( BETA[,2],X))
data&lt;- cbind(y=as.numeric(rnorm(n, sd=ysd))+t(tcrossprod( BETA[,1],X)), as.data.frame(X))


# Estimating the model using default setting: adaptive lasso with BIC tuning
mod &lt;- gamlss(y~gnet(x.vars=names(data)[-1]),
              sigma.fo=~gnet(x.vars=names(data)[-1]), data=data,
              family=NO, i.control = glim.control(cyc=1, bf.cyc=1))

# Estimating the model with standard lasso (BIC tuning)
mod.lasso &lt;- gamlss(y~gnet(x.vars=names(data)[-1], adaptive=NULL),
              sigma.fo=~gnet(x.vars=names(data)[-1], adaptive=NULL), data=data, 
              family=NO, i.control = glim.control(cyc=1, bf.cyc=1))

# Estimated paramters are available at
rbind(true=BETA[,1],alasso=tail(getSmo(mod, "mu") ,1)[[1]]$beta,
                    lasso=tail(getSmo(mod.lasso, "mu") ,1)[[1]]$beta) ##beta for mu
rbind(true=BETA[,2],alasso=tail(getSmo(mod, "sigma") ,1)[[1]]$beta,
                    lasso=tail(getSmo(mod.lasso, "sigma") ,1)[[1]]$beta)##beta for sigma

# Estimating with other setting
nfolds&lt;- 6
n&lt;- dim(data)[1]
# folds for cross-validation and bootstrap
CVfolds&lt;- lapply(as.data.frame(t(sapply(sample(rep_len(1:nfolds,length=n),replace=FALSE)
                 ,"!=", 1:nfolds))), which)  
BOOTfolds&lt;- lapply(as.data.frame(matrix(sample(1:n, nfolds*n, replace=TRUE), n)),sort)  

#Bootstrap + Aggrationg = Bagging:
mod1 &lt;- gamlss(y~gnet(x.vars=names(data)[-1], method="CV",type="agg", subsets=BOOTfolds),
               sigma.fo=~gnet(x.vars=names(data)[-1]), data=data, family=NO,
               i.control = glim.control(cyc=1, bf.cyc=1)) 

# Estimated paramters are available at
tail(getSmo(mod1, "mu") ,1)[[1]]$beta ## beta for mu
tail(getSmo(mod1, "sigma") ,1)[[1]]$beta ## beta for sigma

# Cross-validation (with selection):
mod2 &lt;- gamlss(y~gnet(x.vars=names(data)[-1],method="CV",type="sel", subsets=CVfolds),
               sigma.fo=~gnet(x.vars=names(data)[-1],method="CV",type="sel", ICpen=2, 
               subsets=CVfolds), data=data, family=NO,
               i.control = glim.control(cyc=1, bf.cyc=1)) 

# Estimated paramters are available at
tail(getSmo(mod2, "mu") ,1)[[1]]$beta ## beta for mu
tail(getSmo(mod2, "sigma") ,1)[[1]]$beta ## beta for sigma


</code></pre>

<hr>
<h2 id='lrs'>
Least angle regression and lasso in GAMLSS
</h2><span id='topic+lrs'></span>

<h3>Description</h3>

<p>This function allows estimating the different components of a GAMLSS model (mean, sd. dev., skewness and kurtosis) using the elastic net (with lasso as default special case) estimation method via glmnet.  This method is appropriate for models with many variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrs(X = NULL, x.vars = NULL, lambda = NULL,	method = c("IC","CV"), 
  type = c("agg","sel"), ICpen = c("BIC", "HQC", "AIC"), CVp = 2, k.se = 0, 
  subsets = NULL, lars.type= "lasso", use.gram = TRUE, 
  eps = .Machine$double.eps, max.steps = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lrs_+3A_x">X</code></td>
<td>
<p> The data frame containing the explanatory variables.</p>
</td></tr>
<tr><td><code id="lrs_+3A_x.vars">x.vars</code></td>
<td>
<p> Indicates the name of the variables that must be included as explanatory variables from data the data object of GAMLSS. The explanatory variables must be included by <code>X</code> or by <code>x.vars</code>.</p>
</td></tr>
<tr><td><code id="lrs_+3A_lambda">lambda</code></td>
<td>
<p> The provided lambda grid. By default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lrs_+3A_method">method</code></td>
<td>
<p> The method used to calculate the optimal lambda. If <code>method="IC"</code> information criteria are used, the penalization for the information criterion is selected in <code>ICpen</code>.If <code>method="CV"</code> cross validation resp. sampling is used, the penalization for the cross-validation is selected in <code>CVp</code>.</p>
</td></tr>
<tr><td><code id="lrs_+3A_type">type</code></td>
<td>
<p> The way to select the optimal lambda across the subsample fits. If <code>type="sel"</code> the optimal lambda is computed by selection. If <code>method="agg"</code> the optimal lambda is computed by aggregation.</p>
</td></tr>
<tr><td><code id="lrs_+3A_icpen">ICpen</code></td>
<td>
<p> The penalization for the information criteria. If <code>ICpen="AIC"</code> or  <code>ICpen=2</code> the optimal lambda is computed by Akaike Information Criterion. If <code>ICpen="BIC"</code> the optimal lambda is computed by Bayesian Information Criterion.If <code>ICpen="HQC"</code> the optimal lambda is computed by Hannan-Quinn Information Criterion.</p>
</td></tr>
<tr><td><code id="lrs_+3A_cvp">CVp</code></td>
<td>
<p> The penalization for the cross-validation, establishes the power of the error term. By default is equal to 2, i.e. squared error.</p>
</td></tr>
<tr><td><code id="lrs_+3A_k.se">k.se</code></td>
<td>
<p> This parameter establishes how many times the standard deviation is summed to the mean to select the optimal lambda. By default is equal to 0.</p>
</td></tr>
<tr><td><code id="lrs_+3A_subsets">subsets</code></td>
<td>
<p> The subsets for cross-validation, information criteria or bootstraping, by default 5 random fold are selected.</p>
</td></tr>
<tr><td><code id="lrs_+3A_lars.type">lars.type</code></td>
<td>
<p>As in <code>lars</code>, lars type, e.g. &quot;lasso&quot;, &quot;lar&quot; (least angle regression), &quot;forward.stagewise&quot; or &quot;stepwise&quot;.</p>
</td></tr>
<tr><td><code id="lrs_+3A_use.gram">use.gram</code></td>
<td>
<p>States if Gramian should be precomputed, default TRUE - recommended as gamlss will call lars often during the estimation.</p>
</td></tr>
<tr><td><code id="lrs_+3A_eps">eps</code></td>
<td>
<p>As in <code>lars</code>, a small constant.</p>
</td></tr>
<tr><td><code id="lrs_+3A_max.steps">max.steps</code></td>
<td>
<p>As in <code>lars</code>, number of updating steps (for &quot;lars&quot; method equal to number of variables, for &quot;lasso&quot; it can be smaller), default NULL.</p>
</td></tr>
<tr><td><code id="lrs_+3A_...">...</code></td>
<td>
<p>for extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation of the lambda is carried out by BIC by default.
If the objective is to predict the model must be defined by <code>x.vars</code>. 
Different types of subsets must be constructed if bootstrapping and aggregation are applied, as in this case observations might be repeated. 
</p>


<h3>Value</h3>

<p>This function returns a smooth object of the GAMLSS model. It contains the estimated parameters and related characteristics for the <code>lars</code> component in the GAMLSS model we are estimating.
</p>


<h3>Author(s)</h3>

<p>Florian Ziel, Peru Muniain and Mikis Stasinopoulos
</p>


<h3>References</h3>

<p>Rigby, R. A. and  Stasinopoulos D. M. (2005). Generalized additive models for location, scale, and shape,(with discussion), <em>Appl. Statist.</em>, <b>54</b>, part 3, pp 507-554.
</p>
<p>Rigby, R. A., Stasinopoulos, D. M., Heller, G. Z., and De Bastiani, F. (2019) Distributions for modeling location, scale, and shape: Using GAMLSS in R, Chapman and Hall/CRC. An older version can be found in https://www.gamlss.com/. 
</p>
<p>Stasinopoulos D. M. Rigby R.A. (2007) Generalized additive models for location scale and shape (GAMLSS) in R. <em>Journal of Statistical Software</em>, <b>Vol. 23</b>, Issue 7, Dec 2007, https://www.jstatsoft.org/v23/i07/. 
</p>
<p>Stasinopoulos D. M., Rigby R.A., Heller G., Voudouris V., and De Bastiani F., (2017) Flexible Regression and Smoothing: Using GAMLSS in R, Chapman and Hall/CRC. 
</p>
<p>Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011) Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent, <em>Journal of Statistical Software</em>, <b>Vol. 39(5)</b>, 1-13, https://www.jstatsoft.org/v39/i05/.
</p>
<p>Tibshirani, Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and Tibshirani, Ryan. (2012) Strong Rules for Discarding Predictors in Lasso-type Problems, <em>JRSSB</em>, <b>Vol. 74(2)</b>, 245-266, https://statweb.stanford.edu/~tibs/ftp/strong.pdf.
</p>
<p>Hastie, T., Tibshirani, Robert and Tibshirani, Ryan. Extended Comparisons of Best Subset Selection, Forward Stepwise Selection, and the Lasso (2017), <em>Stanford Statistics Technical Report</em>, https://arxiv.org/abs/1707.08692.
</p>
<p>Efron, Hastie, Johnstone and Tibshirani (2003) &quot;Least Angle Regression&quot;
(with discussion) <em>Annals of Statistics</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Contructing the data
library(gamlss.lasso)
set.seed(123)
n&lt;- 500
d&lt;- 50
X&lt;- matrix(rnorm(n*d), n,d)
BETA&lt;- cbind( "mu"=rbinom(d,1,.1), "sigma"= rbinom(d,1,.1)*.3)
ysd&lt;- exp(1 + tcrossprod( BETA[,2],X))
data&lt;- cbind(y=as.numeric(rnorm(n,sd=ysd)) + t(tcrossprod( BETA[,1],X)),as.data.frame(X))

# Estimating the model with lrs default setting
mod &lt;- gamlss(y~lrs(x.vars=names(data)[-1] ),
              sigma.fo=~lrs(x.vars=names(data)[-1]), data=data, family=NO,
              i.control = glim.control(cyc=1, bf.cyc=1))

# Estimated paramters are available at
rbind(true=BETA[,1],estimate=tail(getSmo(mod, "mu") ,1)[[1]]$beta )## beta for mu
rbind(true=BETA[,2],estimate=tail(getSmo(mod, "sigma") ,1)[[1]]$beta )## beta for sigma

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
