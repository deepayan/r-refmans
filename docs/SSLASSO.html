<!DOCTYPE html><html><head><title>Help for package SSLASSO</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SSLASSO}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#plot.SSLASSO'><p>Plot coefficients from a &quot;SSLASSO&quot; object</p></a></li>
<li><a href='#SSLASSO'><p>The Spike-and-Slab LASSO</p></a></li>
<li><a href='#standard'><p>Standardizes a design matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.2-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-12-13</td>
</tr>
<tr>
<td>Title:</td>
<td>The Spike-and-Slab LASSO</td>
</tr>
<tr>
<td>Author:</td>
<td>Veronika Rockova [aut,cre], Gemma Moran [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gemma Moran &lt;gm2918@columbia.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient coordinate ascent algorithm for fitting regularization paths for linear models penalized by Spike-and-Slab LASSO of Rockova and George (2018) &lt;<a href="https://doi.org/10.1080%2F01621459.2016.1260469">doi:10.1080/01621459.2016.1260469</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://faculty.chicagobooth.edu/veronika.rockova/ssl.pdf">http://faculty.chicagobooth.edu/veronika.rockova/ssl.pdf</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-12-13 19:42:18 UTC; gem</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-12-13 23:20:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='plot.SSLASSO'>Plot coefficients from a &quot;SSLASSO&quot; object</h2><span id='topic+plot.SSLASSO'></span>

<h3>Description</h3>

<p>Produces a plot of the coefficient paths for a fitted
<code>"SSLASSO"</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSLASSO'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SSLASSO_+3A_x">x</code></td>
<td>
<p>Fitted <code>"SSLASSO"</code> model.</p>
</td></tr>
<tr><td><code id="plot.SSLASSO_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Veronika Rockova &lt;Veronika.Rockova@chicagobooth.edu&gt;</p>


<h3>References</h3>

<p>Rockova, V. and George, E.I. (2018) The Spike-and-Slab LASSO. Journal of the American Statistical Association.</p>


<h3>See Also</h3>

<p><code><a href="#topic+SSLASSO">SSLASSO</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	
## Linear regression, where p&gt;n
library(SSLASSO)

n=100
p=1000
X=matrix(rnorm(n*p), n, p)
beta=c(1,2,3,rep(0,p-3))
Y=X[,1]*beta[1]+X[,2]*beta[2]+X[,3]*beta[3]+rnorm(n)
lambda1&lt;-0.1
lambda0&lt;-seq(lambda1,100,length=50)
theta&lt;-0.5


# Separable penalty with fixed theta

result&lt;-SSLASSO(X, Y,penalty="separable", variance = "fixed", 
lambda1 = lambda1, lambda0 = lambda0,theta=theta)

plot(result)

</code></pre>

<hr>
<h2 id='SSLASSO'>The Spike-and-Slab LASSO</h2><span id='topic+SSLASSO'></span>

<h3>Description</h3>

<p>Spike-and-Slab LASSO is a spike-and-slab refinement of the LASSO procedure, using a mixture of Laplace priors indexed by  <code>lambda0</code> (spike) and <code>lambda1</code> (slab). 
</p>
<p>The <code>SSLASSO</code> procedure fits coefficients paths for Spike-and-Slab LASSO-penalized
linear regression models over a grid of values for the regularization
parameter <code>lambda0</code>. The code has been adapted from the <code>ncvreg</code> package (Breheny and Huang, 2011). </p>


<h3>Usage</h3>

<pre><code class='language-R'>SSLASSO(X, y, penalty = c("adaptive", "separable"), variance = c("fixed", "unknown"), 
lambda1, lambda0, nlambda = 100, theta = 0.5, sigma, a = 1, b,  
eps = 0.001, max.iter = 500,  counter = 10, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSLASSO_+3A_x">X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.  <code>SSLASSO</code>
standardizes the data by default.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_y">y</code></td>
<td>
<p>Vector of continuous responses (n x 1). The responses will be centered by default.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  Either &quot;separable&quot;
(with a fixed <code>theta</code>) or &quot;adaptive&quot; (with a random <code>theta</code>, where <code>theta ~ B(a,p)</code>). The default is <code>"adaptive"</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_variance">variance</code></td>
<td>
<p>Whether the error variance is also estimated. Either &quot;fixed&quot; (with a fixed <code>sigma</code>) or &quot;unknown&quot; (with a random <code>sigma</code>, where <code>p(sigma) ~ 1/sigma</code>). The default is <code>"fixed"</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_lambda1">lambda1</code></td>
<td>
<p>Slab variance parameter. Needs to be less than <code>lambda0</code>. The default is <code>lambda0 = 1</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_lambda0">lambda0</code></td>
<td>
<p>Spike penalty parameters (L x 1). Either a numeric value for a single run (L=1) or a sequence of increasing values for dynamic posterior exploration. The default is <code>lambda0 = seq(1, nrow(X), length.out = 100)</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda0</code> values. Default is 100.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_theta">theta</code></td>
<td>
<p>Prior mixing proportion. For &quot;separable&quot; penalty, this value is fixed. For &quot;adaptive&quot; penalty, this value is used as a starting value.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_sigma">sigma</code></td>
<td>
<p>Error variance. For &quot;fixed&quot; variance, this value is fixed. For &quot;unknown&quot; variance, this value is used as a starting value.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_a">a</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>a = 1</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_b">b</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>b = ncol(X)</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_eps">eps</code></td>
<td>
<p>Convergence criterion: converged when difference in regression coefficients is less than <code>eps</code> (default <code>eps = 0.001</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations.  Default is 500.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_counter">counter</code></td>
<td>
<p>Applicable only for the adaptive penalty. Determines how often the parameter <code>theta</code> is updated throughout the cycles of coordinate ascent. Default is 10.</p>
</td></tr>
<tr><td><code id="SSLASSO_+3A_warn">warn</code></td>
<td>
<p>TRUE if warnings should be printed; FALSE by default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter
<code>lambda0</code> is fitted using a coordinate descent algorithm. The algorithm uses 
screening rules for discarding irrelevant predictors along the lines of Breheny (2011).
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"SSLASSO"</code> containing:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients (p x L).  The number of rows is
equal to the number of coefficients <code>p</code>, and the number of columns is
equal to <code>L</code> (the length of <code>lambda0</code>).</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>A vector of length <code>L</code> containing the intercept for each value of <code>lambda0</code>. The intercept is <code>intercept = mean(y) - crossprod(XX, beta)</code>, where <code>XX</code> is the centered design matrix.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>L</code> containing the number
of iterations until convergence at each value of <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>lambda0</code></td>
<td>
<p>The sequence of regularization parameter values in the
path.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>thetas</code></td>
<td>
<p>A vector of length <code>L</code> containing the hyper-parameter values <code>theta</code> (the same as <code>theta</code> for &quot;separable&quot; penalty).</p>
</td></tr>
<tr><td><code>sigmas</code></td>
<td>
<p>A vector of length <code>L</code> containing the values <code>sigma</code> (the same as the initial <code>sigma</code> for &quot;known&quot; variance).</p>
</td></tr>
<tr><td><code>select</code></td>
<td>
<p>A (p x L) binary matrix indicating which variables were selected along the solution path.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>A single model chosen after the stabilization of the regularization path.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Veronika Rockova &lt;Veronika.Rockova@chicagobooth.edu&gt;, Gemma Moran &lt;gmoran@wharton.upenn.edu&gt;</p>


<h3>References</h3>

<p>Rockova, V. and George, E.I. (2018) The Spike-and-Slab LASSO. Journal of the American Statistical Association.
</p>
<p>Moran, G., Rockova, V. and George, E.I. (2018) On variance estimation for Bayesian variable selection. &lt;https://arxiv.org/abs/1801.03019&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.SSLASSO">plot.SSLASSO</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Linear regression, where p &gt; n

library(SSLASSO)

p &lt;- 1000
n &lt;- 100

X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)
beta &lt;- c(1, 2, 3, rep(0, p-3))
y = X[,1] * beta[1] + X[,2] * beta[2] + X[,3] * beta[3] + rnorm(n)

# Oracle SSLASSO with known variance

result1 &lt;- SSLASSO(X, y, penalty = "separable", theta = 3/p)
plot(result1)

# Adaptive SSLASSO with known variance

result2 &lt;- SSLASSO(X, y)
plot(result2)

# Adaptive SSLASSO with unknown variance

result3 &lt;- SSLASSO(X, y, variance = "unknown")
plot(result3)

</code></pre>

<hr>
<h2 id='standard'>Standardizes a design matrix</h2><span id='topic+standard'></span>

<h3>Description</h3>

<p>The function <code>std</code> accepts a design matrix and returns
a standardized version of that matrix (i.e., each column will have
mean 0 and mean sum of squares equal to 1). The code has been adapted from the <code>ncvreg</code> package (Breheny and Huang, 2011).</p>


<h3>Usage</h3>

<pre><code class='language-R'>standard(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standard_+3A_x">X</code></td>
<td>
<p>A matrix (or object that can be coerced to a matrix,
such as a data frame).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function centers and scales each column of <code>X</code> so that
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^n x_{ij}=0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^n x_{ij}^2 = n</code>
</p>

<p>for all j.  This is usually not necessary to call directly, as <code>SSLASSO</code>
internally standardizes the design matrix, but inspection of the
standardized design matrix can sometimes be useful.  This differs from
the base R function <code><a href="base.html#topic+scale">scale</a></code> in two ways: (1) <code>scale</code>
uses the sample standard deviation <code>sqrt(sum(x^2)/(n-1))</code>, while
<code>std</code> uses the root-mean-square, or population, standard
deviation <code>sqrt(mean(sum(x^2)))</code>, and (2) <code>std</code> is faster. The reason for using the population standard deviation is that <code>SSLASSO</code> assumes that the columns of the design matrix have been scaled to have norm <code>sqrt(n)</code>.
</p>


<h3>Value</h3>

<p>The standardized design matrix, with attribues &quot;center&quot; and &quot;scale&quot;
corresponding to the mean and (population) standard deviation used to
scale the columns.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(50), 10, 5)
S &lt;- standard(X)
apply(S, 2, sum)
apply(S, 2, function(x) mean(x^2))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
