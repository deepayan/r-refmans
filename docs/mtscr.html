<!DOCTYPE html><html><head><title>Help for package mtscr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mtscr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mtscr_app'><p>Shiny GUI for mtscr</p></a></li>
<li><a href='#mtscr_creativity'><p>Creativity assessment through semantic distance dataset</p></a></li>
<li><a href='#mtscr_model'><p>Create MTS model</p></a></li>
<li><a href='#mtscr_model_summary'><p>Summarise a model</p></a></li>
<li><a href='#mtscr_prepare'><p>Prepare database for MTS</p></a></li>
<li><a href='#mtscr_score'><p>Score creativity with MTS</p></a></li>
<li><a href='#mtscr_self_rank'><p>Self-chosen best answers</p></a></li>
<li><a href='#mtscr-package'><p>mtscr: Multidimensional Top Scoring for Creativity Research</p></a></li>
<li><a href='#tidyeval'><p>Tidy eval helpers</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multidimensional Top Scoring for Creativity Research</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of Multidimensional Top Scoring
    method for creativity assessment proposed in
    Boris Forthmann, Maciej Karwowski, Roger E. Beaty (2023) &lt;<a href="https://doi.org/10.1037%2Faca0000571">doi:10.1037/aca0000571</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>broom.mixed, cli, dplyr (&ge; 1.1.0), glmmTMB, glue, lifecycle,
methods, purrr, readr, rlang (&ge; 0.4.11), stringr, tibble</td>
</tr>
<tr>
<td>Suggests:</td>
<td>shiny, covr, datamods, DT, roxygen2, shinyWidgets, testthat
(&ge; 3.0.0), withr, writexl</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-27 10:25:44 UTC; jakub</td>
</tr>
<tr>
<td>Author:</td>
<td>Jakub Jędrusiak <a href="https://orcid.org/0000-0002-6481-8210"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph] (University of Wrocław),
  Boris Forthmann <a href="https://orcid.org/0000-0001-9755-7304"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, rev] (University of Münster),
  Roger E. Beaty <a href="https://orcid.org/0000-0001-6114-5973"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (Pennsylvania State University),
  Maciej Karwowski <a href="https://orcid.org/0000-0001-6974-1673"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (University of Wrocław)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jakub Jędrusiak &lt;kuba23031999@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-27 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mtscr_app'>Shiny GUI for mtscr</h2><span id='topic+mtscr_app'></span>

<h3>Description</h3>

<p>Shiny app used as graphical interface for mtscr. Simply invoke <code>mtscr_app()</code> to run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_app()
</code></pre>


<h3>Details</h3>

<p>To use the GUI you need to have the following packages installed:
<code>DT</code>, <code>broom.mixed</code>, <code>datamods</code>, <code>writexl</code>.
</p>
<p>First thing you see after running the app is <code>datamods</code> window for importing your data.
You can use the data already loaded in your environment or any other option.
Then you'll see four dropdown lists used to choose arguments for <code>mtscr_model()</code>
and <code>mtscr_score()</code> functions. Consult these functions' documentation for
more details (execute <code>?mtscr_score</code> in the console). When the parameters are chosen,
click &quot;Generate model&quot; button. After a while (up to a dozen or so seconds) models'
parameters and are shown along with a scored dataframe.
</p>
<p>You can download your data as a .csv or an .xlsx file using buttons in the sidebar.
You can either download the scores only (i.e. the dataframe you see displayed) or
your whole data with <code>.all_max</code> and <code>.all_top2</code> columns added.
</p>
<p>For testing purposes, you may use <code>mtscr_creativity</code> dataframe. In the importing
window change &quot;Global Environment&quot; to &quot;mtscr&quot; and our dataframe should appear
in the upper dropdown list. Use <code>id</code> for the ID column, <code>item</code> for the item
column and <code>SemDis_MEAN</code> for the score column.
</p>


<h3>Value</h3>

<p>Runs the app. No explicit return value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mtscr_score">mtscr_score()</a></code> for more information on the arguments.
</p>
<p><a href="#topic+mtscr_creativity">mtscr_creativity</a> for more information about the example dataset.
</p>
<p>Forthmann, B., Karwowski, M., &amp; Beaty, R. E. (2023).
Don’t throw the “bad” ideas away!
Multidimensional top scoring increases reliability of divergent thinking tasks.
Psychology of Aesthetics, Creativity, and the Arts. <a href="https://doi.org/10.1037/aca0000571">doi:10.1037/aca0000571</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()){
mtscr_app()
}
</code></pre>

<hr>
<h2 id='mtscr_creativity'>Creativity assessment through semantic distance dataset</h2><span id='topic+mtscr_creativity'></span>

<h3>Description</h3>

<p>A dataset from Forthmann, Karwowski &amp; Beaty (2023) paper.
It contains a set of responses in Alternative Uses Task for different items with their
semantic distance assessment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_creativity
</code></pre>


<h3>Format</h3>



<h4><code>mtscr_creativity</code></h4>

<p>A <code>tibble</code> with 4585 rows and 10 columns:
</p>

<dl>
<dt>id</dt><dd><p>patricipant's unique identification number</p>
</dd>
<dt>response</dt><dd><p>response in AUT</p>
</dd>
<dt>item</dt><dd><p>item for which alternative uses were searched for</p>
</dd>
<dt>SemDis_MEAN</dt><dd><p>mean semantic distance</p>
</dd>
</dl>




<h3>Value</h3>

<p>a <a href="tibble.html#topic+tibble-package">tibble</a>
</p>


<h3>Source</h3>

<p><a href="https://osf.io/7rgsp/">https://osf.io/7rgsp/</a>
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.1037/aca0000571">doi:10.1037/aca0000571</a>
</p>

<hr>
<h2 id='mtscr_model'>Create MTS model</h2><span id='topic+mtscr_model'></span>

<h3>Description</h3>

<p>Create MTS model for creativity analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_model(
  df,
  id_column,
  item_column = NULL,
  score_column,
  top = 1,
  prepared = FALSE,
  ties_method = c("random", "average"),
  normalise = TRUE,
  self_ranking = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtscr_model_+3A_df">df</code></td>
<td>
<p>Data frame in long format.</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_id_column">id_column</code></td>
<td>
<p>Name of the column containing participants' id.</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_item_column">item_column</code></td>
<td>
<p>Optional, name of the column containing distinct trials
(e.g. names of items in AUT).</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_score_column">score_column</code></td>
<td>
<p>Name of the column containing divergent thinking scores
(e.g. semantic distance).</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_top">top</code></td>
<td>
<p>Integer or vector of integers (see examples), number of top answers
to include in the model. Default is 1, i.e. only the top answer.</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_prepared">prepared</code></td>
<td>
<p>Logical, is the data already prepared with <code>mtscr_prepare()</code>?</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_ties_method">ties_method</code></td>
<td>
<p>Character string specifying how ties are treated when
ordering. Can be <code>"average"</code> (better for continuous scores like semantic
distance) or <code>"random"</code> (default, better for ratings). See <code><a href="base.html#topic+rank">rank()</a></code> for details.</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_normalise">normalise</code></td>
<td>
<p>Logical, should the creativity score be normalised? Default is <code>TRUE</code> and
it's recommended to leave it as such.</p>
</td></tr>
<tr><td><code id="mtscr_model_+3A_self_ranking">self_ranking</code></td>
<td>
<p>Name of the column containing answers' self-ranking.
Provide if model should be based on top answers self-chosen by the participant.
Every item should have its own ranks. The top answers should have a value of 1,
and the other answers should have a value of 0. In that case, the <code>top</code> argument
doesn't change anything and should be left as <code>top = 1</code>. <code>ties_method</code> is not used if <code>self_ranking</code>
was provided. See <a href="#topic+mtscr_self_rank">mtscr_self_rank</a> for example.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value depends on length of the <code>top</code> argument. If <code>top</code> is a single
integer, a <code>glmmTMB</code> model is returned. If <code>top</code> is a vector of integers, a list
of <code>glmmTMB</code> models is returned, with names corresponding to the <code>top</code> values,
e.g. <code>top1</code>, <code>top2</code>, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("mtscr_creativity", package = "mtscr")

mtscr_creativity &lt;- mtscr_creativity |&gt;
  dplyr::slice_sample(n = 300) # for performance, ignore

mtscr_model(mtscr_creativity, id, item, SemDis_MEAN) |&gt;
  summary()

# three models for top 1, 2, and 3 answers
mtscr_model(mtscr_creativity, id, item, SemDis_MEAN, top = 1:3) |&gt;
  mtscr_model_summary()

# you can prepare data first
data &lt;- mtscr_prepare(mtscr_creativity, id, item, SemDis_MEAN)
mtscr_model(data, id, item, SemDis_MEAN, prepared = TRUE)

# extract effects for creativity score by hand
model &lt;- mtscr_model(mtscr_creativity, id, item, SemDis_MEAN, top = 1)
creativity_score &lt;- glmmTMB::ranef(model)$cond$id[, 1]
</code></pre>

<hr>
<h2 id='mtscr_model_summary'>Summarise a model</h2><span id='topic+mtscr_model_summary'></span>

<h3>Description</h3>

<p>Summarise a model generated with <code><a href="#topic+mtscr_model">mtscr_model</a></code> with
some basic statistics; calculate the empirical reliability
and the first difference of the empirical reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_model_summary(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtscr_model_summary_+3A_model">model</code></td>
<td>
<p>A model generated with <code><a href="#topic+mtscr_model">mtscr_model</a></code>. Can
be a list of models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the following columns:
</p>

<dl>
<dt>model</dt><dd><p>The model number</p>
</dd>
<dt>nobs</dt><dd><p>Number of observations</p>
</dd>
<dt>sigma</dt><dd><p>The square root of the estimated residual variance</p>
</dd>
<dt>logLik</dt><dd><p>The log-likelihood of the model</p>
</dd>
<dt>AIC</dt><dd><p>The Akaike information criterion</p>
</dd>
<dt>BIC</dt><dd><p>The Bayesian information criterion</p>
</dd>
<dt>df.residual</dt><dd><p>The residual degrees of freedom</p>
</dd>
<dt>emp_rel</dt><dd><p>The empirical reliability</p>
</dd>
<dt>FDI</dt><dd><p>The first difference of the empirical reliability</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("mtscr_creativity", package = "mtscr")
mtscr_model(mtscr_creativity, id, item, SemDis_MEAN, top = 1:3) |&gt;
  mtscr_model_summary()
</code></pre>

<hr>
<h2 id='mtscr_prepare'>Prepare database for MTS</h2><span id='topic+mtscr_prepare'></span>

<h3>Description</h3>

<p>Prepare database for MTS analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_prepare(
  df,
  id_column,
  item_column = NULL,
  score_column,
  top = 1,
  minimal = FALSE,
  ties_method = c("random", "average"),
  normalise = TRUE,
  self_ranking = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtscr_prepare_+3A_df">df</code></td>
<td>
<p>Data frame in long format.</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_id_column">id_column</code></td>
<td>
<p>Name of the column containing participants' id.</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_item_column">item_column</code></td>
<td>
<p>Optional, name of the column containing distinct trials
(e.g. names of items in AUT).</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_score_column">score_column</code></td>
<td>
<p>Name of the column containing divergent thinking scores
(e.g. semantic distance).</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_top">top</code></td>
<td>
<p>Integer or vector of integers (see examples), number of top answers
to prepare indicators for. Default is 1, i.e. only the top answer.</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_minimal">minimal</code></td>
<td>
<p>Logical, append columns to df (<code>FALSE</code>) or return only <code>id</code>, <code>item</code>,
and the new columns (<code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_ties_method">ties_method</code></td>
<td>
<p>Character string specifying how ties are treated when
ordering. Can be <code>"average"</code> (better for continuous scores like semantic
distance) or <code>"random"</code> (default, better for ratings). See <code><a href="base.html#topic+rank">rank()</a></code> for details.</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_normalise">normalise</code></td>
<td>
<p>Logical, should the creativity score be normalised? Default is <code>TRUE</code> and
it's recommended to leave it as such.</p>
</td></tr>
<tr><td><code id="mtscr_prepare_+3A_self_ranking">self_ranking</code></td>
<td>
<p>Name of the column containing answers' self-ranking.
Provide if model should be based on top answers self-chosen by the participant.
Every item should have its own ranks. The top answers should have a value of 1,
and the other answers should have a value of 0. In that case, the <code>top</code> argument
doesn't change anything and should be left as <code>top = 1</code>. <code>ties_method</code> is not used if <code>self_ranking</code>
was provided. See <a href="#topic+mtscr_self_rank">mtscr_self_rank</a> for example.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data frame with additional columns:
</p>

<dl>
<dt><code>.z_score</code></dt><dd><p>Numerical, z-score of the creativity score</p>
</dd>
<dt><code>.ordering</code></dt><dd><p>Numerical, ranking of the answer relative to participant and item</p>
</dd>
<dt><code>.ordering_topX</code></dt><dd><p>Numerical, 0 for <em>X</em> top answers, otherwise value of <code>.ordering</code></p>
</dd>
</dl>

<p>Number of <code>.ordering_topX</code> columns depends on the <code>top</code> argument. If <code>minimal = TRUE</code>,
only the new columns and the item and id columns are returned. The values are
relative to the participant AND item, so the values for different
participants scored for different tasks (e.g. uses for &quot;brick&quot; and &quot;can&quot;) are distinct.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("mtscr_creativity", package = "mtscr")
# Indicators for top 1 and top 2 answers
mtscr_prepare(mtscr_creativity, id, item, SemDis_MEAN, top = 1:2, minimal = TRUE)
</code></pre>

<hr>
<h2 id='mtscr_score'>Score creativity with MTS</h2><span id='topic+mtscr_score'></span>

<h3>Description</h3>

<p>Score creativity with MTS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_score(
  df,
  id_column,
  item_column = NULL,
  score_column,
  top = 1,
  format = c("minimal", "full"),
  ties_method = c("random", "average"),
  normalise = TRUE,
  self_ranking = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtscr_score_+3A_df">df</code></td>
<td>
<p>Data frame in long format.</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_id_column">id_column</code></td>
<td>
<p>Name of the column containing participants' id.</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_item_column">item_column</code></td>
<td>
<p>Optional, name of the column containing distinct trials
(e.g. names of items in AUT).</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_score_column">score_column</code></td>
<td>
<p>Name of the column containing divergent thinking scores
(e.g. semantic distance).</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_top">top</code></td>
<td>
<p>Integer or vector of integers (see examples), number of top answers
to prepare indicators for. Default is 1, i.e. only the top answer.</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_format">format</code></td>
<td>
<p>Character, controls the format of the output data frame. Accepts:
</p>

<dl>
<dt><code>"minimal"</code></dt><dd><p>default, returns only the creativity scores and id columns.</p>
</dd>
<dt><code>"full"</code></dt><dd><p>returns the original data frame with creativity scores columns added.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mtscr_score_+3A_ties_method">ties_method</code></td>
<td>
<p>Character string specifying how ties are treated when
ordering. Can be <code>"average"</code> (better for continuous scores like semantic
distance) or <code>"random"</code> (default, better for ratings). See <code><a href="base.html#topic+rank">rank()</a></code> for details.</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_normalise">normalise</code></td>
<td>
<p>Logical, should the creativity score be normalised? Default is <code>TRUE</code> and
it's recommended to leave it as such.</p>
</td></tr>
<tr><td><code id="mtscr_score_+3A_self_ranking">self_ranking</code></td>
<td>
<p>Name of the column containing answers' self-ranking.
Provide if model should be based on top answers self-chosen by the participant.
Every item should have its own ranks. The top answers should have a value of 1,
and the other answers should have a value of 0. In that case, the <code>top</code> argument
doesn't change anything and should be left as <code>top = 1</code>. <code>ties_method</code> is not used if <code>self_ranking</code>
was provided. See <a href="#topic+mtscr_self_rank">mtscr_self_rank</a> for example.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with creativity scores. If <code>format = "full"</code>, the original data frame is
returned with scores columns added. Otherwise, only the scores and id columns are returned.
number of creativity scores columns (e.g. <code>creativity_score_top2</code>) depends on the <code>top</code> argument.
</p>


<h3>See Also</h3>

<p><code><a href="tidyr.html#topic+pivot_wider">tidyr::pivot_wider()</a></code> for converting the output to wide format by yourself.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("mtscr_creativity", package = "mtscr")
mtscr_score(mtscr_creativity, id, item, SemDis_MEAN, top = 1:2)

# add scores to the original data frame
mtscr_score(mtscr_creativity, id, item, SemDis_MEAN, format = "full")

# use self-chosen best answers
data("mtscr_self_rank", package = "mtscr")
mtscr_score(mtscr_self_rank, subject, task, avr, self_ranking = top_two)
</code></pre>

<hr>
<h2 id='mtscr_self_rank'>Self-chosen best answers</h2><span id='topic+mtscr_self_rank'></span>

<h3>Description</h3>

<p>An example dataset with best answers self-chosen by the participant. Use with <code>self_ranking</code>
argument in <a href="#topic+mtscr_model">mtscr_model</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtscr_self_rank
</code></pre>


<h3>Format</h3>



<h4><code>mtscr_self_rank</code></h4>

<p>A tibble with 3225 rows and 4 columns:
</p>

<dl>
<dt>subject</dt><dd><p>patricipant's unique identification number</p>
</dd>
<dt>task</dt><dd><p>divergent thinking task number</p>
</dd>
<dt>avr</dt><dd><p>average judges' raiting</p>
</dd>
<dt>top_two</dt><dd><p>indicator of self-chosen two best answer; 1 if chosen, 0 if not</p>
</dd>
</dl>




<h3>Source</h3>

<p><a href="https://osf.io/7rgsp/">https://osf.io/7rgsp/</a>
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.1037/aca0000571">doi:10.1037/aca0000571</a>
</p>

<hr>
<h2 id='mtscr-package'>mtscr: Multidimensional Top Scoring for Creativity Research</h2><span id='topic+mtscr'></span><span id='topic+mtscr-package'></span>

<h3>Description</h3>

<p>Implementation of Multidimensional Top Scoring method for creativity assessment proposed in Boris Forthmann, Maciej Karwowski, Roger E. Beaty (2023) <a href="https://doi.org/10.1037/aca0000571">doi:10.1037/aca0000571</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jakub Jędrusiak <a href="mailto:kuba23031999@gmail.com">kuba23031999@gmail.com</a> (<a href="https://orcid.org/0000-0002-6481-8210">ORCID</a>) (University of Wrocław) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Boris Forthmann <a href="mailto:boris.forthmann@uni-muenster.de">boris.forthmann@uni-muenster.de</a> (<a href="https://orcid.org/0000-0001-9755-7304">ORCID</a>) (University of Münster) [reviewer]
</p>
</li>
<li><p> Roger E. Beaty <a href="mailto:rebeaty@psu.edu">rebeaty@psu.edu</a> (<a href="https://orcid.org/0000-0001-6114-5973">ORCID</a>) (Pennsylvania State University)
</p>
</li>
<li><p> Maciej Karwowski <a href="mailto:maciej.karwowski@uwr.edu.pl">maciej.karwowski@uwr.edu.pl</a> (<a href="https://orcid.org/0000-0001-6974-1673">ORCID</a>) (University of Wrocław)
</p>
</li></ul>


<hr>
<h2 id='tidyeval'>Tidy eval helpers</h2><span id='topic+tidyeval'></span><span id='topic+enquo'></span><span id='topic+enquos'></span><span id='topic+.data'></span><span id='topic++3A+3D'></span><span id='topic+as_name'></span><span id='topic+as_label'></span>

<h3>Description</h3>

<p>This page lists the tidy eval tools reexported in this package from
rlang. To learn about using tidy eval in scripts and packages at a
high level, see the <a href="https://dplyr.tidyverse.org/articles/programming.html">dplyr programming vignette</a>
and the <a href="https://ggplot2.tidyverse.org/articles/ggplot2-in-packages.html">ggplot2 in packages vignette</a>.
The <a href="https://adv-r.hadley.nz/metaprogramming.html">Metaprogramming section</a> of <a href="https://adv-r.hadley.nz">Advanced R</a> may also be useful for a deeper dive.
</p>

<ul>
<li><p> The tidy eval operators <code style="white-space: pre;">&#8288;{{&#8288;</code>, <code style="white-space: pre;">&#8288;!!&#8288;</code>, and <code style="white-space: pre;">&#8288;!!!&#8288;</code> are syntactic
constructs which are specially interpreted by tidy eval functions.
You will mostly need <code style="white-space: pre;">&#8288;{{&#8288;</code>, as <code style="white-space: pre;">&#8288;!!&#8288;</code> and <code style="white-space: pre;">&#8288;!!!&#8288;</code> are more advanced
operators which you should not have to use in simple cases.
</p>
<p>The curly-curly operator <code style="white-space: pre;">&#8288;{{&#8288;</code> allows you to tunnel data-variables
passed from function arguments inside other tidy eval functions.
<code style="white-space: pre;">&#8288;{{&#8288;</code> is designed for individual arguments. To pass multiple
arguments contained in dots, use <code>...</code> in the normal way.
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, ...) {
  data %&gt;%
    group_by(...) %&gt;%
    summarise(mean = mean({{ var }}))
}
</pre></div>
</li>
<li> <p><code><a href="#topic+enquo">enquo()</a></code> and <code><a href="#topic+enquos">enquos()</a></code> delay the execution of one or several
function arguments. The former returns a single expression, the
latter returns a list of expressions. Once defused, expressions
will no longer evaluate on their own. They must be injected back
into an evaluation context with <code style="white-space: pre;">&#8288;!!&#8288;</code> (for a single expression) and
<code style="white-space: pre;">&#8288;!!!&#8288;</code> (for a list of expressions).
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, ...) {
  # Defuse
  var &lt;- enquo(var)
  dots &lt;- enquos(...)

  # Inject
  data %&gt;%
    group_by(!!!dots) %&gt;%
    summarise(mean = mean(!!var))
}
</pre></div>
<p>In this simple case, the code is equivalent to the usage of <code style="white-space: pre;">&#8288;{{&#8288;</code>
and <code>...</code> above. Defusing with <code>enquo()</code> or <code>enquos()</code> is only
needed in more complex cases, for instance if you need to inspect
or modify the expressions in some way.
</p>
</li>
<li><p> The <code>.data</code> pronoun is an object that represents the current
slice of data. If you have a variable name in a string, use the
<code>.data</code> pronoun to subset that variable with <code>[[</code>.
</p>
<div class="sourceCode"><pre>my_var &lt;- "disp"
mtcars %&gt;% summarise(mean = mean(.data[[my_var]]))
</pre></div>
</li>
<li><p> Another tidy eval operator is <code style="white-space: pre;">&#8288;:=&#8288;</code>. It makes it possible to use
glue and curly-curly syntax on the LHS of <code>=</code>. For technical
reasons, the R language doesn't support complex expressions on
the left of <code>=</code>, so we use <code style="white-space: pre;">&#8288;:=&#8288;</code> as a workaround.
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, suffix = "foo") {
  # Use `{{` to tunnel function arguments and the usual glue
  # operator `{` to interpolate plain strings.
  data %&gt;%
    summarise("{{ var }}_mean_{suffix}" := mean({{ var }}))
}
</pre></div>
</li>
<li><p> Many tidy eval functions like <code>dplyr::mutate()</code> or
<code>dplyr::summarise()</code> give an automatic name to unnamed inputs. If
you need to create the same sort of automatic names by yourself,
use <code>as_label()</code>. For instance, the glue-tunnelling syntax above
can be reproduced manually with:
</p>
<div class="sourceCode"><pre>my_function &lt;- function(data, var, suffix = "foo") {
  var &lt;- enquo(var)
  prefix &lt;- as_label(var)
  data %&gt;%
    summarise("{prefix}_mean_{suffix}" := mean(!!var))
}
</pre></div>
<p>Expressions defused with <code>enquo()</code> (or tunnelled with <code style="white-space: pre;">&#8288;{{&#8288;</code>) need
not be simple column names, they can be arbitrarily complex.
<code>as_label()</code> handles those cases gracefully. If your code assumes
a simple column name, use <code>as_name()</code> instead. This is safer
because it throws an error if the input is not a name as expected.
</p>
</li></ul>



<h3>Value</h3>

<p>Functions imported from rlang, see
their documentation for the return values.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
