<!DOCTYPE html><html lang="en"><head><title>Help for package grafzahl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {grafzahl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#detect_conda'><p>Detecting Miniconda And Cuda</p></a></li>
<li><a href='#ecosent'><p>A Corpus Of Dutch News Headlines</p></a></li>
<li><a href='#get_amharic_data'><p>Download The Amharic News Text Classification Dataset</p></a></li>
<li><a href='#grafzahl'><p>Fine tune a pretrained Transformer model for texts</p></a></li>
<li><a href='#hydrate'><p>Create a grafzahl S3 object from the output_dir</p></a></li>
<li><a href='#predict.grafzahl'><p>Prediction from a fine-tuned grafzahl object</p></a></li>
<li><a href='#setup_grafzahl'><p>Setup grafzahl</p></a></li>
<li><a href='#supported_model_types'><p>Supported model types</p></a></li>
<li><a href='#unciviltweets'><p>A Corpus Of Tweets With Incivility Labels</p></a></li>
<li><a href='#use_nonconda'><p>Set up grafzahl to be used on Google Colab or similar environments</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Supervised Machine Learning for Textual Data Using Transformers
and 'Quanteda'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.11</td>
</tr>
<tr>
<td>Description:</td>
<td>Duct tape the 'quanteda' ecosystem (Benoit et al., 2018) &lt;<a href="https://doi.org/10.21105%2Fjoss.00774">doi:10.21105/joss.00774</a>&gt; to modern Transformer-based text classification models (Wolf et al., 2020) &lt;<a href="https://doi.org/10.18653%2Fv1%2F2020.emnlp-demos.6">doi:10.18653/v1/2020.emnlp-demos.6</a>&gt;, in order to facilitate supervised machine learning for textual data. This package mimics the behaviors of 'quanteda.textmodels' and provides a function to setup the 'Python' environment to use the pretrained models from 'Hugging Face' <a href="https://huggingface.co/">https://huggingface.co/</a>. More information: &lt;<a href="https://doi.org/10.5117%2FCCR2023.1.003.CHAN">doi:10.5117/CCR2023.1.003.CHAN</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://gesistsa.github.io/grafzahl/">https://gesistsa.github.io/grafzahl/</a>,
<a href="https://github.com/gesistsa/grafzahl">https://github.com/gesistsa/grafzahl</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gesistsa/grafzahl/issues">https://github.com/gesistsa/grafzahl/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, quanteda.textmodels, rmarkdown, testthat (&ge; 3.0.0),
withr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>jsonlite, lime, quanteda, reticulate, utils, stats</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>gesistsa/tsatemplate</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-26 09:25:38 UTC; chainsawriot</td>
</tr>
<tr>
<td>Author:</td>
<td>Chung-hong Chan <a href="https://orcid.org/0000-0002-6232-7530"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chung-hong Chan &lt;chainsawtiney@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-26 10:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='detect_conda'>Detecting Miniconda And Cuda</h2><span id='topic+detect_conda'></span><span id='topic+detect_cuda'></span>

<h3>Description</h3>

<p>These functions detects miniconda and cuda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_conda()

detect_cuda()
</code></pre>


<h3>Details</h3>

<p><code>detect_conda</code> conducts a test to check whether 1) a miniconda installation and 2) the grafzahl miniconda environment exist.
</p>
<p><code>detect_cuda</code> checks whether cuda is available. If <code>setup_grafzahl</code> was executed with <code>cuda</code> being <code>FALSE</code>, this function will return <code>FALSE</code>. Even if <code>setup_grafzahl</code> was executed with <code>cuda</code> being <code>TRUE</code> but with any factor that can't enable cuda (e.g. no Nvidia GPU, the environment was incorrectly created), this function will also return <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>boolean, whether the system is available.
</p>

<hr>
<h2 id='ecosent'>A Corpus Of Dutch News Headlines</h2><span id='topic+ecosent'></span>

<h3>Description</h3>

<p>This is a dataset from the paper &quot;The Validity of Sentiment Analysis: Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms.&quot;
The data frame contains four columns: id (identifier), headline (the actual text data), value (sentiment: 0 Neutral, +1 Positive, -1 Negative), gold (whether or not this row is &quot;gold standard&quot;, i.e. test set). The data is available from Wouter van Atteveldt's Github. <a href="https://github.com/vanatteveldt/ecosent">https://github.com/vanatteveldt/ecosent</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecosent
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 6322 rows and 4 columns.
</p>


<h3>References</h3>

<p>Van Atteveldt, W., Van der Velden, M. A., &amp; Boukes, M. (2021). The validity of sentiment analysis: Comparing manual annotation, crowd-coding, dictionary approaches, and machine learning algorithms. Communication Methods and Measures, 15(2), 121-140.
</p>

<hr>
<h2 id='get_amharic_data'>Download The Amharic News Text Classification Dataset</h2><span id='topic+get_amharic_data'></span>

<h3>Description</h3>

<p>This function downloads the training and test sets of the Amharic News Text Classification Dataset from Hugging Face.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_amharic_data()
</code></pre>


<h3>Value</h3>

<p>A named list of two corpora: training and test
</p>


<h3>References</h3>

<p>Azime, Israel Abebe, and Nebil Mohammed (2021). &quot;An Amharic News Text classification Dataset.&quot; arXiv preprint arXiv:2103.05639
</p>

<hr>
<h2 id='grafzahl'>Fine tune a pretrained Transformer model for texts</h2><span id='topic+grafzahl'></span><span id='topic+grafzahl.default'></span><span id='topic+grafzahl.corpus'></span><span id='topic+textmodel_transformer'></span><span id='topic+grafzahl.character'></span>

<h3>Description</h3>

<p>Fine tune (or train) a pretrained Transformer model for your given training labelled data <code>x</code> and <code>y</code>. The prediction task can be classification (if <code>regression</code> is <code>FALSE</code>, default) or regression (if <code>regression</code> is <code>TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

## Default S3 method:
grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

## S3 method for class 'corpus'
grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

textmodel_transformer(...)

## S3 method for class 'character'
grafzahl(
  x,
  y = NULL,
  model_name = "xlmroberta",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grafzahl_+3A_x">x</code></td>
<td>
<p>the corpus or character vector of texts on which the model will be trained. Depending on <code>train_size</code>, some texts will be used for cross-validation.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_y">y</code></td>
<td>
<p>training labels. It can either be a single string indicating which docvars of the corpus is the training labels; a vector of training labels in either character or factor; or <code>NULL</code> if the corpus contains exactly one column in docvars and that column is the training labels. If <code>x</code> is a character vector, <code>y</code> must be a vector of the same length.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_model_name">model_name</code></td>
<td>
<p>string indicates either 1) the model name on Hugging Face website; 2) the local path of the model</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_regression">regression</code></td>
<td>
<p>logical, if <code>TRUE</code>, the task is regression, classification otherwise.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_output_dir">output_dir</code></td>
<td>
<p>string, location of the output model. If missing, the model will be stored in a temporary directory. Important: Please note that if this directory exists, it will be overwritten.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_cuda">cuda</code></td>
<td>
<p>logical, whether to use CUDA, default to <code><a href="#topic+detect_cuda">detect_cuda()</a></code>.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_num_train_epochs">num_train_epochs</code></td>
<td>
<p>numeric, if <code>train_size</code> is not exactly 1.0, the maximum number of epochs to try in the &quot;early stop&quot; regime will be this number times 5 (i.e. 4 * 5 = 20 by default). If <code>train_size</code> is exactly 1.0, the number of epochs is exactly that.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_train_size">train_size</code></td>
<td>
<p>numeric, proportion of data in <code>x</code> and <code>y</code> to be used actually for training. The rest will be used for cross validation.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_args">args</code></td>
<td>
<p>list, additionally parameters to be used in the underlying simple transformers</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_cleanup">cleanup</code></td>
<td>
<p>logical, if <code>TRUE</code>, the <code>runs</code> directory generated will be removed when the training is done</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_model_type">model_type</code></td>
<td>
<p>a string indicating model_type of the input model. If <code>NULL</code>, it will be inferred from <code>model_name</code>. Supported model types are available in <a href="#topic+supported_model_types">supported_model_types</a>.</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_manual_seed">manual_seed</code></td>
<td>
<p>numeric, random seed</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>TRUE</code>, debug messages will be displayed</p>
</td></tr>
<tr><td><code id="grafzahl_+3A_...">...</code></td>
<td>
<p>paramters pass to <code><a href="#topic+grafzahl">grafzahl()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>grafzahl</code> S3 object with the following items
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>original function call</p>
</td></tr>
<tr><td><code>input_data</code></td>
<td>
<p>input_data for the underlying python function</p>
</td></tr>
<tr><td><code>output_dir</code></td>
<td>
<p>location of the output model</p>
</td></tr>
<tr><td><code>model_type</code></td>
<td>
<p>model type</p>
</td></tr>
<tr><td><code>model_name</code></td>
<td>
<p>model name</p>
</td></tr>
<tr><td><code>regression</code></td>
<td>
<p>whether or not it is a regression model</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>factor levels of y</p>
</td></tr>
<tr><td><code>manual_seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code>meta</code></td>
<td>
<p>metadata about the current session</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+predict.grafzahl">predict.grafzahl()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (detect_conda() &amp;&amp; interactive()) {
library(quanteda)
set.seed(20190721)
## Using the default cross validation method
model1 &lt;- grafzahl(unciviltweets, model_type = "bertweet", model_name = "vinai/bertweet-base")
predict(model1)

## Using LIME
input &lt;- corpus(ecosent, text_field = "headline")
training_corpus &lt;- corpus_subset(input, !gold)
model2 &lt;- grafzahl(x = training_corpus,
                 y = "value",
                 model_name = "GroNLP/bert-base-dutch-cased")
test_corpus &lt;- corpus_subset(input, gold)
predicted_sentiment &lt;- predict(model2, test_corpus)
require(lime)
sentences &lt;- c("Dijsselbloem pessimistisch over snelle stappen Grieken",
               "Aandelenbeurzen zetten koersopmars voort")
explainer &lt;- lime(training_corpus, model2)
explanations &lt;- explain(sentences, explainer, n_labels = 1,
                        n_features = 2)
plot_text_explanations(explanations)
}
</code></pre>

<hr>
<h2 id='hydrate'>Create a grafzahl S3 object from the output_dir</h2><span id='topic+hydrate'></span>

<h3>Description</h3>

<p>Create a grafzahl S3 object from the output_dir
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hydrate(output_dir, model_type = NULL, regression = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hydrate_+3A_output_dir">output_dir</code></td>
<td>
<p>string, location of the output model. If missing, the model will be stored in a temporary directory. Important: Please note that if this directory exists, it will be overwritten.</p>
</td></tr>
<tr><td><code id="hydrate_+3A_model_type">model_type</code></td>
<td>
<p>a string indicating model_type of the input model. If <code>NULL</code>, it will be inferred from <code>model_name</code>. Supported model types are available in <a href="#topic+supported_model_types">supported_model_types</a>.</p>
</td></tr>
<tr><td><code id="hydrate_+3A_regression">regression</code></td>
<td>
<p>logical, if <code>TRUE</code>, the task is regression, classification otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>grafzahl</code> S3 object with the following items
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>original function call</p>
</td></tr>
<tr><td><code>input_data</code></td>
<td>
<p>input_data for the underlying python function</p>
</td></tr>
<tr><td><code>output_dir</code></td>
<td>
<p>location of the output model</p>
</td></tr>
<tr><td><code>model_type</code></td>
<td>
<p>model type</p>
</td></tr>
<tr><td><code>model_name</code></td>
<td>
<p>model name</p>
</td></tr>
<tr><td><code>regression</code></td>
<td>
<p>whether or not it is a regression model</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>factor levels of y</p>
</td></tr>
<tr><td><code>manual_seed</code></td>
<td>
<p>random seed</p>
</td></tr>
<tr><td><code>meta</code></td>
<td>
<p>metadata about the current session</p>
</td></tr>
</table>

<hr>
<h2 id='predict.grafzahl'>Prediction from a fine-tuned grafzahl object</h2><span id='topic+predict.grafzahl'></span>

<h3>Description</h3>

<p>Make prediction from a fine-tuned grafzahl object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grafzahl'
predict(object, newdata, cuda = detect_cuda(), return_raw = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.grafzahl_+3A_object">object</code></td>
<td>
<p>an S3 object trained with <code><a href="#topic+grafzahl">grafzahl()</a></code></p>
</td></tr>
<tr><td><code id="predict.grafzahl_+3A_newdata">newdata</code></td>
<td>
<p>a corpus or a character vector of texts on which prediction should be made.</p>
</td></tr>
<tr><td><code id="predict.grafzahl_+3A_cuda">cuda</code></td>
<td>
<p>logical, whether to use CUDA, default to <code><a href="#topic+detect_cuda">detect_cuda()</a></code>.</p>
</td></tr>
<tr><td><code id="predict.grafzahl_+3A_return_raw">return_raw</code></td>
<td>
<p>logical, if <code>TRUE</code>, return a matrix of logits; a vector of class prediction otherwise</p>
</td></tr>
<tr><td><code id="predict.grafzahl_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class prediction or a matrix of logits
</p>

<hr>
<h2 id='setup_grafzahl'>Setup grafzahl</h2><span id='topic+setup_grafzahl'></span>

<h3>Description</h3>

<p>Install a self-contained miniconda environment with all Python components (PyTorch, Transformers, Simpletransformers, etc) which grafzahl required. The default location is &quot;~/.local/share/r-miniconda/envs/grafzahl_condaenv&quot; (suffix &quot;_cuda&quot; is added if <code>cuda</code> is <code>TRUE</code>).
On Linux or Mac and if miniconda is not found, this function will also install miniconda. The path can be changed by the environment variable <code>GRAFZAHL_MINICONDA_PATH</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_grafzahl(cuda = FALSE, force = FALSE, cuda_version = "11.3")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setup_grafzahl_+3A_cuda">cuda</code></td>
<td>
<p>logical, if <code>TRUE</code>, indicate whether a CUDA-enabled environment is wanted.</p>
</td></tr>
<tr><td><code id="setup_grafzahl_+3A_force">force</code></td>
<td>
<p>logical, if <code>TRUE</code>, delete previous environment (if exists) and create a new environment</p>
</td></tr>
<tr><td><code id="setup_grafzahl_+3A_cuda_version">cuda_version</code></td>
<td>
<p>character, indicate CUDA version, ignore if <code>cuda</code> is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE (invisibly) if installation is successful.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># setup an environment with cuda enabled.
if (detect_conda() &amp;&amp; interactive()) {
    setup_grafzahl(cuda = TRUE)
}
</code></pre>

<hr>
<h2 id='supported_model_types'>Supported model types</h2><span id='topic+supported_model_types'></span>

<h3>Description</h3>

<p>A vector of all supported model types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>supported_model_types
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 23.
</p>

<hr>
<h2 id='unciviltweets'>A Corpus Of Tweets With Incivility Labels</h2><span id='topic+unciviltweets'></span>

<h3>Description</h3>

<p>This is a dataset from the paper &quot;The Dynamics of Political Incivility on Twitter&quot;. The tweets were by Members of Congress elected to the 115th Congress (2017–2018). It is important to note that not all the incivility labels were coded by human. Majority of the labels were coded by the Google Perspective API. All mentions were removed. The dataset is available from Pablo Barbera's Github. <a href="https://github.com/pablobarbera/incivility-sage-open">https://github.com/pablobarbera/incivility-sage-open</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unciviltweets
</code></pre>


<h3>Format</h3>

<p>An object of class <code>corpus</code> (inherits from <code>character</code>) of length 19982.
</p>


<h3>References</h3>

<p>Theocharis, Y., Barberá, P., Fazekas, Z., &amp; Popa, S. A. (2020). The dynamics of political incivility on Twitter. Sage Open, 10(2), 2158244020919447.
</p>

<hr>
<h2 id='use_nonconda'>Set up grafzahl to be used on Google Colab or similar environments</h2><span id='topic+use_nonconda'></span>

<h3>Description</h3>

<p>Set up grafzahl to be used on Google Colab or similar environments. This function is also useful if you do not
want to use conda on a local machine, e.g. you have configurateed the required Python package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>use_nonconda(install = TRUE, check = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="use_nonconda_+3A_install">install</code></td>
<td>
<p>logical, whether to install the required Python packages</p>
</td></tr>
<tr><td><code id="use_nonconda_+3A_check">check</code></td>
<td>
<p>logical, whether to perform a check after the setup. The check displays 1) whether CUDA can be detected, 2) whether
the non-conda mode has been activated, i.e. whether the option 'grafzahl.nonconda' is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="use_nonconda_+3A_verbose">verbose</code></td>
<td>
<p>logical, whether to display messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE (invisibly) if installation is successful.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A typical use case for Google Colab
if (interactive()) {
    use_nonconda()
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
