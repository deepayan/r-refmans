<!DOCTYPE html><html lang="en"><head><title>Help for package multinomineq</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {multinomineq}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#multinomineq-package'><p>multinomineq: Bayesian Inference for Inequality-Constrained Multinomial Models</p></a></li>
<li><a href='#Ab_drop_fixed'><p>Drop fixed columns in the Ab-Representation</p></a></li>
<li><a href='#Ab_max'><p>Automatic Construction of Ab-Representation for Common Inequality Constraints</p></a></li>
<li><a href='#Ab_multinom'><p>Get Constraints for Product-Multinomial Probabilities</p></a></li>
<li><a href='#Ab_sort'><p>Sort Inequalities by Acceptance Rate</p></a></li>
<li><a href='#bf_binom'><p>Bayes Factor for Linear Inequality Constraints</p></a></li>
<li><a href='#bf_equality'><p>Bayes Factor with Inequality and (Approximate) Equality Constraints</p></a></li>
<li><a href='#bf_nonlinear'><p>Bayes Factor for Nonlinear Inequality Constraints</p></a></li>
<li><a href='#binom_to_multinom'><p>Converts Binary to Multinomial Frequencies</p></a></li>
<li><a href='#count_binom'><p>Count How Many Samples Satisfy Linear Inequalities (Binomial)</p></a></li>
<li><a href='#count_multinom'><p>Count How Many Samples Satisfy Linear Inequalities (Multinomial)</p></a></li>
<li><a href='#count_to_bf'><p>Compute Bayes Factor Using Prior/Posterior Counts</p></a></li>
<li><a href='#drop_fixed'><p>Drop or Add Fixed Dimensions for Multinomial Probabilities/Frequencies</p></a></li>
<li><a href='#find_inside'><p>Find a Point/Parameter Vector Within a Convex Polytope</p></a></li>
<li><a href='#heck2017'><p>Data: Multiattribute Decisions (Heck, Hilbig &amp; Moshagen, 2017)</p></a></li>
<li><a href='#heck2017_raw'><p>Data: Multiattribute Decisions (Heck, Hilbig &amp; Moshagen, 2017)</p></a></li>
<li><a href='#hilbig2014'><p>Data: Multiattribute Decisions (Hilbig &amp; Moshagen, 2014)</p></a></li>
<li><a href='#inside'><p>Check Whether Points are Inside a Convex Polytope</p></a></li>
<li><a href='#inside_binom'><p>Check Whether Choice Frequencies are in Polytope</p></a></li>
<li><a href='#karabatsos2004'><p>Data: Item Responses Theory (Karabatsos &amp; Sheu, 2004)</p></a></li>
<li><a href='#ml_binom'><p>Maximum-likelihood Estimate</p></a></li>
<li><a href='#model_weights'><p>Get Posterior/NML Model Weights</p></a></li>
<li><a href='#nirt_to_Ab'><p>Nonparametric Item Response Theory (NIRT)</p></a></li>
<li><a href='#population_bf'><p>Aggregation of Individual Bayes Factors</p></a></li>
<li><a href='#postprob'><p>Transform Bayes Factors to Posterior Model Probabilities</p></a></li>
<li><a href='#ppp_binom'><p>Posterior Predictive p-Values</p></a></li>
<li><a href='#regenwetter2012'><p>Data: Ternary Risky Choices (Regenwetter &amp; Davis-Stober, 2012)</p></a></li>
<li><a href='#rpbinom'><p>Random Generation for Independent Multinomial Distributions</p></a></li>
<li><a href='#rpdirichlet'><p>Random Samples from the Product-Dirichlet Distribution</p></a></li>
<li><a href='#sampling_multinom'><p>Posterior Sampling for Inequality-Constrained Multinomial Models</p></a></li>
<li><a href='#sampling_nonlinear'><p>Posterior Sampling for Multinomial Models with Nonlinear Inequalities</p></a></li>
<li><a href='#stochdom_Ab'><p>Ab-Representation for Stochastic Dominance of Histogram Bins</p></a></li>
<li><a href='#stochdom_bf'><p>Bayes Factor for Stochastic Dominance of Continuous Distributions</p></a></li>
<li><a href='#strategy_marginal'><p>Log-Marginal Likelihood for Decision Strategy</p></a></li>
<li><a href='#strategy_multiattribute'><p>Strategy Predictions for Multiattribute Decisions</p></a></li>
<li><a href='#strategy_postprob'><p>Strategy Classification: Posterior Model Probabilities</p></a></li>
<li><a href='#strategy_to_Ab'><p>Transform Pattern of Predictions to Polytope</p></a></li>
<li><a href='#strategy_unique'><p>Unique Patterns/Item Types of Strategy Predictions</p></a></li>
<li><a href='#swop5'><p>Strict Weak Order Polytope for 5 Elements and Ternary Choices</p></a></li>
<li><a href='#V_to_Ab'><p>Transform Vertex/Inequality Representation of Polytope</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Inference for Multinomial Models with Inequality
Constraints</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-19</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel W. Heck &lt;daniel.heck@uni-marburg.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Implements Gibbs sampling and Bayes factors for multinomial models with
    linear inequality constraints on the vector of probability parameters. As
    special cases, the model class includes models that predict a linear order 
    of binomial probabilities (e.g., p[1] &lt; p[2] &lt; p[3] &lt; .50) and mixture models 
    assuming that the parameter vector p must be inside the convex hull of a 
    finite number of predicted patterns (i.e., vertices). A formal definition of 
    inequality-constrained multinomial models and the implemented computational
    methods is provided in: Heck, D.W., &amp; Davis-Stober, C.P. (2019). 
    Multinomial models with linear inequality constraints: Overview and improvements 
    of computational methods for Bayesian inference. Journal of Mathematical 
    Psychology, 91, 70-87. &lt;<a href="https://doi.org/10.1016%2Fj.jmp.2019.03.004">doi:10.1016/j.jmp.2019.03.004</a>&gt;.
    Inequality-constrained multinomial models have applications in the area of 
    judgment and decision making to fit and test random utility models  
    (Regenwetter, M., Dana, J., &amp; Davis-Stober, C.P. (2011). Transitivity of 
    preferences. Psychological Review, 118, 42–56, &lt;<a href="https://doi.org/10.1037%2Fa0021150">doi:10.1037/a0021150</a>&gt;) or to 
    perform outcome-based strategy classification to select the decision strategy 
    that provides the best account for a vector of observed choice frequencies 
    (Heck, D.W., Hilbig, B.E., &amp; Moshagen, M. (2017). From information 
    processing to decisions: Formalizing and comparing probabilistic choice models. 
    Cognitive Psychology, 96, 26–40. &lt;<a href="https://doi.org/10.1016%2Fj.cogpsych.2017.05.003">doi:10.1016/j.cogpsych.2017.05.003</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/danheck/multinomineq">https://github.com/danheck/multinomineq</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.11), parallel, Rglpk, quadprog, coda,
RcppXPtrUtils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, covr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppProgress</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-20 00:34:19 UTC; Daniel</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel W. Heck <a href="https://orcid.org/0000-0002-6302-9252"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-20 09:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='multinomineq-package'>multinomineq: Bayesian Inference for Inequality-Constrained Multinomial Models</h2><span id='topic+multinomineq'></span><span id='topic+multinomineq-package'></span>

<h3>Description</h3>


<p><img src="../help/figures/multinomineq.png" width=120 alt ="multinomineq" style='float: right' />

</p>
<p>Implements Gibbs sampling and Bayes factors for multinomial models with
convex, linear-inequality constraints on the probability parameters. This
includes models that predict a linear order of binomial probabilities
(e.g., p1 &lt; p2 &lt; p3 &lt; .50) and mixture models, which assume that the
parameter vector p must be inside the convex hull of a finite number of
vertices.

</p>


<h3>Details</h3>

<p>A formal definition of inequality-constrained multinomial models and the
implemented computational methods for Bayesian inference is provided in:
</p>

<ul>
<li><p> Heck, D. W., &amp; Davis-Stober, C. P. (2019).
Multinomial models with linear inequality constraints:
Overview and improvements of computational methods for Bayesian inference.
Manuscript under revision. <a href="https://arxiv.org/abs/1808.07140">https://arxiv.org/abs/1808.07140</a>
</p>
</li></ul>

<p>Inequality-constrained multinomial models have applications in multiple areas
in psychology, judgement and decision making, and beyond:
</p>

<ul>
<li><p> Testing choice axioms such as transitivity and random utility theory
(Regenwetter et al., 2012, 2014). See <code><a href="#topic+regenwetter2012">regenwetter2012</a></code>
</p>
</li>
<li><p> Testing deterministic axioms of measurement and choice (Karabatsos, 2005; Myung et al., 2005).
</p>
</li>
<li><p> Multiattribute decisions for probabilistic inferences involving strategies such as
Take-the-best (TTB) vs. weighted additive (WADD; Bröder &amp; Schiffer, 2003; Heck et al., 2017)
See <code><a href="#topic+heck2017">heck2017</a></code> and <code><a href="#topic+hilbig2014">hilbig2014</a></code>
</p>
</li>
<li><p> Fitting and testing nonparametric item response theory models (Karabatsos &amp; Sheu, 2004).
See <code><a href="#topic+karabatsos2004">karabatsos2004</a></code>
</p>
</li>
<li><p> Statistical inference for order-constrained contingency tables (Klugkist et al., 2007, 2010).
See <code><a href="#topic+bf_nonlinear">bf_nonlinear</a></code>
</p>
</li>
<li><p> Testing stochastic dominance of response time distributions (Heathcote et al., 2010).
See <code><a href="#topic+stochdom_bf">stochdom_bf</a></code>
</p>
</li>
<li><p> Cognitive diagnostic assessment (Hoijtink et al., 2014).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Daniel W. Heck
</p>


<h3>References</h3>

<p>Bröder, A., &amp; Schiffer, S. (2003). Bayesian strategy assessment in multi-attribute decision making. Journal of Behavioral Decision Making, 16(3), 193-213. <a href="https://doi.org/10.1002/bdm.442">doi:10.1002/bdm.442</a>
</p>
<p>Bröder, A., &amp; Schiffer, S. (2003). Take The Best versus simultaneous feature matching: Probabilistic inferences from memory and effects of reprensentation format. Journal of Experimental Psychology: General, 132, 277-293. <a href="https://doi.org/10.1037/0096-3445.132.2.277">doi:10.1037/0096-3445.132.2.277</a>
</p>
<p>Heck, D. W., Hilbig, B. E., &amp; Moshagen, M. (2017). From information processing to decisions: Formalizing and comparing probabilistic choice models. Cognitive Psychology, 96, 26-40. <a href="https://doi.org/10.1016/j.cogpsych.2017.05.003">doi:10.1016/j.cogpsych.2017.05.003</a>
</p>
<p>Hilbig, B. E., &amp; Moshagen, M. (2014). Generalized outcome-based strategy classification: Comparing deterministic and probabilistic choice models. Psychonomic Bulletin &amp; Review, 21(6), 1431-1443. <a href="https://doi.org/10.3758/s13423-014-0643-0">doi:10.3758/s13423-014-0643-0</a>
</p>
<p>Regenwetter, M., &amp; Davis-Stober, C. P. (2012). Behavioral variability of choices versus structural inconsistency of preferences. Psychological Review, 119(2), 408-416. <a href="https://doi.org/10.1037/a0027372">doi:10.1037/a0027372</a>
</p>
<p>Regenwetter, M., Davis-Stober, C. P., Lim, S. H., Guo, Y., Popova, A., Zwilling, C., … Messner, W. (2014). QTest: Quantitative testing of theories of binary choice. Decision, 1(1), 2-34. <a href="https://doi.org/10.1037/dec0000007">doi:10.1037/dec0000007</a>
</p>
<p>Karabatsos, G. (2005). The exchangeable multinomial model as an approach to testing deterministic axioms of choice and measurement. Journal of Mathematical Psychology, 49(1), 51-69. <a href="https://doi.org/10.1016/j.jmp.2004.11.001">doi:10.1016/j.jmp.2004.11.001</a>
</p>
<p>Myung, J. I., Karabatsos, G., &amp; Iverson, G. J. (2005). A Bayesian approach to testing decision making axioms. <em>Journal of Mathematical Psychology, 49</em>, 205-225. <a href="https://doi.org/10.1016/j.jmp.2005.02.004">doi:10.1016/j.jmp.2005.02.004</a>
</p>
<p>Karabatsos, G., &amp; Sheu, C.-F. (2004). Order-constrained Bayes inference for dichotomous models of unidimensional nonparametric IRT. Applied Psychological Measurement, 28(2), 110-125. <a href="https://doi.org/10.1177/0146621603260678">doi:10.1177/0146621603260678</a>
</p>
<p>Hoijtink, H. (2011). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton, FL: Chapman &amp; Hall/CRC.
</p>
<p>Hoijtink, H., Béland, S., &amp; Vermeulen, J. A. (2014). Cognitive diagnostic assessment via Bayesian evaluation of informative diagnostic hypotheses. Psychological Methods, 19(1), 21–38. doi:10.1037/a0034176
</p>
<p>Klugkist, I., &amp; Hoijtink, H. (2007). The Bayes factor for inequality and about equality constrained models. Computational Statistics &amp; Data Analysis, 51(12), 6367-6379. <a href="https://doi.org/10.1016/j.csda.2007.01.024">doi:10.1016/j.csda.2007.01.024</a>
</p>
<p>Klugkist, I., Laudy, O., &amp; Hoijtink, H. (2010). Bayesian evaluation of inequality and equality constrained hypotheses for contingency tables. Psychological Methods, 15(3), 281-299. <a href="https://doi.org/10.1037/a0020137">doi:10.1037/a0020137</a>
</p>
<p>Heathcote, A., Brown, S., Wagenmakers, E. J., &amp; Eidels, A. (2010). Distribution-free tests of stochastic dominance for small samples. Journal of Mathematical Psychology, 54(5), 454-463. <a href="https://doi.org/10.1016/j.jmp.2010.06.005">doi:10.1016/j.jmp.2010.06.005</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/danheck/multinomineq">https://github.com/danheck/multinomineq</a>
</p>
</li></ul>


<hr>
<h2 id='Ab_drop_fixed'>Drop fixed columns in the Ab-Representation</h2><span id='topic+Ab_drop_fixed'></span>

<h3>Description</h3>

<p>Often inequalities refer to all probability parameters of a multinomial distribution.
This function allows to transform the inequalities into the appropriate format
<code>A * x &lt;b</code> with respect to the free parameters only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ab_drop_fixed(A, b, options)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ab_drop_fixed_+3A_a">A</code></td>
<td>
<p>a matrix defining the convex polytope via <code>A*x &lt;= b</code>.
The columns of <code>A</code> do not include the last choice option per item type and
thus the number of columns must be equal to <code>sum(options-1)</code>
(e.g., the column order of <code>A</code> for <code>k = c(a1,a2,a2, b1,b2)</code>
is <code>c(a1,a2, b1)</code>).</p>
</td></tr>
<tr><td><code id="Ab_drop_fixed_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="Ab_drop_fixed_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># p1 &lt; p2 &lt; p3 &lt; p4
A4 &lt;- matrix(
  c(
    1, -1, 0, 0,
    0, 1, -1, 0,
    0, 0, 1, -1
  ),
  nrow = 3, byrow = TRUE
)
b4 &lt;- c(0, 0, 0)

# drop the fixed column for: p4 = (1-p1-p2-p3)
Ab_drop_fixed(A4, b4, options = c(4))

</code></pre>

<hr>
<h2 id='Ab_max'>Automatic Construction of Ab-Representation for Common Inequality Constraints</h2><span id='topic+Ab_max'></span>

<h3>Description</h3>

<p>Constructs the matrix <code>A</code> and vector <code>b</code> of the Ab-representation
<code>A*x &lt; b</code> for common inequality constraints such as &quot;the probability j is
larger than all others (<code>Ab_max</code>)&quot; or &quot;the probabilities are ordered
(<code>Ab_monotonicity</code>)&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ab_max(
  which_max,
  options,
  exclude = c(),
  exclude_fixed = FALSE,
  drop_fixed = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ab_max_+3A_which_max">which_max</code></td>
<td>
<p>vector of indices refering to probabilities that are
assumed to be larger than the remaining probabilities
(e.g., <code>which_max=c(1,2)</code> means that <code>p1&gt;p3, p1&gt;p4,..., p2&gt;p3, ...</code>).
Note that the indices refer to <em>all</em> probabilities/categories (including
one fixed probability within each multinomial distribution).</p>
</td></tr>
<tr><td><code id="Ab_max_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="Ab_max_+3A_exclude">exclude</code></td>
<td>
<p>vector of indices refering to probabilities that are
excluded from the construction of the order constraints (including
the fixed probabilities).</p>
</td></tr>
<tr><td><code id="Ab_max_+3A_exclude_fixed">exclude_fixed</code></td>
<td>
<p>whether to exclude the fixed probabilities (i.e., the
last probability within each multinomial) from the construction of the
order constraints. For example, if <code>options=c(2,2,3)</code> then the
probabilities/columns 2, 4, and 7 are dropped (which is equivalent to
<code>exclude=c(2,4,7)</code>). This option is usually appropriate for binomial
probabilities (i.e., if <code>options = c(2,2,2,...)</code>), e.g., when the
interest is in the probability of correct responding across different item types.</p>
</td></tr>
<tr><td><code id="Ab_max_+3A_drop_fixed">drop_fixed</code></td>
<td>
<p>whether to drop columns of <code>A</code> containing the
fixed probabilities (i.e., the last probability within each multinomial).
<em>after</em> construction of the inequalities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the matrix <code>A</code> and the vectors <code>b</code> and <code>options</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Multinomial with 5 categories
# Hypothesis: p1 is larger than p2,p3,p4,p5
Ab_max(which_max = 1, options = 5)

# Example 2: Four binomial probabilities
# Hypothesis: p1 is larger than p2,p3,p4
Ab_max(which_max = 1, options = c(2, 2, 2, 2), exclude_fixed = TRUE)
</code></pre>

<hr>
<h2 id='Ab_multinom'>Get Constraints for Product-Multinomial Probabilities</h2><span id='topic+Ab_multinom'></span>

<h3>Description</h3>

<p>Get or add inequality constraints (or vertices) to ensure that multinomial probabilities are
positive and sum to one for all choice options within each item type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ab_multinom(options, A = NULL, b = NULL, nonneg = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ab_multinom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="Ab_multinom_+3A_a">A</code></td>
<td>
<p>a matrix defining the convex polytope via <code>A*x &lt;= b</code>.
The columns of <code>A</code> do not include the last choice option per item type and
thus the number of columns must be equal to <code>sum(options-1)</code>
(e.g., the column order of <code>A</code> for <code>k = c(a1,a2,a2, b1,b2)</code>
is <code>c(a1,a2, b1)</code>).</p>
</td></tr>
<tr><td><code id="Ab_multinom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="Ab_multinom_+3A_nonneg">nonneg</code></td>
<td>
<p>whether to add constraints that probabilities must be nonnegative</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>A</code> and <code>b</code> are provided, the constraints are added to these inequality constraints.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+add_fixed">add_fixed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># three binary and two ternary choices:
options &lt;- c(2, 2, 2, 3, 3)
Ab_multinom(options)
Ab_multinom(options, nonneg = TRUE)
</code></pre>

<hr>
<h2 id='Ab_sort'>Sort Inequalities by Acceptance Rate</h2><span id='topic+Ab_sort'></span>

<h3>Description</h3>

<p>Uses samples from the prior/posterior to order the inequalities by the acceptance rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ab_sort(A, b, k = 0, options, M = 1000, drop_irrelevant = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ab_sort_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="Ab_sort_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="Ab_sort_+3A_k">k</code></td>
<td>
<p>optional: number of observed frequencies (only for posterior sampling).</p>
</td></tr>
<tr><td><code id="Ab_sort_+3A_options">options</code></td>
<td>
<p>optional: number of options per item type/category system.
Uniform sampling on [0,1] for each parameter is used if omitted.</p>
</td></tr>
<tr><td><code id="Ab_sort_+3A_m">M</code></td>
<td>
<p>number of samples.</p>
</td></tr>
<tr><td><code id="Ab_sort_+3A_drop_irrelevant">drop_irrelevant</code></td>
<td>
<p>whether to drop irrelevant constraints for probabilities such as
<code>theta[1] &gt;= 0</code>, <code>theta[1] &lt;= 1</code>, or <code>sum(theta) &lt;= 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Those constraints that are rejected most often are placed at the first positions.
This can help when computing the encompassing Bayes factor and counting how many samples
satisfy the constraints (e.g., <code><a href="#topic+count_binom">count_binom</a></code> or <code><a href="#topic+bf_multinom">bf_multinom</a></code>).
Essentially, it becomes more likely that the while-loop for testing
whether the inequalities hold can stop earlier, thus making the computation faster.
</p>
<p>The function could also be helpful to improve the efficiency of the stepwise
sampling implemented in <code><a href="#topic+count_binom">count_binom</a></code> and <code><a href="#topic+count_multinom">count_multinom</a></code>.
First, one can use accept-reject sampling to test the first few, rejected
inequalities. Next, one can use a Gibbs sampler to draw samples conditional on the
first constraints.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Binomial probabilities
b &lt;- c(0, 0, .30, .70, 1)
A &lt;- matrix(
  c(
    -1, 1, 0, # p1 &gt;= p2
    0, 1, -1, # p2 &lt;= p3
    1, 0, 0, # p1 &lt;=.30
    0, 1, 0, # p2 &lt;= .70
    0, 0, 1
  ), # p3 &lt;= 1 (redundant)
  ncol = 3, byrow = 2
)
Ab_sort(A, b)


### Multinomial probabilities
# prior sampling:
Ab_sort(A, b, options = 4)
# posterior sampling:
Ab_sort(A, b, k = c(10, 3, 2, 14), options = 4)

</code></pre>

<hr>
<h2 id='bf_binom'>Bayes Factor for Linear Inequality Constraints</h2><span id='topic+bf_binom'></span><span id='topic+bf_multinom'></span>

<h3>Description</h3>

<p>Computes the Bayes factor for product-binomial/-multinomial models with
linear order-constraints (specified via: <code>A*x &lt;= b</code> or the convex hull <code>V</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bf_binom(k, n, A, b, V, map, prior = c(1, 1), log = FALSE, ...)

bf_multinom(
  k,
  options,
  A,
  b,
  V,
  prior = rep(1, sum(options)),
  log = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bf_binom_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_n">n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_map">map</code></td>
<td>
<p>optional: numeric vector of the same length as <code>k</code> with integers
mapping the frequencies <code>k</code> to the free parameters/columns of <code>A</code>/<code>V</code>,
thereby allowing for equality constraints (e.g., <code>map=c(1,1,2,2)</code>).
Reversed probabilities <code>1-p</code> are coded by negative integers.
Guessing probabilities of .50 are encoded by zeros. The default assumes
different parameters for each item type: <code>map=1:ncol(A)</code></p>
</td></tr>
<tr><td><code id="bf_binom_+3A_prior">prior</code></td>
<td>
<p>a vector with two positive numbers defining the shape parameters
of the beta prior distributions for each binomial rate parameter.</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_log">log</code></td>
<td>
<p>whether to return the log-Bayes factor instead of the Bayes factor</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+count_binom">count_binom</a></code> or
<code><a href="#topic+count_multinom">count_multinom</a></code> (e.g., <code>M</code>, <code>steps</code>).</p>
</td></tr>
<tr><td><code id="bf_binom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more control, use <code><a href="#topic+count_binom">count_binom</a></code> to specifiy how many samples
should be drawn from the prior and posterior, respectively. This is especially
recommended if the same prior distribution (and thus the same prior probability/integral)
is used for computing BFs for multiple data sets that differ only in the
observed frequencies <code>k</code> and the sample size <code>n</code>.
In this case, the prior probability/proportion of the parameter space in line
with the inequality constraints can be computed once with high precision
(or even analytically), and only the posterior probability/proportion needs
to be estimated separately for each unique vector <code>k</code>.
</p>


<h3>Value</h3>

<p>a matrix with two columns (Bayes factor and SE of approximation) and three rows:
</p>

<ul>
<li> <p><code>`bf_0u`</code>:  constrained vs. unconstrained (saturated) model
</p>
</li>
<li> <p><code>`bf_u0`</code>:  unconstrained vs. constrained model
</p>
</li>
<li> <p><code>`bf_00'`</code>: constrained vs. complement of inequality-constrained model
(e.g., pi&gt;.2 becomes pi&lt;=.2; this assumes identical equality constraints for both models)
</p>
</li></ul>



<h3>References</h3>

<p>Karabatsos, G. (2005). The exchangeable multinomial model as an approach to testing deterministic axioms of choice and measurement. Journal of Mathematical Psychology, 49(1), 51-69. <a href="https://doi.org/10.1016/j.jmp.2004.11.001">doi:10.1016/j.jmp.2004.11.001</a>
</p>
<p>Regenwetter, M., Davis-Stober, C. P., Lim, S. H., Guo, Y., Popova, A., Zwilling, C., … Messner, W. (2014). QTest: Quantitative testing of theories of binary choice. Decision, 1(1), 2-34. <a href="https://doi.org/10.1037/dec0000007">doi:10.1037/dec0000007</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+count_binom">count_binom</a></code> and <code><a href="#topic+count_multinom">count_multinom</a></code> for
for more control on the number of prior/posterior samples and
<code><a href="#topic+bf_nonlinear">bf_nonlinear</a></code> for nonlinear order constraints.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- c(0, 3, 2, 5, 3, 7)
n &lt;- rep(10, 6)

# linear order constraints:
#             p1 &lt;p2 &lt;p3 &lt;p4 &lt;p5 &lt;p6 &lt;.50
A &lt;- matrix(
  c(
    1, -1, 0, 0, 0, 0,
    0, 1, -1, 0, 0, 0,
    0, 0, 1, -1, 0, 0,
    0, 0, 0, 1, -1, 0,
    0, 0, 0, 0, 1, -1,
    0, 0, 0, 0, 0, 1
  ),
  ncol = 6, byrow = TRUE
)
b &lt;- c(0, 0, 0, 0, 0, .50)

# Bayes factor: unconstrained vs. constrained
bf_binom(k, n, A, b, prior = c(1, 1), M = 10000)
bf_binom(k, n, A, b, prior = c(1, 1), M = 2000, steps = c(2, 4, 5))
bf_binom(k, n, A, b, prior = c(1, 1), M = 1000, cmin = 200)

</code></pre>

<hr>
<h2 id='bf_equality'>Bayes Factor with Inequality and (Approximate) Equality Constraints</h2><span id='topic+bf_equality'></span>

<h3>Description</h3>

<p>To obtain the Bayes factor for the equality constraints <code>C*x = d</code>, a
sequence of approximations <code>abs(C*x - d) &lt; delta</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bf_equality(
  k,
  options,
  A,
  b,
  C,
  d,
  prior = rep(1, sum(options)),
  M1 = 1e+05,
  M2 = 20000,
  delta = 0.5^(1:8),
  return_Ab = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bf_equality_+3A_k">k</code></td>
<td>
<p>the number of choices for each alternative ordered by item type (e.g.
<code>c(a1,a2,a3,  b1,b2)</code> for a ternary and a binary item type).
The length of <code>k</code> must be equal to the sum of <code>options</code>.
The default <code>k=0</code> is equivalent to sampling from the prior.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_c">C</code></td>
<td>
<p>a matrix specifying the equality constraints <code>C*x = d</code> with
columns refering to the free parameters (similar to <code>A</code>)</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_d">d</code></td>
<td>
<p>a vector with the same number of elements as the rows of <code>C</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_prior">prior</code></td>
<td>
<p>the prior parameters of the Dirichlet-shape parameters.
Must have the same length as <code>k</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_m1">M1</code></td>
<td>
<p>number of independent samples from the encompassing model to test
whether <code>A*x &lt; b</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_m2">M2</code></td>
<td>
<p>number of Gibbs-sampling iterations for each step of the approximation
of <code>C*x = d</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_delta">delta</code></td>
<td>
<p>a vector of stepsizes that are used for the approximation.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_return_ab">return_Ab</code></td>
<td>
<p>if <code>TRUE</code>, the function returns a list with the additional
inequality constraints (specified via <code>A</code>, <code>b</code>, and <code>steps</code>)
that are used in the stepwise approximation <code>abs(C*x - d) &lt; delta[i]</code>.</p>
</td></tr>
<tr><td><code id="bf_equality_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+count_binom">count_binom</a></code> or
<code><a href="#topic+count_multinom">count_multinom</a></code> (e.g., <code>M</code>, <code>steps</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, the encompassing Bayes factor for the equality constraint <code>A*x&lt;b</code>
is computed using <code>M1</code> independent Dirichlet samples. Next, the equality
constraint <code>C*x=d</code> is approximated by drawing samples from the model
<code>A*x&lt;b</code> and testing whether <code>abs(C*x - d) &lt; delta[1]</code>. Similarly, the
stepsize <code>delta</code> is reduced step by step until <code>abs(C*x - d) &lt; min(delta)</code>.
Klugkist  et al. (2010) show that this procedure provides a valid approximation
of the exact equality constraints if the step size becomes sufficiently small.
</p>


<h3>References</h3>

<p>Klugkist, I., Laudy, O., &amp; Hoijtink, H. (2010). Bayesian evaluation of inequality and equality constrained hypotheses for contingency tables. Psychological Methods, 15(3), 281-299. <a href="https://doi.org/10.1037/a0020137">doi:10.1037/a0020137</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Equality constraints:  C * x = d
d &lt;- c(.5, .5, 0)
C &lt;- matrix(
  c(
    1, 0, 0, 0, # p1 = .50
    0, 1, 0, 0, # p2 = .50
    0, 0, 1, -1
  ), # p3 = p4
  ncol = 4, byrow = TRUE
)
k &lt;- c(3, 7, 6, 4, 2, 8, 5, 5)
options &lt;- c(2, 2, 2, 2)
bf_equality(k, options,
  C = C, d = d, delta = .5^(1:5),
  M1 = 50000, M2 = 5000
) # only for CRAN checks

# check against exact equality constraints (see ?bf_binom)
k_binom &lt;- k[seq(1, 7, 2)]
bf_binom(k_binom,
  n = 10, A = matrix(0), b = 0,
  map = c(0, 0, 1, 1)
)
</code></pre>

<hr>
<h2 id='bf_nonlinear'>Bayes Factor for Nonlinear Inequality Constraints</h2><span id='topic+bf_nonlinear'></span><span id='topic+count_nonlinear'></span>

<h3>Description</h3>

<p>Computes the encompassing Bayes factor for a user-specified, nonlinear inequality
constraint. Restrictions are defined via an indicator function of the free parameters
<code>c(p11,p12,p13,  p21,p22,...)</code> (i.e., the multinomial probabilities).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bf_nonlinear(
  k,
  options,
  inside,
  prior = rep(1, sum(options)),
  log = FALSE,
  ...
)

count_nonlinear(
  k = 0,
  options,
  inside,
  prior = rep(1, sum(options)),
  M = 5000,
  progress = TRUE,
  cpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bf_nonlinear_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_inside">inside</code></td>
<td>
<p>an indicator function that takes a vector with probabilities
<code>p=c(p11,p12,  p21,p22,...)</code> (where the last probability for each
multinomial is dropped) as input and returns <code>1</code> or <code>TRUE</code>
if the order constraints are satisfied and <code>0</code> or <code>FALSE</code> otherwise
(see details).</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_prior">prior</code></td>
<td>
<p>a vector with two positive numbers defining the shape parameters
of the beta prior distributions for each binomial rate parameter.</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_log">log</code></td>
<td>
<p>whether to return the log-Bayes factor instead of the Bayes factor</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+count_binom">count_binom</a></code> or
<code><a href="#topic+count_multinom">count_multinom</a></code> (e.g., <code>M</code>, <code>steps</code>).</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_m">M</code></td>
<td>
<p>number of posterior samples drawn from the encompassing model</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="bf_nonlinear_+3A_cpu">cpu</code></td>
<td>
<p>either the number of CPUs used for parallel sampling, or a parallel
cluster  (e.g., <code>cl &lt;- parallel::makeCluster(3)</code>).
All arguments of the function call are passed directly to each core,
and thus the total number of samples is <code>M*number_cpu</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inequality constraints are defined via an indicator function <code>inside</code>
which returns <code>inside(x)=1</code> (or <code>0</code>) if the vector of free parameters
<code>x</code> is inside (or outside) the model space. Since the vector <code>x</code>
must include only free (!) parameters, the last probability for each
multinomial must not be used in the function <code>inside(x)</code>!
</p>
<p>Efficiency can be improved greatly if the indicator function is defined as C++
code via the function <a href="RcppXPtrUtils.html#topic+cppXPtr">cppXPtr</a> in the package RcppXPtrUtils
(see below for examples). In this case, please keep in mind that indexing in C++
starts with 0,1,2... (not with 1,2,3,... as in R)!
</p>


<h3>References</h3>

<p>Klugkist, I., &amp; Hoijtink, H. (2007). The Bayes factor for inequality and about equality constrained models. Computational Statistics &amp; Data Analysis, 51(12), 6367-6379. <a href="https://doi.org/10.1016/j.csda.2007.01.024">doi:10.1016/j.csda.2007.01.024</a>
</p>
<p>Klugkist, I., Laudy, O., &amp; Hoijtink, H. (2010). Bayesian evaluation of inequality and equality constrained hypotheses for contingency tables. Psychological Methods, 15(3), 281-299. <a href="https://doi.org/10.1037/a0020137">doi:10.1037/a0020137</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##### 2x2x2 continceny table (Klugkist &amp; Hojtink, 2007)
#
# (defendant's race) x (victim's race) x (death penalty)
# indexing: 0 = white/white/yes  ; 1 = black/black/no
# probabilities: (p000,p001,  p010,p011,  p100,p101,  p110,p111)
# Model2:
# p000*p101 &lt; p100*p001  &amp;   p010*p111 &lt; p110*p011

# observed frequencies:
k &lt;- c(19, 132, 0, 9, 11, 52, 6, 97)

model &lt;- function(x) {
  x[1] * x[6] &lt; x[5] * x[2] &amp; x[3] * (1 - sum(x)) &lt; x[7] * x[4]
}
# NOTE: "1-sum(x)"  must be used instead of "x[8]"!

# compute Bayes factor (Klugkist 2007: bf_0u=1.62)
bf_nonlinear(k, 8, model, M = 50000)


##### Using a C++ indicator function (much faster)
cpp_code &lt;- "SEXP model(NumericVector x){
  return wrap(x[0]*x[5] &lt; x[4]*x[1] &amp; x[2]*(1-sum(x)) &lt; x[6]*x[3]);}"
# NOTE: C++ indexing starts at 0!

# define C++ pointer to indicator function:
model_cpp &lt;- RcppXPtrUtils::cppXPtr(cpp_code)

bf_nonlinear(
  k = c(19, 132, 0, 9, 11, 52, 6, 97), M = 100000,
  options = 8, inside = model_cpp
)

</code></pre>

<hr>
<h2 id='binom_to_multinom'>Converts Binary to Multinomial Frequencies</h2><span id='topic+binom_to_multinom'></span>

<h3>Description</h3>

<p>Converts the number of &quot;hits&quot; in the binary choice format to the observed
frequencies across  for all response categories (i.e., the multinomial format).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binom_to_multinom(k, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binom_to_multinom_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="binom_to_multinom_+3A_n">n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <code>multinomineq</code>, binary choice frequencies are represented by the number
of &quot;hits&quot; for each item type/condition (the vector <code>k</code>) and by the total
number of responses per item type/condition (the scalar or vector <code>n</code>).
</p>
<p>In the multinomial format, the vector <code>k</code> includes all response categories
(not only the number of &quot;hits&quot;). This requires to define a vector <code>options</code>,
which indicates how many categories belong to one item type/condition (since
the total number of responses per item type is fixed).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- c(1, 5, 8, 10)
n &lt;- 10
binom_to_multinom(k, n)

</code></pre>

<hr>
<h2 id='count_binom'>Count How Many Samples Satisfy Linear Inequalities (Binomial)</h2><span id='topic+count_binom'></span>

<h3>Description</h3>

<p>Draws prior/posterior samples for product-binomial data and counts how many samples are
inside the convex polytope defined by
(1) the inequalities <code>A*x &lt;= b</code> or
(2) the convex hull over the vertices <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_binom(
  k,
  n,
  A,
  b,
  V,
  map,
  prior = c(1, 1),
  M = 10000,
  steps,
  start,
  cmin = 0,
  maxiter = 500,
  burnin = 5,
  progress = TRUE,
  cpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count_binom_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_n">n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_map">map</code></td>
<td>
<p>optional: numeric vector of the same length as <code>k</code> with integers
mapping the frequencies <code>k</code> to the free parameters/columns of <code>A</code>/<code>V</code>,
thereby allowing for equality constraints (e.g., <code>map=c(1,1,2,2)</code>).
Reversed probabilities <code>1-p</code> are coded by negative integers.
Guessing probabilities of .50 are encoded by zeros. The default assumes
different parameters for each item type: <code>map=1:ncol(A)</code></p>
</td></tr>
<tr><td><code id="count_binom_+3A_prior">prior</code></td>
<td>
<p>a vector with two positive numbers defining the shape parameters
of the beta prior distributions for each binomial rate parameter.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_m">M</code></td>
<td>
<p>number of posterior samples drawn from the encompassing model</p>
</td></tr>
<tr><td><code id="count_binom_+3A_steps">steps</code></td>
<td>
<p>an integer vector that indicates the row numbers at which the matrix <code>A</code>
is split for a stepwise computation of the Bayes factor (see details).
<code>M</code> can be a vector with the number of samples drawn
in each step from the (partially) order-constrained models  using Gibbs sampling.
If <code>cmin&gt;0</code>, samples are drawn for each step until <code>count[i]&gt;=cmin</code>.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_start">start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_cmin">cmin</code></td>
<td>
<p>if <code>cmin&gt;0</code>: minimum number of counts per step in the automatic stepwise procedure.
If <code>steps</code> is not defined, <code>steps=c(1,2,3,4,...)</code> by default.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_maxiter">maxiter</code></td>
<td>
<p>if <code>cmin&gt;0</code>: maximum number of sampling runs in the automatic stepwise procedure.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_burnin">burnin</code></td>
<td>
<p>number of burnin samples per step that are discarded. Since the
maximum-likelihood estimate is used as a start value (which is updated for each step in
the stepwise procedure in <code>count_multinom</code>), the <code>burnin</code>
number can be smaller than in other MCMC applications.</p>
</td></tr>
<tr><td><code id="count_binom_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="count_binom_+3A_cpu">cpu</code></td>
<td>
<p>either the number of CPUs used for parallel sampling, or a parallel
cluster  (e.g., <code>cl &lt;- parallel::makeCluster(3)</code>).
All arguments of the function call are passed directly to each core,
and thus the total number of samples is <code>M*number_cpu</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Counts the number of random samples drawn from beta distributions that satisfy
the convex, linear-inequalitiy constraints. The function is useful to compute
the encompassing Bayes factor for testing inequality-constrained models
(see <code><a href="#topic+bf_binom">bf_binom</a></code>; Hojtink, 2011).
</p>
<p>The stepwise computation of the Bayes factor proceeds as follows:
If the steps are defined as <code>steps=c(5,10)</code>, the BF is computed in three steps by comparing:
(1) Unconstrained model vs. inequalities in <code>A[1:5,]</code>;
(2) use posterior based on inequalities in <code>A[1:5,]</code> and check inequalities <code>A[6:10,]</code>;
(3) sample from A[1:10,] and check inequalities in <code>A[11:nrow(A),]</code> (i.e., all inequalities).
</p>


<h3>Value</h3>

<p>a matrix with the columns
</p>

<ul>
<li><p><code>count</code>: number of samples in polytope / that satisfy order constraints
</p>
</li>
<li><p><code>M</code>: the  total number of samples in each step
</p>
</li>
<li><p><code>steps</code>: the <code>"steps"</code> used to sample from the polytope
(i.e., the row numbers of <code>A</code> that were considered  stepwise)
</p>
</li></ul>

<p>with the attributes:
</p>

<ul>
<li><p><code>proportion</code>: estimated probability that samples are in polytope
</p>
</li>
<li><p><code>se</code>: standard error of probability estimate
</p>
</li>
<li><p><code>const_map</code>: logarithm of the binomial constants that
have to be considered due to equality constraints
</p>
</li></ul>



<h3>References</h3>

<p>Hoijtink, H. (2011). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton, FL: Chapman &amp; Hall/CRC.
</p>
<p>Fukuda, K. (2004). Is there an efficient way of determining whether a given point q is in the convex hull of a given finite set S of points in Rd? Retrieved from <a href="https://www.cs.mcgill.ca/~fukuda/soft/polyfaq/node22.html">https://www.cs.mcgill.ca/~fukuda/soft/polyfaq/node22.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bf_binom">bf_binom</a></code>, <code><a href="#topic+count_multinom">count_multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### a set of linear order constraints:
### x1 &lt; x2 &lt; .... &lt; x6 &lt; .50
A &lt;- matrix(
  c(
    1, -1, 0, 0, 0, 0,
    0, 1, -1, 0, 0, 0,
    0, 0, 1, -1, 0, 0,
    0, 0, 0, 1, -1, 0,
    0, 0, 0, 0, 1, -1,
    0, 0, 0, 0, 0, 1
  ),
  ncol = 6, byrow = TRUE
)
b &lt;- c(0, 0, 0, 0, 0, .50)

### check whether a specific vector is inside the polytope:
A %*% c(.05, .1, .12, .16, .19, .23) &lt;= b


### observed frequencies and number of observations:
k &lt;- c(0, 3, 2, 5, 3, 7)
n &lt;- rep(10, 6)

### count prior samples and compare to analytical result
prior &lt;- count_binom(0, 0, A, b, M = 5000, steps = 1:4)
prior # to get the proportion: attr(prior, "proportion")
(.50)^6 / factorial(6)

### count posterior samples + get Bayes factor
posterior &lt;- count_binom(k, n, A, b, M = 2000, steps = 1:4)
count_to_bf(posterior, prior)

### automatic stepwise algorithm
prior &lt;- count_binom(0, 0, A, b, M = 500, cmin = 200)
posterior &lt;- count_binom(k, n, A, b, M = 500, cmin = 200)
count_to_bf(posterior, prior)

</code></pre>

<hr>
<h2 id='count_multinom'>Count How Many Samples Satisfy Linear Inequalities (Multinomial)</h2><span id='topic+count_multinom'></span>

<h3>Description</h3>

<p>Draws prior/posterior samples for product-multinomial data and counts how many samples are
inside the convex polytope defined by
(1) the inequalities <code>A*x &lt;= b</code> or
(2) the convex hull over the vertices V.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_multinom(
  k = 0,
  options,
  A,
  b,
  V,
  prior = rep(1, sum(options)),
  M = 5000,
  steps,
  start,
  cmin = 0,
  maxiter = 500,
  burnin = 5,
  progress = TRUE,
  cpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count_multinom_+3A_k">k</code></td>
<td>
<p>the number of choices for each alternative ordered by item type (e.g.
<code>c(a1,a2,a3,  b1,b2)</code> for a ternary and a binary item type).
The length of <code>k</code> must be equal to the sum of <code>options</code>.
The default <code>k=0</code> is equivalent to sampling from the prior.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_a">A</code></td>
<td>
<p>a matrix defining the convex polytope via <code>A*x &lt;= b</code>.
The columns of <code>A</code> do not include the last choice option per item type and
thus the number of columns must be equal to <code>sum(options-1)</code>
(e.g., the column order of <code>A</code> for <code>k = c(a1,a2,a2, b1,b2)</code>
is <code>c(a1,a2, b1)</code>).</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_prior">prior</code></td>
<td>
<p>the prior parameters of the Dirichlet-shape parameters.
Must have the same length as <code>k</code>.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_m">M</code></td>
<td>
<p>number of posterior samples drawn from the encompassing model</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_steps">steps</code></td>
<td>
<p>an integer vector that indicates the row numbers at which the matrix <code>A</code>
is split for a stepwise computation of the Bayes factor (see details).
<code>M</code> can be a vector with the number of samples drawn
in each step from the (partially) order-constrained models  using Gibbs sampling.
If <code>cmin&gt;0</code>, samples are drawn for each step until <code>count[i]&gt;=cmin</code>.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_start">start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_cmin">cmin</code></td>
<td>
<p>if <code>cmin&gt;0</code>: minimum number of counts per step in the automatic stepwise procedure.
If <code>steps</code> is not defined, <code>steps=c(1,2,3,4,...)</code> by default.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_maxiter">maxiter</code></td>
<td>
<p>if <code>cmin&gt;0</code>: maximum number of sampling runs in the automatic stepwise procedure.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_burnin">burnin</code></td>
<td>
<p>number of burnin samples per step that are discarded. Since the
maximum-likelihood estimate is used as a start value (which is updated for each step in
the stepwise procedure in <code>count_multinom</code>), the <code>burnin</code>
number can be smaller than in other MCMC applications.</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="count_multinom_+3A_cpu">cpu</code></td>
<td>
<p>either the number of CPUs used for parallel sampling, or a parallel
cluster  (e.g., <code>cl &lt;- parallel::makeCluster(3)</code>).
All arguments of the function call are passed directly to each core,
and thus the total number of samples is <code>M*number_cpu</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the elements
</p>
<p>a matrix with the columns
</p>

<ul>
<li><p><code>count</code>: number of samples in polytope / that satisfy order constraints
</p>
</li>
<li><p><code>M</code>: the  total number of samples in each step
</p>
</li>
<li><p><code>steps</code>: the <code>"steps"</code> used to sample from the polytope
(i.e., the row numbers of <code>A</code> that were considered stepwise)
</p>
</li></ul>

<p>with the attributes:
</p>

<ul>
<li><p><code>proportion</code>: estimated probability that samples are in polytope
</p>
</li>
<li><p><code>se</code>: standard error of probability estimate
</p>
</li></ul>



<h3>References</h3>

<p>Hoijtink, H. (2011). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton, FL: Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bf_multinom">bf_multinom</a></code>, <code><a href="#topic+count_binom">count_binom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### frequencies:
#           (a1,a2,a3, b1,b2,b3,b4)
k &lt;- c(1, 5, 9, 5, 3, 7, 8)
options &lt;- c(3, 4)

### linear order constraints
# a1&lt;a2&lt;a3   AND   b2&lt;b3&lt;.50
# (note: a2&lt;a3 &lt;=&gt; a2 &lt; 1-a1-a2 &lt;=&gt; a1+2*a2 &lt; 1)
# matrix A:
#             (a1,a2, b1,b2,b3)
A &lt;- matrix(
  c(
    1, -1, 0, 0, 0,
    1, 2, 0, 0, 0,
    0, 0, 0, 1, -1,
    0, 0, 0, 0, 1
  ),
  ncol = sum(options - 1), byrow = TRUE
)
b &lt;- c(0, 1, 0, .50)

# count prior and posterior samples and get BF
prior &lt;- count_multinom(0, options, A, b, M = 2e4)
posterior &lt;- count_multinom(k, options, A, b, M = 2e4)
count_to_bf(posterior, prior)

bf_multinom(k, options, A, b, M = 10000)
bf_multinom(k, options, A, b, cmin = 5000, M = 1000)
</code></pre>

<hr>
<h2 id='count_to_bf'>Compute Bayes Factor Using Prior/Posterior Counts</h2><span id='topic+count_to_bf'></span>

<h3>Description</h3>

<p>Computes the encompassing Bayes factor (and standard error) defined as the
ratio of posterior/prior samples that satisfy the order constraints (e.g., of a polytope).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_to_bf(
  posterior,
  prior,
  exact_prior,
  log = FALSE,
  beta = c(1/2, 1/2),
  samples = 3000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count_to_bf_+3A_posterior">posterior</code></td>
<td>
<p>a vector (or matrix) with entries (or columns)
<code>count</code> = number of posterior samples within polytope and <code>M</code> =
total number of samples. See <code><a href="#topic+count_binom">count_binom</a></code>.</p>
</td></tr>
<tr><td><code id="count_to_bf_+3A_prior">prior</code></td>
<td>
<p>a vecotr or matrix similar as for <code>posterior</code>, but based on
samples from the prior distribution.</p>
</td></tr>
<tr><td><code id="count_to_bf_+3A_exact_prior">exact_prior</code></td>
<td>
<p>optional: the exact prior probabability of the order constraints.
For instance, <code>exact_prior=1/factorial(4)</code> if pi1&lt;pi2&lt;pi3&lt;pi4 (and if  the prior is symmetric).
If provided, <code>prior</code> is ignored.</p>
</td></tr>
<tr><td><code id="count_to_bf_+3A_log">log</code></td>
<td>
<p>whether to return the log-Bayes factor instead of the Bayes factor</p>
</td></tr>
<tr><td><code id="count_to_bf_+3A_beta">beta</code></td>
<td>
<p>prior shape parameters of the beta distributions used for approximating the
standard errors of the Bayes-factor estimates. The default is Jeffreys' prior.</p>
</td></tr>
<tr><td><code id="count_to_bf_+3A_samples">samples</code></td>
<td>
<p>number of samples from beta distributions used to compute
standard errors.
</p>
<p>The unconstrained (encompassing) model is the saturated baseline model that assumes a separate,
independent probability for each observable frequency. The Bayes factor is obtained
as the ratio of posterior/prior samples within an order-constrained subset of the
parameter space.
</p>
<p>The standard error of the (stepwise) encompassing Bayes factor is estimated by sampling
ratios from beta distributions, with parameters defined by the posterior/prior counts
(see Hoijtink, 2011; p. 211).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with two columns (Bayes factor and SE of approximation) and three rows:
</p>

<ul>
<li> <p><code>`bf_0u`</code>:  constrained vs. unconstrained (saturated) model
</p>
</li>
<li> <p><code>`bf_u0`</code>:  unconstrained vs. constrained model
</p>
</li>
<li> <p><code>`bf_00'`</code>: constrained vs. complement of inequality-constrained model
(e.g., pi&gt;.2 becomes pi&lt;=.2; this assumes identical equality constraints for both models)
</p>
</li></ul>



<h3>References</h3>

<p>Hoijtink, H. (2011). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton, FL: Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+count_binom">count_binom</a></code>, <code><a href="#topic+count_multinom">count_multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># vector input
post &lt;- c(count = 1447, M = 5000)
prior &lt;- c(count = 152, M = 10000)
count_to_bf(post, prior)

# matrix input (due to nested stepwise procedure)
post &lt;- cbind(count = c(139, 192), M = c(200, 1000))
count_to_bf(post, prior)

# exact prior probability known
count_to_bf(
  posterior = c(count = 1447, M = 10000),
  exact_prior = 1 / factorial(4)
)
</code></pre>

<hr>
<h2 id='drop_fixed'>Drop or Add Fixed Dimensions for Multinomial Probabilities/Frequencies</h2><span id='topic+drop_fixed'></span><span id='topic+add_fixed'></span>

<h3>Description</h3>

<p>Switches between two representation of polytopes for multinomial probabilities
(whether the fixed parameters are included).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_fixed(x, options = 2)

add_fixed(x, options = 2, sum = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drop_fixed_+3A_x">x</code></td>
<td>
<p>a vector (typically <code>k</code>, <code>n</code>, or <code>prior</code>) or
a matrix (typically <code>A</code> or <code>V</code>), in which case the fixed dimensions
are dropped/added column-wise.</p>
</td></tr>
<tr><td><code id="drop_fixed_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="drop_fixed_+3A_sum">sum</code></td>
<td>
<p>a vector that determines the fixed sum in each multinomial condition.
By default, probabilities are assumed that sum to one.
If frequencies <code>n</code> are provided, use <code>sum=n</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>######## bi- and trinomial (a1,a2, b1,b2,b3)
# vectors with frequencies:
drop_fixed(c(3, 7, 4, 1, 5), options = c(2, 3))
add_fixed(c(3, 4, 1),
  options = c(2, 3),
  sum = c(10, 10)
)

# matrices with probabilities:
V &lt;- matrix(c(
  1, 0, 0,
  1, .5, .5,
  0, 1, 0
), 3, byrow = TRUE)
V2 &lt;- add_fixed(V, options = c(2, 3))
V2
drop_fixed(V2, c(2, 3))
</code></pre>

<hr>
<h2 id='find_inside'>Find a Point/Parameter Vector Within a Convex Polytope</h2><span id='topic+find_inside'></span>

<h3>Description</h3>

<p>Finds the center/a random point that is within the convex polytope defined by the
linear inequalities <code>A*x &lt;= b</code>  or by the convex hull over the vertices in the matrix <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_inside(
  A,
  b,
  V,
  options = NULL,
  random = FALSE,
  probs = TRUE,
  boundary = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_inside_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="find_inside_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="find_inside_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="find_inside_+3A_options">options</code></td>
<td>
<p>optional: number of options per item type (only for <code class="reqn">A x \leq b</code> representation).
Necessary to account for sum-to-one constraints within multinomial
distributions (e.g., p_1 + p_2 + p_3 &lt;= 1).
By default, parameters are assumed to be independent.</p>
</td></tr>
<tr><td><code id="find_inside_+3A_random">random</code></td>
<td>
<p>if <code>TRUE</code>, random starting values in the interior are generated.
If <code>FALSE</code>, the center of the polytope is computed using linear programming.</p>
</td></tr>
<tr><td><code id="find_inside_+3A_probs">probs</code></td>
<td>
<p>only for <code>A*x&lt;b</code> representation: whether to add
inequality constraints that the variables are probabilities (nonnegative and
sum to 1 within each option)</p>
</td></tr>
<tr><td><code id="find_inside_+3A_boundary">boundary</code></td>
<td>
<p>constant value <code class="reqn">c</code> that is subtracted on the right-hand side
of the order constraints, <code class="reqn">A x \leq b - c</code>. This ensuresa that the
resulting point is in the interior of the polytope and
not at the boundary, which is important for MCMC sampling.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If vertices <code>V</code> are provided, a convex combination of the vertices is returned.
If <code>random=TRUE</code>, the weights are drawn uniformly from a Dirichlet distribution.
</p>
<p>If inequalities are provided via <code>A</code> and <code>b</code>, linear programming (LP) is used
to find the Chebyshev center of the polytope (i.e., the center of the largest ball that
fits into the polytope; the solution may not be unique). If <code>random=TRUE</code>,
LP is used to find a random point (not uniformly sampled!) in the convex polytope.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># inequality representation (A*x &lt;= b)
A &lt;- matrix(
  c(
    1, -1, 0, 1, 0,
    0, 0, -1, 0, 1,
    0, 0, 0, 1, -1,
    1, 1, 1, 1, 0,
    1, 1, 1, 0, 0,
    -1, 0, 0, 0, 0
  ),
  ncol = 5, byrow = TRUE
)
b &lt;- c(0.5, 0, 0, .7, .4, -.2)
find_inside(A, b)
find_inside(A, b, random = TRUE)


# vertex representation
V &lt;- matrix(c(
  # strict weak orders
  0, 1, 0, 1, 0, 1, # a &lt; b &lt; c
  1, 0, 0, 1, 0, 1, # b &lt; a &lt; c
  0, 1, 0, 1, 1, 0, # a &lt; c &lt; b
  0, 1, 1, 0, 1, 0, # c &lt; a &lt; b
  1, 0, 1, 0, 1, 0, # c &lt; b &lt; a
  1, 0, 1, 0, 0, 1, # b &lt; c &lt; a

  0, 0, 0, 1, 0, 1, # a ~ b &lt; c
  0, 1, 0, 0, 1, 0, # a ~ c &lt; b
  1, 0, 1, 0, 0, 0, # c ~ b &lt; a
  0, 1, 0, 1, 0, 0, # a &lt; b ~ c
  1, 0, 0, 0, 0, 1, # b &lt; a ~ c
  0, 0, 1, 0, 1, 0, # c &lt; a ~ b

  0, 0, 0, 0, 0, 0 # a ~ b ~ c
), byrow = TRUE, ncol = 6)
find_inside(V = V)
find_inside(V = V, random = TRUE)
</code></pre>

<hr>
<h2 id='heck2017'>Data: Multiattribute Decisions (Heck, Hilbig &amp; Moshagen, 2017)</h2><span id='topic+heck2017'></span>

<h3>Description</h3>

<p>Choice frequencies with multiattribute decisions across 4 item types (Heck, Hilbig &amp; Moshagen, 2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heck2017
</code></pre>


<h3>Format</h3>

<p>A data frame 4 variables:
</p>

<dl>
<dt><code>B1</code></dt><dd><p>Frequency of choosing Option B for Item Type 1</p>
</dd>
<dt><code>B2</code></dt><dd><p>Frequency of choosing Option B for Item Type 2</p>
</dd>
<dt><code>B3</code></dt><dd><p>Frequency of choosing Option B for Item Type 3</p>
</dd>
<dt><code>B4</code></dt><dd><p>Frequency of choosing Option B for Item Type 4</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each participant made 40 choices for each of 4 item types with four cues
(with validities .9, .8, .7, and .6).
The pattern of cue values of Option A and and B was as follows:
</p>

<dl>
<dt>Item Type 1: </dt><dd><p>A = (-1, 1, 1, -1) vs. B = (-1, -1, -1, -1)</p>
</dd>
<dt>Item Type 2: </dt><dd><p>A = (1, -1, -1, 1) vs. B = (-1, 1, -1, 1)</p>
</dd>
<dt>Item Type 3: </dt><dd><p>A = (-1, 1, 1, 1) vs. B = (-1, 1, 1, -1)</p>
</dd>
<dt>Item Type 4: </dt><dd><p>A = (1, -1, -1, -1) vs. B = (-1, 1, 1, -1)</p>
</dd>
</dl>

<p>Raw data are available as <code><a href="#topic+heck2017_raw">heck2017_raw</a></code>
</p>


<h3>References</h3>

<p>Heck, D. W., Hilbig, B. E., &amp; Moshagen, M. (2017). From information processing to decisions: Formalizing and comparing probabilistic choice models. Cognitive Psychology, 96, 26-40. <a href="https://doi.org/10.1016/j.cogpsych.2017.05.003">doi:10.1016/j.cogpsych.2017.05.003</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heck2017)
head(heck2017)
n &lt;- rep(40, 4)

# cue validities and values
v &lt;- c(.9, .8, .7, .6)
cueA &lt;- matrix(
  c(
    -1, 1, 1, -1,
    1, -1, -1, 1,
    -1, 1, 1, 1,
    1, -1, -1, -1
  ),
  ncol = 4, byrow = TRUE
)
cueB &lt;- matrix(
  c(
    -1, -1, -1, -1,
    -1, 1, -1, 1,
    -1, 1, 1, -1,
    -1, 1, 1, -1
  ),
  ncol = 4, byrow = TRUE
)

# get predictions
strategies &lt;- c(
  "baseline", "WADDprob", "WADD",
  "TTBprob", "TTB", "EQW", "GUESS"
)
strats &lt;- strategy_multiattribute(cueA, cueB, v, strategies)

# strategy classification with Bayes factor
strategy_postprob(heck2017[1:4, ], n, strats)
</code></pre>

<hr>
<h2 id='heck2017_raw'>Data: Multiattribute Decisions (Heck, Hilbig &amp; Moshagen, 2017)</h2><span id='topic+heck2017_raw'></span>

<h3>Description</h3>

<p>Raw data with multiattribute decisions (Heck, Hilbig &amp; Moshagen, 2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heck2017_raw
</code></pre>


<h3>Format</h3>

<p>A data frame with 21 variables:
</p>

<dl>
<dt><code>vp</code></dt><dd><p>ID code of participant</p>
</dd>
<dt><code>trial</code></dt><dd><p>Trial index</p>
</dd>
<dt><code>pattern</code></dt><dd><p>Number of cue pattern</p>
</dd>
<dt><code>ttb</code></dt><dd><p>Prediction of take-the-best (TTB)</p>
</dd>
<dt><code>eqw</code></dt><dd><p>Prediction of equal weights (EQW)</p>
</dd>
<dt><code>wadd</code></dt><dd><p>Prediction of  weighted additive (WADD)</p>
</dd>
<dt><code>logoddsdiff</code></dt><dd><p>Log-odds difference (WADDprob)</p>
</dd>
<dt><code>ttbsteps</code></dt><dd><p>Number of TTB steps (TTBprob)</p>
</dd>
<dt><code>itemtype</code></dt><dd><p>Item type as in paper</p>
</dd>
<dt><code>reversedorder</code></dt><dd><p>Whether item is reversed</p>
</dd>
<dt><code>choice</code></dt><dd><p>Choice</p>
</dd>
<dt><code>rt</code></dt><dd><p>Response time</p>
</dd>
<dt><code>choice.rev</code></dt><dd><p>Choice (reversed)</p>
</dd>
<dt><code>a1</code></dt><dd><p>Value of Cue 1 for Option A</p>
</dd>
<dt><code>a2</code></dt><dd><p>Value of Cue 2 for Option A</p>
</dd>
<dt><code>a3</code></dt><dd><p>Value of Cue 3 for Option A</p>
</dd>
<dt><code>a4</code></dt><dd><p>Value of Cue 4 for Option A</p>
</dd>
<dt><code>b1</code></dt><dd><p>Value of Cue 1 for Option B</p>
</dd>
<dt><code>b2</code></dt><dd><p>Value of Cue 2 for Option B</p>
</dd>
<dt><code>b3</code></dt><dd><p>Value of Cue 3 for Option B</p>
</dd>
<dt><code>b4</code></dt><dd><p>Value of Cue 4 for Option B</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each participant made 40 choices for each of 4 item types with four cues
(with validities .9, .8, .7, and .6).
Individual choice freqeuncies are available as <code><a href="#topic+heck2017">heck2017</a></code>
</p>


<h3>References</h3>

<p>Heck, D. W., Hilbig, B. E., &amp; Moshagen, M. (2017). From information processing to decisions: Formalizing and comparing probabilistic choice models. Cognitive Psychology, 96, 26-40. <a href="https://doi.org/10.1016/j.cogpsych.2017.05.003">doi:10.1016/j.cogpsych.2017.05.003</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+heck2017">heck2017</a></code> for the aggregated choice frequencies per item type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heck2017_raw)
head(heck2017_raw)


# get cue values, validities, and predictions
cueA &lt;- heck2017_raw[, paste0("a", 1:4)]
cueB &lt;- heck2017_raw[, paste0("b", 1:4)]
v &lt;- c(.9, .8, .7, .6)
strat &lt;- strategy_multiattribute(
  cueA, cueB, v,
  c(
    "TTB", "TTBprob", "WADD",
    "WADDprob", "EQW", "GUESS"
  )
)

# get unique item types
types &lt;- strategy_unique(strat)
types$unique

# get table of choice frequencies for analysis
freq &lt;- with(
  heck2017_raw,
  table(vp, types$item_type, choice)
)
freqB &lt;- freq[, 4:1, 1] + # reversed items: Option A
  freq[, 5:8, 2] # non-rev. items: Option B
head(40 - freqB)
data(heck2017)
head(heck2017) # same frequencies (different order)

# strategy classification
pp &lt;- strategy_postprob(
  freqB[1:4, ], rep(40, 4),
  types$strategies
)
round(pp, 3)

</code></pre>

<hr>
<h2 id='hilbig2014'>Data: Multiattribute Decisions (Hilbig &amp; Moshagen, 2014)</h2><span id='topic+hilbig2014'></span>

<h3>Description</h3>

<p>Choice frequencies of multiattribute decisions across 3 item types (Hilbig &amp; Moshagen, 2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hilbig2014
</code></pre>


<h3>Format</h3>

<p>A data frame 3 variables:
</p>

<dl>
<dt><code>B1</code></dt><dd><p>Frequency of choosing Option B for Item Type 1</p>
</dd>
<dt><code>B2</code></dt><dd><p>Frequency of choosing Option B for Item Type 2</p>
</dd>
<dt><code>B3</code></dt><dd><p>Frequency of choosing Option B for Item Type 3</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each participant made 32 choices for each of 3 item types with four cues (with validities .9, .8, .7, and .6).
</p>
<p>The pattern of cue values of Option A and and B was as follows:
</p>

<dl>
<dt>Item Type 1: </dt><dd><p>A = (1, 1, 1, -1) vs. B = (-1, 1, -1, 1)</p>
</dd>
<dt>Item Type 2: </dt><dd><p>A = (1, -1, -1, -1) vs. B = (-1, 1, 1, -1)</p>
</dd>
<dt>Item Type 3: </dt><dd><p>A = (1, 1, 1, -1) vs. B = (-1, 1, 1, 1)</p>
</dd>
</dl>



<h3>References</h3>

<p>Hilbig, B. E., &amp; Moshagen, M. (2014). Generalized outcome-based strategy classification: Comparing deterministic and probabilistic choice models. Psychonomic Bulletin &amp; Review, 21(6), 1431-1443. <a href="https://doi.org/10.3758/s13423-014-0643-0">doi:10.3758/s13423-014-0643-0</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hilbig2014)
head(hilbig2014)

# validities and cue values
v &lt;- c(.9, .8, .7, .6)
cueA &lt;- matrix(
  c(
    1, 1, 1, -1,
    1, -1, -1, -1,
    1, 1, 1, -1
  ),
  ncol = 4, byrow = TRUE
)
cueB &lt;- matrix(
  c(
    -1, 1, -1, 1,
    -1, 1, 1, -1,
    -1, 1, 1, 1
  ),
  ncol = 4, byrow = TRUE
)

# get strategy predictions
strategies &lt;- c(
  "baseline", "WADDprob", "WADD",
  "TTB", "EQW", "GUESS"
)
preds &lt;- strategy_multiattribute(cueA, cueB, v, strategies)
c &lt;- c(1, rep(.5, 5)) # upper bound of probabilities

# use Bayes factor for strategy classification
n &lt;- rep(32, 3)
strategy_postprob(k = hilbig2014[1:5, ], n, preds)
</code></pre>

<hr>
<h2 id='inside'>Check Whether Points are Inside a Convex Polytope</h2><span id='topic+inside'></span>

<h3>Description</h3>

<p>Determines whether a point <code>x</code> is inside a convex poltyope by checking whether
(1) all inequalities <code>A*x &lt;= b</code> are satisfied or
(2) the point <code>x</code> is in the convex hull of the vertices in <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inside(x, A, b, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inside_+3A_x">x</code></td>
<td>
<p>a vector of length equal to the number of columns of <code>A</code> or <code>V</code>
(i.e., a single point in D-dimensional space) or matrix of points/vertices (one per row).</p>
</td></tr>
<tr><td><code id="inside_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="inside_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="inside_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+Ab_to_V">Ab_to_V</a></code> and <code><a href="#topic+V_to_Ab">V_to_Ab</a></code> to change between A/b and V representation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># linear order constraints:  x1&lt;x2&lt;x3&lt;.5
A &lt;- matrix(c(
  1, -1, 0,
  0, 1, -1,
  0, 0, 1
), ncol = 3, byrow = TRUE)
b &lt;- c(0, 0, .50)

# vertices: admissible points (corners of polytope)
V &lt;- matrix(c(
  0, 0, 0,
  0, 0, .5,
  0, .5, .5,
  .5, .5, .5
), ncol = 3, byrow = TRUE)

xin &lt;- c(.1, .2, .45) # inside
inside(xin, A, b)
inside(xin, V = V)

xout &lt;- c(.4, .1, .55) # outside
inside(xout, A, b)
inside(xout, V = V)
</code></pre>

<hr>
<h2 id='inside_binom'>Check Whether Choice Frequencies are in Polytope</h2><span id='topic+inside_binom'></span><span id='topic+inside_multinom'></span>

<h3>Description</h3>

<p>Computes relative choice frequencies and checks whether these are in the polytope defined
via (1) <code>A*x &lt;= b</code> or (2) by the convex hull of a set of vertices <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inside_binom(k, n, A, b, V)

inside_multinom(k, options, A, b, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inside_binom_+3A_k">k</code></td>
<td>
<p>choice frequencies.
For <code>inside_binom</code>: per item type (e.g.: a1,b1,c1,..)
For <code>inside_multinom</code>: for all choice options ordered by item type
(e.g., for ternary choices: a1,a2,a3, b1,b2,b3,..)</p>
</td></tr>
<tr><td><code id="inside_binom_+3A_n">n</code></td>
<td>
<p>only for <code>inside_binom</code>: number of choices per item type.</p>
</td></tr>
<tr><td><code id="inside_binom_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="inside_binom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="inside_binom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="inside_binom_+3A_options">options</code></td>
<td>
<p>only for <code>inside_multinom</code>: number of response options per item type.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+inside">inside</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>############ binomial
# x1&lt;x2&lt;x3&lt;.50:
A &lt;- matrix(c(
  1, -1, 0,
  0, 1, -1,
  0, 0, 1
), ncol = 3, byrow = TRUE)
b &lt;- c(0, 0, .50)
k &lt;- c(0, 1, 5)
n &lt;- c(10, 10, 10)
inside_binom(k, n, A, b)

############ multinomial
# two ternary choices:
#     (a1,a2,a3,   b1,b2,b3)
k &lt;- c(1, 4, 10, 5, 9, 1)
options &lt;- c(3, 3)
# a1&lt;b1, a2&lt;b2, no constraints on a3, b3
A &lt;- matrix(c(
  1, -1, 0, 0,
  0, 0, 1, -1
), ncol = 4, byrow = TRUE)
b &lt;- c(0, 0)
inside_multinom(k, options, A, b)

# V-representation:
V &lt;- matrix(c(
  0, 0, 0, 0,
  0, 0, 0, 1,
  0, 1, 0, 0,
  0, 0, 1, 1,
  0, 1, 0, 1,
  1, 1, 0, 0,
  0, 1, 1, 1,
  1, 1, 0, 1,
  1, 1, 1, 1
), 9, 4, byrow = TRUE)
inside_multinom(k, options, V = V)
</code></pre>

<hr>
<h2 id='karabatsos2004'>Data: Item Responses Theory (Karabatsos &amp; Sheu, 2004)</h2><span id='topic+karabatsos2004'></span>

<h3>Description</h3>

<p>The test was part of the 1992 Trial State Assessment in Reading at
Grade 4, conducted by the National Assessments of Educational Progress (NAEP).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>karabatsos2004
</code></pre>


<h3>Format</h3>

<p>A list with 4 matrices:
</p>

<dl>
<dt><code>k.M</code>: </dt><dd><p>Number of correct responses for participants with rest scores
j=0,...,5 (i.e., the sum score minus the score for item i)</p>
</dd>
<dt><code>n.M</code>: </dt><dd><p>Total number of participants for each cell of matrix <code>k.M</code></p>
</dd>
<dt><code>k.IIO</code>: </dt><dd><p>Number of correct responses for participants with sum scores j=0,...,6</p>
</dd>
<dt><code>n.IIO</code>: </dt><dd><p>Total number of participants for each cell of matrix <code>k.IIO</code></p>
</dd>
</dl>



<h3>References</h3>

<p>Karabatsos, G., &amp; Sheu, C.-F. (2004). Order-constrained Bayes inference for dichotomous models of unidimensional nonparametric IRT. Applied Psychological Measurement, 28(2), 110-125. <a href="https://doi.org/10.1177/0146621603260678">doi:10.1177/0146621603260678</a>
</p>


<h3>See Also</h3>

<p>The polytope for the nonparametric item response theory can be obtained
using (see <code><a href="#topic+nirt_to_Ab">nirt_to_Ab</a></code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(karabatsos2004)
head(karabatsos2004)

######################################################
##### Testing Monotonicity (M)                   #####
##### (Karabatsos &amp; Sheu, 2004, Table 3, p. 120) #####

IJ &lt;- dim(karabatsos2004$k.M)
monotonicity &lt;- nirt_to_Ab(IJ[1], IJ[2], axioms = "W1")
p &lt;- sampling_binom(
  k = c(karabatsos2004$k.M),
  n = c(karabatsos2004$n.M),
  A = monotonicity$A, b = monotonicity$b,
  prior = c(.5, .5), M = 300
)

# posterior means (Table 4, p. 120)
post.mean &lt;- matrix(apply(p, 2, mean), IJ[1],
  dimnames = dimnames(karabatsos2004$k.M)
)
round(post.mean, 2)

# posterior predictive checks (Table 4, p. 121)
ppp &lt;- ppp_binom(p, c(karabatsos2004$k.M), c(karabatsos2004$n.M),
  by = 1:prod(IJ)
)
ppp &lt;- matrix(ppp[, 3], IJ[1], dimnames = dimnames(karabatsos2004$k.M))
round(ppp, 2)


######################################################
##### Testing invariant item ordering (IIO)      #####
##### (Karabatsos &amp; Sheu, 2004, Table 6, p. 122) #####

IJ &lt;- dim(karabatsos2004$k.IIO)
iio &lt;- nirt_to_Ab(IJ[1], IJ[2], axioms = "W2")
p &lt;- sampling_binom(
  k = c(karabatsos2004$k.IIO),
  n = c(karabatsos2004$n.IIO),
  A = iio$A, b = iio$b,
  prior = c(.5, .5), M = 300
)
# posterior predictive checks (Table 6, p. 122)
ppp &lt;- ppp_binom(prob = p, k = c(karabatsos2004$k.IIO),
                 n = c(karabatsos2004$n.IIO), by = 1:prod(IJ))
matrix(ppp[,3], 7, dimnames = dimnames(karabatsos2004$k.IIO))

# for each item:
ppp &lt;- ppp_binom(p, c(karabatsos2004$k.IIO), c(karabatsos2004$n.IIO),
                 by = rep(1:IJ[2], each = IJ[1]))
round(ppp[,3], 2)
</code></pre>

<hr>
<h2 id='ml_binom'>Maximum-likelihood Estimate</h2><span id='topic+ml_binom'></span><span id='topic+ml_multinom'></span>

<h3>Description</h3>

<p>Get ML estimate for product-binomial/multinomial model with linear inequality constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ml_binom(k, n, A, b, map, strategy, n.fit = 3, start, progress = FALSE, ...)

ml_multinom(k, options, A, b, V, n.fit = 3, start, progress = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ml_binom_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_n">n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_map">map</code></td>
<td>
<p>optional: numeric vector of the same length as <code>k</code> with integers
mapping the frequencies <code>k</code> to the free parameters/columns of <code>A</code>/<code>V</code>,
thereby allowing for equality constraints (e.g., <code>map=c(1,1,2,2)</code>).
Reversed probabilities <code>1-p</code> are coded by negative integers.
Guessing probabilities of .50 are encoded by zeros. The default assumes
different parameters for each item type: <code>map=1:ncol(A)</code></p>
</td></tr>
<tr><td><code id="ml_binom_+3A_strategy">strategy</code></td>
<td>
<p>a list that defines the predictions of a strategy, see<code><a href="#topic+strategy_multiattribute">strategy_multiattribute</a></code>.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_n.fit">n.fit</code></td>
<td>
<p>number of calls to <a href="stats.html#topic+constrOptim">constrOptim</a>.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_start">start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_...">...</code></td>
<td>
<p>further arguments passed to the function
<code><a href="stats.html#topic+constrOptim">constrOptim</a></code>. To ensure high accuracy, the number of
maximum iterations should be sufficiently large (e.g., by setting
<code>control = list(maxit = 1e6, reltol=.Machine$double.eps^.6), outer.iterations = 1000</code>.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="ml_binom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, it is checked whether the unconstrained maximum-likelihood estimator
(e.g., for the binomial: <code>k/n</code>) is inside the constrained parameter space.
Only if this is not the case, nonlinear optimization with convex linear-inequality
constrained is used to estimate (A) the probability parameters <code class="reqn">\theta</code>
for the Ab-representation or (B) the mixture weights <code class="reqn">\alpha</code> for the V-representation.
</p>


<h3>Value</h3>

<p>the list returned by the optimizer <code><a href="stats.html#topic+constrOptim">constrOptim</a></code>,
including the input arguments (e.g., <code>k</code>, <code>options</code>, <code>A</code>, <code>V</code>, etc.).
</p>

<ul>
<li><p> If the Ab-representation was used, <code>par</code> provides the ML estimate for
the probability vector <code class="reqn">\theta</code>.
</p>
</li>
<li><p> If the V-representation was used, <code>par</code> provides the estimates for the
(usually not identifiable) mixture weights <code class="reqn">\alpha</code> that define the convex
hull of the vertices in <code class="reqn">V</code>, while <code>p</code> provides the ML estimates for
the probability parameters. Because the weights must sum to one, the
<code class="reqn">\alpha</code>-parameter for the last row of the matrix <code class="reqn">V</code> is dropped.
If the unconstrained ML estimate is inside the convex hull, the mixture weights
<code class="reqn">\alpha</code> are not estimated and replaced by missings (<code>NA</code>).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># predicted linear order: p1 &lt; p2 &lt; p3 &lt; .50
# (cf. WADDprob in ?strategy_multiattribute)
A &lt;- matrix(
  c(
    1, -1, 0,
    0, 1, -1,
    0, 0, 1
  ),
  ncol = 3, byrow = TRUE
)
b &lt;- c(0, 0, .50)
ml_binom(k = c(4, 1, 23), n = 40, A, b)[1:2]
ml_multinom(
  k = c(4, 36, 1, 39, 23, 17),
  options = c(2, 2, 2), A, b
)[1:2]


# probabilistic strategy:  A,A,A,B  [e1&lt;e2&lt;e3&lt;e4&lt;.50]
strat &lt;- list(
  pattern = c(-1, -2, -3, 4),
  c = .5, ordered = TRUE, prior = c(1, 1)
)
ml_binom(c(7, 3, 1, 19), 20, strategy = strat)[1:2]


# vertex representation (one prediction per row)
V &lt;- matrix(c(
  # strict weak orders
  0, 1, 0, 1, 0, 1, # a &lt; b &lt; c
  1, 0, 0, 1, 0, 1, # b &lt; a &lt; c
  0, 1, 0, 1, 1, 0, # a &lt; c &lt; b
  0, 1, 1, 0, 1, 0, # c &lt; a &lt; b
  1, 0, 1, 0, 1, 0, # c &lt; b &lt; a
  1, 0, 1, 0, 0, 1, # b &lt; c &lt; a

  0, 0, 0, 1, 0, 1, # a ~ b &lt; c
  0, 1, 0, 0, 1, 0, # a ~ c &lt; b
  1, 0, 1, 0, 0, 0, # c ~ b &lt; a
  0, 1, 0, 1, 0, 0, # a &lt; b ~ c
  1, 0, 0, 0, 0, 1, # b &lt; a ~ c
  0, 0, 1, 0, 1, 0, # c &lt; a ~ b

  0, 0, 0, 0, 0, 0 # a ~ b ~ c
), byrow = TRUE, ncol = 6)
ml_multinom(
  k = c(4, 1, 5, 1, 9, 0, 7, 2, 1), n.fit = 1,
  options = c(3, 3, 3), V = V
)
</code></pre>

<hr>
<h2 id='model_weights'>Get Posterior/NML Model Weights</h2><span id='topic+model_weights'></span>

<h3>Description</h3>

<p>Computes the posterior model probabilities based on the log-marginal likelihoods/negative NML values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_weights(x, prior)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_weights_+3A_x">x</code></td>
<td>
<p>vector or matrix of log-marginal probabilities or negative NML values (if matrix: one model per column)</p>
</td></tr>
<tr><td><code id="model_weights_+3A_prior">prior</code></td>
<td>
<p>vector of prior model probabilities (default: uniform over models). The vector is normalized internally to sum to one.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>logmarginal &lt;- c(-3.4, -2.0, -10.7)
model_weights(logmarginal)

nml &lt;- matrix(c(
  2.5, 3.1, 4.2,
  1.4, 0.3, 8.2
), nrow = 2, byrow = TRUE)
model_weights(-nml)
</code></pre>

<hr>
<h2 id='nirt_to_Ab'>Nonparametric Item Response Theory (NIRT)</h2><span id='topic+nirt_to_Ab'></span>

<h3>Description</h3>

<p>Provides the inequality constraints on choice probabilities implied by
nonparametric item response theory (NIRT; Karabatsos, 2001).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nirt_to_Ab(N, M, options = 2, axioms = c("W1", "W2"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nirt_to_Ab_+3A_n">N</code></td>
<td>
<p>number of persons / rows in item-response table</p>
</td></tr>
<tr><td><code id="nirt_to_Ab_+3A_m">M</code></td>
<td>
<p>number of items / columns in item-response table</p>
</td></tr>
<tr><td><code id="nirt_to_Ab_+3A_options">options</code></td>
<td>
<p>number of item categories/response options. If <code>options=2</code>,
a dichotomous NIRT for product-binomial data is returned.</p>
</td></tr>
<tr><td><code id="nirt_to_Ab_+3A_axioms">axioms</code></td>
<td>
<p>which axioms should be included in the polytope representation <code class="reqn">A*x &lt;= b</code>?
See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to parametric IRT models (e.g., the 1-parameter-logistic Rasch model),
NIRT does not assume specific parametric shapes of the item-response and person-response
functions. Instead, the necessary axioms for a unidimensional representation of
the latent trait are tested directly.
</p>
<p>The axioms are as follows:
</p>

<dl>
<dt><code>"W1"</code>: </dt><dd><p>Weak row/subject independence: Persons can be ordered on
an ordinal scale independent of items.</p>
</dd>
<dt><code>"W2"</code>: </dt><dd><p>Weak column/item independence: Items can be ordered on
an ordinal scale independent of persons</p>
</dd>
<dt><code>"DC"</code>: </dt><dd><p>Double cancellation: A necessary condition for a joint
ordering of (person,item) pairs and an additive representation
(i.e., an interval scale).</p>
</dd>
</dl>

<p>Note that axioms W1 and W2 jointly define the ISOP model by Scheiblechner
(1995; isotonic ordinal probabilistic model) and the double homogeneity model
by Mokken (1971). If DC is added, we obtain the ADISOP model
by Scheiblechner (1999; ).
</p>


<h3>References</h3>

<p>Karabatsos, G. (2001). The Rasch model, additive conjoint measurement, and new models of probabilistic measurement theory. Journal of Applied Measurement, 2(4), 389–423.
</p>
<p>Karabatsos, G., &amp; Sheu, C.-F. (2004). Order-constrained Bayes inference for dichotomous models of unidimensional nonparametric IRT. Applied Psychological Measurement, 28(2), 110-125. <a href="https://doi.org/10.1177/0146621603260678">doi:10.1177/0146621603260678</a>
</p>
<p>Mokken, R. J. (1971). A theory and procedure of scale analysis: With applications in political research (Vol. 1). Berlin: Walter de Gruyter.
</p>
<p>Scheiblechner, H. (1995). Isotonic ordinal probabilistic models (ISOP).
Psychometrika, 60(2), 281–304. <a href="https://doi.org/10.1007/BF02301417">doi:10.1007/BF02301417</a>
</p>
<p>Scheiblechner, H. (1999). Additive conjoint isotonic probabilistic models (ADISOP).
Psychometrika, 64(3), 295–316. <a href="https://doi.org/10.1007/BF02294297">doi:10.1007/BF02294297</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 5 persons, 3 items
nirt_to_Ab(5, 3)
</code></pre>

<hr>
<h2 id='population_bf'>Aggregation of Individual Bayes Factors</h2><span id='topic+population_bf'></span>

<h3>Description</h3>

<p>Aggregation of multiple individual (N=1) Bayes factors to obtain the evidence
for a hypothesis in a population of persons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>population_bf(bfs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="population_bf_+3A_bfs">bfs</code></td>
<td>
<p>a vector with individual Bayes factors,
a matrix with one type of Bayes-factor comparison per column,
or a list of matrices with a named column <code>"bf"</code> (as returned by
<code><a href="#topic+bf_multinom">bf_multinom</a></code>/<code><a href="#topic+count_to_bf">count_to_bf</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix with named elements/columns:
</p>

<ul>
<li> <p><code>population_bf</code>: the product of individual BFs
</p>
</li>
<li> <p><code>geometric_bf</code>: the geometric mean of the individual BFs
</p>
</li>
<li> <p><code>evidence_rate</code>: the proportion of BFs&gt;1 (BFs&lt;1) if <code>geometric_bf&gt;1</code> (&lt;1).
Values close to 1.00 indicate homogeneity.
</p>
</li>
<li> <p><code>stability_rate</code>: the proportion <code>bfs&gt;geometric_bf</code> (&lt;) if <code>geometric_bf&gt;1</code> (&lt;).
Values close to 0.50 indicate stability.
</p>
</li></ul>



<h3>References</h3>

<p>Klaassen, F., Zedelius, C. M., Veling, H., Aarts, H., &amp; Hoijtink, H. (in press).
All for one or some for all? Evaluating informative hypotheses using multiple N = 1 studies.
Behavior Research Methods. https://doi.org/10.3758/s13428-017-0992-5
</p>


<h3>Examples</h3>

<pre><code class='language-R'># consistent evidence across persons:
bfs &lt;- c(2.3, 1.8, 3.3, 2.8, 4.0, 1.9, 2.5)
population_bf(bfs)

# (A) heterogeneous, inconsistent evidence
# (B) heterogeneous, inconsistent evidence
bfs &lt;- cbind(
  A = c(2.3, 1.8, 3.3, 2.8, 4.0, 1.9, 2.5),
  B = c(10.3, .7, 3.3, .8, 14.0, .9, 1.5)
)
population_bf(bfs)

</code></pre>

<hr>
<h2 id='postprob'>Transform Bayes Factors to Posterior Model Probabilities</h2><span id='topic+postprob'></span>

<h3>Description</h3>

<p>Computes posterior model probabilities based on Bayes factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postprob(..., prior, include_unconstr = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="postprob_+3A_...">...</code></td>
<td>
<p>one or more Bayes-factor objects for different models as returned
by the functions <code><a href="#topic+bf_binom">bf_binom</a></code>, <code><a href="#topic+bf_multinom">bf_multinom</a></code> and
<code><a href="#topic+count_to_bf">count_to_bf</a></code> (i.e., a 3x4 matrix containing a row
<code>"bf0u"</code> and a column <code>"bf"</code>). Note that the Bayes factors must
have been computed for the same data and using the same prior (this is not
checked internally).</p>
</td></tr>
<tr><td><code id="postprob_+3A_prior">prior</code></td>
<td>
<p>a vector of prior model probabilities (default: uniform). The
order must be identical to that of the Bayes factors supplied via
<code>...</code>. If <code>include_unconstr=TRUE</code>, the unconstrained model is
automatically added to the list of models (at the last position).</p>
</td></tr>
<tr><td><code id="postprob_+3A_include_unconstr">include_unconstr</code></td>
<td>
<p>whether to include the unconstrained, encompassing
model without inequality constraints (i.e., the saturated model).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># data: binomial frequencies in 4 conditions
n &lt;- 100
k &lt;- c(59, 54, 74)

# Hypothesis 1: p1 &lt; p2 &lt; p3
A1 &lt;- matrix(c(
  1, -1, 0,
  0, 1, -1
), 2, 3, TRUE)
b1 &lt;- c(0, 0)

# Hypothesis 2: p1 &lt; p2 and p1 &lt; p3
A2 &lt;- matrix(c(
  1, -1, 0,
  1, 0, -1
), 2, 3, TRUE)
b2 &lt;- c(0, 0)

# get posterior probability for hypothesis
bf1 &lt;- bf_binom(k, n, A = A1, b = b1)
bf2 &lt;- bf_binom(k, n, A = A2, b = b2)
postprob(bf1, bf2,
  prior = c(bf1 = 1 / 3, bf2 = 1 / 3, unconstr = 1 / 3)
)
</code></pre>

<hr>
<h2 id='ppp_binom'>Posterior Predictive p-Values</h2><span id='topic+ppp_binom'></span><span id='topic+ppp_multinom'></span>

<h3>Description</h3>

<p>Uses posterior samples to get posterior-predicted frequencies and compare
the Pearson's X^2 statistic for (1) the observed frequencies vs. (2) the
posterior-predicted frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppp_binom(prob, k, n, by)

ppp_multinom(prob, k, options, drop_fixed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppp_binom_+3A_prob">prob</code></td>
<td>
<p>vector with probabilities or a matrix with one probability vector per row.
For <code>rpbinom</code>: probabilities of a success for each option.
For <code>rpmultinom</code>: probabilities of all categories excluding
the last category for each option (cf. <code>drop_fixed</code>).
See also <code><a href="#topic+sampling_binom">sampling_binom</a></code> and <code><a href="#topic+sampling_multinom">sampling_multinom</a></code>.</p>
</td></tr>
<tr><td><code id="ppp_binom_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="ppp_binom_+3A_n">n</code></td>
<td>
<p>integer vector, specifying the number of trials for each binomial/multinomial distribution
Note that this is the <code>size</code> argument in <code>rmultinom</code>, cf. <code><a href="stats.html#topic+Multinom">Multinom</a></code>.</p>
</td></tr>
<tr><td><code id="ppp_binom_+3A_by">by</code></td>
<td>
<p>optional: a vector of the same length as <code>k</code> indicating factor levels
by which the posterior-predictive checks should be split (e.g., by item sets).</p>
</td></tr>
<tr><td><code id="ppp_binom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="ppp_binom_+3A_drop_fixed">drop_fixed</code></td>
<td>
<p>whether the output matrix includes the last probability for each category
(which is not a free parameter since probabilities must sum to one).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Myung, J. I., Karabatsos, G., &amp; Iverson, G. J. (2005). A Bayesian approach to testing decision making axioms. <em>Journal of Mathematical Psychology, 49</em>, 205-225. <a href="https://doi.org/10.1016/j.jmp.2005.02.004">doi:10.1016/j.jmp.2005.02.004</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampling_binom">sampling_binom</a></code>/<code><a href="#topic+sampling_multinom">sampling_multinom</a></code> to get
posterior samples and <code><a href="#topic+rpbinom">rpbinom</a></code>/<code><a href="#topic+rpmultinom">rpmultinom</a></code> to
get posterior-predictive samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># uniform samples:  p&lt;.10
prob &lt;- matrix(runif(300 * 3, 0, .1), 300)
n &lt;- rep(10, 3)
ppp_binom(prob, c(1, 2, 0), n) # ok
ppp_binom(prob, c(5, 4, 3), n) # misfit

# multinomial (ternary choice)
prob &lt;- matrix(runif(300 * 2, 0, .05), 300)
ppp_multinom(prob, c(1, 0, 9), 3) # ok
</code></pre>

<hr>
<h2 id='regenwetter2012'>Data: Ternary Risky Choices (Regenwetter &amp; Davis-Stober, 2012)</h2><span id='topic+regenwetter2012'></span>

<h3>Description</h3>

<p>Raw data with choice frequencies for all 20 paired comparison of 5 gambles a, b, c, d, and e.
Participants could either choose &quot;Option 1&quot;, &quot;Option 2&quot;, or &quot;indifferent&quot; (ternary choice).
Each paired comparison (e.g., a vs. b) was repeated 45 times per participant.
The data include 3 different gamble sets and aimed at testing whether people
have transitive preferences (see Regenwetter &amp; Davis-Stober, 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regenwetter2012
</code></pre>


<h3>Format</h3>

<p>A matrix with 22 columns:
</p>

<dl>
<dt><code>participant</code>: </dt><dd><p>Participant number</p>
</dd>
<dt><code>gamble_set</code>: </dt><dd><p>Gamble set</p>
</dd>
<dt><code>a&gt;b</code>: </dt><dd><p>Number of times a preferred over b</p>
</dd>
<dt><code>b&gt;a</code>: </dt><dd><p>Number of times b preferred over a</p>
</dd>
<dt><code>a=b</code>: </dt><dd><p>Number of times being indifferent between a and b</p>
</dd>
</dl>



<h3>References</h3>

<p>Regenwetter, M., &amp; Davis-Stober, C. P. (2012). Behavioral variability of choices versus structural inconsistency of preferences. Psychological Review, 119(2), 408-416. <a href="https://doi.org/10.1037/a0027372">doi:10.1037/a0027372</a>
</p>


<h3>See Also</h3>

<p>The substantive model of interest was the strict weak order polytope (see <code><a href="#topic+swop5">swop5</a></code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(regenwetter2012)
head(regenwetter2012)

# check transitive preferences: strict weak order polytope (SWOP)
data(swop5)
tail(swop5$A, 3)
# participant 1, gamble set 1:
p1 &lt;- regenwetter2012[1, -c(1:2)]
inside_multinom(p1, swop5$options, swop5$A, swop5$b)


# posterior samples
p &lt;- sampling_multinom(regenwetter2012[1, -c(1:2)],
  swop5$options, swop5$A, swop5$b,
  M = 100, start = swop5$start
)
colMeans(p)
apply(p[, 1:6], 2, plot, type = "l")
ppp_multinom(p, p1, swop5$options)

# Bayes factor
bf_multinom(regenwetter2012[1, -c(1:2)], swop5$options,
  swop5$A, swop5$b,
  M = 10000
)

</code></pre>

<hr>
<h2 id='rpbinom'>Random Generation for Independent Multinomial Distributions</h2><span id='topic+rpbinom'></span><span id='topic+rpmultinom'></span>

<h3>Description</h3>

<p>Generates random draws from independent multinomial distributions (= product-multinomial <code>pmultinom</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpbinom(prob, n)

rpmultinom(prob, n, options, drop_fixed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rpbinom_+3A_prob">prob</code></td>
<td>
<p>vector with probabilities or a matrix with one probability vector per row.
For <code>rpbinom</code>: probabilities of a success for each option.
For <code>rpmultinom</code>: probabilities of all categories excluding
the last category for each option (cf. <code>drop_fixed</code>).
See also <code><a href="#topic+sampling_binom">sampling_binom</a></code> and <code><a href="#topic+sampling_multinom">sampling_multinom</a></code>.</p>
</td></tr>
<tr><td><code id="rpbinom_+3A_n">n</code></td>
<td>
<p>integer vector, specifying the number of trials for each binomial/multinomial distribution
Note that this is the <code>size</code> argument in <code>rmultinom</code>, cf. <code><a href="stats.html#topic+Multinom">Multinom</a></code>.</p>
</td></tr>
<tr><td><code id="rpbinom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="rpbinom_+3A_drop_fixed">drop_fixed</code></td>
<td>
<p>whether the output matrix includes the last probability for each category
(which is not a free parameter since probabilities must sum to one).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with one vector of frequencies per row. For <code>rpbinom</code>, only
the frequencies of 'successes' are returned, whereas for <code>rpmultinom</code>, the
complete frequency vectors (which sum to <code>n</code> within each option) are returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 3 binomials
rpbinom(prob = c(.2, .7, .9), n = c(10, 50, 30))

# 2 and 3 options:  [a1,a2,  b1,b2,b3]
rpmultinom(
  prob = c(a1 = .5, b1 = .3, b2 = .6),
  n = c(10, 20), options = c(2, 3)
)
# or:
rpmultinom(
  prob = c(a1 = .5, a2 = .5, b1 = .3, b2 = .6, b3 = .1),
  n = c(10, 20), options = c(2, 3),
  drop_fixed = FALSE
)

# matrix with one probability vector per row:
p &lt;- rpdirichlet(
  n = 6, alpha = c(1, 1, 1, 1, 1),
  options = c(2, 3)
)
rpmultinom(prob = p, n = c(20, 50), options = c(2, 3))
</code></pre>

<hr>
<h2 id='rpdirichlet'>Random Samples from the Product-Dirichlet Distribution</h2><span id='topic+rpdirichlet'></span>

<h3>Description</h3>

<p>Random samples from the prior/posterior (i.e., product-Dirichlet) of the unconstrained
product-multinomial model (the encompassing model).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpdirichlet(n, alpha, options, drop_fixed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rpdirichlet_+3A_n">n</code></td>
<td>
<p>number of samples</p>
</td></tr>
<tr><td><code id="rpdirichlet_+3A_alpha">alpha</code></td>
<td>
<p>Dirichlet parameters concatenated across independent conditions
(e.g., a1,a2,  b1,b2,b3)</p>
</td></tr>
<tr><td><code id="rpdirichlet_+3A_options">options</code></td>
<td>
<p>the number of choice options per item type, e.g., <code>c(2,3)</code>
for a binary and ternary condition.
The sum of <code>options</code> must be equal to the length of <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="rpdirichlet_+3A_drop_fixed">drop_fixed</code></td>
<td>
<p>whether the output matrix includes the last probability for each category
(which is not a free parameter since probabilities must sum to one).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># standard uniform Dirichlet
rpdirichlet(5, c(1,1,1,1), 4)
rpdirichlet(5, c(1,1,1,1), 4, drop_fixed = FALSE)

# two ternary outcomes: (a1,a2,a3,  b1,b2,b3)
rpdirichlet(5, c(9,5,1,  3,6,6), c(3,3))
rpdirichlet(5, c(9,5,1,  3,6,6), c(3,3), drop_fixed = FALSE)
</code></pre>

<hr>
<h2 id='sampling_multinom'>Posterior Sampling for Inequality-Constrained Multinomial Models</h2><span id='topic+sampling_multinom'></span><span id='topic+sampling_binom'></span>

<h3>Description</h3>

<p>Uses Gibbs sampling to draw posterior samples for binomial and multinomial
models with linear inequality-constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampling_multinom(
  k,
  options,
  A,
  b,
  V,
  prior = rep(1, sum(options)),
  M = 5000,
  start,
  burnin = 10,
  progress = TRUE,
  cpu = 1
)

sampling_binom(
  k,
  n,
  A,
  b,
  V,
  map = 1:ncol(A),
  prior = c(1, 1),
  M = 5000,
  start,
  burnin = 10,
  progress = TRUE,
  cpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampling_multinom_+3A_k">k</code></td>
<td>
<p>the number of choices for each alternative ordered by item type (e.g.
<code>c(a1,a2,a3,  b1,b2)</code> for a ternary and a binary item type).
The length of <code>k</code> must be equal to the sum of <code>options</code>.
The default <code>k=0</code> is equivalent to sampling from the prior.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_a">A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_v">V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_prior">prior</code></td>
<td>
<p>the prior parameters of the Dirichlet-shape parameters.
Must have the same length as <code>k</code>.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_m">M</code></td>
<td>
<p>number of posterior samples</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_start">start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_burnin">burnin</code></td>
<td>
<p>number of burnin samples that are discarded. Can be chosen to be
small if the maxmimum-a-posteriori estimate is used as the (default) starting value.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_cpu">cpu</code></td>
<td>
<p>either the number of CPUs using separate MCMC chains in parallel,
or a parallel cluster (e.g., <code>cl &lt;- parallel::makeCluster(3)</code>).
All arguments of the function call are passed directly to each core,
and thus the total number of samples is <code>M*number_cpu</code>.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_n">n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td></tr>
<tr><td><code id="sampling_multinom_+3A_map">map</code></td>
<td>
<p>optional: numeric vector of the same length as <code>k</code> with integers
mapping the frequencies <code>k</code> to the free parameters/columns of <code>A</code>/<code>V</code>,
thereby allowing for equality constraints (e.g., <code>map=c(1,1,2,2)</code>).
Reversed probabilities <code>1-p</code> are coded by negative integers.
Guessing probabilities of .50 are encoded by zeros. The default assumes
different parameters for each item type: <code>map=1:ncol(A)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Draws posterior samples for binomial/multinomial random utility models that
assume a mixture over predefined preference orders/vertices that jointly define
a convex polytope via the set of inequalities <code>A * x &lt; b</code> or as the
convex hull of a set of vertices <code>V</code>.
</p>


<h3>Value</h3>

<p>an <code>mcmc</code> matrix (or an <code>mcmc.list</code> if <code>cpu&gt;1</code>) with
posterior samples of the binomial/multinomial probability parameters.
See <code><a href="coda.html#topic+mcmc">mcmc</a></code>) .
</p>


<h3>References</h3>

<p>Myung, J. I., Karabatsos, G., &amp; Iverson, G. J. (2005). A Bayesian approach to testing decision making axioms. <em>Journal of Mathematical Psychology, 49</em>, 205-225. <a href="https://doi.org/10.1016/j.jmp.2005.02.004">doi:10.1016/j.jmp.2005.02.004</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+count_multinom">count_multinom</a></code>, <code><a href="#topic+ml_multinom">ml_multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>############### binomial ##########################
A &lt;- matrix(
  c(
    1, 0, 0, # x1 &lt; .50
    1, 1, 1, # x1+x2+x3 &lt; 1
    0, 2, 2, # 2*x2+2*x3 &lt; 1
    0, -1, 0, # x2 &gt; .2
    0, 0, 1
  ), # x3 &lt; .1
  ncol = 3, byrow = TRUE
)
b &lt;- c(.5, 1, 1, -.2, .1)
samp &lt;- sampling_binom(c(5, 12, 7), c(20, 20, 20), A, b)
head(samp)
plot(samp)


############### multinomial ##########################
# binary and ternary choice:
#           (a1,a2   b1,b2,b3)
k &lt;- c(15, 9, 5, 2, 17)
options &lt;- c(2, 3)

# columns:   (a1,  b1,b2)
A &lt;- matrix(
  c(
    1, 0, 0, # a1 &lt; .20
    0, 2, 1, # 2*b1+b2 &lt; 1
    0, -1, 0, # b1 &gt; .2
    0, 0, 1
  ), # b2 &lt; .4
  ncol = 3, byrow = TRUE
)
b &lt;- c(.2, 1, -.2, .4)
samp &lt;- sampling_multinom(k, options, A, b)
head(samp)
plot(samp)
</code></pre>

<hr>
<h2 id='sampling_nonlinear'>Posterior Sampling for Multinomial Models with Nonlinear Inequalities</h2><span id='topic+sampling_nonlinear'></span>

<h3>Description</h3>

<p>A Gibbs sampler that draws posterior samples of probability parameters
conditional on a (possibly nonlinear) indicator function defining a
restricted parameter space that is convex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampling_nonlinear(
  k,
  options,
  inside,
  prior = rep(1, sum(options)),
  M = 1000,
  start,
  burnin = 10,
  eps = 1e-06,
  progress = TRUE,
  cpu = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampling_nonlinear_+3A_k">k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_options">options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_inside">inside</code></td>
<td>
<p>an indicator function that takes a vector with probabilities
<code>p=c(p11,p12,  p21,p22,...)</code> (where the last probability for each
multinomial is dropped) as input and returns <code>1</code> or <code>TRUE</code>
if the order constraints are satisfied and <code>0</code> or <code>FALSE</code> otherwise
(see details).</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_prior">prior</code></td>
<td>
<p>a vector with two positive numbers defining the shape parameters
of the beta prior distributions for each binomial rate parameter.</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_m">M</code></td>
<td>
<p>number of posterior samples drawn from the encompassing model</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_start">start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_burnin">burnin</code></td>
<td>
<p>number of burnin samples that are discarded. Can be chosen to be
small if the maxmimum-a-posteriori estimate is used as the (default) starting value.</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_eps">eps</code></td>
<td>
<p>precision of the bisection algorithm</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_progress">progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td></tr>
<tr><td><code id="sampling_nonlinear_+3A_cpu">cpu</code></td>
<td>
<p>either the number of CPUs used for parallel sampling, or a parallel
cluster  (e.g., <code>cl &lt;- parallel::makeCluster(3)</code>).
All arguments of the function call are passed directly to each core,
and thus the total number of samples is <code>M*number_cpu</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inequality constraints are defined via an indicator function <code>inside</code>
which returns <code>inside(x)=1</code> (or <code>0</code>) if the vector of free parameters
<code>x</code> is inside (or outside) the model space. Since the vector <code>x</code>
must include only free (!) parameters, the last probability for each
multinomial must not be used in the function <code>inside(x)</code>!
</p>
<p>Efficiency can be improved greatly if the indicator function is defined as C++
code via the function <a href="RcppXPtrUtils.html#topic+cppXPtr">cppXPtr</a> in the package RcppXPtrUtils
(see below for examples). In this case, please keep in mind that indexing in C++
starts with 0,1,2... (not with 1,2,3,... as in R)!
</p>
<p>For each parameter, the Gibbs sampler draws a sample from the
conditional posterior distribution (a scaled, truncated beta).
The conditional truncation boundaries are computed with a bisection algorithm.
This requires that the restricted parameteter space defined by the indicator
function is convex.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># two binomial success probabilities: x = c(x1, x2)
# restriction to a circle:
model &lt;- function(x) {
  (x[1] - .50)^2 + (x[2] - .50)^2 &lt;= .15
}

# draw prior samples
mcmc &lt;- sampling_nonlinear(
  k = 0, options = c(2, 2),
  inside = model, M = 1000
)
head(mcmc)
plot(c(mcmc[, 1]), c(mcmc[, 2]), xlim = 0:1, ylim = 0:1)


##### Using a C++ indicator function (much faster)
cpp_code &lt;- "SEXP inside(NumericVector x){
  return wrap( sum(pow(x-.50, 2)) &lt;= .15);}"
# NOTE: Uses Rcpp sugar syntax (vectorized sum &amp; pow)

# define function via C++ pointer:
model_cpp &lt;- RcppXPtrUtils::cppXPtr(cpp_code)
mcmc &lt;- sampling_nonlinear(
  k = 0, options = c(2, 2),
  inside = model_cpp
)
head(mcmc)
plot(c(mcmc[, 1]), c(mcmc[, 2]), xlim = 0:1, ylim = 0:1)

</code></pre>

<hr>
<h2 id='stochdom_Ab'>Ab-Representation for Stochastic Dominance of Histogram Bins</h2><span id='topic+stochdom_Ab'></span>

<h3>Description</h3>

<p>Provides the necessary linear equality constraints to test stochastic dominance
of continuous distributions, that is, whether the cumulative density functions
<code class="reqn">F</code> satisfy the constraint <code class="reqn">F_1(t) &lt; F_2(t)</code> for all <code class="reqn">t</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stochdom_Ab(bins, conditions = 2, order = "&lt;")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stochdom_Ab_+3A_bins">bins</code></td>
<td>
<p>number of bins of histogram</p>
</td></tr>
<tr><td><code id="stochdom_Ab_+3A_conditions">conditions</code></td>
<td>
<p>number of conditions</p>
</td></tr>
<tr><td><code id="stochdom_Ab_+3A_order">order</code></td>
<td>
<p>order constraint on the random variables across conditions.
The default <code>order="&lt;"</code> implies that the random variables increase across
conditions (implying that the cdfs decrease: <code class="reqn">F_1(t) &gt; F_2(t)</code>).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Heathcote, A., Brown, S., Wagenmakers, E. J., &amp; Eidels, A. (2010). Distribution-free tests of stochastic dominance for small samples. Journal of Mathematical Psychology, 54(5), 454-463. <a href="https://doi.org/10.1016/j.jmp.2010.06.005">doi:10.1016/j.jmp.2010.06.005</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stochdom_bf">stochdom_bf</a></code> to obtain a Bayes factor directly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stochdom_Ab(4, 2)
stochdom_Ab(4, 3)
</code></pre>

<hr>
<h2 id='stochdom_bf'>Bayes Factor for Stochastic Dominance of Continuous Distributions</h2><span id='topic+stochdom_bf'></span>

<h3>Description</h3>

<p>Uses discrete bins (as in a histogram) to compute the Bayes factor in favor
of stochastic dominance of continuous distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stochdom_bf(x1, x2, breaks = "Sturges", order = "&lt;", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stochdom_bf_+3A_x1">x1</code></td>
<td>
<p>a vector with samples from the first random variable/experimental condition.</p>
</td></tr>
<tr><td><code id="stochdom_bf_+3A_x2">x2</code></td>
<td>
<p>a vector with samples from the second random variable/experimental condition.</p>
</td></tr>
<tr><td><code id="stochdom_bf_+3A_breaks">breaks</code></td>
<td>
<p>number of bins of histogram. See <code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="stochdom_bf_+3A_order">order</code></td>
<td>
<p>order constraint on the random variables across conditions.
The default <code>order="&lt;"</code> implies that the random variables increase across
conditions (implying that the cdfs decrease: <code class="reqn">F_1(t) &gt; F_2(t)</code>).</p>
</td></tr>
<tr><td><code id="stochdom_bf_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+bf_multinom">bf_multinom</a></code>. Note that the
noninformative default prior <code>1/number_of_bins</code> is used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Heathcote, A., Brown, S., Wagenmakers, E. J., &amp; Eidels, A. (2010). Distribution-free tests of stochastic dominance for small samples. Journal of Mathematical Psychology, 54(5), 454-463. <a href="https://doi.org/10.1016/j.jmp.2010.06.005">doi:10.1016/j.jmp.2010.06.005</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(300, 0, 1)
x2 &lt;- rnorm(300, .5, 1) # dominates x1
x3 &lt;- rnorm(300, 0, 1.2) # intersects x1

plot(ecdf(x1))
lines(ecdf(x2), col = "red")
lines(ecdf(x3), col = "blue")

b12 &lt;- stochdom_bf(x1, x2, order = "&lt;", M = 5e4)
b13 &lt;- stochdom_bf(x1, x3, order = "&lt;", M = 5e4)
b12$bf
b13$bf
</code></pre>

<hr>
<h2 id='strategy_marginal'>Log-Marginal Likelihood for Decision Strategy</h2><span id='topic+strategy_marginal'></span>

<h3>Description</h3>

<p>Computes the logarithm of the marginal likelihood, defined as the integral
over the likelihood function weighted by the prior distribution of the error probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_marginal(k, n, strategy)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strategy_marginal_+3A_k">k</code></td>
<td>
<p>observed frequencies of Option B.
Either a vector or a matrix/data frame (one person per row).</p>
</td></tr>
<tr><td><code id="strategy_marginal_+3A_n">n</code></td>
<td>
<p>vector with the number of choices per item type.</p>
</td></tr>
<tr><td><code id="strategy_marginal_+3A_strategy">strategy</code></td>
<td>
<p>a list that defines the predictions of a strategy, see<code><a href="#topic+strategy_multiattribute">strategy_multiattribute</a></code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- c(1, 11, 18)
n &lt;- c(20, 20, 20)
# pattern: A, A, B with constant error e&lt;.50
strat &lt;- list(
  pattern = c(-1, -1, 1),
  c = .5, ordered = FALSE,
  prior = c(1, 1)
)
m1 &lt;- strategy_marginal(k, n, strat)
m1

# pattern: A, B, B with ordered error e1&lt;e3&lt;e2&lt;.50
strat2 &lt;- list(
  pattern = c(-1, 3, 2),
  c = .5, ordered = TRUE,
  prior = c(1, 1)
)
m2 &lt;- strategy_marginal(k, n, strat2)
m2

# Bayes factor: Model 2 vs. Model 1
exp(m2 - m1)
</code></pre>

<hr>
<h2 id='strategy_multiattribute'>Strategy Predictions for Multiattribute Decisions</h2><span id='topic+strategy_multiattribute'></span>

<h3>Description</h3>

<p>Returns a list defining the predictions of different choice strategies (e.g., TTB, WADD)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_multiattribute(cueA, cueB, v, strategy, c = 0.5, prior = c(1, 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strategy_multiattribute_+3A_cuea">cueA</code></td>
<td>
<p>cue values of Option A (-1/+1 = negative/positive; 0 = missing).
If a matrix is provided, each row defines one item type.</p>
</td></tr>
<tr><td><code id="strategy_multiattribute_+3A_cueb">cueB</code></td>
<td>
<p>cue values of Option B (see <code>cueA</code>).</p>
</td></tr>
<tr><td><code id="strategy_multiattribute_+3A_v">v</code></td>
<td>
<p>cue validities: probabilities that cues lead to correct decision.
Must be of the same length as the number of cues.</p>
</td></tr>
<tr><td><code id="strategy_multiattribute_+3A_strategy">strategy</code></td>
<td>
<p>strategy label, e.g., <code>"TTB"</code>, <code>"WADD"</code>, or <code>"WADDprob"</code>.
Can be a vector. See details.</p>
</td></tr>
<tr><td><code id="strategy_multiattribute_+3A_c">c</code></td>
<td>
<p>defines the upper boundary for the error probabilities</p>
</td></tr>
<tr><td><code id="strategy_multiattribute_+3A_prior">prior</code></td>
<td>
<p>defines the prior distribution for the error probabilities
(i.e., truncated independent beta distributions <code>dbeta(prior[1], prior[2])</code> )</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>strategy</code> object (a list) with the entries:
</p>

<dl>
<dt><code>pattern</code>: </dt><dd><p>a numeric vector encoding the predicted choice pattern by the sign
(negative = Option A, positive = Option B, 0 = guessing).
Identical error probabilities are encoded by using the same absolute number
(e.g., <code>c(-1,1,1)</code> defines one error probability with A,B,B predictions).</p>
</dd>
<dt><code>c</code>: </dt><dd><p>upper boundary of error probabilities</p>
</dd>
<dt><code>ordered</code>: </dt><dd><p>whether error probabilities are linearly ordered by their absolute value in <code>pattern</code> (largest error: smallest absolute number)</p>
</dd>
<dt><code>prior</code>: </dt><dd><p>a numeric vector with two positive values specifying the shape parameters of the beta prior distribution (truncated to the interval <code>[0,c]</code></p>
</dd>
<dt><code>label</code>: </dt><dd><p>strategy label</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># single item type
v &lt;- c(.9, .8, .7, .6)
ca &lt;- c(1, -1, -1, 1)
cb &lt;- c(-1, 1, -1, -1)
strategy_multiattribute(ca, cb, v, "TTB")
strategy_multiattribute(ca, cb, v, "WADDprob")

# multiple item types
data(heck2017_raw)
strategy_multiattribute(
  heck2017_raw[1:10, c("a1", "a2", "a3", "a4")],
  heck2017_raw[1:10, c("b1", "b2", "b3", "b4")],
  v, "WADDprob"
)
</code></pre>

<hr>
<h2 id='strategy_postprob'>Strategy Classification: Posterior Model Probabilities</h2><span id='topic+strategy_postprob'></span>

<h3>Description</h3>

<p>Posterior model probabilities for multiple strategies (with equal prior model probabilities).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_postprob(k, n, strategies, cpu = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strategy_postprob_+3A_k">k</code></td>
<td>
<p>observed frequencies of Option B.
Either a vector or a matrix/data frame (one person per row).</p>
</td></tr>
<tr><td><code id="strategy_postprob_+3A_n">n</code></td>
<td>
<p>vector with the number of choices per item type.</p>
</td></tr>
<tr><td><code id="strategy_postprob_+3A_strategies">strategies</code></td>
<td>
<p>list of strategies. See <a href="#topic+strategy_multiattribute">strategy_multiattribute</a></p>
</td></tr>
<tr><td><code id="strategy_postprob_+3A_cpu">cpu</code></td>
<td>
<p>number of processing units for parallel computation.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+strategy_marginal">strategy_marginal</a></code> and <code><a href="#topic+model_weights">model_weights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># pattern 1: A, A, B with constant error e&lt;.50
strat1 &lt;- list(
  pattern = c(-1, -1, 1),
  c = .5, ordered = FALSE,
  prior = c(1, 1)
)
# pattern 2: A, B, B with ordered error e1&lt;e3&lt;e2&lt;.50
strat2 &lt;- list(
  pattern = c(-1, 3, 2),
  c = .5, ordered = TRUE,
  prior = c(1, 1)
)
baseline &lt;- list(
  pattern = 1:3, c = 1, ordered = FALSE,
  prior = c(1, 1)
)

# data
k &lt;- c(3, 4, 12) # frequencies Option B
n &lt;- c(20, 20, 20) # number of choices
strategy_postprob(k, n, list(strat1, strat2, baseline))
</code></pre>

<hr>
<h2 id='strategy_to_Ab'>Transform Pattern of Predictions to Polytope</h2><span id='topic+strategy_to_Ab'></span>

<h3>Description</h3>

<p>Transforms ordered item-type predictions to polytope definition.
This allows to use Monte-Carlo methods to compute the Bayes factor
if the number of item types is large (<code><a href="#topic+bf_binom">bf_binom</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_to_Ab(strategy)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strategy_to_Ab_+3A_strategy">strategy</code></td>
<td>
<p>a decision strategy returned by <code><a href="#topic+strategy_multiattribute">strategy_multiattribute</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: Only works for models without guessing predictions and
without equality constraints (i.e., requires separate error probabilities per item type)
</p>


<h3>Value</h3>

<p>a list containing the matrix <code>A</code> and the vector <code>b</code>
that define a polytope via <code>A*x &lt;= b</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># strategy:  A,B,B,A   e2&lt;e3&lt;e4&lt;e1&lt;.50
strat &lt;- list(
  pattern = c(-1, 4, 3, -2),
  c = .5, ordered = TRUE,
  prior = c(1, 1)
)
pt &lt;- strategy_to_Ab(strat)
pt

# compare results to encompassing BF method:
b &lt;- list(
  pattern = 1:4, c = 1,
  ordered = FALSE, prior = c(1, 1)
)
k &lt;- c(2, 20, 18, 0)
n &lt;- rep(20, 4)
m1 &lt;- strategy_postprob(k, n, list(strat, b))
log(m1[1] / m1[2])
bf_binom(k, n, pt$A, pt$b, log = TRUE)
</code></pre>

<hr>
<h2 id='strategy_unique'>Unique Patterns/Item Types of Strategy Predictions</h2><span id='topic+strategy_unique'></span>

<h3>Description</h3>

<p>Find unique item types, which are defined as patterns of cue values
that lead to identical strategy predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_unique(strategies, add_baseline = TRUE, reversed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strategy_unique_+3A_strategies">strategies</code></td>
<td>
<p>a list of strategy predictions with the same length of
the vector <code>pattern</code>, see <a href="#topic+strategy_multiattribute">strategy_multiattribute</a>.</p>
</td></tr>
<tr><td><code id="strategy_unique_+3A_add_baseline">add_baseline</code></td>
<td>
<p>whether to add a baseline model which assumes one probability in [0,1] for each item type.</p>
</td></tr>
<tr><td><code id="strategy_unique_+3A_reversed">reversed</code></td>
<td>
<p>whether reversed patterns are treated separately
(default: automatically switch Option A and B if <code>pattern=c(-1,1,1,1)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including:
</p>

<ul>
<li> <p><code>unique</code>: a matrix with the unique strategy patterns
</p>
</li>
<li> <p><code>item_type</code>: a vector that maps the original predictions to item types (negative: reversed items)
</p>
</li>
<li> <p><code>strategies</code>: a list with strategy predictions with <code>pattern</code> adapted to the unique item types
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(heck2017_raw)
ca &lt;- heck2017_raw[1:100, c("a1", "a2", "a3", "a4")]
cb &lt;- heck2017_raw[1:100, c("b1", "b2", "b3", "b4")]
v &lt;- c(.9, .8, .7, .6)
strats &lt;- strategy_multiattribute(
  ca, cb, v,
  c("WADDprob", "WADD", "TTB")
)
strategy_unique(strats)
</code></pre>

<hr>
<h2 id='swop5'>Strict Weak Order Polytope for 5 Elements and Ternary Choices</h2><span id='topic+swop5'></span>

<h3>Description</h3>

<p>Facet-defining inequalities of the strict weak order mixture model
for all 10 paired comparisons of 5 choice elements {a,b,c,d,e} in a
3-alternative forced-choice task (Regenwetter &amp; Davis-Stober, 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>swop5
</code></pre>


<h3>Format</h3>

<p>A list with 3 elements:
</p>

<dl>
<dt><code>A</code>: </dt><dd><p>Matrix with inequality constraints that define a polytope via <code>A*x &lt;= b</code>.</p>
</dd>
<dt><code>b</code>: </dt><dd><p>vector with upper bounds for the inequalities.</p>
</dd>
<dt><code>start</code>: </dt><dd><p>A point in the polytope.</p>
</dd>
<dt><code>options</code>: </dt><dd><p>A vector with the number of options (=3) per item type.</p>
</dd>
</dl>



<h3>References</h3>

<p>Regenwetter, M., &amp; Davis-Stober, C. P. (2012). Behavioral variability of choices versus structural inconsistency of preferences. Psychological Review, 119(2), 408-416. <a href="https://doi.org/10.1037/a0027372">doi:10.1037/a0027372</a>
</p>


<h3>See Also</h3>

<p>The corresponding data set <code><a href="#topic+regenwetter2012">regenwetter2012</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(swop5)
tail(swop5$A) # A*x &lt;= b
tail(swop5$b)
swop5$start # inside SWOP polytope
swop5$options # 3 choice options per item

# check whether point is in polytope:
inside(swop5$start, swop5$A, swop5$b)


# get prior samples:
p &lt;- sampling_multinom(0, swop5$options,
  swop5$A, swop5$b,
  M = 100, start = swop5$start
)
colMeans(p)
apply(p[, 1:5], 2, plot, type = "l")

</code></pre>

<hr>
<h2 id='V_to_Ab'>Transform Vertex/Inequality Representation of Polytope</h2><span id='topic+V_to_Ab'></span><span id='topic+Ab_to_V'></span>

<h3>Description</h3>

<p>For convex polytopes: Requires <code>rPorta</code> (<a href="https://github.com/TasCL/rPorta">https://github.com/TasCL/rPorta</a>)
to transform the vertex representation to/from the inequality representation.
Since <code>rPorta</code> cannot be compiled with R versions &gt;=4.0.0 anymore,
the function is currently deprecated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V_to_Ab(V)

Ab_to_V(A, b, options = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="V_to_Ab_+3A_v">V</code></td>
<td>
<p>a matrix with one vertex of a polytope per row
(e.g., the admissible preference orders of a random utility model or any other theory).
Since the values have to sum up to one within each multinomial condition,
the last value of each multinomial is omitted
(e.g., the prediction 1-0-0/0-1 for a tri and binomial becomes 1-0/0).</p>
</td></tr>
<tr><td><code id="V_to_Ab_+3A_a">A</code></td>
<td>
<p>a matrix defining the convex polytope via <code>A*x &lt;= b</code>.
The columns of <code>A</code> do not include the last choice option per item type and
thus the number of columns must be equal to <code>sum(options-1)</code>
(e.g., the column order of <code>A</code> for <code>k = c(a1,a2,a2, b1,b2)</code>
is <code>c(a1,a2, b1)</code>).</p>
</td></tr>
<tr><td><code id="V_to_Ab_+3A_b">b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td></tr>
<tr><td><code id="V_to_Ab_+3A_options">options</code></td>
<td>
<p>number of choice options per item type.
Can be a vector <code>options=c(2,3,4)</code> if item types have 2/3/4 choice options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Choice models can be represented as polytopes if they assume a latent
mixture over a finite number preference patterns (random preference model).
For the general approach and theory underlying binary and ternary choice models,
see Regenwetter et al. (2012, 2014, 2017).
</p>
<p>The function is currently deprecated since the package <code>rPorta</code> cannot be compiled with R&gt;=4.0.0!
</p>
<p>For binary choices (<code>options=2</code>), additional constraints are added to <code>A</code> and <code>b</code>
to ensure that all dimensions of the polytope satisfy:  0 &lt;= p_i &lt;= 1.
For ternary choices (<code>options=3</code>), constraints are added to ensure that 0 &lt;= p_1+p_2 &lt;=1
for pairwise columns (1+2, 3+4, 5+6, ...). See <code><a href="#topic+Ab_multinom">Ab_multinom</a></code>.
</p>


<h3>References</h3>

<p>Regenwetter, M., &amp; Davis-Stober, C. P. (2012). Behavioral variability of choices versus structural inconsistency of preferences. Psychological Review, 119(2), 408-416. <a href="https://doi.org/10.1037/a0027372">doi:10.1037/a0027372</a>
</p>
<p>Regenwetter, M., Davis-Stober, C. P., Lim, S. H., Guo, Y., Popova, A., Zwilling, C., … Messner, W. (2014). QTest: Quantitative testing of theories of binary choice. Decision, 1(1), 2-34. <a href="https://doi.org/10.1037/dec0000007">doi:10.1037/dec0000007</a>
</p>
<p>Regenwetter, M., &amp; Robinson, M. M. (2017). The construct–behavior gap in behavioral decision research: A challenge beyond replicability. Psychological Review, 124(5), 533-550. https://doi.org/10.1037/rev0000067
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
