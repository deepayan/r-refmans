<!DOCTYPE html><html><head><title>Help for package mclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mclust-package'><p>Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation</p></a></li>
<li><a href='#acidity'><p>Acidity data</p></a></li>
<li><a href='#adjustedRandIndex'>
<p>Adjusted Rand Index</p></a></li>
<li><a href='#banknote'><p>Swiss banknotes data</p></a></li>
<li><a href='#Baudry_etal_2010_JCGS_examples'><p>Simulated Example Datasets From Baudry et al. (2010)</p></a></li>
<li><a href='#bic'>
<p>BIC for Parameterized Gaussian Mixture Models</p></a></li>
<li><a href='#BrierScore'><p>Brier score to assess the accuracy of probabilistic predictions</p></a></li>
<li><a href='#cdens'>
<p>Component Density for Parameterized MVN Mixture Models</p></a></li>
<li><a href='#cdensE'>
<p>Component Density for a Parameterized MVN Mixture Model</p></a></li>
<li><a href='#cdfMclust'>
<p>Cumulative Distribution and Quantiles for a univariate Gaussian mixture</p>
distribution</a></li>
<li><a href='#chevron'><p>Simulated minefield data</p></a></li>
<li><a href='#classError'><p>Classification error</p></a></li>
<li><a href='#classPriorProbs'><p>Estimation of class prior probabilities by EM algorithm</p></a></li>
<li><a href='#clPairs'><p>Pairwise Scatter Plots showing Classification</p></a></li>
<li><a href='#clustCombi'>
<p>Combining Gaussian Mixture Components for Clustering</p></a></li>
<li><a href='#clustCombi-internal'><p>Internal clustCombi functions</p></a></li>
<li><a href='#clustCombiOptim'><p>Optimal number of clusters obtained by combining mixture components</p></a></li>
<li><a href='#combiPlot'>
<p>Plot Classifications Corresponding to Successive Combined Solutions</p></a></li>
<li><a href='#combiTree'><p>Tree structure obtained from combining mixture components</p></a></li>
<li><a href='#combMat'>
<p>Combining Matrix</p></a></li>
<li><a href='#coordProj'>
<p>Coordinate projections of multidimensional data modeled by an MVN mixture.</p></a></li>
<li><a href='#covw'><p>Weighted means, covariance and scattering matrices conditioning on a weighted matrix</p></a></li>
<li><a href='#crimcoords'><p>Discriminant coordinates data projection</p></a></li>
<li><a href='#cross'><p>Simulated Cross Data</p></a></li>
<li><a href='#cvMclustDA'><p>MclustDA cross-validation</p></a></li>
<li><a href='#decomp2sigma'>
<p>Convert mixture component covariances to matrix form</p></a></li>
<li><a href='#defaultPrior'>
<p>Default conjugate prior for Gaussian mixtures</p></a></li>
<li><a href='#dens'>
<p>Density for Parameterized MVN Mixtures</p></a></li>
<li><a href='#densityMclust'><p>Density Estimation via Model-Based Clustering</p></a></li>
<li><a href='#densityMclust.diagnostic'><p>Diagnostic plots for <code>mclustDensity</code> estimation</p></a></li>
<li><a href='#diabetes'><p>Diabetes Data (flawed)</p></a></li>
<li><a href='#dmvnorm'><p>Density of multivariate Gaussian distribution</p></a></li>
<li><a href='#dupPartition'><p>Partition the data by grouping together duplicated data</p></a></li>
<li><a href='#em'><p>EM algorithm starting with E-step for parameterized Gaussian mixture models</p></a></li>
<li><a href='#emControl'><p>Set control values for use with the EM algorithm</p></a></li>
<li><a href='#emE'><p>EM algorithm starting with E-step for a parameterized Gaussian mixture model</p></a></li>
<li><a href='#entPlot'>
<p>Plot Entropy Plots</p></a></li>
<li><a href='#errorBars'><p>Draw error bars on a plot</p></a></li>
<li><a href='#estep'>
<p>E-step for parameterized Gaussian mixture models.</p></a></li>
<li><a href='#estepE'>
<p>E-step in the EM algorithm for a parameterized Gaussian mixture model.</p></a></li>
<li><a href='#EuroUnemployment'><p>Unemployment data for European countries in 2014</p></a></li>
<li><a href='#gmmhd'><p>Identifying Connected Components in Gaussian Finite Mixture Models for Clustering</p></a></li>
<li><a href='#GvHD'><p>GvHD Dataset</p></a></li>
<li><a href='#hc'><p>Model-based Agglomerative Hierarchical Clustering</p></a></li>
<li><a href='#hcE'><p>Model-based Hierarchical Clustering</p></a></li>
<li><a href='#hclass'>
<p>Classifications from Hierarchical Agglomeration</p></a></li>
<li><a href='#hcRandomPairs'><p>Random hierarchical structure</p></a></li>
<li><a href='#hdrlevels'><p>Highest Density Region (HDR) Levels</p></a></li>
<li><a href='#hypvol'>
<p>Aproximate Hypervolume for Multivariate Data</p></a></li>
<li><a href='#icl'>
<p>ICL for an estimated Gaussian Mixture Model</p></a></li>
<li><a href='#imputeData'><p>Missing data imputation via the <span class="pkg">mix</span> package</p></a></li>
<li><a href='#imputePairs'>
<p>Pairwise Scatter Plots showing Missing Data Imputations</p></a></li>
<li><a href='#logLik.Mclust'><p>Log-Likelihood of a <code>Mclust</code> object</p></a></li>
<li><a href='#logLik.MclustDA'><p>Log-Likelihood of a <code>MclustDA</code> object</p></a></li>
<li><a href='#logsumexp'><p>Log sum of exponentials</p></a></li>
<li><a href='#majorityVote'><p>Majority vote</p></a></li>
<li><a href='#map'><p>Classification given Probabilities</p></a></li>
<li><a href='#mapClass'><p>Correspondence between classifications</p></a></li>
<li><a href='#Mclust'><p>Model-Based Clustering</p></a></li>
<li><a href='#mclust-deprecated'><p>Deprecated Functions in mclust package</p></a></li>
<li><a href='#mclust-internal'><p>Internal MCLUST functions</p></a></li>
<li><a href='#mclust.options'><p>Default values for use with MCLUST package</p></a></li>
<li><a href='#mclust1Dplot'>
<p>Plot one-dimensional data modeled by an MVN mixture.</p></a></li>
<li><a href='#mclust2Dplot'><p>Plot two-dimensional data modelled by an MVN mixture</p></a></li>
<li><a href='#mclustBIC'><p>BIC for Model-Based Clustering</p></a></li>
<li><a href='#mclustBICupdate'><p>Update BIC values for parameterized Gaussian mixture models</p></a></li>
<li><a href='#MclustBootstrap'><p>Resampling-based Inference for Gaussian finite mixture models</p></a></li>
<li><a href='#mclustBootstrapLRT'><p>Bootstrap Likelihood Ratio Test for the Number of Mixture Components</p></a></li>
<li><a href='#MclustDA'><p>MclustDA discriminant analysis</p></a></li>
<li><a href='#MclustDR'><p>Dimension reduction for model-based clustering and classification</p></a></li>
<li><a href='#MclustDRsubsel'><p>Subset selection for GMMDR directions based on BIC</p></a></li>
<li><a href='#mclustICL'><p>ICL Criterion for Model-Based Clustering</p></a></li>
<li><a href='#mclustLoglik'><p>Log-likelihood from a table of BIC values for parameterized Gaussian mixture models</p></a></li>
<li><a href='#mclustModel'>
<p>Best model based on BIC</p></a></li>
<li><a href='#mclustModelNames'>
<p>MCLUST Model Names</p></a></li>
<li><a href='#MclustSSC'><p>MclustSSC semi-supervised classification</p></a></li>
<li><a href='#mclustVariance'>
<p>Template for variance specification for parameterized Gaussian mixture models</p></a></li>
<li><a href='#me'><p>EM algorithm starting with M-step for parameterized MVN mixture models</p></a></li>
<li><a href='#me.weighted'><p>EM algorithm with weights starting with M-step for parameterized Gaussian mixture models</p></a></li>
<li><a href='#meE'><p>EM algorithm starting with M-step for a parameterized Gaussian mixture model</p></a></li>
<li><a href='#mstep'><p>M-step for parameterized Gaussian mixture models</p></a></li>
<li><a href='#mstepE'><p>M-step for a parameterized Gaussian mixture model</p></a></li>
<li><a href='#mvn'>
<p>Univariate or Multivariate Normal Fit</p></a></li>
<li><a href='#mvnX'>
<p>Univariate or Multivariate Normal Fit</p></a></li>
<li><a href='#nMclustParams'><p>Number of Estimated Parameters in Gaussian Mixture Models</p></a></li>
<li><a href='#nVarParams'>
<p>Number of Variance Parameters in Gaussian Mixture Models</p></a></li>
<li><a href='#partconv'><p>Numeric Encoding of a Partitioning</p></a></li>
<li><a href='#partuniq'>
<p>Classifies Data According to Unique Observations</p></a></li>
<li><a href='#plot.clustCombi'>
<p>Plot Combined Clusterings Results</p></a></li>
<li><a href='#plot.densityMclust'><p>Plots for Mixture-Based Density Estimate</p></a></li>
<li><a href='#plot.hc'><p>Dendrograms for Model-based Agglomerative Hierarchical Clustering</p></a></li>
<li><a href='#plot.Mclust'><p>Plotting method for Mclust model-based clustering</p></a></li>
<li><a href='#plot.mclustBIC'><p>BIC Plot for Model-Based Clustering</p></a></li>
<li><a href='#plot.MclustBootstrap'><p>Plot of bootstrap distributions for mixture model parameters</p></a></li>
<li><a href='#plot.MclustDA'><p>Plotting method for MclustDA discriminant analysis</p></a></li>
<li><a href='#plot.MclustDR'><p>Plotting method for dimension reduction for model-based clustering and classification</p></a></li>
<li><a href='#plot.mclustICL'><p>ICL Plot for Model-Based Clustering</p></a></li>
<li><a href='#plot.MclustSSC'><p>Plotting method for MclustSSC semi-supervised classification</p></a></li>
<li><a href='#predict.densityMclust'><p>Density estimate of multivariate observations by Gaussian finite mixture modeling</p></a></li>
<li><a href='#predict.Mclust'><p>Cluster multivariate observations by Gaussian finite mixture modeling</p></a></li>
<li><a href='#predict.MclustDA'><p>Classify multivariate observations by Gaussian finite mixture modeling</p></a></li>
<li><a href='#predict.MclustDR'><p>Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling</p></a></li>
<li><a href='#predict.MclustSSC'><p>Classification of multivariate observations by semi-supervised Gaussian finite mixtures</p></a></li>
<li><a href='#priorControl'>
<p>Conjugate Prior for Gaussian Mixtures.</p></a></li>
<li><a href='#randomOrthogonalMatrix'><p>Random orthogonal matrix</p></a></li>
<li><a href='#randProj'><p>Random projections of multidimensional data modeled by an MVN mixture</p></a></li>
<li><a href='#sigma2decomp'>
<p>Convert mixture component covariances to decomposition form.</p></a></li>
<li><a href='#sim'>
<p>Simulate from Parameterized MVN Mixture Models</p></a></li>
<li><a href='#simE'>
<p>Simulate from a Parameterized MVN Mixture Model</p></a></li>
<li><a href='#softmax'><p>Softmax function</p></a></li>
<li><a href='#summary.Mclust'><p>Summarizing Gaussian Finite Mixture Model Fits</p></a></li>
<li><a href='#summary.mclustBIC'><p>Summary function for model-based clustering via BIC</p></a></li>
<li><a href='#summary.MclustBootstrap'><p>Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models</p></a></li>
<li><a href='#summary.MclustDA'><p>Summarizing discriminant analysis based on Gaussian finite mixture modeling</p></a></li>
<li><a href='#summary.MclustDR'><p>Summarizing dimension reduction method for model-based clustering and classification</p></a></li>
<li><a href='#summary.MclustSSC'><p>Summarizing semi-supervised classification model based on Gaussian finite mixtures</p></a></li>
<li><a href='#surfacePlot'><p>Density or uncertainty surface for bivariate mixtures</p></a></li>
<li><a href='#thyroid'><p>UCI Thyroid Gland Data</p></a></li>
<li><a href='#uncerPlot'>
<p>Uncertainty Plot for Model-Based Clustering</p></a></li>
<li><a href='#unmap'>
<p>Indicator Variables given Classification</p></a></li>
<li><a href='#wdbc'><p>UCI Wisconsin Diagnostic Breast Cancer Data</p></a></li>
<li><a href='#wreath'><p>Data Simulated from a 14-Component Mixture</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>6.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-23</td>
</tr>
<tr>
<td>Title:</td>
<td>Gaussian Mixture Modelling for Model-Based Clustering,
Classification, and Density Estimation</td>
</tr>
<tr>
<td>Description:</td>
<td>Gaussian finite mixture models fitted via EM algorithm for
  model-based clustering, classification, and density estimation, 
  including Bayesian regularization, dimension reduction for 
  visualisation, and resampling-based inference.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, graphics, grDevices</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr (&ge; 1.4), rmarkdown (&ge; 2.10), mix (&ge; 1.0), geometry
(&ge; 0.4), MASS</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://mclust-org.github.io/mclust/">https://mclust-org.github.io/mclust/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-23 06:38:52 UTC; luca</td>
</tr>
<tr>
<td>Author:</td>
<td>Chris Fraley [aut],
  Adrian E. Raftery <a href="https://orcid.org/0000-0002-6589-301X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Luca Scrucca <a href="https://orcid.org/0000-0003-3826-0484"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Thomas Brendan Murphy
    <a href="https://orcid.org/0000-0002-5668-7046"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Michael Fop <a href="https://orcid.org/0000-0003-3936-2757"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Luca Scrucca &lt;luca.scrucca@unipg.it&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-23 09:50:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='mclust-package'>Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation</h2><span id='topic+mclust-package'></span><span id='topic+mclust'></span>

<h3>Description</h3>

<p>Gaussian finite mixture models estimated via EM algorithm for model-based clustering, classification, and density estimation, including Bayesian regularization and dimension reduction.
</p>


<h3>Details</h3>

<p>For a quick introduction to <span class="pkg">mclust</span> see the vignette <a href="../doc/mclust.html">A quick tour of mclust</a>.
</p>
<p>See also:
</p>

<ul>
<li> <p><code><a href="#topic+Mclust">Mclust</a></code> for clustering;
</p>
</li>
<li> <p><code><a href="#topic+MclustDA">MclustDA</a></code> for supervised classification;
</p>
</li>
<li> <p><code><a href="#topic+MclustSSC">MclustSSC</a></code> for semi-supervised classification;
</p>
</li>
<li>  <p><code><a href="#topic+densityMclust">densityMclust</a></code> for density estimation.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Chris Fraley, Adrian Raftery and Luca Scrucca.
</p>
<p>Maintainer: Luca Scrucca <a href="mailto:luca.scrucca@unipg.it">luca.scrucca@unipg.it</a>
</p>


<h3>References</h3>

<p>Scrucca L., Fraley C., Murphy T. B. and Raftery A. E. (2023) <em>Model-Based Clustering, Classification, and Density Estimation Using mclust in R</em>. Chapman &amp; Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>
<p>Fraley C. and Raftery A. E. (2002) Model-based clustering, discriminant analysis and density estimation, <em>Journal of the American Statistical Association</em>, 97/458, pp. 611-631.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Clustering
mod1 &lt;- Mclust(iris[,1:4])
summary(mod1)
plot(mod1,  what = c("BIC", "classification"))

# Classification
data(banknote)
mod2 &lt;- MclustDA(banknote[,2:7], banknote$Status)
summary(mod2)
plot(mod2)

# Density estimation
mod3 &lt;- densityMclust(faithful$waiting)
summary(mod3)

</code></pre>

<hr>
<h2 id='acidity'>Acidity data</h2><span id='topic+acidity'></span>

<h3>Description</h3>

<p>Acidity index measured in a sample of 155 lakes in the Northeastern United States.
Following Crawford et al. (1992, 1994), the data are expressed as log(ANC+50), where ANC is the acidity neutralising capacity value.
The data were also used to fit mixture of gaussian distributions by Richardson and Green (1997), and by McLachlan and Peel (2000, Sec. 6.6.2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(acidity)</code></pre>


<h3>Source</h3>

<p><code>https://www.stats.bris.ac.uk/~peter/mixdata</code></p>


<h3>References</h3>

<p>Crawford, S. L. (1994) An application of the Laplace method to finite mixture distribution. <em>Journal of the American Statistical Association</em>, 89, 259&ndash;267.
</p>
<p>Crawford, S. L., DeGroot, M. H., Kadane, J. B., and Small, M. J. (1994) Modeling lake chemistry distributions: Approximate Bayesian methods for estimating a finite mixture model. <em>Technometrics</em>, 34, 441&ndash;453.
</p>
<p>McLachlan, G. and Peel, D. (2000) <em>Finite Mixture Models</em>. Wiley, New York.
</p>
<p>Richardson, S. and Green, P. J. (1997) On Bayesian analysis of mixtures with unknown number of components (with discussion). <em>Journal of the Royal Statistical Society, Series B</em>, 59, 731&ndash;792.
</p>

<hr>
<h2 id='adjustedRandIndex'>
Adjusted Rand Index
</h2><span id='topic+adjustedRandIndex'></span>

<h3>Description</h3>

<p>Computes the adjusted Rand index comparing two classifications. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjustedRandIndex(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjustedRandIndex_+3A_x">x</code></td>
<td>

<p>A numeric or character vector of class labels.
</p>
</td></tr>
<tr><td><code id="adjustedRandIndex_+3A_y">y</code></td>
<td>

<p>A numeric or character vector of class labels.
The length of <code>y</code> should be the same as that of <code>x</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The adjusted Rand index comparing the two partitions (a scalar).  
This index has zero expected value in the case of random partition, and it is bounded above by 1 in the case of perfect agreement between two partitions.  
</p>


<h3>References</h3>

<p>L. Hubert and P. Arabie (1985) Comparing Partitions, <em>Journal of the Classification</em>, 2, pp. 193-218.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+classError">classError</a></code>,
<code><a href="#topic+mapClass">mapClass</a></code>,
<code><a href="base.html#topic+table">table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- rep(1:3, 3)
a
b &lt;- rep(c("A", "B", "C"), 3)
b
adjustedRandIndex(a, b)

a &lt;- sample(1:3, 9, replace = TRUE)
a
b &lt;- sample(c("A", "B", "C"), 9, replace = TRUE)
b
adjustedRandIndex(a, b)

a &lt;- rep(1:3, 4)
a
b &lt;- rep(c("A", "B", "C", "D"), 3)
b
adjustedRandIndex(a, b)

irisHCvvv &lt;- hc(modelName = "VVV", data = iris[,-5])
cl3 &lt;- hclass(irisHCvvv, 3)
adjustedRandIndex(cl3,iris[,5])

irisBIC &lt;- mclustBIC(iris[,-5])
adjustedRandIndex(summary(irisBIC,iris[,-5])$classification,iris[,5])
adjustedRandIndex(summary(irisBIC,iris[,-5],G=3)$classification,iris[,5])
</code></pre>

<hr>
<h2 id='banknote'>Swiss banknotes data</h2><span id='topic+banknote'></span>

<h3>Description</h3>

<p>The data set contains six measurements made on 100 genuine and 100 counterfeit old-Swiss 1000-franc bank notes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(banknote)</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables:
</p>

<dl>
<dt>Status</dt><dd><p>the status of the banknote: <code>genuine</code> or <code>counterfeit</code></p>
</dd>
<dt>Length</dt><dd><p>Length of bill (mm)</p>
</dd>
<dt>Left</dt><dd><p>Width of left edge (mm)</p>
</dd>
<dt>Right</dt><dd><p>Width of right edge (mm)</p>
</dd>
<dt>Bottom</dt><dd><p>Bottom margin width (mm)</p>
</dd>
<dt>Top</dt><dd><p>Top margin width (mm)</p>
</dd>
<dt>Diagonal</dt><dd><p>Length of diagonal (mm)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Flury, B. and Riedwyl, H. (1988). <em>Multivariate Statistics: A practical approach.</em> London: Chapman &amp; Hall, Tables 1.1 and 1.2, pp. 5-8.</p>

<hr>
<h2 id='Baudry_etal_2010_JCGS_examples'>Simulated Example Datasets From Baudry et al. (2010)</h2><span id='topic+Baudry_etal_2010_JCGS_examples'></span><span id='topic+ex4.1'></span><span id='topic+ex4.2'></span><span id='topic+ex4.3'></span><span id='topic+ex4.4.1'></span><span id='topic+ex4.4.2'></span><span id='topic+Test1D'></span>

<h3>Description</h3>

<p>Simulated datasets used in Baudry et al. (2010) to illustrate the proposed mixture components combining method for clustering. 
</p>
<p>Please see the cited article for a detailed presentation of these datasets. The data frame with name exN.M is presented in Section N.M in the paper.
</p>
<p>Test1D (not in the article) has been simulated from a Gaussian mixture distribution in R.
</p>
<p>ex4.1 and ex4.2 have been simulated from a Gaussian mixture distribution in R^2.
</p>
<p>ex4.3 has been simulated from a mixture of a uniform distribution on a square and a spherical Gaussian distribution in R^2.
</p>
<p>ex4.4.1 has been simulated from a Gaussian mixture model in R^2
</p>
<p>ex4.4.2 has been simulated from a mixture of two uniform distributions in R^3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Baudry_etal_2010_JCGS_examples)</code></pre>


<h3>Format</h3>

<p><code>ex4.1</code> is a data frame with 600 observations on 2 real variables.
</p>
<p><code>ex4.2</code> is a data frame with 600 observations on 2 real variables.
</p>
<p><code>ex4.3</code> is a data frame with 200 observations on 2 real variables.
</p>
<p><code>ex4.4.1</code> is a data frame with 800 observations on 2 real variables.
</p>
<p><code>ex4.4.2</code> is a data frame with 300 observations on 3 real variables.
</p>
<p><code>Test1D</code> is a data frame with 200 observations on 1 real variable.
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics</em>, 19(2):332-353.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Baudry_etal_2010_JCGS_examples)

output &lt;- clustCombi(data = ex4.4.1)
output # is of class clustCombi

# plots the hierarchy of combined solutions, then some "entropy plots" which 
# may help one to select the number of classes
plot(output) 


</code></pre>

<hr>
<h2 id='bic'>
BIC for Parameterized Gaussian Mixture Models
</h2><span id='topic+bic'></span>

<h3>Description</h3>

<p>Computes the BIC (Bayesian Information Criterion) for parameterized
mixture models given the loglikelihood, the dimension of the data,
and number of mixture components in the model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic(modelName, loglik, n, d, G, noise=FALSE, equalPro=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bic_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="bic_+3A_loglik">loglik</code></td>
<td>

<p>The log-likelihood for a data set with respect to the Gaussian mixture model
specified in the <code>modelName</code> argument.
</p>
</td></tr>
<tr><td><code id="bic_+3A_n">n</code></td>
<td>

<p>The number of observations in the data used to compute <code>loglik</code>.
</p>
</td></tr>
<tr><td><code id="bic_+3A_d">d</code></td>
<td>

<p>The dimension of the data used to compute <code>loglik</code>.
</p>
</td></tr>
<tr><td><code id="bic_+3A_g">G</code></td>
<td>

<p>The number of components in the Gaussian mixture model used to compute
<code>loglik</code>.
</p>
</td></tr>
<tr><td><code id="bic_+3A_noise">noise</code></td>
<td>

<p>A logical variable indicating whether or not the model includes an
optional Poisson noise component. The default is to assume no noise
component.
</p>
</td></tr>
<tr><td><code id="bic_+3A_equalpro">equalPro</code></td>
<td>

<p>A logical variable indicating whether or not the components in the
model are assumed to be present in equal proportion. The default is
to assume unequal mixing proportions.
</p>
</td></tr>
<tr><td><code id="bic_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in an indirect or list call via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The BIC or Bayesian Information Criterion for the given input arguments.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+nVarParams">nVarParams</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- nrow(iris)
d &lt;- ncol(iris)-1
G &lt;- 3

emEst &lt;- me(modelName="VVI", data=iris[,-5], unmap(iris[,5]))
names(emEst)

args(bic)
bic(modelName="VVI", loglik=emEst$loglik, n=n, d=d, G=G)
# do.call("bic", emEst)    ## alternative call

</code></pre>

<hr>
<h2 id='BrierScore'>Brier score to assess the accuracy of probabilistic predictions</h2><span id='topic+BrierScore'></span>

<h3>Description</h3>

<p>The Brier score is a proper score function that measures the accuracy of probabilistic predictions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>BrierScore(z, class)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BrierScore_+3A_z">z</code></td>
<td>

<p>a matrix containing the predicted probabilities of each observation 
to be classified in one of the classes. 
Thus, the number of rows must match the length of <code>class</code>, and
the number of columns the number of known classes.
</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_class">class</code></td>
<td>

<p>a numeric, character vector or factor containing the known class labels
for each observation.
If <code>class</code> is a factor, the number of classes is <code>nlevels(class)</code>
with classes <code>levels(class)</code>.
If <code>class</code> is a numeric or character vector, the number of classes is
equal to the number of classes obtained via <code>unique(class)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Brier Score is the mean square difference between the true classes and the predicted probabilities.
</p>
<p>This function implements the original multi-class definition by Brier (1950), normalized to <code class="reqn">[0,1]</code> as in Kruppa et al (2014). The formula is the following:
</p>
<p style="text-align: center;"><code class="reqn">
BS = \frac{1}{2n} \sum_{i=1}^n \sum_{k=1}^K (C_{ik} - p_{ik})^2
</code>
</p>

<p>where <code class="reqn">n</code> is the number of observations, <code class="reqn">K</code> the number of classes, <code class="reqn">C_{ik} = \{0,1\}</code> the indicator of class <code class="reqn">k</code> for observation <code class="reqn">i</code>, and <code class="reqn">p_{ik}</code> is the predicted probability of observation <code class="reqn">i</code> to belong to class <code class="reqn">k</code>.
</p>
<p>The above formulation is applicable to multi-class predictions, including the binary case. A small value of the Brier Score indicates high prediction accuracy.
</p>
<p>The Brier Score is a strictly proper score (Gneiting and Raftery, 2007), which means that it takes its minimal value only when the predicted probabilities match the empirical probabilities.
</p>


<h3>References</h3>

<p>Brier, G.W. (1950) Verification of forecasts expressed in terms of probability. <em>Monthly Weather Review</em>, 78 (1): 1-3.
</p>
<p>Gneiting, G. and Raftery, A. E. (2007) Strictly proper scoring rules, prediction, and estimation. <em>Journal of the American Statistical Association</em> 102 (477): 359-378.
</p>
<p>Kruppa, J., Liu, Y., Diener, H.-C., Holste, T., Weimar, C., Koonig, I. R., and Ziegler, A. (2014) Probability estimation with machine learning methods for dichotomous and multicategory outcome: Applications. <em>Biometrical Journal</em>, 56 (4): 564-583.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvMclustDA">cvMclustDA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># multi-class case
class &lt;- factor(c(5,5,5,2,5,3,1,2,1,1), levels = 1:5)
probs &lt;- matrix(c(0.15, 0.01, 0.08, 0.23, 0.01, 0.23, 0.59, 0.02, 0.38, 0.45, 
                  0.36, 0.05, 0.30, 0.46, 0.15, 0.13, 0.06, 0.19, 0.27, 0.17, 
                  0.40, 0.34, 0.18, 0.04, 0.47, 0.34, 0.32, 0.01, 0.03, 0.11, 
                  0.04, 0.04, 0.09, 0.05, 0.28, 0.27, 0.02, 0.03, 0.12, 0.25, 
                  0.05, 0.56, 0.35, 0.22, 0.09, 0.03, 0.01, 0.75, 0.20, 0.02),
                nrow = 10, ncol = 5)
cbind(class, probs, map = map(probs))
BrierScore(probs, class)

# two-class case
class &lt;- factor(c(1,1,1,2,2,1,1,2,1,1), levels = 1:2)
probs &lt;- matrix(c(0.91, 0.4, 0.56, 0.27, 0.37, 0.7, 0.97, 0.22, 0.68, 0.43, 
                  0.09, 0.6, 0.44, 0.73, 0.63, 0.3, 0.03, 0.78, 0.32, 0.57),
                nrow = 10, ncol = 2)
cbind(class, probs, map = map(probs))
BrierScore(probs, class)

# two-class case when predicted probabilities are constrained to be equal to 
# 0 or 1, then the (normalized) Brier Score is equal to the classification
# error rate
probs &lt;- ifelse(probs &gt; 0.5, 1, 0)
cbind(class, probs, map = map(probs))
BrierScore(probs, class)
classError(map(probs), class)$errorRate

# plot Brier score for predicted probabilities in range [0,1]
class &lt;- factor(rep(1, each = 100), levels = 0:1)
prob  &lt;- seq(0, 1, by = 0.01)
brier &lt;- sapply(prob, function(p) 
  { z &lt;- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)
    BrierScore(z, class)
  })
plot(prob, brier, type = "l", main = "Scoring all one class",
     xlab = "Predicted probability", ylab = "Brier score")

# brier score for predicting balanced data with constant prob
class &lt;- factor(rep(c(1,0), each = 50), levels = 0:1)
prob  &lt;- seq(0, 1, by = 0.01)
brier &lt;- sapply(prob, function(p) 
  { z &lt;- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)
    BrierScore(z, class)
  })
plot(prob, brier, type = "l", main = "Scoring balanced classes",
     xlab = "Predicted probability", ylab = "Brier score")

# brier score for predicting unbalanced data with constant prob
class &lt;- factor(rep(c(0,1), times = c(90,10)), levels = 0:1)
prob  &lt;- seq(0, 1, by = 0.01)
brier &lt;- sapply(prob, function(p) 
  { z &lt;- matrix(c(1-p,p), nrow = length(class), ncol = 2, byrow = TRUE)
    BrierScore(z, class)
  })
plot(prob, brier, type = "l", main = "Scoring unbalanced classes",
     xlab = "Predicted probability", ylab = "Brier score")
</code></pre>

<hr>
<h2 id='cdens'>
Component Density for Parameterized MVN Mixture Models
</h2><span id='topic+cdens'></span>

<h3>Description</h3>

<p>Computes component densities for observations in MVN mixture models
parameterized by eigenvalue decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdens(data, modelName, parameters, logarithm = FALSE, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdens_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="cdens_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="cdens_+3A_parameters">parameters</code></td>
<td>

<p>The parameters of the model:
</p>

<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="cdens_+3A_logarithm">logarithm</code></td>
<td>

<p>A logical value indicating whether or not the logarithm of the component 
densities should be returned. The default is to return the component 
densities, obtained from the log component densities by exponentiation.
</p>
</td></tr>
<tr><td><code id="cdens_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
when computations fail. The default is <code>warn=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="cdens_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix whose <code>[i,k]</code>th entry is the 
density or log density of observation <em>i</em> in component <em>k</em>. 
The densities are not scaled by mixing proportions.
</p>


<h3>Note</h3>

<p>When one or more component densities are very large in magnitude,
it may be possible to compute the logarithm of the component
densities but not the component densities themselves due to overflow.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdensE">cdensE</a></code>, ...,
<code><a href="#topic+cdensVVV">cdensVVV</a></code>,
<code><a href="#topic+dens">dens</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z2 &lt;- unmap(hclass(hcVVV(faithful),2)) # initial value for 2 class case

model &lt;- me(modelName = "EEE", data = faithful, z = z2)
cdens(modelName = "EEE", data = faithful, logarithm = TRUE, 
      parameters = model$parameters)[1:5,]

data(cross)
odd &lt;- seq(1, nrow(cross), by = 2)
oddBIC &lt;- mclustBIC(cross[odd,-1]) 
oddModel &lt;- mclustModel(cross[odd,-1], oddBIC) ## best parameter estimates
names(oddModel)

even &lt;- odd + 1
densities &lt;- cdens(modelName = oddModel$modelName, data = cross[even,-1], 
                   parameters = oddModel$parameters)
cbind(class = cross[even,1], densities)[1:5,]
</code></pre>

<hr>
<h2 id='cdensE'>
Component Density for a Parameterized MVN Mixture Model
</h2><span id='topic+cdensE'></span><span id='topic+cdensV'></span><span id='topic+cdensX'></span><span id='topic+cdensEII'></span><span id='topic+cdensVII'></span><span id='topic+cdensEEI'></span><span id='topic+cdensVEI'></span><span id='topic+cdensEVI'></span><span id='topic+cdensVVI'></span><span id='topic+cdensEEE'></span><span id='topic+cdensEEV'></span><span id='topic+cdensVEV'></span><span id='topic+cdensVVV'></span><span id='topic+cdensEVE'></span><span id='topic+cdensEVV'></span><span id='topic+cdensVEE'></span><span id='topic+cdensVVE'></span><span id='topic+cdensXII'></span><span id='topic+cdensXXI'></span><span id='topic+cdensXXX'></span>

<h3>Description</h3>

<p>Computes component densities for points in a parameterized MVN mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdensE(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensV(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensX(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEII(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVII(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEEI(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVEI(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEVI(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVVI(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEEE(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEEV(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVEV(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVVV(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEVE(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensEVV(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVEE(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensVVE(data, logarithm = FALSE, parameters, warn = NULL, ...) 
cdensXII(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensXXI(data, logarithm = FALSE, parameters, warn = NULL, ...)
cdensXXX(data, logarithm = FALSE, parameters, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdensE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="cdensE_+3A_logarithm">logarithm</code></td>
<td>

<p>A logical value indicating whether or not the logarithm of the
component densities should be returned.
The default is to return the component densities,
obtained from the log component densities by exponentiation.
</p>
</td></tr>
<tr><td><code id="cdensE_+3A_parameters">parameters</code></td>
<td>

<p>The parameters of the model:
</p>

<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="cdensE_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
when computations fail. The default is <code>warn=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="cdensE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix whose <code>[i,j]</code>th 
entry is the density of observation <em>i</em> in component <em>j</em>. 
The densities are not scaled by mixing proportions.
</p>


<h3>Note</h3>

<p>When one or more component densities are very large in magnitude,
then it may be possible to compute the logarithm of the component
densities but not the component densities themselves due to overflow.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdens">cdens</a></code>,
<code><a href="#topic+dens">dens</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
z2 &lt;- unmap(hclass(hcVVV(faithful),2)) # initial value for 2 class case

model &lt;- meVVV(data=faithful, z=z2)
cdensVVV(data=faithful, logarithm = TRUE, parameters = model$parameters)

data(cross)
z2 &lt;- unmap(cross[,1])

model &lt;- meEEV(data = cross[,-1], z = z2)

EEVdensities &lt;- cdensEEV( data = cross[,-1], parameters = model$parameters)

cbind(cross[,-1],map(EEVdensities))
</code></pre>

<hr>
<h2 id='cdfMclust'>
Cumulative Distribution and Quantiles for a univariate Gaussian mixture 
distribution
</h2><span id='topic+cdfMclust'></span><span id='topic+quantileMclust'></span>

<h3>Description</h3>

<p>Compute the cumulative density function (cdf) or quantiles from an estimated one-dimensional Gaussian mixture fitted using <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfMclust(object, data, ngrid = 100, ...)
quantileMclust(object, p, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfMclust_+3A_object">object</code></td>
<td>
<p>a <code>densityMclust</code> model object.</p>
</td></tr>
<tr><td><code id="cdfMclust_+3A_data">data</code></td>
<td>
<p>a numeric vector of evaluation points.</p>
</td></tr>
<tr><td><code id="cdfMclust_+3A_ngrid">ngrid</code></td>
<td>
<p>the number of points in a regular grid to be used as evaluation points if no <code>data</code> are provided.</p>
</td></tr>
<tr><td><code id="cdfMclust_+3A_p">p</code></td>
<td>
<p>a numeric vector of probabilities.</p>
</td></tr>
<tr><td><code id="cdfMclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cdf is evaluated at points given by the optional argument  <code>data</code>. If not provided, a regular grid of length <code>ngrid</code> for the evaluation points is used. 
</p>
<p>The quantiles are computed using bisection linear search algorithm.
</p>


<h3>Value</h3>

<p><code>cdfMclust</code> returns a list of <code>x</code> and <code>y</code> values providing, respectively, the evaluation points and the estimated cdf. 
</p>
<p><code>quantileMclust</code> returns a vector of quantiles.
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityMclust">densityMclust</a></code>, 
<code><a href="#topic+plot.densityMclust">plot.densityMclust</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- c(rnorm(100), rnorm(100, 3, 2))
dens &lt;- densityMclust(x, plot = FALSE)
summary(dens, parameters = TRUE)
cdf &lt;- cdfMclust(dens)
str(cdf)
q &lt;- quantileMclust(dens, p = c(0.01, 0.1, 0.5, 0.9, 0.99))
cbind(quantile = q, cdf = cdfMclust(dens, q)$y)
plot(cdf, type = "l", xlab = "x", ylab = "CDF")
points(q, cdfMclust(dens, q)$y, pch = 20, col = "red3")

par(mfrow = c(2,2))
dens.waiting &lt;- densityMclust(faithful$waiting)
plot(cdfMclust(dens.waiting), type = "l", 
     xlab = dens.waiting$varname, ylab = "CDF")
dens.eruptions &lt;- densityMclust(faithful$eruptions)
plot(cdfMclust(dens.eruptions), type = "l", 
     xlab = dens.eruptions$varname, ylab = "CDF")
par(mfrow = c(1,1))

</code></pre>

<hr>
<h2 id='chevron'>Simulated minefield data</h2><span id='topic+chevron'></span>

<h3>Description</h3>

<p>A set of simulated bivariate minefield data
(1104 observations).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chevron)</code></pre>


<h3>References</h3>

<p>A. Dasgupta and A. E. Raftery (1998).
Detecting features in spatial point processes with clutter via model-based
clustering. 
<em>Journal of the American Statistical Association 93:294-302</em>. 
</p>
<p>C. Fraley and A.E. Raftery (1998).
<em>Computer Journal 41:578-588</em>.
</p>
<p>G. J. McLachlan and D. Peel (2000).
<em>Finite Mixture Models</em>, Wiley, pages 110-112.
</p>

<hr>
<h2 id='classError'>Classification error</h2><span id='topic+classError'></span>

<h3>Description</h3>

<p>Computes the errore rate of a given classification relative to the known classes, and the location of misclassified data points.</p>


<h3>Usage</h3>

<pre><code class='language-R'>classError(classification, class)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classError_+3A_classification">classification</code></td>
<td>

<p>A numeric, character vector or factor specifying the predicted class 
labels. Must have the same length as <code>class</code>.
</p>
</td></tr>
<tr><td><code id="classError_+3A_class">class</code></td>
<td>

<p>A numeric, character vector or factor of known true class labels. 
Must have the same length as <code>classification</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If more than one mapping between predicted classification and the known 
truth corresponds to the minimum number of classification errors,
only one possible set of misclassified observations is returned.
</p>


<h3>Value</h3>

<p>A list with the following two components:
</p>
<table>
<tr><td><code>misclassified</code></td>
<td>

<p>The indexes of the misclassified data points in a minimum error
mapping between the predicted classification and the known true classes.
</p>
</td></tr>
<tr><td><code>errorRate</code></td>
<td>

<p>The error rate corresponding to a minimum error mapping 
between the predicted classification and the known true classes.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+map">map</a></code>
<code><a href="#topic+mapClass">mapClass</a></code>,
<code><a href="base.html#topic+table">table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(a &lt;- rep(1:3, 3))
(b &lt;- rep(c("A", "B", "C"), 3))
classError(a, b)

(a &lt;- sample(1:3, 9, replace = TRUE))
(b &lt;- sample(c("A", "B", "C"), 9, replace = TRUE))
classError(a, b)

class &lt;- factor(c(5,5,5,2,5,3,1,2,1,1), levels = 1:5)
probs &lt;- matrix(c(0.15, 0.01, 0.08, 0.23, 0.01, 0.23, 0.59, 0.02, 0.38, 0.45, 
                  0.36, 0.05, 0.30, 0.46, 0.15, 0.13, 0.06, 0.19, 0.27, 0.17, 
                  0.40, 0.34, 0.18, 0.04, 0.47, 0.34, 0.32, 0.01, 0.03, 0.11, 
                  0.04, 0.04, 0.09, 0.05, 0.28, 0.27, 0.02, 0.03, 0.12, 0.25, 
                  0.05, 0.56, 0.35, 0.22, 0.09, 0.03, 0.01, 0.75, 0.20, 0.02),
                nrow = 10, ncol = 5)
cbind(class, probs, map = map(probs))
classError(map(probs), class)
</code></pre>

<hr>
<h2 id='classPriorProbs'>Estimation of class prior probabilities by EM algorithm</h2><span id='topic+classPriorProbs'></span>

<h3>Description</h3>

<p>A simple procedure to improve the estimation of class prior probabilities when the training data does not reflect the true a priori probabilities of the target classes. The EM algorithm used is described in Saerens et al (2002).</p>


<h3>Usage</h3>

<pre><code class='language-R'>classPriorProbs(object, newdata = object$data, 
                itmax = 1e3, eps = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classPriorProbs_+3A_object">object</code></td>
<td>

<p>an object of class <code>'MclustDA'</code> resulting from a call to <code><a href="#topic+MclustDA">MclustDA</a></code>.
</p>
</td></tr>
<tr><td><code id="classPriorProbs_+3A_newdata">newdata</code></td>
<td>

<p>a data frame or matrix giving the data. If missing the train data obtained from the call to <code><a href="#topic+MclustDA">MclustDA</a></code> are used.
</p>
</td></tr>
<tr><td><code id="classPriorProbs_+3A_itmax">itmax</code></td>
<td>

<p>an integer value specifying the maximal number of EM iterations.
</p>
</td></tr>
<tr><td><code id="classPriorProbs_+3A_eps">eps</code></td>
<td>

<p>a scalar specifying the tolerance associated with deciding when to 
terminate the EM iterations. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimation procedure employes an EM algorithm as described in Saerens et al (2002). 
</p>


<h3>Value</h3>

<p>A vector of class prior estimates which can then be used in the <code><a href="#topic+predict.MclustDA">predict.MclustDA</a></code> to improve predictions.</p>


<h3>References</h3>

<p>Saerens, M., Latinne, P. and Decaestecker, C. (2002) Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure, <em>Neural computation</em>, 14 (1), 21&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>, <code><a href="#topic+predict.MclustDA">predict.MclustDA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data from a mixture f(x) = 0.9 * N(0,1) + 0.1 * N(3,1)
n &lt;- 10000
mixpro &lt;- c(0.9, 0.1)
class &lt;- factor(sample(0:1, size = n, prob = mixpro, replace = TRUE))
x &lt;- ifelse(class == 1, rnorm(n, mean = 3, sd = 1), 
                        rnorm(n, mean = 0, sd = 1))

hist(x[class==0], breaks = 11, xlim = range(x), main = "", xlab = "x", 
     col = adjustcolor("dodgerblue2", alpha.f = 0.5), border = "white")
hist(x[class==1], breaks = 11, add = TRUE,
     col = adjustcolor("red3", alpha.f = 0.5), border = "white")
box()

# generate training data from a balanced case-control sample, i.e.
# f(x) = 0.5 * N(0,1) + 0.5 * N(3,1)
n_train &lt;- 1000
class_train &lt;- factor(sample(0:1, size = n_train, prob = c(0.5, 0.5), replace = TRUE))
x_train &lt;- ifelse(class_train == 1, rnorm(n_train, mean = 3, sd = 1), 
                                    rnorm(n_train, mean = 0, sd = 1))

hist(x_train[class_train==0], breaks = 11, xlim = range(x_train), 
     main = "", xlab = "x", 
     col = adjustcolor("dodgerblue2", alpha.f = 0.5), border = "white")
hist(x_train[class_train==1], breaks = 11, add = TRUE,
     col = adjustcolor("red3", alpha.f = 0.5), border = "white")
box()

# fit a MclustDA model
mod &lt;- MclustDA(x_train, class_train)
summary(mod, parameters = TRUE)

# test set performance
pred &lt;- predict(mod, newdata = x)
classError(pred$classification, class)$error
BrierScore(pred$z, class)

# compute performance over a grid of prior probs
priorProp &lt;- seq(0.01, 0.99, by = 0.01)
CE &lt;- BS &lt;- rep(as.double(NA), length(priorProp))
for(i in seq(priorProp))
{
  pred &lt;- predict(mod, newdata = x, prop = c(1-priorProp[i], priorProp[i]))
  CE[i] &lt;- classError(pred$classification, class = class)$error
  BS[i] &lt;- BrierScore(pred$z, class)
}

# estimate the optimal class prior probs
(priorProbs &lt;- classPriorProbs(mod, x))
pred &lt;- predict(mod, newdata = x, prop = priorProbs)
# compute performance at the estimated class prior probs
classError(pred$classification, class = class)$error
BrierScore(pred$z, class)

matplot(priorProp, cbind(CE,BS), type = "l", lty = 1, lwd = 2,
        xlab = "Class prior probability", ylab = "", ylim = c(0,max(CE,BS)), 
        panel.first = 
          { abline(h = seq(0,1,by=0.05), col = "grey", lty = 3)
            abline(v = seq(0,1,by=0.05), col = "grey", lty = 3) 
          })
abline(v = mod$prop[2], lty = 2)              # training prop
abline(v = mean(class==1), lty = 4)           # test prop (usually unknown) 
abline(v = priorProbs[2], lty = 3, lwd = 2)      # estimated prior probs
legend("topleft", legend = c("ClassError", "BrierScore"),
       col = 1:2, lty = 1, lwd = 2, inset = 0.02)

# Summary of results:
priorProp[which.min(CE)] # best prior of class 1 according to classification error
priorProp[which.min(BS)] # best prior of class 1 according to Brier score
priorProbs               # optimal estimated class prior probabilities

</code></pre>

<hr>
<h2 id='clPairs'>Pairwise Scatter Plots showing Classification</h2><span id='topic+clPairs'></span><span id='topic+clPairsLegend'></span>

<h3>Description</h3>

<p>Creates a scatter plot for each pair of variables in given data.
Observations in different classes are represented by different colors and symbols.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clPairs(data, classification, 
        symbols = NULL, colors = NULL, cex = NULL,
        labels = dimnames(data)[[2]], cex.labels = 1.5, 
        gap = 0.2, grid = FALSE, ...)

clPairsLegend(x, y, class, col, pch, cex, box = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clPairs_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector representing a classification of observations
(rows) of <code>data</code>.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class in <code>classification</code>. Elements in <code>symbols</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_cex">cex</code></td>
<td>

<p>A vector of numerical values specifying the size of the plotting 
symbol for each unique class in <code>classification</code>. Values in 
<code>cex</code> correspond to classes in order of appearance in the 
sequence of observations (the order used by the function <code>unique</code>). 
By default <code>cex = 1</code> for all classes is used. 	
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_labels">labels</code></td>
<td>

<p>A vector of character strings for labelling the variables. The default
is to use the column dimension names of <code>data</code>.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_cex.labels">cex.labels</code></td>
<td>

<p>A numerical value specifying the size of the text labels.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_gap">gap</code></td>
<td>

<p>An argument specifying the distance between subplots (see <code><a href="graphics.html#topic+pairs">pairs</a></code>).
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_grid">grid</code></td>
<td>

<p>A logical specifying if grid lines should be added to panels (see <code><a href="graphics.html#topic+grid">grid</a></code>).
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_x">x</code>, <code id="clPairs_+3A_y">y</code></td>
<td>

<p>The x and y co-ordinates with respect to a graphic device having 
plotting region coordinates <code>par("usr" = c(0,1,0,1))</code>.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_class">class</code></td>
<td>

<p>The class labels.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_box">box</code></td>
<td>

<p>A logical, if <code>TRUE</code> then a box is drawn around the current plot figure. 
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_col">col</code>, <code id="clPairs_+3A_pch">pch</code></td>
<td>

<p>The colors and plotting symbols appearing in the legend.
</p>
</td></tr>
<tr><td><code id="clPairs_+3A_...">...</code></td>
<td>

<p>For a <code>clPairs</code> call may be additional arguments to be passed to <code><a href="graphics.html#topic+pairs">pairs</a></code>. 
For a <code>clPairsLegend</code> call may be additional arguments to be passed to <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>clPairs()</code> draws scatter plots on the current graphics device for each combination of variables in <code>data</code>. Observations of different classifications are labeled with different symbols. 
</p>
<p>The function <code>clPairsLegend()</code> can be used to add a legend. See examples below.
</p>


<h3>Value</h3>

<p>The function <code>clPairs()</code> invisibly returns a list with the following components:
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>A character vector of class labels.</p>
</td></tr>
<tr><td><code>col</code></td>
<td>
<p>A vector of colors used for each class.</p>
</td></tr>
<tr><td><code>pch</code></td>
<td>
<p>A vector of plotting symbols used for each class.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+pairs">pairs</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>clPairs(iris[,1:4], cl = iris$Species)

clp &lt;- clPairs(iris[,1:4], cl = iris$Species, lower.panel = NULL)
clPairsLegend(0.1, 0.4, class = clp$class, 
              col = clp$col, pch = clp$pch, 
              title = "Iris data")

</code></pre>

<hr>
<h2 id='clustCombi'>
Combining Gaussian Mixture Components for Clustering
</h2><span id='topic+clustCombi'></span><span id='topic+print.clustCombi'></span><span id='topic+summary.clustCombi'></span><span id='topic+print.summary.clustCombi'></span>

<h3>Description</h3>

<p>Provides a hierarchy of combined clusterings from the EM/BIC Gaussian mixture solution to one class, following the methodology proposed in the article cited in the references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustCombi(object = NULL, data = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clustCombi_+3A_object">object</code></td>
<td>

<p>An object returned by <code><a href="#topic+Mclust">Mclust</a></code> giving the optimal (according to BIC) parameters, conditional probabilities, and log-likelihood, together with the associated classification and its uncertainty. If not provided, the <code>data</code> argument must be specified.
</p>
</td></tr>
<tr><td><code id="clustCombi_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical variables are not allowed. If a matrix or data frame, rows correspond to observations and columns correspond to variables. If the <code>object</code> argument is not provided, the function <code><a href="#topic+Mclust">Mclust</a></code> is applied to the given <code>data</code> to fit a mixture model.</p>
</td></tr>
<tr><td><code id="clustCombi_+3A_...">...</code></td>
<td>

<p>Optional arguments to be passed to called functions. Notably, any argument (such as the numbers of components for which the BIC is computed; the models to be fitted by EM; initialization parameters for the EM algorithm, etc.) to be passed to <code><a href="#topic+Mclust">Mclust</a></code> in case <code>object = NULL</code>. Please see the <code><a href="#topic+Mclust">Mclust</a></code> documentation for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mclust provides a Gaussian mixture fitted to the data by maximum likelihood through the EM algorithm, for the model and number of components selected according to BIC. The corresponding components are hierarchically combined according to an entropy criterion, following the methodology described in the article cited in the references section. The solutions with numbers of classes between the one selected by BIC and one are returned as a <code>clustCombi</code> class object.
</p>


<h3>Value</h3>

<p>A list of class <code>clustCombi</code> giving the hierarchy of combined solutions from the number of components selected by BIC to one. The details of the output components are as follows:
</p>
<table>
<tr><td><code>classification</code></td>
<td>
<p>A list of the data classifications obtained for each combined solution of the hierarchy through a MAP assignment</p>
</td></tr>
<tr><td><code>combiM</code></td>
<td>
<p>A list of matrices. <code>combiM[[K]]</code> is the matrix used to combine the components of the (K+1)-classes solution to get the K-classes solution. Please see the examples.</p>
</td></tr>
<tr><td><code>combiz</code></td>
<td>
<p>A list of matrices. <code>combiz[[K]]</code> is a matrix whose [i,k]th entry is the probability that observation i in the data belongs to the kth class according to the K-classes combined solution.</p>
</td></tr>
<tr><td><code>MclustOutput</code></td>
<td>
<p>A list of class <code>Mclust</code>. Output of a call to the Mclust function (as provided by the user or the result of a call to the Mclust function) used to initiate the combined solutions hierarchy: please see the <code><a href="#topic+Mclust">Mclust</a></code> function documentation for details.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.clustCombi">plot.clustCombi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Baudry_etal_2010_JCGS_examples)

# run Mclust using provided data
output &lt;- clustCombi(data = ex4.1) 

# or run Mclust and then clustcombi on the returned object
mod &lt;- Mclust(ex4.1)
output &lt;- clustCombi(mod)


output
summary(output)


# run Mclust using provided data and any further optional argument provided
output &lt;- clustCombi(data = ex4.1, modelName = "EEV", G = 1:15)


# plot the hierarchy of combined solutions
plot(output, what = "classification") 
# plot some "entropy plots" which may help one to select the number of classes
plot(output, what = "entropy") 
# plot the tree structure obtained from combining mixture components
plot(output, what = "tree") 

# the selected model and number of components obtained from Mclust using BIC
output$MclustOutput 

# the matrix whose [i,k]th entry is the probability that i-th observation in 
# the data belongs to the k-th class according to the BIC solution
head( output$combiz[[output$MclustOutput$G]] ) 
# the matrix whose [i,k]th entry is the probability that i-th observation in 
# the data belongs to the k-th class according to the first combined solution
head( output$combiz[[output$MclustOutput$G-1]] ) 
# the matrix describing how to merge the 6-classes solution to get the 
# 5-classes solution
output$combiM[[5]] 
# for example the following code returns the label of the class (in the 
# 5-classes combined solution) to which the 4th class (in the 6-classes
# solution) is assigned. Only two classes in the (K+1)-classes solution 
# are assigned the same class in the K-classes solution: the two which 
# are merged at this step 
output$combiM[[5]] 
# recover the 5-classes soft clustering from the 6-classes soft clustering 
# and the 6 -&gt; 5 combining matrix
all( output$combiz[[5]] == t( output$combiM[[5]] %*% t(output$combiz[[6]]) ) ) 
# the hard clustering under the 5-classes solution
head( output$classification[[5]] )
</code></pre>

<hr>
<h2 id='clustCombi-internal'>Internal clustCombi functions</h2><span id='topic+combi'></span><span id='topic+pcws2_reg'></span><span id='topic+pcws3_reg'></span><span id='topic+xlog'></span>

<h3>Description</h3>

<p>Internal functions not intended to be called directly by users.
</p>

<hr>
<h2 id='clustCombiOptim'>Optimal number of clusters obtained by combining mixture components</h2><span id='topic+clustCombiOptim'></span>

<h3>Description</h3>

<p>Return the optimal number of clusters by combining mixture components based on the entropy method discussed in the reference given below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustCombiOptim(object, reg = 2, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clustCombiOptim_+3A_object">object</code></td>
<td>

<p>An object of class <code>'clustCombi'</code> resulting from a call to <code><a href="#topic+clustCombi">clustCombi</a></code>.
</p>
</td></tr>
<tr><td><code id="clustCombiOptim_+3A_reg">reg</code></td>
<td>

<p>The number of parts of the piecewise linear regression for the entropy plots. 
Choose 2 for a two-segment piecewise linear regression model (i.e. 1 change-point), and 3 for a three-segment piecewise linear regression model (i.e. 3 change-points).
</p>
</td></tr>
<tr><td><code id="clustCombiOptim_+3A_plot">plot</code></td>
<td>

<p>Logical, if <code>TRUE</code> an entropy plot is also produced.
</p>
</td></tr>
<tr><td><code id="clustCombiOptim_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the following components:
</p>
<table>
<tr><td><code>numClusters.combi</code></td>
<td>
<p>The estimated number of clusters.</p>
</td></tr>
<tr><td><code>z.combi</code></td>
<td>
<p>A matrix whose <em>[i,k]</em>th entry is the probability that observation <em>i</em> in the data belongs to the <em>k</em>th cluster.</p>
</td></tr>
<tr><td><code>cluster.combi</code></td>
<td>
<p>The clustering labels.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+combiPlot">combiPlot</a></code>, <code><a href="#topic+entPlot">entPlot</a></code>, <code><a href="#topic+clustCombi">clustCombi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Baudry_etal_2010_JCGS_examples)
output &lt;- clustCombi(data = ex4.1) 
combiOptim &lt;- clustCombiOptim(output)
str(combiOptim)

# plot optimal clustering with alpha color transparency proportional to uncertainty
zmax &lt;- apply(combiOptim$z.combi, 1, max)
col &lt;- mclust.options("classPlotColors")[combiOptim$cluster.combi]
vadjustcolor &lt;- Vectorize(adjustcolor)
alphacol = (zmax - 1/combiOptim$numClusters.combi)/(1-1/combiOptim$numClusters.combi)
col &lt;- vadjustcolor(col, alpha.f = alphacol)
plot(ex4.1, col = col, pch = mclust.options("classPlotSymbols")[combiOptim$cluster.combi])
</code></pre>

<hr>
<h2 id='combiPlot'>
Plot Classifications Corresponding to Successive Combined Solutions
</h2><span id='topic+combiPlot'></span>

<h3>Description</h3>

<p>Plot classifications corresponding to successive combined solutions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combiPlot(data, z, combiM, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combiPlot_+3A_data">data</code></td>
<td>

<p>The data.
</p>
</td></tr>
<tr><td><code id="combiPlot_+3A_z">z</code></td>
<td>

<p>A matrix whose [i,k]th entry is the probability that observation i in the data belongs to the kth class, for the initial solution (ie before any combining). Typically, the one returned by <code>Mclust</code>/BIC.
</p>
</td></tr>
<tr><td><code id="combiPlot_+3A_combim">combiM</code></td>
<td>

<p>A &quot;combining matrix&quot; (as provided by <code><a href="#topic+clustCombi">clustCombi</a></code>), ie a matrix whose kth row contains only zeros, but in columns corresponding to the labels of the classes in the initial solution to be merged together to get the combined solution.
</p>
</td></tr>
<tr><td><code id="combiPlot_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to the <code><a href="#topic+Mclust">Mclust</a></code> plot functions.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot the classifications obtained by MAP from the matrix <code>t(combiM %*% t(z))</code>, which is the matrix whose [i,k]th entry is the probability that observation i in the data belongs to the kth class, according to the combined solution obtained by merging (according to <code>combiM</code>) the initial solution described by <code>z</code>.
</p>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clustCombi">clustCombi</a></code>, <code><a href="#topic+combMat">combMat</a></code>, <code><a href="#topic+clustCombi">clustCombi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Baudry_etal_2010_JCGS_examples)
MclustOutput &lt;- Mclust(ex4.1) 

MclustOutput$G # Mclust/BIC selected 6 classes

par(mfrow=c(2,2))

combiM0 &lt;- diag(6) # is the identity matrix
# no merging: plot the initial solution, given by z
combiPlot(ex4.1, MclustOutput$z, combiM0, cex = 3) 
title("No combining")

combiM1 &lt;- combMat(6, 1, 2) # let's merge classes labeled 1 and 2
combiM1
combiPlot(ex4.1, MclustOutput$z, combiM1)
title("Combine 1 and 2")

# let's merge classes labeled 1 and 2, and then components labeled (in this 
# new 5-classes combined solution) 1 and 2
combiM2 &lt;- combMat(5, 1, 2) %*% combMat(6, 1, 2) 
combiM2 
combiPlot(ex4.1, MclustOutput$z, combiM2)
title("Combine 1, 2 and then 1 and 2 again")

plot(0,0,type="n", xlab = "", ylab = "", axes = FALSE)
legend("center", legend = 1:6,
       col = mclust.options("classPlotColors"), 
       pch = mclust.options("classPlotSymbols"), 
       title = "Class labels:")
</code></pre>

<hr>
<h2 id='combiTree'>Tree structure obtained from combining mixture components</h2><span id='topic+combiTree'></span>

<h3>Description</h3>

<p>The method implemented in <code><a href="#topic+clustCombi">clustCombi</a></code> can be used for combining Gaussian mixture components for clustering. This provides a hierarchical structure which can be graphically represented as a tree.</p>


<h3>Usage</h3>

<pre><code class='language-R'>combiTree(object, type = c("triangle", "rectangle"),
                  yaxis = c("entropy", "step"), 
                  edgePar = list(col = "darkgray", lwd = 2), 
                  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combiTree_+3A_object">object</code></td>
<td>

<p>An object of class <code>'clustCombi'</code> resulting from a call to <code><a href="#topic+clustCombi">clustCombi</a></code>.
</p>
</td></tr>
<tr><td><code id="combiTree_+3A_type">type</code></td>
<td>

<p>A string specifying the dendrogram's type. Possible values are <code>"triangle"</code> (default), and <code>"rectangle"</code>.
</p>
</td></tr>
<tr><td><code id="combiTree_+3A_yaxis">yaxis</code></td>
<td>

<p>A string specifying the quantity used to draw the vertical axis. Possible values are <code>"entropy"</code> (default), and <code>"step"</code>.
</p>
</td></tr>
<tr><td><code id="combiTree_+3A_edgepar">edgePar</code></td>
<td>

<p>A list of plotting parameters. See <code><a href="stats.html#topic+dendrogram">dendrogram</a></code>.
</p>
</td></tr>
<tr><td><code id="combiTree_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function always draw a tree and invisibly returns an object of class <code>'dendrogram'</code> for fine tuning.
</p>


<h3>Author(s)</h3>

<p>L. Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+clustCombi">clustCombi</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Baudry_etal_2010_JCGS_examples)
output &lt;- clustCombi(data = ex4.1) 
combiTree(output)
combiTree(output, type = "rectangle")
combiTree(output, yaxis = "step")
combiTree(output, type = "rectangle", yaxis = "step")

</code></pre>

<hr>
<h2 id='combMat'>
Combining Matrix
</h2><span id='topic+combMat'></span>

<h3>Description</h3>

<p>Create a combining matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combMat(K, l1, l2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combMat_+3A_k">K</code></td>
<td>

<p>The original number of classes: the matrix will define a combining from K to (K-1) classes.
</p>
</td></tr>
<tr><td><code id="combMat_+3A_l1">l1</code></td>
<td>

<p>Label of one of the two classes to be combined.
</p>
</td></tr>
<tr><td><code id="combMat_+3A_l2">l2</code></td>
<td>

<p>Label of the other class to be combined.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>z</code> is a vector (length <em>K</em>) whose <em>k</em>th entry is the probability that an observation belongs to the <em>k</em>th class in a <em>K</em>-classes classification, then <code>combiM %*% z</code> is the vector (length <em>K-1</em>) whose <em>k</em>th entry is the probability that the observation belongs to the <em>k</em>th class in the <em>K-1</em>-classes classification obtained by merging classes <code>l1</code> and <code>l2</code> in the initial classification.
</p>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clustCombi">clustCombi</a></code>, <code><a href="#topic+combiPlot">combiPlot</a></code>
</p>

<hr>
<h2 id='coordProj'>
Coordinate projections of multidimensional data modeled by an MVN mixture.
</h2><span id='topic+coordProj'></span>

<h3>Description</h3>

<p>Plots coordinate projections given multidimensional data
and parameters of an MVN mixture model for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coordProj(data, dimens = c(1,2), parameters = NULL, z = NULL,
          classification = NULL, truth = NULL, uncertainty = NULL, 
          what = c("classification", "error", "uncertainty"),
          addEllipses = TRUE, fillEllipses = mclust.options("fillEllipses"),
          symbols = NULL, colors = NULL, scale = FALSE, 
          xlim = NULL, ylim = NULL, cex = 1, PCH = ".", main = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coordProj_+3A_data">data</code></td>
<td>

<p>A numeric matrix or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_dimens">dimens</code></td>
<td>

<p>A vector of length 2 giving the integer dimensions of the
desired coordinate projections. The default is
<code>c(1,2)</code>, in which the first
dimension is plotted against the second.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_parameters">parameters</code></td>
<td>

<p>A named list giving the parameters of an <em>MCLUST</em> model, 
used to produce superimposing ellipses on the plot. 
The relevant components are as follows:
</p>

<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="coordProj_+3A_z">z</code></td>
<td>

<p>A matrix in which the <code>[i,k]</code>th entry gives the
probability of observation <em>i</em> belonging to the <em>k</em>th class. 
Used to compute <code>classification</code> and
<code>uncertainty</code> if those arguments aren't available.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector representing a classification of
observations (rows) of <code>data</code>. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_truth">truth</code></td>
<td>

<p>A numeric or character vector giving a known
classification of each data point.
If <code>classification</code>
or <code>z</code> is also present, 
this is used for displaying classification errors.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_uncertainty">uncertainty</code></td>
<td>

<p>A numeric vector of values in <em>(0,1)</em> giving the
uncertainty of each data point. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_what">what</code></td>
<td>

<p>Choose from one of the following three options: <code>"classification"</code>
(default), <code>"error"</code>, <code>"uncertainty"</code>. 
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_addellipses">addEllipses</code></td>
<td>

<p>A logical indicating whether or not to add ellipses with axes 
corresponding to the within-cluster covariances in case of 
<code>"classification"</code> or <code>"uncertainty"</code> plots. 
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_fillellipses">fillEllipses</code></td>
<td>

<p>A logical specifying whether or not to fill ellipses with transparent
colors when <code>addEllipses = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_scale">scale</code></td>
<td>

<p>A logical variable indicating whether or not the two chosen
dimensions should be plotted on the same scale, and
thus preserve the shape of the distribution.
Default: <code>scale=FALSE</code> 
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_xlim">xlim</code>, <code id="coordProj_+3A_ylim">ylim</code></td>
<td>

<p>Arguments specifying bounds for the ordinate, abscissa of the plot.
This may be useful for when comparing plots.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_cex">cex</code></td>
<td>

<p>A numerical value specifying the size of the plotting symbols. 
The default value is 1.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_pch">PCH</code></td>
<td>

<p>An argument specifying the symbol to be used when a classification
has not been specified for the data. The default value is a small dot &quot;.&quot;.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_main">main</code></td>
<td>

<p>A logical variable or <code>NULL</code> indicating whether or not to add a title to
the plot identifying the dimensions used.
</p>
</td></tr>
<tr><td><code id="coordProj_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing a two-dimensional coordinate projection of the data, together with the location of the  mixture components, classification, uncertainty, and/or classification errors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clPairs">clPairs</a></code>,
<code><a href="#topic+randProj">randProj</a></code>,
<code><a href="#topic+mclust2Dplot">mclust2Dplot</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
est &lt;- meVVV(iris[,-5], unmap(iris[,5]))
par(pty = "s", mfrow = c(1,1))
coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,
          what = "classification", main = TRUE) 
coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,
          truth = iris[,5], what = "error", main = TRUE) 
coordProj(iris[,-5], dimens=c(2,3), parameters = est$parameters, z = est$z,
          what = "uncertainty", main = TRUE) 

</code></pre>

<hr>
<h2 id='covw'>Weighted means, covariance and scattering matrices conditioning on a weighted matrix</h2><span id='topic+covw'></span>

<h3>Description</h3>

<p>Compute efficiently (via Fortran code) the means, covariance and scattering matrices conditioning on a weighted or indicator matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covw(X, Z, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covw_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">(n x p)</code> data matrix, with <code class="reqn">n</code> observations on <code class="reqn">p</code> variables.</p>
</td></tr>
<tr><td><code id="covw_+3A_z">Z</code></td>
<td>
<p>A <code class="reqn">(n x G)</code> matrix of weights, with <code class="reqn">G</code> number of groups.</p>
</td></tr>
<tr><td><code id="covw_+3A_normalize">normalize</code></td>
<td>
<p>A logical indicating if rows of <code>Z</code> should be normalized to sum to one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>A <code class="reqn">(p x G)</code> matrix of weighted means.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>A <code class="reqn">(p x p x G)</code> array of weighted covariance matrices.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>A <code class="reqn">(p x p x G)</code> array of weighted scattering matrices.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Fop and L. Scrucca</p>


<h3>Examples</h3>

<pre><code class='language-R'># Z as an indicator matrix
X &lt;- iris[,1:4]
Z &lt;- unmap(iris$Species)
str(covw(X, Z))
# Z as a matrix of weights
mod &lt;- Mclust(X, G = 3, modelNames = "VVV")
str(covw(X, mod$z))
</code></pre>

<hr>
<h2 id='crimcoords'>Discriminant coordinates data projection</h2><span id='topic+crimcoords'></span><span id='topic+print.crimcoords'></span><span id='topic+summary.crimcoords'></span><span id='topic+print.summary.crimcoords'></span><span id='topic+plot.crimcoords'></span>

<h3>Description</h3>

<p>Compute the discriminant coordinates or crimcoords obtained by projecting the observed data from multiple groups onto the discriminant subspace.
The optimal projection subspace is given by the linear transformation of the original variables that maximizes the ratio of the between-groups covariance (which represents groups separation) to the pooled within-group covariance (which represents within-group dispersion).</p>


<h3>Usage</h3>

<pre><code class='language-R'>crimcoords(data, classification, 
           numdir = NULL, 
           unbiased = FALSE, 
           ...)

## S3 method for class 'crimcoords'
summary(object, numdir, ...)

## S3 method for class 'crimcoords'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crimcoords_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="crimcoords_+3A_classification">classification</code></td>
<td>

<p>A vector (numerical, character string, or factor) giving the 
groups classification (either the known class labels or the estimated 
clusters) for the observed data.</p>
</td></tr>
<tr><td><code id="crimcoords_+3A_numdir">numdir</code></td>
<td>

<p>An integer value specifying the number of directions of the 
discriminant subspace to return. If not provided, the maximal number of
directions are returned (which is given by the number of non-null 
eigenvalues, the minimum among the number of variables and the number
of groups minus one). 
However, since the effectiveness of the discriminant coordinates in 
highlighting the separation of groups is decreasing, it might be useful
to provide a smaller value, say 2 or 3.</p>
</td></tr>
<tr><td><code id="crimcoords_+3A_unbiased">unbiased</code></td>
<td>

<p>A logical specifying if unbiased estimates should be used for the 
between-groups and within-groups covariances. By default
<code>unbiased = FALSE</code> so MLE estimates are used.
Note that the use of unbiased or MLE estimates only changes the 
eigenvalues and eigenvectors of the generalized eigendecomposition by 
a constant of proportionality, so the discriminant coordinates or 
crimcoords are essentially the same.</p>
</td></tr>
<tr><td><code id="crimcoords_+3A_object">object</code>, <code id="crimcoords_+3A_x">x</code></td>
<td>

<p>An object of class <code>crimcoords</code> as returned by <code>crimcoords()</code> function.</p>
</td></tr>
<tr><td><code id="crimcoords_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>crimcoords</code> with the following components:
</p>
<table>
<tr><td><code>means</code></td>
<td>
<p>A matrix of within-groups means.</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>The between-groups covariance matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The pooled within-groups covariance matrix.</p>
</td></tr>
<tr><td><code>evalues</code></td>
<td>
<p>A vector of eigenvalues.</p>
</td></tr>
<tr><td><code>basis</code></td>
<td>
<p>A matrix of eigenvectors specifying the basis of the 
discriminant subspace.</p>
</td></tr>
<tr><td><code>projection</code></td>
<td>
<p>A matrix of projected data points onto the discriminant
subspace.</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>
<p>A vector giving the groups classification.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca <a href="mailto:luca.scrucca@unipg.it">luca.scrucca@unipg.it</a>
</p>


<h3>References</h3>

<p>Gnanadesikan, R. (1977) <em>Methods for Statistical Data Analysis of Multivariate Observations</em>. John Wiley 1&amp; Sons, Sec. 4.2.
</p>
<p>Flury, B. (1997) <em>A First Course in Multivariate Statistics</em>. Springer, Sec. 7.3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDR">MclustDR</a></code>, <code><a href="#topic+clPairs">clPairs</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'># discriminant coordinates for the iris data using known classes 
data("iris")
CRIMCOORDS = crimcoords(iris[,-5], iris$Species)
summary(CRIMCOORDS)
plot(CRIMCOORDS)

# banknote data
data("banknote")

# discriminant coordinate on known classes 
CRIMCOORDS = crimcoords(banknote[,-1], banknote$Status)
summary(CRIMCOORDS)
plot(CRIMCOORDS)

#  discriminant coordinates on estimated clusters
mod = Mclust(banknote[,-1])
CRIMCOORDS = crimcoords(banknote[,-1], mod$classification)
summary(CRIMCOORDS)
plot(CRIMCOORDS)
plot(CRIMCOORDS$projection, type = "n")
text(CRIMCOORDS$projection, cex = 0.8,
     labels = strtrim(banknote$Status, 2), 
     col = mclust.options("classPlotColors")[1:mod$G][mod$classification])
</code></pre>

<hr>
<h2 id='cross'>Simulated Cross Data</h2><span id='topic+cross'></span>

<h3>Description</h3>

<p>A 500 by 3 matrix in which the first column is the classification and
the remaining columns are two data from a simulation of two crossed
elliptical Gaussians. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cross)</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'># This dataset was created as follows

n &lt;- 250 
set.seed(0)
cross &lt;- rbind(matrix(rnorm(n*2), n, 2) %*% diag(c(1,9)),
               matrix(rnorm(n*2), n, 2) %*% diag(c(1,9))[,2:1])
cross &lt;- cbind(c(rep(1,n),rep(2,n)), cross)

</code></pre>

<hr>
<h2 id='cvMclustDA'>MclustDA cross-validation</h2><span id='topic+cvMclustDA'></span>

<h3>Description</h3>

<p>V-fold cross-validation for classification models based on Gaussian 
finite mixture modelling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvMclustDA(object, nfold = 10, 
           prop = object$prop,
           verbose = interactive(), 
           ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvMclustDA_+3A_object">object</code></td>
<td>

<p>An object of class <code>'MclustDA'</code> resulting from a call to 
<code><a href="#topic+MclustDA">MclustDA</a></code>.
</p>
</td></tr>
<tr><td><code id="cvMclustDA_+3A_nfold">nfold</code></td>
<td>

<p>An integer specifying the number of folds (by defaul 10-fold CV is 
used).
</p>
</td></tr>
<tr><td><code id="cvMclustDA_+3A_prop">prop</code></td>
<td>

<p>A vector of class prior probabilities, which if not provided default
to the class proportions in the training data. 
</p>
</td></tr>
<tr><td><code id="cvMclustDA_+3A_verbose">verbose</code></td>
<td>

<p>A logical controlling if a text progress bar is displayed during 
the cross-validation procedure. By default is <code>TRUE</code> if the 
session is interactive, and <code>FALSE</code> otherwise.
</p>
</td></tr>
<tr><td><code id="cvMclustDA_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements V-fold cross-validation for classification 
models fitted by <code><a href="#topic+MclustDA">MclustDA</a></code>. 
Classification error and Brier score are the metrics returned, but other
metrics can be computed using the output returned by this function
(see Examples section below).
</p>


<h3>Value</h3>

<p>The function returns a list with the following components:
</p>
<table>
<tr><td><code>classification</code></td>
<td>
<p>a factor of cross-validated class labels.</p>
</td></tr> 
<tr><td><code>z</code></td>
<td>
<p>a matrix containing the cross-validated probabilites for class assignment.</p>
</td></tr> 
<tr><td><code>ce</code></td>
<td>
<p>the cross-validation classification error.</p>
</td></tr>
<tr><td><code>se.ce</code></td>
<td>
<p>the standard error of the cross-validated classification error.</p>
</td></tr>
<tr><td><code>brier</code></td>
<td>
<p>the cross-validation Brier score.</p>
</td></tr> 
<tr><td><code>se.brier</code></td>
<td>
<p>the standard error of the cross-validated Brier score.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>, 
<code><a href="#topic+predict.MclustDA">predict.MclustDA</a></code>, 
<code><a href="#topic+classError">classError</a></code>,
<code><a href="#topic+BrierScore">BrierScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Iris data
Class &lt;- iris$Species
X &lt;- iris[,1:4]

## EDDA model with common covariance (essentially equivalent to linear discriminant analysis)
irisEDDA &lt;- MclustDA(X, Class, modelType = "EDDA", modelNames = "EEE")
cv &lt;- cvMclustDA(irisEDDA)                         # 10-fold CV (default)
str(cv)
cv &lt;- cvMclustDA(irisEDDA, nfold = length(Class))  # LOO-CV
str(cv)

## MclustDA model selected by BIC
irisMclustDA &lt;- MclustDA(X, Class)
cv &lt;- cvMclustDA(irisMclustDA)                     # 10-fold CV (default)
str(cv)

# Banknote data
data("banknote")
Class &lt;- banknote$Status
X &lt;- banknote[,2:7]

## EDDA model selected by BIC
banknoteEDDA &lt;- MclustDA(X, Class, modelType = "EDDA")
cv &lt;- cvMclustDA(banknoteEDDA)                     # 10-fold CV (default)
str(cv)

(ConfusionMatrix &lt;- table(Pred = cv$classification, Class))
TP &lt;- ConfusionMatrix[1,1]
FP &lt;- ConfusionMatrix[1,2]
FN &lt;- ConfusionMatrix[2,1]
TN &lt;- ConfusionMatrix[2,2]
(Sensitivity &lt;- TP/(TP+FN))
(Specificity &lt;- TN/(FP+TN))

</code></pre>

<hr>
<h2 id='decomp2sigma'>
Convert mixture component covariances to matrix form
</h2><span id='topic+decomp2sigma'></span>

<h3>Description</h3>

<p>Converts covariances from a parameterization by  eigenvalue decomposition 
or cholesky factorization to representation as a 3-D array.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decomp2sigma(d, G, scale, shape, orientation, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decomp2sigma_+3A_d">d</code></td>
<td>

<p>The dimension of the data. 
</p>
</td></tr>
<tr><td><code id="decomp2sigma_+3A_g">G</code></td>
<td>

<p>The number of components in the mixture model. 
</p>
</td></tr>
<tr><td><code id="decomp2sigma_+3A_scale">scale</code></td>
<td>

<p>Either a <em>G</em>-vector giving the scale of the covariance (the
<em>d</em>th root of its determinant) for each component in the
mixture model, or a single numeric value if the scale is the same
for each component.  
</p>
</td></tr>
<tr><td><code id="decomp2sigma_+3A_shape">shape</code></td>
<td>

<p>Either a <em>G</em> by <em>d</em> matrix in which the <em>k</em>th column
is the shape of the covariance matrix (normalized to have
determinant 1) for the <em>k</em>th component, or a <em>d</em>-vector
giving a common shape for all components. 
</p>
</td></tr>
<tr><td><code id="decomp2sigma_+3A_orientation">orientation</code></td>
<td>

<p>Either a <em>d</em> by <em>d</em> by <em>G</em> array whose <code>[,,k]</code>th
entry is the orthonomal matrix whose columns are the eigenvectors
of the covariance matrix of the <em>k</em>th component, or a
<em>d</em> by <em>d</em> orthonormal matrix if the mixture components have a common
orientation. The <code>orientation</code> component of <code>decomp</code> can
be omitted in spherical and diagonal models, for which the principal
components are parallel to the coordinate axes so that the
orientation matrix is the identity.  
</p>
</td></tr>
<tr><td><code id="decomp2sigma_+3A_...">...</code></td>
<td>

<p>Catches unused arguments from an indirect or list call via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 3-D array whose <code>[,,k]</code>th component is the 
covariance matrix of the <em>k</em>th component in an MVN mixture model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sigma2decomp">sigma2decomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meEst &lt;- meVEV(iris[,-5], unmap(iris[,5])) 
names(meEst)
meEst$parameters$variance

dec &lt;- meEst$parameters$variance
decomp2sigma(d=dec$d, G=dec$G, shape=dec$shape, scale=dec$scale,
             orientation = dec$orientation)

do.call("decomp2sigma", dec)  ## alternative call

</code></pre>

<hr>
<h2 id='defaultPrior'>
Default conjugate prior for Gaussian mixtures
</h2><span id='topic+defaultPrior'></span>

<h3>Description</h3>

<p>Default conjugate prior specification for Gaussian mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defaultPrior(data, G, modelName, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="defaultPrior_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="defaultPrior_+3A_g">G</code></td>
<td>

<p>The number of mixture components.
</p>
</td></tr>
<tr><td><code id="defaultPrior_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model: <br /><br />
<code>"E"</code>: equal variance  (univariate) <br />
<code>"V"</code>: variable variance (univariate)<br /> 
<code>"EII"</code>: spherical, equal volume <br />
<code>"VII"</code>: spherical, unequal volume <br />
<code>"EEI"</code>: diagonal, equal volume and shape<br /> 
<code>"VEI"</code>: diagonal, varying volume, equal shape<br /> 
<code>"EVI"</code>: diagonal, equal volume, varying shape <br />
<code>"VVI"</code>: diagonal, varying volume and shape <br />
<code>"EEE"</code>: ellipsoidal, equal volume, shape, and orientation <br />
<code>"EEV"</code>: ellipsoidal, equal volume and equal shape<br />
<code>"VEV"</code>: ellipsoidal, equal shape <br />
<code>"VVV"</code>: ellipsoidal, varying volume, shape, and orientation. <br /><br />
A description of the models above is provided in the help of 
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>. Note that in the multivariate case 
only 10 out of 14 models may be used in conjunction with a prior, i.e.
those available in <em>MCLUST</em> up to version 4.4.
</p>
</td></tr>
<tr><td><code id="defaultPrior_+3A_...">...</code></td>
<td>

<p>One or more of the following:
</p>

<dl>
<dt><code>dof</code></dt><dd>
<p>The degrees of freedom for the prior on the variance. 
The default is <code>d + 2</code>, where <code>d</code> is
the dimension of the data.
</p>
</dd>
<dt><code>scale</code></dt><dd>
<p>The scale parameter for the prior on the variance. 
The default is <code>var(data)/G^(2/d)</code>,
where <code>d</code> is the dimension of the data.
</p>
</dd>
<dt><code>shrinkage</code></dt><dd>
<p>The shrinkage parameter for the prior on the mean. 
The default value is 0.01. 
If 0 or NA, no prior is assumed for the mean.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean parameter for the prior. 
The default value is <code>colMeans(data)</code>.
</p>
</dd>                   
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p><code>defaultPrior</code> is a function whose default is to output the
default prior specification for EM within <em>MCLUST</em>.<br />
Furthermore, <code>defaultPrior</code> can be used as a template to specify 
alternative parameters for a conjugate prior.
</p>


<h3>Value</h3>

<p>A list giving the prior degrees of freedom, scale, shrinkage, and mean.
</p>


<h3>References</h3>

<p>C. Fraley and A. E. Raftery (2002).
Model-based clustering, discriminant analysis, and density estimation.
<em>Journal of the American Statistical Association</em> 97:611-631. 
</p>
<p>C. Fraley and A. E. Raftery (2005, revised 2009).
Bayesian regularization for normal mixture estimation and model-based
clustering.
Technical Report, Department of Statistics, University of Washington.
</p>
<p>C. Fraley and A. E. Raftery (2007).
Bayesian regularization for normal mixture estimation and model-based
clustering. <em>Journal of Classification</em> 24:155-181.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+priorControl">priorControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># default prior
irisBIC &lt;- mclustBIC(iris[,-5], prior = priorControl())
summary(irisBIC, iris[,-5])

# equivalent to previous example
irisBIC &lt;- mclustBIC(iris[,-5], 
                     prior = priorControl(functionName = "defaultPrior"))
summary(irisBIC, iris[,-5])

# no prior on the mean; default prior on variance
irisBIC &lt;- mclustBIC(iris[,-5], prior = priorControl(shrinkage = 0))
summary(irisBIC, iris[,-5])

# equivalent to previous example
irisBIC &lt;- mclustBIC(iris[,-5], prior =
                     priorControl(functionName="defaultPrior", shrinkage=0))
summary(irisBIC, iris[,-5])

defaultPrior( iris[-5], G = 3, modelName = "VVV")
</code></pre>

<hr>
<h2 id='dens'>
Density for Parameterized MVN Mixtures
</h2><span id='topic+dens'></span>

<h3>Description</h3>

<p>Computes densities of observations in parameterized MVN mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dens(data, modelName, parameters, logarithm = FALSE, warn=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dens_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="dens_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="dens_+3A_parameters">parameters</code></td>
<td>

<p>The parameters of the model:
</p>
 
<dl>
<dt><code>pro</code></dt><dd>
<p>The vector of mixing proportions for the components of the mixture. 
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="dens_+3A_logarithm">logarithm</code></td>
<td>

<p>A logical value indicating whether or not the logarithm of the component 
densities should be returned. The default is to return the component 
densities, obtained from the log component densities by exponentiation.
</p>
</td></tr>
<tr><td><code id="dens_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
when computations fail. The default is <code>warn=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="dens_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector whose <em>i</em>th component is the density of the
<em>ith</em> observation in <code>data</code> in the MVN mixture specified 
by <code>parameters</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdens">cdens</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
faithfulModel &lt;- Mclust(faithful)
Dens &lt;- dens(modelName = faithfulModel$modelName, data = faithful,
             parameters = faithfulModel$parameters)
Dens

## alternative call
do.call("dens", faithfulModel)
</code></pre>

<hr>
<h2 id='densityMclust'>Density Estimation via Model-Based Clustering</h2><span id='topic+densityMclust'></span>

<h3>Description</h3>

<p>Produces a density estimate for each data point using a Gaussian finite 
mixture model from <code>Mclust</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityMclust(data, ..., plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densityMclust_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="densityMclust_+3A_...">...</code></td>
<td>

<p>Additional arguments for the <code><a href="#topic+Mclust">Mclust</a></code> function. 
In particular, setting the arguments <code>G</code> and <code>modelNames</code> 
allow to specify the number of mixture components and the type of
model to be fitted. By default an &quot;optimal&quot; model is selected based
on the BIC criterion. 
</p>
</td></tr>
<tr><td><code id="densityMclust_+3A_plot">plot</code></td>
<td>

<p>A logical value specifying if the estimated density should be 
plotted. For more contols on the resulting graph see the associated 
<code><a href="#topic+plot.densityMclust">plot.densityMclust</a></code> method. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>densityMclust</code>, which inherits from 
<code>Mclust</code>. This contains all the components described in 
<code><a href="#topic+Mclust">Mclust</a></code> and the additional element:
</p>
<table>
<tr><td><code>density</code></td>
<td>
<p>The density evaluated at the input <code>data</code>
computed from the estimated model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Revised version by Luca Scrucca based on 
the original code by C. Fraley and A.E. Raftery.</p>


<h3>References</h3>

<p>Scrucca L., Fraley C., Murphy T. B. and Raftery A. E. (2023) <em>Model-Based Clustering, Classification, and Density Estimation Using mclust in R</em>. Chapman &amp; Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>
<p>Fraley C. and Raftery A. E. (2002) Model-based clustering, discriminant analysis and density estimation, <em>Journal of the American Statistical Association</em>, 97/458, pp. 611-631.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.densityMclust">plot.densityMclust</a></code>, 
<code><a href="#topic+Mclust">Mclust</a></code>, 
<code><a href="#topic+summary.Mclust">summary.Mclust</a></code>,
<code><a href="#topic+predict.densityMclust">predict.densityMclust</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dens &lt;- densityMclust(faithful$waiting)
summary(dens)
summary(dens, parameters = TRUE)
plot(dens, what = "BIC", legendArgs = list(x = "topright"))
plot(dens, what = "density", data = faithful$waiting)

dens &lt;- densityMclust(faithful, modelNames = "EEE", G = 3, plot = FALSE)
summary(dens)
summary(dens, parameters = TRUE)
plot(dens, what = "density", data = faithful, 
     drawlabels = FALSE, points.pch = 20)
plot(dens, what = "density", type = "hdr")
plot(dens, what = "density", type = "hdr", prob = c(0.1, 0.9))
plot(dens, what = "density", type = "hdr", data = faithful)
plot(dens, what = "density", type = "persp")


dens &lt;- densityMclust(iris[,1:4], G = 2)
summary(dens, parameters = TRUE)
plot(dens, what = "density", data = iris[,1:4], 
     col = "slategrey", drawlabels = FALSE, nlevels = 7)
plot(dens, what = "density", type = "hdr", data = iris[,1:4])
plot(dens, what = "density", type = "persp", col = grey(0.9))

</code></pre>

<hr>
<h2 id='densityMclust.diagnostic'>Diagnostic plots for <code>mclustDensity</code> estimation</h2><span id='topic+densityMclust.diagnostic'></span>

<h3>Description</h3>

<p>Diagnostic plots for density estimation. Only available for the one-dimensional case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>densityMclust.diagnostic(object, type = c("cdf", "qq"), 
                         col = c("black", "black"), 
                         lwd = c(2,1), lty = c(1,1), 
                         legend = TRUE, grid = TRUE, 
                         ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densityMclust.diagnostic_+3A_object">object</code></td>
<td>
<p>An object of class <code>'mclustDensity'</code> obtained from a call to <code><a href="#topic+densityMclust">densityMclust</a></code> function.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_type">type</code></td>
<td>
<p>The type of graph requested:
</p>

<dl>
<dt><code>"cdf"</code> =</dt><dd><p>a plot of the estimated CDF versus the empirical distribution function.</p>
</dd>
<dt><code>"qq"</code> =</dt><dd><p>a Q-Q plot of sample quantiles versus the quantiles obtained from the inverse of the estimated cdf.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_col">col</code></td>
<td>
<p>A pair of values for the color to be used for plotting, respectively, the estimated CDF and the empirical cdf.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_lwd">lwd</code></td>
<td>
<p>A pair of values for the line width to be used for plotting, respectively, the estimated CDF and the empirical cdf.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_lty">lty</code></td>
<td>
<p>A pair of values for the line type to be used for plotting, respectively, the estimated CDF and the empirical cdf.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_legend">legend</code></td>
<td>
<p>A logical indicating if a legend must be added to the plot of fitted CDF vs the empirical CDF.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_grid">grid</code></td>
<td>
<p>A logical indicating if a <code><a href="graphics.html#topic+grid">grid</a></code> should be added to the plot.</p>
</td></tr>
<tr><td><code id="densityMclust.diagnostic_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two diagnostic plots for density estimation in the one-dimensional case are discussed in Loader (1999, pp- 87-90).
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Loader C. (1999), Local Regression and Likelihood. New York, Springer.
</p>
<p>Scrucca L., Fraley C., Murphy T. B. and Raftery A. E. (2023) <em>Model-Based Clustering, Classification, and Density Estimation Using mclust in R</em>. Chapman &amp; Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/
</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityMclust">densityMclust</a></code>, 
<code><a href="#topic+plot.densityMclust">plot.densityMclust</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- faithful$waiting
dens &lt;- densityMclust(x, plot = FALSE)
plot(dens, x, what = "diagnostic")
# or
densityMclust.diagnostic(dens, type = "cdf")
densityMclust.diagnostic(dens, type = "qq")

</code></pre>

<hr>
<h2 id='diabetes'>Diabetes Data (flawed)</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>The data set contains three measurements made on 145 non-obese adult patients classified into three groups.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diabetes)</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables:
</p>

<dl>
<dt>class</dt><dd><p>The type of diabete: <code>Normal</code>, <code>Overt</code>, and <code>Chemical</code>.</p>
</dd>
<dt>glucose</dt><dd><p>Area under plasma glucose curve after a three hour oral glucose tolerance test (OGTT).</p>
</dd>
<dt>insulin</dt><dd><p>Area under plasma insulin curve after a three hour oral glucose tolerance test (OGTT).</p>
</dd>
<dt>sspg</dt><dd><p>Steady state plasma glucose.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is <em>flawed</em> (compare with the reference) and it is provided here only for backward compatibility. A 5-variable version of the Reaven and Miller data is available in package <span class="pkg">rrcov</span>. The <em>glucose</em> and <em>sspg</em> columns in this dataset are identical to the <em>fpg</em> and <em>insulin</em> columns, respectively in the <span class="pkg">rrcov</span> version. The <em>insulin</em> column in this dataset differs from the <em>glucose</em> column in the <span class="pkg">rrcov</span> version in one entry: observation 104 has the value 45 in the <em>insulin</em> column in this data, and 455 in the corresponding <em>glucose</em> column of the <span class="pkg">rrcov</span> version.</p>


<h3>Source</h3>

<p>Reaven, G. M. and Miller, R. G. (1979). An attempt to define the nature of chemical diabetes using a multidimensional analysis. <em>Diabetologia</em> 16:17-24.</p>

<hr>
<h2 id='dmvnorm'>Density of multivariate Gaussian distribution</h2><span id='topic+dmvnorm'></span>

<h3>Description</h3>

<p>Efficiently computes the density of observations for a generic multivariate Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmvnorm(data, mean, sigma, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmvnorm_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="dmvnorm_+3A_mean">mean</code></td>
<td>

<p>A vector of means for each variable.
</p>
</td></tr>
<tr><td><code id="dmvnorm_+3A_sigma">sigma</code></td>
<td>

<p>A positive definite covariance matrix.
</p>
</td></tr>
<tr><td><code id="dmvnorm_+3A_log">log</code></td>
<td>

<p>A logical value indicating whether or not the logarithm of the densities 
should be returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector whose <em>i</em>th element gives the density of the
<em>ith</em> observation in <code>data</code> for the multivariate Gaussian 
distribution with parameters <code>mean</code> and <code>sigma</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dnorm">dnorm</a></code>,
<code><a href="#topic+dens">dens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># univariate
ngrid &lt;- 101
x &lt;- seq(-5, 5, length = ngrid)
dens &lt;- dmvnorm(x, mean = 1, sigma = 5)
plot(x, dens, type = "l")

# bivariate
ngrid &lt;- 101
x1 &lt;- x2 &lt;- seq(-5, 5, length = ngrid)
mu &lt;- c(1,0)
sigma &lt;- matrix(c(1,0.5,0.5,2), 2, 2)
dens &lt;- dmvnorm(as.matrix(expand.grid(x1, x2)), mu, sigma)
dens &lt;- matrix(dens, ngrid, ngrid)
image(x1, x2, dens)
contour(x1, x2, dens, add = TRUE)
</code></pre>

<hr>
<h2 id='dupPartition'>Partition the data by grouping together duplicated data</h2><span id='topic+dupPartition'></span>

<h3>Description</h3>

<p>Duplicated data are grouped together to form a basic partition that can be used to start hierarchical agglomeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dupPartition(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dupPartition_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
If a matrix or data frame, rows correspond to observations (<code class="reqn">n</code>) and
columns correspond to variables (<code class="reqn">d</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of indices indicating the partition. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hc">hc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dupPartition(iris[,1:4])
dupPartition(iris)
dupPartition(iris$Species)

</code></pre>

<hr>
<h2 id='em'>EM algorithm starting with E-step for parameterized Gaussian mixture models</h2><span id='topic+em'></span>

<h3>Description</h3>

<p>Implements the EM algorithm for parameterized Gaussian mixture models,
starting with the expectation step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em(data, modelName, parameters, prior = NULL, control = emControl(),
   warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="em_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="em_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="em_+3A_parameters">parameters</code></td>
<td>

<p>A names list giving the parameters of the model.
The components are as follows:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>An estimate of the reciprocal hypervolume of the data region.
If set to NULL or a negative value, the default is determined by 
applying function <code>hypvol</code> to the data.
Used only when <code>pro</code> includes an additional
mixing proportion for a noise component.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="em_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.
</p>
</td></tr>
<tr><td><code id="em_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call 
<code>emControl()</code>.
</p>
</td></tr>
<tr><td><code id="em_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
when computations fail. The default is <code>warn=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="em_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>

<p>The number of observations in the data.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The number of mixture components.
</p>
</td></tr>  
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>control</code></td>
<td>

<p>The list of control parameters for EM used.
</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>

<p>The specification of a conjugate prior on the means and variances used,
<code>NULL</code> if no prior is used.
</p>
</td></tr>        
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> Information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are 
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+emE">emE</a></code>, ...,
<code><a href="#topic+emVVV">emVVV</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
msEst &lt;- mstep(modelName = "EEE", data = iris[,-5], 
               z = unmap(iris[,5]))
names(msEst)

em(modelName = msEst$modelName, data = iris[,-5],
   parameters = msEst$parameters)

do.call("em", c(list(data = iris[,-5]), msEst))   ## alternative call

</code></pre>

<hr>
<h2 id='emControl'>Set control values for use with the EM algorithm</h2><span id='topic+emControl'></span>

<h3>Description</h3>

<p>Supplies a list of values including tolerances for singularity and
convergence assessment, for use functions involving EM within <em>MCLUST</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emControl(eps, tol, itmax, equalPro) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emControl_+3A_eps">eps</code></td>
<td>

<p>A scalar tolerance associated with deciding when to terminate
computations due to computational singularity in
covariances. Smaller values of <code>eps</code> allow computations to
proceed nearer to singularity. The default is the relative machine
precision <code>.Machine$double.eps</code>, which is approximately
<code class="reqn">2e-16</code> on IEEE-compliant machines. 
</p>
</td></tr>
<tr><td><code id="emControl_+3A_tol">tol</code></td>
<td>

<p>A vector of length two giving relative convergence tolerances for the 
log-likelihood and for parameter convergence in the inner loop for models
with iterative M-step (&quot;VEI&quot;, &quot;VEE&quot;, &quot;EVE&quot;, &quot;VVE&quot;, &quot;VEV&quot;), respectively.
The default is <code>c(1.e-5, sqrt(.Machine$double.eps))</code>.
If only one number is supplied, it is used as the tolerance 
for the outer iterations and the tolerance for the inner
iterations is as in the default.
</p>
</td></tr>
<tr><td><code id="emControl_+3A_itmax">itmax</code></td>
<td>

<p>A vector of length two giving integer limits on the number of EM
iterations and on the number of iterations in the inner loop for
models with iterative M-step (&quot;VEI&quot;, &quot;VEE&quot;, &quot;EVE&quot;, &quot;VVE&quot;, &quot;VEV&quot;),
respectively. The default is 
<code>c(.Machine$integer.max, .Machine$integer.max)</code> 
allowing termination to be completely governed by <code>tol</code>. 
If only one number is supplied, it is used as the iteration
limit for the outer iteration only.
</p>
</td></tr>
<tr><td><code id="emControl_+3A_equalpro">equalPro</code></td>
<td>

<p>Logical variable indicating whether or not the mixing proportions are
equal in the model. Default: <code>equalPro = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>emControl</code> is provided for assigning values and defaults
for EM within <em>MCLUST</em>.
</p>


<h3>Value</h3>

<p>A named list in which the names are the names of the arguments
and the values are the values supplied to the arguments.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+em">em</a></code>, 
<code><a href="#topic+estep">estep</a></code>, 
<code><a href="#topic+me">me</a></code>, 
<code><a href="#topic+mstep">mstep</a></code>, 
<code><a href="#topic+mclustBIC">mclustBIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisBIC &lt;- mclustBIC(iris[,-5], control = emControl(tol = 1.e-6))
summary(irisBIC, iris[,-5])
</code></pre>

<hr>
<h2 id='emE'>EM algorithm starting with E-step for a parameterized Gaussian mixture model</h2><span id='topic+emE'></span><span id='topic+emV'></span><span id='topic+emX'></span><span id='topic+emEII'></span><span id='topic+emVII'></span><span id='topic+emEEI'></span><span id='topic+emVEI'></span><span id='topic+emEVI'></span><span id='topic+emVVI'></span><span id='topic+emEEE'></span><span id='topic+emEEV'></span><span id='topic+emVEV'></span><span id='topic+emVVV'></span><span id='topic+emEVV'></span><span id='topic+emEVE'></span><span id='topic+emVEE'></span><span id='topic+emVVE'></span><span id='topic+emXII'></span><span id='topic+emXXI'></span><span id='topic+emXXX'></span>

<h3>Description</h3>

<p>Implements the EM algorithm for a parameterized Gaussian mixture model,
starting with the expectation step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emX(data, prior = NULL, warn = NULL, ...)
emEII(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVII(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEEI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVEI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEVI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVVI(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEEE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVEE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEVE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVVE(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEEV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVEV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emEVV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emVVV(data, parameters, prior = NULL, control = emControl(), warn = NULL, ...)
emXII(data, prior = NULL, warn = NULL, ...)
emXXI(data, prior = NULL, warn = NULL, ...)
emXXX(data, prior = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="emE_+3A_parameters">parameters</code></td>
<td>

<p>The parameters of the model:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
There should one more mixing proportion than the number of 
Gaussian components if the mixture model includes 
a Poisson noise term.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>An estimate of the reciprocal hypervolume of the data region.
The default is determined by applying function  <code>hypvol</code> 
to the data. Used only when <code>pro</code> includes an additional
mixing proportion for a noise component.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="emE_+3A_prior">prior</code></td>
<td>

<p>The default assumes no prior, but this argument allows specification of a
conjugate prior on the means and variances through the function
<code>priorControl</code>.
</p>
</td></tr>
<tr><td><code id="emE_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>.
</p>
</td></tr>
<tr><td><code id="emE_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
whenever a singularity is encountered.
The default is given in <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="emE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion
for the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> Information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are 
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
msEst &lt;- mstepEEE(data = iris[,-5], z = unmap(iris[,5]))
names(msEst)

emEEE(data = iris[,-5], parameters = msEst$parameters)
</code></pre>

<hr>
<h2 id='entPlot'>
Plot Entropy Plots
</h2><span id='topic+entPlot'></span>

<h3>Description</h3>

<p>Plot &quot;entropy plots&quot; to help select the number of classes from a hierarchy of combined clusterings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entPlot(z, combiM, abc = c("standard", "normalized"), reg = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="entPlot_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the probability that observation <em>i</em> in the data belongs to the <em>k</em>th class, for the initial solution (ie before any combining). Typically, the one returned by <code>Mclust</code>/BIC.
</p>
</td></tr>
<tr><td><code id="entPlot_+3A_combim">combiM</code></td>
<td>

<p>A list of &quot;combining matrices&quot; (as provided by <code>clustCombi</code>), ie <code>combiM[[K]]</code> is the matrix whose <em>k</em>th row contains only zeros, but in columns corresponding to the labels of the classes in the <em>(K+1)</em>-classes solution to be merged to get the <em>K</em>-classes combined solution. <code>combiM</code> must contain matrices from <code>K</code> = number of classes in <code>z</code> to one.
</p>
</td></tr>
<tr><td><code id="entPlot_+3A_abc">abc</code></td>
<td>

<p>Choose one or more of: &quot;standard&quot;, &quot;normalized&quot;, to specify whether the number of observations involved in each combining step should be taken into account to scale the plots or not.
</p>
</td></tr>
<tr><td><code id="entPlot_+3A_reg">reg</code></td>
<td>

<p>The number of parts of the piecewise linear regression for the entropy plots. Choose one or more of: 2 (for 1 change-point), 3 (for 2 change-points).
</p>
</td></tr>
<tr><td><code id="entPlot_+3A_...">...</code></td>
<td>

<p>Other graphical arguments to be passed to the plot functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please see the article cited in the references for more details. A clear elbow in the &quot;entropy plot&quot; should suggest the user to consider the corresponding number(s) of class(es).
</p>


<h3>Value</h3>

<p>if <code>abc = "standard"</code>, plots the entropy against the number of clusters and the difference between the entropy of successive combined solutions against the number of clusters.
if <code>abc = "normalized"</code>, plots the entropy against the cumulated number of observations involved in the successive combining steps and the difference between the entropy of successive combined solutions divided by the number of observations involved in the corresponding combining step against the number of clusters.
</p>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.clustCombi">plot.clustCombi</a></code>, <code><a href="#topic+combiPlot">combiPlot</a></code>, <code><a href="#topic+clustCombi">clustCombi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Baudry_etal_2010_JCGS_examples)
# run Mclust to get the MclustOutput
output &lt;- clustCombi(data = ex4.2, modelNames = "VII") 

entPlot(output$MclustOutput$z, output$combiM, reg = c(2,3)) 
# legend: in red, the single-change-point piecewise linear regression;
#         in blue, the two-change-point piecewise linear regression.

</code></pre>

<hr>
<h2 id='errorBars'>Draw error bars on a plot</h2><span id='topic+errorBars'></span>

<h3>Description</h3>

<p>Draw error bars at x from upper to lower. If <code>horizontal = FALSE</code> (default)
bars are drawn vertically, otherwise horizontally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorBars(x, upper, lower, width = 0.1, code = 3, angle = 90, horizontal = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorBars_+3A_x">x</code></td>
<td>
<p>A vector of values where the bars must be drawn.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_upper">upper</code></td>
<td>
<p>A vector of upper values where the bars must end.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_lower">lower</code></td>
<td>
<p>A vector of lower values where the bars must start.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_width">width</code></td>
<td>
<p>A value specifying the width of the end-point segment.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_code">code</code></td>
<td>
<p>An integer code specifying the kind of arrows to be drawn. For details see <code><a href="graphics.html#topic+arrows">arrows</a></code>.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_angle">angle</code></td>
<td>
<p>A value specifying the angle at the arrow edge. For details see <code><a href="graphics.html#topic+arrows">arrows</a></code>.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_horizontal">horizontal</code></td>
<td>
<p>A logical specifying if bars should be drawn vertically (default) or horizontally.</p>
</td></tr>
<tr><td><code id="errorBars_+3A_...">...</code></td>
<td>
<p>Further arguments are passed to <code><a href="graphics.html#topic+arrows">arrows</a></code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow=c(2,2))
# Create a simple example dataset
x &lt;- 1:5
n &lt;- c(10, 15, 12, 6, 3)
se &lt;- c(1, 1.2, 2, 1, .5)
# upper and lower bars
b &lt;- barplot(n, ylim = c(0, max(n)*1.5))
errorBars(b, lower = n-se, upper = n+se, lwd = 2, col = "red3")
# one side bars
b &lt;- barplot(n, ylim = c(0, max(n)*1.5))
errorBars(b, lower = n, upper = n+se, lwd = 2, col = "red3", code = 1)
# 
plot(x, n, ylim = c(0, max(n)*1.5), pch = 0)
errorBars(x, lower = n-se, upper = n+se, lwd = 2, col = "red3")
#
dotchart(n, labels = x, pch = 19, xlim = c(0, max(n)*1.5))
errorBars(x, lower = n-se, upper = n+se, col = "red3", horizontal = TRUE)
</code></pre>

<hr>
<h2 id='estep'>
E-step for parameterized Gaussian mixture models.
</h2><span id='topic+estep'></span>

<h3>Description</h3>

<p>Implements the expectation step of EM algorithm for parameterized Gaussian
mixture models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  estep(data, modelName, parameters, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estep_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="estep_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="estep_+3A_parameters">parameters</code></td>
<td>

<p>A names list giving the parameters of the model.
The components are as follows:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>An estimate of the reciprocal hypervolume of the data region.
If set to NULL or a negative value, the default is determined
by applying function <code>hypvol</code> to the data.
Used only when <code>pro</code> includes an additional
mixing proportion for a noise component.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="estep_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
when computations fail. The default is <code>warn=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="estep_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the conditional probability
of the <em>i</em>th observation belonging to the <em>k</em>th component
of the mixture.   
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>The input parameters.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>Attributes</code></td>
<td>

<p><code>"WARNING"</code>: an appropriate warning if problems are
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+estepE">estepE</a></code>, ...,
<code><a href="#topic+estepVVV">estepVVV</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
<code><a href="#topic+mclustVariance">mclustVariance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
msEst &lt;- mstep(modelName = "VVV", data = iris[,-5], z = unmap(iris[,5]))
names(msEst)

estep(modelName = msEst$modelName, data = iris[,-5],
      parameters = msEst$parameters)
</code></pre>

<hr>
<h2 id='estepE'>
E-step in the EM algorithm for a parameterized Gaussian mixture model.
</h2><span id='topic+estepE'></span><span id='topic+estepV'></span><span id='topic+estepEII'></span><span id='topic+estepVII'></span><span id='topic+estepEEI'></span><span id='topic+estepVEI'></span><span id='topic+estepEVI'></span><span id='topic+estepVVI'></span><span id='topic+estepEEE'></span><span id='topic+estepEEV'></span><span id='topic+estepVEV'></span><span id='topic+estepVVV'></span><span id='topic+estepEVE'></span><span id='topic+estepEVV'></span><span id='topic+estepVEE'></span><span id='topic+estepVVE'></span>

<h3>Description</h3>

<p>Implements the expectation step in the EM algorithm for a 
parameterized Gaussian mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estepE(data, parameters, warn = NULL, ...)
estepV(data, parameters, warn = NULL, ...)
estepEII(data, parameters, warn = NULL, ...)
estepVII(data, parameters, warn = NULL, ...)
estepEEI(data, parameters, warn = NULL, ...)
estepVEI(data, parameters, warn = NULL, ...)
estepEVI(data, parameters, warn = NULL, ...)
estepVVI(data, parameters, warn = NULL, ...)
estepEEE(data, parameters, warn = NULL, ...)
estepEEV(data, parameters, warn = NULL, ...)
estepVEV(data, parameters, warn = NULL, ...)
estepVVV(data, parameters, warn = NULL, ...)
estepEVE(data, parameters, warn = NULL, ...)
estepEVV(data, parameters, warn = NULL, ...)
estepVEE(data, parameters, warn = NULL, ...)
estepVVE(data, parameters, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estepE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="estepE_+3A_parameters">parameters</code></td>
<td>

<p>The parameters of the model:


</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture.
If the model includes a Poisson term for noise, there
should be one more mixing proportion than the number
of Gaussian components.
</p>
</dd>
<dt>mu</dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose columns are the means of the  components.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>An estimate of the reciprocal hypervolume of the data region.
If not supplied or set to a negative value, the default is
determined by applying function <code>hypvol</code> to the data.
Used only when <code>pro</code> includes an additional
mixing proportion for a noise component.
</p>
</dd>
</dl>


</td></tr>
<tr><td><code id="estepE_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or certain warnings should be issued.
The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="estepE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>Character string identifying the model.
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>The input parameters.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The logliklihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>Attribute</code></td>
<td>

<p><code>"WARNING"</code>: An appropriate warning if problems are
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
msEst &lt;- mstepEII(data = iris[,-5], z = unmap(iris[,5]))
names(msEst)

estepEII(data = iris[,-5], parameters = msEst$parameters)
</code></pre>

<hr>
<h2 id='EuroUnemployment'>Unemployment data for European countries in 2014</h2><span id='topic+EuroUnemployment'></span>

<h3>Description</h3>

<p>The data set contains unemployment rates for 31 European countries for the year 2014.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(EuroUnemployment)</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables:
</p>

<dl>
<dt>TUR</dt><dd><p>Total unemployment rate, i.e. percentage of unemployed persons aged 15-74 in the economically active population.</p>
</dd>
<dt>YUR</dt><dd><p>Youth unemployment rate, i.e. percentage of unemployed persons aged 15-24 in the economically active population.</p>
</dd>
<dt>LUR</dt><dd><p>Long-term unemployment rate, i.e. percentage of unemployed persons who have been unemployed for 12 months or more.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dataset downloaded from EUROSTAT <a href="https://ec.europa.eu/eurostat">https://ec.europa.eu/eurostat</a>.</p>

<hr>
<h2 id='gmmhd'>Identifying Connected Components in Gaussian Finite Mixture Models for Clustering</h2><span id='topic+gmmhd'></span><span id='topic+print.gmmhd'></span><span id='topic+summary.gmmhd'></span><span id='topic+print.summary.gmmhd'></span><span id='topic+plot.gmmhd'></span><span id='topic+gmmhdClusterCores'></span><span id='topic+gmmhdClassify'></span>

<h3>Description</h3>

<p>Starting with the density estimate obtained from a fitted Gaussian finite mixture model, cluster cores are identified from the connected components at a given density level. Once cluster cores are identified, the remaining observations are allocated to those cluster cores for which the probability of cluster membership is the highest. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmmhd(object, 
      ngrid = min(round((log(nrow(data)))*10), nrow(data)), 
      dr = list(d = 3, lambda = 1, cumEvalues = NULL, mindir = 2),
      classify = list(G = 1:5, 
                      modelNames = mclust.options("emModelNames")[-c(8, 10)]),
      ...)

## S3 method for class 'gmmhd'
plot(x, what = c("mode", "cores", "clusters"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmmhd_+3A_object">object</code></td>
<td>
<p>An object returned by <code><a href="#topic+Mclust">Mclust</a></code>.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_ngrid">ngrid</code></td>
<td>
<p>An integer specifying the number of grid points used to compute the density levels.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_dr">dr</code></td>
<td>
<p>A list of parameters used in the dimension reduction step.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_classify">classify</code></td>
<td>
<p>A list of parameters used in the classification step.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_x">x</code></td>
<td>
<p>An object of class <code>'gmmhd'</code> as returned by the function <code>gmmhd</code>.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_what">what</code></td>
<td>
<p>A string specifying the type of plot to be produced. See Examples section.</p>
</td></tr>
<tr><td><code id="gmmhd_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model-based clustering associates each component of a finite mixture distribution to a group or cluster.
An underlying implicit assumption is that a one-to-one correspondence exists between mixture components and clusters. However, a single Gaussian density may not be sufficient, and two or more mixture components could be needed to reasonably approximate the distribution within a homogeneous group of observations. 
</p>
<p>This function implements the methodology proposed by Scrucca (2016) based on the identification of high density regions of the underlying density function. Starting with an estimated Gaussian finite mixture model, the corresponding density estimate is used to identify the cluster cores, i.e. those data points which form the core of the clusters. 
These cluster cores are obtained from the connected components at a given density level <code class="reqn">c</code>. A mode function gives the number of connected components as the level <code class="reqn">c</code> is varied. 
Once cluster cores are identified, the remaining observations are allocated to those cluster cores for which the probability of cluster membership is the highest.
</p>
<p>The method usually improves the identification of non-Gaussian clusters compared to a fully parametric approach. Furthermore, it enables the identification of clusters which cannot be obtained by merging mixture components, and it can be straightforwardly extended to cases of higher dimensionality.
</p>


<h3>Value</h3>

<p>A list of class <code>gmmhd</code> with the following components:
</p>
<table>
<tr><td><code>Mclust</code></td>
<td>
<p>The input object of class <code>"Mclust"</code> representing an estimated Gaussian finite mixture model.</p>
</td></tr>
<tr><td><code>MclustDA</code></td>
<td>
<p>An object of class <code>"MclustDA"</code> containing the model used for the classification step.</p>
</td></tr>
<tr><td><code>MclustDR</code></td>
<td>
<p>An object of class <code>"MclustDR"</code> containing the dimension reduction step if performed, otherwise <code>NULL</code>.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The data used in the algorithm. This can be the input data or a projection if a preliminary dimension reduction step is performed.</p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>The density estimated from the input Gaussian finite mixture model evaluated at the input data.</p>
</td></tr>
<tr><td><code>con</code></td>
<td>
<p>A list of connected components at each step.</p>
</td></tr>
<tr><td><code>nc</code></td>
<td>
<p>A vector giving the number of connected components (i.e. modes) at each step.</p>
</td></tr>
<tr><td><code>pn</code></td>
<td>
<p>Vector of values over a uniform grid of proportions of length <code>ngrid</code>.</p>
</td></tr>
<tr><td><code>qn</code></td>
<td>
<p>Vector of density quantiles corresponding to proportions <code>pn</code>.</p>
</td></tr>
<tr><td><code>pc</code></td>
<td>
<p>Vector of empirical proportions corresponding to quantiles <code>qn</code>.</p>
</td></tr>
<tr><td><code>clusterCores</code></td>
<td>
<p>Vector of cluster cores numerical labels; <code>NA</code>s indicate that an observation does not belong to any cluster core.</p>
</td></tr>
<tr><td><code>clusterCores</code></td>
<td>
<p>Vector of numerical labels giving the final clustering.</p>
</td></tr>
<tr><td><code>numClusters</code></td>
<td>
<p>An integer giving the number of clusters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca <a href="mailto:luca.scrucca@unipg.it">luca.scrucca@unipg.it</a>
</p>


<h3>References</h3>

<p>Scrucca, L. (2016) Identifying connected components in Gaussian finite mixture models for clustering. <em>Computational Statistics &amp; Data Analysis</em>, 93, 5-17.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(faithful)
mod &lt;- Mclust(faithful)
summary(mod)
plot(as.densityMclust(mod), faithful, what = "density", 
     points.pch = mclust.options("classPlotSymbols")[mod$classification], 
     points.col = mclust.options("classPlotColors")[mod$classification])

GMMHD &lt;- gmmhd(mod)
summary(GMMHD)

plot(GMMHD, what = "mode")
plot(GMMHD, what = "cores")
plot(GMMHD, what = "clusters")

</code></pre>

<hr>
<h2 id='GvHD'>GvHD Dataset</h2><span id='topic+GvHD'></span><span id='topic+GvHD.pos'></span><span id='topic+GvHD.control'></span>

<h3>Description</h3>

<p>GvHD (Graft-versus-Host Disease) data of Brinkman et al. (2007). Two samples of this flow cytometry data, one from a patient with the GvHD, and the other from a control patient. The GvHD positive and control samples consist of 9083 and 6809 observations, respectively. Both samples include four biomarker variables, namely, CD4, CD8b, CD3, and CD8. The objective of the analysis is to identify CD3+ CD4+ CD8b+ cell sub-populations present in the GvHD positive sample.
</p>
<p>A treatment of this data by combining mixtures is proposed in Baudry et al. (2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GvHD)</code></pre>


<h3>Format</h3>

<p>GvHD.pos (positive patient) is a data frame with 9083 observations on the following 4 variables, which are biomarker measurements.
</p>

<dl>
<dt>CD4</dt><dd></dd>
<dt>CD8b</dt><dd></dd>
<dt>CD3</dt><dd></dd>
<dt>CD8</dt><dd></dd>
</dl>
  
<p>GvHD.control (control patient) is a data frame with 6809 observations on the following 4 variables, which are biomarker measurements.
</p>

<dl>
<dt>CD4</dt><dd></dd>
<dt>CD8b</dt><dd></dd>
<dt>CD3</dt><dd></dd>
<dt>CD8</dt><dd></dd>
</dl>



<h3>References</h3>

<p>R. R. Brinkman, M. Gasparetto, S.-J. J. Lee, A. J. Ribickas, J. Perkins, W. Janssen, R. Smiley and C. Smith (2007). High-content flow cytometry and temporal data analysis for defining a cellular signature of Graft-versus-Host Disease. <em>Biology of Blood and Marrow Transplantation, 13: 691-700.</em>
</p>
<p>K. Lo, R. R. Brinkman, R. Gottardo (2008). Automated gating of flow cytometry data via robust model-based clustering. <em>Cytometry A, 73: 321-332.</em>
</p>
<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(GvHD)
dat &lt;- GvHD.pos[1:500,] # only a few lines for a quick example
output &lt;- clustCombi(data = dat) 
output # is of class clustCombi
# plot the hierarchy of combined solutions
plot(output, what = "classification") 
# plot some "entropy plots" which may help one to select the number of classes
plot(output, what = "entropy") 
# plot the tree structure obtained from combining mixture components
plot(output, what = "tree") 


</code></pre>

<hr>
<h2 id='hc'>Model-based Agglomerative Hierarchical Clustering</h2><span id='topic+hc'></span><span id='topic+print.hc'></span><span id='topic+as.hclust.hc'></span>

<h3>Description</h3>

<p>Agglomerative hierarchical clustering based on maximum likelihood criteria 
for Gaussian mixture models parameterized by eigenvalue decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hc(data,
   modelName = "VVV",  
   use = "VARS",
   partition = dupPartition(data), 
   minclus = 1, ...)
   
## S3 method for class 'hc'
as.hclust(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hc_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations (<code class="reqn">n</code>) and
columns correspond to variables (<code class="reqn">d</code>).
</p>
</td></tr>
<tr><td><code id="hc_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model to be used in model-based agglomerative hierarchical clustering.<br />
Possible models are:
</p>

<dl>
<dt><code>"E"</code></dt><dd><p>equal variance (one-dimensional);</p>
</dd>
<dt><code>"V"</code></dt><dd><p>spherical, variable variance (one-dimensional);</p>
</dd>
<dt><code>"EII"</code></dt><dd><p>spherical, equal volume;</p>
</dd>
<dt><code>"VII"</code></dt><dd><p>spherical, unequal volume;</p>
</dd>
<dt><code>"EEE"</code></dt><dd><p>ellipsoidal, equal volume, shape, and orientation;</p>
</dd>
<dt><code>"VVV"</code></dt><dd><p>ellipsoidal, varying volume, shape, and orientation (default).</p>
</dd>
</dl>

<p>If <code>hc()</code> is used for initialization of EM algorithm then the default is taken from <code>mclust.options("hcModelName")</code>. See <code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="hc_+3A_use">use</code></td>
<td>

<p>A character string specifying the type of input variables/data transformation to be used for model-based agglomerative hierarchical clustering.<br />
Possible values are:
</p>

<dl>
<dt><code>"VARS"</code></dt><dd><p>original variables (default);</p>
</dd>
<dt><code>"STD"</code></dt><dd><p>standardized variables (centered and scaled);</p>
</dd>
<dt><code>"SPH"</code></dt><dd><p>sphered variables (centered, scaled and uncorrelated)  
computed using SVD;</p>
</dd>
<dt><code>"PCS"</code></dt><dd><p>principal components computed using SVD on centered 
variables (i.e. using the covariance matrix);</p>
</dd>
<dt><code>"PCR"</code></dt><dd><p>principal components computed using SVD on standardized 
(center and scaled) variables (i.e. using the correlation matrix);</p>
</dd>
<dt><code>"SVD"</code></dt><dd><p>scaled SVD transformation.</p>
</dd>
</dl>

<p>If <code>hc()</code> is used for initialization of EM algorithm then the default is taken from <code>mclust.options("hcUse")</code>. See <code><a href="#topic+mclust.options">mclust.options</a></code>.<br />
For further details see Scrucca and Raftery (2015).
</p>
</td></tr>
<tr><td><code id="hc_+3A_partition">partition</code></td>
<td>

<p>A numeric or character vector representing a partition of
observations (rows) of <code>data</code>. 
If provided, group merges will start with this partition. 
Otherwise, each observation is assumed to be in a cluster by itself 
at the start of agglomeration.
Starting with version 5.4.8, by default the function
<code><a href="#topic+dupPartition">dupPartition</a></code> is used to start with all duplicated
observations in the same group, thereby keeping duplicates in the 
same group throughout the modelling process.
</p>
</td></tr>
<tr><td><code id="hc_+3A_minclus">minclus</code></td>
<td>

<p>A number indicating the number of clusters at which to stop the
agglomeration. The default is to stop when all observations have been
merged into a single cluster.
</p>
</td></tr>
<tr><td><code id="hc_+3A_...">...</code></td>
<td>

<p>Arguments for the method-specific <code>hc</code> functions. See for example
<code><a href="#topic+hcE">hcE</a></code>.
</p>
</td></tr>
<tr><td><code id="hc_+3A_x">x</code></td>
<td>

<p>An object of class <code>'hc'</code> resulting from a call to <code>hc()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most models have memory usage of the order of the square of the
number groups in the initial partition for fast execution.
Some models, such as equal variance or <code>"EEE"</code>,
do not admit a fast algorithm under the usual agglomerative
hierarchical clustering paradigm. 
These use less memory but are much slower to execute.
</p>


<h3>Value</h3>

<p>The function <code>hc()</code> returns a numeric two-column matrix in which 
the <em>i</em>th row gives the minimum index for observations in each of 
the two clusters merged at the <em>i</em>th stage of agglomerative 
hierarchical clustering. Several other informations are also returned
as attributes.
</p>
<p>The method <code>as.hclust.hc()</code> can be used to convert the input 
object from class <code>'hc'</code> to class <code>'hclust'</code>.
</p>


<h3>Note</h3>

<p>If <code>modelName = "E"</code> (univariate with equal variances) or
<code>modelName = "EII"</code> (multivariate with equal spherical
covariances), then underlying model is the same as that for
Ward's method for hierarchical clustering.
</p>


<h3>References</h3>

<p>Banfield J. D. and Raftery A. E. (1993).
Model-based Gaussian and non-Gaussian Clustering.
<em>Biometrics</em>, 49:803-821. 
</p>
<p>Fraley C. (1998).
Algorithms for model-based Gaussian hierarchical clustering.
<em>SIAM Journal on Scientific Computing</em>, 20:270-281. 
</p>
<p>Fraley C. and Raftery A. E. (2002).
Model-based clustering, discriminant analysis, and density estimation.
<em>Journal of the American Statistical Association</em>, 97:611-631. 
</p>
<p>Scrucca L. and Raftery A. E. (2015).
Improved initialisation of model-based clustering using Gaussian hierarchical partitions. 
<em>Advances in Data Analysis and Classification</em>, 9/4:447-460.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hcE">hcE</a></code>, ...,
<code><a href="#topic+hcVVV">hcVVV</a></code>,
<code><a href="#topic+plot.hc">plot.hc</a></code>,
<code><a href="#topic+hclass">hclass</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hcTree &lt;- hc(modelName = "VVV", data = iris[,-5])
hcTree
cl &lt;- hclass(hcTree,c(2,3))
table(cl[,"2"])
table(cl[,"3"])


clPairs(iris[,-5], classification = cl[,"2"])
clPairs(iris[,-5], classification = cl[,"3"])

</code></pre>

<hr>
<h2 id='hcE'>Model-based Hierarchical Clustering</h2><span id='topic+hcE'></span><span id='topic+hcV'></span><span id='topic+hcEII'></span><span id='topic+hcVII'></span><span id='topic+hcEEE'></span><span id='topic+hcVVV'></span>

<h3>Description</h3>

<p>Agglomerative hierarchical clustering based on maximum likelihood
for a Gaussian mixture model parameterized by eigenvalue decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hcE(data, partition = NULL, minclus=1, ...)
hcV(data, partition = NULL, minclus = 1, alpha = 1, ...)
hcEII(data, partition = NULL, minclus = 1, ...)
hcVII(data, partition = NULL, minclus = 1, alpha = 1, ...)
hcEEE(data, partition = NULL, minclus = 1, ...)
hcVVV(data, partition = NULL, minclus = 1, alpha = 1, beta = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hcE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="hcE_+3A_partition">partition</code></td>
<td>

<p>A numeric or character vector representing a partition of
observations (rows) of <code>data</code>. If provided, group merges will
start with this partition. Otherwise, each observation is assumed to
be in a cluster by itself at the start of agglomeration. 
</p>
</td></tr>
<tr><td><code id="hcE_+3A_minclus">minclus</code></td>
<td>

<p>A number indicating the number of clusters at which to stop the
agglomeration. The default is to stop when all observations have been
merged into a single cluster.
</p>
</td></tr>
<tr><td><code id="hcE_+3A_alpha">alpha</code>, <code id="hcE_+3A_beta">beta</code></td>
<td>

<p>Additional tuning parameters needed for initializatiion in some models. 
For details, see Fraley 1998. The defaults provided are usually adequate.
</p>
</td></tr>
<tr><td><code id="hcE_+3A_...">...</code></td>
<td>

<p>Catch unused arguments from a <code>do.call</code> call.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most models have memory usage of the order of the square of the
number groups in the initial partition for fast execution.
Some models, such as equal variance or <code>"EEE"</code>,
do not admit a fast algorithm under the usual agglomerative
hierachical clustering paradigm. 
These use less memory but are much slower to execute.
</p>


<h3>Value</h3>

<p>A numeric two-column matrix in which the <em>i</em>th row gives the minimum 
index for observations in each of the two clusters merged at the
<em>i</em>th stage of agglomerative hierarchical clustering.
</p>


<h3>References</h3>

<p>J. D. Banfield and A. E. Raftery (1993).
Model-based Gaussian and non-Gaussian Clustering.
<em>Biometrics 49:803-821</em>. 
</p>
<p>C. Fraley (1998).
Algorithms for model-based Gaussian hierarchical clustering.
<em>SIAM Journal on Scientific Computing 20:270-281</em>. 
</p>
<p>C. Fraley and A. E. Raftery (2002).
Model-based clustering, discriminant analysis, and density estimation.
<em>Journal of the American Statistical Association 97:611-631</em>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hc">hc</a></code>,
<code><a href="#topic+hclass">hclass</a></code>
<code><a href="#topic+hcRandomPairs">hcRandomPairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hcTree &lt;- hcEII(data = iris[,-5])
cl &lt;- hclass(hcTree,c(2,3))


par(pty = "s", mfrow = c(1,1))
clPairs(iris[,-5],cl=cl[,"2"])
clPairs(iris[,-5],cl=cl[,"3"])

par(mfrow = c(1,2))
dimens &lt;- c(1,2)
coordProj(iris[,-5], classification=cl[,"2"], dimens=dimens)
coordProj(iris[,-5], classification=cl[,"3"], dimens=dimens)

</code></pre>

<hr>
<h2 id='hclass'>
Classifications from Hierarchical Agglomeration 
</h2><span id='topic+hclass'></span>

<h3>Description</h3>

<p>Determines the classifications corresponding to different numbers of groups
given merge pairs from hierarchical agglomeration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hclass(hcPairs, G)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hclass_+3A_hcpairs">hcPairs</code></td>
<td>

<p>A numeric two-column matrix in which the <em>i</em>th row gives the minimum 
index for observations in each of the two clusters merged at the
<em>i</em>th stage of agglomerative hierarchical clustering.
</p>
</td></tr>
<tr><td><code id="hclass_+3A_g">G</code></td>
<td>

<p>An integer or vector of integers giving the number of clusters for which
the corresponding classfications are wanted.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with <code>length(G)</code> columns, each column 
corresponding to a classification. Columns are indexed by the character
representation of the integers in <code>G</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hc">hc</a></code>,
<code><a href="#topic+hcE">hcE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hcTree &lt;- hc(modelName="VVV", data = iris[,-5])
cl &lt;- hclass(hcTree,c(2,3))


par(pty = "s", mfrow = c(1,1))
clPairs(iris[,-5],cl=cl[,"2"])
clPairs(iris[,-5],cl=cl[,"3"])

</code></pre>

<hr>
<h2 id='hcRandomPairs'>Random hierarchical structure</h2><span id='topic+hcRandomPairs'></span><span id='topic+randomPairs'></span>

<h3>Description</h3>

<p>Create a hierarchical structure using a random hierarchical partition of the data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>hcRandomPairs(data, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hcRandomPairs_+3A_data">data</code></td>
<td>

<p>A numeric matrix or data frame of observations.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="hcRandomPairs_+3A_seed">seed</code></td>
<td>

<p>Optional single value, interpreted as an integer, specifying the seed for random partition.
</p>
</td></tr>
<tr><td><code id="hcRandomPairs_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric two-column matrix in which the <em>i</em>th row gives the minimum 
index for observations in each of the two clusters merged at the
<em>i</em>th stage of a random agglomerative hierarchical clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hc">hc</a></code>,
<code><a href="#topic+hclass">hclass</a></code>
<code><a href="#topic+hcVVV">hcVVV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- iris[,1:4]
randPairs &lt;- hcRandomPairs(data)
str(randPairs)
# start model-based clustering from a random partition
mod &lt;- Mclust(data, initialization = list(hcPairs = randPairs))
summary(mod)
</code></pre>

<hr>
<h2 id='hdrlevels'>Highest Density Region (HDR) Levels</h2><span id='topic+hdrlevels'></span>

<h3>Description</h3>

<p>Compute the levels of Highest Density Regions (HDRs) for any density and probability levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdrlevels(density, prob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdrlevels_+3A_density">density</code></td>
<td>
<p>A vector of density values computed on a set of (observed) evaluation points.</p>
</td></tr>
<tr><td><code id="hdrlevels_+3A_prob">prob</code></td>
<td>
<p>A vector of probability levels in the range <code class="reqn">[0,1]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From Hyndman (1996), let <code class="reqn">f(x)</code> be the density function of a random 
variable <code class="reqn">X</code>. Then the <code class="reqn">100(1-\alpha)\%</code> HDR is the subset 
<code class="reqn">R(f_\alpha)</code> of the sample space of <code class="reqn">X</code> such that
</p>
<p style="text-align: center;"><code class="reqn">
R(f_\alpha) = {x : f(x) \ge f_\alpha }
</code>
</p>

<p>where <code class="reqn">f_\alpha</code> is the largest constant such that 
<code class="reqn">
Pr( X \in R(f_\alpha)) \ge 1-\alpha
</code>
</p>


<h3>Value</h3>

<p>The function returns a vector of density values corresponding to HDRs at given probability levels.
</p>


<h3>Author(s)</h3>

<p>L. Scrucca</p>


<h3>References</h3>

<p>Rob J. Hyndman (1996) Computing and Graphing Highest Density Regions. <em>The American Statistician</em>, 50(2):120-126.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.densityMclust">plot.densityMclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: univariate Gaussian
x &lt;- rnorm(1000)
f &lt;- dnorm(x)
a &lt;- c(0.5, 0.25, 0.1)
(f_a &lt;- hdrlevels(f, prob = 1-a))

plot(x, f)
abline(h = f_a, lty = 2)
text(max(x), f_a, labels = paste0("f_", a), pos = 3)

mean(f &gt; f_a[1])
range(x[which(f &gt; f_a[1])])
qnorm(1-a[1]/2)

mean(f &gt; f_a[2])
range(x[which(f &gt; f_a[2])])
qnorm(1-a[2]/2)

mean(f &gt; f_a[3])
range(x[which(f &gt; f_a[3])])
qnorm(1-a[3]/2)

# Example 2: univariate Gaussian mixture
set.seed(1)
cl &lt;- sample(1:2, size = 1000, prob = c(0.7, 0.3), replace = TRUE)
x &lt;- ifelse(cl == 1, 
            rnorm(1000, mean = 0, sd = 1),
            rnorm(1000, mean = 4, sd = 1))
f &lt;- 0.7*dnorm(x, mean = 0, sd = 1) + 0.3*dnorm(x, mean = 4, sd = 1)

a &lt;- 0.25
(f_a &lt;- hdrlevels(f, prob = 1-a))

plot(x, f)
abline(h = f_a, lty = 2)
text(max(x), f_a, labels = paste0("f_", a), pos = 3)

mean(f &gt; f_a)

# find the regions of HDR
ord &lt;- order(x)
f &lt;- f[ord]
x &lt;- x[ord]
x_a &lt;- x[f &gt; f_a]
j &lt;- which.max(diff(x_a))
region1 &lt;- x_a[c(1,j)]
region2 &lt;- x_a[c(j+1,length(x_a))]
plot(x, f, type = "l")
abline(h = f_a, lty = 2)
abline(v = region1, lty = 3, col = 2)
abline(v = region2, lty = 3, col = 3)
</code></pre>

<hr>
<h2 id='hypvol'>
Aproximate Hypervolume for Multivariate Data
</h2><span id='topic+hypvol'></span>

<h3>Description</h3>

<p>Computes a simple approximation to the hypervolume of a multivariate
data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypvol(data, reciprocal=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hypvol_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="hypvol_+3A_reciprocal">reciprocal</code></td>
<td>

<p>A logical variable indicating whether or not the reciprocal
hypervolume is desired rather than the hypervolume itself. The
default is to return the hypervolume.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the minimum of the hypervolume computed from simple variable bounds
and that computed from variable bounds of the principal component scores.
Used for the default hypervolume parameter for the noise 
component when observations are designated as noise in  <code>Mclust</code>
and <code>mclustBIC</code>.
</p>


<h3>References</h3>

<p>A. Dasgupta and A. E. Raftery (1998).
Detecting features in spatial point processes with clutter via model-based
clustering. 
<em>Journal of the American Statistical Association 93:294-302</em>. 
</p>
<p>C. Fraley and A.E. Raftery (1998).
<em>Computer Journal 41:578-588</em>.
</p>
<p>C. Fraley and A. E. Raftery (2002).
Model-based clustering, discriminant analysis, and density estimation.
<em>Journal of the American Statistical Association 97:611-631</em>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hypvol(iris[,-5])
</code></pre>

<hr>
<h2 id='icl'>
ICL for an estimated Gaussian Mixture Model
</h2><span id='topic+icl'></span>

<h3>Description</h3>

<p>Computes the ICL (Integrated Complete-data Likelihood) for criterion for a Gaussian Mixture Model fitted by <code><a href="#topic+Mclust">Mclust</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icl(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icl_+3A_object">object</code></td>
<td>

<p>An object of class <code>'Mclust'</code> resulting from a call to <code><a href="#topic+Mclust">Mclust</a></code>.
</p>
</td></tr>
<tr><td><code id="icl_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ICL for the given input MCLUST model.
</p>


<h3>References</h3>

<p>Biernacki, C., Celeux, G., Govaert, G. (2000). 
Assessing a mixture model for clustering with the integrated completed likelihood.
<em>IEEE Trans. Pattern Analysis and Machine Intelligence</em>, 22 (7), 719-725.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>,
<code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+mclustICL">mclustICL</a></code>,
<code><a href="#topic+bic">bic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- Mclust(iris[,1:4])
icl(mod)
</code></pre>

<hr>
<h2 id='imputeData'>Missing data imputation via the <span class="pkg">mix</span> package</h2><span id='topic+imputeData'></span><span id='topic+matchCluster'></span>

<h3>Description</h3>

<p>Imputes missing data using the <span class="pkg">mix</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeData(data, categorical = NULL, seed = NULL, verbose = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputeData_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations containing
missing values. Categorical variables are allowed. If a matrix
or data frame, rows correspond to observations and columns
correspond to variables. 
</p>
</td></tr>
<tr><td><code id="imputeData_+3A_categorical">categorical</code></td>
<td>

<p>A logical vectors whose <em>i</em>th entry is <code>TRUE</code> if the
<em>i</em>th variable or column of <code>data</code> is to be interpreted as
categorical and <code>FALSE</code> otherwise. The default is to assume that a
variable is to be interpreted as categorical only if it is a factor.
</p>
</td></tr>
<tr><td><code id="imputeData_+3A_seed">seed</code></td>
<td>

<p>A seed for the function <code>rngseed</code> that is used to initialize
the random number generator in <span class="pkg">mix</span>. By default, a seed is
chosen uniformly in the interval <code>(.Machine$integer.max/1024,
    .Machine$integer.max)</code>.
</p>
</td></tr>
<tr><td><code id="imputeData_+3A_verbose">verbose</code></td>
<td>

<p>A logical, if <code>TRUE</code> reports info about iterations of the algorithm.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataset of the same dimensions as <code>data</code> with missing values
filled in.
</p>


<h3>References</h3>

<p>Schafer J. L. (1997). Analysis of Imcomplete Multivariate Data, Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imputePairs">imputePairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note that package 'mix' must be installed
data(stlouis, package = "mix")
 
# impute the continuos variables in the stlouis data
stlimp &lt;- imputeData(stlouis[,-(1:3)])

# plot imputed values
imputePairs(stlouis[,-(1:3)], stlimp)

</code></pre>

<hr>
<h2 id='imputePairs'>
Pairwise Scatter Plots showing Missing Data Imputations
</h2><span id='topic+imputePairs'></span>

<h3>Description</h3>

<p>Creates a scatter plot for each pair of variables in given data,
allowing display of imputations for missing values in different
colors and symbols than non missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputePairs(data, dataImp, 
            symbols = c(1,16), colors = c("black", "red"), labels,
            panel = points, ..., lower.panel = panel, upper.panel = panel, 
            diag.panel = NULL, text.panel = textPanel, label.pos = 0.5 + 
            has.diag/3, cex.labels = NULL, font.labels = 1, row1attop = TRUE, 
            gap = 0.2) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputePairs_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations containing
missing values. Categorical variables are not allowed. If a matrix
or data frame, rows correspond to observations and columns
correspond to variables. 
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_dataimp">dataImp</code></td>
<td>

<p>The dataset <code>data</code> with missing values imputed.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning plotting symbols to
the nonmissing data and impued  values, respectively. The default is a
closed circle for the nonmissing data
and an open circle for the imputed values.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning colors to
the nonmissing data and impued  values, respectively. The default is 
black for the nonmissing data and red for the imputed values.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_labels">labels</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_panel">panel</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_...">...</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_lower.panel">lower.panel</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_upper.panel">upper.panel</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_diag.panel">diag.panel</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_text.panel">text.panel</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_label.pos">label.pos</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_cex.labels">cex.labels</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_font.labels">font.labels</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_row1attop">row1attop</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="imputePairs_+3A_gap">gap</code></td>
<td>

<p>As in function <code>pairs</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A pairs plot displaying the location of missing and nonmissing values.
</p>


<h3>References</h3>

<p>Schafer J. L. (1997). Analysis of Imcomplete Multivariate Data, Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+pairs">pairs</a></code>,
<code><a href="#topic+imputeData">imputeData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note that package 'mix' must be installed
data(stlouis, package = "mix")
 
# impute the continuos variables in the stlouis data
stlimp &lt;- imputeData(stlouis[,-(1:3)])

# plot imputed values
imputePairs(stlouis[,-(1:3)], stlimp)

</code></pre>

<hr>
<h2 id='logLik.Mclust'>Log-Likelihood of a <code>Mclust</code> object</h2><span id='topic+logLik.Mclust'></span>

<h3>Description</h3>

<p>Returns the log-likelihood for a <code>'Mclust'</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'Mclust'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.Mclust_+3A_object">object</code></td>
<td>
<p>an object of class <code>'Mclust'</code> resulting from a call to <code><a href="#topic+Mclust">Mclust</a></code>.</p>
</td></tr>
<tr><td><code id="logLik.Mclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>'logLik'</code> with an element providing the maximized log-likelihood, and further arguments giving the number of (estimated) parameters in the model (<code>"df"</code>) and the sample size (<code>"nobs"</code>).</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
irisMclust &lt;- Mclust(iris[,1:4])
summary(irisMclust)
logLik(irisMclust)

</code></pre>

<hr>
<h2 id='logLik.MclustDA'>Log-Likelihood of a <code>MclustDA</code> object</h2><span id='topic+logLik.MclustDA'></span>

<h3>Description</h3>

<p>Returns the log-likelihood for a <code>MclustDA</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'MclustDA'
logLik(object, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.MclustDA_+3A_object">object</code></td>
<td>
<p>an object of class <code>'MclustDA'</code> resulting from a call to <code><a href="#topic+MclustDA">MclustDA</a></code>.</p>
</td></tr>
<tr><td><code id="logLik.MclustDA_+3A_data">data</code></td>
<td>
<p>the data for which the log-likelihood must be computed. If missing, the observed data from the <code>'MclustDA'</code> object is used.</p>
</td></tr>
<tr><td><code id="logLik.MclustDA_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>'logLik'</code> with an element providing the maximized log-likelihood, and further arguments giving the number of (estimated) parameters in the model (<code>"df"</code>) and the sample size (<code>"nobs"</code>).</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
irisMclustDA &lt;- MclustDA(iris[,1:4], iris$Species)
summary(irisMclustDA)
logLik(irisMclustDA)

</code></pre>

<hr>
<h2 id='logsumexp'>Log sum of exponentials</h2><span id='topic+logsumexp'></span>

<h3>Description</h3>

<p>Efficient implementation (via Fortran) of the log-sum-exp function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsumexp(x, v = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logsumexp_+3A_x">x</code></td>
<td>
<p>a matrix of dimension <code class="reqn">n \times k</code> of numerical values. If a vector is provided, it is converted to a single-row matrix.</p>
</td></tr>
<tr><td><code id="logsumexp_+3A_v">v</code></td>
<td>
<p>an optional vector of length <code class="reqn">k</code> of numerical values to be added to each row of <code>x</code> matrix. If not provided, a vector of zeros is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the matrix <code>x</code>, for each row <code class="reqn">x_{[i]} = [x_1, \dots, x_k]</code> (with <code class="reqn">i=1,\dots,n</code>), the log-sum-exp (LSE) function calculates
</p>
<p style="text-align: center;"><code class="reqn">
\text{LSE}(x_{[i]}) = \log \sum_{j=1}^k \exp(x_j + v_j) = m + \log \sum_{j=1}^k \exp(x_j + v_j - m)
</code>
</p>

<p>where <code class="reqn">m = \max(x_1+v_1, \dots, x_k+v_k)</code>.
</p>


<h3>Value</h3>

<p>Returns a vector of values of length equal to the number of rows of <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+softmax">softmax</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(15), 5, 3)
v = log(c(0.5, 0.3, 0.2))
logsumexp(x, v)
</code></pre>

<hr>
<h2 id='majorityVote'>Majority vote</h2><span id='topic+majorityVote'></span>

<h3>Description</h3>

<p>A function to compute the majority vote (some would say plurality) label in a vector of labels, breaking ties at random.</p>


<h3>Usage</h3>

<pre><code class='language-R'>majorityVote(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="majorityVote_+3A_x">x</code></td>
<td>
<p>A vector of values, either numerical or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>table</code></td>
<td>
<p>A table of votes for each unique value of <code>x</code>.</p>
</td></tr>
<tr><td><code>ind</code></td>
<td>
<p>An integer specifying which unique value of <code>x</code> corresponds to the majority vote.</p>
</td></tr>
<tr><td><code>majority</code></td>
<td>
<p>A string specifying the majority vote label.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>L. Scrucca</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("A", "C", "A", "B", "C", "B", "A")
majorityVote(x)
</code></pre>

<hr>
<h2 id='map'>Classification given Probabilities</h2><span id='topic+map'></span>

<h3>Description</h3>

<p>Converts a matrix in which each row sums to 1 to an integer vector 
specifying for each row the column index of the maximum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>map(z, warn = mclust.options("warn"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="map_+3A_z">z</code></td>
<td>

<p>A matrix (for example a matrix of conditional
probabilities  in which each row sums to 1
as produced by the E-step of the EM algorithm).
</p>
</td></tr>
<tr><td><code id="map_+3A_warn">warn</code></td>
<td>

<p>A logical variable indicating whether or not a warning should be
issued when there are some columns of <code>z</code> for which no row
attains a maximum.
</p>
</td></tr>
<tr><td><code id="map_+3A_...">...</code></td>
<td>

<p>Provided to allow lists with elements other than the arguments can
be passed in indirect or list calls with <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A integer vector with one entry for each row of z,
in which the <em>i</em>-th value is the column index at which the
<em>i</em>-th row of <code>z</code> attains a maximum.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unmap">unmap</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+me">me</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>emEst &lt;- me(modelName = "VVV", data = iris[,-5], z = unmap(iris[,5]))

map(emEst$z)
</code></pre>

<hr>
<h2 id='mapClass'>Correspondence between classifications</h2><span id='topic+mapClass'></span>

<h3>Description</h3>

<p>Best correspondence between classes given two vectors viewed
as alternative classifications of the same object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapClass(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mapClass_+3A_a">a</code></td>
<td>

<p>A numeric or character vector of class labels.
</p>
</td></tr>
<tr><td><code id="mapClass_+3A_b">b</code></td>
<td>

<p>A numeric or character vector of class labels.
Must have the same length as
<code>a</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two named elements, 
<code>aTOb</code> and 
<code>bTOa</code> which are themselves lists. 
The <code>aTOb</code> list has a component corresponding
to each unique element of <code>a</code>, which gives
the element or elements of <code>b</code> 
that result in the closest class correspondence.
</p>
<p>The <code>bTOa</code> list has a component corresponding
to each unique element of <code>b</code>, which gives
the element or elements of <code>a</code> 
that result in the closest class correspondence.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+classError">classError</a></code>,
<code><a href="base.html#topic+table">table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- rep(1:3, 3)
a
b &lt;- rep(c("A", "B", "C"), 3)
b
mapClass(a, b)
a &lt;- sample(1:3, 9, replace = TRUE)
a
b &lt;- sample(c("A", "B", "C"), 9, replace = TRUE)
b
mapClass(a, b)
</code></pre>

<hr>
<h2 id='Mclust'>Model-Based Clustering</h2><span id='topic+Mclust'></span><span id='topic+print.Mclust'></span>

<h3>Description</h3>

<p>Model-based clustering based on parameterized finite Gaussian mixture models. 
Models are estimated by EM algorithm initialized by hierarchical model-based agglomerative clustering. The optimal model is then selected according to BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mclust(data, G = NULL, modelNames = NULL, 
     prior = NULL, 
     control = emControl(), 
     initialization = NULL, 
     warn = mclust.options("warn"), 
     x =  NULL, 
     verbose = interactive(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mclust_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations (<code class="reqn">n</code>) and columns correspond to variables (<code class="reqn">d</code>). 
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_g">G</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components
(clusters) for which the BIC is to be calculated. 
The default is <code>G=1:9</code>. 
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of character strings indicating the models to be fitted 
in the EM phase of clustering. The default is:
</p>

<ul>
<li><p> for univariate data (<code class="reqn">d = 1</code>): <code>c("E", "V")</code>
</p>
</li>
<li><p> for multivariate data (<code class="reqn">n &gt; d</code>): all the models available in <code>mclust.options("emModelNames")</code>
</p>
</li>
<li><p> for multivariate data (<code class="reqn">n &lt;= d</code>): the spherical and diagonal models, i.e. <code>c("EII", "VII", "EEI", "EVI", "VEI", "VVI")</code>
</p>
</li></ul>

<p>The help file for <code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_prior">prior</code></td>
<td>

<p>The default assumes no prior, but this argument allows specification of a 
conjugate prior on the means and variances through the function 
<code><a href="#topic+priorControl">priorControl</a></code>. <br />
Note that, as described in <code><a href="#topic+defaultPrior">defaultPrior</a></code>, in the multivariate 
case only 10 out of 14 models may be used in conjunction with a prior, i.e.
those available in <em>MCLUST</em> up to version 4.4.
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>. 
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_initialization">initialization</code></td>
<td>

<p>A list containing zero or more of the following components:
</p>

<dl>
<dt><code>hcPairs</code></dt><dd>
<p>A matrix of merge pairs for hierarchical clustering such as produced
by function <code><a href="#topic+hc">hc</a></code>. <br />
For multivariate data, the default is to compute a hierarchical 
agglomerative clustering tree by applying function 
<code><a href="#topic+hc">hc</a></code> with 
model specified by <code>mclust.options("hcModelName")</code>, and
data transformation set by <code>mclust.options("hcUse")</code>.<br />
All the input or a subset as indicated by the <code>subset</code> argument is 
used for initial clustering.<br />
The hierarchical clustering results are then used to start the EM
algorithm from a given partition.<br />
For univariate data, the default is to use quantiles to start the EM
algorithm. However, hierarchical clustering could also be used by 
calling <code><a href="#topic+hc">hc</a></code> with model specified as <code>"V"</code> or <code>"E"</code>.
</p>
</dd>
<dt><code>subset</code></dt><dd>
<p>A logical or numeric vector specifying a subset of the data
to be used in the initial hierarchical clustering phase.
No subset is used unless the number of observations exceeds 
the value specified by <code>mclust.options("subset")</code>, which by 
default is set to 2000 (see <code><a href="#topic+mclust.options">mclust.options</a></code>).
Note that in this case to guarantee exact reproducibility of results 
a seed must be specified (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</dd>
<dt><code>noise</code></dt><dd>
<p>A logical or numeric vector indicating an initial guess as to
which observations are noise in the data. If numeric the entries
should correspond to row indexes of the data. If supplied, a noise
term will be added to the model in the estimation.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="Mclust_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings 
(usually related to singularity) should be issued.
The default is controlled by <code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_x">x</code></td>
<td>

<p>An object of class <code>'mclustBIC'</code>. If supplied, BIC values for models 
that have already been computed and are available in <code>x</code> are not 
recomputed. 
All arguments, with the exception of <code>data</code>, <code>G</code> and 
<code>modelName</code>, are ignored and their values are set as specified in the
attributes of <code>x</code>. Defaults for <code>G</code> and <code>modelNames</code>
are taken from <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_verbose">verbose</code></td>
<td>

<p>A logical controlling if a text progress bar is displayed during the
fitting procedure. By default is <code>TRUE</code> if the session is 
interactive, and <code>FALSE</code> otherwise.
</p>
</td></tr>
<tr><td><code id="Mclust_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>'Mclust'</code> providing the optimal (according to BIC)
mixture model estimation.
</p>
<p>The details of the output components are as follows:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call</p>
</td></tr> 
<tr><td><code>data</code></td>
<td>
<p>The input data matrix.</p>
</td></tr> 
<tr><td><code>modelName</code></td>
<td>

<p>A character string denoting the model at which the optimal BIC occurs.
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>

<p>The number of observations in the data.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The optimal number of mixture components.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>All BIC values.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood corresponding to the optimal BIC.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The number of estimated parameters.
</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>

<p>BIC value of the selected model.
</p>
</td></tr>
<tr><td><code>icl</code></td>
<td>

<p>ICL value of the selected model.
</p>
</td></tr>
<tr><td><code>hypvol</code></td>
<td>

<p>The hypervolume parameter for the noise component if required, otherwise set to <code>NULL</code> (see <code><a href="#topic+hypvol">hypvol</a></code>).
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
If missing, equal proportions are assumed.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <em>[i,k]</em>th entry is the probability that observation
<em>i</em> in the test data belongs to the <em>k</em>th class.
</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>

<p>The classification corresponding to <code>z</code>, i.e. <code>map(z)</code>.
</p>
</td></tr>
<tr><td><code>uncertainty</code></td>
<td>

<p>The uncertainty associated with the classification.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Scrucca L., Fraley C., Murphy T. B. and Raftery A. E. (2023) <em>Model-Based Clustering, Classification, and Density Estimation Using mclust in R</em>. Chapman &amp; Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>
<p>Fraley C. and Raftery A. E. (2002) Model-based clustering, discriminant analysis and density estimation, <em>Journal of the American Statistical Association</em>, 97/458, pp. 611-631.
</p>
<p>C. Fraley and A. E. Raftery (2007) Bayesian regularization for normal mixture estimation and model-based clustering. <em>Journal of Classification</em>, 24, 155-181.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.Mclust">summary.Mclust</a></code>, 
<code><a href="#topic+plot.Mclust">plot.Mclust</a></code>, 
<code><a href="#topic+priorControl">priorControl</a></code>, 
<code><a href="#topic+emControl">emControl</a></code>, 
<code><a href="#topic+hc">hc</a></code>,
<code><a href="#topic+mclustBIC">mclustBIC</a></code>, 
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod1 &lt;- Mclust(iris[,1:4])
summary(mod1)

mod2 &lt;- Mclust(iris[,1:4], G = 3)
summary(mod2, parameters = TRUE)

# Using prior
mod3 &lt;- Mclust(iris[,1:4], prior = priorControl())
summary(mod3)

mod4 &lt;- Mclust(iris[,1:4], prior = priorControl(functionName="defaultPrior", shrinkage=0.1))
summary(mod4)

# Clustering of faithful data with some artificial noise added 
nNoise &lt;- 100
set.seed(0) # to make it reproducible
Noise &lt;- apply(faithful, 2, function(x) 
              runif(nNoise, min = min(x)-.1, max = max(x)+.1))
data &lt;- rbind(faithful, Noise)
plot(faithful)
points(Noise, pch = 20, cex = 0.5, col = "lightgrey")
set.seed(0)
NoiseInit &lt;- sample(c(TRUE,FALSE), size = nrow(faithful)+nNoise, 
          replace = TRUE, prob = c(3,1)/4)
mod5 &lt;- Mclust(data, initialization = list(noise = NoiseInit))
summary(mod5, parameter = TRUE)
plot(mod5, what = "classification")
</code></pre>

<hr>
<h2 id='mclust-deprecated'>Deprecated Functions in mclust package</h2><span id='topic+cv.MclustDA'></span><span id='topic+cv1EMtrain'></span><span id='topic+bicEMtrain'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of the <span class="pkg">mclust</span>
package only, and may be removed eventually. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.MclustDA(...)
cv1EMtrain(data, labels, modelNames=NULL)
bicEMtrain(data, labels, modelNames=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclust-deprecated_+3A_...">...</code></td>
<td>
<p>pass arguments down.</p>
</td></tr>
<tr><td><code id="mclust-deprecated_+3A_data">data</code></td>
<td>
<p>A numeric vector or matrix of observations.</p>
</td></tr>
<tr><td><code id="mclust-deprecated_+3A_labels">labels</code></td>
<td>
<p>Labels for each element or row in the dataset.</p>
</td></tr>
<tr><td><code id="mclust-deprecated_+3A_modelnames">modelNames</code></td>
<td>
<p>Vector of model names that should be tested.
The default is to select all available model names.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+deprecated">deprecated</a></code></p>

<hr>
<h2 id='mclust-internal'>Internal MCLUST functions</h2><span id='topic+pickBIC'></span><span id='topic+bicFill'></span><span id='topic+grid1'></span><span id='topic+grid2'></span><span id='topic+mvn2plot'></span><span id='topic+vecnorm'></span><span id='topic+traceW'></span><span id='topic+qclass'></span><span id='topic+unchol'></span><span id='topic+shapeO'></span><span id='topic+orth2'></span><span id='topic+charconv'></span><span id='topic++5B.mclustBIC'></span><span id='topic+checkModelName'></span><span id='topic+balancedFolds'></span><span id='topic+permuteRows'></span><span id='topic+projpar.MclustDR'></span><span id='topic+projdir.MclustDR'></span><span id='topic+ellipse'></span><span id='topic+eigen.decomp'></span><span id='topic+getParameters.MclustDA'></span><span id='topic+as.Mclust'></span><span id='topic+as.Mclust.default'></span><span id='topic+as.Mclust.densityMclust'></span><span id='topic+as.densityMclust'></span><span id='topic+as.densityMclust.default'></span><span id='topic+as.densityMclust.Mclust'></span>

<h3>Description</h3>

<p>Internal functions not intended to be called directly by users.
</p>

<hr>
<h2 id='mclust.options'>Default values for use with MCLUST package</h2><span id='topic+mclust.options'></span>

<h3>Description</h3>

<p>Set or retrieve default values for use with MCLUST package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclust.options(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclust.options_+3A_...">...</code></td>
<td>
<p>one or more arguments provided in the <code>name = value</code> form, or no argument at all may be given. <br />
Available arguments are described in the Details section below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mclust.options()</code> is provided for assigning or retrieving default values used by various functions in <code>MCLUST</code>.<br />
</p>
<p>Available options are:
</p>

<dl>
<dt><code>emModelNames</code></dt><dd>
<p>A vector of 3-character strings that are associated with multivariate 
models for which EM estimation is available in MCLUST. <br />
The current default is all of the multivariate mixture models
supported in MCLUST.
The help file for <code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the 
available models.
</p>
</dd>
<dt><code>hcModelName</code></dt><dd>
<p>A character string specifying the multivariate model to be used in model-based agglomerative hierarchical clustering for initialization of EM algorithm.<br />
The available models are the following:
</p>

<dl>
<dt><code>"EII"</code></dt><dd><p>spherical, equal volume;</p>
</dd>
<dt><code>"EEE"</code></dt><dd><p>ellipsoidal, equal volume, shape, and orientation;</p>
</dd>
<dt><code>"VII"</code></dt><dd><p>spherical, unequal volume;</p>
</dd>
<dt><code>"VVV"</code></dt><dd><p>ellipsoidal, varying volume, shape, and orientation (default).</p>
</dd>
</dl>

</dd>
<dt><code>hcUse</code></dt><dd>
<p>A character string specifying the type of input variables/transformation to be used in model-based agglomerative hierarchical clustering for initialization of EM algorithm.<br />
Possible values are:
</p>

<dl>
<dt><code>"VARS"</code></dt><dd><p>original variables;</p>
</dd>
<dt><code>"STD"</code></dt><dd><p>standardized variables (centered and scaled);</p>
</dd>
<dt><code>"SPH"</code></dt><dd><p>sphered variables (centered, scaled and uncorrelated)  
computed using SVD;</p>
</dd>
<dt><code>"PCS"</code></dt><dd><p>principal components computed using SVD on centered 
variables (i.e. using the covariance matrix);</p>
</dd>
<dt><code>"PCR"</code></dt><dd><p>principal components computed using SVD on standardized 
(center and scaled) variables (i.e. using the correlation matrix);</p>
</dd>
<dt><code>"SVD"</code></dt><dd><p>scaled SVD transformation (default);</p>
</dd>
<dt><code>"RND"</code></dt><dd><p>no transformation is applied but a random hierarchical structure is returned (see <code><a href="#topic+hcRandomPairs">hcRandomPairs</a></code>).</p>
</dd>
</dl>

<p>For further details see Scrucca and Raftery (2015), Scrucca et al. (2016).
</p>
</dd>
<dt><code>subset</code></dt><dd>
<p>A value specifying the maximal sample size to be used in the model-based 
hierarchical clustering to start the EM algorithm. 
If data sample size exceeds this value, a random sample is drawn of size
specified by <code>subset</code>.
</p>
</dd>
<dt><code>fillEllipses</code></dt><dd>
<p>A logical value specifying whether or not to fill with transparent
colors ellipses corresponding to the within-cluster covariances in case
of <code>"classification"</code> plot for <code>'Mclust'</code> objects, or
<code>"scatterplot"</code> graphs for <code>'MclustDA'</code> objects. 
</p>
</dd>
<dt><code>bicPlotSymbols</code></dt><dd>
<p>A vector whose entries correspond to graphics symbols for plotting the 
BIC values output from <code><a href="#topic+Mclust">Mclust</a></code> and <code><a href="#topic+mclustBIC">mclustBIC</a></code>. 
These are displayed in the legend which appears at the lower right
of the BIC plots.
</p>
</dd>
<dt><code>bicPlotColors</code></dt><dd>
<p>A vector whose entries correspond to colors for plotting the 
BIC curves from output from <code><a href="#topic+Mclust">Mclust</a></code> and
<code><a href="#topic+mclustBIC">mclustBIC</a></code>. 
These are displayed in the legend which appears at the lower right
of the BIC plots.
</p>
</dd>
<dt><code>classPlotSymbols</code></dt><dd>
<p>A vector whose entries are either integers corresponding to graphics 
symbols or single characters for indicating classifications when
plotting data. Classes are assigned symbols in the given order. 
</p>
</dd>
<dt><code>classPlotColors</code></dt><dd>
<p>A vector whose entries correspond to colors for indicating 
classifications when plotting data. Classes are assigned colors 
in the given order. 
</p>
</dd>
<dt><code>warn</code></dt><dd>
<p>A logical value indicating whether or not to issue certain warnings.
Most of these warnings have to do with situations in which 
singularities are encountered. 
The default is <code>warn = FALSE</code>. 
</p>
</dd>
</dl>

<p>The parameter values set via a call to this function will remain in effect for the rest of the session, affecting the subsequent behaviour of the functions for which the given parameters are relevant.
</p>


<h3>Value</h3>

<p>If the argument list is empty the function returns the current list of values.  
If the argument list is not empty, the returned list is invisible.
</p>


<h3>References</h3>

<p>Scrucca L. and Raftery A. E. (2015) Improved initialisation of model-based clustering using Gaussian hierarchical partitions. <em>Advances in Data Analysis and Classification</em>, 9/4, pp. 447-460.
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>, 
<code><a href="#topic+MclustDA">MclustDA</a></code>, 
<code><a href="#topic+densityMclust">densityMclust</a></code>, 
<code><a href="#topic+emControl">emControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>opt &lt;- mclust.options() # save default values
irisBIC &lt;- mclustBIC(iris[,-5])
summary(irisBIC, iris[,-5])

mclust.options(emModelNames = c("EII", "EEI", "EEE"))
irisBIC &lt;- mclustBIC(iris[,-5])
summary(irisBIC, iris[,-5])

mclust.options(opt)    # restore default values
mclust.options()

oldpar &lt;- par(mfrow = c(2,1), no.readonly = TRUE)
n &lt;- with(mclust.options(), 
          max(sapply(list(bicPlotSymbols, bicPlotColors),length)))
plot(seq(n), rep(1,n), ylab = "", xlab = "", yaxt = "n", 
     pch = mclust.options("bicPlotSymbols"), 
     col = mclust.options("bicPlotColors"))
title("mclust.options(\"bicPlotSymbols\") \n mclust.options(\"bicPlotColors\")")
n &lt;- with(mclust.options(), 
          max(sapply(list(classPlotSymbols, classPlotColors),length)))
plot(seq(n), rep(1,n), ylab = "", xlab = "", yaxt = "n", 
     pch = mclust.options("classPlotSymbols"), 
     col = mclust.options("classPlotColors"))
title("mclust.options(\"classPlotSymbols\") \n mclust.options(\"classPlotColors\")")
par(oldpar)
</code></pre>

<hr>
<h2 id='mclust1Dplot'>
Plot one-dimensional data modeled by an MVN mixture.
</h2><span id='topic+mclust1Dplot'></span>

<h3>Description</h3>

<p>Plot one-dimensional data given parameters of an MVN mixture model 
for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclust1Dplot(data, parameters = NULL, z = NULL, 
             classification = NULL, truth = NULL, uncertainty = NULL, 
             what = c("classification", "density", "error", "uncertainty"),
             symbols = NULL, colors = NULL, ngrid = length(data), 
             xlab = NULL, ylab = NULL, 
             xlim = NULL, ylim = NULL,
             cex = 1, main = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclust1Dplot_+3A_data">data</code></td>
<td>

<p>A numeric vector of observations.
Categorical variables are not allowed.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_parameters">parameters</code></td>
<td>

<p>A named list giving the parameters of an <em>MCLUST</em> model,
used to produce superimposing ellipses on the plot.
The relevant components are as follows:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
There should one more mixing proportion than the number of 
Gaussian components if the mixture model includes 
a Poisson noise term.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="mclust1Dplot_+3A_z">z</code></td>
<td>

<p>A matrix in which the <code>[i,k]</code>th entry gives the
probability of observation <em>i</em> belonging to the <em>k</em>th class.
Used to compute <code>classification</code> and
<code>uncertainty</code> if those arguments aren't available.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector representing a classification of
observations (rows) of <code>data</code>. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_truth">truth</code></td>
<td>

<p>A numeric or character vector giving a known
classification of each data point.
If <code>classification</code> or <code>z</code> is also present,
this is used for displaying classification errors.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_uncertainty">uncertainty</code></td>
<td>

<p>A numeric vector of values in <em>(0,1)</em> giving the
uncertainty of each data point. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_what">what</code></td>
<td>

<p>Choose from one of the following options: <code>"classification"</code>
(default), <code>"density"</code>, <code>"error"</code>, <code>"uncertainty"</code>.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to
each unique class <code>classification</code>. Elements in <code>symbols</code>
correspond to classes in <code>classification</code> in order of
appearance in the observations (the order used by the 
function <code>unique</code>). The default is to use a single plotting
symbol <em>|</em>. Classes are delineated by showing them in separate
lines above the whole of the data.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the observations 
(the order used by the function <code>unique</code>).
The default is given is <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_ngrid">ngrid</code></td>
<td>

<p>Number of grid points to use for density computation over the interval
spanned by the data. The default is the length of the data set.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_xlab">xlab</code>, <code id="mclust1Dplot_+3A_ylab">ylab</code></td>
<td>

<p>An argument specifying a label for the axes.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_xlim">xlim</code>, <code id="mclust1Dplot_+3A_ylim">ylim</code></td>
<td>

<p>An argument specifying bounds of the plot.
This may be useful for when comparing plots.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_cex">cex</code></td>
<td>

<p>An argument specifying the size of the plotting symbols. 
The default value is 1.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_main">main</code></td>
<td>

<p>A logical variable or <code>NULL</code> indicating whether or not to add a title
to the plot identifying the dimensions used.
</p>
</td></tr>
<tr><td><code id="mclust1Dplot_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing location of the mixture components, classification, uncertainty, density and/or classification errors. Points in the different classes are shown in separated levels above the whole of the data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclust2Dplot">mclust2Dplot</a></code>,
<code><a href="#topic+clPairs">clPairs</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 250 ## create artificial data
set.seed(1)
y &lt;- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5))
yclass &lt;- c(rep(1,n), rep(2,n), rep(3,n))

yModel &lt;- Mclust(y)

mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z, 
             what = "classification")

mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z, 
             what = "error", truth = yclass)

mclust1Dplot(y, parameters = yModel$parameters, z = yModel$z, 
             what = "density")

mclust1Dplot(y, z = yModel$z, parameters = yModel$parameters,
            what = "uncertainty")


</code></pre>

<hr>
<h2 id='mclust2Dplot'>Plot two-dimensional data modelled by an MVN mixture</h2><span id='topic+mclust2Dplot'></span>

<h3>Description</h3>

<p>Plot two-dimensional data given parameters of an MVN mixture model 
for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclust2Dplot(data, parameters = NULL, z = NULL,
             classification = NULL, truth = NULL, uncertainty = NULL,
             what = c("classification", "uncertainty", "error"), 
             addEllipses = TRUE, fillEllipses = mclust.options("fillEllipses"),
             symbols = NULL, colors = NULL, 
             xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,
             scale = FALSE, cex  = 1, PCH = ".",
             main = FALSE, swapAxes = FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclust2Dplot_+3A_data">data</code></td>
<td>

<p>A numeric matrix or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables. 
In this case the data are two dimensional, so there are two columns.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_parameters">parameters</code></td>
<td>

<p>A named list giving the parameters of an <em>MCLUST</em> model, 
used to produce superimposing ellipses on the plot. 
The relevant components are as follows:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>Mixing proportions for the components of the mixture. 
There should one more mixing proportion than the number of 
Gaussian components if the mixture model includes 
a Poisson noise term.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="mclust2Dplot_+3A_z">z</code></td>
<td>

<p>A matrix in which the <code>[i,k]</code>th entry gives the
probability of observation <em>i</em> belonging to the <em>k</em>th class. 
Used to compute <code>classification</code> and
<code>uncertainty</code> if those arguments aren't available.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector representing a classification of
observations (rows) of <code>data</code>. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_truth">truth</code></td>
<td>

<p>A numeric or character vector giving a known
classification of each data point.
If <code>classification</code>
or <code>z</code> is also present, 
this is used for displaying classification errors.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_uncertainty">uncertainty</code></td>
<td>

<p>A numeric vector of values in <em>(0,1)</em> giving the
uncertainty of each data point. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_what">what</code></td>
<td>

<p>Choose from one of the following three options: <code>"classification"</code>
(default), <code>"error"</code>, <code>"uncertainty"</code>. 
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_addellipses">addEllipses</code></td>
<td>

<p>A logical indicating whether or not to add ellipses with axes 
corresponding to the within-cluster covariances.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_fillellipses">fillEllipses</code></td>
<td>

<p>A logical specifying whether or not to fill ellipses with transparent
colors when <code>addEllipses = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given is <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_xlim">xlim</code>, <code id="mclust2Dplot_+3A_ylim">ylim</code></td>
<td>

<p>Optional argument specifying bounds for the ordinate, abscissa of the plot.
This may be useful for when comparing plots.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_xlab">xlab</code>, <code id="mclust2Dplot_+3A_ylab">ylab</code></td>
<td>

<p>Optional argument specifying labels for the x-axis and y-axis.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_scale">scale</code></td>
<td>

<p>A logical variable indicating whether or not the two chosen
dimensions should be plotted on the same scale, and
thus preserve the shape of the distribution.
Default: <code>scale=FALSE</code> 
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_cex">cex</code></td>
<td>

<p>An argument specifying the size of the plotting symbols. 
The default value is 1.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_pch">PCH</code></td>
<td>

<p>An argument specifying the symbol to be used when a classificatiion
has not been specified for the data. The default value is a small dot &quot;.&quot;.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_main">main</code></td>
<td>

<p>A logical variable or <code>NULL</code> indicating whether or not to add a title 
to the plot identifying the dimensions used.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_swapaxes">swapAxes</code></td>
<td>

<p>A logical variable indicating whether or not the axes should be swapped
for the plot.
</p>
</td></tr>
<tr><td><code id="mclust2Dplot_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the data, together with the location of the mixture components, classification, uncertainty, and/or classification errors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+surfacePlot">surfacePlot</a></code>,
<code><a href="#topic+clPairs">clPairs</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
faithfulModel &lt;- Mclust(faithful)

mclust2Dplot(faithful, parameters=faithfulModel$parameters, 
             z=faithfulModel$z, what = "classification", main = TRUE)

mclust2Dplot(faithful, parameters=faithfulModel$parameters, 
             z=faithfulModel$z, what = "uncertainty", main = TRUE)

</code></pre>

<hr>
<h2 id='mclustBIC'>BIC for Model-Based Clustering</h2><span id='topic+mclustBIC'></span><span id='topic+EMclust'></span><span id='topic+print.mclustBIC'></span>

<h3>Description</h3>

<p>BIC for parameterized Gaussian mixture models fitted by EM algorithm initialized by model-based hierarchical clustering.</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustBIC(data, G = NULL, modelNames = NULL, 
          prior = NULL, control = emControl(), 
          initialization = list(hcPairs = NULL, 
                                subset = NULL, 
                                noise = NULL), 
          Vinv = NULL, warn = mclust.options("warn"), 
          x = NULL, verbose = interactive(), 
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustBIC_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_g">G</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components
(clusters) for which the BIC is to be calculated. 
The default is <code>G=1:9</code>, unless the argument <code>x</code> is specified, 
in which case the default is taken from the values associated 
with <code>x</code>. 
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of character strings indicating the models to be fitted 
in the EM phase of clustering. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
The default is:
</p>

<dl>
<dt><code>c("E", "V")</code></dt><dd><p>for univariate data</p>
</dd>
<dt><code>mclust.options("emModelNames")</code></dt><dd><p>for multivariate data (n &gt; d)</p>
</dd>
<dt><code>c("EII", "VII", "EEI", "EVI", "VEI", "VVI")</code></dt><dd><p>the spherical and diagonal models for multivariate data (n &lt;= d)</p>
</dd>
</dl>

<p>unless the argument <code>x</code> is specified, in which case
the default is taken from the values associated with <code>x</code>. 
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_prior">prior</code></td>
<td>

<p>The default assumes no prior, but this argument allows specification of a 
conjugate prior on the means and variances through the function 
<code>priorControl</code>.
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>. 
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_initialization">initialization</code></td>
<td>

<p>A list containing zero or more of the following components:
</p>

<dl>
<dt><code>hcPairs</code></dt><dd>
<p>A matrix of merge pairs for hierarchical clustering such as produced
by function <code><a href="#topic+hc">hc</a></code>. <br />
For multivariate data, the default is to compute a hierarchical 
agglomerative clustering tree by applying function <code><a href="#topic+hc">hc</a></code> with 
model specified by <code>mclust.options("hcModelName")</code>, and
data transformation set by <code>mclust.options("hcUse")</code>.<br />
All the input or a subset as indicated by the <code>subset</code> argument is 
used for initial clustering.<br />
The hierarchical clustering results are then used to start the EM
algorithm from a given partition.<br />
For univariate data, the default is to use quantiles to start the EM
algorithm. However, hierarchical clustering could also be used by 
calling <code><a href="#topic+hc">hc</a></code> with model specified as <code>"V"</code> or <code>"E"</code>.
</p>
</dd>
<dt><code>subset</code></dt><dd>
<p>A logical or numeric vector specifying a subset of the data
to be used in the initial hierarchical clustering phase.
By default no subset is used unless the number of observations exceeds 
the value specified by <code>mclust.options("subset")</code>. 
The <code>subset</code> argument is ignored if <code>hcPairs</code> are provided.
Note that to guarantee exact reproducibility of results a seed must be 
specified (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).
</p>
</dd>
<dt><code>noise</code></dt><dd>
<p>A logical or numeric vector indicating an initial guess as to
which observations are noise in the data. If numeric the entries
should correspond to row indexes of the data. If supplied, a noise
term will be added to the model in the estimation.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="mclustBIC_+3A_vinv">Vinv</code></td>
<td>

<p>An estimate of the reciprocal hypervolume of the data region.
The default is determined by applying function <code>hypvol</code> to the data. 
Used only if an initial guess as to which observations are noise 
is supplied.
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when
estimation fails. 
The default is controlled by <code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_x">x</code></td>
<td>

<p>An object of class <code>'mclustBIC'</code>. If supplied, <code>mclustBIC</code>
will use the settings in <code>x</code> to produce another object of
class <code>'mclustBIC'</code>, but with <code>G</code> and <code>modelNames</code>
as specified in the arguments. Models that have already been computed
in <code>x</code> are not recomputed. All arguments to <code>mclustBIC</code> 
except <code>data</code>, <code>G</code> and <code>modelName</code> are
ignored and their values are set as specified in the attributes of
<code>x</code>. 
Defaults for <code>G</code> and <code>modelNames</code> are taken from <code>x</code>.
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_verbose">verbose</code></td>
<td>

<p>A logical controlling if a text progress bar is displayed during the
fitting procedure. By default is <code>TRUE</code> if the session is 
interactive, and <code>FALSE</code> otherwise.
</p>
</td></tr>
<tr><td><code id="mclustBIC_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return an object of class <code>'mclustBIC'</code> containing the Bayesian Information
Criterion for the specified mixture models numbers of clusters. 
Auxiliary information returned as attributes.
</p>
<p>The corresponding <code>print</code> method shows the matrix of values and the top models according to the BIC criterion.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.mclustBIC">summary.mclustBIC</a></code>, 
<code><a href="#topic+priorControl">priorControl</a></code>, 
<code><a href="#topic+emControl">emControl</a></code>, 
<code><a href="#topic+mclustModel">mclustModel</a></code>, 
<code><a href="#topic+hc">hc</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisBIC &lt;- mclustBIC(iris[,-5])
irisBIC
plot(irisBIC)


subset &lt;- sample(1:nrow(iris), 100)
irisBIC &lt;- mclustBIC(iris[,-5], initialization=list(subset = subset))
irisBIC
plot(irisBIC)

irisBIC1 &lt;- mclustBIC(iris[,-5], G=seq(from=1,to=9,by=2), 
                    modelNames=c("EII", "EEI", "EEE"))
irisBIC1
plot(irisBIC1)
irisBIC2  &lt;- mclustBIC(iris[,-5], G=seq(from=2,to=8,by=2), 
                       modelNames=c("VII", "VVI", "VVV"), x= irisBIC1)
irisBIC2
plot(irisBIC2)


nNoise &lt;- 450
set.seed(0)
poissonNoise &lt;- apply(apply( iris[,-5], 2, range), 2, function(x, n) 
                      runif(n, min = x[1]-.1, max = x[2]+.1), n = nNoise)
set.seed(0)
noiseInit &lt;- sample(c(TRUE,FALSE),size=nrow(iris)+nNoise,replace=TRUE,
                    prob=c(3,1))
irisNdata &lt;- rbind(iris[,-5], poissonNoise)
irisNbic &lt;- mclustBIC(data = irisNdata, G = 1:5,
                      initialization = list(noise = noiseInit))
irisNbic
plot(irisNbic)
</code></pre>

<hr>
<h2 id='mclustBICupdate'>Update BIC values for parameterized Gaussian mixture models</h2><span id='topic+mclustBICupdate'></span>

<h3>Description</h3>

<p>Update the BIC (Bayesian Information Criterion) for parameterized Gaussian 
mixture models by taking the best from BIC results as returned by <code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustBICupdate(BIC, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustBICupdate_+3A_bic">BIC</code></td>
<td>
<p>Object of class <code>'mclustBIC'</code> containing the 
BIC values as returned by a call to <code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>
</td></tr>
<tr><td><code id="mclustBICupdate_+3A_...">...</code></td>
<td>
<p>Further objects of class <code>'mclustBIC'</code> to be merged.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>'mclustBIC'</code> containing the best values obtained from
merging the input arguments. Attributes are also updated according to the best
BIC found, so calling <code><a href="#topic+Mclust">Mclust</a></code> on the resulting ouput will return
the corresponding best model (see example).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+Mclust">Mclust</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(galaxies, package = "MASS") 
galaxies &lt;- galaxies / 1000

# use several random starting points
BIC &lt;- NULL
for(j in 1:100)
{
  rBIC &lt;- mclustBIC(galaxies, verbose = FALSE,
                    initialization = list(hcPairs = hcRandomPairs(galaxies)))
  BIC &lt;- mclustBICupdate(BIC, rBIC)
}
pickBIC(BIC)
plot(BIC)

mod &lt;- Mclust(galaxies, x = BIC)
summary(mod)

</code></pre>

<hr>
<h2 id='MclustBootstrap'>Resampling-based Inference for Gaussian finite mixture models</h2><span id='topic+MclustBootstrap'></span><span id='topic+print.MclustBootstrap'></span>

<h3>Description</h3>

<p>Bootstrap or jackknife estimation of standard errors and percentile bootstrap confidence intervals for the parameters of a Gaussian mixture model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MclustBootstrap(object, nboot = 999, type = c("bs", "wlbs", "pb", "jk"),
                max.nonfit = 10*nboot, verbose = interactive(), 
                ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MclustBootstrap_+3A_object">object</code></td>
<td>
<p>An object of class <code>'Mclust'</code> or <code>'densityMclust'</code> providing an estimated Gaussian mixture model.</p>
</td></tr>
<tr><td><code id="MclustBootstrap_+3A_nboot">nboot</code></td>
<td>
<p>The number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="MclustBootstrap_+3A_type">type</code></td>
<td>
<p>A character string specifying the type of resampling to use:
</p>

<dl>
<dt><code>"bs"</code></dt><dd><p>nonparametric bootstrap</p>
</dd>
<dt><code>"wlbs"</code></dt><dd><p>weighted likelihood bootstrap</p>
</dd>
<dt><code>"pb"</code></dt><dd><p>parametric bootstrap</p>
</dd>
<dt><code>"jk"</code></dt><dd><p>jackknife</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="MclustBootstrap_+3A_max.nonfit">max.nonfit</code></td>
<td>
<p>The maximum number of non-estimable models allowed.</p>
</td></tr>
<tr><td><code id="MclustBootstrap_+3A_verbose">verbose</code></td>
<td>
<p>A logical controlling if a text progress bar is displayed during the resampling procedure. By default is <code>TRUE</code> if the session is interactive, and <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="MclustBootstrap_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a fitted Gaussian mixture model with <code>object$G</code> mixture components and covariances parameterisation <code>object$modelName</code>, this function returns either the bootstrap distribution or the jackknife distribution of mixture parameters. In the former case, the nonparametric bootstrap or the weighted likelihood bootstrap approach could be used, so the the bootstrap procedure generates <code>nboot</code> bootstrap samples of the same size as the original data by resampling with replacement from the observed data. In the jackknife case, the procedure considers all the samples obtained by omitting one observation at time.
</p>
<p>The resulting resampling distribution can then be used to obtain standard errors and percentile confidence intervals by the use of <code><a href="#topic+summary.MclustBootstrap">summary.MclustBootstrap</a></code> function.</p>


<h3>Value</h3>

<p>An object of class <code>'MclustBootstrap'</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>The number of observations in the data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The dimension of the data.</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>A value specifying the number of mixture components.</p>
</td></tr> 
<tr><td><code>modelName</code></td>
<td>
<p>A character string specifying the mixture model covariances 
parameterisation (see <code><a href="#topic+mclustModelNames">mclustModelNames</a></code>).</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>A list of estimated parameters for the mixture components with the following components:  
</p>

<dl>
<dt><code>pro</code></dt><dd><p>a vector of mixing proportions.</p>
</dd>
<dt><code>mean</code></dt><dd><p>a matrix of means for each component.</p>
</dd>
<dt><code>variance</code></dt><dd><p>an array of covariance matrices for each component.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>nboot</code></td>
<td>
<p>The number of bootstrap replications if <code>type = "bs"</code> or <code>type = "wlbs"</code>. The sample size if <code>type = "jk"</code>.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>The type of resampling approach used.</p>
</td></tr>
<tr><td><code>nonfit</code></td>
<td>
<p>The number of resamples that did not convergence during the procedure.</p>
</td></tr>
<tr><td><code>pro</code></td>
<td>
<p>A matrix of dimension (<code>nboot</code> x <code>G</code>) containing the 
bootstrap distribution for the mixing proportion.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>An array of dimension (<code>nboot</code> x <code>d</code> x <code>G</code>), 
where <code>d</code> is the dimension of the data, containing the bootstrap 
distribution for the component means.</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>An array of dimension (<code>nboot</code> x <code>d</code> x <code>d</code> x 
<code>G</code>), where <code>d</code> is the dimension of the data, containing the 
bootstrap distribution for the component covariances.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Davison, A. and Hinkley, D. (1997) <em>Bootstrap Methods and Their Applications</em>. Cambridge University Press.
</p>
<p>McLachlan, G.J. and Peel, D. (2000) <em>Finite Mixture Models</em>. Wiley.
</p>
<p>O'Hagan A., Murphy T. B., Gormley I. C. and Scrucca L. (2015) On Estimation of Parameter Uncertainty in Model-Based Clustering. Submitted to <em>Computational Statistics</em>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.MclustBootstrap">summary.MclustBootstrap</a></code>, <code><a href="#topic+plot.MclustBootstrap">plot.MclustBootstrap</a></code>, <code><a href="#topic+Mclust">Mclust</a></code>, <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(diabetes)
X &lt;- diabetes[,-1]
modClust &lt;- Mclust(X) 
bootClust &lt;- MclustBootstrap(modClust)
summary(bootClust, what = "se")
summary(bootClust, what = "ci")

data(acidity)
modDens &lt;- densityMclust(acidity, plot = FALSE)
modDens &lt;- MclustBootstrap(modDens)
summary(modDens, what = "se")
summary(modDens, what = "ci")

</code></pre>

<hr>
<h2 id='mclustBootstrapLRT'>Bootstrap Likelihood Ratio Test for the Number of Mixture Components</h2><span id='topic+mclustBootstrapLRT'></span><span id='topic+print.mclustBootstrapLRT'></span><span id='topic+plot.mclustBootstrapLRT'></span>

<h3>Description</h3>

<p>Perform the likelihood ratio test (LRT) for assessing the number of mixture components in a specific finite mixture model parameterisation. The observed significance is approximated by using the (parametric) bootstrap for the likelihood ratio test statistic (LRTS).</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustBootstrapLRT(data, modelName = NULL, nboot = 999, level = 0.05, maxG = NULL, 
                   verbose = interactive(), ...)
                   
## S3 method for class 'mclustBootstrapLRT'
print(x, ...)

## S3 method for class 'mclustBootstrapLRT'
plot(x, G = 1, hist.col = "grey", hist.border = "lightgrey", breaks = "Scott", 
    col = "forestgreen", lwd = 2, lty = 3, main = NULL, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustBootstrapLRT_+3A_data">data</code></td>
<td>
<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_modelname">modelName</code></td>
<td>
<p>A character string indicating the mixture model to be fitted. 
The help file for <code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_nboot">nboot</code></td>
<td>
<p>The number of bootstrap replications to use (by default 999).</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_level">level</code></td>
<td>
<p>The significance level to be used to terminate the sequential bootstrap procedure.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_maxg">maxG</code></td>
<td>
<p>The maximum number of mixture components <code class="reqn">G</code> to test. If not provided
the procedure is stopped when a test is not significant at the specified <code>level</code>.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_verbose">verbose</code></td>
<td>
<p>A logical controlling if a text progress bar is displayed during the bootstrap procedure. By default is <code>TRUE</code> if the session is interactive, and <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. In particular, see the optional arguments in  <code><a href="#topic+mclustBIC">mclustBIC</a></code>.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_x">x</code></td>
<td>
<p>An <code>'mclustBootstrapLRT'</code> object.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_g">G</code></td>
<td>
<p>A value specifying the number of components for which to plot the 
bootstrap distribution.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_hist.col">hist.col</code></td>
<td>
<p>The colour to be used to fill the bars of the histogram.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_hist.border">hist.border</code></td>
<td>
<p>The color of the border around the bars of the histogram.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_breaks">breaks</code></td>
<td>
<p>See the argument in function <code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_col">col</code>, <code id="mclustBootstrapLRT_+3A_lwd">lwd</code>, <code id="mclustBootstrapLRT_+3A_lty">lty</code></td>
<td>
<p>The color, line width and line type to be used to represent the observed LRT statistic.</p>
</td></tr>
<tr><td><code id="mclustBootstrapLRT_+3A_main">main</code></td>
<td>
<p>The title for the graph.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implemented algorithm for computing the LRT observed significance using the bootstrap is the following.
Let <code class="reqn">G_0</code> be the number of mixture components under the null hypothesis versus <code class="reqn">G_1 = G_0+1</code> under the alternative. Bootstrap samples are drawn by simulating data under the null hypothesis. Then, the p-value may be approximated using eq. (13) on McLachlan and Rathnayake (2014). Equivalently, using the notation of Davison and Hinkley (1997) it may be computed as
</p>
<p style="text-align: center;"><code class="reqn">\textnormal{p-value} = \frac{1 + \#\{LRT^*_b \ge LRTS_{obs}\}}{B+1}</code>
</p>

<p>where <br />
<code class="reqn">B</code> = number of bootstrap samples <br />
<code class="reqn">LRT_{obs}</code> = LRTS computed on the observed data<br />
<code class="reqn">LRT^*_b</code> = LRTS computed on the <code class="reqn">b</code>th bootstrap sample.
</p>


<h3>Value</h3>

<p>An object of class <code>'mclustBootstrapLRT'</code> with the following components:
</p>
<table>
<tr><td><code>G</code></td>
<td>
<p>A vector of number of components tested under the null hypothesis.</p>
</td></tr> 
<tr><td><code>modelName</code></td>
<td>
<p>A character string specifying the mixture model as provided 
in the function call (see above).</p>
</td></tr>
<tr><td><code>obs</code></td>
<td>
<p>The observed values of the LRTS.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>A matrix of dimension <code>nboot</code> x the number of components tested 
containing the bootstrap values of LRTS.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>A vector of p-values.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Davison, A. and Hinkley, D. (1997) <em>Bootstrap Methods and Their Applications</em>. Cambridge University Press.
</p>
<p>McLachlan G.J. (1987) On bootstrapping the likelihood ratio test statistic for the number of components in a normal mixture. <em>Applied Statistics</em>, 36, 318-324.
</p>
<p>McLachlan, G.J. and Peel, D. (2000) <em>Finite Mixture Models</em>. Wiley.
</p>
<p>McLachlan, G.J. and Rathnayake, S. (2014) On the number of components in a Gaussian mixture model. <em>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</em>, 4(5), pp. 341-355.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>, <code><a href="#topic+mclustICL">mclustICL</a></code>, <code><a href="#topic+Mclust">Mclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(faithful)
faithful.boot = mclustBootstrapLRT(faithful, model = "VVV")
faithful.boot
plot(faithful.boot, G = 1)
plot(faithful.boot, G = 2)

</code></pre>

<hr>
<h2 id='MclustDA'>MclustDA discriminant analysis</h2><span id='topic+MclustDA'></span><span id='topic+print.MclustDA'></span>

<h3>Description</h3>

<p>Discriminant analysis based on Gaussian finite mixture modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MclustDA(data, class, G = NULL, modelNames = NULL, 
         modelType = c("MclustDA", "EDDA"), 
         prior = NULL, 
         control = emControl(), 
         initialization = NULL, 
         warn = mclust.options("warn"), 
         verbose = interactive(),
         ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MclustDA_+3A_data">data</code></td>
<td>

<p>A data frame or matrix giving the training data.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_class">class</code></td>
<td>

<p>A vector giving the known class labels (either a numerical value or 
a character string) for the observations in the training data.</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_g">G</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components
(clusters) for which the BIC is to be calculated within each class. 
The default is <code>G = 1:5</code>.<br />
A different set of mixture components for each class can be specified
by providing this argument with a list of integers for each class. 
See the examples below.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of character strings indicating the models to be fitted 
by EM within each class (see the description in 
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>).
A different set of mixture models for each class can be specified
by providing this argument with a list of character strings.
See the examples below.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_modeltype">modelType</code></td>
<td>

<p>A character string specifying whether the models given in
<code>modelNames</code> should fit a different number of mixture 
components and covariance structures for each class 
(<code>"MclustDA"</code>, the default) or should be constrained 
to have a single component for each class with the same covariance 
structure among classes (<code>"EDDA"</code>).
See Details section and the examples below.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_prior">prior</code></td>
<td>

<p>The default assumes no prior, but this argument allows specification of a 
conjugate prior on the means and variances through the function 
<code><a href="#topic+priorControl">priorControl</a></code>.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>. 
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_initialization">initialization</code></td>
<td>

<p>A list containing zero or more of the following components:
</p>

<dl>
<dt><code>hcPairs</code></dt><dd>
<p>A matrix of merge pairs for hierarchical clustering such as produced
by function <code>hc</code>. The default is to compute a hierarchical
clustering tree by applying function <code>hc</code> with
<code>modelName = "E"</code> to univariate data and
<code>modelName = "VVV"</code> to multivariate data or a
subset as indicated by the <code>subset</code> argument. 
The hierarchical clustering results are used as starting values 
for EM.</p>
</dd>
<dt><code>subset</code></dt><dd>
<p>A logical or numeric vector specifying a subset of the data
to be used in the initial hierarchical clustering phase.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="MclustDA_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when
estimation fails. 
The default is controlled by <code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="MclustDA_+3A_verbose">verbose</code></td>
<td>

<p>A logical controlling if a text progress bar is displayed during the
fitting procedure. By default is <code>TRUE</code> if the session is 
interactive, and <code>FALSE</code> otherwise.
</p>
</td></tr>  
<tr><td><code id="MclustDA_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>"EDDA"</code> method for discriminant analysis is described in Bensmail and Celeux (1996), while <code>"MclustDA"</code> in Fraley and Raftery (2002).
</p>


<h3>Value</h3>

<p>An object of class <code>'MclustDA'</code> providing the optimal (according 
to BIC) mixture model.
</p>
<p>The details of the output components are as follows:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr> 
<tr><td><code>data</code></td>
<td>
<p>The input data matrix.</p>
</td></tr> 
<tr><td><code>class</code></td>
<td>
<p>The input class labels.</p>
</td></tr> 
<tr><td><code>type</code></td>
<td>
<p>A character string specifying the <code>modelType</code> estimated.</p>
</td></tr>
<tr><td><code>models</code></td>
<td>
<p>A list of <code><a href="#topic+Mclust">Mclust</a></code> objects containing information
on fitted model for each class.</p>
</td></tr> 
<tr><td><code>n</code></td>
<td>
<p>The total number of observations in the data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The dimension of the data.</p>
</td></tr>

<tr><td><code>bic</code></td>
<td>
<p>Optimal BIC value.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>Log-likelihood for the selected model.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Number of estimated parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca L., Fraley C., Murphy T. B. and Raftery A. E. (2023) <em>Model-Based Clustering, Classification, and Density Estimation Using mclust in R</em>. Chapman &amp; Hall/CRC, ISBN: 978-1032234953, https://mclust-org.github.io/book/
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>
<p>Fraley C. and Raftery A. E. (2002) Model-based clustering, discriminant analysis and density estimation, <em>Journal of the American Statistical Association</em>, 97/458, pp. 611-631.
</p>
<p>Bensmail, H., and Celeux, G. (1996) Regularized Gaussian Discriminant Analysis Through Eigenvalue Decomposition.<em>Journal of the American Statistical Association</em>, 91, 1743-1748.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.MclustDA">summary.MclustDA</a></code>, 
<code><a href="#topic+plot.MclustDA">plot.MclustDA</a></code>, 
<code><a href="#topic+predict.MclustDA">predict.MclustDA</a></code>, 
<code><a href="#topic+classError">classError</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>odd &lt;- seq(from = 1, to = nrow(iris), by = 2)
even &lt;- odd + 1
X.train &lt;- iris[odd,-5]
Class.train &lt;- iris[odd,5]
X.test &lt;- iris[even,-5]
Class.test &lt;- iris[even,5]

# common EEE covariance structure (which is essentially equivalent to linear discriminant analysis)
irisMclustDA &lt;- MclustDA(X.train, Class.train, modelType = "EDDA", modelNames = "EEE")
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

# common covariance structure selected by BIC
irisMclustDA &lt;- MclustDA(X.train, Class.train, modelType = "EDDA")
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

# general covariance structure selected by BIC
irisMclustDA &lt;- MclustDA(X.train, Class.train)
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

plot(irisMclustDA)
plot(irisMclustDA, dimens = 3:4)
plot(irisMclustDA, dimens = 4)

plot(irisMclustDA, what = "classification")
plot(irisMclustDA, what = "classification", newdata = X.test)
plot(irisMclustDA, what = "classification", dimens = 3:4)
plot(irisMclustDA, what = "classification", newdata = X.test, dimens = 3:4)
plot(irisMclustDA, what = "classification", dimens = 4)
plot(irisMclustDA, what = "classification", dimens = 4, newdata = X.test)

plot(irisMclustDA, what = "train&amp;test", newdata = X.test)
plot(irisMclustDA, what = "train&amp;test", newdata = X.test, dimens = 3:4)
plot(irisMclustDA, what = "train&amp;test", newdata = X.test, dimens = 4)

plot(irisMclustDA, what = "error")
plot(irisMclustDA, what = "error", dimens = 3:4)
plot(irisMclustDA, what = "error", dimens = 4)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test, dimens = 3:4)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test, dimens = 4)


# simulated 1D data
n &lt;- 250 
set.seed(1)
triModal &lt;- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5))
triClass &lt;- c(rep(1,n), rep(2,n), rep(3,n))
odd &lt;- seq(from = 1, to = length(triModal), by = 2)
even &lt;- odd + 1
triMclustDA &lt;- MclustDA(triModal[odd], triClass[odd])
summary(triMclustDA, parameters = TRUE)
summary(triMclustDA, newdata = triModal[even], newclass = triClass[even])
plot(triMclustDA, what = "scatterplot")
plot(triMclustDA, what = "classification")
plot(triMclustDA, what = "classification", newdata = triModal[even])
plot(triMclustDA, what = "train&amp;test", newdata = triModal[even])
plot(triMclustDA, what = "error")
plot(triMclustDA, what = "error", newdata = triModal[even], newclass = triClass[even])

# simulated 2D cross data
data(cross)
odd &lt;- seq(from = 1, to = nrow(cross), by = 2)
even &lt;- odd + 1
crossMclustDA &lt;- MclustDA(cross[odd,-1], cross[odd,1])
summary(crossMclustDA, parameters = TRUE)
summary(crossMclustDA, newdata = cross[even,-1], newclass = cross[even,1])
plot(crossMclustDA, what = "scatterplot")
plot(crossMclustDA, what = "classification")
plot(crossMclustDA, what = "classification", newdata = cross[even,-1])
plot(crossMclustDA, what = "train&amp;test", newdata = cross[even,-1])
plot(crossMclustDA, what = "error")
plot(crossMclustDA, what = "error", newdata =cross[even,-1], newclass = cross[even,1])

</code></pre>

<hr>
<h2 id='MclustDR'>Dimension reduction for model-based clustering and classification</h2><span id='topic+MclustDR'></span><span id='topic+print.MclustDR'></span>

<h3>Description</h3>

<p>A dimension reduction method for visualizing the clustering or classification structure obtained from a finite mixture of Gaussian densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MclustDR(object, lambda = 1, normalized = TRUE, Sigma,
         tol = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MclustDR_+3A_object">object</code></td>
<td>
<p>An object of class <code>'Mclust'</code> or <code>'MclustDA'</code> 
resulting from a call to, respectively, <code><a href="#topic+Mclust">Mclust</a></code> or 
<code><a href="#topic+MclustDA">MclustDA</a></code>.</p>
</td></tr>
<tr><td><code id="MclustDR_+3A_lambda">lambda</code></td>
<td>
<p>A tuning parameter in the range [0,1] as described in 
Scrucca (2014). The directions that mostly separate the estimated clusters 
or classes are recovered using the default value 1. Users can set this 
parameter to balance the relative importance of information derived from 
cluster/class means and covariances. For instance, a value of 0.5 gives 
equal importance to differences in means and covariances among clusters/classes.</p>
</td></tr>
<tr><td><code id="MclustDR_+3A_normalized">normalized</code></td>
<td>
<p>Logical. If <code>TRUE</code> directions are normalized to unit norm.</p>
</td></tr>
<tr><td><code id="MclustDR_+3A_sigma">Sigma</code></td>
<td>
<p>Marginal covariance matrix of data. If not provided is estimated by the MLE of observed data.</p>
</td></tr>
<tr><td><code id="MclustDR_+3A_tol">tol</code></td>
<td>
<p>A tolerance value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method aims at reducing the dimensionality by identifying a set of linear combinations, ordered by importance as quantified by the associated eigenvalues, of the original features which capture most of the clustering or classification structure contained in the data. 
</p>
<p>Information on the dimension reduction subspace is obtained from the variation on group means and, depending on the estimated mixture model, on the variation on group covariances (see Scrucca, 2010). 
</p>
<p>Observations may then be projected onto such a reduced subspace, thus providing summary plots which help to visualize the underlying structure.
</p>
<p>The method has been extended to the supervised case, i.e. when the true classification is known (see Scrucca, 2014).
</p>
<p>This implementation doesn't provide a formal procedure for the selection of dimensionality. A future release will include one or more methods.
</p>


<h3>Value</h3>

<p>An object of class <code>'MclustDR'</code> with the following components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call</p>
</td></tr> 
<tr><td><code>type</code></td>
<td>
<p>A character string specifying the type of model for which the dimension reduction is computed. Currently, possible values are <code>"Mclust"</code> for clustering, and <code>"MclustDA"</code> or <code>"EDDA"</code> for classification.</p>
</td></tr> 
<tr><td><code>x</code></td>
<td>
<p>The data matrix.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>The covariance matrix of the data.</p>
</td></tr>
<tr><td><code>mixcomp</code></td>
<td>
<p>A numeric vector specifying the mixture component of each data observation.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>A factor specifying the classification of each data observation. For model-based clustering this is equivalent to the corresponding mixture component. For model-based classification this is the known classification.</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>The number of mixture components.</p>
</td></tr>
<tr><td><code>modelName</code></td>
<td>
<p>The name of the parameterization of the estimated mixture model(s). See <code><a href="#topic+mclustModelNames">mclustModelNames</a></code>.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A matrix of means for each mixture component.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>An array of covariance matrices for each mixture component.</p>
</td></tr>
<tr><td><code>pro</code></td>
<td>
<p>The estimated prior for each mixture component.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>The kernel matrix.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The tuning parameter.</p>
</td></tr>
<tr><td><code>evalues</code></td>
<td>
<p>The eigenvalues from the generalized eigen-decomposition of the kernel matrix.</p>
</td></tr>
<tr><td><code>raw.evectors</code></td>
<td>
<p>The raw eigenvectors from the generalized eigen-decomposition of the kernel matrix, ordered according to the eigenvalues.</p>
</td></tr>
<tr><td><code>basis</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace.</p>
</td></tr>
<tr><td><code>std.basis</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace standardized to variables having unit standard deviation.</p>
</td></tr>
<tr><td><code>numdir</code></td>
<td>
<p>The dimension of the projection subspace.</p>
</td></tr>
<tr><td><code>dir</code></td>
<td>
<p>The estimated directions, i.e. the data projected onto the estimated dimension reduction subspace.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca, L. (2010) Dimension reduction for model-based clustering. <em>Statistics and Computing</em>, 20(4), pp. 471-484.
</p>
<p>Scrucca, L. (2014) Graphical Tools for Model-based Mixture Discriminant Analysis. <em>Advances in Data Analysis and Classification</em>, 8(2), pp. 147-165.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.MclustDR">summary.MclustDR</a></code>, <code><a href="#topic+plot.MclustDR">plot.MclustDR</a></code>, <code><a href="#topic+Mclust">Mclust</a></code>, <code><a href="#topic+MclustDA">MclustDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># clustering
data(diabetes)
mod &lt;- Mclust(diabetes[,-1])
summary(mod)

dr &lt;- MclustDR(mod)
summary(dr)
plot(dr, what = "scatterplot")
plot(dr, what = "evalues")

dr &lt;- MclustDR(mod, lambda = 0.5) 
summary(dr)
plot(dr, what = "scatterplot")
plot(dr, what = "evalues")

# classification
data(banknote)

da &lt;- MclustDA(banknote[,2:7], banknote$Status, modelType = "EDDA")
dr &lt;- MclustDR(da)
summary(dr)

da &lt;- MclustDA(banknote[,2:7], banknote$Status)
dr &lt;- MclustDR(da)
summary(dr)
</code></pre>

<hr>
<h2 id='MclustDRsubsel'>Subset selection for GMMDR directions based on BIC</h2><span id='topic+MclustDRsubsel'></span><span id='topic+print.MclustDRsubsel'></span><span id='topic+MclustDRsubsel_classif'></span><span id='topic+MclustDRsubsel_cluster'></span><span id='topic+MclustDRrecoverdir'></span><span id='topic+MclustDRsubsel1cycle'></span><span id='topic+print.MclustDRsubsel'></span><span id='topic+summary.MclustDRsubsel'></span>

<h3>Description</h3>

<p>Implements a subset selection method for selecting the relevant directions spanning the dimension reduction subspace for visualizing the clustering or classification structure obtained from a finite mixture of Gaussian densities.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MclustDRsubsel(object, G = 1:9,
                       modelNames = mclust.options("emModelNames"), 
                       ...,
                       bic.stop = 0, bic.cutoff = 0, 
                       mindir = 1, 
                       verbose = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MclustDRsubsel_+3A_object">object</code></td>
<td>
<p>An object of class <code>'MclustDR'</code> resulting from a call to <code><a href="#topic+MclustDR">MclustDR</a></code>.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_g">G</code></td>
<td>
<p>An integer vector specifying the numbers of mixture components or clusters.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_modelnames">modelNames</code></td>
<td>
<p>A vector of character strings indicating the models to be fitted. See <code><a href="#topic+mclustModelNames">mclustModelNames</a></code> for a description of the available models.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_...">...</code></td>
<td>
<p>Further arguments passed through <code><a href="#topic+Mclust">Mclust</a></code> or <code><a href="#topic+MclustDA">MclustDA</a></code>.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_bic.stop">bic.stop</code></td>
<td>
<p>A criterion to terminate the search. If maximal BIC difference is less than <code>bic.stop</code> then the algorithm stops. <br />
Two tipical values are:
</p>

<table>
<tr>
 <td style="text-align: left;">  
    <code>0</code>: </td><td style="text-align: left;"> algorithm stops when the BIC difference becomes negative (default);</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>-Inf</code>: </td><td style="text-align: left;"> algorithm continues until all directions have been selected.
    </td>
</tr>

</table>

</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_bic.cutoff">bic.cutoff</code></td>
<td>
<p>A value specifying how to select simplest &ldquo;best&rdquo; model within <code>bic.cutoff</code> from the maximum value achieved. Setting this to <code>0</code> (default) simply select the model with the largest BIC difference.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_mindir">mindir</code></td>
<td>
<p>An integer value specifying the minimum number of directions to be estimated.</p>
</td></tr>
<tr><td><code id="MclustDRsubsel_+3A_verbose">verbose</code></td>
<td>
<p>A logical or integer value specifying if and how much detailed information should be reported during the iterations of the algorithm. <br />
Possible values are:
</p>

<table>
<tr>
 <td style="text-align: left;">  
  <code>0</code> or <code>FALSE</code>: </td><td style="text-align: left;"> no trace info is shown;</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>1</code> or <code>TRUE</code>: </td><td style="text-align: left;"> a trace info is shown at each step of the search;</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>2</code>: </td><td style="text-align: left;"> a more detailed trace info is is shown.</td>
</tr>

</table>

</td></tr>
</table>


<h3>Details</h3>

<p>The GMMDR method aims at reducing the dimensionality by identifying a set of linear combinations, ordered by importance as quantified by the associated eigenvalues, of the original features which capture most of the clustering or classification structure contained in the data. This is implemented in <code><a href="#topic+MclustDR">MclustDR</a></code>.
</p>
<p>The <code>MclustDRsubsel</code> function implements the greedy forward search algorithm discussed in Scrucca (2010) to prune the set of all GMMDR directions. The criterion used to select the relevant directions is based on the BIC difference between a clustering model and a model in which the feature proposal has no clustering relevance. The steps are the following:
</p>
<p>1. Select the first feature to be the one which maximizes the BIC difference between the best clustering model and the model which assumes no clustering, i.e. a single component.
</p>
<p>2. Select the next feature amongst those not previously included, to be the one which maximizes the BIC difference.
</p>
<p>3. Iterate the previous step until all the BIC differences for the inclusion of a feature become less than <code>bic.stop</code>.
</p>
<p>At each step, the search over the model space is performed with respect to the model parametrisation and the number of clusters. 
</p>


<h3>Value</h3>

<p>An object of class <code>'MclustDRsubsel'</code> which inherits from <code>'MclustDR'</code>, so it has the same components of the latter plus the following:
</p>
<table>
<tr><td><code>basisx</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace expressed in terms of the original variables.</p>
</td></tr>
<tr><td><code>std.basisx</code></td>
<td>
<p>The basis of the estimated dimension reduction subspace expressed in terms of the original variables standardized to have unit standard deviation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca, L. (2010) Dimension reduction for model-based clustering. <em>Statistics and Computing</em>, 20(4), pp. 471-484.
</p>
<p>Scrucca, L. (2014) Graphical Tools for Model-based Mixture Discriminant Analysis. <em>Advances in Data Analysis and Classification</em>, 8(2), pp. 147-165
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDR">MclustDR</a></code>, <code><a href="#topic+Mclust">Mclust</a></code>, <code><a href="#topic+MclustDA">MclustDA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# clustering
data(crabs, package = "MASS")
x &lt;- crabs[,4:8]
class &lt;- paste(crabs$sp, crabs$sex, sep = "|")
mod &lt;- Mclust(x)
table(class, mod$classification)
dr &lt;- MclustDR(mod)
summary(dr)
plot(dr)
drs &lt;- MclustDRsubsel(dr)
summary(drs)
table(class, drs$classification)
plot(drs, what = "scatterplot")
plot(drs, what = "pairs")
plot(drs, what = "contour")
plot(drs, what = "boundaries")
plot(drs, what = "evalues")

# classification
data(banknote)
da &lt;- MclustDA(banknote[,2:7], banknote$Status)
table(banknote$Status, predict(da)$class)
dr &lt;- MclustDR(da)
summary(dr)
drs &lt;- MclustDRsubsel(dr)
summary(drs)
table(banknote$Status, predict(drs)$class)
plot(drs, what = "scatterplot")
plot(drs, what = "classification")
plot(drs, what = "boundaries")
</code></pre>

<hr>
<h2 id='mclustICL'>ICL Criterion for Model-Based Clustering</h2><span id='topic+mclustICL'></span><span id='topic+print.mclustICL'></span><span id='topic+summary.mclustICL'></span><span id='topic+print.summary.mclustICL'></span>

<h3>Description</h3>

<p>ICL (Integrated Complete-data Likelihood) for parameterized Gaussian mixture models fitted by EM algorithm initialized by model-based hierarchical clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustICL(data, G = NULL, modelNames = NULL, 
          initialization = list(hcPairs = NULL, 
                                subset = NULL, 
                                noise = NULL), 
          x = NULL, ...)

## S3 method for class 'mclustICL'
summary(object, G, modelNames, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustICL_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="mclustICL_+3A_g">G</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components
(clusters) for which the criteria should be calculated. 
The default is <code>G = 1:9</code>. 
</p>
</td></tr>
<tr><td><code id="mclustICL_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of character strings indicating the models to be fitted 
in the EM phase of clustering. The help file for 
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
The default is:
</p>

<dl>
<dt><code>c("E", "V")</code></dt><dd><p>for univariate data</p>
</dd>
<dt><code>mclust.options("emModelNames")</code></dt><dd><p>for multivariate data (n &gt; d)</p>
</dd>
<dt><code>c("EII", "VII", "EEI", "EVI", "VEI", "VVI")</code></dt><dd><p>the spherical and diagonal models for multivariate data (n &lt;= d)</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="mclustICL_+3A_initialization">initialization</code></td>
<td>

<p>A list containing zero or more of the following components:
</p>

<dl>
<dt><code>hcPairs</code></dt><dd>
<p>A matrix of merge pairs for hierarchical clustering such as produced
by function <code>hc</code>. For multivariate data, the default is to compute
a hierarchical clustering tree by applying function <code>hc</code> with
<code>modelName = "VVV"</code> to the data or a subset as indicated by the
<code>subset</code> argument.
The hierarchical clustering results are to start EM.
For univariate data, the default is to use quantiles to start EM.
</p>
</dd>
<dt><code>subset</code></dt><dd>
<p>A logical or numeric vector specifying a subset of the data
to be used in the initial hierarchical clustering phase.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="mclustICL_+3A_x">x</code></td>
<td>

<p>An object of class <code>'mclustICL'</code>. If supplied, <code>mclustICL</code>
will use the settings in <code>x</code> to produce another object of
class <code>'mclustICL'</code>, but with <code>G</code> and <code>modelNames</code>
as specified in the arguments. Models that have already been computed
in <code>x</code> are not recomputed. All arguments to <code>mclustICL</code> 
except <code>data</code>, <code>G</code> and <code>modelName</code> are
ignored and their values are set as specified in the attributes of
<code>x</code>. 
Defaults for <code>G</code> and <code>modelNames</code> are taken from <code>x</code>.
</p>
</td></tr>
<tr><td><code id="mclustICL_+3A_...">...</code></td>
<td>

<p>Futher arguments used in the call to <code><a href="#topic+Mclust">Mclust</a></code>. 
See also <code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>
</td></tr>
<tr><td><code id="mclustICL_+3A_object">object</code></td>
<td>

<p>An integer vector specifying the numbers of mixture components
(clusters) for which the criteria should be calculated. 
The default is <code>G = 1:9</code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>'mclustICL'</code> containing the the ICL criterion 
for the specified mixture models and numbers of clusters.
</p>
<p>The corresponding <code>print</code> method shows the matrix of values and the top models according to the ICL criterion. The <code>summary</code> method shows only the top models.
</p>


<h3>References</h3>

<p>Biernacki, C., Celeux, G., Govaert, G. (2000). 
Assessing a mixture model for clustering with the integrated completed likelihood.
<em>IEEE Trans. Pattern Analysis and Machine Intelligence</em>, 22 (7), 719-725.
</p>
<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mclustICL">plot.mclustICL</a></code>, 
<code><a href="#topic+Mclust">Mclust</a></code>, 
<code><a href="#topic+mclustBIC">mclustBIC</a></code>, 
<code><a href="#topic+mclustBootstrapLRT">mclustBootstrapLRT</a></code>, 
<code><a href="#topic+bic">bic</a></code>,
<code><a href="#topic+icl">icl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(faithful)
faithful.ICL &lt;- mclustICL(faithful)
faithful.ICL
summary(faithful.ICL)
plot(faithful.ICL)

# compare with
faithful.BIC &lt;- mclustBIC(faithful)
faithful.BIC
plot(faithful.BIC)

</code></pre>

<hr>
<h2 id='mclustLoglik'>Log-likelihood from a table of BIC values for parameterized Gaussian mixture models</h2><span id='topic+mclustLoglik'></span><span id='topic+print.mclustLoglik'></span>

<h3>Description</h3>

<p>Compute the maximal log-likelihood from a table of BIC values contained in a <code>'mclustBIC'</code> object as returned by function <code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustLoglik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustLoglik_+3A_object">object</code></td>
<td>
<p>An object of class <code>'mclustBIC'</code> containing the 
BIC values as returned by a call to <code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>
</td></tr>
<tr><td><code id="mclustLoglik_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in an indirect or list call via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>'mclustLoglik'</code> containing the maximal log-likelihood values for the Gaussian mixture models provided as input.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
BIC &lt;- mclustBIC(iris[,1:4])
mclustLoglik(BIC)

</code></pre>

<hr>
<h2 id='mclustModel'>
Best model based on BIC
</h2><span id='topic+mclustModel'></span>

<h3>Description</h3>

<p>Determines the best model from clustering via <code>mclustBIC</code>
for a given set of model parameterizations and numbers of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustModel(data, BICvalues, G, modelNames, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustModel_+3A_data">data</code></td>
<td>

<p>The matrix or vector of observations used to generate &lsquo;object&rsquo;.
</p>
</td></tr>
<tr><td><code id="mclustModel_+3A_bicvalues">BICvalues</code></td>
<td>

<p>An <code>'mclustBIC'</code> object, 
which is the result of applying <code>mclustBIC</code> 
to <code>data</code>.
</p>
</td></tr>
<tr><td><code id="mclustModel_+3A_g">G</code></td>
<td>

<p>A vector of integers giving the numbers of mixture components (clusters)
from which the best model according to BIC will be selected 
(<code>as.character(G)</code> must be a subset of the row names of 
<code>BICvalues</code>).
The default is to select the best model for all numbers 
of mixture components used to obtain <code>BICvalues</code>.
</p>
</td></tr>
<tr><td><code id="mclustModel_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of integers giving the model parameterizations
from which the best model according to BIC will be selected 
(<code>as.character(model)</code> must be a subset of the column names of 
<code>BICvalues</code>).
The default is to select the best model for parameterizations
used to obtain <code>BICvalues</code>.
</p>
</td></tr>
<tr><td><code id="mclustModel_+3A_...">...</code></td>
<td>

<p>Not used. For generic/method consistency.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list giving the optimal (according to BIC) parameters,
conditional probabilities <code>z</code>, and log-likelihood,
together with the associated classification and its uncertainty.
</p>
<p>The details of the output components are as follows:
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>

<p>The number of observations in the data.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The number of components in the Gaussian mixture model corresponding
to the optimal BIC.
</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>

<p>The optimal BIC value.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood corresponding to the optimal BIC.
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
If missing, equal proportions are assumed.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <em>[i,k]</em>th entry is the probability that observation
<em>i</em> in the test data belongs to the <em>k</em>th class.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisBIC &lt;- mclustBIC(iris[,-5])
mclustModel(iris[,-5], irisBIC)
mclustModel(iris[,-5], irisBIC, G = 1:6, modelNames = c("VII", "VVI", "VVV"))
</code></pre>

<hr>
<h2 id='mclustModelNames'>
MCLUST Model Names 
</h2><span id='topic+mclustModelNames'></span>

<h3>Description</h3>

<p>Description of model names used in the <em>MCLUST</em> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustModelNames(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustModelNames_+3A_model">model</code></td>
<td>
<p>A string specifying the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following models are available in package <span class="pkg">mclust</span>:<br />
</p>
<p><b>univariate mixture</b> <br />
</p>

<dl>
<dt><code>"E"</code></dt><dd><p>equal variance (one-dimensional)</p>
</dd>
<dt><code>"V"</code></dt><dd><p>variable/unqual variance (one-dimensional)</p>
</dd>
</dl>

<p><b>multivariate mixture</b><br />
</p>

<dl>
<dt><code>"EII"</code></dt><dd><p>spherical, equal volume</p>
</dd>
<dt><code>"VII"</code></dt><dd><p>spherical, unequal volume</p>
</dd>
<dt><code>"EEI"</code></dt><dd><p>diagonal, equal volume and shape</p>
</dd>
<dt><code>"VEI"</code></dt><dd><p>diagonal, varying volume, equal shape</p>
</dd>
<dt><code>"EVI"</code></dt><dd><p>diagonal, equal volume, varying shape</p>
</dd>
<dt><code>"VVI"</code></dt><dd><p>diagonal, varying volume and shape</p>
</dd>
<dt><code>"EEE"</code></dt><dd><p>ellipsoidal, equal volume, shape, and orientation</p>
</dd>
<dt><code>"VEE"</code></dt><dd><p>ellipsoidal, equal shape and orientation (*)</p>
</dd>
<dt><code>"EVE"</code></dt><dd><p>ellipsoidal, equal volume and orientation (*)</p>
</dd>
<dt><code>"VVE"</code></dt><dd><p>ellipsoidal, equal orientation (*)</p>
</dd>
<dt><code>"EEV"</code></dt><dd><p>ellipsoidal, equal volume and equal shape</p>
</dd>
<dt><code>"VEV"</code></dt><dd><p>ellipsoidal, equal shape</p>
</dd>
<dt><code>"EVV"</code></dt><dd><p>ellipsoidal, equal volume (*)</p>
</dd>
<dt><code>"VVV"</code></dt><dd><p>ellipsoidal, varying volume, shape, and orientation</p>
</dd>
</dl>

<p><b>single component</b><br />
</p>

<dl>
<dt><code>"X"</code></dt><dd><p>univariate normal</p>
</dd>
<dt><code>"XII"</code></dt><dd><p>spherical multivariate normal</p>
</dd>
<dt><code>"XXI"</code></dt><dd><p>diagonal multivariate normal</p>
</dd>
<dt><code>"XXX"</code></dt><dd><p>ellipsoidal multivariate normal</p>
</dd>
</dl>

<p>(*) new models in <span class="pkg">mclust</span> version &gt;= 5.0.0.
</p>


<h3>Value</h3>

<p>Returns a list with the following components:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>a character string indicating the model (as in input).</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the description of the indicated model (see Details section).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>,
<code><a href="#topic+mclustBIC">mclustBIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mclustModelNames("E")
mclustModelNames("EEE")
mclustModelNames("VVV")
mclustModelNames("XXI")
</code></pre>

<hr>
<h2 id='MclustSSC'>MclustSSC semi-supervised classification</h2><span id='topic+MclustSSC'></span><span id='topic+print.MclustSSC'></span>

<h3>Description</h3>

<p>Semi-Supervised classification based on Gaussian finite mixture modeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MclustSSC(data, class, 
          G = NULL, modelNames = NULL, 
          prior = NULL, control = emControl(), 
          warn = mclust.options("warn"), 
          verbose = interactive(),
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MclustSSC_+3A_data">data</code></td>
<td>

<p>A data frame or matrix giving the training data.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_class">class</code></td>
<td>

<p>A vector giving the known class labels (either a numerical value or 
a character string) for the observations in the training data. 
Observations with unknown class are encoded as <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_g">G</code></td>
<td>

<p>An integer value specifying the numbers of mixture components or classes. 
By default is set equal to the number of known classes.
See the examples below.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of character strings indicating the models to be fitted 
by EM (see the description in <code><a href="#topic+mclustModelNames">mclustModelNames</a></code>).
See the examples below.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_prior">prior</code></td>
<td>

<p>The default assumes no prior, but this argument allows specification of a 
conjugate prior on the means and variances through the function 
<code><a href="#topic+priorControl">priorControl</a></code>.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>. 
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when
estimation fails. 
The default is controlled by <code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="MclustSSC_+3A_verbose">verbose</code></td>
<td>

<p>A logical controlling if a text progress bar is displayed during the
fitting procedure. By default is <code>TRUE</code> if the session is 
interactive, and <code>FALSE</code> otherwise.
</p>
</td></tr>  
<tr><td><code id="MclustSSC_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The semi-supervised approach implemented in <code>MclustSSC()</code> is a simple Gaussian mixture model for classification where at the first M-step only observations with known class labels are used for parameters estimation. Then, a standard EM algorithm is used for updating the probabiltiy of class membership for unlabelled data while keeping fixed the probabilities for labelled data. 
</p>


<h3>Value</h3>

<p>An object of class <code>'MclustSSC'</code> providing the optimal (according 
to BIC) Gaussian mixture model for semi-supervised classification.
</p>
<p>The details of the output components are as follows:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr> 
<tr><td><code>data</code></td>
<td>
<p>The input data matrix.</p>
</td></tr> 
<tr><td><code>class</code></td>
<td>
<p>The input class labels (including <code>NA</code>s for unknown labels.</p>
</td></tr> 
<tr><td><code>modelName</code></td>
<td>
<p>A character string specifying the &quot;best&quot; estimated model.</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>A numerical value specifying the number of mixture components or classes of the &quot;best&quot; estimated model.</p>
</td></tr> 
<tr><td><code>n</code></td>
<td>
<p>The total number of observations in the data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The dimension of the data.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>All BIC values.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>Log-likelihood for the selected model.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Number of estimated parameters.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Optimal BIC value.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model specification. 
See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <em>[i,k]</em>th entry is the probability that observation
<em>i</em> in the test data belongs to the <em>k</em>th class.
</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>

<p>The classification corresponding to <code>z</code>, i.e. <code>map(z)</code>.
</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>

<p>The prior used (if any).
</p>
</td></tr>
<tr><td><code>control</code></td>
<td>

<p>A list of control parameters used in the EM algorithm. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and density estimation using Gaussian finite mixture models, <em>The R Journal</em>, 8/1, pp. 289-317. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.MclustSSC">summary.MclustSSC</a></code>, 
<code><a href="#topic+plot.MclustSSC">plot.MclustSSC</a></code>, 
<code><a href="#topic+predict.MclustSSC">predict.MclustSSC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate two overlapping groups
n &lt;- 200
pars &lt;- list(pro = c(0.5, 0.5),
             mean = matrix(c(-1,1), nrow = 2, ncol = 2, byrow = TRUE),
             variance = mclustVariance("EII", d = 2, G = 2))
pars$variance$sigmasq &lt;- 1
data &lt;- sim("EII", parameters = pars, n = n, seed = 12)
class &lt;- data[,1]
X &lt;- data[,-1]
clPairs(X, class, symbols = c(1,2), main = "Full classified data")

# Randomly remove labels
cl &lt;- class; cl[sample(1:n, size = 195)] &lt;- NA
table(cl, useNA = "ifany")
clPairs(X, ifelse(is.na(cl), 0, class),
        symbols = c(0, 16, 17), colors = c("grey", 4, 2),
        main = "Partially classified data")

# Fit semi-supervised classification model
mod_SSC  &lt;- MclustSSC(X, cl)
summary(mod_SSC, parameters = TRUE)

pred_SSC &lt;- predict(mod_SSC)
table(Predicted = pred_SSC$classification, Actual = class)

ngrid &lt;- 50
xgrid &lt;- seq(-3, 3, length.out = ngrid)
ygrid &lt;- seq(-4, 4.5, length.out = ngrid)
xygrid &lt;- expand.grid(xgrid, ygrid)
pred_SSC  &lt;- predict(mod_SSC, newdata = xygrid)
col &lt;- mclust.options("classPlotColors")[class]
pch &lt;- class
pch[!is.na(cl)] = ifelse(cl[!is.na(cl)] == 1, 19, 17)
plot(X, pch = pch, col = col)
contour(xgrid, ygrid, matrix(pred_SSC$z[,1], ngrid, ngrid), 
        add = TRUE, levels = 0.5, drawlabels = FALSE, lty = 2, lwd = 2)
</code></pre>

<hr>
<h2 id='mclustVariance'>
Template for variance specification for parameterized Gaussian mixture models
</h2><span id='topic+mclustVariance'></span>

<h3>Description</h3>

<p>Specification of variance parameters for the various types
of Gaussian mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclustVariance(modelName, d = NULL, G = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclustVariance_+3A_modelname">modelName</code></td>
<td>
<p>A character string specifying the model.</p>
</td></tr>
<tr><td><code id="mclustVariance_+3A_d">d</code></td>
<td>
<p>A integer specifying the dimension of the data.</p>
</td></tr>
<tr><td><code id="mclustVariance_+3A_g">G</code></td>
<td>
<p>An integer specifying the number of components in the mixture model.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>The <code>variance</code> component in the <code>parameters</code> list from the
output to e.g. <code>me</code> or <code>mstep</code> or input to e.g. <code>estep</code> may contain one or more of the following arguments, depending on the model:
</p>

<dl>
<dt><code>modelName</code></dt><dd>
<p>A character string indicating the model.
</p>
</dd>
<dt><code>d</code></dt><dd>
<p>The dimension of the data.
</p>
</dd>
<dt><code>G</code></dt><dd>
<p>The number of components in the mixture model.
</p>
</dd>
<dt><code>sigmasq</code></dt><dd>
<p>for the one-dimensional models (<code>"E"</code>, <code>"V"</code>) and spherical
models (<code>"EII"</code>, <code>"VII"</code>). This is either a vector whose
<em>k</em>th component is the variance for the <em>k</em>th component in 
the mixture model (<code>"V"</code> and <code>"VII"</code>), or a scalar giving 
the common variance for all components in the mixture model (<code>"E"</code>
and <code>"EII"</code>).
</p>
</dd>
<dt><code>Sigma</code></dt><dd>
<p>For the equal variance models <code>"EII"</code>, <code>"EEI"</code>, and
<code>"EEE"</code>. 
A <em>d</em> by <em>d</em>  matrix giving the common covariance for all  
components of the  mixture model.
</p>
</dd>
<dt><code>cholSigma</code></dt><dd>
<p>For the equal variance model <code>"EEE"</code>. 
A <em>d</em> by <em>d</em> upper triangular matrix giving the 
Cholesky factor of the common covariance for all  
components of the  mixture model.
</p>
</dd>
<dt><code>sigma</code></dt><dd>
<p>For all multidimensional mixture models. A
<em>d</em> by <em>d</em> by <em>G</em> matrix array whose
<code>[,,k]</code>th entry is the covariance matrix for
the <em>k</em>th component of the mixture model. 
</p>
</dd>
<dt><code>cholsigma</code></dt><dd>
<p>For the unconstrained covariance mixture model <code>"VVV"</code>. 
A <em>d</em> by <em>d</em> by <em>G</em> matrix array whose
<code>[,,k]</code>th entry is the upper triangular Cholesky factor
of the covariance matrix for the <em>k</em>th component of the 
mixture model. 
</p>
</dd>
<dt><code>scale</code></dt><dd>
<p>For diagonal models <code>"EEI"</code>, <code>"EVI"</code>, <code>"VEI"</code>, 
<code>"VVI"</code> and constant-shape models <code>"EEV"</code> and <code>"VEV"</code>.
Either a <em>G</em>-vector giving the scale of the covariance (the
<em>d</em>th root of its determinant) for each component in the
mixture model, or a single numeric value if the scale is the
same for each component.
</p>
</dd>
<dt><code>shape</code></dt><dd>
<p>For diagonal models <code>"EEI"</code>, <code>"EVI"</code>, <code>"VEI"</code>, 
<code>"VVI"</code> and constant-shape models <code>"EEV"</code> and <code>"VEV"</code>.
Either a <em>G</em> by <em>d</em> matrix in which the <em>k</em>th
column is the shape of the covariance matrix (normalized to have
determinant 1) for the <em>k</em>th component, or a
<em>d</em>-vector giving a common shape for all components.
</p>
</dd>
<dt><code>orientation</code></dt><dd>
<p>For the constant-shape models <code>"EEV"</code> and <code>"VEV"</code>.
Either a <em>d</em> by <em>d</em> by <em>G</em> array whose
<code>[,,k]</code>th entry is the orthonomal matrix whose
columns are the eigenvectors of the covariance matrix of
the <em>k</em>th component, or a <em>d</em> by <em>d</em>
orthonormal matrix if the mixture components have a
common orientation. The <code>orientation</code> component
is not needed in spherical and diagonal models, since
the principal components are parallel to the coordinate axes 
so that the orientation matrix is the identity.
</p>
</dd>
</dl>

<p>In all cases, the value
<code>-1</code> is used as a placeholder for unknown nonzero entries. 
</p>

<hr>
<h2 id='me'>EM algorithm starting with M-step for parameterized MVN mixture models</h2><span id='topic+me'></span>

<h3>Description</h3>

<p>Implements the EM algorithm for MVN mixture models parameterized by
eignevalue decomposition, starting with the maximization step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>me(data, modelName, z, prior = NULL, control = emControl(), 
   Vinv = NULL, warn = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="me_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="me_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="me_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is an initial estimate of the
conditional probability of the ith observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code id="me_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
See the help file for <code>priorControl</code> for further information.
The default assumes no prior.                                              
</p>
</td></tr>
<tr><td><code id="me_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>.
</p>
</td></tr>                                                             
<tr><td><code id="me_+3A_vinv">Vinv</code></td>
<td>

<p>If the model is to include a noise term, <code>Vinv</code> is an estimate of the 
reciprocal hypervolume of the data region. If set to a negative value
or 0, the model will include a noise term with the reciprocal hypervolume
estimated by the function <code>hypvol</code>.
The default is not to assume a noise term in the model through the
setting <code>Vinv=NULL</code>.
</p>
</td></tr>
<tr><td><code id="me_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings 
(usually related to singularity) should be issued when the
estimation fails. The default is set in <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="me_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>

<p>The number of observations in the data.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The number of mixture components.
</p>
</td></tr>  
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>control</code></td>
<td>

<p>The list of control parameters for EM used.
</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>

<p>The specification of a conjugate prior on the means and variances used,
<code>NULL</code> if no prior is used.
</p>
</td></tr>        
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> Information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are encountered 
in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+meE">meE</a></code>, ...,
<code><a href="#topic+meVVV">meVVV</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+priorControl">priorControl</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
me(modelName = "VVV", data = iris[,-5], z = unmap(iris[,5]))
</code></pre>

<hr>
<h2 id='me.weighted'>EM algorithm with weights starting with M-step for parameterized Gaussian mixture models</h2><span id='topic+me.weighted'></span>

<h3>Description</h3>

<p>Implements the EM algorithm for fitting Gaussian mixture models parameterized by eigenvalue decomposition, when observations have weights, starting with the maximization step. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>me.weighted(data, modelName, z, weights = NULL, prior = NULL, 
            control = emControl(), Vinv = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="me.weighted_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is an initial estimate of the
conditional probability of the ith observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_weights">weights</code></td>
<td>

<p>A vector of positive weights, where the <code>[i]</code>th entry is the weight
for the ith observation. If any of the weights are greater than one,
then they are scaled so that the maximum weight is one.
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
See the help file for <code>priorControl</code> for further information.
The default assumes no prior.                                              
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code><a href="#topic+emControl">emControl</a></code>.
</p>
</td></tr>                                                             
<tr><td><code id="me.weighted_+3A_vinv">Vinv</code></td>
<td>

<p>If the model is to include a noise term, <code>Vinv</code> is an estimate of the 
reciprocal hypervolume of the data region. If set to a negative value
or 0, the model will include a noise term with the reciprocal hypervolume
estimated by the function <code>hypvol</code>.
The default is not to assume a noise term in the model through the
setting <code>Vinv=NULL</code>.
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings 
(usually related to singularity) should be issued when the
estimation fails. The default is set by <code>warn</code> using
<code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>
</td></tr>
<tr><td><code id="me.weighted_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a more efficient version made available with <span class="pkg">mclust</span> <code class="reqn">ge 6.1</code> using Fortran code internally.</p>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood for the estimated mixture model. 
</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>

<p>The BIC value for the estimated mixture model. 
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> Information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are encountered 
in the computations.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>T. Brendan Murphy, Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+me">me</a></code>,
<code><a href="#topic+meE">meE</a></code>, ...,
<code><a href="#topic+meVVV">meVVV</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+priorControl">priorControl</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w = rexp(nrow(iris))
w = w/mean(w)
c(summary(w), sum = sum(w))
z = unmap(sample(1:3, size = nrow(iris), replace = TRUE))
MEW = me.weighted(data = iris[,-5], modelName = "VVV", 
                  z = z, weights = w)
str(MEW,1)
</code></pre>

<hr>
<h2 id='meE'>EM algorithm starting with M-step for a parameterized Gaussian mixture model</h2><span id='topic+meE'></span><span id='topic+meV'></span><span id='topic+meX'></span><span id='topic+meEII'></span><span id='topic+meVII'></span><span id='topic+meEEI'></span><span id='topic+meVEI'></span><span id='topic+meEVI'></span><span id='topic+meVVI'></span><span id='topic+meEEE'></span><span id='topic+meVEE'></span><span id='topic+meEVE'></span><span id='topic+meVVE'></span><span id='topic+meEEV'></span><span id='topic+meVEV'></span><span id='topic+meEVV'></span><span id='topic+meVVV'></span><span id='topic+meXII'></span><span id='topic+meXXI'></span><span id='topic+meXXX'></span>

<h3>Description</h3>

<p>Implements the EM algorithm for a parameterized Gaussian mixture model,
starting with the maximization step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meX(data, prior = NULL, warn = NULL, ...)
meEII(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVII(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEEI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVEI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEVI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVVI(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEEE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVEE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEVE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVVE(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEEV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVEV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meEVV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meVVV(data, z, prior=NULL, control=emControl(), Vinv=NULL, warn=NULL, ...)
meXII(data, prior = NULL, warn = NULL, ...)
meXXI(data, prior = NULL, warn = NULL, ...)
meXXX(data, prior = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="meE_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the conditional probability of 
the ith observation belonging to the <em>k</em>th component of the mixture.
</p>
</td></tr>
<tr><td><code id="meE_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.
</p>
</td></tr>
<tr><td><code id="meE_+3A_control">control</code></td>
<td>

<p>A list of control parameters for EM. The defaults are set by the call
<code>emControl()</code>. 
</p>
</td></tr>
<tr><td><code id="meE_+3A_vinv">Vinv</code></td>
<td>

<p>An estimate of the reciprocal hypervolume of the data region, when the
model is to include a noise term. Set to a negative value or zero if
a noise term is desired, but an estimate is unavailable &mdash; in that
case function <code>hypvol</code> will be used to obtain the estimate.
The default is not to assume a noise term in the model through the
setting <code>Vinv=NULL</code>.
</p>
</td></tr>
<tr><td><code id="meE_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when the
estimation fails. The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="meE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the <em>i</em>th observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
<dt><code>Vinv</code></dt><dd>
<p>The estimate of the reciprocal hypervolume of the data region
used in the computation when the input indicates the
addition of a noise component to the model.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model. 
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> Information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are encountered 
in the computations.<br />
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+em">em</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meVVV(data = iris[,-5], z = unmap(iris[,5]))
</code></pre>

<hr>
<h2 id='mstep'>M-step for parameterized Gaussian mixture models</h2><span id='topic+mstep'></span>

<h3>Description</h3>

<p>Maximization step in the EM algorithm for parameterized Gaussian
mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mstep(data, modelName, z, prior = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mstep_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="mstep_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="mstep_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the ith observation belonging to
the <em>k</em>th component of the mixture.  
In analyses involving noise, this should not include the
conditional probabilities for the noise component. 
</p>
</td></tr>
<tr><td><code id="mstep_+3A_prior">prior</code></td>
<td>
                                                      
<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.
</p>
</td></tr>
<tr><td><code id="mstep_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when the
estimation fails. The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="mstep_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> For those models with iterative M-steps
(<code>"VEI"</code> and <code>"VEV"</code>), information  on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are
encountered in the computations.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function computes the M-step only for MVN mixtures, so in 
analyses involving noise, the conditional probabilities input should 
exclude those for the noise component. <br />
</p>
<p>In contrast to <code>me</code> for the EM algorithm, computations in <code>mstep</code>
are carried out unless failure due to overflow would occur. To impose
stricter tolerances on a single <code>mstep</code>, use <code>me</code> with the
<em>itmax</em> component of the <code>control</code> argument set to 1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mstepE">mstepE</a></code>, ...,
<code><a href="#topic+mstepVVV">mstepVVV</a></code>,
<code><a href="#topic+emControl">emControl</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mstep(modelName = "VII", data = iris[,-5], z = unmap(iris[,5]))
</code></pre>

<hr>
<h2 id='mstepE'>M-step for a parameterized Gaussian mixture model</h2><span id='topic+mstepE'></span><span id='topic+mstepV'></span><span id='topic+mstepEII'></span><span id='topic+mstepVII'></span><span id='topic+mstepEEI'></span><span id='topic+mstepVEI'></span><span id='topic+mstepEVI'></span><span id='topic+mstepVVI'></span><span id='topic+mstepEEE'></span><span id='topic+mstepEEV'></span><span id='topic+mstepVEV'></span><span id='topic+mstepVVV'></span><span id='topic+mstepEVE'></span><span id='topic+mstepEVV'></span><span id='topic+mstepVEE'></span><span id='topic+mstepVVE'></span>

<h3>Description</h3>

<p>Maximization step in the EM algorithm for a parameterized Gaussian
mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mstepE( data, z, prior = NULL, warn = NULL, ...)
mstepV( data, z, prior = NULL, warn = NULL, ...)
mstepEII( data, z, prior = NULL, warn = NULL, ...)
mstepVII( data, z, prior = NULL, warn = NULL, ...)
mstepEEI( data, z, prior = NULL, warn = NULL, ...)
mstepVEI( data, z, prior = NULL, warn = NULL, control = NULL, ...)
mstepEVI( data, z, prior = NULL, warn = NULL, ...)
mstepVVI( data, z, prior = NULL, warn = NULL, ...)
mstepEEE( data, z, prior = NULL, warn = NULL, ...)
mstepEEV( data, z, prior = NULL, warn = NULL, ...)
mstepVEV( data, z, prior = NULL, warn = NULL, control = NULL,...)
mstepVVV( data, z, prior = NULL, warn = NULL, ...)
mstepEVE( data, z, prior = NULL, warn = NULL, control = NULL, ...)
mstepEVV( data, z, prior = NULL, warn = NULL, ...)
mstepVEE( data, z, prior = NULL, warn = NULL, control = NULL, ...)
mstepVVE( data, z, prior = NULL, warn = NULL, control = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mstepE_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="mstepE_+3A_z">z</code></td>
<td>

<p>A matrix whose <code>[i,k]</code>th entry is the
conditional probability of the ith observation belonging to
the <em>k</em>th component of the mixture.  
In analyses involving noise, this should not include the
conditional probabilities for the noise component. 
</p>
</td></tr>
<tr><td><code id="mstepE_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.  
</p>
</td></tr>
<tr><td><code id="mstepE_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not certain warnings
(usually related to singularity) should be issued when the
estimation fails. The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="mstepE_+3A_control">control</code></td>
<td>

<p>Values controlling termination for models <code>"VEI"</code> and <code>"VEV"</code> 
that have an iterative M-step. This should be a list with components
named <em>itmax</em> and <em>tol</em>. These components can be of length 1 
or 2; in the latter case, <code>mstep</code> will use the second value, under 
the assumption that the first applies to an outer iteration (as in the 
function <code>me</code>).
The default uses the default values from the function <code>emControl</code>,
which sets no limit on  the number of iterations, and a relative tolerance 
of <code>sqrt(.Machine$double.eps)</code> on successive iterates.
</p>
</td></tr>
<tr><td><code id="mstepE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for 
the <em>k</em>th component of the mixture model.
If the model includes a Poisson term for noise, there 
should be one more mixing proportion than the number 
of Gaussian components.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th 
component of the mixture model. 
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code> 
for details.  
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"info"</code> For those models with iterative M-steps
(<code>"VEI"</code> and <code>"VEV"</code>), information on the iteration.<br />
<code>"WARNING"</code> An appropriate warning if problems are
encountered in the computations.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function computes the M-step only for MVN mixtures, so in 
analyses involving noise, the conditional probabilities input should 
exclude those for the noise component. <br />
</p>
<p>In contrast to <code>me</code> for the EM algorithm, computations in <code>mstep</code>
are carried out unless failure due to overflow would occur. To impose
stricter tolerances on a single <code>mstep</code>, use <code>me</code> with the
<em>itmax</em> component of the <code>control</code> argument set to 1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>,
<code><a href="#topic+priorControl">priorControl</a></code>,
<code><a href="#topic+emControl">emControl</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mstepVII(data = iris[,-5], z = unmap(iris[,5]))
</code></pre>

<hr>
<h2 id='mvn'>
Univariate or Multivariate Normal Fit
</h2><span id='topic+mvn'></span>

<h3>Description</h3>

<p>Computes the mean, covariance, and log-likelihood from fitting a single
Gaussian to given data (univariate or multivariate normal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvn( modelName, data, prior = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvn_+3A_modelname">modelName</code></td>
<td>

<p>A character string representing a model name. This can be either
<code>"Spherical"</code>, <code>"Diagonal"</code>, or <code>"Ellipsoidal"</code> or 
else <br />
<code>"X"</code> for one-dimensional data,<br />
<code>"XII"</code> for a spherical Gaussian, <br />
<code>"XXI"</code> for a diagonal Gaussian <br />
<code>"XXX"</code> for a general ellipsoidal Gaussian 
</p>
</td></tr>
<tr><td><code id="mvn_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations. Categorical
variables are not allowed. If a matrix or data frame, rows
correspond to observations and columns correspond to variables. 
</p>
</td></tr>
<tr><td><code id="mvn_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.
</p>
</td></tr>
<tr><td><code id="mvn_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
whenever a singularity is encountered.
The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="mvn_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following components:
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model.
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"WARNING"</code> An appropriate warning if problems are 
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mvnX">mvnX</a></code>,
<code><a href="#topic+mvnXII">mvnXII</a></code>,
<code><a href="#topic+mvnXXI">mvnXXI</a></code>,
<code><a href="#topic+mvnXXX">mvnXXX</a></code>,
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000

set.seed(0)
x &lt;- rnorm(n, mean = -1, sd = 2)
mvn(modelName = "X", x) 

mu &lt;- c(-1, 0, 1)

set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% (2*diag(3)), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvn(modelName = "XII", x) 
mvn(modelName = "Spherical", x) 

set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% diag(1:3), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvn(modelName = "XXI", x)
mvn(modelName = "Diagonal", x)

Sigma &lt;- matrix(c(9,-4,1,-4,9,4,1,4,9), 3, 3)
set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% chol(Sigma), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvn(modelName = "XXX", x) 
mvn(modelName = "Ellipsoidal", x) 
</code></pre>

<hr>
<h2 id='mvnX'>
Univariate or Multivariate Normal Fit
</h2><span id='topic+mvnX'></span><span id='topic+mvnXII'></span><span id='topic+mvnXXI'></span><span id='topic+mvnXXX'></span>

<h3>Description</h3>

<p>Computes the mean, covariance, and log-likelihood from fitting a single
Gaussian (univariate or multivariate normal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnX(data, prior = NULL, warn = NULL, ...)
mvnXII(data, prior = NULL, warn = NULL, ...)
mvnXXI(data, prior = NULL, warn = NULL, ...)
mvnXXX(data, prior = NULL, warn = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnX_+3A_data">data</code></td>
<td>

<p>A numeric vector, matrix, or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="mvnX_+3A_prior">prior</code></td>
<td>

<p>Specification of a conjugate prior on the means and variances.
The default assumes no prior.                                              
</p>
</td></tr>
<tr><td><code id="mvnX_+3A_warn">warn</code></td>
<td>

<p>A logical value indicating whether or not a warning should be issued
whenever a singularity is encountered.
The default is given by <code>mclust.options("warn")</code>.
</p>
</td></tr>
<tr><td><code id="mvnX_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>mvnXII</code></dt><dd><p>computes the best fitting Gaussian with the covariance restricted to be a multiple of the identity.</p>
</dd>
<dt><code>mvnXXI</code></dt><dd><p>computes the best fitting Gaussian with the covariance restricted to be diagonal.</p>
</dd>
<dt><code>mvnXXX</code></dt><dd><p>computes the best fitting Gaussian with ellipsoidal (unrestricted) covariance.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list including the following components:
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string identifying the model (same as the input argument).
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>


<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log likelihood for the data in the mixture model.
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"WARNING"</code> An appropriate warning if problems are 
encountered in the computations.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mvn">mvn</a></code>,
<code><a href="#topic+mstepE">mstepE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000

set.seed(0)
x &lt;- rnorm(n, mean = -1, sd = 2)
mvnX(x) 

mu &lt;- c(-1, 0, 1)

set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% (2*diag(3)), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvnXII(x) 

set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% diag(1:3), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvnXXI(x)

Sigma &lt;- matrix(c(9,-4,1,-4,9,4,1,4,9), 3, 3)
set.seed(0)
x &lt;- sweep(matrix(rnorm(n*3), n, 3) %*% chol(Sigma), 
           MARGIN = 2, STATS = mu, FUN = "+")
mvnXXX(x) 

</code></pre>

<hr>
<h2 id='nMclustParams'>Number of Estimated Parameters in Gaussian Mixture Models</h2><span id='topic+nMclustParams'></span>

<h3>Description</h3>

<p>Gives the number of estimated parameters for parameterizations of the 
Gaussian mixture model that are used in MCLUST. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nMclustParams(modelName, d, G, noise = FALSE, equalPro = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nMclustParams_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="nMclustParams_+3A_d">d</code></td>
<td>

<p>The dimension of the data. Not used for models in which neither
the shape nor the orientation varies.
</p>
</td></tr>
<tr><td><code id="nMclustParams_+3A_g">G</code></td>
<td>

<p>The number of components in the Gaussian mixture model used to compute
<code>loglik</code>.
</p>
</td></tr>
<tr><td><code id="nMclustParams_+3A_noise">noise</code></td>
<td>

<p>A logical variable indicating whether or not the model includes an
optional Poisson noise component. 
</p>
</td></tr>
<tr><td><code id="nMclustParams_+3A_equalpro">equalPro</code></td>
<td>

<p>A logical variable indicating whether or not the components in the
model are assumed to be present in equal proportion.
</p>
</td></tr>
<tr><td><code id="nMclustParams_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To get the total number of parameters in model, add <code>G*d</code> for the
means and <code>G-1</code> for the mixing proportions if they are unequal.
</p>


<h3>Value</h3>

<p>The number of variance parameters in the corresponding Gaussian mixture
model. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bic">bic</a></code>, <code><a href="#topic+nVarParams">nVarParams</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mapply(nMclustParams, mclust.options("emModelNames"), d = 2, G = 3)
</code></pre>

<hr>
<h2 id='nVarParams'>
Number of Variance Parameters in Gaussian Mixture Models
</h2><span id='topic+nVarParams'></span>

<h3>Description</h3>

<p>Gives the number of variance parameters for parameterizations of the 
Gaussian mixture model that are used in MCLUST. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nVarParams(modelName, d, G, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nVarParams_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="nVarParams_+3A_d">d</code></td>
<td>

<p>The dimension of the data. Not used for models in which neither
the shape nor the orientation varies.
</p>
</td></tr>
<tr><td><code id="nVarParams_+3A_g">G</code></td>
<td>

<p>The number of components in the Gaussian mixture model used to compute
<code>loglik</code>.
</p>
</td></tr>
<tr><td><code id="nVarParams_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To get the total number of parameters in model, add <code>G*d</code> for the
means and <code>G-1</code> for the mixing proportions if they are unequal.
</p>


<h3>Value</h3>

<p>The number of variance parameters in the corresponding Gaussian mixture
model. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bic">bic</a></code>, <code><a href="#topic+nMclustParams">nMclustParams</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mapply(nVarParams, mclust.options("emModelNames"), d = 2, G = 3)
</code></pre>

<hr>
<h2 id='partconv'>Numeric Encoding of a Partitioning</h2><span id='topic+partconv'></span>

<h3>Description</h3>

<p>Converts a vector interpreted as a classification or partitioning 
into a numeric vector. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partconv(x, consec=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partconv_+3A_x">x</code></td>
<td>

<p>A vector interpreted as a classification or partitioning. 
</p>
</td></tr>
<tr><td><code id="partconv_+3A_consec">consec</code></td>
<td>

<p>Logical value indicating whether or not to consecutive class
numbers should be used .
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric encoding of <code>x</code>. 
When <code>consec = TRUE</code>, the distinct values in <code>x</code> are numbered by
the order in which they appear.
When <code>consec = FALSE</code>, each distinct value in <code>x</code> is numbered by
the index corresponding to its first appearance in <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partuniq">partuniq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>partconv(iris[,5])

set.seed(0)
cl &lt;- sample(LETTERS[1:9], 25, replace=TRUE)
partconv(cl, consec=FALSE)
partconv(cl, consec=TRUE)
</code></pre>

<hr>
<h2 id='partuniq'>
Classifies Data According to Unique Observations
</h2><span id='topic+partuniq'></span>

<h3>Description</h3>

<p>Gives a one-to-one mapping from unique observations to rows of a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partuniq(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partuniq_+3A_x">x</code></td>
<td>
<p>Matrix of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>nrow(x)</code> with integer entries. An observation
<code>k</code> is assigned an integer <code>i</code> whenever observation <code>i</code>
is the first row of <code>x</code> that is identical to observation <code>k</code>
(note that <code>i &lt;= k</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partconv">partconv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)

mat &lt;- data.frame(lets = sample(LETTERS[1:2],9,TRUE), nums = sample(1:2,9,TRUE))
mat

ans &lt;- partuniq(mat)
ans

partconv(ans,consec=TRUE)
</code></pre>

<hr>
<h2 id='plot.clustCombi'>
Plot Combined Clusterings Results
</h2><span id='topic+plot.clustCombi'></span>

<h3>Description</h3>

<p>Plot combined clusterings results: classifications corresponding to <code>Mclust</code>/BIC and to the hierarchically combined classes, &quot;entropy plots&quot; to help to select a number of classes, and the tree structure obtained from combining mixture components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clustCombi'
plot(x, what = c("classification", "entropy", "tree"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.clustCombi_+3A_x">x</code></td>
<td>

<p>Object returned by <code><a href="#topic+clustCombi">clustCombi</a></code> function.
</p>
</td></tr>
<tr><td><code id="plot.clustCombi_+3A_what">what</code></td>
<td>

<p>Type of plot.
</p>
</td></tr>
<tr><td><code id="plot.clustCombi_+3A_...">...</code></td>
<td>

<p>Other arguments to be passed to other functions: <code><a href="#topic+combiPlot">combiPlot</a></code>, <code><a href="#topic+entPlot">entPlot</a></code>, <code><a href="#topic+combiTree">combiTree</a></code>. Please see the corresponding documentations.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Classifications are plotted with <code><a href="#topic+combiPlot">combiPlot</a></code>, which relies on the <code>Mclust</code> plot functions. 
Entropy plots are plotted with <code><a href="#topic+entPlot">entPlot</a></code> and may help to select a number of classes: please see the article cited in the references.
Tree plots are produced by <code><a href="#topic+combiTree">combiTree</a></code> and graph the tree structure implied by the clusters combining  process. 
</p>


<h3>Author(s)</h3>

<p>J.-P. Baudry, A. E. Raftery, L. Scrucca
</p>


<h3>References</h3>

<p>J.-P. Baudry, A. E. Raftery, G. Celeux, K. Lo and R. Gottardo (2010). Combining mixture components for clustering. <em>Journal of Computational and Graphical Statistics, 19(2):332-353.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+combiPlot">combiPlot</a></code>, <code><a href="#topic+entPlot">entPlot</a></code>, <code><a href="#topic+combiTree">combiTree</a></code>, <code><a href="#topic+clustCombi">clustCombi</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Baudry_etal_2010_JCGS_examples)

## 1D Example 
output &lt;- clustCombi(data = Test1D, G=1:15)

# plots the hierarchy of combined solutions, then some "entropy plots" which 
# may help one to select the number of classes (please see the article cited 
# in the references)
plot(output) 

## 2D Example 
output &lt;- clustCombi(data = ex4.1) 

# plots the hierarchy of combined solutions, then some "entropy plots" which 
# may help one to select the number of classes (please see the article cited 
# in the references)
plot(output) 

## 3D Example 
output &lt;- clustCombi(data = ex4.4.2)

# plots the hierarchy of combined solutions, then some "entropy plots" which 
# may help one to select the number of classes (please see the article cited 
# in the references)
plot(output)


</code></pre>

<hr>
<h2 id='plot.densityMclust'>Plots for Mixture-Based Density Estimate</h2><span id='topic+plot.densityMclust'></span><span id='topic+plotDensityMclust1'></span><span id='topic+plotDensityMclust2'></span><span id='topic+plotDensityMclustd'></span>

<h3>Description</h3>

<p>Plotting methods for an object of class <code>'mclustDensity'</code>. Available graphs 
are plot of BIC values and density for univariate and bivariate data. For 
higher data dimensionality a scatterplot matrix of pairwise densities is
drawn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'densityMclust'
plot(x, data = NULL, what = c("BIC", "density", "diagnostic"), ...)

plotDensityMclust1(x, data = NULL, col = gray(0.3), hist.col = "lightgrey", 
                   hist.border = "white",  breaks = "Sturges", ...)

plotDensityMclust2(x, data = NULL, nlevels = 11, levels = NULL, 
                   prob = c(0.25, 0.5, 0.75),
                   points.pch = 1, points.col = 1, points.cex = 0.8, ...)

plotDensityMclustd(x, data = NULL, nlevels = 11, levels = NULL, 
                   prob = c(0.25, 0.5, 0.75),
                   points.pch = 1, points.col = 1, points.cex = 0.8,
                   gap = 0.2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.densityMclust_+3A_x">x</code></td>
<td>
<p>An object of class <code>'mclustDensity'</code> obtained from a call to
<code><a href="#topic+densityMclust">densityMclust</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_data">data</code></td>
<td>
<p>Optional data points.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_what">what</code></td>
<td>
<p>The type of graph requested:
</p>

<dl>
<dt><code>"density"</code> =</dt><dd><p>a plot of estimated density; if <code>data</code> is 
also provided the density is plotted over data points (see Details 
section).</p>
</dd>
<dt><code>"BIC"</code> =</dt><dd><p>a plot of BIC values for the estimated models versus
the number of components.</p>
</dd>
<dt><code>"diagnostic"</code> =</dt><dd><p>diagnostic plots (only available for the 
one-dimensional case, see <code><a href="#topic+densityMclust.diagnostic">densityMclust.diagnostic</a></code>)</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="plot.densityMclust_+3A_col">col</code></td>
<td>
<p>The color to be used to draw the density line in 1-dimension 
or contours in higher dimensions.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_hist.col">hist.col</code></td>
<td>
<p>The color to be used to fill the bars of the histogram.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_hist.border">hist.border</code></td>
<td>
<p>The color of the border around the bars of the histogram.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_breaks">breaks</code></td>
<td>
<p>See the argument in function <code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_points.pch">points.pch</code>, <code id="plot.densityMclust_+3A_points.col">points.col</code>, <code id="plot.densityMclust_+3A_points.cex">points.cex</code></td>
<td>
<p>The character symbols, colors, and magnification to be used for plotting <code>data</code> points.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_nlevels">nlevels</code></td>
<td>
<p>An integer, the number of levels to be used in plotting contour densities.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_levels">levels</code></td>
<td>
<p>A vector of density levels at which to draw the contour lines.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_prob">prob</code></td>
<td>
<p>A vector of probability levels for computing HDR. Only used if <code>type = "hdr"</code> and supersede previous <code>nlevels</code> and <code>levels</code> arguments.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_gap">gap</code></td>
<td>
<p>Distance between subplots, in margin lines, for the matrix of pairwise scatterplots.</p>
</td></tr>
<tr><td><code id="plot.densityMclust_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+surfacePlot">surfacePlot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plot.densityMclust</code> allows to obtain the plot of
estimated density or the graph of BIC values for evaluated models. 
</p>
<p>If <code>what = "density"</code> the produced plot dependes on the dimensionality
of the data.
</p>
<p>For one-dimensional data a call with no <code>data</code> provided produces a 
plot of the estimated density over a sensible range of values. If 
<code>data</code> is provided the density is over-plotted on a histogram for the
observed data. 
</p>
<p>For two-dimensional data further arguments available are those accepted by
the <code><a href="#topic+surfacePlot">surfacePlot</a></code> function. In particular, the density can be
represented through <code>"contour"</code>, <code>"hdr"</code>, <code>"image"</code>, and 
<code>"persp"</code> type of graph. 
For <code>type = "hdr"</code> Highest Density Regions (HDRs) are plotted for 
probability levels <code>prob</code>. See <code><a href="#topic+hdrlevels">hdrlevels</a></code> for details.
</p>
<p>For higher dimensionality a scatterplot matrix of pairwise projected
densities is drawn. 
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+densityMclust">densityMclust</a></code>,
<code><a href="#topic+surfacePlot">surfacePlot</a></code>,
<code><a href="#topic+densityMclust.diagnostic">densityMclust.diagnostic</a></code>, 
<code><a href="#topic+Mclust">Mclust</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dens &lt;- densityMclust(faithful$waiting, plot = FALSE)
summary(dens)
summary(dens, parameters = TRUE)
plot(dens, what = "BIC", legendArgs = list(x = "topright"))
plot(dens, what = "density", data = faithful$waiting)

dens &lt;- densityMclust(faithful, plot = FALSE)
summary(dens)
summary(dens, parameters = TRUE)
plot(dens, what = "density", data = faithful, 
     drawlabels = FALSE, points.pch = 20)
plot(dens, what = "density", type = "hdr")
plot(dens, what = "density", type = "hdr", prob = seq(0.1, 0.9, by = 0.1))
plot(dens, what = "density", type = "hdr", data = faithful)
plot(dens, what = "density", type = "persp")

dens &lt;- densityMclust(iris[,1:4], plot = FALSE)
summary(dens, parameters = TRUE)
plot(dens, what = "density", data = iris[,1:4], 
     col = "slategrey", drawlabels = FALSE, nlevels = 7)
plot(dens, what = "density", type = "hdr", data = iris[,1:4])
plot(dens, what = "density", type = "persp", col = grey(0.9))

</code></pre>

<hr>
<h2 id='plot.hc'>Dendrograms for Model-based Agglomerative Hierarchical Clustering</h2><span id='topic+plot.hc'></span>

<h3>Description</h3>

<p>Display two types for dendrograms for model-based hierarchical clustering
objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hc'
plot(x, what=c("loglik","merge"), maxG=NULL, labels=FALSE, hang=0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hc_+3A_x">x</code></td>
<td>

<p>An object of class <code>'hc'</code>.
</p>
</td></tr>
<tr><td><code id="plot.hc_+3A_what">what</code></td>
<td>

<p>A character string indicating the type of dendrogram to be displayed.<br />
Possible options are:
</p>

<dl>
<dt><code>"loglik"</code></dt><dd><p>Distances between dendrogram levels are based on
the classification likelihood.</p>
</dd>
<dt><code>"merge"</code></dt><dd><p>Distances between dendrogram levels are uniform,
so that levels correspond to the number of clusters.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="plot.hc_+3A_maxg">maxG</code></td>
<td>

<p>The maximum number of clusters for the dendrogram.
For <code>what = "merge"</code>, the default is the
number of clusters in the initial partition.
For <code>what = "loglik"</code>, the default is the minimnum of the
maximum number of clusters for which the classification loglikelihood
an be computed in most cases, and the maximum number of clusters for
which the classification likelihood increases with increasing numbers of
clusters.
</p>
</td></tr>
<tr><td><code id="plot.hc_+3A_labels">labels</code></td>
<td>

<p>A logical variable indicating whether or not to display leaf (observation)
labels for the dendrogram (row names of the data). These are likely to be 
useful only if the number of observations in fairly small, since otherwise
the labels will be too crowded to read. 
The default is not to display the leaf labels.
</p>
</td></tr>
<tr><td><code id="plot.hc_+3A_hang">hang</code></td>
<td>

<p>For <code>hclust</code> objects, this argument is the fraction of the plot 
height by which labels should hang below the rest of the plot. A negative 
value will cause the labels to hang down from 0.
Because model-based hierarchical clustering does not share all of the
properties of <code>hclust</code>, the <code>hang</code> argment won't work in
many instances.
</p>
</td></tr>
<tr><td><code id="plot.hc_+3A_...">...</code></td>
<td>

<p>Additional plotting arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plotting input does not share all of the properties of <code>hclust</code>
objects, hence not all plotting arguments associated with <code>hclust</code>
can be expected to work here.
</p>


<h3>Value</h3>

<p>A dendrogram is drawn, with distances based on either the classification
likelihood or the merge level (number of clusters). 
</p>


<h3>Note</h3>

<p>If <code>modelName = "E"</code> (univariate with equal variances) or
<code>modelName = "EII"</code> (multivariate with equal spherical
covariances), then the underlying model is the same as for
Ward's method for hierarchical clustering.
</p>


<h3>References</h3>

<p>J. D. Banfield and A. E. Raftery (1993).
Model-based Gaussian and non-Gaussian Clustering.
<em>Biometrics 49:803-821</em>. 
</p>
<p>C. Fraley (1998).
Algorithms for model-based Gaussian hierarchical clustering.
<em>SIAM Journal on Scientific Computing 20:270-281</em>. 
</p>
<p>C. Fraley and A. E. Raftery (2002).
Model-based clustering, discriminant analysis, and density estimation.
<em>Journal of the American Statistical Association 97:611-631</em>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hc">hc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(EuroUnemployment)
hcTree &lt;- hc(modelName = "VVV", data = EuroUnemployment)
plot(hcTree, what = "loglik")
plot(hcTree, what = "loglik", labels = TRUE)
plot(hcTree, what = "loglik", maxG = 5, labels = TRUE)
plot(hcTree, what = "merge")
plot(hcTree, what = "merge", labels = TRUE)
plot(hcTree, what = "merge", labels = TRUE, hang = 0.1)
plot(hcTree, what = "merge", labels = TRUE, hang = -1)
plot(hcTree, what = "merge", labels = TRUE, maxG = 5)
</code></pre>

<hr>
<h2 id='plot.Mclust'>Plotting method for Mclust model-based clustering</h2><span id='topic+plot.Mclust'></span>

<h3>Description</h3>

<p>Plots for model-based clustering results, such as BIC, classification, uncertainty and density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Mclust'
plot(x, what = c("BIC", "classification", "uncertainty", "density"), 
     dimens = NULL, xlab = NULL, ylab = NULL,
     addEllipses = TRUE, main = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Mclust_+3A_x">x</code></td>
<td>

<p>Output from <code>Mclust</code>.
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_what">what</code></td>
<td>

<p>A string specifying the type of graph requested. Available choices are:
</p>

<dl>
<dt><code>"BIC"</code></dt><dd><p>plot of BIC values used for choosing the number of clusters.</p>
</dd>
<dt><code>"classification"</code> =</dt><dd><p>a plot showing the clustering. For data in more than two dimensions a pairs plot is produced, followed by a coordinate projection plot using specified <code>dimens</code>. Ellipses corresponding to covariances of mixture components are also drawn if <code>addEllipses = TRUE</code>.</p>
</dd>
<dt><code>"uncertainty"</code></dt><dd><p>a plot of classification uncertainty. For data in more than two dimensions a coordinate projection plot is drawn using specified <code>dimens</code>.</p>
</dd>
<dt><code>"density"</code></dt><dd><p>a plot of estimated density. For data in more than two dimensions a matrix of contours for coordinate projection plot is drawn using specified <code>dimens</code>.</p>
</dd>
</dl>

<p>If not specified, in interactive sessions a menu of choices is proposed.
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_dimens">dimens</code></td>
<td>

<p>A vector of integers specifying the dimensions of the coordinate projections
in case of <code>"classification"</code>, <code>"uncertainty"</code>, or <code>"density"</code>
plots. 
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_xlab">xlab</code>, <code id="plot.Mclust_+3A_ylab">ylab</code></td>
<td>

<p>Optional labels for the x-axis and the y-axis.
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_addellipses">addEllipses</code></td>
<td>

<p>A logical indicating whether or not to add ellipses with axes 
corresponding to the within-cluster covariances in case of 
<code>"classification"</code> or <code>"uncertainty"</code> plots. 
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_main">main</code></td>
<td>

<p>A logical or <code>NULL</code> indicating whether or not to add a title 
to the plot identifying the type of plot drawn.
</p>
</td></tr>
<tr><td><code id="plot.Mclust_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more flexibility in plotting, use <code>mclust1Dplot</code>, 
<code>mclust2Dplot</code>, <code>surfacePlot</code>, <code>coordProj</code>, or
<code>randProj</code>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>,
<code><a href="#topic+plot.mclustBIC">plot.mclustBIC</a></code>,
<code><a href="#topic+plot.mclustICL">plot.mclustICL</a></code>,
<code><a href="#topic+mclust1Dplot">mclust1Dplot</a></code>,
<code><a href="#topic+mclust2Dplot">mclust2Dplot</a></code>,
<code><a href="#topic+surfacePlot">surfacePlot</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>,
<code><a href="#topic+randProj">randProj</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
precipMclust &lt;- Mclust(precip)
plot(precipMclust)

faithfulMclust &lt;- Mclust(faithful)
plot(faithfulMclust)

irisMclust &lt;- Mclust(iris[,-5])
plot(irisMclust)

</code></pre>

<hr>
<h2 id='plot.mclustBIC'>BIC Plot for Model-Based Clustering</h2><span id='topic+plot.mclustBIC'></span>

<h3>Description</h3>

<p>Plots the BIC values returned by the <code><a href="#topic+mclustBIC">mclustBIC</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mclustBIC'
plot(x, G = NULL, modelNames = NULL, 
     symbols = NULL, colors = NULL, 
     xlab = NULL, ylab = "BIC", 
     legendArgs = list(x = "bottomright", ncol = 2, cex = 1, inset = 0.01), 
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mclustBIC_+3A_x">x</code></td>
<td>

<p>Output from <code>mclustBIC</code>.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_g">G</code></td>
<td>

<p>One or more numbers of components corresponding to models fit in <code>x</code>.
The default is to plot the BIC for all of the numbers of components fit.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_modelnames">modelNames</code></td>
<td>

<p>One or more model names corresponding to models fit in <code>x</code>.
The default is to plot the BIC for all of the models fit.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_xlab">xlab</code></td>
<td>

<p>Optional label for the horizontal axis of the BIC plot.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_ylab">ylab</code></td>
<td>

<p>Label for the vertical axis of the BIC plot.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_legendargs">legendArgs</code></td>
<td>

<p>Arguments to pass to the <code>legend</code> function. Set to <code>NULL</code>
for no legend.
</p>
</td></tr>
<tr><td><code id="plot.mclustBIC_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the BIC values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plot(mclustBIC(precip), legendArgs =  list(x = "bottomleft"))

plot(mclustBIC(faithful))

plot(mclustBIC(iris[,-5]))

</code></pre>

<hr>
<h2 id='plot.MclustBootstrap'>Plot of bootstrap distributions for mixture model parameters</h2><span id='topic+plot.MclustBootstrap'></span>

<h3>Description</h3>

<p>Plots the bootstrap distribution of parameters as returned by the <code><a href="#topic+MclustBootstrap">MclustBootstrap</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustBootstrap'
plot(x, what = c("pro", "mean", "var"), 
     show.parest = TRUE, show.confint = TRUE,
     hist.col = "grey", hist.border = "lightgrey", breaks = "Sturges", 
     col = "forestgreen", lwd = 2, lty = 3, 
     xlab = NULL, xlim = NULL, ylim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.MclustBootstrap_+3A_x">x</code></td>
<td>
<p>Object returned by <code>MclustBootstrap</code>.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_what">what</code></td>
<td>
<p>Character string specifying if mixing proportions (<code>"pro"</code>),
component means (<code>"mean"</code>) or component variances (<code>"var"</code>) 
should be drawn.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_show.parest">show.parest</code></td>
<td>
<p>A logical specifying if the parameter estimate should be drawn as vertical line.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_show.confint">show.confint</code></td>
<td>
<p>A logical specifying if the resampling-based confidence interval should be drawn at the bottom of the graph. Confidence level can be provided as further argument <code>conf.level</code>; see <code><a href="#topic+summary.MclustBootstrap">summary.MclustBootstrap</a></code>.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_hist.col">hist.col</code></td>
<td>
<p>The color to be used to fill the bars of the histograms.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_hist.border">hist.border</code></td>
<td>
<p>The color of the border around the bars of the histograms.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_breaks">breaks</code></td>
<td>
<p>See the argument in function <code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_col">col</code>, <code id="plot.MclustBootstrap_+3A_lwd">lwd</code>, <code id="plot.MclustBootstrap_+3A_lty">lty</code></td>
<td>
<p>The color, line width and line type to be used to represent the estimated parameters and confidence intervals.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_xlab">xlab</code></td>
<td>
<p>Optional label for the horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_xlim">xlim</code>, <code id="plot.MclustBootstrap_+3A_ylim">ylim</code></td>
<td>
<p>A two-values vector of axis range for, respectively, horizontal and
vertical axis.</p>
</td></tr>
<tr><td><code id="plot.MclustBootstrap_+3A_...">...</code></td>
<td>
<p>Other graphics parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot for each variable/component of the selected parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustBootstrap">MclustBootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(diabetes)
X &lt;- diabetes[,-1]
modClust &lt;- Mclust(X, G = 3, modelNames = "VVV")
bootClust &lt;- MclustBootstrap(modClust, nboot = 99)
par(mfrow = c(1,3), mar = c(4,2,2,0.5))
plot(bootClust, what = "pro")
par(mfrow = c(3,3), mar = c(4,2,2,0.5))
plot(bootClust, what = "mean")

</code></pre>

<hr>
<h2 id='plot.MclustDA'>Plotting method for MclustDA discriminant analysis</h2><span id='topic+plot.MclustDA'></span>

<h3>Description</h3>

<p>Plots for model-based mixture discriminant analysis results, such as scatterplot of training and test data, classification of train and test data, and errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustDA'
plot(x, what = c("scatterplot", "classification", "train&amp;test", "error"), 
     newdata, newclass, dimens = NULL, 
     symbols, colors, main = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.MclustDA_+3A_x">x</code></td>
<td>

<p>An object of class <code>'MclustDA'</code> resulting from a call to <code><a href="#topic+MclustDA">MclustDA</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_what">what</code></td>
<td>

<p>A string specifying the type of graph requested. Available choices are:
</p>

<dl>
<dt><code>"scatterplot"</code> =</dt><dd><p>a plot of training data with points marked based on the known classification. Ellipses corresponding to covariances of mixture components are also drawn.</p>
</dd>
<dt><code>"classification"</code> =</dt><dd><p>a plot of data with points marked on based the predicted classification; if <code>newdata</code> is provided then the test set is shown otherwise the training set.</p>
</dd>
<dt><code>"train&amp;test"</code> =</dt><dd><p>a plot of training and test data with points marked according to the type of set.</p>
</dd>
<dt><code>"error"</code> =</dt><dd><p>a plot of training set (or test set if <code>newdata</code> and <code>newclass</code> are provided) with misclassified points marked.</p>
</dd>
</dl>

<p>If not specified, in interactive sessions a menu of choices is proposed.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_newdata">newdata</code></td>
<td>

<p>A data frame or matrix for test data.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_newclass">newclass</code></td>
<td>

<p>A vector giving the class labels for the observations in 
the test data (if known).
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_dimens">dimens</code></td>
<td>

<p>A vector of integers giving the dimensions of the desired coordinate
projections for multivariate data. The default is to take all the
the available dimensions for plotting.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class. Elements in <code>colors</code> correspond to classes in order of
appearance in the sequence of observations (the order used by the 
function <code>factor</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>factor</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_main">main</code></td>
<td>

<p>A logical, a character string, or <code>NULL</code> (default) for the main title. 
If <code>NULL</code> or <code>FALSE</code> no title is added to a plot. 
If <code>TRUE</code> a default title is added identifying the type of plot drawn.
If a character string is provided, this is used for the title.
</p>
</td></tr>
<tr><td><code id="plot.MclustDA_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more flexibility in plotting, use <code>mclust1Dplot</code>, 
<code>mclust2Dplot</code>, <code>surfacePlot</code>, <code>coordProj</code>, or
<code>randProj</code>. 
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>,
<code><a href="#topic+surfacePlot">surfacePlot</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>,
<code><a href="#topic+randProj">randProj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
odd &lt;- seq(from = 1, to = nrow(iris), by = 2)
even &lt;- odd + 1
X.train &lt;- iris[odd,-5]
Class.train &lt;- iris[odd,5]
X.test &lt;- iris[even,-5]
Class.test &lt;- iris[even,5]

# common EEE covariance structure (which is essentially equivalent to linear discriminant analysis)
irisMclustDA &lt;- MclustDA(X.train, Class.train, modelType = "EDDA", modelNames = "EEE")
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

# common covariance structure selected by BIC
irisMclustDA &lt;- MclustDA(X.train, Class.train, modelType = "EDDA")
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

# general covariance structure selected by BIC
irisMclustDA &lt;- MclustDA(X.train, Class.train)
summary(irisMclustDA, parameters = TRUE)
summary(irisMclustDA, newdata = X.test, newclass = Class.test)

plot(irisMclustDA)
plot(irisMclustDA, dimens = 3:4)
plot(irisMclustDA, dimens = 4)

plot(irisMclustDA, what = "classification")
plot(irisMclustDA, what = "classification", newdata = X.test)
plot(irisMclustDA, what = "classification", dimens = 3:4)
plot(irisMclustDA, what = "classification", newdata = X.test, dimens = 3:4)
plot(irisMclustDA, what = "classification", dimens = 4)
plot(irisMclustDA, what = "classification", dimens = 4, newdata = X.test)

plot(irisMclustDA, what = "train&amp;test", newdata = X.test)
plot(irisMclustDA, what = "train&amp;test", newdata = X.test, dimens = 3:4)
plot(irisMclustDA, what = "train&amp;test", newdata = X.test, dimens = 4)

plot(irisMclustDA, what = "error")
plot(irisMclustDA, what = "error", dimens = 3:4)
plot(irisMclustDA, what = "error", dimens = 4)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test, dimens = 3:4)
plot(irisMclustDA, what = "error", newdata = X.test, newclass = Class.test, dimens = 4)

# simulated 1D data
n &lt;- 250 
set.seed(1)
triModal &lt;- c(rnorm(n,-5), rnorm(n,0), rnorm(n,5))
triClass &lt;- c(rep(1,n), rep(2,n), rep(3,n))
odd &lt;- seq(from = 1, to = length(triModal), by = 2)
even &lt;- odd + 1
triMclustDA &lt;- MclustDA(triModal[odd], triClass[odd])
summary(triMclustDA, parameters = TRUE)
summary(triMclustDA, newdata = triModal[even], newclass = triClass[even])
plot(triMclustDA)
plot(triMclustDA, what = "classification")
plot(triMclustDA, what = "classification", newdata = triModal[even])
plot(triMclustDA, what = "train&amp;test", newdata = triModal[even])
plot(triMclustDA, what = "error")
plot(triMclustDA, what = "error", newdata = triModal[even], newclass = triClass[even])

# simulated 2D cross data
data(cross)
odd &lt;- seq(from = 1, to = nrow(cross), by = 2)
even &lt;- odd + 1
crossMclustDA &lt;- MclustDA(cross[odd,-1], cross[odd,1])
summary(crossMclustDA, parameters = TRUE)
summary(crossMclustDA, newdata = cross[even,-1], newclass = cross[even,1])
plot(crossMclustDA)
plot(crossMclustDA, what = "classification")
plot(crossMclustDA, what = "classification", newdata = cross[even,-1])
plot(crossMclustDA, what = "train&amp;test", newdata = cross[even,-1])
plot(crossMclustDA, what = "error")
plot(crossMclustDA, what = "error", newdata =cross[even,-1], newclass = cross[even,1])

</code></pre>

<hr>
<h2 id='plot.MclustDR'>Plotting method for dimension reduction for model-based clustering and classification</h2><span id='topic+plot.MclustDR'></span><span id='topic+plotEvalues.MclustDR'></span>

<h3>Description</h3>

<p>Graphs data projected onto the estimated subspace for model-based clustering and classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustDR'
plot(x, dimens, 
     what = c("scatterplot", "pairs", "contour", "classification",
              "boundaries", "density", "evalues"), 
     symbols, colors, col.contour = gray(0.7), col.sep = grey(0.4), 
     ngrid = 200, nlevels = 5, asp = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.MclustDR_+3A_x">x</code></td>
<td>

<p>An object of class <code>'MclustDR'</code> resulting from a call to <code><a href="#topic+MclustDR">MclustDR</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_dimens">dimens</code></td>
<td>

<p>A vector of integers giving the dimensions of the desired coordinate
projections for multivariate data.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_what">what</code></td>
<td>

<p>The type of graph requested: 
</p>

<dl>
<dt><code>"scatterplot"</code> =</dt><dd><p>a two-dimensional plot of data projected onto the first two directions specified by <code>dimens</code> and with data points marked according to the corresponding mixture component.
By default, the first two directions are selected for plotting.</p>
</dd>
<dt><code>"pairs"</code> =</dt><dd><p>a scatterplot matrix of data projected onto the estimated subspace and with data points marked according to the corresponding mixture component.
By default, all the available directions are used, unless they have been specified by <code>dimens</code>.</p>
</dd>
<dt><code>"contour"</code> =</dt><dd><p>a two-dimensional plot of data projected onto the first two directions specified by <code>dimens</code> (by default, the first two directions) with density contours for classes or clusters and data points marked according to the corresponding mixture component.</p>
</dd>
<dt><code>"classification"</code> =</dt><dd><p>a two-dimensional plot of data projected onto the first two directions specified by <code>dimens</code> (by default, the first two directions) with classification region and data points marked according to the corresponding mixture component.</p>
</dd>
<dt><code>"boundaries"</code> =</dt><dd><p>a two-dimensional plot of data projected onto the first two directions specified by <code>dimens</code> (by default, the first two directions) with uncertainty boundaries and data points marked according to the corresponding mixture component.
The uncertainty is shown using a greyscale with darker regions indicating higher uncertainty.
</p>
</dd>
<dt><code>"density"</code> =</dt><dd><p>a one-dimensional plot of estimated density for the first direction specified by <code>dimens</code> (by default, the first one). A set of box-plots for each estimated cluster or known class are also shown at the bottom of the graph.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="plot.MclustDR_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique mixture component. Elements in <code>colors</code> correspond to classes
in order of appearance in the sequence of observations (the order used by
the function <code>factor</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique cluster or known class. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>factor</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_col.contour">col.contour</code></td>
<td>

<p>The color of contours in case <code>what = "contour"</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_col.sep">col.sep</code></td>
<td>

<p>The color of classification boundaries in case <code>what = "classification"</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_ngrid">ngrid</code></td>
<td>

<p>An integer specifying the number of grid points to use in evaluating the classification regions.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_nlevels">nlevels</code></td>
<td>

<p>The number of levels to use in case <code>what = "contour"</code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_asp">asp</code></td>
<td>
<p>For scatterplots the <code class="reqn">y/x</code> aspect ratio, see
<code><a href="graphics.html#topic+plot.window">plot.window</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustDR_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca, L. (2010) Dimension reduction for model-based clustering.
<em>Statistics and Computing</em>, 20(4), pp. 471-484.
</p>


<h3>See Also</h3>

<p><a href="#topic+MclustDR">MclustDR</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod &lt;- Mclust(iris[,1:4], G = 3)
dr &lt;- MclustDR(mod, lambda = 0.5)
plot(dr, what = "evalues")
plot(dr, what = "pairs")
plot(dr, what = "scatterplot", dimens = c(1,3))
plot(dr, what = "contour")
plot(dr, what = "classification", ngrid = 200)
plot(dr, what = "boundaries", ngrid = 200)
plot(dr, what = "density")
plot(dr, what = "density", dimens = 2)

data(banknote)
da &lt;- MclustDA(banknote[,2:7], banknote$Status, G = 1:3)
dr &lt;- MclustDR(da)
plot(dr, what = "evalues")
plot(dr, what = "pairs")
plot(dr, what = "contour")
plot(dr, what = "classification", ngrid = 200)
plot(dr, what = "boundaries", ngrid = 200)
plot(dr, what = "density")
plot(dr, what = "density", dimens = 2)

</code></pre>

<hr>
<h2 id='plot.mclustICL'>ICL Plot for Model-Based Clustering</h2><span id='topic+plot.mclustICL'></span>

<h3>Description</h3>

<p>Plots the ICL values returned by the <code><a href="#topic+mclustICL">mclustICL</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mclustICL'
plot(x, ylab = "ICL", ...)     
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mclustICL_+3A_x">x</code></td>
<td>

<p>Output from <code><a href="#topic+mclustICL">mclustICL</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.mclustICL_+3A_ylab">ylab</code></td>
<td>

<p>Label for the vertical axis of the plot.
</p>
</td></tr>
<tr><td><code id="plot.mclustICL_+3A_...">...</code></td>
<td>

<p>Further arguments passed to the <code><a href="#topic+plot.mclustBIC">plot.mclustBIC</a></code> function.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the ICL values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustICL">mclustICL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(faithful)
faithful.ICL = mclustICL(faithful)
plot(faithful.ICL)

</code></pre>

<hr>
<h2 id='plot.MclustSSC'>Plotting method for MclustSSC semi-supervised classification</h2><span id='topic+plot.MclustSSC'></span>

<h3>Description</h3>

<p>Plots for semi-supervised classification based on Gaussian finite mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustSSC'
plot(x, what = c("BIC", "classification", "uncertainty"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.MclustSSC_+3A_x">x</code></td>
<td>

<p>An object of class <code>'MclustSSC'</code> resulting from a call to <code><a href="#topic+MclustSSC">MclustSSC</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.MclustSSC_+3A_what">what</code></td>
<td>

<p>A string specifying the type of graph requested. Available choices are:
</p>

<dl>
<dt><code>"BIC"</code> =</dt><dd><p>plot of BIC values used for model selection, i.e. for choosing the model class covariances.</p>
</dd>
<dt><code>"classification"</code> =</dt><dd><p>a plot of data with points marked based on the known and the predicted classification.</p>
</dd>
<dt><code>"uncertainty"</code> =</dt><dd><p>a plot of classification uncertainty.</p>
</dd>
</dl>

<p>If not specified, in interactive sessions a menu of choices is proposed.
</p>
</td></tr>
<tr><td><code id="plot.MclustSSC_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods. See  <code><a href="#topic+plot.Mclust">plot.Mclust</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustSSC">MclustSSC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[,1:4]
class &lt;- iris$Species
# randomly remove class labels
set.seed(123)
class[sample(1:length(class), size = 120)] &lt;- NA
table(class, useNA = "ifany")
clPairs(X, ifelse(is.na(class), 0, class),
        symbols = c(0, 16, 17, 18), colors = c("grey", 4, 2, 3),
        main = "Partially classified data")

# Fit semi-supervised classification model
mod_SSC  &lt;- MclustSSC(X, class)
summary(mod_SSC, parameters = TRUE)

pred_SSC &lt;- predict(mod_SSC)
table(Predicted = pred_SSC$classification, Actual = class, useNA = "ifany")

plot(mod_SSC, what = "BIC")
plot(mod_SSC, what = "classification")
plot(mod_SSC, what = "uncertainty")
</code></pre>

<hr>
<h2 id='predict.densityMclust'>Density estimate of multivariate observations by Gaussian finite mixture modeling</h2><span id='topic+predict.densityMclust'></span>

<h3>Description</h3>

<p>Compute density estimation for multivariate observations based on Gaussian finite mixture models estimated by <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'densityMclust'
predict(object, newdata, what = c("dens", "cdens", "z"), logarithm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.densityMclust_+3A_object">object</code></td>
<td>
<p>an object of class <code>'densityMclust'</code> resulting from a call to <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>
</td></tr>
<tr><td><code id="predict.densityMclust_+3A_newdata">newdata</code></td>
<td>
<p>a vector, a data frame or matrix giving the data. If missing the density is computed for the input data obtained from the call to <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>
</td></tr>
<tr><td><code id="predict.densityMclust_+3A_what">what</code></td>
<td>
<p>a character string specifying what to retrieve: <code>"dens"</code> returns a vector of values for the mixture density; <code>"cdens"</code> returns a matrix of component densities for each mixture component (along the columns); <code>"z"</code> returns a matrix of conditional probabilities of each data point to belong to a mixture component.</p>
</td></tr>
<tr><td><code id="predict.densityMclust_+3A_logarithm">logarithm</code></td>
<td>
<p>A logical value indicating whether or not the logarithm of the density or component densities should be returned.</p>
</td></tr>
<tr><td><code id="predict.densityMclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector or a matrix of densities evaluated at <code>newdata</code> depending on the argument <code>what</code> (see above).
</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- faithful$waiting
dens &lt;- densityMclust(x, plot = FALSE)
x0 &lt;- seq(50, 100, by = 10)
d0 &lt;- predict(dens, x0)
plot(dens, what = "density")
points(x0, d0, pch = 20)

</code></pre>

<hr>
<h2 id='predict.Mclust'>Cluster multivariate observations by Gaussian finite mixture modeling</h2><span id='topic+predict.Mclust'></span>

<h3>Description</h3>

<p>Cluster prediction for multivariate observations based on Gaussian finite mixture models estimated by <code><a href="#topic+Mclust">Mclust</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'Mclust'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Mclust_+3A_object">object</code></td>
<td>
<p>an object of class <code>'Mclust'</code> resulting from a call to <code><a href="#topic+Mclust">Mclust</a></code>.</p>
</td></tr>
<tr><td><code id="predict.Mclust_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix giving the data. If missing the clustering data obtained from the call to <code><a href="#topic+Mclust">Mclust</a></code> are classified.</p>
</td></tr>
<tr><td><code id="predict.Mclust_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of with the following components:
</p>
<table>
<tr><td><code>classification</code></td>
<td>
<p>a factor of predicted cluster labels for <code>newdata</code>.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>a matrix whose <em>[i,k]</em>th entry is the probability that 
observation <em>i</em> in <code>newdata</code> belongs to the <em>k</em>th cluster.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- Mclust(faithful)

# predict cluster for the observed data
pred &lt;- predict(model) 
str(pred)
pred$z              # equal to model$z
pred$classification # equal to 
plot(faithful, col = pred$classification, pch = pred$classification)

# predict cluster over a grid
grid &lt;- apply(faithful, 2, function(x) seq(min(x), max(x), length = 50))
grid &lt;- expand.grid(eruptions = grid[,1], waiting = grid[,2])
pred &lt;- predict(model, grid)
plot(grid, col = mclust.options("classPlotColors")[pred$classification], pch = 15, cex = 0.5)
points(faithful, pch = model$classification)
</code></pre>

<hr>
<h2 id='predict.MclustDA'>Classify multivariate observations by Gaussian finite mixture modeling</h2><span id='topic+predict.MclustDA'></span>

<h3>Description</h3>

<p>Classify multivariate observations based on Gaussian finite mixture models estimated by <code><a href="#topic+MclustDA">MclustDA</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'MclustDA'
predict(object, newdata, prop = object$prop, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MclustDA_+3A_object">object</code></td>
<td>
<p>an object of class <code>'MclustDA'</code> resulting from a call to <code><a href="#topic+MclustDA">MclustDA</a></code>.</p>
</td></tr>
<tr><td><code id="predict.MclustDA_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix giving the data. If missing the train data obtained from the call to <code><a href="#topic+MclustDA">MclustDA</a></code> are classified.</p>
</td></tr>
<tr><td><code id="predict.MclustDA_+3A_prop">prop</code></td>
<td>
<p>the class proportions or prior class probabilities to belong to each class; by default, this is set at the class proportions in the training data.</p>
</td></tr>
<tr><td><code id="predict.MclustDA_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of with the following components:
</p>
<table>
<tr><td><code>classification</code></td>
<td>
<p>a factor of predicted class labels for <code>newdata</code>.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>a matrix whose <em>[i,k]</em>th entry is the probability that 
observation <em>i</em> in <code>newdata</code> belongs to the <em>k</em>th class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
odd &lt;- seq(from = 1, to = nrow(iris), by = 2)
even &lt;- odd + 1
X.train &lt;- iris[odd,-5]
Class.train &lt;- iris[odd,5]
X.test &lt;- iris[even,-5]
Class.test &lt;- iris[even,5]

irisMclustDA &lt;- MclustDA(X.train, Class.train)

predTrain &lt;- predict(irisMclustDA)
predTrain
predTest &lt;- predict(irisMclustDA, X.test)
predTest

</code></pre>

<hr>
<h2 id='predict.MclustDR'>Classify multivariate observations on a dimension reduced subspace by Gaussian finite mixture modeling</h2><span id='topic+predict.MclustDR'></span><span id='topic+predict2D.MclustDR'></span>

<h3>Description</h3>

<p>Classify multivariate observations on a dimension reduced subspace estimated from a Gaussian finite mixture model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'MclustDR'
predict(object, dim = 1:object$numdir, newdata, eval.points, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MclustDR_+3A_object">object</code></td>
<td>
<p>an object of class <code>'MclustDR'</code> resulting from a call to <code><a href="#topic+MclustDR">MclustDR</a>.</code></p>
</td></tr>
<tr><td><code id="predict.MclustDR_+3A_dim">dim</code></td>
<td>
<p>the dimensions of the reduced subspace used for prediction.</p>
</td></tr>
<tr><td><code id="predict.MclustDR_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix giving the data. If missing the data obtained from the call to <code><a href="#topic+MclustDR">MclustDR</a></code> are used.</p>
</td></tr>
<tr><td><code id="predict.MclustDR_+3A_eval.points">eval.points</code></td>
<td>
<p>a data frame or matrix giving the data projected on the reduced subspace. If provided <code>newdata</code> is not used.</p>
</td></tr>
<tr><td><code id="predict.MclustDR_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of with the following components:
</p>
<table>
<tr><td><code>dir</code></td>
<td>
<p>a matrix containing the data projected onto the <code>dim</code> dimensions of the reduced subspace.</p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>densities from mixture model for each data point.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>a matrix whose <em>[i,k]</em>th entry is the probability that 
observation <em>i</em> in <code>newdata</code> belongs to the <em>k</em>th class.</p>
</td></tr>
<tr><td><code>uncertainty</code></td>
<td>
<p>The uncertainty associated with the classification.</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>
<p>A vector of values giving the MAP classification.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>References</h3>

<p>Scrucca, L. (2010) Dimension reduction for model-based clustering. 
<em>Statistics and Computing</em>, 20(4), pp. 471-484.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDR">MclustDR</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod = Mclust(iris[,1:4])
dr = MclustDR(mod)
pred = predict(dr)
str(pred)

data(banknote)
mod = MclustDA(banknote[,2:7], banknote$Status)
dr = MclustDR(mod)
pred = predict(dr)
str(pred)
</code></pre>

<hr>
<h2 id='predict.MclustSSC'>Classification of multivariate observations by semi-supervised Gaussian finite mixtures</h2><span id='topic+predict.MclustSSC'></span>

<h3>Description</h3>

<p>Classify multivariate observations based on Gaussian finite mixture models estimated by <code><a href="#topic+MclustSSC">MclustSSC</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'MclustSSC'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MclustSSC_+3A_object">object</code></td>
<td>
<p>an object of class <code>'MclustSSC'</code> resulting from a call to <code><a href="#topic+MclustSSC">MclustSSC</a></code>.</p>
</td></tr>
<tr><td><code id="predict.MclustSSC_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix giving the data. If missing the train data obtained from the call to <code><a href="#topic+MclustSSC">MclustSSC</a></code> are classified.</p>
</td></tr>
<tr><td><code id="predict.MclustSSC_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of with the following components:
</p>
<table>
<tr><td><code>classification</code></td>
<td>
<p>a factor of predicted class labels for <code>newdata</code>.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>a matrix whose <em>[i,k]</em>th entry is the probability that 
observation <em>i</em> in <code>newdata</code> belongs to the <em>k</em>th class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustSSC">MclustSSC</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- iris[,1:4]
class &lt;- iris$Species
# randomly remove class labels
set.seed(123)
class[sample(1:length(class), size = 120)] &lt;- NA
table(class, useNA = "ifany")
clPairs(X, ifelse(is.na(class), 0, class),
        symbols = c(0, 16, 17, 18), colors = c("grey", 4, 2, 3),
        main = "Partially classified data")

# Fit semi-supervised classification model
mod_SSC  &lt;- MclustSSC(X, class)

pred_SSC &lt;- predict(mod_SSC)
table(Predicted = pred_SSC$classification, Actual = class, useNA = "ifany")

X_new = data.frame(Sepal.Length = c(5, 8),
                   Sepal.Width  = c(3.1, 4),
                   Petal.Length = c(2, 5),
                   Petal.Width  = c(0.5, 2))
predict(mod_SSC, newdata = X_new)

</code></pre>

<hr>
<h2 id='priorControl'>
Conjugate Prior for Gaussian Mixtures.
</h2><span id='topic+priorControl'></span>

<h3>Description</h3>

<p>Specify a conjugate prior for Gaussian mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorControl(functionName = "defaultPrior", ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="priorControl_+3A_functionname">functionName</code></td>
<td>

<p>The name of the function specifying the conjugate prior.
By default the function <code><a href="#topic+defaultPrior">defaultPrior</a></code> is used, and this 
can also be used as a template for alternative specification.  
</p>
</td></tr>
<tr><td><code id="priorControl_+3A_...">...</code></td>
<td>

<p>Optional named arguments to the function specified in <code>functionName</code>
together with their values.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>priorControl</code> is used to specify a conjugate prior  
for EM within <em>MCLUST</em>.<br />
Note that, as described in <code><a href="#topic+defaultPrior">defaultPrior</a></code>, in the multivariate 
case only 10 out of 14 models may be used in conjunction with a prior, i.e.
those available in <em>MCLUST</em> up to version 4.4.
</p>


<h3>Value</h3>

<p>A list with the function name as the first component. The remaining
components (if any) consist of a list of arguments to the function
with assigned values.
</p>


<h3>References</h3>

<p>C. Fraley and A. E. Raftery (2007).
Bayesian regularization for normal mixture estimation and model-based
clustering. <em>Journal of Classification 24:155-181</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="#topic+defaultPrior">defaultPrior</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># default prior
irisBIC &lt;- mclustBIC(iris[,-5], prior = priorControl())
summary(irisBIC, iris[,-5])

# no prior on the mean; default prior on variance
irisBIC &lt;- mclustBIC(iris[,-5], prior = priorControl(shrinkage = 0))
summary(irisBIC, iris[,-5])
</code></pre>

<hr>
<h2 id='randomOrthogonalMatrix'>Random orthogonal matrix</h2><span id='topic+randomOrthogonalMatrix'></span>

<h3>Description</h3>

<p>Generate a random orthogonal basis matrix of dimension <code class="reqn">(nrow x ncol)</code> using 
the method in Heiberger (1978).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomOrthogonalMatrix(nrow, ncol, n = nrow, d = ncol, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomOrthogonalMatrix_+3A_nrow">nrow</code></td>
<td>
<p>the number of rows of the resulting orthogonal matrix.</p>
</td></tr>
<tr><td><code id="randomOrthogonalMatrix_+3A_ncol">ncol</code></td>
<td>
<p>the number of columns of the resulting orthogonal matrix.</p>
</td></tr>
<tr><td><code id="randomOrthogonalMatrix_+3A_n">n</code></td>
<td>
<p>deprecated. See <code>nrow</code> above.</p>
</td></tr>
<tr><td><code id="randomOrthogonalMatrix_+3A_d">d</code></td>
<td>
<p>deprecated. See <code>ncol</code> above.</p>
</td></tr>
<tr><td><code id="randomOrthogonalMatrix_+3A_seed">seed</code></td>
<td>
<p>an optional integer argument to use in <code>set.seed()</code> for 
reproducibility. By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed()</code>
before calling this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The use of arguments <code>n</code> and <code>d</code> is deprecated and they will be removed in the future.
</p>


<h3>Value</h3>

<p>An orthogonal matrix of dimension <code class="reqn">nrow x ncol</code> such that each column is orthogonal to the other and has unit lenght. Because of the latter, it is also called orthonormal.
</p>


<h3>References</h3>

<p>Heiberger R. (1978) Generation of random orthogonal matrices. <em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em>, 27(2), 199-206.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coordProj">coordProj</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>B &lt;- randomOrthogonalMatrix(10,3)
zapsmall(crossprod(B))
</code></pre>

<hr>
<h2 id='randProj'>Random projections of multidimensional data modeled by an MVN mixture</h2><span id='topic+randProj'></span>

<h3>Description</h3>

<p>Plots random projections given multidimensional data
and parameters of an MVN mixture model for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randProj(data, seeds = NULL, parameters = NULL, z = NULL,
         classification = NULL, truth = NULL, uncertainty = NULL, 
         what = c("classification", "error", "uncertainty"),
         quantiles = c(0.75, 0.95), 
         addEllipses = TRUE, fillEllipses = mclust.options("fillEllipses"),
         symbols = NULL, colors = NULL, scale = FALSE, 
         xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL,
         cex = 1, PCH = ".", main = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randProj_+3A_data">data</code></td>
<td>

<p>A numeric matrix or data frame of observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_seeds">seeds</code></td>
<td>

<p>An integer value or a vector of integer values to be used as seed for 
random number generation. If multiple values are provided, then each seed 
should produce a different projection. 
By default, a single seed is drawn randomnly, so each call of 
<code>randProj()</code> produces different projections.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_parameters">parameters</code></td>
<td>

<p>A named list giving the parameters of an <em>MCLUST</em> model, 
used to produce superimposing ellipses on the plot. 
The relevant components are as follows:
</p>

<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="randProj_+3A_z">z</code></td>
<td>

<p>A matrix in which the <code>[i,k]</code>th entry gives the
probability of observation <em>i</em> belonging to the <em>k</em>th class. 
Used to compute <code>classification</code> and
<code>uncertainty</code> if those arguments aren't available.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector representing a classification of
observations (rows) of <code>data</code>. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_truth">truth</code></td>
<td>

<p>A numeric or character vector giving a known
classification of each data point.
If <code>classification</code>
or <code>z</code> is also present, 
this is used for displaying classification errors.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_uncertainty">uncertainty</code></td>
<td>

<p>A numeric vector of values in <em>(0,1)</em> giving the
uncertainty of each data point. If present argument <code>z</code>
will be ignored.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_what">what</code></td>
<td>

<p>Choose from one of the following three options: <code>"classification"</code>
(default), <code>"error"</code>, <code>"uncertainty"</code>. 
</p>
</td></tr>
<tr><td><code id="randProj_+3A_quantiles">quantiles</code></td>
<td>

<p>A vector of length 2 giving quantiles used in plotting
uncertainty. The smallest symbols correspond to the smallest
quantile (lowest uncertainty), medium-sized (open) symbols to points
falling between the given quantiles, and large (filled) symbols to
those in the largest quantile (highest uncertainty). The default is
<em>(0.75,0.95)</em>. 
</p>
</td></tr>
<tr><td><code id="randProj_+3A_addellipses">addEllipses</code></td>
<td>

<p>A logical indicating whether or not to add ellipses with axes 
corresponding to the within-cluster covariances in case of 
<code>"classification"</code> or <code>"uncertainty"</code> plots. 
</p>
</td></tr>
<tr><td><code id="randProj_+3A_fillellipses">fillEllipses</code></td>
<td>

<p>A logical specifying whether or not to fill ellipses with transparent
colors when <code>addEllipses = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_symbols">symbols</code></td>
<td>

<p>Either an integer or character vector assigning a plotting symbol to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotSymbols")</code>.
</p>
</td></tr> 
<tr><td><code id="randProj_+3A_colors">colors</code></td>
<td>

<p>Either an integer or character vector assigning a color to each
unique class in <code>classification</code>. Elements in <code>colors</code>
correspond to classes in order of appearance in the sequence of
observations (the order used by the function <code>unique</code>). 
The default is given by <code>mclust.options("classPlotColors")</code>.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_scale">scale</code></td>
<td>

<p>A logical variable indicating whether or not the two chosen
dimensions should be plotted on the same scale, and
thus preserve the shape of the distribution.
Default: <code>scale=FALSE</code> 
</p>
</td></tr>
<tr><td><code id="randProj_+3A_xlim">xlim</code>, <code id="randProj_+3A_ylim">ylim</code></td>
<td>

<p>Optional arguments specifying bounds for the ordinate, abscissa of the plot.
This may be useful for when comparing plots.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_xlab">xlab</code>, <code id="randProj_+3A_ylab">ylab</code></td>
<td>

<p>Optional arguments specifying the labels for, respectively, the horizontal 
and vertical axis.
</p>
</td></tr> 
<tr><td><code id="randProj_+3A_cex">cex</code></td>
<td>

<p>A numerical value specifying the size of the plotting symbols. 
The default value is 1.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_pch">PCH</code></td>
<td>

<p>An argument specifying the symbol to be used when a classificatiion
has not been specified for the data. The default value is a small dot &quot;.&quot;.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_main">main</code></td>
<td>

<p>A logical variable or <code>NULL</code> indicating whether or not to add a title 
to the plot identifying the dimensions used.
</p>
</td></tr>
<tr><td><code id="randProj_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing a random two-dimensional projection of the data, together with the location of the  mixture components, classification, uncertainty, and/or classification errors. 
</p>
<p>The function also returns an invisible list with components <code>basis</code>, the randomnly generated basis of the projection subspace, <code>data</code>, a matrix of projected data, and <code>mu</code> and <code>sigma</code> the component parameters transformed to the projection subspace.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clPairs">clPairs</a></code>,
<code><a href="#topic+coordProj">coordProj</a></code>,
<code><a href="#topic+mclust2Dplot">mclust2Dplot</a></code>,
<code><a href="#topic+mclust.options">mclust.options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
est &lt;- meVVV(iris[,-5], unmap(iris[,5]))
par(pty = "s", mfrow = c(1,1))
randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,
          what = "classification", main = TRUE) 
randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,
          truth = iris[,5], what = "error", main = TRUE) 
randProj(iris[,-5], seeds=1:3, parameters = est$parameters, z = est$z,
          what = "uncertainty", main = TRUE) 

</code></pre>

<hr>
<h2 id='sigma2decomp'>
Convert mixture component covariances to decomposition form.
</h2><span id='topic+sigma2decomp'></span>

<h3>Description</h3>

<p>Converts a set of covariance matrices from representation as a 3-D array 
to a parameterization by eigenvalue decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigma2decomp(sigma, G = NULL, tol = sqrt(.Machine$double.eps), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigma2decomp_+3A_sigma">sigma</code></td>
<td>

<p>Either a 3-D array whose [,,k]th component is the covariance matrix for the
kth component in an MVN mixture model, or a single covariance
matrix in the case that all components have the same covariance.
</p>
</td></tr>
<tr><td><code id="sigma2decomp_+3A_g">G</code></td>
<td>

<p>The number of components in the mixture. When 
<code>sigma</code> is a 3-D array, the number of components
can be inferred from its dimensions.
</p>
</td></tr>
<tr><td><code id="sigma2decomp_+3A_tol">tol</code></td>
<td>

<p>Tolerance for determining whether or not the covariances have equal volume,
shape, and or orientation. The default is the square root of the relative
machine precision, <code>sqrt(.Machine$double.eps)</code>, which is about 
<code>1.e-8</code>.
</p>
</td></tr>
<tr><td><code id="sigma2decomp_+3A_...">...</code></td>
<td>

<p>Catches unused arguments from an indirect or list call via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The covariance matrices for the mixture components in decomposition form,
including the following components: 
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string indicating the infered model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data. 
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The number of components in the mixture model. 
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>

<p>Either a <em>G</em>-vector giving the scale of the covariance (the
<em>d</em>th root of its determinant) for each component in the
mixture model, or a single numeric value if the scale is the same
for each component.
</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>

<p>Either a <em>G</em> by <em>d</em> matrix in which the <em>k</em>th
column is the shape of the covariance matrix (normalized to have
determinant 1) for the <em>k</em>th component, or a <em>d</em>-vector
giving a common shape for all components. 
</p>
</td></tr>
<tr><td><code>orientation</code></td>
<td>

<p>Either a <em>d</em> by <em>d</em> by <em>G</em> array whose
<code>[,,k]</code>th entry is the orthonomal matrix whose columns are the
eigenvectors of the covariance matrix of the <em>k</em>th component,
or a <em>d</em> by <em>d</em> orthonormal matrix if the mixture
components have a common orientation. The <code>orientation</code> component of
<code>decomp</code> can be omitted in spherical and diagonal models, for
which the principal components are parallel to the coordinate axes
so that the orientation matrix is the identity.  
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+decomp2sigma">decomp2sigma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meEst &lt;- meEEE(iris[,-5], unmap(iris[,5])) 
names(meEst$parameters$variance)
meEst$parameters$variance$Sigma

sigma2decomp(meEst$parameters$variance$Sigma, G = length(unique(iris[,5])))
</code></pre>

<hr>
<h2 id='sim'>
Simulate from Parameterized MVN Mixture Models
</h2><span id='topic+sim'></span>

<h3>Description</h3>

<p>Simulate data from parameterized MVN mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim(modelName, parameters, n, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_+3A_modelname">modelName</code></td>
<td>

<p>A character string indicating the model. The help file for
<code><a href="#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.
</p>
</td></tr>
<tr><td><code id="sim_+3A_parameters">parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
If missing, equal proportions are assumed.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="sim_+3A_n">n</code></td>
<td>

<p>An integer specifying the number of data points to be simulated.
</p>
</td></tr>
<tr><td><code id="sim_+3A_seed">seed</code></td>
<td>

<p>An optional integer argument to <code>set.seed</code> for reproducible
random class assignment.  By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed</code>
before calling <code>sim</code>.
</p>
</td></tr>
<tr><td><code id="sim_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used with an indirect or list call using
<code>do.call</code>, allowing the output of e.g. <code>mstep</code>, <code>em</code>,
<code>me</code>, <code>Mclust</code> to be passed directly without the need to
specify individual parameters as arguments. 
</p>


<h3>Value</h3>

<p>A matrix in which first column is the classification and the remaining
columns are the <code>n</code> observations simulated from the specified MVN 
mixture model.
</p>
<table>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"modelName"</code> A character string indicating the variance 
model used for the simulation.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+simE">simE</a></code>, ...,
<code><a href="#topic+simVVV">simVVV</a></code>,
<code><a href="#topic+Mclust">Mclust</a></code>,
<code><a href="#topic+mstep">mstep</a></code>,
<code><a href="base.html#topic+do.call">do.call</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisBIC &lt;- mclustBIC(iris[,-5])
irisModel &lt;- mclustModel(iris[,-5], irisBIC)
names(irisModel)
irisSim &lt;- sim(modelName = irisModel$modelName, 
               parameters = irisModel$parameters, 
               n = nrow(iris))


  do.call("sim", irisModel) # alternative call


par(pty = "s", mfrow = c(1,2))

dimnames(irisSim) &lt;- list(NULL, c("dummy", (dimnames(iris)[[2]])[-5]))

dimens &lt;- c(1,2)
lim1 &lt;- apply(iris[,dimens],2,range)
lim2 &lt;- apply(irisSim[,dimens+1],2,range)
lims &lt;- apply(rbind(lim1,lim2),2,range)
xlim &lt;- lims[,1]
ylim &lt;- lims[,2]

coordProj(iris[,-5], parameters=irisModel$parameters, 
          classification=map(irisModel$z), 
          dimens=dimens, xlim=xlim, ylim=ylim)

coordProj(iris[,-5], parameters=irisModel$parameters, 
          classification=map(irisModel$z), truth = irisSim[,-1],
          dimens=dimens, xlim=xlim, ylim=ylim)

irisModel3 &lt;- mclustModel(iris[,-5], irisBIC, G=3)
irisSim3 &lt;- sim(modelName = irisModel3$modelName, 
               parameters = irisModel3$parameters, n = 500, seed = 1)

 irisModel3$n &lt;- NULL
 irisSim3 &lt;- do.call("sim",c(list(n=500,seed=1),irisModel3)) # alternative call

clPairs(irisSim3[,-1], cl = irisSim3[,1])
</code></pre>

<hr>
<h2 id='simE'>
Simulate from a Parameterized MVN Mixture Model
</h2><span id='topic+simE'></span><span id='topic+simV'></span><span id='topic+simEII'></span><span id='topic+simVII'></span><span id='topic+simEEI'></span><span id='topic+simVEI'></span><span id='topic+simEVI'></span><span id='topic+simVVI'></span><span id='topic+simEEV'></span><span id='topic+simEEE'></span><span id='topic+simVEV'></span><span id='topic+simVVV'></span><span id='topic+simEVE'></span><span id='topic+simEVV'></span><span id='topic+simVEE'></span><span id='topic+simVVE'></span>

<h3>Description</h3>

<p>Simulate data from a parameterized MVN mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simE(parameters, n, seed = NULL, ...)
simV(parameters, n, seed = NULL, ...)
simEII(parameters, n, seed = NULL, ...)
simVII(parameters, n, seed = NULL, ...)
simEEI(parameters, n, seed = NULL, ...)
simVEI(parameters, n, seed = NULL, ...)
simEVI(parameters, n, seed = NULL, ...)
simVVI(parameters, n, seed = NULL, ...)
simEEE(parameters, n, seed = NULL, ...)
simVEE(parameters, n, seed = NULL, ...)
simEVE(parameters, n, seed = NULL, ...)
simVVE(parameters, n, seed = NULL, ...)
simEEV(parameters, n, seed = NULL, ...)
simVEV(parameters, n, seed = NULL, ...)
simEVV(parameters, n, seed = NULL, ...)
simVVV(parameters, n, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simE_+3A_parameters">parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
If missing, equal proportions are assumed.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="simE_+3A_n">n</code></td>
<td>

<p>An integer specifying the number of data points to be simulated.
</p>
</td></tr>
<tr><td><code id="simE_+3A_seed">seed</code></td>
<td>

<p>An optional integer argument to <code>set.seed()</code> for reproducible
random class assignment. By default the current seed will be used.
Reproducibility can also be achieved by calling <code>set.seed</code>
before calling <code>sim</code>.
</p>
</td></tr>
<tr><td><code id="simE_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used with an indirect or list call using
<code>do.call</code>, allowing the output of e.g. <code>mstep</code>, <code>em</code>
<code>me</code>, <code>Mclust</code>, to be passed directly without the need
to specify individual parameters as arguments. 
</p>


<h3>Value</h3>

<p>A matrix in which first column is the classification and the remaining
columns are the <code>n</code> observations simulated from the specified MVN 
mixture model.
</p>
<table>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"modelName"</code> A character string indicating the variance 
model used for the simulation.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+sim">sim</a></code>,
<code><a href="#topic+Mclust">Mclust</a></code>,
<code><a href="#topic+mstepE">mstepE</a></code>,
<code><a href="#topic+mclustVariance">mclustVariance</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
d &lt;- 2
G &lt;- 2
scale &lt;- 1
shape &lt;- c(1, 9)

O1 &lt;- diag(2)
O2 &lt;- diag(2)[,c(2,1)]
O &lt;- array(cbind(O1,O2), c(2, 2, 2))
O

variance &lt;- list(d= d, G = G, scale = scale, shape = shape, orientation = O)
mu &lt;- matrix(0, d, G) ## center at the origin
simdat &lt;- simEEV( n = 200, 
                  parameters = list(pro=c(1,1),mean=mu,variance=variance),
                  seed = NULL)

cl &lt;- simdat[,1]

sigma &lt;- array(apply(O, 3, function(x,y) crossprod(x*y), 
                 y = sqrt(scale*shape)), c(2,2,2))
paramList &lt;- list(mu = mu, sigma = sigma)
coordProj( simdat, paramList = paramList, classification = cl)

</code></pre>

<hr>
<h2 id='softmax'>Softmax function</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>Efficient implementation (via Fortran) of the softmax (aka multinomial logistic) function converting a set of numerical values to probabilities summing to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(x, v = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>a matrix of dimension <code class="reqn">n \times k</code> of numerical values. If a vector is provided, it is converted to a single-row matrix.</p>
</td></tr>
<tr><td><code id="softmax_+3A_v">v</code></td>
<td>
<p>an optional vector of length <code class="reqn">k</code> of numerical values to be added to each row of <code>x</code> matrix. If not provided, a vector of zeros is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the matrix <code>x</code>, for each row <code class="reqn">x_{[i]} = [x_1, \dots, x_k]</code> (with <code class="reqn">i=1,\dots,n</code>), the softmax function calculates
</p>
<p style="text-align: center;"><code class="reqn">
\text{softmax}(x_{[i]})_j = 
\dfrac{\exp{x_j + v_j}}{\sum_{l=1}^k \exp(x_l + v_l)}
\qquad \text{for } j = 1,\dots,k 
</code>
</p>



<h3>Value</h3>

<p>Returns a matrix of the same dimension as <code>x</code> with values in the range <code class="reqn">(0,1)</code> that sum to 1 along the rows.</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+logsumexp">logsumexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(15), 5, 3)
v = log(c(0.5, 0.3, 0.2))
(z = softmax(x, v))
rowSums(z)
</code></pre>

<hr>
<h2 id='summary.Mclust'>Summarizing Gaussian Finite Mixture Model Fits</h2><span id='topic+summary.Mclust'></span><span id='topic+print.summary.Mclust'></span>

<h3>Description</h3>

<p>Summary method for class <code>"Mclust"</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Mclust'
summary(object, classification = TRUE, parameters = FALSE, ...)
## S3 method for class 'summary.Mclust'
print(x, digits = getOption("digits"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.Mclust_+3A_object">object</code></td>
<td>
<p>An object of class <code>'Mclust'</code> resulting of a call to <code><a href="#topic+Mclust">Mclust</a></code> or <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>
</td></tr>
<tr><td><code id="summary.Mclust_+3A_x">x</code></td>
<td>
<p>An object of class <code>'summary.Mclust'</code>, usually, a result of a call to <code>summary.Mclust</code>.</p>
</td></tr>
<tr><td><code id="summary.Mclust_+3A_classification">classification</code></td>
<td>
<p>Logical; if <code>TRUE</code> a table of MAP classification/clustering of observations is printed.</p>
</td></tr>
<tr><td><code id="summary.Mclust_+3A_parameters">parameters</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the parameters of mixture components are printed.</p>
</td></tr>
<tr><td><code id="summary.Mclust_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.Mclust_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mclust">Mclust</a></code>, <code><a href="#topic+densityMclust">densityMclust</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod1 = Mclust(iris[,1:4])
summary(mod1)
summary(mod1, parameters = TRUE, classification = FALSE)

mod2 = densityMclust(faithful, plot = FALSE)
summary(mod2)
summary(mod2, parameters = TRUE)

</code></pre>

<hr>
<h2 id='summary.mclustBIC'>Summary function for model-based clustering via BIC</h2><span id='topic+summary.mclustBIC'></span><span id='topic+print.summary.mclustBIC'></span><span id='topic+summary.mclustBIC'></span><span id='topic+summaryMclustBIC'></span><span id='topic+summaryMclustBICn'></span><span id='topic+printSummaryMclustBIC'></span><span id='topic+printSummaryMclustBICn'></span>

<h3>Description</h3>

<p>Optimal model characteristics and classification for model-based
clustering via <code>mclustBIC</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mclustBIC'
summary(object, data, G, modelNames, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mclustBIC_+3A_object">object</code></td>
<td>

<p>An <code>'mclustBIC'</code> object, 
which is the result of applying <code>mclustBIC</code> 
to <code>data</code>.
</p>
</td></tr>
<tr><td><code id="summary.mclustBIC_+3A_data">data</code></td>
<td>

<p>The matrix or vector of observations used to generate &lsquo;object&rsquo;.
</p>
</td></tr>
<tr><td><code id="summary.mclustBIC_+3A_g">G</code></td>
<td>

<p>A vector of integers giving the numbers of mixture components (clusters)
from which the best model according to BIC will be selected
(<code>as.character(G)</code> must be a subset of the row names of
<code>object</code>).
The default is to select the best model for all numbers
of mixture components used to obtain <code>object</code>.
</p>
</td></tr>
<tr><td><code id="summary.mclustBIC_+3A_modelnames">modelNames</code></td>
<td>

<p>A vector of integers giving the model parameterizations
from which the best model according to BIC will be selected
(<code>as.character(model)</code> must be a subset of the column names of
<code>object</code>).
The default is to select the best model for parameterizations
used to obtain <code>object</code>.
</p>
</td></tr>
<tr><td><code id="summary.mclustBIC_+3A_...">...</code></td>
<td>

<p>Not used. For generic/method consistency.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list giving the optimal (according to BIC) parameters,
conditional probabilities <code>z</code>, and log-likelihood,
together with the associated classification and its uncertainty.
</p>
<p>The details of the output components are as follows:
</p>
<table>
<tr><td><code>modelName</code></td>
<td>

<p>A character string denoting the model corresponding to the optimal BIC.
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>

<p>The number of observations in the data.
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The number of mixture components in the model corresponding to the optimal
BIC.
</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>

<p>The optimal BIC value.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood corresponding to the optimal BIC.
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>A list with the following components:
</p>

<dl>
<dt><code>pro</code></dt><dd>
<p>A vector whose <em>k</em>th component is the mixing proportion for
the <em>k</em>th component of the mixture model.
If missing, equal proportions are assumed.
</p>
</dd>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>   
<tr><td><code>z</code></td>
<td>

<p>A matrix whose <em>[i,k]</em>th entry is the probability that observation
<em>i</em> in the data belongs to the <em>k</em>th class.
</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>

<p><code>map(z)</code>: The classification corresponding to <code>z</code>.
</p>
</td></tr>
<tr><td><code>uncertainty</code></td>
<td>

<p>The uncertainty associated with the classification.
</p>
</td></tr>
<tr><td><code>Attributes:</code></td>
<td>

<p><code>"bestBICvalues"</code> Some of the best bic values for the analysis.<br />
<code>"prior"</code> The prior as specified in the input.<br />
<code>"control"</code> The control parameters for EM as specified in 
the input.<br />
<code>"initialization"</code> The parameters used to initial EM for 
computing the maximum likelihood values used to obtain the BIC.
</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>
<code><a href="#topic+mclustModel">mclustModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisBIC &lt;- mclustBIC(iris[,-5])
summary(irisBIC, iris[,-5])
summary(irisBIC, iris[,-5], G = 1:6, modelNames = c("VII", "VVI", "VVV"))
</code></pre>

<hr>
<h2 id='summary.MclustBootstrap'>Summary Function for Bootstrap Inference for Gaussian Finite Mixture Models</h2><span id='topic+summary.MclustBootstrap'></span><span id='topic+print.summary.MclustBootstrap'></span>

<h3>Description</h3>

<p>Summary of bootstrap distribution for the parameters of a Gaussian mixture model providing either standard errors or percentile bootstrap confidence intervals.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustBootstrap'
summary(object, what = c("se", "ci", "ave"), conf.level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.MclustBootstrap_+3A_object">object</code></td>
<td>
<p>An object of class <code>'MclustBootstrap'</code> as returned by <code><a href="#topic+MclustBootstrap">MclustBootstrap</a></code>.</p>
</td></tr>
<tr><td><code id="summary.MclustBootstrap_+3A_what">what</code></td>
<td>
<p>A character string: <code>"se"</code> for the standard errors; <code>"ci"</code> for the confidence intervals; <code>"ave"</code> for the averages.</p>
</td></tr>
<tr><td><code id="summary.MclustBootstrap_+3A_conf.level">conf.level</code></td>
<td>
<p>A value specifying the confidence level of the interval.</p>
</td></tr>
<tr><td><code id="summary.MclustBootstrap_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details about the procedure used to obtain the bootstrap distribution see <code><a href="#topic+MclustBootstrap">MclustBootstrap</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustBootstrap">MclustBootstrap</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(diabetes)
X = diabetes[,-1]
modClust = Mclust(X) 
bootClust = MclustBootstrap(modClust)
summary(bootClust, what = "se")
summary(bootClust, what = "ci")

data(acidity)
modDens = densityMclust(acidity, plot = FALSE)
modDens = MclustBootstrap(modDens)
summary(modDens, what = "se")
summary(modDens, what = "ci")

</code></pre>

<hr>
<h2 id='summary.MclustDA'>Summarizing discriminant analysis based on Gaussian finite mixture modeling</h2><span id='topic+summary.MclustDA'></span><span id='topic+print.summary.MclustDA'></span>

<h3>Description</h3>

<p>Summary method for class <code>"MclustDA"</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustDA'
summary(object, parameters = FALSE, newdata, newclass, ...)
## S3 method for class 'summary.MclustDA'
print(x, digits = getOption("digits"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.MclustDA_+3A_object">object</code></td>
<td>
<p>An object of class <code>'MclustDA'</code> resulting from a call to <code><a href="#topic+MclustDA">MclustDA</a></code>.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_x">x</code></td>
<td>
<p>An object of class <code>'summary.MclustDA'</code>, usually, a result of a call to <code>summary.MclustDA</code>.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_parameters">parameters</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the parameters of mixture components are printed.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or matrix giving the test data.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_newclass">newclass</code></td>
<td>
<p>A vector giving the class labels for the observations in 
the test data.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.MclustDA_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.MclustDA</code> computes and returns a list of summary statistics of the estimated MclustDA or EDDA model for classification.</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDA">MclustDA</a></code>, <code><a href="#topic+plot.MclustDA">plot.MclustDA</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod = MclustDA(data = iris[,1:4], class = iris$Species)
summary(mod)
summary(mod, parameters = TRUE)
</code></pre>

<hr>
<h2 id='summary.MclustDR'>Summarizing dimension reduction method for model-based clustering and classification</h2><span id='topic+summary.MclustDR'></span><span id='topic+print.summary.MclustDR'></span>

<h3>Description</h3>

<p>Summary method for class <code>"MclustDR"</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustDR'
summary(object, numdir, std = FALSE, ...)
## S3 method for class 'summary.MclustDR'
print(x, digits = max(5, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.MclustDR_+3A_object">object</code></td>
<td>
<p>An object of class <code>'MclustDR'</code> resulting from a call to <code><a href="#topic+MclustDR">MclustDR</a></code>.</p>
</td></tr>
<tr><td><code id="summary.MclustDR_+3A_x">x</code></td>
<td>
<p>An object of class <code>'summary.MclustDR'</code>, usually, a result of a call to <code>summary.MclustDR</code>.</p>
</td></tr>
<tr><td><code id="summary.MclustDR_+3A_numdir">numdir</code></td>
<td>
<p>An integer providing the number of basis directions to be printed.</p>
</td></tr>
<tr><td><code id="summary.MclustDR_+3A_std">std</code></td>
<td>
<p>if <code>TRUE</code> the coefficients basis are scaled such that all
predictors have unit standard deviation.</p>
</td></tr>
<tr><td><code id="summary.MclustDR_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.MclustDR_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustDR">MclustDR</a></code>, <code><a href="#topic+plot.MclustDR">plot.MclustDR</a></code>
</p>

<hr>
<h2 id='summary.MclustSSC'>Summarizing semi-supervised classification model based on Gaussian finite mixtures</h2><span id='topic+summary.MclustSSC'></span><span id='topic+print.summary.MclustSSC'></span>

<h3>Description</h3>

<p>Summary method for class <code>"MclustSSC"</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MclustSSC'
summary(object, parameters = FALSE, ...)
## S3 method for class 'summary.MclustSSC'
print(x, digits = getOption("digits"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.MclustSSC_+3A_object">object</code></td>
<td>
<p>An object of class <code>'MclustSSC'</code> resulting from a call to <code><a href="#topic+MclustSSC">MclustSSC</a></code>.</p>
</td></tr>
<tr><td><code id="summary.MclustSSC_+3A_x">x</code></td>
<td>
<p>An object of class <code>'summary.MclustSSC'</code>, usually, a result of a call to <code>summary.MclustSSC</code>.</p>
</td></tr>
<tr><td><code id="summary.MclustSSC_+3A_parameters">parameters</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the parameters of mixture components are printed.</p>
</td></tr>
<tr><td><code id="summary.MclustSSC_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.MclustSSC_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.MclustSSC</code> computes and returns a list of summary statistics of the estimated MclustSSC model for semi-supervised classification.</p>


<h3>Author(s)</h3>

<p>Luca Scrucca</p>


<h3>See Also</h3>

<p><code><a href="#topic+MclustSSC">MclustSSC</a></code>, <code><a href="#topic+plot.MclustSSC">plot.MclustSSC</a></code>.</p>

<hr>
<h2 id='surfacePlot'>Density or uncertainty surface for bivariate mixtures</h2><span id='topic+surfacePlot'></span>

<h3>Description</h3>

<p>Plots a density or uncertainty surface given bivariate data and parameters of 
a MVN mixture model for the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surfacePlot(data, parameters, 
            what = c("density", "uncertainty"), 
            type = c("contour", "hdr", "image", "persp"), 
            transformation = c("none", "log", "sqrt"),          
            grid = 200, nlevels = 11, levels = NULL, 
            prob = c(0.25, 0.5, 0.75),
            col = gray(0.5),
            col.palette = function(...) hcl.colors(..., "blues", rev = TRUE),
            hdr.palette = blue2grey.colors,
            xlim = NULL, ylim = NULL, xlab = NULL, ylab = NULL, 
            main = FALSE, scale = FALSE, swapAxes = FALSE, 
            verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="surfacePlot_+3A_data">data</code></td>
<td>

<p>A matrix, or data frame of bivariate observations.
Categorical variables are not allowed.
If a matrix or data frame, rows correspond to observations and
columns correspond to variables.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_parameters">parameters</code></td>
<td>

<p>A named list giving the parameters of an <em>MCLUST</em> model, 
used to produce superimposing ellipses on the plot. 
The relevant components are as follows:
</p>

<dl>
<dt><code>mean</code></dt><dd>
<p>The mean for each component. If there is more than one component,
this is a matrix whose kth column is the mean of the <em>k</em>th
component of the mixture model.
</p>
</dd>
<dt><code>variance</code></dt><dd>
<p>A list of variance parameters for the model.
The components of this list depend on the model
specification. See the help file for <code><a href="#topic+mclustVariance">mclustVariance</a></code>
for details.
</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="surfacePlot_+3A_what">what</code></td>
<td>

<p>Choose from one of the following options: <code>"density"</code>
(default), <code>"uncertainty"</code> indicating what to plot. 
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_type">type</code></td>
<td>

<p>Choose from one of the following three options: <code>"contour"</code> 
(default), <code>"hdr"</code>, <code>"image"</code>, and <code>"persp"</code> indicating 
the plot type. 
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_transformation">transformation</code></td>
<td>

<p>Choose from one of the following three options: <code>"none"</code>
(default), <code>"log"</code>, <code>"sqrt"</code> indicating a transformation
to be applied before plotting. 
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_grid">grid</code></td>
<td>

<p>The number of grid points (evenly spaced on each axis). 
The mixture density and uncertainty is computed at 
<code>grid x grid</code> points to produce the surface plot.
Default: <code>100</code>.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_nlevels">nlevels</code></td>
<td>

<p>The number of levels to use for a contour plot.
Default: <code>11</code>.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_levels">levels</code></td>
<td>

<p>A vector of levels at which to draw the lines in a contour plot.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_prob">prob</code></td>
<td>

<p>A vector of probability levels for computing HDR. 
Only used if <code>type = "hdr"</code> and supersede previous 
<code>nlevels</code> and <code>levels</code> arguments.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_col">col</code></td>
<td>

<p>A string specifying the colour to be used for <code>type = "contour"</code> 
and <code>type = "persp"</code> plots.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_col.palette">col.palette</code></td>
<td>

<p>A function which defines a palette of colours to be used for 
<code>type = "image"</code> plots. 
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_hdr.palette">hdr.palette</code></td>
<td>

<p>A function which defines a palette of colours to be used for 
<code>type = "hdr"</code> plots. 
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_xlim">xlim</code>, <code id="surfacePlot_+3A_ylim">ylim</code></td>
<td>

<p>Optional argument specifying bounds for the ordinate, abscissa of the plot.
This may be useful for when comparing plots.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_xlab">xlab</code>, <code id="surfacePlot_+3A_ylab">ylab</code></td>
<td>

<p>Optional argument specifying labels for the x-axis and y-axis.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_main">main</code></td>
<td>

<p>A logical variable or <code>NULL</code> indicating whether or not to add a title 
to the plot identifying the dimensions used.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_scale">scale</code></td>
<td>

<p>A logical variable indicating whether or not the two
dimensions should be plotted on the same scale, and
thus preserve the shape of the distribution.
The default is not to scale.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_swapaxes">swapAxes</code></td>
<td>

<p>A logical variable indicating whether or not the axes should be swapped
for the plot.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_verbose">verbose</code></td>
<td>

<p>A logical variable telling whether or not to print an indication that
the function is in the process of computing values at the grid points,
which typically takes some time to complete.
</p>
</td></tr>
<tr><td><code id="surfacePlot_+3A_...">...</code></td>
<td>

<p>Other graphics parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For an image plot, a color scheme may need to be selected on the display
device in order to view the plot.
</p>


<h3>Value</h3>

<p>A plots showing (a transformation of) the density or uncertainty for the given
mixture model and data. 
</p>
<p>The function also returns an invisible list with components <code>x</code>, 
<code>y</code>, and <code>z</code> in which <code>x</code> and <code>y</code> are the values used to 
define the grid and <code>z</code> is the transformed density or uncertainty at the 
grid points.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclust2Dplot">mclust2Dplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
faithfulModel &lt;- Mclust(faithful)
surfacePlot(faithful, parameters = faithfulModel$parameters,
            type = "contour", what = "density", transformation = "none",
            drawlabels = FALSE)
surfacePlot(faithful, parameters = faithfulModel$parameters,
            type = "persp", what = "density", transformation = "log")
surfacePlot(faithful, parameters = faithfulModel$parameters,
            type = "contour", what = "uncertainty", transformation = "log")

</code></pre>

<hr>
<h2 id='thyroid'>UCI Thyroid Gland Data</h2><span id='topic+thyroid'></span>

<h3>Description</h3>

<p>Data on five laboratory tests administered to a sample of 215 patients. The tests are used to predict whether a patient's thyroid can be classified as euthyroidism (normal thyroid gland function), hypothyroidism (underactive thyroid not producing enough thyroid hormone) or hyperthyroidism (overactive thyroid producing and secreting excessive amounts of the free thyroid hormones T3 and/or thyroxine T4). Diagnosis of thyroid operation was based on a complete medical record, including anamnesis, scan, etc.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(thyroid)</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables:
</p>

<dl>
<dt>Diagnosis</dt><dd><p>Diagnosis of thyroid operation: <code>Hypo</code>, <code>Normal</code>, and <code>Hyper</code>.</p>
</dd>
<dt>RT3U</dt><dd><p>T3-resin uptake test (percentage).</p>
</dd>
<dt>T4</dt><dd><p>Total Serum thyroxin as measured by the isotopic displacement method.</p>
</dd>
<dt>T3</dt><dd><p>Total serum triiodothyronine as measured by radioimmuno assay.</p>
</dd>
<dt>TSH</dt><dd><p>Basal thyroid-stimulating hormone (TSH) as measured by radioimmuno assay.</p>
</dd>
<dt>DTSH</dt><dd><p>Maximal absolute difference of TSH value after injection of 200 micro grams of thyrotropin-releasing hormone as compared to the basal value.</p>
</dd>
</dl>



<h3>Source</h3>

<p>One of several databases in the Thyroid Disease Data Set (<code>new-thyroid.data</code>, <code>new-thyroid.names</code>) of the UCI Machine Learning Repository
<a href="https://archive.ics.uci.edu/ml/datasets/thyroid+disease">https://archive.ics.uci.edu/ml/datasets/thyroid+disease</a>. Please note the UCI conditions of use.</p>


<h3>References</h3>

<p>Coomans, D., Broeckaert, M. Jonckheer M. and Massart D.L. (1983)
Comparison of Multivariate Discriminant Techniques for Clinical Data - Application to the Thyroid Functional State, <em>Meth. Inform. Med.</em> 22, pp. 93-101.
</p>
<p>Coomans, D. and I. Broeckaert (1986) <em>Potential Pattern Recognition in Cemical and Medical Decision Making</em>, Research Studies Press, Letchworth, England.
</p>

<hr>
<h2 id='uncerPlot'>
Uncertainty Plot for Model-Based Clustering
</h2><span id='topic+uncerPlot'></span>

<h3>Description</h3>

<p>Displays the uncertainty in converting a conditional probablility from EM
to a classification in model-based clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uncerPlot(z, truth, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uncerPlot_+3A_z">z</code></td>
<td>

<p>A matrix whose <em>[i,k]</em>th entry is the
conditional probability of the ith observation belonging to
the <em>k</em>th component of the mixture.  
</p>
</td></tr>
<tr><td><code id="uncerPlot_+3A_truth">truth</code></td>
<td>

<p>A numeric or character vector giving the true classification of the data. 
</p>
</td></tr>
<tr><td><code id="uncerPlot_+3A_...">...</code></td>
<td>

<p>Provided to allow lists with elements other than the arguments can
be passed in indirect or list calls with <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>truth</code> is provided and the number of classes is compatible
with <code>z</code>, the function <code>compareClass</code> is used to to find best
correspondence between classes in <code>truth</code> and <code>z</code>.
</p>


<h3>Value</h3>

<p>A plot of the uncertainty profile of the data,
with uncertainties in increasing order of magnitude.
If <code>truth</code> is supplied and the number of
classes is the same as the number of columns of 
<code>z</code>, the uncertainty
of the misclassified data is marked by vertical lines on the plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mclustBIC">mclustBIC</a></code>,
<code><a href="#topic+em">em</a></code>,
<code><a href="#topic+me">me</a></code>,
<code><a href="#topic+mapClass">mapClass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>irisModel3 &lt;-  Mclust(iris[,-5], G = 3)

uncerPlot(z = irisModel3$z)
 
uncerPlot(z = irisModel3$z, truth = iris[,5])
</code></pre>

<hr>
<h2 id='unmap'>
Indicator Variables given Classification
</h2><span id='topic+unmap'></span>

<h3>Description</h3>

<p>Converts a classification into a matrix of indicator variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  unmap(classification, groups=NULL, noise=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unmap_+3A_classification">classification</code></td>
<td>

<p>A numeric or character vector. Typically the distinct entries of this
vector would represent a classification of observations in a data set.
</p>
</td></tr>
<tr><td><code id="unmap_+3A_groups">groups</code></td>
<td>

<p>A numeric or character vector indicating the groups from which
<code>classification</code> is drawn. If not supplied, the default
is to assumed to be the unique entries of classification.
</p>
</td></tr>
<tr><td><code id="unmap_+3A_noise">noise</code></td>
<td>

<p>A single numeric or character value used to indicate the value of
<code>groups</code> corresponding to noise.
</p>
</td></tr>
<tr><td><code id="unmap_+3A_...">...</code></td>
<td>

<p>Catches unused arguments in indirect or list calls via <code>do.call</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <em>n</em> by <em>m</em> matrix of <em>(0,1)</em> indicator variables,
where <em>n</em> is the length of <code>classification</code> and <em>m</em> is
the number of unique values or symbols in  <code>classification</code>. 
Columns are labeled by the unique values in <code>classification</code>, 
and the <code>[i,j]</code>th entry is <em>1</em> if <code>classification[i]</code> 
is the <em>j</em>th unique value or symbol in sorted order 
<code>classification</code>. 
If a <code>noise</code> value of symbol is designated, the corresponding indicator 
variables are relocated to the last column of the matrix. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+map">map</a></code>,
<code><a href="#topic+estep">estep</a></code>,
<code><a href="#topic+me">me</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- unmap(iris[,5])
z[1:5, ]
  
emEst &lt;- me(modelName = "VVV", data = iris[,-5], z = z)
emEst$z[1:5,]
  
map(emEst$z)
</code></pre>

<hr>
<h2 id='wdbc'>UCI Wisconsin Diagnostic Breast Cancer Data</h2><span id='topic+wdbc'></span>

<h3>Description</h3>

<p>The data set provides data for 569 patients on 30 features of the cell nuclei obtained from a digitized image of a fine needle aspirate (FNA) of a breast mass. For each patient the cancer was diagnosed as malignant or benign.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wdbc)</code></pre>


<h3>Format</h3>

<p>A data frame with 569 observations on the following variables:
</p>

<dl>
<dt><code>ID</code></dt><dd><p>ID number</p>
</dd>
<dt><code>Diagnosis</code></dt><dd><p>cancer diagnosis: <code>M</code> = malignant, <code>B</code> = benign</p>
</dd>
<dt><code>Radius_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Texture_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Perimeter_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Area_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Smoothness_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Compactness_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Concavity_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Nconcave_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Symmetry_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Fractaldim_mean</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Radius_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Texture_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Perimeter_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Area_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Smoothness_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Compactness_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Concavity_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Nconcave_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Symmetry_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Fractaldim_se</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Radius_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Texture_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Perimeter_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Area_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Smoothness_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Compactness_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Concavity_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Nconcave_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Symmetry_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Fractaldim_extreme</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The recorded features are:
</p>

<ul>
<li> <p><code>Radius</code> as mean of distances from center to points on the perimeter
</p>
</li>
<li> <p><code>Texture</code> as standard deviation of gray-scale values
</p>
</li>
<li> <p><code>Perimeter</code> as cell nucleus perimeter
</p>
</li>
<li> <p><code>Area</code> as cell nucleus area
</p>
</li>
<li> <p><code>Smoothness</code> as local variation in radius lengths
</p>
</li>
<li> <p><code>Compactness</code> as cell nucleus compactness, perimeter^2 / area - 1
</p>
</li>
<li> <p><code>Concavity</code> as severity of concave portions of the contour
</p>
</li>
<li> <p><code>Nconcave</code> as number of concave portions of the contour
</p>
</li>
<li> <p><code>Symmetry</code> as cell nucleus shape
</p>
</li>
<li> <p><code>Fractaldim</code> as fractal dimension, &quot;coastline approximation&quot; - 1
</p>
</li></ul>

<p>For each feature the recorded values are computed from each image as <code>&lt;feature_name&gt;_mean</code>, <code>&lt;feature_name&gt;_se</code>, and <code>&lt;feature_name&gt;_extreme</code>, for the mean, the standard error, and the mean of the three largest values.
</p>


<h3>Source</h3>

<p>The Breast Cancer Wisconsin (Diagnostic) Data Set (<code>wdbc.data</code>, <code>wdbc.names</code>) from the UCI Machine Learning Repository
<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a>. Please note the UCI conditions of use.</p>


<h3>References</h3>

<p>Mangasarian, O. L., Street, W. N., and Wolberg, W. H. (1995) Breast cancer diagnosis and prognosis via linear programming. <em>Operations Research</em>, 43(4), pp. 570-577.
</p>

<hr>
<h2 id='wreath'>Data Simulated from a 14-Component Mixture</h2><span id='topic+wreath'></span>

<h3>Description</h3>

<p>A dataset consisting of 1000 observations drawn from a 14-component 
normal mixture in which the covariances of the components have the
same size and shape but differ in orientation.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wreath)</code></pre>


<h3>References</h3>

<p>C. Fraley,  A. E. Raftery and R. Wehrens (2005).
Incremental model-based clustering for large datasets with small clusters.
<em>Journal of Computational and Graphical Statistics 14:1:18</em>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
