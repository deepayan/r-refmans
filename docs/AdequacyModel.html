<!DOCTYPE html><html lang="en"><head><title>Help for package AdequacyModel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AdequacyModel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AdequacyModel-package'>
<p>Adequacy of probabilistic models and and general purpose optimization</p></a></li>
<li><a href='#carbone'>
<p>Breaking stress of carbon fibres</p></a></li>
<li><a href='#descriptive'>
<p>descriptive - Calculation of descriptive statistics</p></a></li>
<li><a href='#goodness.fit'>
<p>Adequacy of models</p></a></li>
<li><a href='#pso'>
<p>Adequacy of models</p></a></li>
<li><a href='#TTT'>
<p>TTT function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Adequacy of Probabilistic Models and General Purpose
Optimization</td>
</tr>
<tr>
<td>Author:</td>
<td>Pedro Rafael Diniz Marinho [aut, cre],
  Marcelo Bourguignon [aut, ctb],
  Cicero Rafael Barros Dias [aut, ctb]</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pedro Rafael Diniz Marinho &lt;pedro.rafael.marinho@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The main application concerns to a new robust optimization package with two major contributions. The first contribution refers to the assessment of the adequacy of probabilistic models through a combination of several statistics, which measure the relative quality of statistical models for a given data set. The second one provides a general purpose optimization method based on meta-heuristics functions for maximizing or minimizing an arbitrary objective function.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.r-project.org">http://www.r-project.org</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, graphics</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-05-19 18:32:35 UTC; pedrorafael</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-05-20 01:15:58</td>
</tr>
</table>
<hr>
<h2 id='AdequacyModel-package'>
Adequacy of probabilistic models and and general purpose optimization
</h2><span id='topic+AdequacyModel-package'></span><span id='topic+AdequacyModel'></span>

<h3>Description</h3>

<p>The main application concerns to a new robust optimization package with two major contributions. The first contribution refers to the assessment of the adequacy of probabilistic models through a combination of several statistics, which measure the relative quality of statistical models for a given data set. The second one provides a general purpose optimization method based on meta-heuristics functions for maximizing or minimizing an arbitrary objective function.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> AdequacyModel</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.10.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>References</h3>

<p>Aarset, M. V. (1987). How to identify bathtub hazard rate. IEEE Transactions Reliability, 36, 106-108.
</p>
<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) The New S Language. Wadsworth &amp; Brooks/Cole.
</p>
<p>Beni G, Wang J (1993). Swarm intelligence in cellular robotic systems. pp. 703-712.
</p>
<p>Chen, G., Balakrishnan, N. (1995). A general purpose approximate goodness-of-fit test. Journal of Quality Technology 27, 154-16.
</p>
<p>Eberhart RC, Kennedy J (1995). A new optimizer using particle swarm theory. In Proceedings of the sixth international symposium on micro machine and human science, volume 1, pp. 39-43. New York, NY.
</p>
<p>Kennedy J, Kennedy JF, Eberhart RC, Shi Y (2001). Swarm intelligence. Morgan Kaufmann.
</p>
<p>Nichols, M.D, Padgett, W.J. (2006). A Bootstrap control chart for Weibull percentiles. Quality and Reliability Engineering International 22, 141-151.
</p>
<p>Shi Y, Eberhart R (1998). A modified particle swarm optimizer. In Evolutionary Computation Proceedings, 1998. IEEE World Congress on Computational Intelligence., The 1998 IEEE International Conference on, pp. 69-73. IEEE.
</p>

<hr>
<h2 id='carbone'>
Breaking stress of carbon fibres
</h2><span id='topic+carbone'></span>

<h3>Description</h3>

<p>The first real data set corresponds to an uncensored data set from Nichols and Padgett (2006) on breaking stress of carbon fibres (in Gba).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carbone)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:100] 3.7 2.74 2.73 2.5 3.6 3.11 3.27 2.87 1.47 3.11 ...
</p>


<h3>References</h3>

<p>Nichols, M.D, Padgett, W.J. (2006). A Bootstrap control chart for Weibull percentiles. Quality and Reliability Engineering International 22, 141-151.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carbone)
hist(carbone)
</code></pre>

<hr>
<h2 id='descriptive'>
descriptive - Calculation of descriptive statistics
</h2><span id='topic+descriptive'></span>

<h3>Description</h3>

<p>The function <code>descriptive</code> calculates the main descriptive statistics of a vector of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descriptive(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descriptive_+3A_x">x</code></td>
<td>

<p>Data vector.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pedro Rafael Diniz Marinho <a href="mailto:pedro.rafael.marinho@gmail.com">pedro.rafael.marinho@gmail.com</a>
</p>
<p>Marcelo Bourguignon <a href="mailto:m.p.bourguignon@gmail.com">m.p.bourguignon@gmail.com</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988). The New S Language. Wadsworth &amp; Brooks/Cole.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carbone)
descriptive(carbone)
</code></pre>

<hr>
<h2 id='goodness.fit'>
Adequacy of models
</h2><span id='topic+goodness.fit'></span>

<h3>Description</h3>

<p>This function provides some useful statistics to assess the quality of fit of probabilistic models, including the statistics Cramér-von Mises and Anderson-Darling. These statistics are often used to compare models not fitted. You can also calculate other goodness of fit such as AIC, CAIC, BIC, HQIC and Kolmogorov-Smirnov test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodness.fit(pdf, cdf, starts, data, method = "PSO", domain = c(0,Inf),
             mle = NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodness.fit_+3A_pdf">pdf</code></td>
<td>

<p>Probability density function;
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_cdf">cdf</code></td>
<td>

<p>Cumulative distribution function;
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_starts">starts</code></td>
<td>

<p>Initial parameters to maximize the likelihood function;
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_data">data</code></td>
<td>

<p>Data vector;
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_method">method</code></td>
<td>

<p>Method used for minimization of the function <code>-log(likelihood)</code>. The methods supported are: <code>PSO</code> (default), <code>BFGS</code>, <code>Nelder-Mead</code>, <code>SANN</code>, <code>CG</code>. Can also be transmitted only the first letter of the methodology, i.e., <code>P</code>, <code>B</code>, <code>N</code>, <code>S</code> or <code>C</code> respectively;
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_domain">domain</code></td>
<td>

<p>Domain of probability density function. By default the domain of probability density function is the open interval 0 to infinity.This option must be an vector with two values;  
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_mle">mle</code></td>
<td>

<p>Vector with the estimation maximum likelihood. This option should be used if you already have knowledge of the maximum likelihood estimates. The default is <code>NULL</code>, ie, the function will try to obtain the estimates of maximum likelihoods;   
</p>
</td></tr>
<tr><td><code id="goodness.fit_+3A_...">...</code></td>
<td>
<p>If <code>method = "PSO"</code> or <code>method = "P"</code>, inform the arguments of the <code><a href="#topic+pso">pso</a></code> function. Get details about these arguments into <code><a href="#topic+pso">pso</a></code>. Basically the arguments that should be provided are the vectors <code>lim_inf</code> and <code>lim_sup</code>. The other parameters of the <code><a href="#topic+pso">pso</a></code> function can be informed in the desired configuration. However, may be omitted if the default configuration is sufficient.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>goodness.fit</code> returns statistics KS (Kolmogorov-Smirnov), A (Anderson-Darling), W (Cramér-von Misses). Are also calculated other measures of goodness of fit. These functions are: AIC (Akaike Information Criterion), CAIC (Consistent Akaikes Information Criterion), BIC (Bayesian Information Criterion) and HQIC (Hannan-Quinn information criterion).
</p>
<p>The Kolmogorov-Smirnov test may return <code>NA</code> with a certain frequency. The return <code>NA</code> informs that the statistical <code>KS</code> is not reliable for the data set used. More details about this issue can be obtained from <code><a href="stats.html#topic+ks.test">ks.test</a></code>.
</p>
<p>By default, the function calculates the maximum likelihood estimates. The errors of the estimates are also calculated. In cases that the function can not obtain the maximum likelihood estimates, the change of the values initial, in some cases, resolve the problem. You can also enter with the maximum likelihood estimation if there is already prior knowledge. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>W</code></td>
<td>
<p>Statistic Cramér-von Misses;</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Statistic Anderson Darling;</p>
</td></tr>
<tr><td><code>KS</code></td>
<td>
<p>Kolmogorov Smirnov test;</p>
</td></tr>
<tr><td><code>mle</code></td>
<td>
<p>Maximum likelihood estimates;</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion;</p>
</td></tr>
<tr><td><code>CAIC</code></td>
<td>
<p>Consistent Akaikes Information Criterion;</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian Information Criterion;</p>
</td></tr>
<tr><td><code>HQIC</code></td>
<td>
<p>Hannan-Quinn information criterion;</p>
</td></tr>
<tr><td><code>Erro</code></td>
<td>
<p>Standard errors of the maximum likelihood estimates;</p>
</td></tr>
<tr><td><code>Value</code></td>
<td>
<p>Minimum value of the function -log(likelihood);</p>
</td></tr>
<tr><td><code>Convergence</code></td>
<td>
<p>0 indicates successful completion and 1 indicates that the iteration limit maxit had been reached. More details at <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It is not necessary to define the likelihood function or log-likelihood. You only need to define the probability density function and distribution function. 
</p>


<h3>Author(s)</h3>

<p>Pedro Rafael Diniz Marinho <a href="mailto:pedro.rafael.marinho@gmail.com">pedro.rafael.marinho@gmail.com</a>
</p>


<h3>References</h3>

<p>Chen, G., Balakrishnan, N. (1995). A general purpose approximate goodness-of-fit test. Journal of Quality Technology, 27, 154-161.
</p>
<p>Hannan, E. J. and Quinn, B. G. (1979). The Determination of the Order of an Autoregression. Journal of the Royal Statistical Society, Series B, 41, 190-195.
</p>
<p>Nocedal, J. and Wright, S. J. (1999) Numerical Optimization. Springer.
</p>
<p>Sakamoto, Y., Ishiguro, M. and Kitagawa G. (1986). Akaike Information Criterion Statistics. D. Reidel Publishing Company.
</p>


<h3>See Also</h3>

<p>For details about the optimization methodologies may view the functions <code><a href="#topic+pso">pso</a></code> and <code><a href="stats.html#topic+optim">optim</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1:

data(carbone)

# Exponentiated Weibull - Probability density function.
pdf_expweibull &lt;- function(par,x){
  beta = par[1]
  c = par[2]
  a = par[3]
  a * beta * c * exp(-(beta*x)^c) * (beta*x)^(c-1) * (1 - exp(-(beta*x)^c))^(a-1)
}

# Exponentiated Weibull - Cumulative distribution function.
cdf_expweibull &lt;- function(par,x){
  beta = par[1]
  c = par[2]
  a = par[3]
  (1 - exp(-(beta*x)^c))^a
}

set.seed(0)
result_1 = goodness.fit(pdf = pdf_expweibull, cdf = cdf_expweibull, 
                        starts = c(1,1,1), data = carbone, method = "PSO",
                        domain = c(0,Inf),mle = NULL, lim_inf = c(0,0,0),
                        lim_sup = c(2,2,2), S = 250, prop=0.1, N=50)
             
x = seq(0, 6, length.out = 500)
hist(carbone, probability = TRUE)
lines(x, pdf_expweibull(x, par = result_1$mle), col = "blue")

# Example 2:

pdf_weibull &lt;- function(par,x){
  a = par[1]
  b = par[2]
  dweibull(x, shape = a, scale = b)
}

cdf_weibull &lt;- function(par,x){
  a = par[1]
  b = par[2]
  pweibull(x, shape = a, scale = b)
}

set.seed(0)
random_data2 = rweibull(250,2,2)
result_2 = goodness.fit(pdf = pdf_weibull, cdf = cdf_weibull, starts = c(1,1), data = random_data2,
             method = "PSO", domain = c(0,Inf), mle = NULL, lim_inf = c(0,0), lim_sup = c(10,10),
             N = 100, S = 250)

x = seq(0,ceiling(max(random_data2)), length.out = 500)
hist(random_data2, probability = TRUE)
lines(x, pdf_weibull(par = result_2$mle, x), col = "blue")

# TO RUN THE CODE BELOW, UNCOMMENT THE CODES.

# Example 3:

# Kumaraswamy Beta - Probability density function.
#pdf_kwbeta &lt;- function(par,x){
#  beta = par[1]
#  a = par[2]
#  alpha = par[3]
#  b = par[4]
#  (a*b*x^(alpha-1)*(1-x)^(beta-1)*(pbeta(x,alpha,beta))^(a-1)*
#  (1-pbeta(x,alpha,beta)^a)^(b-1))/beta(alpha,beta) 
#}

# Kumaraswamy Beta - Cumulative distribution function.
#cdf_kwbeta &lt;- function(par,x){
#  beta = par[1]
#  a = par[2]
#  alpha = par[3]
#  b = par[4]
#  1 - (1 - pbeta(x,alpha,beta)^a)^b
#}

#set.seed(0)
#random_data3 = rbeta(150,2,2.2)

#system.time(goodness.fit(pdf = pdf_kwbeta, cdf = cdf_kwbeta, starts = c(1,1,1,1),
#              data = random_data3, method = "PSO", domain = c(0,1), lim_inf = c(0,0,0,0),
#              lim_sup = c(10,10,10,10), S = 200, prop = 0.1, N = 40))


</code></pre>

<hr>
<h2 id='pso'>
Adequacy of models
</h2><span id='topic+pso'></span>

<h3>Description</h3>

<p>In computer science, the PSO is a computational method for optimization of parametric and multiparametric functions. The PSO algorithm is a meta-heuristic method, which has been providing good solutions for problems of global optimization functions with box-constrained. As in most heuristic methods that are inspired by biological phenomena, the PSO method is inspired by the behavior of flying birds. The philosophical idea of the PSO algorithm is based on the collective behavior of birds (particle) in search of food (point of global optimal).
</p>
<p>The <code>pso</code> function is an efficient function for global minimization, wherein it is not necessary to provide Initial kicks. This is the function for general purpose optimization. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pso(func, S = 350, lim_inf, lim_sup, e = 0.0001, data = NULL, N = 500, prop = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pso_+3A_func">func</code></td>
<td>

<p>Objective function, i.e, function to be minimized;
</p>
</td></tr>
<tr><td><code id="pso_+3A_s">S</code></td>
<td>

<p>Particle number considered. By default, S = 350;
</p>
</td></tr>
<tr><td><code id="pso_+3A_lim_inf">lim_inf</code></td>
<td>

<p>Vector with the lower limit of the search for the parameters of the objective function that will be minimized;
</p>
</td></tr>
<tr><td><code id="pso_+3A_lim_sup">lim_sup</code></td>
<td>

<p>Vector with the upper limits of search for the parameters of the objective function that will be minimized;
</p>
</td></tr>
<tr><td><code id="pso_+3A_e">e</code></td>
<td>

<p>Stop value of the algorithm, i.e., if the variance of the last 20 minimum values is less than or equal to <code>e</code>, the algorithm will converge to the global minimum. By default, <code>e = 0.0001</code>;
</p>
</td></tr>
<tr><td><code id="pso_+3A_data">data</code></td>
<td>

<p>Vector of data provided in the event of function to be minimized (passed as an argument for <code>func</code>) involve some data set. An example of a function that you should inform a data set is when we want to minimize the log-likelihood function multiplied by -1 (-log-likelihood). By defatul, <code>data = NULL</code>;
</p>
</td></tr>
<tr><td><code id="pso_+3A_n">N</code></td>
<td>

<p>Minimum number of iterations. By default, <code>N = 500</code>;   
</p>
</td></tr>
<tr><td><code id="pso_+3A_prop">prop</code></td>
<td>

<p>Proportion of last minimum value that is calculated variance used as a stopping criterion. That is, if the number of iterations is greater or equal to the minimum number of iterations <code>N</code>, calculate the variance of the last values of minimum obtained, wherein 0 &lt;= prop &lt;= 1</p>
</td></tr></table>
<p>.   
</p>


<h3>Details</h3>

<p>The PSO optimizes a problem by having a population of candidate solutions and moving these particles around in the search-space according to simple mathematical formulae over the particle’s position and velocity. The movement of the particles in the search space is randomized. Each iteration of the PSO algorithm, there is a leader particle, which is the particle that minimizes the objective function in the corresponding iteration. The remaining particles arranged in the search region will follow the leader particle randomly and sweep the area around this leading particle. In this local search process, another particle may become the new leader particle and the other particles will follow the new leader randomly. Each particle
arranged in the search region has a velocity vector and position vector and its movement in the search region is given by changes in these vectors.
</p>
<p>As a stopping criterion is considered the variance of the last 20 minimum values estimated by the algorithm. If this variance is less or equal the <code>e</code> the algorithm will stop providing the global minimum value. This is a conditional criterion, which will only be evaluated if the number of iterations is greater than or equal to the minimum number of iterations set to  <code>N</code>.
</p>
<p>The amount of minimum values considered in the calculation of the variance is given by the proportion of minimum values established by the argument <code>prop</code> which by default is <code>prop = 0.2</code>. That is, if the last 20% (<code>prop = 0.2</code>) of the minimum values has less variance than or equal to <code>e</code>, the algorithm will stop global search, indicating convergence according to the established criteria. This indicates that there was no significant improvements in this proportion of last iterations. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>par_pso</code></td>
<td>
<p>Global minimum point;</p>
</td></tr>
<tr><td><code>f_pso</code></td>
<td>
<p>Global minimum value.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In other versions of the package, the paper with more details that complement the documentation of this function will be provided in the above references and this note will be undone.
</p>


<h3>Author(s)</h3>

<p>Pedro Rafael Diniz Marinho <a href="mailto:pedro.rafael.marinho@gmail.com">pedro.rafael.marinho@gmail.com</a>
</p>


<h3>References</h3>

<p>Beni G, Wang J (1993). Swarm intelligence in cellular robotic systems. pp. 703-712.
</p>
<p>Eberhart RC, Kennedy J (1995). A new optimizer using particle swarm theory. In Proceedings of the sixth international symposium on micro machine and human science, volume 1, pp. 39-43. New York, NY.
</p>
<p>Kennedy J, Kennedy JF, Eberhart RC, Shi Y (2001). Swarm intelligence. Morgan Kaufmann.
</p>
<p>Shi Y, Eberhart R (1998). A modified particle swarm optimizer. In Evolutionary Computation Proceedings, 1998. IEEE World Congress on Computational Intelligence., The 1998 IEEE International Conference on, pp. 69-73. IEEE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The objective functions below are rather difficult to be optimized. 
# However, the function pso has great results.

# Example 1 (Easom function): 

easom_function &lt;- function(par,x){
  x1 = par[1]
  x2 = par[2]
  -cos(x1)*cos(x2)*exp(-((x1-pi)^2 + (x2-pi)^2))
}

set.seed(0)
result_1 = pso(func = easom_function, S = 500, lim_inf = c(-10,-10), lim_sup = c(10,10),
               e = 0.00001)
result_1$par

# Example 2 (Holder table function):

holder &lt;- function(par,x){
  x1 = par[1]
  x2 = par[2]
  -abs(sin(x1)*cos(x2) * exp(abs(1 - sqrt(x1^2+x2^2)/pi)))
}

set.seed(0)
result_2 = pso(func = holder, S = 700, lim_inf = c(-10,-10), lim_sup = c(10,10),
               e = 0.00001, N=500)
result_2$par

# Example 3:

f_pso &lt;- function(par,x){
  theta = par[1]
  -(6 + theta^2 * sin(14*theta))
}

set.seed(0)
result_3 &lt;- pso(func = f_pso, S = 500, lim_inf = c(-2.5), lim_sup = c(2.5), e = 0.0001)
result_3$par

# TO RUN THE CODE BELOW, UNCOMMENT THE CODES.

# Example 4 (maximizing a function of the log-likelihood function):

# pdf_exp &lt;- function(par,x){
#  lambda = par[1]
#  lambda*exp(-lambda*x)
#}

# -log-likelihood function of the exponential distribution.
#likelihood &lt;- function(par,x){
#  lambda = par[1]
#  -sum(log(pdf_exp(par,x)))
#}

#set.seed(0)
#random_data1 = rexp(500,1)
#result_1 = pso(func = likelihood, S = 250, lim_inf = c(0), lim_sup = c(100), e = 0.0001,
#    data = random_data1, N = 50, prop = 0.2)

#x = seq(0,ceiling(max(random_data1)), length.out = 500)
#hist(random_data1, probability = TRUE)
#lines(x, pdf_exp(par = result_1$par, x), col = "blue")

# Example 5 (maximizing a function of the log-likelihood function):

# Probability density function (Weibull) 
#pdf_weibull &lt;- function(par,x){
#  a = par[1]
#  b = par[2]
#  dweibull(x,shape=a,scale=b)
#}

# -log-likelihood function of the Weibull distribution.
#likelihood &lt;- function(par,x){
#  -sum(log(pdf_weibull(par,x)))
#}

#set.seed(0)
#random_data2 = rweibull(250,2,2)
#result_2 = pso(func = likelihood, S = 250, lim_inf = c(0,0), lim_sup = c(10,10), e = 0.0001,
#               data = random_data2, N = 50, prop = 0.2)
    
#x = seq(0,ceiling(max(random_data2)), length.out = 500)
#hist(random_data2, probability = TRUE, ylim = c(0,0.5))
#lines(x, pdf_weibull(par = result_2$par, x), col = "blue")
    
</code></pre>

<hr>
<h2 id='TTT'>
TTT function
</h2><span id='topic+TTT'></span>

<h3>Description</h3>

<p>There are several behaviors that the failure rate function of a random variable T can take. In this context, the graph of total test time (TTT curve) proposed by Aarset (1987) may be used for obtaining empirical behavior of the function failure rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TTT(x, lwd = 2, lty = 2, col = "black", grid = TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TTT_+3A_x">x</code></td>
<td>
<p> Data vector;
</p>
</td></tr>
<tr><td><code id="TTT_+3A_lwd">lwd</code></td>
<td>

<p>Thickness of the TTT curve. The argument <code>lwd</code> must be a nonnegative real number;
</p>
</td></tr>
<tr><td><code id="TTT_+3A_lty">lty</code></td>
<td>

<p>The argument <code>lty</code> modifies the style of the diagonal line chart TTT. Possible values are: 0 [blank], 1 [solid (default)], 2 [dashed], three [dotted], 4 [dotdash], 5 [longdash], 6 [twodash];
</p>
</td></tr>
<tr><td><code id="TTT_+3A_col">col</code></td>
<td>

<p>Color used in the TTT curve;
</p>
</td></tr>
<tr><td><code id="TTT_+3A_grid">grid</code></td>
<td>

<p>If <code>grid = FALSE</code> graphic appears without the grid;
</p>
</td></tr>
<tr><td><code id="TTT_+3A_...">...</code></td>
<td>

<p>Other arguments passed by the user and available for the function <code>plot</code>. More details in <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The graphic TTT may have various forms. Aarset (1987) showed that if the curve approaches a straight diagonal function constant failure rate is adequate. When the curve is convex or concave the failure rate function is monotonically increasing or decescente respectively is adequate. If the failure rate function is convex and concave, the failure rate function in format <code class="reqn">U</code> is adequate, otherwise the failure rate function unimodal is more appropriate.
</p>
<p>The TTT curve is constructed by values <code class="reqn">r/n</code> and <code class="reqn">G(r/n)</code>, wherein
</p>
<p style="text-align: center;"><code class="reqn">
G(r/n) =  \frac{[\sum_{i=1}^{r} T_{i:n} + (n-r)T_{r:n}]}{\sum_{i=1}^{n}T_{i:n}}, r = 1, \ldots, n, T_{1:n} = 1, \ldots, n.
</code>
</p>



<h3>Author(s)</h3>

<p>Pedro Rafael Diniz Marinho (pedro.rafael.marinho@gmail.com);
</p>
<p>Marcelo Bourguignon (m.p.bourguignon@gmail.com).
</p>


<h3>References</h3>

<p>Aarset, M. V. (1987). How to identify bathtub hazard rate. IEEE Transactions Reliability, 36, 106-108.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carbone)
TTT(carbone, col = "red", lwd = 2.5, grid = TRUE, lty = 2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
