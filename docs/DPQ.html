<!DOCTYPE html><html lang="en"><head><title>Help for package DPQ</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DPQ}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DPQ-package'><p>Density, Probability, Quantile ('DPQ') Computations</p></a></li>
<li><a href='#algdiv'><p>Compute log(gamma(b)/gamma(a+b)) when b &gt;= 8</p></a></li>
<li><a href='#b_chi'><p>Compute <code class="reqn">E[\chi_\nu] / \sqrt{\nu}</code></p>
useful for t- and chi-Distributions</a></li>
<li><a href='#Bern'><p>Bernoulli Numbers</p></a></li>
<li><a href='#bpser'><p><code>pbeta()</code>  'bpser' series computation</p></a></li>
<li><a href='#chebyshevPoly'><p>Chebyshev Polynomial Evaluation</p></a></li>
<li><a href='#dbinom_raw'><p>R's C Mathlib (Rmath) dbinom_raw() Binomial Probability pure R Function</p></a></li>
<li><a href='#dchisqApprox'><p>Approximations of the (Noncentral) Chi-Squared Density</p></a></li>
<li><a href='#dgamma-utils'><p>Binomial Deviance &ndash; Auxiliary Functions for <code>dgamma()</code> Etc</p></a></li>
<li><a href='#dgamma.R'><p>Gamma Density Function Alternatives</p></a></li>
<li><a href='#dhyperBinMolenaar'><p>HyperGeometric (Point) Probabilities via Molenaar's Binomial Approximation</p></a></li>
<li><a href='#dnbinomR'><p>Pure R Versions of R's C (Mathlib) dnbinom() Negative Binomial Probabilities</p></a></li>
<li><a href='#dnt'><p>Non-central t-Distribution Density - Algorithms and Approximations</p></a></li>
<li><a href='#dot-D-utils'><p>Distribution Utilities &quot;dpq&quot;</p></a></li>
<li><a href='#dpsifn'><p>Psi Gamma Functions Workhorse from R's API</p></a></li>
<li><a href='#dtWV'><p>Asymptotic Noncentral t Distribution Density by Viechtbauer</p></a></li>
<li><a href='#expm1x'><p>Accurate exp(x) - 1 - x   (for smallish |x|)</p></a></li>
<li><a href='#format01prec'><p>Format Numbers in [0,1] with &quot;Precise&quot; Result</p></a></li>
<li><a href='#fr_ld_exp'><p>Base-2 Representation and Multiplication of Numbers</p></a></li>
<li><a href='#gam1d'><p>Compute  1/Gamma(x+1) - 1  Accurately</p></a></li>
<li><a href='#gamln1'><p>Compute  log( Gamma(x+1) ) Accurately in [-0.2, 1.25]</p></a></li>
<li><a href='#gammaVer'><p>Gamma Function Versions</p></a></li>
<li><a href='#hyper2binomP'><p>Transform Hypergeometric Distribution Parameters to Binomial Probability</p></a></li>
<li><a href='#Ixpq'><p>Normalized Incomplete Beta Function &quot;Like&quot; <code>pbeta()</code></p></a></li>
<li><a href='#lbeta'><p>(Log) Beta and Ratio of Gammas Approximations</p></a></li>
<li><a href='#lfastchoose'><p>R versions of Simple Formulas for Logarithmic Binomial Coefficients</p></a></li>
<li><a href='#lgamma1p'><p>Accurate <code>log(gamma(a+1))</code></p></a></li>
<li><a href='#lgammaAsymp'><p>Asymptotic Log Gamma Function</p></a></li>
<li><a href='#log1mexp'><p>Compute <code class="reqn">\mathrm{log}</code>(1 - <code class="reqn">\mathrm{exp}</code>(-a)) and</p>
<code class="reqn">\log(1 + \exp(x))</code>   Numerically Optimally</a></li>
<li><a href='#log1pmx'><p>Accurate  <code>log(1+x) - x</code>  Computation</p></a></li>
<li><a href='#logcf'><p>Continued Fraction Approximation of Log-Related Power Series</p></a></li>
<li><a href='#logspace.add'><p>Logspace Arithmetix &ndash; Addition and Subtraction</p></a></li>
<li><a href='#lssum'><p>Compute Logarithm of a Sum with Signed Large Summands</p></a></li>
<li><a href='#lsum'><p>Properly Compute the Logarithm of a Sum (of Exponentials)</p></a></li>
<li><a href='#newton'><p>Simple R level Newton Algorithm, Mostly for Didactical Reasons</p></a></li>
<li><a href='#numer-utils'><p>Numerical Utilities - Functions, Constants</p></a></li>
<li><a href='#p1l1'><p>Numerically Stable p1l1(t) = (t+1)*log(1+t) - t</p></a></li>
<li><a href='#pbetaRv1'><p>Pure R Implementation of Old pbeta()</p></a></li>
<li><a href='#phyperAllBin'><p>Compute Hypergeometric Probabilities via Binomial Approximations</p></a></li>
<li><a href='#phyperApprAS152'><p>Normal Approximation to cumulative Hyperbolic Distribution &ndash; AS 152</p></a></li>
<li><a href='#phyperBin'><p>HyperGeometric Distribution via Approximate Binomial Distribution</p></a></li>
<li><a href='#phyperBinMolenaar'><p>HyperGeometric Distribution via Molenaar's Binomial Approximation</p></a></li>
<li><a href='#phyperIbeta'><p>Pearson's incomplete Beta Approximation to the Hyperbolic Distribution</p></a></li>
<li><a href='#phyperMolenaar'><p>Molenaar's Normal Approximations to the Hypergeometric Distribution</p></a></li>
<li><a href='#phyperPeizer'><p>Peizer's Normal Approximation to the Cumulative Hyperbolic</p></a></li>
<li><a href='#phyperR'><p><span class="rlang"><b>R</b></span>-only version of <span class="rlang"><b>R</b></span>'s original phyper() algorithm</p></a></li>
<li><a href='#phyperR2'><p>Pure R version of R's C level phyper()</p></a></li>
<li><a href='#phypers'><p>The Four (4) Symmetric 'phyper()' Calls</p></a></li>
<li><a href='#pl2curves'><p>Plot 2 Noncentral Distribution Curves for Visual Comparison</p></a></li>
<li><a href='#pnbeta'><p>Noncentral Beta Probabilities</p></a></li>
<li><a href='#pnchi1sq'><p>(Probabilities of Non-Central Chi-squared Distribution for Special Cases</p></a></li>
<li><a href='#pnchisqAppr'><p>(Approximate) Probabilities of Non-Central Chi-squared Distribution</p></a></li>
<li><a href='#pnchisqWienergerm'><p>Wienergerm Approximations to (Non-Central) Chi-squared Probabilities</p></a></li>
<li><a href='#pnormAsymp'><p>Asymptotic Approxmation of (Extreme Tail) 'pnorm()'</p></a></li>
<li><a href='#pnormLU'><p>Bounds for 1-Phi(.) &ndash; Mill's Ratio related Bounds for pnorm()</p></a></li>
<li><a href='#pnt'><p>Non-central t Probability Distribution - Algorithms and Approximations</p></a></li>
<li><a href='#pow'><p>X to Power of Y &ndash; R C API <code>R_pow()</code></p></a></li>
<li><a href='#pow1p'><p>Accurate <code class="reqn">(1+x)^y</code>, notably for small <code class="reqn">|x|</code></p></a></li>
<li><a href='#ppoisson'><p>Direct Computation of 'ppois()' Poisson Distribution Probabilities</p></a></li>
<li><a href='#pt_Witkovsky_Tab1'><p>Viktor Witosky's Table_1  pt() Examples</p></a></li>
<li><a href='#qbetaAppr'><p>Compute (Approximate) Quantiles of the Beta Distribution</p></a></li>
<li><a href='#qbinomR'><p>Pure R Implementation of R's qbinom()  with Tuning Parameters</p></a></li>
<li><a href='#qchisqAppr'><p>Compute Approximate Quantiles of the Chi-Squared Distribution</p></a></li>
<li><a href='#qgammaAppr'><p>Compute (Approximate) Quantiles of the Gamma Distribution</p></a></li>
<li><a href='#qnbinomR'><p>Pure R Implementation of R's qnbinom()  with Tuning Parameters</p></a></li>
<li><a href='#qnchisqAppr'><p>Compute Approximate Quantiles of Noncentral Chi-Squared Distribution</p></a></li>
<li><a href='#qnormAppr'><p>Approximations to 'qnorm()', i.e., <code class="reqn">z_\alpha</code></p></a></li>
<li><a href='#qnormAsymp'><p>Asymptotic Approximation to Outer Tail of qnorm()</p></a></li>
<li><a href='#qnormR'><p>Pure R version of <span class="rlang"><b>R</b></span>'s <code>qnorm()</code> with Diagnostics and Tuning Parameters</p></a></li>
<li><a href='#qntR'><p>Pure R Implementation of R's qt() / qnt()</p></a></li>
<li><a href='#qpoisR'><p>Pure R Implementation of R's qpois()  with Tuning Parameters</p></a></li>
<li><a href='#qtAppr'><p>Compute Approximate Quantiles of the (Non-Central) t-Distribution</p></a></li>
<li><a href='#qtR'><p>Pure <span class="rlang"><b>R</b></span> Implementation of <span class="rlang"><b>R</b></span>'s C-level t-Distribution Quantiles <code>qt()</code></p></a></li>
<li><a href='#qtU'><p>'uniroot()'-based Computing of t-Distribution Quantiles</p></a></li>
<li><a href='#r_pois'><p>Compute Relative Size of i-th term of Poisson Distribution Series</p></a></li>
<li><a href='#rexpm1'><p>TOMS 708 Approximation REXP(x) of expm1(x) = exp(x) - 1</p></a></li>
<li><a href='#stirlerr'><p>Stirling's Error Function - Auxiliary for Gamma, Beta, etc</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Density, Probability, Quantile ('DPQ') Computations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5-9</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-08-23</td>
</tr>
<tr>
<td>VersionNote:</td>
<td>Last CRAN: 0.5-8 on 2023-11-30; 0.5-7 on 2023-11-03</td>
</tr>
<tr>
<td>Description:</td>
<td>Computations for approximations and alternatives for the 'DPQ'
  (Density (pdf), Probability (cdf) and Quantile) functions for probability
  distributions in R.
  Primary focus is on (central and non-central) beta, gamma and related
  distributions such as the chi-squared, F, and t.
  &ndash;
  For several distribution functions, provide functions implementing formulas from
  Johnson, Kotz, and Kemp (1992) &lt;<a href="https://doi.org/10.1002%2Fbimj.4710360207">doi:10.1002/bimj.4710360207</a>&gt;  and
  Johnson, Kotz, and Balakrishnan (1995) for discrete or continuous
  distributions respectively.
  This is for the use of researchers in these numerical approximation
  implementations, notably for my own use in order to improve standard
  R pbeta(), qgamma(), ..., etc: {'"dpq"'-functions}.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, methods, utils, sfsmisc (&ge; 1.1-14)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rmpfr, DPQmpfr (&ge; 0.3-1), gmp, MASS, mgcv, scatterplot3d,
interp, cobs</td>
</tr>
<tr>
<td>SuggestsNote:</td>
<td>MASS::fractions() in ex | mgcv, scatt.., .., cobs: some
tests/</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://specfun.r-forge.r-project.org/">https://specfun.r-forge.r-project.org/</a>,
<a href="https://r-forge.r-project.org/R/?group_id=611">https://r-forge.r-project.org/R/?group_id=611</a>,
<a href="https://r-forge.r-project.org/scm/viewvc.php/pkg/DPQ/?root=specfun">https://r-forge.r-project.org/scm/viewvc.php/pkg/DPQ/?root=specfun</a>,
svn://svn.r-forge.r-project.org/svnroot/specfun/pkg/DPQ</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://r-forge.r-project.org/tracker/?atid=2462&amp;group_id=611">https://r-forge.r-project.org/tracker/?atid=2462&amp;group_id=611</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-23 18:56:53 UTC; maechler</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin Maechler <a href="https://orcid.org/0000-0002-8685-9910"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Morten Welinder [ctb] (pgamma C code, see PR#7307, Jan. 2005; further
    pdhyper()),
  Wolfgang Viechtbauer [ctb] (dtWV(), 2002),
  Ross Ihaka [ctb] (src/qchisq_appr.c),
  Marius Hofert [ctb] (lsum(), lssum()),
  R-core [ctb] (src/{dpq.h, algdiv.c, pnchisq.c, bd0.c}),
  R Foundation [cph] (src/qchisq-appr.c)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martin Maechler &lt;maechler@stat.math.ethz.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-23 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='DPQ-package'>Density, Probability, Quantile ('DPQ') Computations</h2><span id='topic+DPQ-package'></span><span id='topic+DPQ'></span>

<h3>Description</h3>

<p>Computations for approximations and alternatives for the 'DPQ'
  (Density (pdf), Probability (cdf) and Quantile) functions for probability
  distributions in R.
  Primary focus is on (central and non-central) beta, gamma and related
  distributions such as the chi-squared, F, and t.
  &ndash;
  For several distribution functions, provide functions implementing formulas from
  Johnson, Kotz, and Kemp (1992) &lt;doi:10.1002/bimj.4710360207&gt;  and
  Johnson, Kotz, and Balakrishnan (1995) for discrete or continuous
  distributions respectively.
  This is for the use of researchers in these numerical approximation
  implementations, notably for my own use in order to improve standard
  R pbeta(), qgamma(), ..., etc: {'&quot;dpq&quot;'-functions}.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file: 
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> DPQ</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Density, Probability, Quantile ('DPQ') Computations</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.5-9</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-08-23</td>
</tr>
<tr>
 <td style="text-align: left;">
VersionNote: </td><td style="text-align: left;"> Last CRAN: 0.5-8 on 2023-11-30;  0.5-7 on 2023-11-03</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person("Martin","Maechler", role=c("aut","cre"),
                    email="maechler@stat.math.ethz.ch", comment = c(ORCID = "0000-0002-8685-9910"))
  , person("Morten",   "Welinder",    role = "ctb", comment = "pgamma C code, see PR#7307, Jan. 2005; further pdhyper()")
  , person("Wolfgang", "Viechtbauer", role = "ctb", comment = "dtWV(), 2002")
  , person("Ross",     "Ihaka",       role = "ctb", comment = "src/qchisq_appr.c")
  , person("Marius",   "Hofert",      role = "ctb", comment = "lsum(), lssum()")
  , person("R-core", email = "R-core@R-project.org", role = "ctb", comment = "src/{dpq.h, algdiv.c, pnchisq.c, bd0.c}")
  , person("R Foundation", role = "cph", comment = "src/qchisq-appr.c")
  	     )</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Computations for approximations and alternatives for the 'DPQ'
  (Density (pdf), Probability (cdf) and Quantile) functions for probability
  distributions in R.
  Primary focus is on (central and non-central) beta, gamma and related
  distributions such as the chi-squared, F, and t.
  --
  For several distribution functions, provide functions implementing formulas from
  Johnson, Kotz, and Kemp (1992) &lt;doi:10.1002/bimj.4710360207&gt;  and
  Johnson, Kotz, and Balakrishnan (1995) for discrete or continuous
  distributions respectively.
  This is for the use of researchers in these numerical approximation
  implementations, notably for my own use in order to improve standard
  R pbeta(), qgamma(), ..., etc: {'"dpq"'-functions}.</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 4.0.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> stats, graphics, methods, utils, sfsmisc (&gt;= 1.1-14)</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> Rmpfr, DPQmpfr (&gt;= 0.3-1), gmp, MASS, mgcv, scatterplot3d, interp, cobs</td>
</tr>
<tr>
 <td style="text-align: left;">
SuggestsNote: </td><td style="text-align: left;"> MASS::fractions() in ex | mgcv, scatt.., .., cobs: some tests/</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://specfun.r-forge.r-project.org/,
https://r-forge.r-project.org/R/?group_id=611,
https://r-forge.r-project.org/scm/viewvc.php/pkg/DPQ/?root=specfun,
svn://svn.r-forge.r-project.org/svnroot/specfun/pkg/DPQ</td>
</tr>
<tr>
 <td style="text-align: left;">
BugReports: </td><td style="text-align: left;"> https://r-forge.r-project.org/tracker/?atid=2462&amp;group_id=611</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Martin Maechler [aut, cre] (&lt;https://orcid.org/0000-0002-8685-9910&gt;),
  Morten Welinder [ctb] (pgamma C code, see PR#7307, Jan. 2005; further
    pdhyper()),
  Wolfgang Viechtbauer [ctb] (dtWV(), 2002),
  Ross Ihaka [ctb] (src/qchisq_appr.c),
  Marius Hofert [ctb] (lsum(), lssum()),
  R-core [ctb] (src/{dpq.h, algdiv.c, pnchisq.c, bd0.c}),
  R Foundation [cph] (src/qchisq-appr.c)</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Martin Maechler &lt;maechler@stat.math.ethz.ch&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
.D_0                    Distribution Utilities "dpq"
Bern                    Bernoulli Numbers
DPQ-package             Density, Probability, Quantile ('DPQ')
                        Computations
Ixpq                    Normalized Incomplete Beta Function "Like"
                        'pbeta()'
M_LN2                   Numerical Utilities - Functions, Constants
algdiv                  Compute log(gamma(b)/gamma(a+b)) when b &gt;= 8
b_chi                   Compute E[chi_nu]/sqrt(nu) useful for t- and
                        chi-Distributions
bd0                     Binomial Deviance - Auxiliary Functions for
                        'dgamma()' Etc
bpser                   'pbeta()' 'bpser' series computation
chebyshevPoly           Chebyshev Polynomial Evaluation
dbinom_raw              R's C Mathlib (Rmath) dbinom_raw() Binomial
                        Probability pure R Function
dgamma.R                Gamma Density Function Alternatives
dhyperBinMolenaar       HyperGeometric (Point) Probabilities via
                        Molenaar's Binomial Approximation
dnbinomR                Pure R Versions of R's C (Mathlib) dnbinom()
                        Negative Binomial Probabilities
dnchisqR                Approximations of the (Noncentral) Chi-Squared
                        Density
dntJKBf1                Non-central t-Distribution Density - Algorithms
                        and Approximations
dpsifn                  Psi Gamma Functions Workhorse from R's API
dtWV                    Asymptotic Noncentral t Distribution Density by
                        Viechtbauer
expm1x                  Accurate exp(x) - 1 - x (for smallish |x|)
format01prec            Format Numbers in [0,1] with "Precise" Result
frexp                   Base-2 Representation and Multiplication of
                        Numbers
gam1d                   Compute 1/Gamma(x+1) - 1 Accurately
gamln1                  Compute log( Gamma(x+1) ) Accurately in [-0.2,
                        1.25]
gammaVer                Gamma Function Versions
hyper2binomP            Transform Hypergeometric Distribution
                        Parameters to Binomial Probability
lbetaM                  (Log) Beta and Ratio of Gammas Approximations
lfastchoose             R versions of Simple Formulas for Logarithmic
                        Binomial Coefficients
lgamma1p                Accurate 'log(gamma(a+1))'
lgammaAsymp             Asymptotic Log Gamma Function
log1mexp                Compute log(1 - exp(-a)) and log(1 + exp(x))
                        Numerically Optimally
log1pmx                 Accurate 'log(1+x) - x' Computation
logcf                   Continued Fraction Approximation of Log-Related
                        Power Series
logspace.add            Logspace Arithmetix - Addition and Subtraction
lssum                   Compute Logarithm of a Sum with Signed Large
                        Summands
lsum                    Properly Compute the Logarithm of a Sum (of
                        Exponentials)
newton                  Simple R level Newton Algorithm, Mostly for
                        Didactical Reasons
p1l1                    Numerically Stable p1l1(t) = (t+1)*log(1+t) - t
pbetaRv1                Pure R Implementation of Old pbeta()
pchisqV                 Wienergerm Approximations to (Non-Central)
                        Chi-squared Probabilities
phyper1molenaar         Molenaar's Normal Approximations to the
                        Hypergeometric Distribution
phyperAllBin            Compute Hypergeometric Probabilities via
                        Binomial Approximations
phyperApprAS152         Normal Approximation to cumulative Hyperbolic
                        Distribution - AS 152
phyperBin.1             HyperGeometric Distribution via Approximate
                        Binomial Distribution
phyperBinMolenaar       HyperGeometric Distribution via Molenaar's
                        Binomial Approximation
phyperIbeta             Pearson's incomplete Beta Approximation to the
                        Hyperbolic Distribution
phyperPeizer            Peizer's Normal Approximation to the Cumulative
                        Hyperbolic
phyperR                 R-only version of R's original phyper()
                        algorithm
phyperR2                Pure R version of R's C level phyper()
phypers                 The Four (4) Symmetric 'phyper()' Calls
pl2curves               Plot 2 Noncentral Distribution Curves for
                        Visual Comparison
pnbetaAppr2             Noncentral Beta Probabilities
pnchi1sq                (Probabilities of Non-Central Chi-squared
                        Distribution for Special Cases
pnchisq                 (Approximate) Probabilities of Non-Central
                        Chi-squared Distribution
pnormAsymp              Asymptotic Approxmation of (Extreme Tail)
                        'pnorm()'
pnormL_LD10             Bounds for 1-Phi(.) - Mill's Ratio related
                        Bounds for pnorm()
pntR                    Non-central t Probability Distribution -
                        Algorithms and Approximations
pow                     X to Power of Y - R C API 'R_pow()'
pow1p                   Accurate (1+x)^y, notably for small |x|
ppoisErr                Direct Computation of 'ppois()' Poisson
                        Distribution Probabilities
pt_Witkovsky_Tab1       Viktor Witosky's Table_1 pt() Examples
qbetaAppr               Compute (Approximate) Quantiles of the Beta
                        Distribution
qbinomR                 Pure R Implementation of R's qbinom() with
                        Tuning Parameters
qchisqAppr              Compute Approximate Quantiles of the
                        Chi-Squared Distribution
qgammaAppr              Compute (Approximate) Quantiles of the Gamma
                        Distribution
qnbinomR                Pure R Implementation of R's qnbinom() with
                        Tuning Parameters
qnchisqAppr             Compute Approximate Quantiles of Noncentral
                        Chi-Squared Distribution
qnormAppr               Approximations to 'qnorm()', i.e., z_alpha
qnormAsymp              Asymptotic Approximation to Outer Tail of
                        qnorm()
qnormR                  Pure R version of R's 'qnorm()' with
                        Diagnostics and Tuning Parameters
qntR                    Pure R Implementation of R's qt() / qnt()
qpoisR                  Pure R Implementation of R's qpois() with
                        Tuning Parameters
qtAppr                  Compute Approximate Quantiles of the
                        (Non-Central) t-Distribution
qtR                     Pure R Implementation of R's C-level
                        t-Distribution Quantiles 'qt()'
qtU                     'uniroot()'-based Computing of t-Distribution
                        Quantiles
r_pois                  Compute Relative Size of i-th term of Poisson
                        Distribution Series
rexpm1                  TOMS 708 Approximation REXP(x) of expm1(x) =
                        exp(x) - 1
stirlerr                Stirling's Error Function - Auxiliary for
                        Gamma, Beta, etc
</pre>

<p>Further information is available in the following vignettes:<br /><br />
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>Noncentral-Chisq</code> </td><td style="text-align: left;"> Noncentral Chi-Squared Probabilities -- Algorithms in R (source)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>comp-beta</code> </td><td style="text-align: left;"> Computing Beta(a,b) for Large Arguments (source)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>log1pmx-etc</code> </td><td style="text-align: left;"> log1pmx, bd0, stirlerr - Probability Computations in R (source)</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>qnorm-asymp</code> </td><td style="text-align: left;"> Asymptotic Tail Formulas For Gaussian Quantiles (source)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>An important goal is to investigate diverse algorithms and approximations
of <span class="rlang"><b>R</b></span>'s own density (<code>d*()</code>), probability (<code>p*()</code>), and
quantile (<code>q*()</code>) functions, notably in &ldquo;border&rdquo; cases where
the traditional published algorithms have shown to be suboptimal, not
quite accurate, or even useless.
</p>
<p>Examples are border cases of the beta distribution, or <b>non-central</b>
distributions such as the non-central chi-squared and t-distributions.
</p>


<h3>Author(s)</h3>

<p>Principal author and maintainer: Martin Maechler &lt;maechler@stat.math.ethz.ch&gt;

</p>


<h3>See Also</h3>

<p>The package <span class="pkg"><a href="DPQmpfr.html#topic+DPQmpfr-package">DPQmpfr</a></span>,
which builds on this package and on
<span class="pkg"><a href="Rmpfr.html#topic+Rmpfr-package">Rmpfr</a></span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Show problem in R's non-central t-distrib. density (and approximations):
example(dntJKBf)

</code></pre>

<hr>
<h2 id='algdiv'>Compute log(gamma(b)/gamma(a+b)) when b &gt;= 8</h2><span id='topic+algdiv'></span>

<h3>Description</h3>

<p>Computes </p>
<p style="text-align: center;"><code class="reqn">\code{algdiv(a,b)} := \log \frac{\Gamma(b)}{\Gamma(a+b)} = \log
    \Gamma(b) - \log\Gamma(a+b) = \code{lgamma(b) - lgamma(a+b)}</code>
</p>

<p>in a numerically stable way.
</p>
<p>This is an auxiliary function in <span class="rlang"><b>R</b></span>'s (TOMS 708) implementation of
<code><a href="stats.html#topic+pbeta">pbeta</a>()</code>, aka the incomplete beta function ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>algdiv(a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="algdiv_+3A_a">a</code>, <code id="algdiv_+3A_b">b</code></td>
<td>
<p>numeric vectors which will be recycled to the same length.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this is also useful to compute the Beta function
</p>
<p style="text-align: center;"><code class="reqn">B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}.</code>
</p>

<p>Clearly,  </p>
<p style="text-align: center;"><code class="reqn">\log B(a,b) = \log\Gamma(a) + \mathrm{algdiv(a,b)} = \log\Gamma(a) - \mathrm{logQab}(a,b)</code>
</p>

<p>In our &lsquo;<span class="file">../tests/qbeta-dist.R</span>&rsquo;  we look into computing
<code class="reqn">\log(p B(p,q))</code> accurately for
<code class="reqn">p \ll q</code> .
</p>
<p>We are proposing a nice solution there.
<br /> How is this related to <code>algdiv()</code> ?
</p>
<p>Additionally, we have defined
</p>
<p style="text-align: center;"><code class="reqn">Qab = Q_{a,b} := \frac{\Gamma(a+b),\Gamma(b)},</code>
</p>

<p>such that <code class="reqn">\code{logQab(a,b)} := \log Qab(a,b)</code>
fulfills simply
</p>
<p style="text-align: center;"><code class="reqn">\code{logQab(a,b)} = - \code{algdiv(a,b)}</code>
</p>

<p>see <code><a href="#topic+logQab_asy">logQab_asy</a></code>.
</p>


<h3>Value</h3>

<p>a numeric vector of length <code>max(length(a), length(b))</code> (if neither
is of length 0, in which case the result has length 0 as well).
</p>


<h3>Author(s)</h3>

<p>Didonato, A. and Morris, A., Jr, (1992); <code>algdiv()</code>'s C
version from the <span class="rlang"><b>R</b></span> sources, authored by the <span class="rlang"><b>R</b></span> core team; C and <span class="rlang"><b>R</b></span>
interface: Martin Maechler
</p>


<h3>References</h3>

<p>Didonato, A. and Morris, A., Jr, (1992)
Algorithm 708: Significant digit computation of the incomplete beta
function ratios,
<em>ACM Transactions on Mathematical Software</em> <b>18</b>, 360&ndash;373. 
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gamma">gamma</a></code>, <code><a href="base.html#topic+beta">beta</a></code>;
my own <code><a href="#topic+logQab_asy">logQab_asy</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Qab &lt;- algdiv(2:3, 8:14)
cbind(a = 2:3, b = 8:14, Qab) # recycling with a warning

## algdiv()  and my  logQab_asy()  give *very* similar results for largish b:
all.equal( -   algdiv(3, 100),
           logQab_asy(3, 100), tolerance=0) # 1.283e-16 !!
(lQab &lt;- logQab_asy(3, 1e10))
## relative error
1 + lQab/ algdiv(3, 1e10) # 0 (64b F 30 Linux; 2019-08-15)

## in-and outside of "certified" argument range {b &gt;= 8}:
a. &lt;- c(1:3, 4*(1:8))/32
b. &lt;- seq(1/4, 20, by=1/4)
ad &lt;- t(outer(a., b., algdiv))
## direct computation:
f.algdiv &lt;- function(a,b) lgamma(b) - lgamma(a+b)
ad.d &lt;- t(outer(a., b., f.algdiv))

matplot (b., ad.d, type = "o", cex=3/4,
         main = quote(log(Gamma(b)/Gamma(a+b)) ~"  vs.  algdiv(a,b)"))
mtext(paste0("a[1:",length(a.),"] = ",
        paste0(paste(head(paste0(formatC(a.*32), "/32")), collapse=", "), ", .., 1")))
matlines(b., ad,   type = "l", lwd=4, lty=1, col=adjustcolor(1:6, 1/2))
abline(v=1, lty=3, col="midnightblue")
# The larger 'b', the more accurate the direct formula wrt algdiv()
all.equal(ad[b. &gt;= 1,], ad.d[b. &gt;= 1,]       )# 1.5e-5
all.equal(ad[b. &gt;= 2,], ad.d[b. &gt;= 2,], tol=0)# 3.9e-9
all.equal(ad[b. &gt;= 4,], ad.d[b. &gt;= 4,], tol=0)# 4.6e-13
all.equal(ad[b. &gt;= 6,], ad.d[b. &gt;= 6,], tol=0)# 3.0e-15
all.equal(ad[b. &gt;= 8,], ad.d[b. &gt;= 8,], tol=0)# 2.5e-15 (not much better)
</code></pre>

<hr>
<h2 id='b_chi'>Compute <code class="reqn">E[\chi_\nu] / \sqrt{\nu}</code>
useful for t- and chi-Distributions</h2><span id='topic+b_chi'></span><span id='topic+b_chiAsymp'></span><span id='topic+lb_chi00'></span><span id='topic+lb_chi0'></span><span id='topic+lb_chiAsymp'></span><span id='topic+c_dt'></span><span id='topic+c_dtAsymp'></span><span id='topic+c_pt'></span>

<h3>Description</h3>

<p style="text-align: center;"><code class="reqn">b_\chi(\nu) := E[\chi(\nu)] / \sqrt{\nu} = \frac{\sqrt{2/\nu}\Gamma((\nu+1)/2)}{\Gamma(\nu/2)},</code>
</p>

<p>where <code class="reqn">\chi(\nu)</code> denotes a chi-distributed random variable, i.e.,
the square of a chi-squared variable, and <code class="reqn">\Gamma(z)</code> is
the Gamma function, <code><a href="base.html#topic+gamma">gamma</a>()</code> in <span class="rlang"><b>R</b></span>.
</p>
<p>This is a relatively important auxiliary function when computing with
non-central t distribution functions and approximations, specifically see
Johnson et al.(1994), p.520, after (31.26a), e.g., our <code><a href="#topic+pntJW39">pntJW39</a>()</code>.
</p>
<p>Its logarithm,
</p>
<p style="text-align: center;"><code class="reqn">lb_\chi(\nu) := log\bigl(\frac{\sqrt{2/\nu}\Gamma((\nu+1)/2)}{\Gamma(\nu/2)}\bigr),</code>
</p>

<p>is even easier to compute via <code><a href="base.html#topic+lgamma">lgamma</a></code> and <code><a href="base.html#topic+log">log</a></code>,
and I have used Maple to derive an asymptotic expansion in
<code class="reqn">\frac{1}{\nu}</code> as well.
</p>
<p>Note that <code class="reqn">lb_\chi(\nu)</code> also appears in the formula
for the t-density (<code><a href="stats.html#topic+dt">dt</a></code>) and distribution (tail) functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>b_chi     (nu, one.minus = FALSE, c1 = 341, c2 = 1000)
b_chiAsymp(nu, order = 2, one.minus = FALSE)
#lb_chi    (nu, ......) # not yet
lb_chiAsymp(nu, order)

c_dt(nu)       # warning("FIXME: current c_dt() is poor -- base it on lb_chi(nu) !")
c_dtAsymp(nu)  # deprecated in favour of lb_chi(nu)
c_pt(nu)       # warning("use better c_dt()") %---&gt; FIXME deprecate even stronger ?
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="b_chi_+3A_nu">nu</code></td>
<td>
<p>non-negative numeric vector of degrees of freedom.</p>
</td></tr>
<tr><td><code id="b_chi_+3A_one.minus">one.minus</code></td>
<td>
<p>logical indicating if <code class="reqn">1 - b()</code> should be
returned instead of <code class="reqn">b()</code>.</p>
</td></tr>
<tr><td><code id="b_chi_+3A_c1">c1</code>, <code id="b_chi_+3A_c2">c2</code></td>
<td>
<p>boundaries for different approximation intervals used:
<br /> for <code>0  &lt; nu &lt;= c1</code>, internal <code>b1()</code> is used,
<br /> for <code>c1 &lt; nu &lt;= c2</code>, internal <code>b2()</code> is used, and
<br /> for <code>c2 &lt; nu</code>, the <code>b_chiAsymp()</code> function is used,
(and you can use that explicitly, also for smaller <code>nu</code>).
</p>
<p>FIXME: <code>c1</code> and <code>c2</code> were defined when the only asymptotic
expansion known to me was the <code>order = 2</code> one.
A future version of <code>b_chi</code> will <em>very likely</em> use
<code>b_chiAsymp(*, order)</code> for higher orders, and the c1 and c2
arguments will change, possibly be abolished.
</p>
</td></tr>
<tr><td><code id="b_chi_+3A_order">order</code></td>
<td>
<p>the polynomial order in <code class="reqn">\frac{1}{\nu}</code> of the
asymptotic expansion of <code class="reqn">b_\chi(\nu)</code> for <code class="reqn">\nu\to\infty</code>.
</p>
<p>The default, <code>order = 2</code> corresponds to the order you can get
out of the Abramowitz and Stegun (6.1.47) formula.
Higher order expansions were derived using <code>Maple</code> by Martin Maechler
in 2002, see below, but implemented in <code>b_chiAsymp()</code> only in 2018.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One can see that <code>b_chi()</code> has the properties of a CDF of a
continuous positive random variable:  It grows monotonely from
<code class="reqn">b_\chi(0) = 0</code> to (asymptotically) one.  Specifically,
for large <code>nu</code>, <code>b_chi(nu) = b_chiAsymp(nu)</code> and
</p>
<p style="text-align: center;"><code class="reqn">1 - b_\chi(\nu) \sim \frac{1}{4\nu}.</code>
</p>

<p>More accurately, derived from Abramowitz and Stegun, 6.1.47 (p.257)
for a= 1/2, b=0,
</p>
<p style="text-align: center;"><code class="reqn">\Gamma(z + 1/2) / \Gamma(z) \sim \sqrt(z)*(1 - 1/(8z) + 1/(128 z^2) + O(1/z^3)),</code>
</p>

<p>and applied for <code class="reqn">b_\chi(\nu)</code> with <code class="reqn">z = \nu/2</code>, we get
</p>
<p style="text-align: center;"><code class="reqn">b_\chi(\nu) \sim 1 - (1/(4\nu) * (1 - 1/(8\nu)) + O(\nu^{-3})),</code>
</p>

<p>which has been implemented in <code>b_chiAsymp(*, order=2)</code> in 1999.
</p>
<p>Even more accurately, Martin Maechler, used Maple to derive an
asymptotic expansion up to order 15, here reported up to order 5,
namely with <code class="reqn">r := \frac{1}{4\nu}</code>,
</p>
<p style="text-align: center;"><code class="reqn">b_\chi(\nu) = c_\chi(r) = 1 - r + \frac{1}{2}r^2 +
    \frac{5}{2}r^3 - \frac{21}{8}r^4 - \frac{399}{8}r^5 + O(r^6).</code>
</p>



<h3>Value</h3>

<p>a numeric vector of the same length as <code>nu</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, Kotz,  Balakrishnan (1995)
<em>Continuous Univariate Distributions</em>,
Vol 2, 2nd Edition; Wiley;  
Formula on page 520, after (31.26a)
</p>
<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>


<h3>See Also</h3>

<p>The t-distribution (base <span class="rlang"><b>R</b></span>) page <code><a href="stats.html#topic+pt">pt</a></code>;
our <code><a href="#topic+pntJW39">pntJW39</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(b_chi, 0, 20); abline(h=0:1, v=0, lty=3)
r &lt;- curve(b_chi, 1e-10, 1e5, log="x")
with(r, lines(x, b_chi(x, one.minus=TRUE), col = 2))

## Zoom in to c1-region
rc1 &lt;- curve(b_chi, 340.5, 341.5, n=1001)# nothing to see
e &lt;- 1e-3; curve(b_chi, 341-e, 341+e, n=1001) # nothing
e &lt;- 1e-5; curve(b_chi, 341-e, 341+e, n=1001) # see noise, but no jump
e &lt;- 1e-7; curve(b_chi, 341-e, 341+e, n=1001) # see float "granularity"+"jump"

## Zoom in to c2-region
rc2 &lt;- curve(b_chi, 999.5, 1001.5, n=1001) # nothing visible
e &lt;- 1e-3; curve(b_chi, 1000-e, 1000+e, n=1001) # clear small jump
c2 &lt;- 1500
e &lt;- 1e-3; curve(b_chi(x,c2=c2), c2-e, c2+e, n=1001)# still
## - - - -
c2 &lt;- 3000
e &lt;- 1e-3; curve(b_chi(x,c2=c2), c2-e, c2+e, n=1001)# ok asymp clearly better!!
curve(b_chiAsymp, add=TRUE, col=adjustcolor("red", 1/3), lwd=3)
if(requireNamespace("Rmpfr")) {
 xm &lt;- Rmpfr::seqMpfr(c2-e, c2+e, length.out=1000)

}
## - - - -
c2 &lt;- 4000
e &lt;- 1e-3; curve(b_chi(x,c2=c2), c2-e, c2+e, n=1001)# ok asymp clearly better!!
curve(b_chiAsymp, add=TRUE, col=adjustcolor("red", 1/3), lwd=3)

grCol &lt;- adjustcolor("forest green", 1/2)
curve(b_chi,                    1/2, 1e11, log="x")
curve(b_chiAsymp, add = TRUE, col = grCol, lwd = 3)
## 1-b(nu) ~= 1/(4 nu) a power function &lt;==&gt; linear in log-log scale:
curve(b_chi(x, one.minus=TRUE), 1/2, 1e11, log="xy")
curve(b_chiAsymp(x, one.minus=TRUE), add = TRUE, col = grCol, lwd = 3)

</code></pre>

<hr>
<h2 id='Bern'>Bernoulli Numbers</h2><span id='topic+Bern'></span>

<h3>Description</h3>


<p>Return the <code class="reqn">n</code>-th Bernoulli number <code class="reqn">B_n</code>, (or <code class="reqn">B_n^+</code>,
see the reference), where <code class="reqn">B_1 = + \frac 1 2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bern(n, verbose = getOption("verbose", FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bern_+3A_n">n</code></td>
<td>
<p>integer, <code class="reqn">n \ge 0</code>.</p>
</td></tr>
<tr><td><code id="Bern_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if computation should be traced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The number <code class="reqn">B_n</code> of type <code><a href="base.html#topic+numeric">numeric</a></code>.
</p>
<p>A side effect is the <em>caching</em> of computed Bernoulli numbers in the
hidden <code><a href="base.html#topic+environment">environment</a></code> <code>.bernoulliEnv</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Bernoulli_number">https://en.wikipedia.org/wiki/Bernoulli_number</a>
</p>


<h3>See Also</h3>

<p><code><a href="Rmpfr.html#topic+Bernoulli">Bernoulli</a></code> in <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a> in arbitrary precision
via Riemann's <code class="reqn">\zeta</code> function.
</p>
<p>The next version of package <a href="https://CRAN.R-project.org/package=gmp"><span class="pkg">gmp</span></a> is to contain 
<code>BernoulliQ()</code>, providing exact Bernoulli numbers as
big rationals (class <code>"bigq"</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(B.0.10 &lt;- vapply(0:10, Bern, 1/2))
## [1]  1.00000000 +0.50000000  0.16666667  0.00000000 -0.03333333  0.00000000
## [7]  0.02380952  0.00000000 -0.03333333  0.00000000  0.07575758
if(requireNamespace("MASS")) {
  print( MASS::fractions(B.0.10) )
  ## 1  +1/2   1/6    0  -1/30     0  1/42     0 -1/30     0  5/66
}
</code></pre>

<hr>
<h2 id='bpser'><code>pbeta()</code>  'bpser' series computation</h2><span id='topic+bpser'></span>

<h3>Description</h3>

<p>Compute the <code>bpser</code> series approximation of <code><a href="stats.html#topic+pbeta">pbeta</a></code>, the
incomplete beta function.
Note that when <code>b</code> is integer valued, the series is a <em>sum</em> of
<code class="reqn">b+1</code> terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpser(a, b, x, log.p = FALSE, eps = 1e-15, verbose = FALSE, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bpser_+3A_a">a</code>, <code id="bpser_+3A_b">b</code></td>
<td>
<p>numeric and non-negative, the two shape parameters of the beta distribution.</p>
</td></tr>
<tr><td><code id="bpser_+3A_x">x</code></td>
<td>
<p>numeric vector of abscissa values in <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="bpser_+3A_log.p">log.p</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> if <code><a href="base.html#topic+log">log</a>(prob)</code> should be
returned, allowing to avoid underflow much farther &ldquo;out in the tails&rdquo;.</p>
</td></tr>
<tr><td><code id="bpser_+3A_eps">eps</code></td>
<td>
<p>series convergence (and other) tolerance, a small positive number.</p>
</td></tr>
<tr><td><code id="bpser_+3A_verbose">verbose</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> indicating if some intermediate
results should be printed to the console.</p>
</td></tr>
<tr><td><code id="bpser_+3A_warn">warn</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> indicating if <code>bpser()</code>
computation problems should be warned about <em>in addition</em> to return
a non-zero error code.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+list">list</a></code> with components
</p>
<table role = "presentation">
<tr><td><code>r</code></td>
<td>
<p>the resulting <code><a href="base.html#topic+numeric">numeric</a></code> vector.</p>
</td></tr>
<tr><td><code>ier</code></td>
<td>
<p>an integer vector of the same length as <code>x</code>, providing one
error code for the computation in each <code>r[i]</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler, ported to <span class="pkg">DPQ</span>; R-Core team for the code in <span class="rlang"><b>R</b></span>.</p>


<h3>References</h3>

<p>TOMS 708, see <code><a href="stats.html#topic+pbeta">pbeta</a></code>
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+pbeta">pbeta</a></code>;
<span class="pkg">DPQ</span>'s <code><a href="#topic+pbetaRv1">pbetaRv1</a>()</code>, and <code><a href="#topic+Ixpq">Ixpq</a>()</code>;
<a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>'s <code><a href="Rmpfr.html#topic+pbetaI">pbetaI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(bpser(100000, 11, (0:64)/64), # all 0 {last one "wrongly"}
     stopifnot(r == c(rep(0, 64), 1), err == 0))
bp1e5.11L &lt;- bpser(100000, 11, (0:64)/64, log.p=TRUE)# -&gt; 2 "underflow to -Inf" warnings!
pbe &lt;- pbeta((0:64)/64, 100000, 11, log.p=TRUE)

## verbose=TRUE showing info on number of terms / iterations
ps11.5 &lt;- bpser(100000, 11.5, (0:64)/64, log.p=TRUE, verbose=TRUE)
</code></pre>

<hr>
<h2 id='chebyshevPoly'>Chebyshev Polynomial Evaluation</h2><span id='topic+chebyshevPoly'></span><span id='topic+chebyshevEval'></span><span id='topic+chebyshev_nc'></span>

<h3>Description</h3>

<p>Provides (evaluation of) Chebyshev polynomials, given their coefficients
vector <code>coef</code> (using <code class="reqn">2 c_0</code>, i.e., <code>2*coef[1]</code> as the base
R mathlib <code>chebyshev*()</code> functions.
Specifically, the following sum is evaluated:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{j=0}^n c_j T_j(x)</code>
</p>

<p>where  <code class="reqn">c_0 :=</code><code>coef[1]</code>  and
<code class="reqn">c_j :=</code><code>coef[j+1]</code> for <code class="reqn">j \ge 1</code>.
<code class="reqn">n :=</code> <code>chebyshev_nc(coef, .)</code> is the maximal degree and hence
one less than the number of terms, and <code class="reqn">T_j()</code> is the
Chebyshev polynomial (of the first kind) of degree <code class="reqn">j</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
chebyshevPoly(coef, nc = chebyshev_nc(coef, eta), eta = .Machine$double.eps/20)

chebyshev_nc(coef, eta = .Machine$double.eps/20)
chebyshevEval(x, coef,
              nc = chebyshev_nc(coef, eta), eta = .Machine$double.eps/20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chebyshevPoly_+3A_coef">coef</code></td>
<td>
<p>a numeric vector of coefficients for the Chebyshev polynomial.</p>
</td></tr>
<tr><td><code id="chebyshevPoly_+3A_nc">nc</code></td>
<td>
<p>the maximal degree, i.e., one less than the number of
polynomial terms to use; typically use the default.</p>
</td></tr>
<tr><td><code id="chebyshevPoly_+3A_eta">eta</code></td>
<td>
<p>a positive number; typically keep the default.</p>
</td></tr>
<tr><td><code id="chebyshevPoly_+3A_x">x</code></td>
<td>
<p>for <code>chebyshevEval()</code>: numeric vector of abscissa values at
which the polynomial should be evaluated.  Typically <code>x</code> values
are inside the interval <code class="reqn">[-1, 1]</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>chebyshevPoly()</code> returns <code><a href="base.html#topic+function">function</a>(x)</code> which computes
the values of the underlying Chebyshev polynomial at <code>x</code>.
</p>
<p><code>chebyshev_nc()</code> returns an <code><a href="base.html#topic+integer">integer</a></code>, and
<code>chebyshevEval(x, coef)</code> returns a numeric &ldquo;like&rdquo; <code>x</code>
with the values of the polynomial at <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>R Core team, notably Ross Ihaka; Martin Maechler provided the <span class="rlang"><b>R</b></span> interface.</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">https://en.wikipedia.org/wiki/Chebyshev_polynomials</a>
</p>


<h3>See Also</h3>

<p><code><a href="sfsmisc.html#topic+polyn.eval">polyn.eval</a>()</code> from CRAN package <a href="https://CRAN.R-project.org/package=sfsmisc"><span class="pkg">sfsmisc</span></a>; as one
example of many more.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The first 5 (base) Chebyshev polynomials:
T0 &lt;- chebyshevPoly(2)  # !! 2, not 1
T1 &lt;- chebyshevPoly(0:1)
T2 &lt;- chebyshevPoly(c(0,0,1))
T3 &lt;- chebyshevPoly(c(0,0,0,1))
T4 &lt;- chebyshevPoly(c(0,0,0,0,1))
curve(T0(x), -1,1, col=1, lwd=2, ylim=c(-1,1))
abline(h=0, lty=2)
curve(T1(x), col=2, lwd=2, add=TRUE)
curve(T2(x), col=3, lwd=2, add=TRUE)
curve(T3(x), col=4, lwd=2, add=TRUE)
curve(T4(x), col=5, lwd=2, add=TRUE)

(Tv &lt;- vapply(c(T0=T0, T1=T1, T2=T2, T3=T3, T4=T4),
              function(Tp) Tp(-1:1), numeric(3)))
x &lt;- seq(-1,1, by = 1/64)
stopifnot(exprs = {
   all.equal(chebyshevPoly(1:5)(x),
             0.5*T0(x) + 2*T1(x) + 3*T2(x) + 4*T3(x) + 5*T4(x))
   all.equal(unname(Tv), rbind(c(1,-1), c(1:-1,0:1), rep(1,5)))# warning on rbind()
})

</code></pre>

<hr>
<h2 id='dbinom_raw'>R's C Mathlib (Rmath) dbinom_raw() Binomial Probability pure R Function</h2><span id='topic+dbinom_raw'></span>

<h3>Description</h3>

<p>A pure <span class="rlang"><b>R</b></span> implementation of R's C API (&lsquo;Mathlib&rsquo; specifically)
<code>dbinom_raw()</code> function which computes binomial probabilities
<em>and</em> is continuous in <code>x</code>, i.e., also &ldquo;works&rdquo; for
non-integer <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dbinom_raw (x, n, p, q = 1-p, log = FALSE,
            version = c("2008", "R4.4"),
            verbose = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dbinom_raw_+3A_x">x</code></td>
<td>
<p>vector with values typically in <code>0:n</code>,  but here allowed to
non-integer values.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_n">n</code></td>
<td>
<p>called <code>size</code> in <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dbinom">dbinom</a>()</code>.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_p">p</code></td>
<td>
<p>called <code>prob</code> in <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dbinom">dbinom</a>()</code>, the success
probability, hence in <code class="reqn">[0, 1]</code>.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_q">q</code></td>
<td>
<p>mathemtically the same as <code class="reqn">1 - p</code>, but may be (much) more
accurate, notably when small.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_log">log</code></td>
<td>
<p>logical indicating if the <code><a href="base.html#topic+log">log</a>()</code> of the resulting
probability should be returned; useful notably in case the probability
itself would underflow to zero.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_version">version</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string; originally,
<code>"2008"</code> was the only option.  Still the default currently,
this <em>may change</em> in the future.</p>
</td></tr>
<tr><td><code id="dbinom_raw_+3A_verbose">verbose</code></td>
<td>
<p>integer indicating the amount of verbosity of
diagnostic output, <code>0</code> means no output, <code>1</code> more, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of the same length as <code>x</code> which may have to be
thought of recycled along <code>n</code>, <code>p</code> and/or <code>q</code>.
</p>


<h3>Author(s)</h3>

<p>R Core and Martin Maechler</p>


<h3>See Also</h3>

<p>Note that our CRAN package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a> provides
<code><a href="Rmpfr.html#topic+dbinom">dbinom</a></code>, an mpfr-accurate function to be used
used instead of <span class="rlang"><b>R</b></span>'s or this pure <span class="rlang"><b>R</b></span> version relying <code><a href="#topic+bd0">bd0</a>()</code> and
<code><a href="#topic+stirlerr">stirlerr</a>()</code> where the latter currently only provides
accurate double precision accuracy.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

for(n in c(3, 10, 27, 100, 500, 2000, 5000, 1e4, 1e7, 1e10)) {
 x &lt;- if(n &lt;= 2000) 0:n else round(seq(0, n, length.out=2000))
 p &lt;- 3/4
 stopifnot(all.equal(dbinom_raw(x, n, p, q=1-p) -&gt; dbin,
                     dbinom    (x, n, p), tolerance = 1e-13))# 1.636e-14 (Apple clang 14.0.3)
 stopifnot(all.equal(dbin, dbinom_raw(x, n, p, q=1-p, version = "R4.4") -&gt; dbin44,
                     tolerance = 1e-13))
 cat("n = ", n, ": ", (aeq &lt;- all.equal(dbin44, dbin, tolerance = 0)), "\n")
 if(n &lt; 3000) stopifnot(is.character(aeq)) # check that dbin44 is "better" ?!
}

n &lt;- 1024 ; x &lt;- 0:n
plot(x, dbinom_raw(x, n, p, q=1-p) - dbinom(x, n, p), type="l", main = "|db_r(x) - db(x)|")
plot(x, dbinom_raw(x, n, p, q=1-p) / dbinom(x, n, p) - 1, type="b", log="y",
     main = "rel.err.  |db_r(x / db(x) - 1)|")
</code></pre>

<hr>
<h2 id='dchisqApprox'>Approximations of the (Noncentral) Chi-Squared Density</h2><span id='topic+dnchisqR'></span><span id='topic+dchisqAsym'></span><span id='topic+dnchisqBessel'></span><span id='topic+dnoncentchisq'></span>

<h3>Description</h3>

<p>Compute the density function <code class="reqn">f(x, *)</code> of the (noncentral) chi-squared
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dnchisqR     (x, df, ncp, log = FALSE,
              eps = 5e-15, termSml = 1e-10, ncpLarge = 1000)
dnchisqBessel(x, df, ncp, log = FALSE)
dchisqAsym   (x, df, ncp, log = FALSE)
dnoncentchisq(x, df, ncp, kmax = floor(ncp/2 + 5 * (ncp/2)^0.5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dchisqApprox_+3A_x">x</code></td>
<td>
<p>non-negative numeric vector.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_df">df</code></td>
<td>
<p>degrees of freedom (parameter), a positive number.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>; ....</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_log">log</code></td>
<td>
<p>logical indicating if the result is desired on the log scale.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_eps">eps</code></td>
<td>
<p>positive convergence tolerance for the series expansion: Terms
are added while <code>term * q &gt; (1-q)*eps</code>, where <code>q</code> is the term's
multiplication factor.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_termsml">termSml</code></td>
<td>
<p>positive tolerance: in the series expansion, terms are
added to the sum as long as they are not smaller than <code>termSml *
      sum</code> even when convergence according to <code>eps</code> had occured.  This
was not part of the original C code, but was added later for
safeguarding against infinite loops, from <a href="https://bugs.R-project.org/show_bug.cgi?id=14105">PR#14105</a>, e.g., for
<code>dchisq(2000, 2, 1000)</code>.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_ncplarge">ncpLarge</code></td>
<td>
<p>in the case where <code>mid</code> underflows to <code>0</code>, when
<code>log</code> is true, or <code>ncp &gt;= ncpLarge</code>, use a central
approximation.  In theory, an optimal choice of <code>ncpLarge</code> would
not be arbitrarily set at <code>1000</code> (hardwired in <span class="rlang"><b>R</b></span>'s
<code><a href="stats.html#topic+dchisq">dchisq</a>()</code> here), but possibly also depend on <code>x</code> or
<code>df</code>.</p>
</td></tr>
<tr><td><code id="dchisqApprox_+3A_kmax">kmax</code></td>
<td>
<p>the number of terms in the sum for <code>dnoncentchisq()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dnchisqR()</code> is a pure <span class="rlang"><b>R</b></span> implementation of <span class="rlang"><b>R</b></span>'s own C implementation
in the sources, &lsquo;<span class="file">R/src/nmath/dnchisq.c</span>&rsquo;, additionally exposing the
three &ldquo;tuning parameters&rdquo; <code>eps</code>, <code>termSml</code>, and <code>ncpLarge</code>.
</p>
<p><code>dnchisqBessel()</code> implements Fisher(1928)'s exact closed form formula
based on the Bessel function <code class="reqn">I_{nu}</code>, i.e., <span class="rlang"><b>R</b></span>'s
<code><a href="base.html#topic+besselI">besselI</a>()</code> function;
specifically formula (29.4) in Johnson et al. (1995).
</p>
<p><code>dchisqAsym()</code> is the simple asymptotic approximation from
Abramowitz and Stegun's formula <code>26.4.27</code>, p. 942.
</p>
<p><code>dnoncentchisq()</code> uses the (typically defining) infinite series expansion
directly, with truncation at <code>kmax</code>, and terms <code class="reqn">t_k</code> which
are products of a Poisson probability and a central chi-square density, i.e.,
terms <code>t.k :=  <a href="stats.html#topic+dpois">dpois</a>(k, lambda = ncp/2) * <a href="stats.html#topic+dchisq">dchisq</a>(x, df = 2*k + df)</code>
for <code>k = 0, 1, ..., kmax</code>.
</p>


<h3>Value</h3>

<p>numeric vector similar to <code>x</code>, containing the (logged if
<code>log=TRUE</code>) values of the density <code class="reqn">f(x,*)</code>.
</p>


<h3>Note</h3>

<p>These functions are mostly of historical interest, notably as <span class="rlang"><b>R</b></span>'s
<code><a href="stats.html#topic+dchisq">dchisq</a>()</code> was not always very accurate in the noncentral
case, i.e., for <code>ncp &gt; 0</code>.
</p>


<h3>Note</h3>

<p><span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dchisq">dchisq</a>()</code> is typically more uniformly
accurate than the approximations nowadays, apart from <code>dnchisqR()</code>
which should behave the same.
There may occasionally exist small differences between <code>dnchisqR(x, *)</code>
and <code><a href="stats.html#topic+dchisq">dchisq</a>(x, *)</code> for the same parameters.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, April 2008</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>
<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
Continuous Univariate Distributions Vol~2, 2nd ed.; Wiley;
chapter 29, Section <em>3  Distribution</em>, (29.4), p. 436.
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s own <code><a href="stats.html#topic+dchisq">dchisq</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sort(outer(c(1,2,5), 2^(-4:5)))
fRR &lt;- dchisq  (x, 10, 2)
f.R &lt;- dnchisqR(x, 10, 2)
all.equal(fRR, f.R, tol = 0) # 64bit Lnx (F 30): 1.723897e-16
stopifnot(all.equal(fRR, f.R, tol = 4e-15))
</code></pre>

<hr>
<h2 id='dgamma-utils'>Binomial Deviance &ndash; Auxiliary Functions for <code>dgamma()</code> Etc</h2><span id='topic+bd0'></span><span id='topic+bd0_p1l1d1'></span><span id='topic+bd0_p1l1d'></span><span id='topic+bd0_l1pm'></span><span id='topic+bd0C'></span><span id='topic+ebd0'></span><span id='topic+ebd0C'></span><span id='topic+dpois_raw'></span><span id='topic+dpois_simpl'></span><span id='topic+dpois_simpl0'></span>

<h3>Description</h3>

<p>The &ldquo;binomial deviance&rdquo; function
<code>bd0(x, M) :=</code> <code class="reqn">D_0(x,M) := M \cdot d_0(x/M)</code>,
where <code class="reqn">d_0(r) := r\log(r) + 1-r</code>.
</p>
<p>Mostly, pure <span class="rlang"><b>R</b></span> transcriptions of the C code utility functions for
<code><a href="stats.html#topic+dgamma">dgamma</a>()</code>, <code><a href="stats.html#topic+dbinom">dbinom</a>()</code>, <code><a href="stats.html#topic+dpois">dpois</a>()</code>, <code><a href="stats.html#topic+dt">dt</a>()</code>,
and similar &ldquo;base&rdquo; density functions by Catherine Loader. <br />
These have extra arguments with defaults that correspond
to <span class="rlang"><b>R</b></span>'s Mathlib C code hardwired cutoffs and tolerances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dpois_raw(x, lambda, log=FALSE,
          version, 
          small.x__lambda = .Machine$double.eps,
          ## the defaults for version will probably change in the future
          bd0.delta = 0.1,
          ## optional arguments of log1pmx() :
          tol_logcf = 1e-14, eps2 = 0.01, minL1 = -0.79149064, trace.lcf = verbose,
          logCF = if (is.numeric(x)) logcf else logcfR,
          verbose = FALSE)

dpois_simpl (x, lambda, log=FALSE)
dpois_simpl0(x, lambda, log=FALSE)

bd0(x, np,
    delta = 0.1, maxit = as.integer(-1100 / log2(delta)),
    s0 = .Machine$double.xmin,
    verbose = getOption("verbose"))
bd0C(x, np, delta = 0.1, maxit = 1000L, version = "R4.0", verbose = getOption("verbose"))
# "simple" log1pmx() based versions :
bd0_p1l1d1(x, M, tol_logcf = 1e-14, ...)
bd0_p1l1d (x, M, tol_logcf = 1e-14, ...)
bd0_l1pm  (x, M, tol_logcf = 1e-14, ...)

ebd0 (x, M, verbose = getOption("verbose"), ...) # experimental, may disappear !!
ebd0C(x, M, verbose = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dgamma-utils_+3A_x">x</code></td>
<td>
<p><code><a href="base.html#topic+numeric">numeric</a></code> (or number-alike such as &quot;mpfr&quot;).</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_lambda">lambda</code>, <code id="dgamma-utils_+3A_np">np</code>, <code id="dgamma-utils_+3A_m">M</code></td>
<td>
<p>each <code><a href="base.html#topic+numeric">numeric</a></code> (or number-alike ..); distribution parameters.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_log">log</code></td>
<td>
<p>logical indicating if the log-density should be returned,
otherwise the density at <code>x</code>.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if some information about the
computations are to be printed.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_small.x__lambda">small.x__lambda</code></td>
<td>
<p>positive number; for <code>dpois_raw(x, lambda)</code>,
when <code>x/lambda</code> is not larger than <code>small.x__lambda</code>, the
direct log poisson formula is used instead of <code>ebd0()</code>,
<code>bd0()</code> or <code><a href="#topic+stirlerr">stirlerr</a>()</code>.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_delta">delta</code>, <code id="dgamma-utils_+3A_bd0.delta">bd0.delta</code></td>
<td>
<p>a non-negative number <code class="reqn">&lt; 1</code> (practically required
to be <code class="reqn">\le .99</code>), a cutoff for <code>bd0()</code>
where a continued fraction series expansion is used when <code class="reqn">|x - M| &lt; delta*(x+M)</code>.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_tol_logcf">tol_logcf</code>, <code id="dgamma-utils_+3A_eps2">eps2</code>, <code id="dgamma-utils_+3A_minl1">minL1</code>, <code id="dgamma-utils_+3A_trace.lcf">trace.lcf</code>, <code id="dgamma-utils_+3A_logcf">logCF</code>, <code id="dgamma-utils_+3A_...">...</code></td>
<td>

<p>optional tuning arguments passed to <code><a href="#topic+log1pmx">log1pmx</a>()</code>, and to its
options passed to <code><a href="#topic+logcf">logcf</a>()</code>.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_maxit">maxit</code></td>
<td>
<p>the number of series expansion terms to be used in
<code>bd0()</code> when <code class="reqn">|x-M|</code> is small.  The default is <code class="reqn">k</code> such
that <code class="reqn">\delta^{2k} \le 2^{-1022-52}</code>, i.e., will underflow to zero.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_s0">s0</code></td>
<td>
<p>the very small <code class="reqn">s_0</code> determining that <code>bd0() = s</code>
already before the locf series expansion.</p>
</td></tr>
<tr><td><code id="dgamma-utils_+3A_version">version</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string specifying the version of
<code class="reqn">bd0()</code> to use.</p>
</td></tr>
</table>


<h3>Details</h3>



<dl>
<dt><code>bd0()</code>:</dt><dd><p>Loader's &ldquo;Binomial Deviance&rdquo; function; for
<code class="reqn">x, M &gt; 0</code> (where the limit <code class="reqn">x \to 0</code> is allowed).
In the case of <code><a href="stats.html#topic+dbinom">dbinom</a></code>, <code class="reqn">x</code> are integers (and
<code class="reqn">M = n p</code>), but in general <code>x</code> is real.
</p>
<p style="text-align: center;"><code class="reqn">bd_0(x,M) := M \cdot D_0\bigl(\frac{x}{M}\bigr),</code>
</p>
<p> where
<code class="reqn">D_0(u) := u \log(u) + 1-u = u(\log(u) - 1) + 1</code>.  Hence
</p>
<p style="text-align: center;"><code class="reqn">bd_0(x,M) = M \cdot \bigl(\frac{x}{M}(\log(\frac{x}{M}) -1) +1 \bigr) =
	x \log(\frac{x}{M}) - x + M.</code>
</p>

<p>A different way to rewrite this from Martyn Plummer, notably for important situation when
<code class="reqn">\left|x-M \right| \ll M</code>, is using <code class="reqn">t := (x-M)/M</code>
(and <code class="reqn">\left|t \right| \ll 1</code> for that situation),
equivalently, <code class="reqn">\frac{x}{M} = 1+t</code>.
Using <code class="reqn">t</code>,
</p>
<p style="text-align: center;"><code class="reqn">bd_0(x,M) = \log(1+t) - t \cdot M = M \cdot [(t+1)(\log(1+t) - 1) + 1]
                                              = M \cdot [(t+1) \log(1+t) - t]
                                              = M \cdot p_1l_1(t),</code>
</p>

<p>and </p>
<p style="text-align: center;"><code class="reqn">p_1l_1(t) := (t+1)\log(1+t) - t = \frac{t^2}{2} - \frac{t^3}{6} ...</code>
</p>
<p> where
the Taylor series expansion is useful for small <code class="reqn">|t|</code>.
</p>
<p>Note that <code>bd0(x, M)</code> now also works when <code>x</code> and/or
<code>M</code> are arbitrary-accurate mpfr-numbers (package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>).
</p>
<p><code>bd0C()</code> interfaces to C code which corresponds to <span class="rlang"><b>R</b></span>'s C Mathlib (Rmath) <code>bd0()</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>a numeric vector &ldquo;like&rdquo; <code>x</code>; in some cases may also be an
(high accuracy) &quot;mpfr&quot;-number vector, using CRAN package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>.
</p>
<p><code>ebd0()</code> (<span class="rlang"><b>R</b></span> code) and <code>ebd0C()</code> (interface to <code>C</code>
code) are <em>experimental</em>, meant to be precision-extended version of
<code>bd0()</code>, returning <code>(yh, yl)</code> (high- and low-part of <code>y</code>,
the numeric result).  In order to work for <em>long</em> vectors <code>x</code>,
<code>yh, yl</code> need to be <code><a href="base.html#topic+list">list</a></code> components; hence we return a
two-column <code><a href="base.html#topic+data.frame">data.frame</a></code> with column names <code>"yh"</code> and
<code>"yl"</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>C. Loader (2000), see <code><a href="stats.html#topic+dbinom">dbinom</a></code>'s documentation.

</p>
<p>Our package vignette <em>log1pmx, bd0, stirlerr - Probability Computations in R</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stirlerr">stirlerr</a></code> for Stirling's error function, 
complementing <code>bd0()</code> for computation of Gamma, Beta, Binomial and Poisson probabilities.
<code><a href="stats.html#topic+dgamma">dgamma</a></code>, 
<code><a href="stats.html#topic+dpois">dpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 800:1200
bd0x1k &lt;- bd0(x, np = 1000)
plot(x, bd0x1k, type="l", ylab = "bd0(x, np=1000)")
bd0x1kC &lt;- bd0C(x, np = 1000)
lines(x, bd0x1kC, col=2)
bd0.1d1 &lt;- bd0_p1l1d1(x, 1000)
bd0.1d  &lt;- bd0_p1l1d (x, 1000)
bd0.1pm &lt;- bd0_l1pm  (x, 1000)
stopifnot(exprs = {
    all.equal(bd0x1kC, bd0x1k,  tol=1e-14) # even tol=0 currently ..
    all.equal(bd0x1kC, bd0.1d1, tol=1e-14)
    all.equal(bd0x1kC, bd0.1d , tol=1e-14)
    all.equal(bd0x1kC, bd0.1pm, tol=1e-14)
})

str(log1pmx) ##--&gt; play with  { tol_logcf, eps2, minL1, trace.lcf, logCF }

ebd0x1k &lt;- ebd0 (x, 1000)
exC     &lt;- ebd0C(x, 1000)
stopifnot(all.equal(exC, ebd0x1k, tol=4e-16))
lines(x, rowSums(ebd0x1k), col=adjustcolor(4, 1/2), lwd=4)

x &lt;- 0:250
dp   &lt;- dpois    (x, 48, log=TRUE)# R's 'stats' pkg function
dp.r &lt;- dpois_raw(x, 48, log=TRUE)
all.equal(dp, dp.r, tol = 0) # on Linux 64b, see TRUE
stopifnot(all.equal(dp, dp.r, tol = 1e-14))
## dpois_raw()  versions:
(vers &lt;- eval(formals(dpois_raw)$version))
mv &lt;- sapply(vers, function(v) dpois_raw(x, 48, version=v))
matplot(x, mv, type="h", log="y", main="dpois_raw(x, 48, version=*)") # "fine"

if(all(mv[,"ebd0_C1"] == mv[,"ebd0_v1"])) {
    cat("versions 'ebd0_C1' and 'ebd0_v1' are identical for lambda=48\n")
    mv &lt;- mv[, vers != "ebd0_C1"]
}
## now look at *relative* errors -- need "Rmpfr" for "truth"
if(requireNamespace("Rmpfr")) {

    dM &lt;- Rmpfr::dpois(Rmpfr::mpfr(x, 256), 48)
    asN &lt;- Rmpfr::asNumeric
    relE &lt;- asN(mv / dM - 1)
    cols &lt;- adjustcolor(1:ncol(mv), 1/2)

    mtit &lt;- "relative Errors of dpois_raw(x, 48, version = * )"
    matplot(x, relE, type="l", col=cols, lwd=3, lty=1, main=mtit)
    legend("topleft", colnames(mv), col=cols, lwd=3, bty="n")

    matplot(x, abs(relE), ylim=pmax(1e-18, range(abs(relE))), type="l", log="y",
            main=mtit, col=cols, lwd=2, lty=1, yaxt="n")
    sfsmisc::eaxis(2)
    legend("bottomright", colnames(mv), col=cols, lwd=2, bty="n", ncol=3)
    ee &lt;- c(.5, 1, 2)* 2^-52; eC &lt;- quote(epsilon[C])
    abline(h=ee, lty=2, col="gray", lwd=c(1,2,1))
    axis(4, at=ee[2:3], expression(epsilon[C], 2 * epsilon[C]), col="gray", las=1)
    par(new=TRUE)
    plot(x, asN(dM), type="h", col=adjustcolor("darkgreen", 1/3), axes=FALSE, ann=FALSE)
    stopifnot(abs(relE) &lt; 8e-13) # seen 2.57e-13
}# Rmpfr
</code></pre>

<hr>
<h2 id='dgamma.R'>Gamma Density Function Alternatives</h2><span id='topic+dgamma.R'></span>

<h3>Description</h3>

<p><code>dgamma.R()</code> is aimed to be an R level &ldquo;clone&rdquo; of <span class="rlang"><b>R</b></span>'s C
level implementation <code><a href="stats.html#topic+dgamma">dgamma</a></code> (from package <span class="pkg">stats</span>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgamma.R(x, shape, scale = 1, log,
         dpois_r_args = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dgamma.R_+3A_x">x</code></td>
<td>
<p>non-negative numeric vector.</p>
</td></tr>
<tr><td><code id="dgamma.R_+3A_shape">shape</code></td>
<td>
<p>non-negative shape parameter of the Gamma distribution.</p>
</td></tr>
<tr><td><code id="dgamma.R_+3A_scale">scale</code></td>
<td>
<p>positive scale parameter; note we do not see the need to have
a <code>rate</code> parameter as the standard <span class="rlang"><b>R</b></span> function.</p>
</td></tr>
<tr><td><code id="dgamma.R_+3A_log">log</code></td>
<td>
<p>logical indicating if the result is desired on the log scale.</p>
</td></tr>
<tr><td><code id="dgamma.R_+3A_dpois_r_args">dpois_r_args</code></td>
<td>
<p>a <code><a href="base.html#topic+list">list</a></code> of optional arguments for
<code><a href="#topic+dpois_raw">dpois_raw</a>()</code>; not much checked, must be specified correctly.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of the same length as <code>x</code> (which may have to be
thought of recycled along <code>shape</code> and/or <code>scale</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p>(As <span class="rlang"><b>R</b></span>'s C code) this depends crucially on the &ldquo;workhorse&rdquo;
function <code><a href="#topic+dpois_raw">dpois_raw</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
xy  &lt;- curve(dgamma  (x, 12), 0,30) # R's dgamma()
xyR &lt;- curve(dgamma.R(x, 12, dpois_r_args = list(verbose=TRUE)), add=TRUE,
             col = adjustcolor(2, 1/3), lwd=3)
stopifnot(all.equal(xy, xyR, tolerance = 4e-15)) # seen 7.12e-16
## TODO: check *vectorization* in x --&gt; add tests/*.R				___ TODO ___


## From R's  &lt;R&gt;/tests/d-p-q-r-tst-2.R -- replacing dgamma() w/ dgamma.R()
## PR#17577 - dgamma(x, shape)  for shape &lt; 1 (=&gt; +Inf at x=0) and very small x
stopifnot(exprs = {
    all.equal(dgamma.R(2^-1027, shape = .99 , log=TRUE), 7.1127667376, tol=1e-10)
    all.equal(dgamma.R(2^-1031, shape = 1e-2, log=TRUE), 702.8889158,  tol=1e-10)
    all.equal(dgamma.R(2^-1048, shape = 1e-7, log=TRUE), 710.30007699, tol=1e-10)
    all.equal(dgamma.R(2^-1048, shape = 1e-7, scale = 1e-315, log=TRUE),
              709.96858768, tol=1e-10)
})
## R's dgamma() gave all Inf in R &lt;= 3.6.1 [and still there in 32-bit Windows !]
</code></pre>

<hr>
<h2 id='dhyperBinMolenaar'>HyperGeometric (Point) Probabilities via Molenaar's Binomial Approximation</h2><span id='topic+dhyperBinMolenaar'></span>

<h3>Description</h3>

<p>Compute hypergeometric (point) probabilities via Molenaar's binomial
approximation, <code><a href="#topic+hyper2binomP">hyper2binomP</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhyperBinMolenaar(x, m, n, k, log = FALSE)
</code></pre>


<h3>Arguments</h3>



<table role = "presentation">
<tr><td><code id="dhyperBinMolenaar_+3A_x">x</code></td>
<td>
<p>(vector of) the number of white balls drawn without replacement
from an urn which contains both black and white balls.</p>
</td></tr>
<tr><td><code id="dhyperBinMolenaar_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="dhyperBinMolenaar_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="dhyperBinMolenaar_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence in <code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="dhyperBinMolenaar_+3A_log">log</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indication if the logarithm
<code><a href="base.html#topic+log">log</a>(P)</code> should be returned (instead of <code class="reqn">P</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector, with the length the maximum of the
lengths of <code>x, m, n, k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>See those in <code><a href="#topic+phyperBinMolenaar">phyperBinMolenaar</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+hyper2binomP">hyper2binomP</a>()</code>;
<span class="rlang"><b>R</b></span>'s own <code><a href="stats.html#topic+dhyper">dhyper</a>()</code> which uses more sophisticated
computations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is simply defined as
function (x, m, n, k, log = FALSE)
  dbinom(x, size = k, prob = hyper2binomP(x, m, n, k), log = log)
</code></pre>

<hr>
<h2 id='dnbinomR'>Pure R Versions of R's C (Mathlib) dnbinom() Negative Binomial Probabilities</h2><span id='topic+dnbinomR'></span><span id='topic+dnbinom.mu'></span>

<h3>Description</h3>

<p>Compute pure <span class="rlang"><b>R</b></span> implementations of <span class="rlang"><b>R</b></span>'s C Mathlib (Rmath)
<code><a href="stats.html#topic+dnbinom">dnbinom</a>()</code> binomial probabilities, allowing to see the
effect of the cutoff <code>eps</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnbinomR  (x, size, prob, log = FALSE, eps = 1e-10)
dnbinom.mu(x, size, mu,   log = FALSE, eps = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dnbinomR_+3A_x">x</code>, <code id="dnbinomR_+3A_size">size</code>, <code id="dnbinomR_+3A_prob">prob</code>, <code id="dnbinomR_+3A_mu">mu</code>, <code id="dnbinomR_+3A_log">log</code></td>
<td>
<p>see <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dnbinom">dnbinom</a>()</code>.</p>
</td></tr>
<tr><td><code id="dnbinomR_+3A_eps">eps</code></td>
<td>
<p>non-negative number specifying the cutoff for &ldquo;small
<code>x/size</code>&rdquo;, in which case the 2-term approximation from
Abramowitz and Stegun, 6.1.47 (p.257) is preferable to the
<code><a href="stats.html#topic+dbinom">dbinom</a>()</code> based evaluation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of the same length as <code>x</code> which may have to be
thought of recycled along <code>size</code> and <code>prob</code> or <code>mu</code>.
</p>


<h3>Author(s)</h3>

<p>R Core and Martin Maechler</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbinom_raw">dbinom_raw</a></code>;
Note that our CRAN package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a> provides
<code><a href="Rmpfr.html#topic+dnbinom">dnbinom</a></code>,
<code><a href="Rmpfr.html#topic+dbinom">dbinom</a></code> and more, where mpfr-accurate functions are
used instead of <span class="rlang"><b>R</b></span>'s (and our pure <span class="rlang"><b>R</b></span> version of) <code><a href="#topic+bd0">bd0</a>()</code> and
<code><a href="#topic+stirlerr">stirlerr</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 stopifnot( dnbinomR(0, 1, 1) == 1 )
 size &lt;- 1000 ; x &lt;- 0:size
 dnb &lt;- dnbinomR(x, size, prob = 5/8, log = FALSE, eps = 1e-10)
 plot(x, dnb, type="b")
 all.equal(dnb, dnbinom(x, size, prob = 5/8)) ## mean rel. diff: 0.00017...

 dnbm &lt;- dnbinom.mu(x, size, mu = 123, eps = 1e-10)
 all.equal(dnbm, dnbinom(x, size, mu = 123)) #  Mean relative diff: 0.00069...
</code></pre>

<hr>
<h2 id='dnt'>Non-central t-Distribution Density - Algorithms and Approximations</h2><span id='topic+dntJKBf1'></span><span id='topic+dntJKBf'></span><span id='topic+.dntJKBch1'></span><span id='topic+.dntJKBch'></span>

<h3>Description</h3>

<p><code>dntJKBf1</code> implements the summation formulas
of Johnson, Kotz and Balakrishnan (1995),
(31.15) on page 516 and (31.15') on p.519, the latter being typo-corrected
for a missing  factor <code class="reqn">1 / j!</code>.
</p>
<p><code>dntJKBf()</code> is <code><a href="base.html#topic+Vectorize">Vectorize</a>(dntJKBf1,
    c("x","df","ncp"))</code>, i.e., works vectorized in all three main
arguments <code>x</code>, <code>df</code> and <code>ncp</code>.
</p>
<p>The functions <code>.dntJKBch1()</code> and  <code>.dntJKBch()</code> are only there
for didactical reasons allowing to check that indeed formula (31.15')
in the reference is missing a <code class="reqn">j!</code> factor in the denominator.
</p>
<p>The <code>dntJKBf*()</code> functions are written to also work with
arbitrary precise numbers of <code><a href="base.html#topic+class">class</a></code>
<code>"<a href="Rmpfr.html#topic+mpfr-class">mpfr</a>"</code> (from package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>)
as arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dntJKBf1(x, df, ncp, log = FALSE, M = 1000)
dntJKBf (x, df, ncp, log = FALSE, M = 1000)

## The "checking" versions, only for proving correctness of formula:
.dntJKBch1(x, df, ncp, log = FALSE, M = 1000, check=FALSE, tol.check = 1e-7)
.dntJKBch (x, df, ncp, log = FALSE, M = 1000, check=FALSE, tol.check = 1e-7)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dnt_+3A_x">x</code>, <code id="dnt_+3A_df">df</code>, <code id="dnt_+3A_ncp">ncp</code></td>
<td>
<p>see <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dt">dt</a>()</code>; note that each can be
of class <code>"<a href="Rmpfr.html#topic+mpfr-class">mpfr</a>"</code>.</p>
</td></tr>
<tr><td><code id="dnt_+3A_log">log</code></td>
<td>
<p>as in <code><a href="stats.html#topic+dt">dt</a>()</code>, a logical indicating if
<code class="reqn">\log(f(x,*))</code> should be returned instead of <code class="reqn">f(x,*)</code>.</p>
</td></tr>
<tr><td><code id="dnt_+3A_m">M</code></td>
<td>
<p>the number of terms to be used, a positive integer.</p>
</td></tr>
<tr><td><code id="dnt_+3A_check">check</code></td>
<td>
<p>logical indicating if checks of the formula equalities
should be done.</p>
</td></tr>
<tr><td><code id="dnt_+3A_tol.check">tol.check</code></td>
<td>
<p>tolerance to be used for <code><a href="base.html#topic+all.equal">all.equal</a>()</code>
when <code>check</code> is true.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>How to choose <code>M</code> optimally has not been investigated yet and
is probably also a function of the precision of the first three arguments (see

<code><a href="Rmpfr.html#topic+getPrec">getPrec</a></code> from <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>).
</p>
<p>Note that relatedly, 
<span class="rlang"><b>R</b></span>'s source code &lsquo;<span class="file">R/src/nmath/dnt.c</span>&rsquo; has claimed from 2003 till 2014
but <b>wrongly</b> that the noncentral t density <code class="reqn">f(x, *)</code> was </p>
<pre>
    f(x, df, ncp) =
 	df^(df/2) * exp(-.5*ncp^2) /
 	(sqrt(pi)*gamma(df/2)*(df+x^2)^((df+1)/2)) *
 	   sum_{k=0}^Inf  gamma((df + k + df)/2)*ncp^k / prod(1:k)*(2*x^2/(df+x^2))^(k/2) .</pre>
<p>These functions (and this help page) prove that it was wrong.
</p>


<h3>Value</h3>

<p>a number for <code>dntJKBf1()</code> and <code>.dntJKBch1()</code>.
</p>
<p>a numeric vector of the same length as the maximum of the lengths of
<code>x, df, ncp</code> for  <code>dntJKBf()</code> and <code>.dntJKBch()</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
Continuous Univariate Distributions Vol~2, 2nd ed.; Wiley;
chapter 31, Section <em>5  Distribution Function</em>, p.514 ff
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+dt">dt</a></code>;
(an improved version of) Viechtbauer's proposal: <code><a href="#topic+dtWV">dtWV</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt &lt;-  seq(0, 10, length.out = 21)
ncp &lt;- seq(0,  6, length.out = 31)
dt3R   &lt;- outer(tt, ncp, dt,     df = 3)
dt3JKB &lt;- outer(tt, ncp, dntJKBf, df = 3)
all.equal(dt3R, dt3JKB) # Lnx(64-b): 51 NA's in dt3R

x &lt;- seq(-1,12, by=1/16)
fx &lt;- dt(x, df=3, ncp=5)
re1 &lt;- 1 - .dntJKBch(x, df=3, ncp=5) / fx ; summary(warnings()) # slow, with warnings
op &lt;- options(warn = 2) # (=&gt; warning == error, for now)
re2 &lt;- 1 -  dntJKBf (x, df=3, ncp=5) / fx  # faster, no warnings
stopifnot(all.equal(re1[!is.na(re1)], re2[!is.na(re1)], tol=1e-6))
head( cbind(x, fx, re1, re2) , 20)
matplot(x, log10(abs(cbind(re1, re2))), type = "o", cex = 1/4)

## One of the numerical problems in "base R"'s non-central t-density:
options(warn = 0) # (factory def.)
x &lt;- 2^seq(-12, 32, by=1/8) ; df &lt;- 1/10
dtm &lt;- cbind(dt(x, df=df,           log=TRUE),
             dt(x, df=df, ncp=df/2, log=TRUE),
             dt(x, df=df, ncp=df,   log=TRUE),
             dt(x, df=df, ncp=df*2, log=TRUE)) #.. quite a few warnings:
summary(warnings())
matplot(x, dtm, type="l", log = "x", xaxt="n",
        main = "dt(x, df=1/10, log=TRUE) central and noncentral")
sfsmisc::eaxis(1)
legend("right", legend=c("", paste0("ncp = df",c("/2","","*2"))),
       lty=1:4, col=1:4, bty="n")

(doExtras &lt;- DPQ:::doExtras()) # TRUE e.g. if interactive()
(ncp &lt;- seq(0, 12, by = if(doExtras) 3/4 else 2))
names(ncp) &lt;- nnMs &lt;- paste0("ncp=", ncp)
tt  &lt;- seq(0, 5, by =  1)
dt3R &lt;- outer(tt, ncp, dt,   df = 3)
if(requireNamespace("Rmpfr")) withAutoprint({
   mt  &lt;- Rmpfr::mpfr(tt , 128)
   mcp &lt;- Rmpfr::mpfr(ncp, 128)
   system.time(
       dt3M &lt;- outer(mt, mcp, dntJKBf, df = 3,
                     M = if(doExtras) 1024 else 256)) # M=1024: 7 sec [10 sec on Winb]
   relE &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(dt3M, dt3R))
   relE[tt != 0, ncp != 0]
})

## all.equal(dt3R, dt3V, tol=0) # 1.2e-12

 # ---- using MPFR high accuracy arithmetic (too slow for routine testing) ---
## no such kink here:
x. &lt;- if(requireNamespace("Rmpfr")) Rmpfr::mpfr(x, 256) else x
system.time(dtJKB &lt;- dntJKBf(x., df=df, ncp=df, log=TRUE)) # 43s, was 21s and only 7s ???
lines(x, dtJKB, col=adjustcolor(3, 1/2), lwd=3)
options(op) # reset to prev.

## Relative Difference / Approximation errors :
plot(x, 1 - dtJKB / dtm[,3], type="l", log="x")
plot(x, 1 - dtJKB / dtm[,3], type="l", log="x", xaxt="n", ylim=c(-1,1)*1e-3); sfsmisc::eaxis(1)
plot(x, 1 - dtJKB / dtm[,3], type="l", log="x", xaxt="n", ylim=c(-1,1)*1e-7); sfsmisc::eaxis(1)
plot(x, abs(1 - dtJKB / dtm[,3]), type="l", log="xy", axes=FALSE, main =
     "dt(*, 1/10, 1/10, log=TRUE) relative approx. error",
     sub= paste("Copyright (C) 2019  Martin Maechler  --- ", R.version.string))
for(j in 1:2) sfsmisc::eaxis(j)

</code></pre>

<hr>
<h2 id='dot-D-utils'>Distribution Utilities &quot;dpq&quot;</h2><span id='topic+.D_0'></span><span id='topic+.D_1'></span><span id='topic+.D_Clog'></span><span id='topic+.D_Cval'></span><span id='topic+.D_exp'></span><span id='topic+.D_LExp'></span><span id='topic+.D_log'></span><span id='topic+.D_Lval'></span><span id='topic+.D_qIv'></span><span id='topic+.D_val'></span><span id='topic+.DT_0'></span><span id='topic+.DT_1'></span><span id='topic+.DT_Cexp'></span><span id='topic+.DT_CIv'></span><span id='topic+.DT_Clog'></span><span id='topic+.DT_Cval'></span><span id='topic+.DT_exp'></span><span id='topic+.DT_log'></span><span id='topic+.DT_Log'></span><span id='topic+.DT_qIv'></span><span id='topic+.DT_val'></span>

<h3>Description</h3>

<p>Utility functions for &quot;dpq&quot;-computations, parelling those in R's own
C source &lsquo;<span class="file">&lt;Rsource&gt;/src/nmath/dpq.h</span>&rsquo;,
(&ldquo;dpq&rdquo; := <b>d</b>ensity&ndash;<b>p</b>robability&ndash;<b>q</b>uantile).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.D_0(log.p) # prob/density == 0   (for log.p=FALSE)
.D_1(log.p) # prob         == 1     "       "

.DT_0(lower.tail, log.p) # == 0  when (lower.tail=TRUE, log.p=FALSE)
.DT_1(lower.tail, log.p) # == 1  when     "                "

.D_Lval(p, lower.tail) # p    {L}ower
.D_Cval(p, lower.tail) # 1-p  {C}omplementary

.D_val (x, log.p)  #     x  in pF(x,..)
.D_qIv (p, log.p)  #     p  in qF(p,..)
.D_exp (x, log.p)  # exp(x)        unless log.p where it's  x
.D_log (p, log.p)  #     p           "      "     "    "   log(p)
.D_Clog(p, log.p)  #   1-p           "      "     "    "   log(1-p) == log1p(-)

.D_LExp(x, log.p)  ## [log](1 - exp(-x))     == log1p(- .D_qIv(x))) even more stable

.DT_val (x, lower.tail, log.p) # := .D_val(.D_Lval(x, lower.tail), log.p) ==    x  in pF
.DT_Cval(x, lower.tail, log.p) # := .D_val(.D_Cval(x, lower.tail), log.p) ==  1-x  in pF

.DT_qIv (p, lower.tail, log.p) # := .D_Lval(.D_qIv(p))	==    p	 in qF
.DT_CIv (p, lower.tail, log.p) # := .D_Cval(.D_qIv(p))	==  1-p  in qF

.DT_exp (x, lower.tail, log.p) #  exp( x )
.DT_Cexp(x, lower.tail, log.p) #  exp(1-x)

.DT_log (p, lower.tail, log.p) # log ( p )  in qF
.DT_Clog(p, lower.tail, log.p) # log (1-p)  in qF
.DT_Log (p, lower.tail)        # log ( p )  in qF(p,..,log.p=TRUE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dot-D-utils_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="dot-D-utils_+3A_p">p</code></td>
<td>
<p>(log) probability&ndash;like numeric vector.</p>
</td></tr>
<tr><td><code id="dot-D-utils_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if true, probabilities are <code class="reqn">P[X \le x]</code>,
otherwise upper tail probabilities, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="dot-D-utils_+3A_log.p">log.p</code></td>
<td>
<p>logical; if true, probabilities <code class="reqn">p</code> are given as
<code class="reqn">\log(p)</code> in argument <code>p</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Typically a numeric vector &ldquo;as&rdquo; <code>x</code> or <code>p</code>, respectively.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+log1mexp">log1mexp</a>()</code> which is called from <code>.D_LExp()</code> and <code>.DT_Log()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>FT &lt;- c(FALSE, TRUE)
stopifnot(exprs = {
    .D_0(log.p = FALSE) ==    (0)
    .D_0(log.p = TRUE ) == log(0)
    identical(c(1,0), vapply(FT, .D_1, double(1)))
})

## all such functions in package DPQ:
eDPQ &lt;- as.environment("package:DPQ")
ls.str(envir=eDPQ, pattern = "^[.]D", all.names=TRUE)
(nD &lt;- local({ n &lt;- names(eDPQ); n[startsWith(n, ".D")] }))
trimW &lt;- function(ch) sub(" +$","", sub("^ +","", ch))
writeLines(vapply(sort(nD), function(nm) {
    B &lt;- deparse(eDPQ[[nm]])
    sprintf("%31s := %s", trimW(sub("function ", nm, B[[1]])),
            paste(trimW(B[-1]), collapse=" "))
                  }, ""))

do.lowlog &lt;- function(Fn, ...) {
    stopifnot(is.function(Fn),
              all(c("lower.tail", "log.p") %in% names(formals(Fn)))) 
    FT &lt;- c(FALSE, TRUE) ; cFT &lt;- c("F", "T")
    L &lt;- lapply(FT, function(lo) sapply(FT, function(lg) Fn(..., lower.tail=lo, log.p=lg)))
    r &lt;- simplify2array(L)
    `dimnames&lt;-`(r, c(rep(list(NULL), length(dim(r)) - 2L),
                      list(log.p = cFT, lower.tail = cFT)))
}
do.lowlog(.DT_0)
do.lowlog(.DT_1)
do.lowlog(.DT_exp, x = 1/4) ; do.lowlog(.DT_exp, x = 3/4)
do.lowlog(.DT_val, x = 1/4) ; do.lowlog(.DT_val, x = 3/4)
do.lowlog(.DT_Cexp, x = 1/4) ; do.lowlog(.DT_Cexp, x = 3/4)
do.lowlog(.DT_Cval, x = 1/4) ; do.lowlog(.DT_Cval, x = 3/4)
do.lowlog(.DT_Clog, p = (1:3)/4) # w/ warn
do.lowlog(.DT_log,  p = (1:3)/4) # w/ warn
do.lowlog(.DT_qIv,  p = (1:3)/4)

## unfinished: FIXME, the above is *not* really checking
stopifnot(exprs = {

})

</code></pre>

<hr>
<h2 id='dpsifn'>Psi Gamma Functions Workhorse from R's API</h2><span id='topic+dpsifn'></span>

<h3>Description</h3>

<p>Log Gamma derivatives, Psi Gamma functions.  <code>dpsifn()</code> is an <span class="rlang"><b>R</b></span>
interface to the <span class="rlang"><b>R</b></span> API function <code>R_dpsifn()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsifn(x, m, deriv1 = 0L, k2 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dpsifn_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="dpsifn_+3A_m">m</code></td>
<td>
<p>number of derivatives to return, an integer &gt;= 0.</p>
</td></tr>
<tr><td><code id="dpsifn_+3A_deriv1">deriv1</code></td>
<td>
<p>&ldquo;start&rdquo; derivative ....</p>
</td></tr>
<tr><td><code id="dpsifn_+3A_k2">k2</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> specifying if <code>kode = 2</code> should be
applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dpsifn()</code> is the underlying &ldquo;workhorse&rdquo; of <span class="rlang"><b>R</b></span>'s own
<code><a href="base.html#topic+digamma">digamma</a></code>, <code><a href="base.html#topic+trigamma">trigamma</a></code> and (generalized)
<code><a href="base.html#topic+psigamma">psigamma</a></code> functions.
</p>
<p>It is useful, e.g., when several derivatives of
<code class="reqn">\log\Gamma=</code><code><a href="base.html#topic+lgamma">lgamma</a></code> are desired.  It
computes and returns length-<var>m</var> sequence
<code class="reqn">(-1)^{k+1} / \Gamma(k+1) \cdot \psi^{(k)}(x)</code>
for
<code class="reqn">k = n, n+1,\ldots, n+m-1</code>, where
<code class="reqn">n=</code><code>deriv1</code>, and <code class="reqn">\psi^{(k)}(x)</code> is the k-th
derivative of <code class="reqn">\psi(x)</code>, i.e., <code>psigamma(x,k)</code>.  For
more details, see the comments in &lsquo;<span class="file">src/nmath/polygamma.c</span>&rsquo;.
</p>


<h3>Value</h3>

<p>A numeric <code class="reqn">l_x \times m</code> <code><a href="base.html#topic+matrix">matrix</a></code> (where
<code class="reqn">l_x=</code><code>length(x)</code>) of scaled <code class="reqn">\psi^{(k)}(x)</code>
values.  The matrix has <code><a href="base.html#topic+attributes">attributes</a></code>
</p>
<table role = "presentation">
<tr><td><code>underflow</code></td>
<td>
<p>of <code class="reqn">l_x</code> integer counts of the number of under- and
over-flows, in computing the corresponding i-th matrix column for <code>x[i]</code>.</p>
</td></tr>
<tr><td><code>ierr</code></td>
<td>
<p>length-<code class="reqn">l_x</code> integer vector of error codes, where
<code>0</code> is normal/successful.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler (R interface); R Core et al., see
<code><a href="base.html#topic+digamma">digamma</a></code>.
</p>


<h3>References</h3>

<p>See those in <code><a href="base.html#topic+psigamma">psigamma</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+digamma">digamma</a></code>, <code><a href="base.html#topic+trigamma">trigamma</a></code>, <code><a href="base.html#topic+psigamma">psigamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-3.5, 6, by=1/4)
dpx &lt;- dpsifn(x, m = if(getRversion() &gt;= "4.2") 7 else 5)
dpx # in R &lt;= 4.2.1, see that sometimes the 'nz' (under-over-flow count) was uninitialized !!
j &lt;- -1L+seq_len(nrow(dpx)); (fj &lt;- (-1)^(j+1)*gamma(j+1))
## mdpsi &lt;- cbind(di =   digamma(x),      -dpx[1,],
## 	       tri=  trigamma(x),       dpx[2,],
## 	       tetra=psigamma(x,2),  -2*dpx[3,],
## 	       penta=psigamma(x,3),   6*dpx[4,],
## 	       hexa =psigamma(x,4), -24*dpx[5,],
## 	       hepta=psigamma(x,5), 120*dpx[6,],
## 	       octa =psigamma(x,6),-720*dpx[7,])
## cbind(x, ie=attr(dpx,"errorCode"), round(mdpsi, 4))
str(psig &lt;- outer(x, j, psigamma))
dpsi &lt;- t(fj * (`attributes&lt;-`(dpx, list(dim=dim(dpx)))))
if(getRversion() &gt;= "4.2") {
      print( all.equal(psig, dpsi, tol=0) )# -&gt; see 1.185e-16
  stopifnot( all.equal(psig, dpsi, tol=1e-15) )
} else { # R &lt;= 4.1.x; dpsifn(x, ..) *not* ok for x &lt; 0
  i &lt;- x &gt;= 0
      print( all.equal(psig[i,], dpsi[i,], tol=0) )# -&gt; see 1.95e-16
  stopifnot( all.equal(psig[i,], dpsi[i,], tol=1e-15) )
}
</code></pre>

<hr>
<h2 id='dtWV'>Asymptotic Noncentral t Distribution Density by Viechtbauer</h2><span id='topic+dtWV'></span>

<h3>Description</h3>

<p>Compute the density function <code class="reqn">f(x)</code> of the t distribution with
<code>df</code> degrees of freedom and non-centrality parameter <code>ncp</code>,
according to Wolfgang Viechtbauer's proposal in 2002.
This is an asymptotic formula for &ldquo;large&rdquo; <code>df</code><code class="reqn"> = \nu</code>,
or mathematically <code class="reqn">\nu \to \infty</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dtWV(x, df, ncp = 0, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dtWV_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="dtWV_+3A_df">df</code></td>
<td>
<p>degrees of freedom (<code class="reqn">&gt; 0</code>, maybe non-integer).  <code>df
      = Inf</code> is allowed.</p>
</td></tr>
<tr><td><code id="dtWV_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>;
If omitted, use the central t distribution.</p>
</td></tr>
<tr><td><code id="dtWV_+3A_log">log</code></td>
<td>
<p>logical; if TRUE, <code class="reqn">log(f(x))</code> is returned instead of <code class="reqn">f(x)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula used is &ldquo;asymptotic&rdquo;: Resnikoff and Lieberman (1957),
p.1 and p.25ff, proposed to use recursive polynomials for (<em>integer !</em>)
degrees of freedom <code class="reqn">f = 1,2,\dots, 20</code>, and then, for
<code>df</code><code class="reqn"> = f &gt; 20</code>, use the asymptotic approximation which
Wolfgang Viechtbauer proposed as a first version of a non-central t
density for <span class="rlang"><b>R</b></span> (when <code><a href="stats.html#topic+dt">dt</a>()</code> did not yet have an <code>ncp</code>
argument).
</p>


<h3>Value</h3>

<p>numeric vector of density values, properly recycled in <code>(x, df, ncp)</code>.
</p>


<h3>Author(s)</h3>

<p>Wolfgang Viechtbauer (2002) post to R-help
(<a href="https://stat.ethz.ch/pipermail/r-help/2002-October/026044.html">https://stat.ethz.ch/pipermail/r-help/2002-October/026044.html</a>),
and Martin Maechler (<code>log</code> argument; tweaks, notably recycling).
</p>


<h3>References</h3>

<p>Resnikoff, George J. and Lieberman, Gerald J. (1957)
<em>Tables of the non-central t-distribution</em>;
Technical report no. 32 (<code>LIE ONR 32</code>), April 1, 1957;
Applied Math. and Stat. Lab., Stanford University.
<a href="https://statistics.stanford.edu/technical-reports/tables-non-central-t-distribution-density-function-cumulative-distribution">https://statistics.stanford.edu/technical-reports/tables-non-central-t-distribution-density-function-cumulative-distribution</a>

</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dt">dt</a></code>, <span class="rlang"><b>R</b></span>'s (C level) implementation of the (non-central) t density;
<code><a href="#topic+dntJKBf">dntJKBf</a></code>, for Johnson et al.'s summation formula approximation.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt &lt;- seq(0, 10, len = 21)
ncp &lt;- seq(0, 6, len = 31)
dt3R  &lt;- outer(tt, ncp, dt  , df = 3)
dt3WV &lt;- outer(tt, ncp, dtWV, df = 3)
all.equal(dt3R, dt3WV) # rel.err 0.00063
dt25R  &lt;- outer(tt, ncp, dt  , df = 25)
dt25WV &lt;- outer(tt, ncp, dtWV, df = 25)
all.equal(dt25R, dt25WV) # rel.err 1.1e-5

x &lt;- -10:700
fx  &lt;- dt  (x, df = 22, ncp =100)
lfx &lt;- dt  (x, df = 22, ncp =100, log=TRUE)
lfV &lt;- dtWV(x, df = 22, ncp =100, log=TRUE)

head(lfx, 20) # shows that R's dt(*, log=TRUE) implementation is "quite suboptimal"

## graphics
opa &lt;- par(no.readonly=TRUE)
par(mar=.1+c(5,4,4,3), mgp = c(2, .8,0))
plot(fx ~ x, type="l")
par(new=TRUE) ; cc &lt;- c("red", adjustcolor("orange", 0.4))
plot(lfx ~ x, type = "o", pch=".", col=cc[1], cex=2, ann=FALSE, yaxt="n")
sfsmisc::eaxis(4, col=cc[1], col.axis=cc[1], small.args = list(col=cc[1]))
lines(x, lfV, col=cc[2], lwd=3)
dtt1 &lt;- "      dt"; dtt2 &lt;- "(x, df=22, ncp=100"; dttL &lt;- paste0(dtt2,", log=TRUE)")
legend("right", c(paste0(dtt1,dtt2,")"), paste0(c(dtt1,"dtWV"), dttL)),
       lty=1, lwd=c(1,1,3), col=c("black", cc), bty = "n")
par(opa) # reset
</code></pre>

<hr>
<h2 id='expm1x'>Accurate exp(x) - 1 - x   (for smallish |x|)</h2><span id='topic+expm1x'></span><span id='topic+expm1xTser'></span>

<h3>Description</h3>

<p>Compute <code class="reqn">e^x - 1 - x =</code> <code>exp(x) - 1 - x</code> accurately, notably for small <code class="reqn">|x|</code>.
</p>
<p>The last two entries in <code>cutx[]</code> denote boundaries where
<code>expm1x(x)</code> uses direct formulas.  For <code>nC &lt;- length(cutx)</code>,
<code>exp(x) - 1 - x</code> is used for <code>abs(x) &gt;= cutx[nC]</code>,  and when <code>abs(x) &lt; cutx[nC]</code>
<code>expm1(x) - x</code>   is used for <code>abs(x) &gt;= cutx[nC-1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expm1x(x, cutx = c( 4.4e-8, 0.1, 0.385, 1.1, 2),
             k = c(2,      9,  12,    17))

expm1xTser(x, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expm1x_+3A_x">x</code></td>
<td>
<p>numeric-alike vector; goal is to work for
<code><a href="Rmpfr.html#topic+mpfr">mpfr</a></code>-numbers too.</p>
</td></tr>
<tr><td><code id="expm1x_+3A_cutx">cutx</code></td>
<td>
<p>increasing positive numeric vector of cut points defining
intervals in which the computations will differ.</p>
</td></tr>
<tr><td><code id="expm1x_+3A_k">k</code></td>
<td>
<p>for </p>

<dl>
<dt><code>exp1mx()</code>:</dt><dd><p>increasing vector of integers with
<code><a href="base.html#topic+length">length</a>(k) == length(cutx) + 2</code>, denoting the order of
Taylor polynomial approximation by <code>expm1xTser(.,k)</code> to <code>expm1x(.)</code>.</p>
</dd>
<dt><code>exp1mxTser()</code>:</dt><dd><p>an integer <code class="reqn">\ge 1</code>, where the
Taylor polynomial approximation has degree <code class="reqn">k + 1</code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector like <code>x</code> containing (approximations to) <code class="reqn">e^x - x - 1</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+expm1">expm1</a>(x)</code> for computing <code class="reqn">e^x - 1</code> is much more widely
known, and part of the ISO C standards now.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## a symmetric set of negative and positive
x &lt;- unique(c(2^-seq(-3/8, 54, by = 1/8), seq(7/8, 3, by = 1/128)))
x &lt;- x0 &lt;- sort(c(-x, 0, x)) # negative *and* positive

## Mathematically,  expm1x() = exp(x) - 1 - x  &gt;= 0  (and == 0 only at x=0):
em1x &lt;- expm1x(x)
stopifnot(em1x &gt;= 0, identical(x == 0, em1x == 0))

plot (x, em1x, type='b', log="y")
lines(x, expm1(x)-x, col = adjustcolor(2, 1/2), lwd = 3) ## should nicely cover ..
lines(x, exp(x)-1-x, col = adjustcolor(4, 1/4), lwd = 5) ## should nicely cover ..
cuts &lt;- c(4.4e-8, 0.10, 0.385, 1.1, 2)[-1] # *not* drawing 4.4e-8
v &lt;- c(-rev(cuts), 0, cuts); stopifnot(!is.unsorted(v))
abline(v = v, lty = 3, col=adjustcolor("gray20", 1/2))

stopifnot(diff(em1x[x &lt;= 0]) &lt;= 0)
stopifnot(diff(em1x[x &gt;= 0]) &gt;= 0)

## direct formula - may be really "bad" :
expm1x.0 &lt;- function(x) exp(x) -1 - x
## less direct formula - improved (but still not universally ok):
expm1x.1 &lt;- function(x) expm1(x)  - x

ax &lt;- abs(x) # ==&gt; show negative and positive x on top of each other
plot (ax, em1x, type='l', log="xy", xlab = "|x|  (for negative and positive x)")
lines(ax, expm1(x)-x, col = adjustcolor(2, 1/2), lwd = 3) ## see problem at very left
lines(ax, exp(x)-1-x, col = adjustcolor(4, 1/4), lwd = 5) ## see huge problems for |x| &lt; ~10^{-7}
legend("topleft", c("expm1x(x)", "expm1(x) - x", "exp(x) - 1 - x"), bty="n",
       col = c(1,2,4), lwd = c(1,3,5))

## -------------------- Relative error of Taylor series approximations :
twoP &lt;- seq(-0.75, 54, by = 1/8)
x &lt;- 2^-twoP
x &lt;- sort(c(-x,x)) # negative *and* positive
e1xAll &lt;- cbind(expm1x.0 = expm1x.0(x),
                expm1x.1 = expm1x.1(x),
                vapply(1:15, \(k) expm1xTser(x, k=k), x))
colnames(e1xAll)[-(1:2)] &lt;- paste0("k=",1:15)
head(e1xAll)
## TODO  plot !!
</code></pre>

<hr>
<h2 id='format01prec'>Format Numbers in [0,1] with &quot;Precise&quot; Result</h2><span id='topic+format01prec'></span>

<h3>Description</h3>

<p>Format numbers in [0,1] with &ldquo;precise&rdquo; result,
notably using <code>"1-.."</code> if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format01prec(x, digits = getOption("digits"), width = digits + 2,
             eps = 1e-06, ...,
             FUN = function(x, ...) formatC(x, flag = "-", ...))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="format01prec_+3A_x">x</code></td>
<td>
<p>numbers in [0,1]; (still works if not)</p>
</td></tr>
<tr><td><code id="format01prec_+3A_digits">digits</code></td>
<td>
<p>number of digits to use; is used as
<code>FUN(*, digits = digits)</code> or
<code>FUN(*, digits = digits - 5)</code> depending on <code>x</code> or <code>eps</code>.</p>
</td></tr>
<tr><td><code id="format01prec_+3A_width">width</code></td>
<td>
<p>desired width (of strings in characters), is used as
<code>FUN(*, width = width)</code> or
<code>FUN(*, width = width - 2)</code> depending on <code>x</code> or <code>eps</code>.</p>
</td></tr>
<tr><td><code id="format01prec_+3A_eps">eps</code></td>
<td>
<p>small positive number: Use <code>'1-'</code> for those <code>x</code>
which are in <code class="reqn">(1-eps, 1]</code>.  The author has claimed in the last
millennium that (the default) 1e-6 is <em>optimal</em>.</p>
</td></tr>
<tr><td><code id="format01prec_+3A_...">...</code></td>
<td>
<p>optional further arguments passed to <code>FUN(x, digits,
      width, ...)</code>.</p>
</td></tr>
<tr><td><code id="format01prec_+3A_fun">FUN</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a></code> used for <code><a href="base.html#topic+format">format</a>()</code>ing;
must accept both a <code>digits</code> and <code>width</code> argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+character">character</a></code> vector of the same length as <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, 14 May 1997</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+formatC">formatC</a></code>, <code><a href="base.html#topic+format.pval">format.pval</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Show that format01prec()  does reveal more precision :
cbind(format      (1 - 2^-(16:24)),
      format01prec(1 - 2^-(16:24)))

## a bit more variety
e &lt;- c(2^seq(-24,0, by=2), 10^-(7:1))
ee &lt;- sort(unique(c(e, 1-e)))
noquote(ff &lt;- format01prec(ee))
data.frame(ee, format01prec = ff)
</code></pre>

<hr>
<h2 id='fr_ld_exp'>Base-2 Representation and Multiplication of Numbers</h2><span id='topic+frexp'></span><span id='topic+ldexp'></span>

<h3>Description</h3>

<p>Both are <span class="rlang"><b>R</b></span> versions of C99 (and POSIX) standard C (and C++) mathlib
functions of the same name.
</p>
<p><code>frexp(x)</code> computes base-2 exponent <code>e</code> and &ldquo;mantissa&rdquo;,
or <em>fraction</em> <code>r</code>, such that <code class="reqn">x = r * 2^e</code>, where <code class="reqn">r \in
    [0.5, 1)</code> (unless when <code>x</code> is in <code>c(0, -Inf, Inf, NaN)</code>
where <code>r == x</code> and <code>e</code> is 0),
and <code class="reqn">e</code> is integer valued.
</p>
<p><code>ldexp(f, E)</code> is the <em>inverse</em> of <code>frexp()</code>: Given
fraction or mantissa <code>f</code> and integer exponent <code>E</code>, it returns
<code class="reqn">x = f * 2^E</code>.
Viewed differently, it's the fastest way to multiply or divide (double
precision) numbers with <code class="reqn">2^E</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frexp(x)
ldexp(f, E)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fr_ld_exp_+3A_x">x</code></td>
<td>
<p>numeric (coerced to <code>double</code>) vector.</p>
</td></tr>
<tr><td><code id="fr_ld_exp_+3A_f">f</code></td>
<td>
<p>numeric fraction (vector), in <code class="reqn">[0.5, 1)</code>.</p>
</td></tr>
<tr><td><code id="fr_ld_exp_+3A_e">E</code></td>
<td>
<p>integer valued, exponent of <code>2</code>, i.e., typically in
<code>(-1024-50):1024</code>, otherwise the result will underflow to 0 or
overflow to <code>+/- Inf</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>frexp</code> returns a <code><a href="base.html#topic+list">list</a></code> with named components <code>r</code>
(of type <code>double</code>) and <code>e</code> (of type <code>integer</code>).
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>On unix-alikes, typically <code>man frexp</code> and <code>man ldexp</code>
</p>


<h3>See Also</h3>

<p>Vaguely relatedly, <code><a href="#topic+log1mexp">log1mexp</a>()</code>, <code><a href="#topic+lsum">lsum</a></code>, <code><a href="#topic+logspace.add">logspace.add</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(47)
x &lt;- c(0, 2^(-3:3), (-1:1)/0,
       rlnorm(2^12, 10, 20) * sample(c(-1,1), 512, replace=TRUE))
head(x, 12)
which(!(iF &lt;- is.finite(x))) # 9 10 11
rF &lt;- frexp(x)
sapply(rF, summary) # (nice only when x had no NA's ..)
data.frame(x=x[!iF], lapply(rF, `[`, !iF))
##  by C.99/POSIX  'r' should be the same as 'x'  for these,
##      x    r e
## 1 -Inf -Inf 0
## 2  NaN  NaN 0
## 3  Inf  Inf 0
## but on Windows, we've seen  3 NA's :
ar &lt;- abs(rF$r)
ldx &lt;- with(rF, ldexp(r, e))
stopifnot(exprs = {
  0.5 &lt;= ar[iF &amp; x != 0]
  ar[iF] &lt; 1
  is.integer(rF$e)
  all.equal(x[iF], ldx[iF], tol= 4*.Machine$double.eps)
  ## but actually, they should even be identical, well at least when finite
  identical(x[iF], ldx[iF])
})
</code></pre>

<hr>
<h2 id='gam1d'>Compute  1/Gamma(x+1) - 1  Accurately</h2><span id='topic+gam1d'></span>

<h3>Description</h3>

<p>Computes <code class="reqn">1/\Gamma(a+1) - 1</code> accurately in <code class="reqn">[-0.5, 1.5]</code> for numeric argument <code>a</code>;
For <code>"mpfr"</code> numbers, the precision is increased intermediately such
that <code class="reqn">a+1</code> should not lose precision.
</p>
<p>FIXME: &quot;Pure-R&quot; implementation is in &lsquo;<span class="file"> ~/R/Pkgs/DPQ/TODO_R_versions_gam1_etc.R </span>&rsquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
gam1d(a, warnIf = TRUE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gam1d_+3A_a">a</code></td>
<td>
<p>a numeric or numeric-alike, typically inheriting from <code>class</code> <code>"mpfr"</code>.</p>
</td></tr>
<tr><td><code id="gam1d_+3A_warnif">warnIf</code></td>
<td>
<p>logical if a <code><a href="base.html#topic+warning">warning</a></code> should be signalled when
<code>a</code> is not in the &ldquo;proper&rdquo; range <code class="reqn">[-0.5, 1.5]</code>.</p>
</td></tr>


<tr><td><code id="gam1d_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if some output from C code execution
should be printed to the console.</p>
</td></tr>
</table>


<h3>Details</h3>

 

<p><a href="https://dlmf.nist.gov/">https://dlmf.nist.gov/</a> states the well-know Taylor series for
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{\Gamma(z)} = \sum_{k=1}^\infty c_k z^k</code>
</p>

<p>with <code class="reqn">c_1 = 1</code>,  <code class="reqn">c_2 = \gamma</code>, (Euler's gamma, <code class="reqn">\gamma = 0.5772...</code>, with
recursion <code class="reqn">c_k = (\gamma c_{k-1} - \zeta(2) c_{k-2} ... +(-1)^k \zeta(k-1) c_1) /(k-1)</code>.
</p>
<p>Hence,  </p>
<p style="text-align: center;"><code class="reqn">\frac{1}{\Gamma(z+1)}    = z+1 + \sum_{k=2}^\infty c_k (z+1)^k</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{1}{\Gamma(z+1)} -1 = z + \gamma*(z+1)^2 + \sum_{k=3}^\infty c_k (z+1)^k</code>
</p>

<p>Consequently, for <code class="reqn">\zeta_k := \zeta(k)</code>,
<code class="reqn">c_3 = (\gamma^2 - \zeta_2)/2</code>,
<code class="reqn">c_4 = \gamma^3/6 - \gamma \zeta_2/2 + \zeta_3/3</code>.
</p>
<pre>
  gam &lt;- Const("gamma", 128)
  z &lt;- Rmpfr::zeta(mpfr(1:7, 128))
  (c3 &lt;- (gam^2 -z[2])/2)                       # -0.655878071520253881077019515145
  (c4 &lt;- (gam*c3 - z[2]*c2 + z[3])/3)           # -0.04200263503409523552900393488
  (c4 &lt;- gam*(gam^2/6 - z[2]/2) + z[3]/3)
  (c5 &lt;- (gam*c4 - z[2]*c3 + z[3]*c2 - z[4])/4) # 0.1665386113822914895017007951
  (c5 &lt;- (gam^4/6 - gam^2*z[2] + z[2]^2/2 + gam*z[3]*4/3 - z[4])/4)
</pre>


<h3>Value</h3>

<p>a numeric-alike vector like <code>a</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler building on C code of TOMS 708</p>


<h3>References</h3>

<p>TOMS 708, see <code><a href="stats.html#topic+pbeta">pbeta</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gamma">gamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>g1 &lt;- function(u) 1/gamma(u+1) - 1
u &lt;- seq(-.5, 1.5, by=1/16); set.seed(1); u &lt;- sample(u) # permuted (to check logic)

g11   &lt;- vapply(u, gam1d, 1)
gam1d. &lt;- gam1d(u)
stopifnot( all.equal(g1(u), g11) )
stopifnot( identical(g11, gam1d.) )

## Comparison of g1() and gam1d(), slightly extending the [-.5, 1.5] interval:
u &lt;- seq(-0.525, 1.525, length.out = 2001)
mg1 &lt;- cbind(g1 = g1(u), gam1d = gam1d(u))
clr &lt;- adjustcolor(1:2, 1/2)
matplot(u, mg1, type = "l", lty = 1, lwd=1:2, col=clr) # *no* visual difference
## now look at *relative* errors
relErrV &lt;- sfsmisc::relErrV
relE &lt;- relErrV(mg1[,"gam1d"], mg1[,"g1"])
plot(u, relE, type = "l")
plot(u, abs(relE), type = "l", log = "y",
     main = "|rel.diff|  gam1d() vs 'direct' 1/gamma(u+1) - 1")

## now {Rmpfr} for "truth" :
if(requireNamespace("Rmpfr")) withAutoprint({
    asN  &lt;- Rmpfr::asNumeric; mpfr &lt;- Rmpfr::mpfr
    gam1M &lt;- g1(mpfr(u, 512)) # "cheap": high precision avoiding "all" cancellation
    relE &lt;- asN(relErrV(gam1M, gam1d(u)))
    plot(relE ~ u, type="l", ylim = c(-1,1) * 2.5e-15,
         main = expression("Relative Error of " ~~ gam1d(u) %~~% frac(1, Gamma(u+1)) - 1))
    grid(lty = 3); abline(v = c(-.5, 1.5), col = adjustcolor(4, 1/2), lty=2, lwd=2)
})


if(requireNamespace("Rmpfr") &amp;&amp; FALSE) { 
  
## Comparison using Rmpfr; slightly extending the [-.5, 1.5] interval:
##	{relErrV(), mpfr(), asN() defined above}

u &lt;- seq(-0.525, 1.525, length.out = 2001)
gam1M &lt;- gam1(mpfr(u, 128))
relE &lt;- asN(relErrV(gam1M, gam1d(u)))

plot(relE ~ u, type="l", ylim = c(-1,1) * 2.5e-15,
     main = expression("Relative Error of " ~~ gam1d(u) == frac(1, Gamma(u+1)) - 1))
grid(lty = 3); abline(v = c(-.5, 1.5), col = adjustcolor(4, 1/2), lty=2, lwd=2)

## what about the direct formula -- how bad is it really ?
relED &lt;- asN(relErrV(gam1M, g1(u)))

plot(relE ~ u, type="l", ylim = c(-1,1) * 1e-14,
     main = expression("Relative Error of " ~~ gam1d(u) == frac(1, Gamma(u+1)) - 1))
lines(relED ~ u, col = adjustcolor(2, 1/2), lwd = 2)
# mtext("comparing with direct formula   1/gamma(u+1) - 1")
legend("top", c("gam1d(u)", "1/gamma(u+1) - 1"), col = 1:2, lwd=1:2, bty="n")
## direct is clearly *worse* , but not catastrophical
}

</code></pre>

<hr>
<h2 id='gamln1'>Compute  log( Gamma(x+1) ) Accurately in [-0.2, 1.25]</h2><span id='topic+gamln1'></span>

<h3>Description</h3>

<p>Computes <code class="reqn">\log \Gamma(a+1)</code> accurately notably when
<code class="reqn">|a| \ll 1</code>.
Specifically, it uses high (double precision) accuracy rational
approximations for  <code class="reqn">-0.2 \le a \le 1.25</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamln1(a, warnIf = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamln1_+3A_a">a</code></td>
<td>
<p>a numeric or numeric-alike, typically inheriting from <code>class</code> <code>"mpfr"</code>.</p>
</td></tr>
<tr><td><code id="gamln1_+3A_warnif">warnIf</code></td>
<td>
<p>logical if a <code><a href="base.html#topic+warning">warning</a></code> should be signalled when
<code>a</code> is not in the &ldquo;proper&rdquo; range <code class="reqn">[-0.2, 1.25]</code>.</p>
</td></tr>


</table>


<h3>Details</h3>

<p>It uses <code class="reqn">-a * p(a)/q(a)</code> for <code class="reqn">a &lt; 0.6</code>, where <code class="reqn">p</code> and <code class="reqn">q</code> are
polynomials of degree 6 with coefficient vectors <code class="reqn">p = [p_0 p_1 \dots p_6]</code>
and <code class="reqn">q</code>, </p>
<pre>
    p &lt;- c( .577215664901533, .844203922187225, -.168860593646662,
	    -.780427615533591, -.402055799310489, -.0673562214325671,
	    -.00271935708322958)
    q &lt;- c( 1, 2.88743195473681, 3.12755088914843, 1.56875193295039,
	      .361951990101499, .0325038868253937, 6.67465618796164e-4)
  </pre>
<p>Similarly, for <code class="reqn">a \ge 0.6</code>, <code class="reqn">x := a - 1</code>, the result is
<code class="reqn">x * r(x)/s(x)</code>, with 5th degree polynomials <code class="reqn">r()</code> and <code class="reqn">s()</code>
and coefficient vectors </p>
<pre>
    r &lt;- c(.422784335098467, .848044614534529, .565221050691933,
           .156513060486551, .017050248402265, 4.97958207639485e-4)
    s &lt;- c( 1 , 1.24313399877507, .548042109832463,
           .10155218743983, .00713309612391, 1.16165475989616e-4)
  </pre>


<h3>Value</h3>

<p>a numeric-alike vector like <code>a</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler building on C code of TOMS 708</p>


<h3>References</h3>

<p>TOMS 708, see <code><a href="stats.html#topic+pbeta">pbeta</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lgamma1p">lgamma1p</a>()</code> for different algorithms to compute <code class="reqn">\log \Gamma(a+1)</code>,
notably when outside the interval <code class="reqn">[-0.2, 1.35]</code>.
Package <a href="https://CRAN.R-project.org/package=DPQmpfr"><span class="pkg">DPQmpfr</span></a>'s <code><a href="DPQmpfr.html#topic+lgamma1pM">lgamma1pM</a>()</code> provides
very precise such computations.
<code><a href="base.html#topic+lgamma">lgamma</a>()</code> (and <code>gamma()</code> (same page)).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lg1 &lt;- function(u) lgamma(u+1) # the simple direct form
## The curve, zeros at  u=0 &amp; u=1:
curve(lg1, -.2, 1.25, col=2, lwd=2, n=999)
title("lgamma(x + 1)"); abline(h=0, v=0:1, lty=3)

u &lt;- (-16:100)/80 ; set.seed(1); u &lt;- sample(u) # permuted (to check logic)
g11   &lt;- vapply(u, gamln1, numeric(1))
gamln1. &lt;- gamln1(u)
stopifnot( identical(g11, gamln1.) )
stopifnot( all.equal(lg1(u), g11) )

u &lt;- (-160:1000)/800
relE &lt;- sfsmisc::relErrV(gamln1(u), lg1(u))
plot(u, relE, type="l", main = expression("rel.diff." ~~ gamln1(u) %~~% lgamma(u+1)))
plot(u, abs(relE), type="l", log="y", yaxt="n",
     main = expression("|rel.diff.|" ~~ gamln1(u) %~~% lgamma(u+1)))
sfsmisc::eaxis(2)


if(requireNamespace("DPQmpfr")) withAutoprint({
  ## Comparison using Rmpfr; extending the [-.2, 1.25] interval a bit
  u &lt;- seq(-0.225, 1.31, length.out = 2000)
  lg1pM &lt;- DPQmpfr::lgamma1pM(Rmpfr::mpfr(u, 128))
  relE &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(lg1pM, gamln1(u, warnIf=FALSE)))

  plot(relE ~ u, type="l", ylim = c(-1,1) * 2.3e-15,
       main = expression("relative error of " ~~ gamln1(u) == log( Gamma(u+1) )))
  grid(lty = 3); abline(v = c(-.2, 1.25), col = adjustcolor(4, 1/2), lty=2, lwd=2)
  ## well... TOMS 708 gamln1() is good (if "only" 14 digits required

  ## what about the direct formula -- how bad is it really ?
  relED &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(lg1pM, lg1(u)))
  lines(relED ~ u, col = adjustcolor(2, 1/2))
  ## amazingly, the direct formula is partly (around -0.2 and +0.4) even better than gamln1() !

  plot(abs(relE) ~ u, type="l", log = "y", ylim = c(7e-17, 1e-14),
       main = expression("|relative error| of " ~~ gamln1(u) == log( Gamma(u+1) )))
  grid(lty = 3); abline(v = c(-.2, 1.25), col = adjustcolor(4, 1/2), lty=2, lwd=2)
  relED &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(lg1pM, lg1(u)))
  lines(abs(relED) ~ u, col = adjustcolor(2, 1/2))
})
</code></pre>

<hr>
<h2 id='gammaVer'>Gamma Function Versions</h2><span id='topic+gammaVer'></span>

<h3>Description</h3>

<p>Provide different variants or versions of computing the Gamma
(<code class="reqn">\Gamma</code>) function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
gammaVer(x, version, stirlerrV = c("R3", "R4..1", "R4.4_0"), traceLev = 0L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gammaVer_+3A_x">x</code></td>
<td>
<p>numeric vector of absissa value for the Gamma function.</p>
</td></tr>

<tr><td><code id="gammaVer_+3A_version">version</code></td>
<td>
<p>integer in {1,2,..,5} specifying which variant is desired.</p>
</td></tr>
<tr><td><code id="gammaVer_+3A_stirlerrv">stirlerrV</code></td>
<td>
<p>a string, specifying the <code>stirlerr()</code>
version/variant to use.</p>
</td></tr>
<tr><td><code id="gammaVer_+3A_tracelev">traceLev</code></td>
<td>
<p>non-negative integer indicating the amount of diagnostic
&ldquo;tracing&rdquo; output to the console during computation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of these are good algorithms to compute <code class="reqn">\Gamma(x)</code> (for real
<code class="reqn">x</code>), and indeed correspond to the versions <span class="rlang"><b>R</b></span>'s implementation of
<code><a href="base.html#topic+gamma">gamma</a>(x)</code> over time.  More specifically, the current version
numbers correspond to
</p>

<ol>
<li><p> . TODO 

</p>
</li>
<li><p> .
</p>
</li>
<li><p> .
</p>
</li>
<li><p> Used in <span class="rlang"><b>R</b></span> from ... up to versions 4.3.z
</p>
</li>
<li><p> Possibly to be used in <span class="rlang"><b>R</b></span> 4.4.z and newer.
</p>
</li></ol>

<p>The <code>stirlerrV</code> must be a string specifying the version of
<code><a href="#topic+stirlerr">stirlerr</a>()</code> to be used:
</p>

<dl>
<dt><code>"R3"</code>:</dt><dd><p>the historical version, used in all <span class="rlang"><b>R</b></span> version up to <span class="rlang"><b>R</b></span> 4.3.z.</p>
</dd>
<dt><code>"R4..1"</code>:</dt><dd><p>only started using <code>lgamma1p(n)</code> instead of
<code>lgamma(n + 1.)</code> in <code><a href="#topic+stirlerr">stirlerr</a>(n)</code> for <code class="reqn">n \le
	15</code>, in the direct formula.</p>
</dd>
<dt><code>"R4.4_0"</code>:</dt><dd><p>uses 10 cutoffs instead 4, and these are larger to gain
accuracy.</p>
</dd>

</dl>



<h3>Value</h3>

<p>numeric vector as <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>.... TODO ....
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gamma">gamma</a>()</code>, <span class="rlang"><b>R</b></span>'s own Gamma function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xx &lt;- seq(-4, 10, by=1/2)
gx &lt;- sapply(1:5, gammaVer, x=xx)
gamx &lt;- gamma(xx)
cbind(xx, gx, gamma=gamx)
apply(gx, 2, all.equal, target=gamx, tol = 0) # typically: {T,T,T,T, 1.357e-16}
stopifnot( apply(gx, 2, all.equal, target = gamx, tol = 1e-14))
                                                 # even 2e-16 (Lnx, 64b, R 4.2.1)
</code></pre>

<hr>
<h2 id='hyper2binomP'>Transform Hypergeometric Distribution Parameters to Binomial Probability</h2><span id='topic+hyper2binomP'></span>

<h3>Description</h3>

<p>Transform the three parameters of the hypergeometric distribution
function to the probability parameter of the &ldquo;corresponding&rdquo; binomial
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hyper2binomP(x, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hyper2binomP_+3A_x">x</code>, <code id="hyper2binomP_+3A_m">m</code>, <code id="hyper2binomP_+3A_n">n</code>, <code id="hyper2binomP_+3A_k">k</code></td>
<td>
<p>see <code><a href="stats.html#topic+dhyper">dhyper</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number, the binomial probability.
</p>


<h3>References</h3>

<p>See those in <code><a href="#topic+phyperBinMolenaar">phyperBinMolenaar</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>,
<code><a href="stats.html#topic+pbinom">pbinom</a></code>.
</p>
<p><code><a href="#topic+dhyperBinMolenaar">dhyperBinMolenaar</a>()</code>, <code><a href="#topic+phyperBinMolenaar.1">phyperBinMolenaar.1</a>()</code>,
<code>*.2()</code>, etc, all of which are crucially based on <code>hyper2binomP()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hyper2binomP(3,4,5,6) # 0.38856

## The function is simply defined as
function (x, m, n, k) {
    N &lt;- m + n
    p &lt;- m/N
    N.n &lt;- N - (k - 1)/2
    (m - x/2)/N.n - k * (x - k * p - 1/2)/(6 * N.n^2)
 }
</code></pre>

<hr>
<h2 id='Ixpq'>Normalized Incomplete Beta Function &quot;Like&quot; <code>pbeta()</code></h2><span id='topic+Ixpq'></span>

<h3>Description</h3>

<p>Computes the normalized incomplete beta function, in pure <span class="rlang"><b>R</b></span> code,
derived from Nico Temme's Maple code for computing Table 1 in  Gil et al (2023).
</p>
<p>It uses a continued fraction, similarly to <code>bfrac()</code> in the TOMS 708
algorithm underlying <span class="rlang"><b>R</b></span>'s  <code><a href="stats.html#topic+pbeta">pbeta</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ixpq(x, l_x, p, q, tol = 3e-16, it.max = 100L, plotIt = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ixpq_+3A_x">x</code></td>
<td>
<p>numeric</p>
</td></tr>
<tr><td><code id="Ixpq_+3A_l_x">l_x</code></td>
<td>
<p><code>1 - x</code>; may be specified with higher precision (e.g.,
when <code class="reqn">x \approx 1</code>, <code class="reqn">1-x</code> suffers from cancellation).</p>
</td></tr>
<tr><td><code id="Ixpq_+3A_p">p</code>, <code id="Ixpq_+3A_q">q</code></td>
<td>
<p>the two shape parameters of the beta distribution.</p>
</td></tr>
<tr><td><code id="Ixpq_+3A_tol">tol</code></td>
<td>
<p>positive number, the convergence tolerance for the continued fraction computation.</p>
</td></tr>
<tr><td><code id="Ixpq_+3A_it.max">it.max</code></td>
<td>
<p>maximal number of continued fraction steps.</p>
</td></tr>
<tr><td><code id="Ixpq_+3A_plotit">plotIt</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code>, if true, plots show the relative
approximation errors in each step.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector like <code>x</code> or <code>l_x</code> with corresponding
<code><a href="stats.html#topic+pbeta">pbeta</a>(x, *)</code> values.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler; based on original Maple code by Nico Temme.</p>


<h3>References</h3>

<p>Gil et al. (2023) 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pbeta">pbeta</a></code>, <code><a href="#topic+pbetaRv1">pbetaRv1</a>()</code>, ..
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0, 1, by=1/16)
r &lt;- Ixpq(x, 1-x, p = 4, q = 7, plotIt = TRUE)
cbind(x, r)
## and "test" ___FIXME__
</code></pre>

<hr>
<h2 id='lbeta'>(Log) Beta and Ratio of Gammas Approximations</h2><span id='topic+lbetaM'></span><span id='topic+lbeta_asy'></span><span id='topic+lbetaMM'></span><span id='topic+lbetaI'></span><span id='topic+betaI'></span><span id='topic+logQab_asy'></span><span id='topic+Qab_terms'></span>

<h3>Description</h3>

<p>Compute <code>log(<a href="base.html#topic+beta">beta</a>(a,b))</code> in a simple (fast) or asymptotic
way.  The asymptotic case is based on the asymptotic <code class="reqn">\Gamma</code>
(<code><a href="base.html#topic+gamma">gamma</a></code>) ratios, provided in <code>Qab_terms()</code> and
<code>logQab_asy()</code>.
</p>
<p><code>lbeta_asy(a,b, ..)</code> is simply <code>lgamma(a) - logQab_asy(a, b, ..)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
lbetaM   (a, b, k.max = 5, give.all = FALSE)
lbeta_asy(a, b, k.max = 5, give.all = FALSE)
lbetaMM  (a, b, cutAsy = 1e-2, verbose = FALSE)

 betaI(a, n)
lbetaI(a, n)

logQab_asy(a, b, k.max = 5, give.all = FALSE)
Qab_terms(a, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lbeta_+3A_a">a</code>, <code id="lbeta_+3A_b">b</code>, <code id="lbeta_+3A_n">n</code></td>
<td>
<p>the Beta parameters, see <code><a href="base.html#topic+beta">beta</a></code>; <code>n</code> must
be a positive integer and &ldquo;small&rdquo;.</p>
</td></tr>
<tr><td><code id="lbeta_+3A_k.max">k.max</code>, <code id="lbeta_+3A_k">k</code></td>
<td>
<p>for <code>lbeta*()</code> and <code>logQab_asy()</code>: the number
of terms to be used in the series expansion of <code>Qab_terms()</code>,
currently must be in <code class="reqn">{0, 1, .., 5}</code>.</p>
</td></tr>
<tr><td><code id="lbeta_+3A_give.all">give.all</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if all terms should be
returned (as columns of a matrix) or just the result.</p>
</td></tr>
<tr><td><code id="lbeta_+3A_cutasy">cutAsy</code></td>
<td>
<p>cutoff value from where to switch to asymptotic formula.</p>
</td></tr>
<tr><td><code id="lbeta_+3A_verbose">verbose</code></td>
<td>
<p>logical (or integer) indicating if and how much monitoring
information should be printed to the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All <code>lbeta*()</code> functions compute <code>log(<a href="base.html#topic+beta">beta</a>(a,b))</code>.
</p>
<p>We use <code class="reqn">Qab = Qab(a,b)</code> for
</p>
<p style="text-align: center;"><code class="reqn">Q_{a,b} := \frac{\Gamma(a + b)}{\Gamma(b)},</code>
</p>

<p>which is numerically challenging when <code class="reqn">b</code> becomes large compared to
<code>a</code>, or <code class="reqn">a \ll b</code>.
</p>
<p>With the beta function
</p>
<p style="text-align: center;"><code class="reqn">B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \frac{\Gamma(a)}{Qab},</code>
</p>

<p>and hence
</p>
<p style="text-align: center;"><code class="reqn">\log B(a,b) = \log\Gamma(a) + \log\Gamma(b) - \log\Gamma(a+b) = \log\Gamma(a) - \log Qab,</code>
</p>

<p>or in <span class="rlang"><b>R</b></span>, <code>lbeta(a,b) := lgamma(a) - logQab(a,b)</code>.
</p>
<p>Indeed, typically everything has to be computed in log scale, as both <code class="reqn">\Gamma(b)</code>
and <code class="reqn">\Gamma(a+b)</code> would overflow numerically for large <code class="reqn">b</code>.
Consequently, we use <code>logQab*()</code>, and for the large <code class="reqn">b</code> case
<code>logQab_asy()</code> specifically,
</p>
<p style="text-align: center;"><code class="reqn">\code{logQab(a,b)} := \log( Qab(a,b) ).</code>
</p>

<p>The 5 polynomial terms in <code>Qab_terms()</code> have been derived by the
author in 1997, but not published, about getting asymptotic formula for
<code class="reqn">\Gamma</code> ratios, related to but <em>different</em> than formula
(6.1.47) in Abramowitz and Stegun. 
</p>
<p>We also have a vignette 
about this, but really the problem has been adressed pragmatically
by the authors of TOMS 708, see the &lsquo;References&rsquo; in
<code><a href="stats.html#topic+pbeta">pbeta</a></code>,
by their routine <code><a href="#topic+algdiv">algdiv</a>()</code> which also is available in our
package <span class="pkg">DPQ</span>, <code class="reqn">\code{algdiv}(a,b) = - \code{logQab}(a,b)</code>.
Note that this is related to computing <code><a href="stats.html#topic+qbeta">qbeta</a>()</code> in boundary
cases.  See also <code><a href="#topic+algdiv">algdiv</a>()</code> &lsquo;Details&rsquo;.
</p>


<h3>Value</h3>

<p>a fast or simple (approximate) computation of <code><a href="base.html#topic+lbeta">lbeta</a>(a,b)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain;
Formula (6.1.47), p.257
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s <code><a href="base.html#topic+beta">beta</a></code> function; <code><a href="#topic+algdiv">algdiv</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(r  &lt;- logQab_asy(1, 50))
(rF &lt;- logQab_asy(1, 50, give.all=TRUE))
r == rF # all TRUE:  here, even the first approx. is good!
(r2  &lt;- logQab_asy(5/4, 50))
(r2F &lt;- logQab_asy(5/4, 50, give.all=TRUE))
r2 == r2F # TRUE only first entry "5"
(r2F.3 &lt;- logQab_asy(5/4, 50, k=3, give.all=TRUE))

## Check relation to Beta(), Gamma() functions:
a &lt;- 1.1 * 2^(-6:4)
b &lt;- 1001.5
rDlgg &lt;- lgamma(a+b) - lgamma(b) # suffers from cancellation for small 'a'
rDlgb &lt;- lgamma(a) - lbeta(a, b) #    (ditto)
ralgd &lt;- - algdiv(a,b)
rQasy &lt;- logQab_asy(a, b)
cbind(a, rDlgg, rDlgb, ralgd, rQasy)
all.equal(rDlgg, rDlgb, tolerance = 0) # 3.0e-14
all.equal(rDlgb, ralgd, tolerance = 0) # 1.2e-16
all.equal(ralgd, rQasy, tolerance = 0) # 4.1e-10
all.equal(rQasy, rDlgg, tolerance = 0) # 3.5e-10

stopifnot(exprs = {
    all.equal(rDlgg, rDlgb, tolerance = 1e-12) # 3e-14 {from cancellations!}
    all.equal(rDlgb, ralgd, tolerance = 1e-13) # 1e-16
    all.equal(ralgd, rQasy, tolerance = 2e-9) # 4.1e-10
    all.equal(rQasy, rDlgg, tolerance = 2e-9) # 3.5e-10
    all.equal(lgamma(a)-lbeta(a, 2*b), logQab_asy(a, 2*b), tolerance =1e-10)# 1.4e-11
    all.equal(lgamma(a)-lbeta(a, b/2), logQab_asy(a, b/2), tolerance = 1e-7)# 1.2e-8
})
if(requireNamespace("Rmpfr")) withAutoprint({
  aM &lt;- Rmpfr::mpfr(a, 512)
  bM &lt;- Rmpfr::mpfr(b, 512)
  rT &lt;- lgamma(aM+bM) - lgamma(bM) # "True" i.e. accurate values
  relE &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(rT, cbind(rDlgg, rDlgb, ralgd, rQasy)))
  cbind(a, signif(relE,4))
  ##          a      rDlgg      rDlgb      ralgd      rQasy
  ##  0.0171875  4.802e-12  3.921e-16  4.145e-17 -4.260e-16
  ##  0.0343750  1.658e-12  1.509e-15 -1.011e-17  1.068e-16
  ##  0.0687500 -2.555e-13  6.853e-16 -1.596e-17 -1.328e-16
  ##  0.1375000  1.916e-12 -7.782e-17  3.905e-17 -7.782e-17
  ##  0.2750000  1.246e-14  7.001e-17  7.001e-17 -4.686e-17
  ##  0.5500000 -2.313e-13  5.647e-17  5.647e-17 -6.040e-17
  ##  1.1000000 -9.140e-14 -1.298e-16 -1.297e-17 -1.297e-17
  ##  2.2000000  9.912e-14  2.420e-17  2.420e-17 -9.265e-17
  ##  4.4000000  1.888e-14  6.810e-17 -4.873e-17 -4.873e-17
  ##  8.8000000 -7.491e-15  1.004e-16 -1.638e-17 -4.118e-13
  ## 17.6000000  2.222e-15  1.207e-16  3.974e-18 -6.972e-10

## ==&gt;  logQab_asy() is very good _here_ as long as  a &lt;&lt; b
})

</code></pre>

<hr>
<h2 id='lfastchoose'>R versions of Simple Formulas for Logarithmic Binomial Coefficients</h2><span id='topic+lfastchoose'></span><span id='topic+f05lchoose'></span>

<h3>Description</h3>

<p>Provide <span class="rlang"><b>R</b></span> versions of simple formulas for computing the logarithm of
(the absolute value of) binomial coefficients, i.e., simpler, more direct
formulas than what (the C level) code of <span class="rlang"><b>R</b></span>'s <code><a href="base.html#topic+lchoose">lchoose</a>()</code>
computes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lfastchoose(n, k)
 f05lchoose(n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lfastchoose_+3A_n">n</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="lfastchoose_+3A_k">k</code></td>
<td>
<p>a integer valued numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector with the same attributes as <code>n + k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+lchoose">lchoose</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lfastchoose # function(n, k) lgamma(n + 1) - lgamma(k + 1) - lgamma(n - k + 1)
f05lchoose  # function(n, k) lfastchoose(n = floor(n + 0.5), k = floor(k + 0.5))

## interesting cases ?

</code></pre>

<hr>
<h2 id='lgamma1p'>Accurate <code>log(gamma(a+1))</code></h2><span id='topic+lgamma1p'></span><span id='topic+lgamma1p.'></span><span id='topic+lgamma1pC'></span><span id='topic+lgamma1p_series'></span>

<h3>Description</h3>

<p>Compute
</p>
<p style="text-align: center;"><code class="reqn">l\Gamma_1(a) := \log\Gamma(a+1) = \log(a\cdot \Gamma(a)) = \log a + \log \Gamma(a),</code>
</p>

<p>which is &ldquo;in principle&rdquo; the same as
<code><a href="base.html#topic+log">log</a>(<a href="base.html#topic+gamma">gamma</a>(a+1))</code> or <code><a href="base.html#topic+lgamma">lgamma</a>(a+1)</code>,
accurately also for (very) small <code class="reqn">a</code> <code class="reqn">(0 &lt; a &lt; 0.5)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lgamma1p (a, tol_logcf = 1e-14, f.tol = 1, ...)	
lgamma1p.(a, cutoff.a = 1e-6, k = 3)		
lgamma1p_series(x, k)               		
lgamma1pC(x)                        		
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lgamma1p_+3A_a">a</code>, <code id="lgamma1p_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="lgamma1p_+3A_tol_logcf">tol_logcf</code></td>
<td>
<p>for <code>lgamma1p()</code>: a non-negative number passed to
<code><a href="#topic+logcf">logcf</a>()</code> (and <code><a href="#topic+log1pmx">log1pmx</a>()</code> which calls <code>logcf()</code>).</p>
</td></tr>
<tr><td><code id="lgamma1p_+3A_f.tol">f.tol</code></td>
<td>
<p>numeric (<b>f</b>actor) used in
<code><a href="#topic+log1pmx">log1pmx</a>(*, tol_logcf = f.tol * tol_logcf)</code>.</p>
</td></tr>
<tr><td><code id="lgamma1p_+3A_...">...</code></td>
<td>
<p>further optional arguments passed on to <code><a href="#topic+log1pmx">log1pmx</a>()</code>.</p>
</td></tr>
<tr><td><code id="lgamma1p_+3A_cutoff.a">cutoff.a</code></td>
<td>
<p>for <code>lgamma1p.()</code>: a positive number indicating
the cutoff to switch from  ...</p>
</td></tr>
<tr><td><code id="lgamma1p_+3A_k">k</code></td>
<td>
<p>an integer, the number of terms in the series expansion used
internally; currently for </p>

<dl>
<dt><code>lgamma1p.()</code>: </dt><dd><p><code class="reqn">k \le 3</code></p>
</dd>
<dt><code>lgamma1p_series()</code>:</dt><dd><p><code class="reqn">k \le 15</code></p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lgamma1p()</code> is an <span class="rlang"><b>R</b></span> translation of the function (in Fortran) in
Didonato and Morris (1992) which uses a 40-degree polynomial approximation.
</p>
<p><code>lgamma1p.(u)</code> for small <code class="reqn">|u|</code> uses up to 4 terms of
</p>
<p style="text-align: center;"><code class="reqn">\Gamma(1+u) = 1 + u*(-\gamma_E + a_0 u + a_1 u^2 + a_2 u^3) + O(u^5),</code>
</p>

<p>where <code class="reqn">a_0 := (\psi'(1) + \psi(1)^2)/2 = (\pi^2/6 + \gamma_E^2)/2</code>,
and <code class="reqn">a_1</code> und <code class="reqn">a_2</code> are similarly determined. 
Then <code>log1p(.)</code> of the <code class="reqn">\Gamma(1+u) - 1</code> approximation above is used.
</p>
<p><code>lgamma1p_series(x, k)</code> is a Taylor series approximation of order
<code>k</code>, directly of <code class="reqn">l\Gamma_1(a) := \log \Gamma(a+1)</code> (mostly via
<code>Maple</code>), which starts as
<code class="reqn">-\gamma_E x + \pi^2 x^2/ 12 + \dots</code>,
where <code class="reqn">\gamma_E</code> is Euler's constant 0.5772156649. 
</p>
<p><code>lgamma1pC()</code> is an interface to <span class="rlang"><b>R</b></span>'s C API (&lsquo;<span class="file">Mathlib</span>&rsquo; / &lsquo;<span class="file">Rmath.h</span>&rsquo;)
function <code>lgamma1p()</code>.
</p>


<h3>Value</h3>

<p>a numeric vector with the same attributes as <code>a</code>.
</p>


<h3>Author(s)</h3>

<p>Morten Welinder (C code of Jan 2005, see R's bug issue
<a href="https://bugs.R-project.org/show_bug.cgi?id=7307">PR#7307</a>) for <code>lgamma1p()</code>.
</p>
<p>Martin Maechler, notably for <code>lgamma1p_series()</code> which works
with package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a> but otherwise may be <em>much</em> less
accurate than Morten's 40 term series!
</p>


<h3>References</h3>

<p>Didonato, A. and Morris, A., Jr, (1992)
Algorithm 708: Significant digit computation of the incomplete beta function ratios.
<em>ACM Transactions on Mathematical Software</em>, <b>18</b>, 360&ndash;373;
see also <code><a href="stats.html#topic+pbeta">pbeta</a></code>.
</p>


<h3>See Also</h3>

<p>Yet another algorithm, fully double precision accurate in <code class="reqn">[-0.2, 1.25]</code>,
is provided by <code><a href="#topic+gamln1">gamln1</a>()</code>.
</p>
<p><code><a href="#topic+log1pmx">log1pmx</a></code>, <code><a href="base.html#topic+log1p">log1p</a></code>, <code><a href="stats.html#topic+pbeta">pbeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(lgamma1p, -1.25, 5, n=1001, col=2, lwd=2)
abline(h=0, v=-1:0, lty=c(2,3,2), lwd=c(1, 1/2,1))
for(k in 1:15)
  curve(lgamma1p_series(x, k=k), add=TRUE, col=adjustcolor(paste0("gray",25+k*4), 2/3), lty = 3)

curve(lgamma1p, -0.25, 1.25, n=1001, col=2, lwd=2)
abline(h=0, v=0, lty=2)
for(k in 1:15)
  curve(lgamma1p_series(x, k=k), add=TRUE, col=adjustcolor("gray20", 2/3), lty = 3)

curve(-log(x*gamma(x)), 1e-30, .8, log="xy", col="gray50", lwd = 3,
      axes = FALSE, ylim = c(1e-30,1)) # underflows to zero at x ~= 1e-16
eaxGrid &lt;- function(at.x = 10^(1-4*(0:8)), at.y = at.x) {
    sfsmisc::eaxis(1, sub10 = c(-2, 2), nintLog=16)
    sfsmisc::eaxis(2, sub10 = 2, nintLog=16)
    abline(h = at.y, v = at.x, col = "lightgray", lty = "dotted")
}
eaxGrid()
curve(-lgamma( 1+x), add=TRUE, col="red2", lwd=1/2)# underflows even earlier
curve(-lgamma1p (x), add=TRUE, col="blue") -&gt; lgxy
curve(-lgamma1p.(x), add=TRUE, col=adjustcolor("forest green",1/4),
      lwd = 5, lty = 2)
for(k in 1:15)
  curve(-lgamma1p_series(x, k=k), add=TRUE, col=paste0("gray",80-k*4), lty = 3)
stopifnot(with(lgxy, all.equal(y, -lgamma1pC(x))))

if(requireNamespace("Rmpfr")) { # accuracy comparisons, originally from  ../tests/qgamma-ex.R
    x &lt;- 2^(-(500:11)/8)
    x. &lt;- Rmpfr::mpfr(x, 200)
    ## versions of lgamma1p(x) := lgamma(1+x)
    ## lgamma1p(x) = log gamma(x+1) = log (x * gamma(x)) = log(x) + lgamma(x)
    xct. &lt;- log(x.  * gamma(x.)) # using  MPFR  arithmetic .. no overflow/underflow ...
    xc2. &lt;- log(x.) + lgamma(x.) #  (ditto)

    AllEq &lt;- function(target, current, ...)
        Rmpfr::all.equal(target, current, ...,
                         formatFUN = function(x, ...) Rmpfr::format(x, digits = 9))
    print(AllEq(xct., xc2., tol = 0)) # 2e-57
    rr &lt;- vapply(1:15, function(k) lgamma1p_series(x, k=k), x)
    colnames(rr) &lt;- paste0("k=",1:15)
    relEr &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(xct., rr))
    ## rel.error of direct simple computation:
    relE.D &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(xct., lgamma(1+x)))

    matplot(x, abs(relEr), log="xy", type="l", axes = FALSE,
            main = "|rel.Err(.)| for lgamma(1+x) =~= lgamma1p_series(x, k = 1:15)")
    eaxGrid()
    p2 &lt;- -(53:52); twp &lt;- 2^p2; labL &lt;- lapply(p2, function(p) substitute(2^E, list(E=p)))
    abline(h = twp, lty=3)
    axis(4, at=twp, las=2, line=-1, labels=as.expression(labL), col=NA,col.ticks=NA)
    legend("topleft", paste("k =", 1:15), ncol=3, col=1:6, lty=1:5, bty="n")
    lines(x, abs(relE.D), col = adjustcolor(2, 2/3), lwd=2)
    legend("top", "lgamma(1+x)", col=2, lwd=2)

    ## zoom in:
    matplot(x, abs(relEr), log="xy", type="l", axes = FALSE,
            xlim = c(1e-5, 0.1), ylim = c(1e-17, 1e-10),
            main = "|rel.Err(.)| for lgamma(1+x) =~= lgamma1p_series(x, k = 1:15)")
    eaxGrid(10^(-5:1), 10^-(17:10))
    abline(h = twp, lty=3)
    axis(4, at=twp, las=2, line=-1, labels=as.expression(labL), col=NA,col.ticks=NA)
    legend("topleft", paste("k =", 1:15), ncol=3, col=1:6, lty=1:5, bty="n")
    lines(x, abs(relE.D), col = adjustcolor(2, 2/3), lwd=2)
    legend("right", "lgamma(1+x)", col=2, lwd=2)

} # Rmpfr only

</code></pre>

<hr>
<h2 id='lgammaAsymp'>Asymptotic Log Gamma Function</h2><span id='topic+lgammaAsymp'></span>

<h3>Description</h3>

<p>Compute an n-th order asymptotic approximation to log Gamma function,
using Bernoulli numbers <code><a href="#topic+Bern">Bern</a>(k)</code> for <code>k</code> in
<code class="reqn">1, \ldots, 2n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lgammaAsymp(x, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lgammaAsymp_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="lgammaAsymp_+3A_n">n</code></td>
<td>
<p>integer specifying the approximation order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector with the same attributes (<code><a href="base.html#topic+length">length</a>()</code> etc) as
<code>x</code>, containing approximate <code><a href="base.html#topic+lgamma">lgamma</a>(x)</code> values.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+lgamma">lgamma</a></code>; the <code class="reqn">n</code>-th Bernoulli number
<code><a href="#topic+Bern">Bern</a>(n)</code>, and also <em>exact</em> fractions Bernoulli numbers
<code><a href="gmp.html#topic+BernoulliQ">BernoulliQ</a>()</code> from package <a href="https://CRAN.R-project.org/package=gmp"><span class="pkg">gmp</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently
lgammaAsymp

</code></pre>

<hr>
<h2 id='log1mexp'>Compute <code class="reqn">\mathrm{log}</code>(1 - <code class="reqn">\mathrm{exp}</code>(-a)) and
<code class="reqn">\log(1 + \exp(x))</code>   Numerically Optimally</h2><span id='topic+log1mexp'></span><span id='topic+log1mexpC'></span><span id='topic+log1pexpC'></span>

<h3>Description</h3>

<p>Compute  f(a) = log(1 - exp(-a))   quickly and numerically accurately.
</p>
<p><code>log1mexp()</code> is simple pure <span class="rlang"><b>R</b></span> code;<br />
<code>log1mexpC()</code> is an interface to <span class="rlang"><b>R</b></span> C API (&lsquo;<span class="file">Mathlib</span>&rsquo; / &lsquo;<span class="file">Rmath.h</span>&rsquo;)
function.
</p>
<p><code>log1pexpC()</code> is an interface to <span class="rlang"><b>R</b></span>'s &lsquo;<span class="file">Mathlib</span>&rsquo; <code>double</code>
function <code>log1pexp()</code> which computes <code class="reqn">\log(1 + \exp(x))</code>,
accurately, notably for large <code class="reqn">x</code>, say, <code class="reqn">x &gt; 720</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log1mexp (x)
log1mexpC(x)
log1pexpC(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log1mexp_+3A_x">x</code></td>
<td>
<p>numeric vector of positive values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>


<p>Martin Mchler (2012).
Accurately Computing <code class="reqn">\log(1-\exp(-|a|))</code>;
<a href="https://CRAN.R-project.org/package=Rmpfr/vignettes/log1mexp-note.pdf">https://CRAN.R-project.org/package=Rmpfr/vignettes/log1mexp-note.pdf</a>.

</p>


<h3>See Also</h3>


<p>The <code><a href="#topic+log1mexp">log1mexp</a>()</code> function in CRAN package <a href="https://CRAN.R-project.org/package=copula"><span class="pkg">copula</span></a>,
and the corresponding vignette (in the &lsquo;References&rsquo;).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>l1m.xy &lt;- curve(log1mexp(x), -10, 10, n=1001)
stopifnot(with(l1m.xy, all.equal(y, log1mexpC(x))))

x &lt;- seq(0, 710, length=1+710*2^4); stopifnot(diff(x) == 1/2^4)
l1pm &lt;- cbind(log1p(exp(x)),
              log1pexpC(x))
matplot(x, l1pm, type="l", log="xy") # both look the same
iF &lt;- is.finite(l1pm[,1])
stopifnot(all.equal(l1pm[iF,2], l1pm[iF,1], tol=1e-15))
</code></pre>

<hr>
<h2 id='log1pmx'>Accurate  <code>log(1+x) - x</code>  Computation</h2><span id='topic+log1pmx'></span><span id='topic+log1pmxC'></span><span id='topic+rlog1'></span>

<h3>Description</h3>

<p>Compute </p>
<p style="text-align: center;"><code class="reqn">\log(1+x) - x</code>
</p>

<p>accurately also for small <code class="reqn">x</code>, i.e., <code class="reqn">|x| \ll 1</code>.
</p>
<p>Since April 2021, the pure <span class="rlang"><b>R</b></span> code version <code>log1pmx()</code> also works
for &quot;mpfr&quot; numbers (from package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>).
</p>
<p><code>rlog1(x)</code>, provided mostly for reference and reproducibility, is
used in TOMS Algorithm 708, see e.g. the reference of <code><a href="#topic+lgamma1p">lgamma1p</a></code>.
and computes <em>minus</em> log1pmx(x), i.e., <code class="reqn">x - \log(1+x)</code>,
using (argument reduction) and a rational approximation when
<code class="reqn">x \in [-0.39, 0.57)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log1pmx (x, tol_logcf = 1e-14, eps2 = 0.01, minL1 = -0.79149064,
         trace.lcf = FALSE,
         logCF = if(is.numeric(x)) logcf else logcfR.)
log1pmxC(x)  # TODO in future: arguments (minL1, eps2, tol_logcf),
             # possibly with *different* defaults (!)
rlog1(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log1pmx_+3A_x">x</code></td>
<td>
<p>numeric (or, for <code>log1pmx()</code> only, <code>"<a href="Rmpfr.html#topic+mpfr">mpfr</a>"</code>
number) vector with values <code class="reqn">x &gt; -1</code>.</p>
</td></tr>
<tr><td><code id="log1pmx_+3A_tol_logcf">tol_logcf</code></td>
<td>
<p>a non-negative number indicating the tolerance
(maximal relative error) for the auxiliary <code><a href="#topic+logcf">logcf</a>()</code> function.</p>
</td></tr>
<tr><td><code id="log1pmx_+3A_eps2">eps2</code></td>
<td>
<p>non-negative cutoff where the algorithm switches from a few
terms, to using <code><a href="#topic+logcf">logcf</a>()</code> explicitly.  Note that for
more accurate mpfr-numbers the default <code>eps = .01</code> is too large,
even more so when the tolerance is lowered (from <code>1e-14</code>).</p>
</td></tr>
<tr><td><code id="log1pmx_+3A_minl1">minL1</code></td>
<td>
<p>negative cutoff, called <code>minLog1Value</code> in Morten
Welinder's C code for <code>log1pmx()</code> in &lsquo;<span class="file">R/src/nmath/pgamma.c</span>&rsquo;,
hard coded there to -0.79149064 which seems not optimal for
computation of <code>log1pmx()</code>, at least in some cases, and hence
<b>the default may be changed in the future</b>.  Also, for mpfr numbers,
the default -0.79149064 may well be far from optimal.
</p>
</td></tr>
<tr><td><code id="log1pmx_+3A_trace.lcf">trace.lcf</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> used in
<code><a href="#topic+logcf">logcf</a>(.., trace=trace.lcf)</code>.</p>
</td></tr>
<tr><td><code id="log1pmx_+3A_logcf">logCF</code></td>
<td>
<p>the <code><a href="base.html#topic+function">function</a></code> to be used as
<code><a href="#topic+logcf">logcf</a>()</code>.  The default chooses the pure <span class="rlang"><b>R</b></span> <code>logcfR()</code>
when <code>x</code> is not numeric, and chooses the C-based <code>logcf()</code>
when <code>is.numeric(x)</code> is true.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>In order to provide full (double precision) accuracy,
the computations happens differently in three regions for <code class="reqn">x</code>,
</p>
<p style="text-align: center;"><code class="reqn">m_l = \code{minL1} = -0.79149064</code>
</p>
<p> is the first cutpoint,
</p>

<dl>
<dt><code class="reqn">x &lt; m_l</code> or <code class="reqn">x &gt; 1</code>:</dt><dd><p>use <code>log1pmx(x) := <a href="base.html#topic+log1p">log1p</a>(x) - x</code>,</p>
</dd>
<dt><code class="reqn">|x| &lt; \epsilon_2</code>:</dt><dd><p>use
<code class="reqn">t((((2/9 * y + 2/7)y + 2/5)y + 2/3)y - x)</code>,</p>
</dd>
<dt><code class="reqn">x \in [ml,1]</code>, and <code class="reqn">|x| \ge \epsilon_2</code>:</dt><dd><p>use
<code class="reqn">t(2y logcf(y, 3, 2) - x)</code>,</p>
</dd>
</dl>

<p>where <code class="reqn">t := \frac{x}{2 + x}</code>, and <code class="reqn">y := t^2</code>.
</p>
<p>Note that the formulas based on <code class="reqn">t</code> are based on the (fast
converging) formula
</p>
<p style="text-align: center;"><code class="reqn">\log(1+x) = 2\left(r + \frac{r^3}{3}+ \frac{r^5}{5} + \ldots\right),</code>
</p>

<p>where <code class="reqn">r := x/(x+2)</code>, see the reference.
</p>
<p><code>log1pmxC()</code> is an interface to <span class="rlang"><b>R</b></span> C API (&lsquo;<span class="file">Rmathlib</span>&rsquo;) function.
</p>


<h3>Value</h3>

<p>a numeric vector (with the same attributes as <code>x</code>).
</p>


<h3>Author(s)</h3>

<p>A translation of Morten Welinder's C code of Jan 2005, see R's bug
issue <a href="https://bugs.R-project.org/show_bug.cgi?id=7307">PR#7307</a>, parametrized and tuned by Martin Maechler.
</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.<br />
Formula (4.1.29), p.68.
</p>
<p>Martin Mchler (2021).

<em>log1pmx, ... Computing ... Probabilities in <span class="rlang"><b>R</b></span></em>.
(<span class="pkg">DPQ</span> package vignette)


</p>


<h3>See Also</h3>

<p><code><a href="#topic+logcf">logcf</a></code>, the auxiliary function,
<code><a href="#topic+lgamma1p">lgamma1p</a></code> which calls <code>log1pmx</code>, <code><a href="base.html#topic+log1p">log1p</a></code>; also
<code><a href="#topic+expm1x">expm1x</a>)()</code> which computes <code><a href="base.html#topic+expm1">expm1</a>(x) - x</code>
accurately, whereas
<code>log1pmx(x)</code> computes <code><a href="base.html#topic+log1p">log1p</a>(x) - x</code> accurately
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(doExtras &lt;- DPQ:::doExtras()) # TRUE e.g. if interactive()
n1 &lt;- if(doExtras) 1001 else 201
curve(log1pmx, -.9999, 7, n=n1); abline(h=0, v=-1:0, lty=3)
curve(log1pmx, -.1,  .1,  n=n1); abline(h=0, v=0, lty=3)
curve(log1pmx, -.01, .01, n=n1) -&gt; l1xz2; abline(h=0, v=0, lty=3)
## C and R versions correspond closely:
with(l1xz2, stopifnot(all.equal(y, log1pmxC(x), tol = 1e-15)))

e &lt;- if(doExtras) 2^-12 else 2^-8; by.p &lt;- 1/(if(doExtras) 256 else 64)
xd &lt;- c(seq(-1+e, 0+100*e, by=e), seq(by.p, 5, by=by.p)) # length 676 or 5476 if do.X.
plot(xd, log1pmx(xd), type="l", col=2, main = "log1pmx(x)")
abline(h=0, v=-1:0, lty=3)

## --- Compare rexp1() with log1pmx() ----------------------------
x &lt;- seq(-0.5, 5/8, by=1/256)
all.equal(log1pmx(x), -rlog1(x), tol = 0) # 2.838e-16 {|rel.error| &lt;= 1.33e-15}
stopifnot(all.equal(log1pmx(x), -rlog1(x), tol = 1e-14))
## much more closely:
x &lt;- c(-1+1e-9, -1+1/256, -(127:50)/128, (-199:295)/512, 74:196/128)
if(is.unsorted(x)) stop("x must be sorted for plots")
rlog1.x &lt;- rlog1(x)
summary(relD &lt;- sfsmisc::relErrV(log1pmx(x), -rlog1.x))
n.relD &lt;- relD * 2^53
table(n.relD)
## 64-bit Linux F36 (gcc 12.2.1):
## -6  -5  -4  -3  -2  -1   0   2   4   6   8  10  12  14
##  2   3  13  24  79  93 259 120  48  22  14  15   5   1
stopifnot(-10 &lt;= n.relD, n.relD &lt;= 20) # above Lnx: [-6, 14]

if(requireNamespace("Rmpfr")) {
  relE &lt;- Rmpfr::asNumeric(sfsmisc::relErrV(log1pmx(Rmpfr::mpfr(x,128)), -rlog1(x)))
  plot(x, pmax(2^-54, abs(relE)), log="y", type="l", main= "|rel.Err| of rlog1(x)")
  rl1.c &lt;- c(-.39, 0.57, -.18, .18) # the cutoffs used inside rlog1()
  lc &lt;- "gray"
  abline(v = rl1.c, col=lc, lty=2)
  axis(3, at=rl1.c, col=lc, cex.axis=3/4, mgp=c(2,.5,0))
  abline(h= (1:4)*2^-53,  lty=3, col = (cg &lt;- adjustcolor(1, 1/4)))
  axis(4, at=(1:4)*2^-53, labels=expression(frac(epsilon[c],2), epsilon[c],
                                            frac(3,2)*epsilon[c], 2*epsilon[c]),
       cex.axis = 3/4, tcl=-1/4, las = 1, mgp=c(1.5,.5,0), col=cg)
  ## it seems the -.18 +.18 cutoffs should be slightly moved "outside"
}

## much more graphics etc in ../tests/dnbinom-tst.R  (and the vignette, see above)
</code></pre>

<hr>
<h2 id='logcf'>Continued Fraction Approximation of Log-Related Power Series</h2><span id='topic+logcf'></span><span id='topic+logcfR'></span><span id='topic+logcfR.'></span>

<h3>Description</h3>

<p>Compute a continued fraction approximation to the series (infinite sum)
</p>
<p style="text-align: center;"><code class="reqn">\sum_{k=0}^\infty \frac{x^k}{i +k\cdot d} = \frac{1}{i} + \frac{x}{i+d} +
    \frac{x^2}{i+2*d} + \frac{x^3}{i+3*d} + \ldots</code>
</p>

<p>Needed as auxiliary function in <code><a href="#topic+log1pmx">log1pmx</a>()</code> and <code><a href="#topic+lgamma1p">lgamma1p</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>					
logcfR (x, i, d, eps, maxit = 10000L, trace = FALSE)
logcfR.(x, i, d, eps, maxit = 10000L, trace = FALSE)
logcf  (x, i, d, eps, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logcf_+3A_x">x</code></td>
<td>
<p>numeric vector of values typically less than 1.
&quot;mpfr&quot; (of potentially high precision, package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>) work in
<code>logcfR*(x,*)</code>.</p>
</td></tr>
<tr><td><code id="logcf_+3A_i">i</code></td>
<td>
<p>positive numeric</p>
</td></tr>
<tr><td><code id="logcf_+3A_d">d</code></td>
<td>
<p>non-negative numeric</p>
</td></tr>
<tr><td><code id="logcf_+3A_eps">eps</code></td>
<td>
<p>positive number, the convergence tolerance.</p>
</td></tr>
<tr><td><code id="logcf_+3A_maxit">maxit</code></td>
<td>
<p>a positive integer, the maximal number of iterations or
terms in the truncated series used.</p>
</td></tr>
<tr><td><code id="logcf_+3A_trace">trace</code></td>
<td>
<p>logical (or non-negative integer in the future) indicating
if (and how much) diagnostic output should be printed to the console
during the computations.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>logcfR.()</code>:</dt><dd><p>a pure <span class="rlang"><b>R</b></span> version where the iterations happen
vectorized in <code>x</code>, only for those components <code>x[i]</code> they
have not yet converged.  This is particularly beneficial for
not-very-short <code>"mpfr"</code> vectors <code>x</code>, and still conceptually
equivalent to the <code>logcfR()</code> version.</p>
</dd>
<dt><code>logcfR()</code>:</dt><dd><p>a pure <span class="rlang"><b>R</b></span> version where each <code>x[i]</code> is
treated separately, hence &ldquo;properly&rdquo; vectorized, but slowly so.</p>
</dd>
<dt><code>logcf()</code>:</dt><dd><p>only for <code><a href="base.html#topic+numeric">numeric</a></code> <code>x</code>, calls
into (a clone of) <span class="rlang"><b>R</b></span>'s own (non-API currently) <code>logcf()</code> C
Rmathlib function.</p>
</dd>
</dl>



<h3>Value</h3>

<p>a numeric-alike vector with the same attributes as <code>x</code>.  For the
<code>logcfR*()</code> versions, an <code>"mpfr"</code> vector if <code>x</code> is one.
</p>


<h3>Note</h3>

<p>Rescaling is done by (namespace hidden) &ldquo;global&rdquo;
<code>scalefactor</code> which is <code class="reqn">2^{256}</code>, represented exactly (in
<code><a href="base.html#topic+double">double</a></code> precision).
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, based on <span class="rlang"><b>R</b></span>'s &lsquo;<span class="file">nmath/pgamma.c</span>&rsquo; implementation.</p>


<h3>See Also</h3>

<p><code><a href="#topic+lgamma1p">lgamma1p</a></code>, <code><a href="#topic+log1pmx">log1pmx</a></code>, and
<code><a href="stats.html#topic+pbeta">pbeta</a></code>, whose prinicipal algorithm has evolved from TOMS 708.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- (-2:1)/2
logcf (x, 2,3, eps=1e-7, trace=TRUE) # shows iterations for each x[]
logcfR(x, 2,3, eps=1e-7, trace=TRUE) # 1 line per x[]
logcfR(x, 2,3, eps=1e-7, trace= 2  ) # shows iterations for each x[]

n &lt;- 2049; x &lt;- seq(-1,1, length.out = n)[-n] ; stopifnot(diff(x) == 1/1024)
plot(x, (lcf &lt;- logcf(x, 2,3, eps=1e-12)), type="l", col=2)
lcR &lt;- logcfR (x, 2,3, eps=1e-12); all.equal(lcf, lcR , tol=0)
lcR.&lt;- logcfR.(x, 2,3, eps=1e-12); all.equal(lcf, lcR., tol=0)
stopifnot(exprs = {
  all.equal(lcf, lcR., tol=1e-14)# seen 0 (!)
  all.equal(lcf, lcR,  tol=1e-14)# seen 0 (!) -- failed for a while
})

l32 &lt;- curve(logcf(x, 3,2, eps=1e-7), -3, 1)
abline(h=0,v=1, lty=3, col="gray50")
plot(y~x, l32, log="y", type = "o", main = "logcf(*, 3,2)  in log-scale")
</code></pre>

<hr>
<h2 id='logspace.add'>Logspace Arithmetix &ndash; Addition and Subtraction</h2><span id='topic+logspace.add'></span><span id='topic+logspace.sub'></span>

<h3>Description</h3>

<p>Compute the log(arithm) of a sum (or difference) from the log of terms
without causing overflows and without throwing away large handfuls of accuracy.
</p>

<dl>
<dt><code>logspace.add(lx, ly)</code>:=</dt><dd>
<p style="text-align: center;"><code class="reqn">\log (\exp (lx) + \exp (ly))</code>
</p>
</dd>
<dt><code>logspace.sub(lx, ly)</code>:=</dt><dd>
<p style="text-align: center;"><code class="reqn">\log (\exp (lx) - \exp (ly))</code>
</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>logspace.add(lx, ly)
logspace.sub(lx, ly)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logspace.add_+3A_lx">lx</code>, <code id="logspace.add_+3A_ly">ly</code></td>
<td>
<p>numeric vectors, typically of the same
<code><a href="base.html#topic+length">length</a></code>, but will be recycled to common length as with
other <span class="rlang"><b>R</b></span> arithmetic.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector of the same length as <code>x+y</code>.
</p>


<h3>Note</h3>

<p>This is really from <span class="rlang"><b>R</b></span>'s C source code for <code><a href="stats.html#topic+pgamma">pgamma</a>()</code>, i.e.,
&lsquo;<span class="file">&lt;R&gt;/src/nmath/pgamma.c</span>&rsquo;
</p>
<p>The function definitions are very simple, <code>logspace.sub()</code> using <code><a href="#topic+log1mexp">log1mexp</a>()</code>.
</p>


<h3>Author(s)</h3>

<p>Morten Welinder (for <span class="rlang"><b>R</b></span>'s <code>pgamma()</code>); Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsum">lsum</a></code>, <code><a href="#topic+lssum">lssum</a></code>; then <code><a href="stats.html#topic+pgamma">pgamma</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12)
ly &lt;- rnorm(100, sd= 50)
lx &lt;- ly + abs(rnorm(100, sd=100))  # lx - ly must be positive for *.sub()
stopifnot(exprs = {
   all.equal(logspace.add(lx,ly),
             log(exp(lx) + exp(ly)), tol=1e-14)
   all.equal(logspace.sub(lx,ly),
             log(exp(lx) - exp(ly)), tol=1e-14)
})
</code></pre>

<hr>
<h2 id='lssum'>Compute Logarithm of a Sum with Signed Large Summands</h2><span id='topic+lssum'></span>

<h3>Description</h3>

<p>Properly compute <code class="reqn">\log(x_1 + \ldots + x_n)</code>
for given log absolute values <code>lxabs = </code>
<code class="reqn">log(|x_1|),.., log(|x_n|)</code>
and corresponding signs <code>signs = </code> <code class="reqn">sign(x_1),.., sign(x_n)</code>.  Here,
<code class="reqn">x_i</code> is of arbitrary sign.
</p>
<p>Notably this works in many cases where the direct sum would have summands
that had overflown to <code>+Inf</code> or underflown to <code>-Inf</code>.
</p>
<p>This is a (simpler, vector-only) version of <code>copula:::lssum()</code> (CRAN
package <a href="https://CRAN.R-project.org/package=copula"><span class="pkg">copula</span></a>). 
</p>
<p>Note that the <em>precision</em> is often not the problem for the direct
summation, as <span class="rlang"><b>R</b></span>'s <code><a href="base.html#topic+sum">sum</a>()</code> internally uses
<code>"long double"</code> precision on most platforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lssum(lxabs, signs, l.off = max(lxabs), strict = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lssum_+3A_lxabs">lxabs</code></td>
<td>
<p>n-vector of values <code class="reqn">\log(|x_1|), \ldots, \log(|x_n|)</code>.</p>
</td></tr>
<tr><td><code id="lssum_+3A_signs">signs</code></td>
<td>
<p>corresponding signs <code class="reqn">sign(x_1), \ldots, sign(x_n)</code>.</p>
</td></tr>
<tr><td><code id="lssum_+3A_l.off">l.off</code></td>
<td>
<p>the offset to substract and re-add; ideally in the order of <code><a href="base.html#topic+max">max</a>(.)</code>.</p>
</td></tr>
<tr><td><code id="lssum_+3A_strict">strict</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if the function should stop on some negative sums.</p>
</td></tr>
</table>


<h3>Value</h3>

<p style="text-align: center;"><code class="reqn">
    log(x_1 + .. + x_n) =
    = log(sum(x)) = log(sum(sign(x)*|x|)) =
    = log(sum(sign(x)*exp(log(|x|)))) =
    = log(exp(log(x0))*sum(signs*exp(log(|x|)-log(x0)))) =
    = log(x0) + log(sum(signs* exp(log(|x|)-log(x0)))) =
    = l.off + log(sum(signs* exp(lxabs - l.off )))
  </code>
</p>



<h3>Author(s)</h3>

<p>Marius Hofert and Martin Maechler (for package <a href="https://CRAN.R-project.org/package=copula"><span class="pkg">copula</span></a>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsum">lsum</a>()</code> which computes an exponential sum in log scale
with <em>out</em> signs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rSamp &lt;- function(n, lmean, lsd = 1/4, roundN = 16) {
  lax &lt;- sort((1+1e-14*rnorm(n))*round(roundN*rnorm(n, m = lmean, sd = lsd))/roundN)
  sx &lt;- rep_len(c(-1,1), n)
  list(lax=lax, sx=sx, x = sx*exp(lax))
}

set.seed(101)
L1 &lt;- rSamp(1000, lmean = 700) # here, lssum() is not needed (no under-/overflow)
summary(as.data.frame(L1))
ax &lt;- exp(lax &lt;- L1$lax)
hist(lax); rug(lax)
hist( ax); rug( ax)
sx &lt;- L1$sx
table(sx)
(lsSimple &lt;- log(sum(L1$x)))           # 700.0373
(lsS &lt;- lssum(lxabs = lax, signs = sx))# ditto
lsS - lsSimple # even exactly zero (in 64b Fedora 30 Linux which has nice 'long double')
stopifnot(all.equal(700.037327351478, lsS, tol=1e-14), all.equal(lsS, lsSimple))

L2 &lt;- within(L1, { lax &lt;- lax + 10; x &lt;- sx*exp(lax) }) ; summary(L2$x) # some -Inf, +Inf
(lsSimpl2 &lt;- log(sum(L2$ x)))                    # NaN
(lsS2 &lt;- lssum(lxabs = L2$ lax, signs = L2$ sx)) # 710.0373
stopifnot(all.equal(lsS2, lsS + 10, tol = 1e-14))
</code></pre>

<hr>
<h2 id='lsum'>Properly Compute the Logarithm of a Sum (of Exponentials)</h2><span id='topic+lsum'></span>

<h3>Description</h3>

<p>Properly compute <code class="reqn">\log(x_1 + \ldots + x_n)</code>.
for given <code class="reqn">log(x_1),..,log(x_n)</code>.  Here, <code class="reqn">x_i &gt; 0</code> for all <code class="reqn">i</code>.
</p>
<p>If the inputs are denoted <code class="reqn">l_i = log(x_i)</code> for <code class="reqn">i = 1,2,..,n</code>, we
compute <code>log(sum(exp(l[])))</code>, numerically stably.
</p>
<p>Simple vector version of <code>copula:::lsum()</code> (CRAN package
<a href="https://CRAN.R-project.org/package=copula"><span class="pkg">copula</span></a>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsum(lx, l.off = max(lx))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lsum_+3A_lx">lx</code></td>
<td>
<p>n-vector of values log(x_1),..,log(x_n).</p>
</td></tr>
<tr><td><code id="lsum_+3A_l.off">l.off</code></td>
<td>
<p>the offset to substract and re-add; ideally in
the order of the maximum of each column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p style="text-align: center;"><code class="reqn">
    log(x_1 + .. + x_n) = log(sum(x)) = log(sum(exp(log(x)))) =
    = log(exp(log(x_max))*sum(exp(log(x)-log(x_max)))) =
    = log(x_max) + log(sum(exp(log(x)-log(x_max))))) =
    = lx.max + log(sum(exp(lx-lx.max)))
  </code>
</p>



<h3>Author(s)</h3>

<p>Originally, via paired programming: Marius Hofert and Martin Maechler.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lssum">lssum</a>()</code> which computes a sum in log scale
with specified (typically alternating) signs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The "naive" version :
lsum0 &lt;- function(lx) log(sum(exp(lx)))

lx1 &lt;- 10*(-80:70) # is easy
lx2 &lt;- 600:750     # lsum0() not ok [could work with rescaling]
lx3 &lt;- -(750:900)  # lsum0() = -Inf - not good enough
m3 &lt;- cbind(lx1,lx2,lx3)
lx6 &lt;- lx5 &lt;- lx4 &lt;- lx3
lx4[149:151] &lt;- -Inf ## = log(0)
lx5[150] &lt;- Inf
lx6[1] &lt;- NA_real_
m6 &lt;- cbind(m3,lx4,lx5,lx6)
stopifnot(exprs = {
  all.equal(lsum(lx1), lsum0(lx1))
  all.equal((ls1 &lt;- lsum(lx1)),  700.000045400960403, tol=8e-16)
  all.equal((ls2 &lt;- lsum(lx2)),  750.458675145387133, tol=8e-16)
  all.equal((ls3 &lt;- lsum(lx3)), -749.541324854612867, tol=8e-16)
  ## identical: matrix-version &lt;==&gt; vector versions
  identical(lsum(lx4), ls3)
  identical(lsum(lx4), lsum(head(lx4, -3))) # the last three were -Inf
  identical(lsum(lx5), Inf)
  identical(lsum(lx6), lx6[1])
  identical((lm3 &lt;- apply(m3, 2, lsum)), c(lx1=ls1, lx2=ls2, lx3=ls3))
  identical(apply(m6, 2, lsum), c(lm3, lx4=ls3, lx5=Inf, lx6=lx6[1]))
})
</code></pre>

<hr>
<h2 id='newton'>Simple R level Newton Algorithm, Mostly for Didactical Reasons</h2><span id='topic+newton'></span>

<h3>Description</h3>

<p>Given the function <code>G()</code> and its derivative <code>g()</code>,
<code>newton()</code> uses the Newton method, starting at <code>x0</code>,
to find a point xp at which G is zero.  <code>G()</code> and <code>g()</code>
may each depend on the same parameter (vector) <code>z</code>.
</p>
<p>Convergence typically happens when the stepsize becomes smaller than
<code>eps</code>.
</p>
<p><code>keepAll = TRUE</code>  to also get  the vectors of consecutive values of
x and G(x, z);
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
newton(x0, G, g, z,
       xMin = -Inf, xMax = Inf, warnRng = TRUE,
       dxMax = 1000, eps = 0.0001, maxiter = 1000L,
       warnIter = missing(maxiter) || maxiter &gt;= 10L,
       keepAll = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newton_+3A_x0">x0</code></td>
<td>
<p>numeric start value.</p>
</td></tr>
<tr><td><code id="newton_+3A_g">G</code>, <code id="newton_+3A_g">g</code></td>
<td>
<p>must be <code><a href="base.html#topic+function">function</a></code>s, mathematically of their first
argument, but they can accept parameters; <code>g()</code> must be the
derivative of <code>G</code>.</p>
</td></tr>
<tr><td><code id="newton_+3A_z">z</code></td>
<td>
<p>parameter vector for <code class="reqn">G()</code> and <code class="reqn">g()</code>, to be kept fixed.</p>
</td></tr>
<tr><td><code id="newton_+3A_xmin">xMin</code>, <code id="newton_+3A_xmax">xMax</code></td>
<td>
<p>numbers defining the allowed range for x during the
iterations; e.g., useful to set to <code>0</code> and <code>1</code> during quantile
search.</p>
</td></tr>
<tr><td><code id="newton_+3A_warnrng">warnRng</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> specifying if a <code><a href="base.html#topic+warning">warning</a></code> should be
signalled when start value <code>x0</code> is outside <code>[xMin, xMax]</code> and
hence will be changed to one of the boundary values.</p>
</td></tr>
<tr><td><code id="newton_+3A_dxmax">dxMax</code></td>
<td>
<p>maximal step size in <code class="reqn">x</code>-space.  (The default <code>1000</code>
is quite arbitrary, do set a good maximal step size yourself!)</p>
</td></tr>
<tr><td><code id="newton_+3A_eps">eps</code></td>
<td>
<p>positive number, the <em>absolute</em> convergence tolerance.</p>
</td></tr>
<tr><td><code id="newton_+3A_maxiter">maxiter</code></td>
<td>
<p>positive integer, specifying the maximal number of Newton
iterations.</p>
</td></tr>
<tr><td><code id="newton_+3A_warniter">warnIter</code></td>
<td>
<p>logical specifying if a <code><a href="base.html#topic+warning">warning</a></code> should be
signalled when the algorithm has not converged in <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code id="newton_+3A_keepall">keepAll</code></td>
<td>
<p>logical specifying if the full sequence of x- and G(x,*)
values should be kept and returned: </p>

<dl>
<dt><code>NA</code>,</dt><dd><p>the default: <code>newton</code> returns a
small list of final &ldquo;data&rdquo;, with 4 components
<code>x</code><code class="reqn"> = x*</code>, <code>G</code><code class="reqn">= G(x*, z)</code>,
<code>it</code>, and <code>converged</code>.</p>
</dd>
<dt><code>TRUE</code>:</dt><dd><p>returns an extended <code><a href="base.html#topic+list">list</a></code>, in
addition containing the vectors <code>x.vec</code> and <code>G.vec</code>.</p>
</dd>
<dt><code>FALSE</code>:</dt><dd><p>returns only the <code class="reqn">x*</code> value.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>Because of the quadrativc convergence at the end of the Newton algorithm,
often <code class="reqn">x^*</code> satisfies approximately <code class="reqn"> | G(x*, z)| &lt; eps^2 </code>.
</p>
<p><code>newton()</code> can be used to compute the quantile function of a
distribution, if you have a good starting value, and provide
the cumulative probability and density functions as <span class="rlang"><b>R</b></span> functions <code>G</code>
and <code>g</code> respectively.
</p>


<h3>Value</h3>

<p>The result always contains the final x-value <code class="reqn">x*</code>, and typically some
information about convergence, depending on the value of <code>keepAll</code>,
see above:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>the optimal <code class="reqn">x^*</code> value (a number).</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>the function value <code class="reqn">G(x*, z)</code>, typically very close to zero.</p>
</td></tr>
<tr><td><code>it</code></td>
<td>
<p>the integer number of iterations used.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>logical indicating if the Newton algorithm converged
within <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code>x.vec</code></td>
<td>
<p>the full vector of x values, <code class="reqn">\{x0,\ldots,x^*\}</code>.</p>
</td></tr>
<tr><td><code>G.vec</code></td>
<td>
<p>the vector of function values (typically tending to zero),
i.e., <code>G(x.vec, .)</code> (even when <code>G(x, .)</code> would not vectorize).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler, ca. 2004</p>


<h3>References</h3>

<p>Newton's Method on Wikipedia,
<a href="https://en.wikipedia.org/wiki/Newton%27s_method">https://en.wikipedia.org/wiki/Newton%27s_method</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a>()</code> is much more sophisticated, works without
derivatives and is generally faster than <code>newton()</code>.
</p>
<p><code>newton(.)</code> is currently crucially used (only) in our function
<code><a href="#topic+qchisqN">qchisqN</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The most simple non-trivial case :  Computing SQRT(a)
  G &lt;- function(x, a) x^2 - a
  g &lt;- function(x, a) 2*x

  newton(1, G, g, z = 4  ) # z = a -- converges immediately
  newton(1, G, g, z = 400) # bad start, needs longer to converge

## More interesting, and related to non-central (chisq, e.t.) computations:
## When is  x * log(x) &lt; B,  i.e., the inverse function of G = x*log(x) :
xlx &lt;- function(x, B) x*log(x) - B
dxlx &lt;- function(x, B) log(x) + 1

Nxlx &lt;- function(B) newton(B, G=xlx, g=dxlx, z=B, maxiter=Inf)$x
N1   &lt;- function(B) newton(B, G=xlx, g=dxlx, z=B, maxiter = 1)$x
N2   &lt;- function(B) newton(B, G=xlx, g=dxlx, z=B, maxiter = 2)$x

Bs &lt;- c(outer(c(1,2,5), 10^(0:4)))
plot (Bs, vapply(Bs, Nxlx, pi), type = "l", log ="xy")
lines(Bs, vapply(Bs, N1  , pi), col = 2, lwd = 2, lty = 2)
lines(Bs, vapply(Bs, N2  , pi), col = 3, lwd = 3, lty = 3)

BL &lt;- c(outer(c(1,2,5), 10^(0:6)))
plot (BL, vapply(BL, Nxlx, pi), type = "l", log ="xy")
lines(BL, BL, col="green2", lty=3)
lines(BL, vapply(BL, N1  , pi), col = 2, lwd = 2, lty = 2)
lines(BL, vapply(BL, N2  , pi), col = 3, lwd = 3, lty = 3)
## Better starting value from an approximate 1 step Newton:
iL1 &lt;- function(B) 2*B / (log(B) + 1)
lines(BL, iL1(BL), lty=4, col="gray20") ## really better ==&gt; use it as start

Nxlx &lt;- function(B) newton(iL1(B), G=xlx, g=dxlx, z=B, maxiter=Inf)$x
N1   &lt;- function(B) newton(iL1(B), G=xlx, g=dxlx, z=B, maxiter = 1)$x
N2   &lt;- function(B) newton(iL1(B), G=xlx, g=dxlx, z=B, maxiter = 2)$x

plot (BL, vapply(BL, Nxlx, pi), type = "o", log ="xy")
lines(BL, iL1(BL),  lty=4, col="gray20")
lines(BL, vapply(BL, N1  , pi), type = "o", col = 2, lwd = 2, lty = 2)
lines(BL, vapply(BL, N2  , pi), type = "o", col = 3, lwd = 2, lty = 3)
## Manual 2-step Newton
iL2 &lt;- function(B) { lB &lt;- log(B) ; B*(lB+1) / (lB * (lB - log(lB) + 1)) }
lines(BL, iL2(BL), col = adjustcolor("sky blue", 0.6), lwd=6)
##==&gt;  iL2() is very close to true curve
## relative error:
iLtrue &lt;- vapply(BL, Nxlx, pi)
cbind(BL, iLtrue, iL2=iL2(BL), relErL2 = 1-iL2(BL)/iLtrue)
## absolute error (in log-log scale; always positive!):
plot(BL, iL2(BL) - iLtrue, type = "o", log="xy", axes=FALSE)
if(requireNamespace("sfsmisc")) {
  sfsmisc::eaxis(1)
  sfsmisc::eaxis(2, sub10=2)
} else {
  cat("no 'sfsmisc' package; maybe  install.packages(\"sfsmisc\")  ?\n")
  axis(1); axis(2)
}
## 1 step from iL2()  seems quite good:
B. &lt;- BL[-1] # starts at 2
NL2 &lt;- lapply(B., function(B) newton(iL2(B), G=xlx, g=dxlx, z=B, maxiter=1))
str(NL2)
iL3 &lt;- sapply(NL2, `[[`, "x")
cbind(B., iLtrue[-1], iL2=iL2(B.), iL3, relE.3 = 1- iL3/iLtrue[-1])
x. &lt;- iL2(B.)
all.equal(iL3, x. - xlx(x., B.) / dxlx(x.)) ## 7.471802e-8
## Algebraic simplification of one newton step :
all.equal((x.+B.)/(log(x.)+1), x. - xlx(x., B.) / dxlx(x.), tol = 4e-16)
iN1 &lt;- function(x, B) (x+B) / (log(x) + 1)
B &lt;- 12345
iN1(iN1(iN1(B, B),B),B)
Nxlx(B)
</code></pre>

<hr>
<h2 id='numer-utils'>Numerical Utilities - Functions, Constants</h2><span id='topic+M_LN2'></span><span id='topic+M_SQRT2'></span><span id='topic+M_minExp'></span><span id='topic+M_cutoff'></span><span id='topic+G_half'></span><span id='topic+all_mpfr'></span><span id='topic+any_mpfr'></span><span id='topic+logr'></span><span id='topic+modf'></span><span id='topic+okLongDouble'></span>

<h3>Description</h3>

<p>The <span class="pkg">DPQ</span> package provides some numeric constants used in some of its
distribution computations.
</p>
<p><code>all_mpfr()</code> and <code>any_mpfr()</code> return <code><a href="base.html#topic+TRUE">TRUE</a></code>
iff all (or &lsquo;any&rsquo;, respectively) of their arguments inherit from
<code><a href="base.html#topic+class">class</a></code> <code>"mpfr"</code> (from package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>).
</p>
<p><code>logr(x,a)</code> computes <code><a href="base.html#topic+log">log</a>(x / (x + a))</code> in a numerically
stable way.
</p>
<p><code>modf(x)</code> splits each <code>x</code> into integer part (as
<code><a href="base.html#topic+trunc">trunc</a>(x)</code>) and fractional (remainder) part in <code class="reqn">(-1, 1)</code>
and corresponds to the <span class="rlang"><b>R</b></span> version of the C99 (and POSIX) standard C (and C++) mathlib
functions of the same name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Numeric Constants : % mostly in   ../R/beta-fns.R
M_LN2        # = log(2)  = 0.693....
M_SQRT2      # = sqrt(2) = 1.4142...
M_cutoff     # := If |x| &gt; |k| * M_cutoff, then  log[ exp(-x) * k^x ]  =~=  -x
             #  = 3196577161300663808 ~= 3.2e+18
M_minExp     # = log(2) * .Machine$double.min.exp # ~= -708.396..
G_half       # = sqrt(pi) = Gamma( 1/2 )

## Functions :
all_mpfr(...)
any_mpfr(...)
logr(x, a)    # == log(x / (x + a)) -- but numerically smart; x &gt;= 0, a &gt; -x
modf(x)
okLongDouble(lambda = 999, verbose = 0L, tol = 1e-15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="numer-utils_+3A_...">...</code></td>
<td>
<p>numeric or <code>"mpfr"</code> numeric vectors.</p>
</td></tr>
<tr><td><code id="numer-utils_+3A_x">x</code>, <code id="numer-utils_+3A_a">a</code></td>
<td>
<p>number-like, not negative, now may be vectors of
<code>length(.) &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="numer-utils_+3A_lambda">lambda</code></td>
<td>
<p>a number, typically in the order of 500&ndash;10'000.</p>
</td></tr>
<tr><td><code id="numer-utils_+3A_verbose">verbose</code></td>
<td>
<p>a non-negative integer, if not zero,
<code>okLongDouble()</code> prints the intermediate long double
computations' results.</p>
</td></tr>
<tr><td><code id="numer-utils_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance used to determine the accuracy required
for near equality in <code>okLongDouble()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>all_mpfr()</code>,</dt><dd></dd>
<dt><code>all_mpfr()</code> :</dt><dd><p>test if <code><a href="base.html#topic+all">all</a></code> or
<code><a href="base.html#topic+any">any</a></code> of their arguments or of class <code>"mpfr"</code> (from
package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>).  The arguments are evaluated only until
the result is determined, see the example.</p>
</dd>
<dt><code>logr()</code></dt><dd><p>computes <code class="reqn">\log( x / (x+a) )</code> in a numerically
stable way.</p>
</dd>


</dl>



<h3>Value</h3>

<p>The numeric constant in the first case; a numeric (or &quot;mpfr&quot;) vector of
appropriate size in the 2nd case.
</p>
<p><code>okLongDouble()</code> returns a <code><a href="base.html#topic+logical">logical</a></code>,
<code><a href="base.html#topic+TRUE">TRUE</a></code> iff the long double arithmetic with <code>expl()</code> and
<code>logl()</code> seems to work accurately
and consistently for <code>exp(-lambda)</code> and <code>log(lambda)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+.Machine">.Machine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(Ms &lt;- ls("package:DPQ", pattern = "^M"))
lapply(Ms, function(nm) { cat(nm,": "); print(get(nm)) }) -&gt; .tmp

logr(1:3, a=1e-10)

okLongDouble(verbose=TRUE) # verbose: show (C-level) computations
## typically TRUE, but not e.g. in a valgrinded R-devel of Oct.2019
## Here is typically the "boundary":
rr &lt;- try(uniroot(function(x) okLongDouble(x) - 1/2,
              c(11350, 11400), tol=1e-7, extendInt = "yes"))
str(rr, digits=9) ## seems somewhat platform dependent: now see
## $ root      : num 11376.563
## $ estim.prec: num 9.313e-08
## $ iter      : int 29

set.seed(2021); x &lt;- runif(100, -7,7)
mx &lt;- modf(x)
with(mx, head( cbind(x, i=mx$i, fr=mx$fr) )) # showing the first cases
with(mx, stopifnot(   x == fr + i,
                      i == trunc(x),
               sign(fr) == sign(x)))
</code></pre>

<hr>
<h2 id='p1l1'>Numerically Stable p1l1(t) = (t+1)*log(1+t) - t</h2><span id='topic+p1l1'></span><span id='topic+p1l1.'></span><span id='topic+p1l1p'></span><span id='topic+p1l1ser'></span><span id='topic+.p1l1ser'></span>

<h3>Description</h3>

<p>The binomial deviance function <code><a href="#topic+bd0">bd0</a>(x,M)</code> can mathematically
be re-written as <code class="reqn">bd0(x,M) = M * p1l1((x-M)/M)</code> where we look into providing
numerically stable formula for <code class="reqn">p1l1(t)</code> as its mathematical formula
<code class="reqn">p1l1(t) = (t+1)\log(1+t) - t</code>
suffers from cancellation for small <code class="reqn">|t|</code>, even when
<code><a href="base.html#topic+log1p">log1p</a>(t)</code> is used instead of <code>log(1+t)</code>.
</p>
<p>Using a hybrid implementation, <code>p1l1()</code> uses a direct formula, now
the stable one in <code>p1l1p()</code>, for <code class="reqn">\left| t \right| &gt; c</code>
and a series approximation for <code class="reqn">\left|t\right| \le c</code> for
some <code class="reqn">c</code>.
</p>
<p>NB:  The re-expression <code><a href="#topic+log1pmx">log1pmx</a>()</code> is almost perfect; it
fixes the cancellation problem entirely (and exposes the fact that
<code><a href="#topic+log1pmx">log1pmx</a>()</code>'s internal cutoff seems sub optimal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
 p1l1p  (t, ...)
 p1l1.  (t)
 p1l1   (t,    F = t^2/2)
 p1l1ser(t, k, F = t^2/2)
.p1l1ser(t, k, F = t^2/2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p1l1_+3A_t">t</code></td>
<td>
<p>numeric a-like vector (&quot;mpfr&quot; included), larger (or equal) to -1.</p>
</td></tr>
<tr><td><code id="p1l1_+3A_...">...</code></td>
<td>
<p>optional (tuning) arguments, passed to <code><a href="#topic+log1pmx">log1pmx</a>()</code>.</p>
</td></tr>
<tr><td><code id="p1l1_+3A_k">k</code></td>
<td>
<p>small positive integer, the number of terms to use in the Taylor
series approximation <code>p1l1ser(t,k)</code> of <code>p1l1(t)</code>.</p>
</td></tr>
<tr><td><code id="p1l1_+3A_f">F</code></td>
<td>
<p>numeric vector of multiplication <b>f</b>actor; <em>must</em> be
<code>t^2/2</code> for the <code>p1l1()</code> function, but can be modified,
e.g. in more direct <code>bd0()</code> computations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>for now see in <code><a href="#topic+bd0">bd0</a>()</code>.
</p>


<h3>Value</h3>

<p>numeric vector &ldquo;as&rdquo; <code>t</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+bd0">bd0</a></code>; our package vignette <em>log1pmx, bd0, stirlerr - Probability Computations in R</em>.
<code><a href="stats.html#topic+dbinom">dbinom</a></code> the latter for the C.Loader(2000) reference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>t &lt;- seq(-1, 4, by=1/64)
plot(t, p1l1ser(t, 1), type="l")
lines(t, p1l1.(t), lwd=5, col=adjustcolor(1, 1/2)) # direct formula
for(k in 2:6) lines(t, p1l1ser(t, k), col=k)

## zoom in
t &lt;- 2^seq(-59,-1, by=1/4)
t &lt;- c(-rev(t), 0, t)
stopifnot(!is.unsorted(t))
k.s &lt;- 1:12; names(k.s) &lt;- paste0("k=", 1:12)

## True function values: use Rmpfr with 256 bits precision: ---
### eventually move this to ../tests/ &amp; ../vignettes/log1pmx-etc.Rnw
#### FIXME: eventually replace with  if(requireNamespace("Rmpfr")){ ......}
#### =====
if((needRmpfr &lt;- is.na(match("Rmpfr", (srch0 &lt;- search())))))
    require("Rmpfr")
p1l1.T &lt;- p1l1.(mpfr(t, 256)) # "true" values
p1l1.n &lt;- asNumeric(p1l1.T)
all.equal(sapply(k.s, function(k)  p1l1ser(t,k)) -&gt; m.p1l1,
          sapply(k.s, function(k) .p1l1ser(t,k)) -&gt; m.p1l., tolerance = 0)
p1tab &lt;-
    cbind(b1 = bd0(t+1, 1),
          b.10 = bd0(10*t+10,10)/10,
          dirct = p1l1.(t),
          p1l1p = p1l1p(t),
          p1l1  = p1l1 (t),
          sapply(k.s, function(k) p1l1ser(t,k)))
matplot(t, p1tab, type="l", ylab = "p1l1*(t)")
## (absolute) error:
##' legend for matplot()
mpLeg &lt;- function(leg = colnames(p1tab), xy = "top", col=1:6, lty=1:5, lwd=1,
                  pch = c(1L:9L, 0L, letters, LETTERS)[seq_along(leg)], ...)
    legend(xy, legend=leg, col=col, lty=lty, lwd=lwd, pch=pch, ncol=3, ...)

titAbs &lt;- "Absolute errors of p1l1(t) approximations"
matplot(t, asNumeric(p1tab - p1l1.T), type="o", main=titAbs); mpLeg()
i &lt;- abs(t) &lt;= 1/10 ## zoom in a bit
matplot(t[i], abs(asNumeric((p1tab - p1l1.T)[i,])), type="o", log="y",
        main=titAbs, ylim = c(1e-18, 0.003)); mpLeg()
## Relative Error
titR &lt;- "|Relative error| of p1l1(t) approximations"
matplot(t[i], abs(asNumeric((p1tab/p1l1.T - 1)[i,])), type="o", log="y",
        ylim = c(1e-18, 2^-10), main=titR)
mpLeg(xy="topright", bg= adjustcolor("gray80", 4/5))
i &lt;- abs(t) &lt;= 2^-10 # zoom in more
matplot(t[i], abs(asNumeric((p1tab/p1l1.T - 1)[i,])), type="o", log="y",
        ylim = c(1e-18, 1e-9))
mpLeg(xy="topright", bg= adjustcolor("gray80", 4/5))


## Correct number of digits
corDig &lt;- asNumeric(-log10(abs(p1tab/p1l1.T - 1)))
cbind(t, round(corDig, 1))# correct number of digits

matplot(t, corDig, type="o", ylim = c(1,17))
(cN &lt;- colnames(corDig))
legend(-.5, 14, cN, col=1:6, lty=1:5, pch = c(1L:9L, 0L, letters), ncol=2)

## plot() function &gt;&gt;&gt;&gt; using global (t, corDig) &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
p.relEr &lt;- function(i, ylim = c(11,17), type = "o",
                    leg.pos = "left", inset=1/128,
                    main = sprintf(
                        "Correct #{Digits} in p1l1() approx., notably Taylor(k=1 .. %d)",
                                   max(k.s)))
{
    if((neg &lt;- all(t[i] &lt; 0)))
        t  &lt;- -t
    stopifnot(all(t[i] &gt; 0), length(ylim) == 2) # as we use log="x"
    matplot(t[i], corDig[i,], type=type, ylim=ylim, log="x", xlab = quote(t), xaxt="n",
            main=main)
    legend(leg.pos, cN, col=1:6, lty=1:5, pch = c(1L:9L, 0L, letters), ncol=2,
           bg=adjustcolor("gray90", 7/8), inset=inset)
    t.epsC &lt;- -log10(c(1,2,4)* .Machine$double.eps)
    axis(2, at=t.epsC, labels = expression(epsilon[C], 2*epsilon[C], 4*epsilon[C]),
         las=2, col=2, line=1)
    tenRs &lt;- function(t) floor(log10(min(t))) : ceiling(log10(max(t)))
    tenE &lt;- tenRs(t[i])
    tE &lt;- 10^tenE
    abline (h = t.epsC,
            v = tE, lty=3, col=adjustcolor("gray",.8), lwd=2)
    AX &lt;- if(requireNamespace("sfsmisc")) sfsmisc::eaxis else axis
    AX(1, at= tE, labels = as.expression(
                      lapply(tenE,
                             if(neg)
                                 function(e) substitute(-10^{E}, list(E = e+0))
                             else
                                 function(e) substitute( 10^{E}, list(E = e+0)))))
}

p.relEr(t &gt; 0, ylim = c(1,17))
p.relEr(t &gt; 0) # full positive range
p.relEr(t &lt; 0) # full negative range
if(FALSE) {## (actually less informative):
 p.relEr(i = 0 &lt; t &amp; t &lt; .01)  ## positive small t
 p.relEr(i = -.1 &lt; t &amp; t &lt; 0) ## negative small t
}

## Find approximate formulas for accuracy of k=k*  approximation
d.corrD &lt;- cbind(t=t, as.data.frame(corDig))
names(d.corrD) &lt;- sub("k=", "nC_",  names(d.corrD))

fmod &lt;- function(k, data, cut.y.at = -log10(2 * .Machine$double.eps),
                 good.y = -log10(.Machine$double.eps), # ~ 15.654
                 verbose=FALSE) {
    varNm &lt;- paste0("nC_",k)
    stopifnot(is.numeric(y &lt;- get(varNm, data, inherits=FALSE)),
              is.numeric(t &lt;- data$t))# '$' works for data.frame, list, environment
    i &lt;- 3 &lt;= y &amp; y &lt;= cut.y.at
    i.pos &lt;- i &amp; t &gt; 0
    i.neg &lt;- i &amp; t &lt; 0
    if(verbose) cat(sprintf("k=%d &gt;&gt; y &lt;= %g ==&gt; #{pos. t} = %d ;  #{neg. t} = %d\n",
                            k, cut.y.at, sum(i.pos), sum(i.neg)))
    nCoefLm &lt;- function(x,y) `names&lt;-`(.lm.fit(x=x, y=y)$coeff, c("int", "slp"))
    nC.t &lt;- function(x,y) { cf &lt;- nCoefLm(x,y); c(cf, t.0 = exp((good.y - cf[[1]])/cf[[2]])) }
    cbind(pos = nC.t(cbind(1, log( t[i.pos])), y[i.pos]),
          neg = nC.t(cbind(1, log(-t[i.neg])), y[i.neg]))
}
rr &lt;- sapply(k.s, fmod, data=d.corrD, verbose=TRUE, simplify="array")
stopifnot(rr["slp",,] &lt; 0) # all slopes are negative (important!)
matplot(k.s, t(rr["slp",,]), type="o", xlab = quote(k), ylab = quote(slope[k]))
## fantastcally close to linear in k
## The numbers, nicely arranged
ftable(aperm(rr, c(3,2,1)))
signif(t(rr["t.0",,]),3) # ==&gt; Should be boundaries for the hybrid p1l1()
##           pos      neg
## k=1  6.60e-16 6.69e-16
## k=2  3.65e-08 3.65e-08
## k=3  1.30e-05 1.32e-05
## k=4  2.39e-04 2.42e-04
## k=5  1.35e-03 1.38e-03
## k=6  4.27e-03 4.34e-03
## k=7  9.60e-03 9.78e-03
## k=8  1.78e-02 1.80e-02
## k=9  2.85e-02 2.85e-02
## k=10 4.13e-02 4.14e-02
## k=11 5.62e-02 5.64e-02
## k=12 7.24e-02 7.18e-02

###------------- Well,  p1l1p()  is really basically good enough ... with a small exception:
rErr1k &lt;- curve(asNumeric(p1l1p(x) / p1l1.(mpfr(x, 4096)) - 1), -.999, .999,
                n = 4000, col=2, lwd=2)
abline(h = c(-8,-4,-2:2,4,8)* 2^-52, lty=2, col=adjustcolor("gray20", 1/4))
## well, have a "spike" at around -0.8 -- why?

plot(abs(y) ~ x, data = rErr1k, ylim = c(4e-17, max(abs(y))),
     ylab = expression(abs(hat(p)/p - 1)),
     main = "p1l1p(x) -- Relative Error wrt mpfr(*. 4096) [log]",
     col=2, lwd=1.5, type = "b", cex=1/2, log="y", yaxt="n")
sfsmisc::eaxis(2)
eps124 &lt;-  c(1, 2,4,8)* 2^-52
abline(h = eps124, lwd=c(3,1,1,1), lty=c(1,2,2,2), col=adjustcolor("gray20", 1/4))
axLab &lt;- expression(epsilon[c], 2*epsilon[c], 4*epsilon[c], 8*epsilon[c])
axis(4, at = eps124, labels = axLab, col="gray20", las=1)
abline(v= -.791, lty=3, lwd=2, col="blue4") # -.789  from visual ..
##--&gt; The "error" is in log1pmx() which has cutoff minLog1Value = -0.79149064
##--&gt; which is clearly not optimal, at least not for computing p1l1p()

d &lt;- 1/2048; x &lt;- seq(-1+d, 1, by=d)
p1l1Xct &lt;- p1l1.(mpfr(x, 4096))
rEx.5 &lt;- asNumeric(p1l1p(x, minL1 = -0.5) / p1l1Xct - 1)
lines(x, abs(rEx.5), lwd=2.5, col=adjustcolor(4, 1/2)); abline(v=-.5, lty=2,col=4)
rEx.25 &lt;- asNumeric(p1l1p(x, minL1 = -0.25) / p1l1Xct - 1)
lines(x, abs(rEx.25), lwd=3.5, col=adjustcolor(6, 1/2)); abline(v=-.25, lty=2,col=6)
lines(lowess(x, abs(rEx.5),  f=1/20), col=adjustcolor(4,offset=rep(1,4)/3), lwd=3)

lines(lowess(x, abs(rEx.25), f=1/20), col=adjustcolor(6,offset=rep(1,4)/3), lwd=
3)

rEx.4 &lt;- asNumeric(p1l1p(x, tol_logcf=1e-15, minL1 = -0.4) / p1l1Xct - 1)
lines(x, abs(rEx.4), lwd=5.5, col=adjustcolor("brown", 1/2)); abline(v=-.25, lty=2,col="brown")

if(needRmpfr &amp;&amp; isNamespaceLoaded("Rmpfr"))
    detach("package:Rmpfr")
</code></pre>

<hr>
<h2 id='pbetaRv1'>Pure R Implementation of Old pbeta()</h2><span id='topic+pbetaRv1'></span>

<h3>Description</h3>

<p><code>pbetaRv1()</code> is an implementation of the original
(&ldquo;version 1&rdquo; <code><a href="stats.html#topic+pbeta">pbeta</a>()</code> function in <span class="rlang"><b>R</b></span> (versions &lt;=
2.2.x), before we started using TOMS 708 <code>bratio()</code> instead, see
the current <code><a href="stats.html#topic+pbeta">pbeta</a></code> help page also for references.
</p>
<p><code>pbetaRv1()</code> is basically a manual translation from C to <span class="rlang"><b>R</b></span> of the
underlying <code>pbeta_raw()</code> C function, see in <span class="rlang"><b>R</b></span>'s source tree at
<a href="https://svn.r-project.org/R/branches/R-2-2-patches/src/nmath/pbeta.c">https://svn.r-project.org/R/branches/R-2-2-patches/src/nmath/pbeta.c</a>
</p>
<p>For consistency within <span class="rlang"><b>R</b></span>, we are using <span class="rlang"><b>R</b></span>'s argument names
<code>(q, shape1, shape2)</code> instead of C code's
<code>(x, pin,    qin   )</code>.
</p>
<p>It is only for the <em>central</em> beta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbetaRv1(q, shape1, shape2, lower.tail = TRUE,
         eps = 0.5 * .Machine$double.eps,
         sml = .Machine$double.xmin,
         verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pbetaRv1_+3A_q">q</code>, <code id="pbetaRv1_+3A_shape1">shape1</code>, <code id="pbetaRv1_+3A_shape2">shape2</code></td>
<td>
<p>non-negative numbers, q in <code class="reqn">[0,1]</code>, see
<code><a href="stats.html#topic+pbeta">pbeta</a></code>.</p>
</td></tr>
<tr><td><code id="pbetaRv1_+3A_lower.tail">lower.tail</code></td>
<td>
<p>indicating if <code class="reqn">F(q; *)</code> should be returned or
the upper tail probability <code class="reqn">1 - F(q)</code>.</p>
</td></tr>
<tr><td><code id="pbetaRv1_+3A_eps">eps</code></td>
<td>
<p>the tolerance used to determine congerence.  <code>eps</code> has
been hard coded in C code to <code>0.5 * .Machine$double.eps</code> which is
equal to <code class="reqn">2^{-53}</code> or <code>1.110223e-16</code>.</p>
</td></tr>
<tr><td><code id="pbetaRv1_+3A_sml">sml</code></td>
<td>
<p>the smallest positive number on the typical platform.  The
default <code>.Machine$double.xmin</code> is hard coded in the C code (as
<code>DBL_MIN</code>), and this is equal to <code class="reqn">2^{-1022}</code> or
<code>2.225074e-308</code> on all current platforms.</p>
</td></tr>
<tr><td><code id="pbetaRv1_+3A_verbose">verbose</code></td>
<td>
<p>integer indicating the amount of verbosity of
diagnostic output, <code>0</code> means no output, <code>1</code> more, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number.
</p>


<h3>Note</h3>

<p>The C code contains <br /> <em>
This routine is a translation into C of a Fortran subroutine
by W. Fullerton of Los Alamos Scientific Laboratory.</em>
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>(From the C code:)
</p>
<p>Nancy E. Bosten and E.L. Battiste (1974).
Remark on Algorithm 179 (S14): Incomplete Beta Ratio.
<em>Communications of the ACM</em>, <b>17</b>(3), 156&ndash;7.

</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pbeta">pbeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>all.equal(pbetaRv1(1/4, 2, 3),
          pbeta   (1/4, 2, 3))
set.seed(101)

N &lt;- 1000
x &lt;- sample.int(7, N, replace=TRUE) / 8
a &lt;-   rlnorm(N)
b &lt;- 5*rlnorm(N)
pbt &lt;- pbeta(x, a, b)
for(i in 1:N) {
   stopifnot(all.equal(pbetaRv1(x[i], a[i], b[i]), pbt[i]))
   cat(".", if(i %% 20 == 0) paste0(i, "\n"))
}

</code></pre>

<hr>
<h2 id='phyperAllBin'>Compute Hypergeometric Probabilities via Binomial Approximations</h2><span id='topic+phyperAllBin'></span><span id='topic+phyperAllBinM'></span><span id='topic+.suppHyper'></span>

<h3>Description</h3>

<p>Simple utilities for ease of comparison of the different
<code><a href="stats.html#topic+phyper">phyper</a></code> approximation in package <span class="pkg">DPQ</span>:
</p>

<ul>
<li> <p><code>phyperAllBinM()</code> computes all four Molenaar binomial approximations
to the hypergeometric cumulative distribution function <code><a href="stats.html#topic+phyper">phyper</a>()</code>.
</p>
</li>
<li> <p><code>phyperAllBin()</code> computes Molenaar's four and additionally the other
four
<code><a href="#topic+phyperBin.1">phyperBin.1</a>()</code>, <code>*.2</code>, <code>*.3</code>, and <code>*.4</code>.
</p>
</li>
<li> <p><code>.suppHyper()</code>, <em>supp</em>ort of the Hyperbolic, is a
simple 1-liner, providing all sensible integer values for the first
argument <code>q</code> (or also <code>x</code>) of the hyperbolic probability
functions (<code><a href="stats.html#topic+dhyper">dhyper</a>()</code> and <code><a href="stats.html#topic+phyper">phyper</a>()</code>), and their
approximations (here in <span class="pkg">DPQ</span>).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>phyperAllBin (m, n, k, q = .suppHyper(m, n, k), lower.tail = TRUE, log.p = FALSE)
phyperAllBinM(m, n, k, q = .suppHyper(m, n, k), lower.tail = TRUE, log.p = FALSE)
.suppHyper(m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperAllBin_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperAllBin_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperAllBin_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in <code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phyperAllBin_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.  The default, <code>.suppHyper(m, n, k)</code> provides the full
(finite) support.</p>
</td></tr>
<tr><td><code id="phyperAllBin_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="phyperAllBin_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the <code>phyperAllBin*()</code> functions return
a numeric <code><a href="base.html#topic+matrix">matrix</a></code>, with each column a different
approximation to <code><a href="stats.html#topic+phyper">phyper</a>(m,n,k,q, lower.tail, log.p)</code>.
</p>
<p>Note that the columns of <code>phyperAllBinM()</code> are a <em>subset</em> of
those from <code>phyperAllBin()</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>See those in <code><a href="#topic+phyperBinMolenaar">phyperBinMolenaar</a></code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+phyperBin.1">phyperBin.1</a></code> etc, and
<code><a href="#topic+phyperBinMolenaar">phyperBinMolenaar</a></code>.
</p>
<p><code><a href="stats.html#topic+phyper">phyper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>.suppHyper # very simple:
stopifnot(identical(.suppHyper, ignore.environment = TRUE,
         function (m, n, k) max(0, k-n):min(k, m)))

phBall &lt;- phyperAllBin (5,15, 7)
phBalM &lt;- phyperAllBinM(5,15, 7)
stopifnot(identical( ## indeed, ph...AllBinM() gives a *subset* of ph...AllBin():
            phBall[, colnames(phBalM)] ,
            phBalM)
         , .suppHyper(5, 15, 7) == 0:5
)

round(phBall, 4)
cbind(q = 0:5, round(-log10(abs(1 - phBall / phyper(0:5, 5,15,7))),  digits=2))

require(sfsmisc)## --&gt;  relErrV() {and eaxis()}: 
qq &lt;-    .suppHyper(20, 47, 31)
phA &lt;- phyperAllBin(20, 47, 31)
rE &lt;- relErrV(target = phyper(qq, 20,47,31), phA)
signif(cbind(qq, rE), 4)
## Relative approximation error [ log scaled ] :
matplot(qq, abs(rE), type="b", log="y", yaxt="n")
eaxis(2)
## ---&gt; approximations useful only "on the right", aka the right tail
</code></pre>

<hr>
<h2 id='phyperApprAS152'>Normal Approximation to cumulative Hyperbolic Distribution &ndash; AS 152</h2><span id='topic+phyperApprAS152'></span>

<h3>Description</h3>

<p>Compute the normal approximation (via <code><a href="stats.html#topic+pnorm">pnorm</a>(.)</code> from AS 152
to the cumulative hyperbolic distribution function <code><a href="stats.html#topic+phyper">phyper</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperApprAS152(q, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperApprAS152_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperApprAS152_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperApprAS152_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperApprAS152_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector of the same length (etc) as <code>q</code>.
</p>


<h3>Note</h3>


<p>I have Fortran (and C code translated from Fortran) which says
</p>
<pre>
   ALGORITHM AS R77  APPL. STATIST. (1989), VOL.38, NO.1
   Replaces AS 59 and AS 152
   Incorporates AS R86 from vol.40(2)
 </pre>


<h3>Author(s)</h3>

<p>Martin Maechler, 19 Apr 1999</p>


<h3>References</h3>

<p>Lund, Richard E. (1980)
Algorithm AS 152: Cumulative Hypergeometric Probabilities.
<em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em>, <b>29</b>(2), 221&ndash;223.
<a href="https://doi.org/10.2307/2986315">doi:10.2307/2986315</a>
</p>
<p>Shea, B. (1989)
Remark AS R77: A Remark on Algorithm AS 152: Cumulative Hypergeometric Probabilities.
<em>JRSS C (Applied Statistics)</em>, <b>38</b>(1), 199&ndash;204.
<a href="https://doi.org/10.2307/2347696">doi:10.2307/2347696</a>
</p>
<p>Berger, R. (1991)
Algorithm AS R86: A Remark on Algorithm AS 152: Cumulative Hypergeometric Probabilities.
<em>JRSS C (Applied Statistics)</em>, <b>40</b>(2), 374&ndash;375.
<a href="https://doi.org/10.2307/2347606">doi:10.2307/2347606</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##---- Should be DIRECTLY executable !! ----
##-- ==&gt;  Define data, use random,
##--	or do  help(data=index)  for the standard data sets.

## The function is currently defined as
function (q, m, n, k)
{
    kk &lt;- n
    nn &lt;- m
    mm &lt;- m + n
    ll &lt;- q
    mean &lt;- kk * nn/mm
    sig &lt;- sqrt(mean * (mm - nn)/mm * (mm - kk)/(mm - 1))
    pnorm(ll + 1/2, mean = mean, sd = sig)
  }
</code></pre>

<hr>
<h2 id='phyperBin'>HyperGeometric Distribution via Approximate Binomial Distribution</h2><span id='topic+phyperBin.1'></span><span id='topic+phyperBin.2'></span><span id='topic+phyperBin.3'></span><span id='topic+phyperBin.4'></span>

<h3>Description</h3>


<p>Compute hypergeometric cumulative probabilities via (good) binomial
distribution approximations.
The arguments of these functions are <em>exactly</em> those of <span class="rlang"><b>R</b></span>'s own
<code><a href="stats.html#topic+phyper">phyper</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperBin.1(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBin.2(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBin.3(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBin.4(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperBin_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperBin_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperBin_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperBin_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in <code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phyperBin_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="phyperBin_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TODO
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector, with the length the maximum of the
lengths of <code>q, m, n, k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>,
<code><a href="stats.html#topic+pbinom">pbinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The 1st function is
function (q, m, n, k, lower.tail = TRUE, log.p = FALSE)
  pbinom(q, size = k, prob = m/(m + n), lower.tail = lower.tail,
         log.p = log.p)
</code></pre>

<hr>
<h2 id='phyperBinMolenaar'>HyperGeometric Distribution via Molenaar's Binomial Approximation</h2><span id='topic+phyperBinMolenaar'></span><span id='topic+phyperBinMolenaar.1'></span><span id='topic+phyperBinMolenaar.2'></span><span id='topic+phyperBinMolenaar.3'></span><span id='topic+phyperBinMolenaar.4'></span>

<h3>Description</h3>


<p>Compute hypergeometric cumulative probabilities via Molenaar's binomial
approximations.
The arguments of these functions are <em>exactly</em> those of <span class="rlang"><b>R</b></span>'s own
<code><a href="stats.html#topic+phyper">phyper</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperBinMolenaar.1(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBinMolenaar.2(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBinMolenaar.3(q, m, n, k, lower.tail = TRUE, log.p = FALSE)
phyperBinMolenaar.4(q, m, n, k, lower.tail = TRUE, log.p = FALSE)

phyperBinMolenaar  (q, m, n, k, lower.tail = TRUE, log.p = FALSE) # Deprecated !
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperBinMolenaar_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperBinMolenaar_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperBinMolenaar_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperBinMolenaar_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phyperBinMolenaar_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="phyperBinMolenaar_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Molenaar(1970), as cited in Johnson et al (1992), proposed
<code>phyperBinMolenaar.1()</code>;
the other three are just using the mathematical symmetries of the
hyperbolic distribution, swapping <code class="reqn">k</code> and <code class="reqn">m</code>, and
using <code>lower.tail = TRUE</code> or <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector, with the length the maximum of the
lengths of <code>q, m, n, k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>


<p>Johnson, N.L., Kotz, S. and Kemp, A.W. (1992)
Univariate Discrete Distributions, 2nd ed.; Wiley, <a href="https://doi.org/10.1002/bimj.4710360207">doi:10.1002/bimj.4710360207</a>.<br />
Chapter 6, mostly Section <em>5  Approximations and Bounds</em>, p.256 ff
</p>
<p>Johnson, N.L., Kotz, S. and Kemp, A.W. (2005)
Univariate Discrete Distributions, 3rd ed.; Wiley; <a href="https://doi.org/10.1002/0471715816">doi:10.1002/0471715816</a>.<br />
Chapter 6, Section <em>6.5 Approximations and Bounds</em>, p.268 ff
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>, the hypergeometric distribution, and <span class="rlang"><b>R</b></span>'s own
&ldquo;exact&rdquo; computation.
<code><a href="stats.html#topic+pbinom">pbinom</a></code>, the binomial distribution functions.
</p>
<p>Our utility <code><a href="#topic+phyperAllBin">phyperAllBin</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The first function is simply
function (q, m, n, k, lower.tail = TRUE, log.p = FALSE)
  pbinom(q, size = k, prob = hyper2binomP(q, m, n, k), lower.tail = lower.tail,
        log.p = log.p)
</code></pre>

<hr>
<h2 id='phyperIbeta'>Pearson's incomplete Beta Approximation to the Hyperbolic Distribution</h2><span id='topic+phyperIbeta'></span>

<h3>Description</h3>

<p>Pearson's incomplete Beta function approximation to the cumulative
hyperbolic distribution function <code><a href="stats.html#topic+phyper">phyper</a>(.)</code>.
</p>
<p>Note that in <span class="rlang"><b>R</b></span>, <code><a href="stats.html#topic+pbeta">pbeta</a>()</code> provides a version of the
incomplete Beta function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperIbeta(q, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperIbeta_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperIbeta_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperIbeta_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperIbeta_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector &ldquo;like&rdquo; <code>q</code> with values approximately equal
to <code><a href="stats.html#topic+phyper">phyper</a>(q,m,n,k)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, Kotz &amp; Kemp (1992):  (6.90), p.260 &ndash;&gt;
Bol'shev (1964)
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as
function (q, m, n, k)
{
    Np &lt;- m
    N &lt;- n + m
    n &lt;- k
    x &lt;- q
    p &lt;- Np/N
    np &lt;- n * p
    xi &lt;- (n + Np - 1 - 2 * np)/(N - 2)
    d.c &lt;- (N - n) * (1 - p) + np - 1
    cc &lt;- n * (n - 1) * p * (Np - 1)/((N - 1) * d.c)
    lam &lt;- (N - 2)^2 * np * (N - n) * (1 - p)/((N - 1) * d.c *
        (n + Np - 1 - 2 * np))
    pbeta(1 - xi, lam - x + cc, x - cc + 1)
  }
</code></pre>

<hr>
<h2 id='phyperMolenaar'>Molenaar's Normal Approximations to the Hypergeometric Distribution</h2><span id='topic+phyper1molenaar'></span><span id='topic+phyper2molenaar'></span>

<h3>Description</h3>

<p>Compute Molenaar's two normal approximations to the (cumulative
hypergeometric distribution <code><a href="stats.html#topic+phyper">phyper</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyper1molenaar(q, m, n, k)
phyper2molenaar(q, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperMolenaar_+3A_q">q</code></td>
<td>
<p>(vector of) the number of white balls drawn without replacement
from an urn which contains both black and white balls.</p>
</td></tr>
<tr><td><code id="phyperMolenaar_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperMolenaar_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperMolenaar_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence in <code class="reqn">0,1,\dots,m+n</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both approximations are from page 261 of Johnson, Kotz &amp; Kemp (1992).
<code>phyper1molenaar</code> is formula <code class="reqn">(6.91)</code>, and
<code>phyper2molenaar</code> is formula <code class="reqn">(6.92)</code>.
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector, with the length the maximum of the
lengths of <code>q, m, n, k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, Kotz &amp; Kemp (1992): p.261
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>,
<code><a href="stats.html#topic+pnorm">pnorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## TODO -- maybe see  ../tests/hyper-dist-ex.R
</code></pre>

<hr>
<h2 id='phyperPeizer'>Peizer's Normal Approximation to the Cumulative Hyperbolic</h2><span id='topic+phyperPeizer'></span>

<h3>Description</h3>

<p>Compute Peizer's extremely good normal approximation to the cumulative
hyperbolic distribution.
</p>
<p>This implementation corrects a typo in the reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperPeizer(q, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperPeizer_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperPeizer_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperPeizer_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperPeizer_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector, with the length the maximum of the
lengths of <code>q, m, n, k</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, Kotz &amp; Kemp (1992):  (6.93) &amp; (6.94), p.261  <em>CORRECTED</em> by M.M.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is defined as

phyperPeizer &lt;- function(q, m, n, k)
{
  ## Purpose: Peizer's extremely good Normal Approx. to cumulative Hyperbolic
  ##  Johnson, Kotz &amp; Kemp (1992):  (6.93) &amp; (6.94), p.261 __CORRECTED__
  ## ----------------------------------------------------------------------
  Np &lt;- m; N &lt;- n + m; n &lt;- k; x &lt;- q
  ## (6.94) -- in proper order!
  nn &lt;- Np			;  n. &lt;- Np     + 1/6
  mm &lt;- N - Np                  ;  m. &lt;- N - Np + 1/6
  r &lt;- n                        ;  r. &lt;- n      + 1/6
  s &lt;- N - n                    ;  s. &lt;- N - n  + 1/6
                                   N. &lt;- N      - 1/6
  A &lt;- x + 1/2                  ;  A. &lt;- x      + 2/3
  B &lt;- Np - x - 1/2             ;  B. &lt;- Np - x - 1/3
  C &lt;- n  - x - 1/2             ;  C. &lt;- n  - x - 1/3
  D &lt;- N - Np - n + x + 1/2     ;  D. &lt;- N - Np - n + x + 2/3

  n &lt;- nn
  m &lt;- mm
  ## After (6.93):
  L &lt;-
    A * log((A*N)/(n*r)) +
    B * log((B*N)/(n*s)) +
    C * log((C*N)/(m*r)) +
    D * log((D*N)/(m*s))
  ## (6.93) :
  pnorm((A.*D. - B.*C.) / abs(A*D - B*C) *
        sqrt(2*L* (m* n* r* s* N.)/
                  (m.*n.*r.*s.*N )))
  # The book wrongly has an extra "2*" before `m* ' (after "2*L* (" ) above
}
</code></pre>

<hr>
<h2 id='phyperR'><span class="rlang"><b>R</b></span>-only version of <span class="rlang"><b>R</b></span>'s original phyper() algorithm</h2><span id='topic+phyperR'></span>

<h3>Description</h3>

<p>An <span class="rlang"><b>R</b></span> version of the first <code>phyper()</code> algorithm in <span class="rlang"><b>R</b></span>, which was
used up to svn rev <code>30227</code> on 2004-07-09.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
phyperR(q, m, n, k, lower.tail=TRUE, log.p=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperR_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.</p>
</td></tr>
<tr><td><code id="phyperR_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperR_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperR_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in <code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phyperR_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="phyperR_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector similar to <code>phyper(q, m, n, k)</code>.
</p>


<h3>Note</h3>

<p>The original argument list in <code>C</code> was <code>(x, NR, NB, n)</code> where
there were <em>red</em> and <em>black</em> balls in the urn.
</p>
<p>Note that we have <em>vectorized</em> a translation to <span class="rlang"><b>R</b></span> of the original C
code.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code> and our <code><a href="#topic+phyperR2">phyperR2</a>()</code> for the pure <span class="rlang"><b>R</b></span>
version of the newer (Welinder) <code>phyper()</code> algorithm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- 9:12; n &lt;- 7:10; k &lt;- 10
x &lt;- 0:(k+1) # length 12
## confirmation that recycling + lower.tail, log.p now work:
for(lg in c(FALSE,TRUE))
  for(lt in c(FALSE, TRUE)) {
    cat("(lower.tail = ", lt, " -- log = ", lg,"):\n", sep="")
    withAutoprint({
      (rr &lt;-
           cbind(x, m, n, k, # recycling (to 12 rows)
                 ph  = phyper (x, m, n, k, lower.tail=lt, log.p=lg),
                 phR = phyperR(x, m, n, k, lower.tail=lt, log.p=lg)))
      all.equal(rr[,"ph"], rr[,"phR"], tol = 0)
      ## saw   4.706e-15 1.742e-15 7.002e-12 1.086e-15  [x86_64 Lnx]
      stopifnot(all.equal(rr[,"ph"], rr[,"phR"],
                          tol = if(lg &amp;&amp; !lt) 2e-11 else 2e-14))
    })
  }

</code></pre>

<hr>
<h2 id='phyperR2'>Pure R version of R's C level phyper()</h2><span id='topic+phyperR2'></span><span id='topic+pdhyper'></span>

<h3>Description</h3>

<p>Use pure <span class="rlang"><b>R</b></span> functions to compute (less efficiently and usually even less
accurately) hypergeometric (point) probabilities with the same
&quot;Welinder&quot;-algorithm as <span class="rlang"><b>R</b></span>'s C level code has been doing since 2004.
</p>
<p>Apart from boundary cases, each <code>phyperR2()</code> call uses one
corresponding <code>pdhyper()</code> call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phyperR2(q, m, n, k, lower.tail = TRUE, log.p = FALSE, ...)
pdhyper (q, m, n, k,                    log.p = FALSE,
         epsC = .Machine$double.eps, verbose = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phyperR2_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.
</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in <code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_...">...</code></td>
<td>
<p>further arguments, passed to <code>pdhyper()</code>.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_epsc">epsC</code></td>
<td>
<p>a non-negative number, the computer epsilon to be used;
effectively a relative convergence tolerance for the <code>while()</code>
loop in <code>pdhyper()</code>.</p>
</td></tr>
<tr><td><code id="phyperR2_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if the <code>pdhyper()</code> calls,
typically one per <code>phyperR2()</code> call, should show how many terms
have been computed and summed up.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number (as <code>q</code>).
</p>

<dl>
<dt>pdhyper(q, m,n,k)</dt><dd><p>computes the ratio
<code>phyper(q, m,n,k) / dhyper(q, m,n,k)</code>
but without computing numerator or denominator explicitly.</p>
</dd>
<dt>phyperR2()</dt><dd><p>(in the non-boundary cases) then just computes the
product <code>dhyper(..) * pdhyper(..)</code>, of course &ldquo;modulo&rdquo;
<code>lower.tail</code> and <code>log.p</code> transformations.
</p>
<p>Consequently, it typically returns values very close to the corresponding
<span class="rlang"><b>R</b></span> <code>phyper(q, m,n,k, ..)</code> call.</p>
</dd>
</dl>



<h3>Note</h3>

<p>For now, all arguments of these functions must be of length <b>one</b>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, based on <span class="rlang"><b>R</b></span>'s C code originally provided by Morton
Welinder from the Gnumeric project, who thanks Ian Smith for ideas.
</p>


<h3>References</h3>

<p>Morten Welinder (2004)
phyper accuracy and efficiency;
R bug report <a href="https://bugs.R-project.org/show_bug.cgi?id=6772">PR#6772</a>; <a href="https://bugs.r-project.org/show_bug.cgi?id=6772">https://bugs.r-project.org/show_bug.cgi?id=6772</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+phyper">phyper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## same example as phyper()
m &lt;- 10; n &lt;- 7; k &lt;- 8
vapply(0:9, phyperR2, 0.1, m=m, n=n, k=k)  ==  phyper(0:9, m,n,k)
##  *all* TRUE (for 64b FC30)

## 'verbose=TRUE' to see the number of terms used:
vapply(0:9, phyperR2, 0.1, m=m, n=n, k=k,  verbose=TRUE)

## Larger arguments:
k &lt;- 100 ; x &lt;- .suppHyper(k,k,k)
ph  &lt;- phyper (x, k,k,k)
ph1 &lt;- phyperR(x, k,k,k) # ~ old R version
ph2 &lt;- vapply(x, phyperR2, 0.1, m=k, n=k, k=k)
cbind(x, ph, ph1, ph2, rE1 = 1-ph1/ph, rE = 1-ph2/ph)
stopifnot(abs(1 -ph2/ph) &lt; 8e-16) # 64bit FC30: see -2.22e-16 &lt;= rE &lt;= 3.33e-16

## Morten Welinder's example:
(p1R &lt;- phyperR (59, 150, 150, 60, lower.tail=FALSE))
## gave 6.372680161e-14 in "old R";, here -1.04361e-14 (worse!!)
(p1x &lt;-  dhyper ( 0, 150, 150, 60))# is 5.111204798e-22.
(p1N &lt;- phyperR2(59, 150, 150, 60, lower.tail=FALSE)) # .. "perfect"
(p1. &lt;- phyper  (59, 150, 150, 60, lower.tail=FALSE))# R's own
all.equal(p1x, p1N, tol=0) # on Lnx even perfectly
all.equal(p1x, p1., tol=0) # on Lnx even perfectly
</code></pre>

<hr>
<h2 id='phypers'>The Four (4) Symmetric 'phyper()' Calls</h2><span id='topic+phypers'></span>

<h3>Description</h3>

<p>Compute the four (4) symmetric <code><a href="stats.html#topic+phyper">phyper</a>()</code> calls which
mathematically would be identical but in practice typically slightly
differ numerically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phypers(m, n, k, q = .suppHyper(m, n, k), tol = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phypers_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="phypers_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="phypers_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
<tr><td><code id="phypers_+3A_q">q</code></td>
<td>
<p>vector of quantiles representing the number of white balls
drawn without replacement from an urn which contains both black and
white balls.  By default all &ldquo;non-trivial&rdquo; abscissa values
i.e., for which the mathematical value is strictly inside <code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="phypers_+3A_tol">tol</code></td>
<td>
<p>a non-negative number, the <code>tolerance</code> for the
<code><a href="base.html#topic+all.equal">all.equal</a>()</code> checks.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+list">list</a></code> with components
</p>
<table role = "presentation">
<tr><td><code>q</code></td>
<td>
<p>Description of 'comp1'</p>
</td></tr>
<tr><td><code>phyp</code></td>
<td>
<p>a numeric <code><a href="base.html#topic+matrix">matrix</a></code> of 4 columns with the 4
different calls to <code><a href="stats.html#topic+phyper">phyper</a>()</code> which are theoretically
equivalent because of mathematical symmetry.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson et al
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s  <code><a href="stats.html#topic+phyper">phyper</a></code>.  In package <a href="https://CRAN.R-project.org/package=DPQmpfr"><span class="pkg">DPQmpfr</span></a>,
<code><a href="DPQmpfr.html#topic+phyperQ">phyperQ</a>()</code> uses (package <a href="https://CRAN.R-project.org/package=gmp"><span class="pkg">gmp</span></a> based) exact
rational arithmetic, summing up <code><a href="DPQmpfr.html#topic+dhyperQ">dhyperQ</a>()</code>, terms
computed by <code><a href="gmp.html#topic+chooseZ">chooseZ</a>()</code>, exact (long integer) arithmetic
binomial coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is defined as
function(m,n,k, q = .suppHyper(m,n,k), tol = sqrt(.Machine$double.eps)) {
    N &lt;- m+n
    pm &lt;- cbind(ph = phyper(q,     m,  n , k), # 1 = orig.
                p2 = phyper(q,     k, N-k, m), # swap m &lt;-&gt; k (keep N = m+n)
                ## "lower.tail = FALSE"  &lt;==&gt;  1 - p..(..)
                Ip2= phyper(m-1-q, N-k, k, m, lower.tail=FALSE),
                Ip1= phyper(k-1-q, n,   m, k, lower.tail=FALSE))

    ## check that all are (approximately) the same :
    stopifnot(all.equal(pm[,1], pm[,2], tolerance=tol),
              all.equal(pm[,2], pm[,3], tolerance=tol),
              all.equal(pm[,3], pm[,4], tolerance=tol))
    list(q = q, phyp = pm)
}


str(phs &lt;- phypers(20, 47, 31))
with(phs, cbind(q, phyp))
with(phs,
     matplot(q, phyp, type = "b"), main = "phypers(20, 47, 31)")

## differences:
with(phs, phyp[,-1] - phyp[,1])
## *relative*
relE &lt;- with(phs, { phM &lt;- rowMeans(phyp); 1 - phyp/phM })
print.table(cbind(q = phs$q, relE / .Machine$double.eps), zero.print = ".")
</code></pre>

<hr>
<h2 id='pl2curves'>Plot 2 Noncentral Distribution Curves for Visual Comparison</h2><span id='topic+pl2curves'></span>

<h3>Description</h3>

<p>Plot two noncentral (chi-squared or <code class="reqn">t</code> or ..) distribution curves
for visual comparison.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pl2curves(fun1, fun2, df, ncp, log = FALSE,
          from = 0, to = 2 * ncp, p.log = "", n = 2001,
          leg = TRUE, col2 = 2, lwd2 = 2, lty2 = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pl2curves_+3A_fun1">fun1</code>, <code id="pl2curves_+3A_fun2">fun2</code></td>
<td>
<p><code><a href="base.html#topic+function">function</a>()</code>s, both to be used via
<code><a href="graphics.html#topic+curve">curve</a>()</code>, and called with the same 4 arguments,
<code>(., df, ncp, log)</code> (the name of the first argument is not specified).</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_df">df</code>, <code id="pl2curves_+3A_ncp">ncp</code>, <code id="pl2curves_+3A_log">log</code></td>
<td>
<p>parameters to be passed and used in both functions,
which hence typically are non-central chi-squared or t density,
probability or quantile functions.</p>
</td></tr>

<tr><td><code id="pl2curves_+3A_from">from</code>, <code id="pl2curves_+3A_to">to</code></td>
<td>
<p>numbers determining the x-range, passed to
<code><a href="graphics.html#topic+curve">curve</a>()</code>.</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_p.log">p.log</code></td>
<td>
<p>string, passed as <code><a href="graphics.html#topic+curve">curve</a>(...., log = log.p)</code>.</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_n">n</code></td>
<td>
<p>the number of evaluation points, passed to <code><a href="graphics.html#topic+curve">curve</a>()</code>.</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_leg">leg</code></td>
<td>
<p>logical specifying if a <code><a href="graphics.html#topic+legend">legend</a>()</code> should be drawn.</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_col2">col2</code>, <code id="pl2curves_+3A_lwd2">lwd2</code>, <code id="pl2curves_+3A_lty2">lty2</code></td>
<td>
<p>color, line width and line type for the second
curve. (The first curve uses defaults for these graphical properties.)</p>
</td></tr>
<tr><td><code id="pl2curves_+3A_...">...</code></td>
<td>
<p>further arguments passed to <em>first</em> <code><a href="graphics.html#topic+curve">curve</a>(..)</code> call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TODO: inivisible return both curve() results, i.e., (x,y1, y2), possibly
as data frame
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+curve">curve</a></code>, ..
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
p.dnchiBessel &lt;- function(df, ncp, log=FALSE, from=0, to = 2*ncp, p.log="", ...)
{
    pl2curves(dnchisqBessel, dchisq, df=df, ncp=ncp, log=log,
              from=from, to=to, p.log=p.log, ...)
}

  ## TODO the p.dnchiB()  examples  &gt;&gt;&gt;&gt;&gt;&gt; ../tests/chisq-nonc-ex.R &lt;&lt;&lt;
</code></pre>

<hr>
<h2 id='pnbeta'>Noncentral Beta Probabilities</h2><span id='topic+pnbetaAppr2'></span><span id='topic+pnbetaAppr2v1'></span><span id='topic+pnbetaAS310'></span>

<h3>Description</h3>

<p><code>pnbetaAppr2()</code> and its inital version <code>pnbetaAppr2v1()</code>
provide the &ldquo;approximation 2&rdquo; of Chattamvelli and Shanmugam(1997)
to the noncentral Beta probability distribution.
</p>
<p><code>pnbetaAS310()</code> is an <span class="rlang"><b>R</b></span> level interface to a C translation (and
&ldquo;Rification&rdquo;) of the <code>AS 310</code> Fortran implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pnbetaAppr2(x, a, b, ncp = 0, lower.tail = TRUE, log.p = FALSE)

pnbetaAS310(x, a, b, ncp = 0, lower.tail = TRUE, log.p = FALSE,
            useAS226 = (ncp &lt; 54.),
            errmax = 1e-6, itrmax = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pnbeta_+3A_x">x</code></td>
<td>
<p>numeric vector (of quantiles), typically from inside <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_a">a</code>, <code id="pnbeta_+3A_b">b</code></td>
<td>
<p>the shape parameters of Beta, aka as <code>shape1</code> and <code>shape2</code>.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_useas226">useAS226</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> specifying if AS 226 (with R84 and
R95 amendments) should be used which is said to be sufficient for small
<code>ncp</code>.  The default <code>ncp &lt; 54</code> had been hardwired in AS 310.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_errmax">errmax</code></td>
<td>
<p>non-negative number determining convergence for AS 310.</p>
</td></tr>
<tr><td><code id="pnbeta_+3A_itrmax">itrmax</code></td>
<td>
<p>positive integer number, only <code>if(useAS226)</code> is passed to AS 226.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of (log) probabilities of the same length as <code>x</code>.
</p>


<h3>Note</h3>

<p>The authors in the reference compare AS 310 with Lam(1995), Frick(1990) and Lenth(1987)
and state to be better than them.  <span class="rlang"><b>R</b></span>'s current (2019) noncentral beta
implementation builds on these, too, with some amendments though; still,
<code>pnbetaAS310()</code> may potentially be better, at least in certain
corners of the 4-dimensional input space.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler; <code>pnbetaAppr2()</code> in Oct 2007.</p>


<h3>References</h3>

<p>&ndash; not yet implemented &ndash;<br />
Gil, A., Segura, J., and Temme, N. M. (2019)
On the computation and inversion of the cumulative noncentral beta distribution function.
<em>Applied Mathematics and Computation</em> <b>361</b>, 74&ndash;86; <a href="https://doi.org/10.1016/j.amc.2019.05.014">doi:10.1016/j.amc.2019.05.014</a> .
Chattamvelli, R., and Shanmugam, R. (1997)
Algorithm AS 310: Computing the Non-Central Beta Distribution Function.
<em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em>
<b>46</b>(1), 146&ndash;156, for &ldquo;approximation 2&rdquo; notably p.154;

<a href="https://doi.org/10.1111/1467-9876.00055">doi:10.1111/1467-9876.00055</a> .
</p>
<p>Lenth, R. V. (1987) Algorithm AS 226, ...,
Frick, H. (1990)'s AS R84, ..., and
Lam, M.L. (1995)'s AS R95 :  See &lsquo;References&rsquo; in <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+pbeta">pbeta</a></code> page.
</p>


<h3>See Also</h3>

<p><span class="rlang"><b>R</b></span>'s own <code><a href="stats.html#topic+pbeta">pbeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Same arguments as for Table 1 (p.151) of the reference
a &lt;- 5*rep(1:3, each=3)
aargs &lt;- cbind(a = a, b = a,
               ncp = rep(c(54, 140, 170), 3),
               x = 1e-4*c(8640, 9000, 9560, 8686, 9000, 9000, 8787, 9000, 9220))
aargs
pnbA2 &lt;- apply(aargs, 1, function(aa) do.call(pnbetaAppr2, as.list(aa)))
pnA310&lt;- apply(aargs, 1, function(aa) do.call(pnbetaAS310, as.list(aa)))
aar2 &lt;- aargs; dimnames(aar2)[[2]] &lt;- c(paste0("shape", 1:2), "ncp", "q")
pnbR  &lt;- apply(aar2,  1, function(aa) do.call(pbeta, as.list(aa)))
range(relD2   &lt;- 1 - pnbA2 /pnbR)
range(relD310 &lt;- 1 - pnA310/pnbR)
cbind(aargs, pnbA2, pnA310, pnbR,
      relD2 = signif(relD2, 3), relD310 = signif(relD310, 3)) # &lt;------&gt; Table 1
stopifnot(abs(relD2)   &lt; 0.009) # max is 0.006286
stopifnot(abs(relD310) &lt; 1e-5 ) # max is 6.3732e-6

## Arguments as for Table 2 (p.152) of the reference :
aarg2 &lt;- cbind(a = c( 10, 10, 15, 20, 20, 20, 30, 30),
               b = c( 20, 10,  5, 10, 30, 50, 20, 40),
               ncp=c(150,120, 80,110, 65,130, 80,130),
               x = c(868,900,880,850,660,720,720,800)/1000)
pnbA2 &lt;- apply(aarg2, 1, function(aa) do.call(pnbetaAppr2, as.list(aa)))
pnA310&lt;- apply(aarg2, 1, function(aa) do.call(pnbetaAS310, as.list(aa)))
aar2 &lt;- aarg2; dimnames(aar2)[[2]] &lt;- c(paste0("shape", 1:2), "ncp", "q")
pnbR  &lt;- apply(aar2,  1, function(aa) do.call(pbeta, as.list(aa)))
range(relD2   &lt;- 1 - pnbA2 /pnbR)
range(relD310 &lt;- 1 - pnA310/pnbR)
cbind(aarg2, pnbA2, pnA310, pnbR,
      relD2 = signif(relD2, 3), relD310 = signif(relD310, 3)) # &lt;------&gt; Table 2
stopifnot(abs(relD2  ) &lt; 0.006) # max is 0.00412
stopifnot(abs(relD310) &lt; 1e-5 ) # max is 5.5953e-6

## Arguments as for Table 3 (p.152) of the reference :
aarg3 &lt;- cbind(a = c( 10, 10, 10, 15, 10, 12, 30, 35),
               b = c(  5, 10, 30, 20,  5, 17, 30, 30),
               ncp=c( 20, 54, 80,120, 55, 64,140, 20),
               x = c(644,700,780,760,795,560,800,670)/1000)
pnbA3 &lt;- apply(aarg3, 1, function(aa) do.call(pnbetaAppr2, as.list(aa)))
pnA310&lt;- apply(aarg3, 1, function(aa) do.call(pnbetaAS310, as.list(aa)))
aar3 &lt;- aarg3; dimnames(aar3)[[2]] &lt;- c(paste0("shape", 1:2), "ncp", "q")
pnbR  &lt;- apply(aar3,  1, function(aa) do.call(pbeta, as.list(aa)))
range(relD2   &lt;- 1 - pnbA3 /pnbR)
range(relD310 &lt;- 1 - pnA310/pnbR)
cbind(aarg3, pnbA3, pnA310, pnbR,
      relD2 = signif(relD2, 3), relD310 = signif(relD310, 3)) # &lt;------&gt; Table 3
stopifnot(abs(relD2  ) &lt; 0.09) # max is 0.06337
stopifnot(abs(relD310) &lt; 1e-4) # max is 3.898e-5

</code></pre>

<hr>
<h2 id='pnchi1sq'>(Probabilities of Non-Central Chi-squared Distribution for Special Cases</h2><span id='topic+pnchi1sq'></span><span id='topic+pnchi3sq'></span>

<h3>Description</h3>

<p>Computes probabilities for the non-central chi-squared distribution, in
special cases, currently for <code>df = 1</code> and <code>df = 3</code>, using
&lsquo;exact&rsquo; formulas only involving the standard normal (Gaussian)
cdf <code class="reqn">\Phi()</code> and its derivative <code class="reqn">\phi()</code>, i.e., <span class="rlang"><b>R</b></span>'s
<code><a href="stats.html#topic+pnorm">pnorm</a>()</code> and <code><a href="stats.html#topic+dnorm">dnorm</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pnchi1sq(q, ncp = 0, lower.tail = TRUE, log.p = FALSE, epsS = .01)
pnchi3sq(q, ncp = 0, lower.tail = TRUE, log.p = FALSE, epsS = .04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pnchi1sq_+3A_q">q</code></td>
<td>
<p>number ( &lsquo;quantile&rsquo;, i.e., abscissa value.)</p>
</td></tr>

<tr><td><code id="pnchi1sq_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>; ....</p>
</td></tr>
<tr><td><code id="pnchi1sq_+3A_lower.tail">lower.tail</code>, <code id="pnchi1sq_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+pchisq">pchisq</a>()</code>.</p>
</td></tr>
<tr><td><code id="pnchi1sq_+3A_epss">epsS</code></td>
<td>
<p>small number, determining where to switch from the
&ldquo;small case&rdquo; to the regular case, namely by defining
<code>small &lt;- sqrt(q/ncp) &lt;= epsS</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<p>In the &ldquo;small case&rdquo; (<code>epsS</code> above), the direct formulas
suffer from cancellation, and we use Taylor series expansions in
<code class="reqn">s := \sqrt{q}</code>, which in turn use
&ldquo;probabilists'&rdquo; Hermite polynomials <code class="reqn">He_n(x)</code>.
</p>
<p>The default values <code>epsS</code> have currently been determined by
experiments as those in the &lsquo;Examples&rsquo; below.
</p>


<h3>Value</h3>

<p>a numeric vector &ldquo;like&rdquo; <code>q+ncp</code>, i.e., recycled to common length.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, notably the Taylor approximations in the
&ldquo;small&rdquo; cases.</p>


<h3>References</h3>

<p>Johnson et al.(1995), see &lsquo;References&rsquo; in
<code><a href="#topic+pnchisqPearson">pnchisqPearson</a></code>.
</p>
<p><a href="https://en.wikipedia.org/wiki/Hermite_polynomials">https://en.wikipedia.org/wiki/Hermite_polynomials</a> for the notation.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pchisq">pchisq</a></code>, the (simple and R-like) approximations, such as
<code><a href="#topic+pnchisqPearson">pnchisqPearson</a></code> and the wienergerm approximations,
<code><a href="#topic+pchisqW">pchisqW</a>()</code> etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qq &lt;- seq(9500, 10500, length=1000)
m1 &lt;- cbind(pch = pchisq  (qq, df=1, ncp = 10000),
            p1  = pnchi1sq(qq,       ncp = 10000))
matplot(qq, m1, type = "l"); abline(h=0:1, v=10000+1, lty=3)
all.equal(m1[,"p1"], m1[,"pch"], tol=0) # for now,  2.37e-12

m3 &lt;- cbind(pch = pchisq  (qq, df=3, ncp = 10000),
             p3 = pnchi3sq(qq,       ncp = 10000))
matplot(qq, m3, type = "l"); abline(h=0:1, v=10000+3, lty=3)
all.equal(m3[,"p3"], m3[,"pch"], tol=0) # for now,  1.88e-12

stopifnot(exprs = {
  all.equal(m1[,"p1"], m1[,"pch"], tol=1e-10)
  all.equal(m3[,"p3"], m3[,"pch"], tol=1e-10)
})

### Very small 'x' i.e., 'q' would lead to cancellation: -----------

##  df = 1 ---------------------------------------------------------

qS &lt;- c(0, 2^seq(-40,4, by=1/16))
m1s &lt;- cbind(pch = pchisq  (qS, df=1, ncp = 1)
           , p1.0= pnchi1sq(qS,       ncp = 1, epsS = 0)
           , p1.4= pnchi1sq(qS,       ncp = 1, epsS = 1e-4)
           , p1.3= pnchi1sq(qS,       ncp = 1, epsS = 1e-3)
           , p1.2= pnchi1sq(qS,       ncp = 1, epsS = 1e-2)
        )
cols &lt;- adjustcolor(1:5, 1/2); lws &lt;- seq(4,2, by = -1/2)
abl.leg &lt;- function(x.leg = "topright", epsS = 10^-(4:2), legend = NULL)
{
   abline(h = .Machine$double.eps, v = epsS^2,
          lty = c(2,3,3,3), col= adjustcolor(1, 1/2))
   if(is.null(legend))
     legend &lt;- c(quote(epsS == 0), as.expression(lapply(epsS,
                             function(K) substitute(epsS == KK,
                                                    list(KK = formatC(K, w=1))))))
   legend(x.leg, legend, lty=1:4, col=cols, lwd=lws, bty="n")
}
matplot(qS, m1s, type = "l", log="y" , col=cols, lwd=lws)
matplot(qS, m1s, type = "l", log="xy", col=cols, lwd=lws) ; abl.leg("right")
## ====  "Errors" ===================================================
## Absolute: -------------------------
matplot(qS,     m1s[,1] - m1s[,-1] , type = "l", log="x" , col=cols, lwd=lws)
matplot(qS, abs(m1s[,1] - m1s[,-1]), type = "l", log="xy", col=cols, lwd=lws)
abl.leg("bottomright")
rbind(all     = range(aE1e2 &lt;- abs(m1s[,"pch"] - m1s[,"p1.2"])),
      less.75 = range(aE1e2[qS &lt;= 3/4]))
##            Lnx(F34;i7)  M1mac(BDR)
## all        0 7.772e-16  1.110e-15
## less.75    0 1.665e-16  2.220e-16
stopifnot(aE1e2[qS &lt;= 3/4] &lt;= 4e-16, aE1e2 &lt;= 2e-15) # check
## Relative: -------------------------
matplot(qS,     1 - m1s[,-1]/m1s[,1] , type = "l", log="x",  col=cols, lwd=lws)
abl.leg()
matplot(qS, abs(1 - m1s[,-1]/m1s[,1]), type = "l", log="xy", col=cols, lwd=lws)
abl.leg()
## number of correct digits ('Inf' |--&gt; 17) :
corrDigs &lt;- pmin(round(-log10(abs(1 - m1s[,-1]/m1s[,1])[-1,]), 1), 17)
table(corrDigs &gt; 9.8) # all
range(corrDigs[qS[-1] &gt; 1e-8,  1 ], corrDigs[, 2:4]) # [11.8 , 17]
(min (corrDigs[qS[-1] &gt; 1e-6, 1:2], corrDigs[, 3:4]) -&gt; mi6) # 13
(min (corrDigs[qS[-1] &gt; 1e-4, 1:3], corrDigs[,   4]) -&gt; mi4) # 13.9
stopifnot(exprs = {
   corrDigs &gt;= 9.8
   c(corrDigs[qS[-1] &gt; 1e-8,  1 ], corrDigs[, 2]) &gt;= 11.5
   mi6 &gt;= 12.7
   mi4 &gt;= 13.6
})

##  df = 3 -------------- NOTE:  epsS=0 for small qS is "non-sense" --------

qS &lt;- c(0, 2^seq(-40,4, by=1/16))
ee &lt;- c(1e-3, 1e-2, .04)
m3s &lt;- cbind(pch = pchisq  (qS, df=3, ncp = 1)
           , p1.0= pnchi3sq(qS,       ncp = 1, epsS = 0)
           , p1.3= pnchi3sq(qS,       ncp = 1, epsS = ee[1])
           , p1.2= pnchi3sq(qS,       ncp = 1, epsS = ee[2])
           , p1.1= pnchi3sq(qS,       ncp = 1, epsS = ee[3])
        )
matplot(qS, m3s, type = "l", log="y" , col=cols, lwd=lws)
matplot(qS, m3s, type = "l", log="xy", col=cols, lwd=lws); abl.leg("right", ee)
## ====  "Errors" ===================================================
## Absolute: -------------------------
matplot(qS,     m3s[,1] - m3s[,-1] , type = "l", log="x" , col=cols, lwd=lws)
matplot(qS, abs(m3s[,1] - m3s[,-1]), type = "l", log="xy", col=cols, lwd=lws)
abl.leg("right", ee)
## Relative: -------------------------
matplot(qS,     1 - m3s[,-1]/m3s[,1] , type = "l", log="x",  col=cols, lwd=lws)
abl.leg(, ee)
matplot(qS, abs(1 - m3s[,-1]/m3s[,1]), type = "l", log="xy", col=cols, lwd=lws)
abl.leg(, ee)
</code></pre>

<hr>
<h2 id='pnchisqAppr'>(Approximate) Probabilities of Non-Central Chi-squared Distribution</h2><span id='topic+pnchisq'></span><span id='topic+pnchisqV'></span><span id='topic+pnchisqRC'></span><span id='topic+pnchisq_ss'></span><span id='topic+pnchisqAbdelAty'></span><span id='topic+pnchisqBolKuz'></span><span id='topic+pnchisqIT'></span><span id='topic+pnchisqPatnaik'></span><span id='topic+pnchisqPearson'></span><span id='topic+pnchisqSankaran_d'></span><span id='topic+pnchisqTerms'></span><span id='topic+pnchisqT93'></span><span id='topic+pnchisqT93.a'></span><span id='topic+pnchisqT93.b'></span><span id='topic+ss'></span><span id='topic+ss2'></span><span id='topic+ss2.'></span>

<h3>Description</h3>

<p>Compute (approximate) probabilities for the non-central chi-squared
distribution.
</p>
<p>The non-central chi-squared distribution with <code>df</code><code class="reqn">= n</code>
degrees of freedom and non-centrality parameter <code>ncp</code>
<code class="reqn">= \lambda</code> has density
</p>
<p style="text-align: center;"><code class="reqn">
    f(x) = f_{n,\lambda}(x) = e^{-\lambda / 2}
      \sum_{r=0}^\infty \frac{(\lambda/2)^r}{r!}\, f_{n + 2r}(x)</code>
</p>

<p>for <code class="reqn">x \ge 0</code>; for more, see <span class="rlang"><b>R</b></span>'s help page for <code><a href="stats.html#topic+pchisq">pchisq</a></code>.

</p>

<ul>
<li> <p><span class="rlang"><b>R</b></span>'s own historical and current versions, but with more tuning parameters;
</p>
</li></ul>

<p>Historical relatively simple approximations listed in Johnson, Kotz, and Balakrishnan (1995):
</p>

<ul>
<li><p> Patnaik(1949)'s approximation to the non-central via central
chi-squared.  Is also the formula <code class="reqn">26.4.27</code> in Abramowitz &amp; Stegun, p.942.
Johnson et al mention that the approximation error is <em>
<code class="reqn">O(1/\sqrt(\lambda))</code> for <code class="reqn">\lambda \to \infty</code></em>.
</p>
</li>
<li><p> Pearson(1959) is using 3 moments instead of 2 as Patnaik (to
approximate via a central chi-squared), and therefore better than
Patnaik for the right tail; further (in Johnson et al.), the
approximation error is <em><code class="reqn">O(1/\lambda)</code> for <code class="reqn">\lambda \to \infty</code></em>.
</p>
</li>
<li><p> Abdel-Aty(1954)'s &ldquo;first approximation&rdquo; based on
Wilson-Hilferty via Gaussian (<code><a href="stats.html#topic+pnorm">pnorm</a></code>) probabilities, is
partly <em>wrongly</em> cited in Johnson et al., p.463, eq.<code class="reqn">(29.61a)</code>.
</p>
</li>
<li><p> Bol'shev and Kuznetzov (1963) concentrate on the case of
<b>small</b> <code>ncp</code> <code class="reqn">\lambda</code> and provide an &ldquo;approximation&rdquo; via
<em>central</em> chi-squared with the same degrees of freedom <code>df</code>,
but a modified <code>q</code> (&lsquo;x&rsquo;); the approximation has error
<code class="reqn">O(\lambda^3)</code> for <code class="reqn">\lambda \to 0</code> and is from
Johnson et al., p.465, eq.<code class="reqn">(29.62)</code> and <code class="reqn">(29.63)</code>.
</p>
</li>
<li><p> Sankaran(1959, 1963) proposes several further approximations base
on Gaussian probabilities, according to Johnson
et al., p.463. <code>pnchisqSankaran_d()</code> implements its formula <code class="reqn">(29.61d)</code>.
</p>
</li></ul>


<dl>
<dt><code>pnchisq()</code>:</dt><dd><p>an R implementation of <span class="rlang"><b>R</b></span>'s own C <code>pnchisq_raw()</code>,
but almost only up to Feb.27, 2004, long before the <code>log.p=TRUE</code>
addition there, including <em>logspace arithmetic</em> in April 2014,
its finish on 2015-09-01.  Currently for historical reference only.</p>
</dd>

<dt><code>pnchisqV()</code>:</dt><dd><p>a <code><a href="base.html#topic+Vectorize">Vectorize</a>()</code>d <code><a href="#topic+pnchisq">pnchisq</a></code>.</p>
</dd>
<dt><code>pnchisqRC()</code>:</dt><dd><p><span class="rlang"><b>R</b></span>'s C implementation as of Aug.2019; but
with many more options.
Currently extreme cases tend to hang on Winbuilder (?) 
</p>
</dd>
<dt><code>pnchisqIT</code>:</dt><dd><p> .... </p>
</dd>
<dt><code>pnchisqTerms</code>:</dt><dd><p> .... </p>
</dd>

<dt><code>pnchisqT93</code>:</dt><dd><p>pure <span class="rlang"><b>R</b></span> implementations of approximations when
both <code>q</code> and <code>ncp</code> are large, by Temme(1993), from Johnson
et al., p.467, formulas <code class="reqn">(29.71 a)</code>, and <code class="reqn">(29.71 b)</code>, using
auxiliary functions <code>pnchisqT93a()</code> and <code>pnchisqT93b()</code>
respectively, with adapted formulas for the <code>log.p=TRUE</code> cases.</p>
</dd>
<dt><code>pnchisq_ss()</code>:</dt><dd><p> .... </p>
</dd>

<dt><code>ss</code>:</dt><dd><p> .... </p>
</dd>
<dt><code>ss2</code>:</dt><dd><p> .... </p>
</dd>
<dt><code>ss2.</code>:</dt><dd><p> .... </p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>pnchisq          (q, df, ncp = 0, lower.tail = TRUE, 
                  cutOffncp = 80, itSimple = 110, errmax = 1e-12, reltol = 1e-11,
                  maxit = 10* 10000, verbose = 0, xLrg.sigma = 5)
pnchisqV(x, ..., verbose = 0)

pnchisqRC        (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE,
                  no2nd.call = FALSE,
                  cutOffncp = 80, small.ncp.logspace = small.ncp.logspaceR2015,
                  itSimple = 110, errmax = 1e-12,
                  reltol = 8 * .Machine$double.eps, epsS = reltol/2, maxit = 1e6,
                  verbose = FALSE)
pnchisqAbdelAty  (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
pnchisqBolKuz    (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
pnchisqPatnaik   (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
pnchisqPearson   (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
pnchisqSankaran_d(q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
pnchisq_ss       (x, df, ncp = 0, lower.tail = TRUE, log.p = FALSE, i.max = 10000)
pnchisqTerms     (x, df, ncp,     lower.tail = TRUE, i.max = 1000)

pnchisqT93  (q, df, ncp, lower.tail = TRUE, log.p = FALSE, use.a = q &gt; ncp)
pnchisqT93.a(q, df, ncp, lower.tail = TRUE, log.p = FALSE)
pnchisqT93.b(q, df, ncp, lower.tail = TRUE, log.p = FALSE)

ss   (x, df, ncp, i.max = 10000, useLv = !(expMin &lt; -lambda &amp;&amp; 1/lambda &lt; expMax))
ss2  (x, df, ncp, i.max = 10000, eps = .Machine$double.eps)
ss2. (q, df, ncp = 0, errmax = 1e-12, reltol = 2 * .Machine$double.eps,
      maxit = 1e+05, eps = reltol, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>


<table role = "presentation">
<tr><td><code id="pnchisqAppr_+3A_x">x</code></td>
<td>
<p>numeric vector (of &lsquo;quantiles&rsquo;, i.e., abscissa values).</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_q">q</code></td>
<td>
<p>number ( &lsquo;quantile&rsquo;, i.e., abscissa value.)</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_df">df</code></td>
<td>
<p>degrees of freedom <code class="reqn">&gt; 0</code>, maybe non-integer.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>; ....</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_lower.tail">lower.tail</code>, <code id="pnchisqAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+pchisq">pchisq</a>()</code>.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_i.max">i.max</code></td>
<td>
<p>number of terms in evaluation ...</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_use.a">use.a</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> vector for Temme <code>pnchisqT93*()</code>
formulas, indicating to use formula &lsquo;a&rsquo; over &lsquo;b&rsquo;.  The
default is as recommended in the references, but they did not take into
account <code>log.p = TRUE</code> situations.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_cutoffncp">cutOffncp</code></td>
<td>
<p>a positive number, the cutoff value for <code>ncp</code>...</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_itsimple">itSimple</code></td>
<td>
<p> ...</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_errmax">errmax</code></td>
<td>
<p>absolute error tolerance.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_reltol">reltol</code></td>
<td>
<p>convergence tolerance for <em>rel</em>ative error.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_maxit">maxit</code></td>
<td>
<p>maximal number of iterations.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_xlrg.sigma">xLrg.sigma</code></td>
<td>
<p>positive number ...</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_no2nd.call">no2nd.call</code></td>
<td>
<p>logical indicating if a 2nd call is made to the
internal function ....</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_small.ncp.logspace">small.ncp.logspace</code></td>
<td>
<p>logical vector or <code><a href="base.html#topic+function">function</a></code>,
indicating if the logspace computations for &ldquo;small&rdquo; <code>ncp</code>
(defined to fulfill <code>ncp &lt; cutOffncp</code> !).</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_epss">epsS</code></td>
<td>
<p>small positive number, the convergence tolerance of the
&lsquo;simple&rsquo; iterations...</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_verbose">verbose</code></td>
<td>
<p>logical or integer specifying if or how much the algorithm
progress should be monitored.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_...">...</code></td>
<td>
<p>further arguments passed from <code>pnchisqV()</code> to <code>pnchisq()</code>.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_uselv">useLv</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if logarithmic scale should
be used for <code class="reqn">\lambda</code> computations.</p>
</td></tr>
<tr><td><code id="pnchisqAppr_+3A_eps">eps</code></td>
<td>
<p>convergence tolerance, a positive number.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>pnchisq_ss()</code></dt><dd><p>uses <code>si &lt;- ss(x, df, ..)</code> to get the series terms,
and returns <code>2*<a href="stats.html#topic+dchisq">dchisq</a>(x, df = df +2) * sum(si$s)</code>.</p>
</dd>
<dt><code>ss()</code></dt><dd><p>computes the terms needed for the expansion used in
<code>pnchisq_ss()</code>.</p>
</dd>
<dt><code>ss2()</code></dt><dd><p>computes some simple &ldquo;statistics&rdquo; about <code>ss(..)</code>.</p>
</dd>

</dl>



<h3>Value</h3>


<dl>
<dt><code>ss()</code></dt><dd><p>returns a list with 3 components</p>
</dd>
</dl>

<table role = "presentation">
<tr><td><code>s</code></td>
<td>
<p>the series</p>
</td></tr>
<tr><td><code>i1</code></td>
<td>
<p>location (in <code>s[]</code>) of the first change from 0 to positive.</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>(first) location of the maximal value in the series (i.e.,
<code><a href="base.html#topic+which.max">which.max</a>(s)</code>).</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Martin Maechler, from May 1999;  starting from a post to the S-news
mailing list by Ranjan Maitra (@ math.umbc.edu) who showed a version of
our <code>pchisqAppr.0()</code> thanking Jim Stapleton for providing it.
</p>


<h3>References</h3>

<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
Continuous Univariate Distributions Vol 2, 2nd ed.; Wiley;

chapter 29 <em>Noncentral <code class="reqn">\chi^2</code>-Distributions</em>;
notably Section <em>8  Approximations</em>, p.461 ff.
</p>
<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pchisq">pchisq</a></code> and the wienergerm approximations for it:
<code><a href="#topic+pchisqW">pchisqW</a>()</code> etc.
</p>
<p><code><a href="#topic+r_pois">r_pois</a>()</code> and its plot function, for an aspect of the series
approximations we use in <code>pnchisq_ss()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## set of quantiles to use :
qq &lt;- c(.001, .005, .01, .05, (1:9)/10, 2^seq(0, 10, by= 0.5))
## Take "all interesting" pchisq-approximation from our pkg :
pkg &lt;- "package:DPQ"
pnchNms &lt;- c(paste0("pchisq", c("V", "W", "W.", "W.R")),
             ls(pkg, pattern = "^pnchisq"))
pnchNms &lt;- pnchNms[!grepl("Terms$", pnchNms)]
pnchF &lt;- sapply(pnchNms, get, envir = as.environment(pkg))
str(pnchF)
ncps &lt;- c(0, 1/8, 1/2)
pnchR &lt;- as.list(setNames(ncps, paste("ncp",ncps, sep="=")))
for(i.n in seq_along(ncps)) {
  ncp &lt;- ncps[i.n]
  pnF &lt;- if(ncp == 0) pnchF[!grepl("chisqT93", pnchNms)] else pnchF
  pnchR[[i.n]] &lt;- sapply(pnF, function(F)
            Vectorize(F, names(formals(F))[[1]])(qq, df = 3, ncp=ncp))
}
str(pnchR, max=2)
		 

## A case where the non-central P[] should be improved :
## First, the central P[] which is close to exact -- choosing df=2 allows
## truly exact values: chi^2 = Exp(1) !
opal &lt;- palette()
palette(c("black", "red", "green3", "blue", "cyan", "magenta", "gold3", "gray44"))
cR  &lt;- curve(pchisq   (x, df=2,        lower.tail=FALSE, log.p=TRUE), 0, 4000, n=2001)
cRC &lt;- curve(pnchisqRC(x, df=2, ncp=0, lower.tail=FALSE, log.p=TRUE),
             add=TRUE, col=adjustcolor(2,1/2), lwd=3, lty=2, n=2001)
cR0 &lt;- curve(pchisq   (x, df=2, ncp=0, lower.tail=FALSE, log.p=TRUE),
             add=TRUE, col=adjustcolor(3,1/2), lwd=4,        n=2001)
## smart "named list" constructur :
list_ &lt;- function(...)
   `names&lt;-`(list(...), vapply(sys.call()[-1L], as.character, ""))
JKBfn &lt;-list_(pnchisqPatnaik,
              pnchisqPearson,
              pnchisqAbdelAty,
              pnchisqBolKuz,
              pnchisqSankaran_d)
cl. &lt;- setNames(adjustcolor(3+seq_along(JKBfn), 1/2), names(JKBfn))
lw. &lt;- setNames(2+seq_along(JKBfn),                   names(JKBfn))
cR.JKB &lt;- sapply(names(JKBfn), function(nmf) {
  curve(JKBfn[[nmf]](x, df=2, ncp=0, lower.tail=FALSE, log.p=TRUE),
        add=TRUE, col=cl.[[nmf]], lwd=lw.[[nmf]], lty=lw.[[nmf]], n=2001)
})
legend("bottomleft", c("pchisq", "pchisq.ncp=0", "pnchisqRC", names(JKBfn)),
       col=c(palette()[1], adjustcolor(2:3,1/2), cl.),
       lwd=c(1,3,4, lw.), lty=c(1,2,1, lw.))
palette(opal)# revert

all.equal(cRC, cR0, tol = 1e-15) # TRUE [for now]
## the problematic "jump" :
as.data.frame(cRC)[744:750,]
if(.Platform$OS.type == "unix")
  ## verbose=TRUE  may reveal which branches of the algorithm are taken:
  pnchisqRC(1500, df=2, ncp=0, lower.tail=FALSE, log.p=TRUE, verbose=TRUE) #
  ## |--&gt;  -Inf currently

## The *two*  principal cases (both lower.tail = {TRUE,FALSE} !), where
##  "2nd call"  happens *and* is currently beneficial :
dfs &lt;- c(1:2, 5, 10, 20)
pL. &lt;- pnchisqRC(.00001, df=dfs, ncp=0, log.p=TRUE, lower.tail=FALSE, verbose = TRUE)
pR. &lt;- pnchisqRC(   100, df=dfs, ncp=0, log.p=TRUE,                   verbose = TRUE)
## R's own non-central version (specifying 'ncp'):
pL0 &lt;- pchisq   (.00001, df=dfs, ncp=0, log.p=TRUE, lower.tail=FALSE)
pR0 &lt;- pchisq   (   100, df=dfs, ncp=0, log.p=TRUE)
## R's *central* version, i.e., *not* specifying 'ncp' :
pL  &lt;- pchisq   (.00001, df=dfs,        log.p=TRUE, lower.tail=FALSE)
pR  &lt;- pchisq   (   100, df=dfs,        log.p=TRUE)
cbind(pL., pL, relEc = signif(1-pL./pL, 3), relE0 = signif(1-pL./pL0, 3))
cbind(pR., pR, relEc = signif(1-pR./pR, 3), relE0 = signif(1-pR./pR0, 3))
</code></pre>

<hr>
<h2 id='pnchisqWienergerm'>Wienergerm Approximations to (Non-Central) Chi-squared Probabilities</h2><span id='topic+pchisqV'></span><span id='topic+pchisqW'></span><span id='topic+pchisqW.'></span><span id='topic+pchisqW.R'></span><span id='topic+sW'></span><span id='topic+qs'></span><span id='topic+z0'></span><span id='topic+z.f'></span><span id='topic+z.s'></span><span id='topic+g2'></span><span id='topic+gnt'></span><span id='topic+h'></span><span id='topic+h0'></span><span id='topic+h1'></span><span id='topic+h2'></span><span id='topic+hnt'></span><span id='topic+scalefactor'></span>

<h3>Description</h3>


<p>Functions implementing the two Wiener germ approximations to
<code><a href="stats.html#topic+pchisq">pchisq</a>()</code>, the (non-central) chi-squared distribution, and to
<code><a href="stats.html#topic+qchisq">qchisq</a>()</code> its inverse, the quantile function.
</p>
<p>These have been proposed by Penev and Raykov (2000) who also listed a
Fortran implementation.
</p>
<p>In order to use them in numeric boundary cases, Martin Maechler has
improved the original formulas.
</p>
<p><b>Auxiliary functions:</b>
</p>

<dl>
<dt><code>sW()</code>:</dt><dd><p>The <code class="reqn">s()</code> as in the Wienergerm approximation,
but using Taylor expansion when needed, i.e., <code>(x*ncp / df^2) &lt;&lt; 1</code>.</p>
</dd>
<dt><code>qs()</code>:</dt><dd><p> ... </p>
</dd>
<dt><code>z0()</code>:</dt><dd><p> ... </p>
</dd>
<dt><code>z.f()</code>:</dt><dd><p> ... </p>
</dd>
<dt><code>z.s()</code>:</dt><dd><p> ... </p>
</dd>
</dl>
<p>..................
..................
</p>
 


<h3>Usage</h3>

<pre><code class='language-R'>pchisqW. (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE,
          Fortran = TRUE, variant = c("s", "f"))
pchisqV  (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE,
          Fortran = TRUE, variant = c("s", "f"))
pchisqW  (q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE, variant = c("s", "f"))
pchisqW.R(x, df, ncp = 0, lower.tail = TRUE, log.p = FALSE, variant = c("s", "f"),
          verbose = getOption("verbose"))

sW(x, df, ncp)
qs(x, df, ncp, f.s = sW(x, df, ncp), eps1 = 1/2, sMax = 1e+100)
z0(x, df, ncp)
z.f(x, df, ncp)
z.s(x, df, ncp, verbose = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pnchisqWienergerm_+3A_q">q</code>, <code id="pnchisqWienergerm_+3A_x">x</code></td>
<td>
<p>vector of quantiles (main argument, see  <code><a href="stats.html#topic+pchisq">pchisq</a></code>).</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_df">df</code></td>
<td>
<p>degrees of freedom (non-negative, but can be non-integer).</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter (non-negative).</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_lower.tail">lower.tail</code>, <code id="pnchisqWienergerm_+3A_log.p">log.p</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code>, see <code><a href="stats.html#topic+pchisq">pchisq</a></code>.</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_variant">variant</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string, currently either
<code>"f"</code> for the <b>f</b>irst or
<code>"s"</code> for the <b>s</b>econd Wienergerm approximation in
Penev and Raykov (2000).</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_fortran">Fortran</code></td>
<td>
<p>logical specifying if the Fortran or the C version should
be used.</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_verbose">verbose</code></td>
<td>
<p>logical (or integer) indicating if or how much diagnostic
output should be printed to the console during the computations.</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_f.s">f.s</code></td>
<td>
<p>a number must be a &ldquo;version&rdquo; of <code class="reqn">s(x, df, ncp)</code>.</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_eps1">eps1</code></td>
<td>
<p>for <code>qs()</code>: use direct approximation instead of
<code>h(1 - 1/s)</code> for <code>s &lt; eps1</code>.</p>
</td></tr>
<tr><td><code id="pnchisqWienergerm_+3A_smax">sMax</code></td>
<td>
<p>for <code>qs()</code>: cutoff to switch the <code class="reqn">h(.)</code> formula for
<code>s &gt; sMax</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>....TODO... or write vignette
</p>


<h3>Value</h3>

<p>all these functions return <code><a href="base.html#topic+numeric">numeric</a></code> vectors according to
their arguments.
</p>


<h3>Note</h3>

<p>The exact auxiliary function names etc, are still considered
<em>provisional</em>; currently they are exported for easier documentation
and use, but may well all disappear from the exported functions or even
completely.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, mostly end of Jan 2004</p>


<h3>References</h3>

<p>Penev, Spiridon and Raykov, Tenko (2000)
A Wiener Germ approximation of the noncentral chi square 
distribution and of its quantiles.
<em>Computational Statistics</em> <b>15</b>, 219&ndash;228.
<a href="https://doi.org/10.1007/s001800000029">doi:10.1007/s001800000029</a>
</p>
<p>Dinges, H. (1989)
Special cases of second order Wiener germ approximations.
<em>Probability Theory and Related Fields</em>, <b>83</b>, 5&ndash;57.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pchisq">pchisq</a></code>, and other approximations for it:
<code><a href="#topic+pnchisq">pnchisq</a>()</code> etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see  example(pnchisqAppr)   which looks at all of the pchisq() approximating functions
</code></pre>

<hr>
<h2 id='pnormAsymp'>Asymptotic Approxmation of (Extreme Tail) 'pnorm()'</h2><span id='topic+pnormAsymp'></span>

<h3>Description</h3>

<p>Provide the first few terms of the asymptotic series approximation to
<code><a href="stats.html#topic+pnorm">pnorm</a>()</code>'s (extreme) tail, from Abramawitz and Stegun's
26.2.13 (p.932).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pnormAsymp(x, k, lower.tail = FALSE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pnormAsymp_+3A_x">x</code></td>
<td>
<p>positive (at least non-negative) numeric vector.</p>
</td></tr>
<tr><td><code id="pnormAsymp_+3A_lower.tail">lower.tail</code>, <code id="pnormAsymp_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+pnorm">pnorm</a>()</code>.</p>
</td></tr>
<tr><td><code id="pnormAsymp_+3A_k">k</code></td>
<td>
<p>integer <code class="reqn">\ge 0</code> indicating how many terms the approximation
should use; currently <code class="reqn">k \le 5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector &ldquo;as&rdquo; <code>x</code>; see the examples, on how to use it
with arbitrary precise <code><a href="Rmpfr.html#topic+mpfr">mpfr</a></code>-numbers from package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pnormU_S53">pnormU_S53</a></code> for (also asymptotic) upper and lower bounds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c((2:10)*2, 25, (3:9)*10, (1:9)*100, (1:8)*1000, (2:4)*5000)
Px &lt;- pnorm(x, lower.tail = FALSE, log.p=TRUE)
PxA &lt;- sapply(setNames(0:5, paste("k =",0:5)),
              pnormAsymp, x=x, lower.tail = FALSE, log.p=TRUE)
## rel.errors :
signif(head( cbind(x, 1 - PxA/Px) , 20))

## Look more closely with high precision computations
if(requireNamespace("Rmpfr")) {
  ## ensure our function uses Rmpfr's dnorm(), etc:
  environment(pnormAsymp) &lt;- asNamespace("Rmpfr")
  environment(pnormU_S53) &lt;- asNamespace("Rmpfr")
  x. &lt;- Rmpfr::mpfr(x, precBits=256)
  Px. &lt;- Rmpfr::pnorm(x., lower.tail = FALSE, log.p=TRUE)
  ## manual, better sapplyMpfr():
  PxA. &lt;- sapply(setNames(0:5, paste("k =",0:5)),
                 pnormAsymp, x=x., lower.tail = FALSE, log.p=TRUE)
  PxA. &lt;- new("mpfrMatrix", unlist(PxA.), Dim=dim(PxA.), Dimnames=dimnames(PxA.))
  PxA2 &lt;- Rmpfr::cbind(pn_dbl = Px, PxA.,
                       pnormU_S53 = pnormU_S53(x=x., lower.tail = FALSE, log.p=TRUE))
  ## rel.errors : note that pnormU_S53() is very slightly better than "k=2":
  print( Rmpfr::roundMpfr(Rmpfr::cbind(x., 1 - PxA2/Px.), precBits = 13), width = 111)
  pch &lt;- c("R", 0:5, "U")
  matplot(x, abs(1 -PxA2/Px.), type="o", log="xy", pch=pch,
          main="pnorm(&lt;tail&gt;) approximations' relative errors - pnormAsymp(*, k=k)")
  legend("bottomleft", colnames(PxA2), col=1:6, pch=pch, lty=1:5, bty="n", inset=.01)
  at1 &lt;- axTicks(1, axp = c(par("xaxp")[1:2], 3))
  axis(1, at=at1)
  abline(h = 1:2* 2^-53, v = at1, lty=3, col=adjustcolor("gray20", 1/2))
  axis(4, las=2, at= 2^-53, label = quote(epsilon[C]), col="gray20")
}

</code></pre>

<hr>
<h2 id='pnormLU'>Bounds for 1-Phi(.) &ndash; Mill's Ratio related Bounds for pnorm()</h2><span id='topic+pnormL_LD10'></span><span id='topic+pnormU_S53'></span>

<h3>Description</h3>

<p>Bounds for <code class="reqn">1 - \Phi(x)</code>, i.e., <code><a href="stats.html#topic+pnorm">pnorm</a>(x, *,
    lower.tail=FALSE)</code>, typically related to Mill's Ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pnormL_LD10(x, lower.tail = FALSE, log.p = FALSE)
pnormU_S53 (x, lower.tail = FALSE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pnormLU_+3A_x">x</code></td>
<td>
<p>positive (at least non-negative) numeric vector.</p>
</td></tr>
<tr><td><code id="pnormLU_+3A_lower.tail">lower.tail</code>, <code id="pnormLU_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+pnorm">pnorm</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector like <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Lutz Duembgen (2010)
<em>Bounding Standard Gaussian Tail Probabilities</em>;
arXiv preprint <code>1012.2063</code>,
<a href="https://arxiv.org/abs/1012.2063">https://arxiv.org/abs/1012.2063</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(1/64, 10, by=1/64)
px &lt;- cbind(
    lQ = pnorm      (x, lower.tail=FALSE, log.p=TRUE)
  , Lo = pnormL_LD10(x, lower.tail=FALSE, log.p=TRUE)
  , Up = pnormU_S53 (x, lower.tail=FALSE, log.p=TRUE))
matplot(x, px, type="l") # all on top of each other

matplot(x, (D &lt;- px[,2:3] - px[,1]), type="l") # the differences
abline(h=0, lty=3, col=adjustcolor(1, 1/2))

## check they are lower and upper bounds indeed :
stopifnot(D[,"Lo"] &lt; 0, D[,"Up"] &gt; 0)

matplot(x[x&gt;4], D[x&gt;4,], type="l") # the differences
abline(h=0, lty=3, col=adjustcolor(1, 1/2))

### zoom out to larger x : [1, 1000]
x &lt;- seq(1, 1000, by=1/4)
px &lt;- cbind(
    lQ = pnorm      (x, lower.tail=FALSE, log.p=TRUE)
  , Lo = pnormL_LD10(x, lower.tail=FALSE, log.p=TRUE)
  , Up = pnormU_S53 (x, lower.tail=FALSE, log.p=TRUE))
matplot(x, px, type="l") # all on top of each other
matplot(x, (D &lt;- px[,2:3] - px[,1]), type="l", log="x") # the differences
abline(h=0, lty=3, col=adjustcolor(1, 1/2))

## check they are lower and upper bounds indeed :
table(D[,"Lo"] &lt; 0) # no longer always true
table(D[,"Up"] &gt; 0)
## not even when equality (where it's much better though):
table(D[,"Lo"] &lt;= 0)
table(D[,"Up"] &gt;= 0)

## *relative* differences:
matplot(x, (rD &lt;- 1 - px[,2:3] / px[,1]), type="l", log = "x")
abline(h=0, lty=3, col=adjustcolor(1, 1/2))
## abs()
matplot(x, abs(rD), type="l", log = "xy", axes=FALSE, # NB: curves *cross*
        main = "relative differences 1 - pnormUL(x, *)/pnorm(x,*)")
legend("top", c("Low.Bnd(D10)", "Upp.Bnd(S53)"), bty="n", col=1:2, lty=1:2)
sfsmisc::eaxis(1, sub10 = 2)
sfsmisc::eaxis(2)
abline(h=(1:4)*2^-53, col=adjustcolor(1, 1/4))

### zoom out to LARGE x : ---------------------------

x &lt;- 2^seq(0,    30, by = 1/64)
if(FALSE)## or even HUGE:
   x &lt;- 2^seq(4, 513, by = 1/16)
px &lt;- cbind(
    lQ = pnorm      (x, lower.tail=FALSE, log.p=TRUE)
  , a0 = dnorm(x, log=TRUE)
  , a1 = dnorm(x, log=TRUE) - log(x)
  , Lo = pnormL_LD10(x, lower.tail=FALSE, log.p=TRUE)
  , Up = pnormU_S53 (x, lower.tail=FALSE, log.p=TRUE))
col4 &lt;- adjustcolor(1:4, 1/2)
doLegTit &lt;- function() {
  title(main = "relative differences 1 - pnormUL(x, *)/pnorm(x,*)")
  legend("top", c("phi(x)", "phi(x)/x", "Low.Bnd(D10)", "Upp.Bnd(S53)"),
         bty="n", col=col4, lty=1:4)
}
## *relative* differences are relevant:
matplot(x, (rD &lt;- 1 - px[,-1] / px[,1]), type="l", log = "x",
            ylim = c(-1,1)/2^8, col=col4) ; doLegTit()
abline(h=0, lty=3, col=adjustcolor(1, 1/2))

## abs(rel.Diff)  ---&gt; can use log-log:
matplot(x, abs(rD), type="l", log = "xy", xaxt="n", yaxt="n"); doLegTit()
sfsmisc::eaxis(1, sub10=2)
sfsmisc::eaxis(2, nintLog=12)
abline(h=(1:4)*2^-53, col=adjustcolor(1, 1/4))

## lower.tail=TRUE (w/ log.p=TRUE) works "the same" for x &lt; 0:
x &lt;- - 2^seq(0,    30, by = 1/64)
##   ==
px &lt;- cbind(
    lQ = pnorm   (x, lower.tail=TRUE, log.p=TRUE)
  , a0 = log1mexp(- dnorm(-x, log=TRUE))
  , a1 = log1mexp(-(dnorm(-x, log=TRUE) - log(-x)))
  , Lo = log1mexp(-pnormL_LD10(-x, lower.tail=TRUE, log.p=TRUE))
  , Up = log1mexp(-pnormU_S53 (-x, lower.tail=TRUE, log.p=TRUE)) )
matplot(-x, (rD &lt;- 1 - px[,-1] / px[,1]), type="l", log = "x",
            ylim = c(-1,1)/2^8, col=col4) ; doLegTit()
abline(h=0, lty=3, col=adjustcolor(1, 1/2))

</code></pre>

<hr>
<h2 id='pnt'>Non-central t Probability Distribution - Algorithms and Approximations</h2><span id='topic+pntR'></span><span id='topic+pntR1'></span><span id='topic+pntP94'></span><span id='topic+pntP94.1'></span><span id='topic+pntLrg'></span><span id='topic+pntJW39'></span><span id='topic+pntJW39.0'></span><span id='topic+pnt3150'></span><span id='topic+pnt3150.1'></span><span id='topic+pntChShP94'></span><span id='topic+pntChShP94.1'></span><span id='topic+pntGST23_T6'></span><span id='topic+pntGST23_T6.1'></span><span id='topic+pntGST23_1'></span><span id='topic+pntVW13'></span>

<h3>Description</h3>

<p>Compute different approximations for the non-central t-Distribution
cumulative probability distribution function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pntR      (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
           use.pnorm = (df &gt; 4e5 ||
                        ncp^2 &gt; 2*log(2)*1021), # .Machine$double.min.exp = -1022
                                          itrmax = 1000, errmax = 1e-12, verbose = TRUE)
pntR1     (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
           use.pnorm = (df &gt; 4e5 ||
                        ncp^2 &gt; 2*log(2)*1021),
                                          itrmax = 1000, errmax = 1e-12, verbose = TRUE)

pntP94    (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
                                          itrmax = 1000, errmax = 1e-12, verbose = TRUE)
pntP94.1  (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
                                          itrmax = 1000, errmax = 1e-12, verbose = TRUE)

pnt3150   (t, df, ncp, lower.tail = TRUE, log.p = FALSE, M = 1000, verbose = TRUE)
pnt3150.1 (t, df, ncp, lower.tail = TRUE, log.p = FALSE, M = 1000, verbose = TRUE)

pntLrg    (t, df, ncp, lower.tail = TRUE, log.p = FALSE)

pntJW39   (t, df, ncp, lower.tail = TRUE, log.p = FALSE)
pntJW39.0 (t, df, ncp, lower.tail = TRUE, log.p = FALSE)


pntVW13 (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
           keepS = FALSE, verbose = FALSE)

pntGST23_T6  (t, df, ncp, lower.tail = TRUE, log.p = FALSE,
              y1.tol = 1e-8, Mterms = 20, alt = FALSE, verbose = TRUE)
pntGST23_T6.1(t, df, ncp, lower.tail = TRUE, log.p = FALSE,
              y1.tol = 1e-8, Mterms = 20, alt = FALSE, verbose = TRUE)

## *Non*-asymptotic, (at least partly much) better version of R's Lenth(1998) algorithm
pntGST23_1(t, df, ncp, lower.tail = TRUE, log.p = FALSE,
           j0max = 1e4, # for now
           IxpqFUN = Ixpq,
           alt = FALSE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>


<table role = "presentation">
<tr><td><code id="pnt_+3A_t">t</code></td>
<td>
<p>vector of quantiles (called <code>q</code> in <code><a href="stats.html#topic+pt">pt</a>(..)</code>).</p>
</td></tr>
<tr><td><code id="pnt_+3A_df">df</code></td>
<td>
<p>degrees of freedom (<code class="reqn">&gt; 0</code>, maybe non-integer).  <code>df
      = Inf</code> is allowed.</p>
</td></tr>
<tr><td><code id="pnt_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta \ge 0</code>;
If omitted, use the central t distribution.</p>
</td></tr>
<tr><td><code id="pnt_+3A_log">log</code>, <code id="pnt_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="pnt_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="pnt_+3A_use.pnorm">use.pnorm</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if the
<code><a href="stats.html#topic+pnorm">pnorm</a>()</code> approximation of Abramowitz and Stegun (26.7.10)
should be used, which is available as <code>pntLrg()</code>.
</p>
<p>The default corresponds to <span class="rlang"><b>R</b></span> <code><a href="stats.html#topic+pt">pt</a>()</code>'s own behaviour (which
is suboptimal).</p>
</td></tr>
<tr><td><code id="pnt_+3A_itrmax">itrmax</code></td>
<td>
<p>number of iterations / terms.</p>
</td></tr>
<tr><td><code id="pnt_+3A_errmax">errmax</code></td>
<td>
<p>convergence bound for the iterations.</p>
</td></tr>
<tr><td><code id="pnt_+3A_verbose">verbose</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> or integer determining the amount of
diagnostic print out to the console.</p>
</td></tr>
<tr><td><code id="pnt_+3A_m">M</code></td>
<td>
<p>positive integer specifying the number of terms to use in the series.</p>
</td></tr>
<tr><td><code id="pnt_+3A_keeps">keepS</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if the function should
return a <code><a href="base.html#topic+list">list</a></code> with component <code>cdf</code> and other
informational elements, or just the CDF values directly (by default).</p>
</td></tr>
<tr><td><code id="pnt_+3A_y1.tol">y1.tol</code></td>
<td>
<p>positive tolerance for warning if <code class="reqn">y:= t^2/(t^2 + df)</code>
is too close to 1 (as the formulas use <code class="reqn">1/(1-y)</code>).</p>
</td></tr>
<tr><td><code id="pnt_+3A_mterms">Mterms</code></td>
<td>
<p>number of summation terms for <code>pntGST23_T6()</code>.</p>
</td></tr>
<tr><td><code id="pnt_+3A_j0max">j0max</code></td>
<td>
<p><em>experimental</em>: large integer limiting the summation
terms in <code>pntGST23_1()</code> .</p>
</td></tr>
<tr><td><code id="pnt_+3A_ixpqfun">IxpqFUN</code></td>
<td>
<p>the (scaled) incomplete beta function <code class="reqn">I_x(p,q)</code> to be
used;  currently, it defaults to the <code>Ixpq</code> function derived from
Nico Temme's Maple code for &ldquo;Table 1&rdquo; in Gil et al. (2023).</p>
</td></tr>
<tr><td><code id="pnt_+3A_alt">alt</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> specifying if and how log-scale should
be used.  <b>Experimental</b> and not-yet-tested.</p>
</td></tr>
<tr><td><code id="pnt_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>IxpqFUN()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>pntR1()</code>:</dt><dd><p>a pure <span class="rlang"><b>R</b></span> version of the (C level)
code of <span class="rlang"><b>R</b></span>'s own <code><a href="stats.html#topic+pt">pt</a>()</code>, additionally giving more
flexibility (via arguments <code>use.pnorm</code>, <code>itrmax</code>, <code>errmax</code>
whose defaults here have been hard-coded in <span class="rlang"><b>R</b></span>'s C code called by <code><a href="stats.html#topic+pt">pt</a>()</code>).
</p>
<p>This implements an improved version of the AS 243 algorithm from
Lenth(1989); </p>

<dl>
<dt><span class="rlang"><b>R</b></span>'s help on non-central <code><a href="stats.html#topic+pt">pt</a>()</code> says:</dt><dd>
<p><em>This computes the lower tail only, so the upper tail suffers from
cancellation and a warning will be given when this is likely to be
significant.</em></p>
</dd>
<dt>and (in &lsquo;Note:&rsquo;)</dt><dd><p><em>The code for non-zero
<code>ncp</code> is principally intended to be used for moderate
values of <code>ncp</code>: it will not be highly accurate,
especially in the tails, for large values.</em></p>
</dd>
</dl>

</dd>
<dt><code>pntR()</code>:</dt><dd><p>the <code><a href="base.html#topic+Vectorize">Vectorize</a>()</code>d version of <code>pntR1()</code>.</p>
</dd>
<dt><code>pntP94()</code>, <code>pntP94.1()</code>:</dt><dd><p>New versions of
<code>pntR1()</code>, <code>pntR()</code>; using the Posten (1994) algorithm.
<code>pntP94()</code> is the <code><a href="base.html#topic+Vectorize">Vectorize</a>()</code>d version of
<code>pntP94.1()</code>.</p>
</dd>
<dt><code>pnt3150()</code>, <code>pnt3150.1()</code>:</dt><dd>
<p>Simple inefficient but hopefully correct version of pntP94..()
This is really a direct implementation of formula
(31.50), p.532 of Johnson, Kotz and Balakrishnan (1995)
</p>
</dd>
<dt><code>pntLrg()</code>:</dt><dd><p>provides the <code><a href="stats.html#topic+pnorm">pnorm</a>()</code>
approximation (to the non-central <code class="reqn">t</code>) from
Abramowitz and Stegun (26.7.10), p.949; which should be employed only for
<em>large</em> <code>df</code> and/or <code>ncp</code>.</p>
</dd>
<dt><code>pntJW39.0()</code>:</dt><dd><p>use the Jennett &amp; Welch (1939) approximation
see Johnson et al. (1995), p. 520, after (31.26a).  This is still
<em>fast</em> for huge <code>ncp</code> but has <em>wrong</em> asymptotic tail
for <code class="reqn">|t| \to \infty</code>.  Crucially needs <code class="reqn">b=</code><code><a href="#topic+b_chi">b_chi</a>(df)</code>.</p>
</dd>
<dt><code>pntJW39()</code>:</dt><dd><p>is an improved version of <code>pntJW39.0()</code>,
using <code class="reqn">1-b =</code><code>b_chi(df, one.minus=TRUE)</code> to avoid
cancellation when computing <code class="reqn">1 - b^2</code>.</p>
</dd>


<dt><code>pntGST23_T6()</code>:</dt><dd><p>(and <code>pntGST23_T6.1()</code> for
informational purposes only) use the Gil et al.(2023)'s
approximation of their Theorem 6.</p>
</dd>
<dt><code>pntGST23_1()</code>:</dt><dd><p>implements Gil et al.(2023)'s direct
<code><a href="stats.html#topic+pbeta">pbeta</a>()</code> based formula (1), which is very close to
Lenth's algorithm.</p>
</dd>
<dt><code>pntVW13()</code>:</dt><dd><p>use MM's <span class="rlang"><b>R</b></span> translation of Viktor
Witkowsk (2013)'s matlab implementation.</p>
</dd>
</dl>



<h3>Value</h3>

<p>a number for <code>pntJKBf1()</code> and <code>.pntJKBch1()</code>.
</p>
<p>a numeric vector of the same length as the maximum of the lengths of
<code>x, df, ncp</code> for  <code>pntJKBf()</code> and <code>.pntJKBch()</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
<em>Continuous Univariate Distributions Vol~2</em>, 2nd ed.; Wiley;
chapter 31, Section <em>5  Distribution Function</em>, p.514 ff
</p>
<p>Lenth, R. V. (1989). <em>Algorithm AS 243</em> &mdash;
Cumulative distribution function of the non-central <code class="reqn">t</code> distribution,
<em>JRSS C (Applied Statistics)</em> <b>38</b>, 185&ndash;189.
</p>
<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover;
formula (26.7.10), p.949
</p>
<p>Posten, Harry O. (1994)
A new algorithm for the noncentral t distribution function,
<em>Journal of Statistical Computation and Simulation</em> <b>51</b>, 79&ndash;87;
<a href="https://doi.org/10.1080/00949659408811623">doi:10.1080/00949659408811623</a>.
</p>
<p>&ndash; not yet implemented &ndash; <br /> 
Chattamvelli, R. and Shanmugam, R. (1994)
An enhanced algorithm for noncentral t-distribution,
<em>Journal of Statistical Computation and Simulation</em> <b>49</b>, 77&ndash;83.
<a href="https://doi.org/10.1080/00949659408811561">doi:10.1080/00949659408811561</a>
</p>
<p>&ndash; not yet implemented &ndash; <br /> 
Akahira, Masafumi. (1995).
A higher order approximation to a percentage point of the noncentral t distribution,
<em>Communications in Statistics - Simulation and Computation</em> <b>24</b>:3, 595&ndash;605;
<a href="https://doi.org/10.1080/03610919508813261">doi:10.1080/03610919508813261</a>
</p>

<p>Michael Perakis and Evdokia Xekalaki (2003)
On a Comparison of the Efficacy of Various Approximations of the Critical Values for Tests on the Process Capability Indices CPL, CPU, and Cpk,
<em>Communications in Statistics - Simulation and Computation</em> <b>32</b>, 1249&ndash;1264;
<a href="https://doi.org/10.1081/SAC-120023888">doi:10.1081/SAC-120023888</a>
</p>
<p>Witkovsk, Viktor (2013)
A Note on Computing Extreme Tail Probabilities of the Noncentral T Distribution with Large
Noncentrality Parameter,
<em>Acta Universitatis Palackianae Olomucensis, Facultas Rerum Naturalium, Mathematica</em>

<b>52</b>(2), 131&ndash;143. 
</p>
<p>Gil A., Segura J., and Temme N.M. (2023)
New asymptotic representations of the noncentral t-distribution,
<em>Stud Appl Math.</em> <b>151</b>, 857&ndash;882; <a href="https://doi.org/10.1111/sapm.12609">doi:10.1111/sapm.12609</a> ;
acronym &ldquo;GST23&rdquo;.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pt">pt</a></code>, for <span class="rlang"><b>R</b></span>'s version of non-central t probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tt &lt;- seq(0, 10, len = 21)
ncp &lt;- seq(0, 6, len = 31)
pt3R   &lt;- outer(tt, ncp, pt, , df = 3)
pt3JKB &lt;- outer(tt, ncp, pntR, df = 3)# currently verbose
stopifnot(all.equal(pt3R, pt3JKB, tolerance = 4e-15))# 64-bit Lnx: 2.78e-16


## Gil et al.(2023) -- Table 1 p.869
str(GST23_tab1 &lt;- read.table(header=TRUE, text = "
 x     pnt_x_delta              Rel.accuracy   l_y   j_max
 5     0.7890745035061528e-20    0.20e-13    0.29178   254
 8     0.1902963697413609e-07    0.40e-12    0.13863   294
11     0.4649258368179092e-03    0.12e-09    0.07845   310
14     0.2912746016055676e-01    0.11e-07    0.04993   317
17     0.1858422833307925e-00    0.41e-06    0.03441   321
20     0.4434882973203470e-00    0.82e-05    0.02510   323"))

x1 &lt;- c(5,8,11,14,17,20)
(p1  &lt;- pt  (x1, df=10.3, ncp=20))
(p1R &lt;- pntR(x1, df=10.3, ncp=20)) # verbose=TRUE  is default
all.equal(p1, p1R, tolerance=0) # 4.355452e-15 {on x86_64} as have *no* LDOUBLE on R level
stopifnot(all.equal(p1, p1R))
## NB: According to Gil et al., the first value (x=5) is really wrong
## p1.23 &lt;- .. Gil et al., Table 1:
p1.23.11 &lt;- pntGST23_T6(x1, df=10.3, ncp=20, Mterms = 11)
p1.23.20 &lt;- pntGST23_T6(x1, df=10.3, ncp=20, Mterms = 20, verbose=TRUE)
                                        # ==&gt; Mterms = 11 is good only for x=5
p1.23.50 &lt;- pntGST23_T6(x1, df=10.3, ncp=20, Mterms = 50, verbose=TRUE)

x &lt;- 4:40 ; df &lt;- 10.3
ncp &lt;- 20
p1     &lt;- pt        (x, df=df, ncp=ncp)
pG1    &lt;- pntGST23_1(x, df=df, ncp=ncp)
pG1.bR &lt;- pntGST23_1(x, df=df, ncp=ncp,
                     IxpqFUN = \(x, l_x=.5-x+.5, p, q) Ixpq(x,l_x, p,q))
pG1.BR &lt;- pntGST23_1(x, df=df, ncp=ncp,
                     IxpqFUN = \(x, l_x, p, q)   pbeta(x, p,q))
cbind(x, p1, pG1, pG1.bR, pG1.BR)
all.equal(pG1, p1,     tolerance=0) # 1.034 e-12
all.equal(pG1, pG1.bR, tolerance=0) # 2.497031 e-13
all.equal(pG1, pG1.BR, tolerance=0) # 2.924698 e-13
all.equal(pG1.BR,pG1.bR,tolerance=0)# 1.68644  e-13
stopifnot(exprs = {
    all.equal(pG1, p1,     tolerance = 4e-12)
    all.equal(pG1, pG1.bR, tolerance = 1e-12)
    all.equal(pG1, pG1.BR, tolerance = 1e-12)
  })

ncp &lt;- 40 ## is  &gt; 37.62 = "critical" for Lenth' algorithm

### --------- pntVW13() --------------------------------------------------
## length 1 arguments:
str(rr &lt;- pntVW13(t = 1, df = 2, ncp = 3, verbose=TRUE, keepS=TRUE))
all.equal(rr$cdf, pt(1,2,3), tol = 0)#  "Mean relative difference: 4.956769e-12"
stopifnot( all.equal(rr$cdf, pt(1,2,3)) )

str(rr &lt;- pntVW13(t = 1:19, df = 2,    ncp = 3,    verbose=TRUE, keepS=TRUE))
str(r2 &lt;- pntVW13(t = 1,    df = 2:20, ncp = 3,    verbose=TRUE, keepS=TRUE))
str(r3 &lt;- pntVW13(t = 1,    df = 2:20, ncp = 3:21, verbose=TRUE, keepS=TRUE))

pt1.10.5_T &lt;- 4.34725285650591657e-5 # Ex. 7 of Witkovsky(2013)
pt1.10.5 &lt;- pntVW13(1, 10, 5)
all.equal(pt1.10.5_T, pt1.10.5, tol = 0)# TRUE! (Lnx Fedora 40; 2024-07-04);
			# 3.117e-16 (Macbuilder R 4.4.0, macOS Ventura 13.3.1)
stopifnot(exprs = {
    identical(rr$cdf, r1 &lt;- pntVW13(t = 1:19, df = 2, ncp = 3))
    identical(r1[1], pntVW13(1, 2, 3))
    identical(r1[7], pntVW13(7, 2, 3))
    all.equal(pt1.10.5_T, pt1.10.5, tol = 9e-16)# NB even tol=0 (64 Lnx)
})
## However, R' pt() is only equal for the very first
cbind(t = 1:19, pntVW = r1, pt = pt(1:19, 2,3))

</code></pre>

<hr>
<h2 id='pow'>X to Power of Y &ndash; R C API <code>R_pow()</code></h2><span id='topic+pow'></span><span id='topic+pow_di'></span><span id='topic+.pow'></span>

<h3>Description</h3>

<p><code>pow(x,y)</code> calls <span class="rlang"><b>R</b></span> C API &lsquo;<span class="file">Rmathlib</span>&rsquo;'s <code>R_pow(x,y)</code>
function to compute <code>x^y</code> <em>or</em> when <code>try.int.y</code> is true
(as by default), and <code>y</code> is integer valued and fits into integer
range, <code>R_pow_di(x,y)</code>.
</p>
<p><code>pow_di(x,y)</code> with integer <code>y</code> calls <span class="rlang"><b>R</b></span> mathlib's <code>R_pow_di(x,y)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pow   (x, y, try.int.y = TRUE)
pow_di(x, y)
.pow  (x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pow_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="pow_+3A_y">y</code></td>
<td>
<p>a numeric or in the case of <code>pow_di()</code> integer vector.</p>
</td></tr>
<tr><td><code id="pow_+3A_try.int.y">try.int.y</code></td>
<td>
<p>logical indicating if <code>pow()</code> should check if
<code>y</code> is integer valued and fits into integer range, and in that
case call <code>pow_di()</code> automatically.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In January 2024, I found (e.g., in &lsquo;<span class="file">tests/pow-tst.R</span>&rsquo;) 
that the accuracy of <code>pow_di()</code>, i.e., also the C function
<code>R_pow_di()</code> in <span class="rlang"><b>R</b></span>'s API is of much lower precision than <span class="rlang"><b>R</b></span>'s
<code>x^y</code> or (equivalently) <code>R_pow(x,y)</code> in <span class="rlang"><b>R</b></span>'s API, notably on
Linux and macOS, using glib etc, sometimes as soon as <code class="reqn">y \ge 6</code>
or so.
</p>
<p><code>.pow(x,y)</code> is identical to <code>pow(x,y, try.int.y = FALSE)</code>
</p>


<h3>Value</h3>

<p>a numeric vector like <code>x</code> or <code>y</code> which are recycled to common
length, of course.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p>Base <span class="rlang"><b>R</b></span>'s <code><a href="base.html#topic++5E">^</a></code> &ldquo;operator&rdquo;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(27)
x &lt;- rnorm(100)
y &lt;- 0:9
stopifnot(exprs = {
    all.equal(x^y, pow(x,y))
    all.equal(x^y, pow(x,y, FALSE))
    all.equal(x^y, pow_di(x,y))
})
</code></pre>

<hr>
<h2 id='pow1p'>Accurate <code class="reqn">(1+x)^y</code>, notably for small <code class="reqn">|x|</code></h2><span id='topic+pow1p'></span>

<h3>Description</h3>

<p>Compute <code class="reqn">(1+x)^y</code> accurately, notably also for small <code class="reqn">|x|</code>, where
the naive formula suffers from cancellation, returning <code>1</code>, often.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pow1p(x, y,
      pow = ((x + 1) - 1) == x || abs(x) &gt; 0.5 || is.na(x))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pow1p_+3A_x">x</code>, <code id="pow1p_+3A_y">y</code></td>
<td>
<p>numeric or number-like; in the latter case, arithmetic incl. <code>^</code>,
comparison, <code><a href="base.html#topic+exp">exp</a></code>, <code><a href="base.html#topic+log1p">log1p</a></code>, <code><a href="base.html#topic+abs">abs</a></code>,
and <code><a href="base.html#topic+is.na">is.na</a></code> methods must work.</p>
</td></tr>
<tr><td><code id="pow1p_+3A_pow">pow</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if the &ldquo;naive&rdquo; /
direct computation <code>(1 + x)^y</code> should be used (unless <code>y</code> is
in 0:4, where the binomial is used, see &lsquo;Details&rsquo;).
The current default is the one used in R's C-level function (but beware
of compiler optimization there!).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A pure <span class="rlang"><b>R</b></span>-implementation of R 4.4.0's new C-level
<code>pow1p()</code> function which was introduced for more accurate
<code><a href="#topic+dbinom_raw">dbinom_raw</a>()</code> computations.
</p>
<p>Currently, we use the &ldquo;exact&rdquo; (nested) polynomial formula for
<code class="reqn">y \in \{0,1,2,3,4\}</code>.
</p>
<p>MM is conjecturing that the default <code>pow=FALSE</code> for (most)
<code class="reqn">x \le \frac 1 2</code> is sub-optimal.
</p>


<h3>Value</h3>

<p>numeric or number-like, as <code>x + y</code>.
</p>


<h3>Author(s)</h3>

<p>Originally proposed by Morten Welinder, see <a href="https://bugs.R-project.org/show_bug.cgi?id=18642">PR#18642</a>;
tweaked, notably for small integer <code>y</code>, by Martin Maechler.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic++5E">^</a></code>, <code><a href="base.html#topic+log1p">log1p</a></code>,
<code><a href="#topic+dbinom_raw">dbinom_raw</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 2^-(1:50)
y &lt;- 99
f1 &lt;- (1+x)^99
f2 &lt;- exp(y * log1p(x))
fp &lt;- pow1p(x, 99)
matplot(x, cbind(f1, f2, fp), type = "l", col = 2:4)
legend("top", legend = expression((1+x)^99, exp(99 * log1p(x)), pow1p(x, 99)),
       bty="n", col=2:4, lwd=2)
cbind(x, f1, f2, sfsmisc::relErrV(f2, f1))
</code></pre>

<hr>
<h2 id='ppoisson'>Direct Computation of 'ppois()' Poisson Distribution Probabilities</h2><span id='topic+ppoisErr'></span><span id='topic+ppoisD'></span>

<h3>Description</h3>

<p>Direct computation and errors of <code><a href="stats.html#topic+ppois">ppois</a></code> Poisson distribution
probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ppoisD(q, lambda, all.from.0 = TRUE, verbose = 0L)
ppoisErr (lambda, ppFUN = ppoisD, iP = 1e-15,
          xM = qpois(iP, lambda=lambda, lower.tail=FALSE),
          verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppoisson_+3A_q">q</code></td>
<td>
<p>numeric vector of non-negative integer values,
&ldquo;quantiles&rdquo; at which to evaluate <code><a href="stats.html#topic+ppois">ppois</a>(q, la)</code> and
<code>ppFUN(q, la)</code>.</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_lambda">lambda</code></td>
<td>
<p>positive parameter of the Poisson distribution,
<code>lambda</code><code class="reqn">= \lambda = E[X] = Var[X]</code> where
<code class="reqn">X \sim Pois(\lambda)</code>.</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_all.from.0">all.from.0</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if <code>q</code> is
positive integer, and the probabilities should computed for all
quantile values of <code>0:q</code>.</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_ppfun">ppFUN</code></td>
<td>
<p>alternative <code><a href="stats.html#topic+ppois">ppois</a></code> evaluation, by default the
<b>d</b>irect summation of <code><a href="stats.html#topic+dpois">dpois</a>(k, lambda)</code>.</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_ip">iP</code></td>
<td>
<p>small number, <code>iP &lt;&lt; 1</code>, used to construct the abscissa values
<code>x</code> at which to evaluate and compare <code>ppois()</code> and
<code>ppFUN()</code>, see <code>xM</code>:</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_xm">xM</code></td>
<td>
<p>(specified instead of <code>iP</code>: ) the maximal x-value to be
used, i.e., the values used will be <code>x &lt;- 0:iM</code>.  The default,
<code>qpois(1-iP, lambda = lambda)</code> is the upper tail
<code>iP</code>-quantile of <code>Poi(lambda)</code>.</p>
</td></tr>
<tr><td><code id="ppoisson_+3A_verbose">verbose</code></td>
<td>
<p><code><a href="base.html#topic+integer">integer</a></code> (<code class="reqn">\ge 0</code>) or
<code><a href="base.html#topic+logical">logical</a></code> indicating if extra information should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ppoisD()</code> contains the poisson probabilities along <code>q</code>, i.e.,
is a numeric vector of length <code>length(q)</code>.
</p>
<p><code>re &lt;- ppoisErr()</code> returns the relative &ldquo;error&rdquo; of
<code><a href="stats.html#topic+ppois">ppois</a>(x0, lambda)</code> where <code>ppFUN(x0, lambda)</code> is
assumed to be the truth and <code>x0</code> the &ldquo;worst case&rdquo;, i.e., the
value (among <code>x</code>) with the largest such difference.
</p>
<p>Additionally, <code>attr(re, "x0")</code> contains that value <code>x0</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, March 2004; 2019 ff</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ppois">ppois</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(lams &lt;- outer(c(1,2,5), 10^(0:3)))# 10^4 is already slow!
system.time(e1 &lt;- sapply(lams, ppoisErr))
e1 / .Machine$double.eps

## Try another 'ppFUN' :---------------------------------
## this relies on the fact that it's *only* used on an 'x' of the form  0:M :
ppD0 &lt;- function(x, lambda, all.from.0=TRUE)
            cumsum(dpois(if(all.from.0) 0:x else x, lambda=lambda))
## and test it:
p0 &lt;- ppD0 (  1000, lambda=10)
p1 &lt;- ppois(0:1000, lambda=10)
stopifnot(all.equal(p0,p1, tol=8*.Machine$double.eps))

system.time(p0.slow &lt;- ppoisD(0:1000, lambda=10, all.from.0=FALSE))# not very slow, here
p0.1 &lt;- ppoisD(1000, lambda=10)
if(requireNamespace("Rmpfr")) {
 ppoisMpfr &lt;- function(x, lambda) cumsum(Rmpfr::dpois(x, lambda=lambda))
 p0.best &lt;- ppoisMpfr(0:1000, lambda = Rmpfr::mpfr(10, precBits = 256))
 AllEq. &lt;- Rmpfr::all.equal
 AllEq &lt;- function(target, current, ...)
    AllEq.(target, current, ...,
           formatFUN = function(x, ...) Rmpfr::format(x, digits = 9))
 print(AllEq(p0.best, p0,      tol = 0)) # 2.06e-18
 print(AllEq(p0.best, p0.slow, tol = 0)) # the "worst" (4.44e-17)
 print(AllEq(p0.best, p0.1,    tol = 0)) # 1.08e-18
}

## Now (with 'all.from.0 = TRUE',  it is fast too):
p15    &lt;- ppoisErr(2^13)
p15.0. &lt;- ppoisErr(2^13, ppFUN = ppD0)
c(p15, p15.0.) / .Machine$double.eps # on Lnx 64b, see (-10  2.5), then (-2 -2)

## lapply(), so you see "x0" values :
str(e0. &lt;- lapply(lams, ppoisErr, ppFUN = ppD0))

## The first version [called 'err.lambd0()' for years] used simple  cumsum(dpois(..))
## NOTE: It is *stil* much faster, as it relies on special  x == 0:M  relation
## Author: Martin Maechler, Date:  1 Mar 2004, 17:40
##
e0 &lt;- sapply(lams, function(lamb) ppoisErr(lamb, ppFUN = ppD0))
all.equal(e1, e0) # typically TRUE,  though small "random" differences:
cbind(e1, e0) * 2^53 # on Lnx 64b, seeing integer values in {-24, .., 33}
</code></pre>

<hr>
<h2 id='pt_Witkovsky_Tab1'>Viktor Witosky's Table_1  pt() Examples</h2><span id='topic+pt_Witkovsky_Tab1'></span>

<h3>Description</h3>

<p>A data frame with 17  <code>pt()</code> examples from Witosky (2013)'s &lsquo;Table 1&rsquo;.
We provide the results for the FOSS Softwares,
additionally including <code>octave</code>'s, running the original 2013
matlab code, and the corrected one from 2022.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pt_Witkovsky_Tab1)
</code></pre>


<h3>Format</h3>

<p>A data frame with 17 observations on the following <code><a href="base.html#topic+numeric">numeric</a></code> variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>the abscissa, called <code>q</code> in <code><a href="stats.html#topic+pt">pt</a>()</code>.</p>
</dd>
<dt><code>nu</code></dt><dd><p>the <em>positive</em> degrees of freedom, called <code>df</code> in <code><a href="stats.html#topic+pt">pt</a>()</code>.</p>
</dd>
<dt><code>delta</code></dt><dd><p>the noncentrality parameter, called <code>ncp</code> in <code><a href="stats.html#topic+pt">pt</a>()</code>.</p>
</dd>
<dt><code>true_pnt</code></dt><dd><p>&ldquo;true&rdquo; values (computed via higher precision, see Witkovsky(2013)).</p>
</dd>
<dt><code>NCTCDFVW</code></dt><dd><p>the <code>pt()</code> values computed with Witkovsky's
matlab implementation.  Confirmed by using <code>octave</code> (on Fedora 40 Linux).
These correspond to our <span class="rlang"><b>R</b></span> (package <a href="https://CRAN.R-project.org/package=DPQ"><span class="pkg">DPQ</span></a>) <code><a href="#topic+pntVW13">pntVW13</a>()</code> values.</p>
</dd>
<dt><code>Boost</code></dt><dd><p>computed via the Boost C++ library; reported by Witkovsky.</p>
</dd>
<dt><code>R_3.3.0</code></dt><dd><p>computed by R version 3.3.0; confirmed to be
identical using R 4.4.1</p>
</dd>
<dt><code>NCT2013_octave_7.3.0</code></dt><dd><p>values computed using Witkovsky's
original matlab code, by <code>octave</code> 7.3.0</p>
</dd>
<dt><code>NCT2022_octave_8.4.0</code></dt><dd><p>values computed using Witkovsky's
2022 corrected matlab code, by <code>octave</code> 8.4.0</p>
</dd>
</dl>



<h3>Source</h3>


<p>The table was extracted (by MM) from the result of
<code>pdftotext --layout &lt;*&gt;.pdf</code> from the publication.
The <code>NCT2013_octave_7.3.0</code> column was computed from the 2013 code,
using GPL <code>octave 7.3.0</code> on Linux Fedora 38, whereas
<code>NCT2013_octave_8.4..0</code> from the 2022 code,
using GPL <code>octave 8.4.0</code> on Linux Fedora 40.
</p>
<p>Note that the &lsquo;<span class="file">arXiv</span>&rsquo; pre-publication has very slightly differing
numbers in its <code style="white-space: pre;">&#8288;R&#8288;</code> column, e.g., first entry ending in <code>00200</code>
instead of <code>00111</code>.
</p>


<h3>References</h3>

<p>Witkovsk, Viktor (2013)
A Note on Computing Extreme Tail Probabilities of the Noncentral T Distribution with Large
Noncentrality Parameter,
<em>Acta Universitatis Palackianae Olomucensis, Facultas Rerum Naturalium, Mathematica</em>

<b>52</b>(2), 131&ndash;143. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pt_Witkovsky_Tab1)
stopifnot(is.data.frame(d.W &lt;- pt_Witkovsky_Tab1), # shorter
          nrow(d.W) &gt;= 17)
mW &lt;- as.matrix(d.W); row.names(mW) &lt;- NULL # more efficient
colnames(mW)[1:3] #  "x" "nu" "delta"
## use 'R pt() - compatible' names:
(n3 &lt;- names(formals(pt)[1:3]))# "q" "df" "ncp"
colnames(mW)[1:3] &lt;- n3
ptR &lt;- apply(mW[, 1:3], 1, \(a3) unname(do.call(pt, as.list(a3))))
cNm &lt;- paste0("R_", with(R.version, paste(major, minor, sep=".")))
mW &lt;- cbind(mW, `colnames&lt;-`(cbind(ptR), cNm),
            relErr = sfsmisc::relErrV(mW[,"true_pnt"], ptR))
mW
## is current R better than R 3.3.0?  -- or even "the same"?
all.equal(ptR, mW[,"R_3.3.0"])                    # still true in R 4.4.1
all.equal(ptR, mW[,"R_3.3.0"], tolerance = 1e-14) # (ditto)
table(ptR == mW[,"R_3.3.0"]) # {see only 4 (out of 17) *exactly* equal ??}

## How close to published NCTCDFVW is octave's run of the 2022 code?
with(d.W, all.equal(NCTCDFVW, NCT2022_octave_8.4.0, tolerance = 0)) # 3.977e-16

pVW &lt;- apply(unname(mW[, 1:3]), 1, \(a3) unname(do.call(pntVW13, as.list(a3))))
all.equal(pVW, d.W$NCT2013_oct, tolerance = 0)# 2013-based pntVW13() --&gt; 5.6443e-16
all.equal(pVW, d.W$NCT2022_oct, tolerance = 0)
</code></pre>

<hr>
<h2 id='qbetaAppr'>Compute (Approximate) Quantiles of the Beta Distribution</h2><span id='topic+qbetaAppr.1'></span><span id='topic+qbetaAppr.3'></span><span id='topic+qbetaAppr.2'></span><span id='topic+qbetaAppr.4'></span><span id='topic+qbetaAppr'></span><span id='topic+qbeta.R'></span>

<h3>Description</h3>

<p>Compute quantiles (inverse distribution values) of the beta distribution,
using diverse approximations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
qbetaAppr.1(a, p, q, lower.tail=TRUE, log.p=FALSE,
            y = qnormUappr(a, lower.tail=lower.tail, log.p=log.p))

qbetaAppr.2(a, p, q, lower.tail=TRUE, log.p=FALSE, logbeta = lbeta(p,q))
qbetaAppr.3(a, p, q, lower.tail=TRUE, log.p=FALSE, logbeta = lbeta(p,q))
qbetaAppr.4(a, p, q, lower.tail=TRUE, log.p=FALSE,
            y = qnormUappr(a, lower.tail=lower.tail, log.p=log.p),
            verbose = getOption("verbose"))

qbetaAppr  (a, p, q, lower.tail=TRUE, log.p=FALSE,
            y = qnormUappr(a, lower.tail=lower.tail, log.p=log.p),
            logbeta = lbeta(p,q),
            verbose = getOption("verbose") &amp;&amp; length(a) == 1)

qbeta.R    (alpha, p, q,
            lower.tail = TRUE, log.p = FALSE,
	    logbeta = lbeta(p,q),
	    low.bnd = 3e-308, up.bnd = 1-2.22e-16,
            method = c("AS109", "Newton-log"),
            tol.outer = 1e-15,
	    f.acu = function(a,p,q) max(1e-300, 10^(-13- 2.5/pp^2 - .5/a^2)),
	    fpu = .Machine$ double.xmin,
	    qnormU.fun = function(u, lu) qnormUappr(p=u, lp=lu)
          , R.pre.2014 = FALSE
	  , verbose = getOption("verbose")
          , non.finite.report = verbose
           )
</code></pre>


<h3>Arguments</h3>




<table role = "presentation">
<tr><td><code id="qbetaAppr_+3A_a">a</code>, <code id="qbetaAppr_+3A_alpha">alpha</code></td>
<td>
<p>vector of probabilities (otherwise, e.g., in
<code><a href="stats.html#topic+qbeta">qbeta</a>()</code>, called <code>p</code>).</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_p">p</code>, <code id="qbetaAppr_+3A_q">q</code></td>
<td>
<p>the two shape parameters of the beta distribution; otherwise, e.g., in
<code><a href="stats.html#topic+qbeta">qbeta</a>()</code>, called <code>shape1</code> and <code>shape2</code>.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_y">y</code></td>
<td>
<p>an approximation to <code class="reqn">\Phi^{-1}(1-\alpha)</code> (aka
<code class="reqn">z_{1-\alpha}</code>) where <code class="reqn">\Phi(x)</code> is the standard normal
cumulative probability function and <code class="reqn">\Phi{-1}(x)</code> its inverse,
i.e., <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qnorm">qnorm</a>(x)</code>.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_lower.tail">lower.tail</code>, <code id="qbetaAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qchisq">qchisq</a>()</code>; must
have length 1.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_logbeta">logbeta</code></td>
<td>
<p>must be <code><a href="base.html#topic+lbeta">lbeta</a>(p,q)</code>; mainly an option to pass
a value already computed.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_verbose">verbose</code></td>
<td>
<p>logical or integer indicating if and how much
&ldquo;monitoring&rdquo; information should be produced by the algorithm.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_low.bnd">low.bnd</code>, <code id="qbetaAppr_+3A_up.bnd">up.bnd</code></td>
<td>
<p>lower and upper bounds for ...TODO...</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_method">method</code></td>
<td>
<p>a string specifying the approximation method to be used.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_tol.outer">tol.outer</code></td>
<td>
<p>the &ldquo;outer loop&rdquo; convergence tolerance; the
default <code>1e-15</code> has been hardwired in <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qbeta">qbeta</a>()</code>.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_f.acu">f.acu</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a></code> with arguments <code>(a,p,q)</code> ...TODO...</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_fpu">fpu</code></td>
<td>
<p>a very small positive number.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_qnormu.fun">qnormU.fun</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a></code> with arguments <code>(u,lu)</code>
to compute &ldquo;the same&rdquo; as <code><a href="#topic+qnormUappr">qnormUappr</a>()</code>, the upper
standard normal quantile.</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_r.pre.2014">R.pre.2014</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> ... TODO ...</p>
</td></tr>
<tr><td><code id="qbetaAppr_+3A_non.finite.report">non.finite.report</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if during the
&ldquo;outer loop&rdquo; refining iterations, if <code>y</code> becomes non finite
and the iterations have to stop, it should be reported (before the
current best value is returned).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>...
</p>


<h3>Author(s)</h3>

<p>The R Core Team for the C version of <code><a href="stats.html#topic+qbeta">qbeta</a></code> in <span class="rlang"><b>R</b></span>'s sources;
Martin Maechler for the <span class="rlang"><b>R</b></span> port, and the approximations.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qbeta">qbeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> qbeta.R(0.6, 2, 3) # 0.4445
 qbeta.R(0.6, 2, 3) - qbeta(0.6, 2,3) # almost 0

 qbetaRV &lt;- Vectorize(qbeta.R, "alpha") # now can use
 curve(qbetaRV(x, 1.5, 2.5))
 curve(qbeta  (x, 1.5, 2.5), add=TRUE, lwd = 3, col = adjustcolor("red", 1/2))

 ## an example of disagreement (and doubt, as borderline, close to underflow):
 qbeta.R(0.5078, .01, 5) # -&gt;  2.77558e-15    # but
 qbeta  (0.5078, .01, 5) # now gives 4.651188e-31  -- correctly!
 qbeta  (0.5078, .01, 5, ncp=0)# ditto
 ## which is because qbeta() now works in log-x scale here:
 curve(pbeta(x, .01, 5), 1e-40, 1, n=10001, log="x", xaxt="n")
 sfsmisc::eaxis(1); abline(h=.5078, lty=3); abline(v=4.651188e-31,col=2)
</code></pre>

<hr>
<h2 id='qbinomR'>Pure R Implementation of R's qbinom()  with Tuning Parameters</h2><span id='topic+qbinomR'></span>

<h3>Description</h3>


<p>A pure R implementation, including many tuning parameter arguments, of
<span class="rlang"><b>R</b></span>'s own Rmathlib C code algorithm, but with more flexibility.
</p>
<p>It is using <code><a href="base.html#topic+Vectorize">Vectorize</a>(qbinomR1, *)</code> where the hidden
<code>qbinomR1</code> works for numbers (aka &lsquo;scalar&rsquo;, length one)
arguments only, the same as the C code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qbinomR(p, size, prob, lower.tail = TRUE, log.p = FALSE,
        yLarge = 4096, # was hard wired to 1e5
        incF = 1/64,   # was hard wired to .001
        iShrink = 8,   # was hard wired to 100
        relTol = 1e-15,# was hard wired to 1e-15
        pfEps.n = 8,   # was hard wired to 64: "fuzz to ensure left continuity"
        pfEps.L = 2,   # was hard wired to 64:   "   "   ..
        fpf = 4, # *MUST* be &gt;= 1 (did not exist previously)
        trace = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qbinomR_+3A_p">p</code>, <code id="qbinomR_+3A_size">size</code>, <code id="qbinomR_+3A_prob">prob</code>, <code id="qbinomR_+3A_lower.tail">lower.tail</code>, <code id="qbinomR_+3A_log.p">log.p</code></td>
<td>
<p><code><a href="stats.html#topic+qbinom">qbinom</a>()</code> standard
argument, see its help page.</p>
</td></tr>

<tr><td><code id="qbinomR_+3A_ylarge">yLarge</code></td>
<td>
<p>when <code class="reqn">y &gt;= y_L, y_L =</code> <code>yLarge</code>, the binary root
finding search is made  &ldquo;cleverer&rdquo;, taking larger increments,
determined by <code>incF</code> and <code>iShrink</code>:</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_incf">incF</code></td>
<td>
<p>a positive &ldquo;increment factor&rdquo; (originally hardwired to
0.001), used only when <code>y &gt;= yLarge</code>; defines the initial increment in
the search algorithm as <code>incr &lt;- floor(incF * y)</code>.</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_ishrink">iShrink</code></td>
<td>
<p>a positive increment shrinking factor, used only when
<code>y &gt;= yLarge</code> to define the new increment from the old one as
<code>incr &lt;- max(1, floor(incr/iShrink))</code> where the LHS was hardired
original to <code>(incr/100)</code>.</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_reltol">relTol</code></td>
<td>
<p>relative tolerance, <code class="reqn"> &gt; 0</code>; the search terminates when
the (integer!) increment is less than <code>relTol * y</code> or the previous
increment was not larger than 1.</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_pfeps.n">pfEps.n</code></td>
<td>
<p>fuzz factor to ensure left continuity in the <b>n</b>ormal
case <code>log.p=FALSE</code>; used to be hardwired to 64 (in <span class="rlang"><b>R</b></span> up to 2021-05-08).</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_pfeps.l">pfEps.L</code></td>
<td>
<p>fuzz factor to ensure left continuity in case
<code>log.p=TRUE</code>; used to be hardwired to 64 (in <span class="rlang"><b>R</b></span> up to 2021-05-08).</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_fpf">fpf</code></td>
<td>
<p>factor <code class="reqn">f \ge 1</code> for the <b>n</b>ormal upper tail case
(<code>log.p=FALSE, lower.tail=FALSE</code>): <code>p</code> is only &ldquo;fuzz-corrected&rdquo;,
i.e., multiplied by <code class="reqn">1+e</code> when <code>1 - p &gt; fpf*e</code> for
<code>e &lt;- pfEps.n * c_e</code> and <code class="reqn">c_e = 2^{-52}</code>, the <code>.Machine$double_epsilon</code>.
</p>
</td></tr>
<tr><td><code id="qbinomR_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) specifying if (and how much) output
should be produced from the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>as mentioned on <code><a href="stats.html#topic+qbinom">qbinom</a></code> help page, 
<code>qbinom</code> uses the Cornish&ndash;Fisher Expansion to include a skewness
correction to a normal approximation, thus defining <code>y := Fn(p, size, prob, ..)</code>.
</p>
<p>The following (root finding) binary search is tweaked by the
<code>yLarge, ..., fpf</code> arguments.
</p>


<h3>Value</h3>

<p>a numeric vector like <code>p</code> recycled to the common lengths of
<code>p</code>, <code>size</code>, and <code>prob</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qbinom">qbinom</a></code>, <code><a href="stats.html#topic+qpois">qpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12)
pr &lt;- (0:16)/16 # supposedly recycled
x10 &lt;- rbinom(500, prob=pr, size =  10); p10 &lt;- pbinom(x10, prob=pr, size= 10)
x1c &lt;- rbinom(500, prob=pr, size = 100); p1c &lt;- pbinom(x1c, prob=pr, size=100)
## stopifnot(exprs = {
table( x10  == (qp10  &lt;- qbinom (p10, prob=pr, size= 10) ))
table( qp10 == (qp10R &lt;- qbinomR(p10, prob=pr, size= 10) )); summary(warnings()) # 30 x NaN
table( x1c  == (qp1c  &lt;- qbinom (p1c, prob=pr, size=100) ))
table( qp1c == (qp1cR &lt;- qbinomR(p1c, prob=pr, size=100) )); summary(warnings()) # 30 x NaN
## })
</code></pre>

<hr>
<h2 id='qchisqAppr'>Compute Approximate Quantiles of the Chi-Squared Distribution</h2><span id='topic+qchisqKG'></span><span id='topic+qchisqWH'></span><span id='topic+qchisqAppr'></span><span id='topic+qchisqAppr.R'></span>

<h3>Description</h3>

<p>Compute quantiles (inverse distribution values) for the chi-squared distribution.
using Johnson,Kotz,.. ............TODO.......
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qchisqKG    (p, df, lower.tail = TRUE, log.p = FALSE)
qchisqWH    (p, df, lower.tail = TRUE, log.p = FALSE)
qchisqAppr  (p, df, lower.tail = TRUE, log.p = FALSE, tol = 5e-7)
qchisqAppr.R(p, df, lower.tail = TRUE, log.p = FALSE, tol = 5e-07,
             maxit = 1000, verbose = getOption("verbose"), kind = NULL)
</code></pre>


<h3>Arguments</h3>


<table role = "presentation">
<tr><td><code id="qchisqAppr_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="qchisqAppr_+3A_df">df</code></td>
<td>
<p>degrees of freedom <code class="reqn">&gt; 0</code>, maybe non-integer; must have
length 1.</p>
</td></tr>
<tr><td><code id="qchisqAppr_+3A_lower.tail">lower.tail</code>, <code id="qchisqAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qchisq">qchisq</a>()</code>; must
have length 1.</p>
</td></tr>
<tr><td><code id="qchisqAppr_+3A_tol">tol</code></td>
<td>
<p>non-negative number, the convergence tolerance</p>
</td></tr>

<tr><td><code id="qchisqAppr_+3A_maxit">maxit</code></td>
<td>
<p>the maximal number of iterations</p>
</td></tr>
<tr><td><code id="qchisqAppr_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if the algorithm should produce
&ldquo;monitoring&rdquo; information.</p>
</td></tr>
<tr><td><code id="qchisqAppr_+3A_kind">kind</code></td>
<td>
<p>the <em>kind</em> of approximation; if <code>NULL</code>, the
default, the approximation chosen depends on the arguments; notably it
is chosen separately for each <code>p</code>.  Otherwise, it must be a
<code><a href="base.html#topic+character">character</a></code> string.  The main approximations are
Wilson-Hilferty versions, when the string contains <code>"WH"</code>.
More specifically, it must be one of the strings
</p>

<dl>
<dt>&quot;chi.small&quot;</dt><dd><p>particularly useful for small chi-squared values <code>p</code>;... ...</p>
</dd>
<dt>&quot;WH&quot;</dt><dd><p>... ...</p>
</dd>
<dt>&quot;p1WH&quot;</dt><dd><p>... ...</p>
</dd>
<dt>&quot;WHchk&quot;</dt><dd><p>... ...</p>
</dd>
<dt>&quot;df.small&quot;</dt><dd><p>particularly useful for small degrees of freedom <code>df</code>... ...</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Value</h3>

<p>...
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qchisq">qchisq</a></code>.   Further, our approximations to the
<em>non-central</em> chi-squared quantiles, <code><a href="#topic+qnchisqAppr">qnchisqAppr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## TODO
</code></pre>

<hr>
<h2 id='qgammaAppr'>Compute (Approximate) Quantiles of the Gamma Distribution</h2><span id='topic+qgammaAppr'></span><span id='topic+qgamma.R'></span><span id='topic+qgammaApprKG'></span><span id='topic+qgammaApprSmallP'></span><span id='topic+.qgammaApprBnd'></span>

<h3>Description</h3>

<p>Compute approximations to the quantile (i.e., inverse cumulative)
function of the Gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qgammaAppr(p, shape, lower.tail = TRUE, log.p = FALSE,
           tol = 5e-07)
qgamma.R  (p, alpha, scale = 1, lower.tail = TRUE, log.p = FALSE,
           EPS1 = 0.01, EPS2 = 5e-07, epsN = 1e-15, maxit = 1000,
           pMin = 1e-100, pMax = (1 - 1e-14),
           verbose = getOption("verbose"))

qgammaApprKG(p, shape, lower.tail = TRUE, log.p = FALSE)
 

qgammaApprSmallP(p, shape, lower.tail = TRUE, log.p = FALSE)
 
 

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qgammaAppr_+3A_p">p</code></td>
<td>
<p>numeric vector (possibly log tranformed) probabilities.</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_shape">shape</code>, <code id="qgammaAppr_+3A_alpha">alpha</code></td>
<td>
<p>shape parameter, non-negative.</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_scale">scale</code></td>
<td>
<p>scale parameter, non-negative, see <code><a href="stats.html#topic+qgamma">qgamma</a></code>.</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_lower.tail">lower.tail</code>, <code id="qgammaAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qgamma">qgamma</a>()</code>; must
have length 1.</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_tol">tol</code></td>
<td>
<p>tolerance of maximal approximation error.</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_eps1">EPS1</code></td>
<td>
<p>small positive number. ...</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_eps2">EPS2</code></td>
<td>
<p>small positive number. ...</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_epsn">epsN</code></td>
<td>
<p>small positive number. ...</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_maxit">maxit</code></td>
<td>
<p>maximal number of iterations. ...</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_pmin">pMin</code>, <code id="qgammaAppr_+3A_pmax">pMax</code></td>
<td>
<p>boundaries for <code>p</code>. ...</p>
</td></tr>
<tr><td><code id="qgammaAppr_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if the algorithm should produce
&ldquo;monitoring&rdquo; information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>qgammaApprSmallP(p, a)</code> should be a good approximation in the
following situation when both <code>p</code> and <code>shape</code> <code class="reqn">= \alpha =:
  a</code> are small :
</p>
<p>If we look at  Abramowitz&amp;Stegun <code class="reqn">gamma*(a,x) = x^-a * P(a,x)</code>
and its series  <code class="reqn">g*(a,x) = 1/gamma(a) * (1/a - 1/(a+1) * x + ...)</code>,
</p>
<p>then the first order approximation <code class="reqn">P(a,x) = x^a * g*(a,x) ~= x^a/gamma(a+1)</code>
and hence its inverse  <code class="reqn">x = qgamma(p, a) ~= (p * gamma(a+1)) ^ (1/a)</code>
should be good as soon as  <code class="reqn">1/a &gt;&gt; 1/(a+1) * x</code>
</p>
<p>&lt;==&gt;  x &lt;&lt; (a+1)/a = (1 + 1/a)
</p>
<p>&lt;==&gt;  x &lt; eps *(a+1)/a
</p>
<p>&lt;==&gt;  log(x) &lt; log(eps) + log( (a+1)/a ) = log(eps) + log((a+1)/a)  ~  -36 - log(a)
where log(x) ~= log(p * gamma(a+1)) / a = (log(p) + lgamma1p(a))/a
</p>
<p>such that the above
</p>
<p>&lt;==&gt;  (log(p) + lgamma1p(a))/a &lt; log(eps) + log((a+1)/a)
</p>
<p>&lt;==&gt;  log(p) + lgamma1p(a) &lt; a*(-log(a)+ log(eps) + log1p(a))
</p>
<p>&lt;==&gt;  log(p) &lt;  a*(-log(a)+ log(eps) + log1p(a)) - lgamma1p(a) =: bnd(a)
</p>
<p>Note that <code>qgammaApprSmallP()</code> indeed also builds on <code><a href="#topic+lgamma1p">lgamma1p</a>()</code>.
</p>
<p><code>.qgammaApprBnd(a)</code> provides this bound <code class="reqn">bnd(a)</code>;
it is simply <code>a*(logEps + log1p(a) - log(a)) - lgamma1p(a)</code>, where
<code>logEps</code> is <code class="reqn">\log(\epsilon)</code> = <code>log(eps)</code> where <code>eps &lt;-
 .Machine$double.eps</code>, i.e. typically (always?) <code>logEps</code><code class="reqn">= \log
 \epsilon = -52 * \log(2) =  -36.04365</code>.
</p>


<h3>Value</h3>

<p>numeric
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.<br />

</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qgamma">qgamma</a></code> for <span class="rlang"><b>R</b></span>'s Gamma distribution functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## TODO :  Move some of the curve()s from ../tests/qgamma-ex.R !!
</code></pre>

<hr>
<h2 id='qnbinomR'>Pure R Implementation of R's qnbinom()  with Tuning Parameters</h2><span id='topic+qnbinomR'></span>

<h3>Description</h3>


<p>A pure R implementation, including many tuning parameter arguments, of
<span class="rlang"><b>R</b></span>'s own Rmathlib C code algorithm, but with more flexibility.
</p>
<p>It is using <code><a href="base.html#topic+Vectorize">Vectorize</a>(qnbinomR1, *)</code> where the hidden
<code>qnbinomR1</code> works for numbers (aka &lsquo;scalar&rsquo;, length one)
arguments only, the same as the C code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qnbinomR(p, size, prob, mu, lower.tail = TRUE, log.p = FALSE,
         yLarge = 4096, # was hard wired to 1e5
         incF = 1/64,   # was hard wired to .001
         iShrink = 8,   # was hard wired to 100
         relTol = 1e-15,# was hard wired to 1e-15
         pfEps.n = 8,   # was hard wired to 64: "fuzz to ensure left continuity"
         pfEps.L = 2,   # was hard wired to 64:   "   "   ..
         fpf = 4, # *MUST* be &gt;= 1 (did not exist previously)
         trace = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qnbinomR_+3A_p">p</code>, <code id="qnbinomR_+3A_size">size</code>, <code id="qnbinomR_+3A_prob">prob</code>, <code id="qnbinomR_+3A_mu">mu</code>, <code id="qnbinomR_+3A_lower.tail">lower.tail</code>, <code id="qnbinomR_+3A_log.p">log.p</code></td>
<td>
<p><code><a href="stats.html#topic+qnbinom">qnbinom</a>()</code> standard
argument, see its help page.</p>
</td></tr>
<tr><td><code id="qnbinomR_+3A_ylarge">yLarge</code>, <code id="qnbinomR_+3A_incf">incF</code>, <code id="qnbinomR_+3A_ishrink">iShrink</code>, <code id="qnbinomR_+3A_reltol">relTol</code>, <code id="qnbinomR_+3A_pfeps.n">pfEps.n</code>, <code id="qnbinomR_+3A_pfeps.l">pfEps.L</code>, <code id="qnbinomR_+3A_fpf">fpf</code></td>
<td>
<p>numeric
arguments tweaking the &ldquo;root finding&rdquo; search after the initial
Cornish-Fisher approximation, see <code><a href="#topic+qbinomR">qbinomR</a></code>, for details.
The defaults should be more reliable (but also a bit more
&ldquo;expensive&rdquo;) than <span class="rlang"><b>R</b></span>'s (original) <code><a href="stats.html#topic+qnbinom">qnbinom</a>()</code> hard
wired values.
</p>
</td></tr>
<tr><td><code id="qnbinomR_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) specifying if (and how much) output
should be produced from the algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector like <code>p</code> recycled to the common lengths of
<code>p</code>, <code>size</code>, and either <code>prob</code> or <code>mu</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qnbinom">qnbinom</a></code>, <code><a href="stats.html#topic+qpois">qpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12)
x10 &lt;- rnbinom(500, mu = 4,       size = 10) ; p10 &lt;- pnbinom(x10, mu=4,       size=10)
x1c &lt;- rnbinom(500, prob = 31/32, size = 100); p1c &lt;- pnbinom(x1c, prob=31/32, size=100)
stopifnot(exprs = {
    x10 == qnbinom (p10, mu=4, size=10)
    x10 == qnbinomR(p10, mu=4, size=10)
    x1c == qnbinom (p1c, prob=31/32, size=100)
    x1c == qnbinomR(p1c, prob=31/32, size=100)
})
</code></pre>

<hr>
<h2 id='qnchisqAppr'>Compute Approximate Quantiles of Noncentral Chi-Squared Distribution</h2><span id='topic+qnchisqAppr'></span><span id='topic+qchisqAppr.0'></span><span id='topic+qchisqAppr.1'></span><span id='topic+qchisqAppr.2'></span><span id='topic+qchisqAppr.3'></span><span id='topic+qchisqApprCF1'></span><span id='topic+qchisqApprCF2'></span><span id='topic+qchisqCappr.2'></span><span id='topic+qchisqN'></span><span id='topic+qnchisqAbdelAty'></span><span id='topic+qnchisqBolKuz'></span><span id='topic+qnchisqPatnaik'></span><span id='topic+qnchisqPearson'></span><span id='topic+qnchisqSankaran_d'></span>

<h3>Description</h3>



<p>Compute quantiles (inverse distribution values) for the <em>non-central</em>
chi-squared distribution.
</p>
<p>....... using Johnson,Kotz,  and other approximations ..............
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qchisqAppr.0 (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqAppr.1 (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqAppr.2 (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqAppr.3 (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqApprCF1(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqApprCF2(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)

qchisqCappr.2 (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qchisqN       (p, df, ncp = 0, qIni = qchisqAppr.0, ...)

qnchisqAbdelAty  (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qnchisqBolKuz    (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qnchisqPatnaik   (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qnchisqPearson   (p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
qnchisqSankaran_d(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>


<table role = "presentation">
<tr><td><code id="qnchisqAppr_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="qnchisqAppr_+3A_df">df</code></td>
<td>
<p>degrees of freedom <code class="reqn">&gt; 0</code>, maybe non-integer.</p>
</td></tr>
<tr><td><code id="qnchisqAppr_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>; ....</p>
</td></tr>
<tr><td><code id="qnchisqAppr_+3A_lower.tail">lower.tail</code>, <code id="qnchisqAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qchisq">qchisq</a>()</code>.</p>
</td></tr>
<tr><td><code id="qnchisqAppr_+3A_qini">qIni</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a></code> that computes an approximate
noncentral chi-squared quantile as starting value <code>x0</code> for the
Newton algorithm <code><a href="#topic+newton">newton</a>()</code>.</p>
</td></tr>
<tr><td><code id="qnchisqAppr_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="#topic+newton">newton</a>()</code>, notably
<code>eps</code> or <code>maxiter</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute (approximate) quantiles, using approximations analogous to those
for the probabilities, see <code><a href="#topic+pnchisqPearson">pnchisqPearson</a></code>.
</p>

<dl>
<dt>qchisqAppr.0():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqAppr.1():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqAppr.2():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqAppr.3():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqApprCF1():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqApprCF2():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqCappr.2():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qchisqN():</dt><dd><p>Uses Newton iterations with <code><a href="stats.html#topic+pchisq">pchisq</a>()</code>
and <code><a href="stats.html#topic+dchisq">dchisq</a>()</code> to determine <code><a href="stats.html#topic+qchisq">qchisq</a>(.)</code> values.</p>
</dd>
<dt>qnchisqAbdelAty():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qnchisqBolKuz():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qnchisqPatnaik():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qnchisqPearson():</dt><dd><p> ...TODO... </p>
</dd>
<dt>qnchisqSankaran_d():</dt><dd><p> ...TODO... </p>
</dd>
</dl>



<h3>Value</h3>

<p><code><a href="base.html#topic+numeric">numeric</a></code> vectors of (noncentral) chi-squared quantiles,
corresponding to probabilities <code>p</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, from May 1999;  starting from a post to the S-news
mailing list by Ranjan Maitra (@ math.umbc.edu) who showed a version of
our <code>qchisqAppr.0()</code> thanking Jim Stapleton for providing it.
</p>


<h3>References</h3>

<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
Continuous Univariate Distributions Vol 2, 2nd ed.; Wiley;
chapter 29 <em>Noncentral <code class="reqn">\chi^2</code>-Distributions</em>;
notably Section <em>8  Approximations</em>, p.461 ff.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qchisq">qchisq</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> pp &lt;- c(.001, .005, .01, .05, (1:9)/10, .95, .99, .995, .999)
 pkg &lt;- "package:DPQ"
 qnchNms &lt;- c(paste0("qchisqAppr.",0:3), paste0("qchisqApprCF",1:2),
              "qchisqN", "qchisqCappr.2", ls(pkg, pattern = "^qnchisq"))
 qnchF &lt;- sapply(qnchNms, get, envir = as.environment(pkg))
 for(ncp in c(0, 1/8, 1/2)) {
   cat("\n~~~~~~~~~~~~~\nncp: ", ncp,"\n=======\n")
   print(sapply(qnchF, function(F) Vectorize(F, "p")(pp, df = 3, ncp=ncp)))
 }

## Bug: qnchisqSankaran_d() has numeric overflow problems for large df:
qnchisqSankaran_d(pp, df=1e200, ncp = 100)

## One current (2019-08) R bug: Noncentral chi-squared quantiles on *LOG SCALE*

## a)  left/lower tail : -------------------------------------------------------
qs &lt;- 2^seq(0,11, by=1/16)
pqL &lt;- pchisq(qs, df=5, ncp=1, log.p=TRUE)
plot(qs, -pqL, type="l", log="xy") # + expected warning on log(0) -- all fine
qpqL &lt;- qchisq(pqL, df=5, ncp=1, log.p=TRUE) # severe overflow :
qm &lt;- cbind(qs, pqL, qchisq=qpqL
	, qchA.0 = qchisqAppr.0 (pqL, df=5, ncp=1, log.p=TRUE)
	, qchA.1 = qchisqAppr.1 (pqL, df=5, ncp=1, log.p=TRUE)
	, qchA.2 = qchisqAppr.2 (pqL, df=5, ncp=1, log.p=TRUE)
	, qchA.3 = qchisqAppr.3 (pqL, df=5, ncp=1, log.p=TRUE)
	, qchACF1= qchisqApprCF1(pqL, df=5, ncp=1, log.p=TRUE)
	, qchACF2= qchisqApprCF2(pqL, df=5, ncp=1, log.p=TRUE)
	, qchCa.2= qchisqCappr.2(pqL, df=5, ncp=1, log.p=TRUE)
	, qnPatnaik   = qnchisqPatnaik   (pqL, df=5, ncp=1, log.p=TRUE)
	, qnAbdelAty  = qnchisqAbdelAty  (pqL, df=5, ncp=1, log.p=TRUE)
	, qnBolKuz    = qnchisqBolKuz    (pqL, df=5, ncp=1, log.p=TRUE)
	, qnPearson   = qnchisqPearson   (pqL, df=5, ncp=1, log.p=TRUE)
	, qnSankaran_d= qnchisqSankaran_d(pqL, df=5, ncp=1, log.p=TRUE)
)

round(qm[ qs %in% 2^(0:11) , -2])
#=&gt; Approximations don't overflow but are not good enough

## b)  right/upper tail , larger ncp -------------------------------------------
qS &lt;- 2^seq(-3, 3, by=1/8)
pqLu &lt;- pchisq(qS, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
## using "the alternative" (here is currently identical):
identical(pqLu, (pqLu.&lt;- log1p(-pchisq(qS, df=5, ncp=100)))) # here TRUE
plot (qS, -pqLu, type="l", log="xy") # fine
qpqLu &lt;- qchisq(pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
cbind(qS, pqLu, pqLu, qpqLu)# # severe underflow
qchMat &lt;- cbind(qchisq = qpqLu
	, qchA.0 = qchisqAppr.0 (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchA.1 = qchisqAppr.1 (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchA.2 = qchisqAppr.2 (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchA.3 = qchisqAppr.3 (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchACF1= qchisqApprCF1(pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchACF2= qchisqApprCF2(pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qchCa.2= qchisqCappr.2(pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qnPatnaik   = qnchisqPatnaik   (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qnAbdelAty  = qnchisqAbdelAty  (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qnBolKuz    = qnchisqBolKuz    (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qnPearson   = qnchisqPearson   (pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	, qnSankaran_d= qnchisqSankaran_d(pqLu, df=5, ncp=100, log.p=TRUE, lower.tail=FALSE)
	)
cbind(L2err &lt;- sort(sqrt(colSums((qchMat - qS)^2))))
##--&gt; "Sankaran_d", "CF1" and "CF2" are good here

plot (qS, qpqLu, type = "b", log="x", lwd=2)
lines(qS, qS, col="gray", lty=2, lwd=3)
top3 &lt;- names(L2err)[1:3]
use &lt;- c("qchisq", top3)
matlines(qS, qchMat[, use]) # 3 of the approximations are "somewhat ok"
legend("topleft", c(use,"True"), bty="n", col=c(palette()[1:4], "gray"),
                  lty = c(1:4,2), lwd = c(2, 1,1,1, 3))
</code></pre>

<hr>
<h2 id='qnormAppr'>Approximations to 'qnorm()', i.e., <code class="reqn">z_\alpha</code></h2><span id='topic+qnormAppr'></span><span id='topic+qnormUappr'></span><span id='topic+qnormUappr6'></span><span id='topic+qnormCappr'></span>

<h3>Description</h3>

<p>Approximations to the standard normal (aka &ldquo;Gaussian&rdquo;) quantiles,
i.e., the inverse of the normal cumulative probability function.
</p>
<p>The <code>qnormUappr*()</code> are relatively simple approximations from
Abramowitz and Stegun, computed by Hastings(1955):
<code>qnormUappr()</code> is the 4-coefficient approximation to (the <b>u</b>pper tail)
standard normal quantiles, <code><a href="stats.html#topic+qnorm">qnorm</a>()</code>, used in some
<code>qbeta()</code> computations.
</p>
<p><code>qnormUappr6()</code> is the &ldquo;traditional&rdquo; 6-coefficient approximation to
<code><a href="stats.html#topic+qnorm">qnorm</a>()</code>, see in &lsquo;Details&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
qnormUappr(p, lp = .DT_Clog(p, lower.tail=lower.tail, log.p=log.p),
           lower.tail = FALSE, log.p = missing(p),
           tLarge = 1e10)
qnormUappr6(p,
            lp = .DT_Clog(p, lower.tail=lower.tail, log.p=log.p),
               # ~= log(1-p) -- independent of lower.tail, log.p
            lower.tail = FALSE, log.p = missing(p),
            tLarge = 1e10)

qnormCappr(p, k = 1) ## *implicit* lower.tail=TRUE, log.p=FALSE  &gt;&gt;&gt; TODO: add! &lt;&lt;

qnormAppr(p) # &lt;&lt; deprecated; use qnormUappr(..) instead!
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qnormAppr_+3A_p">p</code></td>
<td>
<p>numeric vector of probabilities, possibly transformed, depending
on <code>log.p</code>.  Does not need to be specified, if <code>lp</code> is instead.</p>
</td></tr>
<tr><td><code id="qnormAppr_+3A_lp">lp</code></td>
<td>
<p><code>log(1 - p*)</code>, assuming <code class="reqn">p*</code> is the <code>lower.tail=TRUE,
      log.p=FALSE</code> version of <code>p</code>.  If passed as argument, it can be
much more accurate than when computed from <code>p</code> by default.</p>
</td></tr>
<tr><td><code id="qnormAppr_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (<em>not</em> the default here!), probabilities are
<code class="reqn">P[X \le x]</code>, otherwise (by default) upper tail probabilities, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="qnormAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities <code class="reqn">p</code> are given as
<code class="reqn">\log(p)</code> in argument <code>p</code>.  Note that it is <em>not used</em>,
when <code>missing(p)</code> and <code>lp</code> is specified.</p>
</td></tr>
<tr><td><code id="qnormAppr_+3A_tlarge">tLarge</code></td>
<td>
<p>a large number <code class="reqn">t0</code>;
if <code class="reqn">t &gt;= t0</code>, where <code class="reqn">t := sqrt(-2 * lp)</code>, the result will be <code class="reqn">= t</code>.</p>
</td></tr>
<tr><td><code id="qnormAppr_+3A_k">k</code></td>
<td>
<p>positive integer, specifying the iterative plugin &lsquo;order&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is now <em>deprecated</em>; use  <code>qnormUappr()</code> instead!
<code>qnormAppr(p)</code> uses the simple 4 coefficient rational approximation
to <code><a href="stats.html#topic+qnorm">qnorm</a>(p)</code>, provided by Abramowitz and Stegun (26.2.22), p.933,
to be used <em>only</em> for <code class="reqn">p &gt; 1/2</code> and typically
<code><a href="stats.html#topic+qbeta">qbeta</a>()</code> computations, e.g., <code><a href="#topic+qbeta.R">qbeta.R</a></code>.
<br />
The relative error of this approximation is quite <em>asymmetric</em>: It
is mainly &lt; 0.
</p>
<p><code>qnormUappr(p)</code> uses the same rational approximation directly for the
<b>U</b>pper tail where it is relatively good, and for the lower tail via
&ldquo;swapping the tails&rdquo;, so it is good there as well.
</p>
<p><code>qnormUappr6(p, *)</code> uses the 6 coefficient rational approximation
to <code><a href="stats.html#topic+qnorm">qnorm</a>(p, *)</code>, from Abramowitz and Stegun (26.2.23), again
mostly useful in the outer tails.
</p>
<p><code>qnormCappr(p, k)</code> inverts formula (26.2.24) of Abramowitz and Stegun,
and for <code class="reqn">k \ge 2</code> improves it, by iterative recursive
plug-in, using A.&amp;S. (26.2.25).
</p>


<h3>Value</h3>

<p>numeric vector of (approximate) normal quantiles corresponding to
probabilities <code>p</code>
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover.
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>
<p>Hastings jr., Cecil (1955)
<em>Approximations for Digital Computers</em>.
Princeton Univ. Press.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qnorm">qnorm</a></code> (in base <span class="rlang"><b>R</b></span> package <span class="pkg">stats</span>), and importantly,
<code><a href="#topic+qnormR">qnormR</a></code> and <code><a href="#topic+qnormAsymp">qnormAsymp</a>()</code> in this package (<span class="pkg">DPQ</span>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pp &lt;- c(.001, .005, .01, .05, (1:9)/10, .95, .99, .995, .999)
z_p &lt;- qnorm(pp)
assertDeprecation &lt;- function(expr, verbose=TRUE)
  tools::assertCondition(expr, verbose=verbose, "deprecatedWarning")
assertDeprecation(qA &lt;- qnormAppr(pp))
(R &lt;- cbind(pp, z_p, qA,
            qUA = qnormUappr(pp, lower.tail= TRUE),
            qA6 = qnormUappr6(pp, lower.tail=TRUE)))
## Errors, absolute and relative:
relEr &lt;- function(targ, curr) { ## simplistic "smart" rel.error
    E &lt;- curr - targ
    r &lt;- E/targ  # simple, but fix 0/0:
    r[targ == 0 &amp; E == 0] &lt;- 0
    r
}
mER &lt;- cbind(pp,
             errA  = z_p - R[,"qA" ],
             errUA = z_p - R[,"qUA"],
             rE.A  = relEr(z_p, R[,"qA" ]),
             rE.UA = relEr(z_p, R[,"qUA"]),
             rE.A6 = relEr(z_p, R[,"qA6"]))
signif(mER)

lp &lt;- -c(1000, 500, 200, 100, 50, 20:10, seq(9.75, 0, by = -1/8))
signif(digits=5, cbind(lp # 'p' need not be specified if 'lp' is !
    , p.  = -expm1(lp)
    , qnU = qnormUappr (lp=lp)
    , qnU6= qnormUappr6(lp=lp)
    , qnA1= qnormAsymp(lp=lp, lower.tail=FALSE, order=1)
    , qnA5= qnormAsymp(lp=lp, lower.tail=FALSE, order=5)
    , qn  = qnorm(lp, log.p=TRUE)
      )) ## oops! shows *BUG* for last values where qnorm() &gt; 0 !

curve(qnorm(x, lower.tail=FALSE), n=1001)
curve(qnormUappr(x), add=TRUE,    n=1001, col = adjustcolor("red", 1/2))

## Error curve:
curve(qnormUappr(x) - qnorm(x, lower.tail=FALSE), n=1001,
      main = "Absolute Error of  qnormUappr(x)")
abline(h=0, v=1/2, lty=2, col="gray")

curve(qnormUappr(x) / qnorm(x, lower.tail=FALSE) - 1, n=1001,
      main = "Relative Error of  qnormUappr(x)")
 abline(h=0, v=1/2, lty=2, col="gray")

curve(qnormUappr(lp=x) / qnorm(x, log.p=TRUE) - 1, -200, -1, n=1001,
      main = "Relative Error of  qnormUappr(lp=x)"); mtext(" &amp; qnormUappr6()  [log.p scale]", col=2)
curve(qnormUappr6(lp=x) / qnorm(x, log.p=TRUE) - 1, add=TRUE, col=2, n=1001)
abline(h=0, lty=2, col="gray")

curve(qnormUappr(lp=x) / qnorm(x, log.p=TRUE) - 1,
      -2000, -.1, ylim = c(-2e-4, 1e-4), n=1001,
      main = "Relative Error of  qnormUappr(lp=x)"); mtext(" &amp; qnormUappr6()  [log.p scale]", col=2)
curve(qnormUappr6(lp=x) / qnorm(x, log.p=TRUE) - 1, add=TRUE, col=2, n=1001)
abline(h=0, lty=2, col="gray")

## zoom out much more - switch x-axis {use '-x'} and log-scale:
curve(qnormUappr6(lp=-x) / qnorm(-x, log.p=TRUE) - 1,
      .1, 1.1e10, log = "x", ylim = 2.2e-4*c(-2,1), n=2048,
      main = "Relative Error of  qnormUappr6(lp = -x)  [log.p scale]") -&gt; xy.q
abline(h=0, lty=2, col="gray")

## 2023-02: qnormUappr6() can be complemented with
## an approximation around center p=1/2: qnormCappr()
p &lt;- seq(0,1, by=2^-10)
M &lt;- cbind(p, qn=(qn &lt;- qnorm(p)),
           reC1 = relEr(qn, qnormCappr(p)),
           reC2 = relEr(qn, qnormCappr(p, k=2)),
           reC3 = relEr(qn, qnormCappr(p, k=3)),
           reU6 = relEr(qn, qnormUappr6(p,lower.tail=TRUE)))
matplot(M[,"p"], M[,-(1:2)], type="l", col=2:7, lty=1, lwd=2,
        ylim = c(-.004, +1e-4), xlab=quote(p), ylab = "relErr")
abline(h=0, col="gray", lty=2)
oo &lt;- options(width=99)
summary(    M[,-(1:2)])
summary(abs(M[,-(1:2)]))
options(oo)
</code></pre>

<hr>
<h2 id='qnormAsymp'>Asymptotic Approximation to Outer Tail of qnorm()</h2><span id='topic+qnormAsymp'></span>

<h3>Description</h3>

<p>Implementing new asymptotic tail approximations of normal quantiles,
i.e., the <span class="rlang"><b>R</b></span> function <code><a href="stats.html#topic+qnorm">qnorm</a>()</code>, mostly useful when
<code>log.p=TRUE</code> and log-scale <code>p</code> is relatively large negative,
i.e., <code class="reqn">p \ll -1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
qnormAsymp(p,
           lp = .DT_Clog(p, lower.tail = lower.tail, log.p = log.p),
           order, lower.tail = TRUE, log.p = missing(p))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qnormAsymp_+3A_p">p</code></td>
<td>
<p>numeric vector of probabilities, possibly transformed, depending
on <code>log.p</code>.  Does not need to be specified, if <code>lp</code> is used instead.</p>
</td></tr>
<tr><td><code id="qnormAsymp_+3A_lp">lp</code></td>
<td>
<p>numeric (vector) of <code>log(1-p)</code> values; if not specified,
computed from <code>p</code>, depending on <code>lower.tail</code> and <code>log.p</code>.</p>
</td></tr>
<tr><td><code id="qnormAsymp_+3A_order">order</code></td>
<td>
<p>an integer in <code class="reqn">\{0,1,\dots,5\}</code>, specifying the
approximation order.</p>
</td></tr>
<tr><td><code id="qnormAsymp_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if true, probabilities are <code class="reqn">P[X \le x]</code>,
otherwise upper tail probabilities, <code class="reqn">P[X &gt; x]</code>.</p>
</td></tr>
<tr><td><code id="qnormAsymp_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code> (as typical here!), probabilities
<code class="reqn">p</code> are given as <code class="reqn">\log(p)</code> in argument <code>p</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <em>asymptotic</em> approximations have been derived by Maechler (2022)
via iterative plug-in to the well known asymptotic approximations of
<code class="reqn">Q(x) = 1 - \Phi(x)</code> from Abramowitz and Stegun (26.2.13), p.932,
which are provided in our package <span class="pkg">DPQ</span> as <code><a href="#topic+pnormAsymp">pnormAsymp</a>()</code>.

They will be used in <span class="rlang"><b>R</b></span> &gt;= 4.3.0's <code>qnorm()</code> to provide very accurate
quantiles in the extreme tails.
</p>


<h3>Value</h3>

<p>a numeric vector like <code>p</code> or <code>lp</code> if that was specified instead.
</p>
<p>The simplemost (for extreme tails) is <code>order = 0</code>, where the
asymptotic approximation is simply <code class="reqn">\sqrt{-2s}</code> and
<code class="reqn">s</code> is <code>-lp</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>Martin Maechler (2022). Asymptotic Tail Formulas For Gaussian Quantiles;
<a href="https://CRAN.R-project.org/package=DPQ"><span class="pkg">DPQ</span></a> vignette, see
<a href="https://CRAN.R-project.org/package=DPQ/vignettes/qnorm-asymp.pdf">https://CRAN.R-project.org/package=DPQ/vignettes/qnorm-asymp.pdf</a>.
</p>


<h3>See Also</h3>

<p>The upper tail approximations in Abramowitz &amp; Stegun, in <span class="pkg">DPQ</span>
available as <code>qnormUappr()</code> and <code><a href="#topic+qnormUappr6">qnormUappr6</a>()</code>,
are less accurate than our <code>order &gt;= 1</code> formulas in the tails.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
lp &lt;- -c(head(c(outer(c(5,2,1), 10^(18:1))), -2), 20:10, seq(9.75, 2, by = -1/8))
qnU6 &lt;- qnormUappr6(lp=lp) # 'p' need not be specified if 'lp' is
qnAsy &lt;- sapply(0:5, function(ord) qnormAsymp(lp=lp, lower.tail=FALSE, order=ord))
matplot(-lp, cbind(qnU6, qnAsy), type = "b", log = "x", pch=1:7)# all "the same"
legend("center", c("qnormUappr6()",
                paste0("qnormAsymp(*, order=",0:5,")")),
       bty="n", col=1:6, lty=1:5, pch=1:7) # as in matplot()

p.ver &lt;- function() mtext(R.version.string, cex=3/4, adj=1)
matplot(-lp, cbind(qnU6, qnAsy) - qnorm(lp, lower.tail=TRUE, log.p=TRUE),
        pch=1:7, cex = .5, xaxt = "n", # and use eaxis() instead
        main = "absolute Error of qnorm() approximations", type = "b", log = "x")
sfsmisc::eaxis(1, sub10=2); p.ver()
legend("bottom", c("qnormUappr6()",
                paste0("qnormAsymp(*, order=",0:5,")")),
       bty="n", col=1:6, lty=1:5, pch=1:7, pt.cex=.5)

## If you look at the numbers, in versions of R &lt;= 4.2.x,
## qnorm() is *worse* for large -lp than the higher order approximations
## ---&gt; using qnormR() here:
absP &lt;- function(re) pmax(abs(re), 2e-17) # not zero, so log-scale "shows" it
qnT &lt;- qnormR(lp, lower.tail=TRUE, log.p=TRUE, version="2022") # ~= TRUE qnorm()
matplot(-lp, absP(cbind(qnU6, qnAsy) / qnT - 1),
        ylim = c(2e-17, .01), xaxt = "n", yaxt = "n", col=1:7, lty=1:7,
        main = "relative |Error| of qnorm() approximations", type = "l", log = "xy")
abline(h = .Machine$double.eps * c(1/2, 1, 2), col=adjustcolor("bisque",3/4),
       lty=c(5,2,5), lwd=c(1,3,1))
sfsmisc::eaxis(1, sub10 = 2, nintLog=20)
sfsmisc::eaxis(2, sub10 = c(-3, 2), nintLog=16)
mtext("qnT &lt;- qnormR(*, version=\"2022\")", cex=0.9, adj=1)# ; p.ver()
legend("topright", c("qnormUappr6()",
                paste0("qnormAsymp(*, order=",0:5,")")),
       bty="n", col=1:7, lty=1:7, cex = 0.8)


###=== Optimal cut points / regions for different approximation orders k =================

## Zoom into each each cut-point region :
p.qnormAsy2 &lt;- function(r0, k, # use k-1 and k in region around r0
                        n = 2048, verbose=TRUE, ylim = c(-1,1) * 2.5e-16,
                        rr = seq(r0 * 0.5, r0 * 1.25, length = n), ...)
{
  stopifnot(is.numeric(rr), !is.unsorted(rr), # the initial 'r'
            length(k) == 1L, is.numeric(k), k == as.integer(k), k &gt;= 1)
  k.s &lt;- (k-1L):k; nks &lt;- paste0("k=", k.s)
  if(missing(r0)) r0 &lt;- quantile(rr, 2/3)# allow specifying rr instead of r0
  if(verbose) cat("Around r0 =", r0,";  k =", deparse(k.s), "\n")
  lp &lt;- (-rr^2) # = -r^2 = -s  &lt;==&gt; rr = sqrt(- lp)
  q. &lt;- qnormR(lp, lower.tail=FALSE, log.p=TRUE, version="2022-08")# *not* depending on R ver!
  pq &lt;- pnorm(q., lower.tail=FALSE, log.p=TRUE) # ~= lp
  ## the arg of pnorm() is the true qnorm(pq, ..) == q.  by construction
  ## cbind(rr, lp, q., pq)
  r &lt;- sqrt(- pq)
  stopifnot(all.equal(rr, r, tol=1e-15))
  qnAsy &lt;- sapply(setNames(k.s, nks), function(ord)
                  qnormAsymp(pq, lower.tail=FALSE, log.p=TRUE, order=ord))
  relE &lt;- qnAsy / q. - 1
  m &lt;- cbind(r, pq, relE)
  if(verbose) {
    print(head(m, 9)); for(j in 1:2) cat(" ..........\n")
    print(tail(m, 4))
  }
  ## matplot(r, relE, type = "b", main = paste("around r0 = ", r0))
  matplot(r, relE, type = "l", ylim = ylim,
     main = paste("Relative error of qnormAsymp(*, k) around r0 = ", r0,
                  "for  k =", deparse(k.s)),
     xlab = quote(r == sqrt(-log(p))), ...)
  legend("topleft", nks, col=1:2, lty=1:2, bty="n", lwd=2)
  for(j in seq_along(k.s))
    lines(smooth.spline(r, relE[,j]), col=adjustcolor(j, 2/3), lwd=4, lty=2)
  cc &lt;- "blue2"; lab &lt;- substitute(r[0] == R, list(R = r0))
  abline(v  = r0, lty=2, lwd=2, col=cc)
  axis(3, at= r0, labels=lab, col=cc, col.axis=cc, line=-1)
  abline(h = (-1:1)*.Machine$double.eps, lty=c(3,1,3),
         col=c("green3", "gray", "tan2"))
  invisible(cbind(r = r, qn = q., relE))
}

r0 &lt;- c(27, 55, 109, 840, 36000, 6.4e8) # &lt;--&gt; in ../R/norm_f.R {and R's qnorm.c eventually}
## use k =   5   4    3    2      1       0    e.g.  k = 0  good for r &gt;= 6.4e8
for(ir in 2:length(r0)) {
  p.qnormAsy2(r0[ir], k = 5 +2-ir) # k = 5, 4, ..
  if(interactive() &amp;&amp; ir &lt; length(r0)) {
       cat("[Enter] to continue: "); cat(readLines(stdin(), n=1), "\n") }
}

</code></pre>

<hr>
<h2 id='qnormR'>Pure R version of <span class="rlang"><b>R</b></span>'s <code>qnorm()</code> with Diagnostics and Tuning Parameters</h2><span id='topic+qnormR1'></span><span id='topic+qnormR'></span>

<h3>Description</h3>

<p>Computes <span class="rlang"><b>R</b></span> level implementations of <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qnorm">qnorm</a>()</code> as
implemented in C code (in <span class="rlang"><b>R</b></span>'s &lsquo;<span class="file">Rmathlib</span>&rsquo;), historically and present.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qnormR1(p, mu = 0, sd = 1, lower.tail = TRUE, log.p = FALSE, trace = 0, version = )
qnormR (p, mu = 0, sd = 1, lower.tail = TRUE, log.p = FALSE, trace = 0,
        version = c("4.0.x", "1.0.x", "1.0_noN", "2020-10-17", "2022-08-04"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qnormR_+3A_p">p</code></td>
<td>
<p>probability <code class="reqn">p</code>, <code class="reqn">1-p</code>, or <code class="reqn">\log(p)</code>,
<code class="reqn">\log(1-p)</code>, depending on <code>lower.tail</code> and <code>log.p</code>.</p>
</td></tr>
<tr><td><code id="qnormR_+3A_mu">mu</code></td>
<td>
<p>mean of the normal distribution.</p>
</td></tr>
<tr><td><code id="qnormR_+3A_sd">sd</code></td>
<td>
<p>standard deviation of the normal distribution.</p>
</td></tr>
<tr><td><code id="qnormR_+3A_lower.tail">lower.tail</code>, <code id="qnormR_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qnorm">qnorm</a>()</code>.</p>
</td></tr>
<tr><td><code id="qnormR_+3A_trace">trace</code></td>
<td>
<p>logical or integer; if positive or <code>TRUE</code>, diagnostic
output is printed to the console during the computations.</p>
</td></tr>
<tr><td><code id="qnormR_+3A_version">version</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string specifying which version
or variant is used.  The <em>current</em> default, <code>"4.0.x"</code> is the
one used in <span class="rlang"><b>R</b></span> versions up to 4.0.x.
The two <code>"1.0*"</code> versions are as used up to <span class="rlang"><b>R</b></span> 1.0.1, based on
Algorithm AS 111, improved by a branch for extreme tails by Wichura,
<em>and</em> a final Newton step which is only sensible when
<code>log.p=FALSE</code>.  That final stepped is skipped for
<code>version = "1.0_noN"</code>, &ldquo;noN&rdquo; := &ldquo;no Newton&rdquo;.

<code>"2020-10-17"</code> is the one committed to the R development sources
on 2020-10-17, which prevents the worst for very large <code class="reqn">|p|</code> when
<code>log.p=TRUE</code>.
<code>"2022-08-04"</code> uses very accurate asymptotic formulas found on
that date and provides full double precision accuracy also for extreme
tails.</p>
</td></tr>

</table>


<h3>Details</h3>

<p>For <code>qnormR1(p, ..)</code>, <code>p</code> must be of length one, whereas
<code>qnormR(p, m, s, ..)</code> works vectorized in <code>p</code>, <code>mu</code>, and
<code>sd</code>.  In the <span class="pkg">DPQ</span> package source, <code>qnormR</code> is simply the result of
<code><a href="base.html#topic+Vectorize">Vectorize</a>(qnormR1, ...)</code>.
</p>


<h3>Value</h3>

<p>a numeric vector like the input <code>q</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>For <code>version</code>s <code>"1.0.x"</code> and <code>"1.0_noN"</code>:
<br />
Beasley, J.D. and Springer, S.G. (1977)
Algorithm AS 111: The Percentage Points of the Normal Distribution.
<em>JRSS C (Appied Statistics)</em> <b>26</b>, 118&ndash;121; <a href="https://doi.org/10.2307/2346889">doi:10.2307/2346889</a>.
</p>
<p>For the asymptotic approximations used in <code>version</code>s newer than
<code>"4.0.x"</code>, i.e., <code>"2020-10-17"</code> and later, see the
reference(s) on <code><a href="#topic+qnormAsymp">qnormAsymp</a></code>'s help page.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qnorm">qnorm</a></code>, <code><a href="#topic+qnormAsymp">qnormAsymp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qR &lt;- curve(qnormR, n = 2^11)
abline(h=0, v=0:1, lty=3, col=adjustcolor(1, 1/2))
with(qR, all.equal(y, qnorm(x), tol=0)) # currently shows TRUE
with(qR, all.equal(pnorm(y), x, tol=0)) # currently: mean rel. diff.: 2e-16
stopifnot(with(qR, all.equal(pnorm(y), x, tol = 1e-14)))

(ver.qn &lt;- eval(formals(qnormR)$version)) # the possible versions
(doExtras &lt;- DPQ:::doExtras()) # TRUE e.g. if interactive()
lp &lt;- - 4^(1:30) # effect of  'trace = *' :
qpAll &lt;- sapply(ver.qn, function (V)
    qnormR(lp, log.p=TRUE, trace=doExtras, version = V))
head(qpAll) # the "1.0" versions underflow quickly ..

cAdj &lt;- adjustcolor(palette(), 1/2)
matplot(-lp, -qpAll, log="xy", type="l", lwd=3, col=cAdj, axes=FALSE,
        main = "- qnormR(lp, log.p=TRUE, version = * )")
sfsmisc::eaxis(1, nintLog=15, sub=2); sfsmisc::eaxis(2)
lines(-lp, sqrt(-2*lp), col=cAdj[ncol(qpAll)+1])
leg &lt;- as.expression(c(paste("version=", ver.qn), quote(sqrt(-2 %.% lp))))
matlines(-lp, -qpAll[,2:3], lwd=6, col=cAdj[2:3])
legend("top", leg, bty='n', col=cAdj, lty=1:3, lwd=2)

## Showing why/where R's qnorm() was poor up to 2020: log.p=TRUE extreme tail
##% MM: more TODO? --&gt; ~/R/MM/NUMERICS/dpq-functions/qnorm-extreme-bad.R
qs &lt;- 2^seq(0, 155, by=1/8)
lp &lt;- pnorm(qs, lower.tail=FALSE, log.p=TRUE)
## The inverse of pnorm() fails BADLY for extreme tails:
## this is identical to qnorm(..) in R &lt;= 4.0.x:
qp &lt;- qnormR(lp, lower.tail=FALSE, log.p=TRUE, version="4.0.x")
## asymptotically correct approximation :
qpA &lt;- sqrt(- 2* lp)
##^
col2 &lt;- c("black", adjustcolor(2, 0.6))
col3 &lt;- c(col2, adjustcolor(4, 0.6))
## instead of going toward infinity, it converges at  9.834030e+07 :
matplot(-lp, cbind(qs, qp, qpA), type="l", log="xy", lwd = c(1,1,3), col=col3,
        main = "Poorness of qnorm(lp, lower.tail=FALSE, log.p=TRUE)",
        ylab = "qnorm(lp, ..)", axes=FALSE)
sfsmisc::eaxis(1); sfsmisc::eaxis(2)
legend("top", c("truth", "qnorm(.) = qnormR(., \"4.0.x\")", "asymp. approx"),
       lwd=c(1,1,3), lty=1:3, col=col3, bty="n")

rM &lt;- cbind(lp, qs, 1 - cbind(relE.qnorm=qp, relE.approx=qpA)/qs)
rM[ which(1:nrow(rM) %% 20 == 1) ,]
</code></pre>

<hr>
<h2 id='qntR'>Pure R Implementation of R's qt() / qnt()</h2><span id='topic+qntR'></span><span id='topic+qntR1'></span>

<h3>Description</h3>

<p>A pure <span class="rlang"><b>R</b></span> implementation of R's C API (&lsquo;Mathlib&rsquo; specifically)
<code>qnt()</code> function which computes (non-central) t quantiles.
</p>
<p>The simple inversion (of <code>pnt()</code>) scheme has seen to be deficient,
even in cases where <code>pnt()</code>, i.e., <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+pt">pt</a>(.., ncp=*)</code>
does not loose accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qntR1(p, df, ncp, lower.tail = TRUE, log.p = FALSE,
      pnt = stats::pt, accu = 1e-13, eps = 1e-11)
qntR (p, df, ncp, lower.tail = TRUE, log.p = FALSE,
      pnt = stats::pt, accu = 1e-13, eps = 1e-11)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qntR_+3A_p">p</code>, <code id="qntR_+3A_df">df</code>, <code id="qntR_+3A_ncp">ncp</code></td>
<td>
<p>vectors of probabilities, degrees of freedom, and
non-centrality parameter; see <code><a href="stats.html#topic+qt">qt</a></code>.</p>
</td></tr>
<tr><td><code id="qntR_+3A_lower.tail">lower.tail</code>, <code id="qntR_+3A_log.p">log.p</code></td>
<td>
<p>logical; see <code><a href="stats.html#topic+qt">qt</a></code>.</p>
</td></tr>
<tr><td><code id="qntR_+3A_pnt">pnt</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a></code> for computing the CDF of the (non-central) t-distribution.</p>
</td></tr>
<tr><td><code id="qntR_+3A_accu">accu</code></td>
<td>
<p>a non-negative number, the &ldquo;accu&rdquo;racy desired in the &quot;root finding&quot; loop.</p>
</td></tr>
<tr><td><code id="qntR_+3A_eps">eps</code></td>
<td>
<p>a non-negative number, used for determining the start interval
for the root finding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of t quantiles, properly recycled in <code>(p, df, ncp)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p>Our <code><a href="#topic+qtU">qtU</a>()</code> and <code><a href="#topic+qtAppr">qtAppr</a>()</code>; non-central density and probability
approximations in <code><a href="#topic+dntJKBf">dntJKBf</a></code>, and e.g., <code><a href="#topic+pntR">pntR</a></code>.
Further, <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qt">qt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example where qt() and qntR() "fail" {warnings; --&gt; Inf}
lp &lt;- seq(-30, -24, by=1/4)
summary(p &lt;- exp(lp))
(qp &lt;- qntR( p, df=35, ncp=-7, lower.tail=FALSE))
qp2 &lt;- qntR(lp, df=35, ncp=-7, lower.tail = FALSE, log.p=TRUE)
all.equal(qp, qp2)## same warnings, same values
</code></pre>

<hr>
<h2 id='qpoisR'>Pure R Implementation of R's qpois()  with Tuning Parameters</h2><span id='topic+qpoisR'></span>

<h3>Description</h3>


<p>A pure R implementation, including many tuning parameter arguments, of
<span class="rlang"><b>R</b></span>'s own Rmathlib C code algorithm, but with more flexibility.
</p>
<p>It is using <code><a href="base.html#topic+Vectorize">Vectorize</a>(qpoisR1, *)</code> where the hidden
<code>qpoisR1</code> works for numbers (aka &lsquo;scalar&rsquo;, length one)
arguments only, the same as the C code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpoisR(p, lambda, lower.tail = TRUE, log.p = FALSE,
       yLarge = 4096, # was hard wired to 1e5
       incF = 1/64,   # was hard wired to .001
       iShrink = 8,   # was hard wired to 100
       relTol = 1e-15,# was hard wired to 1e-15
       pfEps.n = 8,   # was hard wired to 64: "fuzz to ensure left continuity"
       pfEps.L = 2,   # was hard wired to 64:   "   "   ..
       fpf = 4, # *MUST* be &gt;= 1 (did not exist previously)
       trace = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qpoisR_+3A_p">p</code>, <code id="qpoisR_+3A_lambda">lambda</code>, <code id="qpoisR_+3A_lower.tail">lower.tail</code>, <code id="qpoisR_+3A_log.p">log.p</code></td>
<td>
<p><code><a href="stats.html#topic+qpois">qpois</a>()</code> standard
argument, see its help page.</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_ylarge">yLarge</code></td>
<td>
<p>a positive number; in <span class="rlang"><b>R</b></span> up to 2021, was internally
hardwired to <code>yLarge = 1e5</code>:  Uses more careful search for
<code class="reqn">y \ge y_L</code>, where <code class="reqn">y</code> is the initial approximate result,
derived from a Cornish-Fisher expansiion.





</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_incf">incF</code></td>
<td>
<p>a positive &ldquo;increment factor&rdquo; (originally hardwired to
0.001), used only when <code>y &gt;= yLarge</code>; defines the initial increment in
the search algorithm as <code>incr &lt;- floor(incF * y)</code>.</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_ishrink">iShrink</code></td>
<td>
<p>a positive increment shrinking factor, used only when
<code>y &gt;= yLarge</code> to define the new increment from the old one as
<code>incr &lt;- max(1, floor(incr/iShrink))</code> where the LHS was hardired
original to <code>(incr/100)</code>.</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_reltol">relTol</code></td>
<td>
<p>originally hard wired to 1e-15, defines the convergence
tolerance for the search iterations when <code>y &gt;= yLarge</code>; the
iterations stop when (new) <code>incr &lt;= y * relTol</code>.</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_pfeps.n">pfEps.n</code>, <code id="qpoisR_+3A_pfeps.l">pfEps.L</code></td>
<td>
<p>positive factors defining &ldquo;fuzz to ensure
left continuity&rdquo;, both originally hardwired to <code>64</code>, the fuzz adjustment was
</p>
<pre>p &lt;- p * (1 - 64 *.Machine$double.eps)</pre>
<p>Now, <code>pfEps.L</code> is used <code>if(log.p)</code> is true and <code>pfEps.n</code>
is used otherwise (&quot;n&quot;ormal case), and the adjustments also depend on
<code>lower.tail</code>, and also on <code>fpf</code> : </p>
</td></tr>
<tr><td><code id="qpoisR_+3A_fpf">fpf</code></td>
<td>
<p>a number larger than <code>1</code>, together with <code>pfEps.n</code>
determines the fuzz-adjustment to <code>p</code> in the case
<code>(lower=tail=FALSE, log.p=FALSE)</code>:
with <code>e &lt;- pfEps.n * .Machine$double.eps</code>, the adjustment
<code>p &lt;- p * (1 + e)</code> is made <em>iff</em> <code>1 - p &gt; fpf*e</code>.</p>
</td></tr>
<tr><td><code id="qpoisR_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) specifying if (and how much) output
should be produced from the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The defaults and exact meaning of the algorithmic tuning arguments from
<code>yLarge</code> to <code>fpf</code> were experimentally determined are subject to change.
</p>


<h3>Value</h3>

<p>a numeric vector like <code>p</code> recycled to the common lengths of <code>p</code>
and <code>lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qpois">qpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 10*(15:25)
Pp &lt;- ppois(x, lambda = 100, lower.tail = FALSE)  # no cancellation
qPp &lt;- qpois(Pp, lambda = 100, lower.tail=FALSE)
table(x == qPp) # all TRUE ?
## future: if(getRversion() &gt;= "4.2") stopifnot(x == qPp) # R-devel
qpRp &lt;- qpoisR(Pp, lambda = 100, lower.tail=FALSE)
all.equal(x, qpRp, tol = 0)
stopifnot(all.equal(x, qpRp, tol = 1e-15))
</code></pre>

<hr>
<h2 id='qtAppr'>Compute Approximate Quantiles of the (Non-Central) t-Distribution</h2><span id='topic+qtAppr'></span><span id='topic+qtNappr'></span>

<h3>Description</h3>

<p>Compute quantiles (inverse distribution values) for the non-central t distribution.
using Johnson,Kotz,.. p.521, formula (31.26 a) (31.26 b) &amp; (31.26 c)
</p>
<p>Note that <code><a href="stats.html#topic+qt">qt</a>(.., ncp=*)</code> did not exist yet in 1999, when MM
implemented <code>qtAppr()</code>.
</p>
<p><code>qtNappr()</code> approximates t-quantiles for large <code>df</code>, i.e., when
close to the Gaussian / normal distribution, using up to 4 asymptotic
terms from Abramowitz &amp; Stegun 26.7.5 (p.949).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtAppr (p, df, ncp, lower.tail = TRUE, log.p = FALSE, method = c("a", "b", "c"))
qtNappr(p, df,      lower.tail = TRUE, log.p=FALSE, k) 
</code></pre>


<h3>Arguments</h3>


<table role = "presentation">
<tr><td><code id="qtAppr_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="qtAppr_+3A_df">df</code></td>
<td>
<p>degrees of freedom <code class="reqn">&gt; 0</code>, maybe non-integer.</p>
</td></tr>
<tr><td><code id="qtAppr_+3A_ncp">ncp</code></td>
<td>
<p>non-centrality parameter <code class="reqn">\delta</code>; ....</p>
</td></tr>
<tr><td><code id="qtAppr_+3A_lower.tail">lower.tail</code>, <code id="qtAppr_+3A_log.p">log.p</code></td>
<td>
<p>logical, see, e.g., <code><a href="stats.html#topic+qt">qt</a>()</code>.</p>
</td></tr>
<tr><td><code id="qtAppr_+3A_method">method</code></td>
<td>
<p>a string specifying the approximation method to be used.</p>
</td></tr>
<tr><td><code id="qtAppr_+3A_k">k</code></td>
<td>
<p>an integer in {0,1,2,3,4}, choosing the number of terms in <code>qtNappr()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of length <code>length(p + df + ncp)</code> with approximate t-quantiles.
</p>


<h3>References</h3>

<p>Johnson, N.L., Kotz, S. and Balakrishnan, N. (1995)
Continuous Univariate Distributions Vol~2, 2nd ed.; Wiley;
chapter 31, Section <em>6  Approximation</em>, p.519 ff
</p>
<p>Abramowitz, M. and Stegun, I. A. (1972)
<em>Handbook of Mathematical Functions</em>. New York: Dover;
formula (26.7.5), p.949;
<a href="https://en.wikipedia.org/wiki/Abramowitz_and_Stegun">https://en.wikipedia.org/wiki/Abramowitz_and_Stegun</a> provides
links to the full text which is in public domain.
</p>


<h3>See Also</h3>

<p>Our <code><a href="#topic+qtU">qtU</a>()</code>; several non-central density and probability
approximations in <code><a href="#topic+dntJKBf">dntJKBf</a></code>, and e.g., <code><a href="#topic+pntR">pntR</a></code>.
Further, <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qt">qt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
qts &lt;- function(p, df) {
    cbind(qt = qt(p, df=df)
        , qtN0 = qtNappr(p, df=df, k=0)
        , qtN1 = qtNappr(p, df=df, k=1)
        , qtN2 = qtNappr(p, df=df, k=2)
        , qtN3 = qtNappr(p, df=df, k=3)
        , qtN4 = qtNappr(p, df=df, k=4)
          )
}
p &lt;- (0:100)/100
ii &lt;- 2:100 # drop p=0 &amp; p=1  where q*(p, .) == +/- Inf

df &lt;- 100 # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
qsp1c &lt;- qts(p, df = df)
matplot(p, qsp1c, type="l") # "all on top"
(dq &lt;- (qsp1c[,-1] - qsp1c[,1])[ii,])
matplot(p[ii], dq, type="l", col=2:6,
        main = paste0("difference qtNappr(p,df) - qt(p,df), df=",df), xlab=quote(p))
matplot(p[ii], pmax(abs(dq), 1e-17), log="y", type="l", col=2:6,
        main = paste0("abs. difference |qtNappr(p,df) - qt(p,df)|, df=",df), xlab=quote(p))
legend("bottomright", paste0("k=",0:4), col=2:6, lty=1:5, bty="n")
matplot(p[ii], abs(dq/qsp1c[ii,"qt"]), log="y", type="l", col=2:6,
        main = sprintf("rel.error qtNappr(p, df=%g, k=*)",df), xlab=quote(p))
legend("left", paste0("k=",0:4), col=2:6, lty=1:5, bty="n")

df &lt;- 2000 # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
qsp1c &lt;- qts(p, df=df)
(dq &lt;- (qsp1c[,-1] - qsp1c[,1])[ii,])
matplot(p[ii], dq, type="l", col=2:6,
        main = paste0("difference qtNappr(p,df) - qt(p,df), df=",df), xlab=quote(p))
legend("top", paste0("k=",0:4), col=2:6, lty=1:5)
matplot(p[ii], pmax(abs(dq), 1e-17), log="y", type="l", col=2:6,
        main = paste0("abs.diff. |qtNappr(p,df) - qt(p,df)|, df=",df), xlab=quote(p))
legend("right", paste0("k=",0:4), col=2:6, lty=1:5, bty="n")

matplot(p[ii], abs(dq/qsp1c[ii,"qt"]), log="y", type="l", col=2:6,
        main = sprintf("rel.error qtNappr(p, df=%g, k=*)",df), xlab=quote(p))
legend("left", paste0("k=",0:4), col=2:6, lty=1:5, bty="n")
</code></pre>

<hr>
<h2 id='qtR'>Pure <span class="rlang"><b>R</b></span> Implementation of <span class="rlang"><b>R</b></span>'s C-level t-Distribution Quantiles <code>qt()</code></h2><span id='topic+qtR'></span><span id='topic+qtR1'></span>

<h3>Description</h3>

<p>A pure <span class="rlang"><b>R</b></span> implementation of <span class="rlang"><b>R</b></span>'s Mathlib own C-level <code><a href="stats.html#topic+qt">qt</a>()</code> function.
<br /> 
<code>qtR()</code> is simply defined as </p>
<pre>qtR &lt;- Vectorize(qtR1, c("p","df"))</pre>
<p>where in <code>qtR1(p, df, *)</code> both <code>p</code> and <code>df</code> must be of length one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtR1(p, df, lower.tail = TRUE, log.p = FALSE,
     eps = 1e-12, d1_accu = 1e-13, d1_eps = 1e-11,
     itNewt = 10L, epsNewt = 1e-14, logNewton = log.p,
     verbose = FALSE)
qtR (p, df, lower.tail = TRUE, log.p = FALSE,
     eps = 1e-12, d1_accu = 1e-13, d1_eps = 1e-11,
     itNewt = 10L, epsNewt = 1e-14, logNewton = log.p,
     verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qtR_+3A_p">p</code>, <code id="qtR_+3A_df">df</code></td>
<td>
<p>vectors of probabilities and degrees of freedom, see <code><a href="stats.html#topic+qt">qt</a></code>.</p>
</td></tr>
<tr><td><code id="qtR_+3A_lower.tail">lower.tail</code>, <code id="qtR_+3A_log.p">log.p</code></td>
<td>
<p>logical; see <code><a href="stats.html#topic+qt">qt</a></code>.</p>
</td></tr>
<tr><td><code id="qtR_+3A_eps">eps</code></td>
<td>
<p>non-negative tolerance for checking if <code>df</code> is
&ldquo;very close&rdquo; to <code>1</code> or <code>2</code>, respectively (when a
special branch will be chosen).</p>
</td></tr>
<tr><td><code id="qtR_+3A_d1_accu">d1_accu</code>, <code id="qtR_+3A_d1_eps">d1_eps</code></td>
<td>
<p>non-negative tolerances only for the <code>df &lt; 1</code> cases.</p>
</td></tr>
<tr><td><code id="qtR_+3A_itnewt">itNewt</code></td>
<td>
<p>integer, the maximal number of final Newton(-Raphson) steps.</p>
</td></tr>
<tr><td><code id="qtR_+3A_epsnewt">epsNewt</code></td>
<td>
<p>non-negative convergence tolerance for the final Newton steps.</p>
</td></tr>
<tr><td><code id="qtR_+3A_lognewton">logNewton</code></td>
<td>
<p>logical, in case of <code>log.p=TRUE</code> indicating if
final Newton steps should happen in log-scale.</p>
</td></tr>
<tr><td><code id="qtR_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if diagnostic console output should be produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of t quantiles, properly recycled in <code>(p, df)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+qtU">qtU</a></code> and <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+qt">qt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Inspired from Bugzilla PR#16380
pxy &lt;- curve(pt(-x, df = 1.09, log.p = TRUE), 4e152, 1e156, log="x", n=501)
qxy &lt;- curve(-qt(x, df = 1.09, log.p = TRUE), -392, -385, n=501, log="y", col=4, lwd=2)
lines(x ~ y, data=pxy, col = adjustcolor(2, 1/2), lwd=5, lty=3)
## now our "pure R" version:

qRy &lt;- -qtR(qxy$x, df = 1.09, log.p = TRUE)
all.equal(qRy, qxy$y) # "'is.NA' value mismatch: 14 in current 0 in target" for R &lt;= 4.2.1
cbind(as.data.frame(qxy), qRy, D = qxy$y - qRy)
plot((y - qRy) ~ x, data = qxy, type="o", cex=1/4)

qtR1(.1, .1, verbose=TRUE)
pt(qtR(-390.5, df=1.10, log.p=TRUE, verbose=TRUE, itNewt = 100), df=1.10, log.p=TRUE)/-390.5 - 1
## qt(p=     -390.5, df=        1.1, *) -- general case
##  -&gt; P=2.55861e-170, neg=TRUE, is_neg_lower=TRUE; -&gt; final P=5.11723e-170
## usual 'df' case:  P_ok:= P_ok1 = TRUE, y=3.19063e-308, P..., !P_ok: log.p2=-390.5, y=3.19063e-308
## !P_ok &amp;&amp; x &lt; -36.04: q=5.87162e+153
## P_ok1: log-scale Taylor (iterated):
## it= 1, .. d{q}1=exp(lF - dt(q,df,log=T))*(lF - log(P/2)) = -5.03644e+152; n.q=5.36798e+153
## it= 2, .. d{q}1=exp(lF - dt(q,df,log=T))*(lF - log(P/2)) =  2.09548e+151; n.q=5.38893e+153
## it= 3, .. d{q}1=exp(lF - dt(q,df,log=T))*(lF - log(P/2)) =  4.09533e+148; n.q=5.38897e+153
## it= 4, .. d{q}1=exp(lF - dt(q,df,log=T))*(lF - log(P/2)) =   1.5567e+143; n.q=5.38897e+153
## [1] 0
##    === perfect!
pt(qtR(-391, df=1.10, log.p=TRUE, verbose=TRUE),
   df=1.10, log.p=TRUE)/-391 - 1 # now perfect
</code></pre>

<hr>
<h2 id='qtU'>'uniroot()'-based Computing of t-Distribution Quantiles</h2><span id='topic+qtU'></span><span id='topic+qtU1'></span>

<h3>Description</h3>

<p>Currently, <span class="rlang"><b>R</b></span>'s own <code><a href="stats.html#topic+qt">qt</a>()</code>  (aka <code>qnt()</code> in the
non-central case) uses simple inversion of <code><a href="stats.html#topic+pt">pt</a></code> to compute
quantiles in the case where <code>ncp</code> is specified.
<br />
That simple inversion (of <code>pnt()</code>) has seen to be deficient,
even in cases where <code>pnt()</code>, i.e., <span class="rlang"><b>R</b></span>'s <code><a href="stats.html#topic+pt">pt</a>(.., ncp=*)</code>
does not loose accuracy.
</p>
<p>This <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>-based inversion does <em>not</em> suffer from
these deficits in some cases.
<br /> 
<code>qtU()</code> is simply defined as </p>
<pre>qtU &lt;- Vectorize(qtU1, c("p","df","ncp"))</pre>
<p>where in <code>qtU1(p, df, ncp, *)</code> each of <code>(p, df, ncp)</code> must be of
length one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtU1(p, df, ncp, lower.tail = TRUE, log.p = FALSE, interval = c(-10, 10),
     tol = 1e-05, verbose = FALSE, ...)
qtU (p, df, ncp, lower.tail = TRUE, log.p = FALSE, interval = c(-10, 10),
     tol = 1e-05, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qtU_+3A_p">p</code>, <code id="qtU_+3A_df">df</code>, <code id="qtU_+3A_ncp">ncp</code></td>
<td>
<p>vectors of probabilities, degrees of freedom, and
non-centrality parameter; see <code><a href="stats.html#topic+qt">qt</a></code>.  As there, <code>ncp</code>
may be <code><a href="base.html#topic+missing">missing</a></code> which amounts to being zero.</p>
</td></tr>
<tr><td><code id="qtU_+3A_lower.tail">lower.tail</code>, <code id="qtU_+3A_log.p">log.p</code></td>
<td>
<p>logical; see <code><a href="stats.html#topic+qt">qt</a></code>.</p>
</td></tr>
<tr><td><code id="qtU_+3A_interval">interval</code></td>
<td>
<p>the interval in which quantiles should be searched;
passed to <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>;
the current default is arbitrary and suboptimal; when <code>pt(q,*)</code> is
accurate enough and hence <em>montone</em> (increasing iff
<code>lower.tail</code>), this interval is automatically correctly extended
by <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>
<tr><td><code id="qtU_+3A_tol">tol</code></td>
<td>
<p>non-negative convergence tolerance passed to <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>
<tr><td><code id="qtU_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if <em>every</em> call of the objective
function should produce a line of console output.</p>
</td></tr>
<tr><td><code id="qtU_+3A_...">...</code></td>
<td>
<p>optional further arguments passed to <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of t quantiles, properly recycled in <code>(p, df, ncp)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code> and <code><a href="stats.html#topic+pt">pt</a></code> are the simple <span class="rlang"><b>R</b></span> level
building blocks.  The length-1 argument version <code>qtU1()</code> is short and
simple to understand.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qtU1 # simple definition {with extras only for  'verbose = TRUE'}

## An example, seen to be deficient
## Stephen Berman to R-help, 13 June 2022,
## "Why does qt() return Inf with certain negative ncp values?"
q2 &lt;- seq(-3/4, -1/4, by=1/128)
pq2 &lt;- pt(q2, 35, ncp=-7, lower.tail=FALSE)
### ==&gt; via qtU(), a simple uniroot() - based inversion of pt()
qpqU  &lt;- qtU(pq2, 35, ncp=-7, lower.tail=FALSE, tol=1e-10)
stopifnot(all.equal(q2, qpqU, tol=1e-9)) # perfect!

## These two currently (2022-06-14) give Inf  whereas qtU() works fine
qt  (9e-12, df=35, ncp=-7, lower.tail=FALSE) # warnings; --&gt; Inf
qntR(9e-12, df=35, ncp=-7, lower.tail=FALSE) #  (ditto)
## verbose = TRUE  shows all calls to pt():
qtU1(9e-12, df=35, ncp=-7, lower.tail=FALSE, verbose=TRUE)
</code></pre>

<hr>
<h2 id='r_pois'>Compute Relative Size of i-th term of Poisson Distribution Series</h2><span id='topic+r_pois'></span><span id='topic+r_pois_expr'></span><span id='topic+plRpois'></span>

<h3>Description</h3>

<p>Compute </p>
<p style="text-align: center;"><code class="reqn">r_\lambda(i) := (\lambda^i / i!) / e_{i-1}(\lambda),</code>
</p>

<p>where <code class="reqn">\lambda =</code><code>lambda</code>,  and
</p>
<p style="text-align: center;"><code class="reqn">e_n(x) := 1 + x + x^2/2! + .... + x^n/n! </code>
</p>
<p> is the <code class="reqn">n</code>-th
partial sum of <code class="reqn">\exp(x) = e^x</code>.
</p>
<p>Questions: As function of <code class="reqn">i</code> </p>

<ul>
<li><p> Can this be put in a simple formula, or at least be well
approximated for large <code class="reqn">\lambda</code> and/or large <code class="reqn">i</code>?
</p>
</li>
<li><p> For which <code class="reqn">i</code> (<code class="reqn"> := i_m(\lambda)</code>) is it maximal?
</p>
</li>
<li><p> When does <code class="reqn">r_{\lambda}(i)</code> become smaller than (f+2i-x)/x = a + b*i ?

</p>
</li></ul>

<p>NB: This is relevant in computations for non-central chi-squared (and
similar non-central distribution functions) defined as weighted sum with
&ldquo;Poisson weights&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r_pois(i, lambda)
r_pois_expr  # the R expression() for the asymptotic branch of r_pois()

plRpois(lambda, iset = 1:(2*lambda), do.main = TRUE,
        log = 'xy', type = "o", cex = 0.4, col = c("red","blue"),
        do.eaxis = TRUE, sub10 = "10")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r_pois_+3A_i">i</code></td>
<td>
<p>integer ..</p>
</td></tr>
<tr><td><code id="r_pois_+3A_lambda">lambda</code></td>
<td>
<p>non-negative number ... </p>
</td></tr>
<tr><td><code id="r_pois_+3A_iset">iset</code></td>
<td>
<p> ..... </p>
</td></tr>
<tr><td><code id="r_pois_+3A_do.main">do.main</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> specifying if a main
<code><a href="graphics.html#topic+title">title</a></code> should be drawn via (<code>main = r_pois_expr</code>).</p>
</td></tr>
<tr><td><code id="r_pois_+3A_type">type</code></td>
<td>
<p>type of (line) plot, see <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="r_pois_+3A_log">log</code></td>
<td>
<p>string specifying if (and where) logarithmic scales should be
used, see <code><a href="graphics.html#topic+plot.default">plot.default</a>()</code>.</p>
</td></tr>
<tr><td><code id="r_pois_+3A_cex">cex</code></td>
<td>
<p>character expansion factor.</p>
</td></tr>
<tr><td><code id="r_pois_+3A_col">col</code></td>
<td>
<p>colors for the two curves.</p>
</td></tr>
<tr><td><code id="r_pois_+3A_do.eaxis">do.eaxis</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> specifying if
<code><a href="sfsmisc.html#topic+eaxis">eaxis</a>()</code> (package <a href="https://CRAN.R-project.org/package=sfsmisc"><span class="pkg">sfsmisc</span></a>) should
be used.</p>
</td></tr>
<tr><td><code id="r_pois_+3A_sub10">sub10</code></td>
<td>
<p>argument for <code><a href="sfsmisc.html#topic+eaxis">eaxis</a>()</code> (with a
different default than the original).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>r_pois()</code> is related to our series expansions and approximations
for the non-central chi-squared;
in particular
........... 
</p>
<p><code>plRpois()</code> simply produces a &ldquo;nice&rdquo; plot of <code>r_pois(ii, *)</code>
vs <code>ii</code>.
</p>


<h3>Value</h3>


<dl>
<dt><code>r_pois()</code></dt><dd><p>returns a numeric vector
<code class="reqn">r_\lambda(i)</code> values.</p>
</dd>
<dt><code>r_pois_expr()</code></dt><dd><p>an <code><a href="base.html#topic+expression">expression</a></code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Martin Maechler, 20 Jan 2004</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dpois">dpois</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
plRpois(12)
plRpois(120)
</code></pre>

<hr>
<h2 id='rexpm1'>TOMS 708 Approximation REXP(x) of expm1(x) = exp(x) - 1</h2><span id='topic+rexpm1'></span>

<h3>Description</h3>

<p>Originally <code>REXP()</code>, now <code>rexpm1()</code> is a numeric (double
precision) approximation of <code class="reqn">exp(x) - 1</code>,
notably for small <code class="reqn">|x| \ll 1</code> where direct evaluation
looses accuracy through cancellation.
</p>
<p>Fully accurate computations of <code class="reqn">exp(x) - 1</code> are now known as
<code><a href="base.html#topic+expm1">expm1</a>(x)</code> and have been provided by math libraries (for C,
C++, ..) and <span class="rlang"><b>R</b></span>, (and are typically more accurate than <code>rexp1()</code>).
</p>
<p>The <code>rexpm1()</code> approximation
was developed by Didonato &amp; Morris (1986) and uses a minimax rational
approximation for <code class="reqn">|x| &lt;= 0.15</code>; the authors say
&ldquo;<em>accurate to within 2 units of the 14th significant digit</em>&rdquo;
(top of p.379).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rexpm1(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rexpm1_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector (or array) as <code>x</code>,
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, for the C to R *vectorized* translation.
</p>


<h3>References</h3>

<p>Didonato, A.R. and Morris, A.H. (1986)
Computation of the Incomplete Gamma Function Ratios and their Inverse.
<em>ACM Trans. on Math. Softw.</em> <b>12</b>, 377&ndash;393, <a href="https://doi.org/10.1145/22721.23109">doi:10.1145/22721.23109</a>;
The above is the &ldquo;flesh&rdquo; of &lsquo;TOMS 654&rsquo;:
</p>
<p>Didonato, A.R. and Morris, A.H. (1987)
Algorithm 654: FORTRAN subroutines for Compute the Incomplete Gamma
Function Ratios and their Inverse.
<em>ACM Transactions on Mathematical Software</em> <b>13</b>, 318&ndash;319, <a href="https://doi.org/10.1145/29380.214348">doi:10.1145/29380.214348</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pbeta">pbeta</a></code>, where the C version of <code>rexpm1()</code> has been used in
several places, notably in the original TOMS 708 algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-3/4, 3/4, by=1/1024)
plot(x,     rexpm1(x)/expm1(x) - 1, type="l", main = "Error wrt expm1()")
abline(h = (-8:8)*2^-53, lty=1:2, col=adjustcolor("gray", 1/2))
cb2 &lt;- adjustcolor("blue", 1/2)
do.15 &lt;- function(col = cb2) {
    abline(v = 0.15*(-1:1), lty=3, lwd=c(3,1,3), col=col)
    axis(1, at=c(-.15, .15), col=cb2, col.axis=cb2)
}
do.15()

 op &lt;- par(mar = par("mar") + c(0,0,0,2))
plot(x, abs(rexpm1(x)/expm1(x) - 1),type="l", log = 'y',
     main = "*Relative* Error wrt expm1() [log scale]")#, yaxt="n"
abline(h = (1:9)*2^-53, lty=2, col=adjustcolor("gray", 1/2))
axis(4, at = (1:9)*2^-53, las = 1, labels =
     expression(2^-53, 2^-52, 3 %*% 2^-53, 2^-51, 5 %*% 2^-53,
                6 %*% 2^-53, 7 %*% 2^-53, 2^-50, 9 %*% 2^-53))
do.15()
 par(op)

## "True" Accuracy comparison of  rexpm1() with [OS mathlib based] expm1():
if(require("Rmpfr")) withAutoprint({
  xM &lt;- mpfr(x, 128); Xexpm1 &lt;- expm1(xM)
  REr1 &lt;- asNumeric(rexpm1(x)/Xexpm1 - 1)
  REe1 &lt;- asNumeric(expm1(x) /Xexpm1 - 1)
  absC &lt;- function(E) pmax(2^-55, abs(E))

  plot(x, absC(REr1), type= "l", log="y",
       main = "|rel.Error|  of exp(x)-1 computations wrt 128-bit MPFR ")
  lines(x, absC(REe1), col = (c2 &lt;- adjustcolor(2, 3/4)))
  abline(h = (1:9)*2^-53, lty=2, col=adjustcolor("gray60", 1/2))
  do.15()
  axis(4, mgp=c(2,1/4,0),tcl=-1/8, at=2^-(53:51), labels=expression(2^-53, 2^-52, 2^-51), las=1)
  legend("topleft", c("rexpm1(x)", " expm1(x)"), lwd=2, col=c("black", c2),
         bg = "gray90", box.lwd=.1)

})
</code></pre>

<hr>
<h2 id='stirlerr'>Stirling's Error Function - Auxiliary for Gamma, Beta, etc</h2><span id='topic+stirlerr'></span><span id='topic+stirlerrC'></span><span id='topic+stirlerr_simpl'></span><span id='topic+lgammacor'></span>

<h3>Description</h3>


<p>Stirling's approximation (to the factorial or <code class="reqn">\Gamma</code> function)
error in <code class="reqn">\log</code> scale is the difference of the left and right hand
side of Stirling's approximation to <code class="reqn">n!</code>,
<code class="reqn">n! \approx \bigl(\frac{n}{e}\bigr)^n \sqrt{2\pi n},</code> i.e., <code>stirlerr(n) :=</code> <code class="reqn">\delta(n)</code>,
where </p>
<p style="text-align: center;"><code class="reqn">\delta(n) =  \log\Gamma(n + 1) - n\log(n) + n - \log(2 \pi n)/2.</code>
</p>

<p>Partly, pure <span class="rlang"><b>R</b></span> transcriptions of the C code utility functions for
<code><a href="stats.html#topic+dgamma">dgamma</a>()</code>, <code><a href="stats.html#topic+dbinom">dbinom</a>()</code>, <code><a href="stats.html#topic+dpois">dpois</a>()</code>, <code><a href="stats.html#topic+dt">dt</a>()</code>,
and similar &ldquo;base&rdquo; density functions by Catherine Loader.
</p>
<p>These <span class="pkg">DPQ</span> versions typically have extra arguments with defaults
that correspond to <span class="rlang"><b>R</b></span>'s Mathlib C code hardwired cutoffs and tolerances.
</p>
<p><code>lgammacor(x)</code> is &ldquo;the same&rdquo; as <code>stirlerr(x)</code>, both
computing <code class="reqn">delta(x)</code> accurately, however is only defined for <code class="reqn">x
    \ge 10</code>, and has been crucially used for <span class="rlang"><b>R</b></span>'s own <code><a href="base.html#topic+lgamma">lgamma</a>()</code>
and <code><a href="base.html#topic+lbeta">lbeta</a>()</code> computations.
</p>
<p>Note that the example below suggests that R's hardwired default of
<code>nalgm = 5</code> is unnecessarily losing more than one digit accuracy,
<code>nalgm = 6</code> seems much better.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
stirlerr(n, scheme = c("R3", "R4.4_0"),
         cutoffs = switch(scheme
                        , R3     = c(15, 35, 80, 500)
                        , R4.4_0 = c(5.25, rep(6.5, 4), 7.1, 7.6, 8.25, 8.8, 9.5, 11,
                                     14, 19,   25, 36, 81, 200, 3700, 17.4e6)
                        
                        
                        
                        
                          ),
         use.halves = missing(cutoffs),
         direct.ver = c("R3", "lgamma1p", "MM2", "n0"),
         order = NA,
         verbose = FALSE)

stirlerrC(n, version = c("R3", "R4..1", "R4.4_0"))

stirlerr_simpl(n, version = c("R3", "lgamma1p", "MM2", "n0"), minPrec = 128L)

lgammacor(x, nalgm = 5, xbig = 2^26.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stirlerr_+3A_x">x</code>, <code id="stirlerr_+3A_n">n</code></td>
<td>
<p><code><a href="base.html#topic+numeric">numeric</a></code> (or number-alike such as &quot;mpfr&quot;).</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if some information about the
computations are to be printed.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_version">version</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string specifying the version of
<code>stirlerr_simpl()</code> or <code>stirlerrC()</code>.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_scheme">scheme</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string specifying the
<code>cutoffs</code> scheme for <code>stirlerr()</code>.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_cutoffs">cutoffs</code></td>
<td>
<p>an increasing numeric vector, required to start with
with <code>cutoffs[1] &lt;= 15</code> specifying the cutoffs to switch from 2 to 3 to ...,
up to 10 term approximations for non-small <code>n</code>, where the direct
formula loses precision.  When missing (as by default), <code>scheme</code>
is used, where <code>scheme = "R3"</code> chooses (15, 35, 80, 500), the
cutoffs in use in <span class="rlang"><b>R</b></span> versions up to (and including) 4.3.z.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_use.halves">use.halves</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if the full-accuracy
prestored values should be use when
<code class="reqn">2n \in \{0,1,\dots,30\}</code>, i.e.,
<code class="reqn">n \le 15</code> and n is integer or integer +
<code class="reqn">\frac{1}{2}</code>.
Turn this off to judge the underlying approximation accuracy by
comparison with MPFR.   However, keep the default <code>TRUE</code> for
back-compatibility.</p>
</td></tr>




<tr><td><code id="stirlerr_+3A_direct.ver">direct.ver</code></td>
<td>
<p>a <code><a href="base.html#topic+character">character</a></code> string specifying the version of
<code>stirlerr_simpl()</code> to be used for the &ldquo;direct&rdquo; case in
<code>stirlerr(n)</code>.
</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_order">order</code></td>
<td>
<p>approximation order, <code>1 &lt;= order &lt;= 20</code> or <code>NA</code>
for <code>stirlerr()</code>.  If not <code>NA</code>, it specifies the number of
terms to be used in the Stirling series which will be used for all
<code>n</code>, i.e., <code>scheme</code>, <code>cutoffs</code>, <code>use.halves</code>, and
<code>direct.ver</code> are irrelevant.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_minprec">minPrec</code></td>
<td>
<p>a positive integer; for <code>stirlerr_simpl</code> the minimal
accuracy or precision in bits when <code><a href="Rmpfr.html#topic+mpfr">mpfr</a></code> numbers
are used.</p>
</td></tr>

<tr><td><code id="stirlerr_+3A_nalgm">nalgm</code></td>
<td>
<p>number of terms to use for Chebyshev polynomial approximation
in <code>lgammacor()</code>.  The default, 5, is the value hard wired in <span class="rlang"><b>R</b></span>'s
C Mathlib.</p>
</td></tr>
<tr><td><code id="stirlerr_+3A_xbig">xbig</code></td>
<td>
<p>a large positive number; if <code>x &gt;= xbig</code>, the simple
asymptotic approximation <code>lgammacor(x) := 1/(12*x)</code> is used.  The
default, <code class="reqn">2^{26.5} = 94906265.6</code>, is the value hard wired in <span class="rlang"><b>R</b></span>'s C
Mathlib.</p>
</td></tr>
</table>


<h3>Details</h3>



<dl>
<dt><code>stirlerr()</code>:</dt><dd><p>Stirling's error, <code>stirlerr(n):=</code>
<code class="reqn">\delta(n)</code> has asymptotic (<code class="reqn">n \to\infty</code>) expansion
</p>
<p style="text-align: center;"><code class="reqn">\delta(n) = \frac 1{12 n} - \frac 1{360 n^3} + \frac 1{1260 n^5} \pm O(n^{-7}),</code>
</p>

<p>and this expansion is used up to remainder <code class="reqn">O(n^{-35})</code> 
in current (package <span class="pkg">DPQ</span>) <code>stirlerr(n)</code>;
different numbers of terms between different cutoffs for <code class="reqn">n</code>, and
using the direct formula for <code class="reqn">n &lt;= c_1</code>, where <code class="reqn">c_1</code> is the first
cutoff, <code>cutoff[1]</code>.
</p>
<p>Note that (new in 2024-01) <code>stirlerr(n, order = k)</code> will
<em>not</em> use <code>cutoffs</code> nor the direct formula (with its
<code>direct.ver</code>), nor halves (<code>use.halves=TRUE</code>),
and allows <code class="reqn">k \le 20</code>.
Tests seem to indicate that for current double precision arithmetic,
only <code class="reqn">k \le 17</code> seem to make sense. 
</p>
</dd>
</dl>



<h3>Value</h3>

<p>a numeric vector &ldquo;like&rdquo; <code>x</code>; in some cases may also be an
(high accuracy) &quot;mpfr&quot;-number vector, using CRAN package <a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a>.
</p>
<p><code>lgammacor(x)</code> originally returned <code>NaN</code> for all <code class="reqn">|x| &lt; 10</code>,
as its Chebyshev polynomial approximation has been constructed for
<code class="reqn">x \in [10, xbig]</code>,
specifically for <code class="reqn">u \in [-1,1]</code> where
<code class="reqn">t := 10/x \in [1/x_B, 1]</code>  and
<code class="reqn">u := 2t^2 -1 \in [-1 + \epsilon_B, 1]</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>References</h3>

<p>C. Loader (2000), see <code><a href="stats.html#topic+dbinom">dbinom</a></code>'s documentation.

</p>
<p>Our package vignette <em>log1pmx, bd0, stirlerr - Probability Computations in R</em>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dgamma">dgamma</a></code>, 
<code><a href="stats.html#topic+dpois">dpois</a></code>.
High precision versions <code><a href="DPQmpfr.html#topic+stirlerrM">stirlerrM</a>(n)</code> and 
<code>stirlerrSer(n,k)</code> in package <a href="https://CRAN.R-project.org/package=DPQmpfr"><span class="pkg">DPQmpfr</span></a> (via the
<a href="https://CRAN.R-project.org/package=Rmpfr"><span class="pkg">Rmpfr</span></a> and <a href="https://CRAN.R-project.org/package=gmp"><span class="pkg">gmp</span></a> packages).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- seq(1, 50, by=1/4)
st.n &lt;- stirlerr(n) # now vectorized
stopifnot(identical(st.n, sapply(n, stirlerr)))
st3. &lt;- stirlerr(n, "R3", direct.ver = "R3") # previous default
st3  &lt;- stirlerr(n, "R3", direct.ver = "lgamma1p") # new? default
## for these n, there is *NO* difference:
stopifnot(st3 == st3.)
plot(n, st.n, type = "b", log="xy", ylab = "stirlerr(n)")
st4 &lt;- stirlerr(n, "R4.4_0", verbose = TRUE) # verbose: give info on cases
## order = k = 1:20  terms in series approx:
k &lt;- 1:20
stirlOrd &lt;- sapply(k, function(k) stirlerr(n, order = k))
matlines(n, stirlOrd)
matplot(n, stirlOrd - st.n, type = "b", cex=1/2, ylim = c(-1,1)/10, log = "x",
        main = substitute(list(stirlerr(n, order=k) ~~"error", k == 1:mK),  list(mK = max(k))))

matplot(n, abs(stirlOrd - st.n), type = "b", cex=1/2, log = "xy",
        main = "| stirlerr(n, order=k) error |")
mtext(paste("k =", deparse(k))) ; abline(h = 2^-(53:51), lty=3, lwd=1/2)
colnames(stirlOrd) &lt;- paste0("k=", k)

stCn &lt;- stirlerrC(n)
all.equal(st.n, stCn, tolerance = 0)  # see 6.7447e-14
stopifnot(all.equal(st.n, stCn, tolerance = 1e-12))
stC2 &lt;- stirlerrC(n, version = "R4..1")
stC4 &lt;- stirlerrC(n, version = "R4.4_0")


## lgammacor(n) : only defined for n &gt;= 10
lgcor &lt;- lgammacor(n)
lgcor6 &lt;- lgammacor(n, nalgm = 6) # more accurate?

all.equal(lgcor[n &gt;= 10], st.n[n &gt;= 10], tolerance=0)# .. rel.diff.: 4.687e-14
stopifnot(identical(is.na(lgcor), n &lt; 10),
          all.equal(lgcor[n &gt;= 10],
                    st.n [n &gt;= 10], tolerance = 1e-12))

## look at *relative* errors -- need "Rmpfr" for "truth" % Rmpfr / DPQmpfr in 'Suggests'
if(requireNamespace("Rmpfr") &amp;&amp; requireNamespace("DPQmpfr")) {
    ## stirlerr(n) uses DPQmpfr::stirlerrM()  automagically when n is &lt;mpfr&gt;
    relErrV &lt;- sfsmisc::relErrV; eaxis &lt;- sfsmisc::eaxis
    mpfr &lt;- Rmpfr::mpfr;     asNumeric &lt;- Rmpfr::asNumeric
    stM &lt;- stirlerr(mpfr(n, 512))
    relE &lt;- asNumeric(relErrV(stM, cbind(st3, st4, stCn, stC4,
                                         lgcor, lgcor6, stirlOrd)))

    matplot(n, pmax(abs(relE),1e-20), type="o", cex=1/2, log="xy", ylim =c(8e-17, 0.1),
            xaxt="n", yaxt="n", main = quote(abs(relErr(stirlerr(n)))))
    ## mark "lgcor*" -- lgammacor() particularly !
    col.lgc &lt;- adjustcolor(c(2,4), 2/3)
    matlines(n, abs(relE[,c("lgcor","lgcor6")]), col=col.lgc, lwd=3)
    lines(n, abs(relE[,"lgcor6"]), col=adjustcolor(4, 2/3), lwd=3)
    eaxis(1, sub10=2); eaxis(2); abline(h = 2^-(53:51), lty=3, col=adjustcolor(1, 1/2))
    axis(1, at=15, col=NA, line=-1); abline(v=c(10,15), lty=2, col=adjustcolor(1, 1/4))
    legend("topright", legend=colnames(relE), cex = 3/4,
           col=1:6, lty=1:5, pch= c(1L:9L, 0L, letters)[seq_len(ncol(relE))])
    legend("topright", legend=colnames(relE)[1:6], cex = 3/4, lty=1:5, lwd=3,
           col=c(rep(NA,4), col.lgc), bty="n")
    ## Note that lgammacor(x) {default, n=5} is clearly inferior,
    ## but lgammacor(x, 6) is really good {in [10, 50] at least}
}# end if( &lt;Rmpfr&gt; )
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
