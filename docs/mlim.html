<!DOCTYPE html><html><head><title>Help for package mlim</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlim}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#charity'><p>some items about attitude towards charity</p></a></li>
<li><a href='#manifest'><p>Manifest Anxiety Scale</p></a></li>
<li><a href='#mlim'><p>missing data imputation with automated machine learning</p></a></li>
<li><a href='#mlim.error'><p>imputation error</p></a></li>
<li><a href='#mlim.mids'><p>prepare &quot;mids&quot; class object</p></a></li>
<li><a href='#mlim.na'><p>add stratified/unstratified artificial missing observations</p></a></li>
<li><a href='#mlim.preimpute'><p>carries out preimputation</p></a></li>
<li><a href='#mlim.summarize'><p>mlim imputation summary</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Single and Multiple Imputation with Automated Machine Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>Machine learning algorithms have been used for performing 
    single missing data imputation and most recently, multiple imputations. 
    However, this is the first attempt for using automated machine learning algorithms 
    for performing both 
    single and multiple imputation. Automated machine learning is a procedure for 
    fine-tuning the model automatic, performing a random search for a model that 
    results in less error, without overfitting the data. The main idea is 
    to allow the model to set its own parameters for imputing each variable separately 
    instead of setting fixed predefined parameters to impute all variables 
    of the dataset.
    Using automated machine learning, the package fine-tunes an Elastic 
    Net (default) or Gradient Boosting, Random Forest, Deep Learning, Extreme Gradient Boosting,
    or Stacked Ensemble machine learning model (from one or a combination of other 
    supported algorithms) for imputing the missing 
    observations. This procedure has been implemented for the 
    first time by this package and is expected to outperform other packages for 
    imputing missing data that do not fine-tune their models. The multiple imputation 
    is implemented via bootstrapping without letting the duplicated observations to 
    harm the cross-validation procedure, which is the way imputed variables are evaluated.
    Most notably, the package implements automated procedure for handling imputing imbalanced 
    data (class rarity problem), which happens when a factor variable has a level that is far more 
    prevalent than the other(s). This is known to result in biased predictions, hence, biased 
    imputation of missing data. However, the autobalancing procedure ensures that instead of 
    focusing on maximizing accuracy (classification error) in imputing factor variables, 
    a fairer procedure and imputation method is practiced. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>h2o (&ge; 3.34.0.0), curl (&ge; 4.3.2), mice, missRanger, memuse,
md.log (&ge; 0.2.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/haghish/mlim">https://github.com/haghish/mlim</a>,
<a href="https://www.sv.uio.no/psi/english/people/aca/haghish/">https://www.sv.uio.no/psi/english/people/aca/haghish/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/haghish/mlim/issues">https://github.com/haghish/mlim/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-15 13:16:01 UTC; U-Shaped-Valley</td>
</tr>
<tr>
<td>Author:</td>
<td>E. F. Haghish [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>E. F. Haghish &lt;haghish@uio.no&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-16 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='charity'>some items about attitude towards charity</h2><span id='topic+charity'></span>

<h3>Description</h3>

<p>A dataset containing likert-scale items about attitude towards charity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>charity
</code></pre>


<h3>Format</h3>

<p>A data frame with 832 rows and 5 variables:
</p>

<dl>
<dt>ta1</dt><dd><p>Charitable Organizations More Effective</p>
</dd>
<dt>ta2</dt><dd><p>Degree of Trust</p>
</dd>
<dt>ta3</dt><dd><p>Charitable Organizations Honest/Ethical</p>
</dd>
<dt>ta4</dt><dd><p>Role Improving Communities</p>
</dd>
<dt>ta5</dt><dd><p>Job Delivering Services</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://www.stata.com/">https://www.stata.com/</a>
</p>

<hr>
<h2 id='manifest'>Manifest Anxiety Scale</h2><span id='topic+manifest'></span>

<h3>Description</h3>

<p>The Taylor Manifest Anxiety Scale was first developed in 1953 to identify
individuals who would be good subjects for studies of stress and other
related psychological phenomenon. Since then it has been used as a measure of
anxiety as general personality trait. Anxiety is a complex psychological
construct that includes a multiple of different facets related to extensive
worrying that may impair normal functioning. The test has been widely studied
and used in research, however there are some concerns that it does not measure
a single trait, but instead, measures a basket of loosely related ones and so
the score is not that meaningful.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manifest
</code></pre>


<h3>Format</h3>

<p>A data frame with 4469 rows and 52 variables:
</p>

<dl>
<dt>gender</dt><dd><p>participants' gender</p>
</dd>
<dt>age</dt><dd><p>participants' age in years</p>
</dd>
<dt>Q1</dt><dd><p>I do not tire quickly.</p>
</dd>
<dt>Q2</dt><dd><p>I am troubled by attacks of nausea.</p>
</dd>
<dt>Q3</dt><dd><p>I believe I am no more nervous than most others.</p>
</dd>
<dt>Q4</dt><dd><p>I have very few headaches.</p>
</dd>
<dt>Q5</dt><dd><p>I work under a great deal of tension.</p>
</dd>
<dt>Q6</dt><dd><p>I cannot keep my mind on one thing.</p>
</dd>
<dt>Q7</dt><dd><p>I worry over money and business.</p>
</dd>
<dt>Q8</dt><dd><p>I frequently notice my hand shakes when I try to do something.</p>
</dd>
<dt>Q9</dt><dd><p>I blush no more often than others.</p>
</dd>
<dt>Q10</dt><dd><p>I have diarrhea once a month or more.</p>
</dd>
<dt>Q11</dt><dd><p>I worry quite a bit over possible misfortunes.</p>
</dd>
<dt>Q12</dt><dd><p>I practically never blush.</p>
</dd>
<dt>Q13</dt><dd><p>I am often afraid that I am going to blush.</p>
</dd>
<dt>Q14</dt><dd><p>I have nightmares every few nights.</p>
</dd>
<dt>Q15</dt><dd><p>My hands and feet are usually warm.</p>
</dd>
<dt>Q16</dt><dd><p>I sweat very easily even on cool days.</p>
</dd>
<dt>Q17</dt><dd><p>Sometimes when embarrassed, I break out in a sweat.</p>
</dd>
<dt>Q18</dt><dd><p>I hardly ever notice my heart pounding and I am seldom short of breath.</p>
</dd>
<dt>Q19</dt><dd><p>I feel hungry almost all the time.</p>
</dd>
<dt>Q20</dt><dd><p>I am very seldom troubled by constipation.</p>
</dd>
<dt>Q21</dt><dd><p>I have a great deal of stomach trouble.</p>
</dd>
<dt>Q22</dt><dd><p>I have had periods in which I lost sleep over worry.</p>
</dd>
<dt>Q23</dt><dd><p>My sleep is fitful and disturbed.</p>
</dd>
<dt>Q24</dt><dd><p>I dream frequently about things that are best kept to myself.</p>
</dd>
<dt>Q25</dt><dd><p>I am easily embarrassed.</p>
</dd>
<dt>Q26</dt><dd><p>I am more sensitive than most other people.</p>
</dd>
<dt>Q27</dt><dd><p>I frequently find myself worrying about something.</p>
</dd>
<dt>Q28</dt><dd><p>I wish I could be as happy as others seem to be.</p>
</dd>
<dt>Q29</dt><dd><p>I am usually calm and not easily upset.</p>
</dd>
<dt>Q30</dt><dd><p>I cry easily.</p>
</dd>
<dt>Q31</dt><dd><p>I feel anxiety about something or someone almost all the time.</p>
</dd>
<dt>Q32</dt><dd><p>I am happy most of the time.</p>
</dd>
<dt>Q33</dt><dd><p>It makes me nervous to have to wait.</p>
</dd>
<dt>Q34</dt><dd><p>I have periods of such great restlessness that I cannot sit long I a chair.</p>
</dd>
<dt>Q35</dt><dd><p>Sometimes I become so excited that I find it hard to get to sleep.</p>
</dd>
<dt>Q36</dt><dd><p>I have sometimes felt that difficulties were piling up so high that I could not overcome them.</p>
</dd>
<dt>Q37</dt><dd><p>I must admit that I have at times been worried beyond reason over something that really did not matter.</p>
</dd>
<dt>Q38</dt><dd><p>I have very few fears compared to my friends.</p>
</dd>
<dt>Q39</dt><dd><p>I have been afraid of things or people that I know could not hurt me.</p>
</dd>
<dt>Q40</dt><dd><p>I certainly feel useless at times.</p>
</dd>
<dt>Q41</dt><dd><p>I find it hard to keep my mind on a task or job.</p>
</dd>
<dt>Q42</dt><dd><p>I am usually self-conscious.</p>
</dd>
<dt>Q43</dt><dd><p>I am inclined to take things hard.</p>
</dd>
<dt>Q44</dt><dd><p>I am a high-strung person.</p>
</dd>
<dt>Q45</dt><dd><p>Life is a trial for me much of the time.</p>
</dd>
<dt>Q46</dt><dd><p>At times I think I am no good at all.</p>
</dd>
<dt>Q47</dt><dd><p>I am certainly lacking in self-confidence.</p>
</dd>
<dt>Q48</dt><dd><p>I sometimes feel that I am about to go to pieces.</p>
</dd>
<dt>Q49</dt><dd><p>I shrink from facing crisis of difficulty.</p>
</dd>
<dt>Q50</dt><dd><p>I am entirely self-confident.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data comes from an online offering of the Taylor Manifest Anxiety Scale.
At the end of the test users were asked if their answers were accurate and
could be used for research, 76
<a href="https://openpsychometrics.org/">https://openpsychometrics.org/</a>.
</p>
<p>#' items 1 to 50 were rated 1=True and 2=False. gender, chosen from
a drop down menu (1=male, 2=female, 3=other) and age was
entered as a free response (ages&lt;14 have been removed)
</p>


<h3>Source</h3>

<p><a href="https://openpsychometrics.org/tests/TMAS/">https://openpsychometrics.org/tests/TMAS/</a>
</p>


<h3>References</h3>

<p>Taylor, J. (1953). &quot;A personality scale of manifest anxiety&quot;.
The Journal of Abnormal and Social Psychology, 48(2), 285-290.
</p>

<hr>
<h2 id='mlim'>missing data imputation with automated machine learning</h2><span id='topic+mlim'></span>

<h3>Description</h3>

<p>imputes data.frame with mixed variable types using automated
machine learning (AutoML)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim(
  data = NULL,
  m = 1,
  algos = c("ELNET"),
  postimpute = FALSE,
  stochastic = m &gt; 1,
  ignore = NULL,
  tuning_time = 900,
  max_models = NULL,
  maxiter = 10L,
  cv = 10L,
  matching = "AUTO",
  autobalance = TRUE,
  balance = NULL,
  seed = NULL,
  verbosity = NULL,
  report = NULL,
  tolerance = 0.001,
  doublecheck = TRUE,
  preimpute = "RF",
  cpu = -1,
  ram = NULL,
  flush = FALSE,
  preimputed.data = NULL,
  save = NULL,
  load = NULL,
  shutdown = TRUE,
  java = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> (strictly) with missing data to be
imputed. if <code>'load'</code> argument is provided, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="mlim_+3A_m">m</code></td>
<td>
<p>integer, specifying number of multiple imputations. the default value is
1, carrying out a single imputation.</p>
</td></tr>
<tr><td><code id="mlim_+3A_algos">algos</code></td>
<td>
<p>character vector, specifying algorithms to be used for missing data
imputation. supported algorithms are &quot;ELNET&quot;, &quot;RF&quot;, &quot;GBM&quot;, &quot;DL&quot;,
&quot;XGB&quot;, and &quot;Ensemble&quot;. if more than one algorithm is specified,
mlim changes behavior to save on runtime. for example,
the default is &quot;ELNET&quot;, which fine-tunes an Elastic Net model.
In general, &quot;ELNET&quot; is expected to
be the best algorithm because it fine-tunes very fast, it is
very robust to over-fitting, and hence, it generalizes very well.
However, if your data has many factor variables, each with several
levels, it is recommended to have c(&quot;ELNET&quot;, &quot;RF&quot;) as your imputation
algorithms (and possibly add &quot;Ensemble&quot; as well, to make the most out
of tuning the models).
</p>
<p>Note that code&quot;XGB&quot; is only available in Mac OS and Linux. moreover,
&quot;GBM&quot;, &quot;DL&quot; and &quot;XGB&quot; take the full given &quot;tuning_time&quot; (see below) to
tune the best model for imputing he given variable, whereas &quot;ELNET&quot;
will produce only one fine-tuned model, often at less time than
other algorithms need for developing a single model, which is why &quot;ELNET&quot;
is work horse of the mlim imputation package.</p>
</td></tr>
<tr><td><code id="mlim_+3A_postimpute">postimpute</code></td>
<td>
<p>(EXPERIMENTAL FEATURE) logical. if TRUE, mlim uses algorithms rather than 'ELNET' for carrying out
postimputation optimization. however, if FALSE, all specified algorihms will
be used in the process of 'reimputation' together. the 'Ensemble' algorithm
is encouraged when other algorithms are used. However, for general users
unspecialized in machine learning, postimpute is NOT recommended because this
feature is currently experimental, prone to over-fitting, and highly computationally extensive.</p>
</td></tr>
<tr><td><code id="mlim_+3A_stochastic">stochastic</code></td>
<td>
<p>logical. by default it is set to TRUE for multiple imputation and FALSE for
single imputation. stochastic argument is currently under testing and is intended to
avoid inflating the correlation between imputed valuables.</p>
</td></tr>
<tr><td><code id="mlim_+3A_ignore">ignore</code></td>
<td>
<p>character vector of column names or index of columns that should
should be ignored in the process of imputation.</p>
</td></tr>
<tr><td><code id="mlim_+3A_tuning_time">tuning_time</code></td>
<td>
<p>integer. maximum runtime (in seconds) for fine-tuning the
imputation model for each variable in each iteration. the default
time is 900 seconds but for a large dataset, you
might need to provide a larger model development
time. this argument also influences <code>max_models</code>,
see below. If you are using 'ELNET' algorithm (default),
you can be generous with the 'tuning_time' argument because
'ELNET' tunes much faster than the rest and will only
produce one model.</p>
</td></tr>
<tr><td><code id="mlim_+3A_max_models">max_models</code></td>
<td>
<p>integer. maximum number of models that can be generated in
the proecess of fine-tuning the parameters. this value
default to 100, meaning that for imputing each variable in
each iteration, up to 100 models can be fine-tuned. increasing
this value should be consistent with increasing
<code>max_model_runtime_secs</code>, allowing the model to spend
more time in the process of individualized fine-tuning.
as a result, the better tuned the model, the more accurate
the imputed values are expected to be</p>
</td></tr>
<tr><td><code id="mlim_+3A_maxiter">maxiter</code></td>
<td>
<p>integer. maximum number of iterations. the default value is <code>15</code>,
but it can be reduced to <code>3</code> (not recommended, see below).</p>
</td></tr>
<tr><td><code id="mlim_+3A_cv">cv</code></td>
<td>
<p>logical. specify number of k-fold Cross-Validation (CV). values of
10 or higher are recommended. default is 10.</p>
</td></tr>
<tr><td><code id="mlim_+3A_matching">matching</code></td>
<td>
<p>logical. if <code>TRUE</code>, imputed values are coerced to the
closest value to the non-missing values of the variable.
if set to &quot;AUTO&quot;, 'mlim' decides whether to match
or not, based on the variable classes. the default is &quot;AUTO&quot;.</p>
</td></tr>
<tr><td><code id="mlim_+3A_autobalance">autobalance</code></td>
<td>
<p>logical. if TRUE (default), binary and multinomial factor variables
will be balanced before the imputation to obtain fairer
and less-biased imputations, which are typically in favor
of the majority class.
if FALSE, imputation fairness will be sacrificed for overall accuracy, which
is not recommended, although it is commonly practiced in other missing data
imputation software. MLIM is highly concerned with imputation fairness for
factor variables and autobalancing is generally recommended.
in fact, higher overall accuracy does not mean a better imputation as
long as minority classes are neglected, which increases the bias in favor of the
majority class. if you do not wish to autobalance all the
factor variables, you can manually specify the variables
that should be balanced using the 'balance' argument (see below).</p>
</td></tr>
<tr><td><code id="mlim_+3A_balance">balance</code></td>
<td>
<p>character vector, specifying variable names that should be
balanced before imputation. balancing the prevalence might
decrease the overall accuracy of the imputation, because it
attempts to ensure the representation of the rare outcome.
this argument is optional and intended for advanced users that
impute a severely imbalance categorical (nominal) variable.</p>
</td></tr>
<tr><td><code id="mlim_+3A_seed">seed</code></td>
<td>
<p>integer. specify the random generator seed</p>
</td></tr>
<tr><td><code id="mlim_+3A_verbosity">verbosity</code></td>
<td>
<p>character. controls how much information is printed to console.
the value can be &quot;warn&quot; (default), &quot;info&quot;, &quot;debug&quot;, or NULL.
to FALSE.</p>
</td></tr>
<tr><td><code id="mlim_+3A_report">report</code></td>
<td>
<p>filename. if a filename is specified (e.g. report = &quot;mlim.md&quot;), the <code>"md.log"</code> R
package is used to generate a Markdown progress report for the
imputation. the format of the report is adopted based on the
<code>'verbosity'</code> argument. the higher the verbosity, the more
technical the report becomes. if verbosity equals &quot;debug&quot;, then
a log file is generated, which includes time stamp and shows
the function that has generated the message. otherwise, a
reduced markdown-like report is generated. default is NULL.</p>
</td></tr>
<tr><td><code id="mlim_+3A_tolerance">tolerance</code></td>
<td>
<p>numeric. the minimum rate of improvement in estimated error metric
of a variable to qualify the imputation for another round of iteration,
if the <code>maxiter</code> is not yet reached. any improvement of imputation
is desirable.  however, specifying values above 0 can reduce the number
of required iterations at a marginal increase of imputation error.
for larger datasets, value of &quot;1e-3&quot; is recommended to reduce number
of iterations. the default value is '1e-3'.</p>
</td></tr>
<tr><td><code id="mlim_+3A_doublecheck">doublecheck</code></td>
<td>
<p>logical. default is TRUE (which is conservative). if FALSE, if the estimated
imputation error of a variable does not improve, the variable
will be not reimputed in the following iterations. in general,
deactivating this argument will slightly reduce the imputation
accuracy, however, it significantly reduces the computation time.
if your dataset is large, you are advised to set this argument to
FALSE. (EXPERIMENTAL: consider that by avoiding several iterations
that marginally improve the imputation accuracy, you might gain
higher accuracy by investing your computational resources in fine-tuning
better algorithms such as &quot;GBM&quot;)</p>
</td></tr>
<tr><td><code id="mlim_+3A_preimpute">preimpute</code></td>
<td>
<p>character. specifies the 'primary' procedure of handling the missing
data. before 'mlim' begins imputing the missing observations, they should
be prepared for the imputation algorithms and thus, they should be replaced
with some values.
the default procedure is a quick &quot;RF&quot;, which models the missing
data with parallel Random Forest model. this is a very fast procedure,
which later on, will be replaced within the &quot;reimputation&quot; procedure (see below).
possible other alternative is <code>"mm"</code>,
which carries out mean/mode replacement, as practiced by most imputation algorithms.
&quot;mm&quot; is much faster than &quot;RF&quot;. if your dataset is very
large, consider pre-imputing it before hand using 'mlim.preimpute()'
function and passing the preimputed dataset to mlim (see &quot;preimputed.data&quot; argument).</p>
</td></tr>
<tr><td><code id="mlim_+3A_cpu">cpu</code></td>
<td>
<p>integer. number of CPUs to be dedicated for the imputation.
the default takes all of the available CPUs.</p>
</td></tr>
<tr><td><code id="mlim_+3A_ram">ram</code></td>
<td>
<p>integer. specifies the maximum size, in Gigabytes, of the
memory allocation. by default, all the available memory is
used for the imputation.
large memory size is particularly advised, especially
for multicore processes. the more you give the more you get!</p>
</td></tr>
<tr><td><code id="mlim_+3A_flush">flush</code></td>
<td>
<p>logical (experimental). if TRUE, after each model, the server is
cleaned to retrieve RAM. this feature is in testing mode and is
currently set to FALSE by default, but it is recommended if you
have limited amount of RAM or large datasets.</p>
</td></tr>
<tr><td><code id="mlim_+3A_preimputed.data">preimputed.data</code></td>
<td>
<p>data.frame. if you have used another software for missing
data imputation, you can still optimize the imputation
by handing the data.frame to this argument, which will
bypass the &quot;preimpute&quot; procedure.</p>
</td></tr>
<tr><td><code id="mlim_+3A_save">save</code></td>
<td>
<p>filename (with .mlim extension). if a filename is specified, an <code>mlim</code> object is
saved after the end of each variable imputation. this object not only
includes the imputed dataframe and estimated cross-validation error, but also
includes the information needed for continuing the imputation,
which is very useful feature for imputing large datasets, with a
long runtime. this argument is activated by default and an
mlim object is stored in the local directory named <code>"mlim.rds"</code>.</p>
</td></tr>
<tr><td><code id="mlim_+3A_load">load</code></td>
<td>
<p>filename (with .mlim extension). an object of class &quot;mlim&quot;, which includes the data, arguments,
and settings for re-running the imputation, from where it was
previously stopped. the &quot;mlim&quot; object saves the current state of
the imputation and is particularly recommended for large datasets
or when the user specifies a computationally extensive settings
(e.g. specifying several algorithms, increasing tuning time, etc.).</p>
</td></tr>
<tr><td><code id="mlim_+3A_shutdown">shutdown</code></td>
<td>
<p>logical. if TRUE, h2o server is closed after the imputation.
the default is TRUE</p>
</td></tr>
<tr><td><code id="mlim_+3A_java">java</code></td>
<td>
<p>character, specifying path to the executable 64bit Java JDK on the
Microsoft Windows machines, if JDK is installed but the path environment
variable is not set.</p>
</td></tr>
<tr><td><code id="mlim_+3A_...">...</code></td>
<td>
<p>arguments that are used internally between 'mlim' and 'mlim.postimpute'.
these arguments are not documented in the help file and are not
intended to be used by end user.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code>, showing the
estimated imputation error from the cross validation within the data.frame's
attribution
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(iris)

# add stratified missing observations to the data. to make the example run
# faster, I add NAs only to a single variable.
dfNA &lt;- iris
dfNA$Species &lt;- mlim.na(dfNA$Species, p = 0.1, stratify = TRUE, seed = 2022)

# run the ELNET single imputation (fastest imputation via 'mlim')
MLIM &lt;- mlim(dfNA, shutdown = FALSE)

# in single imputation, you can estimate the imputation accuracy via cross validation RMSE
mlim.summarize(MLIM)

### or if you want to carry out ELNET multiple imputation with 5 datasets.
### next, to carry out analysis on the multiple imputation, use the 'mlim.mids' function
### minimum of 5 datasets
MLIM2 &lt;- mlim(dfNA, m = 5)
mids &lt;- mlim.mids(MLIM2, dfNA)
fit &lt;- with(data=mids, exp=glm(Species ~ Sepal.Length, family = "binomial"))
res &lt;- mice::pool(fit)
summary(res)

# you can check the accuracy of the imputation, if you have the original dataset
mlim.error(MLIM2, dfNA, iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='mlim.error'>imputation error</h2><span id='topic+mlim.error'></span>

<h3>Description</h3>

<p>calculates NRMSE, missclassification rate, and miss-ranking
absolute mean distance, scaled between 0 to 1, where 1 means
maximum distance between the actual rank of a level and the
imputed level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim.error(
  imputed,
  incomplete,
  complete,
  transform = NULL,
  varwise = FALSE,
  ignore.missclass = TRUE,
  ignore.rank = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim.error_+3A_imputed">imputed</code></td>
<td>
<p>the imputed dataframe</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_incomplete">incomplete</code></td>
<td>
<p>the dataframe with missing values</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_complete">complete</code></td>
<td>
<p>the original dataframe with no missing values</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_transform">transform</code></td>
<td>
<p>character. it can be either &quot;standardize&quot;, which standardizes the
numeric variables before evaluating the imputation error, or
&quot;normalize&quot;, which change the scale of continuous variables to
range from 0 to 1. the default is NULL.</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_varwise">varwise</code></td>
<td>
<p>logical, default is FALSE. if TRUE, in addition to
mean accuracy for each variable type, the algorithm's
performance for each variable (column) of the datast is
also returned. if TRUE, instead of a numeric vector, a
list is retuned.</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_ignore.missclass">ignore.missclass</code></td>
<td>
<p>logical. the default is TRUE. if FALSE, the overall
missclassification rate for imputed unordered factors will be
returned. in general, missclassification is not recommended,
particularly for multinomial factors because it is not robust
to imbalanced data. in other words, an imputation might show
a very high accuracy, because it is biased towards the majority
class, ignoring the minority levels. to avoid this error,
Mean Per Class Error (MPCE) is returned, which is the average
missclassification of each class and thus, it is a fairer
criteria for evaluating multinomial classes.</p>
</td></tr>
<tr><td><code id="mlim.error_+3A_ignore.rank">ignore.rank</code></td>
<td>
<p>logical (default is FALSE, which is recommended). if TRUE,
the accuracy of imputation of ordered factors (ordinal variables)
will be evaluated based on 'missclassification rate' instead of
normalized euclidean distance. this practice is not recommended
because higher classification rate for ordinal variables does not
guarantee lower distances between the imputed levels, despite the
popularity of evaluating ordinal variables based on missclassification
rate. in other words, assume an ordinal variable has 5 levels (1. strongly
disagree, 2. disagree, 3. uncertain, 4. agree, 5.strongly agree). in this
example, if &quot;ignore.rank = TRUE&quot;, then an imputation that imputes level
&quot;5&quot; as &quot;4&quot; is equally inaccurate as other algorithm that imputes level &quot;5&quot;
as &quot;1&quot;. therefore, if you have ordinal variables in your dataset, make sure
you declare them as &quot;ordered&quot; factors to get the best imputation accuracy.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(iris)

# add 10% missing values, ensure missingness is stratified for factors
irisNA &lt;- mlim.na(iris, p = 0.1, stratify = TRUE, seed = 2022)

# run the default imputation
MLIM &lt;- mlim(irisNA)
mlim.error(MLIM, irisNA, iris)

# get error estimations for each variable
mlim.error(MLIM, irisNA, iris, varwise = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='mlim.mids'>prepare &quot;mids&quot; class object</h2><span id='topic+mlim.mids'></span>

<h3>Description</h3>

<p>takes &quot;mlim&quot; object and prepares a &quot;mids&quot; class for data analysis with
multiple imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim.mids(mlim, incomplete)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim.mids_+3A_mlim">mlim</code></td>
<td>
<p>array of class &quot;mlim&quot;, returned by &quot;mlim&quot; function</p>
</td></tr>
<tr><td><code id="mlim.mids_+3A_incomplete">incomplete</code></td>
<td>
<p>the original data.frame with NAs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class 'mids', as required by 'mice' package for analyzing
multiple imputation data
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish, based on code from 'prelim' frunction in missMDA R package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(iris)
require(mice)
irisNA &lt;- mlim.na(iris, p = 0.1, seed = 2022)

# adding unstratified NAs to all variables of a data.frame
MLIM &lt;- mlim(irisNA, m=5, tuning_time = 180, doublecheck = T, seed = 2022)

# create the mids object for MICE package
mids &lt;- mlim.mids(MLIM, irisNA)

# run an analysis on the mids data (just as example)
fit &lt;- with(data=mids, exp=glm(Species~ Sepal.Length, family = "binomial"))

# then, pool the results!
summary(pool(fit))

## End(Not run)
</code></pre>

<hr>
<h2 id='mlim.na'>add stratified/unstratified artificial missing observations</h2><span id='topic+mlim.na'></span>

<h3>Description</h3>

<p>to examine the performance of imputation algorithms, artificial
missing data are added to datasets and then imputed, to compare
the original observations with the imputed values. this function
can add stratified or unstratified artificial missing data. stratified
missing data can be particularly useful if your categorical or ordinal
variables are imbalanced, i.e., one category appears at a much higher
rate than others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim.na(x, p = 0.1, stratify = FALSE, classes = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim.na_+3A_x">x</code></td>
<td>
<p>data.frame. x must be strictly a data.frame and any other
data.table classes will be rejected</p>
</td></tr>
<tr><td><code id="mlim.na_+3A_p">p</code></td>
<td>
<p>percentage of missingness to be added to the data</p>
</td></tr>
<tr><td><code id="mlim.na_+3A_stratify">stratify</code></td>
<td>
<p>logical. if TRUE (default), stratified sampling will be
carried out, when adding NA values to 'factor' variables
(either ordered or unordered). this feature makes evaluation
of missing data imputation algorithms more fair, especially
when the factor levels are imbalanced.</p>
</td></tr>
<tr><td><code id="mlim.na_+3A_classes">classes</code></td>
<td>
<p>character vector, specifying the variable classes that should
be selected for adding NA values. the default value is NULL,
meaning all variables will receive NA values with probability of 'p'.
however, if you wish to add NA values only to a specific classes, e.g.
'numeric' variables or 'ordered' factors, specify them in this argument.
e.g. write &quot;classes = c('numeric', 'ordered')&quot; if you wish to add NAs
only to numeric and ordered factors.</p>
</td></tr>
<tr><td><code id="mlim.na_+3A_seed">seed</code></td>
<td>
<p>integer. a random seed number for reproducing the result (recommended)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# adding stratified NA to an atomic vector
x &lt;- as.factor(c(rep("M", 100), rep("F", 900)))
table(mlim.na(x, p=.5, stratify = TRUE))

# adding unstratified NAs to all variables of a data.frame
data(iris)
mlim.na(iris, p=0.5, stratify = FALSE, seed = 1)

# or add stratified NAs only to factor variables, ignoring other variables
mlim.na(iris, p=0.5, stratify = TRUE, classes = "factor", seed = 1)

# or add NAs to numeric variables
mlim.na(iris, p=0.5, classes = "numeric", seed = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='mlim.preimpute'>carries out preimputation</h2><span id='topic+mlim.preimpute'></span>

<h3>Description</h3>

<p>instead of replacing missing data with mean and mode, a smarter
start-point would be to use fast imputation algorithms and then
optimize the imputed dataset with mlim. this procedure usually
requires less iterations and will savea lot of computation
resources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim.preimpute(data, preimpute = "RF", seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim.preimpute_+3A_data">data</code></td>
<td>
<p>data.frame with missing values</p>
</td></tr>
<tr><td><code id="mlim.preimpute_+3A_preimpute">preimpute</code></td>
<td>
<p>character. specify the algorithm for preimputation. the
supported options are &quot;RF&quot; (Random Forest), &quot;mm&quot;
(mean-mode replacement), and &quot;random&quot; (random sampling from available data).
the default is &quot;RF&quot;, which carries
a parallel random forest imputation, using all the CPUs available.
the other alternative is &quot;mm&quot; which performs mean/mode
imputation.</p>
</td></tr>
<tr><td><code id="mlim.preimpute_+3A_seed">seed</code></td>
<td>
<p>integer. specify the random generator seed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>imputed data.frame
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)

# add 10% stratified missing values to one factor variable
irisNA &lt;- iris
irisNA$Species &lt;- mlim.na(irisNA$Species, p = 0.1, stratify = TRUE, seed = 2022)

# run the default random forest preimputation
MLIM &lt;- mlim.preimpute(irisNA)
mlim.error(MLIM, irisNA, iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='mlim.summarize'>mlim imputation summary</h2><span id='topic+mlim.summarize'></span>

<h3>Description</h3>

<p>provides information about estimated accuracy of the imputation as well
as the overall procedure of the imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlim.summarize(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlim.summarize_+3A_data">data</code></td>
<td>
<p>dataset imputed with mlim</p>
</td></tr>
</table>


<h3>Value</h3>

<p>estimated imputation accuracy via cross-valdiation procedure
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)

# add 10% stratified missing values to one factor variable
irisNA &lt;- iris
irisNA$Species &lt;- mlim.na(irisNA$Species, p = 0.1, stratify = TRUE, seed = 2022)

# run the ELNET single imputation (fastest imputation via 'mlim')
MLIM &lt;- mlim(irisNA)

# in single imputation, you can estimate the imputation accuracy via cross validation RMSE
mlim.summarize(MLIM)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
