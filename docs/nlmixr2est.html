<!DOCTYPE html><html><head><title>Help for package nlmixr2est</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nlmixr2est}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.foceiPreProcessData'><p>This function process the data for use in focei</p></a></li>
<li><a href='#.nlmFinalizeList'><p>Finalizes output list</p></a></li>
<li><a href='#.nlmFreeEnv'><p>Frees nlm environment</p></a></li>
<li><a href='#.nlmixr2estLastPredSimulationInfo'><p>Get the least prediction simulation information for VPC</p></a></li>
<li><a href='#.nlmixr2objectNameAssign'><p>Allows external methods (like those in nlmixr2) to assign object name</p></a></li>
<li><a href='#.nlmixrNlmeFun'><p>A surrogate function for nlme to call for ode solving</p></a></li>
<li><a href='#.nlmixrNlmFunC'><p>A surrogate function for nlm to call for ode solving</p></a></li>
<li><a href='#.nlmixrNlminbFunC'><p>A surrogate function for nlminb to call for ode solving</p></a></li>
<li><a href='#.nlmixrNlsData'><p>Returns the data currently setup to run nls</p></a></li>
<li><a href='#.nlmixrNlsFun'><p>A surrogate function for nls to call for ode solving</p></a></li>
<li><a href='#.nlmixrNlsFunVal'><p>Internal nls functions for minpack.lm</p></a></li>
<li><a href='#.nlmixrOptimFunC'><p>A surrogate function for optim to call for ode solving</p></a></li>
<li><a href='#.nlmSetupEnv'><p>Setup a nonlinear system for optimization</p></a></li>
<li><a href='#.rxGetDVFTransform'><p>Get the DV transformation</p></a></li>
<li><a href='#.saemDropMuRefFromModel'><p>Drop mu referenced etas and covariates</p></a></li>
<li><a href='#.uiApplyMu2'><p>This is an internal function for modifying the UI to apply mu2 referencing</p></a></li>
<li><a href='#.uiFinalizeMu2'><p>This is an internal function for replacing the ui with original</p>
model and dropping artificial data in output</a></li>
<li><a href='#addCwres'><p>Add CWRES</p></a></li>
<li><a href='#addNpde'><p>NPDE calculation for nlmixr2</p></a></li>
<li><a href='#addTable'><p>Add table information to nlmixr2 fit object without tables</p></a></li>
<li><a href='#assertNlmixrFit'><p>Assert that this is a nlmixr2 fit object</p></a></li>
<li><a href='#assertNlmixrFitData'><p>Assert that this is a nlmixr2 fit data object</p></a></li>
<li><a href='#bobyqaControl'><p>Control for bobyqa estimation method in nlmixr2</p></a></li>
<li><a href='#boxCox'><p>Cox Box, Yeo Johnson and inverse transformation</p></a></li>
<li><a href='#cholSE'><p>Generalized Cholesky Matrix Decomposition</p></a></li>
<li><a href='#foceiControl'><p>Control Options for FOCEi</p></a></li>
<li><a href='#foceiFitCpp_'><p>Fit/Evaluate FOCEi</p></a></li>
<li><a href='#getBaseSimModelFit'><p>Method for getting simulation rxode2 classic models based on fits</p></a></li>
<li><a href='#getValidNlmixrCtl.bobyqa'><p>Get valid nlmixr control object</p></a></li>
<li><a href='#lbfgsb3cControl'><p>Control for lbfgsb3c estimation method in nlmixr2</p></a></li>
<li><a href='#n1qn1Control'><p>Control for n1qn1 estimation method in nlmixr2</p></a></li>
<li><a href='#newuoaControl'><p>Control for newuoa estimation method in nlmixr2</p></a></li>
<li><a href='#nlmControl'><p>nlmixr2 defaults controls for nlm</p></a></li>
<li><a href='#nlminbControl'><p>nlmixr2 nlminb defaults</p></a></li>
<li><a href='#nlmixr2'><p>nlmixr2 fits population PK and PKPD non-linear mixed effects models.</p></a></li>
<li><a href='#nlmixr2AllEst'><p>Show all the current estimation methods</p></a></li>
<li><a href='#nlmixr2AugPredSolve'><p>Augmented Prediction for nlmixr2 fit</p></a></li>
<li><a href='#nlmixr2CreateOutputFromUi'><p>Create nlmixr output from the UI</p></a></li>
<li><a href='#nlmixr2Est.bobyqa'><p>Generic for nlmixr2 estimation methods</p></a></li>
<li><a href='#nlmixr2Eval_'><p>Create a gradient function based on gill numerical differences</p></a></li>
<li><a href='#nlmixr2Gill83'><p>Get the optimal forward difference interval by Gill83 method</p></a></li>
<li><a href='#nlmixr2Hess'><p>Calculate Hessian</p></a></li>
<li><a href='#nlmixr2Keywords'><p>A list and description of the fields in the nlmxir2 object</p></a></li>
<li><a href='#nlmixr2Logo'><p>Messages the nlmixr2 logo...</p></a></li>
<li><a href='#nlmixr2NlmeControl'><p>Control Values for nlme Fit with extra options for nlmixr</p></a></li>
<li><a href='#nlmixr2Print'><p>Print x using the message facility</p></a></li>
<li><a href='#nlmixr2Validate'><p>Validate nlmixr2</p></a></li>
<li><a href='#nlmixr2Version'><p>Display nlmixr2's version</p></a></li>
<li><a href='#nlmixrAddObjectiveFunctionDataFrame'><p>Add objective function data frame to the current objective function</p></a></li>
<li><a href='#nlmixrAddTiming'><p>Manually add time to a nlmixr2 object</p></a></li>
<li><a href='#nlmixrCbind'><p>nlmixrCbind</p></a></li>
<li><a href='#nlmixrClone'><p>Clone nlmixr environment</p></a></li>
<li><a href='#nlmixrUpdateObject'><p>Update the nlmixr2 object with new fit information</p></a></li>
<li><a href='#nlmixrWithTiming'><p>Time a part of a nlmixr operation and add to nlmixr object</p></a></li>
<li><a href='#nlsControl'><p>nlmixr2 defaults controls for nls</p></a></li>
<li><a href='#nmGetDistributionSaemLines'><p>This is a S3 method for getting the distribution lines for a base rxode2 saem problem</p></a></li>
<li><a href='#nmNearPD'><p>C++ implementation of Matrix's nearPD</p></a></li>
<li><a href='#nmObjGet'><p>Get an item from a nlmixr core object</p></a></li>
<li><a href='#nmObjGetControl.bobyqa'><p>Get control object from fit</p></a></li>
<li><a href='#nmObjGetData.addCwres'><p>Get an item from a nlmixr2FitData object</p></a></li>
<li><a href='#nmObjGetEstimationModel'><p>Get the estimation model for a fit object depending on the object type</p></a></li>
<li><a href='#nmObjGetFoceiControl.nlme'><p>Method for getting focei compatible control object from nlmixr object</p></a></li>
<li><a href='#nmObjGetIpredModel'><p>Get the ipred model for a fit object depending on the object type</p></a></li>
<li><a href='#nmObjGetPredOnly'><p>Get the pred-only model for a fit depending on the object type</p></a></li>
<li><a href='#nmObjGetRxSolve'><p>Get an option for the estimation method</p></a></li>
<li><a href='#nmObjHandleControlObject.bobyqaControl'><p>Handle the control object</p></a></li>
<li><a href='#nmObjHandleModelObject'><p>Handle Model Object</p></a></li>
<li><a href='#nmObjUiSetCompressed'><p>Set if the nlmixr2 object will return a compressed ui</p></a></li>
<li><a href='#nmsimplex'><p>Nelder-Mead simplex search</p></a></li>
<li><a href='#nmSuppressMsg'><p>Respect suppress messages for nlmixr2 C functions</p></a></li>
<li><a href='#ofv'><p>Return the objective function</p></a></li>
<li><a href='#optimControl'><p>nlmixr2 optim defaults</p></a></li>
<li><a href='#print.saemFit'><p>Print an SAEM model fit summary</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#residuals.nlmixr2FitData'><p>Extract residuals from the FOCEI fit</p></a></li>
<li><a href='#rxGetDistributionFoceiLines'><p>This is a S3 method for getting the distribution lines for a base rxode2 focei problem</p></a></li>
<li><a href='#rxGetDistributionNlmeLines'><p>This is a S3 method for getting the distribution lines for a base rxode2 nlme problem</p></a></li>
<li><a href='#rxGetDistributionNlsLines'><p>This is a S3 method for getting the distribution lines for a base rxode2 nls problem</p></a></li>
<li><a href='#saemControl'><p>Control Options for SAEM</p></a></li>
<li><a href='#setCov'><p>Set the covariance type based on prior calculated covariances</p></a></li>
<li><a href='#setOfv'><p>Set/get Objective function type for a nlmixr2 object</p></a></li>
<li><a href='#sqrtm'><p>Return the square root of general square matrix A</p></a></li>
<li><a href='#summary.saemFit'><p>Print an SAEM model fit summary</p></a></li>
<li><a href='#tableControl'><p>Output table/data.frame options</p></a></li>
<li><a href='#uobyqaControl'><p>Control for uobyqa estimation method in nlmixr2</p></a></li>
<li><a href='#vpcNameDataCmts'><p>Name the data and compartments</p></a></li>
<li><a href='#vpcSim'><p>VPC simulation</p></a></li>
<li><a href='#vpcSimExpand'><p>Expand a VPC simulation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonlinear Mixed Effects Models in Population PK/PD, Estimation
Routines</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthew Fidler &lt;matthew.fidler@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit and compare nonlinear mixed-effects models in
    differential equations with flexible dosing information commonly seen
    in pharmacokinetics and pharmacodynamics (Almquist, Leander, and
    Jirstrand 2015 &lt;<a href="https://doi.org/10.1007%2Fs10928-015-9409-1">doi:10.1007/s10928-015-9409-1</a>&gt;). Differential equation
    solving is by compiled C code provided in the 'rxode2' package (Wang,
    Hallow, and James 2015 &lt;<a href="https://doi.org/10.1002%2Fpsp4.12052">doi:10.1002/psp4.12052</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/nlmixr2/nlmixr2est">https://github.com/nlmixr2/nlmixr2est</a>,
<a href="https://nlmixr2.github.io/nlmixr2est/">https://nlmixr2.github.io/nlmixr2est/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>nlmixr2data, R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>backports, checkmate, cli, graphics, knitr, lbfgsb3c, lotri,
magrittr, Matrix, methods, minqa, n1qn1 (&ge; 6.0.1-10), nlme,
Rcpp, rex, rxode2 (&ge; 2.1.0), stats, symengine, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>broom.mixed, crayon, data.table, devtools, digest, dplyr (&ge;
1.1.0), generics, nloptr, qs, sys, testthat, tibble, withr,
xgxr, sfsmisc, rxode2parse (&ge; 2.0.11), rxode2random (&ge;
2.0.9), minpack.lm</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, lbfgsb3c, Rcpp, RcppArmadillo (&ge; 0.11.2.3.1), rxode2
(&ge; 2.0.12), rxode2parse (&ge; 2.0.11), rxode2random (&ge; 2.0.9)</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-31 02:30:15 UTC; matt</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthew Fidler <a href="https://orcid.org/0000-0001-8538-6691"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Yuan Xiong [aut],
  Rik Schoemaker <a href="https://orcid.org/0000-0002-7538-3005"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Justin Wilkins <a href="https://orcid.org/0000-0002-7099-9396"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Wenping Wang [aut],
  Robert Leary [ctb],
  Mason McComb <a href="https://orcid.org/0000-0001-9871-8616"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Vipul Mann [aut],
  Mirjam Trame [ctb],
  Mahmoud Abdelwahab [ctb],
  Teun Post [ctb],
  Richard Hooijmaijers [aut],
  Hadley Wickham [ctb],
  Dirk Eddelbuettel [cph],
  Johannes Pfeifer [ctb],
  Robert B. Schnabel [ctb],
  Elizabeth Eskow [ctb],
  Emmanuelle Comets [ctb],
  Audrey Lavenu [ctb],
  Marc Lavielle [ctb],
  David Ardia [cph],
  Katharine Mullen [cph],
  Ben Goodrich [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-31 05:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.foceiPreProcessData'>This function process the data for use in focei</h2><span id='topic+.foceiPreProcessData'></span>

<h3>Description</h3>

<p>The $origData is the data that is fed into the focei before modification
The $dataSav is the data saved for focei
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.foceiPreProcessData(data, env, ui, rxControl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".foceiPreProcessData_+3A_data">data</code></td>
<td>
<p>Input dataset</p>
</td></tr>
<tr><td><code id=".foceiPreProcessData_+3A_env">env</code></td>
<td>
<p>focei environment where focei family is run</p>
</td></tr>
<tr><td><code id=".foceiPreProcessData_+3A_ui">ui</code></td>
<td>
<p>rxode2 ui</p>
</td></tr>
<tr><td><code id=".foceiPreProcessData_+3A_rxcontrol">rxControl</code></td>
<td>
<p>is the rxode2 control that is used to translate to the modeling dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmFinalizeList'>Finalizes output list</h2><span id='topic+.nlmFinalizeList'></span>

<h3>Description</h3>

<p>Finalizes output list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmFinalizeList(env, lst, par = "par", printLine = TRUE, hessianCov = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmFinalizeList_+3A_env">env</code></td>
<td>
<p>nlm environment</p>
</td></tr>
<tr><td><code id=".nlmFinalizeList_+3A_lst">lst</code></td>
<td>
<p>output list</p>
</td></tr>
<tr><td><code id=".nlmFinalizeList_+3A_par">par</code></td>
<td>
<p>parameter name of final estimate in output</p>
</td></tr>
<tr><td><code id=".nlmFinalizeList_+3A_printline">printLine</code></td>
<td>
<p>Print the final line when print is nonzero</p>
</td></tr>
<tr><td><code id=".nlmFinalizeList_+3A_hessiancov">hessianCov</code></td>
<td>
<p>boolean indicating a hessian should be
used/calculated for covariance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>modified list with '$cov'
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmFreeEnv'>Frees nlm environment</h2><span id='topic+.nlmFreeEnv'></span>

<h3>Description</h3>

<p>Frees nlm environment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmFreeEnv()
</code></pre>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixr2estLastPredSimulationInfo'>Get the least prediction simulation information for VPC</h2><span id='topic+.nlmixr2estLastPredSimulationInfo'></span>

<h3>Description</h3>

<p>Get the least prediction simulation information for VPC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixr2estLastPredSimulationInfo()
</code></pre>


<h3>Value</h3>

<p>The last prediction simulation from the 'vpcSim' function (data.frame)
</p>

<hr>
<h2 id='.nlmixr2objectNameAssign'>Allows external methods (like those in nlmixr2) to assign object name</h2><span id='topic+.nlmixr2objectNameAssign'></span>

<h3>Description</h3>

<p>Allows external methods (like those in nlmixr2) to assign object name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixr2objectNameAssign(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixr2objectNameAssign_+3A_x">x</code></td>
<td>
<p>String or null for assigning a nlmixr object name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlmeFun'>A surrogate function for nlme to call for ode solving</h2><span id='topic+.nlmixrNlmeFun'></span>

<h3>Description</h3>

<p>A surrogate function for nlme to call for ode solving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlmeFun(pars, id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrNlmeFun_+3A_pars">pars</code></td>
<td>
<p>Parameters that will be estimated</p>
</td></tr>
<tr><td><code id=".nlmixrNlmeFun_+3A_id">id</code></td>
<td>
<p>The patient identifiers for the estimated data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Predictions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlmFunC'>A surrogate function for nlm to call for ode solving</h2><span id='topic+.nlmixrNlmFunC'></span>

<h3>Description</h3>

<p>A surrogate function for nlm to call for ode solving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlmFunC(pars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrNlmFunC_+3A_pars">pars</code></td>
<td>
<p>Parameters that will be estimated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Predictions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlminbFunC'>A surrogate function for nlminb to call for ode solving</h2><span id='topic+.nlmixrNlminbFunC'></span><span id='topic+.nlmixrNlminbGradC'></span><span id='topic+.nlmixrNlminbHessC'></span>

<h3>Description</h3>

<p>A surrogate function for nlminb to call for ode solving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlminbFunC(pars)

.nlmixrNlminbGradC(pars)

.nlmixrNlminbHessC(pars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrNlminbFunC_+3A_pars">pars</code></td>
<td>
<p>Parameters that will be estimated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Predictions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlsData'>Returns the data currently setup to run nls</h2><span id='topic+.nlmixrNlsData'></span>

<h3>Description</h3>

<p>Returns the data currently setup to run nls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlsData()
</code></pre>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Returns the data currently setup to run nls
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlsFun'>A surrogate function for nls to call for ode solving</h2><span id='topic+.nlmixrNlsFun'></span><span id='topic+.nlmixrNlsFunValGrad'></span>

<h3>Description</h3>

<p>A surrogate function for nls to call for ode solving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlsFun(DV, ...)

.nlmixrNlsFunValGrad(DV, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrNlsFun_+3A_dv">DV</code></td>
<td>
<p>dependent variable</p>
</td></tr>
<tr><td><code id=".nlmixrNlsFun_+3A_...">...</code></td>
<td>
<p>Other parameters fed to prediction function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Predictions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmixrNlsFunVal'>Internal nls functions for minpack.lm</h2><span id='topic+.nlmixrNlsFunVal'></span><span id='topic+.nlmixrNlsFunGrad'></span>

<h3>Description</h3>

<p>Internal nls functions for minpack.lm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrNlsFunVal(x)

.nlmixrNlsFunGrad(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrNlsFunVal_+3A_x">x</code></td>
<td>
<p>Parameter for estimate</p>
</td></tr>
</table>

<hr>
<h2 id='.nlmixrOptimFunC'>A surrogate function for optim to call for ode solving</h2><span id='topic+.nlmixrOptimFunC'></span><span id='topic+.nlmixrOptimGradC'></span>

<h3>Description</h3>

<p>A surrogate function for optim to call for ode solving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmixrOptimFunC(pars)

.nlmixrOptimGradC(pars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmixrOptimFunC_+3A_pars">pars</code></td>
<td>
<p>Parameters that will be estimated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an internal function and should not be called directly.
</p>


<h3>Value</h3>

<p>Predictions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.nlmSetupEnv'>Setup a nonlinear system for optimization</h2><span id='topic+.nlmSetupEnv'></span>

<h3>Description</h3>

<p>Setup a nonlinear system for optimization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.nlmSetupEnv(par, ui, data, modelInfo, control, lower = NULL, upper = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".nlmSetupEnv_+3A_par">par</code></td>
<td>
<p>A named vector of initial estimates to setup the
nonlinear model solving environment. The names of the parameter
should match the names of the model to run (not 'THETA[#]' as
required in the 'modelInfo' argument)</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_ui">ui</code></td>
<td>
<p>rxode2 ui model</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_data">data</code></td>
<td>
<p>rxode2 compatible data for solving/setting up</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_modelinfo">modelInfo</code></td>
<td>
<p>A list containing the following elements:
</p>
<p>- 'predOnly' &ndash; A model with only predictions calculated.  These
predictions should be in terms of 'THETA[#]' and 'DV'.  The
</p>
<p>- 'eventTheta' is an indicator if the 'THETA[#]' is related to an
event (like 'dur(x)' 'f(x)').  These variables will use Shi2021
finite differences and need to be indicated when setting up the
solving environment.  When finite differences are required, this is
'1L' when they are not it should be '0L'.  This should match the
length of 'par'
</p>
<p>- 'thetaGrad' &ndash; needed when solveType != 1; a model that gives the
value and gradient of each 'THETA[#]'
</p>
<p>An example can be found with 'ui$nlmSensModel' or 'ui$nlmRxModel'</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_control">control</code></td>
<td>
<p>is a control structure with a few required elements:
</p>
<p>- 'rxControl' represents the rxode2 solving options
- 'solveType' integer indicating the solveType (optional)
- 'stickyRecalcN'
- 'maxOdeRecalc'
- 'odeRecalcFactor'
- 'eventType' (optional)
- 'shi21maxFD' (optional)
- 'shiErr' (optional)
- 'optimHessType' (optional)
- 'shi21maxHess' (optional)
- 'hessErr' (optional)
- 'useColor'
- 'printNcol'
- 'print'
- 'normType'
- 'scaleType'
- 'scaleCmin'
- 'scaleCmax'
- 'scaleTo'
- 'scaleC'
- 'gradTo' (optional); if missing assumed gradTo=0</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_lower">lower</code></td>
<td>
<p>lower bounds, will be scaled if present</p>
</td></tr>
<tr><td><code id=".nlmSetupEnv_+3A_upper">upper</code></td>
<td>
<p>upper bounds, will be scaled if present</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In between using this, rxode2 solving should not be called.
</p>
<p>This will also print the header for solving (if print != 0)
</p>


<h3>Value</h3>

<p>nlm solve environment; of interest
</p>
<p>'$par.ini' &ndash; scaled parameter initial value
</p>
<p>'$lower' &ndash; scaled parameter lower value
</p>
<p>'$upper' &ndash; scaled parameter upper value
</p>
<p>'$.ctl'  &ndash; control structure
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='.rxGetDVFTransform'>Get the DV transformation</h2><span id='topic+.rxGetDVFTransform'></span>

<h3>Description</h3>

<p>Get the DV transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rxGetDVFTransform(env, pred1, yj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".rxGetDVFTransform_+3A_env">env</code></td>
<td>
<p>Environment for the parsed model</p>
</td></tr>
<tr><td><code id=".rxGetDVFTransform_+3A_pred1">pred1</code></td>
<td>
<p>The 'data.frame' of the current error</p>
</td></tr>
<tr><td><code id=".rxGetDVFTransform_+3A_yj">yj</code></td>
<td>
<p>The transformation number for the current error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformation expression
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='.saemDropMuRefFromModel'>Drop mu referenced etas and covariates</h2><span id='topic+.saemDropMuRefFromModel'></span>

<h3>Description</h3>

<p>Drop mu referenced etas and covariates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.saemDropMuRefFromModel(ui, noCovs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".saemDropMuRefFromModel_+3A_ui">ui</code></td>
<td>
<p>rxode2 ui</p>
</td></tr>
<tr><td><code id=".saemDropMuRefFromModel_+3A_nocovs">noCovs</code></td>
<td>
<p>Do not look for covariates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model line expression with mu referenced information dropped.
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.uiApplyMu2'>This is an internal function for modifying the UI to apply mu2 referencing</h2><span id='topic+.uiApplyMu2'></span>

<h3>Description</h3>

<p>mu2 referencing is algebraic mu-referencing by converting to the
transformation to a single value in the original dataset, and
moving that around
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.uiApplyMu2(env)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".uiApplyMu2_+3A_env">env</code></td>
<td>
<p>Environment needed for nlmixr2 fits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either the original model() block (if changed) or NULL if
not changed
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='.uiFinalizeMu2'>This is an internal function for replacing the ui with original
model and dropping artificial data in output</h2><span id='topic+.uiFinalizeMu2'></span>

<h3>Description</h3>

<p>This is an internal function for replacing the ui with original
model and dropping artificial data in output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.uiFinalizeMu2(ret, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".uiFinalizeMu2_+3A_ret">ret</code></td>
<td>
<p>The object that would be returned, without modification</p>
</td></tr>
<tr><td><code id=".uiFinalizeMu2_+3A_model">model</code></td>
<td>
<p>The original model to apply</p>
</td></tr>
</table>


<h3>Value</h3>

<p>modified fit updated to show the original model and without
the internal transformations
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='addCwres'>Add CWRES</h2><span id='topic+addCwres'></span>

<h3>Description</h3>

<p>This returns a new fit object with CWRES attached
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addCwres(fit, focei = TRUE, updateObject = TRUE, envir = parent.frame(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addCwres_+3A_fit">fit</code></td>
<td>
<p>nlmixr2 fit without WRES/CWRES</p>
</td></tr>
<tr><td><code id="addCwres_+3A_focei">focei</code></td>
<td>
<p>Boolean indicating if the focei objective function is
added.  If not the foce objective function is added.</p>
</td></tr>
<tr><td><code id="addCwres_+3A_updateobject">updateObject</code></td>
<td>
<p>Boolean indicating if the original fit object
should be updated. By default this is true.</p>
</td></tr>
<tr><td><code id="addCwres_+3A_envir">envir</code></td>
<td>
<p>Environment that should be checked for object to
update.  By default this is the global environment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fit with CWRES
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
  ini({
    ## You may label each parameter with a comment
    tka &lt;- 0.45 # Log Ka
    tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
    ## This works with interactive models
    ## You may also label the preceding line with label("label text")
    tv &lt;- 3.45; label("log V")
    ## the label("Label name") works with all models
    eta.ka ~ 0.6
    eta.cl ~ 0.3
    eta.v ~ 0.1
    add.sd &lt;- 0.7
  })
  model({
    ka &lt;- exp(tka + eta.ka)
    cl &lt;- exp(tcl + eta.cl)
    v &lt;- exp(tv + eta.v)
    linCmt() ~ add(add.sd)
  })
}

f &lt;- try(nlmixr2(one.cmt, theo_sd, "saem"))

print(f)

# even though you may have forgotten to add the cwres, you can add it to the data.frame:

if (!inherits(f, "try-error")) {
  f &lt;- try(addCwres(f))
  print(f)
}

# Note this also adds the FOCEi objective function

</code></pre>

<hr>
<h2 id='addNpde'>NPDE calculation for nlmixr2</h2><span id='topic+addNpde'></span>

<h3>Description</h3>

<p>NPDE calculation for nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addNpde(
  object,
  updateObject = TRUE,
  table = tableControl(),
  ...,
  envir = parent.frame(1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addNpde_+3A_object">object</code></td>
<td>
<p>nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="addNpde_+3A_updateobject">updateObject</code></td>
<td>
<p>Boolean indicating if original object should be updated.  By default this is TRUE.</p>
</td></tr>
<tr><td><code id="addNpde_+3A_table">table</code></td>
<td>
<p>'tableControl()' list of options</p>
</td></tr>
<tr><td><code id="addNpde_+3A_...">...</code></td>
<td>
<p>Other ignored parameters.</p>
</td></tr>
<tr><td><code id="addNpde_+3A_envir">envir</code></td>
<td>
<p>Environment that should be checked for object to
update.  By default this is the global environment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>New nlmixr2 fit object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
  ini({
    ## You may label each parameter with a comment
    tka &lt;- 0.45 # Log Ka
    tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
    ## This works with interactive models
    ## You may also label the preceding line with label("label text")
    tv &lt;- 3.45; label("log V")
    ## the label("Label name") works with all models
    eta.ka ~ 0.6
    eta.cl ~ 0.3
    eta.v ~ 0.1
    add.sd &lt;- 0.7
  })
  model({
    ka &lt;- exp(tka + eta.ka)
    cl &lt;- exp(tcl + eta.cl)
    v &lt;- exp(tv + eta.v)
    linCmt() ~ add(add.sd)
  })
}

f &lt;- nlmixr2(one.cmt, theo_sd, "saem")

# even though you may have forgotten to add the NPDE, you can add it to the data.frame:

f &lt;- addNpde(f)


</code></pre>

<hr>
<h2 id='addTable'>Add table information to nlmixr2 fit object without tables</h2><span id='topic+addTable'></span>

<h3>Description</h3>

<p>Add table information to nlmixr2 fit object without tables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addTable(
  object,
  updateObject = FALSE,
  data = object$dataSav,
  thetaEtaParameters = object$foceiThetaEtaParameters,
  table = tableControl(),
  keep = NULL,
  drop = NULL,
  envir = parent.frame(1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addTable_+3A_object">object</code></td>
<td>
<p>nlmixr2 family of objects</p>
</td></tr>
<tr><td><code id="addTable_+3A_updateobject">updateObject</code></td>
<td>
<p>Update the object (default FALSE)</p>
</td></tr>
<tr><td><code id="addTable_+3A_data">data</code></td>
<td>
<p>Saved data from</p>
</td></tr>
<tr><td><code id="addTable_+3A_thetaetaparameters">thetaEtaParameters</code></td>
<td>
<p>Internal theta/eta parameters</p>
</td></tr>
<tr><td><code id="addTable_+3A_table">table</code></td>
<td>
<p>a 'tableControl()' list of options</p>
</td></tr>
<tr><td><code id="addTable_+3A_keep">keep</code></td>
<td>
<p>Character Vector of items to keep</p>
</td></tr>
<tr><td><code id="addTable_+3A_drop">drop</code></td>
<td>
<p>Character Vector of items to drop or NULL</p>
</td></tr>
<tr><td><code id="addTable_+3A_envir">envir</code></td>
<td>
<p>Environment to search for updating</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fit with table information attached
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
  ini({
    ## You may label each parameter with a comment
    tka &lt;- 0.45 # Log Ka
    tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
    ## This works with interactive models
    ## You may also label the preceding line with label("label text")
    tv &lt;- 3.45; label("log V")
    ## the label("Label name") works with all models
    eta.ka ~ 0.6
    eta.cl ~ 0.3
    eta.v ~ 0.1
    add.sd &lt;- 0.7
  })
  model({
    ka &lt;- exp(tka + eta.ka)
    cl &lt;- exp(tcl + eta.cl)
    v &lt;- exp(tv + eta.v)
    linCmt() ~ add(add.sd)
  })
}

# run without tables step
f &lt;- nlmixr2(one.cmt, theo_sd, "saem", control=list(calcTables=FALSE))

print(f)

# Now add the tables

f &lt;- addTable(f)

print(f)


</code></pre>

<hr>
<h2 id='assertNlmixrFit'>Assert that this is a nlmixr2 fit object</h2><span id='topic+assertNlmixrFit'></span>

<h3>Description</h3>

<p>Will error without nlmixr2 fit object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assertNlmixrFit(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assertNlmixrFit_+3A_fit">fit</code></td>
<td>
<p>Fit object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

f &lt;- 4
assertNlmixrFit(f) # throw error


## End(Not run)
</code></pre>

<hr>
<h2 id='assertNlmixrFitData'>Assert that this is a nlmixr2 fit data object</h2><span id='topic+assertNlmixrFitData'></span>

<h3>Description</h3>

<p>Will error without nlmixr2 fit data object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assertNlmixrFitData(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assertNlmixrFitData_+3A_fit">fit</code></td>
<td>
<p>Fit object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

f &lt;- 4
assertNlmixrFitData(f) # throw errors


## End(Not run)
</code></pre>

<hr>
<h2 id='bobyqaControl'>Control for bobyqa estimation method in nlmixr2</h2><span id='topic+bobyqaControl'></span>

<h3>Description</h3>

<p>Control for bobyqa estimation method in nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bobyqaControl(
  npt = NULL,
  rhobeg = NULL,
  rhoend = NULL,
  iprint = 0L,
  maxfun = 100000L,
  returnBobyqa = FALSE,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bobyqaControl_+3A_npt">npt</code></td>
<td>
<p>The number of points used to approximate the objective
function via a quadratic approximation. The value of npt must be
in the interval [n+2,(n+1)(n+2)/2] where n is the number of
parameters in 'par'. Choices that exceed 2*n+1 are not
recommended.  If not defined, it will be set to min(n * 2, n+2).</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_rhobeg">rhobeg</code></td>
<td>
<p>'rhobeg' and 'rhoend' must be set to the initial and
final values of a trust region radius, so both must be positive
with '0 &lt; rhoend &lt; rhobeg'. Typically 'rhobeg' should be about
one tenth of the greatest expected change to a variable.  If the
user does not provide a value, this will be set to 'min(0.95, 0.2
* max(abs(par)))'.  Note also that smallest difference
'abs(upper-lower)' should be greater than or equal to 'rhobeg*2'.
If this is not the case then 'rhobeg' will be adjusted.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_rhoend">rhoend</code></td>
<td>
<p>The smallest value of the trust region radius that is
allowed. If not defined, then 1e-6 times the value set for
'rhobeg' will be used.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_iprint">iprint</code></td>
<td>
<p>The value of 'iprint' should be set to an integer
value in '0, 1, 2, 3, ...', which controls the amount of
printing.  Specifically, there is no output if 'iprint=0' and
there is output only at the start and the return if 'iprint=1'.
Otherwise, each new value of 'rho' is printed, with the best
vector of variables so far and the corresponding value of the
objective function. Further, each new value of the objective
function with its variables are output if 'iprint=3'.  If 'iprint
&gt; 3', the objective function value and corresponding variables
are output every 'iprint' evaluations.  Default value is '0'.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_maxfun">maxfun</code></td>
<td>
<p>The maximum allowed number of function
evaluations. If this is exceeded, the method will terminate.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_returnbobyqa">returnBobyqa</code></td>
<td>
<p>return the bobyqa output instead of the nlmixr2
fit</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="bobyqaControl_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>bobqya control structure
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="bobyqa")

print(fit2)

# you can also get the nlm output with

fit2$bobyqa

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='boxCox'>Cox Box, Yeo Johnson and inverse transformation</h2><span id='topic+boxCox'></span><span id='topic+iBoxCox'></span><span id='topic+yeoJohnson'></span><span id='topic+iYeoJohnson'></span>

<h3>Description</h3>

<p>Cox Box, Yeo Johnson and inverse transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxCox(x, lambda = 1)

iBoxCox(x, lambda = 1)

yeoJohnson(x, lambda = 1)

iYeoJohnson(x, lambda = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boxCox_+3A_x">x</code></td>
<td>
<p>data to transform</p>
</td></tr>
<tr><td><code id="boxCox_+3A_lambda">lambda</code></td>
<td>
<p>Cox-box lambda parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Cox-Box Transformed Data
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
boxCox(1:3,1) ## Normal
iBoxCox(boxCox(1:3,1))

boxCox(1:3,0) ## Log-Normal
iBoxCox(boxCox(1:3,0),0)

boxCox(1:3,0.5) ## lambda=0.5
iBoxCox(boxCox(1:3,0.5),0.5)

yeoJohnson(seq(-3,3),1) ## Normal
iYeoJohnson(yeoJohnson(seq(-3,3),1))

yeoJohnson(seq(-3,3),0)
iYeoJohnson(yeoJohnson(seq(-3,3),0),0)
</code></pre>

<hr>
<h2 id='cholSE'>Generalized Cholesky Matrix Decomposition</h2><span id='topic+cholSE'></span>

<h3>Description</h3>

<p>Performs a (modified) Cholesky factorization of the form
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cholSE(matrix, tol = (.Machine$double.eps)^(1/3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cholSE_+3A_matrix">matrix</code></td>
<td>
<p>Matrix to be Factorized.</p>
</td></tr>
<tr><td><code id="cholSE_+3A_tol">tol</code></td>
<td>
<p>Tolerance; Algorithm suggests (.Machine$double.eps) ^ (1 / 3), default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>t(P) %*% A %*% P  + E = t(R) %*% R
</p>
<p>As detailed in Schnabel/Eskow (1990)
</p>


<h3>Value</h3>

<p>Generalized Cholesky decomposed matrix.
</p>


<h3>Note</h3>

<p>This version does not pivot or return the E matrix
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler (translation), Johannes Pfeifer, Robert
B. Schnabel and Elizabeth Eskow
</p>


<h3>References</h3>

<p>matlab source: http://www.dynare.org/dynare-matlab-m2html/matlab/chol_SE.html; Slightly different return values
</p>
<p>Robert B. Schnabel and Elizabeth
Eskow. 1990. &quot;A New Modified Cholesky Factorization,&quot; SIAM Journal
of Scientific Statistical Computing, 11, 6: 1136-58.
</p>
<p>Elizabeth Eskow and Robert B. Schnabel
1991. &quot;Algorithm 695 - Software for a New Modified Cholesky Factorization,&quot;
ACM Transactions on Mathematical Software, Vol 17, No 3: 306-312
</p>

<hr>
<h2 id='foceiControl'>Control Options for FOCEi</h2><span id='topic+foceiControl'></span>

<h3>Description</h3>

<p>Control Options for FOCEi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foceiControl(
  sigdig = 3,
  ...,
  epsilon = NULL,
  maxInnerIterations = 1000,
  maxOuterIterations = 5000,
  n1qn1nsim = NULL,
  print = 1L,
  printNcol = floor((getOption("width") - 23)/12),
  scaleTo = 1,
  scaleObjective = 0,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleC0 = 1e+05,
  derivEps = rep(20 * sqrt(.Machine$double.eps), 2),
  derivMethod = c("switch", "forward", "central"),
  derivSwitchTol = NULL,
  covDerivMethod = c("central", "forward"),
  covMethod = c("r,s", "r", "s", ""),
  hessEps = (.Machine$double.eps)^(1/3),
  hessEpsLlik = (.Machine$double.eps)^(1/3),
  optimHessType = c("central", "forward"),
  optimHessCovType = c("central", "forward"),
  eventType = c("central", "forward"),
  centralDerivEps = rep(20 * sqrt(.Machine$double.eps), 2),
  lbfgsLmm = 7L,
  lbfgsPgtol = 0,
  lbfgsFactr = NULL,
  eigen = TRUE,
  addPosthoc = TRUE,
  diagXform = c("sqrt", "log", "identity"),
  sumProd = FALSE,
  optExpression = TRUE,
  ci = 0.95,
  useColor = crayon::has_color(),
  boundTol = NULL,
  calcTables = TRUE,
  noAbort = TRUE,
  interaction = TRUE,
  cholSEtol = (.Machine$double.eps)^(1/3),
  cholAccept = 0.001,
  resetEtaP = 0.15,
  resetThetaP = 0.05,
  resetThetaFinalP = 0.15,
  diagOmegaBoundUpper = 5,
  diagOmegaBoundLower = 100,
  cholSEOpt = FALSE,
  cholSECov = FALSE,
  fo = FALSE,
  covTryHarder = FALSE,
  outerOpt = c("nlminb", "bobyqa", "lbfgsb3c", "L-BFGS-B", "mma", "lbfgsbLG", "slsqp",
    "Rvmmin"),
  innerOpt = c("n1qn1", "BFGS"),
  rhobeg = 0.2,
  rhoend = NULL,
  npt = NULL,
  rel.tol = NULL,
  x.tol = NULL,
  eval.max = 4000,
  iter.max = 2000,
  abstol = NULL,
  reltol = NULL,
  resetHessianAndEta = FALSE,
  stateTrim = Inf,
  shi21maxOuter = 0L,
  shi21maxInner = 20L,
  shi21maxInnerCov = 20L,
  shi21maxFD = 20L,
  gillK = 10L,
  gillStep = 4,
  gillFtol = 0,
  gillRtol = sqrt(.Machine$double.eps),
  gillKcov = 10L,
  gillKcovLlik = 10L,
  gillStepCovLlik = 4.5,
  gillStepCov = 2,
  gillFtolCov = 0,
  gillFtolCovLlik = 0,
  rmatNorm = TRUE,
  rmatNormLlik = TRUE,
  smatNorm = TRUE,
  smatNormLlik = TRUE,
  covGillF = TRUE,
  optGillF = TRUE,
  covSmall = 1e-05,
  adjLik = TRUE,
  gradTrim = Inf,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  gradCalcCentralSmall = 1e-04,
  gradCalcCentralLarge = 10000,
  etaNudge = qnorm(1 - 0.05/2)/sqrt(3),
  etaNudge2 = qnorm(1 - 0.05/2) * sqrt(3/5),
  nRetries = 3,
  seed = 42,
  resetThetaCheckPer = 0.1,
  etaMat = NULL,
  repeatGillMax = 1,
  stickyRecalcN = 4,
  gradProgressOfvTime = 10,
  addProp = c("combined2", "combined1"),
  badSolveObjfAdj = 100,
  compress = TRUE,
  rxControl = NULL,
  sigdigTable = NULL,
  fallbackFD = FALSE,
  smatPer = 0.6
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="foceiControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="foceiControl_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_epsilon">epsilon</code></td>
<td>
<p>Precision of estimate for n1qn1 optimization.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_maxinneriterations">maxInnerIterations</code></td>
<td>
<p>Number of iterations for n1qn1
optimization.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_maxouteriterations">maxOuterIterations</code></td>
<td>
<p>Maximum number of L-BFGS-B optimization
for outer problem.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_n1qn1nsim">n1qn1nsim</code></td>
<td>
<p>Number of function evaluations for n1qn1
optimization.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_scaleobjective">scaleObjective</code></td>
<td>
<p>Scale the initial objective function to this
value.  By default this is 0 (meaning do not scale)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="foceiControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="foceiControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_scalec0">scaleC0</code></td>
<td>
<p>Number to adjust the scaling factor by if the initial
gradient is zero.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_deriveps">derivEps</code></td>
<td>
<p>Forward difference tolerances, which is a
vector of relative difference and absolute difference.  The
central/forward difference step size h is calculated as:
</p>
<p><code>h = abs(x)*derivEps[1] + derivEps[2]</code></p>
</td></tr>
<tr><td><code id="foceiControl_+3A_derivmethod">derivMethod</code></td>
<td>
<p>indicates the method for calculating
derivatives of the outer problem.  Currently supports
&quot;switch&quot;, &quot;central&quot; and &quot;forward&quot; difference methods.  Switch
starts with forward differences.  This will switch to central
differences when abs(delta(OFV)) &lt;= derivSwitchTol and switch
back to forward differences when abs(delta(OFV)) &gt;
derivSwitchTol.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_derivswitchtol">derivSwitchTol</code></td>
<td>
<p>The tolerance to switch forward to central
differences.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_covderivmethod">covDerivMethod</code></td>
<td>
<p>indicates the method for calculating the
derivatives while calculating the covariance components
(Hessian and S).</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="foceiControl_+3A_hesseps">hessEps</code></td>
<td>
<p>is a double value representing the epsilon for the
Hessian calculation. This is used for the R matrix calculation.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_hessepsllik">hessEpsLlik</code></td>
<td>
<p>is a double value representing the epsilon for
the Hessian calculation when doing focei generalized
log-likelihood estimation.  This is used for the R matrix
calculation.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_optimhesstype">optimHessType</code></td>
<td>
<p>The hessian type for when calculating the
individual hessian by numeric differences (in generalized
log-likelihood estimation).  The options are &quot;central&quot;, and
&quot;forward&quot;.  The central differences is what R's 'optimHess()'
uses and is the default for this method. (Though the &quot;forward&quot; is
faster and still reasonable for most cases).  The Shi21 cannot be
changed for the Gill83 algorithm with the optimHess in a
generalized likelihood problem.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_optimhesscovtype">optimHessCovType</code></td>
<td>
<p>The hessian type for when calculating the
individual hessian by numeric differences (in generalized
log-likelihood estimation).  The options are &quot;central&quot;, and
&quot;forward&quot;.  The central differences is what R's 'optimHess()'
uses.  While this takes longer in optimization, it is more
accurate, so for calculating the covariance and final likelihood,
the central differences are used. This also uses the modified
Shi21 method</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_eventtype">eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
&quot;central&quot; or &quot;forward&quot;</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_centralderiveps">centralDerivEps</code></td>
<td>
<p>Central difference tolerances.  This is a
numeric vector of relative difference and absolute difference.
The central/forward difference step size h is calculated as:
</p>
<p><code>h = abs(x)*derivEps[1] + derivEps[2]</code></p>
</td></tr>
<tr><td><code id="foceiControl_+3A_lbfgslmm">lbfgsLmm</code></td>
<td>
<p>An integer giving the number of BFGS updates
retained in the &quot;L-BFGS-B&quot; method, It defaults to 7.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_lbfgspgtol">lbfgsPgtol</code></td>
<td>
<p>is a double precision variable.
</p>
<p>On entry pgtol &gt;= 0 is specified by the user.  The iteration
will stop when:
</p>
<p><code>max(\| proj g_i \| i = 1, ..., n) &lt;= lbfgsPgtol</code>
</p>
<p>where pg_i is the ith component of the projected gradient.
</p>
<p>On exit pgtol is unchanged.  This defaults to zero, when the
check is suppressed.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_lbfgsfactr">lbfgsFactr</code></td>
<td>
<p>Controls the convergence of the &quot;L-BFGS-B&quot;
method.  Convergence occurs when the reduction in the
objective is within this factor of the machine
tolerance. Default is 1e10, which gives a tolerance of about
<code>2e-6</code>, approximately 4 sigdigs.  You can check your
exact tolerance by multiplying this value by
<code>.Machine$double.eps</code></p>
</td></tr>
<tr><td><code id="foceiControl_+3A_eigen">eigen</code></td>
<td>
<p>A boolean indicating if eigenvectors are calculated
to include a condition number calculation.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_addposthoc">addPosthoc</code></td>
<td>
<p>Boolean indicating if posthoc parameters are
added to the table output.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_diagxform">diagXform</code></td>
<td>
<p>This is the transformation used on the diagonal
of the <code>chol(solve(omega))</code>. This matrix and values are the
parameters estimated in FOCEi. The possibilities are:
</p>

<ul>
<li> <p><code>sqrt</code> Estimates the sqrt of the diagonal elements of <code>chol(solve(omega))</code>.  This is the default method.
</p>
</li>
<li> <p><code>log</code> Estimates the log of the diagonal elements of <code>chol(solve(omega))</code>
</p>
</li>
<li> <p><code>identity</code> Estimates the diagonal elements without any transformations
</p>
</li></ul>
</td></tr>
<tr><td><code id="foceiControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_boundtol">boundTol</code></td>
<td>
<p>Tolerance for boundary issues.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="foceiControl_+3A_noabort">noAbort</code></td>
<td>
<p>Boolean to indicate if you should abort the FOCEi
evaluation if it runs into troubles.  (default TRUE)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_interaction">interaction</code></td>
<td>
<p>Boolean indicate FOCEi should be used (TRUE)
instead of FOCE (FALSE)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_cholsetol">cholSEtol</code></td>
<td>
<p>tolerance for Generalized Cholesky
Decomposition.  Defaults to suggested (.Machine$double.eps)^(1/3)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_cholaccept">cholAccept</code></td>
<td>
<p>Tolerance to accept a Generalized Cholesky
Decomposition for a R or S matrix.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_resetetap">resetEtaP</code></td>
<td>
<p>represents the p-value for reseting the
individual ETA to 0 during optimization (instead of the saved
value).  The two test statistics used in the z-test are either
chol(omega^-1) %*% eta or eta/sd(allEtas).  A p-value of 0
indicates the ETAs never reset.  A p-value of 1 indicates the
ETAs always reset.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_resetthetap">resetThetaP</code></td>
<td>
<p>represents the p-value for reseting the
population mu-referenced THETA parameters based on ETA drift
during optimization, and resetting the optimization.  A
p-value of 0 indicates the THETAs never reset.  A p-value of 1
indicates the THETAs always reset and is not allowed.  The
theta reset is checked at the beginning and when nearing a
local minima.  The percent change in objective function where
a theta reset check is initiated is controlled in
<code>resetThetaCheckPer</code>.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_resetthetafinalp">resetThetaFinalP</code></td>
<td>
<p>represents the p-value for reseting the
population mu-referenced THETA parameters based on ETA drift
during optimization, and resetting the optimization one final time.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_diagomegaboundupper">diagOmegaBoundUpper</code></td>
<td>
<p>This represents the upper bound of the
diagonal omega matrix.  The upper bound is given by
diag(omega)*diagOmegaBoundUpper.  If
<code>diagOmegaBoundUpper</code> is 1, there is no upper bound on
Omega.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_diagomegaboundlower">diagOmegaBoundLower</code></td>
<td>
<p>This represents the lower bound of the
diagonal omega matrix.  The lower bound is given by
diag(omega)/diagOmegaBoundUpper.  If
<code>diagOmegaBoundLower</code> is 1, there is no lower bound on
Omega.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_cholseopt">cholSEOpt</code></td>
<td>
<p>Boolean indicating if the generalized Cholesky
should be used while optimizing.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_cholsecov">cholSECov</code></td>
<td>
<p>Boolean indicating if the generalized Cholesky
should be used while calculating the Covariance Matrix.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_fo">fo</code></td>
<td>
<p>is a boolean indicating if this is a FO approximation routine.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_covtryharder">covTryHarder</code></td>
<td>
<p>If the R matrix is non-positive definite and
cannot be corrected to be non-positive definite try estimating
the Hessian on the unscaled parameter space.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_outeropt">outerOpt</code></td>
<td>
<p>optimization method for the outer problem</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_inneropt">innerOpt</code></td>
<td>
<p>optimization method for the inner problem (not
implemented yet.)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rhobeg">rhobeg</code></td>
<td>
<p>Beginning change in parameters for bobyqa algorithm
(trust region).  By default this is 0.2 or 20
parameters when the parameters are scaled to 1. rhobeg and
rhoend must be set to the initial and final values of a trust
region radius, so both must be positive with 0 &lt; rhoend &lt;
rhobeg. Typically rhobeg should be about one tenth of the
greatest expected change to a variable.  Note also that
smallest difference abs(upper-lower) should be greater than or
equal to rhobeg*2. If this is not the case then rhobeg will be
adjusted. (bobyqa)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rhoend">rhoend</code></td>
<td>
<p>The smallest value of the trust region radius that
is allowed. If not defined, then 10^(-sigdig-1) will be used. (bobyqa)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_npt">npt</code></td>
<td>
<p>The number of points used to approximate the objective
function via a quadratic approximation for bobyqa. The value
of npt must be in the interval [n+2,(n+1)(n+2)/2] where n is
the number of parameters in par. Choices that exceed 2*n+1 are
not recommended. If not defined, it will be set to 2*n + 1. (bobyqa)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Relative tolerance before nlminb stops (nlmimb).</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_x.tol">x.tol</code></td>
<td>
<p>X tolerance for nlmixr2 optimizer</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_eval.max">eval.max</code></td>
<td>
<p>Number of maximum evaluations of the objective function (nlmimb)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_iter.max">iter.max</code></td>
<td>
<p>Maximum number of iterations allowed (nlmimb)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_abstol">abstol</code></td>
<td>
<p>Absolute tolerance for nlmixr2 optimizer (BFGS)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_reltol">reltol</code></td>
<td>
<p>tolerance for nlmixr2 (BFGS)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_resethessianandeta">resetHessianAndEta</code></td>
<td>
<p>is a boolean representing if the
individual Hessian is reset when ETAs are reset using the
option <code>resetEtaP</code>.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_statetrim">stateTrim</code></td>
<td>
<p>Trim state amounts/concentrations to this value.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_shi21maxouter">shi21maxOuter</code></td>
<td>
<p>The maximum number of steps for the
optimization of the forward-difference step size.  When not zero,
use this instead of Gill differences.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_shi21maxinner">shi21maxInner</code></td>
<td>
<p>The maximum number of steps for the
optimization of the individual Hessian matrices in the
generalized likelihood problem. When 0, un-optimized finite differences
are used.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_shi21maxinnercov">shi21maxInnerCov</code></td>
<td>
<p>The maximum number of steps for the
optimization of the individual Hessian matrices in the
generalized likelihood problem for the covariance step. When 0,
un-optimized finite differences are used.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_shi21maxfd">shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillk">gillK</code></td>
<td>
<p>The total number of possible steps to determine the
optimal forward/central difference step size per parameter (by
the Gill 1983 method).  If 0, no optimal step size is
determined.  Otherwise this is the optimal step size
determined.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillstep">gillStep</code></td>
<td>
<p>When looking for the optimal forward difference
step size, this is This is the step size to increase the
initial estimate by.  So each iteration the new step size =
(prior step size)*gillStep</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillftol">gillFtol</code></td>
<td>
<p>The gillFtol is the gradient error tolerance that
is acceptable before issuing a warning/error about the gradient estimates.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillrtol">gillRtol</code></td>
<td>
<p>The relative tolerance used for Gill 1983
determination of optimal step size.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillkcov">gillKcov</code></td>
<td>
<p>The total number of possible steps to determine
the optimal forward/central difference step size per parameter
(by the Gill 1983 method) during the covariance step.  If 0,
no optimal step size is determined.  Otherwise this is the
optimal step size determined.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillkcovllik">gillKcovLlik</code></td>
<td>
<p>The total number of possible steps to determine
the optimal forward/central difference step per parameter when
using the generalized focei log-likelihood method (by the Gill
1986 method).  If 0, no optimal step size is
determined. Otherwise this is the optimal step size is determined</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillstepcovllik">gillStepCovLlik</code></td>
<td>
<p>Same as above but during generalized focei
log-likelihood</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillstepcov">gillStepCov</code></td>
<td>
<p>When looking for the optimal forward difference
step size, this is This is the step size to increase the
initial estimate by.  So each iteration during the covariance
step is equal to the new step size = (prior step size)*gillStepCov</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillftolcov">gillFtolCov</code></td>
<td>
<p>The gillFtol is the gradient error tolerance
that is acceptable before issuing a warning/error about the
gradient estimates during the covariance step.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gillftolcovllik">gillFtolCovLlik</code></td>
<td>
<p>Same as above but applied during generalized
log-likelihood estimation.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rmatnorm">rmatNorm</code></td>
<td>
<p>A parameter to normalize gradient step size by the
parameter value during the calculation of the R matrix</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rmatnormllik">rmatNormLlik</code></td>
<td>
<p>A parameter to normalize gradient step size by
the parameter value during the calculation of the R matrix if you
are using generalized log-likelihood Hessian matrix.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_smatnorm">smatNorm</code></td>
<td>
<p>A parameter to normalize gradient step size by the
parameter value during the calculation of the S matrix</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_smatnormllik">smatNormLlik</code></td>
<td>
<p>A parameter to normalize gradient step size by
the parameter value during the calculation of the S matrix if you
are using the generalized log-likelihood.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_covgillf">covGillF</code></td>
<td>
<p>Use the Gill calculated optimal Forward difference
step size for the instead of the central difference step size
during the central difference gradient calculation.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_optgillf">optGillF</code></td>
<td>
<p>Use the Gill calculated optimal Forward difference
step size for the instead of the central difference step size
during the central differences for optimization.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_covsmall">covSmall</code></td>
<td>
<p>The covSmall is the small number to compare
covariance numbers before rejecting an estimate of the
covariance as the final estimate (when comparing sandwich vs
R/S matrix estimates of the covariance).  This number controls
how small the variance is before the covariance matrix is
rejected.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_adjlik">adjLik</code></td>
<td>
<p>In nlmixr2, the objective function matches NONMEM's
objective function, which removes a 2*pi constant from the
likelihood calculation. If this is TRUE, the likelihood
function is adjusted by this 2*pi factor.  When adjusted this
number more closely matches the likelihood approximations of
nlme, and SAS approximations.  Regardless of if this is turned
on or off the objective function matches NONMEM's objective
function.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gradtrim">gradTrim</code></td>
<td>
<p>The parameter to adjust the gradient to if the
|gradient| is very large.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gradcalccentralsmall">gradCalcCentralSmall</code></td>
<td>
<p>A small number that represents the value
where |grad| &lt; gradCalcCentralSmall where forward differences
switch to central differences.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gradcalccentrallarge">gradCalcCentralLarge</code></td>
<td>
<p>A large number that represents the value
where |grad| &gt; gradCalcCentralLarge where forward differences
switch to central differences.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_etanudge">etaNudge</code></td>
<td>
<p>By default initial ETA estimates start at zero;
Sometimes this doesn't optimize appropriately.  If this value is
non-zero, when the n1qn1 optimization didn't perform
appropriately, reset the Hessian, and nudge the ETA up by this
value; If the ETA still doesn't move, nudge the ETA down by this
value. By default this value is qnorm(1-0.05/2)*1/sqrt(3), the
first of the Gauss Quadrature numbers times by the 0.95% normal
region. If this is not successful try the second eta nudge
number (below).  If +-etaNudge2 is not successful, then assign
to zero and do not optimize any longer</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_etanudge2">etaNudge2</code></td>
<td>
<p>This is the second eta nudge.  By default it is
qnorm(1-0.05/2)*sqrt(3/5), which is the n=3 quadrature point
(excluding zero) times by the 0.95% normal region</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_nretries">nRetries</code></td>
<td>
<p>If FOCEi doesn't fit with the current parameter
estimates, randomly sample new parameter estimates and restart
the problem.  This is similar to 'PsN' resampling.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_seed">seed</code></td>
<td>
<p>an object specifying if and how the random number
generator should be initialized</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_resetthetacheckper">resetThetaCheckPer</code></td>
<td>
<p>represents objective function
% percentage below which resetThetaP is checked.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_etamat">etaMat</code></td>
<td>
<p>Eta matrix for initial estimates or final estimates
of the ETAs.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_repeatgillmax">repeatGillMax</code></td>
<td>
<p>If the tolerances were reduced when
calculating the initial Gill differences, the Gill difference
is repeated up to a maximum number of times defined by this
parameter.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_gradprogressofvtime">gradProgressOfvTime</code></td>
<td>
<p>This is the time for a single objective
function evaluation (in seconds) to start progress bars on gradient evaluations</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_badsolveobjfadj">badSolveObjfAdj</code></td>
<td>
<p>The objective function adjustment when the
ODE system cannot be solved.  It is based on each individual bad
solve.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_fallbackfd">fallbackFD</code></td>
<td>
<p>Fallback to the finite differences if the
sensitivity equations do not solve.</p>
</td></tr>
<tr><td><code id="foceiControl_+3A_smatper">smatPer</code></td>
<td>
<p>A percentage representing the number of failed
parameter gradients for each individual (which are replaced with
the overall gradient for the parameter) out of the total number
of gradients parameters (ie 'ntheta*nsub') before the S matrix is
considered to be a bad matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note this uses the R's L-BFGS-B in <code><a href="stats.html#topic+optim">optim</a></code> for the
outer problem and the BFGS <code><a href="n1qn1.html#topic+n1qn1">n1qn1</a></code> with that
allows restoring the prior individual Hessian (for faster
optimization speed).
</p>
<p>However the inner problem is not scaled.  Since most eta estimates
start near zero, scaling for these parameters do not make sense.
</p>
<p>This process of scaling can fix some ill conditioning for the
unscaled problem.  The covariance step is performed on the
unscaled problem, so the condition number of that matrix may not
be reflective of the scaled problem's condition-number.
</p>


<h3>Value</h3>

<p>The control object that changes the options for the FOCEi
family of estimation methods
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>References</h3>

<p>Gill, P.E., Murray, W., Saunders, M.A., &amp; Wright,
M.H. (1983). Computing Forward-Difference Intervals for Numerical
Optimization. Siam Journal on Scientific and Statistical Computing,
4, 310-321.
</p>
<p>Shi, H.M., Xie, Y., Xuan, M.Q., &amp; Nocedal, J. (2021). Adaptive
Finite-Difference Interval Estimation for Noisy Derivative-Free
Optimization.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>
</p>
<p><code><a href="n1qn1.html#topic+n1qn1">n1qn1</a></code>
</p>
<p><code><a href="rxode2.html#topic+rxSolve">rxSolve</a></code>
</p>
<p>Other Estimation control: 
<code><a href="#topic+nlmixr2NlmeControl">nlmixr2NlmeControl</a>()</code>,
<code><a href="#topic+saemControl">saemControl</a>()</code>
</p>

<hr>
<h2 id='foceiFitCpp_'>Fit/Evaluate FOCEi</h2><span id='topic+foceiFitCpp_'></span>

<h3>Description</h3>

<p>This shouldn't be called directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foceiFitCpp_(e)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="foceiFitCpp__+3A_e">e</code></td>
<td>
<p>Environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A focei fit object
</p>

<hr>
<h2 id='getBaseSimModelFit'>Method for getting simulation rxode2 classic models based on fits</h2><span id='topic+getBaseSimModelFit'></span><span id='topic+getBaseSimModelFit.focei'></span><span id='topic+getBaseSimModelFit.foce'></span><span id='topic+getBaseSimModelFit.fo'></span><span id='topic+getBaseSimModelFit.foi'></span><span id='topic+getBaseSimModelFit.posthoc'></span><span id='topic+getBaseSimModelFit.default'></span>

<h3>Description</h3>

<p>Method for getting simulation rxode2 classic models based on fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBaseSimModelFit(x)

## S3 method for class 'focei'
getBaseSimModelFit(x)

## S3 method for class 'foce'
getBaseSimModelFit(x)

## S3 method for class 'fo'
getBaseSimModelFit(x)

## S3 method for class 'foi'
getBaseSimModelFit(x)

## S3 method for class 'posthoc'
getBaseSimModelFit(x)

## Default S3 method:
getBaseSimModelFit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBaseSimModelFit_+3A_x">x</code></td>
<td>
<p>list where first element is the fit.  The class represents the estimation method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>model for fit$simulationModel
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='getValidNlmixrCtl.bobyqa'>Get valid nlmixr control object</h2><span id='topic+getValidNlmixrCtl.bobyqa'></span><span id='topic+getValidNlmixrCtl.lbfgsb3c'></span><span id='topic+getValidNlmixrCtl.n1qn1'></span><span id='topic+getValidNlmixrCtl.newuoa'></span><span id='topic+getValidNlmixrCtl.nlm'></span><span id='topic+getValidNlmixrCtl.nlminb'></span><span id='topic+getValidNlmixrCtl.nls'></span><span id='topic+getValidNlmixrCtl.optim'></span><span id='topic+getValidNlmixrControl'></span><span id='topic+getValidNlmixrCtl'></span><span id='topic+getValidNlmixrCtl.focei'></span><span id='topic+getValidNlmixrCtl.foce'></span><span id='topic+getValidNlmixrCtl.fo'></span><span id='topic+getValidNlmixrCtl.foi'></span><span id='topic+getValidNlmixrCtl.posthoc'></span><span id='topic+getValidNlmixrCtl.nlme'></span><span id='topic+getValidNlmixrCtl.saem'></span><span id='topic+getValidNlmixrCtl.rxSolve'></span><span id='topic+getValidNlmixrCtl.simulate'></span><span id='topic+getValidNlmixrCtl.simulation'></span><span id='topic+getValidNlmixrCtl.tableControl'></span><span id='topic+getValidNlmixrCtl.default'></span><span id='topic+getValidNlmixrCtl.uobyqa'></span>

<h3>Description</h3>

<p>Get valid nlmixr control object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bobyqa'
getValidNlmixrCtl(control)

## S3 method for class 'lbfgsb3c'
getValidNlmixrCtl(control)

## S3 method for class 'n1qn1'
getValidNlmixrCtl(control)

## S3 method for class 'newuoa'
getValidNlmixrCtl(control)

## S3 method for class 'nlm'
getValidNlmixrCtl(control)

## S3 method for class 'nlminb'
getValidNlmixrCtl(control)

## S3 method for class 'nls'
getValidNlmixrCtl(control)

## S3 method for class 'optim'
getValidNlmixrCtl(control)

getValidNlmixrControl(control, est)

getValidNlmixrCtl(control)

## S3 method for class 'focei'
getValidNlmixrCtl(control)

## S3 method for class 'foce'
getValidNlmixrCtl(control)

## S3 method for class 'fo'
getValidNlmixrCtl(control)

## S3 method for class 'foi'
getValidNlmixrCtl(control)

## S3 method for class 'posthoc'
getValidNlmixrCtl(control)

## S3 method for class 'foce'
getValidNlmixrCtl(control)

## S3 method for class 'nlme'
getValidNlmixrCtl(control)

## S3 method for class 'saem'
getValidNlmixrCtl(control)

## S3 method for class 'rxSolve'
getValidNlmixrCtl(control)

## S3 method for class 'simulate'
getValidNlmixrCtl(control)

## S3 method for class 'simulation'
getValidNlmixrCtl(control)

## S3 method for class 'tableControl'
getValidNlmixrCtl(control)

## Default S3 method:
getValidNlmixrCtl(control)

## S3 method for class 'uobyqa'
getValidNlmixrCtl(control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getValidNlmixrCtl.bobyqa_+3A_control">control</code></td>
<td>
<p>nlmixr control object</p>
</td></tr>
<tr><td><code id="getValidNlmixrCtl.bobyqa_+3A_est">est</code></td>
<td>
<p>Estimation routine</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is based on running the S3 method 'getValidNlmixrCtl()' the
'control' object is put into a list and the class of this new list
is 'c(est, &quot;getValidNlmixrControl&quot;)'
</p>


<h3>Value</h3>

<p>Valid control object based on estimation method run.
</p>

<hr>
<h2 id='lbfgsb3cControl'>Control for lbfgsb3c estimation method in nlmixr2</h2><span id='topic+lbfgsb3cControl'></span>

<h3>Description</h3>

<p>Control for lbfgsb3c estimation method in nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lbfgsb3cControl(
  trace = 0,
  factr = 1e+07,
  pgtol = 0,
  abstol = 0,
  reltol = 0,
  lmm = 5L,
  maxit = 10000L,
  returnLbfgsb3c = FALSE,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lbfgsb3cControl_+3A_trace">trace</code></td>
<td>
<p>If positive, tracing information on the progress of
the optimization is produced. Higher values may produce more
tracing information: for method &quot;L-BFGS-B&quot; there are six levels
of tracing. (To understand exactly what these do see the source
code: higher levels give more detail.)</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_factr">factr</code></td>
<td>
<p>controls the convergence of the &quot;L-BFGS-B&quot; method.
Convergence occurs when the reduction in the objective is within
this factor of the machine tolerance. Default is 1e7, that is a
tolerance of about 1e-8.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_pgtol">pgtol</code></td>
<td>
<p>helps control the convergence of the &quot;L-BFGS-B&quot;
method. It is a tolerance on the projected gradient in the
current search direction. This defaults to zero, when the check
is suppressed.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_abstol">abstol</code></td>
<td>
<p>helps control the convergence of the &quot;L-BFGS-B&quot;
method. It is an absolute tolerance difference in x values. This
defaults to zero, when the check is suppressed.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_reltol">reltol</code></td>
<td>
<p>helps control the convergence of the &quot;L-BFGS-B&quot;
method. It is an relative tolerance difference in x values. This
defaults to zero, when the check is suppressed.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_lmm">lmm</code></td>
<td>
<p>is an integer giving the number of BFGS updates retained
in the &quot;L-BFGS-B&quot; method, It defaults to 5.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_returnlbfgsb3c">returnLbfgsb3c</code></td>
<td>
<p>return the lbfgsb3c output instead of the nlmixr2
fit</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="lbfgsb3cControl_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>bobqya control structure
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="lbfgsb3c")

print(fit2)

# you can also get the nlm output with fit2$lbfgsb3c

fit2$lbfgsb3c

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='n1qn1Control'>Control for n1qn1 estimation method in nlmixr2</h2><span id='topic+n1qn1Control'></span>

<h3>Description</h3>

<p>Control for n1qn1 estimation method in nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n1qn1Control(
  epsilon = (.Machine$double.eps)^0.25,
  max_iterations = 10000,
  nsim = 10000,
  imp = 0,
  print.functions = FALSE,
  returnN1qn1 = FALSE,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", "n1qn1", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n1qn1Control_+3A_epsilon">epsilon</code></td>
<td>
<p>Precision of estimate for n1qn1 optimization.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_nsim">nsim</code></td>
<td>
<p>Number of function evaluations</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_imp">imp</code></td>
<td>
<p>Verbosity of messages.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_print.functions">print.functions</code></td>
<td>
<p>Boolean to control if the function value
and parameter estimates are echoed every time a function is
called.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_returnn1qn1">returnN1qn1</code></td>
<td>
<p>return the n1qn1 output instead of the nlmixr2
fit</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="n1qn1Control_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>bobqya control structure
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="n1qn1")

print(fit2)

# you can also get the nlm output with fit2$n1qn1

fit2$n1qn1

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='newuoaControl'>Control for newuoa estimation method in nlmixr2</h2><span id='topic+newuoaControl'></span>

<h3>Description</h3>

<p>Control for newuoa estimation method in nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newuoaControl(
  npt = NULL,
  rhobeg = NULL,
  rhoend = NULL,
  iprint = 0L,
  maxfun = 100000L,
  returnNewuoa = FALSE,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="newuoaControl_+3A_npt">npt</code></td>
<td>
<p>The number of points used to approximate the objective
function via a quadratic approximation for bobyqa. The value
of npt must be in the interval [n+2,(n+1)(n+2)/2] where n is
the number of parameters in par. Choices that exceed 2*n+1 are
not recommended. If not defined, it will be set to 2*n + 1. (bobyqa)</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_rhobeg">rhobeg</code></td>
<td>
<p>Beginning change in parameters for bobyqa algorithm
(trust region).  By default this is 0.2 or 20
parameters when the parameters are scaled to 1. rhobeg and
rhoend must be set to the initial and final values of a trust
region radius, so both must be positive with 0 &lt; rhoend &lt;
rhobeg. Typically rhobeg should be about one tenth of the
greatest expected change to a variable.  Note also that
smallest difference abs(upper-lower) should be greater than or
equal to rhobeg*2. If this is not the case then rhobeg will be
adjusted. (bobyqa)</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_rhoend">rhoend</code></td>
<td>
<p>The smallest value of the trust region radius that
is allowed. If not defined, then 10^(-sigdig-1) will be used. (bobyqa)</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_iprint">iprint</code></td>
<td>
<p>The value of 'iprint' should be set to an integer
value in '0, 1, 2, 3, ...', which controls the amount of
printing.  Specifically, there is no output if 'iprint=0' and
there is output only at the start and the return if 'iprint=1'.
Otherwise, each new value of 'rho' is printed, with the best
vector of variables so far and the corresponding value of the
objective function. Further, each new value of the objective
function with its variables are output if 'iprint=3'.  If 'iprint
&gt; 3', the objective function value and corresponding variables
are output every 'iprint' evaluations.  Default value is '0'.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_maxfun">maxfun</code></td>
<td>
<p>The maximum allowed number of function
evaluations. If this is exceeded, the method will terminate.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_returnnewuoa">returnNewuoa</code></td>
<td>
<p>return the newuoa output instead of the nlmixr2
fit</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="newuoaControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="newuoaControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="newuoaControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="newuoaControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="newuoaControl_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>newuoa control structure
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="newuoa")

print(fit2)

# you can also get the nlm output with

fit2$newuoa

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='nlmControl'>nlmixr2 defaults controls for nlm</h2><span id='topic+nlmControl'></span>

<h3>Description</h3>

<p>nlmixr2 defaults controls for nlm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmControl(
  typsize = NULL,
  fscale = 1,
  print.level = 0,
  ndigit = NULL,
  gradtol = 1e-06,
  stepmax = NULL,
  steptol = 1e-06,
  iterlim = 10000,
  check.analyticals = FALSE,
  returnNlm = FALSE,
  solveType = c("hessian", "grad", "fun"),
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  optimHessType = c("central", "forward"),
  hessErr = (.Machine$double.eps)^(1/3),
  shi21maxHess = 20L,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", "nlm", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmControl_+3A_typsize">typsize</code></td>
<td>
<p>an estimate of the size of each parameter
at the minimum.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_fscale">fscale</code></td>
<td>
<p>an estimate of the size of <code>f</code> at the minimum.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_print.level">print.level</code></td>
<td>
<p>this argument determines the level of printing
which is done during the minimization process.  The default
value of <code>0</code> means that no printing occurs, a value of <code>1</code>
means that initial and final details are printed and a value
of 2 means that full tracing information is printed.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_ndigit">ndigit</code></td>
<td>
<p>the number of significant digits in the function <code>f</code>.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_gradtol">gradtol</code></td>
<td>
<p>a positive scalar giving the tolerance at which the
scaled gradient is considered close enough to zero to
terminate the algorithm.  The scaled gradient is a
measure of the relative change in <code>f</code> in each direction
<code>p[i]</code> divided by the relative change in <code>p[i]</code>.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_stepmax">stepmax</code></td>
<td>
<p>a positive scalar which gives the maximum allowable
scaled step length.  <code>stepmax</code> is used to prevent steps which
would cause the optimization function to overflow, to prevent the
algorithm from leaving the area of interest in parameter space, or to
detect divergence in the algorithm. <code>stepmax</code> would be chosen
small enough to prevent the first two of these occurrences, but should
be larger than any anticipated reasonable step.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_steptol">steptol</code></td>
<td>
<p>A positive scalar providing the minimum allowable
relative step length.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_iterlim">iterlim</code></td>
<td>
<p>a positive integer specifying the maximum number of
iterations to be performed before the program is terminated.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_check.analyticals">check.analyticals</code></td>
<td>
<p>a logical scalar specifying whether the
analytic gradients and Hessians, if they are supplied, should be
checked against numerical derivatives at the initial parameter
values. This can help detect incorrectly formulated gradients or
Hessians.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_returnnlm">returnNlm</code></td>
<td>
<p>is a logical that allows a return of the 'nlm'
object</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_solvetype">solveType</code></td>
<td>
<p>tells if &lsquo;nlm' will use nlmixr2&rsquo;s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '&quot;hessian&quot;' which will use the analytical gradients to create a
Hessian with finite differences.
</p>
<p>- '&quot;gradient&quot;' which will use the gradient and let 'nlm' calculate
the finite difference hessian
</p>
<p>- '&quot;fun&quot;' where nlm will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the &quot;ideal&quot; step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_eventtype">eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
&quot;central&quot; or &quot;forward&quot;</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_shierr">shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_shi21maxfd">shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_optimhesstype">optimHessType</code></td>
<td>
<p>The hessian type for when calculating the
individual hessian by numeric differences (in generalized
log-likelihood estimation).  The options are &quot;central&quot;, and
&quot;forward&quot;.  The central differences is what R's 'optimHess()'
uses and is the default for this method. (Though the &quot;forward&quot; is
faster and still reasonable for most cases).  The Shi21 cannot be
changed for the Gill83 algorithm with the optimHess in a
generalized likelihood problem.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_hesserr">hessErr</code></td>
<td>
<p>This represents the epsilon when optimizing the
Hessian step size using the Shi2021 method.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_shi21maxhess">shi21maxHess</code></td>
<td>
<p>Maximum number of times to optimize the best
step size for the hessian calculation</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlmControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlmControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlmControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_covmethod">covMethod</code></td>
<td>
<p>allows selection of &quot;r&quot;, which uses nlmixr2's
'nlmixr2Hess()' for the hessian calculation or &quot;nlm&quot; which uses
the hessian from 'stats::nlm(.., hessian=TRUE)'. When using
&lsquo;nlmixr2&rsquo;s&lsquo; hessian for optimization or 'nlmixr2&rsquo;s' gradient for
solving this defaults to &quot;nlm&quot; since 'stats::optimHess()' assumes
an accurate gradient and is faster than 'nlmixr2Hess'</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlmControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlmControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="nlmControl_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nlm control object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="nlm")

print(fit2)

# you can also get the nlm output with fit2$nlm

fit2$nlm

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='nlminbControl'>nlmixr2 nlminb defaults</h2><span id='topic+nlminbControl'></span>

<h3>Description</h3>

<p>nlmixr2 nlminb defaults
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlminbControl(
  eval.max = 200,
  iter.max = 150,
  trace = 0,
  abs.tol = 0,
  rel.tol = 1e-10,
  x.tol = 1.5e-08,
  xf.tol = 2.2e-14,
  step.min = 1,
  step.max = 1,
  sing.tol = rel.tol,
  scale = 1,
  scale.init = NULL,
  diff.g = NULL,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  returnNlminb = FALSE,
  solveType = c("hessian", "grad", "fun"),
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  optimHessType = c("central", "forward"),
  hessErr = (.Machine$double.eps)^(1/3),
  shi21maxHess = 20L,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", "nlminb", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlminbControl_+3A_eval.max">eval.max</code></td>
<td>
<p>Maximum number of evaluations of the objective
function allowed.  Defaults to 200.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_iter.max">iter.max</code></td>
<td>
<p>Maximum number of iterations allowed.  Defaults to
150.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_trace">trace</code></td>
<td>
<p>The value of the objective function and the parameters
is printed every trace'th iteration.  When 0 no trace information
is to be printed</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_abs.tol">abs.tol</code></td>
<td>
<p>Absolute tolerance.  Defaults to 0 so the absolute
convergence test is not used.  If the objective function is known
to be non-negative, the previous default of '1e-20' would be more
appropriate</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Relative tolerance.  Defaults to '1e-10'.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_x.tol">x.tol</code></td>
<td>
<p>X tolerance.  Defaults to '1.5e-8'.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_xf.tol">xf.tol</code></td>
<td>
<p>false convergence tolerance.  Defaults to '2.2e-14'.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_step.min">step.min</code></td>
<td>
<p>Minimum step size.  Default to ‘1.’.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_step.max">step.max</code></td>
<td>
<p>Maximum step size.  Default to ‘1.’.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_sing.tol">sing.tol</code></td>
<td>
<p>singular convergence tolerance; defaults to 'rel.tol;.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scale">scale</code></td>
<td>
<p>See PORT documentation (or leave alone).</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scale.init">scale.init</code></td>
<td>
<p>... probably need to check PORT documentation</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_diff.g">diff.g</code></td>
<td>
<p>an estimated bound on the relative error in the
objective function value</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_returnnlminb">returnNlminb</code></td>
<td>
<p>logical; when TRUE this will return the nlminb
result instead of the nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_solvetype">solveType</code></td>
<td>
<p>tells if &lsquo;nlm' will use nlmixr2&rsquo;s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '&quot;hessian&quot;' which will use the analytical gradients to create a
Hessian with finite differences.
</p>
<p>- '&quot;gradient&quot;' which will use the gradient and let 'nlm' calculate
the finite difference hessian
</p>
<p>- '&quot;fun&quot;' where nlm will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the &quot;ideal&quot; step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_eventtype">eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
&quot;central&quot; or &quot;forward&quot;</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_shierr">shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_shi21maxfd">shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_optimhesstype">optimHessType</code></td>
<td>
<p>The hessian type for when calculating the
individual hessian by numeric differences (in generalized
log-likelihood estimation).  The options are &quot;central&quot;, and
&quot;forward&quot;.  The central differences is what R's 'optimHess()'
uses and is the default for this method. (Though the &quot;forward&quot; is
faster and still reasonable for most cases).  The Shi21 cannot be
changed for the Gill83 algorithm with the optimHess in a
generalized likelihood problem.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_hesserr">hessErr</code></td>
<td>
<p>This represents the epsilon when optimizing the
Hessian step size using the Shi2021 method.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_shi21maxhess">shi21maxHess</code></td>
<td>
<p>Maximum number of times to optimize the best
step size for the hessian calculation</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlminbControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlminbControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="nlminbControl_+3A_...">...</code></td>
<td>
<p>Further arguments to be supplied to <code>objective</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="nlminb")

print(fit2)

# you can also get the nlm output with fit2$nlminb

fit2$nlminb

</code></pre>

<hr>
<h2 id='nlmixr2'>nlmixr2 fits population PK and PKPD non-linear mixed effects models.</h2><span id='topic+nlmixr2'></span><span id='topic+nlmixr'></span><span id='topic+nlmixr2.function'></span><span id='topic+nlmixr2.rxUi'></span><span id='topic+nlmixr2.nlmixr2FitCore'></span><span id='topic+nlmixr2.nlmixr2FitData'></span>

<h3>Description</h3>

<p>nlmixr2 is an R package for fitting population pharmacokinetic (PK)
and pharmacokinetic-pharmacodynamic (PKPD) models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2(
  object,
  data,
  est = NULL,
  control = list(),
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)

nlmixr(
  object,
  data,
  est = NULL,
  control = list(),
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)

## S3 method for class ''function''
nlmixr2(
  object,
  data = NULL,
  est = NULL,
  control = NULL,
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)

## S3 method for class 'rxUi'
nlmixr2(
  object,
  data = NULL,
  est = NULL,
  control = NULL,
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)

## S3 method for class 'nlmixr2FitCore'
nlmixr2(
  object,
  data = NULL,
  est = NULL,
  control = NULL,
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)

## S3 method for class 'nlmixr2FitData'
nlmixr2(
  object,
  data = NULL,
  est = NULL,
  control = NULL,
  table = tableControl(),
  ...,
  save = NULL,
  envir = parent.frame()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2_+3A_object">object</code></td>
<td>
<p>Fitted object or function specifying the model.</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_data">data</code></td>
<td>
<p>nlmixr data</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_est">est</code></td>
<td>
<p>estimation method (all methods are shown by
'nlmixr2AllEst()'). Methods can be added for other tools</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_control">control</code></td>
<td>
<p>The estimation control object.  These are expected
to be different for each type of estimation method</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_table">table</code></td>
<td>
<p>The output table control object (like
'tableControl()')</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_save">save</code></td>
<td>
<p>Boolean to save a nlmixr2 object in a rds file in the
working directory.  If <code>NULL</code>, uses option &quot;nlmixr2.save&quot;</p>
</td></tr>
<tr><td><code id="nlmixr2_+3A_envir">envir</code></td>
<td>
<p>Environment where the nlmixr object/function is
evaluated before running the estimation routine.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The nlmixr2 generalized function allows common access to the nlmixr2
estimation routines.
</p>
<p>The nlmixr object has the following fields:</p>

<table>
<tr>
 <td style="text-align: left;">
   Field </td><td style="text-align: left;"> Description </td>
</tr>
<tr>
 <td style="text-align: left;">
   conditionNumber </td><td style="text-align: left;"> Condition number, that is the highest divided by the lowest eigenvalue in the population covariance matrix </td>
</tr>
<tr>
 <td style="text-align: left;">
   cor </td><td style="text-align: left;"> Correlation matrix </td>
</tr>
<tr>
 <td style="text-align: left;">
   phiR </td><td style="text-align: left;"> correlation matrix of each individual’s eta (if present) </td>
</tr>
<tr>
 <td style="text-align: left;">
   objDF </td><td style="text-align: left;"> Data frame containing objective function information (AIC, BIC, etc.) </td>
</tr>
<tr>
 <td style="text-align: left;">
   time </td><td style="text-align: left;"> Duration of different parts of the analysis (e.g. setup, optimization, calculation of covariance, etc.) </td>
</tr>
<tr>
 <td style="text-align: left;">
   theta </td><td style="text-align: left;"> Estimates for eta for each individual </td>
</tr>
<tr>
 <td style="text-align: left;">
   etaObf </td><td style="text-align: left;"> Estimates for eta for each individual, This also includes the objective function for each individual </td>
</tr>
<tr>
 <td style="text-align: left;">
   fixef </td><td style="text-align: left;"> Estimates of fixed effects </td>
</tr>
<tr>
 <td style="text-align: left;">
   foceiControl </td><td style="text-align: left;"> Estimation options if focei was used </td>
</tr>
<tr>
 <td style="text-align: left;">
   ui </td><td style="text-align: left;"> Final estimates for the model </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataMergeFull </td><td style="text-align: left;"> Full data merge with the fit output and the original dataset; Also includes nlmixrLlikObs which includes the individual observation contribution to the likelihood </td>
</tr>
<tr>
 <td style="text-align: left;">
   censInfo </td><td style="text-align: left;"> Gives the censorng information abot the fit (the type of censoring that was seend and handled in the dataset) </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataLloq </td><td style="text-align: left;"> Gives the lloq from the dataset (average) when cesoring has occured; Requires the fit to have a table step </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataUloq </td><td style="text-align: left;"> Gives the uloq from the dataset (average) when censoring has occured; requires the fit to have a table step </td>
</tr>
<tr>
 <td style="text-align: left;">
   eta </td><td style="text-align: left;"> IIV values for each indiviudal </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataMergeInner </td><td style="text-align: left;"> Inner data merge with the fit output and the original dataset; Also includes nlmixrLlikObs which includes the individual observation contribution to the likelihood </td>
</tr>
<tr>
 <td style="text-align: left;">
   rxControl </td><td style="text-align: left;"> Integration options used to control rxode2 </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataMergeLeft </td><td style="text-align: left;"> Left data merge with the fit output and the original dataset; Also includes nlmixrLlikObs which includes the individual observation contribution to the likelihood </td>
</tr>
<tr>
 <td style="text-align: left;">
   omega </td><td style="text-align: left;"> Matrix containing the estimates of the multivarte normal covariance matrix for between subject varaibilities (omega) </td>
</tr>
<tr>
 <td style="text-align: left;">
   covMethod </td><td style="text-align: left;"> Method used to calculate covariance of the fixed effects </td>
</tr>
<tr>
 <td style="text-align: left;">
   modelName </td><td style="text-align: left;"> Name of the R object containing the model </td>
</tr>
<tr>
 <td style="text-align: left;">
   origData </td><td style="text-align: left;"> Original dataset </td>
</tr>
<tr>
 <td style="text-align: left;">
   phiRSE </td><td style="text-align: left;"> Relative standard error of each individuals eta </td>
</tr>
<tr>
 <td style="text-align: left;">
   dataMergeRight </td><td style="text-align: left;"> Right data merge with the fit output and the original dataset; Also includes nlmixrLlikObs which includes the individual observation contribution to the likelihood </td>
</tr>
<tr>
 <td style="text-align: left;">
   ipredModel </td><td style="text-align: left;"> rxode2 estimation model for fit (internal will likely be removed from visibility </td>
</tr>
<tr>
 <td style="text-align: left;">
   phiSE </td><td style="text-align: left;"> Standard error of each individuals eta </td>
</tr>
<tr>
 <td style="text-align: left;">
   parFixed </td><td style="text-align: left;"> Table of parameter estimates (rounded and pretty looking) </td>
</tr>
<tr>
 <td style="text-align: left;">
   parFixedDF </td><td style="text-align: left;"> Table of parameter estimates as a data frame </td>
</tr>
<tr>
 <td style="text-align: left;">
   omegaR </td><td style="text-align: left;"> The correlation matirx of omega with standard deviations for the diagonal pieces </td>
</tr>
<tr>
 <td style="text-align: left;">
   iniUi </td><td style="text-align: left;"> The initial model used to start the estimation </td>
</tr>
<tr>
 <td style="text-align: left;">
   finalUi </td><td style="text-align: left;"> The model with the estimates replaced as values </td>
</tr>
<tr>
 <td style="text-align: left;">
   scaleInfo </td><td style="text-align: left;"> The scaling factors used for nlmixr2 estimation in focei; The can be changed by foceiControl(scaleC=…) if you think these are unreasonable. It also tells the Gill83 outcome of trying to find the best step size (High gradient error, bad gradient etc) </td>
</tr>
<tr>
 <td style="text-align: left;">
   table </td><td style="text-align: left;"> These are the table options that were used when generating the table output (were CWRES included, etc </td>
</tr>
<tr>
 <td style="text-align: left;">
   shrink </td><td style="text-align: left;"> This is a table of shrinkages for all the individual ETAs as well as the variance shrinkage as well as summary statistics for the ETAs and Residual Error </td>
</tr>
<tr>
 <td style="text-align: left;">
   env </td><td style="text-align: left;"> This is the environment where all the information for the fit is stored outside of the data-frame. It is an R environment hence $env </td>
</tr>
<tr>
 <td style="text-align: left;">
   seed </td><td style="text-align: left;"> This is the initial seed used for saem </td>
</tr>
<tr>
 <td style="text-align: left;">
   simInfo </td><td style="text-align: left;"> This returns a list of all the fit information used for a traditional rxode2 simulation, which you can tweak yourself if you wish </td>
</tr>
<tr>
 <td style="text-align: left;">
   runInfo </td><td style="text-align: left;"> This returns a list of all the warnings or fit information </td>
</tr>
<tr>
 <td style="text-align: left;">
   parHistStacked </td><td style="text-align: left;"> Value of objective function and parameters at each iteration (tall format) </td>
</tr>
<tr>
 <td style="text-align: left;">
   parHist </td><td style="text-align: left;"> Value of objective function and parameters at each iteration (wide format) </td>
</tr>
<tr>
 <td style="text-align: left;">
   cov </td><td style="text-align: left;"> Variance-covariance matrix </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Value</h3>

<p>Either a nlmixr2 model or a nlmixr2 fit object
</p>


<h3>nlmixr modeling mini-language</h3>

<p><b>Rationale</b>
</p>
<p>nlmixr estimation routines each have their own way of specifying
models.  Often the models are specified in ways that are most
intuitive for one estimation routine, but do not make sense for
another estimation routine.  Sometimes, legacy estimation
routines like <code><a href="nlme.html#topic+nlme">nlme</a></code> have their own syntax that
is outside of the control of the nlmixr package.
</p>
<p>The unique syntax of each routine makes the routines themselves
easier to maintain and expand, and allows interfacing with
existing packages that are outside of nlmixr (like
<code><a href="nlme.html#topic+nlme">nlme</a></code>).  However, a model definition language
that is common between estimation methods, and an output object
that is uniform, will make it easier to switch between estimation
routines and will facilitate interfacing output with external
packages like Xpose.
</p>
<p>The nlmixr mini-modeling language, attempts to address this issue
by incorporating a common language.  This language is inspired by
both R and NONMEM, since these languages are familiar to many
pharmacometricians.
</p>
<p><b>Initial Estimates and boundaries for population parameters</b>
</p>
<p>nlmixr models are contained in a R function with two blocks:
<code>ini</code> and <code>model</code>.  This R function can be named
anything, but is not meant to be called directly from R.  In fact
if you try you will likely get an error such as <code>Error: could
not find function "ini"</code>.
</p>
<p>The <code>ini</code> model block is meant to hold the initial estimates
for the model, and the boundaries of the parameters for estimation
routines that support boundaries (note nlmixr's <code>saem</code>
and <code>nlme</code> do not currently support parameter boundaries).
</p>
<p>To explain how these initial estimates are specified we will start
with an annotated example:
</p>
<pre>
f &lt;- function(){ ## Note the arguments to the function are currently
                 ## ignored by nlmixr
    ini({
        ## Initial conditions for population parameters (sometimes
        ## called theta parameters) are defined by either `&lt;-` or '='
        lCl &lt;- 1.6      #log Cl (L/hr)
        ## Note that simple expressions that evaluate to a number are
        ## OK for defining initial conditions (like in R)
        lVc = log(90)  #log V (L)
        ## Also a comment on a parameter is captured as a parameter label
        lKa &lt;- 1 #log Ka (1/hr)
        ## Bounds may be specified by c(lower, est, upper), like NONMEM:
        ## Residuals errors are assumed to be population parameters
        prop.err &lt;- c(0, 0.2, 1)
    })
    ## The model block will be discussed later
    model({})
}
</pre>
<p>As shown in the above examples:
</p>

<ul>
<li><p> Simple parameter values are specified as a R-compatible assignment
</p>
</li>
<li><p> Boundaries my be specified by <code>c(lower, est, upper)</code>.
</p>
</li>
<li><p> Like NONMEM, <code>c(lower,est)</code> is equivalent to <code>c(lower,est,Inf)</code>
</p>
</li>
<li><p> Also like NONMEM, <code>c(est)</code> does not specify a lower bound, and is equivalent
to specifying the parameter  without R's 'c' function.
</p>
</li>
<li><p> The initial estimates are specified on the variance scale, and in analogy with
NONMEM, the square roots of the diagonal elements correspond to coefficients of
variation when used in the exponential IIV implementation
</p>
</li></ul>

<p>These parameters can be named almost any R compatible name.  Please note that:
</p>

<ul>
<li><p> Residual error estimates should be coded as population estimates (i.e. using an
'=' or '&lt;-' statement, not a '~').
</p>
</li>
<li><p> Naming variables that start with &quot;<code>_</code>&quot; are not supported.  Note that R does not
allow variable starting with &quot;<code>_</code>&quot; to be assigned without quoting them.
</p>
</li>
<li><p> Naming variables that start with &quot;<code>rx_</code>&quot; or &quot;<code>nlmixr_</code>&quot; is
not supported since <a href="rxode2.html#topic+rxode2">rxode2</a> and nlmixr2 use these prefixes
internally for certain estimation routines and calculating residuals.
</p>
</li>
<li><p> Variable names are case sensitive, just like they are in R. &quot;<code>CL</code>&quot; is not the
same as &quot;<code>Cl</code>&quot;.
</p>
</li></ul>

<p><b>Initial Estimates for between subject error distribution (NONMEM's  $OMEGA)</b>
</p>
<p>In mixture models, multivariate normal individual deviations from
the population parameters are estimated (in NONMEM these are
called <code>eta</code> parameters).  Additionally the
variance/covariance matrix of these deviations is also estimated
(in NONMEM this is the OMEGA matrix).  These also have initial
estimates.  In nlmixr these are specified by the '~' operator that
is typically used in R for &quot;modeled by&quot;, and was chosen to
distinguish these estimates from the population and residual error
parameters.
</p>
<p>Continuing the prior example, we can annotate the estimates for
the between subject error distribution
</p>
<pre>
f &lt;- function(){
    ini({
        lCl &lt;- 1.6      #log Cl (L/hr)
        lVc = log(90)  #log V (L)
        lKa &lt;- 1 #log Ka (1/hr)
        prop.err &lt;- c(0, 0.2, 1)
        ## Initial estimate for ka IIV variance
        ## Labels work for single parameters
        eta.ka ~ 0.1 # BSV Ka

        ## For correlated parameters, you specify the names of each
        ## correlated parameter separated by a addition operator `+`
        ## and the left handed side specifies the lower triangular
        ## matrix initial of the covariance matrix.
        eta.cl + eta.vc ~ c(0.1,
                            0.005, 0.1)
        ## Note that labels do not currently work for correlated
        ## parameters.  Also do not put comments inside the lower
        ## triangular matrix as this will currently break the model.
    })
    ## The model block will be discussed later
    model({})
}
</pre>
<p>As shown in the above examples:
</p>

<ul>
<li><p> Simple variances are specified by the variable name  and the
estimate separated by '~'.
</p>
</li>
<li><p> Correlated parameters are specified by the sum of the variable
labels and then the lower triangular matrix of the covariance is
specified on the left handed side of the equation. This is also
separated by '~'.
</p>
</li></ul>

<p>Currently the model syntax does not allow comments inside the
lower triangular matrix.
</p>
<p><b>Model Syntax for ODE based models (NONMEM's $PK, $PRED, $DES and $ERROR)</b>
</p>
<p>Once the initialization block has been defined, you can define a
model in terms of the defined variables in the <code>ini</code> block.  You can
also mix in RxODE blocks into the model.
</p>
<p>The current method of defining a nlmixr model is to specify the
parameters, and then possibly the RxODE lines:
</p>
<p>Continuing describing the syntax with an annotated example:
</p>
<pre>
f &lt;- function(){
    ini({
        lCl &lt;- 1.6      #log Cl (L/hr)
        lVc &lt;- log(90)   #log Vc (L)
        lKA &lt;- 0.1      #log Ka (1/hr)
        prop.err &lt;- c(0, 0.2, 1)
        eta.Cl ~ 0.1 ## BSV Cl
        eta.Vc ~ 0.1 ## BSV Vc
        eta.KA ~ 0.1 ## BSV Ka
    })
    model({
        ## First parameters are defined in terms of the initial estimates
        ## parameter names.
        Cl &lt;- exp(lCl + eta.Cl)
        Vc = exp(lVc + eta.Vc)
        KA &lt;- exp(lKA + eta.KA)
        ## After the differential equations are defined
        kel &lt;- Cl / Vc;
        d/dt(depot)    = -KA*depot;
        d/dt(centr)  =  KA*depot-kel*centr;
        ## And the concentration is then calculated
        cp = centr / Vc;
        ## Last, nlmixr is told that the plasma concentration follows
        ## a proportional error (estimated by the parameter prop.err)
        cp ~ prop(prop.err)
    })
}
</pre>
<p>A few points to note:
</p>

<ul>
<li><p> Parameters are often defined before the differential equations.
</p>
</li>
<li><p> The differential equations, parameters and error terms are in a single
block, instead of multiple sections.
</p>
</li>
<li><p> State names, calculated variables cannot start with either &quot;<code>rx_</code>&quot;
or &quot;<code>nlmixr_</code>&quot; since these are used internally in some estimation routines.
</p>
</li>
<li><p> Errors are specified using the '~'.  Currently you can use either <code>add(parameter)</code>
for additive error,  prop(parameter) for proportional error or <code>add(parameter1) + prop(parameter2)</code>
for additive plus proportional error.  You can also specify <code>norm(parameter)</code> for the additive error,
since it follows a normal distribution.
</p>
</li>
<li><p> Some routines, like <code>saem</code> require  parameters in terms of <code>Pop.Parameter + Individual.Deviation.Parameter + Covariate*Covariate.Parameter</code>.
The order of these parameters do not matter.  This is similar to NONMEM's mu-referencing, though
not quite so restrictive.
</p>
</li>
<li><p> The type of parameter in the model is determined by the initial block;  Covariates used in the
model are missing in the <code>ini</code> block.  These variables need to be present in the modeling
dataset for the model to run.
</p>
</li></ul>

<p><b>Model Syntax for solved PK systems</b>
</p>
<p>Solved PK systems are also currently supported by nlmixr with the
'linCmt()' pseudo-function.  An annotated example of a solved
system is below:
</p>
<p>##' </p>
<pre>
f &lt;- function(){
    ini({
        lCl &lt;- 1.6      #log Cl (L/hr)
        lVc &lt;- log(90)   #log Vc (L)
        lKA &lt;- 0.1      #log Ka (1/hr)
        prop.err &lt;- c(0, 0.2, 1)
        eta.Cl ~ 0.1 ## BSV Cl
        eta.Vc ~ 0.1 ## BSV Vc
        eta.KA ~ 0.1 ## BSV Ka
    })
    model({
        Cl &lt;- exp(lCl + eta.Cl)
        Vc = exp(lVc + eta.Vc)
        KA &lt;- exp(lKA + eta.KA)
        ## Instead of specifying the ODEs, you can use
        ## the linCmt() function to use the solved system.
        ##
        ## This function determines the type of PK solved system
        ## to use by the parameters that are defined.  In this case
        ## it knows that this is a one-compartment model with first-order
        ## absorption.
        linCmt() ~ prop(prop.err)
    })
}
</pre>
<p>A few things to keep in mind:
</p>

<ul>
<li><p> While RxODE allows mixing of solved systems and ODEs, this has not
been implemented in nlmixr yet.
</p>
</li>
<li><p> The solved systems implemented are the one, two and three compartment
models with or without first-order absorption.  Each of the models support a
lag time with a tlag parameter.
</p>
</li>
<li><p> In general the linear compartment model figures out the model by the parameter names.
nlmixr currently knows about numbered volumes, Vc/Vp, Clearances in terms of both Cl and
Q/CLD.  Additionally nlmixr knows about elimination micro-constants (ie K12).  Mixing of
these parameters for these models is currently not supported.
</p>
</li></ul>

<p><b>Checking model syntax</b>
</p>
<p>After specifying the model syntax you can check that nlmixr is
interpreting it correctly by using the <code>nlmixr</code> function on
it.
</p>
<p>Using the above function we can get:
</p>
<pre>
&gt; nlmixr(f)
## 1-compartment model with first-order absorption in terms of Cl
## Initialization:
################################################################################
Fixed Effects ($theta):
    lCl     lVc     lKA
1.60000 4.49981 0.10000

Omega ($omega):
     [,1] [,2] [,3]
[1,]  0.1  0.0  0.0
[2,]  0.0  0.1  0.0
[3,]  0.0  0.0  0.1

## Model:
################################################################################
Cl &lt;- exp(lCl + eta.Cl)
Vc = exp(lVc + eta.Vc)
KA &lt;- exp(lKA + eta.KA)
## Instead of specifying the ODEs, you can use
## the linCmt() function to use the solved system.
##
## This function determines the type of PK solved system
## to use by the parameters that are defined.  In this case
## it knows that this is a one-compartment model with first-order
## absorption.
linCmt() ~ prop(prop.err)
</pre>
<p>In general this gives you information about the model (what type
of solved system/RxODE), initial estimates as well as the code for
the model block.
</p>
<p><b>Using the model syntax for estimating a model</b>
</p>
<p>Once the model function has been created, you can use it and a
dataset to estimate the parameters for a model given a dataset.
</p>
<p>This dataset has to have RxODE compatible events IDs.  Both
Monolix and NONMEM use a a very similar standard to what nlmixr can support.
</p>
<p>Once the data has been converted to the appropriate format, you
can use the <code>nlmixr</code> function to run the appropriate code.
</p>
<p>The method to estimate the model is:
</p>
<pre>
fit &lt;- nlmixr(model.function, dataset, est="est", control=estControl(options))
</pre>
<p>Currently <code>nlme</code> and <code>saem</code> are implemented.  For example, to run the
above model with <code>saem</code>, we could have the following:
</p>
<pre>
&gt; f &lt;- function(){
    ini({
        lCl &lt;- 1.6      #log Cl (L/hr)
        lVc &lt;- log(90)   #log Vc (L)
        lKA &lt;- 0.1      #log Ka (1/hr)
        prop.err &lt;- c(0, 0.2, 1)
        eta.Cl ~ 0.1 ## BSV Cl
        eta.Vc ~ 0.1 ## BSV Vc
        eta.KA ~ 0.1 ## BSV Ka
    })
    model({
        ## First parameters are defined in terms of the initial estimates
        ## parameter names.
        Cl &lt;- exp(lCl + eta.Cl)
        Vc = exp(lVc + eta.Vc)
        KA &lt;- exp(lKA + eta.KA)
        ## After the differential equations are defined
        kel &lt;- Cl / Vc;
        d/dt(depot)    = -KA*depot;
        d/dt(centr)  =  KA*depot-kel*centr;
        ## And the concentration is then calculated
        cp = centr / Vc;
        ## Last, nlmixr is told that the plasma concentration follows
        ## a proportional error (estimated by the parameter prop.err)
        cp ~ prop(prop.err)
    })
}
&gt; fit.s &lt;- nlmixr(f,d,est="saem",control=saemControl(n.burn=50,n.em=100,print=50));
Compiling RxODE differential equations...done.
c:/Rtools/mingw_64/bin/g++  -I"c:/R/R-34~1.1/include" -DNDEBUG     -I"d:/Compiler/gcc-4.9.3/local330/include"  -Ic:/nlmixr/inst/include -Ic:/R/R-34~1.1/library/STANHE~1/include -Ic:/R/R-34~1.1/library/Rcpp/include -Ic:/R/R-34~1.1/library/RCPPAR~1/include -Ic:/R/R-34~1.1/library/RCPPEI~1/include -Ic:/R/R-34~1.1/library/BH/include   -O2 -Wall  -mtune=core2 -c saem3090757b4bd1x64.cpp -o saem3090757b4bd1x64.o
In file included from c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo:52:0,
                 from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadilloForward.h:46,
                 from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadillo.h:31,
                 from saem3090757b4bd1x64.cpp:1:
c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo_bits/compiler_setup.hpp:474:96: note: #pragma message: WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+
   #pragma message ("WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+")
                                                                                                ^
c:/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o saem3090757b4bd1x64.dll tmp.def saem3090757b4bd1x64.o c:/nlmixr/R/rx_855815def56a50f0e7a80e48811d947c_x64.dll -Lc:/R/R-34~1.1/bin/x64 -lRblas -Lc:/R/R-34~1.1/bin/x64 -lRlapack -lgfortran -lm -lquadmath -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -Lc:/R/R-34~1.1/bin/x64 -lR
done.
1:    1.8174   4.6328   0.0553   0.0950   0.0950   0.0950   0.6357
50:    1.3900   4.2039   0.0001   0.0679   0.0784   0.1082   0.1992
100:    1.3894   4.2054   0.0107   0.0686   0.0777   0.1111   0.1981
150:    1.3885   4.2041   0.0089   0.0683   0.0778   0.1117   0.1980
Using sympy via SnakeCharmR
## Calculate ETA-based prediction and error derivatives:
Calculate Jacobian...................done.
Calculate sensitivities.......
done.
## Calculate d(f)/d(eta)
## ...
## done
## ...
## done
The model-based sensitivities have been calculated
Calculating Table Variables...
done
</pre>
<p>The options for <code>saem</code> are controlled by <code><a href="#topic+saemControl">saemControl</a></code>.
You may wish to make sure the minimization is complete in the case
of <code>saem</code>.  You can do that with <code>traceplot</code> which shows the
iteration history with the divided by burn-in and EM phases.  In
this case, the burn in seems reasonable; you may wish to increase
the number of iterations in the EM phase of the estimation.
Overall it is probably a semi-reasonable solution.
</p>
<p><b>nlmixr output objects</b>
</p>
<p>In addition to unifying the modeling language sent to each of the
estimation routines, the outputs currently have a unified structure.
</p>
<p>You can see the fit object by typing the object name:
</p>
<pre>
&gt; fit.s
 -- nlmixr SAEM fit (ODE); OBJF calculated from FOCEi approximation -------------
      OBJF      AIC      BIC Log-likelihood Condition Number
  62337.09 62351.09 62399.01      -31168.55          82.6086

 -- Time (sec; fit.s$time): -----------------------------------------------------
           saem setup Likelihood Calculation covariance table
 elapsed 430.25 31.64                   1.19          0  3.44

 -- Parameters (fit.s$par.fixed): -----------------------------------------------
              Parameter Estimate     SE  
 lCl      log Cl (L/hr)     1.39 0.0240  1.73       4.01 (3.83, 4.20)    26.6
 lVc         log Vc (L)     4.20 0.0256 0.608       67.0 (63.7, 70.4)    28.5
 lKA      log Ka (1/hr)  0.00924 0.0323  349.      1.01 (0.947, 1.08)    34.3
 prop.err      prop.err    0.198                             19.8
          Shrink(SD)
 lCl          0.248
 lVc           1.09
 lKA           4.19
 prop.err      1.81

   No correlations in between subject variability (BSV) matrix
   Full BSV covariance (fit.s$omega) or correlation (fit.s$omega.R; diagonals=SDs)
   Distribution stats (mean/skewness/kurtosis/p-value) available in fit.s$shrink

 -- Fit Data (object fit.s is a modified data.frame): ---------------------------
 # A tibble: 6,947 x 22
   ID     TIME    DV  PRED    RES    WRES IPRED  IRES  IWRES CPRED   CRES
 * &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
 1 1      0.25  205.  198.   6.60  0.0741  189.  16.2  0.434  198.   6.78
 2 1      0.5   311.  349. -38.7  -0.261   330. -19.0 -0.291  349. -38.3
 3 1      0.75  389.  464. -74.5  -0.398   434. -45.2 -0.526  463. -73.9
 # ... with 6,944 more rows, and 11 more variables: CWRES &lt;dbl&gt;, eta.Cl &lt;dbl&gt;,
 #   eta.Vc &lt;dbl&gt;, eta.KA &lt;dbl&gt;, depot &lt;dbl&gt;, centr &lt;dbl&gt;, Cl &lt;dbl&gt;, Vc &lt;dbl&gt;,
 #   KA &lt;dbl&gt;, kel &lt;dbl&gt;, cp &lt;dbl&gt;
</pre>
<p>This example shows what is typical printout of a nlmixr fit object.  The elements of the fit are:
</p>

<ul>
<li><p> The type of fit (<code><a href="nlme.html#topic+nlme">nlme</a></code>, <code>saem</code>, etc)
</p>
</li>
<li><p> Metrics of goodness of fit (<code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+BIC">BIC</a></code>,
and <code><a href="stats.html#topic+logLik">logLik</a></code>).
</p>

<ul>
<li><p> To align the comparison between methods, the FOCEi likelihood objective is calculated
regardless of the method used and used for goodness of fit metrics.
</p>
</li>
<li><p> This FOCEi likelihood has been compared to NONMEM's objective function and gives
the same values (based on the data in Wang 2007)
</p>
</li>
<li><p> Also note that <code>saem</code> does not calculate an objective function,
and the FOCEi is used as the only objective function for the fit.
</p>
</li>
<li><p> Even though the objective functions are calculated in the same manner, caution should
be used when comparing fits from various estimation routines.
</p>
</li></ul>

</li>
<li><p> The next item is the timing of each of the steps of the fit.
</p>

<ul>
<li><p> These can be also accessed by (<code>fit.s$time</code>).
</p>
</li>
<li><p> As a mnemonic, the access for this item is shown in the printout.
This is true for almost all of the other items in the printout.
</p>
</li></ul>

</li>
<li><p> After the timing of the fit, the parameter estimates are displayed (can be accessed by
<code>fit.s$par.fixed</code>)
</p>

<ul>
<li><p> While the items are rounded for R printing, each estimate without rounding is still accessible by the '$' syntax.
For example, the '$Untransformed' gives the untransformed parameter values.
</p>
</li>
<li><p> The Untransformed parameter takes log-space parameters and back-transforms them to normal parameters.  Not the CIs
are listed on the back-transformed parameter space.
</p>
</li>
<li><p> Proportional Errors are converted to 
</p>
</li></ul>

</li>
<li><p> Omega block (accessed by <code>fit.s$omega</code>)
</p>
</li>
<li><p> The table of fit data. Please note:
</p>

<ul>
<li><p> A nlmixr fit object is actually a data frame.  Saving it as a Rdata object and then loading it
without nlmixr will just show the data by itself.  Don't worry; the fit information has not vanished,
you can bring it back by simply loading nlmixr, and then accessing the data.
</p>
</li>
<li><p> Special access to fit information (like the <code>$omega</code>) needs nlmixr to extract the information.
</p>
</li>
<li><p> If you use the <code>$</code> to access information, the order of precedence is:
</p>

<ul>
<li><p> Fit data from the overall data.frame
</p>
</li>
<li><p> Information about the parsed nlmixr model (via <code>$uif</code>)
</p>
</li>
<li><p> Parameter history if available (via <code>$par.hist</code> and <code>$par.hist.stacked</code>)
</p>
</li>
<li><p> Fixed effects table (via <code>$par.fixed</code>)
</p>
</li>
<li><p> Individual differences from the typical population parameters (via <code>$eta</code>)
</p>
</li>
<li><p> Fit information from the list of information generated during the post-hoc
residual calculation.
</p>
</li>
<li><p> Fit information from the environment where the post-hoc residual were calculated
</p>
</li>
<li><p> Fit information about how the data and options interacted with the specified model
(such as estimation options or if the solved system is for an infusion or an IV bolus).
</p>
</li></ul>

</li>
<li><p> While the printout may displays the data as a <code>data.table</code> object or <code>tbl</code>
object, the data is NOT any of these objects, but rather a derived data frame.
</p>
</li>
<li><p> Since the object <em>is</em> a data.frame, you can treat it like one.
</p>
</li></ul>

</li></ul>

<p>In addition to the above properties of the fit object, there are a
few additional that may be helpful for the modeler:
</p>

<ul>
<li> <p><code>$theta</code> gives the fixed effects parameter estimates (in NONMEM the
<code>theta</code>s). This can also be accessed in <code><a href="nlme.html#topic+fixed.effects">fixed.effects</a></code>
function. Note that the residual variability is treated as a fixed effect parameter
and is included in this list.
</p>
</li>
<li> <p><code>$eta</code> gives the random effects parameter estimates, or in NONMEM the
<code>eta</code>s.  This can also be accessed in using the <code><a href="#topic+random.effects">random.effects</a></code>
function.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
 ini({
   ## You may label each parameter with a comment
   tka &lt;- 0.45 # Ka
   tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
   ## This works with interactive models
   ## You may also label the preceding line with label("label text")
   tv &lt;- 3.45; label("log V")
   ## the label("Label name") works with all models
   eta.ka ~ 0.6
   eta.cl ~ 0.3
   eta.v ~ 0.1
   add.sd &lt;- 0.7
   prop.sd &lt;- 0.01
 })
 model({
   ka &lt;- exp(tka + eta.ka)
   cl &lt;- exp(tcl + eta.cl)
   v &lt;- exp(tv + eta.v)
   linCmt() ~ add(add.sd) + prop(prop.sd)
 })
}

# fitF &lt;- nlmixr(one.cmt, theo_sd, "focei")

fitS &lt;- nlmixr(one.cmt, theo_sd, "saem")



</code></pre>

<hr>
<h2 id='nlmixr2AllEst'>Show all the current estimation methods</h2><span id='topic+nlmixr2AllEst'></span>

<h3>Description</h3>

<p>Show all the current estimation methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2AllEst()
</code></pre>


<h3>Value</h3>

<p>List of supported nlmixr2 estimation options (est=...)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nlmixr2AllEst()
</code></pre>

<hr>
<h2 id='nlmixr2AugPredSolve'>Augmented Prediction for nlmixr2 fit</h2><span id='topic+nlmixr2AugPredSolve'></span><span id='topic+augPred.nlmixr2FitData'></span>

<h3>Description</h3>

<p>Augmented Prediction for nlmixr2 fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2AugPredSolve(
  fit,
  covsInterpolation = c("locf", "nocb", "linear", "midpoint"),
  minimum = NULL,
  maximum = NULL,
  length.out = 51L,
  ...
)

## S3 method for class 'nlmixr2FitData'
augPred(
  object,
  primary = NULL,
  minimum = NULL,
  maximum = NULL,
  length.out = 51,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2AugPredSolve_+3A_fit">fit</code></td>
<td>
<p>Nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_covsinterpolation">covsInterpolation</code></td>
<td>
<p>specifies the interpolation method for
time-varying covariates. When solving ODEs it often samples
times outside the sampling time specified in <code>events</code>.
When this happens, the time varying covariates are
interpolated.  Currently this can be:
</p>

<ul>
<li> <p><code>"linear"</code> interpolation, which interpolates the covariate
by solving the line between the observed covariates and extrapolating the new
covariate value.
</p>
</li>
<li> <p><code>"constant"</code> &ndash; Last observation carried forward (the default).
</p>
</li>
<li> <p><code>"NOCB"</code> &ndash; Next Observation Carried Backward.  This is the same method
that NONMEM uses.
</p>
</li>
<li> <p><code>"midpoint"</code> Last observation carried forward to midpoint; Next observation
carried backward to midpoint.
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_minimum">minimum</code></td>
<td>
<p>an optional lower limit for the primary
covariate. Defaults to <code>min(primary)</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_maximum">maximum</code></td>
<td>
<p>an optional upper limit for the primary
covariate. Defaults to <code>max(primary)</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_length.out">length.out</code></td>
<td>
<p>an optional integer with the number of primary
covariate values at which to evaluate the predictions.  Defaults to
51.</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_...">...</code></td>
<td>
<p>some methods for the generic may require additional
arguments.</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_object">object</code></td>
<td>
<p>a fitted model object from which predictions can be
extracted, using a <code>predict</code> method.</p>
</td></tr>
<tr><td><code id="nlmixr2AugPredSolve_+3A_primary">primary</code></td>
<td>
<p>an optional one-sided formula specifying the primary
covariate to be used to generate the augmented predictions. By
default, if a  covariate can be extracted from the data used to generate
<code>object</code> (using <code>getCovariate</code>), it will be used as
<code>primary</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Stacked data.frame with observations, individual/population predictions.
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixr2CreateOutputFromUi'>Create nlmixr output from the UI</h2><span id='topic+nlmixr2CreateOutputFromUi'></span>

<h3>Description</h3>

<p>Create nlmixr output from the UI
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2CreateOutputFromUi(
  ui,
  data = NULL,
  control = NULL,
  table = NULL,
  env = NULL,
  est = "none"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_ui">ui</code></td>
<td>
<p>This is the UI that will be used for the translation</p>
</td></tr>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_data">data</code></td>
<td>
<p>This has the data</p>
</td></tr>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_control">control</code></td>
<td>
<p>focei control for data creation</p>
</td></tr>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_table">table</code></td>
<td>
<p>Table options</p>
</td></tr>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_env">env</code></td>
<td>
<p>Environment setup which needs the following:
- '$table' for table options
- '$origData' &ndash; Original Data
- '$dataSav' &ndash; Processed data from .foceiPreProcessData
- '$idLvl' &ndash; Level information for ID factor added
- '$covLvl' &ndash; Level information for items to convert to factor
- '$ui' for ui object
- '$fullTheta' Full theta information
- '$etaObf' data frame with ID, etas and OBJI
- '$cov' For covariance
- '$covMethod' for the method of calculating the covariance
- '$adjObf' Should the objective function value be adjusted
- '$objective' objective function value
- '$extra' Extra print information
- '$method' Estimation method (for printing)
- '$omega' Omega matrix
- '$theta' Is a theta data frame
- '$model' a list of model information for table generation.  Needs a 'predOnly' model
- '$message' Message for display
- '$est' estimation method
- '$ofvType' (optional) tells the type of ofv is currently being use
</p>
<p>There are some more details that need to be described here</p>
</td></tr>
<tr><td><code id="nlmixr2CreateOutputFromUi_+3A_est">est</code></td>
<td>
<p>Estimation method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nlmixr fit object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixr2Est.bobyqa'>Generic for nlmixr2 estimation methods</h2><span id='topic+nlmixr2Est.bobyqa'></span><span id='topic+nlmixr2Est.focei'></span><span id='topic+nlmixr2Est.foce'></span><span id='topic+nlmixr2Est.posthoc'></span><span id='topic+nlmixr2Est.foi'></span><span id='topic+nlmixr2Est.fo'></span><span id='topic+nlmixr2Est.output'></span><span id='topic+nlmixr2Est.lbfgsb3c'></span><span id='topic+nlmixr2Est.n1qn1'></span><span id='topic+nlmixr2Est.newuoa'></span><span id='topic+nlmixr2Est.nlm'></span><span id='topic+nlmixr2Est.nlme'></span><span id='topic+nlmixr2Est.nlminb'></span><span id='topic+nlmixr2Est'></span><span id='topic+nlmixr2Est.default'></span><span id='topic+nlmixr2Est.nls'></span><span id='topic+nlmixr2Est.optim'></span><span id='topic+nlmixr2Est.rxSolve'></span><span id='topic+nlmixr2Est.simulate'></span><span id='topic+nlmixr2Est.simulation'></span><span id='topic+nlmixr2Est.predict'></span><span id='topic+nlmixr2Est.saem'></span><span id='topic+nlmixr2Est.uobyqa'></span>

<h3>Description</h3>

<p>Generic for nlmixr2 estimation methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bobyqa'
nlmixr2Est(env, ...)

## S3 method for class 'focei'
nlmixr2Est(env, ...)

## S3 method for class 'foce'
nlmixr2Est(env, ...)

## S3 method for class 'posthoc'
nlmixr2Est(env, ...)

## S3 method for class 'foi'
nlmixr2Est(env, ...)

## S3 method for class 'fo'
nlmixr2Est(env, ...)

## S3 method for class 'output'
nlmixr2Est(env, ...)

## S3 method for class 'lbfgsb3c'
nlmixr2Est(env, ...)

## S3 method for class 'n1qn1'
nlmixr2Est(env, ...)

## S3 method for class 'newuoa'
nlmixr2Est(env, ...)

## S3 method for class 'nlm'
nlmixr2Est(env, ...)

## S3 method for class 'nlme'
nlmixr2Est(env, ...)

## S3 method for class 'nlminb'
nlmixr2Est(env, ...)

nlmixr2Est(env, ...)

## Default S3 method:
nlmixr2Est(env, ...)

## S3 method for class 'nls'
nlmixr2Est(env, ...)

## S3 method for class 'optim'
nlmixr2Est(env, ...)

## S3 method for class 'rxSolve'
nlmixr2Est(env, ...)

## S3 method for class 'simulate'
nlmixr2Est(env, ...)

## S3 method for class 'simulation'
nlmixr2Est(env, ...)

## S3 method for class 'predict'
nlmixr2Est(env, ...)

## S3 method for class 'saem'
nlmixr2Est(env, ...)

## S3 method for class 'uobyqa'
nlmixr2Est(env, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Est.bobyqa_+3A_env">env</code></td>
<td>
<p>Environment for the nlmixr2 estimation routines.
</p>
<p>This needs to have:
</p>
<p>- rxode2 ui object in '$ui'
</p>
<p>- data to fit in the estimation routine in '$data'
</p>
<p>- control for the estimation routine's control options in '$ui'</p>
</td></tr>
<tr><td><code id="nlmixr2Est.bobyqa_+3A_...">...</code></td>
<td>
<p>Other arguments provided to 'nlmixr2Est()' provided for
flexibility but not currently used inside nlmixr</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a S3 generic that allows others to use the nlmixr2
environment to do their own estimation routines
</p>


<h3>Value</h3>

<p>nlmixr2 fit object
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='nlmixr2Eval_'>Create a gradient function based on gill numerical differences</h2><span id='topic+nlmixr2Eval_'></span><span id='topic+nlmixr2Unscaled_'></span><span id='topic+nlmixr2Grad_'></span><span id='topic+nlmixr2ParHist_'></span><span id='topic+nlmixr2GradFun'></span>

<h3>Description</h3>

<p>Create a gradient function based on gill numerical differences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Eval_(theta, md5)

nlmixr2Unscaled_(theta, md5)

nlmixr2Grad_(theta, md5)

nlmixr2ParHist_(md5)

nlmixr2GradFun(
  what,
  envir = parent.frame(),
  which,
  thetaNames,
  gillRtol = sqrt(.Machine$double.eps),
  gillK = 10L,
  gillStep = 2,
  gillFtol = 0,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Eval__+3A_theta">theta</code></td>
<td>
<p>for the internal functions theta is the parameter
values</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_md5">md5</code></td>
<td>
<p>the md5 identifier for the internal gradient function
information.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_what">what</code></td>
<td>
<p>either a function or a non-empty character string naming the
function to be called.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_envir">envir</code></td>
<td>
<p>an environment within which to evaluate the call.  This
will be most useful if <code>what</code> is a character string and
the arguments are symbols or quoted expressions.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_which">which</code></td>
<td>
<p>Which parameters to calculate the forward difference
and optimal forward difference interval</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_thetanames">thetaNames</code></td>
<td>
<p>Names for the theta parameters</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_gillrtol">gillRtol</code></td>
<td>
<p>The relative tolerance used for Gill 1983
determination of optimal step size.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_gillk">gillK</code></td>
<td>
<p>The total number of possible steps to determine the
optimal forward/central difference step size per parameter (by
the Gill 1983 method).  If 0, no optimal step size is
determined.  Otherwise this is the optimal step size
determined.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_gillstep">gillStep</code></td>
<td>
<p>When looking for the optimal forward difference
step size, this is This is the step size to increase the
initial estimate by.  So each iteration the new step size =
(prior step size)*gillStep</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_gillftol">gillFtol</code></td>
<td>
<p>The gillFtol is the gradient error tolerance that
is acceptable before issuing a warning/error about the gradient estimates.</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="nlmixr2Eval__+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 'eval', 'grad', 'hist' and 'unscaled'
functions.  This is an internal module used with dynmodel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
func0 &lt;- function(x){ sum(sin(x))  }

## This will printout every interation or when print=X
gf &lt;- nlmixr2GradFun(func0)

## x
x &lt;- (0:10)*2*pi/10;
gf$eval(x)
gf$grad(x)

## x2
x2 &lt;- x+0.1
gf$eval(x2)
gf$grad(x2)

## Gives the parameter history as a data frame
gf$hist()

</code></pre>

<hr>
<h2 id='nlmixr2Gill83'>Get the optimal forward difference interval by Gill83 method</h2><span id='topic+nlmixr2Gill83'></span>

<h3>Description</h3>

<p>Get the optimal forward difference interval by Gill83 method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Gill83(
  what,
  args,
  envir = parent.frame(),
  which,
  gillRtol = sqrt(.Machine$double.eps),
  gillK = 10L,
  gillStep = 2,
  gillFtol = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Gill83_+3A_what">what</code></td>
<td>
<p>either a function or a non-empty character string naming the
function to be called.</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_args">args</code></td>
<td>
<p>a <em>list</em> of arguments to the function call.  The
<code>names</code> attribute of <code>args</code> gives the argument names.</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_envir">envir</code></td>
<td>
<p>an environment within which to evaluate the call.  This
will be most useful if <code>what</code> is a character string and
the arguments are symbols or quoted expressions.</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_which">which</code></td>
<td>
<p>Which parameters to calculate the forward difference
and optimal forward difference interval</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_gillrtol">gillRtol</code></td>
<td>
<p>The relative tolerance used for Gill 1983
determination of optimal step size.</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_gillk">gillK</code></td>
<td>
<p>The total number of possible steps to determine the
optimal forward/central difference step size per parameter (by
the Gill 1983 method).  If 0, no optimal step size is
determined.  Otherwise this is the optimal step size
determined.</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_gillstep">gillStep</code></td>
<td>
<p>When looking for the optimal forward difference
step size, this is This is the step size to increase the
initial estimate by.  So each iteration the new step size =
(prior step size)*gillStep</p>
</td></tr>
<tr><td><code id="nlmixr2Gill83_+3A_gillftol">gillFtol</code></td>
<td>
<p>The gillFtol is the gradient error tolerance that
is acceptable before issuing a warning/error about the gradient estimates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the following columns:
</p>
<p>- info Gradient evaluation/forward difference information
</p>
<p>- hf Forward difference final estimate
</p>
<p>- df Derivative estimate
</p>
<p>- df2 2nd Derivative Estimate
</p>
<p>- err Error of the final estimate derivative
</p>
<p>- aEps Absolute difference for forward numerical differences
</p>
<p>- rEps Relative Difference for backward numerical differences
</p>
<p>- aEpsC Absolute difference for central numerical differences
</p>
<p>- rEpsC Relative difference for central numerical differences
</p>
<p>The <code>info</code> returns one of the following:
</p>
<p>- &quot;Not Assessed&quot; Gradient wasn't assessed
</p>
<p>- &quot;Good Success&quot; in Estimating optimal forward difference interval
</p>
<p>- &quot;High Grad Error&quot; Large error; Derivative estimate error <code>fTol</code> or more of the derivative
</p>
<p>- &quot;Constant Grad&quot; Function constant or nearly constant for this parameter
</p>
<p>- &quot;Odd/Linear Grad&quot; Function odd or nearly linear, df = K, df2 ~ 0
</p>
<p>- &quot;Grad changes quickly&quot; df2 increases rapidly as h decreases
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## These are taken from the numDeriv::grad examples to show how
## simple gradients are assessed with nlmixr2Gill83

nlmixr2Gill83(sin, pi)

nlmixr2Gill83(sin, (0:10)*2*pi/10)

func0 &lt;- function(x){ sum(sin(x))  }
nlmixr2Gill83(func0 , (0:10)*2*pi/10)

func1 &lt;- function(x){ sin(10*x) - exp(-x) }
curve(func1,from=0,to=5)

x &lt;- 2.04
numd1 &lt;- nlmixr2Gill83(func1, x)
exact &lt;- 10*cos(10*x) + exp(-x)
c(numd1$df, exact, (numd1$df - exact)/exact)

x &lt;- c(1:10)
numd1 &lt;- nlmixr2Gill83(func1, x)
exact &lt;- 10*cos(10*x) + exp(-x)
cbind(numd1=numd1$df, exact, err=(numd1$df - exact)/exact)

sc2.f &lt;- function(x){
  n &lt;- length(x)
   sum((1:n) * (exp(x) - x)) / n
}

sc2.g &lt;- function(x){
  n &lt;- length(x)
  (1:n) * (exp(x) - 1) / n
}

x0 &lt;- rnorm(100)
exact &lt;- sc2.g(x0)

g &lt;- nlmixr2Gill83(sc2.f, x0)

max(abs(exact - g$df)/(1 + abs(exact)))

</code></pre>

<hr>
<h2 id='nlmixr2Hess'>Calculate Hessian</h2><span id='topic+nlmixr2Hess'></span>

<h3>Description</h3>

<p>Unlike 'stats::optimHess' which assumes the gradient is accurate,
nlmixr2Hess does not make as strong an assumption that the gradient
is accurate but takes more function evaluations to calculate the
Hessian.  In addition, this procedures optimizes the forward
difference interval by <code><a href="#topic+nlmixr2Gill83">nlmixr2Gill83</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Hess(par, fn, ..., envir = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Hess_+3A_par">par</code></td>
<td>
<p>Initial values for the parameters to be optimized over.</p>
</td></tr>
<tr><td><code id="nlmixr2Hess_+3A_fn">fn</code></td>
<td>
<p>A function to be minimized (or maximized), with first
argument the vector of parameters over which minimization is to take
place.  It should return a scalar result.</p>
</td></tr>
<tr><td><code id="nlmixr2Hess_+3A_...">...</code></td>
<td>
<p>Extra arguments sent to <code><a href="#topic+nlmixr2Gill83">nlmixr2Gill83</a></code></p>
</td></tr>
<tr><td><code id="nlmixr2Hess_+3A_envir">envir</code></td>
<td>
<p>an environment within which to evaluate the call.  This
will be most useful if <code>what</code> is a character string and
the arguments are symbols or quoted expressions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you have an analytical gradient function, you should use
'stats::optimHess'
</p>


<h3>Value</h3>

<p>Hessian matrix based on Gill83
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlmixr2Gill83">nlmixr2Gill83</a></code>, <code><a href="stats.html#topic+optimHess">optimHess</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> func0 &lt;- function(x){ sum(sin(x))  }
 x &lt;- (0:10)*2*pi/10
 nlmixr2Hess(x, func0)

fr &lt;- function(x) {   ## Rosenbrock Banana function
    x1 &lt;- x[1]
    x2 &lt;- x[2]
    100 * (x2 - x1 * x1)^2 + (1 - x1)^2
}
grr &lt;- function(x) { ## Gradient of 'fr'
    x1 &lt;- x[1]
    x2 &lt;- x[2]
    c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),
       200 *      (x2 - x1 * x1))
}

h1 &lt;- optimHess(c(1.2,1.2), fr, grr)

h2 &lt;- optimHess(c(1.2,1.2), fr)

## in this case h3 is closer to h1 where the gradient is known

h3 &lt;- nlmixr2Hess(c(1.2,1.2), fr)
</code></pre>

<hr>
<h2 id='nlmixr2Keywords'>A list and description of the fields in the nlmxir2 object</h2><span id='topic+nlmixr2Keywords'></span>

<h3>Description</h3>

<p>A list and description of the fields in the nlmxir2 object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Keywords
</code></pre>


<h3>Format</h3>

<p>A data frame with 2 columns and 40 or more rows
</p>

<dl>
<dt>Field</dt><dd><p>Name of the field in the nlmixr2 object</p>
</dd>
<dt>Description</dt><dd><p>Description of the information in the field</p>
</dd>
</dl>


<hr>
<h2 id='nlmixr2Logo'>Messages the nlmixr2 logo...</h2><span id='topic+nlmixr2Logo'></span>

<h3>Description</h3>

<p>Messages the nlmixr2 logo...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Logo(str = "", version = sessionInfo()$otherPkgs$nlmixr2$Version)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Logo_+3A_str">str</code></td>
<td>
<p>String to print</p>
</td></tr>
<tr><td><code id="nlmixr2Logo_+3A_version">version</code></td>
<td>
<p>Version information (by default use package version)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing; Called to display version information
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixr2NlmeControl'>Control Values for nlme Fit with extra options for nlmixr</h2><span id='topic+nlmixr2NlmeControl'></span><span id='topic+nlmeControl'></span>

<h3>Description</h3>

<p>The values supplied in the function call replace the defaults and
a list with all possible arguments is returned.  The returned list
is used as the ‘control’ argument to the ‘nlme’ function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2NlmeControl(
  maxIter = 100,
  pnlsMaxIter = 100,
  msMaxIter = 100,
  minScale = 0.001,
  tolerance = 1e-05,
  niterEM = 25,
  pnlsTol = 0.001,
  msTol = 1e-06,
  returnObject = FALSE,
  msVerbose = FALSE,
  msWarnNoConv = TRUE,
  gradHess = TRUE,
  apVar = TRUE,
  .relStep = .Machine$double.eps^(1/3),
  minAbsParApVar = 0.05,
  opt = c("nlminb", "nlm"),
  natural = TRUE,
  sigma = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  rxControl = NULL,
  method = c("ML", "REML"),
  random = NULL,
  fixed = NULL,
  weights = NULL,
  verbose = TRUE,
  returnNlme = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  muRefCovAlg = TRUE,
  ...
)

nlmeControl(
  maxIter = 100,
  pnlsMaxIter = 100,
  msMaxIter = 100,
  minScale = 0.001,
  tolerance = 1e-05,
  niterEM = 25,
  pnlsTol = 0.001,
  msTol = 1e-06,
  returnObject = FALSE,
  msVerbose = FALSE,
  msWarnNoConv = TRUE,
  gradHess = TRUE,
  apVar = TRUE,
  .relStep = .Machine$double.eps^(1/3),
  minAbsParApVar = 0.05,
  opt = c("nlminb", "nlm"),
  natural = TRUE,
  sigma = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  rxControl = NULL,
  method = c("ML", "REML"),
  random = NULL,
  fixed = NULL,
  weights = NULL,
  verbose = TRUE,
  returnNlme = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  muRefCovAlg = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2NlmeControl_+3A_maxiter">maxIter</code></td>
<td>
<p>maximum number of iterations for the <code>nlme</code>
optimization algorithm.  Default is 50.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_pnlsmaxiter">pnlsMaxIter</code></td>
<td>
<p>maximum number of iterations
for the <code>PNLS</code> optimization step inside the <code>nlme</code>
optimization.  Default is 7.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_msmaxiter">msMaxIter</code></td>
<td>
<p>maximum number of iterations for <code><a href="stats.html#topic+nlminb">nlminb</a></code>
(<code>iter.max</code>) or the <code><a href="stats.html#topic+nlm">nlm</a></code> (<code>iterlim</code>, from the
10-th step) optimization step inside the <code>nlme</code>
optimization.  Default is 50 (which may be too small for e.g. for
overparametrized cases).</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_minscale">minScale</code></td>
<td>
<p>minimum factor by which to shrink the default step size
in an attempt to decrease the sum of squares in the <code>PNLS</code> step.
Default <code>0.001</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_tolerance">tolerance</code></td>
<td>
<p>tolerance for the convergence criterion in the
<code>nlme</code> algorithm.  Default is <code>1e-6</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_niterem">niterEM</code></td>
<td>
<p>number of iterations for the EM algorithm used to refine
the initial estimates of the random effects variance-covariance
coefficients.  Default is 25.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_pnlstol">pnlsTol</code></td>
<td>
<p>tolerance for the convergence criterion in <code>PNLS</code>
step.  Default is <code>1e-3</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_mstol">msTol</code></td>
<td>
<p>tolerance for the convergence criterion in <code>nlm</code>,
passed as the <code>gradtol</code> argument to the function (see
documentation on <code>nlm</code>).  Default is <code>1e-7</code>. </p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_returnobject">returnObject</code></td>
<td>
<p>a logical value indicating whether the fitted
object should be returned when the maximum number of iterations is
reached without convergence of the algorithm.  Default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_msverbose">msVerbose</code></td>
<td>
<p>a logical value passed as the <code>trace</code> to
<code><a href="stats.html#topic+nlminb">nlminb</a>(.., control= list(trace = *, ..))</code> or
as argument <code>print.level</code> to <code><a href="stats.html#topic+nlm">nlm</a>()</code>.  Default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_mswarnnoconv">msWarnNoConv</code></td>
<td>
<p>logical indicating if a <code><a href="base.html#topic+warning">warning</a></code>
should be signalled whenever the minimization (by <code>opt</code>) in the
LME step does not converge; defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_gradhess">gradHess</code></td>
<td>
<p>a logical value indicating whether numerical gradient
vectors and Hessian matrices of the log-likelihood function should
be used in the <code>nlm</code> optimization. This option is only available
when the correlation structure (<code>corStruct</code>) and the variance
function structure (<code>varFunc</code>) have no &quot;varying&quot; parameters and
the <code>pdMat</code> classes used in the random effects structure are
<code>pdSymm</code> (general positive-definite), <code>pdDiag</code> (diagonal),
<code>pdIdent</code> (multiple of the identity),  or
<code>pdCompSymm</code> (compound symmetry).  Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_apvar">apVar</code></td>
<td>
<p>a logical value indicating whether the approximate
covariance matrix of the variance-covariance parameters should be
calculated.  Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_.relstep">.relStep</code></td>
<td>
<p>relative step for numerical derivatives
calculations.  Default is <code>.Machine$double.eps^(1/3)</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_minabsparapvar">minAbsParApVar</code></td>
<td>
<p>numeric value - minimum absolute parameter value
in the approximate variance calculation.  The default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_opt">opt</code></td>
<td>
<p>the optimizer to be used, either <code>"<a href="stats.html#topic+nlminb">nlminb</a>"</code> (the
default) or <code>"<a href="stats.html#topic+nlm">nlm</a>"</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_natural">natural</code></td>
<td>
<p>a logical value indicating whether the <code>pdNatural</code>
parametrization should be used for general positive-definite matrices
(<code>pdSymm</code>) in <code>reStruct</code>, when the approximate covariance
matrix of the estimators is calculated.  Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_sigma">sigma</code></td>
<td>
<p>optionally a positive number to fix the residual error at.
If <code>NULL</code>, as by default, or <code>0</code>, sigma is estimated.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_method">method</code></td>
<td>
<p>a character string.  If <code>"REML"</code> the model is fit by
maximizing the restricted log-likelihood.  If <code>"ML"</code> the
log-likelihood is maximized.  Defaults to <code>"ML"</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_random">random</code></td>
<td>
<p>optionally, any of the following: (i) a two-sided formula
of the form <code>r1+...+rn~x1+...+xm | g1/.../gQ</code>, with
<code>r1,...,rn</code> naming parameters included on the right
hand side of <code>model</code>, <code>x1+...+xm</code> specifying the
random-effects model for
these parameters and <code>g1/.../gQ</code> the grouping structure
(<code>Q</code> may be equal to 1, in which case no <code>/</code> is
required). The random effects formula will be repeated
for all levels of grouping, in the case of multiple levels of
grouping; (ii) a two-sided formula of the form
<code>r1+...+rn~x1+..+xm</code>, a list of two-sided formulas of the form
<code>r1~x1+...+xm</code>, with possibly different random-effects models
for different parameters, a <code>pdMat</code> object with a two-sided
formula, or list of two-sided formulas (i.e. a non-<code>NULL</code> value for
<code>formula(random)</code>), or a list of pdMat objects with two-sided
formulas, or lists of two-sided formulas. In this case, the grouping
structure formula will be given in <code>groups</code>, or derived from the
data used to fit the nonlinear mixed-effects model, which should
inherit from class  <code>groupedData</code>,; (iii) a named list
of formulas, lists of formulas, or <code>pdMat</code> objects as in (ii),
with the grouping factors as names. The order of nesting will be
assumed the same as the order of the order of the elements in the
list; (iv) an <code>reStruct</code> object. See the documentation on
<code><a href="nlme.html#topic+pdClasses">pdClasses</a></code> for a description of the available <code>pdMat</code>
classes. Defaults to <code>fixed</code>,
resulting in all fixed effects having also random effects.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_fixed">fixed</code></td>
<td>
<p>a two-sided linear formula of the form
<code>f1+...+fn~x1+...+xm</code>, or a list of two-sided formulas of the form
<code>f1~x1+...+xm</code>, with possibly different models for different
parameters. The <code>f1,...,fn</code> are the names of parameters included on
the right hand side of <code>model</code> and the <code>x1+...+xm</code>
expressions define linear models for these parameters (when the left
hand side of the formula contains several parameters, they all are
assumed to follow the same linear model, described by the right hand
side expression).
A <code>1</code> on the right hand side of the formula(s) indicates a single
fixed effects for the corresponding parameter(s).</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_weights">weights</code></td>
<td>
<p>an optional <code>varFunc</code> object or one-sided formula
describing the within-group heteroscedasticity structure. If given as
a formula, it is used as the argument to <code>varFixed</code>,
corresponding to fixed variance weights. See the documentation on
<code><a href="nlme.html#topic+varClasses">varClasses</a></code> for a description of the available <code>varFunc</code>
classes. Defaults to <code>NULL</code>, corresponding to homoscedastic
within-group errors.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_verbose">verbose</code></td>
<td>
<p>an optional logical value. If <code>TRUE</code> information on
the evolution of the iterative algorithm is printed. Default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_returnnlme">returnNlme</code></td>
<td>
<p>Returns the nlme object instead of the nlmixr
object (by default FALSE).  If any of the nlme specific options
of 'random', 'fixed', 'sens', the nlme object is returned</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_murefcovalg">muRefCovAlg</code></td>
<td>
<p>This controls if algebraic expressions that can
be mu-referenced are treated as mu-referenced covariates by:
</p>
<p>1. Creating a internal data-variable 'nlmixrMuDerCov#' for each
algebraic mu-referenced expression
</p>
<p>2. Change the algebraic expression to 'nlmixrMuDerCov# * mu_cov_theta'
</p>
<p>3. Use the internal mu-referenced covariate for saem
</p>
<p>4. After optimization is completed, replace 'model()' with old
'model()' expression
</p>
<p>5. Remove 'nlmixrMuDerCov#' from nlmix2 output
</p>
<p>In general, these covariates should be more accurate since it
changes the system to a linear compartment model.  Therefore, by default this is 'TRUE'.</p>
</td></tr>
<tr><td><code id="nlmixr2NlmeControl_+3A_...">...</code></td>
<td>
<p>Further, named control arguments to be passed to
<code><a href="stats.html#topic+nlminb">nlminb</a></code> (apart from <code>trace</code> and <code>iter.max</code>
mentioned above), where used (<code>eval.max</code> and those from
<code>abs.tol</code> down).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a nlmixr-nlme list
</p>


<h3>See Also</h3>

<p>Other Estimation control: 
<code><a href="#topic+foceiControl">foceiControl</a>()</code>,
<code><a href="#topic+saemControl">saemControl</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nlmeControl()
nlmixr2NlmeControl()
</code></pre>

<hr>
<h2 id='nlmixr2Print'>Print x using the message facility</h2><span id='topic+nlmixr2Print'></span>

<h3>Description</h3>

<p>This allows the suppressMessages to work on print functions.  This
captures the output function sends it through the message routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Print_+3A_x">x</code></td>
<td>
<p>object to print</p>
</td></tr>
<tr><td><code id="nlmixr2Print_+3A_...">...</code></td>
<td>
<p>Other things output</p>
</td></tr>
</table>


<h3>Details</h3>

<p>catpureOutput was used since it is much faster than the internal
capture.output see https://www.r-bloggers.com/performance-captureoutput-is-much-faster-than-capture-output/
</p>


<h3>Value</h3>

<p>Nothing, called for its side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixr2Validate'>Validate nlmixr2</h2><span id='topic+nlmixr2Validate'></span><span id='topic+nmTest'></span>

<h3>Description</h3>

<p>This allows easy validation/qualification of nlmixr2 by running the
testing suite on your system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Validate(type = NULL, skipOnCran = TRUE)

nmTest(type = NULL, skipOnCran = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixr2Validate_+3A_type">type</code></td>
<td>
<p>of test to be run</p>
</td></tr>
<tr><td><code id="nlmixr2Validate_+3A_skiponcran">skipOnCran</code></td>
<td>
<p>when 'TRUE' skip the test on CRAN.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for its side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixr2Version'>Display nlmixr2's version</h2><span id='topic+nlmixr2Version'></span>

<h3>Description</h3>

<p>Display nlmixr2's version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixr2Version()
</code></pre>


<h3>Value</h3>

<p>Nothing, called for its side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixrAddObjectiveFunctionDataFrame'>Add objective function data frame to the current objective function</h2><span id='topic+nlmixrAddObjectiveFunctionDataFrame'></span>

<h3>Description</h3>

<p>Add objective function data frame to the current objective function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrAddObjectiveFunctionDataFrame(fit, objDf, type, etaObf = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrAddObjectiveFunctionDataFrame_+3A_fit">fit</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
<tr><td><code id="nlmixrAddObjectiveFunctionDataFrame_+3A_objdf">objDf</code></td>
<td>
<p>nlmixr objective function data frame which has column
names &quot;OBJF&quot;, &quot;AIC&quot;, &quot;BIC&quot;, &quot;Log-likelihood&quot; and
&quot;Condition#(Cov)&quot; &quot;Condition#(Cor)&quot;</p>
</td></tr>
<tr><td><code id="nlmixrAddObjectiveFunctionDataFrame_+3A_type">type</code></td>
<td>
<p>Objective Function Type</p>
</td></tr>
<tr><td><code id="nlmixrAddObjectiveFunctionDataFrame_+3A_etaobf">etaObf</code></td>
<td>
<p>Eta objective function table to add (with focei) to
give focei objective function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixrAddTiming'>Manually add time to a nlmixr2 object</h2><span id='topic+nlmixrAddTiming'></span>

<h3>Description</h3>

<p>Manually add time to a nlmixr2 object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrAddTiming(object, name, time)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrAddTiming_+3A_object">object</code></td>
<td>
<p>nlmixr2 object</p>
</td></tr>
<tr><td><code id="nlmixrAddTiming_+3A_name">name</code></td>
<td>
<p>string of the timing name</p>
</td></tr>
<tr><td><code id="nlmixrAddTiming_+3A_time">time</code></td>
<td>
<p>time (in seconds)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
 ini({
   ## You may label each parameter with a comment
   tka &lt;- 0.45 # Ka
   tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
   ## This works with interactive models
   ## You may also label the preceding line with label("label text")
   tv &lt;- 3.45; label("log V")
   ## the label("Label name") works with all models
   eta.ka ~ 0.6
   eta.cl ~ 0.3
   eta.v ~ 0.1
   add.sd &lt;- 0.7
 })
 model({
   ka &lt;- exp(tka + eta.ka)
   cl &lt;- exp(tcl + eta.cl)
   v &lt;- exp(tv + eta.v)
   linCmt() ~ add(add.sd)
 })
}

fit &lt;- nlmixr(one.cmt, theo_sd, est="saem")

# will add to the current setup
nlmixrAddTiming(fit, "setup", 3)

# Add a new item to the timing dataframe
nlmixrAddTiming(fit, "new", 3)



</code></pre>

<hr>
<h2 id='nlmixrCbind'>nlmixrCbind</h2><span id='topic+nlmixrCbind'></span>

<h3>Description</h3>

<p>'cbind' for 'nlmixr' objects that preserve the fit information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrCbind(fit, extra)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrCbind_+3A_fit">fit</code></td>
<td>
<p>nlmixr fit</p>
</td></tr>
<tr><td><code id="nlmixrCbind_+3A_extra">extra</code></td>
<td>
<p>data to cbind to nlmixr fit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fit expanded with extra values, without disturbing the fit information
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixrClone'>Clone nlmixr environment</h2><span id='topic+nlmixrClone'></span>

<h3>Description</h3>

<p>Clone nlmixr environment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrClone(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrClone_+3A_x">x</code></td>
<td>
<p>nlmixr fit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cloned nlmixr environment
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

one.cmt &lt;- function() {
  ini({
    ## You may label each parameter with a comment
    tka &lt;- 0.45 # Log Ka
    tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
    ## This works with interactive models
    ## You may also label the preceding line with label("label text")
    tv &lt;- 3.45; label("log V")
    ## the label("Label name") works with all models
    eta.ka ~ 0.6
    eta.cl ~ 0.3
    eta.v ~ 0.1
    add.sd &lt;- 0.7
  })
  model({
    ka &lt;- exp(tka + eta.ka)
    cl &lt;- exp(tcl + eta.cl)
    v &lt;- exp(tv + eta.v)
    linCmt() ~ add(add.sd)
  })
}

f &lt;- nlmixr2(one.cmt, theo_sd, "saem")

nlmixrClone(f)


## End(Not run)
</code></pre>

<hr>
<h2 id='nlmixrUpdateObject'>Update the nlmixr2 object with new fit information</h2><span id='topic+nlmixrUpdateObject'></span>

<h3>Description</h3>

<p>Update the nlmixr2 object with new fit information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrUpdateObject(fit, objName, envir, origFitEnv = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrUpdateObject_+3A_fit">fit</code></td>
<td>
<p>nlmixr2 fit object to update in the environment</p>
</td></tr>
<tr><td><code id="nlmixrUpdateObject_+3A_objname">objName</code></td>
<td>
<p>Name of the object</p>
</td></tr>
<tr><td><code id="nlmixrUpdateObject_+3A_envir">envir</code></td>
<td>
<p>Environment to search</p>
</td></tr>
<tr><td><code id="nlmixrUpdateObject_+3A_origfitenv">origFitEnv</code></td>
<td>
<p>Original fit$env to compare, otherwise simply use fit$env</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nlmixrWithTiming'>Time a part of a nlmixr operation and add to nlmixr object</h2><span id='topic+nlmixrWithTiming'></span>

<h3>Description</h3>

<p>Time a part of a nlmixr operation and add to nlmixr object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlmixrWithTiming(name, code, envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlmixrWithTiming_+3A_name">name</code></td>
<td>
<p>Name of the timing to be integrated</p>
</td></tr>
<tr><td><code id="nlmixrWithTiming_+3A_code">code</code></td>
<td>
<p>Code to be evaluated and timed</p>
</td></tr>
<tr><td><code id="nlmixrWithTiming_+3A_envir">envir</code></td>
<td>
<p>can be either the nlmixr2 fit data, the nlmixr2 fit
environment or NULL, which implies it is going to be added to the
nlmixr fit when it is finalized.  If the function is being called
after a fit is created, please supply this environmental variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result of code
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


one.cmt &lt;- function() {
 ini({
   ## You may label each parameter with a comment
   tka &lt;- 0.45 # Ka
   tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
   ## This works with interactive models
   ## You may also label the preceding line with label("label text")
   tv &lt;- 3.45; label("log V")
   ## the label("Label name") works with all models
   eta.ka ~ 0.6
   eta.cl ~ 0.3
   eta.v ~ 0.1
   add.sd &lt;- 0.7
 })
 model({
   ka &lt;- exp(tka + eta.ka)
   cl &lt;- exp(tcl + eta.cl)
   v &lt;- exp(tv + eta.v)
   linCmt() ~ add(add.sd)
 })
}
fit &lt;- nlmixr(one.cmt, theo_sd, est="saem")

nlmixrWithTiming("time1", {
   Sys.sleep(1)
   # note this can be nested, time1 will exclude the timing from time2
   nlmixrWithTiming("time2", {
      Sys.sleep(1)
   }, envir=fit)
}, envir=fit)

print(fit)



</code></pre>

<hr>
<h2 id='nlsControl'>nlmixr2 defaults controls for nls</h2><span id='topic+nlsControl'></span>

<h3>Description</h3>

<p>nlmixr2 defaults controls for nls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlsControl(
  maxiter = 10000,
  tol = 1e-05,
  minFactor = 1/1024,
  printEval = FALSE,
  warnOnly = FALSE,
  scaleOffset = 0,
  nDcentral = FALSE,
  algorithm = c("LM", "default", "plinear", "port"),
  ftol = sqrt(.Machine$double.eps),
  ptol = sqrt(.Machine$double.eps),
  gtol = 0,
  diag = list(),
  epsfcn = 0,
  factor = 100,
  maxfev = integer(),
  nprint = 0,
  solveType = c("grad", "fun"),
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  trace = FALSE,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  returnNls = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlsControl_+3A_maxiter">maxiter</code></td>
<td>
<p>A positive integer specifying the maximum number of
iterations allowed.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_tol">tol</code></td>
<td>
<p>A positive numeric value specifying the tolerance level for
the relative offset convergence criterion.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_minfactor">minFactor</code></td>
<td>
<p>A positive numeric value specifying the minimum
step-size factor allowed on any step in the iteration.  The
increment is calculated with a Gauss-Newton algorithm and
successively halved until the residual sum of squares has been
decreased or until the step-size factor has been reduced below this
limit.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_printeval">printEval</code></td>
<td>
<p>a logical specifying whether the number of evaluations
(steps in the gradient direction taken each iteration) is printed.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_warnonly">warnOnly</code></td>
<td>
<p>a logical specifying whether <code><a href="stats.html#topic+nls">nls</a>()</code> should
return instead of signalling an error in the case of termination
before convergence.
Termination before convergence happens upon completion of <code>maxiter</code>
iterations, in the case of a singular gradient, and in the case that the
step-size factor is reduced below <code>minFactor</code>.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_scaleoffset">scaleOffset</code></td>
<td>
<p>a constant to be added to the denominator of the relative
offset convergence criterion calculation to avoid a zero divide in the case
where the fit of a model to data is very close.  The default value of
<code>0</code> keeps the legacy behaviour of <code>nls()</code>.  A value such as
<code>1</code> seems to work for problems of reasonable scale with very small
residuals.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_ndcentral">nDcentral</code></td>
<td>
<p>only when <em>numerical</em> derivatives are used:
<code><a href="base.html#topic+logical">logical</a></code> indicating if <em>central</em> differences
should be employed, i.e., <code><a href="stats.html#topic+numericDeriv">numericDeriv</a>(*, central=TRUE)</code>
be used.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_algorithm">algorithm</code></td>
<td>
<p>character string specifying the algorithm to use.
The default algorithm is a Gauss-Newton algorithm.  Other possible
values are <code>"plinear"</code> for the Golub-Pereyra algorithm for
partially linear least-squares models and <code>"port"</code> for the
&lsquo;nl2sol&rsquo; algorithm from the Port library &ndash; see the
references.  Can be abbreviated.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_ftol">ftol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
both the actual and predicted relative reductions in the sum of
squares are at most <code>ftol</code>. Therefore, <code>ftol</code> measures
the relative error desired in the sum of squares.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_ptol">ptol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
the relative error between two consecutive iterates is at most
<code>ptol</code>. Therefore, <code>ptol</code> measures the relative error
desired in the approximate solution.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_gtol">gtol</code></td>
<td>
<p>non-negative numeric. Termination occurs when
the cosine of the angle between result of <code>fn</code> evaluation
<code class="reqn">fvec</code> and any column of the Jacobian is at most <code>gtol</code>
in absolute value. Therefore, <code>gtol</code> measures the
orthogonality desired between the function vector and the
columns of the Jacobian.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_diag">diag</code></td>
<td>
<p>a list or numeric vector containing positive
entries that serve as multiplicative scale factors for the
parameters. Length of <code>diag</code> should be equal to that of
<code>par</code>. If not, user-provided <code>diag</code> is ignored and
<code>diag</code> is internally set.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_epsfcn">epsfcn</code></td>
<td>
<p>(used if <code>jac</code> is not provided) is a
numeric used in determining a suitable step for the
forward-difference approximation. This approximation assumes
that the relative errors in the functions are of the order of
<code>epsfcn</code>. If <code>epsfcn</code> is less than the machine
precision, it is assumed that the relative errors in the
functions are of the order of the machine precision.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_factor">factor</code></td>
<td>
<p>positive numeric, used in determining the
initial step bound.  This bound is set to the product of
<code>factor</code> and the <code class="reqn">|\code{diag}*\code{par}|</code> if nonzero,
or else to <code>factor</code> itself. In most cases <code>factor</code>
should lie in the interval (0.1,100). 100 is a generally
recommended value.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_maxfev">maxfev</code></td>
<td>
<p>integer; termination occurs
when the number of calls to <code>fn</code> has reached <code>maxfev</code>.
Note that <code>nls.lm</code> sets the value of <code>maxfev</code> to 
<code>100*(length(par) + 1)</code> if 
<code>maxfev = integer()</code>, where <code>par</code> is the list or
vector of parameters to be optimized.  </p>
</td></tr>
<tr><td><code id="nlsControl_+3A_nprint">nprint</code></td>
<td>
<p>is an integer; set <code>nprint</code> to be positive
to enable printing of iterates</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_solvetype">solveType</code></td>
<td>
<p>tells if &lsquo;nlm' will use nlmixr2&rsquo;s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '&quot;hessian&quot;' which will use the analytical gradients to create a
Hessian with finite differences.
</p>
<p>- '&quot;gradient&quot;' which will use the gradient and let 'nlm' calculate
the finite difference hessian
</p>
<p>- '&quot;fun&quot;' where nlm will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the &quot;ideal&quot; step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_eventtype">eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
&quot;central&quot; or &quot;forward&quot;</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_shierr">shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_shi21maxfd">shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlsControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlsControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_trace">trace</code></td>
<td>
<p>logical value indicating if a trace of the iteration
progress should be printed.  Default is <code>FALSE</code>.  If
<code>TRUE</code> the residual (weighted) sum-of-squares, the convergence
criterion and the parameter values are printed at the conclusion of
each iteration.  Note that <code><a href="base.html#topic+format">format</a>()</code> is used, so these
mostly depend on <code><a href="base.html#topic+getOption">getOption</a>("digits")</code>.
When the <code>"plinear"</code> algorithm is used, the conditional
estimates of the linear parameters are printed after the nonlinear
parameters.  When the <code>"port"</code> algorithm is used the
objective function value printed is half the residual (weighted)
sum-of-squares.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_returnnls">returnNls</code></td>
<td>
<p>logical; when TRUE, will return the nls object
instead of the nlmixr object</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlsControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="nlsControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="nlsControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="nlsControl_+3A_...">...</code></td>
<td>
<p>Additional optional arguments.  None are used at present.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nls control object
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

if (rxode2parse::.linCmtSens()) {

one.cmt &lt;- function() {
  ini({
   tka &lt;- 0.45
   tcl &lt;- log(c(0, 2.7, 100))
   tv &lt;- 3.45
   add.sd &lt;- 0.7
 })
 model({
   ka &lt;- exp(tka)
   cl &lt;- exp(tcl)
   v &lt;- exp(tv)
   linCmt() ~ add(add.sd)
 })
}

# Uses nlsLM from minpack.lm if available

fit1 &lt;- nlmixr(one.cmt, nlmixr2data::theo_sd, est="nls", nlsControl(algorithm="LM"))

# Uses port and respect parameter boundaries
fit2 &lt;- nlmixr(one.cmt, nlmixr2data::theo_sd, est="nls", nlsControl(algorithm="port"))

# You can access the underlying nls object with `$nls`
fit2$nls
}

</code></pre>

<hr>
<h2 id='nmGetDistributionSaemLines'>This is a S3 method for getting the distribution lines for a base rxode2 saem problem</h2><span id='topic+nmGetDistributionSaemLines'></span><span id='topic+nmGetDistributionSaemLines.rxUi'></span><span id='topic+nmGetDistributionSaemLines.norm'></span>

<h3>Description</h3>

<p>This is a S3 method for getting the distribution lines for a base rxode2 saem problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmGetDistributionSaemLines(line)

## S3 method for class 'rxUi'
nmGetDistributionSaemLines(line)

## S3 method for class 'norm'
nmGetDistributionSaemLines(line)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmGetDistributionSaemLines_+3A_line">line</code></td>
<td>
<p>Parsed rxode2 model environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lines for the estimation of saem
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='nmNearPD'>C++ implementation of Matrix's nearPD</h2><span id='topic+nmNearPD'></span>

<h3>Description</h3>

<p>With 'ensureSymmetry' it makes sure it is symmetric by applying 0.5*(t(x) + x) before using nmNearPD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmNearPD(
  x,
  keepDiag = FALSE,
  do2eigen = TRUE,
  doDykstra = TRUE,
  only.values = FALSE,
  ensureSymmetry = !isSymmetric(x),
  eig.tol = 1e-06,
  conv.tol = 1e-07,
  posd.tol = 1e-08,
  maxit = 100L,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmNearPD_+3A_x">x</code></td>
<td>
<p>numeric <code class="reqn">n \times n</code> approximately positive
definite matrix, typically an approximation to a correlation or
covariance matrix.  If <code>x</code> is not symmetric (and
<code>ensureSymmetry</code> is not false), <code><a href="Matrix.html#topic+symmpart">symmpart</a>(x)</code> is used.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_keepdiag">keepDiag</code></td>
<td>
<p>logical, generalizing <code>corr</code>: if <code>TRUE</code>, the
resulting matrix should have the same diagonal
(<code><a href="base.html#topic+diag">diag</a>(x)</code>) as the input matrix.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_do2eigen">do2eigen</code></td>
<td>
<p>logical indicating if a
<code><a href="sfsmisc.html#topic+posdefify">posdefify</a>()</code> eigen step should be applied to
the result of the Higham algorithm.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_dodykstra">doDykstra</code></td>
<td>
<p>logical indicating if Dykstra's correction should be
used; true by default.  If false, the algorithm is basically the
direct fixpoint iteration
<code class="reqn">Y_k = P_U(P_S(Y_{k-1}))</code>.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_only.values">only.values</code></td>
<td>
<p>logical; if <code>TRUE</code>, the result is just the
vector of eigenvalues of the approximating matrix.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_ensuresymmetry">ensureSymmetry</code></td>
<td>
<p>logical; by default, <code><a href="Matrix.html#topic+symmpart">symmpart</a>(x)</code>
is used whenever <code>isSymmetric(x)</code> is not true.  The user
can explicitly set this to <code>TRUE</code> or <code>FALSE</code>, saving the
symmetry test. <em>Beware</em> however that setting it <code>FALSE</code>
for an <b>a</b>symmetric input <code>x</code>, is typically nonsense!</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_eig.tol">eig.tol</code></td>
<td>
<p>defines relative positiveness of eigenvalues compared
to largest one, <code class="reqn">\lambda_1</code>. Eigenvalues <code class="reqn">\lambda_k</code> are
treated as if zero when <code class="reqn">\lambda_k / \lambda_1 \le eig.tol</code>.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_conv.tol">conv.tol</code></td>
<td>
<p>convergence tolerance for Higham algorithm.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_posd.tol">posd.tol</code></td>
<td>
<p>tolerance for enforcing positive definiteness (in the
final <code>posdefify</code> step when <code>do2eigen</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations allowed.</p>
</td></tr>
<tr><td><code id="nmNearPD_+3A_trace">trace</code></td>
<td>
<p>logical or integer specifying if convergence monitoring
should be traced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implements the algorithm of Higham (2002), and then (if
<code>do2eigen</code> is true) forces positive definiteness using code from
<code><a href="sfsmisc.html#topic+posdefify">posdefify</a></code>.  The algorithm of Knol and ten
Berge (1989) (not implemented here) is more general in that it
allows constraints to (1) fix some rows (and columns) of the matrix and
(2) force the smallest eigenvalue to have a certain value.
</p>
<p>Note that setting <code>corr = TRUE</code> just sets <code>diag(.) &lt;- 1</code>
within the algorithm.
</p>
<p>Higham (2002) uses Dykstra's correction, but the version by Jens
Oehlschlägel did not use it (accidentally),
and still gave reasonable results; this simplification, now only
used if <code>doDykstra = FALSE</code>,
was active in <code>nearPD()</code> up to Matrix version 0.999375-40.
</p>


<h3>Value</h3>

<p>If <code>only.values = TRUE</code>, a numeric vector of eigenvalues of the
approximating matrix;
Otherwise, as by default, an S3 object of <code><a href="base.html#topic+class">class</a></code>
<code>"nearPD"</code>, basically a list with components
</p>
<table>
<tr><td><code>mat</code></td>
<td>
<p>a matrix of class <code><a href="Matrix.html#topic+dpoMatrix-class">dpoMatrix</a></code>, the
computed positive-definite matrix.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>numeric vector of eigenvalues of <code>mat</code>.</p>
</td></tr>
<tr><td><code>corr</code></td>
<td>
<p>logical, just the argument <code>corr</code>.</p>
</td></tr>
<tr><td><code>normF</code></td>
<td>
<p>the Frobenius norm (<code><a href="Matrix.html#topic+norm">norm</a>(x-X, "F")</code>) of the
difference between the original and the resulting matrix.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>number of iterations needed.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical indicating if iterations converged.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jens Oehlschlägel donated a first version.
Subsequent changes by the Matrix package authors.
</p>


<h3>References</h3>


<p>Cheng, Sheung Hun and Higham, Nick (1998)
A Modified Cholesky Algorithm Based on a Symmetric Indefinite Factorization;
<em>SIAM J. Matrix Anal.\ Appl.</em>, <b>19</b>, 1097&ndash;1110.
</p>
<p>Knol DL, ten Berge JMF (1989)
Least-squares approximation of an improper correlation matrix by a
proper one.
<em>Psychometrika</em> <b>54</b>, 53&ndash;61.
</p>
<p>Higham, Nick (2002)
Computing the nearest correlation matrix - a problem from finance;
<em>IMA Journal of Numerical Analysis</em> <b>22</b>, 329&ndash;343.
</p>


<h3>See Also</h3>

<p>A first version of this (with non-optional <code>corr=TRUE</code>)
has been available as <code><a href="sfsmisc.html#topic+nearcor">nearcor</a>()</code>; and
more simple versions with a similar purpose
<code><a href="sfsmisc.html#topic+posdefify">posdefify</a>()</code>, both from package <span class="pkg">sfsmisc</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(27)
m &lt;- matrix(round(rnorm(25),2), 5, 5)
m &lt;- m + t(m)
diag(m) &lt;- pmax(0, diag(m)) + 1
(m &lt;- round(cov2cor(m), 2))

near.m &lt;- nmNearPD(m)
round(near.m, 2)
norm(m - near.m) # 1.102 / 1.08

round(nmNearPD(m, only.values=TRUE), 9)

## A longer example, extended from Jens' original,
## showing the effects of some of the options:

pr &lt;- matrix(c(1,     0.477, 0.644, 0.478, 0.651, 0.826,
               0.477, 1,     0.516, 0.233, 0.682, 0.75,
               0.644, 0.516, 1,     0.599, 0.581, 0.742,
               0.478, 0.233, 0.599, 1,     0.741, 0.8,
               0.651, 0.682, 0.581, 0.741, 1,     0.798,
               0.826, 0.75,  0.742, 0.8,   0.798, 1),
               nrow = 6, ncol = 6)

nc  &lt;- nmNearPD(pr)

</code></pre>

<hr>
<h2 id='nmObjGet'>Get an item from a nlmixr core object</h2><span id='topic+nmObjGet'></span><span id='topic+nmObjGet.default'></span><span id='topic+nmObjGet.modelName'></span><span id='topic+nmObjGet.cor'></span><span id='topic+nmObjGet.omegaR'></span><span id='topic+nmObjGet.phiR'></span><span id='topic+nmObjGet.phiSE'></span><span id='topic+nmObjGet.phiRSE'></span><span id='topic+nmObjGet.dataSav'></span><span id='topic+nmObjGet.idLvl'></span><span id='topic+nmObjGet.covLvl'></span><span id='topic+nmObjGet.parHist'></span><span id='topic+nmObjGet.parHistStacked'></span><span id='topic+nmObjGet.md5'></span><span id='topic+nmObjGet.notes'></span><span id='topic+nmObjGet.sigma'></span><span id='topic+nmObjGet.coefficients'></span><span id='topic+nmObjGet.env'></span><span id='topic+nmObjGet.condition'></span><span id='topic+nmObjGet.simInfo'></span><span id='topic+nmObjGet.seed'></span><span id='topic+nmObjGet.saemCfg'></span><span id='topic+nmObjGet.estimationModel'></span><span id='topic+nmObjGet.atol'></span><span id='topic+nmObjGet.rtol'></span><span id='topic+nmObjGet.maxstepsOde'></span><span id='topic+nmObjGet.hmin'></span><span id='topic+nmObjGet.hmax'></span><span id='topic+nmObjGet.hini'></span><span id='topic+nmObjGet.maxordn'></span><span id='topic+nmObjGet.maxords'></span><span id='topic+nmObjGet.methodOde'></span><span id='topic+nmObjGet.covsInterpolation'></span><span id='topic+nmObjGet.control'></span><span id='topic+nmObjGet.simulationModel'></span><span id='topic+nmObjGet.rxControl'></span><span id='topic+nmObjGet.rxControlWithVar'></span><span id='topic+nmObjGet.saemDopredIpred'></span><span id='topic+nmObjGet.saemDopredPred'></span>

<h3>Description</h3>

<p>Get an item from a nlmixr core object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjGet(x, ...)

## Default S3 method:
nmObjGet(x, ...)

## S3 method for class 'modelName'
nmObjGet(x, ...)

## S3 method for class 'cor'
nmObjGet(x, ...)

## S3 method for class 'omegaR'
nmObjGet(x, ...)

## S3 method for class 'phiR'
nmObjGet(x, ...)

## S3 method for class 'phiSE'
nmObjGet(x, ...)

## S3 method for class 'phiRSE'
nmObjGet(x, ...)

## S3 method for class 'dataSav'
nmObjGet(x, ...)

## S3 method for class 'idLvl'
nmObjGet(x, ...)

## S3 method for class 'covLvl'
nmObjGet(x, ...)

## S3 method for class 'parHist'
nmObjGet(x, ...)

## S3 method for class 'parHistStacked'
nmObjGet(x, ...)

## S3 method for class 'md5'
nmObjGet(x, ...)

## S3 method for class 'notes'
nmObjGet(x, ...)

## S3 method for class 'sigma'
nmObjGet(x, ...)

## S3 method for class 'coefficients'
nmObjGet(x, ...)

## S3 method for class 'env'
nmObjGet(x, ...)

## S3 method for class 'condition'
nmObjGet(x, ...)

## S3 method for class 'simInfo'
nmObjGet(x, ...)

## S3 method for class 'seed'
nmObjGet(x, ...)

## S3 method for class 'saemCfg'
nmObjGet(x, ...)

## S3 method for class 'estimationModel'
nmObjGet(x, ...)

## S3 method for class 'atol'
nmObjGet(x, ...)

## S3 method for class 'rtol'
nmObjGet(x, ...)

## S3 method for class 'maxstepsOde'
nmObjGet(x, ...)

## S3 method for class 'hmin'
nmObjGet(x, ...)

## S3 method for class 'hmax'
nmObjGet(x, ...)

## S3 method for class 'hini'
nmObjGet(x, ...)

## S3 method for class 'maxordn'
nmObjGet(x, ...)

## S3 method for class 'maxords'
nmObjGet(x, ...)

## S3 method for class 'methodOde'
nmObjGet(x, ...)

## S3 method for class 'covsInterpolation'
nmObjGet(x, ...)

## S3 method for class 'control'
nmObjGet(x, ...)

## S3 method for class 'simulationModel'
nmObjGet(x, ...)

## S3 method for class 'rxControl'
nmObjGet(x, ...)

## S3 method for class 'rxControlWithVar'
nmObjGet(x, ...)

## S3 method for class 'saemDopredIpred'
nmObjGet(x, ...)

## S3 method for class 'saemDopredPred'
nmObjGet(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGet_+3A_x">x</code></td>
<td>
<p>A specialized list with:
- First argument is a nlmixrFitCore environment
- Second argument is if the exact argument is requested
- The class would be the requested argument name followed by the class &quot;nmObjGet&quot;</p>
</td></tr>
<tr><td><code id="nmObjGet_+3A_...">...</code></td>
<td>
<p>Other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of argument or NULL
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nmObjGetControl.bobyqa'>Get control object from fit</h2><span id='topic+nmObjGetControl.bobyqa'></span><span id='topic+nmObjGetControl.lbfgsb3c'></span><span id='topic+nmObjGetControl.n1qn1'></span><span id='topic+nmObjGetControl.newuoa'></span><span id='topic+nmObjGetControl.nlm'></span><span id='topic+nmObjGetControl.nlme'></span><span id='topic+nmObjGetControl.nlminb'></span><span id='topic+nmObjGetControl.nls'></span><span id='topic+nmObjGetControl'></span><span id='topic+nmObjGetControl.focei'></span><span id='topic+nmObjGetControl.foce'></span><span id='topic+nmObjGetControl.foi'></span><span id='topic+nmObjGetControl.fo'></span><span id='topic+nmObjGetControl.posthoc'></span><span id='topic+nmObjGetControl.saem'></span><span id='topic+nmObjGetControl.default'></span><span id='topic+nmObjGetControl.optim'></span><span id='topic+nmObjGetControl.uobyqa'></span>

<h3>Description</h3>

<p>Get control object from fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bobyqa'
nmObjGetControl(x, ...)

## S3 method for class 'lbfgsb3c'
nmObjGetControl(x, ...)

## S3 method for class 'n1qn1'
nmObjGetControl(x, ...)

## S3 method for class 'newuoa'
nmObjGetControl(x, ...)

## S3 method for class 'nlm'
nmObjGetControl(x, ...)

## S3 method for class 'nlme'
nmObjGetControl(x, ...)

## S3 method for class 'nlminb'
nmObjGetControl(x, ...)

## S3 method for class 'nls'
nmObjGetControl(x, ...)

nmObjGetControl(x, ...)

## S3 method for class 'focei'
nmObjGetControl(x, ...)

## S3 method for class 'foce'
nmObjGetControl(x, ...)

## S3 method for class 'foi'
nmObjGetControl(x, ...)

## S3 method for class 'fo'
nmObjGetControl(x, ...)

## S3 method for class 'posthoc'
nmObjGetControl(x, ...)

## S3 method for class 'saem'
nmObjGetControl(x, ...)

## Default S3 method:
nmObjGetControl(x, ...)

## S3 method for class 'optim'
nmObjGetControl(x, ...)

## S3 method for class 'uobyqa'
nmObjGetControl(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetControl.bobyqa_+3A_x">x</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
<tr><td><code id="nmObjGetControl.bobyqa_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Control object of estimation method
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nmObjGetData.addCwres'>Get an item from a nlmixr2FitData object</h2><span id='topic+nmObjGetData.addCwres'></span><span id='topic+nmObjGetData'></span><span id='topic+nmObjGetData.dataMergeLeft'></span><span id='topic+nmObjGetData.dataMergeRight'></span><span id='topic+nmObjGetData.dataMergeInner'></span><span id='topic+nmObjGetData.dataMergeFull'></span><span id='topic+nmObjGetData.fitMergeLeft'></span><span id='topic+nmObjGetData.fitMergeRight'></span><span id='topic+nmObjGetData.fitMergeInner'></span><span id='topic+nmObjGetData.fitMergeFull'></span>

<h3>Description</h3>

<p>Get an item from a nlmixr2FitData object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'addCwres'
nmObjGetData(x, ...)

nmObjGetData(x, ...)

## S3 method for class 'dataMergeLeft'
nmObjGetData(x, ...)

## S3 method for class 'dataMergeRight'
nmObjGetData(x, ...)

## S3 method for class 'dataMergeInner'
nmObjGetData(x, ...)

## S3 method for class 'dataMergeFull'
nmObjGetData(x, ...)

## S3 method for class 'fitMergeLeft'
nmObjGetData(x, ...)

## S3 method for class 'fitMergeRight'
nmObjGetData(x, ...)

## S3 method for class 'fitMergeInner'
nmObjGetData(x, ...)

## S3 method for class 'fitMergeFull'
nmObjGetData(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetData.addCwres_+3A_x">x</code></td>
<td>
<p>A specialized list with:
- First argument is a nlmixr2FitData object
- Second argument is if the exact argument is requested
- The class would be the requested argument name followed by the class &quot;nmObjGet&quot;</p>
</td></tr>
<tr><td><code id="nmObjGetData.addCwres_+3A_...">...</code></td>
<td>
<p>Other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of argument or NULL
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nmObjGetEstimationModel'>Get the estimation model for a fit object depending on the object type</h2><span id='topic+nmObjGetEstimationModel'></span>

<h3>Description</h3>

<p>By default it gets the focei models if available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjGetEstimationModel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetEstimationModel_+3A_x">x</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the estimation '$model' for the estimation type
</p>

<hr>
<h2 id='nmObjGetFoceiControl.nlme'>Method for getting focei compatible control object from nlmixr object</h2><span id='topic+nmObjGetFoceiControl.nlme'></span><span id='topic+nmObjGetFoceiControl'></span><span id='topic+nmObjGetFoceiControl.default'></span><span id='topic+nmObjGetFoceiControl.saem'></span>

<h3>Description</h3>

<p>Method for getting focei compatible control object from nlmixr object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlme'
nmObjGetFoceiControl(x, ...)

nmObjGetFoceiControl(x, ...)

## Default S3 method:
nmObjGetFoceiControl(x, ...)

## S3 method for class 'saem'
nmObjGetFoceiControl(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetFoceiControl.nlme_+3A_x">x</code></td>
<td>
<p>nlmixr composed fit object</p>
</td></tr>
<tr><td><code id="nmObjGetFoceiControl.nlme_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>foceiControl translated from current control
</p>

<hr>
<h2 id='nmObjGetIpredModel'>Get the ipred model for a fit object depending on the object type</h2><span id='topic+nmObjGetIpredModel'></span><span id='topic+nmObjGetIpredModel.saem'></span><span id='topic+nmObjGetIpredModel.default'></span><span id='topic+nmObjGetEstimationModel.saem'></span><span id='topic+nmObjGetEstimationModel.default'></span>

<h3>Description</h3>

<p>By default it gets the focei models if available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjGetIpredModel(x)

## S3 method for class 'saem'
nmObjGetIpredModel(x)

## Default S3 method:
nmObjGetIpredModel(x)

## S3 method for class 'saem'
nmObjGetEstimationModel(x)

## Default S3 method:
nmObjGetEstimationModel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetIpredModel_+3A_x">x</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ipred 'rxode2' model
</p>

<hr>
<h2 id='nmObjGetPredOnly'>Get the pred-only model for a fit depending on the object type</h2><span id='topic+nmObjGetPredOnly'></span><span id='topic+nmObjGetPredOnly.saem'></span><span id='topic+nmObjGetPredOnly.default'></span>

<h3>Description</h3>

<p>By default it gets the focei models if available
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjGetPredOnly(x)

## S3 method for class 'saem'
nmObjGetPredOnly(x)

## Default S3 method:
nmObjGetPredOnly(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetPredOnly_+3A_x">x</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>rxode2 pred-only model
</p>

<hr>
<h2 id='nmObjGetRxSolve'>Get an option for the estimation method</h2><span id='topic+nmObjGetRxSolve'></span><span id='topic+nmObjGetRxSolve.default'></span>

<h3>Description</h3>

<p>By default it gets the focei models if available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjGetRxSolve(x, what)

## Default S3 method:
nmObjGetRxSolve(x, what)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjGetRxSolve_+3A_x">x</code></td>
<td>
<p>nlmixr fit object in a list.  The class is the
estimation method used.</p>
</td></tr>
<tr><td><code id="nmObjGetRxSolve_+3A_what">what</code></td>
<td>
<p>What part of the rx solve are you attempting to get?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimation option based on 'what', for example
'nlmixrObjGetRxSolve(x, &quot;atol&quot;)' will get a double vector of
absolute tolerances
</p>

<hr>
<h2 id='nmObjHandleControlObject.bobyqaControl'>Handle the control object</h2><span id='topic+nmObjHandleControlObject.bobyqaControl'></span><span id='topic+nmObjHandleControlObject.lbfgsb3cControl'></span><span id='topic+nmObjHandleControlObject.n1qn1Control'></span><span id='topic+nmObjHandleControlObject.newuoaControl'></span><span id='topic+nmObjHandleControlObject.nlmControl'></span><span id='topic+nmObjHandleControlObject.nlmeControl'></span><span id='topic+nmObjHandleControlObject.nlminbControl'></span><span id='topic+nmObjHandleControlObject.nlsControl'></span><span id='topic+nmObjHandleControlObject'></span><span id='topic+nmObjHandleControlObject.foceiControl'></span><span id='topic+nmObjHandleControlObject.saemControl'></span><span id='topic+nmObjHandleControlObject.default'></span><span id='topic+nmObjHandleControlObject.optimControl'></span><span id='topic+nmObjHandleControlObject.uobyqaControl'></span>

<h3>Description</h3>

<p>Handle the control object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bobyqaControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'lbfgsb3cControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'n1qn1Control'
nmObjHandleControlObject(control, env)

## S3 method for class 'newuoaControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'nlmControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'nlmeControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'nlminbControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'nlsControl'
nmObjHandleControlObject(control, env)

nmObjHandleControlObject(control, env)

## S3 method for class 'foceiControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'saemControl'
nmObjHandleControlObject(control, env)

## Default S3 method:
nmObjHandleControlObject(control, env)

## S3 method for class 'optimControl'
nmObjHandleControlObject(control, env)

## S3 method for class 'uobyqaControl'
nmObjHandleControlObject(control, env)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjHandleControlObject.bobyqaControl_+3A_control">control</code></td>
<td>
<p>Control object</p>
</td></tr>
<tr><td><code id="nmObjHandleControlObject.bobyqaControl_+3A_env">env</code></td>
<td>
<p>fit environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing, called for side effects
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='nmObjHandleModelObject'>Handle Model Object</h2><span id='topic+nmObjHandleModelObject'></span><span id='topic+nmObjHandleModelObject.saemModelList'></span><span id='topic+nmObjHandleModelObject.foceiModelList'></span><span id='topic+nmObjHandleModelObject.default'></span>

<h3>Description</h3>

<p>Handle Model Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjHandleModelObject(model, env)

## S3 method for class 'saemModelList'
nmObjHandleModelObject(model, env)

## S3 method for class 'foceiModelList'
nmObjHandleModelObject(model, env)

## Default S3 method:
nmObjHandleModelObject(model, env)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjHandleModelObject_+3A_model">model</code></td>
<td>
<p>model list should have at least:
</p>
<p>- 'predOnly' &ndash; this is the prediction model with all the left
handed equations added so they will be added the table.  The
model should have 'rx_pred_', the model based prediction, as the
first defined lhs component.  The second component should be
'rx_r_', the variance of the prediction.  These variables may
change based on distribution type.  In additional all
interesting calculated variables should be included.
</p>
<p>- 'predNoLhs' &ndash; This is the prediction model.  It only has the
prediction and no left handed equations.</p>
</td></tr>
<tr><td><code id="nmObjHandleModelObject_+3A_env">env</code></td>
<td>
<p>Environment for the fit information</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This returns the '$model' object for a fit.  It is a s3
method because it may be different between different model types
</p>

<hr>
<h2 id='nmObjUiSetCompressed'>Set if the nlmixr2 object will return a compressed ui</h2><span id='topic+nmObjUiSetCompressed'></span>

<h3>Description</h3>

<p>Set if the nlmixr2 object will return a compressed ui
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmObjUiSetCompressed(type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmObjUiSetCompressed_+3A_type">type</code></td>
<td>
<p>is a boolean indicating if the compressed ui will be
returned ('TRUE') or not be returned ('FALSE')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisible logical type
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nmObjUiSetCompressed(FALSE) # now the $ui will return an environment
nmObjUiSetCompressed(TRUE) # now the $ui will return a compressed value

</code></pre>

<hr>
<h2 id='nmsimplex'>Nelder-Mead simplex search</h2><span id='topic+nmsimplex'></span>

<h3>Description</h3>

<p>Nelder-Mead simplex search
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmsimplex(start, fr, rho = NULL, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nmsimplex_+3A_start">start</code></td>
<td>
<p>initials</p>
</td></tr>
<tr><td><code id="nmsimplex_+3A_fr">fr</code></td>
<td>
<p>objective function</p>
</td></tr>
<tr><td><code id="nmsimplex_+3A_rho">rho</code></td>
<td>
<p>evaluation environment</p>
</td></tr>
<tr><td><code id="nmsimplex_+3A_control">control</code></td>
<td>
<p>additional optimization options</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of ...
</p>

<hr>
<h2 id='nmSuppressMsg'>Respect suppress messages for nlmixr2 C functions</h2><span id='topic+nmSuppressMsg'></span>

<h3>Description</h3>

<p>This turns on the silent REprintf in C when 'suppressMessages()' is
turned on. This makes the 'REprintf' act like 'messages' in R,
they can be suppressed with 'suppressMessages()'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmSuppressMsg()
</code></pre>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# nmSupressMsg() is called with nlmixr2()

# In nlmixr2, we use REprintf so that interrupted threads do not crash R
# if there is a user interrupt. This isn't captured by R's messages, but
# This interface allows the `suppressMessages()` to suppress the C printing
# as well

# If you  want to suppress messages from nlmixr2 in other packages, you can use
# this function
</code></pre>

<hr>
<h2 id='ofv'>Return the objective function</h2><span id='topic+ofv'></span>

<h3>Description</h3>

<p>Return the objective function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ofv(x, type, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ofv_+3A_x">x</code></td>
<td>
<p>object to return objective function value</p>
</td></tr>
<tr><td><code id="ofv_+3A_type">type</code></td>
<td>
<p>Objective function type value to retrieve or add.
</p>

<ul>
<li><p>focei For most models you can specify &quot;focei&quot; and it will
add the focei objective function.
</p>
</li>
<li><p>nlme This switches/chooses the nlme objective function if
applicable.  This objective function cannot be added if it
isn't present.
</p>
</li>
<li><p>fo FO objective function value. Cannot be generated
</p>
</li>
<li><p>foce FOCE object function value. Cannot be generated
</p>
</li>
<li><p>laplace# This adds/retrieves  the Laplace objective function value.
The <code>#</code> represents the number of standard deviations
requested when expanding the Gaussian Quadrature.  This can
currently only be used with saem fits.
</p>
</li>
<li><p>gauss#.# This adds/retrieves the Gaussian Quadrature
approximation of the objective function.  The first number is the
number of nodes to use in the approximation. The second number is
the number of standard deviations to expand upon.
</p>
</li></ul>
</td></tr>
<tr><td><code id="ofv_+3A_...">...</code></td>
<td>
<p>Other arguments sent to ofv for other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Objective function value
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='optimControl'>nlmixr2 optim defaults</h2><span id='topic+optimControl'></span>

<h3>Description</h3>

<p>nlmixr2 optim defaults
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimControl(
  method = c("Nelder-Mead", "BFGS", "CG", "L-BFGS-B", "SANN", "Brent"),
  trace = 0,
  fnscale = 1,
  parscale = 1,
  ndeps = 0.001,
  maxit = 10000,
  abstol = 1e-08,
  reltol = 1e-08,
  alpha = 1,
  beta = 0.5,
  gamma = 2,
  REPORT = NULL,
  warn.1d.NelderMead = TRUE,
  type = NULL,
  lmm = 5,
  factr = 1e+07,
  pgtol = 0,
  temp = 10,
  tmax = 10,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  eventType = c("central", "forward"),
  shiErr = (.Machine$double.eps)^(1/3),
  shi21maxFD = 20L,
  solveType = c("grad", "fun"),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  gradTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  returnOptim = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", "optim", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimControl_+3A_method">method</code></td>
<td>
<p>The method to be used. See &lsquo;Details&rsquo;.  Can be abbreviated.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer. If positive, tracing information
on the progress of the optimization is produced. Higher values
may produce more tracing information: for method '&quot;L-BFGS-B&quot;',
there are six levels of tracing. See 'optim()' for more
information</p>
</td></tr>
<tr><td><code id="optimControl_+3A_fnscale">fnscale</code></td>
<td>
<p>An overall scaling to be applied to the value of 'fn'
and 'gr' during optimization. If negative, turns the problem
into a maximization problem. Optimization is performed on
'fn(par)/fnscale'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_parscale">parscale</code></td>
<td>
<p>A vector of scaling values for the parameters.
Optimization is performed on 'par/parscale' and these should be
comparable in the sense that a unit change in any element
produces about a unit change in the scaled value.  Not used (nor
needed) for 'method = &quot;Brent&quot;'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_ndeps">ndeps</code></td>
<td>
<p>A vector of step sizes for the finite-difference
approximation to the gradient, on 'par/parscale' scale.  Defaults
to '1e-3'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations. Defaults to '100'
for the derivative-based methods, and '500' for '&quot;Nelder-Mead&quot;'.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_abstol">abstol</code></td>
<td>
<p>The absolute convergence tolerance. Only useful for
non-negative functions, as a tolerance for reaching zero.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_reltol">reltol</code></td>
<td>
<p>Relative convergence tolerance.  The algorithm stops
if it is unable to reduce the value by a factor of 'reltol *
(abs(val) + reltol)' at a step</p>
</td></tr>
<tr><td><code id="optimControl_+3A_alpha">alpha</code></td>
<td>
<p>Reflection factor for the '&quot;Nelder-Mead&quot;' method.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_beta">beta</code></td>
<td>
<p>Contraction factor for the '&quot;Nelder-Mead&quot;' method</p>
</td></tr>
<tr><td><code id="optimControl_+3A_gamma">gamma</code></td>
<td>
<p>Expansion  factor for the '&quot;Nelder-Mead&quot;' method</p>
</td></tr>
<tr><td><code id="optimControl_+3A_report">REPORT</code></td>
<td>
<p>The frequency of reports for the '&quot;BFGS&quot;',
'&quot;L-BFGS-B&quot;' and '&quot;SANN&quot;' methods if 'control$trace' is
positive. Defaults to every 10 iterations for '&quot;BFGS&quot;' and
'&quot;L-BFGS-B&quot;', or every 100 temperatures for '&quot;SANN&quot;'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_warn.1d.neldermead">warn.1d.NelderMead</code></td>
<td>
<p>a logical indicating if the (default)
'&quot;Nelder-Mead&quot;' method should signal a warning when used for
one-dimensional minimization.  As the warning is sometimes
inappropriate, you can suppress it by setting this option to
'FALSE'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_type">type</code></td>
<td>
<p>for the conjugate-gradients method.  Takes value '1'
for the Fletcher-Reeves update, '2' for Polak-Ribiere and '3' for
Beale-Sorenson.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_lmm">lmm</code></td>
<td>
<p>is an integer giving the number of BFGS updates retained
in the '&quot;L-BFGS-B&quot;' method, It defaults to '5'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_factr">factr</code></td>
<td>
<p>controls the convergence of the '&quot;L-BFGS-B&quot;' method.
Convergence occurs when the reduction in the objective is within
this factor of the machine tolerance. Default is '1e7', that is a
tolerance of about '1e-8'.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_pgtol">pgtol</code></td>
<td>
<p>helps control the convergence of the ‘&quot;L-BFGS-B&quot;’
method.  It is a tolerance on the projected gradient in the
current search direction. This defaults to zero, when the check
is suppressed</p>
</td></tr>
<tr><td><code id="optimControl_+3A_temp">temp</code></td>
<td>
<p>controls the '&quot;SANN&quot;' method. It is the starting
temperature for the cooling schedule. Defaults to '10'.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_tmax">tmax</code></td>
<td>
<p>is the number of function evaluations at each
temperature for the '&quot;SANN&quot;' method. Defaults to '10'.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="optimControl_+3A_eventtype">eventType</code></td>
<td>
<p>Event gradient type for dosing events; Can be
&quot;central&quot; or &quot;forward&quot;</p>
</td></tr>
<tr><td><code id="optimControl_+3A_shierr">shiErr</code></td>
<td>
<p>This represents the epsilon when optimizing the ideal
step size for numeric differentiation using the Shi2021 method</p>
</td></tr>
<tr><td><code id="optimControl_+3A_shi21maxfd">shi21maxFD</code></td>
<td>
<p>The maximum number of steps for the optimization
of the forward difference step size when using dosing events (lag
time, modeled duration/rate and bioavailability)</p>
</td></tr>
<tr><td><code id="optimControl_+3A_solvetype">solveType</code></td>
<td>
<p>tells if &lsquo;optim' will use nlmixr2&rsquo;s analytical
gradients when available (finite differences will be used for
event-related parameters like parameters controlling lag time,
duration/rate of infusion, and modeled bioavailability). This can
be:
</p>
<p>- '&quot;gradient&quot;' which will use the gradient and let 'optim' calculate
the finite difference hessian
</p>
<p>- '&quot;fun&quot;' where optim will calculate both the finite difference
gradient and the finite difference Hessian
</p>
<p>When using nlmixr2's finite differences, the &quot;ideal&quot; step size for
either central or forward differences are optimized for with the
Shi2021 method which may give more accurate derivatives
</p>
<p>These are only applied in the gradient based methods: &quot;BFGS&quot;, &quot;CG&quot;,
&quot;L-BFGS-B&quot;</p>
</td></tr>
<tr><td><code id="optimControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="optimControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="optimControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="optimControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="optimControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_gradto">gradTo</code></td>
<td>
<p>this is the factor that the gradient is scaled to
before optimizing.  This only works with
scaleType=&quot;nlmixr2&quot;.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_returnoptim">returnOptim</code></td>
<td>
<p>logical; when TRUE this will return the optim
list instead of the nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="optimControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="optimControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="optimControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="optimControl_+3A_covmethod">covMethod</code></td>
<td>
<p>allows selection of &quot;r&quot;, which uses nlmixr2's
'nlmixr2Hess()' for the hessian calculation or &quot;optim&quot; which uses
the hessian from 'stats::optim(.., hessian=TRUE)'</p>
</td></tr>
<tr><td><code id="optimControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="optimControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="optimControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="optimControl_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>fn</code> and <code>gr</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>optimControl object for nlmixr2
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="optim", optimControl(method="BFGS"))
fit2

</code></pre>

<hr>
<h2 id='print.saemFit'>Print an SAEM model fit summary</h2><span id='topic+print.saemFit'></span>

<h3>Description</h3>

<p>Print an SAEM model fit summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'saemFit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.saemFit_+3A_x">x</code></td>
<td>
<p>a saemFit object</p>
</td></tr>
<tr><td><code id="print.saemFit_+3A_...">...</code></td>
<td>
<p>others</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span><span id='topic+rxode2'></span><span id='topic+as.rxUi'></span><span id='topic+rxode'></span><span id='topic+RxODE'></span><span id='topic+ini'></span><span id='topic+model'></span><span id='topic+lotri'></span><span id='topic+logit'></span><span id='topic+expit'></span><span id='topic+probit'></span><span id='topic+probitInv'></span><span id='topic+rxSolve'></span><span id='topic+rxClean'></span><span id='topic+rxCat'></span><span id='topic+nlme'></span><span id='topic+ACF'></span><span id='topic+VarCorr'></span><span id='topic+getVarCov'></span><span id='topic+augPred'></span><span id='topic+fixef'></span><span id='topic+fixed.effects'></span><span id='topic+ranef'></span><span id='topic+random.effects'></span><span id='topic+eventTable'></span><span id='topic+add.dosing'></span><span id='topic+add.sampling'></span><span id='topic+pdDiag'></span><span id='topic+pdSymm'></span><span id='topic+pdLogChol'></span><span id='topic+pdIdent'></span><span id='topic+pdCompSymm'></span><span id='topic+pdBlocked'></span><span id='topic+pdNatural'></span><span id='topic+pdConstruct'></span><span id='topic+pdFactor'></span><span id='topic+pdMat'></span><span id='topic+pdMatrix'></span><span id='topic+reStruct'></span><span id='topic+varWeights'></span><span id='topic+varPower'></span><span id='topic+varFixed'></span><span id='topic+varFunc'></span><span id='topic+varExp'></span><span id='topic+varConstPower'></span><span id='topic+varIdent'></span><span id='topic+varComb'></span><span id='topic+groupedData'></span><span id='topic+getData'></span><span id='topic+et'></span><span id='topic+rxParams'></span><span id='topic+rxParam'></span><span id='topic+geom_cens'></span><span id='topic+geom_amt'></span><span id='topic+stat_cens'></span><span id='topic+stat_amt'></span><span id='topic+rxControl'></span><span id='topic+rxModelVars'></span><span id='topic+rxLhs'></span><span id='topic+rxState'></span><span id='topic+rxInit'></span><span id='topic+rxModelVarsS3'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
<dt>nlme</dt><dd><p><code><a href="nlme.html#topic+ACF">ACF</a></code>, <code><a href="nlme.html#topic+augPred">augPred</a></code>, <code><a href="nlme.html#topic+fixed.effects">fixed.effects</a></code>, <code><a href="nlme.html#topic+fixed.effects">fixef</a></code>, <code><a href="nlme.html#topic+getData">getData</a></code>, <code><a href="nlme.html#topic+getVarCov">getVarCov</a></code>, <code><a href="nlme.html#topic+groupedData">groupedData</a></code>, <code><a href="nlme.html#topic+nlme">nlme</a></code>, <code><a href="nlme.html#topic+pdBlocked">pdBlocked</a></code>, <code><a href="nlme.html#topic+pdCompSymm">pdCompSymm</a></code>, <code><a href="nlme.html#topic+pdConstruct">pdConstruct</a></code>, <code><a href="nlme.html#topic+pdDiag">pdDiag</a></code>, <code><a href="nlme.html#topic+pdFactor">pdFactor</a></code>, <code><a href="nlme.html#topic+pdIdent">pdIdent</a></code>, <code><a href="nlme.html#topic+pdLogChol">pdLogChol</a></code>, <code><a href="nlme.html#topic+pdMat">pdMat</a></code>, <code><a href="nlme.html#topic+pdMatrix">pdMatrix</a></code>, <code><a href="nlme.html#topic+pdNatural">pdNatural</a></code>, <code><a href="nlme.html#topic+pdSymm">pdSymm</a></code>, <code><a href="nlme.html#topic+random.effects">random.effects</a></code>, <code><a href="nlme.html#topic+random.effects">ranef</a></code>, <code><a href="nlme.html#topic+reStruct">reStruct</a></code>, <code><a href="nlme.html#topic+varComb">varComb</a></code>, <code><a href="nlme.html#topic+varConstPower">varConstPower</a></code>, <code><a href="nlme.html#topic+VarCorr">VarCorr</a></code>, <code><a href="nlme.html#topic+varExp">varExp</a></code>, <code><a href="nlme.html#topic+varFixed">varFixed</a></code>, <code><a href="nlme.html#topic+varFunc">varFunc</a></code>, <code><a href="nlme.html#topic+varIdent">varIdent</a></code>, <code><a href="nlme.html#topic+varPower">varPower</a></code>, <code><a href="nlme.html#topic+varWeights">varWeights</a></code></p>
</dd>
<dt>rxode2</dt><dd><p><code><a href="rxode2.html#topic+reexports">add.dosing</a></code>, <code><a href="rxode2.html#topic+reexports">add.sampling</a></code>, <code><a href="rxode2.html#topic+as.rxUi">as.rxUi</a></code>, <code><a href="rxode2.html#topic+reexports">et</a></code>, <code><a href="rxode2.html#topic+reexports">et</a></code>, <code><a href="rxode2.html#topic+reexports">eventTable</a></code>, <code><a href="rxode2.html#topic+logit">expit</a></code>, <code><a href="rxode2.html#topic+stat_amt">geom_amt</a></code>, <code><a href="rxode2.html#topic+stat_cens">geom_cens</a></code>, <code><a href="rxode2.html#topic+ini">ini</a></code>, <code><a href="rxode2.html#topic+logit">logit</a></code>, <code><a href="rxode2.html#topic+reexports">lotri</a></code>, <code><a href="rxode2.html#topic+model">model</a></code>, <code><a href="rxode2.html#topic+probit">probit</a></code>, <code><a href="rxode2.html#topic+probit">probitInv</a></code>, <code><a href="rxode2.html#topic+rxCat">rxCat</a></code>, <code><a href="rxode2.html#topic+rxClean">rxClean</a></code>, <code><a href="rxode2.html#topic+rxSolve">rxControl</a></code>, <code><a href="rxode2.html#topic+rxInits">rxInit</a></code>, <code><a href="rxode2.html#topic+rxLhs">rxLhs</a></code>, <code><a href="rxode2.html#topic+rxModelVars">rxModelVars</a></code>, <code><a href="rxode2.html#topic+rxModelVars">rxModelVarsS3</a></code>, <code><a href="rxode2.html#topic+rxode2">rxode</a></code>, <code><a href="rxode2.html#topic+rxode2">RxODE</a></code>, <code><a href="rxode2.html#topic+rxode2">rxode2</a></code>, <code><a href="rxode2.html#topic+rxParams">rxParam</a></code>, <code><a href="rxode2.html#topic+rxParams">rxParams</a></code>, <code><a href="rxode2.html#topic+rxParams">rxParams</a></code>, <code><a href="rxode2.html#topic+rxSolve">rxSolve</a></code>, <code><a href="rxode2.html#topic+rxSolve">rxSolve</a></code>, <code><a href="rxode2.html#topic+rxState">rxState</a></code>, <code><a href="rxode2.html#topic+stat_amt">stat_amt</a></code>, <code><a href="rxode2.html#topic+stat_cens">stat_cens</a></code></p>
</dd>
</dl>

<hr>
<h2 id='residuals.nlmixr2FitData'>Extract residuals from the FOCEI fit</h2><span id='topic+residuals.nlmixr2FitData'></span>

<h3>Description</h3>

<p>Extract residuals from the FOCEI fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlmixr2FitData'
residuals(
  object,
  ...,
  type = c("ires", "res", "iwres", "wres", "cwres", "cpred", "cres")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.nlmixr2FitData_+3A_object">object</code></td>
<td>
<p>focei.fit object</p>
</td></tr>
<tr><td><code id="residuals.nlmixr2FitData_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="residuals.nlmixr2FitData_+3A_type">type</code></td>
<td>
<p>Residuals type fitted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>residuals
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='rxGetDistributionFoceiLines'>This is a S3 method for getting the distribution lines for a base rxode2 focei problem</h2><span id='topic+rxGetDistributionFoceiLines'></span>

<h3>Description</h3>

<p>This is a S3 method for getting the distribution lines for a base rxode2 focei problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rxGetDistributionFoceiLines(line)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rxGetDistributionFoceiLines_+3A_line">line</code></td>
<td>
<p>Parsed rxode2 model environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lines for the focei. This is based
on the idea that the focei parameters are defined
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='rxGetDistributionNlmeLines'>This is a S3 method for getting the distribution lines for a base rxode2 nlme problem</h2><span id='topic+rxGetDistributionNlmeLines'></span>

<h3>Description</h3>

<p>This is a S3 method for getting the distribution lines for a base rxode2 nlme problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rxGetDistributionNlmeLines(line)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rxGetDistributionNlmeLines_+3A_line">line</code></td>
<td>
<p>Parsed rxode2 model environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lines for the focei. This is based
on the idea that the focei parameters are defined
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='rxGetDistributionNlsLines'>This is a S3 method for getting the distribution lines for a base rxode2 nls problem</h2><span id='topic+rxGetDistributionNlsLines'></span><span id='topic+rxGetDistributionNlsLines.norm'></span><span id='topic+rxGetDistributionNlsLines.default'></span>

<h3>Description</h3>

<p>This is a S3 method for getting the distribution lines for a base rxode2 nls problem
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rxGetDistributionNlsLines(line)

## S3 method for class 'norm'
rxGetDistributionNlsLines(line)

## Default S3 method:
rxGetDistributionNlsLines(line)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rxGetDistributionNlsLines_+3A_line">line</code></td>
<td>
<p>Parsed rxode2 model environment</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lines for the focei. This is based
on the idea that the focei parameters are defined
</p>


<h3>Author(s)</h3>

<p>Matthew Fidler
</p>

<hr>
<h2 id='saemControl'>Control Options for SAEM</h2><span id='topic+saemControl'></span>

<h3>Description</h3>

<p>Control Options for SAEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saemControl(
  seed = 99,
  nBurn = 200,
  nEm = 300,
  nmc = 3,
  nu = c(2, 2, 2),
  print = 1,
  trace = 0,
  covMethod = c("linFim", "fim", "r,s", "r", "s", ""),
  calcTables = TRUE,
  logLik = FALSE,
  nnodesGq = 3,
  nsdGq = 1.6,
  optExpression = TRUE,
  adjObf = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  tol = 1e-06,
  itmax = 30,
  type = c("nelder-mead", "newuoa"),
  powRange = 10,
  lambdaRange = 3,
  odeRecalcFactor = 10^(0.5),
  maxOdeRecalc = 5L,
  perSa = 0.75,
  perNoCor = 0.75,
  perFixOmega = 0.1,
  perFixResid = 0.1,
  compress = TRUE,
  rxControl = NULL,
  sigdig = NULL,
  sigdigTable = NULL,
  ci = 0.95,
  muRefCov = TRUE,
  muRefCovAlg = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saemControl_+3A_seed">seed</code></td>
<td>
<p>Random Seed for SAEM step.  (Needs to be set for
reproducibility.)  By default this is 99.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nburn">nBurn</code></td>
<td>
<p>Number of iterations in the first phase, ie the  MCMC/Stochastic Approximation
steps. This is equivalent to Monolix's <code>K_0</code> or <code>K_b</code>.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nem">nEm</code></td>
<td>
<p>Number of iterations in the Expectation-Maximization
(EM) Step. This is equivalent to Monolix's <code>K_1</code>.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nmc">nmc</code></td>
<td>
<p>Number of Markov Chains. By default this is 3.  When
you increase the number of chains the numerical integration by
MC method will be more accurate at the cost of more
computation.  In Monolix this is equivalent to <code>L</code>.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nu">nu</code></td>
<td>
<p>This is a vector of 3 integers. They represent the
numbers of transitions of the three different kernels used in
the Hasting-Metropolis algorithm.  The default value is <code>c(2,2,2)</code>,
representing 40 for each transition initially (each value is
multiplied by 20).
</p>
<p>The first value represents the initial number of multi-variate
Gibbs samples are taken from a normal distribution.
</p>
<p>The second value represents the number of uni-variate, or multi-
dimensional random walk Gibbs samples are taken.
</p>
<p>The third value represents the number of bootstrap/reshuffling or
uni-dimensional random samples are taken.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_print">print</code></td>
<td>
<p>The number it iterations that are completed before
anything is printed to the console.  By default, this is 1.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_trace">trace</code></td>
<td>
<p>An integer indicating if you want to trace(1) the
SAEM algorithm process.  Useful for debugging, but not for
typical fitting.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of each individual's
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>
<p>&quot;<code>linFim</code>&quot; Use the Linearized Fisher Information Matrix to calculate the covariance.
</p>
<p>&quot;<code>fim</code>&quot; Use the SAEM-calculated Fisher Information Matrix to calculate the covariance.
</p>
<p>&quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the covariance, that is: <code class="reqn">R^-1 \times S \times R^-1</code>
</p>
<p>&quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the covariance as <code class="reqn">2\times R^-1</code>
</p>
<p>&quot;<code>s</code>&quot; Uses the crossproduct matrix to calculate the covariance as <code class="reqn">4\times S^-1</code>
</p>
<p>&quot;&quot; Does not calculate the covariance step.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="saemControl_+3A_loglik">logLik</code></td>
<td>
<p>boolean indicating that log-likelihood should be
calculate by Gaussian quadrature.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nnodesgq">nnodesGq</code></td>
<td>
<p>number of nodes to use for the Gaussian
quadrature when computing the likelihood with this method
(defaults to 1, equivalent to the Laplacian likelihood)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_nsdgq">nsdGq</code></td>
<td>
<p>span (in SD) over which to integrate when computing
the likelihood by Gaussian quadrature. Defaults to 3 (eg 3
times the SD)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="saemControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_tol">tol</code></td>
<td>
<p>This is the tolerance for the regression models used
for complex residual errors (ie add+prop etc)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_itmax">itmax</code></td>
<td>
<p>This is the maximum number of iterations for the
regression models used for complex residual errors.  The number
of iterations is itmax*number of parameters</p>
</td></tr>
<tr><td><code id="saemControl_+3A_type">type</code></td>
<td>
<p>indicates the type of optimization for the residuals; Can be one of c(&quot;nelder-mead&quot;, &quot;newuoa&quot;)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_powrange">powRange</code></td>
<td>
<p>This indicates the range that powers can take for residual errors;  By default this is 10 indicating the range is c(-10, 10)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_lambdarange">lambdaRange</code></td>
<td>
<p>This indicates the range that Box-Cox and Yeo-Johnson parameters are constrained to be;  The default is 3 indicating the range c(-3,3)</p>
</td></tr>
<tr><td><code id="saemControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="saemControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_persa">perSa</code></td>
<td>
<p>This is the percent of the time the 'nBurn'
iterations in phase runs runs a simulated annealing.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_pernocor">perNoCor</code></td>
<td>
<p>This is the percentage of the MCMC phase of the SAEM
algorithm where the variance/covariance matrix has no
correlations. By default this is 0.75 or 75
Monte-carlo iteration.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_perfixomega">perFixOmega</code></td>
<td>
<p>This is the percentage of the 'nBurn' phase
where the omega values are unfixed to allow better exploration
of the likelihood surface.  After this time, the omegas are
fixed during optimization.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_perfixresid">perFixResid</code></td>
<td>
<p>This is the percentage of the 'nBurn' phase
where the residual components are unfixed to allow better
exploration of the likelihood surface.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="saemControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="saemControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Specifies the &quot;significant digits&quot; that the ode
solving requests.  When specified this controls the relative and
absolute tolerances of the ODE solvers.  By default the tolerance
is <code>0.5*10^(-sigdig-2)</code> for regular ODEs. For the
sensitivity equations the default is <code style="white-space: pre;">&#8288;0.5*10\^(-sigdig-1.5)&#8288;</code>
(sensitivity changes only applicable for liblsoda).  This also
controls the <code>atol</code>/<code>rtol</code> of the steady state solutions. The
<code>ssAtol</code>/<code>ssRtol</code> is <code style="white-space: pre;">&#8288;0.5*10\^(-sigdig)&#8288;</code> and for the sensitivities
<code style="white-space: pre;">&#8288;0.5*10\^(-sigdig+0.625)&#8288;</code>.  By default
this is unspecified (<code>NULL</code>) and uses the standard <code>atol</code>/<code>rtol</code>.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_murefcov">muRefCov</code></td>
<td>
<p>This controls if mu-referenced covariates in 'saem'
are handled differently than non mu-referenced covariates.  When
'TRUE', mu-referenced covariates have special handling.  When
'FALSE' mu-referenced covariates are treated the same as any
other input parameter.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_murefcovalg">muRefCovAlg</code></td>
<td>
<p>This controls if algebraic expressions that can
be mu-referenced are treated as mu-referenced covariates by:
</p>
<p>1. Creating a internal data-variable 'nlmixrMuDerCov#' for each
algebraic mu-referenced expression
</p>
<p>2. Change the algebraic expression to 'nlmixrMuDerCov# * mu_cov_theta'
</p>
<p>3. Use the internal mu-referenced covariate for saem
</p>
<p>4. After optimization is completed, replace 'model()' with old
'model()' expression
</p>
<p>5. Remove 'nlmixrMuDerCov#' from nlmix2 output
</p>
<p>In general, these covariates should be more accurate since it
changes the system to a linear compartment model.  Therefore, by default this is 'TRUE'.</p>
</td></tr>
<tr><td><code id="saemControl_+3A_...">...</code></td>
<td>
<p>Other arguments to control SAEM.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of options to be used in <code><a href="#topic+nlmixr2">nlmixr2</a></code> fit for
SAEM.
</p>


<h3>Author(s)</h3>

<p>Wenping Wang &amp; Matthew L. Fidler
</p>


<h3>See Also</h3>

<p>Other Estimation control: 
<code><a href="#topic+foceiControl">foceiControl</a>()</code>,
<code><a href="#topic+nlmixr2NlmeControl">nlmixr2NlmeControl</a>()</code>
</p>

<hr>
<h2 id='setCov'>Set the covariance type based on prior calculated covariances</h2><span id='topic+setCov'></span>

<h3>Description</h3>

<p>Set the covariance type based on prior calculated covariances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setCov(fit, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setCov_+3A_fit">fit</code></td>
<td>
<p>nlmixr2 fit</p>
</td></tr>
<tr><td><code id="setCov_+3A_method">method</code></td>
<td>
<p>covariance method (see the 'covMethod' argument for the control
options for the choices)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fit object with covariance updated
</p>


<h3>Author(s)</h3>

<p>Matt Fidler
</p>


<h3>See Also</h3>

<p><code><a href="#topic+foceiControl">foceiControl</a>()</code>, <code><a href="#topic+saemControl">saemControl</a>()</code>
</p>

<hr>
<h2 id='setOfv'>Set/get Objective function type for a nlmixr2 object</h2><span id='topic+setOfv'></span><span id='topic+getOfvType'></span>

<h3>Description</h3>

<p>Set/get Objective function type for a nlmixr2 object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setOfv(x, type)

getOfvType(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setOfv_+3A_x">x</code></td>
<td>
<p>nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="setOfv_+3A_type">type</code></td>
<td>
<p>Type of objective function to use for AIC, BIC, and
$objective</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='sqrtm'>Return the square root of general square matrix A</h2><span id='topic+sqrtm'></span>

<h3>Description</h3>

<p>Return the square root of general square matrix A
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrtm(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sqrtm_+3A_m">m</code></td>
<td>
<p>Matrix to take the square root of.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square root general square matrix of m
</p>

<hr>
<h2 id='summary.saemFit'>Print an SAEM model fit summary</h2><span id='topic+summary.saemFit'></span>

<h3>Description</h3>

<p>Print an SAEM model fit summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'saemFit'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.saemFit_+3A_object">object</code></td>
<td>
<p>a saemFit object</p>
</td></tr>
<tr><td><code id="summary.saemFit_+3A_...">...</code></td>
<td>
<p>others</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='tableControl'>Output table/data.frame options</h2><span id='topic+tableControl'></span>

<h3>Description</h3>

<p>Output table/data.frame options
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tableControl(
  npde = NULL,
  cwres = NULL,
  nsim = 300,
  ties = TRUE,
  censMethod = c("truncated-normal", "cdf", "ipred", "pred", "epred", "omit"),
  seed = 1009,
  cholSEtol = (.Machine$double.eps)^(1/3),
  state = TRUE,
  lhs = TRUE,
  eta = TRUE,
  covariates = TRUE,
  addDosing = FALSE,
  subsetNonmem = TRUE,
  cores = NULL,
  keep = NULL,
  drop = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tableControl_+3A_npde">npde</code></td>
<td>
<p>When TRUE, request npde regardless of the algorithm used.</p>
</td></tr>
<tr><td><code id="tableControl_+3A_cwres">cwres</code></td>
<td>
<p>When TRUE, request CWRES and FOCEi likelihood
regardless of the algorithm used.</p>
</td></tr>
<tr><td><code id="tableControl_+3A_nsim">nsim</code></td>
<td>
<p>represents the number of simulations.  For rxode2, if
you supply single subject event tables (created with
<code style="white-space: pre;">&#8288;[eventTable()]&#8288;</code>)</p>
</td></tr>
<tr><td><code id="tableControl_+3A_ties">ties</code></td>
<td>
<p>When 'TRUE' jitter prediction-discrepancy points to discourage ties in cdf.</p>
</td></tr>
<tr><td><code id="tableControl_+3A_censmethod">censMethod</code></td>
<td>
<p>Handle censoring method:
</p>
<p>- '&quot;truncated-normal&quot;' Simulates from a truncated normal distribution under the assumption of the model and censoring.
</p>
<p>- '&quot;cdf&quot;' Use the cdf-method for censoring with npde and use this for any other residuals ('cwres' etc)
</p>
<p>- '&quot;omit&quot;' omit the residuals for censoring</p>
</td></tr>
<tr><td><code id="tableControl_+3A_seed">seed</code></td>
<td>
<p>an object specifying if and how the random number
generator should be initialized</p>
</td></tr>
<tr><td><code id="tableControl_+3A_cholsetol">cholSEtol</code></td>
<td>
<p>The tolerance for the 'rxode2::choleSE' function</p>
</td></tr>
<tr><td><code id="tableControl_+3A_state">state</code></td>
<td>
<p>is a Boolean indicating if 'state' values will be included (default 'TRUE')</p>
</td></tr>
<tr><td><code id="tableControl_+3A_lhs">lhs</code></td>
<td>
<p>is a Boolean indicating if remaining 'lhs' values will be included (default 'TRUE')</p>
</td></tr>
<tr><td><code id="tableControl_+3A_eta">eta</code></td>
<td>
<p>is a Boolean indicating if 'eta' values will be included (default 'TRUE')</p>
</td></tr>
<tr><td><code id="tableControl_+3A_covariates">covariates</code></td>
<td>
<p>is a Boolean indicating if covariates will be included (default 'TRUE')</p>
</td></tr>
<tr><td><code id="tableControl_+3A_adddosing">addDosing</code></td>
<td>
<p>Boolean indicating if the solve should add rxode2
EVID and related columns.  This will also include dosing
information and estimates at the doses.  Be default, rxode2
only includes estimates at the observations. (default
<code>FALSE</code>). When <code>addDosing</code> is <code>NULL</code>, only
include <code>EVID=0</code> on solve and exclude any model-times or
<code>EVID=2</code>. If <code>addDosing</code> is <code>NA</code> the classic
<code>rxode2</code> EVID events are returned. When <code>addDosing</code> is <code>TRUE</code>
add the event information in NONMEM-style format; If
<code>subsetNonmem=FALSE</code> rxode2 will also include extra event types
(<code>EVID</code>) for ending infusion and modeled times:
</p>

<ul>
<li> <p><code>EVID=-1</code> when the modeled rate infusions are turned
off (matches <code>rate=-1</code>)
</p>
</li>
<li> <p><code>EVID=-2</code> When the modeled duration infusions are
turned off (matches <code>rate=-2</code>)
</p>
</li>
<li> <p><code>EVID=-10</code> When the specified <code>rate</code> infusions are
turned off (matches <code>rate&gt;0</code>)
</p>
</li>
<li> <p><code>EVID=-20</code> When the specified <code>dur</code> infusions are
turned off (matches <code>dur&gt;0</code>)
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;EVID=101,102,103,...&#8288;</code> Modeled time where 101 is the
first model time, 102 is the second etc.
</p>
</li></ul>
</td></tr>
<tr><td><code id="tableControl_+3A_subsetnonmem">subsetNonmem</code></td>
<td>
<p>subset to NONMEM compatible EVIDs only.  By
default <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="tableControl_+3A_cores">cores</code></td>
<td>
<p>Number of cores used in parallel ODE solving.  This
is equivalent to calling <code><a href="rxode2.html#topic+setRxThreads">setRxThreads()</a></code></p>
</td></tr>
<tr><td><code id="tableControl_+3A_keep">keep</code></td>
<td>
<p>is the keep sent to the table</p>
</td></tr>
<tr><td><code id="tableControl_+3A_drop">drop</code></td>
<td>
<p>is the dropped variables sent to the table</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you ever want to add CWRES/FOCEi objective function you can use the <code><a href="#topic+addCwres">addCwres</a></code>
</p>
<p>If you ever want to add NPDE/EPRED columns you can use the <code><a href="#topic+addNpde">addNpde</a></code>
</p>


<h3>Value</h3>

<p>A list of table options for nlmixr2
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='uobyqaControl'>Control for uobyqa estimation method in nlmixr2</h2><span id='topic+uobyqaControl'></span>

<h3>Description</h3>

<p>Control for uobyqa estimation method in nlmixr2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uobyqaControl(
  npt = NULL,
  rhobeg = NULL,
  rhoend = NULL,
  iprint = 0L,
  maxfun = 100000L,
  returnUobyqa = FALSE,
  stickyRecalcN = 4,
  maxOdeRecalc = 5,
  odeRecalcFactor = 10^(0.5),
  useColor = crayon::has_color(),
  printNcol = floor((getOption("width") - 23)/12),
  print = 1L,
  normType = c("rescale2", "mean", "rescale", "std", "len", "constant"),
  scaleType = c("nlmixr2", "norm", "mult", "multAdd"),
  scaleCmax = 1e+05,
  scaleCmin = 1e-05,
  scaleC = NULL,
  scaleTo = 1,
  rxControl = NULL,
  optExpression = TRUE,
  sumProd = FALSE,
  addProp = c("combined2", "combined1"),
  calcTables = TRUE,
  compress = TRUE,
  covMethod = c("r", ""),
  adjObf = TRUE,
  ci = 0.95,
  sigdig = 4,
  sigdigTable = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uobyqaControl_+3A_npt">npt</code></td>
<td>
<p>The number of points used to approximate the objective
function via a quadratic approximation for bobyqa. The value
of npt must be in the interval [n+2,(n+1)(n+2)/2] where n is
the number of parameters in par. Choices that exceed 2*n+1 are
not recommended. If not defined, it will be set to 2*n + 1. (bobyqa)</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_rhobeg">rhobeg</code></td>
<td>
<p>Beginning change in parameters for bobyqa algorithm
(trust region).  By default this is 0.2 or 20
parameters when the parameters are scaled to 1. rhobeg and
rhoend must be set to the initial and final values of a trust
region radius, so both must be positive with 0 &lt; rhoend &lt;
rhobeg. Typically rhobeg should be about one tenth of the
greatest expected change to a variable.  Note also that
smallest difference abs(upper-lower) should be greater than or
equal to rhobeg*2. If this is not the case then rhobeg will be
adjusted. (bobyqa)</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_rhoend">rhoend</code></td>
<td>
<p>The smallest value of the trust region radius that
is allowed. If not defined, then 10^(-sigdig-1) will be used. (bobyqa)</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_iprint">iprint</code></td>
<td>
<p>The value of 'iprint' should be set to an integer
value in '0, 1, 2, 3, ...', which controls the amount of
printing.  Specifically, there is no output if 'iprint=0' and
there is output only at the start and the return if 'iprint=1'.
Otherwise, each new value of 'rho' is printed, with the best
vector of variables so far and the corresponding value of the
objective function. Further, each new value of the objective
function with its variables are output if 'iprint=3'.  If 'iprint
&gt; 3', the objective function value and corresponding variables
are output every 'iprint' evaluations.  Default value is '0'.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_maxfun">maxfun</code></td>
<td>
<p>The maximum allowed number of function
evaluations. If this is exceeded, the method will terminate.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_returnuobyqa">returnUobyqa</code></td>
<td>
<p>return the uobyqa output instead of the nlmixr2
fit</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_stickyrecalcn">stickyRecalcN</code></td>
<td>
<p>The number of bad ODE solves before reducing
the atol/rtol for the rest of the problem.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_maxoderecalc">maxOdeRecalc</code></td>
<td>
<p>Maximum number of times to reduce the ODE
tolerances and try to resolve the system if there was a bad
ODE solve.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_oderecalcfactor">odeRecalcFactor</code></td>
<td>
<p>The ODE recalculation factor when ODE
solving goes bad, this is the factor the rtol/atol is reduced</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_usecolor">useColor</code></td>
<td>
<p>Boolean indicating if focei can use ASCII color codes</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_printncol">printNcol</code></td>
<td>
<p>Number of columns to printout before wrapping
parameter estimates/gradient</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_print">print</code></td>
<td>
<p>Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_normtype">normType</code></td>
<td>
<p>This is the type of parameter
normalization/scaling used to get the scaled initial values
for nlmixr2.  These are used with <code>scaleType</code> of.
</p>
<p>With the exception of <code>rescale2</code>, these come
from
<a href="https://en.wikipedia.org/wiki/Feature_scaling">Feature
Scaling</a>. The <code>rescale2</code> The rescaling is the same type
described in the
<a href="http://apmonitor.com/me575/uploads/Main/optimization_book.pdf">OptdesX</a>
software manual.
</p>
<p>In general, all all scaling formula can be described by:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>

<p>Where
</p>
<p>The other data normalization approaches follow the following formula
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{unscaled}-C_{1}</code>
</p>
<p>)/</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>


<ul>
<li> <p><code>rescale2</code> This scales all parameters from (-1 to 1).
The relative differences between the parameters are preserved
with this approach and the constants are:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = (max(all unscaled values)+min(all unscaled values))/2
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = (max(all unscaled values) - min(all unscaled values))/2
</p>
</li>
<li> <p><code>rescale</code> or min-max normalization. This rescales all
parameters from (0 to 1).  As in the <code>rescale2</code> the
relative differences are preserved.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = min(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>mean</code> or mean normalization.  This rescales to center
the parameters around the mean but the parameters are from 0
to 1.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = max(all unscaled values) - min(all unscaled values)
</p>
</li>
<li> <p><code>std</code> or standardization.  This standardizes by the mean
and standard deviation.  In this approach:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = mean(all unscaled values)
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = sd(all unscaled values)
</p>
</li>
<li> <p><code>len</code> or unit length scaling.  This scales the
parameters to the unit length.  For this approach we use the Euclidean length, that
is:
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">\sqrt(v_1^2 + v_2^2 + \cdots + v_n^2)</code>
</p>

</li>
<li> <p><code>constant</code> which does not perform data normalization. That is
</p>
<p style="text-align: center;"><code class="reqn">C_{1}</code>
</p>
<p> = 0
</p>
<p style="text-align: center;"><code class="reqn">C_{2}</code>
</p>
<p> = 1
</p>
</li></ul>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_scaletype">scaleType</code></td>
<td>
<p>The scaling scheme for nlmixr2.  The supported types are:
</p>

<ul>
<li> <p><code>nlmixr2</code>  In this approach the scaling is performed by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current} - v_{init}</code>
</p>
<p>)*scaleC[i] + scaleTo
</p>
<p>The <code>scaleTo</code> parameter is specified by the <code>normType</code>,
and the scales are specified by <code>scaleC</code>.
</p>
</li>
<li> <p><code>norm</code> This approach uses the simple scaling provided
by the <code>normType</code> argument.
</p>
</li>
<li> <p><code>mult</code> This approach does not use the data
normalization provided by <code>normType</code>, but rather uses
multiplicative scaling to a constant provided by the <code>scaleTo</code>
argument.
</p>
<p>In this case:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li>
<li> <p><code>multAdd</code> This approach changes the scaling based on
the parameter being specified.  If a parameter is defined in an
exponential block (ie exp(theta)), then it is scaled on a
linearly, that is:
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = (</p>
<p style="text-align: center;"><code class="reqn">v_{current}-v_{init}</code>
</p>
<p>) + scaleTo
</p>
<p>Otherwise the parameter is scaled multiplicatively.
</p>
<p style="text-align: center;"><code class="reqn">v_{scaled}</code>
</p>
<p> = </p>
<p style="text-align: center;"><code class="reqn">v_{current}</code>
</p>
<p>/</p>
<p style="text-align: center;"><code class="reqn">v_{init}</code>
</p>
<p>*scaleTo
</p>
</li></ul>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_scalecmax">scaleCmax</code></td>
<td>
<p>Maximum value of the scaleC to prevent overflow.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_scalecmin">scaleCmin</code></td>
<td>
<p>Minimum value of the scaleC to prevent underflow.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_scalec">scaleC</code></td>
<td>
<p>The scaling constant used with
<code>scaleType=nlmixr2</code>.  When not specified, it is based on
the type of parameter that is estimated.  The idea is to keep
the derivatives similar on a log scale to have similar
gradient sizes.  Hence parameters like log(exp(theta)) would
have a scaling factor of 1 and log(theta) would have a scaling
factor of ini_value (to scale by 1/value; ie
d/dt(log(ini_value)) = 1/ini_value or scaleC=ini_value)
</p>

<ul>
<li><p> For parameters in an exponential (ie exp(theta)) or
parameters specifying powers, boxCox or yeoJohnson
transformations , this is 1.
</p>
</li>
<li><p> For additive, proportional, lognormal error structures,
these are given by 0.5*abs(initial_estimate)
</p>
</li>
<li><p> Factorials are scaled by abs(1/digamma(initial_estimate+1))
</p>
</li>
<li><p> parameters in a log scale (ie log(theta)) are transformed
by log(abs(initial_estimate))*abs(initial_estimate)
</p>
</li></ul>

<p>These parameter scaling coefficients are chose to try to keep
similar slopes among parameters.  That is they all follow the
slopes approximately on a log-scale.
</p>
<p>While these are chosen in a logical manner, they may not always
apply.  You can specify each parameters scaling factor by this
parameter if you wish.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_scaleto">scaleTo</code></td>
<td>
<p>Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_rxcontrol">rxControl</code></td>
<td>
<p>'rxode2' ODE solving options during fitting, created with 'rxControl()'</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_optexpression">optExpression</code></td>
<td>
<p>Optimize the rxode2 expression to speed up
calculation. By default this is turned on.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_sumprod">sumProd</code></td>
<td>
<p>Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_addprop">addProp</code></td>
<td>
<p>specifies the type of additive plus proportional
errors, the one where standard deviations add (combined1) or the
type where the variances add (combined2).
</p>
<p>The combined1 error type can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + (a + b\times f^c) \times \varepsilon</code>
</p>

<p>The combined2 error model can be described by the following equation:
</p>
<p style="text-align: center;"><code class="reqn">y = f + \sqrt{a^2 + b^2\times f^{2\times c}} \times \varepsilon</code>
</p>

<p>Where:
</p>
<p>- y represents the observed value
</p>
<p>- f represents the predicted value
</p>
<p>- a  is the additive standard deviation
</p>
<p>- b is the proportional/power standard deviation
</p>
<p>- c is the power exponent (in the proportional case c=1)</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_calctables">calcTables</code></td>
<td>
<p>This boolean is to determine if the foceiFit
will calculate tables. By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_compress">compress</code></td>
<td>
<p>Should the object have compressed items</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_covmethod">covMethod</code></td>
<td>
<p>Method for calculating covariance.  In this
discussion, R is the Hessian matrix of the objective
function. The S matrix is the sum of individual
gradient cross-product (evaluated at the individual empirical
Bayes estimates).
</p>

<ul>
<li><p> &quot;<code>r,s</code>&quot; Uses the sandwich matrix to calculate the
covariance, that is: <code>solve(R) %*% S %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>r</code>&quot; Uses the Hessian matrix to calculate the
covariance as <code>2 %*% solve(R)</code>
</p>
</li>
<li><p> &quot;<code>s</code>&quot; Uses the cross-product matrix to calculate the
covariance as <code>4 %*% solve(S)</code>
</p>
</li>
<li><p> &quot;&quot; Does not calculate the covariance step.
</p>
</li></ul>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_adjobf">adjObf</code></td>
<td>
<p>is a boolean to indicate if the objective function
should be adjusted to be closer to NONMEM's default objective
function.  By default this is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_ci">ci</code></td>
<td>
<p>Confidence level for some tables.  By default this is
0.95 or 95% confidence.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_sigdig">sigdig</code></td>
<td>
<p>Optimization significant digits. This controls:
</p>

<ul>
<li><p> The tolerance of the inner and outer optimization is <code>10^-sigdig</code>
</p>
</li>
<li><p> The tolerance of the ODE solvers is
<code>0.5*10^(-sigdig-2)</code>; For the sensitivity equations and
steady-state solutions the default is <code>0.5*10^(-sigdig-1.5)</code>
(sensitivity changes only applicable for liblsoda)
</p>
</li>
<li><p> The tolerance of the boundary check is <code>5 * 10 ^ (-sigdig + 1)</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_sigdigtable">sigdigTable</code></td>
<td>
<p>Significant digits in the final output table.
If not specified, then it matches the significant digits in the
'sigdig' optimization algorithm.  If 'sigdig' is NULL, use 3.</p>
</td></tr>
<tr><td><code id="uobyqaControl_+3A_...">...</code></td>
<td>
<p>Ignored parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>uobyqa control structure
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A logit regression example with emax model

dsn &lt;- data.frame(i=1:1000)
dsn$time &lt;- exp(rnorm(1000))
dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))

mod &lt;- function() {
 ini({
   E0 &lt;- 0.5
   Em &lt;- 0.5
   E50 &lt;- 2
   g &lt;- fix(2)
 })
 model({
   v &lt;- E0+Em*time^g/(E50^g+time^g)
   ll(bin) ~ DV * v - log(1 + exp(v))
 })
}

fit2 &lt;- nlmixr(mod, dsn, est="uobyqa")

print(fit2)

# you can also get the nlm output with fit2$nlm

fit2$uobyqa

# The nlm control has been modified slightly to include
# extra components and name the parameters

</code></pre>

<hr>
<h2 id='vpcNameDataCmts'>Name the data and compartments</h2><span id='topic+vpcNameDataCmts'></span>

<h3>Description</h3>

<p>Name the data and compartments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vpcNameDataCmts(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vpcNameDataCmts_+3A_object">object</code></td>
<td>
<p>nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="vpcNameDataCmts_+3A_data">data</code></td>
<td>
<p>dataset to name 'dvid' and 'cmt' columns to correspond with the model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Updated object/data
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

<hr>
<h2 id='vpcSim'>VPC simulation</h2><span id='topic+vpcSim'></span>

<h3>Description</h3>

<p>VPC simulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vpcSim(
  object,
  ...,
  keep = NULL,
  n = 300,
  pred = FALSE,
  seed = 1009,
  nretry = 50,
  minN = 10,
  normRelated = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vpcSim_+3A_object">object</code></td>
<td>
<p>This is the nlmixr2 fit object</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_...">...</code></td>
<td>
<p>Other arguments sent to 'rxSolve()'</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_keep">keep</code></td>
<td>
<p>Column names to keep in the output simulated dataset</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_n">n</code></td>
<td>
<p>Number of simulations</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_pred">pred</code></td>
<td>
<p>Should predictions be added to the simulation</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_seed">seed</code></td>
<td>
<p>Seed to set for the VPC simulation</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_nretry">nretry</code></td>
<td>
<p>Number of times to retry the simulation if there is
NA values in the simulation</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_minn">minN</code></td>
<td>
<p>With retries, the minimum number of studies to
restimulate (by default 10)</p>
</td></tr>
<tr><td><code id="vpcSim_+3A_normrelated">normRelated</code></td>
<td>
<p>should the VPC style simulation be for normal
related variables only</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame of the VPC simulation
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


if (rxode2parse::.linCmtSens()) {

one.cmt &lt;- function() {
 ini({
   ## You may label each parameter with a comment
   tka &lt;- 0.45 # Log Ka
   tcl &lt;- log(c(0, 2.7, 100)) # Log Cl
   ## This works with interactive models
   ## You may also label the preceding line with label("label text")
   tv &lt;- 3.45; label("log V")
   ## the label("Label name") works with all models
   eta.ka ~ 0.6
   eta.cl ~ 0.3
   eta.v ~ 0.1
   add.sd &lt;- 0.7
 })
 model({
   ka &lt;- exp(tka + eta.ka)
   cl &lt;- exp(tcl + eta.cl)
   v &lt;- exp(tv + eta.v)
   linCmt() ~ add(add.sd)
 })
}

fit &lt;- nlmixr(one.cmt, theo_sd, est="focei")

head(vpcSim(fit, pred=TRUE))

}


</code></pre>

<hr>
<h2 id='vpcSimExpand'>Expand a VPC simulation</h2><span id='topic+vpcSimExpand'></span>

<h3>Description</h3>

<p>Expand a VPC simulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vpcSimExpand(object, sim, extra, fullData = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vpcSimExpand_+3A_object">object</code></td>
<td>
<p>nlmixr fit object</p>
</td></tr>
<tr><td><code id="vpcSimExpand_+3A_sim">sim</code></td>
<td>
<p>vpc simulation object</p>
</td></tr>
<tr><td><code id="vpcSimExpand_+3A_extra">extra</code></td>
<td>
<p>extra data from original fit to add</p>
</td></tr>
<tr><td><code id="vpcSimExpand_+3A_fulldata">fullData</code></td>
<td>
<p>is the full data (possibly modified); This is used
for the vpc tad calculation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Expanded data frame with extra pieces added
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
