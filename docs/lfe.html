<!DOCTYPE html><html><head><title>Help for package lfe</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lfe}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lfe-package'><p>Overview. Linear Group Fixed Effects</p></a></li>
<li><a href='#..oldfelm'><p>Fit a linear model with multiple group fixed effects (old interface)</p></a></li>
<li><a href='#bccorr'><p>Compute limited mobility bias corrected correlation between fixed effects</p></a></li>
<li><a href='#btrap'><p>Bootstrap standard errors for the group fixed effects</p></a></li>
<li><a href='#cgsolve'><p>Solve a symmetric linear system with the conjugate gradient method</p></a></li>
<li><a href='#chainsubset'><p>Chain subset conditions</p></a></li>
<li><a href='#compfactor'><p>Find the connected components</p></a></li>
<li><a href='#condfstat'><p>Compute conditional F statistic for weak instruments in an IV-estimation</p>
with multiple endogenous variables</a></li>
<li><a href='#demeanlist'><p>Centre vectors on multiple groups</p></a></li>
<li><a href='#diammatrix'><p>Find diameters of mobility graphs</p></a></li>
<li><a href='#efactory'><p>Create estimable function</p></a></li>
<li><a href='#felm'><p>Fit a linear model with multiple group fixed effects</p></a></li>
<li><a href='#fepois'><p>Fit a Poisson model with multiple group fixed effects</p></a></li>
<li><a href='#fevcov'><p>Compute limited mobility bias corrected covariance matrix between fixed</p>
effects</a></li>
<li><a href='#fixedse'><p>Compute standard errors for fixed effects</p></a></li>
<li><a href='#getfe'><p>Retrieve the group fixed effects</p></a></li>
<li><a href='#is.estimable'><p>Verify estimability of function</p></a></li>
<li><a href='#kaczmarz'><p>Solve a linear system defined by factors</p></a></li>
<li><a href='#makeDmatrix'><p>Make sparse matrix of dummies from factor list</p></a></li>
<li><a href='#mctrace'><p>Compute trace of a large matrix by sample means</p></a></li>
<li><a href='#nlexpect'><p>Compute expectation of a function of the coefficients.</p></a></li>
<li><a href='#sargan'><p>Compute Sargan's S</p></a></li>
<li><a href='#summary.felm'><p>Summarize felm model fits</p></a></li>
<li><a href='#varvars'><p>Compute the variance of the fixed effect variance estimate</p></a></li>
<li><a href='#waldtest'><p>Compute Wald test for joint restrictions on coefficients</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>3.0-0</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Group Fixed Effects</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.2), Matrix (&ge; 1.1-2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Formula, xtable, compiler, utils, methods, sandwich, parallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, digest, igraph, plm, cubature (&ge; 2.0.3), numDeriv,
data.table, alpaca</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Description:</td>
<td>Transforms away factors with many levels prior to doing an OLS.
  Useful for estimating linear models with multiple group fixed effects, and for
  estimating linear models which uses factors with many levels as pure control variables. See Gaure (2013) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2013.03.024">doi:10.1016/j.csda.2013.03.024</a>&gt;
  Includes support for instrumental variables, conditional F statistics for weak instruments,
  robust and multi-way clustered standard errors, as well as limited mobility bias correction (Gaure 2014 &lt;<a href="https://doi.org/10.1002%2Fsta4.68">doi:10.1002/sta4.68</a>&gt;).
  Since version 3.0, it provides dedicated functions to estimate Poisson models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Classification/JEL:</td>
<td>C13, C23, C60</td>
</tr>
<tr>
<td>Classification/MSC:</td>
<td>62J05, 65F10, 65F50</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/r-econometrics/lfe">https://github.com/r-econometrics/lfe</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-econometrics/lfe/issues">https://github.com/r-econometrics/lfe/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-29 07:38:48 UTC; pacha</td>
</tr>
<tr>
<td>Author:</td>
<td>Simen Gaure <a href="https://orcid.org/0000-0001-7251-8747"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Grant McDermott [ctb],
  Mauricio Vargas Sepulveda
    <a href="https://orcid.org/0000-0003-1017-7574"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb, cre],
  Karl Dunkle Werner [ctb],
  Matthieu Stigler <a href="https://orcid.org/0000-0002-6802-4290"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Daniel LÃ¼decke [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mauricio Vargas Sepulveda &lt;m.sepulveda@mail.utoronto.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-29 11:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='lfe-package'>Overview. Linear Group Fixed Effects</h2><span id='topic+lfe-package'></span><span id='topic+lfe'></span>

<h3>Description</h3>

<p>The package uses the Method of Alternating Projections to estimate linear
models with multiple group fixed effects.  A generalization of the within
estimator. It supports IV-estimation with multiple endogenous variables via
2SLS, with conditional F statistics for detection of weak instruments. It is
thread-parallelized and intended for large problems. A method for correcting
limited mobility bias is also included.
</p>


<h3>Details</h3>

<p>This package is intended for linear models with multiple group fixed
effects, i.e. with 2 or more factors with a large number of levels.  It
performs similar functions as <code><a href="stats.html#topic+lm">stats::lm()</a></code>, but it uses a special
method for projecting out multiple group fixed effects from the normal
equations, hence it is faster. It is a generalization of the within
estimator.  This may be required if the groups have high cardinality (many
levels), resulting in tens or hundreds of thousands of dummy variables.  It
is also useful if one only wants to control for the group effects, without
actually estimating them.  The package may optionally compute standard
errors for the group effects by bootstrapping, but this is a very time- and
memory-consuming process compared to finding the point estimates.  If you
only have a single huge factor, the package <span class="pkg">plm</span> is probably better
suited.  If your factors don't have thousands of levels,
<code><a href="stats.html#topic+lm">stats::lm()</a></code> or other packages are probably better suited.
<span class="pkg">lfe</span> is designed to produce the same results as <code><a href="stats.html#topic+lm">stats::lm()</a></code>
will do if run with the full set of dummies.
</p>
<p>Projecting out interactions between continuous covariates and factors is
supported. I.e. individual slopes, not only individual intercepts. Multiple
left hand sides are supported.
</p>
<p>The package does not support non-linear models. For GLMs with many dummies there
is a package <span class="pkg">alpaca</span> which uses similar methods to project them out.
</p>
<p>The estimation is done in two steps.  First the other coefficients are
estimated with the function <code><a href="#topic+felm">felm()</a></code> by centering on all the group
means, followed by an OLS (similar to lm).  Then the group effects are
extracted (if needed) with the function <code><a href="#topic+getfe">getfe()</a></code>.  This method is
described by <cite>Gaure (2013)</cite>, but also appears in <cite>Guimaraes and
Portugal (2010)</cite>, disguised as the Gauss-Seidel algorithm.
</p>
<p>There's also a function <code><a href="#topic+demeanlist">demeanlist()</a></code> which just does the
centering on an arbitrary matrix or data frame, and there's a function
<code><a href="#topic+compfactor">compfactor()</a></code> which computes the connected components which are
used for interpreting the group effects when there are only two factors (see
the Abowd et al references), they are also returned by <code><a href="#topic+getfe">getfe()</a></code>.
</p>
<p>For those who study the correlation between the fixed effects, like in
<cite>Abowd et al. (1999)</cite>, there are functions <code><a href="#topic+bccorr">bccorr()</a></code> and
<code><a href="#topic+fevcov">fevcov()</a></code> for computing limited mobility bias corrected
correlations and variances with the method described in <cite>Gaure
(2014b)</cite>.
</p>
<p>Instrumental variable estimations are supported with 2SLS. Conditional F
statistics for testing reduced rank weak instruments as in <cite>Sanderson
and Windmeijer (2015)</cite> are available in <code><a href="#topic+condfstat">condfstat()</a></code>.  Joint
significance testing of coefficients is available in <code><a href="#topic+waldtest">waldtest()</a></code>.
</p>
<p>The centering on the means is done with a tolerance which is set by
<code>options(lfe.eps=1e-8)</code> (the default).  This is a somewhat conservative
tolerance, in many cases I'd guess <code>1e-6</code> may be sufficient.  This may
speed up the centering.  In the other direction, setting
<code>options(lfe.eps=0)</code> will provide maximum accuracy at the cost of
computing time and warnings about convergence failure.
</p>
<p>The package is threaded, that is, it may use more than one cpu.  The number
of threads is fetched upon loading the package from the environment variable
<span class="env">LFE_THREADS</span>, <span class="env">OMP_THREAD_LIMIT</span>, <span class="env">OMP_NUM_THREADS</span> or
<span class="env">NUMBER_OF_PROCESSORS</span> (for Windows), and stored by
<code>options(lfe.threads=n)</code>.  This option can be changed prior to calling
<code><a href="#topic+felm">felm()</a></code>, if so desired.  Note that, typically, <span class="pkg">lfe</span> is
limited by memory bandwidth, not cpu speed, thus fast memory and large cache
is more important than clock frequency. It is therefore also not always true
that running on all available cores is much better than running on half of
them.
</p>
<p>Threading is only done for the centering; the extraction of the group
effects is not threaded. The default method for extracting the group
coefficients is the iterative Kaczmarz-method, its tolerance is also the
<code>lfe.eps</code> option. For some datasets the Kaczmarz-method is converging
very slowly, in this case it may be replaced with a conjugate gradient
method by setting the option <code>options(lfe.usecg=TRUE)</code>. Various
time-consuming parts of <span class="pkg">lfe</span> may print progress reports, the minimum
interval in seconds is <code>options(lfe.pint=1800)</code>.
</p>
<p>The package has been tested on datasets with approx 20,000,000 observations
with 15 covariates and approx 2,300,000 and 270,000 group levels (the
<code><a href="#topic+felm">felm()</a></code> took about 50 minutes on 8 cpus, the <code><a href="#topic+getfe">getfe()</a></code>
takes 5 minutes).  Though, beware that not only the size of the dataset
matters, but also its structure, as demonstrated by <cite>Gaure (2014a)</cite>.
</p>
<p>The package will work with any number of grouping factors, but if more than
two, their interpretation is in general not well understood, i.e. one should
make sure that the group coefficients are estimable. A discussion of
estimability, the algorithm used, and convergence rate are available in
vignettes, as well as in the published papers in the citation list
(<code>citation('lfe')</code>).
</p>
<p>In the exec-directory there is a perl-script <code>lfescript</code> which is used
at the author's site for automated creation of R-scripts from a simple
specification file.  The format is documented in <code>doc/lfeguide.txt</code>.
</p>
<p><span class="pkg">lfe</span> is similar in function, though not in method, to the Stata modules
<code>a2reg</code> and <code>felsdvreg</code>.  The method is very similar to the one in
the Stata module <code>reghdfe</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Mauricio Vargas Sepulveda <a href="mailto:m.sepulveda@mail.utoronto.ca">m.sepulveda@mail.utoronto.ca</a> (<a href="https://orcid.org/0000-0003-1017-7574">ORCID</a>) [contributor]
</p>
<p>Authors:
</p>

<ul>
<li><p> Simen Gaure (<a href="https://orcid.org/0000-0001-7251-8747">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Grant McDermott [contributor]
</p>
</li>
<li><p> Karl Dunkle Werner [contributor]
</p>
</li>
<li><p> Matthieu Stigler (<a href="https://orcid.org/0000-0002-6802-4290">ORCID</a>) [contributor]
</p>
</li>
<li><p> Daniel LÃ¼decke [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Abowd, J.M., F. Kramarz and D.N. Margolis (1999) <cite>High Wage
Workers and High Wage Firms</cite>, Econometrica 67 (1999), no. 2, 251&ndash;333.
<a href="https://doi.org/10.1111/1468-0262.00020">doi:10.1111/1468-0262.00020</a>
</p>
<p>Abowd, J.M., R. Creecy and F. Kramarz (2002) <cite>Computing Person and Firm
Effects Using Linked Longitudinal Employer-Employee Data.</cite> Technical Report
TP-2002-06, U.S. Census Bureau.
<a href="https://www2.census.gov/ces/tp/tp-2002-06.pdf">https://www2.census.gov/ces/tp/tp-2002-06.pdf</a>
</p>
<p>Andrews, M., L. Gill, T. Schank and R. Upward (2008) <cite>High wage workers
and low wage firms: negative assortative matching or limited mobility bias?</cite>
J.R. Stat. Soc.(A) 171(3), 673&ndash;697.
<a href="https://doi.org/10.1111/j.1467-985X.2007.00533.x">doi:10.1111/j.1467-985X.2007.00533.x</a>
</p>
<p>Cornelissen, T. (2008) <cite>The stata command felsdvreg to fit a linear
model with two high-dimensional fixed effects.</cite> Stata Journal,
8(2):170&ndash;189, 2008.
<a href="https://econpapers.repec.org/RePEc:tsj:stataj:v:8:y:2008:i:2:p:170-189">https://econpapers.repec.org/RePEc:tsj:stataj:v:8:y:2008:i:2:p:170-189</a>
</p>
<p>Correia, S. (2014) <cite>REGHDFE: Stata module to perform linear or
instrumental-variable regression absorbing any number of high-dimensional
fixed effects</cite>, Statistical Software Components, Boston College Department
of Economics. <a href="https://econpapers.repec.org/RePEc:boc:bocode:s457874">https://econpapers.repec.org/RePEc:boc:bocode:s457874</a>
</p>
<p>Croissant, Y. and G. Millo (2008) <cite>Panel Data Econometrics in R: The
plm Package</cite>, Journal of Statistical Software, 27(2).
<a href="https://www.jstatsoft.org/v27/i02/">https://www.jstatsoft.org/v27/i02/</a>
</p>
<p>Gaure, S. (2013) <cite>OLS with Multiple High Dimensional Category
Variables.</cite> Computational Statistics and Data Analysis, 66:8&ndash;18, 2013
<a href="https://doi.org/10.1016/j.csda.2013.03.024">doi:10.1016/j.csda.2013.03.024</a>
</p>
<p>Gaure, S. (2014a) <cite>lfe: Linear Group Fixed Effects.</cite> The R Journal,
5(2):104-117, Dec 2013.
<a href="https://journal.r-project.org/archive/2013/RJ-2013-031/RJ-2013-031.pdf">https://journal.r-project.org/archive/2013/RJ-2013-031/RJ-2013-031.pdf</a>
</p>
<p>Gaure, S. (2014b), <cite>Correlation bias correction in two-way
fixed-effects linear regression</cite>, Stat 3(1):379-390, 2014.
<a href="https://doi.org/10.1002/sta4.68">doi:10.1002/sta4.68</a>
</p>
<p>Guimaraes, P. and Portugal, P. (2010) <cite>A simple feasible procedure to
fit models with high-dimensional fixed effects.</cite> The Stata Journal,
10(4):629&ndash;649, 2010.
<a href="https://www.stata-journal.com/article.html?article=st0212">https://www.stata-journal.com/article.html?article=st0212</a>
</p>
<p>Ouazad, A. (2008) <cite>A2REG: Stata module to estimate models with two
fixed effects.</cite> Statistical Software Components S456942, Boston College
Department of Economics.
<a href="https://ideas.repec.org/c/boc/bocode/s456942.html">https://ideas.repec.org/c/boc/bocode/s456942.html</a>
</p>
<p>Sanderson, E. and F. Windmeijer (2014) <cite>A weak instrument F-test in
linear IV models with multiple endogenous variables</cite>, Journal of
Econometrics, 2015.
<a href="https://www.sciencedirect.com/science/article/pii/S0304407615001736">https://www.sciencedirect.com/science/article/pii/S0304407615001736</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/r-econometrics/lfe">https://github.com/r-econometrics/lfe</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/r-econometrics/lfe/issues">https://github.com/r-econometrics/lfe/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
x &lt;- rnorm(1000)
x2 &lt;- rnorm(length(x))
id &lt;- factor(sample(10, length(x), replace = TRUE))
firm &lt;- factor(sample(3, length(x), replace = TRUE, prob = c(2, 1.5, 1)))
year &lt;- factor(sample(10, length(x), replace = TRUE, prob = c(2, 1.5, rep(1, 8))))
id.eff &lt;- rnorm(nlevels(id))
firm.eff &lt;- rnorm(nlevels(firm))
year.eff &lt;- rnorm(nlevels(year))
y &lt;- x + 0.25 * x2 + id.eff[id] + firm.eff[firm] +
  year.eff[year] + rnorm(length(x))
est &lt;- felm(y ~ x + x2 | id + firm + year)
summary(est)

getfe(est, se = TRUE)
# compare with an ordinary lm
summary(lm(y ~ x + x2 + id + firm + year - 1))
options(oldopts)

</code></pre>

<hr>
<h2 id='..oldfelm'>Fit a linear model with multiple group fixed effects (old interface)</h2><span id='topic+..oldfelm'></span>

<h3>Description</h3>

<p>Fit a linear model with multiple group fixed effects (old interface)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>..oldfelm(
  formula,
  data,
  exactDOF = FALSE,
  subset,
  na.action,
  contrasts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="..oldfelm_+3A_formula">formula</code></td>
<td>
<p>an object of class '&quot;formula&quot;' (or one that can be coerced to
that class): a symbolic description of the model to be fitted. Similarly to
'lm'.  See Details.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables of the model.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_exactdof">exactDOF</code></td>
<td>
<p>logical. If more than two factors, the degrees of freedom
used to scale the covariance matrix (and the standard errors) is normally
estimated. Setting <code>exactDOF=TRUE</code> causes <code>felm</code> to attempt to
compute it, but this may fail if there are too many levels in the factors.
<code>exactDOF='rM'</code> will use the exact method in
<code>Matrix::rankMatrix()</code>, but this is slower. If neither of these methods
works, it is possible to specify <code>exactDOF='mc'</code>, which utilizes a
Monte-Carlo method to estimate the expectation E(x' P x) = tr(P), the trace
of a certain projection, a method which may be more accurate than the
default guess.
</p>
<p>If the degrees of freedom for some reason are known, they can be specified
like <code>exactDOF=342772</code>.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain <code>NA</code>s.  The default is set by the <code>na.action</code> setting of
<code>options</code>, and is <code>na.fail</code> if that is unset.  The 'factory-fresh'
default is <code>na.omit</code>.  Another possible value is <code>NULL</code>, no
action. <code>na.exclude</code> is currently not supported.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code> of
<code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="..oldfelm_+3A_...">...</code></td>
<td>
<p>other arguments.  </p>

<ul>
<li> <p><code>cmethod</code> character. Which clustering method to use. Known
arguments are <code>'cgm'</code> (the default), <code>'cgm2'</code> (or <code>'reghdfe'</code>,
its alias). These alternate methods will generally
yield equivalent results, except in the case of multiway clustering with few
clusters along at least one dimension.
</p>
</li>
<li> <p><code>keepX</code> logical. To include a copy of the expanded data matrix in
the return value, as needed by <code><a href="#topic+bccorr">bccorr()</a></code> and <code><a href="#topic+fevcov">fevcov()</a></code>
for proper limited mobility bias correction.
</p>
</li>
<li> <p><code>keepCX</code> logical. Keep a copy of the centred expanded data matrix
in the return value. As list elements <code>cX</code> for the explanatory
variables, and <code>cY</code> for the outcome.
</p>
</li>
<li> <p><code>keepModel</code> logical. Keep a copy of the model frame.
</p>
</li>
<li> <p><code>nostats</code> logical. Don't include covariance matrices in the
output, just the estimated coefficients and various descriptive information.
For IV, <code>nostats</code> can be a logical vector of length 2, with the last
value being used for the 1st stages.  </p>
</li>
<li> <p><code>psdef</code> logical. In case of
multiway clustering, the method of Cameron, Gelbach and Miller may yield a
non-definite variance matrix. Ordinarily this is forced to be semidefinite
by setting negative eigenvalues to zero. Setting <code>psdef=FALSE</code> will
switch off this adjustment.  Since the variance estimator is asymptotically
correct, this should only have an effect when the clustering factors have
very few levels.
</p>
</li>
<li> <p><code>kclass</code> character. For use with instrumental variables. Use a
k-class estimator rather than 2SLS/IV. Currently, the values <code style="white-space: pre;">&#8288;'nagar', 'b2sls', 'mb2sls', 'liml'&#8288;</code> are accepted, where the names are from
<cite>Kolesar et al (2014)</cite>, as well as a numeric value for the 'k' in
k-class. With <code>kclass='liml'</code>, <code>felm</code> also accepts the argument
<code style="white-space: pre;">&#8288;fuller=&lt;numeric&gt;&#8288;</code>, for using a Fuller adjustment of the
liml-estimator.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;Nboot, bootexpr, bootcluster&#8288;</code> Since <code>felm</code> has quite a bit
of overhead in the creation of the model matrix, if one wants confidence
intervals for some function of the estimated parameters, it is possible to
bootstrap internally in <code>felm</code>.  That is, the model matrix is resampled
<code>Nboot</code> times and estimated, and the <code>bootexpr</code> is evaluated
inside an <code>sapply</code>. The estimated coefficients and the left hand
side(s) are available by name. Any right hand side variable <code>x</code> is
available by the name <code>var.x</code>.  The <code>"felm"</code>-object for each
estimation is available as <code>est</code>. If a <code>bootcluster</code> is specified
as a factor, entire levels are resampled. <code>bootcluster</code> can also be a
function with no arguments, it should return a vector of integers, the rows
to use in the sample. It can also be the string 'model', in which case the
cluster is taken from the model. <code>bootexpr</code> should be an expression,
e.g. like <code>quote(x/x2 * abs(x3)/mean(y))</code>.  It could be wise to specify
<code>nostats=TRUE</code> when bootstrapping, unless the covariance matrices are
needed in the bootstrap. If you need the covariance matrices in the full
estimate, but not in the bootstrap, you can specify it in an attribute
<code>"boot"</code> as <code>nostats=structure(FALSE, boot=TRUE)</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;iv, clustervar&#8288;</code> deprecated.  These arguments will be removed at
a later time, but are still supported in this field. Users are
<em>STRONGLY</em> encouraged to use multipart formulas instead.  In
particular, not all functionality is supported with the deprecated syntax;
iv-estimations actually run a lot faster if multipart formulas are used, due
to new algorithms which I didn't bother to shoehorn in place for the
deprecated syntax.
</p>
</li></ul>
</td></tr>
</table>

<hr>
<h2 id='bccorr'>Compute limited mobility bias corrected correlation between fixed effects</h2><span id='topic+bccorr'></span>

<h3>Description</h3>

<p>With a model like <code class="reqn">y = X\beta + D\theta + F\psi + \epsilon</code>, where <code class="reqn">D</code>
and <code class="reqn">F</code> are matrices with dummy encoded factors, one application of <span class="pkg">lfe</span> is to
study the correlation <code class="reqn">cor(D\theta, F\psi)</code>.  However, if we use
estimates for <code class="reqn">\theta</code> and <code class="reqn">\psi</code>, the resulting correlation is biased.
The function <code>bccorr</code> computes a bias corrected correlation
as described in <cite>Gaure (2014)</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bccorr(
  est,
  alpha = getfe(est),
  corrfactors = 1L:2L,
  nocovar = (length(est$X) == 0) &amp;&amp; length(est$fe) == 2,
  tol = 0.01,
  maxsamples = Inf,
  lhs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bccorr_+3A_est">est</code></td>
<td>
<p>an object of class '&quot;felm&quot;', the result of a call to
<code style="white-space: pre;">&#8288;[felm](keepX=TRUE)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bccorr_+3A_alpha">alpha</code></td>
<td>
<p>a data frame, the result of a call to <code><a href="#topic+getfe">getfe()</a></code>.</p>
</td></tr>
<tr><td><code id="bccorr_+3A_corrfactors">corrfactors</code></td>
<td>
<p>integer or character vector of length 2. The factors to
correlate. The default is fine if there are only two factors in the model.</p>
</td></tr>
<tr><td><code id="bccorr_+3A_nocovar">nocovar</code></td>
<td>
<p>logical. Assume no other covariates than the two
factors are present, or that they are uncorrelated with them.</p>
</td></tr>
<tr><td><code id="bccorr_+3A_tol">tol</code></td>
<td>
<p>The absolute tolerance for the bias-corrected correlation.</p>
</td></tr>
<tr><td><code id="bccorr_+3A_maxsamples">maxsamples</code></td>
<td>
<p>Maximum number of samples for the trace sample means estimates</p>
</td></tr>
<tr><td><code id="bccorr_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of left hand side if multiple left hand sides.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bias expressions from <cite>Andrews et al.</cite> are of the form <code class="reqn">tr(AB^{-1}C)</code>
where <code class="reqn">A</code>, <code class="reqn">B</code>, and <code class="reqn">C</code> are  matrices too large to be handled
directly. <code>bccorr</code> estimates the trace by using the formula <code class="reqn">tr(M) = E(x^t M x)</code>
where x is a vector with coordinates drawn uniformly from the set <code class="reqn">\{-1,1\}</code>.
More specifically, the expectation is estimated by
sample means, i.e. in each sample a vector x is drawn, the
equation <code class="reqn">Bv = Cx</code> is solved by a conjugate gradient method, and the
real number <code class="reqn">x^t Av</code> is computed.
</p>
<p>There are three bias corrections, for the variances of <code class="reqn">D\theta</code> (<code>vD</code>) and
<code class="reqn">F\psi</code> (<code>vF</code>), and their covariance (<code>vDF</code>).The correlation is computed as
<code>rho &lt;- vDF/sqrt(vD*vF)</code>.  The variances are estimated to a
relative tolerance specified by the argument <code>tol</code>. The covariance
bias is estimated to an absolute tolerance in the correlation <code>rho</code>
(conditional on the already bias corrected <code>vD</code> and <code>vF</code>) specified by
<code>tol</code>.  The CG algorithm does not need to be exceedingly precise,
it is terminated when the solution reaches a precision which is
sufficient for the chosen precision in <code style="white-space: pre;">&#8288;vD, vF, vDF&#8288;</code>.
</p>
<p>If <code>est</code> is the result of a weighted <code><a href="#topic+felm">felm()</a></code> estimation,
the variances and correlations are weighted too.
</p>


<h3>Value</h3>

<p><code>bccorr</code> returns a named integer vector with the following fields:
</p>
<table>
<tr><td><code>corr</code></td>
<td>
<p>the bias corrected correlation.</p>
</td></tr>
<tr><td><code>v1</code></td>
<td>
<p>the bias corrected variance for the first factor specified
by <code>corrfactors</code>.</p>
</td></tr>
<tr><td><code>v2</code></td>
<td>
<p>the bias corrected variance for the second factor.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the bias corrected covariance between the two factors.</p>
</td></tr>
<tr><td><code>d1</code></td>
<td>
<p>the bias correction for the first factor.</p>
</td></tr>
<tr><td><code>d2</code></td>
<td>
<p>the bias correction for the second factor.</p>
</td></tr>
<tr><td><code>d12</code></td>
<td>
<p>the bias correction for covariance.</p>
</td></tr>
</table>
<p>The bias corrections have been subtracted from the bias estimates.
E.g. v2 = v2' - d2, where v2' is the biased variance.
</p>


<h3>Note</h3>

<p>Bias correction for IV-estimates are not supported as of now.
</p>
<p>Note that if <code>est</code> is the result of a call to <code><a href="#topic+felm">felm()</a></code>
with <code>keepX=FALSE</code> (the default), the correlation will be computed
as if the covariates X are independent of the two factors. This will be
faster (typically by a factor of approx. 4), and possibly wronger.
</p>
<p>Note also that the computations performed by this function are
non-trivial, they may take quite some time.  It would be wise to start
out with quite liberal tolerances, e.g. <cite>tol=0.1</cite>, to
get an idea of the time requirements.
</p>
<p>The algorithm used is not very well suited for small datasets with only
a few thousand levels in the factors.
</p>


<h3>References</h3>

<p>Gaure, S. (2014), <cite>Correlation bias correction in two-way
fixed-effects linear regression</cite>, Stat 3(1):379:390, 2014.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fevcov">fevcov()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(500)
x2 &lt;- rnorm(length(x))

## create individual and firm
id &lt;- factor(sample(40, length(x), replace = TRUE))
firm &lt;- factor(sample(30, length(x), replace = TRUE, prob = c(2, rep(1, 29))))
foo &lt;- factor(sample(20, length(x), replace = TRUE))
## effects
id.eff &lt;- rnorm(nlevels(id))
firm.eff &lt;- rnorm(nlevels(firm))
foo.eff &lt;- rnorm(nlevels(foo))
## left hand side
y &lt;- x + 0.25 * x2 + id.eff[id] + firm.eff[firm] + foo.eff[foo] + rnorm(length(x))

# make a data frame
fr &lt;- data.frame(y, x, x2, id, firm, foo)
## estimate and print result
est &lt;- felm(y ~ x + x2 | id + firm + foo, data = fr, keepX = TRUE)
# find bias corrections
bccorr(est)
</code></pre>

<hr>
<h2 id='btrap'>Bootstrap standard errors for the group fixed effects</h2><span id='topic+btrap'></span>

<h3>Description</h3>

<p>Bootstrap standard errors for the group fixed effects which were swept out
during an estimation with <code><a href="#topic+felm">felm()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>btrap(
  alpha,
  obj,
  N = 100,
  ef = NULL,
  eps = getOption("lfe.eps"),
  threads = getOption("lfe.threads"),
  robust = FALSE,
  cluster = NULL,
  lhs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="btrap_+3A_alpha">alpha</code></td>
<td>
<p>data frame returned from <code><a href="#topic+getfe">getfe()</a></code></p>
</td></tr>
<tr><td><code id="btrap_+3A_obj">obj</code></td>
<td>
<p>object of class <code>"felm"</code>, usually, a result of a call to
<code><a href="#topic+felm">felm()</a></code></p>
</td></tr>
<tr><td><code id="btrap_+3A_n">N</code></td>
<td>
<p>integer.  The number of bootstrap iterations</p>
</td></tr>
<tr><td><code id="btrap_+3A_ef">ef</code></td>
<td>
<p>function.  An estimable function such as in <code><a href="#topic+getfe">getfe()</a></code>.
The default is to use the one used on <code>alpha</code></p>
</td></tr>
<tr><td><code id="btrap_+3A_eps">eps</code></td>
<td>
<p>double. Tolerance for centering, as in getfe</p>
</td></tr>
<tr><td><code id="btrap_+3A_threads">threads</code></td>
<td>
<p>integer.  The number of threads to use</p>
</td></tr>
<tr><td><code id="btrap_+3A_robust">robust</code></td>
<td>
<p>logical. Should heteroskedastic standard errors be estimated?</p>
</td></tr>
<tr><td><code id="btrap_+3A_cluster">cluster</code></td>
<td>
<p>logical or factor. Estimate clustered standard errors.</p>
</td></tr>
<tr><td><code id="btrap_+3A_lhs">lhs</code></td>
<td>
<p>character vector. Specify which left hand side if <code>obj</code> has
multiple lhs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bootstrapping is done in parallel if <code>threads &gt; 1</code>.
<code><a href="#topic+btrap">btrap()</a></code> is run automatically from <code><a href="#topic+getfe">getfe()</a></code> if
<code>se=TRUE</code> is specified.  To save some overhead, the individual
iterations are grouped together, the memory available for this grouping is
fetched with <code>getOption('lfe.bootmem')</code>, which is initialized upon
loading of <span class="pkg">lfe</span> to <code>options(lfe.bootmem=500)</code> (MB).
</p>
<p>If <code>robust=TRUE</code>, heteroskedastic robust standard errors are estimated.
If <code>robust=FALSE</code> and <code>cluster=TRUE</code>, clustered standard errors
with the cluster specified to <code>felm()</code> are estimated. If <code>cluster</code>
is a factor, it is used for the cluster definition.  <code style="white-space: pre;">&#8288;cluster may&#8288;</code> also
be a list of factors.
</p>


<h3>Value</h3>

<p>A data-frame of the same size as alpha is returned, with standard
errors filled in.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
## create covariates
x &lt;- rnorm(3000)
x2 &lt;- rnorm(length(x))

## create individual and firm
id &lt;- factor(sample(700, length(x), replace = TRUE))
firm &lt;- factor(sample(300, length(x), replace = TRUE))

## effects
id.eff &lt;- rlnorm(nlevels(id))
firm.eff &lt;- rexp(nlevels(firm))

## left hand side
y &lt;- x + 0.25 * x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))

## estimate and print result
est &lt;- felm(y ~ x + x2 | id + firm)
summary(est)
## extract the group effects
alpha &lt;- getfe(est)
head(alpha)
## bootstrap standard errors
head(btrap(alpha, est))

## bootstrap some differences
ef &lt;- function(v, addnames) {
  w &lt;- c(v[2] - v[1], v[3] - v[2], v[3] - v[1])
  if (addnames) {
    names(w) &lt;- c("id2-id1", "id3-id2", "id3-id1")
    attr(w, "extra") &lt;- list(note = c("line1", "line2", "line3"))
  }
  w
}
# check that it's estimable
is.estimable(ef, est$fe)

head(btrap(alpha, est, ef = ef))
options(oldopts)

</code></pre>

<hr>
<h2 id='cgsolve'>Solve a symmetric linear system with the conjugate gradient method</h2><span id='topic+cgsolve'></span>

<h3>Description</h3>

<p><code>cgsolve</code> uses a conjugate gradient algorithm to solve the linear
system <code class="reqn">A x = b</code> where <code class="reqn">A</code> is a symmetric matrix.  <code>cgsolve</code> is
used internally in <span class="pkg">lfe</span> in the routines <code><a href="#topic+fevcov">fevcov()</a></code> and
<code><a href="#topic+bccorr">bccorr()</a></code>, but has been made public because it might be useful
for other purposes as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cgsolve(A, b, eps = 0.001, init = NULL, symmtest = FALSE, name = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cgsolve_+3A_a">A</code></td>
<td>
<p>matrix, Matrix or function.</p>
</td></tr>
<tr><td><code id="cgsolve_+3A_b">b</code></td>
<td>
<p>vector or matrix of columns vectors.</p>
</td></tr>
<tr><td><code id="cgsolve_+3A_eps">eps</code></td>
<td>
<p>numeric. Tolerance.</p>
</td></tr>
<tr><td><code id="cgsolve_+3A_init">init</code></td>
<td>
<p>numeric. Initial guess.</p>
</td></tr>
<tr><td><code id="cgsolve_+3A_symmtest">symmtest</code></td>
<td>
<p>logical. Should the matrix be tested for symmetry?</p>
</td></tr>
<tr><td><code id="cgsolve_+3A_name">name</code></td>
<td>
<p>character. Arbitrary name used in progress reports.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>A</code> can be a symmetric matrix or a symmetric sparse matrix
inheriting from <code>"Matrix"</code> of the package <span class="pkg">Matrix</span>.  It can also be
a function which performs the matrix-vector product. If so, the function
must be able to take as input a matrix of column vectors.
</p>
<p>If the matrix <code>A</code> is rank deficient, some solution is returned.  If
there is no solution, a vector is returned which may or may not be close to
a solution.  If <code>symmtest</code> is <code>FALSE</code>, no check is performed that
<code>A</code> is symmetric. If not symmetric, <code>cgsolve</code> is likely to raise
an error about divergence.
</p>
<p>The tolerance <code>eps</code> is a relative tolerance, i.e.  <code class="reqn">||x - x_0|| &lt;
\epsilon ||x_0||</code> where <code class="reqn">x_0</code> is the true solution and <code class="reqn">x</code> is the
solution returned by <code>cgsolve</code>. Use a negative <code>eps</code> for absolute
tolerance.  The termination criterion for <code>cgsolve</code> is the one from
<cite>Kaasschieter (1988)</cite>, Algorithm 3.
</p>
<p>Preconditioning is currently not supported.
</p>
<p>If <code>A</code> is a function, the test for symmetry is performed by drawing two
random vectors <code style="white-space: pre;">&#8288;x,y&#8288;</code>, and testing whether <code class="reqn">|(Ax, y) - (x, Ay)| &lt;
10^{-6} sqrt((||Ax||^2 + ||Ay||^2)/N)</code>, where <code class="reqn">N</code> is the vector length.
Thus, the test is neither deterministic nor perfect.
</p>


<h3>Value</h3>

<p>A solution <code class="reqn">x</code> of the linear system <code class="reqn">A x = b</code> is returned.
</p>


<h3>References</h3>

<p>Kaasschieter, E. (1988) <cite>A practical termination criterion
for the conjugate gradient method</cite>, BIT Numerical Mathematics,
28(2):308-322.  <a href="https://link.springer.com/article/10.1007/BF01934094">https://link.springer.com/article/10.1007/BF01934094</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kaczmarz">kaczmarz()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
N &lt;- 100000
# create some factors
f1 &lt;- factor(sample(34000, N, replace = TRUE))
f2 &lt;- factor(sample(25000, N, replace = TRUE))
# a matrix of dummies, which probably is rank deficient
B &lt;- makeDmatrix(list(f1, f2))
dim(B)
# create a right hand side
b &lt;- as.matrix(B %*% rnorm(ncol(B)))
# solve B' B x = B' b
sol &lt;- cgsolve(crossprod(B), crossprod(B, b), eps = -1e-2)
# verify solution
sqrt(sum((B %*% sol - b)^2))

</code></pre>

<hr>
<h2 id='chainsubset'>Chain subset conditions</h2><span id='topic+chainsubset'></span>

<h3>Description</h3>

<p>Chain subset conditions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chainsubset(..., out.vars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chainsubset_+3A_...">...</code></td>
<td>
<p>Logical conditions to be chained.</p>
</td></tr>
<tr><td><code id="chainsubset_+3A_out.vars">out.vars</code></td>
<td>
<p>character. Variables not in data.frame, only needed if you use variables which
are not in the frame.  If <code>out.vars</code> is not specified, it is assumed to match all variables
starting with a dot ('.').</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A set of logical conditions are chained, not and'ed. That is, each argument to
<code>chainsubset</code> is used as a filter to create a smaller dataset. Each subsequent
argument filters further.
For independent conditions this will be the same as and'ing them. I.e.
<code>chainsubset(x &lt; 0 , y &lt; 0)</code> will yield  the same subset as <code>(x &lt; 0) &amp; (y &lt; 0)</code>.
However, for aggregate filters like <code>chainsubset(x &lt; mean(y), x &gt; mean(y))</code>
we first find all the observations with <code>x &lt; mean(y)</code>, then among these we
find the ones with <code>x &gt; mean(y)</code>.  The last <code>mean(y)</code> is now conditional on
<code>x &lt; mean(y)</code>.
</p>


<h3>Value</h3>

<p>Expression that can be <code>eval</code>'ed to yield a logical subset mask.
</p>


<h3>Note</h3>

<p>Some trickery is done to make this work directly in the subset argument of functions like
<code>felm()</code> and <code>lm()</code>. It might possibly fail with an error message in some situations.
If this happens, it should be done in two steps: <code style="white-space: pre;">&#8288;ss &lt;- eval(chainsubset(...),data); lm(...,data=data, subset=ss)&#8288;</code>. In particular, the arguments are taken literally,
constructions like <code>function(...) {chainsubset(...)}</code> or <code style="white-space: pre;">&#8288;a &lt;- quote(x &lt; y); chainsubset(a)&#8288;</code> do
not work, but <code>do.call(chainsubset,list(a))</code> does.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(48)
N &lt;- 10000
dat &lt;- data.frame(y = rnorm(N), x = rnorm(N))
# It's not the same as and'ing the conditions:
felm(y ~ x, data = dat, subset = chainsubset(x &lt; mean(y), y &lt; 2 * mean(x)))
felm(y ~ x, data = dat, subset = chainsubset(y &lt; 2 * mean(x), x &lt; mean(y)))
felm(y ~ x, data = dat, subset = (x &lt; mean(y)) &amp; (y &lt; 2 * mean(x)))
lm(y ~ x, data = dat, subset = chainsubset(x &lt; mean(y), x &gt; mean(y)))
</code></pre>

<hr>
<h2 id='compfactor'>Find the connected components</h2><span id='topic+compfactor'></span>

<h3>Description</h3>

<p>'compfactor' computes the connected components of the dummy-part of the
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compfactor(fl, WW = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compfactor_+3A_fl">fl</code></td>
<td>
<p>a list of factors defining the dummies</p>
</td></tr>
<tr><td><code id="compfactor_+3A_ww">WW</code></td>
<td>
<p>logical. Use Weeks and Williams components</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are more than two factors and <code>WW=FALSE</code>, only the first two
will be used.
</p>
<p>If <code>WW=TRUE</code> and <code>length(fl) &gt; 2</code>, the component structure will be
as in &quot;A Note on the Determination of Connectedness in an N-Way Cross
Classification&quot; by D.L. Weeks and D.R. Williams, Technometrics, vol 6 no 3,
August 1964. I.e. in each component, the coefficients within each factor are
comparable, that is, their difference is estimable even if there are more
than two factors.  That is, one may use one reference in each factor in each
component, and interpret the coefficients within a component as usual. This
is not an exhaustion of all the estimable functions.  There is somewhat more
about this in one of the vignettes.
</p>


<h3>Value</h3>

<p>A factor of the same length as the factors in the input argument.
It defines the connected components. E.g. <code>nlevels(compfactor(fl))</code>
will yield the number of connected components.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## create two factors
f1 &lt;- factor(sample(300, 400, replace = TRUE))
f2 &lt;- factor(sample(300, 400, replace = TRUE))

## find the components
cf &lt;- compfactor(list(f1 = f1, f2 = f2))

## show the third largest component
fr &lt;- data.frame(f1, f2, cf)
fr[cf == 3, ]

</code></pre>

<hr>
<h2 id='condfstat'>Compute conditional F statistic for weak instruments in an IV-estimation
with multiple endogenous variables</h2><span id='topic+condfstat'></span>

<h3>Description</h3>

<p>When using multiple instruments for multiple endogenous variables, the
ordinary individual t-tests for the instruments in the first stage do not
always reveal a weak set of instruments.  Conditional F statistics can be
used for such testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>condfstat(object, type = "default", quantiles = 0, bN = 100L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="condfstat_+3A_object">object</code></td>
<td>
<p>object of class <code>"felm"</code>, a result of a call to
<code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code id="condfstat_+3A_type">type</code></td>
<td>
<p>character. Error structure. Passed to <code><a href="#topic+waldtest">waldtest()</a></code>. If
<code>NULL</code>, both iid and robust Fs are returned.</p>
</td></tr>
<tr><td><code id="condfstat_+3A_quantiles">quantiles</code></td>
<td>
<p>numeric. Quantiles for bootstrap.</p>
</td></tr>
<tr><td><code id="condfstat_+3A_bn">bN</code></td>
<td>
<p>integer. Number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>IV coefficient estimates are not normally distributed, in particular they do
not have the right expectation.  They follow a quite complicated
distribution which is fairly close to normal if the instruments are good.
The conditional F-statistic is a measure of how good the instruments are.
If the F is large, the instruments are good, and any bias due to the
instruments is small compared to the estimated standard errors, and also
small relative to the bias in OLS. See <cite>Sanderson and Windmeijer
(2014)</cite> and <cite>Stock and Yogo (2004)</cite>.  If F is small, the bias can be
large compared to the standard error.
</p>
<p>If <code>any(quantiles &gt; 0.0)</code>, a bootstrap with <code>bN</code> samples will be
performed to estimate quantiles of the endogenous parameters which includes
the variance both from the 1st and 2nd stage.  The result is returned in an
array attribute <code>quantiles</code> of the value returned by <code>condfstat</code>.
The argument <code>quantiles</code> can be a vector to estimate more than one
quantile at once.  If <code>quantiles=NULL</code>, the bootstrapped estimates
themselves are returned.  The bootstrap is normally much faster than running
<code>felm</code> over and over again. This is so because all exogenous variables
are projected out of the equations before doing the bootstrap.
</p>


<h3>Value</h3>

<p>A p x k matrix, where k is the number of endogenous variables. Each
row are the conditional F statistics on a residual equation as described in
<cite>Sanderson and Windmeijer (2014)</cite>, for a certain error structure.  The
default is to use iid, or cluster if a cluster was specified to
<code><a href="#topic+felm">felm()</a></code>. The third choice is <code>'robust'</code>, for heteroskedastic
errors. If <code>type=NULL</code>, iid and robust Fs are returned, and cluster, if
that was specified to <code>felm</code>.
</p>
<p>Note that for these F statistics it is not the p-value that matters, it is
the F statistic itself which (coincidentally) pops up in the denominator for
the asymptotic bias of the IV estimates, and thus a large F is beneficial.
</p>


<h3>Note</h3>

<p>Please note that <code>condfstat</code> does not work with the old syntax
for IV in <code style="white-space: pre;">&#8288;[felm](...,iv=)&#8288;</code>. The new multipart syntax must be
used.
</p>


<h3>References</h3>

<p>Sanderson, E. and F. Windmeijer (2014) <cite>A weak instrument
F-test in linear IV models with multiple endogenous variables</cite>, Journal of
Econometrics, 2015.
<a href="https://www.sciencedirect.com/science/article/pii/S0304407615001736">https://www.sciencedirect.com/science/article/pii/S0304407615001736</a>
</p>
<p>Stock, J.H. and M. Yogo (2004) <cite>Testing for weak instruments in linear
IV regression</cite>, <a href="https://www.ssrn.com/abstract=1734933">https://www.ssrn.com/abstract=1734933</a> in
<cite>Identification and inference for econometric models: Essays in honor
of Thomas Rothenberg</cite>, 2005.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
z1 &lt;- rnorm(4000)
z2 &lt;- rnorm(length(z1))
u &lt;- rnorm(length(z1))
# make x1, x2 correlated with errors u

x1 &lt;- z1 + z2 + 0.2 * u + rnorm(length(z1))
x2 &lt;- z1 + 0.94 * z2 - 0.3 * u + rnorm(length(z1))
y &lt;- x1 + x2 + u
est &lt;- felm(y ~ 1 | 0 | (x1 | x2 ~ z1 + z2))
summary(est)
## Not run: 
summary(est$stage1, lhs = "x1")
summary(est$stage1, lhs = "x2")

## End(Not run)

# the joint significance of the instruments in both the first stages are ok:
t(sapply(est$stage1$lhs, function(lh) waldtest(est$stage1, ~ z1 | z2, lhs = lh)))
# everything above looks fine, t-tests for instruments,
# as well as F-tests for excluded instruments in the 1st stages.
# The conditional F-test reveals that the instruments are jointly weak
# (it's close to being only one instrument, z1+z2, for both x1 and x2)
condfstat(est, quantiles = c(0.05, 0.95))

</code></pre>

<hr>
<h2 id='demeanlist'>Centre vectors on multiple groups</h2><span id='topic+demeanlist'></span>

<h3>Description</h3>

<p>Uses the method of alternating projections to centre
a (model) matrix on multiple groups, as specified by a list of factors.
This function is called by <code><a href="#topic+felm">felm()</a></code>, but it has been
made available as standalone in case it's needed. In particular, if
one does not need transformations provided by R-formulas but have the covariates present
as a matrix or a data.frame, a substantial amount of time can be saved in the centering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demeanlist(
  mtx,
  fl,
  icpt = 0L,
  eps = getOption("lfe.eps"),
  threads = getOption("lfe.threads"),
  progress = getOption("lfe.pint"),
  accel = getOption("lfe.accel"),
  randfact = TRUE,
  means = FALSE,
  weights = NULL,
  scale = TRUE,
  na.rm = FALSE,
  attrs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="demeanlist_+3A_mtx">mtx</code></td>
<td>
<p>matrix whose columns form vectors to be group-centred. mtx
can also be a list of vectors or matrices, such as a data frame.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_fl">fl</code></td>
<td>
<p>list of factors defining the grouping structure.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_icpt">icpt</code></td>
<td>
<p>the position of the intercept, this column is removed from
the result matrix.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_eps">eps</code></td>
<td>
<p>a tolerance for the centering.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_threads">threads</code></td>
<td>
<p>an integer specifying the number of threads to use.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_progress">progress</code></td>
<td>
<p>integer. If positive, make progress reports (whenever a
vector is centered, but not more often than every <code>progress</code> minutes).</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_accel">accel</code></td>
<td>
<p>integer. Set to 1 if Gearhart-Koshy acceleration should be done.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_randfact">randfact</code></td>
<td>
<p>logical. Should the order of the factors be randomized?
This may improve convergence.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_means">means</code></td>
<td>
<p>logical. Should the means instead of the demeaned matrix be
returned? Setting <code>means=TRUE</code> will return <code>mtx -  demeanlist(mtx,...)</code>,
but without the extra copy.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_weights">weights</code></td>
<td>
<p>numeric. For weighted demeaning.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_scale">scale</code></td>
<td>
<p>logical. Specify scaling for weighted demeaning.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_na.rm">na.rm</code></td>
<td>
<p>logical which indicates what should happen when the data
contain <code>NA</code>s. If TRUE, rows in the input <code>mtx</code> are removed
prior to centering. If FALSE, they are kept, leading to entire groups becoming NA
in the output.</p>
</td></tr>
<tr><td><code id="demeanlist_+3A_attrs">attrs</code></td>
<td>
<p>list. List of attributes which should be attached to the output.
Used internally.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column <code>y</code> in <code>mtx</code>, the equivalent of the
following centering is performed, with <code>cy</code> as the result.
</p>
<pre>
cy &lt;- y; oldy &lt;- y-1
while(sqrt(sum((cy-oldy)**2)) &gt;= eps) {
 oldy &lt;- cy
 for(f in fl) cy &lt;- cy - ave(cy,f)
}
</pre>
<p>Each factor in <code>fl</code> may contain an
attribute <code>'x'</code> which is a numeric vector of the same length as
the factor. The centering is then not done on the means of each group,
but on the projection onto the covariate in each group.  That is, with a
covariate <code>x</code> and a factor <code>f</code>, it is like projecting out the
interaction <code>x:f</code>.  The <code>'x'</code> attribute can also be a matrix of column
vectors, in this case it can be beneficial to orthogonalize the columns,
either with a stabilized Gram-Schmidt method, or with the simple
method <code style="white-space: pre;">&#8288;x \%*\% solve(chol(crossprod(x)))&#8288;</code>.
</p>
<p>The <code>weights</code> argument is used if a weighted projection is
computed.  If <code class="reqn">W</code> is the diagonal matrix with <code>weights</code> on the
diagonal, <code>demeanlist</code> computes <code class="reqn">W^{-1} M_{WD} W x</code> where <code class="reqn">x</code> is
the input vector, <code class="reqn">D</code> is the matrix of dummies from <code>fl</code> and
<code class="reqn">M_{WD}</code> is the projection on the orthogonal complement of
the range of the matrix <code class="reqn">WD</code>.  It is possible to implement the
weighted projection with the <code>'x'</code> attribute mentioned above, but
it is a separate argument for convenience.
If <code>scale=FALSE</code>, <code>demeanlist</code> computes <code class="reqn">M_{WD} x</code> without
any <code class="reqn">W</code> scaling.
If <code>length(scale) &gt; 1</code>, then <code>scale[1]</code> specifies whether
the input should be scaled by <code class="reqn">W</code>, and <code>scale[2]</code> specifies
whether the output should be scaled by <code class="reqn">W^{-1}</code>.  This is just
a convenience to save some memory copies in other functions in the package.
</p>
<p>Note that for certain large datasets the overhead in <code><a href="#topic+felm">felm()</a></code>
is large compared to the time spent in <code>demeanlist</code>. If the data
are present directly without having to use the formula-interface to
<code>felm</code> for transformations etc, it is possible to run
<code>demeanlist</code> directly on a matrix or <code>"data.frame"</code> and do the
OLS &quot;manually&quot;, e.g. with something like
<code style="white-space: pre;">&#8288;cx &lt;- demeanlist(x,...); beta &lt;- solve(crossprod(cx), crossprod(cx,y))&#8288;</code>
</p>
<p>In some applications it is known that a single centering iteration is
sufficient. In particular, if <code>length(fl)==1</code> and there is no
interaction attribute <code>x</code>.  In this case the centering algorithm is
terminated after the first iteration. There may be other cases, e.g. if
there is a single factor with a matrix <code>x</code> with orthogonal columns. If
you have such prior knowledge, it is possible to force termination after
the first iteration by adding an attribute <code>attr(fl, 'oneiter') &lt;- TRUE</code>.  Convergence will be reached in the second iteration anyway, but
you save one iteration, i.e. you double the speed.
</p>


<h3>Value</h3>

<p>If <code>mtx</code> is a matrix, a matrix of the same shape, possibly with
column <code>icpt</code> deleted.
</p>
<p>If <code>mtx</code> is a list of vectors and matrices, a list of the same
length is returned, with the same vector and matrix-pattern, but the
matrices have the column <code>icpt</code> deleted.
</p>
<p>If <code>mtx</code> is a <code>'data.frame'</code>, a <code>'data.frame'</code>
with the same names is returned; the <code>icpt</code> argument is ignored.
</p>
<p>If <code>na.rm</code> is specified, the return value has an attribute <code>'na.rm'</code> with a vector of
row numbers which has been removed. In case the input is a matrix or list, the same rows
are removed from all of them. Note that removing NAs incurs a copy of the input, so if
memory usage is an issue and many runs are done, one might consider removing NAs from the data set entirely.
</p>


<h3>Note</h3>

<p>The <code>accel</code> argument enables Gearhart-Koshy acceleration as
described in Theorem 3.16 by Bauschke, Deutsch, Hundal and Park in &quot;Accelerating the
convergence of the method of alternating projections&quot;,
Trans. Amer. Math. Soc. 355 pp 3433-3461 (2003).
</p>
<p><code>demeanlist</code> will use an in place transform to save memory, provided the <code>mtx</code>
argument is unnamed. Thus, as always in R, you shouldn't use temporary variables
like <code style="white-space: pre;">&#8288;tmp &lt;- fun(x[v,]); bar &lt;- demeanlist(tmp,...); rm(tmp)&#8288;</code>, it will be much better to
do <code>bar &lt;- demeanlist(fun(x[v,]),...)</code>. However, demeanlist allows a construction like
<code>bar &lt;- demeanlist(unnamed(tmp),...)</code> which will use an in place transformation, i.e. tmp
will be modified, quite contrary to the usual semantics of R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
## create a matrix
mtx &lt;- data.frame(matrix(rnorm(999), ncol = 3))
# a list of factors
rgb &lt;- c("red", "green", "blue")
fl &lt;- replicate(4, factor(sample(rgb, nrow(mtx), replace = TRUE)), simplify = FALSE)
names(fl) &lt;- paste("g", seq_along(fl), sep = "")
# centre on all means
mtx0 &lt;- demeanlist(mtx, fl)
head(data.frame(mtx0, fl))
# verify that the group means for the columns are zero
lapply(fl, function(f) apply(mtx0, 2, tapply, f, mean))
options(oldopts)
</code></pre>

<hr>
<h2 id='diammatrix'>Find diameters of mobility graphs</h2><span id='topic+diammatrix'></span>

<h3>Description</h3>

<p>'diammatrix' computes the diameters of certain graphs related to convergence
speed of <code>felm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diammatrix(flist, approx = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diammatrix_+3A_flist">flist</code></td>
<td>
<p>a list of factors defining the dummies.</p>
</td></tr>
<tr><td><code id="diammatrix_+3A_approx">approx</code></td>
<td>
<p>logical. Approximate diameters are computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each pair of factors (f1,f2) from <code>flist</code> defines a bipartite graph in
which the vertices are the levels of the factors, and two vertices are
adjacent if they are observed simultaneously. The connected components of
this graph are important for identification of the coefficients for the
factor levels, i.e. for <code>getfe</code>. But experience and some trials have
led the author to speculate that the diameter of the graph (or its largest
component) is also important for the convergence rate.  Specifically, the
author suspects that under some assumptions, time to convergence goes like
the square of the diameter.  At least in the case of two factors.  This
function computes the diameter for each pair of factors.  If the graph is
disconnected, the largest connected component is used. If <code>accel=TRUE</code>
(the default), the diameter is approximated from below by drawing two sets
of 10 random vertices and finding the maximum length of the shortest paths
between them.
</p>


<h3>Value</h3>

<p>A matrix of dimension K x K where K is <code>length(flist)</code>.
</p>


<h3>Note</h3>

<p>This function is not important to the operation of the package, it is
included for easy experimentation with the convergence rate.  It requires
that the suggested package <span class="pkg">igraph</span> is attached.
</p>

<hr>
<h2 id='efactory'>Create estimable function</h2><span id='topic+efactory'></span>

<h3>Description</h3>

<p>Creates an estimable function for a factor-structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efactory(obj, opt = "ref", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efactory_+3A_obj">obj</code></td>
<td>
<p>object of class <code>"felm"</code>, usually, a result of a call to
<code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code id="efactory_+3A_opt">opt</code></td>
<td>
<p>character.  Which type of estimable function.</p>
</td></tr>
<tr><td><code id="efactory_+3A_...">...</code></td>
<td>
<p>various.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several possibilities for the input parameter <code>opt</code>.
</p>
 <ul>
<li> <p><code>"ref"</code> yields an estimable function which is similar
to the default one in <code><a href="stats.html#topic+lm">lm()</a></code>, one reference is forced to <code>0</code>
in each connected component.  </p>
</li>
<li> <p><code>"zm"</code> Similar to <code>"ref"</code>, but
the factor which does not contain a reference is made to have zero mean, and
an intercept is added.  </p>
</li>
<li> <p><code>"zm2"</code> Similar to <code>"zm"</code>, but both
factors are made to have zero mean.  </p>
</li>
<li> <p><code>"ln"</code> Least norm function.
This will yield the raw coefficients from the Kaczmarz-method, i.e. the
solution with smallest norm. This function is not estimable.  </p>
</li></ul>
<p> Note that in
the case with more than two factors, it is not known how to analyze the
factors to find the structure of the rank-deficiencies, i.e. the estimable
functions.  In this case, the factors beyond the first two are assumed not
to contribute to the rank-deficiency beyond a single dimension in each.
Both <code>"ref"</code> and <code>"zm"</code> keep one such reference at zero in each of
these factors.  This is the common method when using dummies.
</p>
<p>In the case that interactions are specified in the model, i.e. with
<code>x:f</code> in the second part of the formula, these terms are not analyzed
to create an estimable function. Only the pure <code>f</code> terms are used for
this purpose.  It is assumed that the <code>x:f</code> terms are all identified.
Note that in this case, all the levels of <code>f</code> are included.
</p>


<h3>Value</h3>

<p>A function of two parameters <code style="white-space: pre;">&#8288;function(v,addnames)&#8288;</code>.  An
estimable function (i.e. the result is the vector of some length <code>N</code>)
of the input vector <code>v</code>. When <code>addnames==TRUE</code> the returned vector
should have names, and optionally an attribute <code>"extra"</code> which is a
list of vectors of length <code>N</code> which may be used to code additional
information.
</p>


<h3>Note</h3>

<p>The author is open to suggestions for other estimable functions, i.e.
other useful normalizations of the solutions.
</p>
<p>It is not strictly necessary that the <code>obj</code> argument is of class
<code>"felm"</code>, any list with entries <code>"fe"</code> and <code>"cfactor"</code> of the
appropriate form will do. That is, <code>list(fe=fl,cfactor=compfactor(fl))</code>
where <code>fl</code> is the list of factors defining the component structure.
I.e. if the model is <code>y ~ ... |id + firm</code>, we have
<code>fl=list(id=id,firm=firm)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
id &lt;- factor(sample(5000, 50000, replace = TRUE))
firm &lt;- factor(sample(3000, 50000, replace = TRUE))
fl &lt;- list(id = id, firm = firm)
obj &lt;- list(fe = fl, cfactor = compfactor(fl))
## the trivial least-norm  transformtion, which by the way is non-estimable
print(ef &lt;- efactory(obj, "ln"))
is.estimable(ef, fl)
## then the default
print(ef &lt;- efactory(obj, "ref"))
is.estimable(ef, fl)
# get the names of the coefficients, i.e. the nm-variable in the function
head(evalq(nm, environment(ef)))
options(oldopts)

</code></pre>

<hr>
<h2 id='felm'>Fit a linear model with multiple group fixed effects</h2><span id='topic+felm'></span>

<h3>Description</h3>

<p>'felm' is used to fit linear models with multiple group fixed effects,
similarly to lm.  It uses the Method of Alternating projections to sweep out
multiple group effects from the normal equations before estimating the
remaining coefficients with OLS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>felm(
  formula,
  data,
  exactDOF = FALSE,
  subset,
  na.action,
  contrasts = NULL,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="felm_+3A_formula">formula</code></td>
<td>
<p>an object of class '&quot;formula&quot;' (or one that can be coerced to
that class): a symbolic description of the model to be fitted. Similarly to
'lm'.  See Details.</p>
</td></tr>
<tr><td><code id="felm_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables of the model.</p>
</td></tr>
<tr><td><code id="felm_+3A_exactdof">exactDOF</code></td>
<td>
<p>logical. If more than two factors, the degrees of freedom
used to scale the covariance matrix (and the standard errors) is normally
estimated. Setting <code>exactDOF=TRUE</code> causes <code>felm</code> to attempt to
compute it, but this may fail if there are too many levels in the factors.
<code>exactDOF='rM'</code> will use the exact method in
<code>Matrix::rankMatrix()</code>, but this is slower. If neither of these methods
works, it is possible to specify <code>exactDOF='mc'</code>, which utilizes a
Monte-Carlo method to estimate the expectation E(x' P x) = tr(P), the trace
of a certain projection, a method which may be more accurate than the
default guess.
</p>
<p>If the degrees of freedom for some reason are known, they can be specified
like <code>exactDOF=342772</code>.</p>
</td></tr>
<tr><td><code id="felm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="felm_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain <code>NA</code>s.  The default is set by the <code>na.action</code> setting of
<code>options</code>, and is <code>na.fail</code> if that is unset.  The 'factory-fresh'
default is <code>na.omit</code>.  Another possible value is <code>NULL</code>, no
action. <code>na.exclude</code> is currently not supported.</p>
</td></tr>
<tr><td><code id="felm_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code> of
<code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="felm_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process.  Should be 'NULL' or a numeric vector.  If non-NULL, weighted least
squares is used with weights <code>weights</code> (that is, minimizing
<code>sum(w*e^2)</code>); otherwise ordinary least squares is used.</p>
</td></tr>
<tr><td><code id="felm_+3A_...">...</code></td>
<td>
<p>other arguments.  </p>

<ul>
<li> <p><code>cmethod</code> character. Which clustering method to use. Known
arguments are <code>'cgm'</code> (the default), <code>'cgm2'</code> (or <code>'reghdfe'</code>,
its alias). These alternate methods will generally
yield equivalent results, except in the case of multiway clustering with few
clusters along at least one dimension.
</p>
</li>
<li> <p><code>keepX</code> logical. To include a copy of the expanded data matrix in
the return value, as needed by <code><a href="#topic+bccorr">bccorr()</a></code> and <code><a href="#topic+fevcov">fevcov()</a></code>
for proper limited mobility bias correction.
</p>
</li>
<li> <p><code>keepCX</code> logical. Keep a copy of the centred expanded data matrix
in the return value. As list elements <code>cX</code> for the explanatory
variables, and <code>cY</code> for the outcome.
</p>
</li>
<li> <p><code>keepModel</code> logical. Keep a copy of the model frame.
</p>
</li>
<li> <p><code>nostats</code> logical. Don't include covariance matrices in the
output, just the estimated coefficients and various descriptive information.
For IV, <code>nostats</code> can be a logical vector of length 2, with the last
value being used for the 1st stages.  </p>
</li>
<li> <p><code>psdef</code> logical. In case of
multiway clustering, the method of Cameron, Gelbach and Miller may yield a
non-definite variance matrix. Ordinarily this is forced to be semidefinite
by setting negative eigenvalues to zero. Setting <code>psdef=FALSE</code> will
switch off this adjustment.  Since the variance estimator is asymptotically
correct, this should only have an effect when the clustering factors have
very few levels.
</p>
</li>
<li> <p><code>kclass</code> character. For use with instrumental variables. Use a
k-class estimator rather than 2SLS/IV. Currently, the values <code style="white-space: pre;">&#8288;'nagar', 'b2sls', 'mb2sls', 'liml'&#8288;</code> are accepted, where the names are from
<cite>Kolesar et al (2014)</cite>, as well as a numeric value for the 'k' in
k-class. With <code>kclass='liml'</code>, <code>felm</code> also accepts the argument
<code style="white-space: pre;">&#8288;fuller=&lt;numeric&gt;&#8288;</code>, for using a Fuller adjustment of the
liml-estimator.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;Nboot, bootexpr, bootcluster&#8288;</code> Since <code>felm</code> has quite a bit
of overhead in the creation of the model matrix, if one wants confidence
intervals for some function of the estimated parameters, it is possible to
bootstrap internally in <code>felm</code>.  That is, the model matrix is resampled
<code>Nboot</code> times and estimated, and the <code>bootexpr</code> is evaluated
inside an <code>sapply</code>. The estimated coefficients and the left hand
side(s) are available by name. Any right hand side variable <code>x</code> is
available by the name <code>var.x</code>.  The <code>"felm"</code>-object for each
estimation is available as <code>est</code>. If a <code>bootcluster</code> is specified
as a factor, entire levels are resampled. <code>bootcluster</code> can also be a
function with no arguments, it should return a vector of integers, the rows
to use in the sample. It can also be the string 'model', in which case the
cluster is taken from the model. <code>bootexpr</code> should be an expression,
e.g. like <code>quote(x/x2 * abs(x3)/mean(y))</code>.  It could be wise to specify
<code>nostats=TRUE</code> when bootstrapping, unless the covariance matrices are
needed in the bootstrap. If you need the covariance matrices in the full
estimate, but not in the bootstrap, you can specify it in an attribute
<code>"boot"</code> as <code>nostats=structure(FALSE, boot=TRUE)</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;iv, clustervar&#8288;</code> deprecated.  These arguments will be removed at
a later time, but are still supported in this field. Users are
<em>STRONGLY</em> encouraged to use multipart formulas instead.  In
particular, not all functionality is supported with the deprecated syntax;
iv-estimations actually run a lot faster if multipart formulas are used, due
to new algorithms which I didn't bother to shoehorn in place for the
deprecated syntax.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended for use with large datasets with multiple group
effects of large cardinality.  If dummy-encoding the group effects results
in a manageable number of coefficients, you are probably better off by using
<code><a href="stats.html#topic+lm">lm()</a></code>.
</p>
<p>The formula specification is a response variable followed by a four part
formula. The first part consists of ordinary covariates, the second part
consists of factors to be projected out. The third part is an
IV-specification. The fourth part is a cluster specification for the
standard errors.  I.e. something like <code>y ~ x1 + x2 | f1 + f2 | (Q|W ~ x3+x4) | clu1 + clu2</code> where <code>y</code> is the response, <code style="white-space: pre;">&#8288;x1,x2&#8288;</code> are
ordinary covariates, <code style="white-space: pre;">&#8288;f1,f2&#8288;</code> are factors to be projected out, <code>Q</code>
and <code>W</code> are covariates which are instrumented by <code>x3</code> and
<code>x4</code>, and <code style="white-space: pre;">&#8288;clu1,clu2&#8288;</code> are factors to be used for computing cluster
robust standard errors. Parts that are not used should be specified as
<code>0</code>, except if it's at the end of the formula, where they can be
omitted.  The parentheses are needed in the third part since <code>|</code> has
higher precedence than <code>~</code>. Multiple left hand sides like <code>y|w|x ~ x1 + x2 |f1+f2|...</code> are allowed.
</p>
<p>Interactions between a covariate <code>x</code> and a factor <code>f</code> can be
projected out with the syntax <code>x:f</code>.  The terms in the second and
fourth parts are not treated as ordinary formulas, in particular it is not
possible with things like <code>y ~ x1 | x*f</code>, rather one would specify
<code>y ~ x1 + x | x:f + f</code>. Note that <code>f:x</code> also works, since R's
parser does not keep the order.  This means that in interactions, the factor
<em>must</em> be a factor, whereas a non-interacted factor will be coerced to
a factor. I.e. in <code>y ~ x1 | x:f1 + f2</code>, the <code>f1</code> must be a factor,
whereas it will work as expected if <code>f2</code> is an integer vector.
</p>
<p>In older versions of <span class="pkg">lfe</span> the syntax was 'felm(y ~ x1 + x2 + G(f1)
</p>

<ul>
<li><p> G(f2), iv=list(Q ~ x3+x4, W ~ x3+x4), clustervar=c('clu1','clu2'))'. This
syntax still works, but yields a warning. Users are <em>strongly</em>
encouraged to change to the new multipart formula syntax.  The old syntax
will be removed at a later time.
</p>
</li></ul>

<p>The standard errors are adjusted for the reduced degrees of freedom coming
from the dummies which are implicitly present.  (An exception occurs in the
case of clustered standard errors and, specifically, where clusters are
nested within fixed effects; see
<a href="https://github.com/sgaure/lfe/issues/1#issuecomment-528643802">here</a>.)
In the case of two factors,
the exact number of implicit dummies is easy to compute.  If there are more
factors, the number of dummies is estimated by assuming there's one
reference-level for each factor, this may be a slight over-estimation,
leading to slightly too large standard errors. Setting <code>exactDOF='rM'</code>
computes the exact degrees of freedom with <code>rankMatrix()</code> in package
<span class="pkg">Matrix</span>.
</p>
<p>For the iv-part of the formula, it is only necessary to include the
instruments on the right hand side.  The other explanatory covariates, from
the first and second part of <code>formula</code>, are added automatically in the
first stage regression.  See the examples.
</p>
<p>The <code>contrasts</code> argument is similar to the one in <code>lm()</code>, it is
used for factors in the first part of the formula. The factors in the second
part are analyzed as part of a possible subsequent <code>getfe()</code> call.
</p>
<p>The <code>cmethod</code> argument may affect the clustered covariance matrix (and
thus regressor standard errors), either directly or via adjustments to a
degrees of freedom scaling factor. In particular, Cameron, Gelbach and Miller
(CGM2011, sec. 2.3) describe two possible small cluster corrections that are
relevant in the case of multiway clustering. </p>

<ul>
<li><p> The first approach adjusts each component of the cluster-robust
variance estimator (CRVE) by its own <code class="reqn">c_i</code> adjustment factor. For
example, the first component (with <code class="reqn">G</code> clusters) is adjusted by
<code class="reqn">c_1=\frac{G}{G-1}\frac{N-1}{N-K}</code>,
the second component (with <code class="reqn">H</code> clusters) is adjusted
by <code class="reqn">c_2=\frac{H}{H-1}\frac{N-1}{N-K}</code>, etc.
</p>
</li>
<li><p> The second approach applies the same adjustment to all CRVE components:
<code class="reqn">c=\frac{J}{J-1}\frac{N-1}{N-K}</code>, where
<code class="reqn">J=\min(G,H)</code> in the case of two-way clustering, for example.
</p>
</li></ul>

<p>Any differences resulting from these two approaches are likely to be minor,
and they will obviously yield exactly the same results when there is only one
cluster dimension. Still, CGM2011 adopt the former approach in their own
paper and simulations. This is also the default method that <code>felm</code> uses
(i.e. <code>cmethod = 'cgm'</code>). However, the latter approach has since been
adopted by several other packages that allow for robust inference with
multiway clustering. This includes the popular Stata package
<a href="http://scorreia.com/software/reghdfe/">reghdfe</a>, as well as the
<a href="https://github.com/matthieugomez/FixedEffectModels.jl">FixedEffectModels.jl</a>
implementation in Julia. To match results from these packages exactly, use
<code>cmethod = 'cgm2'</code> (or its alias, <code>cmethod = 'reghdfe'</code>). It is
possible that some residual differences may still remain; see discussion
<a href="https://github.com/sgaure/lfe/issues/1#issuecomment-530561314">here</a>.
</p>
<p>The old syntax with a single part formula with the <code>G()</code> syntax for the
factors to transform away is still supported, as well as the
<code>clustervar</code> and <code>iv</code> arguments, but users are encouraged to move
to the new multi part formulas as described here.  The <code>clustervar</code> and
<code>iv</code> arguments have been moved to the <code>...</code> argument list. They
will be removed in some future update.
</p>


<h3>Value</h3>

<p><code>felm</code> returns an object of <code>class</code> <code>"felm"</code>.  It is
quite similar to an <code>"lm"</code> object, but not entirely compatible.
</p>
<p>The generic <code>summary</code>-method will yield a summary which may be
<code>print</code>'ed.  The object has some resemblance to an <code>'lm'</code> object,
and some postprocessing methods designed for <code>lm</code> may happen to work.
It may however be necessary to coerce the object to succeed with this.
</p>
<p>The <code>"felm"</code> object is a list containing the following fields:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a numerical vector. The estimated coefficients.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>an integer. The number of observations</p>
</td></tr> <tr><td><code>p</code></td>
<td>
<p>an integer. The
total number of coefficients, including those projected out.</p>
</td></tr>
<tr><td><code>response</code></td>
<td>
<p>a numerical vector. The response vector.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>a numerical vector. The fitted values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>a numerical vector. The residuals of the full system, with
dummies.  For IV-estimations, this is the residuals when the original
endogenous variables are used, not their predictions from the 1st stage.</p>
</td></tr>
<tr><td><code>r.residuals</code></td>
<td>
<p>a numerical vector. Reduced residuals, i.e. the residuals
resulting from predicting <em>without</em> the dummies.</p>
</td></tr>
<tr><td><code>iv.residuals</code></td>
<td>
<p>numerical vector. When using instrumental variables,
residuals from 2. stage, i.e. when predicting with the predicted endogenous
variables from the 1st stage.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>numeric. The square root of the argument <code>weights</code>.</p>
</td></tr>
<tr><td><code>cfactor</code></td>
<td>
<p>factor of length N. The factor describing the connected
components of the two first terms in the second part of the model formula.</p>
</td></tr>
<tr><td><code>vcv</code></td>
<td>
<p>a matrix. The variance-covariance matrix.</p>
</td></tr>
<tr><td><code>fe</code></td>
<td>
<p>list of factors. A list of the terms in the second part of the
model formula.</p>
</td></tr>
<tr><td><code>stage1</code></td>
<td>
<p>The '<code>felm</code>' objects for the IV 1st stage, if used. The
1st stage has multiple left hand sides if there are more than one
instrumented variable.</p>
</td></tr>
<tr><td><code>iv1fstat</code></td>
<td>
<p>list of numerical vectors. For IV 1st stage, F-value for
excluded instruments, the number of parameters in restricted model and in
the unrestricted model.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>matrix. The expanded data matrix, i.e. from the first part of the
formula. To save memory with large datasets, it is only included if
<code>felm(keepX=TRUE)</code> is specified.  Must be included if
<code><a href="#topic+bccorr">bccorr()</a></code> or <code><a href="#topic+fevcov">fevcov()</a></code> is to be used for correcting
limited mobility bias.  </p>
</td></tr>
<tr><td><code>cX</code>, <code>cY</code></td>
<td>
<p>matrix. The centred expanded data matrix. Only included if
<code>felm(keepCX=TRUE)</code>.  </p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>The result of a <code>replicate</code> applied to the <code>bootexpr</code>
(if used).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Side effect: If <code>data</code> is an object of class <code>"pdata.frame"</code> (from
the <span class="pkg">plm</span> package), the <span class="pkg">plm</span> namespace is loaded if available, and
<code>data</code> is coerced to a <code>"data.frame"</code> with <code>as.data.frame</code>
which dispatches to a <span class="pkg">plm</span> method.  This ensures that transformations
like <code>diff</code> and <code>lag</code> from <span class="pkg">plm</span> works as expected, but it
also incurs an additional copy of the <code>data</code>, and the <span class="pkg">plm</span>
namespace remains loaded after <code>felm</code> returns.  When working with
<code>"pdata.frame"</code>s, this is what is usually wanted anyway.
</p>
<p>For technical reasons, when running IV-estimations, the data frame supplied
in the <code>data</code> argument to <code>felm</code>, should <em>not</em> contain
variables with names ending in <code>'(fit)'</code>.  Variables with such names
are used internally by <code>felm</code>, and may then accidentally be looked up
in the data frame instead of the local environment where they are defined.
</p>


<h3>References</h3>

<p>Cameron, A.C., J.B. Gelbach and D.L. Miller (2011) <cite>Robust
inference with multiway clustering</cite>, Journal of Business &amp; Economic
Statistics 29 (2011), no. 2, 238&ndash;249.
<a href="https://doi.org/10.1198/jbes.2010.07136">doi:10.1198/jbes.2010.07136</a>
</p>
<p>Kolesar, M., R. Chetty, J. Friedman, E. Glaeser, and G.W. Imbens (2014)
<cite>Identification and Inference with Many Invalid Instruments</cite>, Journal
of Business &amp; Economic Statistics (to appear).
<a href="https://doi.org/10.1080/07350015.2014.978175">doi:10.1080/07350015.2014.978175</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getfe">getfe()</a></code> <code><a href="#topic+summary.felm">summary.felm()</a></code>
<code><a href="#topic+condfstat">condfstat()</a></code> <code><a href="#topic+waldtest">waldtest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Default is to use all cores. We'll limit it to 2 for this example.
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)

## Simulate data
set.seed(42)
n &lt;- 1e3

d &lt;- data.frame(
  # Covariates
  x1 = rnorm(n),
  x2 = rnorm(n),
  # Individuals and firms
  id = factor(sample(20, n, replace = TRUE)),
  firm = factor(sample(13, n, replace = TRUE)),
  # Noise
  u = rnorm(n)
)

# Effects for individuals and firms
id.eff &lt;- rnorm(nlevels(d$id))
firm.eff &lt;- rnorm(nlevels(d$firm))

# Left hand side
d$y &lt;- d$x1 + 0.5 * d$x2 + id.eff[d$id] + firm.eff[d$firm] + d$u

## Estimate the model and print the results
est &lt;- felm(y ~ x1 + x2 | id + firm, data = d)
summary(est)
# Compare with lm
summary(lm(y ~ x1 + x2 + id + firm - 1, data = d))

## Example with 'reverse causation' (IV regression)

# Q and W are instrumented by x3 and the factor x4.
d$x3 &lt;- rnorm(n)
d$x4 &lt;- sample(12, n, replace = TRUE)
d$Q &lt;- 0.3 * d$x3 + d$x1 + 0.2 * d$x2 + id.eff[d$id] + 0.3 * log(d$x4) - 0.3 * d$y +
  rnorm(n, sd = 0.3)
d$W &lt;- 0.7 * d$x3 - 2 * d$x1 + 0.1 * d$x2 - 0.7 * id.eff[d$id] + 0.8 * cos(d$x4) -
  0.2 * d$y + rnorm(n, sd = 0.6)

# Add them to the outcome variable
d$y &lt;- d$y + d$Q + d$W

## Estimate the IV model and report robust SEs
ivest &lt;- felm(y ~ x1 + x2 | id + firm | (Q | W ~ x3 + factor(x4)), data = d)
summary(ivest, robust = TRUE)
condfstat(ivest)
# Compare with the not instrumented fit:
summary(felm(y ~ x1 + x2 + Q + W | id + firm, data = d))

## Example with multiway clustering

# Create a large cluster group (500 clusters) and a small one (20 clusters)
d$cl1 &lt;- factor(sample(rep(1:500, length.out = n)))
d$cl2 &lt;- factor(sample(rep(1:20, length.out = n)))
# Function for adding clustered noise to our outcome variable
cl_noise &lt;- function(cl) {
  obs_per_cluster &lt;- n / nlevels(cl)
  unlist(replicate(nlevels(cl),
    rnorm(obs_per_cluster, mean = rnorm(1), sd = runif(1)),
    simplify = FALSE
  ))
}

# New outcome variable
d$y_cl &lt;- d$x1 + 0.5 * d$x2 + id.eff[d$id] + firm.eff[d$firm] +
  cl_noise(d$cl1) + cl_noise(d$cl2)

## Estimate and print the model with cluster-robust SEs (default)
est_cl &lt;- felm(y_cl ~ x1 + x2 | id + firm | 0 | cl1 + cl2, data = d)
summary(est_cl)

# Print ordinary standard errors:
summary(est_cl, robust = FALSE)
# Match cluster-robust SEs from Stata's reghdfe package:
summary(felm(y_cl ~ x1 + x2 | id + firm | 0 | cl1 + cl2,
  data = d,
  cmethod = "reghdfe"
))

## Restore default options
options(oldopts)

</code></pre>

<hr>
<h2 id='fepois'>Fit a Poisson model with multiple group fixed effects</h2><span id='topic+fepois'></span>

<h3>Description</h3>

<p>Fit a Poisson model with multiple group fixed effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fepois(
  formula,
  data,
  offset = NULL,
  subset = NULL,
  robust = TRUE,
  cluster = NULL,
  pseudo_rsq = FALSE,
  tol = 1e-10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fepois_+3A_formula">formula</code></td>
<td>
<p>an object of class '&quot;formula&quot;' (or one that can be coerced to
that class): a symbolic description of the model to be fitted. Similarly to
'lm'.  See Details.</p>
</td></tr>
<tr><td><code id="fepois_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables of the model.</p>
</td></tr>
<tr><td><code id="fepois_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em> known component
to be included in the linear predictor during fitting. This should be
<code>NULL</code> or a numeric vector or matrix of extents matching those of the
response. One or more <code><a href="stats.html#topic+offset">offset</a></code> terms can be included in the
formula instead or as well, and if more than one are specified their sum is
used. See <code><a href="stats.html#topic+model.offset">model.offset</a></code>.</p>
</td></tr>
<tr><td><code id="fepois_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="fepois_+3A_robust">robust</code></td>
<td>
<p>logical value to return a robust standard error computation.</p>
</td></tr>
<tr><td><code id="fepois_+3A_cluster">cluster</code></td>
<td>
<p>optional variable to group by and compute sandwich-type
robust standard errors. Should be a formula of the form <code>~x_j</code> or
an object that be coerced to a formula.</p>
</td></tr>
<tr><td><code id="fepois_+3A_pseudo_rsq">pseudo_rsq</code></td>
<td>
<p>logical value to return a a pseudo-R2 based on Kendall's
correlation.</p>
</td></tr>
<tr><td><code id="fepois_+3A_tol">tol</code></td>
<td>
<p>tolerance value for GLM convergence criteria.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>felm
</p>

<hr>
<h2 id='fevcov'>Compute limited mobility bias corrected covariance matrix between fixed
effects</h2><span id='topic+fevcov'></span>

<h3>Description</h3>

<p>With a model like <code class="reqn">y = X\beta + D\theta + F\psi + \epsilon</code>, where
<code class="reqn">D</code> and <code class="reqn">F</code> are matrices with dummy encoded factors, one application
of <span class="pkg">lfe</span> is to study the variances <code class="reqn">var(D\theta)</code>, <code class="reqn">var(F\psi)</code>
and covariances <code class="reqn">cov(D\theta, F\psi)</code>. However, if we use estimates for
<code class="reqn">\theta</code> and <code class="reqn">\psi</code>, the resulting variances are biased. The
function <code>fevcov</code> computes a bias corrected covariance matrix as
described in <cite>Gaure (2014)</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fevcov(
  est,
  alpha = getfe(est),
  tol = 0.01,
  robust = !is.null(est$clustervar),
  maxsamples = Inf,
  lhs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fevcov_+3A_est">est</code></td>
<td>
<p>an object of class '&quot;felm&quot;', the result of a call to
<code style="white-space: pre;">&#8288;[felm](keepX=TRUE)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="fevcov_+3A_alpha">alpha</code></td>
<td>
<p>a data frame, the result of a call to <code><a href="#topic+getfe">getfe()</a></code>.</p>
</td></tr>
<tr><td><code id="fevcov_+3A_tol">tol</code></td>
<td>
<p>numeric. The absolute tolerance for the bias-corrected
correlation.</p>
</td></tr>
<tr><td><code id="fevcov_+3A_robust">robust</code></td>
<td>
<p>logical. Should robust (heteroskedastic or cluster) residuals
be used, rather than i.i.d.</p>
</td></tr>
<tr><td><code id="fevcov_+3A_maxsamples">maxsamples</code></td>
<td>
<p>integer. Maximum number of samples for expectation
estimates.</p>
</td></tr>
<tr><td><code id="fevcov_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of left hand side if multiple left hand sides.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>tol</code> argument specifies the tolerance. The tolerance is relative
for the variances, i.e. the diagonal of the output.  For the covariances,
the tolerance is relative to the square root of the product of the
variances, i.e. an absolute tolerance for the correlation.  If a numeric of
length 1, <code>tol</code> specifies the same tolerance for all
variances/covariances.  If it is of length 2, <code>tol[1]</code> specifies the
variance tolerance, and <code>tol[2]</code> the covariance tolerance.  <code>tol</code>
can also be a square matrix of size <code>length(est$fe)</code>, in which case the
tolerance for each variance and covariance is specified individually.
</p>
<p>The function performs no checks for estimability. If the fixed effects are
not estimable, the result of a call to <code>fevcov</code> is not useable.
Moreover, there should be just a single connected component among the fixed
effects.
</p>
<p><code>alpha</code> must contain a full set of coefficients, and contain columns
<code>'fe'</code> and <code>'effect'</code> like the default estimable functions from
<code><a href="#topic+efactory">efactory()</a></code>.
</p>
<p>In the case that the <code><a href="#topic+felm">felm()</a></code>-estimation has weights, it is the
weighted variances and covariance which are bias corrected.
</p>


<h3>Value</h3>

<p><code>fevcov</code> returns a square matrix with the bias corrected
covariances. An attribute <code>'bias'</code> contains the biases.  The bias
corrections have been subtracted from the bias estimates.  I.e. vc = vc' -
b, where vc' is the biased variance and b is the bias.
</p>


<h3>Note</h3>

<p>Bias correction for IV-estimates are not supported as of now.
</p>
<p>Note that if <code>est</code> is the result of a call to <code><a href="#topic+felm">felm()</a></code> with
<code>keepX=FALSE</code> (the default), the biases will be computed as if the
covariates X are independent of the factors. This will be faster (typically
by a factor of approx. 4), and possibly wronger.  Note also that the
computations performed by this function are non-trivial, they may take quite
some time.  It would be wise to start out with quite liberal tolerances,
e.g. <cite>tol=0.1</cite>, to get an idea of the time requirements.
</p>
<p>If there are only two fixed effects, <code>fevcov</code> returns the same
information as <code><a href="#topic+bccorr">bccorr()</a></code>, though in a slightly different format.
</p>


<h3>References</h3>

<p>Gaure, S. (2014), <cite>Correlation bias correction in two-way
fixed-effects linear regression</cite>, Stat 3(1):379-390, 2014.
<a href="https://doi.org/10.1002/sta4.68">doi:10.1002/sta4.68</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varvars">varvars()</a></code> <code><a href="#topic+bccorr">bccorr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(5000)
x2 &lt;- rnorm(length(x))

## create individual and firm
id &lt;- factor(sample(40, length(x), replace = TRUE))
firm &lt;- factor(sample(30, length(x), replace = TRUE, prob = c(2, rep(1, 29))))
foo &lt;- factor(sample(20, length(x), replace = TRUE))
## effects
id.eff &lt;- rnorm(nlevels(id))
firm.eff &lt;- runif(nlevels(firm))
foo.eff &lt;- rchisq(nlevels(foo), df = 1)
## left hand side
id.m &lt;- id.eff[id]
firm.m &lt;- firm.eff[firm]
foo.m &lt;- foo.eff[foo]
# normalize them
id.m &lt;- id.m / sd(id.m)
firm.m &lt;- firm.m / sd(firm.m)
foo.m &lt;- foo.m / sd(foo.m)
y &lt;- x + 0.25 * x2 + id.m + firm.m + foo.m + rnorm(length(x), sd = 2)
z &lt;- x + 0.5 * x2 + 0.7 * id.m + 0.5 * firm.m + 0.3 * foo.m + rnorm(length(x), sd = 2)
# make a data frame
fr &lt;- data.frame(y, z, x, x2, id, firm, foo)
## estimate and print result
est &lt;- felm(y | z ~ x + x2 | id + firm + foo, data = fr, keepX = TRUE)
# find bias corrections, there's little bias in this example
print(yv &lt;- fevcov(est, lhs = "y"))
## Here's how to compute the unbiased correlation matrix:
cm &lt;- cov2cor(yv)
structure(cm, bias = NULL)

</code></pre>

<hr>
<h2 id='fixedse'>Compute standard errors for fixed effects</h2><span id='topic+fixedse'></span>

<h3>Description</h3>

<p>fixedse computes the standard errors for the fixed effects when there is only one.
While <code><a href="#topic+getfe">getfe()</a></code> can provide standard errors, it does so by bootstrapping
for general estimable functions. In the special case that there's only a single fixed
effect, and the estimable function is just the levels, this function can be used to
compute the fixed effects without bootstrapping. It requires that <code><a href="#topic+felm">felm()</a></code>
is run with keepX=TRUE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixedse(est, lhs = NULL, E)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixedse_+3A_est">est</code></td>
<td>
<p>'felm' object. The result of a call to <code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code id="fixedse_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of the left hand side, if more than one.</p>
</td></tr>
<tr><td><code id="fixedse_+3A_e">E</code></td>
<td>
<p>Matrix. Estimable function. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric. Vector of standard errors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000)
f &lt;- factor(sample(5, 1000, replace = TRUE))
y &lt;- x + (1:5)[f] + rnorm(1000)
est &lt;- felm(y ~ x | f, keepX = TRUE)
# both bootstrap and computed se:
cbind(getfe(est, ef = efactory(est, "ref"), se = TRUE), fse = fixedse(est))
# compare with lm:
summary(lm(y ~ x + f - 1))
</code></pre>

<hr>
<h2 id='getfe'>Retrieve the group fixed effects</h2><span id='topic+getfe'></span>

<h3>Description</h3>

<p>Compute the group fixed effects, i.e. the dummy parameters, which were swept
out during an estimation with <code><a href="#topic+felm">felm()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getfe(
  obj,
  references = NULL,
  se = FALSE,
  method = "kaczmarz",
  ef = "ref",
  bN = 100,
  robust = FALSE,
  cluster = obj[["clustervar"]],
  lhs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getfe_+3A_obj">obj</code></td>
<td>
<p>object of class <code>"felm"</code>, usually, a result of a call to
<code><a href="#topic+felm">felm()</a></code></p>
</td></tr>
<tr><td><code id="getfe_+3A_references">references</code></td>
<td>
<p>a vector of strings.  If there are more than two factors
and you have prior knowledge of what the reference levels should be like
<code>references='id.23'</code>.  Not used with <code>method='kaczmarz'</code></p>
</td></tr>
<tr><td><code id="getfe_+3A_se">se</code></td>
<td>
<p>logical.  Set to TRUE if standard errors for the group effects are
wanted.  This is <strong>very</strong> time-consuming for large problems, so leave
it as FALSE unless absolutely needed.</p>
</td></tr>
<tr><td><code id="getfe_+3A_method">method</code></td>
<td>
<p>character string.  Either 'cholesky', 'cg', or the default
'kaczmarz'.  The latter is often very fast and consumes little memory, it
requires an estimable function to be specified, see <code><a href="#topic+efactory">efactory()</a></code>.
The 'cholesky' method is no longer maintained as the author sees no use for
it.</p>
</td></tr>
<tr><td><code id="getfe_+3A_ef">ef</code></td>
<td>
<p>function. A function of two variables, a vector of group fixed
effects and a logical, i.e. <code style="white-space: pre;">&#8288;function(v,addnames)&#8288;</code>.  This function
should be estimable and is used to transform the raw-coefficients <code>v</code>
from the kaczmarz-method.  The second variable indicates whether the
function must return a named vector (if this is FALSE, one may skip the
names, saving memory allocations and time).
</p>
<p>If a string is specified, it is fed to the <code><a href="#topic+efactory">efactory()</a></code>-function.
The default function is one which picks one reference in each component.
</p>
<p>Can be set to <code>ef="ln"</code> to yield the minimal-norm solution from the
kaczmarz-method.
</p>
<p>It can also be set to <code>ef="zm"</code> to get zero means (and intercept) in
one of the factors, and a reference in the other.</p>
</td></tr>
<tr><td><code id="getfe_+3A_bn">bN</code></td>
<td>
<p>integer.  The number of bootstrap runs when standard errors are
requested.</p>
</td></tr>
<tr><td><code id="getfe_+3A_robust">robust</code></td>
<td>
<p>logical. Should heteroskedastic standard errors be estimated?</p>
</td></tr>
<tr><td><code id="getfe_+3A_cluster">cluster</code></td>
<td>
<p>logical or factor. Estimate clustered standard errors.</p>
</td></tr>
<tr><td><code id="getfe_+3A_lhs">lhs</code></td>
<td>
<p>character vector. Specify which left hand side if <code>obj</code> has
multiple lhs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the case with two factors (the terms in the second part of the formula
supplied to <code><a href="#topic+felm">felm()</a></code>), one reference in each connected component
is adequate when interpreting the results.
</p>
<p>For three or more factors, no such easy method is known; for the
<code>"cholesky"</code> method- reference levels are found by analyzing the
pivoted Cholesky-decomposition of a slightly perturbed system.  The
<code>"kaczmarz"</code> method provides no rank-deficiency analysis, it is assumed
that the factors beyond the two first contribute nothing to the
rank-deficiency, so one reference in each is used.
</p>
<p>If there are more than two factors, only the first two will be used to
report connected components.  In this case, it is not known which graph
theoretic concept may be used to analyze the rank-deficiency.
</p>
<p>The standard errors returned by the Kaczmarz-method are bootstrapped,
keeping the other coefficients (from <code><a href="#topic+felm">felm()</a></code>) constant, i.e. they
are from the variance when resampling the residuals.  If <code>robust=TRUE</code>,
heteroskedastic robust standard errors are estimated. If <code>robust=FALSE</code>
and <code>cluster=TRUE</code>, clustered standard errors with the cluster
specified to <code>felm()</code> are estimated. If <code>cluster</code> is a factor, it
is used for the cluster definition.
</p>


<h3>Value</h3>

<p>The function <code>getfe</code> computes and returns a data frame
containing the group fixed effects.  It has the columns
<code>c('effect','se','obs','comp','fe','idx')</code>
</p>
 <ul>
<li> <p><code>effect</code> is the estimated effect.  </p>
</li>
<li> <p><code>se</code> is
the standard error.  </p>
</li>
<li> <p><code>obs</code> is the number of observations of this
level.  </p>
</li>
<li> <p><code>comp</code> is the graph-theoretic component number, useful
for interpreting the effects.  </p>
</li>
<li> <p><code>fe</code> is the name of factor.  </p>
</li>
<li>
<p><code>idx</code> is the level of the factor. </p>
</li></ul>

<p>With the Kaczmarz-method it's possible to specify a different estimable
function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
## create covariates
x &lt;- rnorm(4000)
x2 &lt;- rnorm(length(x))

## create individual and firm
id &lt;- factor(sample(500, length(x), replace = TRUE))
firm &lt;- factor(sample(300, length(x), replace = TRUE))

## effects
id.eff &lt;- rlnorm(nlevels(id))
firm.eff &lt;- rexp(nlevels(firm))

## left hand side
y &lt;- x + 0.25 * x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))

## estimate and print result
est &lt;- felm(y ~ x + x2 | id + firm)
summary(est)
## extract the group effects
alpha &lt;- getfe(est, se = TRUE)

## find some estimable functions, with standard errors, we don't get
## names so we must precompute some numerical indices in ef
idx &lt;- match(c("id.5", "id.6", "firm.11", "firm.12"), rownames(alpha))
alpha[idx, ]
ef &lt;- function(v, addnames) {
  w &lt;- c(
    v[idx[[2]]] - v[idx[[1]]], v[idx[[4]]] + v[idx[[1]]],
    v[idx[[4]]] - v[idx[[3]]]
  )
  if (addnames) names(w) &lt;- c("id6-id5", "f12+id5", "f12-f11")
  w
}
getfe(est, ef = ef, se = TRUE)
options(oldopts)
## Not run: 
summary(lm(y ~ x + x2 + id + firm - 1))

## End(Not run)

</code></pre>

<hr>
<h2 id='is.estimable'>Verify estimability of function</h2><span id='topic+is.estimable'></span>

<h3>Description</h3>

<p>Verify that a function you have written for <code><a href="#topic+getfe">getfe()</a></code> is indeed
estimable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.estimable(
  ef,
  fe,
  R = NULL,
  nowarn = FALSE,
  keepdiff = FALSE,
  threshold = 500 * getOption("lfe.eps")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.estimable_+3A_ef">ef</code></td>
<td>
<p>function.  The function to be verified.</p>
</td></tr>
<tr><td><code id="is.estimable_+3A_fe">fe</code></td>
<td>
<p>list of factors.</p>
</td></tr>
<tr><td><code id="is.estimable_+3A_r">R</code></td>
<td>
<p>numeric.  Vector of residuals, if <code>NULL</code>, a random one is
created.</p>
</td></tr>
<tr><td><code id="is.estimable_+3A_nowarn">nowarn</code></td>
<td>
<p>logical. Set to <code>TRUE</code> if <code>is.estimable</code> should not
throw a warning for non-estimable functions.</p>
</td></tr>
<tr><td><code id="is.estimable_+3A_keepdiff">keepdiff</code></td>
<td>
<p>logical. Return differences between two different runs of
the Kaczmarz method.</p>
</td></tr>
<tr><td><code id="is.estimable_+3A_threshold">threshold</code></td>
<td>
<p>numeric. Threshold for determining estimability.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When writing custom estimable functions for <code><a href="#topic+getfe">getfe()</a></code>, the
function <code>is.estimable</code> can be used to test it for estimability.
<code>is.estimable()</code> solves the sparse residual system with the Kaczmarz
method, using two different initial values. Then <code>ef()</code> is applied to
the two solutions. If the value of <code>ef()</code> differs by more than
<code>1e-5</code> in any coordinate, <code>FALSE</code> is returned, otherwise
<code>TRUE</code> is returned.  If <code>keepdiff=TRUE</code>, the vector of differences
is attached as an attribute <code>'diff'</code> to the returned logical value.  If
you have problems with estimability, it is a fair guess that those entries
with a difference in absolute values smaller than, say, <code>1e-5</code> are
estimable, whereas the others are not.
</p>


<h3>Value</h3>

<p>Returns a logical.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getfe">getfe()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldopts &lt;- options("lfe.threads")
options(lfe.threads = 2)
## create individual and firm
id &lt;- factor(sample(5000, 50000, replace = TRUE))
firm &lt;- factor(sample(3000, 50000, replace = TRUE))

## create some estimable functions. It's faster to
## use numerical indices in ef rather than strings, and the input v
## to ef has no names, we have to add them when requested
ef &lt;- function(v, addnames) {
  w &lt;- c(v[6] - v[5], v[7000] + v[5], v[7000] - v[6000])
  if (addnames) names(w) &lt;- c("id6-id5", "f2k+id5", "f2k-f1k")
  w
}
is.estimable(ef, list(id = id, firm = firm))

## Then make an error; in the last coordinate, sum two firms
ef &lt;- function(v, addnames) {
  w &lt;- c(v[6] - v[5], v[7000] + v[5], v[7000] + v[6000])
  if (addnames) names(w) &lt;- c("id6-id5", "f2k+id5", "f2k-f1k")
  w
}
is.estimable(ef, list(id = id, firm = firm), keepdiff = TRUE)
options(oldopts)

</code></pre>

<hr>
<h2 id='kaczmarz'>Solve a linear system defined by factors</h2><span id='topic+kaczmarz'></span>

<h3>Description</h3>

<p>Uses the Kaczmarz method to solve a system of the type Dx = R, where D is
the matrix of dummies created from a list of factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kaczmarz(
  fl,
  R,
  eps = getOption("lfe.eps"),
  init = NULL,
  threads = getOption("lfe.threads")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kaczmarz_+3A_fl">fl</code></td>
<td>
<p>A list of arbitrary factors of the same length</p>
</td></tr>
<tr><td><code id="kaczmarz_+3A_r">R</code></td>
<td>
<p>numeric.  A vector, matrix or list of such of the same length as
the factors</p>
</td></tr>
<tr><td><code id="kaczmarz_+3A_eps">eps</code></td>
<td>
<p>a tolerance for the method</p>
</td></tr>
<tr><td><code id="kaczmarz_+3A_init">init</code></td>
<td>
<p>numeric. A vector to use as initial value for the Kaczmarz
iterations. The algorithm converges to the solution closest to this</p>
</td></tr>
<tr><td><code id="kaczmarz_+3A_threads">threads</code></td>
<td>
<p>integer. The number of threads to use when <code>R</code> is more
than one vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector <code>x</code> of length equal to the sum of the number of levels
of the factors in <code>fl</code>, which solves the system <code class="reqn">Dx=R</code>. If the
system is inconsistent, the algorithm may not converge, it will give a
warning and return something which may or may not be close to a solution. By
setting <code>eps=0</code>, maximum accuracy (with convergence warning) will be
achieved.
</p>


<h3>Note</h3>

<p>This function is used by <code><a href="#topic+getfe">getfe()</a></code>, it's quite specialized,
but it might be useful for other purposes too.
</p>
<p>In case of convergence problems, setting <code>options(lfe.usecg=TRUE)</code> will
cause the kaczmarz() function to dispatch to the more general conjugate
gradient method of <code><a href="#topic+cgsolve">cgsolve()</a></code>.  This may or may not be faster.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cgsolve">cgsolve()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## create factors
f1 &lt;- factor(sample(24000, 100000, replace = TRUE))
f2 &lt;- factor(sample(20000, length(f1), replace = TRUE))
f3 &lt;- factor(sample(10000, length(f1), replace = TRUE))
f4 &lt;- factor(sample(8000, length(f1), replace = TRUE))
## the matrix of dummies
D &lt;- makeDmatrix(list(f1, f2, f3, f4))
dim(D)
## an x
truex &lt;- runif(ncol(D))
## and the right hand side
R &lt;- as.vector(D %*% truex)
## solve it
sol &lt;- kaczmarz(list(f1, f2, f3, f4), R)
## verify that the solution solves the system Dx = R
sqrt(sum((D %*% sol - R)^2))
## but the solution is not equal to the true x, because the system is
## underdetermined
sqrt(sum((sol - truex)^2))
## moreover, the solution from kaczmarz has smaller norm
sqrt(sum(sol^2)) &lt; sqrt(sum(truex^2))

</code></pre>

<hr>
<h2 id='makeDmatrix'>Make sparse matrix of dummies from factor list</h2><span id='topic+makeDmatrix'></span>

<h3>Description</h3>

<p>Given a list of factors, return the matrix of dummies as a sparse matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDmatrix(fl, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDmatrix_+3A_fl">fl</code></td>
<td>
<p>list of factors.</p>
</td></tr>
<tr><td><code id="makeDmatrix_+3A_weights">weights</code></td>
<td>
<p>numeric vector. Multiplied into the rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the model matrix for a list of factors. This matrix is
not used internally by the package, but it's used in some of the
documentation for illustrative purposes.
</p>


<h3>Value</h3>

<p>Returns a sparse matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fl &lt;- lapply(1:3, function(i) factor(sample(3, 10, replace = TRUE)))
fl
makeDmatrix(fl, weights = seq(0.1, 1, 0.1))

</code></pre>

<hr>
<h2 id='mctrace'>Compute trace of a large matrix by sample means</h2><span id='topic+mctrace'></span>

<h3>Description</h3>

<p>Some matrices are too large to be represented as a matrix, even as a sparse
matrix.  Nevertheless, it can be possible to compute the matrix vector
product fairly easy, and this is utilized to estimate the trace of the
matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mctrace(mat, N, tol = 0.001, maxsamples = Inf, trname = "", init)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mctrace_+3A_mat">mat</code></td>
<td>
<p>square matrix, Matrix, function or list of factors.</p>
</td></tr>
<tr><td><code id="mctrace_+3A_n">N</code></td>
<td>
<p>integer. if <code>mat</code> is a function, the size of the matrix is
specified here.</p>
</td></tr>
<tr><td><code id="mctrace_+3A_tol">tol</code></td>
<td>
<p>numeric. Tolerance.</p>
</td></tr>
<tr><td><code id="mctrace_+3A_maxsamples">maxsamples</code></td>
<td>
<p>numeric. Maximum number of samples in the expectation
estimation.</p>
</td></tr>
<tr><td><code id="mctrace_+3A_trname">trname</code></td>
<td>
<p>character. Arbitrary name used in progress reports.</p>
</td></tr>
<tr><td><code id="mctrace_+3A_init">init</code></td>
<td>
<p>numeric. Initial guess for the trace.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mctrace</code> is used internally by <code><a href="#topic+fevcov">fevcov()</a></code> and
<code><a href="#topic+bccorr">bccorr()</a></code>, but has been made public since it might be useful for
other tasks as well.
</p>
<p>For any matrix <code class="reqn">A</code>, the trace equals the sum of the diagonal elements,
or the sum of the eigenvalues. However, if the size of the matrix is very
large, we may not have a matrix representation, so the diagonal is not
immediately available.  In that case we can use the formula <code class="reqn">tr(A) =
E(x^t A x)</code> where <code class="reqn">x</code> is a random vector with zero
expectation and <code class="reqn">Var(x) = I</code>. We estimate the expectation with sample
means.  <code>mctrace</code> draws <code class="reqn">x</code> in <code class="reqn">\{-1,1\}^N</code>, and
evaluates <code>mat</code> on these vectors.
</p>
<p>If <code>mat</code> is a function, it must be able to take a matrix of column
vectors as input.  Since <code class="reqn">x^t A x = (Ax,x)</code> is evaluated,
where <code class="reqn">(\cdot,\cdot)</code> is the Euclidean inner product, the function
<code>mat</code> can perform this inner product itself. In that case the function
should have an attribute <code>attr(mat,'IP') &lt;- TRUE</code> to signal this.
</p>
<p>If <code>mat</code> is a list of factors, the matrix for which to estimate the
trace, is the projection matrix which projects out the factors. I.e.  how
many dimensions are left when the factors have been projected out.  Thus, it
is possible to estimate the degrees of freedom in an OLS where factors are
projected out.
</p>
<p>The tolerance <code>tol</code> is a relative tolerance.  The iteration terminates
when the normalized standard deviation of the sample mean (s.d. divided by
absolute value of the current sample mean) goes below <code>tol</code>.  Specify a
negative <code>tol</code> to use the absolute standard deviation.  The tolerance
can also change during the iterations; you can specify
<code>tol=function(curest) {...}</code> and return a tolerance based on the
current estimate of the trace (i.e. the current sample mean).
</p>


<h3>Value</h3>

<p>An estimate of the trace of the matrix represented by <code>mat</code> is
returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(lfe.threads = 1, digits = 5, warn = 1)
f1 &lt;- factor(sample(1500, 3000, replace = TRUE))
f2 &lt;- factor(sample(1500, 3000, replace = TRUE))
fl &lt;- list(f1, f2)
mctrace(fl, tol = -5)
# exact:
# length(f1) - nlevels(f1) - nlevels(f2) + nlevels(compfactor(fl))

</code></pre>

<hr>
<h2 id='nlexpect'>Compute expectation of a function of the coefficients.</h2><span id='topic+nlexpect'></span>

<h3>Description</h3>

<p>Use integration of the joint distribution of the coefficients to compute the
expectation of some function of the coefficients.  Can be used for
non-linear inference tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlexpect(
  est,
  fun,
  coefs,
  ...,
  tol = getOption("lfe.etol"),
  lhs = NULL,
  cv,
  istats = FALSE,
  flags = list(verbose = 0),
  max.eval = 200000L,
  method = c("hcubature", "pcubature", "cuhre", "suave", "vegas", "divonne"),
  vectorize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlexpect_+3A_est">est</code></td>
<td>
<p>object of class <code>"felm"</code> or <code>"lm"</code>, a result of a call to
<code><a href="#topic+felm">felm()</a></code> or <code>lm</code>.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_fun">fun</code></td>
<td>
<p>function of coefficients to be integrated. Can also be a
<code>quote</code>d expression.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_coefs">coefs</code></td>
<td>
<p>character. Names of coefficients to test. Only needed if
<code>fun</code> is a function.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_...">...</code></td>
<td>
<p>other arguments passed to fun or the integration routine.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_tol">tol</code></td>
<td>
<p>numeric. Tolerance for the computed integral.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of the left hand side, if <code>est</code> has more
than one.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_cv">cv</code></td>
<td>
<p>Covariance matrix to use in place of <code>vcov(est)</code></p>
</td></tr>
<tr><td><code id="nlexpect_+3A_istats">istats</code></td>
<td>
<p>logical. Should convergence information from the integration
routine be included as attributes?</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_flags">flags</code></td>
<td>
<p>list. Additional flags for the underlying integration routine. Not used after the
package <span class="pkg">R2Cuba</span> disappeared.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_max.eval">max.eval</code></td>
<td>
<p>integer. Maximum number of integral evaluations.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_method">method</code></td>
<td>
<p>character. A method specification usable by <code>cubature::cubintegrate</code>.
The documentation there says that <code>"pcubature"</code> is good for smooth integrands of low dimensions.</p>
</td></tr>
<tr><td><code id="nlexpect_+3A_vectorize">vectorize</code></td>
<td>
<p>logical or numeric. Use vectorized function evaluation from package
<span class="pkg">cubature</span>. This can speed up integration significantly. If method is from the Cuba library
(i.e. not pcubature or hcubature), <code>vectorize</code> should be specified as a numeric, a vectorization
factor. The default is 128.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>nlexpect</code> integrates the function <code>fun(x)</code> over the
multivariate normal distribution specified by the point estimates and the
covariance matrix <code>vcov(est)</code>.  This is the expectation of
<code>fun(beta)</code> if we were to bootstrap the data (e.g. by drawing the
residuals anew) and do repeated estimations.
</p>
<p>The list of coefficients used by <code>fun</code> must be specified in
<code>coefs</code>.
</p>
<p>If the function is simple, it can be specified as a quoted expression like
<code>quote(a*b+log(abs(d)))</code>. In this case, if <code>coefs</code> is not
specified, it will be set to the list of all the variables occurring in the
expression which are also names of coefficients.
</p>
<p><code>fun</code> may return a vector of values, in which case a vector of
expectations is computed, like <code>quote(c(a*b, a^3-b))</code>. However, if the
expressions contain different variables, like <code>quote(c(a*b, d*e))</code>, a
quite compute intensive 4-dimensional integral will be computed, compared to
two cheap 2-dimensional integrals if you do them separately. There is nothing to gain
from using vector-valued functions compared to multiple calls to <code>nlexpect()</code>.
</p>
<p>You may of course also integrate inequalities like <code>quote(abs(x1-0.2) &gt; 0.2)</code> to simulate the probability from t-tests or Wald-tests. See the
examples.
</p>
<p>The function you provide will get an argument <code>...</code> if it does not have
one already.  It will also be passed an argument <code>.z</code> which contains
the actual coefficients in normalized coordinates, i.e. if <code>ch</code> is the
Cholesky decomposition of the covariance matrix, and <code>pt</code> are the point
estimates, the coefficients will be <code style="white-space: pre;">&#8288;pt + ch \%*\% .z&#8288;</code>. The first argument
is a vector with names corresponding to the coefficients.
</p>
<p>If you specify <code>vectorized=TRUE</code>, your function will be passed a list with vectors
in its first argument. The function must
be able to handle a list, and must return a vector of the same length as the vectors
in the list.  If you pass an expression like <code>x &lt; y</code>, each variable will be a vector.
If your function is vector valued, it must return a matrix where each
column is the values.
</p>
<p>The <code>tol</code> argument specifies both the relative tolerance and the
absolute tolerance. If these should not be the same, specify <code>tol</code> as a
vector of length 2. The first value is the relative tolerance, the second is
the absolute tolerance. Termination occurs when at least one of the
tolerances is met.
</p>
<p>The <code>...</code> can be used for passing other arguments to the integration
routine <code>cubature::cubintegrate</code> and the function to be integrated.
</p>


<h3>Value</h3>

<p>The function <code>nlexpect</code> computes and returns the expectation of
the function <code>fun(beta)</code>, with <code>beta</code> a vector of coefficients.
I.e., if the coefficients <code>beta</code> are bootstrapped a large number of
times, <code>nlexpect(est, fun)</code> should be equal to <code>mean(fun(beta))</code>.
</p>


<h3>Note</h3>

<p>An alternative to this method is to use the <code>bootexpr</code> argument
with <code><a href="#topic+felm">felm()</a></code>, to do a Monte Carlo integration.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+waldtest">waldtest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
N &lt;- 100
x1 &lt;- rnorm(N)
# make some correlation
x2 &lt;- 0.1 * rnorm(N) + 0.1 * x1
y &lt;- 0.1 * x1 + x2 + rnorm(N)
summary(est &lt;- felm(y ~ x1 + x2))
pt1 &lt;- coef(est)["x1"]
pt2 &lt;- coef(est)["x2"]
# expected values of coefficients, should match the summary
# and variance, i.e. square of standard errors in the summary
nlexpect(est, quote(c(x1 = x1, x2 = x2, var = c((x1 - pt1)^2, (x2 - pt2)^2))))

# the covariance matrix:
nlexpect(est, tcrossprod(as.matrix(c(x1 - pt1, x2 - pt2))))

# Wald test of single variable
waldtest(est, ~x1)["p.F"]
# the same with nlexpect, i.e. probability for observing abs(x1)&gt;abs(pt1) conditional
# on E(x1) = 0.
nlexpect(est, (x1 - pt1)^2 &gt; pt1^2, tol = 1e-7, vectorize = TRUE)
# which is the same as
2 * nlexpect(est, x1 * sign(pt1) &lt; 0)

# Here's a multivalued, vectorized example
nlexpect(est, rbind(a = x1 * x2 &lt; pt1, b = x1 * x2 &gt; 0), vectorize = TRUE, method = "divonne")


# Non-linear test:

# A simple one, what's the probability that product x1*x2 is between 0 and |E(x1)|?
nlexpect(est, x1 * x2 &gt; 0 &amp; x1 * x2 &lt; abs(pt1), vectorize = TRUE, method = "divonne")
# Then a more complicated one with the expected value of a polynomal in the coefficients
f &lt;- function(x) c(poly = x[["x1"]] * (6 * x[["x1"]] - x[["x2"]]^2))
# This is the linearized test:
waldtest(est, f)["p.F"]
# In general, for a function f, the non-linear Wald test is something like
# the following:
# expected value of function
Ef &lt;- nlexpect(est, f, coefs = c("x1", "x2"))
# point value of function
Pf &lt;- f(c(pt1, pt2))
# similar to a Wald test, but non-linear:
nlexpect(est, function(x) (f(x) - Ef)^2 &gt; Pf^2, c("x1", "x2"), vectorize = TRUE)
# one-sided
nlexpect(est, function(x) f(x) - Ef &gt; abs(Pf), c("x1", "x2"), vectorize = TRUE)
# other sided
nlexpect(est, function(x) f(x) - Ef &lt; -abs(Pf), c("x1", "x2"), vectorize = TRUE)


</code></pre>

<hr>
<h2 id='sargan'>Compute Sargan's S</h2><span id='topic+sargan'></span>

<h3>Description</h3>

<p>Compute Sargan's S
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sargan(object, ..., lhs = object$lhs[1])
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sargan_+3A_object">object</code></td>
<td>
<p>and object type '&quot;felm&quot;', the return value from <code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code id="sargan_+3A_...">...</code></td>
<td>
<p>Not used at the moment.</p>
</td></tr>
<tr><td><code id="sargan_+3A_lhs">lhs</code></td>
<td>
<p>in case of multiple left hand sides, specify the name of the left
hand side for which you want to compute Sargan's S.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sargan</code> returns a numeric, the Sargan's S. The Basmann statistic is
returned in the '&quot;basmann&quot;' attribute.
</p>

<hr>
<h2 id='summary.felm'>Summarize felm model fits</h2><span id='topic+summary.felm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"felm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'felm'
summary(
  object,
  ...,
  robust = !is.null(object$clustervar) || getOption("lfe.robust"),
  lhs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.felm_+3A_object">object</code></td>
<td>
<p>an object of class <code>"felm"</code>, a result of a call to
<code>felm</code>.</p>
</td></tr>
<tr><td><code id="summary.felm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.felm_+3A_robust">robust</code></td>
<td>
<p>logical. Use robust standard errors. See notes.</p>
</td></tr>
<tr><td><code id="summary.felm_+3A_lhs">lhs</code></td>
<td>
<p>character. If multiple left hand sides, specify the name of the
one to obtain a summary for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.felm</code> returns an object of <code>class</code>
<code>"summary.felm"</code>.  It is quite similar to en <code>"summary.lm"</code>
object, but not entirely compatible.
</p>
<p>The <code>"summary.felm"</code> object is a list containing the following fields:
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>a numerical vector. The residuals of the full system, with
dummies.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>an integer. The total number of coefficients, including
those projected out.</p>
</td></tr>
<tr><td><code>Pp</code></td>
<td>
<p>an integer. The number of coefficients,
excluding those projected out.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a Pp x 4 matrix with
columns for the estimated coefficients, their standard errors, t-statistic
and corresponding (two-sided) p-value.</p>
</td></tr>
<tr><td><code>rse</code></td>
<td>
<p>residual standard error.</p>
</td></tr>
<tr><td><code>r2</code></td>
<td>
<p>R^2, the fraction of variance explained by the model.</p>
</td></tr>
<tr><td><code>r2adj</code></td>
<td>
<p>Adjusted R^2.</p>
</td></tr>
<tr><td><code>fstat</code></td>
<td>
<p>F-statistic.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>P-values.</p>
</td></tr>
<tr><td><code>P.fstat</code></td>
<td>
<p>Projected F-statistic. The result of a
call to <code><a href="#topic+waldtest">waldtest()</a></code></p>
</td></tr>
<tr><td><code>fe</code></td>
<td>
<p>list of factors. A list of the
terms in the second part of the model.</p>
</td></tr>
<tr><td><code>lhs.</code></td>
<td>
<p>character. If
<code>object</code> is the result of an estimation with multiple left hand sides,
the actual argument <code>lhs</code> will be copied to this field.</p>
</td></tr>
<tr><td><code>iv1fstat</code></td>
<td>
<p>F-statistic for excluded instruments in 1. step IV, see
<code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code>iv1pval</code></td>
<td>
<p>P-value for <code>iv1fstat</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The standard errors are adjusted for the reduced degrees of freedom
coming from the dummies which are implicitly present.  They are also
small-sample corrected.
</p>
<p>If the <code>robust</code> parameter is <code>FALSE</code>, the returned object will
contain ordinary standard errors. If the <code>robust</code> parameter is
<code>TRUE</code>, clustered standard errors are reported if a cluster was
specified in the call to <code>felm</code>; if not, heteroskedastic robust
standard errors are reported.
</p>
<p>Several F-statistics reported. The <code>P.fstat</code> is for the projected
system.  I.e. a joint test on whether all the <code>Pp</code> coefficients in
<code>coefficients</code> are zero.  Then there are <code>fstat</code> and <code>pval</code>
which is a test on all the coefficients including the ones projected out,
except for an intercept.  This statistic assumes i.i.d. errors and is not
reliable for robust or clustered data.
</p>
<p>For a 1st stage IV-regression, an F-statistic against the model with
excluded instruments is also computed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+waldtest">waldtest()</a></code>
</p>

<hr>
<h2 id='varvars'>Compute the variance of the fixed effect variance estimate</h2><span id='topic+varvars'></span>

<h3>Description</h3>

<p>Compute the variance of the fixed effect variance estimate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varvars(est, alpha = getfe(est), tol = 0.01, biascorrect = FALSE, lhs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varvars_+3A_est">est</code></td>
<td>
<p>an object of class '&quot;felm&quot;', the result of a call to
<code style="white-space: pre;">&#8288;[felm](keepX=TRUE)&#8288;</code>.</p>
</td></tr>
<tr><td><code id="varvars_+3A_alpha">alpha</code></td>
<td>
<p>a data frame, the result of a call to <code><a href="#topic+getfe">getfe()</a></code>.</p>
</td></tr>
<tr><td><code id="varvars_+3A_tol">tol</code></td>
<td>
<p>numeric. The absolute tolerance for the bias-corrected
correlation.</p>
</td></tr>
<tr><td><code id="varvars_+3A_biascorrect">biascorrect</code></td>
<td>
<p>logical. Should the estimates be bias corrected?</p>
</td></tr>
<tr><td><code id="varvars_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of left hand side if multiple left hand sides.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With a model like <code class="reqn">y = X\beta + D\theta + F\psi + \epsilon</code>, where <code class="reqn">D</code> and
<code class="reqn">F</code> are matrices with dummy encoded factors, one application of <span class="pkg">lfe</span> is
to study the variances <code class="reqn">var(D\theta)</code>, <code class="reqn">var(F\psi)</code> and covariances
<code class="reqn">cov(D\theta, F\psi)</code>. The function <code><a href="#topic+fevcov">fevcov()</a></code> computes bias corrected
variances and covariances.  However, these variance estimates are still
random variables for which <code><a href="#topic+fevcov">fevcov()</a></code> only estimate the
expectation. The function <code>varvars</code> estimates the variance of these
estimates.
</p>
<p>This function returns valid results only for normally distributed residuals.
Note that the estimates for the fixed effect variances from
<code><a href="#topic+fevcov">fevcov()</a></code> are not normally distributed, but a sum of chi-square
distributions which depends on the eigenvalues of certain large matrices. We
do not compute that distribution. The variances returned by <code>varvars</code>
can therefore <em>not</em> be used directly to estimate confidence intervals,
other than through coarse methods like the Chebyshev inequality. These
estimates only serve as a rough guideline as to how wrong the variance
estimates from <code><a href="#topic+fevcov">fevcov()</a></code> might be.
</p>
<p>Like the fixed effect variances themselves, their variances are also biased
upwards.  Correcting this bias can be costly, and is therefore by default
switched off.
</p>
<p>The variances tend to zero with increasing number of observations. Thus, for
large datasets they will be quite small.
</p>


<h3>Value</h3>

<p><code>varvars</code> returns a vector with a variance estimate for each
fixed effect variance.  I.e. for the diagonal returned by
<code><a href="#topic+fevcov">fevcov()</a></code>.
</p>


<h3>Note</h3>

<p>The <code>tol</code> argument specifies the tolerance as in
<code><a href="#topic+fevcov">fevcov()</a></code>.  Note that if <code>est</code> is the result of a call to
<code><a href="#topic+felm">felm()</a></code> with <code>keepX=FALSE</code> (the default), the variances will
be estimated as if the covariates X are independent of the factors.  There
is currently no function available for estimating the variance of the
covariance estimates from <code><a href="#topic+fevcov">fevcov()</a></code>.
</p>
<p>The cited paper does not contain the expressions for the variances computed
by <code>varvars</code> (there's a 10 page limit in that journal), though they can
be derived in the same fashion as in the paper, with the formula for the
variance of a quadratic form.
</p>


<h3>References</h3>

<p>Gaure, S. (2014), <cite>Correlation bias correction in two-way
fixed-effects linear regression</cite>, Stat 3(1):379-390, 2014.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bccorr">bccorr()</a></code> <code><a href="#topic+fevcov">fevcov()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(500)
x2 &lt;- rnorm(length(x))

## create individual and firm
id &lt;- factor(sample(40, length(x), replace = TRUE))
firm &lt;- factor(sample(30, length(x), replace = TRUE, prob = c(2, rep(1, 29))))
foo &lt;- factor(sample(20, length(x), replace = TRUE))
## effects
id.eff &lt;- rnorm(nlevels(id))
firm.eff &lt;- rnorm(nlevels(firm))
foo.eff &lt;- rnorm(nlevels(foo))
## left hand side
id.m &lt;- id.eff[id]
firm.m &lt;- 2 * firm.eff[firm]
foo.m &lt;- 3 * foo.eff[foo]
y &lt;- x + 0.25 * x2 + id.m + firm.m + foo.m + rnorm(length(x))

# make a data frame
fr &lt;- data.frame(y, x, x2, id, firm, foo)
## estimate and print result
est &lt;- felm(y ~ x + x2 | id + firm + foo, data = fr, keepX = TRUE)
alpha &lt;- getfe(est)
# estimate the covariance matrix of the fixed effects
fevcov(est, alpha)
# estimate variances of the diagonal
varvars(est, alpha)

</code></pre>

<hr>
<h2 id='waldtest'>Compute Wald test for joint restrictions on coefficients</h2><span id='topic+waldtest'></span>

<h3>Description</h3>

<p>Compute a Wald test for a linear hypothesis on the coefficients.  Also
supports Delta-approximation for non-linear hypotheses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waldtest(
  object,
  R,
  r,
  type = c("default", "iid", "robust", "cluster"),
  lhs = NULL,
  df1,
  df2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="waldtest_+3A_object">object</code></td>
<td>
<p>object of class <code>"felm"</code>, a result of a call to
<code><a href="#topic+felm">felm()</a></code>.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_r">R</code></td>
<td>
<p>matrix, character, formula, function, integer or logical.
Specification of which exclusions to test.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_r">r</code></td>
<td>
<p>numerical vector.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_type">type</code></td>
<td>
<p>character. Error structure type.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_lhs">lhs</code></td>
<td>
<p>character. Name of left hand side if multiple left hand sides.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_df1">df1</code></td>
<td>
<p>integer. If you know better than the default df, specify it here.</p>
</td></tr>
<tr><td><code id="waldtest_+3A_df2">df2</code></td>
<td>
<p>integer. If you know better than the default df, specify it here.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>waldtest</code> computes a Wald test for the H0: R beta = r,
where beta is the estimated vector <code>coef(object)</code>.
</p>
<p>If <code>R</code> is a character, integer, or logical vector it is assumed to
specify a matrix which merely picks out a subset of the coefficients for
joint testing. If <code>r</code> is not specified, it is assumed to be a zero
vector of the appropriate length.
</p>
<p><code>R</code> can also be a formula which is linear in the estimated
coefficients, e.g. of the type <code>~Q-2|x-2*z</code> which will test the joint
hypothesis Q=2 and x=2*z.
</p>
<p>If <code>R</code> is a function (of the coefficients), an approximate Wald test
against H0: <code>R(beta) == 0</code>, using the Delta-method, is computed.
</p>
<p>In case of an IV-estimation, the names for the endogenous variables in
<code>coef(object)</code> are of the type <code style="white-space: pre;">&#8288;"&#8288;</code>Q(fit)<code style="white-space: pre;">&#8288;"&#8288;</code> which is a bit dull to
type; if all the endogenous variables are to be tested they can be specified
as <code>"endovars"</code>. It is also possible to specify an endogenous variable
simply as <code>"Q"</code>, and <code>waldtest</code> will add the other syntactic sugar
to obtain <code style="white-space: pre;">&#8288;"&#8288;</code>Q(fit)<code style="white-space: pre;">&#8288;"&#8288;</code>.
</p>
<p>The <code>type</code> argument works as follows. If <code>type=='default'</code> it is
assumed that the residuals are i.i.d., unless a cluster structure was
specified to <code><a href="#topic+felm">felm()</a></code>. If <code>type=='robust'</code>, a heteroscedastic
structure is assumed, even if a cluster structure was specified in
<code><a href="#topic+felm">felm()</a></code>.
</p>


<h3>Value</h3>

<p>The function <code>waldtest</code> computes and returns a named numeric
vector containing the following elements.
</p>
 <ul>
<li> <p><code>p</code> is the p-value for the Chi^2-test </p>
</li>
<li> <p><code>chi2</code>
is the Chi^2-distributed statistic.  </p>
</li>
<li> <p><code>df1</code> is the degrees of
freedom for the Chi^2 statistic.  </p>
</li>
<li> <p><code>p.F</code> is the p-value for the F
statistics </p>
</li>
<li> <p><code>F</code> is the F-distributed statistic.  </p>
</li>
<li> <p><code>df2</code>
is the additional degrees of freedom for the F statistic. </p>
</li></ul>

<p>The return value has an attribute <code>'formula'</code> which encodes the
restrictions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlexpect">nlexpect()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(10000)
x2 &lt;- rnorm(length(x))
y &lt;- x - 0.2 * x2 + rnorm(length(x))
# Also works for lm
summary(est &lt;- lm(y ~ x + x2))
# We do not reject the true values
waldtest(est, ~ x - 1 | x2 + 0.2 | `(Intercept)`)
# The Delta-method coincides when the function is linear:
waldtest(est, function(x) x - c(0, 1, -0.2))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
