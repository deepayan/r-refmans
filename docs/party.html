<!DOCTYPE html><html><head><title>Help for package party</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {party}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BinaryTree Class'><p>Class &quot;BinaryTree&quot;</p></a></li>
<li><a href='#cforest'><p> Random Forest</p></a></li>
<li><a href='#Conditional Inference Trees'><p> Conditional Inference Trees</p></a></li>
<li><a href='#Control ctree Hyper Parameters'><p> Control for Conditional Inference Trees</p></a></li>
<li><a href='#Control Forest Hyper Parameters'><p> Control for Conditional Tree Forests</p></a></li>
<li><a href='#Fit Methods'><p> Fit &lsquo;StatModel&rsquo; Objects to Data</p></a></li>
<li><a href='#ForestControl-class'><p>Class &quot;ForestControl&quot;</p></a></li>
<li><a href='#Initialize Methods'><p> Methods for Function initialize in Package &lsquo;party&rsquo;</p></a></li>
<li><a href='#initVariableFrame-methods'><p>Set-up VariableFrame objects</p></a></li>
<li><a href='#LearningSample Class'><p>Class &quot;LearningSample&quot;</p></a></li>
<li><a href='#mob'><p>Model-based Recursive Partitioning</p></a></li>
<li><a href='#mob_control'><p>Control Parameters for Model-based Partitioning</p></a></li>
<li><a href='#Panel Generating Functions'><p> Panel-Generators for Visualization of Party Trees</p></a></li>
<li><a href='#party_intern'>
<p>Call internal functions.</p></a></li>
<li><a href='#Plot BinaryTree'><p> Visualization of Binary Regression Trees</p></a></li>
<li><a href='#plot.mob'><p> Visualization of MOB Trees</p></a></li>
<li><a href='#prettytree'>
<p>Print a tree.</p></a></li>
<li><a href='#RandomForest-class'><p>Class &quot;RandomForest&quot;</p></a></li>
<li><a href='#readingSkills'><p> Reading Skills</p></a></li>
<li><a href='#reweight'><p>Re-fitting Models with New Weights</p></a></li>
<li><a href='#SplittingNode Class'><p>Class &quot;SplittingNode&quot;</p></a></li>
<li><a href='#Transformations'><p> Function for Data Transformations</p></a></li>
<li><a href='#TreeControl Class'><p>Class &quot;TreeControl&quot;</p></a></li>
<li><a href='#varimp'><p> Variable Importance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Laboratory for Recursive Partytioning</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-27</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3-14</td>
</tr>
<tr>
<td>Description:</td>
<td>A computational toolbox for recursive partitioning.
  The core of the package is ctree(), an implementation of
  conditional inference trees which embed tree-structured 
  regression models into a well defined theory of conditional
  inference procedures. This non-parametric class of regression
  trees is applicable to all kinds of regression problems, including
  nominal, ordinal, numeric, censored as well as multivariate response
  variables and arbitrary measurement scales of the covariates. 
  Based on conditional inference trees, cforest() provides an
  implementation of Breiman's random forests. The function mob()
  implements an algorithm for recursive partitioning based on
  parametric models (e.g. linear models, GLMs or survival
  regression) employing parameter instability tests for split
  selection. Extensible functionality for visualizing tree-structured
  regression models is available. The methods are described in
  Hothorn et al. (2006) &lt;<a href="https://doi.org/10.1198%2F106186006X133933">doi:10.1198/106186006X133933</a>&gt;,
  Zeileis et al. (2008) &lt;<a href="https://doi.org/10.1198%2F106186008X319331">doi:10.1198/106186008X319331</a>&gt; and 
  Strobl et al. (2007) &lt;<a href="https://doi.org/10.1186%2F1471-2105-8-25">doi:10.1186/1471-2105-8-25</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), methods, grid, stats, mvtnorm (&ge; 1.0-2),
modeltools (&ge; 0.2-21), strucchange</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival (&ge; 2.37-7), coin (&ge; 1.1-0), zoo, sandwich (&ge;
1.1-1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>TH.data (&ge; 1.0-3), mlbench, colorspace, MASS, vcd, ipred,
varImp, randomForest</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://party.R-forge.R-project.org">http://party.R-forge.R-project.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-27 11:56:01 UTC; hothorn</td>
</tr>
<tr>
<td>Author:</td>
<td>Torsten Hothorn <a href="https://orcid.org/0000-0001-8301-0471"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Kurt Hornik [aut],
  Carolin Strobl [aut],
  Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Torsten Hothorn &lt;Torsten.Hothorn@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 07:00:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='BinaryTree+20Class'>Class &quot;BinaryTree&quot;</h2><span id='topic+BinaryTree-class'></span><span id='topic+weights'></span><span id='topic+weights-methods'></span><span id='topic+weights+2CBinaryTree-method'></span><span id='topic+show+2CBinaryTree-method'></span><span id='topic+where'></span><span id='topic+where-methods'></span><span id='topic+where+2CBinaryTree-method'></span><span id='topic+response'></span><span id='topic+response-methods'></span><span id='topic+response+2CBinaryTree-method'></span><span id='topic+nodes'></span><span id='topic+nodes-methods'></span><span id='topic+nodes+2CBinaryTree+2Cinteger-method'></span><span id='topic+nodes+2CBinaryTree+2Cnumeric-method'></span><span id='topic+treeresponse'></span><span id='topic+treeresponse-methods'></span><span id='topic+treeresponse+2CBinaryTree-method'></span>

<h3>Description</h3>

<p>A class for representing binary trees.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("BinaryTree", ...)</code>.
The most important slot is <code>tree</code>, a (recursive) list with elements
</p>

<dl>
<dt>nodeID</dt><dd><p> an integer giving the number of the node, starting with
<code>1</code> in the root node.</p>
</dd>
<dt>weights</dt><dd><p> the case weights (of the learning sample) corresponding to
this node.</p>
</dd>
<dt>criterion</dt><dd><p> a list with test statistics and p-values for each partial
hypothesis.</p>
</dd>
<dt>terminal</dt><dd><p> a logical specifying if this is a terminal node.</p>
</dd>
<dt>psplit</dt><dd><p> primary split: a list with elements <code>variableID</code> (the
number of the input variable splitted), <code>ordered</code> (a
logical whether the input variable is ordered),
<code>splitpoint</code> (the cutpoint or set of levels to the left),
<code>splitstatistics</code> saves the process of standardized 
two-sample statistics the split point estimation is based on.
The logical <code>toleft</code> determines if observations
go left or right down the tree. For nominal splits, the slot
<code>table</code> is a vector being greater zero if the
corresponding level is available in the corresponding node.</p>
</dd>
<dt>ssplits</dt><dd><p> a list of surrogate splits, each with the same elements as
<code>psplit</code>.</p>
</dd>
<dt>prediction</dt><dd><p> the prediction of the node: the mean for numeric
responses and the conditional class probabilities for 
nominal or ordered respones. For censored responses,
this is the mean of the logrank scores and useless as
such.</p>
</dd>
<dt>left</dt><dd><p> a list representing the left daughter node. </p>
</dd>
<dt>right</dt><dd><p> a list representing the right daugther node.</p>
</dd>
</dl>

<p>Please note that this data structure may be subject to change in future
releases of the package.
</p>


<h3>Slots</h3>


<dl>
<dt><code>data</code>:</dt><dd><p> an object of class <code>"<a href="modeltools.html#topic+ModelEnv-class">ModelEnv</a>"</code>.</p>
</dd>
<dt><code>responses</code>:</dt><dd><p> an object of class <code>"VariableFrame"</code>
storing the values of the response variable(s). </p>
</dd>
<dt><code>cond_distr_response</code>:</dt><dd><p> a function computing the conditional
distribution of the response. </p>
</dd> 
<dt><code>predict_response</code>:</dt><dd><p> a function for computing predictions. </p>
</dd>
<dt><code>tree</code>:</dt><dd><p> a recursive list representing the tree. See above. </p>
</dd>
<dt><code>where</code>:</dt><dd><p> an integer vector of length n (number of
observations in the learning sample) giving the
number of the terminal node the corresponding
observations is element of. </p>
</dd>
<dt><code>prediction_weights</code>:</dt><dd><p> a function for extracting weights from
terminal nodes. </p>
</dd>
<dt><code>get_where</code>:</dt><dd><p> a function for determining the number
of terminal nodes observations fall into. </p>
</dd>
<dt><code>update</code>:</dt><dd><p> a function for updating weights.</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"BinaryTreePartition"</code>, directly.
</p>


<h3>Methods</h3>


<dl>
<dt><code>response(object, ...)</code>:</dt><dd><p>extract the response variables the
tree was fitted to.</p>
</dd>
<dt><code>treeresponse(object, newdata = NULL, ...)</code>:</dt><dd><p>compute
statistics for the conditional distribution of the response as
modelled by the tree. For regression problems, this is just the mean.
For nominal or ordered responses, estimated conditional class
probabilities are returned. Kaplan-Meier curves are computed for
censored responses. Note that a list with one element for each
observation is returned.</p>
</dd>
<dt><code>Predict(object, newdata = NULL, ...)</code>:</dt><dd><p> compute predictions.</p>
</dd>
<dt><code>weights(object, newdata = NULL, ...)</code>:</dt><dd><p> extract the weight
vector from terminal nodes each element of the learning sample is
element of (<code>newdata = NULL</code>) and for new observations, 
respectively.</p>
</dd>
<dt><code>where(object, newdata = NULL, ...)</code>:</dt><dd><p> extract the number of 
the terminal nodes each element of the learning sample is
element of (<code>newdata = NULL</code>) and for new observations, 
respectively.</p>
</dd>
<dt><code>nodes(object, where, ...)</code>:</dt><dd><p> extract the nodes with
given number (<code>where</code>).</p>
</dd>
<dt><code>plot(x, ...)</code>:</dt><dd><p> a plot method for <code>BinaryTree</code>
objects, see <code><a href="#topic+plot.BinaryTree">plot.BinaryTree</a></code>.</p>
</dd>
<dt><code>print(x, ...)</code>:</dt><dd><p> a print method for <code>BinaryTree</code>
objects.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(290875)

  airq &lt;- subset(airquality, !is.na(Ozone))
  airct &lt;- ctree(Ozone ~ ., data = airq,   
                 controls = ctree_control(maxsurrogate = 3))

  ### distribution of responses in the terminal nodes
  plot(airq$Ozone ~ as.factor(where(airct)))

  ### get all terminal nodes from the tree
  nodes(airct, unique(where(airct)))

  ### extract weights and compute predictions
  pmean &lt;- sapply(weights(airct), function(w) weighted.mean(airq$Ozone, w))

  ### the same as
  drop(Predict(airct))

  ### or
  unlist(treeresponse(airct))

  ### don't use the mean but the median as prediction in each terminal node
  pmedian &lt;- sapply(weights(airct), function(w) 
                 median(airq$Ozone[rep(1:nrow(airq), w)]))

  plot(airq$Ozone, pmean, col = "red")
  points(airq$Ozone, pmedian, col = "blue")
</code></pre>

<hr>
<h2 id='cforest'> Random Forest </h2><span id='topic+cforest'></span><span id='topic+proximity'></span>

<h3>Description</h3>

<p>An implementation of the random forest and bagging ensemble algorithms
utilizing conditional inference trees as base learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cforest(formula, data = list(), subset = NULL, weights = NULL, 
        controls = cforest_unbiased(),
        xtrafo = ptrafo, ytrafo = ptrafo, scores = NULL)
proximity(object, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cforest_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit. Note 
that symbols like <code>:</code> and <code>-</code> will not work
and the tree will make use of all variables listed on the
rhs of <code>formula</code>.</p>
</td></tr>                  
<tr><td><code id="cforest_+3A_data">data</code></td>
<td>
<p> an data frame containing the variables in the model. </p>
</td></tr>
<tr><td><code id="cforest_+3A_subset">subset</code></td>
<td>
<p> an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="cforest_+3A_weights">weights</code></td>
<td>
<p> an optional vector of weights to be used in the fitting
process. Non-negative integer valued weights are
allowed as well as non-negative real weights.
Observations are sampled (with or without replacement)
according to probabilities <code>weights / sum(weights)</code>.
The fraction of observations to be sampled (without replacement)
is computed based on the sum of the weights if all weights
are integer-valued and based on the number of weights greater zero
else. Alternatively, <code>weights</code> can be a double matrix defining
case weights for all <code>ncol(weights)</code> trees in the forest directly.
This requires more storage but gives the user more control.</p>
</td></tr>
<tr><td><code id="cforest_+3A_controls">controls</code></td>
<td>
<p>an object of class <code><a href="#topic+ForestControl-class">ForestControl-class</a></code>, which can be
obtained using <code><a href="#topic+cforest_control">cforest_control</a></code> (and its
convenience interfaces <code>cforest_unbiased</code> and <code>cforest_classical</code>).</p>
</td></tr>
<tr><td><code id="cforest_+3A_xtrafo">xtrafo</code></td>
<td>
<p> a function to be applied to all input variables.
By default, the <code><a href="#topic+ptrafo">ptrafo</a></code> function is applied.</p>
</td></tr>
<tr><td><code id="cforest_+3A_ytrafo">ytrafo</code></td>
<td>
<p> a function to be applied to all response variables.
By default, the <code><a href="#topic+ptrafo">ptrafo</a></code> function is applied.</p>
</td></tr>
<tr><td><code id="cforest_+3A_scores">scores</code></td>
<td>
<p> an optional named list of scores to be attached to ordered
factors.</p>
</td></tr>
<tr><td><code id="cforest_+3A_object">object</code></td>
<td>
<p> an object as returned by <code>cforest</code>.</p>
</td></tr>
<tr><td><code id="cforest_+3A_newdata">newdata</code></td>
<td>
<p> an optional data frame containing test data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation of the random forest (and bagging) algorithm differs
from the reference implementation in <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
with respect to the base learners used and the aggregation scheme applied.
</p>
<p>Conditional inference trees, see <code><a href="#topic+ctree">ctree</a></code>, are fitted to each
of the <code>ntree</code> (defined via <code><a href="#topic+cforest_control">cforest_control</a></code>) 
bootstrap samples of the learning sample. Most of the hyper parameters in 
<code><a href="#topic+cforest_control">cforest_control</a></code> regulate the construction of the conditional inference trees.
Therefore you MUST NOT change anything you don't understand completely.
</p>
<p>Hyper parameters you might want to change in <code><a href="#topic+cforest_control">cforest_control</a></code> are: 
</p>
<p>1. The number of randomly preselected variables <code>mtry</code>, which is fixed 
to the value 5 by default here for technical reasons, while in 
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code> the default values for classification and regression
vary with the number of input variables. 
</p>
<p>2. The number of trees <code>ntree</code>. Use more trees if you have more variables.
</p>
<p>3. The depth of the trees, regulated by <code>mincriterion</code>. Usually unstopped and unpruned
trees are used in random forests. To grow large trees, set <code>mincriterion</code> to a small value.
</p>
<p>The aggregation scheme works by averaging observation weights extracted
from each of the <code>ntree</code> trees and NOT by averaging predictions directly
as in <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>.
See Hothorn et al. (2004) for a description. 
</p>
<p>Predictions can be computed using <code><a href="stats.html#topic+predict">predict</a></code>. For observations
with zero weights, predictions are computed from the fitted tree 
when <code>newdata = NULL</code>. While <code><a href="stats.html#topic+predict">predict</a></code> returns predictions
of the same type as the response in the data set by default (i.e., predicted class labels for factors), 
<code><a href="#topic+treeresponse">treeresponse</a></code> returns the statistics of the conditional distribution of the response
(i.e., predicted class probabilities for factors). The same is done by <code>predict(..., type = "prob")</code>.
Note that for multivariate responses <code>predict</code> does not convert predictions to the type 
of the response, i.e., <code>type = "prob"</code> is used.
</p>
<p>Ensembles of conditional inference trees have not yet been extensively
tested, so this routine is meant for the expert user only and its current
state is rather experimental. However, there are some things available 
in <code><a href="#topic+cforest">cforest</a></code> that can't be done with <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, 
for example fitting forests to censored response variables (see Hothorn et al., 2006a) or to
multivariate and ordered responses.
</p>
<p>Moreover, when predictors vary in their scale of measurement of number 
of categories, variable selection and computation of variable importance is biased 
in favor of variables with many potential cutpoints in <code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, 
while in <code><a href="#topic+cforest">cforest</a></code> unbiased trees and an adequate resampling scheme 
are used by default. See Hothorn et al. (2006b) and Strobl et al. (2007) 
as well as Strobl et al. (2009). 
</p>
<p>The <code>proximity</code> matrix is an <code class="reqn">n \times n</code> matrix <code class="reqn">P</code> with <code class="reqn">P_{ij}</code>
equal to the fraction of trees where observations <code class="reqn">i</code> and <code class="reqn">j</code> 
are element of the same terminal node (when both <code class="reqn">i</code> and <code class="reqn">j</code>
had non-zero weights in the same bootstrap sample).
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+RandomForest-class">RandomForest-class</a></code>.
</p>


<h3>References</h3>

 
<p>Leo Breiman (2001). Random Forests. <em>Machine Learning</em>, 45(1), 5&ndash;32.
</p>
<p>Torsten Hothorn, Berthold Lausen, Axel Benner and Martin Radespiel-Troeger
(2004). Bagging Survival Trees. <em>Statistics in Medicine</em>, <b>23</b>(1), 77&ndash;91.
</p>
<p>Torsten Hothorn, Peter Buhlmann, Sandrine Dudoit, Annette Molinaro 
and Mark J. van der Laan (2006a). Survival Ensembles. <em>Biostatistics</em>, 
<b>7</b>(3), 355&ndash;373.
</p>
<p>Torsten Hothorn, Kurt Hornik and Achim Zeileis (2006b). Unbiased
Recursive Partitioning: A Conditional Inference Framework.
<em>Journal of Computational and Graphical Statistics</em>, <b>15</b>(3),
651&ndash;674.  Preprint available from 
<a href="https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf">https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf</a>
</p>
<p>Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis and Torsten Hothorn (2007).
Bias in Random Forest Variable Importance Measures: Illustrations, Sources and 
a Solution. <em>BMC Bioinformatics</em>, <b>8</b>, 25. 
<a href="https://doi.org/10.1186/1471-2105-8-25">doi:10.1186/1471-2105-8-25</a>
</p>
<p>Carolin Strobl, James Malley and Gerhard Tutz (2009).
An Introduction to Recursive Partitioning: Rationale, Application, and Characteristics of
Classification and Regression Trees, Bagging, and Random forests.
<em>Psychological Methods</em>, <b>14</b>(4), 323&ndash;348.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    set.seed(290875)

    ### honest (i.e., out-of-bag) cross-classification of
    ### true vs. predicted classes
    data("mammoexp", package = "TH.data")
    table(mammoexp$ME, predict(cforest(ME ~ ., data = mammoexp, 
                               control = cforest_unbiased(ntree = 50)),
                               OOB = TRUE))

    ### fit forest to censored response
    if (require("TH.data") &amp;&amp; require("survival")) {

        data("GBSG2", package = "TH.data")
        bst &lt;- cforest(Surv(time, cens) ~ ., data = GBSG2, 
                   control = cforest_unbiased(ntree = 50))

        ### estimate conditional Kaplan-Meier curves
        treeresponse(bst, newdata = GBSG2[1:2,], OOB = TRUE)

        ### if you can't resist to look at individual trees ...
        party:::prettytree(bst@ensemble[[1]], names(bst@data@get("input")))
    }

    ### proximity, see ?randomForest
    iris.cf &lt;- cforest(Species ~ ., data = iris, 
                       control = cforest_unbiased(mtry = 2))
    iris.mds &lt;- cmdscale(1 - proximity(iris.cf), eig = TRUE)
    op &lt;- par(pty="s")
    pairs(cbind(iris[,1:4], iris.mds$points), cex = 0.6, gap = 0, 
          col = c("red", "green", "blue")[as.numeric(iris$Species)],
          main = "Iris Data: Predictors and MDS of Proximity Based on cforest")
    par(op)

</code></pre>

<hr>
<h2 id='Conditional+20Inference+20Trees'> Conditional Inference Trees </h2><span id='topic+ctree'></span><span id='topic+conditionalTree'></span>

<h3>Description</h3>

<p>Recursive partitioning for continuous, censored, ordered, nominal and
multivariate response variables in a conditional inference framework. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctree(formula, data, subset = NULL, weights = NULL, 
      controls = ctree_control(), xtrafo = ptrafo, ytrafo = ptrafo, 
      scores = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit. Note
that symbols like <code>:</code> and <code>-</code> will not work
and the tree will make use of all variables listed on the
rhs of <code>formula</code>.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_data">data</code></td>
<td>
<p> a data frame containing the variables in the model. </p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_subset">subset</code></td>
<td>
<p> an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_weights">weights</code></td>
<td>
<p> an optional vector of weights to be used in the fitting
process. Only non-negative integer valued weights are
allowed.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_controls">controls</code></td>
<td>
<p>an object of class <code><a href="#topic+TreeControl">TreeControl</a></code>, which can be
obtained using <code><a href="#topic+ctree_control">ctree_control</a></code>.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_xtrafo">xtrafo</code></td>
<td>
<p> a function to be applied to all input variables.
By default, the <code><a href="#topic+ptrafo">ptrafo</a></code> function is applied.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_ytrafo">ytrafo</code></td>
<td>
<p> a function to be applied to all response variables. 
By default, the <code><a href="#topic+ptrafo">ptrafo</a></code> function is applied.</p>
</td></tr>
<tr><td><code id="Conditional+2B20Inference+2B20Trees_+3A_scores">scores</code></td>
<td>
<p> an optional named list of scores to be attached to ordered
factors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conditional inference trees estimate a regression relationship by binary recursive
partitioning in a conditional inference framework. Roughly, the algorithm
works as follows: 1) Test the global null hypothesis of independence between
any of the input variables and the response (which may be multivariate as well). 
Stop if this hypothesis cannot be rejected. Otherwise select the input
variable with strongest association to the resonse. This
association is measured by a p-value corresponding to a test for the
partial null hypothesis of a single input variable and the response.
2) Implement a binary split in the selected input variable. 
3) Recursively repeate steps 1) and 2). 
</p>
<p>The implementation utilizes a unified framework for conditional inference,
or permutation tests, developed by Strasser and Weber (1999). The stop
criterion in step 1) is either based on multiplicity adjusted p-values 
(<code>testtype == "Bonferroni"</code>
or <code>testtype == "MonteCarlo"</code> in <code><a href="#topic+ctree_control">ctree_control</a></code>),
on the univariate p-values (<code>testtype == "Univariate"</code>),
or on values of the test statistic
(<code>testtype == "Teststatistic"</code>). In both cases, the
criterion is maximized, i.e., 1 - p-value is used. A split is implemented 
when the criterion exceeds the value given by <code>mincriterion</code> as
specified in <code><a href="#topic+ctree_control">ctree_control</a></code>. For example, when 
<code>mincriterion = 0.95</code>, the p-value must be smaller than
$0.05$ in order to split this node. This statistical approach ensures that
the right sized tree is grown and no form of pruning or cross-validation
or whatsoever is needed. The selection of the input variable to split in
is based on the univariate p-values avoiding a variable selection bias
towards input variables with many possible cutpoints.
</p>
<p>Multiplicity-adjusted Monte-Carlo p-values are computed 
following a &quot;min-p&quot; approach. The univariate 
p-values based on the limiting distribution (chi-square
or normal) are computed for each of the random 
permutations of the data. This means that one should
use a quadratic test statistic when factors are in
play (because the evaluation of the corresponding
multivariate normal distribution is time-consuming).
</p>
<p>By default, the scores for each ordinal factor <code>x</code> are
<code>1:length(x)</code>, this may be changed using <code>scores = list(x =
  c(1,5,6))</code>, for example.
</p>
<p>Predictions can be computed using <code><a href="stats.html#topic+predict">predict</a></code> or
<code><a href="#topic+treeresponse">treeresponse</a></code>.  The first function accepts arguments
<code>type = c("response", "node", "prob")</code> where <code>type = "response"</code>
returns predicted means, predicted classes or median predicted survival
times, <code>type = "node"</code> returns terminal node IDs (identical to
<code><a href="#topic+where">where</a></code>) and <code>type = "prob"</code> gives more information about
the conditional distribution of the response, i.e., class probabilities or
predicted Kaplan-Meier curves and is identical to
<code><a href="#topic+treeresponse">treeresponse</a></code>.  For observations with zero weights,
predictions are computed from the fitted tree when <code>newdata = NULL</code>.
</p>
<p>For a general description of the methodology see Hothorn, Hornik and
Zeileis (2006) and Hothorn, Hornik, van de Wiel and Zeileis (2006). 
Introductions for novices can be found in Strobl et al. (2009) and
at <a href="https://github.com/christophM/overview-ctrees">https://github.com/christophM/overview-ctrees</a>.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+BinaryTree-class">BinaryTree-class</a></code>.
</p>


<h3>References</h3>

 
<p>Helmut Strasser and Christian Weber (1999). On the asymptotic theory of permutation
statistics. <em>Mathematical Methods of Statistics</em>, <b>8</b>, 220&ndash;250.
</p>
<p>Torsten Hothorn, Kurt Hornik, Mark A. van de Wiel and Achim Zeileis (2006).
A Lego System for Conditional Inference. <em>The American Statistician</em>,
<b>60</b>(3), 257&ndash;263.
</p>
<p>Torsten Hothorn, Kurt Hornik and Achim Zeileis (2006). Unbiased Recursive
Partitioning: A Conditional Inference Framework. <em>Journal of
Computational and Graphical Statistics</em>, <b>15</b>(3), 651&ndash;674. 
Preprint available
from <a href="https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf">https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf</a>
</p>
<p>Carolin Strobl, James Malley and Gerhard Tutz (2009).
An Introduction to Recursive Partitioning: Rationale, Application, and Characteristics of 
Classification and Regression Trees, Bagging, and Random forests.
<em>Psychological Methods</em>, <b>14</b>(4), 323&ndash;348. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
    set.seed(290875)

    ### regression
    airq &lt;- subset(airquality, !is.na(Ozone))
    airct &lt;- ctree(Ozone ~ ., data = airq, 
                   controls = ctree_control(maxsurrogate = 3))
    airct
    plot(airct)
    mean((airq$Ozone - predict(airct))^2)
    ### extract terminal node ID, two ways
    all.equal(predict(airct, type = "node"), where(airct))

    ### classification
    irisct &lt;- ctree(Species ~ .,data = iris)
    irisct
    plot(irisct)
    table(predict(irisct), iris$Species)

    ### estimated class probabilities, a list
    tr &lt;- treeresponse(irisct, newdata = iris[1:10,])

    ### ordinal regression
    data("mammoexp", package = "TH.data")
    mammoct &lt;- ctree(ME ~ ., data = mammoexp) 
    plot(mammoct)

    ### estimated class probabilities
    treeresponse(mammoct, newdata = mammoexp[1:10,])

    ### survival analysis
    if (require("TH.data") &amp;&amp; require("survival")) {
        data("GBSG2", package = "TH.data")
        GBSG2ct &lt;- ctree(Surv(time, cens) ~ .,data = GBSG2)
        plot(GBSG2ct)
        treeresponse(GBSG2ct, newdata = GBSG2[1:2,])        
    }

    ### if you are interested in the internals:
    ### generate doxygen documentation
    ## Not run: 

        ### download src package into temp dir
        tmpdir &lt;- tempdir()
        tgz &lt;- download.packages("party", destdir = tmpdir)[2]
        ### extract
        untar(tgz, exdir = tmpdir)
        wd &lt;- setwd(file.path(tmpdir, "party"))
        ### run doxygen (assuming it is there)
        system("doxygen inst/doxygen.cfg")
        setwd(wd)
        ### have fun
        browseURL(file.path(tmpdir, "party", "inst", 
                            "documentation", "html", "index.html")) 
    
## End(Not run)
</code></pre>

<hr>
<h2 id='Control+20ctree+20Hyper+20Parameters'> Control for Conditional Inference Trees </h2><span id='topic+ctree_control'></span>

<h3>Description</h3>

<p>Various parameters that control aspects of the &lsquo;ctree&rsquo; fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctree_control(teststat = c("quad", "max"), 
              testtype = c("Bonferroni", "MonteCarlo", 
                           "Univariate", "Teststatistic"), 
              mincriterion = 0.95, minsplit = 20, minbucket = 7, 
              stump = FALSE, nresample = 9999, maxsurrogate = 0, 
              mtry = 0, savesplitstats = TRUE, maxdepth = 0, remove_weights = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_teststat">teststat</code></td>
<td>
<p> a character specifying the type of the test statistic
to be applied. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_testtype">testtype</code></td>
<td>
<p> a character specifying how to compute the distribution of
the test statistic. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_mincriterion">mincriterion</code></td>
<td>
<p> the value of the test statistic (for <code>testtype == "Teststatistic"</code>),
or 1 - p-value (for other values of <code>testtype</code>) that
must be exceeded in order to implement a split. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_minsplit">minsplit</code></td>
<td>
<p> the minimum sum of weights in a node in order to be considered
for splitting. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_minbucket">minbucket</code></td>
<td>
<p> the minimum sum of weights in a terminal node. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_stump">stump</code></td>
<td>
<p> a logical determining whether a stump (a tree with three
nodes only) is to be computed. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_nresample">nresample</code></td>
<td>
<p> number of Monte-Carlo replications to use when the
distribution of the test statistic is simulated.</p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_maxsurrogate">maxsurrogate</code></td>
<td>
<p> number of surrogate splits to evaluate. Note that
currently only surrogate splits in ordered
covariables are implemented. </p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_mtry">mtry</code></td>
<td>
<p> number of input variables randomly sampled as candidates 
at each node for random forest like algorithms. The default
<code>mtry = 0</code> means that no random selection takes place.</p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_savesplitstats">savesplitstats</code></td>
<td>
<p> a logical determining if the process of standardized
two-sample statistics for split point estimate
is saved for each primary split.</p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_maxdepth">maxdepth</code></td>
<td>
<p> maximum depth of the tree. The default <code>maxdepth = 0</code>
means that no restrictions are applied to tree sizes.</p>
</td></tr>
<tr><td><code id="Control+2B20ctree+2B20Hyper+2B20Parameters_+3A_remove_weights">remove_weights</code></td>
<td>
<p> a logical determining if weights attached to nodes shall be removed
after fitting the tree.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments <code>teststat</code>, <code>testtype</code> and <code>mincriterion</code>
determine how the global null hypothesis of independence between all input
variables and the response is tested (see <code><a href="#topic+ctree">ctree</a></code>). The 
argument <code>nresample</code> is the number of Monte-Carlo replications to be
used when <code>testtype = "MonteCarlo"</code>.
</p>
<p>A split is established when the sum of the weights in both daugther nodes
is larger than <code>minsplit</code>, this avoids pathological splits at the
borders. When <code>stump = TRUE</code>, a tree with at most two terminal nodes
is computed.
</p>
<p>The argument <code>mtry &gt; 0</code> means that a random forest like 'variable
selection', i.e., a random selection of <code>mtry</code> input variables, is
performed in each node.
</p>
<p>It might be informative to look at scatterplots of input variables against
the standardized two-sample split statistics, those are available when
<code>savesplitstats = TRUE</code>. Each node is then associated with a vector
whose length is determined by the number of observations in the learning
sample and thus much more memory is required.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+TreeControl">TreeControl</a></code>.
</p>

<hr>
<h2 id='Control+20Forest+20Hyper+20Parameters'> Control for Conditional Tree Forests </h2><span id='topic+cforest_control'></span><span id='topic+cforest_classical'></span><span id='topic+cforest_unbiased'></span>

<h3>Description</h3>

<p>Various parameters that control aspects of the &lsquo;cforest&rsquo; fit via
its &lsquo;control&rsquo; argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cforest_unbiased(...)
cforest_classical(...)
cforest_control(teststat = "max",
                testtype = "Teststatistic",
                mincriterion = qnorm(0.9),
                savesplitstats = FALSE,
                ntree = 500, mtry = 5, replace = TRUE,
                fraction = 0.632, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_teststat">teststat</code></td>
<td>
<p> a character specifying the type of the test statistic
to be applied. </p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_testtype">testtype</code></td>
<td>
<p> a character specifying how to compute the distribution of
the test statistic. </p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_mincriterion">mincriterion</code></td>
<td>
<p> the value of the test statistic (for <code>testtype == "Teststatistic"</code>),
or 1 - p-value (for other values of <code>testtype</code>) that
must be exceeded in order to implement a split. </p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_mtry">mtry</code></td>
<td>
<p> number of input variables randomly sampled as candidates 
at each node for random forest like algorithms. Bagging, as special case 
of a random forest without random input variable sampling, can 
be performed by setting <code>mtry</code> either equal to <code>NULL</code> or 
manually equal to the number of input variables.</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_savesplitstats">savesplitstats</code></td>
<td>
<p> a logical determining whether the process of standardized
two-sample statistics for split point estimate
is saved for each primary split.</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_ntree">ntree</code></td>
<td>
<p> number of trees to grow in a forest.</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_replace">replace</code></td>
<td>
<p> a logical indicating whether sampling of observations is 
done with or without replacement.</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_fraction">fraction</code></td>
<td>
<p> fraction of number of observations to draw without 
replacement (only relevant if <code>replace = FALSE</code>).</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_trace">trace</code></td>
<td>
<p> a logical indicating if a progress bar shall be printed
while the forest grows.</p>
</td></tr>
<tr><td><code id="Control+2B20Forest+2B20Hyper+2B20Parameters_+3A_...">...</code></td>
<td>
<p> additional arguments to be passed to 
<code><a href="#topic+ctree_control">ctree_control</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All three functions return an object of class <code><a href="#topic+ForestControl-class">ForestControl-class</a></code>
defining hyper parameters to be specified via the <code>control</code> argument
of <code><a href="#topic+cforest">cforest</a></code>.
</p>
<p>The arguments <code>teststat</code>, <code>testtype</code> and <code>mincriterion</code>
determine how the global null hypothesis of independence between all input
variables and the response is tested (see <code><a href="#topic+ctree">ctree</a></code>). The 
argument <code>nresample</code> is the number of Monte-Carlo replications to be
used when <code>testtype = "MonteCarlo"</code>.
</p>
<p>A split is established when the sum of the weights in both daugther nodes
is larger than <code>minsplit</code>, this avoids pathological splits at the
borders. When <code>stump = TRUE</code>, a tree with at most two terminal nodes
is computed.
</p>
<p>The <code>mtry</code> argument regulates a random selection of <code>mtry</code> input 
variables in each node. Note that here <code>mtry</code> is fixed to the value 5 by 
default for merely technical reasons, while in <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> 
the default values for classification and regression vary with the number of input 
variables. Make sure that <code>mtry</code> is defined properly before using <code>cforest</code>.
</p>
<p>It might be informative to look at scatterplots of input variables against
the standardized two-sample split statistics, those are available when
<code>savesplitstats = TRUE</code>. Each node is then associated with a vector
whose length is determined by the number of observations in the learning
sample and thus much more memory is required.
</p>
<p>The number of trees <code>ntree</code> can be increased for large numbers of input variables.
</p>
<p>Function <code>cforest_unbiased</code> returns the settings suggested 
for the construction of unbiased random forests (<code>teststat = "quad", testtype = "Univ", 
    replace = FALSE</code>) by Strobl et al. (2007)
and is the default since version 0.9-90.
Hyper parameter settings mimicing the behaviour of
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code> are available in
<code>cforest_classical</code> which have been used as default up to
version 0.9-14. 
</p>
<p>Please note that <code><a href="#topic+cforest">cforest</a></code>, in contrast to 
<code><a href="randomForest.html#topic+randomForest">randomForest</a></code>, doesn't grow trees of
maximal depth. To grow large trees, set <code>mincriterion = 0</code>.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+ForestControl-class">ForestControl-class</a></code>.
</p>


<h3>References</h3>

<p>Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis and Torsten Hothorn (2007).
Bias in Random Forest Variable Importance Measures: Illustrations, Sources and  
a Solution. <em>BMC Bioinformatics</em>, <b>8</b>, 25. DOI: 10.1186/1471-2105-8-25
</p>

<hr>
<h2 id='Fit+20Methods'> Fit &lsquo;StatModel&rsquo; Objects to Data </h2><span id='topic+fit-methods'></span><span id='topic+fit+2CStatModel+2CLearningSample-method'></span>

<h3>Description</h3>

<p>Fit a &lsquo;StatModel&rsquo; model to objects of class &lsquo;LearningSample&rsquo;.
</p>


<h3>Methods</h3>


<dl>
<dt>fit</dt><dd><p><code>signature(model = "StatModel", data = "LearningSample")</code>:
fit <code>model</code> to <code>data</code>.</p>
</dd>
</dl>


<hr>
<h2 id='ForestControl-class'>Class &quot;ForestControl&quot; </h2><span id='topic+ForestControl-class'></span>

<h3>Description</h3>

<p>Objects of this class represent the hyper parameter setting for forest
growing.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by <code><a href="#topic+cforest_control">cforest_control</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>ntree</code>:</dt><dd><p>number of trees in the forest.</p>
</dd>
<dt><code>replace</code>:</dt><dd><p>sampling with or without replacement.</p>
</dd>
<dt><code>fraction</code>:</dt><dd><p>fraction of observations to sample without replacement.</p>
</dd>
<dt><code>trace</code>:</dt><dd><p>logical indicating if a progress bar shall be printed.</p>
</dd>
<dt><code>varctrl</code>:</dt><dd><p>Object of class <code>"VariableControl"</code></p>
</dd>
<dt><code>splitctrl</code>:</dt><dd><p>Object of class <code>"SplitControl"</code></p>
</dd>
<dt><code>gtctrl</code>:</dt><dd><p>Object of class <code>"GlobalTestControl"</code></p>
</dd>
<dt><code>tgctrl</code>:</dt><dd><p>Object of class <code>"TreeGrowControl"</code></p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"TreeControl"</code>, directly.
</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;ForestControl&quot; in the signature.
</p>

<hr>
<h2 id='Initialize+20Methods'> Methods for Function initialize in Package &lsquo;party&rsquo; </h2><span id='topic+initialize'></span><span id='topic+initialize-methods'></span><span id='topic+initialize+2CExpectCovarInfluence-method'></span><span id='topic+initialize+2CExpectCovar-method'></span><span id='topic+initialize+2CLinStatExpectCovar-method'></span><span id='topic+initialize+2CLinStatExpectCovarMPinv-method'></span><span id='topic+initialize+2Csvd_mem-method'></span><span id='topic+initialize+2CVariableFrame-method'></span>

<h3>Description</h3>

<p>Methods for function <code>initialize</code> in package <span class="pkg">party</span> &ndash; those are
internal functions not to be called by users.
</p>


<h3>Methods</h3>


<dl>
<dt>.Object = &quot;ExpectCovarInfluence&quot;</dt><dd><p><code>new("ExpectCovarInfluence")</code></p>
</dd>
<dt>.Object = &quot;ExpectCovar&quot;</dt><dd><p><code>new("ExpectCovar")</code></p>
</dd>
<dt>.Object = &quot;LinStatExpectCovar&quot;</dt><dd><p><code>new("LinStatExpectCovar")</code></p>
</dd>
<dt>.Object = &quot;LinStatExpectCovarMPinv&quot;</dt><dd><p><code>new("LinStatExpectCovarMPinv")</code></p>
</dd>
<dt>.Object = &quot;VariableFrame&quot;</dt><dd><p><code>new("VariableFrame")</code></p>
</dd>
</dl>

<hr>
<h2 id='initVariableFrame-methods'>Set-up VariableFrame objects</h2><span id='topic+initVariableFrame'></span><span id='topic+initVariableFrame-methods'></span><span id='topic+initVariableFrame+2Cdata.frame-method'></span><span id='topic+initVariableFrame+2Cmatrix-method'></span>

<h3>Description</h3>

<p>Set-up VariableFrame objects
</p>


<h3>Methods</h3>

<p>These methods are not to be called by the user.
</p>

<dl>
<dt><code>signature(obj = "data.frame")</code></dt><dd>
<p>converges a data frame to VariableFrame
</p>
</dd>
<dt><code>signature(obj = "matrix")</code></dt><dd>
<p>converges a matrix to VariableFrame
</p>
</dd>
</dl>

<hr>
<h2 id='LearningSample+20Class'>Class &quot;LearningSample&quot;</h2><span id='topic+LearningSample-class'></span>

<h3>Description</h3>

  
<p>Objects of this class represent data for fitting tree-based models.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("LearningSample", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>responses</code>:</dt><dd><p>Object of class <code>"VariableFrame"</code> with the
response variables. </p>
</dd>
<dt><code>inputs</code>:</dt><dd><p>Object of class <code>"VariableFrame"</code> with the
input variables.</p>
</dd>
<dt><code>weights</code>:</dt><dd><p>Object of class <code>"numeric"</code>, a vector of
case counts or weights. </p>
</dd>
<dt><code>nobs</code>:</dt><dd><p>Object of class <code>"integer"</code>, the number of
observations. </p>
</dd>
<dt><code>ninputs</code>:</dt><dd><p>Object of class <code>"integer"</code>, the number of
input variables.</p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods defined with class &quot;LearningSample&quot; in the signature.
</p>

<hr>
<h2 id='mob'>Model-based Recursive Partitioning</h2><span id='topic+mob'></span><span id='topic+mob-class'></span><span id='topic+coef.mob'></span><span id='topic+deviance.mob'></span><span id='topic+fitted.mob'></span><span id='topic+logLik.mob'></span><span id='topic+predict.mob'></span><span id='topic+print.mob'></span><span id='topic+residuals.mob'></span><span id='topic+sctest.mob'></span><span id='topic+summary.mob'></span><span id='topic+weights.mob'></span>

<h3>Description</h3>

<p>MOB is an algorithm for model-based recursive partitioning yielding
a tree with fitted models associated with each terminal node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mob(formula, weights, data = list(), na.action = na.omit, model = glinearModel,
  control = mob_control(), ...)

## S3 method for class 'mob'
predict(object, newdata = NULL, type = c("response", "node"), ...)
## S3 method for class 'mob'
summary(object, node = NULL, ...)
## S3 method for class 'mob'
coef(object, node = NULL, ...)
## S3 method for class 'mob'
sctest(x, node = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mob_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fit. This
should be of type <code>y ~ x1 + ... + xk | z1 + ... + zl</code> where
the variables before the <code>|</code> are passed to the <code>model</code> and
the variables after the <code>|</code> are used for partitioning.</p>
</td></tr>
<tr><td><code id="mob_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used in the fitting
process. Only non-negative integer valued weights are allowed (default = 1).</p>
</td></tr>
<tr><td><code id="mob_+3A_data">data</code></td>
<td>
<p>A data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="mob_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain <code>NA</code>s, defaulting to <code><a href="stats.html#topic+na.omit">na.omit</a></code>.</p>
</td></tr>
<tr><td><code id="mob_+3A_model">model</code></td>
<td>
<p>A model of class <code>"<a href="modeltools.html#topic+StatModel-class">StatModel</a>"</code>. See details
for requirements.</p>
</td></tr>
<tr><td><code id="mob_+3A_control">control</code></td>
<td>
<p>A list with control parameters as returned by
<code><a href="#topic+mob_control">mob_control</a></code>.</p>
</td></tr>
<tr><td><code id="mob_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the <code>fit</code> call for
the <code>model</code>.</p>
</td></tr>
<tr><td><code id="mob_+3A_object">object</code>, <code id="mob_+3A_x">x</code></td>
<td>
<p>A fitted <code>mob</code> object.</p>
</td></tr>
<tr><td><code id="mob_+3A_newdata">newdata</code></td>
<td>
<p>A data frame with new inputs, by default the learning data
is used.</p>
</td></tr>
<tr><td><code id="mob_+3A_type">type</code></td>
<td>
<p>A character string specifying whether the response should be
predicted (inherited from the <code>predict</code> method for the <code>model</code>)
or the ID of the associated terminal node.</p>
</td></tr>
<tr><td><code id="mob_+3A_node">node</code></td>
<td>
<p>A vector of node IDs for which the corresponding method should
be applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model-based partitioning fits a model tree using the following algorithm:
</p>

<ol>
<li> <p><code>fit</code> a <code>model</code> (default: a generalized linear model
<code>"<a href="modeltools.html#topic+StatModel-class">StatModel</a>"</code> with formula <code>y ~ x1 + ... + xk</code>
for the observations in the current node.
</p>
</li>
<li><p> Assess the stability of the model parameters with respect to each
of the partitioning variables <code>z1</code>, ..., <code>zl</code>. If
there is some overall instability, choose the variable <code>z</code>
associated with the smallest <code class="reqn">p</code> value for partitioning, otherwise
stop. For performing the parameter instability fluctuation test,
a <code><a href="sandwich.html#topic+estfun">estfun</a></code> method and a <code><a href="#topic+weights">weights</a></code> method is
needed.
</p>
</li>
<li><p> Search for the locally optimal split in <code>z</code> by minimizing the
objective function of the <code>model</code>. Typically, this will be
something like <code><a href="stats.html#topic+deviance">deviance</a></code> or the negative <code><a href="stats.html#topic+logLik">logLik</a></code>
and can be specified in <code><a href="#topic+mob_control">mob_control</a></code>.
</p>
</li>
<li><p> Re-fit the <code>model</code> in both children, using <code><a href="#topic+reweight">reweight</a></code>
and repeat from step 2.
</p>
</li></ol>

<p>More details on the conceptual design of the algorithm can be found in 
Zeileis, Hothorn, Hornik (2008) and some illustrations are provided in
<code>vignette("MOB")</code>.  
</p>
<p>For the fitted MOB tree, several standard methods are inherited if they are
available for fitted <code>model</code>s, such as <code>print</code>, <code>predict</code>,
<code>residuals</code>, <code>logLik</code>, <code>deviance</code>, <code>weights</code>, <code>coef</code> and
<code>summary</code>. By default, the latter four return the result (deviance, weights,
coefficients, summary) for all terminal nodes, but take a <code>node</code> argument
that can be set to any node ID. The <code>sctest</code> method extracts the results
of the parameter stability tests (aka structural change tests) for any given
node, by default for all nodes. Some examples are given below.
</p>


<h3>Value</h3>

<p>An object of class <code>mob</code> inheriting from <code><a href="#topic+BinaryTree-class">BinaryTree-class</a></code>.
Every node of the tree is additionally associated with a fitted model.
</p>


<h3>References</h3>

 
<p>Achim Zeileis, Torsten Hothorn, and Kurt Hornik (2008). Model-Based
Recursive Partitioning. <em>Journal of Computational and Graphical Statistics</em>, 
<b>17</b>(2), 492&ndash;514.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mob">plot.mob</a></code>, <code><a href="#topic+mob_control">mob_control</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(290875)

if(require("mlbench")) {

## recursive partitioning of a linear regression model
## load data
data("BostonHousing", package = "mlbench")
## and transform variables appropriately (for a linear regression)
BostonHousing$lstat &lt;- log(BostonHousing$lstat)
BostonHousing$rm &lt;- BostonHousing$rm^2
## as well as partitioning variables (for fluctuation testing)
BostonHousing$chas &lt;- factor(BostonHousing$chas, levels = 0:1, 
                             labels = c("no", "yes"))
BostonHousing$rad &lt;- factor(BostonHousing$rad, ordered = TRUE)

## partition the linear regression model medv ~ lstat + rm
## with respect to all remaining variables:
fmBH &lt;- mob(medv ~ lstat + rm | zn + indus + chas + nox + age + 
                                dis + rad + tax + crim + b + ptratio,
  control = mob_control(minsplit = 40), data = BostonHousing, 
  model = linearModel)

## print the resulting tree
fmBH
## or better visualize it
plot(fmBH)

## extract coefficients in all terminal nodes
coef(fmBH)
## look at full summary, e.g., for node 7
summary(fmBH, node = 7)
## results of parameter stability tests for that node
sctest(fmBH, node = 7)
## -&gt; no further significant instabilities (at 5% level)

## compute mean squared error (on training data)
mean((BostonHousing$medv - fitted(fmBH))^2)
mean(residuals(fmBH)^2)
deviance(fmBH)/sum(weights(fmBH))

## evaluate logLik and AIC
logLik(fmBH)
AIC(fmBH)
## (Note that this penalizes estimation of error variances, which
## were treated as nuisance parameters in the fitting process.)


## recursive partitioning of a logistic regression model
## load data
data("PimaIndiansDiabetes", package = "mlbench")
## partition logistic regression diabetes ~ glucose 
## wth respect to all remaining variables
fmPID &lt;- mob(diabetes ~ glucose | pregnant + pressure + triceps + 
                                  insulin + mass + pedigree + age,
  data = PimaIndiansDiabetes, model = glinearModel, 
  family = binomial())

## fitted model
coef(fmPID)
plot(fmPID)
plot(fmPID, tp_args = list(cdplot = TRUE))
}
</code></pre>

<hr>
<h2 id='mob_control'>Control Parameters for Model-based Partitioning</h2><span id='topic+mob_control'></span>

<h3>Description</h3>

<p>Various parameters that control aspects the fitting algorithm
for recursively partitioned <code><a href="#topic+mob">mob</a></code> models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mob_control(alpha = 0.05, bonferroni = TRUE, minsplit = 20, trim = 0.1,
  objfun = deviance, breakties = FALSE, parm = NULL, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mob_control_+3A_alpha">alpha</code></td>
<td>
<p>numeric significance level. A node is splitted when
the (possibly Bonferroni-corrected) <code class="reqn">p</code> value for any parameter
stability test in that node falls below <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="mob_control_+3A_bonferroni">bonferroni</code></td>
<td>
<p>logical. Should <code class="reqn">p</code> values be Bonferroni corrected?</p>
</td></tr>
<tr><td><code id="mob_control_+3A_minsplit">minsplit</code></td>
<td>
<p>integer. The minimum number of observations (sum of the
weights) in a node.</p>
</td></tr>
<tr><td><code id="mob_control_+3A_trim">trim</code></td>
<td>
<p>numeric. This specifies the trimming in the parameter instability
test for the numerical variables. If smaller than 1, it is interpreted
as the fraction relative to the current node size.</p>
</td></tr>
<tr><td><code id="mob_control_+3A_objfun">objfun</code></td>
<td>
<p>function. A function for extracting the minimized value of
the objective function from a fitted model in a node.</p>
</td></tr>
<tr><td><code id="mob_control_+3A_breakties">breakties</code></td>
<td>
<p>logical. Should ties in numeric variables be broken
randomly for computing the associated parameter instability test?</p>
</td></tr>
<tr><td><code id="mob_control_+3A_parm">parm</code></td>
<td>
<p>numeric or character. Number or name of model parameters
included in the parameter instability tests (by default all parameters
are included).</p>
</td></tr>
<tr><td><code id="mob_control_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should information about the fitting process
of <code><a href="#topic+mob">mob</a></code> (such as test statistics, <code class="reqn">p</code> values, selected
splitting variables and split points) be printed to the screen?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+mob">mob</a></code> for more details and references.
</p>


<h3>Value</h3>

<p>A list of class <code>mob_control</code> containing the control parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mob">mob</a></code></p>

<hr>
<h2 id='Panel+20Generating+20Functions'> Panel-Generators for Visualization of Party Trees </h2><span id='topic+node_inner'></span><span id='topic+node_terminal'></span><span id='topic+edge_simple'></span><span id='topic+node_surv'></span><span id='topic+node_barplot'></span><span id='topic+node_boxplot'></span><span id='topic+node_hist'></span><span id='topic+node_density'></span><span id='topic+node_scatterplot'></span><span id='topic+node_bivplot'></span>

<h3>Description</h3>

<p>The plot method for <code>BinaryTree</code> and <code>mob</code> objects are rather
flexible and can be extended by panel functions. Some pre-defined
panel-generating functions of class <code>grapcon_generator</code>
for the most important cases are documented here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>node_inner(ctreeobj, digits = 3, abbreviate = FALSE, 
  fill = "white", pval = TRUE, id = TRUE)
node_terminal(ctreeobj, digits = 3, abbreviate = FALSE, 
  fill = c("lightgray", "white"), id = TRUE)
edge_simple(treeobj, digits = 3, abbreviate = FALSE)
node_surv(ctreeobj, ylines = 2, id = TRUE, ...)
node_barplot(ctreeobj, col = "black", fill = NULL, beside = NULL,
  ymax = NULL, ylines = NULL, widths = 1, gap = NULL, 
  reverse = NULL, id = TRUE)
node_boxplot(ctreeobj, col = "black", fill = "lightgray", 
  width = 0.5,  yscale = NULL, ylines = 3, cex = 0.5, id = TRUE)
node_hist(ctreeobj, col = "black", fill = "lightgray", 
  freq = FALSE, horizontal = TRUE, xscale = NULL, ymax = NULL, 
  ylines = 3, id = TRUE, ...)
node_density(ctreeobj, col = "black", rug = TRUE, 
  horizontal = TRUE, xscale = NULL, yscale = NULL, ylines = 3, 
  id = TRUE)
node_scatterplot(mobobj, which = NULL, col = "black", 
  linecol = "red", cex = 0.5, pch = NULL, jitter = FALSE, 
  xscale = NULL, yscale = NULL, ylines = 1.5, id = TRUE, 
  labels = FALSE)
node_bivplot(mobobj, which = NULL, id = TRUE, pop = TRUE,
  pointcol = "black", pointcex = 0.5,
  boxcol = "black", boxwidth = 0.5, boxfill = "lightgray",
  fitmean = TRUE, linecol = "red",
  cdplot = FALSE, fivenum = TRUE, breaks = NULL,
  ylines = NULL, xlab = FALSE, ylab = FALSE, margins = rep(1.5, 4), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_ctreeobj">ctreeobj</code></td>
<td>
<p> an object of class <code>BinaryTree</code>.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_treeobj">treeobj</code></td>
<td>
<p> an object of class <code>BinaryTree</code> or <code>mob</code>.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_mobobj">mobobj</code></td>
<td>
<p> an object of class <code>mob</code>.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_digits">digits</code></td>
<td>
<p> integer, used for formating numbers. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_abbreviate">abbreviate</code></td>
<td>
<p> logical indicating whether strings should be 
abbreviated. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_col">col</code>, <code id="Panel+2B20Generating+2B20Functions_+3A_pointcol">pointcol</code></td>
<td>
<p> a color for points and lines. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_fill">fill</code></td>
<td>
<p> a color to filling rectangles. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_pval">pval</code></td>
<td>
<p> logical. Should p values be plotted?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_id">id</code></td>
<td>
<p> logical. Should node IDs be plotted?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_ylines">ylines</code></td>
<td>
<p> number of lines for spaces in y-direction. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_widths">widths</code></td>
<td>
<p> widths in barplots. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_width">width</code>, <code id="Panel+2B20Generating+2B20Functions_+3A_boxwidth">boxwidth</code></td>
<td>
<p> width in boxplots. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_gap">gap</code></td>
<td>
<p> gap between bars in a barplot (<code>node_barplot</code>). </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_yscale">yscale</code></td>
<td>
<p> limits in y-direction</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_xscale">xscale</code></td>
<td>
<p> limits in x-direction</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_ymax">ymax</code></td>
<td>
<p> upper limit in y-direction</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_beside">beside</code></td>
<td>
<p> logical indicating if barplots should be side by side or stacked. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_reverse">reverse</code></td>
<td>
<p>logical indicating whether the order of levels should be reversed
for barplots.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_horizontal">horizontal</code></td>
<td>
<p> logical indicating if the plots should be horizontal. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_freq">freq</code></td>
<td>
<p>logical; if <code>TRUE</code>, the histogram graphic is a representation
of frequencies. If <code>FALSE</code>, probabilities are plotted.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_rug">rug</code></td>
<td>
<p>logical indicating if a rug representation should be added. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_which">which</code></td>
<td>
<p> numeric or character vector indicating which of the regressor
variables should be plotted (default = all).</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_linecol">linecol</code></td>
<td>
<p> color for fitted model lines.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_cex">cex</code>, <code id="Panel+2B20Generating+2B20Functions_+3A_pointcex">pointcex</code></td>
<td>
<p>character extension of points in scatter plots.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_pch">pch</code></td>
<td>
<p>plotting character of points in scatter plots.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_jitter">jitter</code></td>
<td>
<p>logical. Should the points be jittered in y-direction?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_labels">labels</code></td>
<td>
<p>logical. Should axis labels be plotted?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_pop">pop</code></td>
<td>
<p>logical. Should the panel viewports be popped?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_boxcol">boxcol</code></td>
<td>
<p>color for box plot borders.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_boxfill">boxfill</code></td>
<td>
<p>fill color for box plots.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_fitmean">fitmean</code></td>
<td>
<p>logical. Should lines for the predicted means from the model
be added?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_cdplot">cdplot</code></td>
<td>
<p>logical. Should CD plots (or spinograms) be used for visualizing
the dependence of a categorical on a numeric variable?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_fivenum">fivenum</code></td>
<td>
<p>logical. When using spinograms, should the five point summary
of the explanatory variable be used for determining the breaks?</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_breaks">breaks</code></td>
<td>
<p>a (list of) numeric vector(s) of breaks for the spinograms. If set to <code>NULL</code>
(the default), the <code>breaks</code> are chosen according to the <code>fivenum</code>
argument.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_xlab">xlab</code>, <code id="Panel+2B20Generating+2B20Functions_+3A_ylab">ylab</code></td>
<td>
<p> character with x- and y-axis labels. Can also be logical: if <code>FALSE</code>
axis labels are surpressed, if <code>TRUE</code> they are taken from the underlying data.
Can be a vector of labels for <code>xlab</code>. </p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_margins">margins</code></td>
<td>
<p>margins of the viewports.</p>
</td></tr>
<tr><td><code id="Panel+2B20Generating+2B20Functions_+3A_...">...</code></td>
<td>
<p> additional arguments passed to callies.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> methods for <code>BinaryTree</code> and <code>mob</code> objects provide an
extensible framework for the visualization of binary regression trees. The
user is allowed to specify panel functions for plotting terminal and inner
nodes as well as the corresponding edges. The panel functions to be used
should depend only on the node being visualzied, however, for setting up
an appropriate panel function, information from the whole tree is typically
required. Hence, <span class="pkg">party</span> adopts the framework of <code>grapcon_generator</code>
(graphical appearance control) from the <span class="pkg">vcd</span> package (Meyer, Zeileis and
Hornik, 2005) and provides several panel-generating functions. For convenience,
the panel-generating functions <code>node_inner</code> and <code>edge_simple</code> 
return panel functions to draw inner nodes and left and right edges. 
For drawing terminal nodes, the functions returned by the other panel 
functions can be used. The panel generating function <code>node_terminal</code> 
is a terse text-based representation of terminal nodes.
</p>
<p>Graphical representations of terminal nodes are available and depend on
the kind of model and the measurement scale of the variables modelled.
</p>
<p>For univariate regressions (typically fitted by <code>ctree</code>),
<code>node_surv</code> returns a functions that plots Kaplan-Meier curves in each 
terminal node; <code>node_barplot</code>, <code>node_boxplot</code>, <code>node_hist</code> and
<code>node_density</code> can be used to plot bar plots, box plots, histograms and 
estimated densities into the terminal nodes.
</p>
<p>For multivariate regressions (typically fitted by <code>mob</code>),
<code>node_bivplot</code> returns a panel function that creates bivariate plots
of the response against all regressors in the model. Depending on the scale
of the variables involved, scatter plots, box plots, spinograms (or CD plots)
and spine plots are created. For the latter two <code><a href="vcd.html#topic+spine">spine</a></code> and
<code><a href="vcd.html#topic+cd_plot">cd_plot</a></code> from the <span class="pkg">vcd</span> package are re-used.
</p>


<h3>References</h3>

<p>David Meyer, Achim Zeileis, and Kurt Hornik (2006).
The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd.
<em>Journal of Statistical Software</em>, <b>17</b>(3).
<a href="https://doi.org/10.18637/jss.v017.i03">doi:10.18637/jss.v017.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(290875)

  airq &lt;- subset(airquality, !is.na(Ozone))
  airct &lt;- ctree(Ozone ~ ., data = airq)

  ## default: boxplots
  plot(airct)
  
  ## change colors
  plot(airct, tp_args = list(col = "blue", fill = hsv(2/3, 0.5, 1)))
  ## equivalent to
  plot(airct, terminal_panel = node_boxplot(airct, col = "blue", 
                                            fill = hsv(2/3, 0.5, 1)))

  ### very simple; the mean is given in each terminal node
  plot(airct, type = "simple")

  ### density estimates
  plot(airct, terminal_panel = node_density)
    
  ### histograms 
  plot(airct, terminal_panel = node_hist(airct, ymax = 0.06, 
                                         xscale = c(0, 250)))
</code></pre>

<hr>
<h2 id='party_intern'>
Call internal functions.
</h2><span id='topic+party_intern'></span>

<h3>Description</h3>

<p>Call one of the internal party functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>party_intern(..., fun = c("R_TreeGrow", "R_get_nodeID", 
             "R_getpredictions", "initVariableFrame", 
             "ctreedpp", "newinputs", "R_predict"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="party_intern_+3A_...">...</code></td>
<td>
<p>Arguments to <code>fun</code>.</p>
</td></tr>
<tr><td><code id="party_intern_+3A_fun">fun</code></td>
<td>
<p>The name on an internal party function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function must not be called under any circumstances.
</p>

<hr>
<h2 id='Plot+20BinaryTree'> Visualization of Binary Regression Trees </h2><span id='topic+plot.BinaryTree'></span>

<h3>Description</h3>

<p><code>plot</code> method for <code>BinaryTree</code> objects with
extended facilities for plugging in panel functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BinaryTree'
plot(x, main = NULL, type = c("extended", "simple"),
     terminal_panel = NULL, tp_args = list(),
     inner_panel = node_inner, ip_args = list(),
     edge_panel = edge_simple, ep_args = list(),
     drop_terminal = (type[1] == "extended"), 
     tnex = (type[1] == "extended") + 1, newpage = TRUE,  
     pop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Plot+2B20BinaryTree_+3A_x">x</code></td>
<td>
<p> an object of class <code>BinaryTree</code>.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_main">main</code></td>
<td>
<p> an optional title for the plot.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_type">type</code></td>
<td>
<p> a character specifying the complexity of the plot:
<code>extended</code> tries to visualize the distribution of the
response variable in each terminal node whereas <code>simple</code> 
only gives some summary information.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_terminal_panel">terminal_panel</code></td>
<td>
<p> an optional panel function of the form 
<code>function(node)</code> plotting the terminal nodes.
Alternatively, a panel generating function of class
<code>"grapcon_generator"</code> that is called with arguments
<code>x</code> and <code>tp_args</code> to set up a panel function.
By default, an appropriate panel function is chosen 
depending on the scale of the dependent variable.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_tp_args">tp_args</code></td>
<td>
<p> a list of arguments passed to <code>terminal_panel</code> if this
is a <code>"grapcon_generator"</code> object.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_inner_panel">inner_panel</code></td>
<td>
<p> an optional panel function of the form 
<code>function(node)</code> plotting the inner nodes.
Alternatively, a panel generating function of class
<code>"grapcon_generator"</code> that is called with arguments
<code>x</code> and <code>ip_args</code> to set up a panel function.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_ip_args">ip_args</code></td>
<td>
<p> a list of arguments passed to <code>inner_panel</code> if this
is a <code>"grapcon_generator"</code> object.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_edge_panel">edge_panel</code></td>
<td>
<p> an optional panel function of the form 
<code>function(split, ordered = FALSE, left = TRUE)</code>
plotting the edges.
Alternatively, a panel generating function of class
<code>"grapcon_generator"</code> that is called with arguments
<code>x</code> and <code>ip_args</code> to set up a panel function.</p>
</td></tr>		       
<tr><td><code id="Plot+2B20BinaryTree_+3A_ep_args">ep_args</code></td>
<td>
<p> a list of arguments passed to <code>edge_panel</code> if this
is a <code>"grapcon_generator"</code> object.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_drop_terminal">drop_terminal</code></td>
<td>
<p> a logical indicating whether all terminal nodes
should be plotted at the bottom.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_tnex">tnex</code></td>
<td>
<p>a numeric value giving the terminal node extension in relation
to the inner nodes.</p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_newpage">newpage</code></td>
<td>
<p> a logical indicating whether <code>grid.newpage()</code> should be called. </p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_pop">pop</code></td>
<td>
<p> a logical whether the viewport tree should be popped before
return. </p>
</td></tr>
<tr><td><code id="Plot+2B20BinaryTree_+3A_...">...</code></td>
<td>
<p> additional arguments passed to callies.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <code>plot</code> method for <code>BinaryTree</code> objects provides an
extensible framework for the visualization of binary regression trees. The
user is allowed to specify panel functions for plotting terminal and inner
nodes as well as the corresponding edges. Panel functions for plotting
inner nodes, edges and terminal nodes are available for the most important
cases and can serve as the basis for user-supplied extensions, see
<code><a href="#topic+node_inner">node_inner</a></code> and <code>vignette("party")</code>.
</p>
<p>More details on the ideas and concepts of panel-generating functions and
<code>"grapcon_generator"</code> objects in general can be found in Meyer, Zeileis
and Hornik (2005).
</p>


<h3>References</h3>

<p>David Meyer, Achim Zeileis, and Kurt Hornik (2006).
The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd.
<em>Journal of Statistical Software</em>, <b>17</b>(3).
<a href="https://doi.org/10.18637/jss.v017.i03">doi:10.18637/jss.v017.i03</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+node_inner">node_inner</a></code>, <code><a href="#topic+node_terminal">node_terminal</a></code>, <code><a href="#topic+edge_simple">edge_simple</a></code>, 
<code><a href="#topic+node_surv">node_surv</a></code>, <code><a href="#topic+node_barplot">node_barplot</a></code>, <code><a href="#topic+node_boxplot">node_boxplot</a></code>, 
<code><a href="#topic+node_hist">node_hist</a></code>, <code><a href="#topic+node_density">node_density</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(290875)

  airq &lt;- subset(airquality, !is.na(Ozone))
  airct &lt;- ctree(Ozone ~ ., data = airq)

  ### regression: boxplots in each node
  plot(airct, terminal_panel = node_boxplot, drop_terminal = TRUE)

  if(require("TH.data")) {
  ## classification: barplots in each node
  data("GlaucomaM", package = "TH.data")
  glauct &lt;- ctree(Class ~ ., data = GlaucomaM)
  plot(glauct)
  plot(glauct, inner_panel = node_barplot,
    edge_panel = function(ctreeobj, ...) { function(...) invisible() },
    tnex = 1)

  ## survival: Kaplan-Meier curves in each node
  data("GBSG2", package = "TH.data")
  library("survival")
  gbsg2ct &lt;- ctree(Surv(time, cens) ~ ., data = GBSG2)
  plot(gbsg2ct)
  plot(gbsg2ct, type = "simple")  
  }

</code></pre>

<hr>
<h2 id='plot.mob'> Visualization of MOB Trees </h2><span id='topic+plot.mob'></span>

<h3>Description</h3>

<p><code>plot</code> method for <code>mob</code> objects with
extended facilities for plugging in panel functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mob'
plot(x, terminal_panel = node_bivplot, tnex = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mob_+3A_x">x</code></td>
<td>
<p>an object of class <code>mob</code>.</p>
</td></tr>
<tr><td><code id="plot.mob_+3A_terminal_panel">terminal_panel</code></td>
<td>
<p>a panel function or panel-generating function of
class <code>"grapcon_generator"</code>. See <code><a href="#topic+plot.BinaryTree">plot.BinaryTree</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="plot.mob_+3A_tnex">tnex</code></td>
<td>
<p>a numeric value giving the terminal node extension in relation
to the inner nodes.</p>
</td></tr>
<tr><td><code id="plot.mob_+3A_...">...</code></td>
<td>
<p> further arguments passed to <code><a href="#topic+plot.BinaryTree">plot.BinaryTree</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <code>plot</code> method for <code>mob</code> objects simply calls the
<code><a href="#topic+plot.BinaryTree">plot.BinaryTree</a></code> method, setting a different <code>terminal_panel</code>
function by default (<code><a href="#topic+node_bivplot">node_bivplot</a></code>) and <code>tnex</code> value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+node_bivplot">node_bivplot</a></code>, <code><a href="#topic+node_scatterplot">node_scatterplot</a></code>,
<code><a href="#topic+plot.BinaryTree">plot.BinaryTree</a></code>, <code><a href="#topic+mob">mob</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(290875)

if(require("mlbench")) {

## recursive partitioning of a linear regression model
## load data
data("BostonHousing", package = "mlbench")
## and transform variables appropriately (for a linear regression)
BostonHousing$lstat &lt;- log(BostonHousing$lstat)
BostonHousing$rm &lt;- BostonHousing$rm^2
## as well as partitioning variables (for fluctuation testing)
BostonHousing$chas &lt;- factor(BostonHousing$chas, levels = 0:1, 
                             labels = c("no", "yes"))
BostonHousing$rad &lt;- factor(BostonHousing$rad, ordered = TRUE)

## partition the linear regression model medv ~ lstat + rm
## with respect to all remaining variables:
fm &lt;- mob(medv ~ lstat + rm | zn + indus + chas + nox + age + dis + 
                              rad + tax + crim + b + ptratio,
  control = mob_control(minsplit = 40), data = BostonHousing, 
  model = linearModel)

## visualize medv ~ lstat and medv ~ rm
plot(fm)

## visualize only one of the two regressors
plot(fm, tp_args = list(which = "lstat"), tnex = 2)
plot(fm, tp_args = list(which = 2), tnex = 2)

## omit fitted mean lines
plot(fm, tp_args = list(fitmean = FALSE))

## mixed numerical and categorical regressors 
fm2 &lt;- mob(medv ~ lstat + rm + chas | zn + indus + nox + age + 
                                      dis + rad,
  control = mob_control(minsplit = 100), data = BostonHousing, 
  model = linearModel)
plot(fm2)

## recursive partitioning of a logistic regression model
data("PimaIndiansDiabetes", package = "mlbench")
fmPID &lt;- mob(diabetes ~ glucose | pregnant + pressure + triceps + 
                                  insulin + mass + pedigree + age,
  data = PimaIndiansDiabetes, model = glinearModel, 
  family = binomial())
## default plot: spinograms with breaks from five point summary
plot(fmPID)
## use the breaks from hist() instead
plot(fmPID, tp_args = list(fivenum = FALSE))
## user-defined breaks
plot(fmPID, tp_args = list(breaks = 0:4 * 50))
## CD plots instead of spinograms
plot(fmPID, tp_args = list(cdplot = TRUE))
## different smoothing bandwidth
plot(fmPID, tp_args = list(cdplot = TRUE, bw = 15))

}
</code></pre>

<hr>
<h2 id='prettytree'>
Print a tree.
</h2><span id='topic+prettytree'></span>

<h3>Description</h3>

<p>Produces textual output representing a tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prettytree(x, inames = NULL, ilevels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prettytree_+3A_x">x</code></td>
<td>

<p>a recursive list representing a tree.
</p>
</td></tr>
<tr><td><code id="prettytree_+3A_inames">inames</code></td>
<td>

<p>optional variable names.
</p>
</td></tr>
<tr><td><code id="prettytree_+3A_ilevels">ilevels</code></td>
<td>

<p>an optional list of levels for factors.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is normally not called by users 
but needed in some reverse dependencies of party.
</p>

<hr>
<h2 id='RandomForest-class'>Class &quot;RandomForest&quot;</h2><span id='topic+RandomForest-class'></span><span id='topic+treeresponse+2CRandomForest-method'></span><span id='topic+weights+2CRandomForest-method'></span><span id='topic+where+2CRandomForest-method'></span><span id='topic+show+2CRandomForest-method'></span>

<h3>Description</h3>

<p>A class for representing random forest ensembles. </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("RandomForest", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>ensemble</code>:</dt><dd><p>Object of class <code>"list"</code>, each element
being an object of class <code>"<a href="#topic+BinaryTree-class">BinaryTree</a>"</code>.</p>
</dd>
<dt><code>data</code>:</dt><dd><p> an object of class <code>"<a href="modeltools.html#topic+ModelEnv-class">ModelEnv</a>"</code>.</p>
</dd>
<dt><code>initweights</code>:</dt><dd><p> a vector of initial weights.</p>
</dd>
<dt><code>weights</code>:</dt><dd><p> a list of weights defining the sub-samples.</p>
</dd>
<dt><code>where</code>:</dt><dd><p> a matrix of integers vectors of length n (number of
observations in the learning sample) giving the
number of the terminal node the corresponding
observations is element of (in each tree).</p>
</dd>
<dt><code>data</code>:</dt><dd><p> an object of class <code>"<a href="modeltools.html#topic+ModelEnv-class">ModelEnv</a>"</code>.</p>
</dd>
<dt><code>responses</code>:</dt><dd><p> an object of class <code>"VariableFrame"</code>
storing the values of the response variable(s). </p>
</dd>
<dt><code>cond_distr_response</code>:</dt><dd><p> a function computing the conditional
distribution of the response. </p>
</dd>
<dt><code>predict_response</code>:</dt><dd><p> a function for computing predictions. </p>
</dd>
<dt><code>prediction_weights</code>:</dt><dd><p> a function for extracting weights from
terminal nodes. </p>
</dd>
<dt><code>get_where</code>:</dt><dd><p> a function for determining the number
of terminal nodes observations fall into. </p>
</dd>
<dt><code>update</code>:</dt><dd><p> a function for updating weights.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>treeresponse</dt><dd><p><code>signature(object = "RandomForest")</code>: ... </p>
</dd>
<dt>weights</dt><dd><p><code>signature(object = "RandomForest")</code>: ... </p>
</dd>
<dt>where</dt><dd><p><code>signature(object = "RandomForest")</code>: ... </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
    set.seed(290875)

    ### honest (i.e., out-of-bag) cross-classification of 
    ### true vs. predicted classes
    data("mammoexp", package = "TH.data")
    table(mammoexp$ME, predict(cforest(ME ~ ., data = mammoexp, 
                               control = cforest_unbiased(ntree = 50)), 
                               OOB = TRUE))
</code></pre>

<hr>
<h2 id='readingSkills'> Reading Skills </h2><span id='topic+readingSkills'></span>

<h3>Description</h3>

<p>A toy data set illustrating the spurious correlation
between reading skills and shoe size in school-children.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("readingSkills")</code></pre>


<h3>Format</h3>

<p>A data frame with 200 observations on the following 4 variables.
</p>

<dl>
<dt><code>nativeSpeaker</code></dt><dd><p>a factor with levels <code>no</code> and <code>yes</code>,
where <code>yes</code> indicates that the child
is a native speaker of the language of the reading test.</p>
</dd>
<dt><code>age</code></dt><dd><p>age of the child in years.</p>
</dd>
<dt><code>shoeSize</code></dt><dd><p>shoe size of the child in cm.</p>
</dd>
<dt><code>score</code></dt><dd><p>raw score on the reading test.</p>
</dd>
</dl>



<h3>Details</h3>

<p>In this artificial data set, that was generated by means of a linear model, 
<code>age</code> and <code>nativeSpeaker</code> are actual predictors of the 
<code>score</code>, while the spurious correlation between <code>score</code> and 
<code>shoeSize</code> is merely caused by the fact that both depend on <code>age</code>.  
</p>
<p>The true predictors can be identified, e.g., by means of partial correlations, 
standardized beta coefficients in linear models or the conditional random 
forest variable importance, but not by means of the standard random 
forest variable importance (see example).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
   set.seed(290875)
   readingSkills.cf &lt;- cforest(score ~ ., data = readingSkills,
       control = cforest_unbiased(mtry = 2, ntree = 50))

   # standard importance
   varimp(readingSkills.cf)
   # the same modulo random variation
   varimp(readingSkills.cf, pre1.0_0 = TRUE)

   # conditional importance, may take a while...
   varimp(readingSkills.cf, conditional = TRUE) 

</code></pre>

<hr>
<h2 id='reweight'>Re-fitting Models with New Weights</h2><span id='topic+reweight'></span><span id='topic+reweight.linearModel'></span><span id='topic+reweight.glinearModel'></span>

<h3>Description</h3>

<p>Generic function for re-fitting a model object using the same
observations but different weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reweight(object, weights, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reweight_+3A_object">object</code></td>
<td>
<p>a fitted model object.</p>
</td></tr>
<tr><td><code id="reweight_+3A_weights">weights</code></td>
<td>
<p>a vector of weights.</p>
</td></tr>
<tr><td><code id="reweight_+3A_...">...</code></td>
<td>
<p>arguments passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method is not unsimilar in spirit to <code><a href="stats.html#topic+update">update</a></code>, but
much more narrowly focused. It should return an updated fitted model 
derived from re-fitting the model on the same observations but using
different weights.
</p>


<h3>Value</h3>

<p>The re-weighted fitted model object.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+update">update</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## fit cars regression
  mf &lt;- dpp(linearModel, dist ~ speed, data = cars)
  fm &lt;- fit(linearModel, mf)
  fm
  
  ## re-fit, excluding the last 4 observations
  ww &lt;- c(rep(1, 46), rep(0, 4))
  reweight(fm, ww)
</code></pre>

<hr>
<h2 id='SplittingNode+20Class'>Class &quot;SplittingNode&quot;</h2><span id='topic+SplittingNode-class'></span><span id='topic+TerminalNode-class'></span><span id='topic+TerminalModelNode-class'></span>

<h3>Description</h3>

  
<p>A list representing the inner node of a binary tree.
</p>


<h3>Extends</h3>

<p>Class <code>"list"</code>, from data part.
Class <code>"vector"</code>, by class <code>"list"</code>. See
<code><a href="#topic+BinaryTree-class">BinaryTree-class</a></code> for more details.
</p>

<hr>
<h2 id='Transformations'> Function for Data Transformations </h2><span id='topic+ptrafo'></span><span id='topic+ff_trafo'></span>

<h3>Description</h3>

<p>Transformations of Response or Input Variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ptrafo(data, numeric_trafo = id_trafo, factor_trafo = ff_trafo, 
    ordered_trafo = of_trafo, surv_trafo = logrank_trafo, 
    var_trafo = NULL)
ff_trafo(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Transformations_+3A_data">data</code></td>
<td>
<p>an object of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="Transformations_+3A_numeric_trafo">numeric_trafo</code></td>
<td>
<p>a function to by applied to <code>numeric</code> 
elements of <code>data</code> returning a matrix with <code>nrow(data)</code>
rows and an arbitrary number of columns.</p>
</td></tr>
<tr><td><code id="Transformations_+3A_ordered_trafo">ordered_trafo</code></td>
<td>
<p>a function to by applied to <code>ordered</code>
elements of <code>data</code> returning a matrix with <code>nrow(data)</code>
rows and an arbitrary number of columns (usually some scores).</p>
</td></tr>
<tr><td><code id="Transformations_+3A_factor_trafo">factor_trafo</code></td>
<td>
<p>a function to by applied to <code>factor</code>
elements of <code>data</code> returning a matrix with <code>nrow(data)</code>
rows and an arbitrary number of columns (usually a dummy or contrast 
matrix).</p>
</td></tr>
<tr><td><code id="Transformations_+3A_surv_trafo">surv_trafo</code></td>
<td>
<p>a function to by applied to 
elements of class <code>Surv</code> of <code>data</code> returning a 
matrix with <code>nrow(data)</code> rows and an arbitrary number of columns.</p>
</td></tr>
<tr><td><code id="Transformations_+3A_var_trafo">var_trafo</code></td>
<td>
<p>an optional named list of functions to be applied to the
corresponding variables in <code>data</code>.</p>
</td></tr>
<tr><td><code id="Transformations_+3A_x">x</code></td>
<td>
<p> a factor</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>trafo</code> applies its arguments to the elements of <code>data</code>
according to the classes of the elements. See <code><a href="coin.html#topic+Transformations">Transformations</a></code>
for more documentation and examples.
</p>
<p>In the presence of missing values, one needs to make sure that all
user-supplied functions deal with that. 
</p>


<h3>Value</h3>

<p>A named matrix with <code>nrow(data)</code> rows and 
arbitrary number of columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ### rank a variable
  ptrafo(data.frame(y = 1:20), 
         numeric_trafo = function(x) rank(x, na.last = "keep"))

  ### dummy coding of a factor
  ptrafo(data.frame(y = gl(3, 9)))

</code></pre>

<hr>
<h2 id='TreeControl+20Class'>Class &quot;TreeControl&quot;</h2><span id='topic+TreeControl-class'></span><span id='topic+TreeControl'></span>

<h3>Description</h3>

 
<p>Objects of this class represent the hyper parameter setting for tree
growing.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by <code><a href="#topic+ctree_control">ctree_control</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>varctrl</code>:</dt><dd><p>Object of class <code>"VariableControl"</code>.</p>
</dd>
<dt><code>splitctrl</code>:</dt><dd><p>Object of class <code>"SplitControl"</code>.</p>
</dd>
<dt><code>gtctrl</code>:</dt><dd><p>Object of class <code>"GlobalTestControl"</code>.</p>
</dd>
<dt><code>tgctrl</code>:</dt><dd><p>Object of class <code>"TreeGrowControl"</code>.</p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods defined with class &quot;TreeControl&quot; in the signature.
</p>

<hr>
<h2 id='varimp'> Variable Importance </h2><span id='topic+varimp'></span><span id='topic+varimpAUC'></span>

<h3>Description</h3>

<p>Standard and conditional variable importance for &lsquo;cforest&rsquo;, following the permutation
principle of the &lsquo;mean decrease in accuracy&rsquo; importance in &lsquo;randomForest&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varimp(object, mincriterion = 0, conditional = FALSE, 
       threshold = 0.2, nperm = 1, OOB = TRUE, pre1.0_0 = conditional)
varimpAUC(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varimp_+3A_object">object</code></td>
<td>
<p> an object as returned by <code>cforest</code>.</p>
</td></tr>
<tr><td><code id="varimp_+3A_mincriterion">mincriterion</code></td>
<td>
<p> the value of the test statistic or 1 - p-value that
must be exceeded in order to include a split in the 
computation of the importance. The default <code>mincriterion = 0</code>
guarantees that all splits are included.</p>
</td></tr>
<tr><td><code id="varimp_+3A_conditional">conditional</code></td>
<td>
<p> a logical determining whether unconditional or conditional 
computation of the importance is performed. </p>
</td></tr>
<tr><td><code id="varimp_+3A_threshold">threshold</code></td>
<td>
<p> the threshold value for (1 - p-value) of the association 
between the variable of interest and a covariate, which must be 
exceeded inorder to include the covariate in the conditioning 
scheme for the variable of interest (only relevant if 
<code>conditional = TRUE</code>). A threshold value of zero includes 
all covariates.</p>
</td></tr>
<tr><td><code id="varimp_+3A_nperm">nperm</code></td>
<td>
<p> the number of permutations performed.</p>
</td></tr>
<tr><td><code id="varimp_+3A_oob">OOB</code></td>
<td>
<p> a logical determining whether the importance is computed from the out-of-bag 
sample or the learning sample (not suggested).</p>
</td></tr>
<tr><td><code id="varimp_+3A_pre1.0_0">pre1.0_0</code></td>
<td>
<p> Prior to party version 1.0-0, the actual data values
were permuted according to the original permutation
importance suggested by Breiman (2001). Now the assignments
to child nodes of splits in the variable of interest
are permuted as described by Hapfelmeier et al. (2012),
which allows for missing values in the explanatory
variables and is more efficient wrt memory consumption and 
computing time. This method does not apply to conditional
variable importances.</p>
</td></tr>
<tr><td><code id="varimp_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="varImp.html#topic+varImpAUC">varImpAUC</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>varimp</code> can be used to compute variable importance measures
similar to those computed by <code><a href="randomForest.html#topic+importance">importance</a></code>. Besides the
standard version, a conditional version is available, that adjusts for correlations between
predictor variables. 
</p>
<p>If <code>conditional = TRUE</code>, the importance of each variable is computed by permuting 
within a grid defined by the covariates that are associated  (with 1 - p-value 
greater than <code>threshold</code>) to the variable of interest.
The resulting variable importance score is conditional in the sense of beta coefficients in   
regression models, but represents the effect of a variable in both main effects and interactions.
See Strobl et al. (2008) for details.
</p>
<p>Note, however, that all random forest results are subject to random variation. Thus, before
interpreting the importance ranking, check whether the same ranking is achieved with a
different random seed &ndash; or otherwise increase the number of trees <code>ntree</code> in 
<code><a href="#topic+ctree_control">ctree_control</a></code>.
</p>
<p>Note that in the presence of missings in the predictor variables the procedure
described in Hapfelmeier et al. (2012) is performed.
</p>
<p>Function <code>varimpAUC</code> is a wrapper for
<code><a href="varImp.html#topic+varImpAUC">varImpAUC</a></code> which implements AUC-based variables importances as
described by Janitza et al. (2012).  Here, the area under the curve
instead of the accuracy is used to calculate the importance of each variable. 
This AUC-based variable importance measure is more robust towards class imbalance.
</p>
<p>For right-censored responses, <code>varimp</code> uses the integrated Brier score as a 
risk measure for computing variable importances. This feature is extremely slow and
experimental; use at your own risk.
</p>


<h3>Value</h3>

<p>A vector of &lsquo;mean decrease in accuracy&rsquo; importance scores.
</p>


<h3>References</h3>

 
<p>Leo Breiman (2001). Random Forests. <em>Machine Learning</em>, 45(1), 5&ndash;32.
</p>
<p>Alexander Hapfelmeier, Torsten Hothorn, Kurt Ulm, and Carolin Strobl (2012).
A New Variable Importance Measure for Random Forests with Missing Data.
<em>Statistics and Computing</em>, <a href="https://doi.org/10.1007/s11222-012-9349-1">doi:10.1007/s11222-012-9349-1</a>
</p>
<p>Torsten Hothorn, Kurt Hornik, and Achim Zeileis (2006b). Unbiased
Recursive Partitioning: A Conditional Inference Framework.
<em>Journal of Computational and Graphical Statistics</em>, <b>15</b> (3),
651-674.  Preprint available from 
<a href="https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf">https://www.zeileis.org/papers/Hothorn+Hornik+Zeileis-2006.pdf</a>
</p>
<p>Silke Janitza, Carolin Strobl and Anne-Laure Boulesteix (2013). An AUC-based Permutation 
Variable Importance Measure for Random Forests. BMC Bioinformatics.2013, <b>14</b> 119.
<a href="https://doi.org/10.1186/1471-2105-14-119">doi:10.1186/1471-2105-14-119</a>
</p>
<p>Carolin Strobl, Anne-Laure Boulesteix, Thomas Kneib, Thomas Augustin, and Achim Zeileis (2008).
Conditional Variable Importance for Random Forests. <em>BMC Bioinformatics</em>, <b>9</b>, 307. 
<a href="https://doi.org/10.1186/1471-2105-9-307">doi:10.1186/1471-2105-9-307</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    
   set.seed(290875)
   readingSkills.cf &lt;- cforest(score ~ ., data = readingSkills, 
       control = cforest_unbiased(mtry = 2, ntree = 50))

   # standard importance
   varimp(readingSkills.cf)
   # the same modulo random variation
   varimp(readingSkills.cf, pre1.0_0 = TRUE)

   # conditional importance, may take a while...
   varimp(readingSkills.cf, conditional = TRUE)

   ## Not run: 
   data("GBSG2", package = "TH.data")
   ### add a random covariate for sanity check
   set.seed(29)
   GBSG2$rand &lt;- runif(nrow(GBSG2))
   object &lt;- cforest(Surv(time, cens) ~ ., data = GBSG2, 
                     control = cforest_unbiased(ntree = 20)) 
   vi &lt;- varimp(object)
   ### compare variable importances and absolute z-statistics
   layout(matrix(1:2))
   barplot(vi)
   barplot(abs(summary(coxph(Surv(time, cens) ~ ., data = GBSG2))$coeff[,"z"]))
   ### looks more or less the same
   
## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
