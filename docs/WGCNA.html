<!DOCTYPE html><html lang="en"><head><title>Help for package WGCNA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {WGCNA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#accuracyMeasures'>
<p>Accuracy measures for a 2x2 confusion matrix or for vectors of predicted and observed values.</p></a></li>
<li><a href='#addErrorBars'><p> Add error bars to a barplot.</p></a></li>
<li><a href='#addGrid'><p> Add grid lines to an existing plot.</p></a></li>
<li><a href='#addGuideLines'><p> Add vertical &ldquo;guide lines&rdquo; to a dendrogram plot</p></a></li>
<li><a href='#addTraitToMEs'><p> Add trait information to multi-set module eigengene structure</p></a></li>
<li><a href='#adjacency'><p> Calculate network adjacency</p></a></li>
<li><a href='#adjacency.polyReg'><p>Adjacency matrix based on polynomial regression</p></a></li>
<li><a href='#adjacency.splineReg'><p>Calculate network adjacency based on natural cubic spline regression</p></a></li>
<li><a href='#AFcorMI'><p>Prediction of Weighted Mutual Information Adjacency Matrix by Correlation</p></a></li>
<li><a href='#alignExpr'><p> Align expression data with given vector</p></a></li>
<li><a href='#allocateJobs'>
<p>Divide tasks among workers</p></a></li>
<li><a href='#allowWGCNAThreads'>
<p>Allow and disable multi-threading for certain WGCNA calculations</p></a></li>
<li><a href='#automaticNetworkScreening'><p> One-step automatic network gene screening</p></a></li>
<li><a href='#automaticNetworkScreeningGS'><p> One-step automatic network gene screening with external gene significance</p></a></li>
<li><a href='#BD.getData'>
<p>Various basic operations on <code>BlockwiseData</code> objects.</p></a></li>
<li><a href='#bicor'><p> Biweight Midcorrelation</p></a></li>
<li><a href='#bicorAndPvalue'>
<p>Calculation of biweight midcorrelations and associated p-values</p></a></li>
<li><a href='#bicovWeights'>
<p>Weights used in biweight midcovariance</p></a></li>
<li><a href='#binarizeCategoricalColumns'>
<p>Turn categorical columns into sets of binary indicators</p></a></li>
<li><a href='#binarizeCategoricalVariable'>
<p>Turn a categorical variable into a set of binary indicators</p></a></li>
<li><a href='#blockSize'>
<p>Attempt to calculate an appropriate block size to maximize efficiency of block-wise calcualtions.</p></a></li>
<li><a href='#blockwiseConsensusModules'><p>Find consensus modules across several datasets.</p></a></li>
<li><a href='#blockwiseIndividualTOMs'>
<p>Calculation of block-wise topological overlaps</p></a></li>
<li><a href='#blockwiseModules'><p> Automatic network construction and module detection</p></a></li>
<li><a href='#BloodLists'><p>Blood Cell Types with Corresponding Gene Markers</p></a></li>
<li><a href='#blueWhiteRed'><p> Blue-white-red color sequence</p></a></li>
<li><a href='#BrainLists'><p>Brain-Related Categories with Corresponding Gene Markers</p></a></li>
<li><a href='#BrainRegionMarkers'><p>Gene Markers for Regions of the Human Brain</p></a></li>
<li><a href='#branchEigengeneDissim'>
<p>Branch dissimilarity based on eigennodes (eigengenes).</p></a></li>
<li><a href='#branchSplit'>
<p>Branch split.</p></a></li>
<li><a href='#branchSplit.dissim'>
<p>Branch split based on dissimilarity.</p></a></li>
<li><a href='#branchSplitFromStabilityLabels'>
<p>Branch split (dissimilarity) statistics derived from labels determined from a stability study</p></a></li>
<li><a href='#checkAdjMat'><p> Check adjacency matrix</p></a></li>
<li><a href='#checkSets'><p>Check structure and retrieve sizes of a group of datasets.</p></a></li>
<li><a href='#chooseOneHubInEachModule'><p> Chooses a single hub gene in each module</p></a></li>
<li><a href='#chooseTopHubInEachModule'><p> Chooses the top hub gene in each module</p></a></li>
<li><a href='#clusterCoef'><p> Clustering coefficient calculation</p></a></li>
<li><a href='#coClustering'>
<p>Co-clustering measure of cluster preservation between two clusterings</p></a></li>
<li><a href='#coClustering.permutationTest'>
<p>Permutation test for co-clustering</p></a></li>
<li><a href='#collapseRows'><p>Select one representative row per group</p></a></li>
<li><a href='#collapseRowsUsingKME'><p> Selects one representative row per group based on kME</p></a></li>
<li><a href='#collectGarbage'><p>Iterative garbage collection.</p></a></li>
<li><a href='#colQuantileC'><p> Fast colunm- and row-wise quantile of a matrix.</p></a></li>
<li><a href='#conformityBasedNetworkConcepts'><p> Calculation of conformity-based network concepts.</p></a></li>
<li><a href='#conformityDecomposition'>
<p>Conformity and module based decomposition of a network adjacency matrix.</p></a></li>
<li><a href='#consensusCalculation'>
<p>Calculation of a (single) consenus with optional data calibration.</p></a></li>
<li><a href='#consensusDissTOMandTree'><p> Consensus clustering based on topological overlap and hierarchical clustering</p></a></li>
<li><a href='#consensusKME'>
<p>Calculate consensus kME (eigengene-based connectivities) across multiple data sets.</p></a></li>
<li><a href='#consensusMEDissimilarity'><p> Consensus dissimilarity of module eigengenes.</p></a></li>
<li><a href='#consensusOrderMEs'><p> Put close eigenvectors next to each other in several sets.</p></a></li>
<li><a href='#consensusProjectiveKMeans'><p> Consensus projective K-means (pre-)clustering of expression data</p></a></li>
<li><a href='#consensusRepresentatives'>
<p>Consensus selection of group representatives</p></a></li>
<li><a href='#consensusTOM'><p>Consensus network (topological overlap).</p></a></li>
<li><a href='#consensusTreeInputs'>
<p>Get all elementary inputs in a consensus tree</p></a></li>
<li><a href='#convertNumericColumnsToNumeric'>
<p>Convert character columns that represent numbers to numeric</p></a></li>
<li><a href='#cor'><p> Fast calculations of Pearson correlation.</p></a></li>
<li><a href='#corAndPvalue'>
<p>Calculation of correlations and associated p-values</p></a></li>
<li><a href='#corPredictionSuccess'><p> Qunatification of success of gene screening</p></a></li>
<li><a href='#corPvalueFisher'><p> Fisher's asymptotic p-value for correlation</p></a></li>
<li><a href='#corPvalueStudent'><p>Student asymptotic p-value for correlation</p></a></li>
<li><a href='#correlationPreservation'><p> Preservation of eigengene correlations</p></a></li>
<li><a href='#coxRegressionResiduals'><p>Deviance- and martingale residuals from a Cox regression model</p></a></li>
<li><a href='#cutreeStatic'><p> Constant-height tree cut</p></a></li>
<li><a href='#cutreeStaticColor'><p> Constant height tree cut using color labels</p></a></li>
<li><a href='#displayColors'><p> Show colors used to label modules</p></a></li>
<li><a href='#dynamicMergeCut'><p> Threshold for module merging</p></a></li>
<li><a href='#empiricalBayesLM'>
<p>Empirical Bayes-moderated adjustment for unwanted covariates</p></a></li>
<li><a href='#exportNetworkToCytoscape'><p> Export network to Cytoscape</p></a></li>
<li><a href='#exportNetworkToVisANT'><p> Export network data in format readable by VisANT</p></a></li>
<li><a href='#factorizeNonNumericColumns'>
<p>Turn non-numeric columns into factors</p></a></li>
<li><a href='#fixDataStructure'><p>Put single-set data into a form useful for multiset calculations.</p></a></li>
<li><a href='#formatLabels'>
<p>Break long character strings into multiple lines</p></a></li>
<li><a href='#fundamentalNetworkConcepts'><p> Calculation of fundamental network concepts from an adjacency matrix.</p></a></li>
<li><a href='#GOenrichmentAnalysis'><p> Calculation of GO enrichment (experimental)</p></a></li>
<li><a href='#goodGenes'><p> Filter genes with too many missing entries</p></a></li>
<li><a href='#goodGenesMS'><p>Filter genes with too many missing entries across multiple sets</p></a></li>
<li><a href='#goodSamples'><p> Filter samples with too many missing entries</p></a></li>
<li><a href='#goodSamplesGenes'><p> Iterative filtering of samples and genes with too many missing entries</p></a></li>
<li><a href='#goodSamplesGenesMS'><p>  Iterative filtering of samples and genes with too many missing entries across multiple data sets</p></a></li>
<li><a href='#goodSamplesMS'><p>  Filter samples with too many missing entries across multiple data sets</p></a></li>
<li><a href='#greenBlackRed'><p> Green-black-red color sequence</p></a></li>
<li><a href='#greenWhiteRed'><p> Green-white-red color sequence</p></a></li>
<li><a href='#GTOMdist'><p> Generalized Topological Overlap Measure</p></a></li>
<li><a href='#hierarchicalConsensusCalculation'>
<p>Hierarchical consensus calculation</p></a></li>
<li><a href='#hierarchicalConsensusKME'>
<p>Calculation of measures of fuzzy module membership (KME) in hierarchical consensus modules</p></a></li>
<li><a href='#hierarchicalConsensusMEDissimilarity'>
<p>Hierarchical consensus calculation of module eigengene dissimilarity</p></a></li>
<li><a href='#hierarchicalConsensusModules'>
<p>Hierarchical consensus network construction and module identification</p></a></li>
<li><a href='#hierarchicalConsensusTOM'>
<p>Calculation of hierarchical consensus topological overlap matrix</p></a></li>
<li><a href='#hierarchicalMergeCloseModules'>
<p>Merge close (similar) hierarchical consensus modules</p></a></li>
<li><a href='#hubGeneSignificance'><p> Hubgene significance</p></a></li>
<li><a href='#ImmunePathwayLists'><p>Immune Pathways with Corresponding Gene Markers</p></a></li>
<li><a href='#imputeByModule'>
<p>Impute missing data separately in each module</p></a></li>
<li><a href='#individualTOMs'>
<p>Calculate individual correlation network matrices</p></a></li>
<li><a href='#Inline+20display+20of+20progress'><p> Inline display of progress</p></a></li>
<li><a href='#intramodularConnectivity'><p> Calculation of intramodular connectivity</p></a></li>
<li><a href='#isMultiData'>
<p>Determine whether the supplied object is a valid multiData structure</p></a></li>
<li><a href='#keepCommonProbes'><p> Keep probes that are shared among given data sets</p></a></li>
<li><a href='#kMEcomparisonScatterplot'><p> Function to plot kME values between two comparable data sets.</p></a></li>
<li><a href='#labeledBarplot'><p> Barplot with text or color labels.</p></a></li>
<li><a href='#labeledHeatmap'><p> Produce a labeled heatmap plot</p></a></li>
<li><a href='#labeledHeatmap.multiPage'>
<p>Labeled heatmap divided into several separate plots.</p></a></li>
<li><a href='#labelPoints'>
<p>Label scatterplot points</p></a></li>
<li><a href='#labels2colors'><p>Convert numerical labels to colors.</p></a></li>
<li><a href='#list2multiData'>
<p>Convert a list to a multiData structure and vice-versa.</p></a></li>
<li><a href='#lowerTri2matrix'>
<p>Reconstruct a symmetric matrix from a distance (lower-triangular) representation</p></a></li>
<li><a href='#matchLabels'><p> Relabel module labels to best match the given reference labels</p></a></li>
<li><a href='#matrixToNetwork'>
<p>Construct a network from a matrix</p></a></li>
<li><a href='#mergeCloseModules'><p>Merge close modules in gene expression data</p></a></li>
<li><a href='#metaAnalysis'>
<p>Meta-analysis of binary and continuous variables</p></a></li>
<li><a href='#metaZfunction'>
<p>Meta-analysis Z statistic</p></a></li>
<li><a href='#minWhichMin'>
<p>Fast joint calculation of row- or column-wise minima and indices of minimum elements</p></a></li>
<li><a href='#modifiedBisquareWeights'>
<p>Modified Bisquare Weights</p></a></li>
<li><a href='#moduleColor.getMEprefix'><p>Get the prefix used to label module eigengenes.</p></a></li>
<li><a href='#moduleEigengenes'><p>Calculate module eigengenes.</p></a></li>
<li><a href='#moduleMergeUsingKME'><p> Merge modules and reassign genes using kME.</p></a></li>
<li><a href='#moduleNumber'><p>Fixed-height cut of a dendrogram.</p></a></li>
<li><a href='#modulePreservation'><p> Calculation of module preservation statistics</p></a></li>
<li><a href='#mtd.apply'>
<p>Apply a function to each set in a multiData structure.</p></a></li>
<li><a href='#mtd.mapply'>
<p>Apply a function to elements of given multiData structures.</p></a></li>
<li><a href='#mtd.rbindSelf'>
<p>Turn a multiData structure into a single matrix or data frame.</p></a></li>
<li><a href='#mtd.setAttr'>
<p>Set attributes on each component of a multiData structure</p></a></li>
<li><a href='#mtd.setColnames'>
<p>Get and set column names in a multiData structure.</p></a></li>
<li><a href='#mtd.simplify'>
<p>If possible, simplify a multiData structure to a 3-dimensional array.</p></a></li>
<li><a href='#mtd.subset'>
<p>Subset rows and columns in a multiData structure</p></a></li>
<li><a href='#multiData'>
<p>Create a multiData structure.</p></a></li>
<li><a href='#multiData.eigengeneSignificance'>
<p>Eigengene significance across multiple sets</p></a></li>
<li><a href='#multiGSub'>
<p>Analogs of grep(l) and (g)sub for multiple patterns and relacements</p></a></li>
<li><a href='#multiSetMEs'><p>Calculate module eigengenes.</p></a></li>
<li><a href='#multiUnion'>
<p>Union and intersection of multiple sets</p></a></li>
<li><a href='#mutualInfoAdjacency'><p>Calculate weighted adjacency matrices based on mutual information</p></a></li>
<li><a href='#nearestCentroidPredictor'>
<p>Nearest centroid predictor</p></a></li>
<li><a href='#nearestNeighborConnectivity'><p> Connectivity to a constant number of nearest neighbors</p></a></li>
<li><a href='#nearestNeighborConnectivityMS'><p> Connectivity to a constant number of nearest neighbors across multiple data sets</p></a></li>
<li><a href='#networkConcepts'><p> Calculations of network concepts</p></a></li>
<li><a href='#networkScreening'><p> Identification of genes related to a trait</p></a></li>
<li><a href='#networkScreeningGS'><p> Network gene screening with an external gene significance measure</p></a></li>
<li><a href='#newBlockInformation'>
<p>Create a list holding information about dividing data into blocks</p></a></li>
<li><a href='#newBlockwiseData'>
<p>Create, merge and expand BlockwiseData objects</p></a></li>
<li><a href='#newConsensusOptions'>
<p>Create a list holding consensus calculation options.</p></a></li>
<li><a href='#newConsensusTree'>
<p>Create a new consensus tree</p></a></li>
<li><a href='#newCorrelationOptions'>
<p>Creates a list of correlation options.</p></a></li>
<li><a href='#newNetworkOptions'>
<p>Create a list of network construction arguments (options).</p></a></li>
<li><a href='#normalizeLabels'><p>Transform numerical labels into normal order.</p></a></li>
<li><a href='#nPresent'><p> Number of present data entries.</p></a></li>
<li><a href='#nSets'><p> Number of sets in a multi-set variable</p></a></li>
<li><a href='#numbers2colors'><p> Color representation for a numeric variable</p></a></li>
<li><a href='#orderBranchesUsingHubGenes'><p> Optimize dendrogram using branch swaps and reflections.</p></a></li>
<li><a href='#orderMEs'><p>Put close eigenvectors next to each other</p></a></li>
<li><a href='#orderMEsByHierarchicalConsensus'>
<p>Order module eigengenes by their hierarchical consensus similarity</p></a></li>
<li><a href='#overlapTable'><p> Calculate overlap of modules</p></a></li>
<li><a href='#overlapTableUsingKME'><p> Determines significant overlap between modules in two networks based on kME tables.</p></a></li>
<li><a href='#pickHardThreshold'><p> Analysis of scale free topology for hard-thresholding.</p></a></li>
<li><a href='#pickSoftThreshold'><p> Analysis of scale free topology for soft-thresholding</p></a></li>
<li><a href='#plotClusterTreeSamples'><p> Annotated clustering dendrogram of microarray samples</p></a></li>
<li><a href='#plotColorUnderTree'><p>Plot color rows in a given order, for example under a dendrogram</p></a></li>
<li><a href='#plotCor'><p>Red and Green Color Image of Correlation Matrix</p></a></li>
<li><a href='#plotDendroAndColors'><p> Dendrogram plot with color annotation of objects</p></a></li>
<li><a href='#plotEigengeneNetworks'><p> Eigengene network plot</p></a></li>
<li><a href='#plotMat'><p>Red and Green Color Image of Data Matrix</p></a></li>
<li><a href='#plotMEpairs'><p> Pairwise scatterplots of eigengenes</p></a></li>
<li><a href='#plotModuleSignificance'><p> Barplot of module significance</p></a></li>
<li><a href='#plotMultiHist'>
<p>Plot multiple histograms in a single plot</p></a></li>
<li><a href='#plotNetworkHeatmap'><p> Network heatmap plot</p></a></li>
<li><a href='#populationMeansInAdmixture'><p>Estimate the population-specific mean values in an admixed population.</p></a></li>
<li><a href='#pquantile'><p> Parallel quantile, median, mean</p></a></li>
<li><a href='#prepComma'>
<p>Prepend a comma to a non-empty string</p></a></li>
<li><a href='#prependZeros'>
<p>Pad numbers with leading zeros to specified total width</p></a></li>
<li><a href='#preservationNetworkConnectivity'><p> Network preservation calculations</p></a></li>
<li><a href='#projectiveKMeans'><p> Projective K-means (pre-)clustering of expression data</p></a></li>
<li><a href='#proportionsInAdmixture'><p>Estimate the proportion of pure populations in an admixed population based on marker expression</p>
values.</a></li>
<li><a href='#propVarExplained'><p> Proportion of variance explained by eigengenes.</p></a></li>
<li><a href='#pruneAndMergeConsensusModules'>
<p>Iterative pruning and merging of (hierarchical) consensus modules</p></a></li>
<li><a href='#pruneConsensusModules'>
<p>Prune (hierarchical) consensus modules by removing genes with low eigengene-based intramodular connectivity</p></a></li>
<li><a href='#PWLists'><p>Pathways with Corresponding Gene Markers - Compiled by Mike Palazzolo and Jim Wang from CHDI</p></a></li>
<li><a href='#qvalue'><p>Estimate the q-values for a given set of p-values</p></a></li>
<li><a href='#qvalue.restricted'>
<p>qvalue convenience wrapper</p></a></li>
<li><a href='#randIndex'><p> Rand index of two partitions</p></a></li>
<li><a href='#rankPvalue'>
<p>Estimate the p-value for ranking consistently high (or low) on multiple lists</p></a></li>
<li><a href='#recutBlockwiseTrees'><p> Repeat blockwise module detection from pre-calculated data</p></a></li>
<li><a href='#recutConsensusTrees'><p> Repeat blockwise consensus module detection from pre-calculated data</p></a></li>
<li><a href='#redWhiteGreen'><p> Red-white-green color sequence</p></a></li>
<li><a href='#relativeCorPredictionSuccess'><p> Compare prediction success</p></a></li>
<li><a href='#removeGreyME'><p>Removes the grey eigengene from a given collection of eigengenes.</p></a></li>
<li><a href='#removePrincipalComponents'>
<p>Remove leading principal components from data</p></a></li>
<li><a href='#replaceMissing'>
<p>Replace missing values with a constant.</p></a></li>
<li><a href='#returnGeneSetsAsList'>
<p>Return pre-defined gene lists in several biomedical categories.</p></a></li>
<li><a href='#rgcolors.func'><p>Red and Green Color Specification</p></a></li>
<li><a href='#sampledBlockwiseModules'>
<p>Blockwise module identification in sampled data</p></a></li>
<li><a href='#sampledHierarchicalConsensusModules'>
<p>Hierarchical consensus module identification in sampled data</p></a></li>
<li><a href='#scaleFreeFitIndex'>
<p>Calculation of fitting statistics for evaluating scale free topology fit.</p></a></li>
<li><a href='#scaleFreePlot'><p> Visual check of scale-free topology</p></a></li>
<li><a href='#SCsLists'><p>Stem Cell-Related Genes with Corresponding Gene Markers</p></a></li>
<li><a href='#selectFewestConsensusMissing'>
<p>Select columns with the lowest consensus number of missing data</p></a></li>
<li><a href='#setCorrelationPreservation'><p> Summary correlation preservation measure</p></a></li>
<li><a href='#shortenStrings'>
<p>Shorten given character strings by truncating at a suitable separator.</p></a></li>
<li><a href='#sigmoidAdjacencyFunction'><p> Sigmoid-type adacency function.</p></a></li>
<li><a href='#signedKME'><p> Signed eigengene-based connectivity</p></a></li>
<li><a href='#signifNumeric'>
<p>Round numeric columns to given significant digits.</p></a></li>
<li><a href='#signumAdjacencyFunction'><p> Hard-thresholding adjacency function</p></a></li>
<li><a href='#simpleConsensusCalculation'>
<p>Simple calculation of a single consenus</p></a></li>
<li><a href='#simpleHierarchicalConsensusCalculation'>
<p>Simple hierarchical consensus calculation</p></a></li>
<li><a href='#simulateDatExpr'><p> Simulation of expression data</p></a></li>
<li><a href='#simulateDatExpr5Modules'><p> Simplified simulation of expression data</p></a></li>
<li><a href='#simulateEigengeneNetwork'><p> Simulate eigengene network from a causal model</p></a></li>
<li><a href='#simulateModule'><p> Simulate a gene co-expression module</p></a></li>
<li><a href='#simulateMultiExpr'><p> Simulate multi-set expression data</p></a></li>
<li><a href='#simulateSmallLayer'><p> Simulate small modules</p></a></li>
<li><a href='#sizeGrWindow'><p> Opens a graphics window with specified dimensions</p></a></li>
<li><a href='#sizeRestrictedClusterMerge'>
<p>Cluter merging with size restrictions</p></a></li>
<li><a href='#softConnectivity'><p> Calculates connectivity of a weighted network.</p></a></li>
<li><a href='#spaste'>
<p>Space-less paste</p></a></li>
<li><a href='#standardColors'><p>Colors this library uses for labeling modules.</p></a></li>
<li><a href='#standardScreeningBinaryTrait'>
<p>Standard screening for binatry traits</p></a></li>
<li><a href='#standardScreeningCensoredTime'>
<p>Standard Screening with regard to a Censored Time Variable</p></a></li>
<li><a href='#standardScreeningNumericTrait'>
<p>Standard screening for numeric traits</p></a></li>
<li><a href='#stdErr'><p> Standard error of the mean of a given vector.</p></a></li>
<li><a href='#stratifiedBarplot'><p> Bar plots of data across two splitting parameters</p></a></li>
<li><a href='#subsetTOM'><p> Topological overlap for a subset of a whole set of genes</p></a></li>
<li><a href='#swapTwoBranches'><p> Select, swap, or reflect branches in a dendrogram.</p></a></li>
<li><a href='#TOMplot'><p> Graphical representation of the Topological Overlap Matrix</p></a></li>
<li><a href='#TOMsimilarity'><p> Topological overlap matrix similarity and dissimilarity</p></a></li>
<li><a href='#TOMsimilarityFromExpr'><p> Topological overlap matrix</p></a></li>
<li><a href='#transposeBigData'><p>Transpose a big matrix or data frame</p></a></li>
<li><a href='#TrueTrait'><p>Estimate the true trait underlying a list of surrogate markers.</p></a></li>
<li><a href='#unsignedAdjacency'><p> Calculation of unsigned adjacency</p></a></li>
<li><a href='#userListEnrichment'>
<p>Measure enrichment between inputted and user-defined lists</p></a></li>
<li><a href='#vectorizeMatrix'><p> Turn a matrix into a vector of non-redundant components</p></a></li>
<li><a href='#vectorTOM'><p> Topological overlap for a subset of the whole set of genes</p></a></li>
<li><a href='#verboseBarplot'><p> Barplot with error bars, annotated by Kruskal-Wallis or ANOVA p-value</p></a></li>
<li><a href='#verboseBoxplot'><p> Boxplot annotated by a Kruskal-Wallis p-value</p></a></li>
<li><a href='#verboseIplot'>
<p>Scatterplot with density</p></a></li>
<li><a href='#verboseScatterplot'><p> Scatterplot annotated by regression line and p-value</p></a></li>
<li><a href='#votingLinearPredictor'><p> Voting linear predictor</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.73</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-18</td>
</tr>
<tr>
<td>Title:</td>
<td>Weighted Correlation Network Analysis</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Langfelder &lt;Peter.Langfelder@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0), dynamicTreeCut (&ge; 1.62), fastcluster</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, grDevices, utils, matrixStats (&ge; 0.8.1), Hmisc,
impute, splines, foreach, doParallel, preprocessCore, survival,
parallel, GO.db, AnnotationDbi, Rcpp (&ge; 0.11.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>org.Hs.eg.db, org.Mm.eg.db, infotheo, entropy, minet</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>ZipData:</td>
<td>no</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions necessary to perform Weighted Correlation Network Analysis on high-dimensional data as originally described in Horvath and Zhang (2005) &lt;<a href="https://doi.org/10.2202%2F1544-6115.1128">doi:10.2202/1544-6115.1128</a>&gt; and Langfelder and Horvath (2008) &lt;<a href="https://doi.org/10.1186%2F1471-2105-9-559">doi:10.1186/1471-2105-9-559</a>&gt;. Includes functions for rudimentary data cleaning, construction of correlation networks, module identification, summarization, and relating of variables and modules to sample traits. Also includes a number of utility functions for data manipulation and visualization.</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-18 12:43:22 UTC; plangfelder</td>
</tr>
<tr>
<td>Author:</td>
<td>Peter Langfelder [aut, cre],
  Steve Horvath [aut],
  Chaochao Cai [aut],
  Jun Dong [aut],
  Jeremy Miller [aut],
  Lin Song [aut],
  Andy Yip [aut],
  Bin Zhang [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-18 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='accuracyMeasures'>
Accuracy measures for a 2x2 confusion matrix or for vectors of predicted and observed values.
</h2><span id='topic+accuracyMeasures'></span>

<h3>Description</h3>

<p>The function calculates various prediction accuracy statistics for predictions of binary or quantitative
(continuous) responses. For binary classification, the function calculates 
the error rate, accuracy, sensitivity, specificity, positive predictive value, and
other accuracy measures. For quantitative prediction, the function calculates correlation, R-squared, error
measures, and the C-index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracyMeasures(
  predicted, 
  observed = NULL, 
  type = c("auto", "binary", "quantitative"),
  levels = if (isTRUE(all.equal(dim(predicted), c(2,2)))) colnames(predicted)
            else if (is.factor(predicted))
              sort(unique(c(as.character(predicted), as.character(observed))))
            else sort(unique(c(observed, predicted))),
  negativeLevel = levels[2], 
  positiveLevel = levels[1] )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="accuracyMeasures_+3A_predicted">predicted</code></td>
<td>
<p> either a a 2x2 confusion matrix (table) whose entries contain non-negative
integers, or a vector of predicted values. Predicted values can be binary or quantitative (see <code>type</code>
below). If a 2x2 matrix is given, it must have valid column and row names that specify the levels of the
predicted and observed variables whose counts the matrix is giving (e.g., the
function <code><a href="base.html#topic+table">table</a></code> sets the names appropriately.) If it is a 2x2 table and the table 
contains non-negative real (non-integer) numbers the function outputs a warning.
</p>
</td></tr>
<tr><td><code id="accuracyMeasures_+3A_observed">observed</code></td>
<td>
<p> if <code>predicted</code> is a vector of predicted values, this (<code>observed</code>) must be a
vector of the same length giving the &quot;gold standard&quot; (or observed) values. Ignored if <code>predicted</code> is a 2x2
table. </p>
</td></tr>
<tr><td><code id="accuracyMeasures_+3A_type">type</code></td>
<td>
<p> character string specifying the type of the prediction problem (i.e., values in the 
<code>predicted</code> and <code>observed</code> vectors). The
default <code>"auto"</code> decides type automatically: 
if <code>predicted</code> is a 2x2 table or if the number of unique values in
the concatenation of <code>predicted</code> and <code>observed</code> is 2, the prediction problem (type) is assumed to
be binary, otherwise it is assumed to be quantitative. Inconsistent specification (for example, when
<code>predicted</code> is a 2x2 matrix and <code>type</code> is <code>"quantitative"</code>) trigger errors. </p>
</td></tr> 
<tr><td><code id="accuracyMeasures_+3A_levels">levels</code></td>
<td>
<p> a 2-element vector specifying the two levels of binary variables. Only used if <code>type</code> is
<code>"binary"</code> (or <code>"auto"</code> that results in the binary type). Defaults to either the column names of
the confusion matrix (if the matrix is specified) or to the sorted unique values of <code>observed</code> and
<code>opredicted</code>. </p>
</td></tr>
<tr><td><code id="accuracyMeasures_+3A_negativelevel">negativeLevel</code></td>
<td>
<p> the binary value (level) that corresponds to the negative outcome. Note that the
default is the second of the sorted levels (for example, if levels are 1,2, the default negative level is
2). Only used if <code>type</code> is
<code>"binary"</code> (or <code>"auto"</code> that results in the binary type).</p>
</td></tr>
<tr><td><code id="accuracyMeasures_+3A_positivelevel">positiveLevel</code></td>
<td>
<p> the binary value (level) that corresponds to the positive outcome. Note that the 
default is the second of the sorted levels (for example, if levels are 1,2, the default negative level is
2). Only used if <code>type</code> is
<code>"binary"</code> (or <code>"auto"</code> that results in the binary type).</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The rows of the 2x2 table tab must correspond to a test (or predicted) outcome and the columns to a true
outcome (&quot;gold standard&quot;). A table that relates a predicted outcome to a true test outcome is also known as
confusion matrix. Warning: To correctly calculate sensitivity and specificity, the positive and negative
outcome must be properly specified so they can be matched to the appropriate rows and columns in the
confusion table. 
</p>
<p>Interchanging the negative and positive levels swaps the estimates of the sensitivity and specificity 
but has no effect on the error rate or
accuracy. Specifically, denote by <code>pos</code> the index of the positive level in the confusion table, and by
<code>neg</code> th eindex of the negative level in the confusion table. 
The function then defines number of true positives=TP=tab[pos, pos], no.false positives
=FP=tab[pos, neg], no.false negatives=FN=tab[neg, pos], no.true negatives=TN=tab[neg, neg]. 
Then Specificity= TN/(FP+TN)
Sensitivity= TP/(TP+FN) NegativePredictiveValue= TN/(FN + TN) PositivePredictiveValue= TP/(TP + FP)
FalsePositiveRate = 1-Specificity FalseNegativeRate = 1-Sensitivity Power = Sensitivity
LikelihoodRatioPositive = Sensitivity / (1-Specificity) LikelihoodRatioNegative =
(1-Sensitivity)/Specificity. The naive error rate is the error rate of a constant (naive) predictor that
assigns the same outcome to all samples. The prediction of the naive predictor equals the most frequenly
observed outcome. Example: Assume you want to predict disease status and 70 percent of the observed samples
have the disease. Then the naive predictor has an error rate of 30 percent (since it only misclassifies 30
percent of the healthy individuals). </p>


<h3>Value</h3>

<p>Data frame with two columns: 
</p>
<table role = "presentation">
<tr><td><code>Measure</code></td>
<td>
<p>this column contais character strings that specify name of the accuracy measure.</p>
</td></tr>
<tr><td><code>Value</code></td>
<td>
<p>this column contains the numeric estimates of the corresponding accuracy measures.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath and Peter Langfelder
</p>


<h3>References</h3>

<p>http://en.wikipedia.org/wiki/Sensitivity_and_specificity 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m=100
trueOutcome=sample( c(1,2),m,replace=TRUE)
predictedOutcome=trueOutcome
# now we noise half of the entries of the predicted outcome
predictedOutcome[ 1:(m/2)] =sample(predictedOutcome[ 1:(m/2)] )
tab=table(predictedOutcome, trueOutcome) 
accuracyMeasures(tab)

# Same result:
accuracyMeasures(predictedOutcome, trueOutcome)

</code></pre>

<hr>
<h2 id='addErrorBars'> Add error bars to a barplot. </h2><span id='topic+addErrorBars'></span>

<h3>Description</h3>

<p>This function adds error bars to an existing barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addErrorBars(means, errors, two.side = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addErrorBars_+3A_means">means</code></td>
<td>
<p> vector of means plotted in the barplot </p>
</td></tr>
<tr><td><code id="addErrorBars_+3A_errors">errors</code></td>
<td>
<p> vector of standard errors (signle positive values) to be plotted. </p>
</td></tr>
<tr><td><code id="addErrorBars_+3A_two.side">two.side</code></td>
<td>
<p> should the error bars be two-sided? </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>

<hr>
<h2 id='addGrid'> Add grid lines to an existing plot. </h2><span id='topic+addGrid'></span>

<h3>Description</h3>

<p>This function adds horizontal and/or vertical grid lines to an existing plot. The grid lines are
aligned with tick marks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addGrid(
  linesPerTick = NULL, 
  linesPerTick.horiz = linesPerTick,
  linesPerTick.vert = linesPerTick,
  horiz = TRUE, 
  vert = FALSE, 
  col = "grey30", 
  lty = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addGrid_+3A_linespertick">linesPerTick</code></td>
<td>
<p> Number of lines between successive tick marks (including the line on the
tickmarks themselves). </p>
</td></tr>
<tr><td><code id="addGrid_+3A_linespertick.horiz">linesPerTick.horiz</code></td>
<td>
<p> Number of horizontal lines between successive tick marks (including the line on the
tickmarks themselves). </p>
</td></tr>
<tr><td><code id="addGrid_+3A_linespertick.vert">linesPerTick.vert</code></td>
<td>
<p> Number of vertical lines between successive tick marks (including the line on the
tickmarks themselves). </p>
</td></tr>
<tr><td><code id="addGrid_+3A_horiz">horiz</code></td>
<td>
<p> Draw horizontal grid lines? </p>
</td></tr>
<tr><td><code id="addGrid_+3A_vert">vert</code></td>
<td>
<p> Draw vertical tick lines? </p>
</td></tr>
<tr><td><code id="addGrid_+3A_col">col</code></td>
<td>
<p> Specifies color of the grid lines </p>
</td></tr>
<tr><td><code id="addGrid_+3A_lty">lty</code></td>
<td>
<p> Specifies line type of grid lines. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>linesPerTick</code> is not specified, it is set to 5 if number of tick s is 5 or less, and it
is set to 2 if number of ticks is greater than 5.
</p>


<h3>Note</h3>

<p> The function does not work whenever logarithmic scales are in use. </p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>Examples</h3>

<pre><code class='language-R'>  plot(c(1:10), c(1:10))
  addGrid();
</code></pre>

<hr>
<h2 id='addGuideLines'> Add vertical &ldquo;guide lines&rdquo; to a dendrogram plot</h2><span id='topic+addGuideLines'></span>

<h3>Description</h3>

<p>Adds vertical &ldquo;guide lines&rdquo; to a dendrogram plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addGuideLines(dendro, 
              all = FALSE, 
              count = 50, 
              positions = NULL, 
              col = "grey30", 
              lty = 3, 
              hang = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addGuideLines_+3A_dendro">dendro</code></td>
<td>
<p> The dendrogram (see <code><a href="stats.html#topic+hclust">hclust</a></code>) to which the guide lines are to be added. </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_all">all</code></td>
<td>
<p> Add a guide line to every object on the dendrogram? Useful if the number of objects is
relatively low. </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_count">count</code></td>
<td>
<p> Number of guide lines to be plotted. The lines will be equidistantly spaced. </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_positions">positions</code></td>
<td>
<p> Horizontal positions of the added guide lines. If given, overrides <code>count</code>. </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_col">col</code></td>
<td>
<p> Color of the guide lines </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_lty">lty</code></td>
<td>
<p> Line type of the guide lines. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="addGuideLines_+3A_hang">hang</code></td>
<td>
<p> Fraction of the figure height that will separate top ends of guide lines and the
merge heights of the corresponding objects. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>

<hr>
<h2 id='addTraitToMEs'> Add trait information to multi-set module eigengene structure </h2><span id='topic+addTraitToMEs'></span>

<h3>Description</h3>

<p>Adds trait information to multi-set module eigengene structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addTraitToMEs(multiME, multiTraits)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addTraitToMEs_+3A_multime">multiME</code></td>
<td>
<p> Module eigengenes in multi-set format. A vector of lists, one list per set. Each list
must contain an element named <code>data</code> that is a data frame with module eigengenes. </p>
</td></tr>
<tr><td><code id="addTraitToMEs_+3A_multitraits">multiTraits</code></td>
<td>
<p> Microarray sample trait(s) in multi-set format. A vector of lists, one list per
set. Each list 
must contain an element named <code>data</code> that is a data frame in which each column corresponds to a
trait, and each row to an individual sample.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function simply <code>cbind</code>'s the module eigengenes and traits for each set. The number of sets
and numbers of samples in each set must be consistent between <code>multiMEs</code> and <code>multiTraits</code>.
</p>


<h3>Value</h3>

<p>A multi-set structure analogous to the input: a vector of lists, one list per set. Each list will
contain a component <code>data</code> with the merged eigengenes and traits for the corresponding set.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+checkSets">checkSets</a></code>, <code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> </p>

<hr>
<h2 id='adjacency'> Calculate network adjacency </h2><span id='topic+adjacency'></span><span id='topic+adjacency.fromSimilarity'></span>

<h3>Description</h3>

<p>Calculates (correlation or distance) network adjacency from given expression data or from a similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjacency(datExpr, 
          selectCols = NULL, 
          type = "unsigned", 
          power = if (type=="distance") 1 else 6,
          corFnc = "cor", corOptions = list(use = "p"),
          weights = NULL,
          distFnc = "dist", distOptions = "method = 'euclidean'",
          weightArgNames = c("weights.x", "weights.y"))

adjacency.fromSimilarity(similarity, 
                         type = "unsigned", 
                         power = if (type=="distance") 1 else 6)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjacency_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame containing expression data. Columns correspond to genes and rows to
samples.</p>
</td></tr>
<tr><td><code id="adjacency_+3A_similarity">similarity</code></td>
<td>
<p>a (signed) similarity matrix: square, symmetric matrix with entries between -1 and 1. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_selectcols">selectCols</code></td>
<td>
<p> for correlation networks only (see below); 
can be used to select genes whose adjacencies will be calculated. Should be either a
numeric vector giving the indices of the genes to be used, or a boolean vector indicating which genes are
to be used. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_type">type</code></td>
<td>
<p>network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>, <code>"distance"</code>. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_power">power</code></td>
<td>
<p>soft thresholding power. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_corfnc">corFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity for correlation networks. 
Defaults to Pearson correlation. Any function returning values between -1 and 1 can be used. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_coroptions">corOptions</code></td>
<td>
<p> character string or a list specifying additional arguments to be passed to the function given
by <code>corFnc</code>. Use <code>"use = 'p', method = 'spearman'"</code> or, equivalently, 
<code>list(use = 'p', method = 'spearman')</code> to obtain Spearman correlation.   </p>
</td></tr>
<tr><td><code id="adjacency_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>datExpr</code> to be used in correlation calculation.
A matrix of the same dimensions as <code>datExpr</code>, containing non-negative weights. Only used with Pearson
correlation.</p>
</td></tr>
<tr><td><code id="adjacency_+3A_distfnc">distFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity for distance networks. Defaults to the function <code><a href="stats.html#topic+dist">dist</a></code>. 
Any function returning non-negative values can be used.</p>
</td></tr>
<tr><td><code id="adjacency_+3A_distoptions">distOptions</code></td>
<td>
<p> character string or a list specifying additional arguments to be passed to the function given
by <code>distFnc</code>. For example, when the function  <code><a href="stats.html#topic+dist">dist</a></code> is used, the argument <code>method</code>
can be used to specify various ways of computing the distance. </p>
</td></tr>
<tr><td><code id="adjacency_+3A_weightargnames">weightArgNames</code></td>
<td>
<p>character vector of length 2 giving the names of the arguments to <code>corFnc</code> that
represent weights for variable x and y. Only used if <code>weights</code> are non-NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>type</code> determines whether a correlation (<code>type</code> one of <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>), or a distance network (<code>type</code> equal <code>"distance"</code>) will
be calculated. In correlation networks the adajcency is constructed from correlations (values between -1 and
1, with high numbers meaning high similarity). In distance networks, the adjacency is constructed from
distances (non-negative values, high values mean low similarity). 
</p>
<p>The function calculates the similarity of columns (genes) in <code>datExpr</code> by calling the function
given in <code>corFnc</code> (for correlation networks) or <code>distFnc</code> (for distance networks), 
transforms the similarity according to <code>type</code> and raises it to <code>power</code>,
resulting in a weighted network adjacency matrix. If <code>selectCols</code> is given, the <code>corFnc</code> function
will be given arguments <code>(datExpr, datExpr[selectCols], ...)</code>; hence the returned adjacency will have
rows corresponding to all genes and columns corresponding to genes selected by <code>selectCols</code>.
</p>
<p>Correlation and distance are transformed as follows: for <code>type = "unsigned"</code>, adjacency = |cor|^power;
for <code>type = "signed"</code>, adjacency = (0.5 * (1+cor) )^power; for <code>type = "signed hybrid"</code>, adjacency
= cor^power if cor&gt;0 and 0 otherwise; and for <code>type = "distance"</code>, adjacency =
(1-(dist/max(dist))^2)^power.
</p>
<p>The function <code>adjacency.fromSimilarity</code> inputs a similarity matrix, that is it skips the correlation
calculation step but is otherwise identical.
</p>


<h3>Value</h3>

<p>Adjacency matrix of dimensions <code>ncol(datExpr)</code> times <code>ncol(datExpr)</code> (or the same dimensions 
as <code>similarity</code>). If <code>selectCols</code> was
given, the number of columns will be the length (if numeric) or sum (if boolean) of <code>selectCols</code>.
</p>


<h3>Note</h3>

<p>When calculated from the <code>datExpr</code>, the network is always calculated among the columns of 
<code>datExpr</code> irrespective of whether a correlation or a distance network is requested. </p>


<h3>Author(s)</h3>

<p> Peter Langfelder and Steve Horvath </p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) A General Framework for Weighted Gene Co-Expression
Network Analysis, Statistical Applications in Genetics and Molecular Biology, Vol. 4 No. 1, Article 17 
</p>
<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression
modules. BMC Systems Biology 2007, 1:54
</p>

<hr>
<h2 id='adjacency.polyReg'>Adjacency matrix based on polynomial regression
</h2><span id='topic+adjacency.polyReg'></span>

<h3>Description</h3>

<p>adjacency.polyReg calculates a network adjacency matrix by fitting polynomial regression models to pairs of variables (i.e. pairs of columns from
<code>datExpr</code>). Each polynomial fit results in a model fitting index R.squared. 
Thus, the n columns of  <code>datExpr</code> result in an n x n dimensional matrix whose entries contain R.squared
measures. This matrix is typically non-symmetric. To arrive at a (symmetric) adjacency matrix, one can
specify different symmetrization methods with <code>symmetrizationMethod</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjacency.polyReg(datExpr, degree=3, symmetrizationMethod = "mean")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjacency.polyReg_+3A_datexpr">datExpr</code></td>
<td>
<p>data frame containing numeric variables. Example: Columns may correspond to genes and rows to observations (samples).</p>
</td></tr>
<tr><td><code id="adjacency.polyReg_+3A_degree">degree</code></td>
<td>

<p>the degree of the polynomial. Must be less than the number of unique points.</p>
</td></tr>
<tr><td><code id="adjacency.polyReg_+3A_symmetrizationmethod">symmetrizationMethod</code></td>
<td>
<p>character string (eg &quot;none&quot;, &quot;min&quot;,&quot;max&quot;,&quot;mean&quot;) that specifies the method used to symmetrize the pairwise model fitting index matrix (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A network adjacency matrix is a symmetric matrix whose entries lie between 0 and 1. It is a special case of a similarity matrix.
Each variable (column of <code>datExpr</code>) is regressed on every other variable, with each model fitting index recorded in a square matrix. Note that the model fitting index of regressing variable x and variable y is usually different from that of regressing y on x.  From the polynomial regression model glm(y ~ poly(x,degree))  one can calculate the model fitting index R.squared(y,x). 
R.squared(y,x) is a number between 0 and 1. The closer it is to 1, the better the polynomial describes the relationship between x and y and the more significant is the pairwise relationship between the 2 variables. One can also reverse the roles of x and y to arrive at a model fitting index R.squared(x,y). If <code>degree</code>&gt;1 then R.squared(x,y) is typically different from R.squared(y,x). Assume a set of n variables x1,...,xn (corresponding to the columns of <code>datExpr</code> then one can define R.squared(xi,xj). The model fitting indices for the elements of an n x n dimensional matrix (R.squared(ij)). 
<code>symmetrizationMethod</code> implements the following symmetrization methods: 
A.min(ij)=min(R.squared(ij),R.squared(ji)), 
A.ave(ij)=(R.squared(ij)+R.squared(ji))/2, 
A.max(ij)=max(R.squared(ij),R.squared(ji)).
</p>


<h3>Value</h3>

<p>An adjacency matrix of dimensions ncol(datExpr) times ncol(datExpr).</p>


<h3>Author(s)</h3>

<p>Lin Song, Steve Horvath 
</p>


<h3>References</h3>

<p>Song L, Langfelder P, Horvath S Avoiding mutual information based co-expression measures (to appear).
</p>
<p>Horvath S (2011) Weighted Network Analysis. Applications in Genomics and Systems Biology. Springer Book. ISBN: 978-1-4419-8818-8
</p>


<h3>See Also</h3>

<p>For more information about polynomial regression, please refer to functions 
<code><a href="stats.html#topic+poly">poly</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate a data frame datE which contains 5 columns and 50 observations
m=50
x1=rnorm(m)
r=.5; x2=r*x1+sqrt(1-r^2)*rnorm(m)
r=.3; x3=r*(x1-.5)^2+sqrt(1-r^2)*rnorm(m)
x4=rnorm(m)
r=.3; x5=r*x4+sqrt(1-r^2)*rnorm(m)
datE=data.frame(x1,x2,x3,x4,x5)
#calculate adjacency by symmetrizing using max
A.max=adjacency.polyReg(datE, symmetrizationMethod="max")
A.max
#calculate adjacency by symmetrizing using max
A.mean=adjacency.polyReg(datE, symmetrizationMethod="mean")
A.mean
# output the unsymmetrized pairwise model fitting indices R.squared 
R.squared=adjacency.polyReg(datE, symmetrizationMethod="none")
R.squared
</code></pre>

<hr>
<h2 id='adjacency.splineReg'>Calculate network adjacency based on natural cubic spline regression
</h2><span id='topic+adjacency.splineReg'></span>

<h3>Description</h3>

<p>adjacency.splineReg calculates a network adjacency matrix by fitting spline regression models to pairs of variables (i.e. pairs of columns from
<code>datExpr</code>). Each spline regression model results in a fitting index R.squared.  Thus, the n columns of
<code>datExpr</code> result in an n x n dimensional matrix whose entries contain R.squared measures. This matrix
is typically non-symmetric. To arrive at a (symmetric) adjacency matrix, one can specify different
symmetrization methods with <code>symmetrizationMethod</code>. </p>


<h3>Usage</h3>

<pre><code class='language-R'>adjacency.splineReg(
   datExpr, 
   df = 6-(nrow(datExpr)&lt;100)-(nrow(datExpr)&lt;30), 
   symmetrizationMethod = "mean", 
   ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjacency.splineReg_+3A_datexpr">datExpr</code></td>
<td>

<p>data frame containing numeric variables. Example: Columns may correspond to genes and rows to observations (samples).</p>
</td></tr>
<tr><td><code id="adjacency.splineReg_+3A_df">df</code></td>
<td>

<p>degrees of freedom in generating natural cubic spline. The default is as follows: if nrow(datExpr)&gt;100 use 6, if nrow(datExpr)&gt;30 use 4, otherwise use 5.</p>
</td></tr>
<tr><td><code id="adjacency.splineReg_+3A_symmetrizationmethod">symmetrizationMethod</code></td>
<td>

<p>character string (eg &quot;none&quot;, &quot;min&quot;,&quot;max&quot;,&quot;mean&quot;) that specifies the method used to symmetrize the pairwise model fitting index matrix (see details).</p>
</td></tr>
<tr><td><code id="adjacency.splineReg_+3A_...">...</code></td>
<td>

<p>other arguments from function <code><a href="splines.html#topic+ns">ns</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>A network adjacency matrix is a symmetric matrix whose entries lie between 0 and 1. It is a special case of a similarity matrix.
Each variable (column of <code>datExpr</code>) is regressed on every other variable, with each model fitting index recorded in a square matrix. Note that the model fitting index of regressing variable x and variable y is usually different from that of regressing y on x.  From the spline regression model
glm( y ~ ns( x, df)) one can calculate the model fitting index R.squared(y,x). 
R.squared(y,x) is a number between 0 and 1. The closer it is to 1, the better the spline regression model
describes the relationship between x and y and the more significant is the pairwise relationship between the
2 variables. One can also reverse the roles of x and y to arrive at a model fitting index R.squared(x,y).
R.squared(x,y) is typically different from R.squared(y,x). Assume a set of n variables x1,...,xn
(corresponding to the columns of <code>datExpr</code>) then one can define R.squared(xi,xj). The model fitting
indices for the elements of an n x n dimensional matrix (R.squared(ij)).  
<code>symmetrizationMethod</code> implements the following symmetrization methods: 
A.min(ij)=min(R.squared(ij),R.squared(ji)),
A.ave(ij)=(R.squared(ij)+R.squared(ji))/2, 
A.max(ij)=max(R.squared(ij),R.squared(ji)).
For more information about natural cubic spline regression, please refer to functions &quot;ns&quot; and &quot;glm&quot;.</p>


<h3>Value</h3>

<p>An adjacency matrix of dimensions ncol(datExpr) times ncol(datExpr).</p>


<h3>Author(s)</h3>

<p>Lin Song, Steve Horvath
</p>


<h3>References</h3>

<p>Song L, Langfelder P, Horvath S Avoiding mutual information based co-expression measures (to appear).
</p>
<p>Horvath S (2011) Weighted Network Analysis. Applications in Genomics and Systems Biology. Springer Book. ISBN: 978-1-4419-8818-8
</p>


<h3>See Also</h3>

<p><code><a href="splines.html#topic+ns">ns</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate a data frame datE which contains 5 columns and 50 observations
m=50
x1=rnorm(m)
r=.5; x2=r*x1+sqrt(1-r^2)*rnorm(m)
r=.3; x3=r*(x1-.5)^2+sqrt(1-r^2)*rnorm(m)
x4=rnorm(m)
r=.3; x5=r*x4+sqrt(1-r^2)*rnorm(m)
datE=data.frame(x1,x2,x3,x4,x5)
#calculate adjacency by symmetrizing using max
A.max=adjacency.splineReg(datE, symmetrizationMethod="max")
A.max
#calculate adjacency by symmetrizing using max
A.mean=adjacency.splineReg(datE, symmetrizationMethod="mean")
A.mean
# output the unsymmetrized pairwise model fitting indices R.squared 
R.squared=adjacency.splineReg(datE, symmetrizationMethod="none")
R.squared
</code></pre>

<hr>
<h2 id='AFcorMI'>Prediction of Weighted Mutual Information Adjacency Matrix by Correlation
</h2><span id='topic+AFcorMI'></span>

<h3>Description</h3>

<p>AFcorMI computes a predicted weighted mutual information adjacency matrix from a given
correlation matrix.</p>


<h3>Usage</h3>

<pre><code class='language-R'>AFcorMI(r, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AFcorMI_+3A_r">r</code></td>
<td>

<p>a symmetric correlation matrix with values from -1 to 1.
</p>
</td></tr>
<tr><td><code id="AFcorMI_+3A_m">m</code></td>
<td>

<p>number of observations from which the correlation was calcuated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a one-to-one prediction when we consider correlation as unsigned. The prediction
corresponds to the <code>AdjacencyUniversalVersion2</code> discussed in the help file for  the function
<code><a href="#topic+mutualInfoAdjacency">mutualInfoAdjacency</a></code>. For more information
about the generation and features of the predicted mutual information adjacency, please refer to the function
<code><a href="#topic+mutualInfoAdjacency">mutualInfoAdjacency</a></code>.
</p>


<h3>Value</h3>

<p>A matrix with the same size as the input correlation matrix, containing the predicted mutual information of
type  <code>AdjacencyUniversalVersion2</code>.
</p>


<h3>Author(s)</h3>

<p>Steve Horvath, Lin Song, Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mutualInfoAdjacency">mutualInfoAdjacency</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate a data frame datE which contains 5 columns and 50 observations
m=50
x1=rnorm(m)
r=.5; x2=r*x1+sqrt(1-r^2)*rnorm(m)
r=.3; x3=r*(x1-.5)^2+sqrt(1-r^2)*rnorm(m)
x4=rnorm(m)
r=.3; x5=r*x4+sqrt(1-r^2)*rnorm(m)
datE=data.frame(x1,x2,x3,x4,x5)
#calculate predicted AUV2
cor.data=cor(datE, use="p")
AUV2=AFcorMI(r=cor.data, m=nrow(datE))

</code></pre>

<hr>
<h2 id='alignExpr'> Align expression data with given vector </h2><span id='topic+alignExpr'></span>

<h3>Description</h3>

<p>Multiplies genes (columns) in given expression data such that their correlation with given reference
vector is non-negative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alignExpr(datExpr, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="alignExpr_+3A_datexpr">datExpr</code></td>
<td>
<p> expression data to be aligned. A data frame with columns corresponding to genes and
rows to samples. </p>
</td></tr>
<tr><td><code id="alignExpr_+3A_y">y</code></td>
<td>
<p> reference vector of length equal the number of samples (rows) in <code>datExpr</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function basically multiplies each column in <code>datExpr</code> by the sign of its correlation with
<code>y</code>. If <code>y</code> is not given, the first column in <code>datExpr</code> will be used as the reference
vector.
</p>


<h3>Value</h3>

<p>A data frame containing the aligned expression data, of the same dimensions as the input data frame.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>

<hr>
<h2 id='allocateJobs'>
Divide tasks among workers
</h2><span id='topic+allocateJobs'></span>

<h3>Description</h3>

<p>This function calculates an even splitting of a given number of tasks among a given number of workers
(threads).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allocateJobs(nTasks, nWorkers)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="allocateJobs_+3A_ntasks">nTasks</code></td>
<td>

<p>number of tasks to be divided
</p>
</td></tr>
<tr><td><code id="allocateJobs_+3A_nworkers">nWorkers</code></td>
<td>

<p>number of workers
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tasks are labeled consecutively 1,2,..., <code>nTasks</code>. The tasks are split in contiguous blocks as evenly
as possible. 
</p>


<h3>Value</h3>

<p>A list with one component per worker giving the task indices to be worked on by each worker. If there are
more workers than tasks, the tasks for the extra workers are 0-length numeric vectors. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>allocateJobs(10, 3);
allocateJobs(2,4);
</code></pre>

<hr>
<h2 id='allowWGCNAThreads'>
Allow and disable multi-threading for certain WGCNA calculations
</h2><span id='topic+allowWGCNAThreads'></span><span id='topic+enableWGCNAThreads'></span><span id='topic+disableWGCNAThreads'></span><span id='topic+WGCNAnThreads'></span>

<h3>Description</h3>

<p>These functions allow and disable multi-threading for WGCNA calculations that can optionally be
multi-threaded, which includes all functions using <code><a href="#topic+cor">cor</a></code>
or <code><a href="#topic+bicor">bicor</a></code> functions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allowWGCNAThreads(nThreads = NULL)

enableWGCNAThreads(nThreads = NULL)

disableWGCNAThreads()

WGCNAnThreads()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="allowWGCNAThreads_+3A_nthreads">nThreads</code></td>
<td>

<p>Number of threads to allow. If not given, the number of processors online (as reported by system
configuration) will be used. There appear to be some cases where the automatically-determined number is
wrong; please check the output to see that the number of threads makes sense. Except for testing and/or
torturing your system, the number of threads should be no more than the number of actual processors/cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>allowWGCNAThreads</code> enables parallel calculation within the compiled code in WGCNA, principally for
calculation of correlations in the presence of missing data. This function is now deprecated; use
<code>enableWGCNAThreads</code> instead.
</p>
<p><code>enableWGCNAThreads</code> enables parallel calculations within user-level R functions as well as within the
compiled code, and registers an
appropriate parallel calculation back-end for the operating system/platform. 
</p>
<p><code>disableWGCNAThreads</code> disables parallel processing. 
</p>
<p><code>WGCNAnThreads</code> returns the number of threads (parallel processes) that WGCNA is currently configured
to run with.
</p>


<h3>Value</h3>

<p><code>allowWGCNAThreads</code>,  <code>enableWGCNAThreads</code>, and <code>disableWGCNAThreads</code> return the 
maximum number of threads WGCNA calculations will be allowed to use.
</p>


<h3>Note</h3>

<p>Multi-threading within compiled code is not available on Windows; R code parallelization works on all
platforms. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='automaticNetworkScreening'> One-step automatic network gene screening </h2><span id='topic+automaticNetworkScreening'></span>

<h3>Description</h3>

<p>This function performs gene screening based on a given trait and gene network properties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>automaticNetworkScreening(
   datExpr, 
   y, 
   power = 6, 
   networkType = "unsigned", 
   detectCutHeight = 0.995,
   minModuleSize = min(20, ncol(as.matrix(datExpr))/2), 
   datME = NULL, 
   getQValues = TRUE, 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="automaticNetworkScreening_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame containing the expression data, columns corresponding to genes and rows to
samples </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_y">y</code></td>
<td>
<p> vector containing trait values for all samples in <code>datExpr</code></p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_power">power</code></td>
<td>
<p> soft thresholding power used in network construction </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_networktype">networkType</code></td>
<td>
<p> character string specifying network type. Allowed values are (unique abbreviations
of) <code>"unsigned"</code>, <code>"signed"</code>, <code>"hybrid"</code>. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> cut height of the gene hierarchical clustering dendrogram. See
<code>cutreeDynamic</code> for details. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size to be used in module detection procedure. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_datme">datME</code></td>
<td>
<p> optional specification of module eigengenes. A data frame whose columns are the module
eigengenes. If given, module analysis will not be performed. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_getqvalues">getQValues</code></td>
<td>
<p>logical: should q-values (local FDR) be calculated? </p>
</td></tr>
<tr><td><code id="automaticNetworkScreening_+3A_...">...</code></td>
<td>
<p>other arguments to the module identification function <code><a href="#topic+blockwiseModules">blockwiseModules</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Network screening is a method for identifying genes that have a high gene significance and are members
of important modules at the same time.
If <code>datME</code> is given, the function calls <code><a href="#topic+networkScreening">networkScreening</a></code> with the default
parameters. If <code>datME</code> is not given, module eigengenes are first calculated using network analysis
based on supplied parameters.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>networkScreening</code></td>
<td>
<p>a data frame containing results of the network screening procedure. See
<code><a href="#topic+networkScreening">networkScreening</a></code> for more details.</p>
</td></tr>
<tr><td><code>datME</code></td>
<td>
<p> calculated module eigengenes (or a copy of the input <code>datME</code>, if given).</p>
</td></tr>
<tr><td><code>hubGeneSignificance</code></td>
<td>
<p> hub gene significance for all calculated modules. See
<code><a href="#topic+hubGeneSignificance">hubGeneSignificance</a></code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+networkScreening">networkScreening</a></code>, <code><a href="#topic+hubGeneSignificance">hubGeneSignificance</a></code>,
<code><a href="#topic+networkScreening">networkScreening</a></code>, <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> </p>

<hr>
<h2 id='automaticNetworkScreeningGS'> One-step automatic network gene screening with external gene significance </h2><span id='topic+automaticNetworkScreeningGS'></span>

<h3>Description</h3>

<p>This function performs gene screening based on external gene significance and their network properties.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>automaticNetworkScreeningGS(
     datExpr, GS, 
     power = 6, networkType = "unsigned", 
     detectCutHeight = 0.995, minModuleSize = min(20, ncol(as.matrix(datExpr))/2), 
     datME = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="automaticNetworkScreeningGS_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame containing the expression data, columns corresponding to genes and rows to
samples </p>
</td></tr>
<tr><td><code id="automaticNetworkScreeningGS_+3A_gs">GS</code></td>
<td>
<p> vector containing gene significance for all genes given in <code>datExpr</code> </p>
</td></tr>
<tr><td><code id="automaticNetworkScreeningGS_+3A_power">power</code></td>
<td>
<p> soft thresholding power used in network construction </p>
</td></tr>
<tr><td><code id="automaticNetworkScreeningGS_+3A_networktype">networkType</code></td>
<td>
<p> character string specifying network type. Allowed values are (unique abbreviations
of) <code>"unsigned"</code>, <code>"signed"</code>, <code>"hybrid"</code>. </p>
</td></tr> 
<tr><td><code id="automaticNetworkScreeningGS_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> cut height of the gene hierarchical clustering dendrogram. See
<code>cutreeDynamic</code> for details. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreeningGS_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size to be used in module detection procedure. </p>
</td></tr>
<tr><td><code id="automaticNetworkScreeningGS_+3A_datme">datME</code></td>
<td>
<p> optional specification of module eigengenes. A data frame whose columns are the module
eigengenes. If given, module analysis will not be performed. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Network screening is a method for identifying genes that have a high gene significance and are members
of important modules at the same time. 
If <code>datME</code> is given, the function calls <code><a href="#topic+networkScreeningGS">networkScreeningGS</a></code> with the default
parameters. If <code>datME</code> is not given, module eigengenes are first calculated using network analysis
based on supplied parameters.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>networkScreening</code></td>
<td>
<p>a data frame containing results of the network screening procedure. See
<code><a href="#topic+networkScreeningGS">networkScreeningGS</a></code> for more details.</p>
</td></tr>
<tr><td><code>datME</code></td>
<td>
<p> calculated module eigengenes (or a copy of the input <code>datME</code>, if given).</p>
</td></tr>
<tr><td><code>hubGeneSignificance</code></td>
<td>
<p> hub gene significance for all calculated modules. See
<code><a href="#topic+hubGeneSignificance">hubGeneSignificance</a></code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+networkScreening">networkScreening</a></code>, <code><a href="#topic+hubGeneSignificance">hubGeneSignificance</a></code>,
<code><a href="#topic+networkScreening">networkScreening</a></code>, <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> </p>

<hr>
<h2 id='BD.getData'>
Various basic operations on <code>BlockwiseData</code> objects.
</h2><span id='topic+BD.actualFileNames'></span><span id='topic+BD.nBlocks'></span><span id='topic+BD.blockLengths'></span><span id='topic+BD.getMetaData'></span><span id='topic+BD.getData'></span><span id='topic+BD.checkAndDeleteFiles'></span>

<h3>Description</h3>

<p>These functions implement basic operations on <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> objects.
Blockwise here means
that the data is too large to be loaded or processed in one piece and is therefore split into blocks that can
be handled one by one in a divide-and-conquer manner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BD.actualFileNames(bwData)
BD.nBlocks(bwData)
BD.blockLengths(bwData)
BD.getMetaData(bwData, blocks = NULL, simplify = TRUE)
BD.getData(bwData, blocks = NULL, simplify = TRUE)
BD.checkAndDeleteFiles(bwData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BD.getData_+3A_bwdata">bwData</code></td>
<td>

<p>A <code>BlockwiseData</code> object.
</p>
</td></tr>
<tr><td><code id="BD.getData_+3A_blocks">blocks</code></td>
<td>

<p>Optional vector of integers specifying the blocks on which to execute the operation.
</p>
</td></tr>
<tr><td><code id="BD.getData_+3A_simplify">simplify</code></td>
<td>

<p>Logical: if the <code>blocks</code> argument above is of length 1, should the returned list be simplified by
removing the redundant outer <code>list</code> structure? 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several functions in this package use the concept of blockwise, or &quot;divide-and-conquer&quot;, analysis. The
BlockwiseData class is meant to hold the blockwise data, or all necessary information about blockwise data
that is saved in disk files. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>BD.actualFileNames</code></td>
<td>
<p>returns a vector of character strings giving the file names in which the files are
saved, or <code>NULL</code> if the data are held in-memory.</p>
</td></tr>
<tr><td><code>BD.nBlocks</code></td>
<td>
<p>returns the number of blocks in the input object.</p>
</td></tr>
<tr><td><code>BD.blockLengths</code></td>
<td>
<p>returns the block lengths (results of applying <code><a href="base.html#topic+length">length</a></code> to the data in
each block).</p>
</td></tr>
<tr><td><code>BD.getMetaData</code></td>
<td>
<p>returns a list with one component per block. Each component is in turn a list
containing the stored meta-data for the corresponding block. If <code>blocks</code> is of length 1 and
<code>simplify</code> is <code>TRUE</code>, the outer (redundant) <code>list</code> is removed.</p>
</td></tr>
<tr><td><code>BD.getData</code></td>
<td>
<p>returns a list with one component per block. Each component is in turn a list
containing the stored data for the corresponding block. If <code>blocks</code> is of length 1 and
<code>simplify</code> is <code>TRUE</code>, the outer (redundant) <code>list</code> is removed.</p>
</td></tr>
<tr><td><code>BD.checkAndDeleteFiles</code></td>
<td>
<p>deletes the files referenced in the input <code>bwData</code> if they exist.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The definition of <code>BlockwiseData</code> and the functions here 
should be considered experimental and may change in
the future.</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>Definition of and other functions on <code><a href="#topic+BlockwiseData">BlockwiseData</a></code>:
</p>
<p><code><a href="#topic+newBlockwiseData">newBlockwiseData</a></code> for creating new <code>BlockwiseData</code> objects;
</p>
<p><code><a href="#topic+mergeBlockwiseData">mergeBlockwiseData</a></code> for merging blockwise data structure;
</p>
<p><code><a href="#topic+addBlockToBlockwiseData">addBlockToBlockwiseData</a></code> for adding a new block to existing blockwise data;
</p>

<hr>
<h2 id='bicor'> Biweight Midcorrelation </h2><span id='topic+bicor'></span>

<h3>Description</h3>

<p>Calculate biweight midcorrelation efficiently for matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicor(x, y = NULL, 
      robustX = TRUE, robustY = TRUE, 
      use = "all.obs", 
      maxPOutliers = 1,
      quick = 0,
      pearsonFallback = "individual",
      cosine = FALSE, 
      cosineX = cosine,
      cosineY = cosine,
      nThreads = 0, 
      verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicor_+3A_x">x</code></td>
<td>
<p> a vector or matrix-like numeric object </p>
</td></tr>
<tr><td><code id="bicor_+3A_y">y</code></td>
<td>
<p> a vector or matrix-like numeric object </p>
</td></tr>
<tr><td><code id="bicor_+3A_robustx">robustX</code></td>
<td>
<p> use robust calculation for <code>x</code>?</p>
</td></tr>
<tr><td><code id="bicor_+3A_robusty">robustY</code></td>
<td>
<p> use robust calculation for <code>y</code>?</p>
</td></tr>
<tr><td><code id="bicor_+3A_use">use</code></td>
<td>
<p> specifies handling of <code>NA</code>s. One of (unique abbreviations of) &quot;all.obs&quot;,
&quot;pairwise.complete.obs&quot;. </p>
</td></tr>
<tr><td><code id="bicor_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> specifies the maximum percentile of data that can be considered outliers on either
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>  
<tr><td><code id="bicor_+3A_quick">quick</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="bicor_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation should revert to Pearson when median
absolute deviation (mad) is zero. Recongnized values are (abbreviations of) 
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation. 
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad.
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). </p>
</td></tr>
<tr><td><code id="bicor_+3A_cosine">cosine</code></td>
<td>
<p> logical: calculate cosine biweight midcorrelation? 
Cosine bicorrelation is similar to standard bicorrelation but the median subtraction is not performed. </p>
</td></tr>
<tr><td><code id="bicor_+3A_cosinex">cosineX</code></td>
<td>
<p> logical: use the cosine calculation for <code>x</code>? This setting does not affect <code>y</code> 
and can be used to give a hybrid cosine-standard bicorrelation. </p>
</td></tr>
<tr><td><code id="bicor_+3A_cosiney">cosineY</code></td>
<td>
<p> logical: use the cosine calculation for <code>y</code>? This setting does not affect <code>x</code>
and can be used to give a hybrid cosine-standard bicorrelation. </p>
</td></tr>
<tr><td><code id="bicor_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. 
Note that this option does not affect what is usually the most expensive part of the
calculation, namely the matrix multiplication. The matrix multiplication is carried out by BLAS routines provided by R;
these can be sped up by installing a fast BLAS and making R use it.</p>
</td></tr>
<tr><td><code id="bicor_+3A_verbose">verbose</code></td>
<td>
<p> if non-zero, the underlying C function will print some diagnostics.</p>
</td></tr>
<tr><td><code id="bicor_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements biweight midcorrelation calculation (see references). If <code>y</code> is not
supplied, midcorrelation of columns of <code>x</code> will be calculated; otherwise, the midcorrelation between
columns of <code>x</code> and <code>y</code> will be calculated. Thus, <code>bicor(x)</code> is equivalent to
<code>bicor(x,x)</code> but is more efficient. 
</p>
<p>The options <code>robustX</code>, <code>robustY</code> allow the user to revert the calculation to standard
correlation calculation. This is important, for example, if any of the variables is binary
(or, more generally, discrete) as in such cases the robust methods produce meaningless results. 
If both <code>robustX</code>, <code>robustY</code> are set to <code>FALSE</code>, the function calculates the
standard Pearson correlation (but is slower than the function <code><a href="#topic+cor">cor</a></code>).
</p>
<p>The argument <code>quick</code> specifies the precision of handling of missing data in the correlation
calculations. Value <code>quick = 0</code> will cause all
calculations to be executed accurately, which may be significantly slower than calculations without
missing data. Progressively higher values will speed up the
calculations but introduce progressively larger errors. Without missing data, all column meadians and
median absolute deviations (MADs) can be pre-calculated before the covariances are calculated. When
missing data are present, 
exact calculations require the column medians and MADs to be calculated for each covariance. The
approximate calculation uses the pre-calculated median and MAD and simply ignores missing data in the
covariance calculation. If the number of missing data is high, the pre-calculated medians and MADs may
be very different from the actual ones, thus potentially introducing large errors.
The <code>quick</code> value times the
number of rows specifies the maximum difference in the
number of missing entries for median and MAD calculations on the one hand and covariance on the other
hand that will be tolerated before a recalculation is triggered. The hope is that if only a few missing
data are treated approximately, the error introduced will be small but the potential speedup can be
significant.
</p>
<p>The choice <code>"all"</code> for <code>pearsonFallback</code> is not fully implemented in the sense that there are
rare but possible cases in which the calculation is equivalent to <code>"individual"</code>. This may happen if
the <code>use</code> option is set to <code>"pairwise.complete.obs"</code> and
the missing data are arranged such that each individual mad is non-zero, but when two columns are analyzed
together, the missing data from both columns may make a mad zero. In such a case, the calculation is treated
as Pearson, but other columns will be treated as bicor. 
</p>


<h3>Value</h3>

<p>A matrix of biweight midcorrelations. Dimnames on the result are set appropriately.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>References</h3>

 
<p>Peter Langfelder, Steve Horvath (2012)
Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software, 46(11), 1-17.
<a href="https://www.jstatsoft.org/v46/i11/">https://www.jstatsoft.org/v46/i11/</a>
</p>
<p>&quot;Introduction to Robust Estimation and Hypothesis Testing&quot;, Rand Wilcox, Academic Press, 1997.
</p>
<p>&quot;Data Analysis and Regression: A Second Course in Statistics&quot;, Mosteller and Tukey, Addison-Wesley,
1977, pp. 203-209. 
</p>

<hr>
<h2 id='bicorAndPvalue'>
Calculation of biweight midcorrelations and associated p-values
</h2><span id='topic+bicorAndPvalue'></span>

<h3>Description</h3>

<p>A faster, one-step calculation of Student correlation p-values for multiple biweight 
midcorrelations, properly taking
into account the actual number of observations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicorAndPvalue(x, y = NULL, 
             use = "pairwise.complete.obs", 
             alternative = c("two.sided", "less", "greater"),
             ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicorAndPvalue_+3A_x">x</code></td>
<td>

<p>a vector or a matrix
</p>
</td></tr>
<tr><td><code id="bicorAndPvalue_+3A_y">y</code></td>
<td>

<p>a vector or a matrix. If <code>NULL</code>, the correlation of columns of <code>x</code> will be calculated.
</p>
</td></tr>
<tr><td><code id="bicorAndPvalue_+3A_use">use</code></td>
<td>

<p>determines handling of missing data. See <code><a href="#topic+bicor">bicor</a></code> for details.
</p>
</td></tr>
<tr><td><code id="bicorAndPvalue_+3A_alternative">alternative</code></td>
<td>

<p>specifies the alternative hypothesis and must be (a unique abbreviation of) one of
<code>"two.sided"</code>, <code>"greater"</code> or <code>"less"</code>.
the initial letter.  <code>"greater"</code> corresponds to positive
association, <code>"less"</code> to negative association.
</p>
</td></tr>
<tr><td><code id="bicorAndPvalue_+3A_...">...</code></td>
<td>

<p>other arguments to the function <code><a href="#topic+bicor">bicor</a></code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the biweight midcorrelations of a matrix or of two matrices 
and the corresponding Student p-values.
The output is not as full-featured as <code><a href="stats.html#topic+cor.test">cor.test</a></code>, but can work with matrices as input.
</p>


<h3>Value</h3>

<p>A list with the following components, each a marix:
</p>
<table role = "presentation">
<tr><td><code>bicor</code></td>
<td>
<p>the calculated correlations</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the Student p-values corresponding to the calculated correlations</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Fisher transform of the calculated correlations</p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>Student t statistics of the calculated correlations</p>
</td></tr>
<tr><td><code>nObs</code></td>
<td>
<p>Numbers of observations for the correlation, p-values etc.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder and Steve Horvath 
</p>


<h3>References</h3>

<p>Peter Langfelder, Steve Horvath (2012)
Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software, 46(11), 1-17.
<a href="https://www.jstatsoft.org/v46/i11/">https://www.jstatsoft.org/v46/i11/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bicor">bicor</a></code> for calculation of correlations only;
</p>
<p><code><a href="stats.html#topic+cor.test">cor.test</a></code> for another function for significance test of correlations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate random data with non-zero correlation
set.seed(1);
a = rnorm(100);
b = rnorm(100) + a;
x = cbind(a, b);
# Call the function and display all results
bicorAndPvalue(x)
# Set some components to NA
x[c(1:4), 1] = NA
corAndPvalue(x)
# Note that changed number of observations.
</code></pre>

<hr>
<h2 id='bicovWeights'>
Weights used in biweight midcovariance
</h2><span id='topic+bicovWeights'></span><span id='topic+bicovWeightFactors'></span><span id='topic+bicovWeightsFromFactors'></span>

<h3>Description</h3>

<p>Calculation of weights and the intermediate weight factors 
used in the calculation of biweight midcovariance and midcorrelation. The
weights are designed such that outliers get smaller weights; the weights become zero for data points more than
9 median absolute deviations from the median.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bicovWeights(
   x, 
   pearsonFallback = TRUE, 
   maxPOutliers = 1,
   outlierReferenceWeight = 0.5625,
   defaultWeight = 0)

bicovWeightFactors(
   x, 
   pearsonFallback = TRUE, 
   maxPOutliers = 1, 
   outlierReferenceWeight = 0.5625,
   defaultFactor = NA)

bicovWeightsFromFactors(
   u, 
   defaultWeight = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bicovWeights_+3A_x">x</code></td>
<td>

<p>A vector or a two-dimensional array (matrix or data frame). 
If two-dimensional, the weights will be calculated separately on each column.
</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_u">u</code></td>
<td>

<p>A vector or matrix of weight factors, usually calculated by <code>bicovWeightFactors</code>.
</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_pearsonfallback">pearsonFallback</code></td>
<td>

<p>Logical: if the median absolute deviation is zero, should standard deviation be substituted?
</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_maxpoutliers">maxPOutliers</code></td>
<td>

<p>Optional specification of the maximum proportion of outliers, i.e., data with weights equal to
<code>outlierReferenceWeight</code> below.
</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_outlierreferenceweight">outlierReferenceWeight</code></td>
<td>
<p>A number between 0 and 1 specifying what is to be considered an outlier when
calculating the proportion of outliers.</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_defaultweight">defaultWeight</code></td>
<td>
<p>Value used for weights that correspond to a finite <code>x</code> but the weights themselves
would not be finite, for example, when a column in <code>x</code> is constant.</p>
</td></tr>
<tr><td><code id="bicovWeights_+3A_defaultfactor">defaultFactor</code></td>
<td>
<p>Value used for factors that correspond to a finite <code>x</code> but the weights themselves
would not be finite, for example, when a column in <code>x</code> is constant.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are based on Equations (1) and (3) in Langfelder and Horvath (2012). The weight factor is denoted
<code>u</code> in that article.
</p>
<p>Langfelder and Horvath (2012) also describe the Pearson fallback and 
maximum proportion of outliers in detail. For a full
discussion of the biweight midcovariance and midcorrelation, see Wilcox (2005).
</p>


<h3>Value</h3>

<p>A vector or matrix of the same dimensions as the input <code>x</code> giving the bisquare weights
(<code>bicovWeights</code> and <code>bicovWeightsFromFactors</code>) or the bisquare factors
(<code>bicovWeightFactors</code>).
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>Langfelder P, Horvath S (2012) Fast R Functions for Robust Correlations and Hierarchical Clustering Journal of
Statistical Software 46(11) 1-17 PMID: 23050260 PMCID: PMC3465711 
Wilcox RR (2005). Introduction to Robust Estimation and Hypothesis Testing. 2nd edition.
Academic Press, Section 9.3.8, page 399 as well as Section 3.12.1, page 83. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bicor">bicor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(100);
x[1] = 10;
plot(x, bicovWeights(x));
</code></pre>

<hr>
<h2 id='binarizeCategoricalColumns'>
Turn categorical columns into sets of binary indicators 
</h2><span id='topic+binarizeCategoricalColumns'></span><span id='topic+binarizeCategoricalColumns.pairwise'></span><span id='topic+binarizeCategoricalColumns.forRegression'></span><span id='topic+binarizeCategoricalColumns.forPlots'></span>

<h3>Description</h3>

<p>Given a data frame with (some) categorical columns, 
this function creates a set of indicator variables for the various possible
sets of levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binarizeCategoricalColumns(
   data,
   convertColumns = NULL,
   considerColumns = NULL,
   maxOrdinalLevels = 3,
   levelOrder = NULL,
   minCount = 3,
   val1 = 0, val2 = 1,
   includePairwise = FALSE,
   includeLevelVsAll = TRUE,
   dropFirstLevelVsAll = TRUE,
   dropUninformative = TRUE,
   includePrefix = TRUE,
   prefixSep = ".",
   nameForAll = "all",
   levelSep = NULL,
   levelSep.pairwise = if (length(levelSep)==0) ".vs." else levelSep,
   levelSep.vsAll = if (length(levelSep)==0) 
              (if (nameForAll=="") "" else ".vs.") else levelSep,
   checkNames = FALSE,
   includeLevelInformation = FALSE)

binarizeCategoricalColumns.pairwise(
   data, 
   maxOrdinalLevels = 3,
   convertColumns = NULL,
   considerColumns = NULL,
   levelOrder = NULL,
   val1 = 0, val2 = 1, 
   includePrefix = TRUE,
   prefixSep = ".", 
   levelSep = ".vs.",
   checkNames = FALSE)

binarizeCategoricalColumns.forRegression(
   data, 
   maxOrdinalLevels = 3,
   convertColumns = NULL,
   considerColumns = NULL,
   levelOrder = NULL,
   val1 = 0, val2 = 1,
   includePrefix = TRUE,
   prefixSep = ".",
   checkNames = TRUE)

binarizeCategoricalColumns.forPlots(
   data, 
   maxOrdinalLevels = 3,
   convertColumns = NULL,
   considerColumns = NULL,
   levelOrder = NULL,
   val1 = 0, val2 = 1,
   includePrefix = TRUE,
   prefixSep = ".",
   checkNames = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binarizeCategoricalColumns_+3A_data">data</code></td>
<td>

<p>A data frame.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_convertcolumns">convertColumns</code></td>
<td>

<p>Optional character vector giving the column names of the columns to be converted. See <code>maxOrdinalLevels</code>
below.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_considercolumns">considerColumns</code></td>
<td>

<p>Optional character vector giving the column names of columns that should be looked at and possibly converted.
If not given, all columns will be considered. See <code>maxOrdinalLevels</code> below. 
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_maxordinallevels">maxOrdinalLevels</code></td>
<td>

<p>When <code>convertColumns</code> above is <code>NULL</code>, the function looks at all columns in <code>considerColumns</code>
and converts all non-numeric columns and those numeric columns that have at most <code>maxOrdinalLevels</code>
unique values. A column is considered numeric if its storage mode is numeric or if it is character and all
entries with the expception of &quot;NA&quot;, &quot;NULL&quot; and &quot;NO DATA&quot; represent valid numbers.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_levelorder">levelOrder</code></td>
<td>

<p>Optional list giving the ordering of levels (unique values) in each of the converted columns. Best used in
conjunction with <code>convertColumns</code>.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_mincount">minCount</code></td>
<td>

<p>Levels of <code>x</code> for which there are fewer than <code>minCount</code> elements will be ignored.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_val1">val1</code></td>
<td>

<p>Value for the lower level in binary comparisons.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_val2">val2</code></td>
<td>

<p>Value for the higher level in binary comparisons.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_includepairwise">includePairwise</code></td>
<td>

<p>Logical: should pairwise binary indicators be included? For each pair of levels, the indicator is <code>val1</code>
for the lower level (earlier in <code>levelOrder</code>), <code>val2</code> for the higher level and <code>NA</code> otherwise.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_includelevelvsall">includeLevelVsAll</code></td>
<td>

<p>Logical: should binary indicators for each level be included? The indicator is <code>val2</code> where <code>x</code>
equals the level and <code>val1</code> otherwise.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_dropfirstlevelvsall">dropFirstLevelVsAll</code></td>
<td>

<p>Logical: should the column representing first level vs. all be dropped? This makes the resulting matrix of
indicators usable for regression models.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_dropuninformative">dropUninformative</code></td>
<td>

<p>Logical: should uninformative (constant) columns be dropped?
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_includeprefix">includePrefix</code></td>
<td>

<p>Logical: should the column name of the binarized column be included in column names of the output? See
details.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_prefixsep">prefixSep</code></td>
<td>

<p>Separator of column names and level names in column names of the output. See details.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_nameforall">nameForAll</code></td>
<td>
<p> Character string that represents &quot;all others&quot; in the column names of indicators of level vs. all
others.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_levelsep">levelSep</code></td>
<td>

<p>Separator for levels to be used in column names of the output. If <code>NULL</code>, pairwise and level vs. all indicators will
use different level separators set by <code>levelSep.pairwise</code> and <code>levelSep.vsAll</code>.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_levelsep.pairwise">levelSep.pairwise</code></td>
<td>

<p>Separator for levels to be used in column names for pairwise indicators in the output. 
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_levelsep.vsall">levelSep.vsAll</code></td>
<td>

<p>Separator for levels to be used in column names for level vs. all indicators in the output.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_checknames">checkNames</code></td>
<td>

<p>Logical: should the names of the output be made into syntactically correct R language names?
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalColumns_+3A_includelevelinformation">includeLevelInformation</code></td>
<td>

<p>Logical: should information about which levels are represented by which columns be included in the attributes
of the output?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>binarizeCategoricalColumns</code> is the most general function, the rest are convenience wrappers that set some of the
options to achieve the following:
</p>
<p><code>binarizeCategoricalColumns.pairwise</code> returns only pairwise (level vs. level) binary indicators.
</p>
<p><code>binarizeCategoricalColumns.forRegression</code> returns only level vs. all others binary indicators, with the first
(according to <code>levelOrder</code>) level
vs. all removed. This is essentially the same as would be returned by <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> except for the column
representing intercept.
</p>
<p><code>binarizeCategoricalColumns.forPlots</code> returns only level vs. all others binary indicators and keeps them all.
</p>
<p>The columns to be converted are identified as follows. If <code>considerColumns</code> is given, columns not
contained in it will not be converted, even if they are included in <code>convertColumns</code>. 
</p>
<p>If <code>convertColumns</code> is given, those columns will
be converted (except any not contained in non-empty <code>considerColumns</code>). If <code>convertColumns</code> 
is <code>NULL</code>, the function converts columns that are not numeric (as reported by <code><a href="base.html#topic+is.numeric">is.numeric</a></code>) and those
numeric columns that have at most <code>maxOrdinalValues</code> unique non-missing values. 
</p>
<p>The function creates two types of indicators. The first is one level (unique value) of <code>x</code> vs. all
others, i.e., for a given level, the indicator is <code>val2</code> (usually 1) for all elements of <code>x</code> that
equal the level, and <code>val1</code> (usually 0)
otherwise. Column names for these indicators are the concatenation of <code>namePrefix</code>, the level,
<code>nameSep</code> and <code>nameForAll</code>. The level vs. all indicators are created for all levels that have at
least <code>minCounts</code> samples, are present in <code>levelOrder</code> (if it is non-NULL) and are not included in
<code>ignore</code>.
</p>
<p>The second type of indicator encodes binary comparisons. For each pair of levels (both with at least
<code>minCount</code> samples), the indicator is <code>val2</code> (usually 1) for the higher level and <code>val1</code>
(usually 0) for the lower level. The level order is given by <code>levelOrder</code> (which defaults to the sorted
levels of <code>x</code>), assumed to be sorted in increasing order. All levels with at least <code>minCount</code>
samples that are included in <code>levelOrder</code> and not included in <code>ignore</code> are included.
</p>
<p>Internally, the function calls <code><a href="#topic+binarizeCategoricalVariable">binarizeCategoricalVariable</a></code> for each column that is converted.
</p>


<h3>Value</h3>

<p>A data frame in which the converted columns have been replaced by sets of binarized indicators. When
<code>includeLevelInformation</code> is
<code>TRUE</code>, the attribute <code>includedLevels</code> is a table with one column per output column and two rows,
giving the two levels (unique values of x) represented by the column.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2);
x = data.frame(a = sample(c("A", "B", "C"), 15, replace = TRUE),
               b = sample(c(1:3), 15, replace = TRUE));
out = binarizeCategoricalColumns(x, includePairwise = TRUE, includeLevelVsAll = TRUE,
                     includeLevelInformation = TRUE);
data.frame(x, out);
attr(out, "includedLevels")

</code></pre>

<hr>
<h2 id='binarizeCategoricalVariable'>
Turn a categorical variable into a set of binary indicators
</h2><span id='topic+binarizeCategoricalVariable'></span>

<h3>Description</h3>

<p>Given a categorical variable, this function creates a set of indicator variables for the various possible
sets of levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binarizeCategoricalVariable(
   x,
   levelOrder = NULL,
   ignore = NULL,
   minCount = 3,
   val1 = 0, val2 = 1,
   includePairwise = TRUE,
   includeLevelVsAll = FALSE,
   dropFirstLevelVsAll = FALSE,
   dropUninformative = TRUE,
   namePrefix = "",
   levelSep = NULL,
   nameForAll = "all",
   levelSep.pairwise = if (length(levelSep)==0) ".vs." else levelSep,
   levelSep.vsAll = if (length(levelSep)==0) 
                       (if (nameForAll=="") "" else ".vs.") else levelSep,
   checkNames = FALSE,
   includeLevelInformation = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binarizeCategoricalVariable_+3A_x">x</code></td>
<td>

<p>A vector with categorical values.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_levelorder">levelOrder</code></td>
<td>

<p>Optional specification of the levels (unique values) of <code>x</code>. Defaults to sorted unique values of
<code>x</code>, but can be used to only include a subset of the existing levels as well as to specify the order of
the levels in the output variables.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_ignore">ignore</code></td>
<td>

<p>Optional specification of levels of <code>x</code> that are to be ignored. Note that the levels are ignored only when
deciding which variables to include in the output; the samples with these values of <code>x</code> will be included
in &quot;all&quot; in indicators of level vs. all others.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_mincount">minCount</code></td>
<td>

<p>Levels of <code>x</code> for which there are fewer than <code>minCount</code> elements will be ignored.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_val1">val1</code></td>
<td>

<p>Value for the lower level in binary comparisons.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_val2">val2</code></td>
<td>

<p>Value for the higher level in binary comparisons.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_includepairwise">includePairwise</code></td>
<td>

<p>Logical: should pairwise binary indicators be included? For each pair of levels, the indicator is <code>val1</code>
for the lower level (earlier in <code>levelOrder</code>), <code>val2</code> for the higher level and <code>NA</code> otherwise.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_includelevelvsall">includeLevelVsAll</code></td>
<td>

<p>Logical: should binary indicators for each level be included? The indicator is <code>val2</code> where <code>x</code>
equals the level and <code>val1</code> otherwise. 
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_dropfirstlevelvsall">dropFirstLevelVsAll</code></td>
<td>

<p>Logical: should the column representing first level vs. all be dropped? This makes the resulting matrix of
indicators usable for regression models. 
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_dropuninformative">dropUninformative</code></td>
<td>

<p>Logical: should uninformative (constant) columns be dropped?
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_nameprefix">namePrefix</code></td>
<td>

<p>Prefix to be used in column names of the output.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_nameforall">nameForAll</code></td>
<td>

<p>When naming columns that represent a level vs. all others, <code>nameForAll</code> will be used to represent all
others.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_levelsep">levelSep</code></td>
<td>

<p>Separator for levels to be used in column names of the output. If <code>NULL</code>, pairwise and level vs. all indicators will
use different level separators set by <code>levelSep.pairwise</code> and <code>levelSep.vsAll</code>.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_levelsep.pairwise">levelSep.pairwise</code></td>
<td>

<p>Separator for levels to be used in column names for pairwise indicators in the output.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_levelsep.vsall">levelSep.vsAll</code></td>
<td>

<p>Separator for levels to be used in column names for level vs. all indicators in the output.
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_checknames">checkNames</code></td>
<td>

<p>Logical: should the names of the output be made into syntactically correct R language names?
</p>
</td></tr>
<tr><td><code id="binarizeCategoricalVariable_+3A_includelevelinformation">includeLevelInformation</code></td>
<td>

<p>Logical: should information about which levels are represented by which columns be included in the attributes
of the output?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates two types of indicators. The first is one level (unique value) of <code>x</code> vs. all
others, i.e., for a given level, the indicator is <code>val2</code> (usually 1) for all elements of <code>x</code> that
equal the level, and <code>val1</code> (usually 0) 
otherwise. Column names for these indicators are the concatenation of <code>namePrefix</code>, the level,
<code>nameSep</code> and <code>nameForAll</code>. The level vs. all indicators are created for all levels that have at
least <code>minCounts</code> samples, are present in <code>levelOrder</code> (if it is non-NULL) and are not included in
<code>ignore</code>.
</p>
<p>The second type of indicator encodes binary comparisons. For each pair of levels (both with at least
<code>minCount</code> samples), the indicator is <code>val2</code> (usually 1) for the higher level and <code>val1</code>
(usually 0) for the lower level. The level order is given by <code>levelOrder</code> (which defaults to the sorted
levels of <code>x</code>), assumed to be sorted in increasing order. All levels with at least <code>minCount</code>
samples that are included in <code>levelOrder</code> and not included in <code>ignore</code> are included.
</p>


<h3>Value</h3>

<p>A matrix containing the indicators variabels, one in each column. When <code>includeLevelInformation</code> is
<code>TRUE</code>, the attribute <code>includedLevels</code> is a table with one column per output column and two rows,
giving the two levels (unique values of x) represented by the column.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>Variations and wrappers for this function:
<code>binarizeCategoricalColumns</code> for binarizing several columns of a matrix or data frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2);
x = sample(c("A", "B", "C"), 15, replace = TRUE);
out = binarizeCategoricalVariable(x, includePairwise = TRUE, includeLevelVsAll = TRUE);
data.frame(x, out);
attr(out, "includedLevels")
# A different naming for level vs. all columns
binarizeCategoricalVariable(x, includeLevelVsAll = TRUE, nameForAll = "");
</code></pre>

<hr>
<h2 id='blockSize'>
Attempt to calculate an appropriate block size to maximize efficiency of block-wise calcualtions.
</h2><span id='topic+blockSize'></span>

<h3>Description</h3>

<p>The function uses a rather primitive way to estimate available memory and use it to suggest a block size
appropriate for the many block-by-block calculations in this package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockSize(
   matrixSize, 
   rectangularBlocks = TRUE, 
   maxMemoryAllocation = NULL, 
   overheadFactor = 3);
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blockSize_+3A_matrixsize">matrixSize</code></td>
<td>
<p>the relevant dimension (usually the number of columns) 
of the matrix that is to be operated on block-by-block.
</p>
</td></tr>
<tr><td><code id="blockSize_+3A_rectangularblocks">rectangularBlocks</code></td>
<td>
<p>logical indicating whether the bocks of data are rectangular (of size
<code>blockSize</code> times <code>matrixSize</code>) or square (of size <code>blockSize</code> times <code>blockSize</code>).</p>
</td></tr>
<tr><td><code id="blockSize_+3A_maxmemoryallocation">maxMemoryAllocation</code></td>
<td>
<p>maximum desired memory allocation, in bytes. Should not exceed 2GB or total
installed RAM (whichever is greater) on 32-bit systems, while on 64-bit systems it should not exceed the
total installed RAM. If not supplied, the available memory will be estimated internally.
</p>
</td></tr>
<tr><td><code id="blockSize_+3A_overheadfactor">overheadFactor</code></td>
<td>
<p>overhead factor for the memory use by R. Recommended values are between 2 (for
simple calculations) and 4 or more for complicated calculations where intermediate results (for which R must
also allocate memory) take up a lot of space.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiple functions within the WGCNA package use a divide-and-conquer (also known as block-by-block, or
block-wise) approach to handling large data sets.
This function is meant to assist in choosing a suitable block size, given the size of the data and the
available memory.
</p>
<p>If the entire expected result fits
into the allowed memory (after taking into account the expected overhead), the returned block size will
equal the input <code>matrixSize</code>.
</p>
<p>The internal estimation of available memory works by returning the size of largest successfully allocated
block of memory. It is hoped that this will lead to reasonable results but some operating systems may
actually allocate more than is available. It is therefore preferable that the user specifies the available
memory by hand.
</p>


<h3>Value</h3>

<p>A single integer giving the suggested block size, or <code>matrixSize</code> if the entire calculation is
expected to fit into memory in one piece.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Suitable blocks for handling 30,000 genes within 2GB (=2^31 bytes) of memory
blockSize(30000, rectangularBlocks = TRUE, maxMemoryAllocation = 2^31)
</code></pre>

<hr>
<h2 id='blockwiseConsensusModules'>Find consensus modules across several datasets.</h2><span id='topic+blockwiseConsensusModules'></span>

<h3>Description</h3>

<p>Perform network construction and consensus module detection across several datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockwiseConsensusModules(
     multiExpr, 

     # Data checking options

     checkMissingData = TRUE,

     # Blocking options

     blocks = NULL, 
     maxBlockSize = 5000, 
     blockSizePenaltyPower = 5,
     nPreclusteringCenters = NULL,
     randomSeed = 54321,

     # TOM precalculation arguments, if available

     individualTOMInfo = NULL,
     useIndivTOMSubset = NULL,

     # Network construction arguments: correlation options

     corType = "pearson",
     maxPOutliers = 1,
     quickCor = 0,
     pearsonFallback = "individual", 
     cosineCorrelation = FALSE,

     # Adjacency function options

     power = 6, 
     networkType = "unsigned", 
     checkPower = TRUE,
     replaceMissingAdjacencies = FALSE,

     # Topological overlap options

     TOMType = "unsigned",
     TOMDenom = "min",
     suppressNegativeTOM = FALSE,

     # Save individual TOMs?

     saveIndividualTOMs = TRUE,
     individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",

     # Consensus calculation options: network calibration

     networkCalibration = c("single quantile", "full quantile", "none"),

     # Simple quantile calibration options

     calibrationQuantile = 0.95,
     sampleForCalibration = TRUE, sampleForCalibrationFactor = 1000,
     getNetworkCalibrationSamples = FALSE,

     # Consensus definition

     consensusQuantile = 0,
     useMean = FALSE,
     setWeights = NULL,

     # Saving the consensus TOM

     saveConsensusTOMs = FALSE,
     consensusTOMFilePattern = "consensusTOM-block.%b.RData",

     # Internal handling of TOMs

     useDiskCache = TRUE, chunkSize = NULL,
     cacheBase = ".blockConsModsCache",
     cacheDir = ".",

     # Alternative consensus TOM input from a previous calculation 

     consensusTOMInfo = NULL,

     # Basic tree cut options 

     # Basic tree cut options 

     deepSplit = 2, 
     detectCutHeight = 0.995, minModuleSize = 20,
     checkMinModuleSize = TRUE,

     # Advanced tree cut opyions

     maxCoreScatter = NULL, minGap = NULL,
     maxAbsCoreScatter = NULL, minAbsGap = NULL,
     minSplitHeight = NULL, minAbsSplitHeight = NULL,
     useBranchEigennodeDissim = FALSE,
     minBranchEigennodeDissim = mergeCutHeight,
     stabilityLabels = NULL,
     minStabilityDissim = NULL,

     pamStage = TRUE,  pamRespectsDendro = TRUE,

     # Gene reassignment and trimming from a module, and module "significance" criteria

     reassignThresholdPS = 1e-4,
     trimmingConsensusQuantile = consensusQuantile,
     minCoreKME = 0.5, minCoreKMESize = minModuleSize/3,
     minKMEtoStay = 0.2,

     # Module eigengene calculation options

     impute = TRUE,
     trapErrors = FALSE,

     #Module merging options

     equalizeQuantilesForModuleMerging = FALSE,
     quantileSummaryForModuleMerging = "mean",
     mergeCutHeight = 0.15, 
     mergeConsensusQuantile = consensusQuantile,

     # Output options

     numericLabels = FALSE,

     # General options

     nThreads = 0,
     verbose = 2, indent = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blockwiseConsensusModules_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_checkmissingdata">checkMissingData</code></td>
<td>
<p>logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_blocks">blocks</code></td>
<td>
<p> optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p> integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>number of centers to be used in the preclustering. Defaults to smaller of
<code>nGenes/20</code> and <code>100*nGenes/maxBlockSize</code>, where <code>nGenes</code> is the nunber of genes (variables) in
<code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_individualtominfo">individualTOMInfo</code></td>
<td>
<p> Optional data for TOM matrices in individual data sets. This object is returned by
the function <code><a href="#topic+blockwiseIndividualTOMs">blockwiseIndividualTOMs</a></code>. If not given, appropriate topological overlaps will be
calculated using the network contruction options below. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_useindivtomsubset">useIndivTOMSubset</code></td>
<td>
<p> If <code>individualTOMInfo</code> is given, this argument allows to only select a subset
of the individual set networks contained in <code>individualTOMInfo</code>. It should be a numeric vector giving the
indices of the individual sets to be used. Note that this argument is NOT applied to <code>multiExpr</code>. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pariwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> only used for <code>corType=="bicor"</code>. Specifies the maximum percentile of data 
that can be considered outliers on either 
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_quickcor">quickCor</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation, if used, should revert to Pearson when
median absolute deviation (mad) is zero. Recongnized values are (abbreviations of)
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation.
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad.
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). Has no
effect for Pearson correlation. See <code><a href="#topic+bicor">bicor</a></code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>
<p>logical: should the cosine version of the correlation calculation be used? The 
cosine calculation differs from the standard one in that it does not subtract the mean. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. Either a single number or a vector of the same length as
the number of sets, with one power for each set. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_checkpower">checkPower</code></td>
<td>
<p> logical: should basic sanity check be performed on the supplied <code>power</code>? If
you would like to experiment with unusual powers, set the argument to <code>FALSE</code> and proceed with
caution. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>logical: should missing values in the calculation of adjacency be replaced
by 0?</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>, 
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are 
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which 
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce 
better results but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? Negative TOM values can occur when
<code>TOMType</code> is <code>"signed Nowick"</code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_saveindividualtoms">saveIndividualTOMs</code></td>
<td>
<p>logical: should individual TOMs be saved to disk for later use? </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>
<p>character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names turn
out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_networkcalibration">networkCalibration</code></td>
<td>
<p>network calibration method. One of &quot;single quantile&quot;, &quot;full quantile&quot;, &quot;none&quot;
(or a unique abbreviation of one of them).</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_calibrationquantile">calibrationQuantile</code></td>
<td>
<p> if <code>networkCalibration</code> is <code>"single quantile"</code>, 
topological overlaps (or adjacencies if
TOMs are not computed) will be scaled such that their <code>calibrationQuantile</code> quantiles will agree. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_sampleforcalibration">sampleForCalibration</code></td>
<td>
<p> if <code>TRUE</code>, calibration quantiles will be determined from a sample of network
similarities. Note that using all data can double the memory footprint of the function and the function
may fail. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_sampleforcalibrationfactor">sampleForCalibrationFactor</code></td>
<td>
<p> determines the number of samples for calibration: the number is
<code>1/calibrationQuantile * sampleForCalibrationFactor</code>. Should be set well above 1 to ensure accuracy of the
sampled quantile. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_getnetworkcalibrationsamples">getNetworkCalibrationSamples</code></td>
<td>
<p> logical: should samples used for TOM calibration be saved for future analysis?
This option is only available when <code>sampleForCalibration</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_consensusquantile">consensusQuantile</code></td>
<td>
<p> quantile at which consensus is to be defined. See details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_usemean">useMean</code></td>
<td>
<p>logical: should the consensus be determined from a (possibly weighted) mean across the
data sets rather than a quantile?</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_setweights">setWeights</code></td>
<td>
<p>Optional vector (one component per input set) of weights to be used for weighted mean
consensus. Only used when <code>useMean</code> above is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_saveconsensustoms">saveConsensusTOMs</code></td>
<td>
<p> logical: should the consensus topological overlap matrices for each block be saved
and returned?  </p>
</td></tr> 
<tr><td><code id="blockwiseConsensusModules_+3A_consensustomfilepattern">consensusTOMFilePattern</code></td>
<td>
<p> character string containing the file namefiles containing the
consensus topological overlaps. The tag <code>%b</code> will be replaced by the block number. If the resulting file
names are non-unique (for example, because the user gives a file name without a <code>%b</code> tag), an error
will be generated.
These files are standard R data files and can be loaded using the <code><a href="base.html#topic+load">load</a></code>
function. </p>
</td></tr> 
<tr><td><code id="blockwiseConsensusModules_+3A_usediskcache">useDiskCache</code></td>
<td>
<p> should calculated network similarities in individual sets be temporarilly saved
to disk? Saving to disk is somewhat slower than keeping all data in memory, but for large blocks and/or
many sets the memory footprint may be too big. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_chunksize">chunkSize</code></td>
<td>
<p> network similarities are saved in smaller chunks of size <code>chunkSize</code>. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_cachebase">cacheBase</code></td>
<td>
<p> character string containing the desired name for the cache files. The actual file
names will consists of <code>cacheBase</code> and a suffix to make the file names unique. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_cachedir">cacheDir</code></td>
<td>
<p> character string containing the desired path for the cache files.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_consensustominfo">consensusTOMInfo</code></td>
<td>
<p>optional list summarizing consensus TOM, output of <code><a href="#topic+consensusTOM">consensusTOM</a></code>. It
contains information about pre-calculated consensus TOM. Supplying this argument replaces TOM calculation,
so none of the individual or consensus TOM calculation arguments are taken into account.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_deepsplit">deepSplit</code></td>
<td>
<p> integer value between 0 and 4. Provides a simplified control over how sensitive
module detection should be to module splitting, with 0 least and 4 most sensitive. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> dendrogram cut height for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_checkminmodulesize">checkMinModuleSize</code></td>
<td>
<p> logical: should sanity checks be performed on <code>minModuleSize</code>?</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_maxcorescatter">maxCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster, given as the fraction
of <code>cutHeight</code> relative to the 5th percentile of joining heights. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_mingap">minGap</code></td>
<td>
<p> minimum cluster gap given as the fraction of the difference between <code>cutHeight</code> and
the 5th percentile of joining heights. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr> 
<tr><td><code id="blockwiseConsensusModules_+3A_maxabscorescatter">maxAbsCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster given as absolute
heights. If given, overrides <code>maxCoreScatter</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minabsgap">minAbsGap</code></td>
<td>
<p> minimum cluster gap given as absolute height difference. If given, overrides
<code>minGap</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minsplitheight">minSplitHeight</code></td>
<td>
<p>Minimum split height given as the fraction of the difference between
<code>cutHeight</code> and the 5th percentile of joining heights. Branches merging below this height will
automatically be merged. Defaults to zero but is used only if <code>minAbsSplitHeight</code> below is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minabssplitheight">minAbsSplitHeight</code></td>
<td>
<p>Minimum split height given as an absolute height.
Branches merging below this height will automatically be merged. If not given (default), will be determined
from <code>minSplitHeight</code> above.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_usebrancheigennodedissim">useBranchEigennodeDissim</code></td>
<td>
<p>Logical: should branch eigennode (eigengene) dissimilarity be considered
when merging branches in Dynamic Tree Cut?</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minbrancheigennodedissim">minBranchEigennodeDissim</code></td>
<td>
<p>Minimum consensus branch eigennode (eigengene) dissimilarity for
branches to be considerd separate. The branch eigennode dissimilarity in individual sets
is simly 1-correlation of the
eigennodes; the consensus is defined as quantile with probability <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_stabilitylabels">stabilityLabels</code></td>
<td>
<p>Optional matrix of cluster labels that are to be used for calculating branch
dissimilarity based on split stability. The number of rows must equal the number of genes in
<code>multiExpr</code>; the number of columns (clusterings) is arbitrary. See
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minstabilitydissim">minStabilityDissim</code></td>
<td>
<p>Minimum stability dissimilarity criterion for two branches to be considered
separate. Should be a number between 0 (essentially no dissimilarity required) and 1 (perfect dissimilarity
or distinguishability based on <code>stabilityLabels</code>). See 
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_pamstage">pamStage</code></td>
<td>
<p> logical.  If TRUE, the second (PAM-like) stage of module detection will be performed.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_pamrespectsdendro">pamRespectsDendro</code></td>
<td>
<p>Logical, only used when <code>pamStage</code> is <code>TRUE</code>.
If <code>TRUE</code>, the PAM stage will
respect the dendrogram in the sense an object can be PAM-assigned only to clusters that lie below it on
the branch that the object is merged into.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_reassignthresholdps">reassignThresholdPS</code></td>
<td>
<p> per-set p-value ratio threshold for reassigning genes between modules. 
See Details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_trimmingconsensusquantile">trimmingConsensusQuantile</code></td>
<td>
<p>a number between 0 and 1 specifying the consensus quantile used for kME
calculation that determines module trimming according to the arguments below.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled and returned to the pool of genes waiting for mofule detection). </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_equalizequantilesformodulemerging">equalizeQuantilesForModuleMerging</code></td>
<td>
<p>Logical: equalize quantiles of the module eigengene networks
before module merging? If <code>TRUE</code>, the quantiles of the eigengene correlation matrices (interpreted as a
single vectors of non-redundant components) will be equalized across the input data sets. Note that
although this seems like a reasonable option, it should be considered experimental and not necessarily
recommended.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_quantilesummaryformodulemerging">quantileSummaryForModuleMerging</code></td>
<td>
<p>One of <code>"mean"</code> or <code>"median"</code>. 
If quantile equalization of the module eigengene networks is
performed, the resulting &quot;normal&quot; quantiles will be given by this function of the corresponding quantiles
across the input data sets.</p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_mergecutheight">mergeCutHeight</code></td>
<td>
<p> dendrogram cut height for module merging. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_mergeconsensusquantile">mergeConsensusQuantile</code></td>
<td>
<p>consensus quantile for module merging. See <code>mergeCloseModules</code> for
details. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_numericlabels">numericLabels</code></td>
<td>
<p> logical: should the returned modules be labeled by colors (<code>FALSE</code>), or by
numbers (<code>TRUE</code>)? </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="blockwiseConsensusModules_+3A_...">...</code></td>
<td>
<p>Other arguments. At present these can include <code>reproduceBranchEigennodeQuantileError</code> that
instructs the function to reproduce a bug in branch eigennode dissimilarity calculations for purposes if
reproducing old reults. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function starts by optionally filtering out samples that have too many missing entries and genes
that have either too many missing entries or zero variance in at least one set. Genes that are filtered
out are left unassigned by the module detection. Returned eigengenes will contain <code>NA</code> in entries
corresponding to filtered-out samples. 
</p>
<p>If <code>blocks</code> is not given and
the number of genes exceeds <code>maxBlockSize</code>, genes are pre-clustered into blocks using the function
<code><a href="#topic+consensusProjectiveKMeans">consensusProjectiveKMeans</a></code>; otherwise all genes are treated in a single block. 
</p>
<p>For each block of genes, the network is constructed and (if requested) topological overlap is calculated
in each set. To minimize memory usage, calculated topological overlaps are optionally saved to disk in
chunks until they are needed again for the calculation of the consensus network topological overlap. 
</p>
<p>Before calculation of the consensus Topological Overlap, individual TOMs are optionally calibrated.
Calibration methods include single quantile scaling and full quantile normalization. 
</p>
<p>Single quantile
scaling raises individual TOM in sets 2,3,... to a power such that the quantiles given by 
<code>calibrationQuantile</code> agree with the quantile in set 1. Since the high TOMs are usually the most important
for module identification, the value of <code>calibrationQuantile</code> is close to (but not equal) 1. To speed up
quantile calculation, the quantiles can be determined on a randomly-chosen component subset of the TOM matrices.
</p>
<p>Full quantile normalization, implemented in <code><a href="preprocessCore.html#topic+normalize.quantiles">normalize.quantiles</a></code>, adjusts the
TOM matrices such that all quantiles equal each other (and equal to the quantiles of the component-wise 
average of the individual TOM matrices). 
</p>
<p>Note that network calibration is performed separately in each block, i.e., the normalizing transformation
may differ between blocks. This is necessary to avoid manipulating a full TOM in memory.
</p>
<p>The consensus TOM is calculated as the component-wise <code>consensusQuantile</code> quantile of the individual
(set) TOMs; that is, for each gene pair (TOM entry), the <code>consensusQuantile</code> quantile across all input
sets. Alternatively, one can also use (weighted) component-wise mean across all imput data sets.
If requested, the consensus topological overlaps are saved to disk for later use.
</p>
<p>Genes are then clustered using average linkage hierarchical clustering and modules are identified in the
resulting dendrogram by the Dynamic Hybrid tree cut. Found modules are trimmed of genes whose
consensus module membership kME (that is, correlation with module eigengene) 
is less than <code>minKMEtoStay</code>.
Modules in which
fewer than <code>minCoreKMESize</code> genes have consensus KME higher than <code>minCoreKME</code>
are disbanded, i.e., their constituent genes are pronounced
unassigned. 
</p>
<p>After all blocks have been processed, the function checks whether there are genes whose KME in the module
they assigned is lower than KME to another module. If p-values of the higher correlations are smaller
than those of the native module by the factor <code>reassignThresholdPS</code> (in every set), 
the gene is re-assigned to the closer module. 
</p>
<p>In the last step, modules whose eigengenes are highly correlated are merged. This is achieved by
clustering module eigengenes using the dissimilarity given by one minus their correlation, 
cutting the dendrogram at the height <code>mergeCutHeight</code> and merging all modules on each branch. The
process is iterated until no modules are merged. See <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for more details on
module merging.
</p>
<p>The argument <code>quick</code> specifies the precision of handling of missing data in the correlation 
calculations. Zero will cause all  
calculations to be executed precisely, which may be significantly slower than calculations without
missing data. Progressively higher values will speed up the
calculations but introduce progressively larger errors. Without missing data, all column means and
variances can be pre-calculated before the covariances are calculated. When missing data are present,
exact calculations require the column means and variances to be calculated for each covariance. The
approximate calculation uses the pre-calculated mean and variance and simply ignores missing data in the
covariance calculation. If the number of missing data is high, the pre-calculated means and variances may
be very different from the actual ones, thus potentially introducing large errors. 
The <code>quick</code> value times the
number of rows specifies the maximum difference in the
number of missing entries for mean and variance calculations on the one hand and covariance on the other
hand that will be tolerated before a recalculation is triggered. The hope is that if only a few missing
data are treated approximately, the error introduced will be small but the potential speedup can be
significant.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p> module assignment of all input genes. A vector containing either character strings with
module colors (if input <code>numericLabels</code> was unset) or numeric module labels (if <code>numericLabels</code>
was set to <code>TRUE</code>). The color &quot;grey&quot; and the numeric label 0 are reserved for unassigned genes.  </p>
</td></tr>
<tr><td><code>unmergedColors</code></td>
<td>
<p> module colors or numeric labels before the module merging step. </p>
</td></tr>
<tr><td><code>multiMEs</code></td>
<td>
<p> module eigengenes corresponding to the modules returned in <code>colors</code>, in multi-set
format. A vector of lists, one per set, containing eigengenes, proportion of variance explained and other
information. See <code><a href="#topic+multiSetMEs">multiSetMEs</a></code> for a detailed description. </p>
</td></tr>
<tr><td><code>goodSamples</code></td>
<td>
<p> a list, with one component per input set. Each component is 
a logical vector with one entry per sample from the corresponding set. The entry indicates whether 
the sample in the set passed basic quality control criteria. </p>
</td></tr>
<tr><td><code>goodGenes</code></td>
<td>
<p>a logical vector with one entry per input gene indicating whether the gene passed
basic quality control criteria in all sets.</p>
</td></tr>
<tr><td><code>dendrograms</code></td>
<td>
<p>a list with one component for each block of genes. Each component is the
hierarchical clustering dendrogram obtained by clustering the consensus gene dissimilarity in the
corresponding block. </p>
</td></tr>
<tr><td><code>TOMFiles</code></td>
<td>
<p> if <code>saveConsensusTOMs==TRUE</code>, 
a vector of character strings, one string per block, giving the file names of files
(relative to current directory) in which blockwise  topological overlaps were saved. </p>
</td></tr>
<tr><td><code>blockGenes</code></td>
<td>
<p>a list with one component for each block of genes. Each component is a vector giving
the indices (relative to the input <code>multiExpr</code>) of genes in the corresponding block. </p>
</td></tr>
<tr><td><code>blocks</code></td>
<td>
<p>if input <code>blocks</code> was given, its copy; otherwise a vector of length equal number of
genes giving the block label for each gene. Note that block labels are not necessarilly sorted in the
order in which the blocks were processed (since we do not require this for the input <code>blocks</code>). See
<code>blockOrder</code> below. </p>
</td></tr>
<tr><td><code>blockOrder</code></td>
<td>
<p> a vector giving the order in which blocks were processed and in which
<code>blockGenes</code> above is returned. For example, <code>blockOrder[1]</code> contains the label of the
first-processed block. </p>
</td></tr> 
<tr><td><code>originCount</code></td>
<td>
<p>A vector of length <code>nSets</code> that
contains, for each set, the number of (calibrated) elements that were less than or equal the consensus for that element.</p>
</td></tr>
<tr><td><code>networkCalibrationSamples</code></td>
<td>
<p>if the input <code>getNetworkCalibrationSamples</code> is <code>TRUE</code>, this component is a
list with one component per block. Each component is again a list with two components:
<code>sampleIndex</code> contains indices of the distance structure in which TOM is stored that were sampled,
and <code>TOMSamples</code> is a matrix whose rows correspond to TOM samples and columns to individual set.
Hence, <code>networkCalibrationSamples[[blockNo]]$TOMSamples[index, setNo]</code> contains the TOM entry that
corresponds to element <code>networkCalibrationSamples[[blockNo]]$sampleIndex[index]</code> of the TOM distance
structure in block <code>blockNo</code> and set <code>setNo</code>. (For details on the distance structure, see
<code><a href="stats.html#topic+dist">dist</a></code>.)</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>If the input datasets have large numbers of genes, consider carefully the <code>maxBlockSize</code> as it
significantly affects the memory footprint (and whether the function will fail with a memory allocation
error). From a theoretical point of view it is advantageous to use blocks as large as possible; on the
other hand, using smaller blocks is substantially faster and often the only way to work with large
numbers of genes. As a rough guide, it is unlikely a standard desktop
computer with 4GB memory or less will be able to work with blocks larger than 7000 genes. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder</p>


<h3>References</h3>

<p> Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between
co-expression modules. BMC Systems Biology 2007, 1:54 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for basic quality control and filtering; 
</p>
<p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> for network construction;
</p>
<p><code><a href="stats.html#topic+hclust">hclust</a></code> for hierarchical clustering;
</p>
<p><code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for adaptive branch cutting in hierarchical clustering
dendrograms; 
</p>
<p><code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for merging of close modules.
</p>

<hr>
<h2 id='blockwiseIndividualTOMs'>
Calculation of block-wise topological overlaps 
</h2><span id='topic+blockwiseIndividualTOMs'></span>

<h3>Description</h3>

<p>Calculates topological overlaps in the given (expression) data. If the number of variables (columns) in the
input data is too large, the data is first split using pre-clustering, then topological overlaps are
calculated in each block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockwiseIndividualTOMs(
   multiExpr,
   multiWeights = NULL,

   # Data checking options

   checkMissingData = TRUE,

   # Blocking options

   blocks = NULL,
   maxBlockSize = 5000,
   blockSizePenaltyPower = 5,
   nPreclusteringCenters = NULL,
   randomSeed = 54321,

   # Network construction arguments: correlation options

   corType = "pearson",
   maxPOutliers = 1,
   quickCor = 0,
   pearsonFallback = "individual",
   cosineCorrelation = FALSE,

   # Adjacency function options

   power = 6,
   networkType = "unsigned",
   checkPower = TRUE,
   replaceMissingAdjacencies = FALSE,

   # Topological overlap options

   TOMType = "unsigned",
   TOMDenom = "min",
   suppressTOMForZeroAdjacencies = FALSE,
   suppressNegativeTOM = FALSE,

   # Save individual TOMs? If not, they will be returned in the session.

   saveTOMs = TRUE,
   individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",

   # General options

   nThreads = 0,
   useInternalMatrixAlgebra = FALSE,
   verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blockwiseIndividualTOMs_+3A_multiexpr">multiExpr</code></td>
<td>
<p>expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes.
</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_multiweights">multiWeights</code></td>
<td>
<p>optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used in correlation calculation.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_checkmissingdata">checkMissingData</code></td>
<td>
<p>logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_blocks">blocks</code></td>
<td>
<p> optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p> integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>number of centers for pre-clustering. Larger numbers typically results in better
but slower pre-clustering. The default is <code>as.integer(min(nGenes/20, 100*nGenes/preferredSize))</code>
and is an attempt to arrive at a reasonable number given the resources available. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pariwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> only used for <code>corType=="bicor"</code>. Specifies the maximum percentile of data
that can be considered outliers on either
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_quickcor">quickCor</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation, if used, should revert to Pearson when
median absolute deviation (mad) is zero. Recongnized values are (abbreviations of)
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation.
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad.
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). Has no
effect for Pearson correlation. See <code><a href="#topic+bicor">bicor</a></code>.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>
<p>logical: should the cosine version of the correlation calculation be used? The
cosine calculation differs from the standard one in that it does not subtract the mean. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. Either a single number or a vector of the same length as
the number of sets, with one power for each set.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_checkpower">checkPower</code></td>
<td>
<p> logical: should basic sanity check be performed on the supplied <code>power</code>? If
you would like to experiment with unusual powers, set the argument to <code>FALSE</code> and proceed with
caution. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>logical: should missing values in calculated adjacency be replaced by 0?</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce
better results in certain special situations but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_suppresstomforzeroadjacencies">suppressTOMForZeroAdjacencies</code></td>
<td>
<p>Logical: should TOM be set to zero for zero adjacencies?</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? Negative TOM values can occur when
<code>TOMType</code> is <code>"signed Nowick"</code>.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_savetoms">saveTOMs</code></td>
<td>
<p>logical: should calculated TOMs be saved to disk (<code>TRUE</code>) or returned in the return
value (<code>FALSE</code>)? Returning calculated TOMs via the return value ay be more convenient bt not always
feasible if the matrices are too big to fit all in memory at the same time.
</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>
<p>character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_useinternalmatrixalgebra">useInternalMatrixAlgebra</code></td>
<td>
<p>Logical: should WGCNA's own, slow, matrix multiplication be used instead of
R-wide BLAS? Only useful for debugging.</p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="blockwiseIndividualTOMs_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function starts by optionally filtering out samples that have too many missing entries and genes
that have either too many missing entries or zero variance in at least one set. Genes that are filtered
out are excluded from the TOM calculations. 
</p>
<p>If <code>blocks</code> is not given and
the number of genes exceeds <code>maxBlockSize</code>, genes are pre-clustered into blocks using the function
<code><a href="#topic+consensusProjectiveKMeans">consensusProjectiveKMeans</a></code>; otherwise all genes are treated in a single block.
</p>
<p>For each block of genes, the network is constructed and (if requested) topological overlap is calculated
in each set. The topological overlaps can be saved to disk as RData files, or returned directly within the
return value (see below). Note that the matrices can be big and returning them within the return value can
quickly exhaust the system's memory. In particular, if the block-wise calculation is necessary, it is
nearly certain that returning all matrices via the return value will be impossible.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>actualTOMFileNames</code></td>
<td>
<p>Only returned if input <code>saveTOMs</code> is <code>TRUE</code>. A matrix of character
strings giving the file names in which each block TOM is saved. Rows correspond to data sets and columns to
blocks.</p>
</td></tr>
<tr><td><code>TOMSimilarities</code></td>
<td>
<p>Only returned if input <code>saveTOMs</code> is <code>FALSE</code>. A list in which each
component corresponds to one block. Each component is a matrix of dimensions (N times (number of sets)), where
N is the length of a distance structure corresponding to the block. That is, if the block contains n genes,
N=n*(n-1)/2. Each column of the matrix contains the topological overlap of variables in the corresponding set (
and the corresponding block), arranged as a distance structure. Do note however that the topological overlap
is a similarity (not a distance). </p>
</td></tr>
<tr><td><code>blocks</code></td>
<td>
<p>if input <code>blocks</code> was given, its copy; otherwise a vector of length equal number of
genes giving the block label for each gene. Note that block labels are not necessarilly sorted in the
order in which the blocks were processed (since we do not require this for the input <code>blocks</code>). See
<code>blockOrder</code> below. </p>
</td></tr>
<tr><td><code>blockGenes</code></td>
<td>
<p>a list with one component for each block of genes. Each component is a vector giving
the indices (relative to the input <code>multiExpr</code>) of genes in the corresponding block. </p>
</td></tr>
<tr><td><code>goodSamplesAndGenes</code></td>
<td>
<p>if input 
<code>checkMissingData</code> is <code>TRUE</code>, the output of the function <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>. 
A list with components
<code>goodGenes</code> (logical vector indicating which genes passed the missing data filters), <code>goodSamples</code>
(a list of logical vectors indicating which samples passed the missing data filters in each set), and
<code>allOK</code> (a logical indicating whether all genes and all samples passed the filters). See
<code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for more details. If <code>checkMissingData</code> is <code>FALSE</code>,
<code>goodSamplesAndGenes</code> contains a list of the same type but indicating that all genes and all samples
passed the missing data filters.</p>
</td></tr> 
</table>
<p>The following components are present mostly to streamline the interaction of this function with
<code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>.
</p>
<table role = "presentation">
<tr><td><code>nGGenes</code></td>
<td>
<p> Number of genes that passed missing data filters (if input  
<code>checkMissingData</code> is <code>TRUE</code>), or the number of all genes (if <code>checkMissingData</code> is
<code>FALSE</code>).</p>
</td></tr>
<tr><td><code>gBlocks</code></td>
<td>
<p> the vector <code>blocks</code> (above), restricted to good genes only. </p>
</td></tr>
<tr><td><code>nThreads</code></td>
<td>
<p> number of threads used to calculate correlation and TOM matrices. </p>
</td></tr>
<tr><td><code>saveTOMs</code></td>
<td>
<p> logical: were calculated matrices saved in files (<code>TRUE</code>) or returned in the
return value (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code>intNetworkType</code>, <code>intCorType</code></td>
<td>
<p>integer codes for network and  correlation type. </p>
</td></tr>
<tr><td><code>nSets</code></td>
<td>
<p>number of sets in input data.</p>
</td></tr>
<tr><td><code>setNames</code></td>
<td>
<p>the <code>names</code> attribute of input <code>multiExpr</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>For a general discussion of the weighted network formalism, see
</p>
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network Analysis&quot;,
Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>The blockwise approach is briefly described in the article describing this package,
</p>
<p>Langfelder P, Horvath S (2008) &quot;WGCNA: an R package for weighted correlation network analysis&quot;. 
BMC Bioinformatics 2008, 9:559
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>
</p>

<hr>
<h2 id='blockwiseModules'> Automatic network construction and module detection </h2><span id='topic+blockwiseModules'></span>

<h3>Description</h3>

<p>This function performs automatic network construction and module detection on large expression datasets
in a block-wise manner.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockwiseModules(
  # Input data

  datExpr, 
  weights = NULL,

  # Data checking options

  checkMissingData = TRUE,

  # Options for splitting data into blocks

  blocks = NULL,
  maxBlockSize = 5000,
  blockSizePenaltyPower = 5,
  nPreclusteringCenters = as.integer(min(ncol(datExpr)/20, 
                             100*ncol(datExpr)/maxBlockSize)),
  randomSeed = 54321,

 # load TOM from previously saved file?

  loadTOM = FALSE,

  # Network construction arguments: correlation options

  corType = "pearson",
  maxPOutliers = 1, 
  quickCor = 0,
  pearsonFallback = "individual",
  cosineCorrelation = FALSE,

  # Adjacency function options

  power = 6,
  networkType = "unsigned",
  replaceMissingAdjacencies = FALSE,

  # Topological overlap options

  TOMType = "signed",
  TOMDenom = "min",
  suppressTOMForZeroAdjacencies = FALSE,
  suppressNegativeTOM = FALSE,

  # Saving or returning TOM

  getTOMs = NULL,
  saveTOMs = FALSE, 
  saveTOMFileBase = "blockwiseTOM",

  # Basic tree cut options

  deepSplit = 2,
  detectCutHeight = 0.995, 
  minModuleSize = min(20, ncol(datExpr)/2 ),

  # Advanced tree cut options

  maxCoreScatter = NULL, minGap = NULL,
  maxAbsCoreScatter = NULL, minAbsGap = NULL,
  minSplitHeight = NULL, minAbsSplitHeight = NULL,

  useBranchEigennodeDissim = FALSE,
  minBranchEigennodeDissim = mergeCutHeight,

  stabilityLabels = NULL,
  stabilityCriterion = c("Individual fraction", "Common fraction"),
  minStabilityDissim = NULL,

  pamStage = TRUE, pamRespectsDendro = TRUE,

  # Gene reassignment, module trimming, and module "significance" criteria

  reassignThreshold = 1e-6,
  minCoreKME = 0.5, 
  minCoreKMESize = minModuleSize/3,
  minKMEtoStay = 0.3,

  # Module merging options

  mergeCutHeight = 0.15, 
  impute = TRUE, 
  trapErrors = FALSE, 

  # Output options

  numericLabels = FALSE,

  # Options controlling behaviour

  nThreads = 0,
  useInternalMatrixAlgebra = FALSE,
  useCorOptionsThroughout = TRUE,
  verbose = 0, indent = 0,
  ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blockwiseModules_+3A_datexpr">datExpr</code></td>
<td>
<p> Expression data. A matrix (preferred) or 
data frame in which columns are genes and rows ar samples. NAs are
allowed, but not too many. See <code>checkMissingData</code> below and details.</p>
</td></tr> 
<tr><td><code id="blockwiseModules_+3A_weights">weights</code></td>
<td>
<p>optional observation weights in the same format (and dimensions) as <code>datExpr</code>.
These weights are used in correlation calculation.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_checkmissingdata">checkMissingData</code></td>
<td>
<p>logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_blocks">blocks</code></td>
<td>
<p>optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per column (gene) 
of <code>exprData</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p>integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>number of centers for pre-clustering. Larger numbers typically results in better
but slower pre-clustering. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_randomseed">randomSeed</code></td>
<td>
<p>integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the 
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_loadtom">loadTOM</code></td>
<td>
<p>logical: should Topological Overlap Matrices be loaded from previously saved files (<code>TRUE</code>) 
or calculated (<code>FALSE</code>)? It may be useful to load previously saved TOM matrices if these have been
calculated previously, since TOM calculation is often the most computationally expensive part of network
construction and module identification. See <code>saveTOMs</code> and <code>saveTOMFileBase</code> below for when and how TOM
files are saved, and what the file names are. If <code>loadTOM</code> is <code>TRUE</code> but the files cannot be
found, or do not contain the correct TOM data, TOM will be recalculated.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_cortype">corType</code></td>
<td>
<p>character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pairwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> only used for <code>corType=="bicor"</code>. Specifies the maximum percentile of data 
that can be considered outliers on either 
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_quickcor">quickCor</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr> 
<tr><td><code id="blockwiseModules_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation, if used, should revert to Pearson when
median absolute deviation (mad) is zero. Recongnized values are (abbreviations of) 
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation. 
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad. 
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in 
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). Has no 
effect for Pearson correlation.  See <code><a href="#topic+bicor">bicor</a></code>.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>
<p>logical: should the cosine version of the correlation calculation be used? The
cosine calculation differs from the standard one in that it does not subtract the mean. </p>
</td></tr> 
<tr><td><code id="blockwiseModules_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>logical: should missing values in the calculation of adjacency be replaced
by 0?</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are 
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which 
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce 
better results but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_suppresstomforzeroadjacencies">suppressTOMForZeroAdjacencies</code></td>
<td>
<p>Logical: should TOM be set to zero for zero adjacencies?</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? Negative TOM values can occur when
<code>TOMType</code> is <code>"signed Nowick"</code>.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_gettoms">getTOMs</code></td>
<td>
<p> deprecated, please use saveTOMs below. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_savetoms">saveTOMs</code></td>
<td>
<p> logical: should the consensus topological overlap matrices for each block be saved
and returned?  </p>
</td></tr> 
<tr><td><code id="blockwiseModules_+3A_savetomfilebase">saveTOMFileBase</code></td>
<td>
<p> character string containing the file name base for files containing the
consensus topological overlaps. The full file names have <code>"block.1.RData"</code>, <code>"block.2.RData"</code>
etc. appended. These files are standard R data files and can be loaded using the <code><a href="base.html#topic+load">load</a></code>
function. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_deepsplit">deepSplit</code></td>
<td>
<p> integer value between 0 and 4. Provides a simplified control over how sensitive
module detection should be to module splitting, with 0 least and 4 most sensitive. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> dendrogram cut height for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_maxcorescatter">maxCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster, given as the fraction
of <code>cutHeight</code> relative to the 5th percentile of joining heights. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_mingap">minGap</code></td>
<td>
<p> minimum cluster gap given as the fraction of the difference between <code>cutHeight</code> and
the 5th percentile of joining heights. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr> 
<tr><td><code id="blockwiseModules_+3A_maxabscorescatter">maxAbsCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster given as absolute
heights. If given, overrides <code>maxCoreScatter</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minabsgap">minAbsGap</code></td>
<td>
<p> minimum cluster gap given as absolute height difference. If given, overrides
<code>minGap</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minsplitheight">minSplitHeight</code></td>
<td>
<p>Minimum split height given as the fraction of the difference between
<code>cutHeight</code> and the 5th percentile of joining heights. Branches merging below this height will
automatically be merged. Defaults to zero but is used only if <code>minAbsSplitHeight</code> below is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minabssplitheight">minAbsSplitHeight</code></td>
<td>
<p>Minimum split height given as an absolute height.
Branches merging below this height will automatically be merged. If not given (default), will be determined
from <code>minSplitHeight</code> above.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_usebrancheigennodedissim">useBranchEigennodeDissim</code></td>
<td>
<p>Logical: should branch eigennode (eigengene) dissimilarity be considered
when merging branches in Dynamic Tree Cut?</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minbrancheigennodedissim">minBranchEigennodeDissim</code></td>
<td>
<p>Minimum consensus branch eigennode (eigengene) dissimilarity for
branches to be considerd separate. The branch eigennode dissimilarity in individual sets
is simly 1-correlation of the
eigennodes; the consensus is defined as quantile with probability <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_stabilitylabels">stabilityLabels</code></td>
<td>
<p>Optional matrix of cluster labels that are to be used for calculating branch
dissimilarity based on split stability. The number of rows must equal the number of genes in
<code>multiExpr</code>; the number of columns (clusterings) is arbitrary. See
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_stabilitycriterion">stabilityCriterion</code></td>
<td>
<p>One of <code>c("Individual fraction", "Common fraction")</code>, indicating which method
for assessing stability similarity of two branches should be used. We recommend <code>"Individual fraction"</code>
which appears to perform better; the <code>"Common fraction"</code> method is provided for backward compatibility
since it was the (only) method available prior to WGCNA version 1.60.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minstabilitydissim">minStabilityDissim</code></td>
<td>
<p>Minimum stability dissimilarity criterion for two branches to be considered
separate. Should be a number between 0 (essentially no dissimilarity required) and 1 (perfect dissimilarity
or distinguishability based on <code>stabilityLabels</code>). See
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_pamstage">pamStage</code></td>
<td>
<p> logical.  If TRUE, the second (PAM-like) stage of module detection will be performed.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_pamrespectsdendro">pamRespectsDendro</code></td>
<td>
<p>Logical, only used when <code>pamStage</code> is <code>TRUE</code>. 
If <code>TRUE</code>, the PAM stage will
respect the dendrogram in the sense an object can be PAM-assigned only to clusters that lie below it on
the branch that the object is merged into. 
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled and returned to the pool of genes waiting for mofule detection). </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_reassignthreshold">reassignThreshold</code></td>
<td>
<p> p-value ratio threshold for reassigning genes between modules. See Details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_mergecutheight">mergeCutHeight</code></td>
<td>
<p> dendrogram cut height for module merging. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_numericlabels">numericLabels</code></td>
<td>
<p> logical: should the returned modules be labeled by colors (<code>FALSE</code>), or by
numbers (<code>TRUE</code>)? </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows). 
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_useinternalmatrixalgebra">useInternalMatrixAlgebra</code></td>
<td>
<p>Logical: should WGCNA's own, slow, matrix multiplication be used instead of
R-wide BLAS? Only useful for debugging.</p>
</td></tr>  
<tr><td><code id="blockwiseModules_+3A_usecoroptionsthroughout">useCorOptionsThroughout</code></td>
<td>
<p>Logical: should correlation options passed to network analysis also be used
in calculation of kME? Set to <code>FALSE</code> to reproduce results obtained with WGCNA 1.62 and older.</p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="blockwiseModules_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before module detection starts, genes and samples are optionally checked for the presence of <code>NA</code>s.
Genes and/or samples that have too many <code>NA</code>s are flagged as bad and removed from the analysis; bad
genes will be automatically labeled as unassigned, while the returned eigengenes will have <code>NA</code>
entries for all bad samples. 
</p>
<p>If <code>blocks</code> is not given and
the number of genes exceeds <code>maxBlockSize</code>, genes are pre-clustered into blocks using the function
<code><a href="#topic+projectiveKMeans">projectiveKMeans</a></code>; otherwise all genes are treated in a single block.
</p>
<p>For each block of genes, the network is constructed and (if requested) topological overlap is calculated.
If requested, the topological overlaps are returned as part of the return value list.
Genes are then clustered using average linkage hierarchical clustering and modules are identified in the
resulting dendrogram by the Dynamic Hybrid tree cut. Found modules are trimmed of genes whose
correlation with module eigengene (KME) is less than <code>minKMEtoStay</code>. Modules in which
fewer than <code>minCoreKMESize</code> genes have KME higher than <code>minCoreKME</code> 
are disbanded, i.e., their constituent genes are pronounced
unassigned. 
</p>
<p>After all blocks have been processed, the function checks whether there are genes whose KME in the module
they assigned is lower than KME to another module. If p-values of the higher correlations are smaller
than those of the native module by the factor <code>reassignThresholdPS</code>,
the gene is re-assigned to the closer module.
</p>
<p>In the last step, modules whose eigengenes are highly correlated are merged. This is achieved by
clustering module eigengenes using the dissimilarity given by one minus their correlation,
cutting the dendrogram at the height <code>mergeCutHeight</code> and merging all modules on each branch. The
process is iterated until no modules are merged. See <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for more details on
module merging.
</p>
<p>The argument <code>quick</code> specifies the precision of handling of missing data in the correlation
calculations. Zero will cause all 
calculations to be executed precisely, which may be significantly slower than calculations without 
missing data. Progressively higher values will speed up the
calculations but introduce progressively larger errors. Without missing data, all column means and
variances can be pre-calculated before the covariances are calculated. When missing data are present, 
exact calculations require the column means and variances to be calculated for each covariance. The 
approximate calculation uses the pre-calculated mean and variance and simply ignores missing data in the
covariance calculation. If the number of missing data is high, the pre-calculated means and variances may
be very different from the actual ones, thus potentially introducing large errors. 
The <code>quick</code> value times the
number of rows specifies the maximum difference in the
number of missing entries for mean and variance calculations on the one hand and covariance on the other 
hand that will be tolerated before a recalculation is triggered. The hope is that if only a few missing
data are treated approximately, the error introduced will be small but the potential speedup can be 
significant.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p> a vector of color or numeric module labels for all genes.</p>
</td></tr>
<tr><td><code>unmergedColors</code></td>
<td>
<p> a vector of color or numeric module labels for all genes before module merging.</p>
</td></tr>
<tr><td><code>MEs</code></td>
<td>
<p> a data frame containing module eigengenes of the found modules (given by <code>colors</code>).</p>
</td></tr>
<tr><td><code>goodSamples</code></td>
<td>
<p>numeric vector giving indices of good samples, that is samples that do not have too
many missing entries. </p>
</td></tr>
<tr><td><code>goodGenes</code></td>
<td>
<p> numeric vector giving indices of good genes, that is genes that do not have too
many missing entries.</p>
</td></tr>
<tr><td><code>dendrograms</code></td>
<td>
<p> a list whose components conatain hierarchical clustering dendrograms of genes 
in each block. </p>
</td></tr>
<tr><td><code>TOMFiles</code></td>
<td>
<p> if <code>saveTOMs==TRUE</code>,
a vector of character strings, one string per block, giving the file names of files
(relative to current directory) in which blockwise  topological overlaps were saved. </p>
</td></tr>
<tr><td><code>blockGenes</code></td>
<td>
<p> a list whose components give the indices of genes in each block. </p>
</td></tr>
<tr><td><code>blocks</code></td>
<td>
<p>if input <code>blocks</code> was given, its copy; otherwise a vector of length equal number of
genes giving the block label for each gene. Note that block labels are not necessarilly sorted in the
order in which the blocks were processed (since we do not require this for the input <code>blocks</code>). See
<code>blockOrder</code> below. </p>
</td></tr>
<tr><td><code>blockOrder</code></td>
<td>
<p> a vector giving the order in which blocks were processed and in which
<code>blockGenes</code> above is returned. For example, <code>blockOrder[1]</code> contains the label of the
first-processed block. </p>
</td></tr>
<tr><td><code>MEsOK</code></td>
<td>
<p>logical indicating whether the module eigengenes were calculated without errors. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>significantly affects the memory footprint (and whether the function will fail with a memory allocation
error). From a theoretical point of view it is advantageous to use blocks as large as possible; on the
other hand, using smaller blocks is substantially faster and often the only way to work with large
numbers of genes. As a rough guide, it is unlikely a standard desktop
computer with 4GB memory or less will be able to work with blocks larger than 8000 genes.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> for basic quality control and filtering;
</p>
<p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> for network construction;
</p>
<p><code><a href="stats.html#topic+hclust">hclust</a></code> for hierarchical clustering;
</p>
<p><code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for adaptive branch cutting in hierarchical clustering
dendrograms;
</p>
<p><code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for merging of close modules.
</p>

<hr>
<h2 id='BloodLists'>Blood Cell Types with Corresponding Gene Markers</h2><span id='topic+BloodLists'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of marker genes for many blood cell types, as reported in several previously-published studies.  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BloodLists)</code></pre>


<h3>Format</h3>

<p>A 2048 x 2 matrix of characters containing Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;Blood cell type&gt;__&lt;reference&gt;, where the references can be found at <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>.  Note that the matrix is sorted first by Category and then by Gene, such that all genes related to the same category are listed sequentially.
</p>


<h3>Source</h3>

<p>For references used in this variable, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BloodLists)
head(BloodLists)
</code></pre>

<hr>
<h2 id='blueWhiteRed'> Blue-white-red color sequence </h2><span id='topic+blueWhiteRed'></span>

<h3>Description</h3>

<p>Generate a blue-white-red color sequence of a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blueWhiteRed(
    n, 
    gamma = 1, 
    endSaturation = 1,
    blueEnd = c(0.05 + (1-endSaturation) * 0.45 , 0.55 + (1-endSaturation) * 0.25, 1.00),
    redEnd = c(1.0, 0.2 + (1-endSaturation) * 0.6, 0.6*(1-endSaturation)),
    middle = c(1,1,1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blueWhiteRed_+3A_n">n</code></td>
<td>
<p> number of colors to be returned. </p>
</td></tr>
<tr><td><code id="blueWhiteRed_+3A_gamma">gamma</code></td>
<td>
<p> color change power. </p>
</td></tr>
<tr><td><code id="blueWhiteRed_+3A_endsaturation">endSaturation</code></td>
<td>
<p> a number between 0 and 1 giving the saturation of the colors that will represent the
ends of the scale. Lower numbers mean less saturation (lighter colors).</p>
</td></tr>
<tr><td><code id="blueWhiteRed_+3A_blueend">blueEnd</code></td>
<td>
<p>vector of length 3 giving the RGB relative values (between 0 and 1) for the blue or negative end color.</p>
</td></tr>
<tr><td><code id="blueWhiteRed_+3A_redend">redEnd</code></td>
<td>
<p>vector of length 3 giving the RGB relative values (between 0 and 1) for the red or positive end color.</p>
</td></tr>
<tr><td><code id="blueWhiteRed_+3A_middle">middle</code></td>
<td>
<p>vector of length 3 giving the RGB relative values (between 0 and 1) for the middle of the scale.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a color vector that starts with blue, gradually turns into white and then to
red. The power <code>gamma</code> can be used to control the behaviour of the quarter- and three quarter-values
(between blue and white, and white and red, respectively). Higher powers will make the mid-colors more
white, while lower powers will make the colors more saturated, respectively.
</p>


<h3>Value</h3>

<p>A vector of colors of length <code>n</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

<p><code><a href="#topic+numbers2colors">numbers2colors</a></code> for a function that produces a color representation for continuous numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  par(mfrow = c(3, 1))
  displayColors(blueWhiteRed(50));
  title("gamma = 1")
  displayColors(blueWhiteRed(50, 3));
  title("gamma = 3")
  displayColors(blueWhiteRed(50, 0.5));
  title("gamma = 0.5")
</code></pre>

<hr>
<h2 id='BrainLists'>Brain-Related Categories with Corresponding Gene Markers</h2><span id='topic+BrainLists'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of marker genes for many brain-related categories (ie., cell type, organelle, changes with disease, etc.), as reported in several previously-published studies.  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BrainLists)</code></pre>


<h3>Format</h3>

<p>A 48319 x 2 matrix of characters containing Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;Brain descriptor&gt;__&lt;reference&gt;, where the references can be found at <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>.  Note that the matrix is sorted first by Category and then by Gene, such that all genes related to the same category are listed sequentially.
</p>


<h3>Source</h3>

<p>For references used in this variable, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BrainLists)
head(BrainLists)
</code></pre>

<hr>
<h2 id='BrainRegionMarkers'>Gene Markers for Regions of the Human Brain</h2><span id='topic+BrainRegionMarkers'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of marker genes for many regions of the human brain, using data from the Allen Human Brain Atlas (https://human.brain-map.org/) as reported in: Hawrylycz MJ, Lein ES, Guillozet-Bongaarts AL, Shen EH, Ng L, Miller JA, et al. (2012) An Anatomically Comprehensive Atlas of the Adult Human Brain Transcriptome. Nature (in press).  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BrainRegionMarkers)</code></pre>


<h3>Format</h3>

<p>A 28477 x 2 matrix of characters containing Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;Brain Region&gt;_&lt;Marker Type&gt;__HBA.  Note that the matrix is sorted first by Category and then by Gene, such that all genes related to the same category are listed sequentially.
</p>


<h3>Source</h3>

<p>For references used in this variable, or other information, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BrainRegionMarkers)
head(BrainRegionMarkers)
</code></pre>

<hr>
<h2 id='branchEigengeneDissim'>
Branch dissimilarity based on eigennodes (eigengenes).
</h2><span id='topic+branchEigengeneDissim'></span><span id='topic+branchEigengeneSimilarity'></span><span id='topic+mtd.branchEigengeneDissim'></span><span id='topic+hierarchicalBranchEigengeneDissim'></span>

<h3>Description</h3>

<p>Calculation of branch dissimilarity based on eigennodes (eigengenes) in single set and multi-data
situations. This function is used as a plugin for the
dynamicTreeCut package and the user should not call this function directly. This function is experimental
and subject to change.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>branchEigengeneDissim(
  expr, 
  branch1, branch2, 
  corFnc = cor, corOptions = list(use = "p"), 
  signed = TRUE, ...)

branchEigengeneSimilarity(
  expr, 
  branch1, 
  branch2, 
  networkOptions, 
  returnDissim = TRUE, ...)

mtd.branchEigengeneDissim(
  multiExpr, 
  branch1, branch2,
  corFnc = cor, corOptions = list(use = 'p'),
  consensusQuantile = 0, 
  signed = TRUE, reproduceQuantileError = FALSE, ...)

hierarchicalBranchEigengeneDissim(
    multiExpr,
    branch1, branch2,
    networkOptions,
    consensusTree, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="branchEigengeneDissim_+3A_expr">expr</code></td>
<td>

<p>Expression data.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_multiexpr">multiExpr</code></td>
<td>

<p>Expression data in multi-set format.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_branch1">branch1</code></td>
<td>

<p>Branch 1.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_branch2">branch2</code></td>
<td>

<p>Branch 2.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_corfnc">corFnc</code></td>
<td>

<p>Correlation function.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_coroptions">corOptions</code></td>
<td>

<p>Other arguments to the correlation function.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_consensusquantile">consensusQuantile</code></td>
<td>

<p>Consensus quantile.
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_signed">signed</code></td>
<td>

<p>Should the network be considered signed?
</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_reproducequantileerror">reproduceQuantileError</code></td>
<td>
<p>Logical: should an error in the calculation from previous versions, which
caused the true consensus quantile to be <code>1-consensusQuantile</code> rather than <code>consensusQuantile</code>,
be reproduced? Use this only to reproduce old calculations.</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_networkoptions">networkOptions</code></td>
<td>
<p>An object of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving the network construction
options to be used in the calculation of the similarity.</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_returndissim">returnDissim</code></td>
<td>
<p>Logical: if <code>TRUE</code>, dissimarity, rather than similarity, will be returned.</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_consensustree">consensusTree</code></td>
<td>
<p>A list of class <code><a href="#topic+ConsensusTree">ConsensusTree</a></code> specifying the consensus calculation.
Note that calibration options within the
consensus specifications are ignored: since the consensus is calulated from entries representing a single
value, calibration would not make sense.</p>
</td></tr>
<tr><td><code id="branchEigengeneDissim_+3A_...">...</code></td>
<td>

<p>Other arguments for compatibility; currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions calculate the similarity or dissimilarity of two groups of genes (variables) in <code>expr</code> or
<code>multiExpr</code> using correlations of the first singular vectors (&quot;eigengenes&quot;). For a single data set
(<code>branchEigengeneDissim</code> and <code>branchEigengeneSimilarity</code>), the similarity is the correlation, and
dissimilarity 1-correlation of the first signular vectors. 
</p>
<p>Functions <code>mtd.branchEigengeneDissim</code> and 
<code>hierarchicalBranchEigengeneDissim</code> calculate consensus eigengene dissimilarity.
Function <code>mtd.branchEigengeneDissim</code> calculates a simple (&quot;flat&quot;) consensus of branch eigengene
similarities across the given data set, at the given consensus quantile. 
Function <code>hierarchicalBranchEigengeneDissim</code> can calculate a hierarchical consensus in which consensus
calculations are hierarchically nested. 
</p>


<h3>Value</h3>

<p>A single number, the dissimilarity for <code>branchEigengeneDissim</code>, <code>mtd.branchEigengeneDissim</code>, and
<code>hierarchicalBranchEigengeneDissim</code>. 
</p>
<p><code>branchEigengeneSimilarity</code> returns similarity or dissimilarity, depending on imput.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code></p>

<hr>
<h2 id='branchSplit'>
Branch split.
</h2><span id='topic+branchSplit'></span>

<h3>Description</h3>

<p>Calculation of branch split based on expression data. This function is used as a plugin for the
dynamicTreeCut package and the user should not call this function directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>branchSplit(
  expr, 
  branch1, branch2, 
  discardProp = 0.05, minCentralProp = 0.75, 
  nConsideredPCs = 3, 
  signed = FALSE, 
  getDetails = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="branchSplit_+3A_expr">expr</code></td>
<td>

<p>Expression data.
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_branch1">branch1</code></td>
<td>

<p>Branch 1,
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_branch2">branch2</code></td>
<td>

<p>Branch 2.
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_discardprop">discardProp</code></td>
<td>

<p>Proportion of data to be discarded as outliers.
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_mincentralprop">minCentralProp</code></td>
<td>

<p>Minimum central proportion
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_nconsideredpcs">nConsideredPCs</code></td>
<td>

<p>Number of principal components to consider.
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_signed">signed</code></td>
<td>

<p>Should the network be considered signed?
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_getdetails">getDetails</code></td>
<td>

<p>Should details of the calculation be returned?
</p>
</td></tr>
<tr><td><code id="branchSplit_+3A_...">...</code></td>
<td>

<p>Other arguments. Present for compatibility; currently unusued.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single number or a list containing detils of the calculation.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='branchSplit.dissim'>
Branch split based on dissimilarity.
</h2><span id='topic+branchSplit.dissim'></span>

<h3>Description</h3>

<p>Calculation of branch split based on a dissimilarity matrix. This function is used as a plugin for the
dynamicTreeCut package and the user should not call this function directly. This function is experimental
and subject to change.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>branchSplit.dissim(
  dissimMat, 
  branch1, branch2, 
  upperP, 
  minNumberInSplit = 5, 
  getDetails = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="branchSplit.dissim_+3A_dissimmat">dissimMat</code></td>
<td>

<p>Dissimilarity matrix.</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_branch1">branch1</code></td>
<td>

<p>Branch 1.
</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_branch2">branch2</code></td>
<td>

<p>Branch 2.
</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_upperp">upperP</code></td>
<td>

<p>Percentile of (closest) objects to be considered.
</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_minnumberinsplit">minNumberInSplit</code></td>
<td>

<p>Minimum number of objects to be considered.
</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_getdetails">getDetails</code></td>
<td>

<p>Should details of the calculation be returned?
</p>
</td></tr>
<tr><td><code id="branchSplit.dissim_+3A_...">...</code></td>
<td>

<p>Other arguments for compatibility; currently unused.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single number or a list containing details of the calculation.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='branchSplitFromStabilityLabels'>
Branch split (dissimilarity) statistics derived from labels determined from a stability study
</h2><span id='topic+branchSplitFromStabilityLabels'></span><span id='topic+branchSplitFromStabilityLabels.individualFraction'></span><span id='topic+branchSplitFromStabilityLabels.prediction'></span>

<h3>Description</h3>

<p>These functions evaluate how different two branches are based on a series of cluster labels that are usually
obtained in a stability study but can in principle be arbitrary. The idea is to quantify how well
membership on the two tested branches can be predicted from clusters in the given stability labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>branchSplitFromStabilityLabels(
   branch1, branch2, 
   stabilityLabels, 
   ignoreLabels = 0,
   ...)

branchSplitFromStabilityLabels.prediction(
            branch1, branch2,
            stabilityLabels, ignoreLabels = 0, ...)

branchSplitFromStabilityLabels.individualFraction(
            branch1, branch2,
            stabilityLabels, ignoreLabels = 0, 
            verbose = 1, indent = 0,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="branchSplitFromStabilityLabels_+3A_branch1">branch1</code></td>
<td>

<p>A vector of indices giving members of branch 1.
</p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_branch2">branch2</code></td>
<td>

<p>A vector of indices giving members of branch 1.
</p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_stabilitylabels">stabilityLabels</code></td>
<td>

<p>A matrix of cluster labels. Each column corresponds to one clustering and each row to one object (whose
indices <code>branch1</code> and <code>branch2</code> refer to). 
</p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_ignorelabels">ignoreLabels</code></td>
<td>

<p>Label or labels that do not constitute proper clusters in <code>stabilityLabels</code>, for example because they
label unassigned objects. 
</p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="branchSplitFromStabilityLabels_+3A_...">...</code></td>
<td>

<p>Ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The idea is to measure how well clusters in <code>stabilityLabels</code> can distinguish the two given branches.
For example, if a cluster C intersects with branch1 but not branch2, it can distinguish branches 1 and 2
perfectly. On the other hand, if there is a cluster C that contains both branch 1 and branch 2, 
the two branches are
indistinguishable (based on the test clustering).  The three functions differ in the details of the
similarity calculation.  
</p>
<p><code>branchSplitFromStabilityLabels.individualFraction</code>: Currently the recommended branch split calculation
method, and default for <code><a href="#topic+hierarchicalConsensusModules">hierarchicalConsensusModules</a></code>. 
For each branch and all clusters that overlap with the branch (not necessarily with the other
branch), calculate the fraction of the cluster objects (restricted to the two
branches) that belongs to the branch. For each branch, sum these fractions over all clusters. 
If this number is relatively low, around 0.5, it means most elements are in
non-discriminative clusters.
</p>
<p><code>branchSplitFromStabilityLabels</code>: This was the original branch split measure and for backward
compatibility it still is the default method in <code><a href="#topic+blockwiseModules">blockwiseModules</a></code> and
<code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>. For each cluster C in each clustering in <code>stabilityLabels</code>, 
its contribution to the branch similarity
is min(r1, r2), where r1 = |intersect(C, branch1)|/|branch1| and r2 = |intersect(C, branch2)|/|branch2|.
The statistics for clusters in each clustering are added; the sums are then averaged across the
clusterings. 
</p>
<p><code>branchSplitFromStabilityLabels.prediction</code>: Use only for experiments, not recommended for actual
analyses because it is not stable under small changes in the branch membership.
For each cluster that overlaps with both branches, count the objects in the branch with which the cluster 
has a smaller overlap
and add it to the score for that branch. The final counts divided by number of genes on branch give a
&quot;indistinctness&quot; score; take the larger of the two indistinctness scores and call this the similarity.
</p>
<p>Since the result of the last two calculations is a similarity statistic, the final dissimilarity is defined as
1-similarity. The dissimilarity ranges between 0 (branch1 and branch2 are indistinguishable) and 1 (branch1
and branch2 are perfectly distinguishable).
</p>
<p>These statistics are quite simple and do not correct for similarity that would be expected by chance. On the
other hand, all 3 statistics are fairly (though not perfectly) stable under splitting and joining of clusters
in <code>stabilityLabels</code>.
</p>


<h3>Value</h3>

<p>Branch dissimilarity (a single number between 0 and 1).
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>These function are utilized in <code><a href="#topic+blockwiseModules">blockwiseModules</a></code>, <code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code> and
<code><a href="#topic+hierarchicalConsensusModules">hierarchicalConsensusModules</a></code>.
</p>

<hr>
<h2 id='checkAdjMat'> Check adjacency matrix </h2><span id='topic+checkAdjMat'></span><span id='topic+checkSimilarity'></span>

<h3>Description</h3>

<p>Checks a given matrix for properties that an adjacency matrix must satisfy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkAdjMat(adjMat, min = 0, max = 1)
checkSimilarity(similarity, min = -1, max = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkAdjMat_+3A_adjmat">adjMat</code></td>
<td>
<p> matrix to be checked </p>
</td></tr>
<tr><td><code id="checkAdjMat_+3A_similarity">similarity</code></td>
<td>
<p> matrix to be checked </p>
</td></tr>
<tr><td><code id="checkAdjMat_+3A_min">min</code></td>
<td>
<p>minimum allowed value for entries of the input</p>
</td></tr>
<tr><td><code id="checkAdjMat_+3A_max">max</code></td>
<td>
<p>maximum allowed value for entries of the input</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks whether the given matrix really is a 2-dimensional numeric matrix, whether it is
square, symmetric, and all finite entries are between <code>min</code> and <code>max</code>. 
If any of the conditions is not met, the
function issues an error. 
</p>


<h3>Value</h3>

<p>None. The function returns normally if all conditions are met.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjacency">adjacency</a></code></p>

<hr>
<h2 id='checkSets'>Check structure and retrieve sizes of a group of datasets.  </h2><span id='topic+checkSets'></span>

<h3>Description</h3>

<p>Checks whether given sets have the correct format and retrieves dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkSets(data, checkStructure = FALSE, useSets = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkSets_+3A_data">data</code></td>
<td>
<p> A vector of lists; in each list there must be a component named <code>data</code> whose content
is a matrix or dataframe or array of dimension 2. </p>
</td></tr>
<tr><td><code id="checkSets_+3A_checkstructure">checkStructure</code></td>
<td>
<p>If <code>FALSE</code>, incorrect structure of <code>data</code> will trigger an error. If
<code>TRUE</code>, an appropriate flag (see output) will be set to indicate whether <code>data</code> has correct
structure.</p>
</td></tr>
<tr><td><code id="checkSets_+3A_usesets">useSets</code></td>
<td>
<p>Optional specification of entries of the vector <code>data</code> that are to be checked.
Defaults to all components. This may be useful when <code>data</code> only contains information for some
of the sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For multiset calculations, many quantities (such as expression data, traits, module eigengenes etc) are
presented by a common structure, a vector of lists (one list for each set) where each list has a
component <code>data</code> that contains the actual (expression, trait, eigengene) data for the corresponding
set in the form of a dataframe. This funtion checks whether <code>data</code> conforms to this convention and
retrieves some basic dimension information (see output).
</p>


<h3>Value</h3>

<p> A list with components
</p>
<table role = "presentation">
<tr><td><code>nSets</code></td>
<td>
<p>Number of sets (length of the vector <code>data</code>).</p>
</td></tr>
<tr><td><code>nGenes</code></td>
<td>
<p>Number of columns in the <code>data</code> components in the lists. This number must be the
same for all sets.</p>
</td></tr>
<tr><td><code>nSamples</code></td>
<td>
<p>A vector of length <code>nSets</code> giving the number of rows in the <code>data</code>
components.</p>
</td></tr>
<tr><td><code>structureOK</code></td>
<td>
<p>Only set if the argument <code>checkStructure</code> equals <code>TRUE</code>. 
The value is <code>TRUE</code> if the paramter <code>data</code> passes a few tests of its
structure, and <code>FALSE</code> otherwise. The tests are not exhaustive and are meant to catch obvious user
errors rather than be bulletproof.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>

<hr>
<h2 id='chooseOneHubInEachModule'> Chooses a single hub gene in each module </h2><span id='topic+chooseOneHubInEachModule'></span>

<h3>Description</h3>

<p>chooseOneHubInEachModule returns one gene in each module with high connectivity, 
given a number of randomly selected genes to test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chooseOneHubInEachModule(
   datExpr, 
   colorh,  
   numGenes = 100, 
   omitColors = "grey", 
   power = 2, 
   type = "signed", 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chooseOneHubInEachModule_+3A_datexpr">datExpr</code></td>
<td>

<p>Gene expression data with rows as samples and columns as genes.
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_colorh">colorh</code></td>
<td>

<p>The module assignments (color vectors) corresponding to the columns in datExpr.
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_numgenes">numGenes</code></td>
<td>

<p>Th number of random genes to select per module.  Higher number of genes increases the accuracy of hub selection but slows down the function.
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_omitcolors">omitColors</code></td>
<td>

<p>All colors in this character vector (default is &quot;grey&quot;) are ignored by this function.
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_power">power</code></td>
<td>

<p>Power to use for the adjacency network (default = 2).
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_type">type</code></td>
<td>

<p>What type of network is being entered.  Common choices are &quot;signed&quot; (default) and &quot;unsigned&quot;.  With &quot;signed&quot; negative correlations count against, whereas with &quot;unsigned&quot; negative correlations are treated identically as positive correlations.
</p>
</td></tr>
<tr><td><code id="chooseOneHubInEachModule_+3A_...">...</code></td>
<td>

<p>Any other parameters accepted by the *adjacency* function
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Both functions output a character vector of genes, where the genes are the hub gene picked for each module, and the names correspond to the module in which each gene is a hub.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example: first simulate some data.

MEturquoise = sample(1:100,50)
MEblue      = sample(1:100,50)
MEbrown     = sample(1:100,50)
MEyellow    = sample(1:100,50) 
MEgreen     = c(MEyellow[1:30], sample(1:100,20))
MEred	    = c(MEbrown [1:20], sample(1:100,30))
MEblack	    = c(MEblue  [1:25], sample(1:100,25))
ME     = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen, MEred, MEblack)
dat1   = simulateDatExpr(ME,300,c(0.2,0.1,0.08,0.051,0.05,0.042,0.041,0.3), 
                         signed=TRUE)
TOM1   = TOMsimilarityFromExpr(dat1$datExpr, networkType="signed")
colnames(TOM1) &lt;- rownames(TOM1) &lt;- colnames(dat1$datExpr)
tree1 &lt;- tree2 &lt;- fastcluster::hclust(as.dist(1-TOM1),method="average")
colorh = labels2colors(dat1$allLabels)
hubs    = chooseOneHubInEachModule(dat1$datExpr, colorh)
hubs

</code></pre>

<hr>
<h2 id='chooseTopHubInEachModule'> Chooses the top hub gene in each module </h2><span id='topic+chooseTopHubInEachModule'></span>

<h3>Description</h3>

<p>chooseTopHubInEachModule returns the gene in each module with the highest connectivity, looking at all genes in the expression file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chooseTopHubInEachModule(
   datExpr, 
   colorh, 
   omitColors = "grey", 
   power = 2, 
   type = "signed", 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chooseTopHubInEachModule_+3A_datexpr">datExpr</code></td>
<td>

<p>Gene expression data with rows as samples and columns as genes.
</p>
</td></tr>
<tr><td><code id="chooseTopHubInEachModule_+3A_colorh">colorh</code></td>
<td>

<p>The module assignments (color vectors) corresponding to the columns in datExpr.
</p>
</td></tr>
<tr><td><code id="chooseTopHubInEachModule_+3A_omitcolors">omitColors</code></td>
<td>

<p>All colors in this character vector (default is &quot;grey&quot;) are ignored by this function.
</p>
</td></tr>
<tr><td><code id="chooseTopHubInEachModule_+3A_power">power</code></td>
<td>

<p>Power to use for the adjacency network (default = 2).
</p>
</td></tr>
<tr><td><code id="chooseTopHubInEachModule_+3A_type">type</code></td>
<td>

<p>What type of network is being entered.  Common choices are &quot;signed&quot; (default) and &quot;unsigned&quot;.  With &quot;signed&quot; negative correlations count against, whereas with &quot;unsigned&quot; negative correlations are treated identically as positive correlations.
</p>
</td></tr>
<tr><td><code id="chooseTopHubInEachModule_+3A_...">...</code></td>
<td>

<p>Any other parameters accepted by the *adjacency* function
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Both functions output a character vector of genes, where the genes are the hub gene picked for each module, and the names correspond to the module in which each gene is a hub.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example: first simulate some data.

MEturquoise = sample(1:100,50)
MEblue      = sample(1:100,50)
MEbrown     = sample(1:100,50)
MEyellow    = sample(1:100,50) 
MEgreen     = c(MEyellow[1:30], sample(1:100,20))
MEred	    = c(MEbrown [1:20], sample(1:100,30))
MEblack	    = c(MEblue  [1:25], sample(1:100,25))
ME     = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen, MEred, MEblack)
dat1   = simulateDatExpr(ME,300,c(0.2,0.1,0.08,0.051,0.05,0.042,0.041,0.3), signed=TRUE)
colorh = labels2colors(dat1$allLabels)
hubs    = chooseTopHubInEachModule(dat1$datExpr, colorh)
hubs

</code></pre>

<hr>
<h2 id='clusterCoef'> Clustering coefficient calculation </h2><span id='topic+clusterCoef'></span>

<h3>Description</h3>

<p>This function calculates the clustering coefficients for all nodes in the network given by the input
adjacency matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clusterCoef(adjMat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clusterCoef_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of clustering coefficients for each node.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='coClustering'>
Co-clustering measure of cluster preservation between two clusterings
</h2><span id='topic+coClustering'></span>

<h3>Description</h3>

<p>The function calculates the co-clustering statistics for each module in the reference clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coClustering(clusters.ref, clusters.test, tupletSize = 2, unassignedLabel = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coClustering_+3A_clusters.ref">clusters.ref</code></td>
<td>

<p>Reference input clustering. A vector in which each element gives the cluster label of an object.
</p>
</td></tr>
<tr><td><code id="coClustering_+3A_clusters.test">clusters.test</code></td>
<td>

<p>Test input clustering. Must be a vector of the same size as <code>cluster.ref</code>. 
</p>
</td></tr>
<tr><td><code id="coClustering_+3A_tupletsize">tupletSize</code></td>
<td>

<p>Co-clutering tuplet size.
</p>
</td></tr>
<tr><td><code id="coClustering_+3A_unassignedlabel">unassignedLabel</code></td>
<td>

<p>Optional specification of a clustering label that denotes unassigned objects. Objects with this label are
excluded from the calculation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Co-clustering of cluster q in the reference clustering and cluster q' in the test clustering measures the
overlap of clusters q and q' by the number of tuplets that can be chosen from the overlap of clusters q and
q' relative to the number of tuplets in cluster q. To arrive at a co-clustering measure for cluster q, we
sum the co-clustering of q and q' over all clusters q' in the test clustering. A value close to 1 indicates
high preservation of the reference cluster in the test clustering, while a value close to zero indicates a
low preservation.
</p>


<h3>Value</h3>

<p>A vector in which each component corresponds to a cluster in the reference clustering. Entries give the
co-clustering measure of cluster preservation. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>For example, see Langfelder P, Luo R, Oldham MC, Horvath S (2011) Is My Network Module Preserved and
Reproducible? PLoS Comput Biol 7(1): e1001057. Co-clustering is discussed in the Methods Supplement
(Supplementary text 1) of that article. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modulePreservation">modulePreservation</a></code> for a large suite of module preservation statistics
<code><a href="#topic+coClustering.permutationTest">coClustering.permutationTest</a></code> for a permutation test for co-clustering significance
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  # An example with random (unrelated) clusters:

  set.seed(1);
  nModules = 10;
  nGenes = 1000;
  cl1 = sample(c(1:nModules), nGenes, replace = TRUE);
  cl2 = sample(c(1:nModules), nGenes, replace = TRUE);
  coClustering(cl1, cl2)

  # For the same reference and test clustering:

  coClustering(cl1, cl1)


</code></pre>

<hr>
<h2 id='coClustering.permutationTest'>
Permutation test for co-clustering
</h2><span id='topic+coClustering.permutationTest'></span>

<h3>Description</h3>

<p>This function calculates permutation Z statistics that measure how different the co-clustering of modules
in a reference and test clusterings is from random. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coClustering.permutationTest(
      clusters.ref, clusters.test, 
      tupletSize = 2, 
      nPermutations = 100, 
      unassignedLabel = 0, 
      randomSeed = 12345, verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coClustering.permutationTest_+3A_clusters.ref">clusters.ref</code></td>
<td>

<p>Reference input clustering. A vector in which each element gives the cluster label of an object.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_clusters.test">clusters.test</code></td>
<td>

<p>Test input clustering. Must be a vector of the same size as <code>cluster.ref</code>.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_tupletsize">tupletSize</code></td>
<td>

<p>Co-clutering tuplet size.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_npermutations">nPermutations</code></td>
<td>

<p>Number of permutations to execute. Since the function calculates parametric p-values, a relatively small
number of permutations (at least 50) should be sufficient.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_unassignedlabel">unassignedLabel</code></td>
<td>

<p>Optional specification of a clustering label that denotes unassigned objects. Objects with this label are
excluded from the calculation.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_randomseed">randomSeed</code></td>
<td>

<p>Random seed for initializing the random number generator. If <code>NULL</code>, the generator is not initialized
(useful for calling the function sequentially). The default assures reproducibility. 
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_verbose">verbose</code></td>
<td>

<p>If non-zero, function will print out progress messages.
</p>
</td></tr>
<tr><td><code id="coClustering.permutationTest_+3A_indent">indent</code></td>
<td>

<p>Indentation for progress messages. Each unit adds two spaces.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a permutation test to determine whether observed co-clustering statistics are
significantly different from those expected by chance. It returns the observed co-clustering as well as the
permutation Z statistic, calculated as <code>(observed - mean)/sd</code>, where <code>mean</code> and <code>sd</code> are the
mean and standard deviation of the co-clustering when the test clustering is repeatedly randomly permuted. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>observed</code></td>
<td>
<p>the observed co-clustering measures for clusters in <code>clusters.ref</code> </p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>permutation Z statics</p>
</td></tr>
<tr><td><code>permuted.mean</code></td>
<td>
<p>means of the co-clustering measures when the test clustering is permuted</p>
</td></tr>
<tr><td><code>permuted.sd</code></td>
<td>
<p>standard deviations of the co-clustering measures when the test clustering is permuted</p>
</td></tr>
<tr><td><code>permuted.cc</code></td>
<td>
<p>values of the co-clustering measure for each permutation of the test clustering. A
matrix of dimensions (number of permutations)x(number of clusters in reference clustering). </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>For example, see Langfelder P, Luo R, Oldham MC, Horvath S (2011) Is My Network Module Preserved and
Reproducible? PLoS Comput Biol 7(1): e1001057. Co-clustering is discussed in the Methods Supplement
(Supplementary text 1) of that article.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coClustering">coClustering</a></code> for calculation of the &quot;observed&quot; co-clustering measure 
<code><a href="#topic+modulePreservation">modulePreservation</a></code> for a large suite of module preservation statistics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(1);
  nModules = 5;
  nGenes = 100;
  cl1 = sample(c(1:nModules), nGenes, replace = TRUE);
  cl2 = sample(c(1:nModules), nGenes, replace = TRUE);
  
  cc = coClustering(cl1, cl2)

  # Choose a low number of permutations to make the example fast
  ccPerm = coClustering.permutationTest(cl1, cl2, nPermutations = 20, verbose = 1);

  ccPerm$observed
  ccPerm$Z

  # Combine cl1 and cl2 to obtain clustering that is somewhat similar to cl1:

  cl3 = cl2;
  from1 = sample(c(TRUE, FALSE), nGenes, replace = TRUE);
  cl3[from1] = cl1[from1];

  ccPerm = coClustering.permutationTest(cl1, cl3, nPermutations = 20, verbose = 1);

  # observed co-clustering is higher than before:
  ccPerm$observed

  # Note the high preservation Z statistics:
  ccPerm$Z
</code></pre>

<hr>
<h2 id='collapseRows'>Select one representative row per group</h2><span id='topic+collapseRows'></span>

<h3>Description</h3>

<p>Abstractly speaking, the function allows one to collapse the rows of a numeric matrix, 
e.g. by forming an average or selecting one representative row for each group of rows specified by a 
grouping variable (referred to as <code>rowGroup</code>). The word &quot;collapse&quot; reflects the fact that the 
method yields a new matrix whose rows correspond to other rows of the original input data. The function 
implements several network-based and biostatistical methods for finding a representative row for each 
group specified in <code>rowGroup</code>.
Optionally, the function identifies the representative row according to the least number of missing data, 
the highest sample mean, the highest sample variance, the highest connectivity. One of the advantages of 
this function is that it implements default settings which have worked well in numerous applications. 
Below, we describe these default settings in more detail. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapseRows(datET, rowGroup, rowID, 
             method="MaxMean", connectivityBasedCollapsing=FALSE,
             methodFunction=NULL, connectivityPower=1,
             selectFewestMissing=TRUE, thresholdCombine=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collapseRows_+3A_datet">datET</code></td>
<td>
<p>matrix or data frame containing numeric values where rows correspond to variables (e.g.
microarray probes) and columns correspond to observations (e.g. microarrays). Each row of <code>datET</code> must
have a unique row identifier (specified in the vector <code>rowID</code>). The group label of each row is encoded
in the vector <code>rowGroup</code>. While <code>rowID</code> should have non-missing, unique values (identifiers), the
values of the vector <code>rowGroup</code> will typically not be unique since the function aims to pick a
representative row for each group.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_rowgroup">rowGroup</code></td>
<td>
<p>character vector whose components contain the group label (e.g. a character string) for
each row of <code>datET</code>. This vector needs to have the same length as the vector <code>rowID</code>. In gene
expression applications, this vector could contain the gene symbol (or a co-expression module label).
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_rowid">rowID</code></td>
<td>
<p>character vector of row identifiers.  This should include all the rows from
rownames(<code>datET</code>), but can include other rows. Its entries should be unique (no duplicates) and no
missing values are permitted. If the row identifier is missing for a given row, we suggest you remove this
row from <code>datET</code> before applying the function.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_method">method</code></td>
<td>
<p>character string for determining which method is used to choose a probe among
exactly 2 corresponding rows or when connectivityBasedCollapsing=FALSE. These are the options:
&quot;MaxMean&quot; (default) or &quot;MinMean&quot; = choose the row with the highest or lowest mean value, respectively.
&quot;maxRowVariance&quot; = choose the row with the highest variance (across the columns of <code>datET</code>). 
&quot;absMaxMean&quot; or &quot;absMinMean&quot; = choose the row with the highest or lowest mean absolute value.
&quot;ME&quot; = choose the eigenrow (first principal component of the rows in each group).  Note that with this
method option, connectivityBasedCollapsing is automatically set to FALSE.
&quot;Average&quot; = for each column, take the average value of the rows in each group 
&quot;function&quot; = use this method for a user-input function (see the description of the argument
&quot;methodFunction&quot;).
Note: if method=&quot;ME&quot;, &quot;Average&quot; or &quot;function&quot;, the output parameters &quot;group2row&quot; and &quot;selectedRow&quot; are not informative.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_connectivitybasedcollapsing">connectivityBasedCollapsing</code></td>
<td>
<p>logical value.
If TRUE, groups with 3 or more corresponding rows will be represented by the row with the highest
connectivity according to a signed weighted correlation network adjacency matrix among the corresponding
rows. Recall that the connectivity is defined as the rows sum of the adjacency matrix. The signed weighted
adjacency matrix is defined as A=(0.5+0.5*COR)^power where power is determined by the argument
<code>connectivityPower</code> and COR denotes the matrix of pairwise Pearson correlation coefficients among the
corresponding rows.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_methodfunction">methodFunction</code></td>
<td>
<p>character string. It only needs to be specified if method=&quot;function&quot; otherwise
its input is ignored.  Must be a function that takes a Nr x Nc matrix of numbers as input and outputs a
vector with the length Nc (e.g., colMeans).  This will then be the method used for collapsing values for
multiple rows into a single value for the row.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_connectivitypower">connectivityPower</code></td>
<td>
<p>Positive number (typically integer) for specifying the threshold (power) used
to construct the signed weighted adjacency matrix, see the description of <code>connectivityBasedCollapsing</code>.
This option is only used if connectivityBasedCollapsing=TRUE.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_selectfewestmissing">selectFewestMissing</code></td>
<td>
<p>logical values. If TRUE (default), the input expression matrix is trimmed
such that for each group only the rows with the fewest number of missing values are retained.  In situations
where an equal number of values are missing (or where there is no missing data), all rows for a given group
are retained.  Whether this value is set to TRUE or FALSE, all rows with &gt;90% missing data are omitted from
the analysis.
</p>
</td></tr>
<tr><td><code id="collapseRows_+3A_thresholdcombine">thresholdCombine</code></td>
<td>
<p>Number between -1 and 1, or NA. If NA (default), this input is ignored.
If a number between -1 and 1 is input, this value is taken as a threshold value, and collapseRows proceeds
following the &quot;maxMean&quot; method, but ONLY for ids with correlations of R&gt;thresholdCombine.  Specifically:
...1) If there is one id/group, keep the id
...2) If there are 2 ids/group, take the maximum mean expression if their correlation is &gt; thresholdCombine
...3) If there are 3+ ids/group, iteratively repeat (2) for the 2 ids with the highest correlation until 
all ids remaining have correlation &lt; thresholdCombine for each group
Note that this option usually results in more than one id per group; therefore, one must use care when 
implementing this option for use in comparisons between multiple matrices / data frames.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is robust to missing data.  Also, if rowIDs are missing, they are inferred according to the
rownames of datET when possible.  
When a group corresponds to only 1 row then it is represented by this row since there is no other choice.
Having said this, the row may be removed if it contains an excessive amount of missing data (90 percent or
more missing values), see the description of the argument <code>selectFewestMissing</code> for more details.
</p>
<p>A group is represented by a corresponding row with the fewest number of missing data if
<code>selectFewestMissing</code> has been set to TRUE. 
Often several rows have the same minimum number of missing values (or no missing values) and a representative 
must be chosen among those rows.  In this case we distinguish 2 situations:
(1) If a group corresponds to exactly 2 rows then the corresponding row with the highest average is selected
if <code>method="maxMean"</code>. Alternative methods can be chosen as described in <code>method</code>.
(2) If a group corresponds to more than 2 rows, then the function calculates a signed weighted correlation
network (with power specified in <code>connectivityPower</code>) among the corresponding rows if
<code>connectivityBasedCollapsing=TRUE</code>. Next the function calculates the network connectivity of each row 
(closely related to the sum or correlations with the other matching rows). Next it chooses the most highly
connected row as representative. If connectivityBasedCollapsing=FALSE, then <code>method</code> is used. 
For both situations, if more than one row has the same value, the first such row is chosen.
</p>
<p>Setting <code>thresholdCombine</code> is a special case of this function, as not all ids for a single group are
necessarily collapsed&ndash;only those with similar expression patterns are collapsed.  We suggest
using this option when the goal is to decrease the number of ids for computational reasons, but when
ALL ids for a single group should not be combined (for example, if two probes could represent different 
splice variants for the same gene for many genes on a microarray).
</p>
<p>Example application: when dealing with microarray gene expression data then the rows of <code>datET</code> may
correspond to unique probe identifiers and <code>rowGroup</code> may contain corresponding gene symbols. Recall
that multiple probes (specified using <code>rowID</code>=ProbeID) may correspond to the same gene symbol
(specified using <code>rowGroup</code>=GeneSymbol). In this case, <code>datET</code> contains the input expression data
with rows as rowIDs and output expression data with rows as gene symbols, collapsing all probes for a given
gene symbol into one representative.  
</p>


<h3>Value</h3>

<p>The output is a list with the following components.
</p>
<table role = "presentation">
<tr><td><code>datETcollapsed</code></td>
<td>
<p> is a numeric matrix with the same columns as the input matrix <code>datET</code>, but with
rows corresponding to the different row groups rather than individual row identifiers.  (If thresholdCombine
is set, then rows still correspond to individual row identifiers.) </p>
</td></tr>
<tr><td><code>group2row</code></td>
<td>
<p> is a matrix whose rows correspond to the unique group labels and whose 2 columns report
which group label (first column called <code>group</code>) is represented by what row label (second column called
<code>selectedRowID</code>).  Set to NULL if method=&quot;ME&quot; or &quot;function&quot;.</p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code>selectedRow</code></td>
<td>
<p> is a logical vector whose components are TRUE for probes selected as representatives and
FALSE otherwise. It has the same length as the vector probeID.  Set to NULL if method=&quot;ME&quot; or &quot;function&quot;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy A. Miller, Steve Horvath, Peter Langfelder, Chaochao Cai
</p>


<h3>References</h3>

<p>Miller JA, Langfelder P, Cai C, Horvath S (2010) Strategies for optimally aggregating gene expression data: 
The collapseRows R function. Technical Report.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ########################################################################
    # EXAMPLE 1:
    # The code simulates a data frame (called dat1) of correlated rows.
    # You can skip this part and start at the line called Typical Input Data
    # The first column of the data frame will contain row identifiers
    # number of columns (e.g. observations or microarrays)
    m=60
    # number of rows (e.g. variables or probes on a microarray) 
    n=500
    # seed module eigenvector for the simulateModule function
    MEtrue=rnorm(m)
    # numeric data frame of n rows and m columns
    datNumeric=data.frame(t(simulateModule(MEtrue,n)))
    RowIdentifier=paste("Probe", 1:n, sep="")
    ColumnName=paste("Sample",1:m, sep="")
    dimnames(datNumeric)[[2]]=ColumnName
    # Let us now generate a data frame whose first column contains the rowID
    dat1=data.frame(RowIdentifier, datNumeric)
    #we simulate a vector with n/5 group labels, i.e. each row group corresponds to 5 rows
    rowGroup=rep(  paste("Group",1:(n/5),  sep=""), 5 )
    
    # Typical Input Data 
    # Since the first column of dat1 contains the RowIdentifier, we use the following code
    datET=dat1[,-1]
    rowID=dat1[,1]
    
    # assign row names according to the RowIdentifier 
    dimnames(datET)[[1]]=rowID
    # run the function and save it in an object
    
    collapse.object=collapseRows(datET=datET, rowGroup=rowGroup, rowID=rowID)
    
    # this creates the collapsed data where 
    # the first column contains the group name
    # the second column reports the corresponding selected row name (the representative)
    # and the remaining columns report the values of the representative row
    dat1Collapsed=data.frame( collapse.object$group2row, collapse.object$datETcollapsed)
    dat1Collapsed[1:5,1:5]

    ########################################################################
    # EXAMPLE 2:
    # Using the same data frame as above, run collapseRows with a user-inputted function.
    # In this case we will use the mean.  Note that since we are choosing some combination
    #   of the probe values for each gene, the group2row and selectedRow output 
    #   parameters are not meaningful.

    collapse.object.mean=collapseRows(datET=datET, rowGroup=rowGroup, rowID=rowID, 
          method="function", methodFunction=colMeans)[[1]]

    # Note that in this situation, running the following code produces the identical results:

    collapse.object.mean.2=collapseRows(datET=datET, rowGroup=rowGroup, rowID=rowID,
          method="Average")[[1]]

    ########################################################################
    # EXAMPLE 3:
    # Using collapseRows to calculate the module eigengene.
    # First we create some sample data as in example 1 (or use your own!)
    m=60
    n=500
    MEtrue=rnorm(m)
    datNumeric=data.frame(t(simulateModule(MEtrue,n)))

    # In this example, rows are genes, and groups are modules.
    RowIdentifier=paste("Gene", 1:n, sep="")
    ColumnName=paste("Sample",1:m, sep="")
    dimnames(datNumeric)[[2]]=ColumnName
    dat1=data.frame(RowIdentifier, datNumeric)
    # We simulate a vector with n/100 modules, i.e. each row group corresponds to 100 rows
    rowGroup=rep(  paste("Module",1:(n/100),  sep=""), 100 )
    datET=dat1[,-1]
    rowID=dat1[,1]
    dimnames(datET)[[1]]=rowID

    # run the function and save it in an object
    collapse.object.ME=collapseRows(datET=datET, rowGroup=rowGroup, rowID=rowID, method="ME")[[1]]
    
    # Note that in this situation, running the following code produces the identical results:
    collapse.object.ME.2 = t(moduleEigengenes(expr=t(datET),colors=rowGroup)$eigengene)
    colnames(collapse.object.ME.2) = ColumnName
    rownames(collapse.object.ME.2) = sort(unique(rowGroup))
</code></pre>

<hr>
<h2 id='collapseRowsUsingKME'> Selects one representative row per group based on kME </h2><span id='topic+collapseRowsUsingKME'></span>

<h3>Description</h3>

<p>This function selects only the most informative probe for each gene in a kME table, only keeping the probe which has the highest kME with respect to any module in the module membership matrix.  This function is a special case of the function collapseRows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapseRowsUsingKME(MM, Gin, Pin = NULL, kMEcols = 1:dim(MM)[2])
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collapseRowsUsingKME_+3A_mm">MM</code></td>
<td>

<p>A module membership (kME) table with at least a subset of the columns corresponding to kME values.
</p>
</td></tr>
<tr><td><code id="collapseRowsUsingKME_+3A_gin">Gin</code></td>
<td>

<p>Genes labels in a 1 to 1 correspondence with the rows of MM.
</p>
</td></tr>
<tr><td><code id="collapseRowsUsingKME_+3A_pin">Pin</code></td>
<td>

<p>If NULL (default), rownames of MM are assumed to be probe IDs.  If entered, Pin must be the same length as Gin and correspond to probe IDs for MM.
</p>
</td></tr>
<tr><td><code id="collapseRowsUsingKME_+3A_kmecols">kMEcols</code></td>
<td>

<p>A numeric vector showing which columns in MM correspond to kME values.  The default is all of them. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>datETcollapsed</code></td>
<td>

<p>A numeric matrix with the same columns as the input matrix MM, but with rows corresponding to the genes rather than the probes.
</p>
</td></tr>
<tr><td><code>group2row</code></td>
<td>

<p>A matrix whose rows correspond to the unique gene labels and whose 2 columns report which gene label (first column called group) is represented by what probe (second column called selectedRowID)
</p>
</td></tr>
<tr><td><code>selectedRow</code></td>
<td>

<p>A logical vector whose components are TRUE for probes selected as representatives and FALSE otherwise. It has the same length as the vector Pin.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+collapseRows">collapseRows</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: first simulate some data
set.seed(100)
ME.A = sample(1:100,50);  ME.B = sample(1:100,50)
ME.C = sample(1:100,50);  ME.D = sample(1:100,50)  
ME1     = data.frame(ME.A, ME.B, ME.C, ME.D)
simDatA = simulateDatExpr(ME1,1000,c(0.2,0.1,0.08,0.05,0.3), signed=TRUE)
simDatB = simulateDatExpr(ME1,1000,c(0.2,0.1,0.08,0.05,0.3), signed=TRUE)
Gin     = c(colnames(simDatA$datExpr),colnames(simDatB$datExpr))
Pin     = paste("Probe",1:length(Gin),sep=".")
datExpr = cbind(simDatA$datExpr, simDatB$datExpr)
MM      = corAndPvalue(datExpr,ME1)$cor

# Now run the function and see some example output
results = collapseRowsUsingKME(MM, Gin, Pin)
head(results$MMcollapsed)
head(results$group2Row)
head(results$selectedRow)

</code></pre>

<hr>
<h2 id='collectGarbage'>Iterative garbage collection. </h2><span id='topic+collectGarbage'></span>

<h3>Description</h3>

<p>Performs garbage collection until free memory idicators show no change.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collectGarbage()
</code></pre>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='colQuantileC'> Fast colunm- and row-wise quantile of a matrix. </h2><span id='topic+colQuantileC'></span><span id='topic+rowQuantileC'></span>

<h3>Description</h3>

<p>Fast calculation of column- and row-wise quantiles of a matrix at a single probability. Implemented via compiled
code, it is much faster than the equivalent <code>apply(data, 2, quantile, prob = p)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colQuantileC(data, p)
rowQuantileC(data, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="colQuantileC_+3A_data">data</code></td>
<td>
<p> a numerical matrix column-wise quantiles are desired. Missing values are removed.</p>
</td></tr>
<tr><td><code id="colQuantileC_+3A_p">p</code></td>
<td>
<p> a single probability at which the quantile is to be calculated. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>At present, only one quantile type is implemented, namely the default type 7 used by R.
</p>


<h3>Value</h3>

<p>A vector of length equal the number of columns (for <code>colQuantileC</code>) or rows (for <code>rowQuantileC</code>) 
in <code>data</code> containing the column- or row-wise quantiles.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="stats.html#topic+quantile">quantile</a></code>; 
<code><a href="#topic+pquantile">pquantile</a></code> for another way of calculating quantiles across structured data.
</p>

<hr>
<h2 id='conformityBasedNetworkConcepts'> Calculation of conformity-based network concepts. </h2><span id='topic+conformityBasedNetworkConcepts'></span>

<h3>Description</h3>

<p>This function computes 3 types of network concepts (also known as network indices or statistics) based on
an adjacency matrix and optionally a node significance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conformityBasedNetworkConcepts(adj, GS = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conformityBasedNetworkConcepts_+3A_adj">adj</code></td>
<td>
<p> adjacency matrix. A symmetric matrix with components between 0 and 1. </p>
</td></tr>
<tr><td><code id="conformityBasedNetworkConcepts_+3A_gs">GS</code></td>
<td>
<p> optional node significance measure. A vector with length equal the dimension of <code>adj</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes 3 types of network concepts (also known as network indices or statistics) based on
an adjacency matrix and optionally a node significance measure. Specifically, it computes I) fundamental
network concepts, II) conformity based network concepts, and III) approximate conformity based network
concepts.
These network concepts are defined for any symmetric adjacency matrix (weighted and unweighted). The
network concepts are described in Dong and Horvath (2007) and Horvath and Dong (2008).
In the following, we use the term gene and node interchangeably since these methods were originally
developed for gene networks. In the following, we briefly describe the 
3 types of network concepts:
</p>
<p>Type I: fundamental network concepts are defined as a function of the off-diagonal elements of an
adjacency matrix A and/or a node significance measure GS. 
Type II: conformity-based network concepts are functions of the off-diagonal elements of the conformity
based adjacency matrix A.CF=CF*t(CF) and/or the node significance measure. These network concepts are
defined for any network for which a conformity vector can be defined. Details: For any adjacency matrix
A, the conformity vector CF is calculated by requiring that A[i,j] is approximately equal to CF[i]*CF[j].
Using the conformity one can define the matrix A.CF=CF*t(CF) which is the outer product of the conformity
vector with itself. In general, A.CF is not an adjacency matrix since its diagonal elements are different
from 1. If the off-diagonal elements of A.CF are similar to those of A according to the Frobenius matrix
norm, then A is approximately factorizable. To measure the factorizability of a network, one can
calculate the Factorizability, which is a number between 0 and 1 (Dong and Horvath 2007). The conformity
is defined using a monotonic, iterative algorithm that maximizes the factorizability measure. 
Type III: approximate conformity based network concepts are functions of all elements of the conformity
based adjacency matrix A.CF (including the diagonal) and/or the node significance measure GS. These
network concepts are very useful for deriving relationships between network concepts in networks that are
approximately factorizable.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>Factorizability</code></td>
<td>
<p>number between 0 and 1 giving the factorizability of the matrix. 
The closer to 1 the higher the evidence of factorizability,
that is, A-I is close to outer(CF,CF)-diag(CF^2).</p>
</td></tr>
<tr><td><code>fundamentalNCs</code></td>
<td>
<p>fundamental network concepts, that is network concepts calculated directly from
the given adjacency matrix <code>adj</code>. A list with components <code>ScaledConnectivity</code> (giving the
scaled connectivity of each node), <code>Connectivity</code> (connectivity of each node), <code>ClusterCoef</code>
(the clustering coefficient of each node), <code>MAR</code> (maximum adjacency ratio of each node),
<code>Density</code> (the mean density of the network), <code>Centralization</code> (the centralization of the
network), <code>Heterogeneity</code> (the heterogeneity of the network). If the input node significance
<code>GS</code> is specified, the following additional components are included: <code>NetworkSignificance</code>
(network significance, the mean node significance), and <code>HubNodeSignificance</code> (hub node significance
given by the linear regression of node significance on connectivity). </p>
</td></tr>
<tr><td><code>conformityBasedNCs</code></td>
<td>
<p>network concepts based on an approximate adjacency matrix given by the
outer product of the conformity vector but with unit diagonal. A list with components <code>Conformity</code>
(the conformity vector) and <code>Connectivity.CF, ClusterCoef.CF, MAR.CF, Density.CF, Centralization.CF,
Heterogeneity.CF</code> giving the conformity-based analogs of the above network concepts. </p>
</td></tr>
<tr><td><code>approximateConformityBasedNCs</code></td>
<td>
<p>network concepts based on an approximate adjacency matrix given by
the outer product of the conformity vector. A list with components <code>Conformity</code> 
(the conformity vector) and <code>Connectivity.CF.App, ClusterCoef.CF.App, MAR.CF.App, Density.CF.App,
Centralization.CF.App,
Heterogeneity.CF.App</code> giving the conformity-based analogs of the above network concepts. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology 2007, 1:24 
Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+networkConcepts">networkConcepts</a></code> for calculation of eigennode based network concepts for a
correlation network;
</p>
<p><code><a href="#topic+fundamentalNetworkConcepts">fundamentalNetworkConcepts</a></code> for calculation of fundamental network concepts only. 
</p>

<hr>
<h2 id='conformityDecomposition'>
Conformity and module based decomposition of a network adjacency matrix.
</h2><span id='topic+conformityDecomposition'></span>

<h3>Description</h3>

<p>The function calculates the conformity based approximation <code>A.CF</code> of an adjacency matrix and a factorizability
measure <code>Factorizability</code>. If a module assignment <code>Cl</code> is provided, it also estimates a corresponding intermodular adjacency matrix. In this case, function automatically carries out the module- and conformity based decomposition of the adjacency matrix described in chapter 2 of (Horvath 2011). </p>


<h3>Usage</h3>

<pre><code class='language-R'>conformityDecomposition(adj, Cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conformityDecomposition_+3A_adj">adj</code></td>
<td>
<p>a symmetric numeric matrix (or data frame) whose entries lie between 0 and 1.
</p>
</td></tr>
<tr><td><code id="conformityDecomposition_+3A_cl">Cl</code></td>
<td>
<p>a vector (or factor variable) of length equal to the number of rows of <code>adj</code>. The variable assigns each network node (row of <code>adj</code>) to a module. The entries of <code>Cl</code> could be integers or character strings.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We distinguish two situation depending on whether or not <code>Cl</code> equals <code>NULL</code>. 
1) Let us start out assuming that <code>Cl = NULL</code>. In this case,
the function calculates the conformity vector for a general, possibly non-factorizable network <code>adj</code> by minimizing a quadratic (sums of squares) loss function. The conformity and factorizability for an adjacency matrix is defined in (Dong and Horvath 2007, Horvath and Dong 2008) but we briefly describe it in the following. A network is called exactly factorizable if the pairwise connection strength (adjacency) between 2 network nodes can be factored into node specific contributions, named node 'conformity', i.e. if <code>adj[i,j]=Conformity[i]*Conformity[j]</code>. The conformity turns out to be highly related to the network connectivity (aka degree). If <code>adj</code> is not exactly factorizable, then the function <code>conformityDecomposition</code> calculates a conformity vector of the exactly factorizable network that best approximates <code>adj</code>. The factorizability measure <code>Factorizability</code> is a number between 0 and 1. The higher <code>Factorizability</code>, the more factorizable is <code>adj</code>. Warning: the algorithm may only converge to a local optimum and it may not converge at all. Also see the notes below.
</p>
<p>2) Let us now assume that <code>Cl</code> is not NULL, i.e. it specifies the module assignment of each node.
Then the function calculates a module- and CF-based approximation of <code>adj</code> (explained in chapter 2 in Horvath 2011). In this case, the function calculates a conformity vector <code>Conformity</code> and a matrix <code>IntermodularAdjacency</code> such that <code>adj[i,j]</code> is approximately equal to
<code>Conformity[i]*Conformity[j]*IntermodularAdjacency[module.index[i],module.index[j]]</code> where <code>module.index[i]</code> is the row of the matrix <code>IntermodularAdjacency</code> that corresponds to the module assigned to node i.
To estimate <code>Conformity</code> and a matrix <code>IntermodularAdjacency</code>, the function attempts to minimize a quadratic loss function (sums of squares).
Currently, the function only implements a heuristic algorithm for optimizing the objective function (chapter 2 of Horvath 2011). Another, more accurate Majorization Minorization (MM) algorithm for the decomposition is implemented in the function <code>propensityDecomposition</code> by Ranola et al (2011).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>A.CF</code></td>
<td>
<p>a symmetric matrix that approximates the input matrix <code>adj</code>. Roughly speaking, the i,j-the element of the matrix equals <code>Conformity[i]*Conformity[j]*IntermodularAdjacency[module.index[i],module.index[j]]</code> where <code>module.index[i]</code> is the row of the matrix <code>IntermodularAdjacency</code> that corresponds to the module assigned to node i. </p>
</td></tr> 
<tr><td><code>Conformity</code></td>
<td>
<p>a numeric vector whose entries correspond to the rows of <code>adj</code>. If <code>Cl=NULL</code> then <code>Conformity[i]</code> is the conformity.
If <code>Cl</code> is not NULL then <code>Conformity[i]</code> is the intramodular conformity with respect to the module that node i belongs to.
</p>
</td></tr>
<tr><td><code>IntermodularAdjacency</code></td>
<td>
<p> a symmetric matrix (data frame) whose rows and columns correspond to the number of modules specified in <code>Cl</code>. Interpretation: it measures the similarity (adjacency) between the modules. In this case, the rows (and columns) of <code>IntermodularAdjacency</code> correspond to the entries of <code>Cl.level</code>. </p>
</td></tr>
<tr><td><code>Factorizability</code></td>
<td>
<p> is a number between 0 and 1. If <code>Cl=NULL</code> then it equals 1, if (and only if) <code>adj</code> is exactly factorizable. If <code>Cl</code> is a vector, then it measures how well the module- and CF based decomposition approximates <code>adj</code>.  </p>
</td></tr>
<tr><td><code>Cl.level</code></td>
<td>
<p> is a vector of character strings which correspond to the factor levels of the module assignment <code>Cl</code>. Incidentally, the function automatically turns <code>Cl</code> into a factor variable. The components of Conformity and <code>IntramodularFactorizability</code> correspond to the entries of <code>Cl.level</code>. </p>
</td></tr>
<tr><td><code>IntramodularFactorizability</code></td>
<td>
<p> is a numeric vector of length equal to the number of modules specified by <code>Cl</code>. Its entries report the factorizability measure for each module. The components correspond to the entries of <code>Cl.level</code>.</p>
</td></tr>
<tr><td><code>listConformity</code></td>
<td>
</td></tr> 
</table>


<h3>Note</h3>

<p>Regarding the situation when <code>Cl=NULL</code>.
One can easily show that the conformity vector is not unique if <code>adj</code> contains only 2 nodes. However, for more than 2 nodes the conformity is uniquely defined when dealing with an exactly factorizable weighted network whose entries <code>adj[i,j]</code> are larger than 0. In this case, one can get explicit formulas for the conformity (Dong and Horvath 2007). 
</p>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>


<h3>References</h3>

<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules. BMC Systems Biology 2007, June 1:24
Horvath S, Dong J (2008) Geometric Interpretation of Gene Co-Expression Network Analysis. PloS Computational Biology. 4(8): e1000117. PMID: 18704157
Horvath S (2011) Weighted Network Analysis. Applications in Genomics and Systems Biology. Springer Book. ISBN: 978-1-4419-8818-8
Ranola JMO, Langfelder P, Song L, Horvath S, Lange K (2011) An MM algorithm for the module- and propensity based decomposition of a network. Currently a draft.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conformityBasedNetworkConcepts">conformityBasedNetworkConcepts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# assume the number of nodes can be divided by 2 and by 3
n=6
# here is a perfectly factorizable matrix
A=matrix(1,nrow=n,ncol=n)
# this provides the conformity vector and factorizability measure
conformityDecomposition(adj=A)
# now assume we have a class assignment
Cl=rep(c(1,2),c(n/2,n/2))
conformityDecomposition(adj=A,Cl=Cl)
# here is a block diagonal matrix
blockdiag.A=A
blockdiag.A[1:(n/3),(n/3+1):n]=0
blockdiag.A[(n/3+1):n , 1:(n/3)]=0
block.Cl=rep(c(1,2),c(n/3,2*n/3))
conformityDecomposition(adj= blockdiag.A,Cl=block.Cl)

# another block diagonal matrix
blockdiag.A=A
blockdiag.A[1:(n/3),(n/3+1):n]=0.3
blockdiag.A[(n/3+1):n , 1:(n/3)]=0.3
block.Cl=rep(c(1,2),c(n/3,2*n/3))
conformityDecomposition(adj= blockdiag.A,Cl=block.Cl)

</code></pre>

<hr>
<h2 id='consensusCalculation'>
Calculation of a (single) consenus with optional data calibration.
</h2><span id='topic+consensusCalculation'></span>

<h3>Description</h3>

<p>This function calculates a single consensus from given individual data, optionally first calibrating the
individual data to make them comparable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusCalculation(
  individualData,
  consensusOptions,

  useBlocks = NULL,
  randomSeed = NULL,
  saveCalibratedIndividualData = FALSE,
  calibratedIndividualDataFilePattern = "calibratedIndividualData-%a-Set%s-Block%b.RData",

  # Return options: the data can be either saved or returned but not both.
  saveConsensusData = NULL,
  consensusDataFileNames = "consensusData-%a-Block%b.RData",
  getCalibrationSamples= FALSE,

  # Internal handling of data
  useDiskCache = NULL, chunkSize = NULL,
  cacheDir = ".",
  cacheBase = ".blockConsModsCache",

  # Behaviour
  collectGarbage = FALSE,
  verbose = 1, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusCalculation_+3A_individualdata">individualData</code></td>
<td>

<p>Individual data from which the consensus is to be calculated. It can be either a list or a
<code><a href="#topic+multiData">multiData</a></code> structure. Each element in <code>individulData</code> can in turn either be a numeric
obeject (vector, matrix or array) or a <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> structure.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_consensusoptions">consensusOptions</code></td>
<td>

<p>A list of class <code>ConsensusOptions</code> that contains options for the consensus calculation. A suitable list
can be obtained by calling function <code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_useblocks">useBlocks</code></td>
<td>

<p>When <code>individualData</code> contains <code><a href="#topic+BlockwiseData">BlockwiseData</a></code>, this argument can be an
integer vector with indices of blocks for which the calculation should be performed.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_randomseed">randomSeed</code></td>
<td>

<p>If non-<code>NULL</code>, the function will save the current state of the random generator, set the given seed,
and restore the random seed to its original state upon exit. If <code>NULL</code>, the seed is not set nor is it
restored on exit.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_savecalibratedindividualdata">saveCalibratedIndividualData</code></td>
<td>

<p>Logical: should calibrated individual data be saved?
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_calibratedindividualdatafilepattern">calibratedIndividualDataFilePattern</code></td>
<td>

<p>Pattern from which file names for saving calibrated individual data are determined. The conversions
<code>%a</code>, <code>%s</code> and <code>%b</code> will be replaced by analysis name, set number and block number,
respectively.</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_saveconsensusdata">saveConsensusData</code></td>
<td>

<p>Logical: should final consensus be saved (<code>TRUE</code>) or returned in the return value (<code>FALSE</code>)?
If <code>NULL</code>, data will be saved only if input data were blockwise data saved on disk rather than held in memory
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_consensusdatafilenames">consensusDataFileNames</code></td>
<td>

<p>Pattern from which file names for saving the final consensus are determined. The conversions
<code>%a</code> and <code>%b</code> will be replaced by analysis name and block number,
respectively.</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_getcalibrationsamples">getCalibrationSamples</code></td>
<td>

<p>When calibration method in the <code>consensusOptions</code> component of <code>ConsensusTree</code> is 
<code>"single quantile"</code>, this logical argument determines whether the calibration samples should be retuned within the
return value.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_usediskcache">useDiskCache</code></td>
<td>

<p>Logical: should disk cache be used for consensus calculations? The disk cache can be used to sture chunks of
calibrated data that are small enough to fit one chunk from each set into memory (blocks may be small enough
to fit one block of one set into memory, but not small enogh to fit one block from all sets in a consensus
calculation into memory at the same time). Using disk cache is slower but lessens the memry footprint of
the calculation.
As a general guide, if individual data are split into blocks, we
recommend setting this argument to <code>TRUE</code>. If this argument is <code>NULL</code>, the function will decide
whether to use disk cache based on the number of sets and block sizes.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_chunksize">chunkSize</code></td>
<td>

<p>Integer giving the chunk size. If left <code>NULL</code>, a suitable size will be chosen automatically.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_cachedir">cacheDir</code></td>
<td>

<p>Directory in which to save cache files. The files are deleted on normal exit but persist if the function
terminates abnormally.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_cachebase">cacheBase</code></td>
<td>

<p>Base for the file names of cache files.
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage collection be forced after each major calculation?
</p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_verbose">verbose</code></td>
<td>
<p>Integer level of verbosity of diagnostic messages. Zero means silent, higher values make the
output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="consensusCalculation_+3A_indent">indent</code></td>
<td>
<p>Indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consensus is defined as the element-wise (also known as &quot;parallel&quot;) quantile of the individual data at
probability given by the <code>consensusQuantile</code> element of <code>consensusOptions</code>. Depending on the value
of component <code>calibration</code> of <code>consensusOptions</code>, the individual data are first calibrated. For
<code>consensusOptions$calibration="full quantile"</code>, the individual data are quantile normalized using
<code><a href="preprocessCore.html#topic+normalize.quantiles">normalize.quantiles</a></code>. For
<code>consensusOptions$calibration="single quantile"</code>, the individual data are raised to a power such that
the quantiles at probability <code>consensusOptions$calibrationQuantile</code> are the same. 
For <code>consensusOptions$calibration="none"</code>, the individual data are not calibrated.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>consensusData</code></td>
<td>
<p>A <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> list containing the consensus.</p>
</td></tr>
<tr><td><code>nSets</code></td>
<td>
<p>Number of input data sets.</p>
</td></tr>
<tr><td><code>saveCalibratedIndividualData</code></td>
<td>
<p>Copy of the input <code>saveCalibratedIndividualData</code>.</p>
</td></tr>
<tr><td><code>calibratedIndividualData</code></td>
<td>
<p>If input <code>saveCalibratedIndividualData</code> is <code>TRUE</code>, 
a list in which each component is a <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> structure containing the calibrated
individual data for the corresponding input individual data set.</p>
</td></tr>
<tr><td><code>calibrationSamples</code></td>
<td>
<p>If <code>consensusOptions$calibration</code> is <code>"single quantile"</code> and 
<code>getCalibrationSamples</code> is <code>TRUE</code>, a list in which each component contains the calibration samples
for the corresponding input individual data set.</p>
</td></tr>
<tr><td><code>originCount</code></td>
<td>
<p>A vector of length <code>nSets</code> that
contains, for each set, the number of (calibrated) elements that were less than or equal the consensus for that element.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>Consensus network analysis was originally described in 
Langfelder P, Horvath S. Eigengene networks for studying the relationships
between co-expression modules. BMC Systems Biology 2007, 1:54 
https://bmcsystbiol.biomedcentral.com/articles/10.1186/1752-0509-1-54
</p>


<h3>See Also</h3>

<p><code><a href="preprocessCore.html#topic+normalize.quantiles">normalize.quantiles</a></code> for quantile normalization.
</p>

<hr>
<h2 id='consensusDissTOMandTree'> Consensus clustering based on topological overlap and hierarchical clustering </h2><span id='topic+consensusDissTOMandTree'></span>

<h3>Description</h3>

<p>This function makes a consensus network using all of the default values in the WGCNA library.  Details regarding how consensus modules are formed can be found here: http://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/Consensus-NetworkConstruction-man.pdf
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusDissTOMandTree(multiExpr, softPower, TOM = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusDissTOMandTree_+3A_multiexpr">multiExpr</code></td>
<td>

<p>Expression data in the multi-set format (see checkSets). A vector of lists, one per set. Each set must contain a component data that contains the expression data.  Rows correspond to samples and columns to genes or probes. Two or more sets of data must be included and adjacencies cannot be used.
</p>
</td></tr>
<tr><td><code id="consensusDissTOMandTree_+3A_softpower">softPower</code></td>
<td>

<p>Soft thresholding power used to make each of the networks in multiExpr.
</p>
</td></tr>
<tr><td><code id="consensusDissTOMandTree_+3A_tom">TOM</code></td>
<td>

<p>A LIST of matrices holding the topological overlap corresponding to the sets in multiExpr, if they have already been calculated. Otherwise, keep TOM set as NULL (default), and TOM similarities will be calculated using the WGCNA defaults.  If inputted, this variable must be a list with each entree a TOM corresponding to the same entries in multiExpr.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>consensusTOM</code></td>
<td>

<p>The TOM difference matrix (1-TOM similarity) corresponding to the consensus network.
</p>
</td></tr>
<tr><td><code>consTree</code></td>
<td>

<p>Returned value is the same as that of hclust: An object of class hclust which describes the tree produced by the clustering process.  This tree corresponds to the dissimilarity matrix consensusTOM.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder, Steve Horvath, Jeremy Miller
</p>


<h3>References</h3>

<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression modules. BMC Systems Biology 2007, 1:54
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example consensus network using two simulated data sets

set.seed    = 100
MEturquoise = sample(1:100,50)
MEblue      = sample(1:100,50)
MEbrown     = sample(1:100,50)
MEyellow    = sample(1:100,50) 
MEgreen     = sample(1:100,50)

ME   = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen)
system.time({
dat1 = simulateDatExpr(ME,300,c(0.2,  0.10,  0.10,  0.10,  0.10,  0.2), signed=TRUE)})
system.time({
dat2 = simulateDatExpr(ME,300,c(0.18, 0.11, 0.11, 0.09, 0.11, 0.23),signed=TRUE)})
multiExpr = list(S1=list(data=dat1$datExpr),S2=list(data=dat2$datExpr))
softPower=8

system.time( {
consensusNetwork = consensusDissTOMandTree(multiExpr, softPower)})
system.time({
plotDendroAndColors(consensusNetwork$consTree, cbind(labels2colors(dat1$allLabels), 
     labels2colors(dat2$allLabels)),c("S1","S2"), dendroLabels=FALSE)})

</code></pre>

<hr>
<h2 id='consensusKME'>
Calculate consensus kME (eigengene-based connectivities) across multiple data sets.
</h2><span id='topic+consensusKME'></span>

<h3>Description</h3>

<p>Calculate consensus kME (eigengene-based connectivities) across multiple data sets, typically following a
consensus module analysis. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusKME(
  multiExpr,
  moduleLabels, 
  multiEigengenes = NULL, 
  consensusQuantile = 0, 
  signed = TRUE,
  useModules = NULL,
  metaAnalysisWeights = NULL,
  corAndPvalueFnc = corAndPvalue, corOptions = list(), corComponent = "cor",
  getQvalues = FALSE,
  useRankPvalue = TRUE,
  rankPvalueOptions = list(calculateQvalue = getQvalues, pValueMethod = "scale"),
  setNames = NULL, 
  excludeGrey = TRUE, 
  greyLabel = if (is.numeric(moduleLabels)) 0 else "grey")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusKME_+3A_multiexpr">multiExpr</code></td>
<td>

<p>Expression (or other numeric) data in a multi-set format. A vector of lists; in each list there must be a
component named &lsquo;data&rsquo; whose content is a matrix or dataframe or array of dimension 2.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_modulelabels">moduleLabels</code></td>
<td>

<p>Module labels: one label for each gene in <code>multiExpr</code>.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_multieigengenes">multiEigengenes</code></td>
<td>

<p>Optional eigengenes of modules specified in <code>moduleLabels</code>. If not given, will be calculated from
<code>multiExpr</code>. 
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_signed">signed</code></td>
<td>

<p>logical: should the network be considered signed? In signed networks (<code>TRUE</code>), 
negative kME values are not considered significant and the corresponding p-values will be one-sided. In
unsigned networks (<code>FALSE</code>), negative kME values are considered significant and the corresponding
p-values will be two-sided.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_usemodules">useModules</code></td>
<td>

<p>Optional specification of module labels to which the analysis should be restricted. This could be useful
if there are many modules, most of which are not interesting. Note that the &quot;grey&quot; module cannot be used
with <code>useModules</code>.</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_consensusquantile">consensusQuantile</code></td>
<td>

<p>Quantile for the consensus calculation. Should be a number between 0 (minimum) and 1.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_metaanalysisweights">metaAnalysisWeights</code></td>
<td>

<p>Optional specification of meta-analysis weights for each input set. If given, must be a numeric vector
of length equal the number of input data sets (i.e., <code>length(multiExpr)</code>). These weights will be used
in addition to constant weights and weights proportional to number of samples (observations) in each set.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_corandpvaluefnc">corAndPvalueFnc</code></td>
<td>

<p>Function that calculates associations between expression profiles and eigengenes. See details.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_coroptions">corOptions</code></td>
<td>

<p>List giving additional arguments to function <code>corAndPvalueFnc</code>. See details.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_corcomponent">corComponent</code></td>
<td>

<p>Name of the component of output of <code>corAndPvalueFnc</code> that contains the actual correlation.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_getqvalues">getQvalues</code></td>
<td>

<p>logical: should q-values (estimates of FDR) be calculated?
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_userankpvalue">useRankPvalue</code></td>
<td>
<p> Logical: should the <code><a href="#topic+rankPvalue">rankPvalue</a></code> function be used to obtain alternative
meta-analysis statistics?</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_rankpvalueoptions">rankPvalueOptions</code></td>
<td>
<p> Additional options for function <code><a href="#topic+rankPvalue">rankPvalue</a></code>. These include
<code>na.last</code> (default <code>"keep"</code>), <code>ties.method</code> (default <code>"average"</code>),
<code>calculateQvalue</code> (default copied from input <code>getQvalues</code>),
and <code>pValueMethod</code> (default <code>"scale"</code>).
See the help file for <code><a href="#topic+rankPvalue">rankPvalue</a></code> for full details.</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_setnames">setNames</code></td>
<td>

<p>names for the input sets. If not given, will be taken from <code>names(multiExpr)</code>. If those are
<code>NULL</code> as well, the names will be <code>"Set_1", "Set_2", ...</code>.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_excludegrey">excludeGrey</code></td>
<td>

<p>logical: should the grey module be excluded from the kME tables? Since the grey module is typically not a
real module, it makes little sense to report kME values for it.
</p>
</td></tr>
<tr><td><code id="consensusKME_+3A_greylabel">greyLabel</code></td>
<td>

<p>label that labels the grey module.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>corAndPvalueFnc</code> is currently
is expected to accept arguments <code>x</code> (gene expression profiles), <code>y</code> (eigengene expression
profiles), and <code>alternative</code> with possibilities at least <code>"greater", "two.sided"</code>. 
Any additional arguments can be passed via <code>corOptions</code>. 
</p>
<p>The function <code>corAndPvalueFnc</code> should return a list which at the least contains (1) a matrix 
of associations of genes and eigengenes (this component should have the name given by <code>corComponent</code>),
and (2) a matrix of the corresponding p-values, named &quot;p&quot; or &quot;p.value&quot;. Other components are optional but
for full functionality should include
(3) <code>nObs</code> giving the number of observations for each association (which is the number of samples less
number of missing data - this can in principle vary from association to association), and (4) <code>Z</code>
giving a Z static for each observation. If these are missing, <code>nObs</code> is calculated in the main
function, and calculations using the Z statistic are skipped.
</p>


<h3>Value</h3>

<p>Data frame with the following components (for easier readability the order here is not the same as in the
actual output):
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p>Gene ID, taken from the column names of the first input data set</p>
</td></tr>
<tr><td><code>consensus.kME.1</code>, <code>consensus.kME.2</code>, <code>...</code></td>
<td>
<p>Consensus kME (that is, the requested quantile of the kMEs in the
individual data sets)in each module for each gene across the input data
sets. The module labels (here 1, 2, etc.) correspond to those in <code>moduleLabels</code>.</p>
</td></tr>
<tr><td><code>weightedAverage.equalWeights.kME1</code>, <code>weightedAverage.equalWeights.kME2</code>, <code>...</code></td>
<td>

<p>Average kME in each module for each gene across the
input data sets. </p>
</td></tr>
<tr><td><code>weightedAverage.RootDoFWeights.kME1</code>, <code>weightedAverage.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is proportional to the square root of the 
number of samples in the set. </p>
</td></tr>
<tr><td><code>weightedAverage.DoFWeights.kME1</code>, <code>weightedAverage.DoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is proportional to number of samples in the set. </p>
</td></tr>
<tr><td><code>weightedAverage.userWeights.kME1</code>, <code>weightedAverage.userWeights.kME2</code>, <code>...</code></td>
<td>

<p>(Only present if input <code>metaAnalysisWeights</code> is non-NULL.)
Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is given in <code>metaAnalysisWeights</code>.</p>
</td></tr>
<tr><td><code>meta.Z.equalWeights.kME1</code>, <code>meta.Z.equalWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set equally. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.RootDoFWeights.kME1</code>, <code>meta.Z.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by the square root of the number of
samples. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.DoFWeights.kME1</code>, <code>meta.Z.DoFWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by the number of
samples. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.userWeights.kME1</code>, <code>meta.Z.userWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by <code>metaAnalysisWeights</code>. 
Only returned if <code>metaAnalysisWeights</code> is non-NULL and the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.p.equalWeights.kME1</code>, <code>meta.p.equalWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the equal-weight meta-analysis Z statistics. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.RootDoFWeights.kME1</code>, <code>meta.p.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the meta-analysis Z statistics with weights proportional to the square root of the
number of samples. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.DoFWeights.kME1</code>, <code>meta.p.DoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the degree-of-freedom weight meta-analysis Z statistics. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.userWeights.kME1</code>, <code>meta.p.userWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the user-supplied weight meta-analysis Z statistics. Only returned if
<code>metaAnalysisWeights</code> is non-NULL and the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.q.equalWeights.kME1</code>, <code>meta.q.equalWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the equal-weight meta-analysis p-values. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.RootDoFWeights.kME1</code>, <code>meta.q.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the meta-analysis p-values with weights proportional to the square root of the 
number of samples. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.DoFWeights.kME1</code>, <code>meta.q.DoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the degree-of-freedom weight meta-analysis p-values. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.userWeights.kME1</code>, <code>meta.q.userWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the user-specified weight meta-analysis p-values. Only present if
<code>metaAnalysisWeights</code> is non-NULL, 
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
</table>
<p>The next set of columns contain the results of function <code><a href="#topic+rankPvalue">rankPvalue</a></code> and are only present if
input <code>useRankPvalue</code> is <code>TRUE</code>. Some columns may be missing depending on the options specified in
<code>rankPvalueOptions</code>. We explicitly list columns that are based on weighing each set equally; names of
these columns carry the suffix <code>.equalWeights</code>
</p>
<table role = "presentation">
<tr><td><code>pValueExtremeRank.ME1.equalWeights</code>, <code>pValueExtremeRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>This is the minimum between pValueLowRank and
pValueHighRank, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowRank.ME1.equalWeights</code>, <code>pValueLowRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
across the columns of datS based on the rank method.</p>
</td></tr>
<tr><td><code>pValueHighRank.ME1.equalWeights</code>, <code>pValueHighRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
across the columns of datS based on the rank method.</p>
</td></tr> 
<tr><td><code>pValueExtremeScale.ME1.equalWeights</code>, <code>pValueExtremeScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>This is the minimum between pValueLowScale and
pValueHighScale, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowScale.ME1.equalWeights</code>, <code>pValueLowScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
across the columns of datS based on the Scale method.</p>
</td></tr> 
<tr><td><code>pValueHighScale.ME1.equalWeights</code>, <code>pValueHighScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low
value across the columns of datS based on the Scale method.</p>
</td></tr> 
<tr><td><code>qValueExtremeRank.ME1.equalWeights</code>, <code>qValueExtremeRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding
to the p-value pValueExtremeRank</p>
</td></tr> 
<tr><td><code>qValueLowRank.ME1.equalWeights</code>, <code>qValueLowRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueLowRank</p>
</td></tr> 
<tr><td><code>qValueHighRank.ME1.equalWeights</code>, <code>lueHighRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueHighRank</p>
</td></tr> 
<tr><td><code>qValueExtremeScale.ME1.equalWeights</code>, <code>qValueExtremeScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value)
corresponding to the p-value pValueExtremeScale</p>
</td></tr>
<tr><td><code>qValueLowScale.ME1.equalWeights</code>, <code>qValueLowScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueLowScale</p>
</td></tr>
<tr><td><code>qValueHighScale.ME1.equalWeights</code>, <code>qValueHighScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to
the p-value pValueHighScale</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Analogous columns corresponding to weighing individual sets by the square root of the number of
samples, by number of samples, and by user weights (if given). The corresponding column name suffixes are 
<code>.RootDoFWeights</code>, <code>.DoFWeights</code>, and <code>.userWeights</code>.</p>
</td></tr>
</table>
<p>The following set of columns summarize kME in individual input data sets.
</p>
<table role = "presentation">
<tr><td><code>kME1.Set_1</code>, <code>kME1.Set_2</code>, <code>...</code>, <code>kME2.Set_1</code>, <code>kME2.Set_2</code>, <code>...</code></td>
<td>
<p> kME values for each gene in each module in
each given data set. </p>
</td></tr>
<tr><td><code>p.kME1.Set_1</code>, <code>p.kME1.Set_2</code>, <code>...</code>, <code>p.kME2.Set_1</code>, <code>p.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> p-values corresponding to 
kME values for each gene in each module in each given data set. </p>
</td></tr>
<tr><td><code>q.kME1.Set_1</code>, <code>q.kME1.Set_2</code>, <code>...</code>, <code>q.kME2.Set_1</code>, <code>q.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> q-values corresponding to 
kME values for each gene in each module in each given data set. Only returned if <code>getQvalues</code> is
<code>TRUE</code>. </p>
</td></tr>
<tr><td><code>Z.kME1.Set_1</code>, <code>Z.kME1.Set_2</code>, <code>...</code>, <code>Z.kME2.Set_1</code>, <code>Z.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> Z statistics corresponding to
kME values for each gene in each module in each given data set. Only present if the function
<code>corAndPvalueFnc</code>                 
returns the Z statistics corresponding to the kME values. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>Langfelder P, Horvath S., WGCNA: an R package for weighted correlation network analysis.
BMC Bioinformatics. 2008 Dec 29; 9:559.
</p>


<h3>See Also</h3>

<p><a href="#topic+signedKME">signedKME</a> for eigengene based connectivity in a single data set.
<a href="#topic+corAndPvalue">corAndPvalue</a>, <a href="#topic+bicorAndPvalue">bicorAndPvalue</a> for two alternatives for calculating correlations and the
corresponding p-values and Z scores. Both can be used with this function.
</p>

<hr>
<h2 id='consensusMEDissimilarity'> Consensus dissimilarity of module eigengenes. </h2><span id='topic+consensusMEDissimilarity'></span>

<h3>Description</h3>

<p>Calculates consensus dissimilarity <code>(1-cor)</code> of given module eigengenes realized in several sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusMEDissimilarity(MEs, useAbs = FALSE, useSets = NULL, method = "consensus")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusMEDissimilarity_+3A_mes">MEs</code></td>
<td>
<p>Module eigengenes of the same modules in several sets. </p>
</td></tr>
<tr><td><code id="consensusMEDissimilarity_+3A_useabs">useAbs</code></td>
<td>
<p>Controls whether absolute value of correlation should be used instead of correlation in
the calculation of dissimilarity. </p>
</td></tr>
<tr><td><code id="consensusMEDissimilarity_+3A_usesets">useSets</code></td>
<td>
<p>If the consensus is to include only a selection of the given sets, this vector (or
scalar in the case of a single set) can be used to specify the selection. If <code>NULL</code>, all sets will
be used. </p>
</td></tr>
<tr><td><code id="consensusMEDissimilarity_+3A_method">method</code></td>
<td>
<p>A character string giving the method to use. Allowed values are (abbreviations of) 
<code>"consensus"</code> and <code>"majority"</code>. The consensus dissimilarity is calculated as the
minimum of given set dissimilarities for <code>"consensus"</code> and as the average for <code>"majority"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the
individual set dissimilarities of the given eigengenes in each set, then takes the (parallel) maximum or
average over all sets. For details on the structure of imput data, see <code><a href="#topic+checkSets">checkSets</a></code>. 
</p>


<h3>Value</h3>

<p>A dataframe containing the matrix of dissimilarities, with <code>names</code> and <code>rownames</code> set
appropriately.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+checkSets">checkSets</a></code></p>

<hr>
<h2 id='consensusOrderMEs'> Put close eigenvectors next to each other in several sets. </h2><span id='topic+consensusOrderMEs'></span>

<h3>Description</h3>

<p>Reorder given (eigen-)vectors such that similar ones (as measured by correlation) are next to each
other. This is a multi-set version of <code><a href="#topic+orderMEs">orderMEs</a></code>; the dissimilarity used can be of consensus
type (for each pair of eigenvectors the consensus dissimilarity is the maximum of individual set
dissimilarities over all sets) or of majority type (for each pair of eigenvectors the consensus
dissimilarity is the average of individual set dissimilarities over all sets).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusOrderMEs(MEs, useAbs = FALSE, useSets = NULL, 
                  greyLast = TRUE, 
                  greyName = paste(moduleColor.getMEprefix(), "grey", sep=""), 
                  method = "consensus")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusOrderMEs_+3A_mes">MEs</code></td>
<td>
<p>Module eigengenes of several sets in a multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A
vector of lists, with each list corresponding to one dataset and the module eigengenes in the component
<code>data</code>, that is <code>MEs[[set]]$data[sample, module]</code> is the expression of the eigengene of module
<code>module</code> in sample <code>sample</code> in dataset <code>set</code>. The number of samples can be different
between the sets, but the modules must be the same. </p>
</td></tr> 
<tr><td><code id="consensusOrderMEs_+3A_useabs">useAbs</code></td>
<td>
<p>Controls whether vector similarity should be given by absolute value of correlation or
plain correlation.</p>
</td></tr>
<tr><td><code id="consensusOrderMEs_+3A_usesets">useSets</code></td>
<td>
<p>Allows the user to specify for which sets the eigengene ordering is to be performed.</p>
</td></tr>
<tr><td><code id="consensusOrderMEs_+3A_greylast">greyLast</code></td>
<td>
<p>Normally the color grey is reserved for unassigned genes; hence the grey module is not
a proper module and it is conventional to put it last. If this is not desired, set the parameter to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="consensusOrderMEs_+3A_greyname">greyName</code></td>
<td>
<p>Name of the grey module eigengene.</p>
</td></tr>
<tr><td><code id="consensusOrderMEs_+3A_method">method</code></td>
<td>
<p>A character string giving the method to be used calculating the consensus
dissimilarity. Allowed values are (abbreviations of) 
<code>"consensus"</code> and <code>"majority"</code>. The consensus dissimilarity is calculated as the
maximum of given set dissimilarities for <code>"consensus"</code> and as the average for <code>"majority"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ordering module eigengenes is useful for plotting purposes. This function calculates the consensus
or majority
dissimilarity of given eigengenes over the sets specified by <code>useSets</code> (defaults to all sets).
A hierarchical dendrogram is calculated using the dissimilarity and the order given by the dendrogram is
used for the eigengenes in all other sets.
</p>


<h3>Value</h3>

<p>A vector of lists of the same type as <code>MEs</code> containing the re-ordered eigengenes.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code>, <code><a href="#topic+multiSetMEs">multiSetMEs</a></code>, <code><a href="#topic+orderMEs">orderMEs</a></code></p>

<hr>
<h2 id='consensusProjectiveKMeans'> Consensus projective K-means (pre-)clustering of expression data </h2><span id='topic+consensusProjectiveKMeans'></span>

<h3>Description</h3>

<p>Implementation of a consensus variant of K-means clustering for expression data across multiple data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusProjectiveKMeans(
  multiExpr, 
  preferredSize = 5000, 
  nCenters = NULL, 
  sizePenaltyPower = 4,
  networkType = "unsigned", 
  randomSeed = 54321,
  checkData = TRUE,
  imputeMissing = TRUE,
  useMean = (length(multiExpr) &gt; 3),
  maxIterations = 1000, 
  verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusProjectiveKMeans_+3A_multiexpr">multiExpr</code></td>
<td>
<p>  expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_preferredsize">preferredSize</code></td>
<td>
<p> preferred maximum size of clusters. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_ncenters">nCenters</code></td>
<td>
<p> number of initial clusters. Empirical evidence suggests that more centers will give a 
better preclustering; the default is <code>as.integer(min(nGenes/20, 100*nGenes/preferredSize))</code> 
and is an attempt to arrive at a reasonable number given the resources available. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_sizepenaltypower">sizePenaltyPower</code></td>
<td>
<p> parameter specifying how severe is the penalty for clusters that exceed
<code>preferredSize</code>. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_checkdata">checkData</code></td>
<td>
<p> logical: should data be checked for genes with zero variance and 
genes and samples with excessive numbers of missing samples? Bad samples are ignored; returned cluster
assignment for bad genes will be <code>NA</code>. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_imputemissing">imputeMissing</code></td>
<td>
<p> logical: should missing values in <code>datExpr</code> be imputed before the calculations
start? If the missing data are not imputed, they will be replaced by 0 which can be problematic.</p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_usemean">useMean</code></td>
<td>
<p> logical: should mean distance across sets be used instead of maximum? See details. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_maxiterations">maxIterations</code></td>
<td>
<p> maximum iterations to be attempted. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="consensusProjectiveKMeans_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The principal aim of this function within WGCNA is to pre-cluster a large number of genes into smaller
blocks that can be handled using standard WGCNA techniques. 
</p>
<p>This function implements a variant of K-means clustering that is suitable for co-expression analysis.
Cluster centers are defined by the first principal component, and distances by correlation. Consensus
distance across several sets is defined as the maximum of the corresponding distances in individual
sets; however, if <code>useMean</code> is set, the mean distance will be used instead of the maximum. 
The distance between a gene and a center of a cluster is multiplied by a factor of
<code class="reqn">max(clusterSize/preferredSize, 1)^{sizePenaltyPower}</code>, thus penalizing clusters whose size exceeds
<code>preferredSize</code>. The function starts with randomly generated cluster assignment (hence the need to
set the random seed for repeatability) and executes interations of calculating new centers and
reassigning genes to nearest (in the consensus sense) center until the clustering becomes stable. 
Before returning, nearby
clusters are iteratively combined if their combined size is below <code>preferredSize</code>.
</p>
<p>Consensus distance defined as maximum of distances in all sets is consistent with the approach taken in
<code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>, but the procedure may not converge. Hence it is advisable to use
the mean as consensus in cases where there are multiple data sets (4 or more, say) and/or if the input
data sets are very different. 
</p>
<p>The standard principal component calculation via the function <code>svd</code> fails from time to time
(likely a convergence problem of the underlying lapack functions). Such errors are trapped and the
principal component is approximated by a weighted average of expression profiles in the cluster. If
<code>verbose</code> is set above 2, an informational message is printed whenever this approximation is used.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>clusters</code></td>
<td>
<p> a numerical vector with one component per input gene, giving the cluster number in
which the gene is assigned. </p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p> a vector of lists, one list per set. Each list contains a component <code>data</code> that
contains a matrix whose columns are the cluster centers in the corresponding set. </p>
</td></tr>
<tr><td><code>unmergedClusters</code></td>
<td>
<p>  a numerical vector with one component per input gene, giving the cluster
number in which the gene was assigned before the final merging step. </p>
</td></tr>
<tr><td><code>unmergedCenters</code></td>
<td>
<p>  a vector of lists, one list per set. Each list contains a component
<code>data</code> that contains a matrix whose columns are the cluster centers before merging in the
corresponding set. </p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+projectiveKMeans">projectiveKMeans</a></code> </p>

<hr>
<h2 id='consensusRepresentatives'>
Consensus selection of group representatives
</h2><span id='topic+consensusRepresentatives'></span>

<h3>Description</h3>

<p>Given multiple data sets corresponding to the same variables and a grouping of variables into groups, 
the function selects a
representative variable for each group using a variety of possible selection approaches. Typical uses include
selecting a representative probe for each gene in microarray data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusRepresentatives(
   mdx, 
   group, 
   colID, 
   consensusQuantile = 0, 
   method = "MaxMean", 
   useGroupHubs = TRUE, 
   calibration = c("none", "full quantile"), 
   selectionStatisticFnc = NULL, 
   connectivityPower = 1, 
   minProportionPresent = 1, 
   getRepresentativeData = TRUE, 
   statisticFncArguments = list(), 
   adjacencyArguments = list(), 
   verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusRepresentatives_+3A_mdx">mdx</code></td>
<td>
<p> A <code><a href="#topic+multiData">multiData</a></code> structure. All sets must have the same columns.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_group">group</code></td>
<td>

<p>Character vector whose components contain the group label (e.g. a character string) for
each entry of <code>colID</code>. This vector must be of the same length as the vector <code>colID</code>. In gene
expression applications, this vector could contain the gene symbol (or a co-expression module label).
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_colid">colID</code></td>
<td>
<p>Character vector of column identifiers.  This must include all the column names from
<code>mdx</code>, but can include other values as well. Its entries must be unique (no duplicates) and no
missing values are permitted.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_consensusquantile">consensusQuantile</code></td>
<td>

<p>A number between 0 and 1 giving the quantile probability for consensus calculation.
0 means the minimum value (true consensus) will be used.</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_method">method</code></td>
<td>
<p>character string for determining which method is used to choose the representative 
(when <code>useGroupHubs</code> is <code>TRUE</code>, this method is only used for groups with 2
variables).
The following values can be used:
&quot;MaxMean&quot; (default) or &quot;MinMean&quot; return the variable with the highest or lowest mean value, respectively;
&quot;maxRowVariance&quot; return the variable with the highest variance;
&quot;absMaxMean&quot; or &quot;absMinMean&quot; return the variable with the highest or lowest mean absolute value; and
&quot;function&quot; will call a user-input function (see the description of the argument
<code>selectionStatisticFnc</code>). The built-in functions can be instructed to use robust analogs (median and
median absolute deviation) by also specifying <code>statisticFncArguments=list(robust = TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_usegrouphubs">useGroupHubs</code></td>
<td>
<p>Logical: if <code>TRUE</code>, groups with 3 or more variables will be
represented by the variable with the highest
connectivity according to a signed weighted correlation network adjacency matrix among the corresponding
rows. The connectivity is defined as the row sum of the adjacency matrix. The signed weighted
adjacency matrix is defined as A=(0.5+0.5*COR)^power where power is determined by the argument
<code>connectivityPower</code> and COR denotes the matrix of pairwise correlation coefficients among the
corresponding rows. Additional arguments to the underlying function <code><a href="#topic+adjacency">adjacency</a></code> can be specified
using the argument <code>adjacencyArguments</code> below.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_calibration">calibration</code></td>
<td>
<p>Character string describing the method of calibration of the selection statistic among
the data sets. Recognized values are <code>"none"</code> (no calibration) and <code>"full quantile"</code> (quantile
normalization). </p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_selectionstatisticfnc">selectionStatisticFnc</code></td>
<td>
<p>User-supplied function used to calculate the selection statistic when
<code>method</code> above equals <code>"function"</code>.  The function must take argumens <code>x</code> (a matrix) and
possibly other arguments that can be specified using <code>statisticFncArguments</code> below. The return value
must be a vector with one component per column of <code>x</code> giving the selection statistic for each column. 
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_connectivitypower">connectivityPower</code></td>
<td>
<p>Positive number (typically integer) for specifying the soft-thresholding power used
to construct the signed weighted adjacency matrix, see the description of <code>useGroupHubs</code>.
This option is only used if <code>useGroupHubs</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_minproportionpresent">minProportionPresent</code></td>
<td>

<p>A number between 0 and 1 specifying a filter of candidate probes. Specifically, for each group, the variable 
with the maximum consensus proportion of present data is found. Only variables whose consensus proportion of 
present data is at least <code>minProportionPresent</code> times the  maximum consensus proportion are retained as 
candidates for being a representative.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_getrepresentativedata">getRepresentativeData</code></td>
<td>
<p>Logical: should the representative data, i.e., <code>mdx</code> restricted to
the representative variables, be returned? </p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_statisticfncarguments">statisticFncArguments</code></td>
<td>
<p> A list giving further arguments to the selection statistic function. Can be
used to supply additional arguments to the user-specified <code>selectionStatisticFnc</code>; the value 
<code>list(robust = TRUE)</code> can be used with the built-in functions to use their robust variants.</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_adjacencyarguments">adjacencyArguments</code></td>
<td>
<p>Further arguments to the function <code>adjacency</code>, e.g.
<code>adjacencyArguments=list(corFnc = "bicor", corOptions = "use = 'p', maxPOutliers = 0.05")</code> will select
the robust correlation <code><a href="#topic+bicor">bicor</a></code> with a good set of options. Note that the <code><a href="#topic+adjacency">adjacency</a></code>
arguments <code>type</code> and <code>power</code> cannot be changed.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_verbose">verbose</code></td>
<td>

<p>Level of verbosity; 0 means silent, larger values will cause progress messages to be printed.
</p>
</td></tr>
<tr><td><code id="consensusRepresentatives_+3A_indent">indent</code></td>
<td>

<p>Indent for the diagnostic messages; each unit equals two spaces.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was inspired by <code><a href="#topic+collapseRows">collapseRows</a></code>, but there are also important differences. This function
focuses on selecting representatives; when summarization is more important, <code>collapseRows</code> provides more
flexibility since it does not require that a single representative be selected. 
</p>
<p>This function and <code>collapseRows</code> use different input and ouput conventions; user-specified functions need
to be tailored differently for <code>collapseRows</code> than for <code>consensusRepresentatives</code>.
</p>
<p>Missing data are allowed and are treated as missing at random. If <code>rowID</code> is <code>NULL</code>, it is replaced
by the variable names in <code>mdx</code>.
</p>
<p>All groups with a single variable are represented by that variable, unless the consensus proportion of present
data in the variable is lower than <code>minProportionPresent</code>, in which case the variable and the group are
excluded from the output. 
</p>
<p>For all variables belonging to groups with 2 variables (when <code>useGroupHubs=TRUE</code>) or with at least 2 variables
(when <code>useGroupHubs=FALSE</code>), selection statistics are calculated in each set (e.g., the selection
statistic may be the mean, variance, etc). This results in a matrix of selection statistics (one entry per
variable per data set). The selection statistics are next optionally calibrated (normalized) between sets to
make them comparable; currently the only implemented calibration method is quantile normalization. 
</p>
<p>For
each variable, the consensus selection statistic is defined as the 
consensus of the (calibrated) selection statistics across the data sets is calculated. The
'consensus' of a vector (say 'x') is simply defined as the quantile with probability
<code>consensusQuantile</code> of the vector x. Important exception: for the <code>"MinMean"</code> and
<code>"absMinMean"</code> methods, the consensus is the quantile with probability <code>1-consensusQuantile</code>, since
the idea of the consensus is to select the worst (or close to worst) value across the data sets.
</p>
<p>For each group, the representative is selected as the variable with the best (typically highest, but for
<code>"MinMean"</code> and 
<code>"absMinMean"</code> methods the lowest) consensus selection statistic.
</p>
<p>If <code>useGroupHubs=TRUE</code>, the intra-group connectivity is calculated for all variables in each set. The
intra-group connectivities are optionally calibrated (normalized) between sets, and consensus intra-group
connectivity is calculated similarly to the consensus selection statistic above. In each group, the variable
with the highest consensus intra-group connectivity is chosen as the representative. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>representatives</code></td>
<td>
<p>A named vector giving, for each group, the selected representative (input <code>rowID</code>
or the variable (column) name in <code>mdx</code>). Names correspond to groups.</p>
</td></tr>
<tr><td><code>varSelected</code></td>
<td>
<p>A logical vector with one entry per variable (column) in input <code>mdx</code> (possibly
after restriction to variables occurring in <code>colID</code>), <code>TRUE</code> if the column was selected as a
representative.</p>
</td></tr>
<tr><td><code>representativeData</code></td>
<td>
<p>Only present if <code>getRepresentativeData</code> is <code>TRUE</code>;
the input <code>mdx</code> restricted to the representative variables, with column
names changed to the corresponding groups.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder, based on code by Jeremy Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> for a description of the <code>multiData</code> structures;
<code><a href="#topic+collapseRows">collapseRows</a></code> that solves a related but different problem. Please note the differences in input
and output!
</p>

<hr>
<h2 id='consensusTOM'>Consensus network (topological overlap).</h2><span id='topic+consensusTOM'></span>

<h3>Description</h3>

<p>Calculation of a consensus network (topological overlap).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusTOM(
      # Supply either ...
      # ... information needed to calculate individual TOMs
      multiExpr,

      # Data checking options
      checkMissingData = TRUE,

      # Blocking options
      blocks = NULL,
      maxBlockSize = 5000,
      blockSizePenaltyPower = 5,
      nPreclusteringCenters = NULL,
      randomSeed = 54321,

      # Network construction arguments: correlation options

      corType = "pearson",
      maxPOutliers = 1,
      quickCor = 0,
      pearsonFallback = "individual",
      cosineCorrelation = FALSE,
      replaceMissingAdjacencies = FALSE,

      # Adjacency function options

      power = 6,
      networkType = "unsigned",
      checkPower = TRUE,

      # Topological overlap options

      TOMType = "unsigned",
      TOMDenom = "min",
      suppressNegativeTOM = FALSE,

      # Save individual TOMs?

      saveIndividualTOMs = TRUE,
      individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",

      # ... or individual TOM information

      individualTOMInfo = NULL,
      useIndivTOMSubset = NULL,

   ##### Consensus calculation options 

      useBlocks = NULL,

      networkCalibration = c("single quantile", "full quantile", "none"),

      # Save calibrated TOMs?
      saveCalibratedIndividualTOMs = FALSE,
      calibratedIndividualTOMFilePattern = "calibratedIndividualTOM-Set%s-Block%b.RData",

      # Simple quantile calibration options
      calibrationQuantile = 0.95,
      sampleForCalibration = TRUE, sampleForCalibrationFactor = 1000,
      getNetworkCalibrationSamples = FALSE,

      # Consensus definition
      consensusQuantile = 0,
      useMean = FALSE,
      setWeights = NULL,

      # Return options
      saveConsensusTOMs = TRUE,
      consensusTOMFilePattern = "consensusTOM-Block%b.RData",
      returnTOMs = FALSE,

      # Internal handling of TOMs
      useDiskCache = NULL, chunkSize = NULL,
      cacheDir = ".",
      cacheBase = ".blockConsModsCache",

      nThreads = 1,

      # Diagnostic messages
      verbose = 1,
      indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusTOM_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_checkmissingdata">checkMissingData</code></td>
<td>
<p>logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_blocks">blocks</code></td>
<td>
<p> optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p> integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>number of centers for pre-clustering. Larger numbers typically results in better
but slower pre-clustering. The default is <code>as.integer(min(nGenes/20, 100*nGenes/preferredSize))</code>
and is an attempt to arrive at a reasonable number given the resources available. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pariwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> only used for <code>corType=="bicor"</code>. Specifies the maximum percentile of data
that can be considered outliers on either
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_quickcor">quickCor</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation, if used, should revert to Pearson when
median absolute deviation (mad) is zero. Recongnized values are (abbreviations of)
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation.
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad.
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). Has no
effect for Pearson correlation. See <code><a href="#topic+bicor">bicor</a></code>.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>
<p>logical: should the cosine version of the correlation calculation be used? The
cosine calculation differs from the standard one in that it does not subtract the mean. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_checkpower">checkPower</code></td>
<td>
<p> logical: should basic sanity check be performed on the supplied <code>power</code>? If
you would like to experiment with unusual powers, set the argument to <code>FALSE</code> and proceed with
caution. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>logical: should missing values in the calculation of adjacency be replaced
by 0?</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce
better results but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? Negative TOM values can occur when
<code>TOMType</code> is <code>"signed Nowick"</code>.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_saveindividualtoms">saveIndividualTOMs</code></td>
<td>
<p>logical: should individual TOMs be saved to disk for later use? </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>
<p>character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names turn
out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_individualtominfo">individualTOMInfo</code></td>
<td>
<p> Optional data for TOM matrices in individual data sets. This object is returned by
the function <code><a href="#topic+blockwiseIndividualTOMs">blockwiseIndividualTOMs</a></code>. If not given, appropriate topological overlaps will be
calculated using the network contruction options below. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_useindivtomsubset">useIndivTOMSubset</code></td>
<td>
<p> If <code>individualTOMInfo</code> is given, this argument allows to only select a subset
of the individual set networks contained in <code>individualTOMInfo</code>. It should be a numeric vector giving the
indices of the individual sets to be used. Note that this argument is NOT applied to <code>multiExpr</code>. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_useblocks">useBlocks</code></td>
<td>
<p>optional specification of blocks that should be used for the calcualtions. The default is to
use all blocks.
</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_networkcalibration">networkCalibration</code></td>
<td>
<p>network calibration method. One of &quot;single quantile&quot;, &quot;full quantile&quot;, &quot;none&quot;
(or a unique abbreviation of one of them).</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_savecalibratedindividualtoms">saveCalibratedIndividualTOMs</code></td>
<td>
<p>logical: should the calibrated individual TOMs be saved?
</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_calibratedindividualtomfilepattern">calibratedIndividualTOMFilePattern</code></td>
<td>
<p>pattern of file names for saving calibrated individual TOMs.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_calibrationquantile">calibrationQuantile</code></td>
<td>
<p> if <code>networkCalibration</code> is <code>"single quantile"</code>, 
topological overlaps (or adjacencies if
TOMs are not computed) will be scaled such that their <code>calibrationQuantile</code> quantiles will agree. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_sampleforcalibration">sampleForCalibration</code></td>
<td>
<p> if <code>TRUE</code>, calibration quantiles will be determined from a sample of network
similarities. Note that using all data can double the memory footprint of the function and the function
may fail. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_sampleforcalibrationfactor">sampleForCalibrationFactor</code></td>
<td>
<p> determines the number of samples for calibration: the number is
<code>1/calibrationQuantile * sampleForCalibrationFactor</code>. Should be set well above 1 to ensure accuracy of the
sampled quantile. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_getnetworkcalibrationsamples">getNetworkCalibrationSamples</code></td>
<td>
<p>logical: should the sampled values used for network calibration be
returned?</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_consensusquantile">consensusQuantile</code></td>
<td>
<p> quantile at which consensus is to be defined. See details. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_usemean">useMean</code></td>
<td>
<p>logical: should the consensus be determined from a (possibly weighted) mean across the
data sets rather than a quantile?</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_setweights">setWeights</code></td>
<td>
<p>Optional vector (one component per input set) of weights to be used for weighted mean
consensus. Only used when <code>useMean</code> above is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_saveconsensustoms">saveConsensusTOMs</code></td>
<td>
<p> logical: should the consensus topological overlap matrices for each block be saved
and returned?  </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_consensustomfilepattern">consensusTOMFilePattern</code></td>
<td>
<p> character string containing the file namefiles containing the
consensus topological overlaps. The tag <code>%b</code> will be replaced by the block number. If the resulting file
names are non-unique (for example, because the user gives a file name without a <code>%b</code> tag), an error
will be generated.
These files are standard R data files and can be loaded using the <code><a href="base.html#topic+load">load</a></code>
function. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_returntoms">returnTOMs</code></td>
<td>
<p>logical: should calculated consensus TOM(s) be returned?
</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_usediskcache">useDiskCache</code></td>
<td>
<p> should calculated network similarities in individual sets be temporarilly saved
to disk? Saving to disk is somewhat slower than keeping all data in memory, but for large blocks and/or
many sets the memory footprint may be too big. If not given (the default), the function will determine
the need of caching based on the size of the data. See <code>chunkSize</code> below for additional information. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_chunksize">chunkSize</code></td>
<td>
<p> network similarities are saved in smaller chunks of size <code>chunkSize</code>. If <code>NULL</code>,
an appropriate chunk size will be determined from an estimate of available memory. Note that if the chunk size
is greater than the memory required for storing intemediate results, disk cache use will automatically be
disabled. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_cachedir">cacheDir</code></td>
<td>
<p> character string containing the directory into which cache files should be written. The
user should make sure that the filesystem has enough free space to hold the cache files which can get quite
large.
</p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_cachebase">cacheBase</code></td>
<td>
<p> character string containing the desired name for the cache files. The actual file
names will consists of <code>cacheBase</code> and a suffix to make the file names unique. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="consensusTOM_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function starts by optionally filtering out samples that have too many missing entries and genes
that have either too many missing entries or zero variance in at least one set. Genes that are filtered
out are left unassigned by the module detection. Returned eigengenes will contain <code>NA</code> in entries
corresponding to filtered-out samples.
</p>
<p>If <code>blocks</code> is not given and
the number of genes exceeds <code>maxBlockSize</code>, genes are pre-clustered into blocks using the function
<code><a href="#topic+consensusProjectiveKMeans">consensusProjectiveKMeans</a></code>; otherwise all genes are treated in a single block.
</p>
<p>For each block of genes, the network is constructed and (if requested) topological overlap is calculated
in each set. To minimize memory usage, calculated topological overlaps are optionally saved to disk in
chunks until they are needed again for the calculation of the consensus network topological overlap.
</p>
<p>Before calculation of the consensus Topological Overlap, individual TOMs are optionally calibrated.
Calibration methods include single quantile scaling and full quantile normalization.
</p>
<p>Single quantile
scaling raises individual TOM in sets 2,3,... to a power such that the quantiles given by
<code>calibrationQuantile</code> agree with the quantile in set 1. Since the high TOMs are usually the most
important
for module identification, the value of <code>calibrationQuantile</code> is close to (but not equal) 1. To speed up
quantile calculation, the quantiles can be determined on a randomly-chosen component subset of the TOM
matrices.
</p>
<p>Full quantile normalization, implemented in <code><a href="preprocessCore.html#topic+normalize.quantiles">normalize.quantiles</a></code>, adjusts the
TOM matrices such that all quantiles equal each other (and equal to the quantiles of the component-wise
average of the individual TOM matrices).
</p>
<p>Note that network calibration is performed separately in each block, i.e., the normalizing transformation
may differ between blocks. This is necessary to avoid manipulating a full TOM in memory.
</p>
<p>The consensus TOM is calculated as the component-wise <code>consensusQuantile</code> quantile of the individual
(set) TOMs; that is, for each gene pair (TOM entry), the <code>consensusQuantile</code> quantile across all input
sets. Alternatively, one can also use (weighted) component-wise mean across all imput data sets.
If requested, the consensus topological overlaps are saved to disk for later use.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>consensusTOM</code></td>
<td>
<p>only present if input <code>returnTOMs</code> is <code>TRUE</code>. A list containing consensus TOM
for each block, stored as a distance structure.</p>
</td></tr>
<tr><td><code>TOMFiles</code></td>
<td>
<p>only present if input <code>saveConsensusTOMs</code> is <code>TRUE</code>. A vector of file names, one for
each block, in which the TOM for the corresponding block is stored. TOM is saved as a distance structure to
save space.</p>
</td></tr>
<tr><td><code>saveConsensusTOMs</code></td>
<td>
<p>a copy of the input <code>saveConsensusTOMs</code>.</p>
</td></tr>
<tr><td><code>individualTOMInfo</code></td>
<td>
<p>information about individual set TOMs. A copy of the input <code>individualTOMInfo</code>
if given; otherwise the result of calling <code>blockwiseIndividualTOMs</code>. See <code>blockwiseIndividualTOMs</code> for
details.</p>
</td></tr>
</table>
<p>Further components are retained for debugging and/or convenience.
</p>
<table role = "presentation">
<tr><td><code>useIndivTOMSubset</code></td>
<td>
<p>a copy of the input <code>useIndivTOMSubset</code>.</p>
</td></tr>
<tr><td><code>goodSamplesAndGenes</code></td>
<td>
<p>a list containing information about which samples and genes are &quot;good&quot; in the sense
that they do not contain more than a certain fraction of missing data and (for genes) have non-zero variance.
See <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for details.</p>
</td></tr>
<tr><td><code>nGGenes</code></td>
<td>
<p>number of &quot;good&quot; genes in <code>goodSamplesGenes</code> above. </p>
</td></tr>
<tr><td><code>nSets</code></td>
<td>
<p>number of input sets.</p>
</td></tr>
<tr><td><code>saveCalibratedIndividualTOMs</code></td>
<td>
<p>a copy of the input <code>saveCalibratedIndividualTOMs</code>.</p>
</td></tr>
<tr><td><code>calibratedIndividualTOMFileNames</code></td>
<td>
<p>if input <code>saveCalibratedIndividualTOMs</code> is <code>TRUE</code>, this
component will contain the file names of calibrated individual networks. The file names are arranged in a
character matrix with each row corresponding to one input set and each column to one block.</p>
</td></tr>
<tr><td><code>networkCalibrationSamples</code></td>
<td>
<p>if input <code>getNetworkCalibrationSamples</code> is <code>TRUE</code>, a list with one
component per block. Each component is in turn a list with two components: <code>sampleIndex</code> is a vector
contain the indices of the TOM samples (the indices refer to a flattened distance structure), and
<code>TOMSamples</code> is a matrix of TOM samples with each row corresponding to a sample in <code>sampleIndex</code>,
and each column to one input set.</p>
</td></tr>
<tr><td><code>consensusQuantile</code></td>
<td>
<p>a copy of the input <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code>originCount</code></td>
<td>
<p>A vector of length <code>nSets</code> that
contains, for each set, the number of (calibrated) elements that were less than or equal the consensus for that element.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>WGCNA methodology has been described in
</p>
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network Analysis&quot;,
Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 PMID: 16646834
</p>
<p>The original reference for the WGCNA package is 
</p>
<p>Langfelder P, Horvath S (2008) WGCNA: an R package for weighted correlation network analysis. BMC
Bioinformatics 2008, 9:559 PMID: 19114008
</p>
<p>For consensus modules, see 
</p>
<p>Langfelder P, Horvath S (2007) &quot;Eigengene networks for studying the relationships between
co-expression modules&quot;, BMC Systems Biology 2007, 1:54
</p>
<p>This function uses quantile normalization described, for example, in
</p>
<p>Bolstad BM1, Irizarry RA, Astrand M, Speed TP (2003) &quot;A comparison of normalization methods for high density
oligonucleotide array data based on variance and bias&quot;, Bioinformatics. 2003 Jan 22;19(2):1 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockwiseIndividualTOMs">blockwiseIndividualTOMs</a></code>  for calculation of topological overlaps across multiple sets.
</p>

<hr>
<h2 id='consensusTreeInputs'>
Get all elementary inputs in a consensus tree
</h2><span id='topic+consensusTreeInputs'></span>

<h3>Description</h3>

<p>This function returns a flat vector or a structured list of elementary inputs to a given consensus tree, that is, inputs
that are not consensus trees themselves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensusTreeInputs(consensusTree, flatten = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="consensusTreeInputs_+3A_consensustree">consensusTree</code></td>
<td>

<p>A consensus tree of class <code><a href="#topic+ConsensusTree">ConsensusTree</a></code>.
</p>
</td></tr>
<tr><td><code id="consensusTreeInputs_+3A_flatten">flatten</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the function returns a flat character vector of inputs; otherwise, a list whose structure reflects 
the structure of <code>consensusTree</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of inputs or a list of inputs whose structure reflects 
the structure of <code>consensusTree</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for creating consensus trees.
</p>

<hr>
<h2 id='convertNumericColumnsToNumeric'>
Convert character columns that represent numbers to numeric
</h2><span id='topic+convertNumericColumnsToNumeric'></span>

<h3>Description</h3>

<p>This function converts to numeric those character columns in the input that can be converted to numeric without generating
missing values except for the allowed NA representations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertNumericColumnsToNumeric(
   data, 
   naStrings = c("NA", "NULL", "NO DATA"), 
   unFactor = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertNumericColumnsToNumeric_+3A_data">data</code></td>
<td>

<p>A data frame.
</p>
</td></tr>
<tr><td><code id="convertNumericColumnsToNumeric_+3A_nastrings">naStrings</code></td>
<td>

<p>Character vector of values that are allowd to convert to <code>NA</code> (a missing numeric value).
</p>
</td></tr>
<tr><td><code id="convertNumericColumnsToNumeric_+3A_unfactor">unFactor</code></td>
<td>

<p>Logical: should the function first convert all factor columns to character?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with convertible columns converted to numeric.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='cor'> Fast calculations of Pearson correlation. </h2><span id='topic+cor1'></span><span id='topic+corFast'></span><span id='topic+cor'></span>

<h3>Description</h3>

<p>These functions implements a faster calculation of (weighted) Pearson correlation. 
</p>
<p>The speedup against the R's standard <code><a href="stats.html#topic+cor">cor</a></code> function will be substantial particularly
if the input matrix only contains a small number of missing data. If there are no missing data, or the
missing data are numerous, the speedup will be smaller.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor(x, y = NULL, 
    use = "all.obs", 
    method = c("pearson", "kendall", "spearman"),
    weights.x = NULL,
    weights.y = NULL,
    quick = 0, 
    cosine = FALSE, 
    cosineX = cosine,
    cosineY = cosine, 
    drop = FALSE,
    nThreads = 0, 
    verbose = 0, indent = 0)

corFast(x, y = NULL, 
    use = "all.obs", 
    quick = 0, nThreads = 0, 
    verbose = 0, indent = 0)

cor1(x, use = "all.obs", verbose = 0, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cor_+3A_x">x</code></td>
<td>
<p> a numeric vector or a matrix. If <code>y</code> is null, <code>x</code> must be a matrix. </p>
</td></tr>
<tr><td><code id="cor_+3A_y">y</code></td>
<td>
<p> a numeric vector or a matrix. If not given, correlations of columns of <code>x</code> will be
calculated. </p>
</td></tr>
<tr><td><code id="cor_+3A_use">use</code></td>
<td>
<p> a character string specifying the handling of missing data. The fast calculations currently
support <code>"all.obs"</code> and <code>"pairwise.complete.obs"</code>; for other options, see R's standard
correlation function <code><a href="stats.html#topic+cor">cor</a></code>.  Abbreviations are allowed. </p>
</td></tr>
<tr><td><code id="cor_+3A_method">method</code></td>
<td>
<p> a character string specifying the method to be used. Fast calculations are currently
available only for <code>"pearson"</code>. </p>
</td></tr>
<tr><td><code id="cor_+3A_weights.x">weights.x</code></td>
<td>
<p>optional observation weights for <code>x</code>. A matrix of the same dimensions as <code>x</code>, 
containing non-negative weights. Only used in fast calculations: <code>methods</code> must be <code>"pearson"</code> and
<code>use</code> must be one of <code>"all.obs", "pairwise.complete.obs"</code>.</p>
</td></tr>
<tr><td><code id="cor_+3A_weights.y">weights.y</code></td>
<td>
<p>optional observation weights for <code>y</code>. A matrix of the same dimensions as <code>y</code>, 
containing non-negative weights. Only used in fast calculations: <code>methods</code> must be <code>"pearson"</code> and 
<code>use</code> must be one of <code>"all.obs", "pairwise.complete.obs"</code>.</p>
</td></tr>
<tr><td><code id="cor_+3A_quick">quick</code></td>
<td>
<p> real number between 0 and 1 that controls the precision of handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="cor_+3A_cosine">cosine</code></td>
<td>
<p> logical: calculate cosine correlation? Only valid for <code>method="pearson"</code>.
Cosine correlation is similar to Pearson correlation but the mean subtraction is not performed. The result
is the cosine of the angle(s) between (the columns of) <code>x</code> and <code>y</code>. </p>
</td></tr>
<tr><td><code id="cor_+3A_cosinex">cosineX</code></td>
<td>
<p> logical: use the cosine calculation for <code>x</code>? This setting does not affect <code>y</code>
and can be used to give a hybrid cosine-standard correlation. </p>
</td></tr>
<tr><td><code id="cor_+3A_cosiney">cosineY</code></td>
<td>
<p> logical: use the cosine calculation for <code>y</code>? This setting does not affect <code>x</code>
and can be used to give a hybrid cosine-standard correlation. </p>
</td></tr>
<tr><td><code id="cor_+3A_drop">drop</code></td>
<td>
<p>logical: should the result be turned into a vector if it is effectively one-dimensional? </p>
</td></tr>
<tr><td><code id="cor_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. 
This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. 
Note that this option does not affect what is usually the most expensive part of the
calculation, namely the matrix multiplication. The matrix multiplication is carried out by BLAS routines provided by R;
these can be sped up by installing a fast BLAS and making R use it. </p>
</td></tr>
<tr><td><code id="cor_+3A_verbose">verbose</code></td>
<td>
<p> Controls the level of verbosity. Values above zero will cause a small amount of
diagnostic messages to be printed. </p>
</td></tr>
<tr><td><code id="cor_+3A_indent">indent</code></td>
<td>
<p> Indentation of printed diagnostic messages. Each unit above zero adds two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fast calculations are currently implemented only for <code>method="pearson"</code> and <code>use</code> either
<code>"all.obs"</code> or <code>"pairwise.complete.obs"</code>. 
The <code>corFast</code> function is a wrapper that calls the function <code>cor</code>. If the combination of
<code>method</code> and <code>use</code> is implemented by the fast calculations, the fast code is executed; 
otherwise, R's own correlation <code><a href="stats.html#topic+cor">cor</a></code> is executed.
</p>
<p>The argument <code>quick</code> specifies the precision of handling of missing data. Zero will cause all
calculations to be executed precisely, which may be significantly slower than calculations without
missing data. Progressively higher values will speed up the
calculations but introduce progressively larger errors. Without missing data, all column means and
variances can be pre-calculated before the covariances are calculated. When missing data are present,
exact calculations require the column means and variances to be calculated for each covariance. The
approximate calculation uses the pre-calculated mean and variance and simply ignores missing data in the
covariance calculation. If the number of missing data is high, the pre-calculated means and variances may
be very different from the actual ones, thus potentially introducing large errors. 
The <code>quick</code> value times the
number of rows specifies the maximum difference in the 
number of missing entries for mean and variance calculations on the one hand and covariance on the other   
hand that will be tolerated before a recalculation is triggered. The hope is that if only a few missing
data are treated approximately, the error introduced will be small but the potential speedup can be
significant. 
</p>


<h3>Value</h3>

<p>The matrix of the Pearson correlations of the columns of <code>x</code> with columns of <code>y</code> if <code>y</code>
is given, and the correlations of the columns of <code>x</code> if <code>y</code> is not given. 
</p>


<h3>Note</h3>

 
<p>The implementation uses the BLAS library matrix multiplication function for the most expensive step of
the calculation. Using a tuned, architecture-specific BLAS may significantly improve the performance of
this function.
</p>
<p>The values returned by the corFast function may differ from the values returned by R's function
<code><a href="stats.html#topic+cor">cor</a></code> by rounding errors on the order of 1e-15. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p>Peter Langfelder, Steve Horvath (2012)
Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software, 46(11), 1-17.
<a href="https://www.jstatsoft.org/v46/i11/">https://www.jstatsoft.org/v46/i11/</a>
</p>


<h3>See Also</h3>

<p> R's standard Pearson correlation function <code><a href="#topic+cor">cor</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Test the speedup compared to standard function cor

# Generate a random matrix with 200 rows and 1000 columns

set.seed(10)
nrow = 100;
ncol = 500;
data = matrix(rnorm(nrow*ncol), nrow, ncol);

## First test: no missing data

system.time( {corStd = stats::cor(data)} );

system.time( {corFast = cor(data)} );

all.equal(corStd, corFast)

# Here R's standard correlation performs very well.

# We now add a few missing entries.

data[sample(nrow, 10), 1] = NA;

# And test the correlations again...

system.time( {corStd = stats::cor(data, use ='p')} );

system.time( {corFast = cor(data, use = 'p')} );

all.equal(corStd, corFast)

# Here the R's standard correlation slows down considerably
# while corFast still retains it speed. Choosing
# higher ncol above will make the difference more pronounced.

</code></pre>

<hr>
<h2 id='corAndPvalue'>
Calculation of correlations and associated p-values
</h2><span id='topic+corAndPvalue'></span>

<h3>Description</h3>

<p>A faster, one-step calculation of Student correlation p-values for multiple correlations, properly taking
into account the actual number of observations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corAndPvalue(x, y = NULL, 
             use = "pairwise.complete.obs", 
             alternative = c("two.sided", "less", "greater"),
             ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corAndPvalue_+3A_x">x</code></td>
<td>

<p>a vector or a matrix
</p>
</td></tr>
<tr><td><code id="corAndPvalue_+3A_y">y</code></td>
<td>

<p>a vector or a matrix. If <code>NULL</code>, the correlation of columns of <code>x</code> will be calculated.
</p>
</td></tr>
<tr><td><code id="corAndPvalue_+3A_use">use</code></td>
<td>

<p>determines handling of missing data. See <code><a href="#topic+cor">cor</a></code> for details.
</p>
</td></tr>
<tr><td><code id="corAndPvalue_+3A_alternative">alternative</code></td>
<td>

<p>specifies the alternative hypothesis and must be (a unique abbreviation of) one of
<code>"two.sided"</code>, <code>"greater"</code> or <code>"less"</code>.
the initial letter.  <code>"greater"</code> corresponds to positive
association, <code>"less"</code> to negative association.
</p>
</td></tr>
<tr><td><code id="corAndPvalue_+3A_...">...</code></td>
<td>

<p>other arguments to the function <code><a href="#topic+cor">cor</a></code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates correlations of a matrix or of two matrices and the corresponding Student p-values.
The output is not as full-featured as <code><a href="stats.html#topic+cor.test">cor.test</a></code>, but can work with matrices as input.
</p>


<h3>Value</h3>

<p>A list with the following components, each a matrix:
</p>
<table role = "presentation">
<tr><td><code>cor</code></td>
<td>
<p>the calculated correlations</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the Student p-values corresponding to the calculated correlations</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Fisher transforms of the calculated correlations</p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>Student t statistics of the calculated correlations</p>
</td></tr>
<tr><td><code>nObs</code></td>
<td>
<p>Numbers of observations for the correlation, p-values etc.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder and Steve Horvath 
</p>


<h3>References</h3>

<p>Peter Langfelder, Steve Horvath (2012)
Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software, 46(11), 1-17.
<a href="https://www.jstatsoft.org/v46/i11/">https://www.jstatsoft.org/v46/i11/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor">cor</a></code> for calculation of correlations only;
</p>
<p><code><a href="stats.html#topic+cor.test">cor.test</a></code> for another function for significance test of correlations
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate random data with non-zero correlation
set.seed(1);
a = rnorm(100);
b = rnorm(100) + a;
x = cbind(a, b);
# Call the function and display all results
corAndPvalue(x)
# Set some components to NA
x[c(1:4), 1] = NA
corAndPvalue(x)
# Note that changed number of observations.
</code></pre>

<hr>
<h2 id='corPredictionSuccess'> Qunatification of success of gene screening </h2><span id='topic+corPredictionSuccess'></span>

<h3>Description</h3>

<p>This function calculates the success of gene screening.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corPredictionSuccess(corPrediction, corTestSet, topNumber = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corPredictionSuccess_+3A_corprediction">corPrediction</code></td>
<td>
<p> a vector or a matrix of prediction statistics </p>
</td></tr>
<tr><td><code id="corPredictionSuccess_+3A_cortestset">corTestSet</code></td>
<td>
<p> correlation or other statistics on test set </p>
</td></tr>
<tr><td><code id="corPredictionSuccess_+3A_topnumber">topNumber</code></td>
<td>
<p> a vector of the number of top genes to consider</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column in <code>corPrediction</code>, the function evaluates the mean <code>corTestSet</code> for the number
of top genes (ranked by the column in <code>corPrediction</code>) given in <code>topNumber</code>. The higher the mean
<code>corTestSet</code> (for positive <code>corPrediction</code>) or negative (for negative <code>corPrediction</code>), the
more successful the prediction.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>meancorTestSetOverall</code></td>
<td>
<p> difference of <code>meancorTestSetPositive</code> and
<code>meancorTestSetNegative</code> below </p>
</td></tr>
<tr><td><code>meancorTestSetPositive</code></td>
<td>
<p> mean <code>corTestSet</code> on top genes with positive <code>corPrediction</code> </p>
</td></tr>
<tr><td><code>meancorTestSetNegative</code></td>
<td>
<p> mean <code>corTestSet</code> on top genes with negative <code>corPrediction</code> </p>
</td></tr>
</table>
<p>...
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+relativeCorPredictionSuccess">relativeCorPredictionSuccess</a></code></p>

<hr>
<h2 id='corPvalueFisher'> Fisher's asymptotic p-value for correlation</h2><span id='topic+corPvalueFisher'></span>

<h3>Description</h3>

<p>Calculates Fisher's asymptotic p-value for given correlations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corPvalueFisher(cor, nSamples, twoSided = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corPvalueFisher_+3A_cor">cor</code></td>
<td>
<p> A vector of correlation values whose corresponding p-values are to be calculated </p>
</td></tr>
<tr><td><code id="corPvalueFisher_+3A_nsamples">nSamples</code></td>
<td>
<p> Number of samples from which the correlations were calculated </p>
</td></tr>
<tr><td><code id="corPvalueFisher_+3A_twosided">twoSided</code></td>
<td>
<p> logical: should the calculated p-values be two sided? </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of p-values of the same length as the input correlations. 
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>

<hr>
<h2 id='corPvalueStudent'>Student asymptotic p-value for correlation</h2><span id='topic+corPvalueStudent'></span>

<h3>Description</h3>

<p>Calculates Student asymptotic p-value for given correlations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corPvalueStudent(cor, nSamples)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corPvalueStudent_+3A_cor">cor</code></td>
<td>
<p> A vector of correlation values whose corresponding p-values are to be calculated </p>
</td></tr>
<tr><td><code id="corPvalueStudent_+3A_nsamples">nSamples</code></td>
<td>
<p> Number of samples from which the correlations were calculated </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of p-values of the same length as the input correlations. 
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>

<hr>
<h2 id='correlationPreservation'> Preservation of eigengene correlations </h2><span id='topic+correlationPreservation'></span>

<h3>Description</h3>

<p>Calculates a summary measure of  preservation of eigengene correlations across data sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlationPreservation(multiME, setLabels, excludeGrey = TRUE, greyLabel = "grey")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correlationPreservation_+3A_multime">multiME</code></td>
<td>
<p>consensus module eigengenes in a multi-set format. A vector of lists with one list
corresponding to each set. Each list must contain a component <code>data</code> that is a data frame whose
columns are consensus module eigengenes. </p>
</td></tr> 
<tr><td><code id="correlationPreservation_+3A_setlabels">setLabels</code></td>
<td>
<p>names to be used for the sets represented in <code>multiME</code>.</p>
</td></tr>
<tr><td><code id="correlationPreservation_+3A_excludegrey">excludeGrey</code></td>
<td>
<p>logical: exclude the 'grey' eigengene from preservation measure?</p>
</td></tr>
<tr><td><code id="correlationPreservation_+3A_greylabel">greyLabel</code></td>
<td>
<p>module label corresponding to the 'grey' module. Usually this will be the
character string <code>"grey"</code> if the labels are colors, and the number 0 if the labels are numeric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the preservation of correlation of each eigengene with all other
eigengenes (optionally except the 'grey' eigengene) in all pairs of sets.  
</p>


<h3>Value</h3>

<p>A data frame whose rows correspond to consensus module eigengenes given in the input
<code>multiME</code>, and columns correspond to all possible set comparisons. The two sets compared in
each column are indicated in the column name.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships
between co-expression modules. BMC Systems Biology 2007, 1:54</p>


<h3>See Also</h3>

 <p><code><a href="#topic+multiSetMEs">multiSetMEs</a></code> and module<code><a href="#topic+checkSets">checkSets</a></code> in package moduleColor for
more on eigengenes and the multi-set format </p>

<hr>
<h2 id='coxRegressionResiduals'>Deviance- and martingale residuals from a Cox regression model
</h2><span id='topic+coxRegressionResiduals'></span>

<h3>Description</h3>

<p>The function inputs a censored time variable which is specified by two input variables <code>time</code> and <code>event</code>.
It outputs i) the martingale residual and ii) deviance residual corresponding to a Cox regression model. 
By default, the Cox regression model is an intercept only Cox regression model. But optionally, the user can input covariates using the argument <code>datCovariates</code>.
The function makes use of the coxph function in the survival library. 
See <code>help(residuals.coxph)</code> to learn more.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxRegressionResiduals(time, event, datCovariates = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coxRegressionResiduals_+3A_time">time</code></td>
<td>
<p> is a numeric variable that contains follow up time or time to event.
</p>
</td></tr>
<tr><td><code id="coxRegressionResiduals_+3A_event">event</code></td>
<td>
<p> is a binary variable that takes on values 1 and 0. 1 means that the event took place (e.g. person died, or tumor recurred). 0 means censored, i.e. event has not yet been observed or loss to follow up.
</p>
</td></tr>
<tr><td><code id="coxRegressionResiduals_+3A_datcovariates">datCovariates</code></td>
<td>
<p> a data frame whose columns correspond to covariates that should be used in the Cox regression model. By default, the only covariate the intercept term 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Residuals are often used to investigate the lack of fit of a model.  For Cox regression, there is no easy
analog to the usual &quot;observed minus predicted&quot; residual of linear regression. Instead, several specialized residuals have been proposed for Cox regression analysis. The function calculates residuals that are well defined for an intercept only Cox regression model: the martingale and deviance residuals (Therneau et al 1990). The martingale residual of a subject (person) specifies excess failures beyond the expected baseline hazard. 
For example, a subject who was censored at 3 years, and whose predicted cumulative hazard at 3 years was 30
Another subject who had an event at 10 years, and whose predicted cumulative hazard at 10 years  was 60
Since martingale residuals are not symmetrically distributed, even when the fitted model is correct, it is often advantageous to transform them into more symmetrically distributed residuals: deviance residuals. 
Thus, deviance residuals are defined as transformations of the martingale residual and the event variable. Deviance residuals are often symmetrically distributed around zero
Deviance Residuals are similar to residuals from ordinary linear regression in that they are symmetrically distributed around 0 and have standard deviation of 1.0. .  A subjects with a large deviance residual is poorly predicted by the model, i.e. is different from the baseline cumulative hazard.
A negative value indicates a longer than expected survival time.
When covariates are specified in <code>datCovariates</code>, then one can plot deviance (or martingale) residuals against the covariates. Unusual patterns may indicate poor fit of the Cox model.
Cryptic comments: Deviance (or martingale) residuals can sometimes be used as (uncensored) quantitative variables instead of the original time censored variable.
For example, they could be used as outcome in a regression tree or regression forest predictor.
</p>


<h3>Value</h3>

<p>It outputs a data frame with 2 columns. The first and second column correspond to martingale and deviance residuals respectively.
</p>


<h3>Note</h3>

<p>This function can be considered a wrapper of the coxph function. 
</p>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>


<h3>References</h3>

<p>Thereneau TM, Grambsch PM, Fleming TR (1990) Martingale-based residuals for survival models. Biometrika (1990), 77, 1, pp. 147-60
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
# simulate time and event data
time1=sample(1:100)
event1=sample(c(1,0), 100,replace=TRUE)

event1[1:5]=NA
time1[1:5]=NA
# no covariates
datResiduals= coxRegressionResiduals(time=time1,event=event1)

# now we simulate a covariate
z= rnorm(100)
cor(datResiduals,use="p")
datResiduals=coxRegressionResiduals(time=time1,event=event1,datCovariates=data.frame(z))
cor(datResiduals,use="p")

</code></pre>

<hr>
<h2 id='cutreeStatic'> Constant-height tree cut </h2><span id='topic+cutreeStatic'></span>

<h3>Description</h3>

<p>Module detection in hierarchical dendrograms using a constant-height tree cut. Only branches whose size
is at least <code>minSize</code> are retained. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutreeStatic(dendro, cutHeight = 0.9, minSize = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutreeStatic_+3A_dendro">dendro</code></td>
<td>
<p> a hierarchical clustering dendrogram such as returned by <code><a href="stats.html#topic+hclust">hclust</a></code>. </p>
</td></tr>
<tr><td><code id="cutreeStatic_+3A_cutheight">cutHeight</code></td>
<td>
<p> height at which branches are to be cut. </p>
</td></tr>
<tr><td><code id="cutreeStatic_+3A_minsize">minSize</code></td>
<td>
<p> minimum number of object on a branch to be considered a cluster. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a straightforward constant-height cut as implemented by <code><a href="stats.html#topic+cutree">cutree</a></code>,
then calculates the number of objects on each branch and only keeps branches that have at least
<code>minSize</code> objects on them.
</p>


<h3>Value</h3>

<p>A numeric vector giving labels of objects, with 0 meaning unassigned. The largest cluster
is conventionally labeled 1, the next largest 2, etc. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+hclust">hclust</a></code> for hierarchical clustering, <code><a href="stats.html#topic+cutree">cutree</a></code> and
<code><a href="#topic+cutreeStatic">cutreeStatic</a></code> for other constant-height branch cuts, <code><a href="#topic+standardColors">standardColors</a></code> to convert
the retuned numerical lables into colors for easier visualization. </p>

<hr>
<h2 id='cutreeStaticColor'> Constant height tree cut using color labels</h2><span id='topic+cutreeStaticColor'></span>

<h3>Description</h3>

<p>Cluster detection by a constant height cut of a hierarchical clustering dendrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutreeStaticColor(dendro, cutHeight = 0.9, minSize = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cutreeStaticColor_+3A_dendro">dendro</code></td>
<td>
<p> a hierarchical clustering dendrogram such as returned by <code><a href="stats.html#topic+hclust">hclust</a></code>. </p>
</td></tr>
<tr><td><code id="cutreeStaticColor_+3A_cutheight">cutHeight</code></td>
<td>
<p> height at which branches are to be cut. </p>
</td></tr>
<tr><td><code id="cutreeStaticColor_+3A_minsize">minSize</code></td>
<td>
<p> minimum number of object on a branch to be considered a cluster. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a straightforward constant-height cut as implemented by <code><a href="stats.html#topic+cutree">cutree</a></code>,
then calculates the number of objects on each branch and only keeps branches that have at least
<code>minSize</code> objects on them.
</p>


<h3>Value</h3>

<p>A character vector giving color labels of objects, with &quot;grey&quot; meaning unassigned. The largest cluster
is conventionally labeled &quot;turquoise&quot;, next &quot;blue&quot; etc. Run <code>standardColors()</code> to see the sequence
of standard color labels.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+hclust">hclust</a></code> for hierarchical clustering, <code><a href="stats.html#topic+cutree">cutree</a></code> and
<code><a href="#topic+cutreeStatic">cutreeStatic</a></code> for other constant-height branch cuts, <code><a href="#topic+standardColors">standardColors</a></code> to see
the sequence of color labels that can be assigned.</p>

<hr>
<h2 id='displayColors'> Show colors used to label modules </h2><span id='topic+displayColors'></span>

<h3>Description</h3>

<p>The function plots a barplot using colors that label modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>displayColors(colors = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="displayColors_+3A_colors">colors</code></td>
<td>
<p>colors to be displayed. Defaults to all colors available for module labeling. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>To see the first <code>n</code> colors, use argument <code>colors = standardColors(n)</code>.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+standardColors">standardColors</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  displayColors(standardColors(10))
</code></pre>

<hr>
<h2 id='dynamicMergeCut'> Threshold for module merging </h2><span id='topic+dynamicMergeCut'></span>

<h3>Description</h3>

<p>Calculate a suitable threshold for module merging based on the number of samples and a desired Z
quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynamicMergeCut(n, mergeCor = 0.9, Zquantile = 2.35)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dynamicMergeCut_+3A_n">n</code></td>
<td>
<p>number of samples </p>
</td></tr>
<tr><td><code id="dynamicMergeCut_+3A_mergecor">mergeCor</code></td>
<td>
<p> theoretical correlation threshold for module merging  </p>
</td></tr>
<tr><td><code id="dynamicMergeCut_+3A_zquantile">Zquantile</code></td>
<td>
<p> Z quantile for module merging </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the threshold for module merging. The threshold is calculated as the lower
boundary of the interval around the theoretical correlation <code>mergeCor</code> whose width is given by the
Z value <code>Zquantile</code>.
</p>


<h3>Value</h3>

<p>The correlation threshold for module merging; a single number.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code>, <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  dynamicMergeCut(20)
  dynamicMergeCut(50)
  dynamicMergeCut(100)
</code></pre>

<hr>
<h2 id='empiricalBayesLM'>
Empirical Bayes-moderated adjustment for unwanted covariates
</h2><span id='topic+empiricalBayesLM'></span>

<h3>Description</h3>

<p>This functions removes variation in high-dimensional data 
due to unwanted covariates while preserving variation due to retained covariates. To prevent numerical
instability, it uses Empirical bayes-moderated linear regression, optionally in a robust (outlier-resistant)
form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empiricalBayesLM(
  data,
  removedCovariates,
  retainedCovariates = NULL,

  initialFitFunction = NULL,
  initialFitOptions = NULL,
  initialFitRequiresFormula = NULL,
  initialFit.returnWeightName = NULL,

  fitToSamples = NULL,

  weights = NULL,
  automaticWeights = c("none", "bicov"),
  aw.maxPOutliers = 0.1,
  weightType = c("apriori", "empirical"),
  stopOnSmallWeights = TRUE,

  minDesignDeviation = 1e-10,
  robustPriors = FALSE,
  tol = 1e-4, maxIterations = 1000,
  garbageCollectInterval = 50000,

  scaleMeanToSamples = fitToSamples,
  scaleMeanOfSamples = NULL,
  getOLSAdjustedData = TRUE,
  getResiduals = TRUE,
  getFittedValues = TRUE,
  getWeights = TRUE,
  getEBadjustedData = TRUE,

  verbose = 0, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="empiricalBayesLM_+3A_data">data</code></td>
<td>

<p>A 2-dimensional matrix or data frame of numeric data to be adjusted. Variables (for example, genes or
methylation profiles) should be in columns and observations (samples) should be in rows.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_removedcovariates">removedCovariates</code></td>
<td>

<p>A vector or two-dimensional object (matrix or data frame) giving the covariates whose effect on the data is to
be removed. At least one such covariate must be given.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_retainedcovariates">retainedCovariates</code></td>
<td>

<p>A vector or two-dimensional object (matrix or data frame) giving the covariates whose effect on the data is
to be retained. May be <code>NULL</code> if there are no such &quot;retained&quot; covariates.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_initialfitfunction">initialFitFunction</code></td>
<td>

<p>Function name to perform the initial fit. The default is to use the internal implementation of linear model
fitting. The function must take arguments <code>formula</code> and <code>data</code> or <code>x</code> and <code>y</code>,
plus possibly additional arguments.
The return value must be a list with component <code>coefficients</code>, either <code>scale</code> or
<code>residuals</code>, and weights must be returned in component specified by <code>initialFit.returnWeightName</code>. 
See <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="MASS.html#topic+rlm">rlm</a></code> and other standard fit functions for examples of
suitable functions.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_initialfitoptions">initialFitOptions</code></td>
<td>

<p>Optional specifications of extra arguments for <code>initialFitFunction</code>, apart from <code>formula</code> and
<code>data</code> or <code>x</code> and <code>y</code>. 
Defaults are provided for function <code><a href="MASS.html#topic+rlm">rlm</a></code>, 
i.e., if this function is used as <code>initialFitFunction</code>, suitable initial fit options
will be chosen automatically.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_initialfitrequiresformula">initialFitRequiresFormula</code></td>
<td>

<p>Logical: does the initial fit function need <code>formula</code> and <code>data</code> arguments? If <code>TRUE</code>,
<code>initialFitFunction</code> will be called with arguments <code>formula</code> and <code>data</code>, otherwise with
arguments <code>x</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_initialfit.returnweightname">initialFit.returnWeightName</code></td>
<td>

<p>Name of the component of the return value of <code>initialFitFunction</code> that contains the weights used in the
fit. Suitable default value will be chosen automatically for <code><a href="MASS.html#topic+rlm">rlm</a></code>.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_fittosamples">fitToSamples</code></td>
<td>

<p>Optional index of samples from which the linear model fits should be calculated. Defaults to all samples. If given, the
models will be only fit to the specified samples but all samples will be transformed using the calculated coefficients.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_weights">weights</code></td>
<td>

<p>Optional 2-dimensional matrix or data frame of the same dimensions as <code>data</code> giving weights for each
entry in <code>data</code>. These weights will be used in the initial fit and are are separate from the ones returned by
<code>initialFitFunction</code> if it is specified.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_automaticweights">automaticWeights</code></td>
<td>

<p>One of (unique abrreviations of) <code>"none"</code> or <code>"bicov"</code>, instructing the function to calculate
weights from the given <code>data</code>. Value <code>"none"</code> will result in trivial weights; value <code>"bicov"</code>
will result in biweight midcovariance weights being used.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_aw.maxpoutliers">aw.maxPOutliers</code></td>
<td>

<p>If <code>automaticWeights</code> above is <code>"bicov"</code>, this argument gets passed to the function
<code><a href="#topic+bicovWeights">bicovWeights</a></code> and determines the maximum proportion of outliers in calculating the weights. See
<code><a href="#topic+bicovWeights">bicovWeights</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_weighttype">weightType</code></td>
<td>

<p>One of (unique abbreviations of) <code>"apriori"</code> or <code>"empirical"</code>. Determines whether a standard
(<code>"apriori"</code>) or a modified (<code>"empirical"</code>) weighted regression is used. The <code>"apriori"</code> choice is
suitable for weights that have been determined without knowledge of the actual <code>data</code>, while
<code>"empirical"</code> is appropriate for situations where one wants to down-weigh cartain entries of <code>data</code>
because they may be outliers. In either case, the weights should be determined in a way that is independent of 
the covariates (both retained and removed).
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_stoponsmallweights">stopOnSmallWeights</code></td>
<td>

<p>Logical: should presence of small <code>"apriori"</code> weights trigger an error? Because standard weighted regression
assumes that all weights are non-zero (otherwise estimates of standard errors will be biased), this function
will by default complain about the presence of too small <code>"apriori"</code> weights.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_mindesigndeviation">minDesignDeviation</code></td>
<td>

<p>Minimum standard deviation for columns of the design matrix to be retained. Columns with standard deviations
below this number will be removed (effectively removing the corresponding terms from the design).
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_robustpriors">robustPriors</code></td>
<td>

<p>Logical: should robust priors be used? This essentially means replacing mean by median and covariance by
biweight mid-covariance.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_tol">tol</code></td>
<td>

<p>Convergence criterion used in the numerical equation solver. When the relative change in coefficients falls
below this threshold, the system will be considered to have converged.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_maxiterations">maxIterations</code></td>
<td>

<p>Maximum number of iterations to use.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_garbagecollectinterval">garbageCollectInterval</code></td>
<td>

<p>Number of variables after which to call garbage collection.
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_scalemeantosamples">scaleMeanToSamples</code></td>
<td>

<p>Optional specification of samples (given as a vector of indices) to whose means the resulting adjusted data
should be scaled (more precisely, shifted). 
</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_scalemeanofsamples">scaleMeanOfSamples</code></td>
<td>

<p>Optional specification of samples (given as a vector of indices) that will be used in calculating the shift. Specifically,
the shift is such that the mean of samples given in <code>scaleMeanOfSamples</code> will equal the mean of samples given in
<code>scaleMeanToSamples</code>. Defaults to all samples.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_getolsadjusteddata">getOLSAdjustedData</code></td>
<td>
<p>Logical: should data adjusted by ordinary least squares or by
<code>initialFitFunction</code>, if specified, be returned?</p>
</td></tr> 
<tr><td><code id="empiricalBayesLM_+3A_getresiduals">getResiduals</code></td>
<td>
<p>Logical: should the residuals (adjusted values without the means) be returned?</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_getfittedvalues">getFittedValues</code></td>
<td>
<p>Logical: should fitted values be returned?</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_getweights">getWeights</code></td>
<td>
<p>Logical: should the final weights be returned?</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_getebadjusteddata">getEBadjustedData</code></td>
<td>
<p>Logical: should the EB step be performed and the adjusted data returned? If this
is <code>FALSE</code>, the function acts as a rather slow but still potentially useful adjustment using standard
fit functions.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_verbose">verbose</code></td>
<td>
<p>Level of verbosity. Zero means silent, higher values result in more diagnostic messages
being printed.</p>
</td></tr>
<tr><td><code id="empiricalBayesLM_+3A_indent">indent</code></td>
<td>
<p>Indentation of diagnostic messages. Each unit adds two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses Empirical Bayes-moderated (EB) linear regression to remove variation in <code>data</code> due to the
variables in <code>removedCovariates</code> while retaining variation due to variables in <code>retainedCovariates</code>,
if any are given. The EB step uses simple normal priors on the regression coefficients and inverse gamma 
priors on the
variances. The procedure starts with multivariate ordinary linear regression of individual columns in
<code>data</code> on <code>retainedCovariates</code> and <code>removedCovariates</code>. Alternatively, the user may specify an
intial fit function (e.g., robust linear regression). To make the coefficients comparable,
columns of <code>data</code> are scaled to (weighted if weights are given) mean 0 and variance 1.
The resulting regression coefficients are used to
determine the parameters of the normal prior (mean, covariance, and inverse gamma or median and biweight
mid-covariance if robust priors are used), and the variances are used to determine the parameters of the
inverse gamma prior. The EB step then essentially shrinks the coefficients toward their means, with the amount
of shrinkage determined by the prior covariance.
</p>
<p>Using appropriate weights can make the data adjustment robust to outliers. This can be achieved automatically
by using the argument <code>automaticWeights = "bicov"</code>. When bicov weights are used, we also recommend
setting the argument <code>maxPOutliers</code> to a maximum proportion of samples that could be outliers. This is
especially important if some of the design variables are binary and can be expected to have a strong effect on
some of the columns in <code>data</code>, since standard biweight midcorrelation (and its weights) do not work well
on bimodal data. 
</p>
<p>The automatic bicov weights are determined from <code>data</code> only. It is implicitly assumed that there are no
outliers in the retained and removed covariates. Outliers in the covariates are more difficult to work with
since, even if the regression is made robust to them, they can influence the adjusted values for the sample in
which they appear. Unless the the covariate outliers can be attributed to a relevant variation in experimental
conditions, samples with covariate outliers are best removed entirely before calling this function.
</p>


<h3>Value</h3>

<p>A list with the following components (some of which may be missing depending on input options):
</p>
<table role = "presentation">
<tr><td><code>adjustedData</code></td>
<td>
<p>A matrix of the same dimensions as the input <code>data</code>, giving the adjusted data. If
input <code>data</code> has non-NULL <code>dimnames</code>, these are copied.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>A matrix of the same dimensions as the input <code>data</code>, giving the residuals,
that is, adjusted data with zero means.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>A matrix of regression coefficients. Rows correspond to the design matrix variables 
(mean, retained and removed covariates) and columns correspond to the variables (columns) in <code>data</code>.</p>
</td></tr>
<tr><td><code>coefficiens.scaled</code></td>
<td>
<p>A matrix of regression coefficients corresponding to columns in <code>data</code> scaled
to mean 0 and variance 1.</p>
</td></tr>
<tr><td><code>sigmaSq</code></td>
<td>
<p>Estimated error variances (one for each column of input <code>data</code>.</p>
</td></tr>
<tr><td><code>sigmaSq.scaled</code></td>
<td>
<p>Estimated error variances corresponding to columns in <code>data</code> scaled
to mean 0 and variance 1.</p>
</td></tr>
<tr><td><code>fittedValues</code></td>
<td>
<p>Fitted values calculated from the means and coefficients corresponding to the removed
covariates, i.e., roughly the values that are subtracted out of the data.</p>
</td></tr>
<tr><td><code>adjustedData.OLS</code></td>
<td>
<p>A matrix of the same dimensions as the input <code>data</code>, giving the data adjusted by
ordinary least squares. This component should only be used for diagnostic purposes, not as input for further
downstream analyses, as the OLS adjustment is inferior to EB adjustment. </p>
</td></tr>
<tr><td><code>residuals.OLS</code></td>
<td>
<p>A matrix of the same dimensions as the input <code>data</code>, giving the residuals obtained
from ordinary least squares regression, that is, OLS-adjusted data with zero means.</p>
</td></tr>
<tr><td><code>coefficients.OLS</code></td>
<td>
<p>A matrix of ordinary least squares regression coefficients. 
Rows correspond to the design matrix variables        
(mean, retained and removed covariates) and columns correspond to the variables (columns) in <code>data</code>.</p>
</td></tr>
<tr><td><code>coefficiens.OLS.scaled</code></td>
<td>
<p>A matrix of ordinary least squares regression coefficients corresponding to columns
in <code>data</code> scaled to mean 0 and variance 1.  These coefficients are used to calculate priors for the EB step.</p>
</td></tr>
<tr><td><code>sigmaSq.OLS</code></td>
<td>
<p>Estimated OLS error variances (one for each column of input <code>data</code>.</p>
</td></tr>
<tr><td><code>sigmaSq.OLS.scaled</code></td>
<td>
<p>Estimated OLS error variances corresponding to columns in <code>data</code> scaled
to mean 0 and variance 1. These are used to calculate variance priors for the EB step.</p>
</td></tr>
<tr><td><code>fittedValues.OLS</code></td>
<td>
<p>OLS fitted values calculated from the means and coefficients corresponding to the removed
covariates.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>A matrix of weights used in the regression models. The matrix has the same dimension as the
input <code>data</code>.</p>
</td></tr>
<tr><td><code>dataColumnValid</code></td>
<td>
<p>Logical vector with one element per column of input <code>data</code>, indicating whether the
column was adjusted. Columns with zero variance or too many missing data cannot be adjusted.</p>
</td></tr>
<tr><td><code>dataColumnWithZeroVariance</code></td>
<td>
<p>Logical vector with one element per column of input <code>data</code>, indicating
whether the  
column had zero variance.</p>
</td></tr>
<tr><td><code>coefficientValid</code></td>
<td>
<p>Logical matrix of the dimension (number of covariates +1) times (number of
variables in <code>data</code>), indicating whether the corresponding regression coefficient is valid. Invalid
regression coefficients may be returned as missing values or as zeroes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bicovWeights">bicovWeights</a></code> for suitable weights that make the adjustment robust to outliers.
</p>

<hr>
<h2 id='exportNetworkToCytoscape'> Export network to Cytoscape </h2><span id='topic+exportNetworkToCytoscape'></span>

<h3>Description</h3>

<p>This function exports a network in edge and node list files in a format suitable for importing to
Cytoscape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exportNetworkToCytoscape(
   adjMat,
   edgeFile = NULL,
   nodeFile = NULL,
   weighted = TRUE,
   threshold = 0.5,
   nodeNames = NULL,
   altNodeNames = NULL,
   nodeAttr = NULL,
   includeColNames = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="exportNetworkToCytoscape_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix giving connection strengths among the nodes in the network. </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_edgefile">edgeFile</code></td>
<td>
<p> file name of the file to contain the edge information. </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_nodefile">nodeFile</code></td>
<td>
<p> file name of the file to contain the node information. </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_weighted">weighted</code></td>
<td>
<p> logical: should the exported network be weighted? </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_threshold">threshold</code></td>
<td>
<p> adjacency threshold for including edges in the output.  </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_nodenames">nodeNames</code></td>
<td>
<p> names of the nodes. If not given, <code>dimnames</code> of <code>adjMat</code> will be used. </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_altnodenames">altNodeNames</code></td>
<td>
<p> optional alternate names for the nodes, for example gene names if nodes are
labeled by probe IDs. </p>
</td></tr> 
<tr><td><code id="exportNetworkToCytoscape_+3A_nodeattr">nodeAttr</code></td>
<td>
<p> optional node attribute, for example module color. Can be a vector or a data frame. </p>
</td></tr>
<tr><td><code id="exportNetworkToCytoscape_+3A_includecolnames">includeColNames</code></td>
<td>
<p> logical: should column names be included in the output files? Note that
Cytoscape can read files both with and without column names.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the corresponding file names are supplied, the edge and node data is written to the appropriate
files. The edge and node data is also returned as return value (see below). </p>


<h3>Value</h3>

<p>A list with the following componens:
</p>
<table role = "presentation">
<tr><td><code>egdeData</code></td>
<td>
<p>a data frame containing the edge data, with one row per edge</p>
</td></tr>
<tr><td><code>nodeData</code></td>
<td>
<p>a data frame containing the node data, with one row per node</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>See Also</h3>

 <p><code><a href="#topic+exportNetworkToVisANT">exportNetworkToVisANT</a></code></p>

<hr>
<h2 id='exportNetworkToVisANT'> Export network data in format readable by VisANT</h2><span id='topic+exportNetworkToVisANT'></span>

<h3>Description</h3>

<p>Exports network data in a format readable and displayable by the VisANT software.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exportNetworkToVisANT(
  adjMat, 
  file = NULL, 
  weighted = TRUE, 
  threshold = 0.5, 
  maxNConnections = NULL,
  probeToGene = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="exportNetworkToVisANT_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix of the network to be exported. </p>
</td></tr>
<tr><td><code id="exportNetworkToVisANT_+3A_file">file</code></td>
<td>
<p> character string specifying the file name of the file in which the data should be written.
If not given, no file will be created. The file is in a plain text format. </p>
</td></tr>
<tr><td><code id="exportNetworkToVisANT_+3A_weighted">weighted</code></td>
<td>
<p> logical: should the exported network by weighted? </p>
</td></tr>
<tr><td><code id="exportNetworkToVisANT_+3A_threshold">threshold</code></td>
<td>
<p> adjacency threshold for including edges in the output. </p>
</td></tr>
<tr><td><code id="exportNetworkToVisANT_+3A_maxnconnections">maxNConnections</code></td>
<td>
<p>maximum number of exported adjacency edges. This can be used as another filter on
the exported edges.</p>
</td></tr>
<tr><td><code id="exportNetworkToVisANT_+3A_probetogene">probeToGene</code></td>
<td>
<p> optional specification of a conversion between probe names (that label columns and
rows of <code>adjacency</code>) and gene names (that should label nodes in the output). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The adjacency matrix is checked for validity. The entries can be negative, however. The adjacency
matrix is expected to also have valid <code>names</code> or <code>dimnames[[2]]</code> that represent the probe names
of the corresponding edges. 
</p>
<p>Whether the output is a weighted network or not, only edges whose (absolute value of) adjacency are
above <code>threshold</code> will be included in the output. If <code>maxNConnections</code> is given, at most
<code>maxNConnections</code> will be included in the output.
</p>
<p>If <code>probeToGene</code> is given, it is expected to have two columns, the first one corresponding to the
probe names, the second to their corresponding gene names that will be used in the output. 
</p>


<h3>Value</h3>

<p>A data frame containing the network information suitable as input to VisANT. The same data frame is
also written into a file specified by <code>file</code>, if given. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> VisANT software is available from http://www.visantnet.org/visantnet.html/. </p>

<hr>
<h2 id='factorizeNonNumericColumns'>
Turn non-numeric columns into factors
</h2><span id='topic+factorizeNonNumericColumns'></span>

<h3>Description</h3>

<p>Given a data frame, this function turns non-numeric columns into factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorizeNonNumericColumns(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="factorizeNonNumericColumns_+3A_data">data</code></td>
<td>

<p>A data frame. Non-data frame inputs (e.g., a matrix) are coerced to a data frame.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A column is considered numeric if its storage mode is numeric or if it is a character vector, it only contains
character representations of numbers and possibly missing values encoded as &quot;NA&quot;, &quot;NULL&quot;, &quot;NO DATA&quot;.
</p>


<h3>Value</h3>

<p>The input data frame with non-numeric columns turned into factors.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='fixDataStructure'>Put single-set data into a form useful for multiset calculations. </h2><span id='topic+fixDataStructure'></span>

<h3>Description</h3>

<p>Encapsulates single-set data in a wrapper that makes the data suitable for functions working on
multiset data collections.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixDataStructure(data, verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fixDataStructure_+3A_data">data</code></td>
<td>
<p> A dataframe, matrix or array with two dimensions to be encapsulated. </p>
</td></tr>
<tr><td><code id="fixDataStructure_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity. 0 is silent. </p>
</td></tr>
<tr><td><code id="fixDataStructure_+3A_indent">indent</code></td>
<td>
<p>Controls indentation of printed progress messages. 0 means no indentation, every unit
adds two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For multiset calculations, many quantities (such as expression data, traits, module eigengenes etc) are
presented by a common structure, a vector of lists (one list for each set) where each list has a
component <code>data</code> that contains the actual (expression, trait, eigengene) data for the corresponding
set in the form of a dataframe. This funtion creates a vector of lists of length 1 and fills the
component <code>data</code> with the content of parameter <code>data</code>.
</p>


<h3>Value</h3>

<p>As described above, input data in a format suitable for functions operating on multiset data
collections.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+checkSets">checkSets</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
singleSetData = matrix(rnorm(100), 10,10);
encapsData = fixDataStructure(singleSetData);
length(encapsData)
names(encapsData[[1]])
dim(encapsData[[1]]$data)
all.equal(encapsData[[1]]$data, singleSetData);

</code></pre>

<hr>
<h2 id='formatLabels'>
Break long character strings into multiple lines
</h2><span id='topic+formatLabels'></span>

<h3>Description</h3>

<p>This function attempts to break lomg character strings into multiple lines by replacing a given pattern by
a newline character.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formatLabels(
   labels, 
   maxCharPerLine = 14, 
   maxWidth = NULL,
   maxLines = Inf,
   cex = 1,
   font = 1,
   split = " ", 
   fixed = TRUE, 
   newsplit = split,
   keepSplitAtEOL = TRUE, 
   capitalMultiplier = 1.4,
   eol = "\n", 
   ellipsis = "...")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formatLabels_+3A_labels">labels</code></td>
<td>
<p>Character strings to be formatted.
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_maxcharperline">maxCharPerLine</code></td>
<td>

<p>Integer giving the maximum number of characters per line.
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_maxwidth">maxWidth</code></td>
<td>
<p>Maximum width in user coordinates. If given, overrides <code>maxCharPerLine</code> above and
usually gives a much more efficient formatting.</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_maxlines">maxLines</code></td>
<td>
<p>Maximum lines to retain. If a label extends past the maximum number of lines,
<code>ellipsis</code> is added at the end of the last line.</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_cex">cex</code></td>
<td>
<p>Character expansion factor that the user intends to use when adding <code>labels</code> to the current
figure. Only used when <code>maxWidth</code> is specified.</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_font">font</code></td>
<td>
<p>Integer specifying the font. See <code><a href="graphics.html#topic+par">par</a></code> for details. </p>
</td></tr>
<tr><td><code id="formatLabels_+3A_split">split</code></td>
<td>

<p>Pattern to be replaced by newline ('\n') characters.
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_fixed">fixed</code></td>
<td>

<p>Logical: Should the pattern be interpreted literally (<code>TRUE</code>) or as a regular expression (<code>FALSE</code>)?
See <code><a href="base.html#topic+strsplit">strsplit</a></code> and its argument <code>fixed</code>.
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_newsplit">newsplit</code></td>
<td>

<p>Character string to replace the occurrences of <code>split</code> above with.
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_keepsplitateol">keepSplitAtEOL</code></td>
<td>

<p>When replacing an occurrence of <code>split</code> with a newline character, should the <code>newsplit</code> be added
before the newline as well? 
</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_capitalmultiplier">capitalMultiplier</code></td>
<td>
<p>A multiplier for capital letters which typically occupy more space than lowercase
letters.</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_eol">eol</code></td>
<td>
<p>Character string to separate lines in the output.</p>
</td></tr>
<tr><td><code id="formatLabels_+3A_ellipsis">ellipsis</code></td>
<td>
<p>Chararcter string to add to the last line if the input label is longer than fits on
<code>maxLines</code> lines.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each given element of <code>labels</code> is processed independently. The character string is split using
<code>strsplit</code>, with <code>split</code> as the splitting pattern. The resulting shorter character strings are
then concatenated together with <code>newsplit</code> as the separator. Whenever the length (adjusted using the
capital letter multiplier) of the combined
result from the start or the previous newline character exceeds <code>maxCharPerLine</code>, or
<code><a href="graphics.html#topic+strwidth">strwidth</a></code> exceeds <code>maxWidth</code>, the character specified by <code>eol</code>
is inserted (at the previous split). 
</p>
<p>Note that individual segements (i.e., sections of the input between occurrences of <code>split</code>) whose
number of characters exceeds <code>maxCharPerLine</code> will not be split.
</p>


<h3>Value</h3>

<p>A character vector of the same length as input <code>labels</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s = "A quick hare jumps over the brown fox";
formatLabels(s);
</code></pre>

<hr>
<h2 id='fundamentalNetworkConcepts'> Calculation of fundamental network concepts from an adjacency matrix. </h2><span id='topic+fundamentalNetworkConcepts'></span>

<h3>Description</h3>

<p>This function computes fundamental network concepts (also known as network indices or statistics) based
on an adjacency matrix and optionally a node significance measure. These network concepts are defined for
any symmetric adjacency matrix (weighted and unweighted). The network concepts are described in Dong and
Horvath (2007) and Horvath and Dong (2008). 
Fundamental network concepts are defined as a function of the off-diagonal elements of an adjacency
matrix <code>adj</code> and/or a node significance measure <code>GS</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fundamentalNetworkConcepts(adj, GS = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fundamentalNetworkConcepts_+3A_adj">adj</code></td>
<td>
<p> an adjacency matrix, that is a square, symmetric matrix with entries between 0 and 1</p>
</td></tr>
<tr><td><code id="fundamentalNetworkConcepts_+3A_gs">GS</code></td>
<td>
<p> a node significance measure: a vector of the same length as the number of rows
(and columns) of the adjacency matrix.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>Connectivity</code></td>
<td>
<p>a numerical vector that reports the connectivity (also known as degree) of each
node. This fundamental network concept is also known as whole network connectivity. One can also define
the scaled connectivity <code>K=Connectivity/max(Connectivity)</code> which is used for computing the hub gene
significance.</p>
</td></tr>
<tr><td><code>ScaledConnectivity</code></td>
<td>
<p>the <code>Connectivity</code> vector scaled by the highest connectivity in the
network, i.e., <code>Connectivity/max(Connectivity)</code>.</p>
</td></tr>
<tr><td><code>ClusterCoef</code></td>
<td>
<p>a numerical vector that reports the cluster coefficient for each node. This
fundamental network concept measures the cliquishness of each node.</p>
</td></tr>
<tr><td><code>MAR</code></td>
<td>
<p>a numerical vector that reports the maximum adjacency ratio for each node. <code>MAR[i]</code>
equals 1 if all non-zero adjacencies between node <code>i</code> and the remaining network nodes equal 1. This
fundamental network concept is always 1 for nodes of an unweighted network.  This is a useful measure for
weighted networks since it allows one to determine whether a node has high connectivity because of many
weak connections (small MAR) or because of strong (but few) connections (high MAR), see Horvath and Dong
2008. 
</p>
</td></tr>
<tr><td><code>Density</code></td>
<td>
<p>the density of the network. </p>
</td></tr>
<tr><td><code>Centralization</code></td>
<td>
<p>the centralization of the network. </p>
</td></tr>
<tr><td><code>Heterogeneity</code></td>
<td>
<p>the heterogeneity of the network. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology 2007, 1:24 
</p>
<p>Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+conformityBasedNetworkConcepts">conformityBasedNetworkConcepts</a></code> for calculation of conformity based network concepts
for a network adjacency matrix;
</p>
<p><code><a href="#topic+networkConcepts">networkConcepts</a></code>, for calculation of conformity based and eigennode based network concepts
for a correlation network.
</p>

<hr>
<h2 id='GOenrichmentAnalysis'> Calculation of GO enrichment (experimental)</h2><span id='topic+GOenrichmentAnalysis'></span>

<h3>Description</h3>

<p>NOTE: GOenrichmentAnalysis is deprecated. Please use function
enrichmentAnalysis from R package anRichment, available from
https://labs.genetics.ucla.edu/horvath/htdocs/CoexpressionNetwork/GeneAnnotation/
</p>
<p>WARNING: This function should be considered experimental. The arguments and resulting values (in
particular, the enrichment p-values) are not
yet finalized and may change in the future. The function should only be used to get a quick and rough
overview of GO enrichment in the modules in a data set; for a publication-quality analysis, please use an
established tool.
</p>
<p>Using Bioconductor's annotation packages, this function calculates enrichments and returns terms with
best enrichment values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GOenrichmentAnalysis(labels, 
                     entrezCodes, 
                     yeastORFs = NULL,
                     organism = "human", 
                     ontologies = c("BP", "CC", "MF"), 
                     evidence = "all",
                     includeOffspring = TRUE, 
                     backgroundType = "givenInGO",
                     removeDuplicates = TRUE,
                     leaveOutLabel = NULL,
                     nBestP = 10, pCut = NULL, 
                     nBiggest = 0, 
                     getTermDetails = TRUE,
                     verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GOenrichmentAnalysis_+3A_labels">labels</code></td>
<td>
<p> cluster (module, group) labels of genes to be analyzed. Either a single vector, or a
matrix. In the matrix case, each column will be analyzed separately; analyzing a collection of module
assignments in one function call will be faster than calling the function several tinmes. For each row,
the labels in all columns must correspond to the same gene specified in <code>entrezCodes</code>.  </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_entrezcodes">entrezCodes</code></td>
<td>
<p> Entrez (a.k.a. LocusLink) codes of the genes whose labels are given in
<code>labels</code>. A single vector; the i-th entry corresponds to row i of the matrix
<code>labels</code> (or to the i-the entry if <code>labels</code> is a vector). </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_yeastorfs">yeastORFs</code></td>
<td>
<p> if <code>organism=="yeast"</code> (below), this argument can be used to input yeast open
reading frame (ORF) identifiers instead of Entrez codes. Since the GO mappings for yeast are provided in
terms of ORF identifiers, this may lead to a more accurate GO enrichment analysis. If given, the argument
<code>entrezCodes</code> is ignored. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_organism">organism</code></td>
<td>
<p> character string specifying the organism for which to perform the analysis. Recognized
values are (unique abbreviations of) <code>"human", "mouse", "rat", "malaria", "yeast", "fly", "bovine",
"worm", "canine", "zebrafish", "chicken"</code>. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_ontologies">ontologies</code></td>
<td>
<p> vector of character strings specifying GO ontologies to be included in the analysis. 
Can be any subset of <code>"BP", "CC", "MF"</code>. The result will contain the terms with highest enrichment
in each specified category, plus a separate list of terms with best enrichment in all ontologies
combined. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_evidence">evidence</code></td>
<td>
<p> vector of character strings specifying admissible evidence for each gene in its
specific term, or &quot;all&quot; for all evidence codes. See Details or http://www.geneontology.org/GO.evidence.shtml for
available evidence codes and their meaning.</p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_includeoffspring">includeOffspring</code></td>
<td>
<p> logical: should genes belonging to the offspring of each term be included in
the term? As a default, only genes belonging directly to each term are associated with the term. Note
that the calculation of enrichments with offspring included can be quite slow for large data sets.</p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_backgroundtype">backgroundType</code></td>
<td>
<p>specification of the background to use. Recognized values are (unique
abbreviations of) <code>"allGiven", "allInGO", "givenInGO"</code>, meaning that the functions will take all
genes given in <code>labels</code> as backround (<code>"allGiven"</code>), all genes present in any of the GO
categories (<code>"allInGO"</code>), or the intersection of given genes and genes present in GO
(<code>"givenInGO"</code>). The default is recommended for genome-wide enrichment studies. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_removeduplicates">removeDuplicates</code></td>
<td>
<p>logical: should duplicate entries in <code>entrezCodes</code> be removed? If
<code>TRUE</code>, only the first occurence of each unique Entrez code will be kept. The cluster labels
<code>labels</code> will be adjusted accordingly.</p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_leaveoutlabel">leaveOutLabel</code></td>
<td>
<p>optional specifications of module labels for which enrichment calculation is not
desired. Can be a single label or a vector of labels to be ignored. However, if in any of the sets no
labels are left to calculate enrichment of, the function will stop with an error.</p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_nbestp">nBestP</code></td>
<td>
<p> specifies the number of terms with highest enrichment whose detailed information will be
returned. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_pcut">pCut</code></td>
<td>
<p> alternative specification of terms to be returned: all terms whose enrichment p-value is
more significant than <code>pCut</code> will be returned. If <code>pCut</code> is given, <code>nBestP</code> is ignored. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_nbiggest">nBiggest</code></td>
<td>
<p> in addition to returning terms with highest enrichment, terms that contain most of the
genes in each cluster can be returned by specifying the number of biggest terms per cluster to be
returned. This may be useful for development and testing purposes. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_gettermdetails">getTermDetails</code></td>
<td>
<p> logical indicating whether detailed information on the most enriched terms should
be returned. </p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_verbose">verbose</code></td>
<td>
<p> integer specifying the verbosity of the function. Zero means silent, positive values
will cause the function to print progress reports.</p>
</td></tr>
<tr><td><code id="GOenrichmentAnalysis_+3A_indent">indent</code></td>
<td>
<p> integer specifying indentation of the diagnostic messages. Zero means no indentation,
each unit adds two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is basically a wrapper for the annotation packages available from Bioconductor. It
requires the packages GO.db, AnnotationDbi, and org.xx.eg.db, where xx is the code corresponding to the
organism that the user wishes to analyze (e.g., Hs for human Homo Sapiens, Mm for mouse Mus Musculus
etc). For each cluster specified in the input, the function calculates all enrichments in the specified
ontologies, and collects information about the terms with highest enrichment. The enrichment p-value is
calculated using Fisher exact test. As background we use all of the supplied genes that are present in at
least one term in GO (in any of the ontologies). 
</p>
<p>For best results, the newest annotation libraries should be used. Because of the way
Bioconductor is set up, to get the newest annotation libraries you may have to use the current version of
R. 
</p>
<p>According to http://www.geneontology.org/GO.evidence.shtml, the following codes are used by GO:
</p>
<pre>
  Experimental Evidence Codes
      EXP: Inferred from Experiment
      IDA: Inferred from Direct Assay
      IPI: Inferred from Physical Interaction
      IMP: Inferred from Mutant Phenotype
      IGI: Inferred from Genetic Interaction
      IEP: Inferred from Expression Pattern

  Computational Analysis Evidence Codes
      ISS: Inferred from Sequence or Structural Similarity
      ISO: Inferred from Sequence Orthology
      ISA: Inferred from Sequence Alignment
      ISM: Inferred from Sequence Model
      IGC: Inferred from Genomic Context
      IBA: Inferred from Biological aspect of Ancestor
      IBD: Inferred from Biological aspect of Descendant
      IKR: Inferred from Key Residues
      IRD: Inferred from Rapid Divergence
      RCA: inferred from Reviewed Computational Analysis

  Author Statement Evidence Codes
      TAS: Traceable Author Statement
      NAS: Non-traceable Author Statement

  Curator Statement Evidence Codes
      IC: Inferred by Curator
      ND: No biological Data available

  Automatically-assigned Evidence Codes
      IEA: Inferred from Electronic Annotation

  Obsolete Evidence Codes
      NR: Not Recorded 
</pre>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>keptForAnalysis</code></td>
<td>
<p> logical vector with one entry per given gene. <code>TRUE</code> if the entry was
used for enrichment analysis. Depending on the setting of <code>removeDuplicates</code> above, only a single
entry per gene may be used. </p>
</td></tr>
<tr><td><code>inGO</code></td>
<td>
<p> logical vector with one entry per given gene. <code>TRUE</code> if the gene belongs to any GO
term, <code>FALSE</code> otherwise. Also <code>FALSE</code> for genes not used for the analysis because of
duplication. </p>
</td></tr>
</table>
<p>If input <code>labels</code> contained only one vector of labels, the following components:
</p>
<table role = "presentation">
<tr><td><code>countsInTerms</code></td>
<td>
<p> a matrix whose rows correspond to given cluster, and whose columns correspond to
GO terms, contaning number of genes in the intersection of the corresponding module and GO term. Row and
column names are set appropriately.</p>
</td></tr>
<tr><td><code>enrichmentP</code></td>
<td>
<p>a matrix whose rows correspond to given cluster, and whose columns correspond to 
GO terms, contaning enrichment p-values of each term in each cluster. Row and
column names are set appropriately.</p>
</td></tr>
<tr><td><code>bestPTerms</code></td>
<td>
<p>a list of lists with each inner list corresponding to an ontology given in
<code>ontologies</code> in input, plus one component corresponding to all given ontologies combined. 
The name of each component is set appropriately. Each inner list contains two components: 
<code>enrichment</code> is
a data frame containing the highest enriched terms for each module; and <code>forModule</code> is a list of
lists with one inner list per module, appropriately named. Each inner list contains one component per term.
If input <code>getTermDeyails</code> is <code>TRUE</code>, 
this component is yet another list and contains components <code>termName</code> (term name), 
<code>enrichmentP</code> (enrichment P value), <code>termDefinition</code> (GO term definition), 
<code>termOntology</code> (GO term ontology), <code>geneCodes</code> (Entrez codes of module genes in this term),
<code>genePositions</code> (indices of the genes listed in <code>geneCodes</code> within the given <code>labels</code>). 
Thus, to obtain information on say the second term of the 5th module in ontology BP, 
one can look at the appropriate row of <code>bestPTerms$BP$enrichment</code>, or one can reference
<code>bestPTerms$BP$forModule[[5]][[2]]</code>. The author of the function apologizes for any confusion this
structure of the output may cause. </p>
</td></tr>
<tr><td><code>biggestTerms</code></td>
<td>
<p>a list of the same format as <code>bestPTerms</code>, containing information about the
terms with most genes in the module for each supplied ontology. </p>
</td></tr>
</table>
<p>If input <code>labels</code> contained more than one vector, instead of the above components the return value
contains a list named <code>setResults</code> that has one component per given set; each component is a list
containing the above components for the corresponding set.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

<p> Bioconductor's annotation packages such as GO.db and organism-specific annotation
packages such as org.Hs.eg.db. </p>

<hr>
<h2 id='goodGenes'> Filter genes with too many missing entries </h2><span id='topic+goodGenes'></span>

<h3>Description</h3>

<p>This function checks data for missing entries and returns a list of genes that have non-zero variance
and pass two criteria on maximum
number of missing values and values whose weight is below a threshold: 
the fraction of missing values must be below a given threshold and the total number
of present samples must be at least equal to a given threshold. If weights are given, entries whose relative
weight is below a threshold will be considered missing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodGenes(
  datExpr, 
  weights = NULL,
  useSamples = NULL, 
  useGenes = NULL, 
  minFraction = 1/2, 
  minNSamples = ..minNSamples, 
  minNGenes = ..minNGenes, 
  tol = NULL,
  minRelativeWeight = 0.1,
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodGenes_+3A_datexpr">datExpr</code></td>
<td>
<p>  expression data. A data frame in which columns are genes and rows ar samples. </p>
</td></tr>
<tr><td><code id="goodGenes_+3A_weights">weights</code></td>
<td>
<p>optional observation weights in the same format (and dimensions) as <code>datExpr</code>.</p>
</td></tr>
<tr><td><code id="goodGenes_+3A_usesamples">useSamples</code></td>
<td>
<p> optional specifications of which samples to use for the check. Should be a logical
vector; samples whose entries are <code>FALSE</code> will be ignored for the missing value counts. Defaults to
using all samples.</p>
</td></tr>
<tr><td><code id="goodGenes_+3A_usegenes">useGenes</code></td>
<td>
<p> optional specifications of genes for which to perform the check. Should be a logical 
vector; genes whose entries are <code>FALSE</code> will be ignored. Defaults to 
using all genes.</p>
</td></tr>
<tr><td><code id="goodGenes_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodGenes_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of non-missing samples for a gene to be considered good.  </p>
</td></tr>
<tr><td><code id="goodGenes_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of good genes for the data set to be considered fit for analysis. If
the actual number of good genes falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodGenes_+3A_tol">tol</code></td>
<td>
<p> an optional 'small' number to compare the variance against. Defaults to the square of
<code>1e-10 * max(abs(datExpr), na.rm = TRUE)</code>. The reason of comparing the variance to this number, rather than
zero, is that the fast way of computing variance used by this function sometimes causes small numerical
overflow errors which make variance of constant vectors slightly non-zero; comparing the variance to
<code>tol</code> rather than zero prevents the retaining of such genes as 'good genes'.</p>
</td></tr>
<tr><td><code id="goodGenes_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose relative weight is below
this threshold will be considered missing. Here relative weight is weight divided by the maximum weight in
the column (gene).</p>
</td></tr> 
<tr><td><code id="goodGenes_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodGenes_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4.
</p>
<p>If weights are given, entries whose relative
weight (i.e., weight divided by maximum weight in the column or gene) will be considered missing.
</p>
<p>For most data sets, the fraction of missing samples criterion will be much more stringent than the
absolute number of missing samples criterion.
</p>


<h3>Value</h3>

<p>A logical vector with one entry per gene that is <code>TRUE</code> if the gene is considered good and
<code>FALSE</code> otherwise. Note that all genes excluded by <code>useGenes</code> are automatically assigned
<code>FALSE</code>. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder and Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> </p>

<hr>
<h2 id='goodGenesMS'>Filter genes with too many missing entries across multiple sets </h2><span id='topic+goodGenesMS'></span>

<h3>Description</h3>

<p>This function checks data for missing entries and returns a list of genes that have non-zero variance
in all sets and pass two criteria on
maximum number of missing values in each given set: the fraction of missing values must be below a given
threshold and the total number of missing samples must be below a given threshold. If weights are given,
entries whose relative weight is below a threshold will be considered missing. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodGenesMS(
  multiExpr,
  multiWeights = NULL,
  useSamples = NULL,
  useGenes = NULL,
  minFraction = 1/2,
  minNSamples = ..minNSamples,
  minNGenes = ..minNGenes,
  tol = NULL,
  minRelativeWeight = 0.1,
  verbose = 1, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodGenesMS_+3A_multiexpr">multiExpr</code></td>
<td>
<p>  expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_usesamples">useSamples</code></td>
<td>
<p> optional specifications of which samples to use for the check. Should be a logical
vector; samples whose entries are <code>FALSE</code> will be ignored for the missing value counts. Defaults to
using all samples.</p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_usegenes">useGenes</code></td>
<td>
<p> optional specifications of genes for which to perform the check. Should be a logical
vector; genes whose entries are <code>FALSE</code> will be ignored. Defaults to
using all genes.</p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of non-missing samples for a gene to be considered good.  </p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of good genes for the data set to be considered fit for analysis. If
the actual number of good genes falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_tol">tol</code></td>
<td>
<p> an optional 'small' number to compare the variance against. For each set in <code>multiExpr</code>, 
the default value is <code>1e-10 * max(abs(multiExpr[[set]]$data), na.rm = TRUE)</code>. 
The reason of comparing the variance to this number, rather than
zero, is that the fast way of computing variance used by this function sometimes causes small numerical 
overflow errors which make variance of constant vectors slightly non-zero; comparing the variance to
<code>tol</code> rather than zero prevents the retaining of such genes as 'good genes'.</p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose relative weight is below
this threshold will be considered missing. Here relative weight is weight divided by the maximum weight in
the column (gene).</p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodGenesMS_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4. 
</p>
<p>If weights are given, entries whose relative
weight (i.e., weight divided by maximum weight in the column or gene) will be considered missing.
</p>
<p>For most data sets, the fraction of missing samples criterion will be much more stringent than the
absolute number of missing samples criterion.
</p>


<h3>Value</h3>

<p>A logical vector with one entry per gene that is <code>TRUE</code> if the gene is considered good and
<code>FALSE</code> otherwise. Note that all genes excluded by <code>useGenes</code> are automatically assigned
<code>FALSE</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+goodGenes">goodGenes</a></code>, <code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> for cleaning
individual sets separately;
</p>
<p><code><a href="#topic+goodSamplesMS">goodSamplesMS</a></code>,  <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for additional cleaning of multiple data
sets together. </p>

<hr>
<h2 id='goodSamples'> Filter samples with too many missing entries </h2><span id='topic+goodSamples'></span>

<h3>Description</h3>

<p>This function checks data for missing entries and returns a list of samples that pass two criteria on
maximum
number of missing values: the fraction of missing values must be below a given threshold and the total
number
of missing genes must be below a given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodSamples(
  datExpr, 
  weights = NULL,
  useSamples = NULL, 
  useGenes = NULL, 
  minFraction = 1/2, 
  minNSamples = ..minNSamples, 
  minNGenes = ..minNGenes, 
  minRelativeWeight = 0.1,
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodSamples_+3A_datexpr">datExpr</code></td>
<td>
<p>  expression data. A data frame in which columns are genes and rows ar samples. </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_weights">weights</code></td>
<td>
<p>optional observation weights in the same format (and dimensions) as <code>datExpr</code>.</p>
</td></tr>
<tr><td><code id="goodSamples_+3A_usesamples">useSamples</code></td>
<td>
<p> optional specifications of which samples to use for the check. Should be a logical
vector; samples whose entries are <code>FALSE</code> will be ignored for the missing value counts. Defaults to
using all samples.</p>
</td></tr>
<tr><td><code id="goodSamples_+3A_usegenes">useGenes</code></td>
<td>
<p> optional specifications of genes for which to perform the check. Should be a logical
vector; genes whose entries are <code>FALSE</code> will be ignored. Defaults to
using all genes.</p>
</td></tr>
<tr><td><code id="goodSamples_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of good samples for the data set to be considered fit for analysis.
If the actual number of good samples falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of non-missing samples for a sample to be considered good.  </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose weight divided by the maximum weight is below this threshold
will be considered missing. </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodSamples_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4.
For most data sets, the fraction of missing samples criterion will be much more stringent than the
absolute number of missing samples criterion.
</p>


<h3>Value</h3>

<p>A logical vector with one entry per sample that is <code>TRUE</code> if the sample is considered good and
<code>FALSE</code> otherwise. Note that all samples excluded by <code>useSamples</code> are automatically assigned
<code>FALSE</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder and Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> </p>

<hr>
<h2 id='goodSamplesGenes'> Iterative filtering of samples and genes with too many missing entries </h2><span id='topic+goodSamplesGenes'></span>

<h3>Description</h3>

<p>This function checks data for missing entries, entries with weights below a threshold, and zero-variance genes, 
and returns a list of samples and genes 
that pass criteria on maximum number of missing or low weight values. If necessary, the filtering is iterated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodSamplesGenes(
  datExpr, 
  weights = NULL,
  minFraction = 1/2, 
  minNSamples = ..minNSamples, 
  minNGenes = ..minNGenes, 
  tol = NULL,
  minRelativeWeight = 0.1,
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodSamplesGenes_+3A_datexpr">datExpr</code></td>
<td>
<p>  expression data. A matrix or data frame in which columns are genes and rows ar samples. </p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_weights">weights</code></td>
<td>
<p>optional observation weights in the same format (and dimensions) as <code>datExpr</code>.</p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of non-missing samples for a gene to be considered good.  </p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of good genes for the data set to be considered fit for analysis. If
the actual number of good genes falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_tol">tol</code></td>
<td>
<p> an optional 'small' number to compare the variance against. Defaults to the square of
<code>1e-10 * max(abs(datExpr), na.rm = TRUE)</code>. The reason of comparing the variance to this number, rather
than
zero, is that the fast way of computing variance used by this function sometimes causes small numerical 
overflow errors which make variance of constant vectors slightly non-zero; comparing the variance to
<code>tol</code> rather than zero prevents the retaining of such genes as 'good genes'.</p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose relative weight is below
this threshold will be considered missing. Here relative weight is weight divided by the maximum weight in 
the column (gene).</p>
</td></tr> 
<tr><td><code id="goodSamplesGenes_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodSamplesGenes_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function iteratively identifies samples and genes with too many missing entries and genes with
zero variance. If weights are given, entries with relative weight (weight divided by maximum weight in the 
column) below <code>minRelativeWeight</code> will be considered missing. The process is
repeated until the lists of good samples and genes are stable.
The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4.
</p>


<h3>Value</h3>

<p>A list with the foolowing components:
</p>
<table role = "presentation">
<tr><td><code>goodSamples</code></td>
<td>
<p>   A logical vector with one entry per sample that is <code>TRUE</code> if the sample is
considered good and <code>FALSE</code> otherwise.  </p>
</td></tr>
<tr><td><code>goodGenes</code></td>
<td>
<p>  A logical vector with one entry per gene that is <code>TRUE</code> if the gene is
considered good and <code>FALSE</code> otherwise.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodGenes">goodGenes</a></code> </p>

<hr>
<h2 id='goodSamplesGenesMS'>  Iterative filtering of samples and genes with too many missing entries across multiple data sets
</h2><span id='topic+goodSamplesGenesMS'></span>

<h3>Description</h3>

<p>This function checks data for missing entries and zero variance across multiple data sets 
and returns a list of samples and genes
that pass criteria maximum number of missing values. If weights are given, entries whose relative
weight is below a threshold will be considered missing.
The filtering is iterated until convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodSamplesGenesMS(
  multiExpr,
  multiWeights = NULL,
  minFraction = 1/2,
  minNSamples = ..minNSamples,
  minNGenes = ..minNGenes,
  tol = NULL,
  minRelativeWeight = 0.1,
  verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodSamplesGenesMS_+3A_multiexpr">multiExpr</code></td>
<td>
<p>  expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of non-missing samples for a gene to be considered good.  </p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of good genes for the data set to be considered fit for analysis. If
the actual number of good genes falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_tol">tol</code></td>
<td>
<p> an optional 'small' number to compare the variance against. For each set in <code>multiExpr</code>, 
the default value is <code>1e-10 * max(abs(multiExpr[[set]]$data), na.rm = TRUE)</code>. 
The reason of comparing the variance to this number, rather than
zero, is that the fast way of computing variance used by this function sometimes causes small numerical
overflow errors which make variance of constant vectors slightly non-zero; comparing the variance to
<code>tol</code> rather than zero prevents the retaining of such genes as 'good genes'.</p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose relative weight is below
this threshold will be considered missing. Here relative weight is weight divided by the maximum weight in
the column (gene).</p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodSamplesGenesMS_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function iteratively identifies samples and genes with too many missing entries, and genes with
zero variance; iterations are necessary
since excluding samples effectively changes criteria on genes and vice versa. The process is
repeated until the lists of good samples and genes are stable. If weights are given, entries whose relative
weight (i.e., weight divided by maximum weight in the column or gene) 
is below a threshold will be considered missing.
The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4.
</p>


<h3>Value</h3>

<p>A list with the foolowing components:
</p>
<table role = "presentation">
<tr><td><code>goodSamples</code></td>
<td>
<p> A list with one component per given set. Each component is a logical vector with
one entry per sample in the corresponding set that is <code>TRUE</code> if the sample is
considered good and <code>FALSE</code> otherwise.  </p>
</td></tr>
<tr><td><code>goodGenes</code></td>
<td>
<p>  A logical vector with one entry per gene that is <code>TRUE</code> if the gene is
considered good and <code>FALSE</code> otherwise.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

<p><code><a href="#topic+goodGenes">goodGenes</a></code>, <code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> for cleaning
individual sets separately;
</p>
<p><code><a href="#topic+goodSamplesMS">goodSamplesMS</a></code>,  <code><a href="#topic+goodGenesMS">goodGenesMS</a></code> for additional cleaning of multiple data
sets together. </p>

<hr>
<h2 id='goodSamplesMS'>  Filter samples with too many missing entries across multiple data sets </h2><span id='topic+goodSamplesMS'></span>

<h3>Description</h3>

<p>This function checks data for missing entries and returns a list of samples that pass two criteria on
maximum
number of missing values: the fraction of missing values must be below a given threshold and the total
number
of missing genes must be below a given threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodSamplesMS(multiExpr, 
      multiWeights = NULL,
      useSamples = NULL,
      useGenes = NULL,
      minFraction = 1/2,
      minNSamples = ..minNSamples,
      minNGenes = ..minNGenes,
      minRelativeWeight = 0.1,
      verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goodSamplesMS_+3A_multiexpr">multiExpr</code></td>
<td>
<p>  expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_usesamples">useSamples</code></td>
<td>
<p> optional specifications of which samples to use for the check. Should be a logical
vector; samples whose entries are <code>FALSE</code> will be ignored for the missing value counts. Defaults to
using all samples.</p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_usegenes">useGenes</code></td>
<td>
<p> optional specifications of genes for which to perform the check. Should be a logical
vector; genes whose entries are <code>FALSE</code> will be ignored. Defaults to
using all genes.</p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_minfraction">minFraction</code></td>
<td>
<p> minimum fraction of non-missing samples for a gene to be considered good. </p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of good samples for the data set to be considered fit for analysis.
If
the actual number of good samples falls below this threshold, an error will be issued. </p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_minngenes">minNGenes</code></td>
<td>
<p> minimum number of non-missing samples for a sample to be considered good.  </p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_minrelativeweight">minRelativeWeight</code></td>
<td>
<p> observations whose relative weight is below
this threshold will be considered missing. Here relative weight is weight divided by the maximum weight in
the column (gene).</p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="goodSamplesMS_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constants <code>..minNSamples</code> and <code>..minNGenes</code> are both set to the value 4.
</p>
<p>If weights are given, entries whose relative
weight (i.e., weight divided by maximum weight in the column or gene) will be considered missing.
</p>
<p>For most data sets, the fraction of missing samples criterion will be much more stringent than the
absolute number of missing samples criterion.
</p>


<h3>Value</h3>

<p>A list with one component per input set. Each component is a logical vector with one entry per sample
in the corresponding set, indicating whether the sample passed the missing value criteria.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder and Steve Horvath </p>


<h3>See Also</h3>

<p><code><a href="#topic+goodGenes">goodGenes</a></code>, <code><a href="#topic+goodSamples">goodSamples</a></code>, <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> for cleaning
individual sets separately;
</p>
<p><code><a href="#topic+goodGenesMS">goodGenesMS</a></code>,  <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for additional cleaning of multiple data
sets together. 
</p>

<hr>
<h2 id='greenBlackRed'> Green-black-red color sequence </h2><span id='topic+greenBlackRed'></span>

<h3>Description</h3>

<p>Generate a green-black-red color sequence of a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greenBlackRed(n, gamma = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greenBlackRed_+3A_n">n</code></td>
<td>
<p> number of colors to be returned </p>
</td></tr>
<tr><td><code id="greenBlackRed_+3A_gamma">gamma</code></td>
<td>
<p> color correction power </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a color vector that starts with pure green, gradually turns into black and then to
red. The power <code>gamma</code> can be used to control the behaviour of the quarter- and three quarter-values
(between green and black, and black and red, respectively). Higher powers will make the mid-colors more
green and red, respectively.
</p>


<h3>Value</h3>

<p>A vector of colors of length <code>n</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>Examples</h3>

<pre><code class='language-R'>  par(mfrow = c(3, 1))
  displayColors(greenBlackRed(50));
  displayColors(greenBlackRed(50, 2));
  displayColors(greenBlackRed(50, 0.5));
</code></pre>

<hr>
<h2 id='greenWhiteRed'> Green-white-red color sequence </h2><span id='topic+greenWhiteRed'></span>

<h3>Description</h3>

<p>Generate a green-white-red color sequence of a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>greenWhiteRed(n, gamma = 1, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="greenWhiteRed_+3A_n">n</code></td>
<td>
<p> number of colors to be returned </p>
</td></tr>
<tr><td><code id="greenWhiteRed_+3A_gamma">gamma</code></td>
<td>
<p> color change power </p>
</td></tr>
<tr><td><code id="greenWhiteRed_+3A_warn">warn</code></td>
<td>
<p>logical: should the user be warned that this function produces a palette unsuitable for
people with most common color blindness?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a color vector that starts with green, gradually turns into white and then to
red. The power <code>gamma</code> can be used to control the behaviour of the quarter- and three quarter-values
(between green and white, and white and red, respectively). Higher powers will make the mid-colors more
white, while lower powers will make the colors more saturated, respectively.
</p>
<p>Typical use of this function is to produce (via function <code><a href="#topic+numbers2colors">numbers2colors</a></code>) 
a color representation of numbers within a symmetric interval
around 0, for example, the interval [-1, 1]. Note though that since green and red are not distinguishable by
people with the most common type of color blindness, we recommend using the analogous palette returned by
the function <code><a href="#topic+blueWhiteRed">blueWhiteRed</a></code>.
</p>


<h3>Value</h3>

<p>A vector of colors of length <code>n</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+blueWhiteRed">blueWhiteRed</a></code> for a color sequence more friendly to people with the most common type of color
blindness;
</p>
<p><code><a href="#topic+numbers2colors">numbers2colors</a></code> for a function that produces a color representation for continuous numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  par(mfrow = c(3, 1))
  displayColors(greenWhiteRed(50));
  title("gamma = 1")
  displayColors(greenWhiteRed(50, 3));
  title("gamma = 3")
  displayColors(greenWhiteRed(50, 0.5));
  title("gamma = 0.5")
</code></pre>

<hr>
<h2 id='GTOMdist'> Generalized Topological Overlap Measure </h2><span id='topic+GTOMdist'></span>

<h3>Description</h3>

<p>Generalized Topological Overlap Measure, taking into account interactions of higher degree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GTOMdist(adjMat, degree = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GTOMdist_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix. See details below. </p>
</td></tr>
<tr><td><code id="GTOMdist_+3A_degree">degree</code></td>
<td>
<p> integer specifying the maximum degree to be calculated. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of the same dimension as the input <code>adjMat</code>.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Andy Yip </p>


<h3>References</h3>

<p> Yip A, Horvath S (2007) Gene network interconnectedness and the generalized topological
overlap measure. BMC Bioinformatics 2007, 8:22 </p>

<hr>
<h2 id='hierarchicalConsensusCalculation'>
Hierarchical consensus calculation
</h2><span id='topic+hierarchicalConsensusCalculation'></span>

<h3>Description</h3>

<p>Hierarchical consensus calculation with optional data calibration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalConsensusCalculation(
   individualData,

   consensusTree,

   level = 1,
   useBlocks = NULL,
   randomSeed = NULL,
   saveCalibratedIndividualData = FALSE,
   calibratedIndividualDataFilePattern = 
         "calibratedIndividualData-%a-Set%s-Block%b.RData",

   # Return options: the data can be either saved or returned but not both.
   saveConsensusData = TRUE,
   consensusDataFileNames = "consensusData-%a-Block%b.RData",
   getCalibrationSamples= FALSE,

   # Return the intermediate results as well?
   keepIntermediateResults = FALSE,

   # Internal handling of data
   useDiskCache = NULL, 
   chunkSize = NULL,
   cacheDir = ".",
   cacheBase = ".blockConsModsCache",

   # Behaviour
   collectGarbage = FALSE,
   verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalConsensusCalculation_+3A_individualdata">individualData</code></td>
<td>

<p>Individual data from which the consensus is to be calculated. It can be either a list or a
<code><a href="#topic+multiData">multiData</a></code> structure. Each element in <code>individulData</code> can in turn either be a numeric
object (vector, matrix or array) or a <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> structure.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_level">level</code></td>
<td>

<p>Integer which the user should leave at 1.  This serves to keep default set names unique.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_useblocks">useBlocks</code></td>
<td>

<p>When <code>individualData</code> contains <code><a href="#topic+BlockwiseData">BlockwiseData</a></code>, this argument can be an 
integer vector with indices of blocks for which the calculation should be performed.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_randomseed">randomSeed</code></td>
<td>

<p>If non-<code>NULL</code>, the function will save the current state of the random generator, set the given seed,
and restore the random seed to its original state upon exit. If <code>NULL</code>, the seed is not set nor is it
restored on exit.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_savecalibratedindividualdata">saveCalibratedIndividualData</code></td>
<td>

<p>Logical: should calibrated individual data be saved?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_calibratedindividualdatafilepattern">calibratedIndividualDataFilePattern</code></td>
<td>

<p>Pattern from which file names for saving calibrated individual data are determined. The conversions
<code>%a</code>, <code>%s</code> and <code>%b</code> will be replaced by analysis name, set number and block number,
respectively.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_saveconsensusdata">saveConsensusData</code></td>
<td>

<p>Logical: should final consensus be saved (<code>TRUE</code>) or returned in the return value (<code>FALSE</code>)?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_consensusdatafilenames">consensusDataFileNames</code></td>
<td>

<p>Pattern from which file names for saving the final consensus are determined. The conversions
<code>%a</code> and <code>%b</code> will be replaced by analysis name and block number,
respectively.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_getcalibrationsamples">getCalibrationSamples</code></td>
<td>

<p>When calibration method in the <code>consensusOptions</code> component of <code>ConsensusTree</code> is <code>"single
quantile"</code>, this logical argument determines whether the calibration samples should be returned within the
return value.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_keepintermediateresults">keepIntermediateResults</code></td>
<td>

<p>Logical: should results of intermediate consensus calculations (if any) be kept? These are always returned
as <code>BlockwiseData</code> whose data are saved to disk.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_usediskcache">useDiskCache</code></td>
<td>

<p>Logical: should disk cache be used for consensus calculations? The disk cache can be used to store chunks of
calibrated data that are small enough to fit one chunk from each set into memory (blocks may be small enough
to fit one block of one set into memory, but not small enough to fit one block from all sets in a consensus
calculation into memory at the same time). Using disk cache is slower but lessens the memory footprint of 
the calculation.
As a general guide, if individual data are split into blocks, we
recommend setting this argument to <code>TRUE</code>. If this argument is <code>NULL</code>, the function will decide
whether to use disk cache based on the number of sets and block sizes.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_chunksize">chunkSize</code></td>
<td>

<p>Integer giving the chunk size. If left <code>NULL</code>, a suitable size will be chosen automatically.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_cachedir">cacheDir</code></td>
<td>

<p>Directory in which to save cache files. The files are deleted on normal exit but persist if the function
terminates abnormally.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_cachebase">cacheBase</code></td>
<td>

<p>Base for the file names of cache files.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage collection be forced after each major calculation?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_verbose">verbose</code></td>
<td>
<p>Integer level of verbosity of diagnostic messages. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusCalculation_+3A_indent">indent</code></td>
<td>
<p>Indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates consensus in a hierarchical manner, using a separate (and possibly different) set of
consensus options at each step. The &quot;recipe&quot; for the consensus calculation is supplied in the argument
<code>consensusTree</code>. 
</p>
<p>The argument <code>consensusTree</code> should have the following components: (1) <code>inputs</code> must be either a
character vector whose components match <code>names(inputData)</code>, or consensus trees in the own right.
(2) <code>consensusOptions</code> must be a list of class <code>"ConsensusOptions"</code> that specifies options for
calculating the consensus. A suitable set of options can be obtained by calling
<code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>. (3) Optionally, the component <code>analysisName</code> can be a single
character string giving the name for the analysis. When intermediate results are returned, they are returned
in a list whose names will be set from <code>analysisName</code> components, if they exist.
</p>
<p>The actual consensus calculation at each level of the consensus tree
is carried out in function <code><a href="#topic+consensusCalculation">consensusCalculation</a></code>. The consensus options for each individual
consensus calculation are independent from one another, i.e., the consensus options for different steps can
be different.
</p>


<h3>Value</h3>

<p>A list containing the output of the top level call to <code><a href="#topic+consensusCalculation">consensusCalculation</a></code>; if
<code>keepIntermediateResults</code> is <code>TRUE</code>, component <code>inputs</code> contains a (possibly recursive) list
of the results of intermediate consensus calculations. Names of the <code>inputs</code> list are taken from the
corresponding <code>analysisName</code> components if they exist, otherwise from names of the corresponding
<code>inputs</code> components of the supplied <code>consensusTree</code>.  See example below for an example of a
relatively simple consensus tree.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code> for obtaining a suitable list of consensus options;
</p>
<p><code><a href="#topic+consensusCalculation">consensusCalculation</a></code> for the actual calculation of a consensus that underpins this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We generate 3 simple matrices
set.seed(5)
data = replicate(3, matrix(rnorm(10*100), 10, 100))
names(data) = c("Set1", "Set2", "Set3");
# Put together a consensus tree. In this example the final consensus uses 
# as input set 1 and a consensus of sets 2 and 3. 

# First define the consensus of sets 2 and 3:
consTree.23 = newConsensusTree(
           inputs = c("Set2", "Set3"),
           consensusOptions = newConsensusOptions(calibration = "none",
                               consensusQuantile = 0.25),
           analysisName = "Consensus of sets 1 and 2");

# Now define the final consensus
consTree.final = newConsensusTree(
   inputs = list("Set1", consTree.23),
   consensusOptions = newConsensusOptions(calibration = "full quantile",
                               consensusQuantile = 0),
   analysisName = "Final consensus");

consensus = hierarchicalConsensusCalculation(
  individualData = data,
  consensusTree = consTree.final,
  saveConsensusData = FALSE,
  keepIntermediateResults = FALSE)

names(consensus)
</code></pre>

<hr>
<h2 id='hierarchicalConsensusKME'>
Calculation of measures of fuzzy module membership (KME) in hierarchical consensus modules
</h2><span id='topic+hierarchicalConsensusKME'></span>

<h3>Description</h3>

<p>This function calculates several measures of fuzzy module membership in hiearchical consensus modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalConsensusKME(
   multiExpr,
   moduleLabels,
   multiWeights = NULL,
   multiEigengenes = NULL,
   consensusTree,
   signed = TRUE,
   useModules = NULL,
   metaAnalysisWeights = NULL,
   corAndPvalueFnc = corAndPvalue, corOptions = list(),
   corComponent = "cor", getFDR = FALSE,
   useRankPvalue = TRUE,
   rankPvalueOptions = list(calculateQvalue = getFDR, pValueMethod = "scale"),
   setNames = names(multiExpr), excludeGrey = TRUE,
   greyLabel = if (is.numeric(moduleLabels)) 0 else "grey",
   reportWeightType = NULL,
   getOwnModuleZ = TRUE,
   getBestModuleZ = TRUE,
   getOwnConsensusKME = TRUE,
   getBestConsensusKME = TRUE,
   getAverageKME = FALSE,
   getConsensusKME = TRUE,

   getMetaColsFor1Set = FALSE,
   getMetaP = FALSE,
   getMetaFDR = getMetaP &amp;&amp; getFDR,

   getSetKME = TRUE,
   getSetZ = FALSE,
   getSetP = FALSE,
   getSetFDR = getSetP &amp;&amp; getFDR,

   includeID = TRUE,
   additionalGeneInfo = NULL,
   includeWeightTypeInColnames = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalConsensusKME_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_modulelabels">moduleLabels</code></td>
<td>

<p>A vector with one entry per column (gene or probe) in <code>multiExpr</code>, giving the module labels. 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights for data in <code>multiExpr</code>, 
in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used in calculation of KME, i.e., the correlation of module eigengenes with data in
<code>multiExpr</code>. The module eigengenes are not weighted in this calculation.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_multieigengenes">multiEigengenes</code></td>
<td>

<p>Optional specification of module eigengenes of the modules (<code>moduleLabels</code>) in data sets within
<code>multiExpr</code>. If not given, will be calculated.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_signed">signed</code></td>
<td>

<p>Logical: should module membership be considered singed? Signed membership should be used for signed (including
signed hybrid) networks and means that negative module membership means the
gene is not a member of the module.
In other words, in signed networks 
negative kME values are not considered significant and the corresponding p-values will be one-sided. In
unsigned networks, negative kME values are considered significant and the corresponding
p-values will be two-sided.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_usemodules">useModules</code></td>
<td>

<p>Optional vector specifying which modules should be used. Defaults to all modules except the unassigned module.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_metaanalysisweights">metaAnalysisWeights</code></td>
<td>

<p>Optional specification of meta-analysis weights for each input set. If given, must be a numeric vector
of length equal the number of input data sets (i.e., <code>length(multiExpr)</code>). These weights will be used
in addition to constant weights and weights proportional to number of samples (observations) in each set.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_corandpvaluefnc">corAndPvalueFnc</code></td>
<td>

<p>Function that calculates associations between expression profiles and eigengenes. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_coroptions">corOptions</code></td>
<td>

<p>List giving additional arguments to function <code>corAndPvalueFnc</code>. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_corcomponent">corComponent</code></td>
<td>

<p>Name of the component of output of <code>corAndPvalueFnc</code> that contains the actual correlation.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getfdr">getFDR</code></td>
<td>

<p>Logical: should FDR be calculated?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_userankpvalue">useRankPvalue</code></td>
<td>
<p> Logical: should the <code><a href="#topic+rankPvalue">rankPvalue</a></code> function be used to obtain alternative
meta-analysis statistics?</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_rankpvalueoptions">rankPvalueOptions</code></td>
<td>
<p> Additional options for function <code><a href="#topic+rankPvalue">rankPvalue</a></code>. These include
<code>na.last</code> (default <code>"keep"</code>), <code>ties.method</code> (default <code>"average"</code>),
<code>calculateQvalue</code> (default copied from input <code>getQvalues</code>),
and <code>pValueMethod</code> (default <code>"scale"</code>).
See the help file for <code><a href="#topic+rankPvalue">rankPvalue</a></code> for full details.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_setnames">setNames</code></td>
<td>

<p>Names for the input sets. If not given, will be taken from <code>names(multiExpr)</code>. If those are
<code>NULL</code> as well, the names will be <code>"Set_1", "Set_2", ...</code>.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_excludegrey">excludeGrey</code></td>
<td>

<p>logical: should the grey module be excluded from the kME tables? Since the grey module is typically not a
real module, it makes little sense to report kME values for it.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_greylabel">greyLabel</code></td>
<td>

<p>label that labels the grey module.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_reportweighttype">reportWeightType</code></td>
<td>

<p>One of <code>"equal", "rootDoF", "DoF", "user"</code>. Indicates which of the weights should be reported in the
output. If not given, all available weight types will be reported; this always includes <code>"equal",
"rootDoF", "DoF"</code>, while <code>"user"</code> weights are reported if <code>metaAnalysisWeights</code> above is given.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getownmodulez">getOwnModuleZ</code></td>
<td>

<p>Logical: should meta-analysis Z statistic in own module be returned as a column of the output?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getbestmodulez">getBestModuleZ</code></td>
<td>

<p>Logical: should highest meta-analysis Z statistic across all modules and the corresponding module be returned
as columns of the output?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getownconsensuskme">getOwnConsensusKME</code></td>
<td>

<p>Logical: should consensus KME (eigengene-based connectivity) statistic in own module be returned as a 
column of the output?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getbestconsensuskme">getBestConsensusKME</code></td>
<td>

<p>Logical: should highest consensus KME across all modules and the corresponding module be returned 
as columns of the output?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getaveragekme">getAverageKME</code></td>
<td>

<p>Logical: Should average KME be calculated? 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getconsensuskme">getConsensusKME</code></td>
<td>

<p>Logical: should consensus KME be calculated?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getmetacolsfor1set">getMetaColsFor1Set</code></td>
<td>

<p>Logical: should the meta-statistics be returned if the input data only have 1 set? For 1 set, meta- and individual kME
values are the same, so meta-columns essentially duplicate individual columns.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getmetap">getMetaP</code></td>
<td>

<p>Logical: should meta-analysis p-values corresponding to the KME meta-analysis Z statistics be calculated?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getmetafdr">getMetaFDR</code></td>
<td>

<p>Logical: should FDR estimates for the meta-analysis p-values corresponding to the KME meta-analysis Z
statistics be calculated? 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getsetkme">getSetKME</code></td>
<td>

<p>Logical: should KME values for individual sets be returned?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getsetz">getSetZ</code></td>
<td>

<p>Logical: should Z statistics corresponding to KME for individual sets be returned?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getsetp">getSetP</code></td>
<td>

<p>Logical: should p values corresponding to KME for individual sets be returned?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_getsetfdr">getSetFDR</code></td>
<td>

<p>Logical: should FDR estimates corresponding to KME for individual sets be returned?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_includeid">includeID</code></td>
<td>

<p>Logical: should gene ID (taken from column names of <code>multiExpr</code>) be included as the first column in
the output?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_additionalgeneinfo">additionalGeneInfo</code></td>
<td>

<p>Optional data frame with rows corresponding to genes in <code>multiExpr</code> that should be included as part of
the output.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusKME_+3A_includeweighttypeincolnames">includeWeightTypeInColnames</code></td>
<td>

<p>Logical: should weight type (<code>"equal", "rootDoF", "DoF", "user"</code>) be included in appropriate
meta-analysis column names?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates several measures of (hierarchical) consensus KME (eigengene-based intramodular
connectivity or fuzzy module membership) for all genes in all modules.
</p>
<p>First, it calculates the meta-analysis Z statistics for correlations
between genes and module eigengenes; this is known as the consensus module membership Z statistic. The
meta-analysis weights can be specified by the user either explicitly or implicitly (&quot;equal&quot;, &quot;RootDoF&quot; or
&quot;DoF&quot;). 
</p>
<p>Second, it can calculate the consensus KME, i.e., the hierarchical consensus of the KMEs (correlations with
eigengenes) across the individual sets. The consensus calculation is specified in the argument
<code>consensusTree</code>; 
typically, the <code>consensusTree</code> used here will be the same as the one used for the actual consensus
network construction and module identification.  
See <code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for details on how to specify consensus trees.
</p>
<p>Third, the function can also calculate the (weighted) average KME using the meta-analysis weights; the average
KME can be interpreted as the meta-analysis of the KMEs in the individual sets. This is related to but
somewhat distinct from the meta-analysis Z statistics.
</p>
<p>In addition to these, optional output also includes, for each gene, KME values in the module to which the gene
is assigned as well as the maximum KME values and modules for
which the maxima are attained. For most genes, the assigned module will be the one with highest KME values,
but for some genes the assigned module and module of maximum KME may be different.
</p>
<p>The function <code>corAndPvalueFnc</code> is currently
is expected to accept arguments <code>x</code> (gene expression profiles), <code>y</code> (eigengene expression
profiles), and <code>alternative</code> with possibilities at least <code>"greater", "two.sided"</code>. If weights are
given, these are passed to <code>corAndPvalueFnc</code> as argument <code>weights.x</code>.
Any additional arguments can be passed via <code>corOptions</code>.
</p>
<p>The function <code>corAndPvalueFnc</code> should return a list which at the least contains (1) a matrix
of associations of genes and eigengenes (this component should have the name given by <code>corComponent</code>),
and (2) a matrix of the corresponding p-values, named &quot;p&quot; or &quot;p.value&quot;. Other components are optional but
for full functionality should include
(3) <code>nObs</code> giving the number of observations for each association (which is the number of samples less
number of missing data - this can in principle vary from association to association), and (4) <code>Z</code>
giving a Z static for each observation. If these are missing, <code>nObs</code> is calculated in the main
function, and calculations using the Z statistic are skipped.
</p>


<h3>Value</h3>

<p>Data frame with the following components, some of which may be missing depending on input options (for easier
readability the order here is not the same as in the actual output): 
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p>Gene ID, taken from the column names of the first input data set</p>
</td></tr>
</table>
<p>If given, a copy of <code>additionalGeneInfo</code>.
</p>
<table role = "presentation">
<tr><td><code>Z.kME.inOwnModule</code></td>
<td>
<p>Meta-analysis Z statistic for membership in assigned module.</p>
</td></tr>
<tr><td><code>maxZ.kME</code></td>
<td>
<p>Maximum meta-analysis Z statistic for membership across all modules.</p>
</td></tr>
<tr><td><code>moduleOfMaxZ.kME</code></td>
<td>
<p>Module in which the maximum meta-analysis Z statistic is attained. </p>
</td></tr>
<tr><td><code>consKME.inOwnModule</code></td>
<td>
<p>Consensus KME in assigned module.</p>
</td></tr>
<tr><td><code>maxConsKME</code></td>
<td>
<p>Maximum consensus KME across all modules.</p>
</td></tr>
<tr><td><code>moduleOfMaxConsKME</code></td>
<td>
<p>Module in which the maximum consensus KME is attained.</p>
</td></tr>
<tr><td><code>consensus.kME.1</code>, <code>consensus.kME.2</code>, <code>...</code></td>
<td>
<p>Consensus kME (that is, the requested quantile of the kMEs in the
individual data sets)in each module for each gene across the input data
sets. The module labels (here 1, 2, etc.) correspond to those in <code>moduleLabels</code>.</p>
</td></tr>
<tr><td><code>weightedAverage.equalWeights.kME1</code>, <code>weightedAverage.equalWeights.kME2</code>, <code>...</code></td>
<td>

<p>Average kME in each module for each gene across the
input data sets. </p>
</td></tr>
<tr><td><code>weightedAverage.RootDoFWeights.kME1</code>, <code>weightedAverage.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is proportional to the square root of the 
number of samples in the set. </p>
</td></tr>
<tr><td><code>weightedAverage.DoFWeights.kME1</code>, <code>weightedAverage.DoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is proportional to number of samples in the set. </p>
</td></tr>
<tr><td><code>weightedAverage.userWeights.kME1</code>, <code>weightedAverage.userWeights.kME2</code>, <code>...</code></td>
<td>

<p>(Only present if input <code>metaAnalysisWeights</code> is non-NULL.)
Weighted average kME in each module for each gene across the
input data sets. The weight of each data set is given in <code>metaAnalysisWeights</code>.</p>
</td></tr>
<tr><td><code>meta.Z.equalWeights.kME1</code>, <code>meta.Z.equalWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set equally. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.RootDoFWeights.kME1</code>, <code>meta.Z.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>

<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by the square root of the number of
samples. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.DoFWeights.kME1</code>, <code>meta.Z.DoFWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by the number of
samples. Only returned if the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.Z.userWeights.kME1</code>, <code>meta.Z.userWeights.kME2</code>, <code>...</code></td>
<td>
<p>Meta-analysis Z statistic for kME in each module, 
obtained by weighing the Z scores in each set by <code>metaAnalysisWeights</code>. 
Only returned if <code>metaAnalysisWeights</code> is non-NULL and the function <code>corAndPvalueFnc</code>
returns the Z statistics corresponding to the correlations.</p>
</td></tr>
<tr><td><code>meta.p.equalWeights.kME1</code>, <code>meta.p.equalWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the equal-weight meta-analysis Z statistics. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.RootDoFWeights.kME1</code>, <code>meta.p.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the meta-analysis Z statistics with weights proportional to the square root of the
number of samples. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.DoFWeights.kME1</code>, <code>meta.p.DoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the degree-of-freedom weight meta-analysis Z statistics. Only returned if the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.p.userWeights.kME1</code>, <code>meta.p.userWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>p-values obtained from the user-supplied weight meta-analysis Z statistics. Only returned if
<code>metaAnalysisWeights</code> is non-NULL and the function
<code>corAndPvalueFnc</code> returns the Z statistics corresponding to the correlations. </p>
</td></tr> 
<tr><td><code>meta.q.equalWeights.kME1</code>, <code>meta.q.equalWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the equal-weight meta-analysis p-values. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.RootDoFWeights.kME1</code>, <code>meta.q.RootDoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the meta-analysis p-values with weights proportional to the square root of the 
number of samples. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.DoFWeights.kME1</code>, <code>meta.q.DoFWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the degree-of-freedom weight meta-analysis p-values. Only present if
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
<tr><td><code>meta.q.userWeights.kME1</code>, <code>meta.q.userWeights.kME2</code>, <code>...</code></td>
<td>
 
<p>q-values obtained from the user-specified weight meta-analysis p-values. Only present if
<code>metaAnalysisWeights</code> is non-NULL, 
<code>getQvalues</code> is <code>TRUE</code> and the function <code>corAndPvalueFnc</code> 
returns the Z statistics corresponding to the kME values.</p>
</td></tr>
</table>
<p>The next set of columns contain the results of function <code><a href="#topic+rankPvalue">rankPvalue</a></code> and are only present if
input <code>useRankPvalue</code> is <code>TRUE</code>. Some columns may be missing depending on the options specified in
<code>rankPvalueOptions</code>. We explicitly list columns that are based on weighing each set equally; names of
these columns carry the suffix <code>.equalWeights</code>
</p>
<table role = "presentation">
<tr><td><code>pValueExtremeRank.ME1.equalWeights</code>, <code>pValueExtremeRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>This is the minimum between pValueLowRank and
pValueHighRank, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowRank.ME1.equalWeights</code>, <code>pValueLowRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
based on the rank method.</p>
</td></tr>
<tr><td><code>pValueHighRank.ME1.equalWeights</code>, <code>pValueHighRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
across the columns of datS based on the rank method.</p>
</td></tr> 
<tr><td><code>pValueExtremeScale.ME1.equalWeights</code>, <code>pValueExtremeScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>This is the minimum between pValueLowScale and
pValueHighScale, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowScale.ME1.equalWeights</code>, <code>pValueLowScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low value
across the columns of datS based on the Scale method.</p>
</td></tr> 
<tr><td><code>pValueHighScale.ME1.equalWeights</code>, <code>pValueHighScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>Asymptotic p-value for observing a consistently low
value across the columns of datS based on the Scale method.</p>
</td></tr> 
<tr><td><code>qValueExtremeRank.ME1.equalWeights</code>, <code>qValueExtremeRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding
to the p-value pValueExtremeRank</p>
</td></tr> 
<tr><td><code>qValueLowRank.ME1.equalWeights</code>, <code>qValueLowRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueLowRank</p>
</td></tr> 
<tr><td><code>qValueHighRank.ME1.equalWeights</code>, <code>lueHighRank.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueHighRank</p>
</td></tr> 
<tr><td><code>qValueExtremeScale.ME1.equalWeights</code>, <code>qValueExtremeScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value)
corresponding to the p-value pValueExtremeScale</p>
</td></tr>
<tr><td><code>qValueLowScale.ME1.equalWeights</code>, <code>qValueLowScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to the
p-value pValueLowScale</p>
</td></tr>
<tr><td><code>qValueHighScale.ME1.equalWeights</code>, <code>qValueHighScale.ME2.equalWeights</code>, <code>...</code></td>
<td>

<p>local false discovery rate (q-value) corresponding to
the p-value pValueHighScale</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Analogous columns corresponding to weighing individual sets by the square root of the number of
samples, by number of samples, and by user weights (if given). The corresponding column name suffixes are 
<code>.RootDoFWeights</code>, <code>.DoFWeights</code>, and <code>.userWeights</code>.</p>
</td></tr>
</table>
<p>The following set of columns summarize kME in individual input data sets.
</p>
<table role = "presentation">
<tr><td><code>kME1.Set_1</code>, <code>kME1.Set_2</code>, <code>...</code>, <code>kME2.Set_1</code>, <code>kME2.Set_2</code>, <code>...</code></td>
<td>
<p> kME values for each gene in each module in
each given data set. </p>
</td></tr>
<tr><td><code>p.kME1.Set_1</code>, <code>p.kME1.Set_2</code>, <code>...</code>, <code>p.kME2.Set_1</code>, <code>p.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> p-values corresponding to 
kME values for each gene in each module in each given data set. </p>
</td></tr>
<tr><td><code>q.kME1.Set_1</code>, <code>q.kME1.Set_2</code>, <code>...</code>, <code>q.kME2.Set_1</code>, <code>q.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> q-values corresponding to 
kME values for each gene in each module in each given data set. Only returned if <code>getQvalues</code> is
<code>TRUE</code>. </p>
</td></tr>
<tr><td><code>Z.kME1.Set_1</code>, <code>Z.kME1.Set_2</code>, <code>...</code>, <code>Z.kME2.Set_1</code>, <code>Z.kME2.Set_2</code>, <code>...</code></td>
<td>
<p> Z statistics corresponding to
kME values for each gene in each module in each given data set. Only present if the function
<code>corAndPvalueFnc</code>                 
returns the Z statistics corresponding to the kME values. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+signedKME">signedKME</a></code> for eigengene based connectivity in a single data set.
<code><a href="#topic+corAndPvalue">corAndPvalue</a></code>, <code><a href="#topic+bicorAndPvalue">bicorAndPvalue</a></code> for two alternatives for calculating correlations and the 
corresponding p-values and Z scores. Both can be used with this function.
<code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for more details on hierarchical consensus trees and calculations.
</p>

<hr>
<h2 id='hierarchicalConsensusMEDissimilarity'>
Hierarchical consensus calculation of module eigengene dissimilarity
</h2><span id='topic+hierarchicalConsensusMEDissimilarity'></span>

<h3>Description</h3>

<p>Hierarchical consensus calculation of module eigengene dissimilarities, or more generally, correlation-based
dissimilarities of sets of vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalConsensusMEDissimilarity(
   MEs, 
   networkOptions, 
   consensusTree, 
   greyName = "ME0", 
   calibrate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalConsensusMEDissimilarity_+3A_mes">MEs</code></td>
<td>

<p>A <code><a href="#topic+multiData">multiData</a></code> structure containing vectors (usually module eigengenes) whose consensus
dissimilarity is to be calculated.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusMEDissimilarity_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A <code><a href="#topic+multiData">multiData</a></code> structure containing, for each input data set, a list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the networks.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusMEDissimilarity_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusMEDissimilarity_+3A_greyname">greyName</code></td>
<td>

<p>Name of the &quot;grey&quot; module eigengene. Currently not used.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusMEDissimilarity_+3A_calibrate">calibrate</code></td>
<td>

<p>Logical: should the dissimilarities be calibrated using the calibration method specified in
<code>consensusTree</code>? See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function first calculates the similarities of the ME vectors from their correlations, using the appropriate
options in <code>networkOptions</code> (correlation type and options, signed or unsigned dissimilarity etc). This
results in a similarity matrix in each of the input data sets. 
</p>
<p>Next, a hierarchical consensus of the similarities is calculated via a call to
<code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code>, using the consensus specification and
options in <code>consensusTree</code>. In typical use, <code>consensusTree</code> contains the same consensus
specification as the consensus network calculation that gave rise to the consensus modules whose eigengenes
are contained in <code>MEs</code> but this is not mandatory.
</p>
<p>The argument <code>consensusTree</code> should have the following components: (1) <code>inputs</code> must be either a
character vector whose components match <code>names(inputData)</code>, or consensus trees in the own right.
(2) <code>consensusOptions</code> must be a list of class <code>"ConsensusOptions"</code> that specifies options for
calculating the consensus. A suitable set of options can be obtained by calling
<code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>. (3) Optionally, the component <code>analysisName</code> can be a single
character string giving the name for the analysis. When intermediate results are returned, they are returned
in a list whose names will be set from <code>analysisName</code> components, if they exist.
</p>
<p>In the final step, the consensus similarity is turned into a dissimilarity by subtracting it from 1.
</p>


<h3>Value</h3>

<p>A matrix with rows and columns corresponding to the variables (modules) in MEs, containing the consensus
dissimilarities. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> for the actual consensus calculation.
</p>

<hr>
<h2 id='hierarchicalConsensusModules'>
Hierarchical consensus network construction and module identification
</h2><span id='topic+hierarchicalConsensusModules'></span>

<h3>Description</h3>

<p>Hierarchical consensus network construction and module identification across multiple data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalConsensusModules(
   multiExpr, 
   multiWeights = NULL,
   multiExpr.imputed = NULL,

   # Data checking options
   checkMissingData = TRUE,

   # Blocking options
   blocks = NULL, 
   maxBlockSize = 5000, 
   blockSizePenaltyPower = 5,
   nPreclusteringCenters = NULL,
   randomSeed = 12345,

   # Network construction options. 
   networkOptions,

   # Save individual TOMs?
   saveIndividualTOMs = TRUE,
   individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",
   keepIndividualTOMs = FALSE,

   # Consensus calculation options
   consensusTree = NULL,  

   # Return options
   saveConsensusTOM = TRUE,
   consensusTOMFilePattern = "consensusTOM-%a-Block%b.RData",

   # Keep the consensus? 
   keepConsensusTOM = saveConsensusTOM,

   # Internal handling of TOMs
   useDiskCache = NULL, chunkSize = NULL,
   cacheBase = ".blockConsModsCache",
   cacheDir = ".",

   # Alternative consensus TOM input from a previous calculation 
   consensusTOMInfo = NULL,

   # Basic tree cut options 
   deepSplit = 2, 
   detectCutHeight = 0.995, minModuleSize = 20,
   checkMinModuleSize = TRUE,

   # Advanced tree cut opyions
   maxCoreScatter = NULL, minGap = NULL,
   maxAbsCoreScatter = NULL, minAbsGap = NULL,
   minSplitHeight = NULL, minAbsSplitHeight = NULL,

   useBranchEigennodeDissim = FALSE,
   minBranchEigennodeDissim = mergeCutHeight,

   stabilityLabels = NULL,
   stabilityCriterion = c("Individual fraction", "Common fraction"),
   minStabilityDissim = NULL,

   pamStage = TRUE,  pamRespectsDendro = TRUE,

   iteratePruningAndMerging = FALSE,
   minCoreKME = 0.5, minCoreKMESize = minModuleSize/3,
   minKMEtoStay = 0.2,

   # Module eigengene calculation options

   impute = TRUE,
   trapErrors = FALSE,
   excludeGrey = FALSE,

   # Module merging options

   calibrateMergingSimilarities = FALSE,
   mergeCutHeight = 0.15, 
                    
   # General options
   collectGarbage = TRUE,
   verbose = 2, indent = 0,
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalConsensusModules_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_multiexpr.imputed">multiExpr.imputed</code></td>
<td>
<p>If <code>multiExpr</code> contain missing data, this argument can be used to supply the
expression data with missing data imputed. If not given, the <code><a href="impute.html#topic+impute.knn">impute.knn</a></code> function will
be used to impute the missing data.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_checkmissingdata">checkMissingData</code></td>
<td>

<p>Logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_blocks">blocks</code></td>
<td>

<p>Optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p>Integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>Number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>Number of centers to be used in the preclustering. Defaults to smaller of
<code>nGenes/20</code> and <code>100*nGenes/maxBlockSize</code>, where <code>nGenes</code> is the nunber of genes (variables)
in <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_randomseed">randomSeed</code></td>
<td>
<p>Integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_saveindividualtoms">saveIndividualTOMs</code></td>
<td>

<p>Logical: should individual TOMs be saved to disk (<code>TRUE</code>) or retuned directly in the
return value (<code>FALSE</code>)?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>

<p>Character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_keepindividualtoms">keepIndividualTOMs</code></td>
<td>

<p>Logical: should individual TOMs be retained after the calculation is finished?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_saveconsensustom">saveConsensusTOM</code></td>
<td>

<p>Logical: should the consensus TOM be saved to disk?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_consensustomfilepattern">consensusTOMFilePattern</code></td>
<td>

<p>Character string giving the file names to save consensus TOMs into. The 
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_keepconsensustom">keepConsensusTOM</code></td>
<td>

<p>Logical: should consensus TOM be retained after the calculation ends? Depending on <code>saveConsensusTOM</code>,
the retained TOM is either saved to disk or returned within the return value.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_usediskcache">useDiskCache</code></td>
<td>

<p>Logical: should disk cache be used for consensus calculations? The disk cache can be used to store chunks of
calibrated data that are small enough to fit one chunk from each set into memory (blocks may be small enough
to fit one block of one set into memory, but not small enough to fit one block from all sets in a consensus
calculation into memory at the same time). Using disk cache is slower but lessens the memory footprint of
the calculation.
As a general guide, if individual data are split into blocks, we
recommend setting this argument to <code>TRUE</code>. If this argument is <code>NULL</code>, the function will decide
whether to use disk cache based on the number of sets and block sizes.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_chunksize">chunkSize</code></td>
<td>

<p>Integer giving the chunk size. If left <code>NULL</code>, a suitable size will be chosen automatically.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_cachedir">cacheDir</code></td>
<td>

<p>Directory in which to save cache files. The files are deleted on normal exit but persist if the function
terminates abnormally.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_cachebase">cacheBase</code></td>
<td>

<p>Base for the file names of cache files.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_consensustominfo">consensusTOMInfo</code></td>
<td>

<p>If the consensus TOM has been pre-calculated using function <code><a href="#topic+hierarchicalConsensusTOM">hierarchicalConsensusTOM</a></code>,
this argument can be used to supply it. If given, the consensus
TOM calculation options above are ignored. 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_deepsplit">deepSplit</code></td>
<td>
<p>Numeric value between 0 and 4. Provides a simplified control over how sensitive
module detection should be to module splitting, with 0 least and 4 most sensitive. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p>Dendrogram cut height for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p>Minimum module size for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_checkminmodulesize">checkMinModuleSize</code></td>
<td>
<p> logical: should sanity checks be performed on <code>minModuleSize</code>?</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_maxcorescatter">maxCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster, given as the fraction
of <code>cutHeight</code> relative to the 5th percentile of joining heights. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_mingap">minGap</code></td>
<td>
<p> minimum cluster gap given as the fraction of the difference between <code>cutHeight</code> and
the 5th percentile of joining heights. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_maxabscorescatter">maxAbsCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster given as absolute
heights. If given, overrides <code>maxCoreScatter</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minabsgap">minAbsGap</code></td>
<td>
<p> minimum cluster gap given as absolute height difference. If given, overrides
<code>minGap</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minsplitheight">minSplitHeight</code></td>
<td>
<p>Minimum split height given as the fraction of the difference between
<code>cutHeight</code> and the 5th percentile of joining heights. Branches merging below this height will
automatically be merged. Defaults to zero but is used only if <code>minAbsSplitHeight</code> below is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minabssplitheight">minAbsSplitHeight</code></td>
<td>
<p>Minimum split height given as an absolute height.
Branches merging below this height will automatically be merged. If not given (default), will be determined
from <code>minSplitHeight</code> above.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_usebrancheigennodedissim">useBranchEigennodeDissim</code></td>
<td>
<p>Logical: should branch eigennode (eigengene) dissimilarity be considered
when merging branches in Dynamic Tree Cut?</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minbrancheigennodedissim">minBranchEigennodeDissim</code></td>
<td>
<p>Minimum consensus branch eigennode (eigengene) dissimilarity for
branches to be considerd separate. The branch eigennode dissimilarity in individual sets
is simly 1-correlation of the
eigennodes; the consensus is defined as quantile with probability <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_stabilitylabels">stabilityLabels</code></td>
<td>
<p>Optional matrix of cluster labels that are to be used for calculating branch
dissimilarity based on split stability. The number of rows must equal the number of genes in
<code>multiExpr</code>; the number of columns (clusterings) is arbitrary. See
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_stabilitycriterion">stabilityCriterion</code></td>
<td>
<p>One of <code>c("Individual fraction", "Common fraction")</code>, indicating which method
for assessing stability similarity of two branches should be used. We recommend <code>"Individual fraction"</code>
which appears to perform better; the <code>"Common fraction"</code> method is provided for backward compatibility
since it was the (only) method available prior to WGCNA version 1.60.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minstabilitydissim">minStabilityDissim</code></td>
<td>
<p>Minimum stability dissimilarity criterion for two branches to be considered
separate. Should be a number between 0 (essentially no dissimilarity required) and 1 (perfect dissimilarity
or distinguishability based on <code>stabilityLabels</code>). See
<code><a href="#topic+branchSplitFromStabilityLabels">branchSplitFromStabilityLabels</a></code> for details.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_pamstage">pamStage</code></td>
<td>
<p> logical.  If TRUE, the second (PAM-like) stage of module detection will be performed.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_pamrespectsdendro">pamRespectsDendro</code></td>
<td>
<p>Logical, only used when <code>pamStage</code> is <code>TRUE</code>.
If <code>TRUE</code>, the PAM stage will
respect the dendrogram in the sense an object can be PAM-assigned only to clusters that lie below it on
the branch that the object is merged into.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_iteratepruningandmerging">iteratePruningAndMerging</code></td>
<td>
<p>Logical: should pruning of low-KME genes and module merging be iterated?
For backward compatibility, the default is <code>FALSE</code> but it setting it to <code>TRUE</code> may lead to
better-defined modules.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled and returned to the pool of genes waiting for mofule detection). </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_excludegrey">excludeGrey</code></td>
<td>
<p> logical: should the returned module eigengenes exclude the eigengene of the &quot;module&quot; that contains
unassigned genes? </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_calibratemergingsimilarities">calibrateMergingSimilarities</code></td>
<td>

<p>Logical: should module eigengene similarities be calibrataed before calculating the consensus? Although
calibration is in principle desirable, the calibration methods currently available assume large data and do
not work very well on eigengene similarities.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_mergecutheight">mergeCutHeight</code></td>
<td>

<p>Dendrogram cut height for module merging. 
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage be collected after some of the memory-intensive steps?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusModules_+3A_...">...</code></td>
<td>

<p>Other arguments. Currently ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates a consensus network with a flexible, possibly hierarchical consensus specification,
identifies (consensus) modules in the network, and calculates their eigengenes. &quot;Blockwise&quot; calculation is
available for large data sets for which a full network (TOM or adjacency matrix) would not fit into avilable
RAM. 
</p>
<p>The input can be either several numerical data sets (expression etc) in the argument <code>multiExpr</code>
together with all necessary network construction options, or a pre-calculated network, typically the result
of a call to <code><a href="#topic+hierarchicalConsensusTOM">hierarchicalConsensusTOM</a></code>. 
</p>
<p>Steps in the network construction include the following: (1) optional 
filtering of variables (genes) and observations
(samples) that contain too many missing values or have zero variance; (2) optional pre-clustering to split
data into blocks of manageable size;
(3) calculation of adjacencies and optionally of TOMs in each individual data set;
(4) calculation of consensus network from the individual networks;
(5) hierarchical clustering and module identification;
(6) trimming of modules by removing genes with low correlation with the eigengene of the module; and 
(7) merging of modules whose eigengenes are strongly correlated.
</p>
<p>Steps 1-4 (up to and including the calculation of consensus network from the individual networks) are
handled by the function <code><a href="#topic+hierarchicalConsensusTOM">hierarchicalConsensusTOM</a></code>. 
</p>
<p>Variables (genes) are clustered using average-linkage hierarchical clustering and modules are identified in the
resulting dendrogram by the Dynamic Hybrid tree cut. 
</p>
<p>Found modules are trimmed of genes whose
consensus module membership kME (that is, correlation with module eigengene)
is less than <code>minKMEtoStay</code>.
Modules in which
fewer than <code>minCoreKMESize</code> genes have consensus KME higher than <code>minCoreKME</code>
are disbanded, i.e., their constituent genes are pronounced
unassigned.
</p>
<p>After all blocks have been processed, the function checks whether there are genes whose KME in the module
they assigned is lower than KME to another module. If p-values of the higher correlations are smaller
than those of the native module by the factor <code>reassignThresholdPS</code> (in every set),
the gene is re-assigned to the closer module.
</p>
<p>In the last step, modules whose eigengenes are highly correlated are merged. This is achieved by
clustering module eigengenes using the dissimilarity given by one minus their correlation,
cutting the dendrogram at the height <code>mergeCutHeight</code> and merging all modules on each branch. The
process is iterated until no modules are merged. See <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for more details on
module merging.
</p>
<p>The module trimming and merging process is optionally iterated. Iterations are recommended but are (for now)
not the default for backward compatibility.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>labels</code></td>
<td>
<p>A numeric vector with one component per variable (gene), 
giving the module label of each variable (gene).  Label 0 is reserved for unassigned variables; module labels
are sequential and smaller numbers are used for larger modules.</p>
</td></tr>
<tr><td><code>unmergedLabels</code></td>
<td>
<p>A numeric vector with one component per variable (gene),
giving the unmerged module label of each variable (gene), i.e., module labels before the call to module
merging.</p>
</td></tr>
<tr><td><code>colors</code></td>
<td>
<p>A character vector with one component per variable (gene),
giving the module colors. The labels are mapped to colors using <code><a href="#topic+labels2colors">labels2colors</a></code>.</p>
</td></tr>
<tr><td><code>unmergedColors</code></td>
<td>
<p>A character vector with one component per variable (gene),
giving the unmerged module colors.</p>
</td></tr>
<tr><td><code>multiMEs</code></td>
<td>
<p>Module eigengenes corresponding to the modules returned in <code>colors</code>, in multi-set
format. A vector of lists, one per set, containing eigengenes, proportion of variance explained and other
information. See <code><a href="#topic+multiSetMEs">multiSetMEs</a></code> for a detailed description.</p>
</td></tr>
<tr><td><code>dendrograms</code></td>
<td>
<p>A list with one component for each block of genes. Each component is the
hierarchical clustering dendrogram obtained by clustering the consensus gene dissimilarity in the
corresponding block. </p>
</td></tr>
<tr><td><code>consensusTOMInfo</code></td>
<td>
<p>A list detailing various aspects of the consensus TOM. See
<code><a href="#topic+hierarchicalConsensusTOM">hierarchicalConsensusTOM</a></code> for details.</p>
</td></tr>
<tr><td><code>blockInfo</code></td>
<td>
<p>A list with information about blocks as well as the vriables and observations 
(genes and samples) retained after filtering out those with zero variance and too many missing values.</p>
</td></tr>
<tr><td><code>moduleIdentificationArguments</code></td>
<td>
<p>A list with the module identification arguments supplied to this
function. Contains
<code>deepSplit</code>,
<code>detectCutHeight</code>,
<code>minModuleSize</code>,
<code>maxCoreScatter</code>,
<code>minGap</code>,
<code>maxAbsCoreScatter</code>,
<code>minAbsGap</code>,
<code>minSplitHeight</code>,
<code>useBranchEigennodeDissim</code>,
<code>minBranchEigennodeDissim</code>,
<code>minStabilityDissim</code>,
<code>pamStage</code>,
<code>pamRespectsDendro</code>,
<code>minCoreKME</code>,
<code>minCoreKMESize</code>,
<code>minKMEtoStay</code>,
<code>calibrateMergingSimilarities</code>, and
<code>mergeCutHeight</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the input datasets have large numbers of genes, consider carefully the <code>maxBlockSize</code> as it
significantly affects the memory footprint (and whether the function will fail with a memory allocation
error). From a theoretical point of view it is advantageous to use blocks as large as possible; on the
other hand, using smaller blocks is substantially faster and often the only way to work with large
numbers of genes. As a rough guide, when 4GB of memory are available, blocks should be no larger than 8,000
genes; with 8GB one can handle some 13,000 genes; with 16GB around 20,000; and with 32GB around 30,000.
Depending on the operating system and its setup, these numbers may vary substantially.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

 
<p>Non-hierarchical consensus networks are described in Langfelder P, Horvath S (2007), Eigengene networks for
studying the relationships between co-expression modules. BMC Systems Biology 2007, 1:54. 
</p>
<p>More in-depth discussion of selected topics can be found at http://www.peterlangfelder.com/ , and an FAQ at
https://labs.genetics.ucla.edu/horvath/CoexpressionNetwork/Rpackages/WGCNA/faq.html .
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusTOM">hierarchicalConsensusTOM</a></code> for calculation of hierarchical consensus networks (adjacency and
TOM), and a more detailed description of the calculation;
</p>
<p><code><a href="fastcluster.html#topic+hclust">hclust</a></code> and <code><a href="dynamicTreeCut.html#topic+cutreeHybrid">cutreeHybrid</a></code> for hierarchical clustering
and the Dynamic Tree Cut branch cutting method;
</p>
<p><code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for module merging;
</p>
<p><code><a href="#topic+blockwiseModules">blockwiseModules</a></code> for an analogous analysis on a single data set.
</p>

<hr>
<h2 id='hierarchicalConsensusTOM'>
Calculation of hierarchical consensus topological overlap matrix
</h2><span id='topic+hierarchicalConsensusTOM'></span>

<h3>Description</h3>

<p>This function calculates consensus topological overlap in a hierarchical manner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalConsensusTOM(
      # ... information needed to calculate individual TOMs
      multiExpr,
      multiWeights = NULL,

      # Data checking options
      checkMissingData = TRUE,

      # Blocking options
      blocks = NULL,
      maxBlockSize = 20000,
      blockSizePenaltyPower = 5,
      nPreclusteringCenters = NULL,
      randomSeed = 12345,

      # Network construction options
      networkOptions,

      # Save individual TOMs?

      keepIndividualTOMs = TRUE,
      individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",

      # ... or information about individual (more precisely, input) TOMs
      individualTOMInfo = NULL,

      # Consensus calculation options 
      consensusTree,

      useBlocks = NULL,

      # Save calibrated TOMs?
      saveCalibratedIndividualTOMs = FALSE,
      calibratedIndividualTOMFilePattern = "calibratedIndividualTOM-Set%s-Block%b.RData",

      # Return options
      saveConsensusTOM = TRUE,
      consensusTOMFilePattern = "consensusTOM-%a-Block%b.RData",
      getCalibrationSamples = FALSE,

      # Return the intermediate results as well?  
      keepIntermediateResults = saveConsensusTOM,

      # Internal handling of TOMs
      useDiskCache = NULL, 
      chunkSize = NULL,
      cacheDir = ".",
      cacheBase = ".blockConsModsCache",

      # Behavior
      collectGarbage = TRUE,
      verbose = 1,
      indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalConsensusTOM_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_checkmissingdata">checkMissingData</code></td>
<td>

<p>Logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_blocks">blocks</code></td>
<td>

<p>Optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p>Integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>Number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>Number of centers to be used in the preclustering. Defaults to smaller of
<code>nGenes/20</code> and <code>100*nGenes/maxBlockSize</code>, where <code>nGenes</code> is the nunber of genes (variables)
in <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_randomseed">randomSeed</code></td>
<td>
<p>Integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_keepindividualtoms">keepIndividualTOMs</code></td>
<td>

<p>Logical: should individual TOMs be retained after the calculation is finished?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>

<p>Character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_individualtominfo">individualTOMInfo</code></td>
<td>

<p>A list, typically returned by <code><a href="#topic+individualTOMs">individualTOMs</a></code>, containing information about the topological
overlap matrices in the individual data sets in <code>multiExpr</code>. See the output of 
<code><a href="#topic+individualTOMs">individualTOMs</a></code> for
details on the content of the list.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_useblocks">useBlocks</code></td>
<td>

<p>Optional vector giving the blocks that should be used for the calcualtions. If <code>NULL</code>, all 
all blocks will be used.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_savecalibratedindividualtoms">saveCalibratedIndividualTOMs</code></td>
<td>

<p>Logical: should the calibrated individual TOMs be saved?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_calibratedindividualtomfilepattern">calibratedIndividualTOMFilePattern</code></td>
<td>

<p>Specification of file names in which calibrated individual TOMs should be saved.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_saveconsensustom">saveConsensusTOM</code></td>
<td>

<p>Logical: should the consensus TOM be saved to disk?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_consensustomfilepattern">consensusTOMFilePattern</code></td>
<td>

<p>Character string giving the file names to save consensus TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_getcalibrationsamples">getCalibrationSamples</code></td>
<td>

<p>Logical: should the sampled values used for network calibration be returned?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_keepintermediateresults">keepIntermediateResults</code></td>
<td>

<p>Logical: should intermediate consensus TOMs be saved as well?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_usediskcache">useDiskCache</code></td>
<td>

<p>Logical: should disk cache be used for consensus calculations? The disk cache can be used to store chunks of
calibrated data that are small enough to fit one chunk from each set into memory (blocks may be small enough
to fit one block of one set into memory, but not small enough to fit one block from all sets in a consensus
calculation into memory at the same time). Using disk cache is slower but lessens the memory footprint of
the calculation.
As a general guide, if individual data are split into blocks, we
recommend setting this argument to <code>TRUE</code>. If this argument is <code>NULL</code>, the function will decide
whether to use disk cache based on the number of sets and block sizes.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_chunksize">chunkSize</code></td>
<td>
<p> network similarities are saved in smaller chunks of size <code>chunkSize</code>. If <code>NULL</code>,
an appropriate chunk size will be determined from an estimate of available memory. Note that if the chunk size
is greater than the memory required for storing intemediate results, disk cache use will automatically be
disabled. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_cachedir">cacheDir</code></td>
<td>
<p> character string containing the directory into which cache files should be written. The
user should make sure that the filesystem has enough free space to hold the cache files which can get quite
large.
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_cachebase">cacheBase</code></td>
<td>
<p> character string containing the desired name for the cache files. The actual file
names will consists of <code>cacheBase</code> and a suffix to make the file names unique. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage be collected after memory-intensive operations?
</p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="hierarchicalConsensusTOM_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is essentially a wrapper for <code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code>, with a few
additional operations specific to calculations of topological overlaps.
</p>


<h3>Value</h3>

<p>A list that contains the output of <code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> and two extra components:
</p>
<table role = "presentation">
<tr><td><code>individualTOMInfo</code></td>
<td>
<p>A copy of the input <code>individualTOMInfo</code> if it was non-<code>NULL</code>, or the
result of <code><a href="#topic+individualTOMs">individualTOMs</a></code>.
</p>
</td></tr>
<tr><td><code>consensusTree</code></td>
<td>
<p>A copy of the input <code>consensusTree</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> for the actual hierarchical consensus calculation;
</p>
<p><code><a href="#topic+individualTOMs">individualTOMs</a></code> for the calculation of individual TOMs in a format suitable for consensus
calculation.
</p>

<hr>
<h2 id='hierarchicalMergeCloseModules'>
Merge close (similar) hierarchical consensus modules
</h2><span id='topic+hierarchicalMergeCloseModules'></span>

<h3>Description</h3>

<p>Merges hierarchical consensus modules that are too close as measured by the correlation of their
eigengenes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hierarchicalMergeCloseModules(
  # input data
  multiExpr, 
  multiExpr.imputed = NULL,
  labels,

  # Optional starting eigengenes
  MEs = NULL,

  unassdColor = if (is.numeric(labels)) 0 else "grey",
  # If missing data are present, impute them?
  impute = TRUE,


  # Options for eigengene network construction
  networkOptions,

  # Options for constructing the consensus
  consensusTree,
  calibrateMESimilarities = FALSE,

  # Merging options
  cutHeight = 0.2,
  iterate = TRUE,

  # Output options
  relabel = FALSE,
  colorSeq = NULL,
  getNewMEs = TRUE,
  getNewUnassdME = TRUE,

  # Options controlling behaviour of the function
  trapErrors = FALSE,
  verbose = 1, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hierarchicalMergeCloseModules_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+multiData">multiData</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_multiexpr.imputed">multiExpr.imputed</code></td>
<td>
<p>If <code>multiExpr</code> contain missing data, this argument can be used to supply the
expression data with missing data imputed. If not given, the <code><a href="impute.html#topic+impute.knn">impute.knn</a></code> function will
be used to impute the missing data within each module (see <code><a href="#topic+imputeByModule">imputeByModule</a></code>.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_labels">labels</code></td>
<td>

<p>A vector (numeric, character or a factor) giving module labels for genes (variables) in <code>multiExpr</code>.
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_mes">MEs</code></td>
<td>

<p>If module eigengenes have been calculated before, the user can save some computational time
by inputting them. <code>MEs</code> should have the same format as <code>multiExpr</code>.
If they are not given, they will be calculated.
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_unassdcolor">unassdColor</code></td>
<td>
<p>The label (value in <code>labels</code>)
that represents unassigned genes. Module of this label will
not enter the module eigengene clustering and will not be merged with other modules.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_impute">impute</code></td>
<td>
<p>Should missing values be imputed in eigengene calculation? If imputation is disabled, the
presence of <code>NA</code> entries will cause the eigengene calculation to fail and eigengenes will be
replaced by their hubgene approximation. See <code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See <code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for details.
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_calibratemesimilarities">calibrateMESimilarities</code></td>
<td>

<p>Logical: should module eigengene similarities be calibrated? This setting overrides the calibration options
in <code>consensusTree</code>.
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_cutheight">cutHeight</code></td>
<td>

<p>Maximum dissimilarity (i.e., 1-correlation) that qualifies modules for merging. 
</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_iterate">iterate</code></td>
<td>
<p>Controls whether the merging procedure should be repeated until there is no change. If
FALSE, only one iteration will be executed.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_relabel">relabel</code></td>
<td>
<p>Controls whether, after merging, color labels should be ordered by module size.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_colorseq">colorSeq</code></td>
<td>
<p>Color labels to be used for relabeling. Defaults to the standard color order used
in this package if <code>colors</code> are not numeric, and to integers starting from 1 if
<code>colors</code> is numeric.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_getnewmes">getNewMEs</code></td>
<td>
<p>Controls whether module eigengenes of merged modules should be calculated and
returned.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_getnewunassdme">getNewUnassdME</code></td>
<td>
<p>When doing module eigengene manipulations, the function does not normally
calculate the eigengene of the 'module' of unassigned ('grey') genes. Setting this option to
<code>TRUE</code> will force the calculation of the unassigned eigengene in the returned newMEs, but not
in the returned oldMEs.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_traperrors">trapErrors</code></td>
<td>
<p>Controls whether computational errors in calculating module eigengenes, their
dissimilarity, and merging trees should be trapped. If <code>TRUE</code>, errors will be trapped and the
function will return the input colors. If <code>FALSE</code>, errors will cause the function to stop.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity of printed progress messages. 0 means silent, up to (about) 5 the
verbosity gradually increases.</p>
</td></tr>
<tr><td><code id="hierarchicalMergeCloseModules_+3A_indent">indent</code></td>
<td>
<p>A single non-negative integer controlling indentation of printed messages. 0 means no
indentation, each unit above that adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function merges input modules 
that are closely related. The similarities are quantified by correlations of module eigengenes; a
&ldquo;consensus&rdquo; similarity is calculated using <code>hierarchicalConsensusMEDissimilarity</code> 
according to the recipe in <code>consensusTree</code>. Once the
(dis-)similarities are calculated, average linkage hierarchical clustering of the module eigengenes is
performed, the dendrogram is cut at the height <code>cutHeight</code> and modules on each branch are merged.
The process is (optionally) repeated until no more modules are merged.
</p>
<p>If, for a particular module, the module eigengene calculation fails, a hubgene approximation will be
used.
</p>
<p>The user should be aware that if a computational error occurs and <code>trapErrors==TRUE</code>,
the returned list (see below) will not contain all of the components returned upon normal execution.
</p>


<h3>Value</h3>

<p>If no errors occurred, a list with components
</p>
<table role = "presentation">
<tr><td><code>labels</code></td>
<td>
<p>Labels for the genes corresponding to merged modules. The function attempts to
mimic the mode of the input <code>labels</code>: if the input <code>labels</code> is numeric, character and
factor, respectively, so is the output. Note, however, that if the function performs relabeling, a
standard sequence of labels will be used: integers starting at 1 if the input <code>labels</code> is
numeric, and a sequence of color labels otherwise (see <code>colorSeq</code> above).</p>
</td></tr>
<tr><td><code>dendro</code></td>
<td>
<p>Hierarchical clustering dendrogram (average linkage) of the eigengenes of the most
recently computed tree. If <code>iterate</code> was set TRUE, this will be the dendrogram of the merged
modules, otherwise it will be the dendrogram of the original modules.</p>
</td></tr>
<tr><td><code>oldDendro</code></td>
<td>
<p>Hierarchical clustering dendrogram (average linkage) of the eigengenes of the original
modules.</p>
</td></tr>
<tr><td><code>cutHeight</code></td>
<td>
<p>The input cutHeight.</p>
</td></tr>
<tr><td><code>oldMEs</code></td>
<td>
<p>Module eigengenes of the original modules in the sets given by <code>useSets</code>.</p>
</td></tr>
<tr><td><code>newMEs</code></td>
<td>
<p>Module eigengenes of the merged modules in the sets given by <code>useSets</code>.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>A logical set to <code>TRUE</code>.</p>
</td></tr>
</table>
<p>If an error occurred and <code>trapErrors==TRUE</code>, the list only contains these components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p>A copy of the input colors.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>a logical set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiSetMEs">multiSetMEs</a></code> for calculation of (consensus) module eigengenes across multiple data sets;
</p>
<p><code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for information about consensus trees;
</p>
<p><code><a href="#topic+hierarchicalConsensusMEDissimilarity">hierarchicalConsensusMEDissimilarity</a></code> for calculation of hierarchical consensus eigengene
dissimilarity.
</p>

<hr>
<h2 id='hubGeneSignificance'> Hubgene significance </h2><span id='topic+hubGeneSignificance'></span>

<h3>Description</h3>

<p>Calculate approximate hub gene significance for all modules in network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hubGeneSignificance(datKME, GS)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hubGeneSignificance_+3A_datkme">datKME</code></td>
<td>
<p> a data frame (or a matrix-like object) containing eigengene-based connectivities of all
genes in the network. </p>
</td></tr>
<tr><td><code id="hubGeneSignificance_+3A_gs">GS</code></td>
<td>
<p> a vector with one entry for every gene containing its gene significance. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <code>datKME</code> rows correspond to genes and columns to modules. 
</p>


<h3>Value</h3>

<p>A vector whose entries are the hub gene significances for each module.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

<p> Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology
2007, 1:24 </p>

<hr>
<h2 id='ImmunePathwayLists'>Immune Pathways with Corresponding Gene Markers</h2><span id='topic+ImmunePathwayLists'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of marker genes for many immune response pathways, as assembled by Brian Modena (a member of Daniel R Salomon's lab at Scripps Research Institute), and colleagues.  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ImmunePathwayLists)</code></pre>


<h3>Format</h3>

<p>A 3597 x 2 matrix of characters containing Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;Immune Pathway&gt;__ImmunePathway.  Note that the matrix is sorted first by Category and then by Gene, such that all genes related to the same category are listed sequentially.
</p>


<h3>Source</h3>

<p>For more information about this list, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ImmunePathwayLists)
head(ImmunePathwayLists)
</code></pre>

<hr>
<h2 id='imputeByModule'>
Impute missing data separately in each module
</h2><span id='topic+imputeByModule'></span>

<h3>Description</h3>

<p>Use <code><a href="impute.html#topic+impute.knn">impute.knn</a></code> to ipmpute missing data, separately in each module. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeByModule(
  data, 
  labels, 
  excludeUnassigned = FALSE, 
  unassignedLabel = if (is.numeric(labels)) 0 else "grey", 
  scale = TRUE, 
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="imputeByModule_+3A_data">data</code></td>
<td>

<p>Data to be imputed, with variables (genes) in columns and observations (samples) in rows.
</p>
</td></tr>
<tr><td><code id="imputeByModule_+3A_labels">labels</code></td>
<td>

<p>Module labels. A vector with one entry for each column in <code>data</code>.
</p>
</td></tr>
<tr><td><code id="imputeByModule_+3A_excludeunassigned">excludeUnassigned</code></td>
<td>

<p>Logical: should unassigned variables (genes) be excluded from the imputation?
</p>
</td></tr>
<tr><td><code id="imputeByModule_+3A_unassignedlabel">unassignedLabel</code></td>
<td>

<p>The value in <code>labels</code> that represents unassigned variables.
</p>
</td></tr>
<tr><td><code id="imputeByModule_+3A_scale">scale</code></td>
<td>

<p>Logical: should <code>data</code> be scaled to mean 0 and variance 1 before imputation? 
</p>
</td></tr>
<tr><td><code id="imputeByModule_+3A_...">...</code></td>
<td>

<p>Other arguments to <code><a href="impute.html#topic+impute.knn">impute.knn</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>data</code> with missing values imputed.
</p>


<h3>Note</h3>

<p>This function is potentially faster but could give different imputed values than applying <code>impute.knn</code>
directly to (scaled) <code>data</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="impute.html#topic+impute.knn">impute.knn</a></code> that does the actual imputation.
</p>

<hr>
<h2 id='individualTOMs'>
Calculate individual correlation network matrices
</h2><span id='topic+individualTOMs'></span>

<h3>Description</h3>

<p>This function calculates correlation network matrices (adjacencies or topological overlaps), after optionally
first pre-clustering input data into blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>individualTOMs(
   multiExpr,
   multiWeights = NULL,
   multiExpr.imputed = NULL,  

   # Data checking options
   checkMissingData = TRUE,

   # Blocking options
   blocks = NULL,
   maxBlockSize = 5000,
   blockSizePenaltyPower = 5,
   nPreclusteringCenters = NULL,
   randomSeed = 54321,

   # Network construction options
   networkOptions,

   # Save individual TOMs? 
   saveTOMs = TRUE,
   individualTOMFileNames = "individualTOM-Set%s-Block%b.RData",

   # Behaviour options
   collectGarbage = TRUE,
   verbose = 2, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="individualTOMs_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_multiexpr.imputed">multiExpr.imputed</code></td>
<td>

<p>Optional version of <code>multiExpr</code> with missing data imputed. If not given and <code>multiExpr</code> contains
missing data, they will be imputed using the function <code><a href="impute.html#topic+impute.knn">impute.knn</a></code>.
</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_checkmissingdata">checkMissingData</code></td>
<td>
<p>logical: should data be checked for excessive numbers of missing entries in
genes and samples, and for genes with zero variance? See details. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_blocks">blocks</code></td>
<td>
<p> optional specification of blocks in which hierarchical clustering and module detection
should be performed. If given, must be a numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_maxblocksize">maxBlockSize</code></td>
<td>
<p> integer giving maximum block size for module detection. Ignored if <code>blocks</code>
above is non-NULL. Otherwise, if the number of genes in <code>datExpr</code> exceeds <code>maxBlockSize</code>, genes
will be pre-clustered into blocks whose size should not exceed <code>maxBlockSize</code>. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_blocksizepenaltypower">blockSizePenaltyPower</code></td>
<td>
<p>number specifying how strongly blocks should be penalized for exceeding the
maximum size. Set to a lrge number or <code>Inf</code> if not exceeding maximum block size is very important.</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_npreclusteringcenters">nPreclusteringCenters</code></td>
<td>
<p>number of centers to be used in the preclustering. Defaults to smaller of
<code>nGenes/20</code> and <code>100*nGenes/maxBlockSize</code>, where <code>nGenes</code> is the nunber of genes (variables)
in
<code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. If <code>NULL</code> is given, the
function will not save and restore the seed. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set. 
</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_savetoms">saveTOMs</code></td>
<td>
<p>logical: should individual TOMs be saved to disk (<code>TRUE</code>) or retuned directly in the
return value (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_individualtomfilenames">individualTOMFileNames</code></td>
<td>
<p>character string giving the file names to save individual TOMs into. The
following tags should be used to make the file names unique for each set and block: <code>%s</code> will be
replaced by the set number; <code>%N</code> will be replaced by the set name (taken from <code>names(multiExpr)</code>)
if it exists, otherwise by set number; <code>%b</code> will be replaced by the block number. If the file names
turn out to be non-unique, an error will be generated.</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage collection be called after each block calculation? This can be useful when the data
are large, but could unnecessarily slow down calculation with small data.
</p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_verbose">verbose</code></td>
<td>
<p> Integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="individualTOMs_+3A_indent">indent</code></td>
<td>
<p> Indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function starts by optionally filtering out samples that have too many missing entries and genes
that have either too many missing entries or zero variance in at least one set. Genes that are filtered
out are excluded from the network calculations.
</p>
<p>If <code>blocks</code> is not given and
the number of genes (columns) in <code>multiExpr</code> 
exceeds <code>maxBlockSize</code>, genes are pre-clustered into blocks using the function
<code><a href="#topic+consensusProjectiveKMeans">consensusProjectiveKMeans</a></code>; otherwise all genes are treated in a single block. Any missing data
in <code>multiExpr</code> will be imputed; if imputed data are already available, they can be supplied separately.
</p>
<p>For each block of genes, the network adjacency is constructed and (if requested) topological overlap is calculated
in each set. The topological overlaps can be saved to disk as RData files, or returned directly within the
return value (see below). Note that the matrices can be big and returning them within the return value can
quickly exhaust the system's memory. In particular, if the block-wise calculation is necessary, it is
usually impossible to return all matrices in the return value.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>blockwiseAdjacencies</code></td>
<td>
<p>A <code><a href="#topic+multiData">multiData</a></code> structure containing (possibly blockwise) network
matrices for each input data set. The network matrices are stored as <code><a href="#topic+BlockwiseData">BlockwiseData</a></code> objects.</p>
</td></tr>
<tr><td><code>setNames</code></td>
<td>
<p>A copy of <code>names(multiExpr)</code>.</p>
</td></tr>
<tr><td><code>nSets</code></td>
<td>
<p>Number of sets in <code>multiExpr</code></p>
</td></tr>
<tr><td><code>blockInfo</code></td>
<td>
<p>A list of class <code><a href="#topic+BlockInformation">BlockInformation</a></code>, giving information about blocks and gene and
sample filtering.</p>
</td></tr>
<tr><td><code>networkOptions</code></td>
<td>
<p>The input <code>networkOptions</code>, returned as a <code><a href="#topic+multiData">multiData</a></code> structure with
one entry per input data set.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>Input arguments and output components of this function use <code><a href="#topic+multiData">multiData</a></code>,
<code><a href="#topic+NetworkOptions">NetworkOptions</a></code>, <code><a href="#topic+BlockwiseData">BlockwiseData</a></code>, and <code><a href="#topic+BlockInformation">BlockInformation</a></code>.
</p>
<p>Underlying functions of interest include <code><a href="#topic+consensusProjectiveKMeans">consensusProjectiveKMeans</a></code>,
<code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code>.
</p>

<hr>
<h2 id='Inline+20display+20of+20progress'> Inline display of progress </h2><span id='topic+initProgInd'></span><span id='topic+updateProgInd'></span>

<h3>Description</h3>

<p>These functions provide an inline display of pregress. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initProgInd(leadStr = "..", trailStr = "", quiet = !interactive())
updateProgInd(newFrac, progInd, quiet = !interactive())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Inline+2B20display+2B20of+2B20progress_+3A_leadstr">leadStr</code></td>
<td>
<p> character string that will be printed before the actual progress number. </p>
</td></tr>
<tr><td><code id="Inline+2B20display+2B20of+2B20progress_+3A_trailstr">trailStr</code></td>
<td>
<p> character string that will be printed after the actual progress number. </p>
</td></tr>
<tr><td><code id="Inline+2B20display+2B20of+2B20progress_+3A_quiet">quiet</code></td>
<td>
<p> can be used to silence the indicator for non-interactive sessions whose output is
typically redirected to a file. </p>
</td></tr>
<tr><td><code id="Inline+2B20display+2B20of+2B20progress_+3A_newfrac">newFrac</code></td>
<td>
<p> new fraction of progress to be displayed. </p>
</td></tr>
<tr><td><code id="Inline+2B20display+2B20of+2B20progress_+3A_progind">progInd</code></td>
<td>
<p> an object of class <code>progressIndicator</code> that encodes previously printed message. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A progress indicator is a simple inline display of progress intended to satisfy impatient users during
lengthy operations. The function <code>initProgInd</code> initializes a progress indicator (at zero);
<code>updateProgInd</code> updates it to a specified fraction. 
</p>
<p>Note that excessive use of <code>updateProgInd</code> may lead to a performance penalty (see examples). 
</p>


<h3>Value</h3>

<p>Both functions return an object of class <code>progressIndicator</code> that holds information on the last
printed value and should be used for subsequent updates of the indicator. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>Examples</h3>

<pre><code class='language-R'>max = 10;
prog = initProgInd("Counting: ", "done");
for (c in 1:max)
{
  Sys.sleep(0.10);
  prog = updateProgInd(c/max, prog);
}
printFlush("");

printFlush("Example 2:");
prog = initProgInd();
for (c in 1:max)
{
  Sys.sleep(0.10);
  prog = updateProgInd(c/max, prog);
}
printFlush("");

## Example of a significant slowdown:

## Without progress indicator:

system.time( {a = 0; for (i in 1:10000) a = a+i; } )

## With progress indicator, some 50 times slower:

system.time( 
  {
    prog = initProgInd("Counting: ", "done");
    a = 0; 
    for (i in 1:10000) 
    {
      a = a+i; 
      prog = updateProgInd(i/10000, prog);
    }
  }   
)
</code></pre>

<hr>
<h2 id='intramodularConnectivity'> Calculation of intramodular connectivity </h2><span id='topic+intramodularConnectivity'></span><span id='topic+intramodularConnectivity.fromExpr'></span>

<h3>Description</h3>

<p>Calculates intramodular connectivity, i.e., connectivity of nodes to other nodes within the same
module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intramodularConnectivity(adjMat, colors, scaleByMax = FALSE)

intramodularConnectivity.fromExpr(datExpr, colors, 
              corFnc = "cor", corOptions = "use = 'p'",
              weights = NULL,
              distFnc = "dist", distOptions = "method = 'euclidean'",
              networkType = "unsigned", power = if (networkType=="distance") 1 else 6,
              scaleByMax = FALSE,
              ignoreColors = if (is.numeric(colors)) 0 else "grey",
              getWholeNetworkConnectivity = TRUE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intramodularConnectivity_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix, a square, symmetric matrix with entries between 0 and 1. </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_colors">colors</code></td>
<td>
<p> module labels. A vector of length <code>ncol(adjMat)</code> giving a module label for each
gene (node) of the network.</p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_scalebymax">scaleByMax</code></td>
<td>
<p> logical: should intramodular connectivities be scaled by the maximum IM connectivity
in each module? </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame or matrix containing expression data. Columns correspond to genes and rows to
samples.</p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_corfnc">corFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity for correlation networks.
Defaults to Pearson correlation. Any function returning values between -1 and 1 can be used. </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_coroptions">corOptions</code></td>
<td>
<p> character string specifying additional arguments to be passed to the function given
by <code>corFnc</code>. Use <code>"use = 'p', method = 'spearman'"</code> to obtain Spearman correlation.   </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_weights">weights</code></td>
<td>
<p>optional matrix of the same dimensions as <code>datExpr</code>, giving the weights for individual
observations in <code>datExpr</code>. These will be passed on to the correlation function.</p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_distfnc">distFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity for distance networks. Defaults to the function <code><a href="stats.html#topic+dist">dist</a></code>.
Any function returning non-negative values can be used.</p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_distoptions">distOptions</code></td>
<td>
<p> character string specifying additional arguments to be passed to the function given
by <code>distFnc</code>. For example, when the function  <code><a href="stats.html#topic+dist">dist</a></code> is used, the argument <code>method</code>
can be used to specify various ways of computing the distance. </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_networktype">networkType</code></td>
<td>
<p>network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>, <code>"distance"</code>. </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_power">power</code></td>
<td>
<p>soft thresholding power. </p>
</td></tr>
<tr><td><code id="intramodularConnectivity_+3A_ignorecolors">ignoreColors</code></td>
<td>
<p>level(s) of <code>colors</code> that identifies unassigned genes. The intramodular
connectivity in this &quot;module&quot; will not be calculated.</p>
</td></tr> 
<tr><td><code id="intramodularConnectivity_+3A_getwholenetworkconnectivity">getWholeNetworkConnectivity</code></td>
<td>
<p>logical: should whole-network connectivity be computed as well? For
large networks, this can be quite time-consuming.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The module labels can be numeric or character. For each node (gene), the function sums adjacency
entries (excluding the diagonal) to other nodes within the same module. Optionally, the connectivities
can be scaled by the maximum connectivy in each module. 
</p>


<h3>Value</h3>

<p>If input <code>getWholeNetworkConnectivity</code> is <code>TRUE</code>, a data frame with 4 columns giving the total connectivity, intramodular connectivity, extra-modular
connectivity, and the difference of the intra- and extra-modular connectivities for all genes; otherwise a
vector of intramodular connectivities, 
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder</p>


<h3>References</h3>

<p> Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology
2007, 1:24 </p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code> </p>

<hr>
<h2 id='isMultiData'>
Determine whether the supplied object is a valid multiData structure
</h2><span id='topic+isMultiData'></span>

<h3>Description</h3>

<p>Attempts to determine whether the supplied object is a valid multiData structure (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isMultiData(x, strict = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isMultiData_+3A_x">x</code></td>
<td>

<p>An object.
</p>
</td></tr>
<tr><td><code id="isMultiData_+3A_strict">strict</code></td>
<td>
<p>Logical: should the structure of multiData be checked for &quot;strict&quot; compliance?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>This function checks whether the supplied <code>x</code> is a multiData structure in the &quot;strict&quot; (when
<code>strict = TRUE</code> or &quot;loose&quot; <code>strict = FALSE</code> sense.
</p>


<h3>Value</h3>

<p>Logical: <code>TRUE</code> if the input <code>x</code> is a multiData structure, <code>FALSE</code> otherwise.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>Other multiData handling functions whose names start with <code>mtd.</code>
</p>

<hr>
<h2 id='keepCommonProbes'> Keep probes that are shared among given data sets </h2><span id='topic+keepCommonProbes'></span>

<h3>Description</h3>

<p>This function strips out probes that are not shared by all given data sets, and orders the remaining
common probes using the same order in all sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keepCommonProbes(multiExpr, orderBy = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="keepCommonProbes_+3A_multiexpr">multiExpr</code></td>
<td>
<p>  expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="keepCommonProbes_+3A_orderby">orderBy</code></td>
<td>
<p> index of the set by which probes are to be ordered. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Expression data in the same format as the input data, containing only common probes.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

<p><code><a href="#topic+checkSets">checkSets</a></code></p>

<hr>
<h2 id='kMEcomparisonScatterplot'> Function to plot kME values between two comparable data sets.  </h2><span id='topic+kMEcomparisonScatterplot'></span>

<h3>Description</h3>

<p>Plots the kME values of genes in two groups of expression data for each module in an inputted color vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kMEcomparisonScatterplot(
   datExpr1, datExpr2, colorh, 
   inA = NULL, inB = NULL, MEsA = NULL, MEsB = NULL, 
   nameA = "A", nameB = "B", 
   plotAll = FALSE, noGrey = TRUE, maxPlot = 1000, pch = 19, 
   fileName = if (plotAll) paste("kME_correlations_between_",nameA,"_and_",
                                 nameB,"_all.pdf",sep="") else
                           paste("kME_correlations_between_",nameA,"_and_",
                                 nameB,"_inMod.pdf",sep=""), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kMEcomparisonScatterplot_+3A_datexpr1">datExpr1</code></td>
<td>

<p>The first expression matrix (samples=rows, genes=columns).  This can either include only the data for group A (in which case dataExpr2 must be entered), or can contain all of the data for groups A and B (in which case inA and inB must be entered).
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_datexpr2">datExpr2</code></td>
<td>

<p>The second expression matrix, or set to NULL if all data is from same expression matrix.  If entered, datExpr2 must contain the same genes as datExpr1 in the same order.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_colorh">colorh</code></td>
<td>

<p>The common color vector (module labels) corresponding to both sets of expression data.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_ina">inA</code>, <code id="kMEcomparisonScatterplot_+3A_inb">inB</code></td>
<td>

<p>Vectors of TRUE/FALSE indicating whether a sample is in group A/B, or a vector of numeric indices indicating which samples are in group A/B. If datExpr2 is entered, these inputs are ignored (thus default = NULL).  For these and all other A/B inputs, &quot;A&quot; corresponds to datExpr1 and &quot;B&quot; corresponds to datExpr2 if datExpr2 is entered; otherwise &quot;A&quot; corresponds to datExpr1[inA,] while &quot;B&quot; corresponds to datExpr1[inB,].
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_mesa">MEsA</code>, <code id="kMEcomparisonScatterplot_+3A_mesb">MEsB</code></td>
<td>

<p>Either the module eigengenes or NULL (default) in which case the module eigengenes will be calculated.  In inputted, MEs MUST be calculated using &quot;moduleEigengenes(&lt;parameters&gt;)$eigengenes&quot; for function to work properly.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_namea">nameA</code>, <code id="kMEcomparisonScatterplot_+3A_nameb">nameB</code></td>
<td>

<p>The names of these groups (defaults = &quot;A&quot; and &quot;B&quot;).  The resulting file name (see below) and x and y axis labels for each scatter plot depend on these names.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_plotall">plotAll</code></td>
<td>

<p>If TRUE, plot gene-ME correlations for all genes.  If FALSE, plot correlations for only genes in the plotted module (default).  Note that the output file name will be different depending on this parameter, so both can be run without overwriting results.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_nogrey">noGrey</code></td>
<td>

<p>If TRUE (default), the grey module genes are ignored.  This parameter is only used if MEsA and MEsB are calculated.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_maxplot">maxPlot</code></td>
<td>

<p>The maximum number of random genes to include (default=1000).  Smaller values lead to smaller and less cluttered plots, usually without significantly affecting the resulting correlations. This parameter is only used if plotAll=TRUE.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_pch">pch</code></td>
<td>

<p>See help file for &quot;points&quot;. Setting pch=19 (default) produces solid circles.
</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_filename">fileName</code></td>
<td>
<p> Name of the file to hold the plots. Since the output format is pdf, the extension should
be .pdf .</p>
</td></tr>
<tr><td><code id="kMEcomparisonScatterplot_+3A_...">...</code></td>
<td>

<p>Other plotting parameters that are allowable inputs to verboseScatterplot.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The default output is a file called &quot;kME_correlations_between_[nameA]_and_[nameB]_[all/inMod].pdf&quot;, where
[nameA] and [nameB] correspond to the nameA and nameB input parameters, and [all/inMod] depends on whether
plotAll=TRUE or FALSE. This output file contains all of the plots as separate pdf images, and will be
located in the current working directory.  
</p>


<h3>Note</h3>

<p>The function &quot;pdf&quot;, which can be found in the grDevices library, is required to run this function.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example output file ("kME_correlations_between_A_and_B_inMod.pdf") using simulated data.
## Not run: 
set.seed = 100
ME=matrix(0,50,5)
for (i in 1:5) ME[,i]=sample(1:100,50)
simData1 = simulateDatExpr5Modules(MEturquoise=ME[,1],MEblue=ME[,2],
                          MEbrown=ME[,3],MEyellow=ME[,4], MEgreen=ME[,5])
simData2 = simulateDatExpr5Modules(MEturquoise=ME[,1],MEblue=ME[,2],
                          MEbrown=ME[,3],MEyellow=ME[,4], MEgreen=ME[,5])
kMEcomparisonScatterplot(simData1$datExpr,simData2$datExpr,simData1$truemodule)

## End(Not run)

</code></pre>

<hr>
<h2 id='labeledBarplot'> Barplot with text or color labels. </h2><span id='topic+labeledBarplot'></span>

<h3>Description</h3>

<p>Produce a barplot with extra annotation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labeledBarplot(
      Matrix, labels, 
      colorLabels = FALSE, 
      colored = TRUE, 
      setStdMargins = TRUE, 
      stdErrors = NULL, 
      cex.lab = NULL, 
      xLabelsAngle = 45,
      ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labeledBarplot_+3A_matrix">Matrix</code></td>
<td>
<p> vector or a matrix to be plotted. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_labels">labels</code></td>
<td>
<p> labels to annotate the bars underneath the barplot. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_colorlabels">colorLabels</code></td>
<td>
<p> logical: should the labels be interpreted as colors? If <code>TRUE</code>, the bars will
be labeled by colored squares instead of text. See details.  </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_colored">colored</code></td>
<td>
<p> logical: should the bars be divided into segments and colored? If <code>TRUE</code>, assumes
the <code>labels</code> can be interpreted as colors, and the input
<code>Matrix</code> is square and the rows have the same labels as the columns. See details. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_setstdmargins">setStdMargins</code></td>
<td>
<p> if <code>TRUE</code>, the function wil set margins <code>c(3, 3, 2, 2)+0.2</code>. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_stderrors">stdErrors</code></td>
<td>
<p> if given, error bars corresponding to <code>1.96*stdErrors</code> will be plotted on top of
the bars. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_cex.lab">cex.lab</code></td>
<td>
<p> character expansion factor for axis labels, including the text labels underneath the
barplot. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_xlabelsangle">xLabelsAngle</code></td>
<td>
<p>angle at which text labels under the barplot will be printed. </p>
</td></tr>
<tr><td><code id="labeledBarplot_+3A_...">...</code></td>
<td>
<p> other parameters for the function <code><a href="graphics.html#topic+barplot">barplot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Individual bars in the barplot can be identified either by printing the text of the corresponding entry
in <code>labels</code> underneath the bar at the angle specified by <code>xLabelsAngle</code>, 
or by interpreting the <code>labels</code> entry as a
color (see below) and drawing a correspondingly colored square underneath the bar. 
</p>
<p>For reasons of compatibility with other functions, <code>labels</code> are interpreted as colors after
stripping the first two characters from each label. For example, the label <code>"MEturquoise"</code> is
interpreted as the color turquoise. 
</p>
<p>If <code>colored</code> is set, the code assumes that <code>labels</code> can be interpreted as colors, and the input
<code>Matrix</code> is square and the rows have the same labels as the columns. Each bar in the barplot is then
sectioned into contributions from each row entry in <code>Matrix</code> and is colored by the color given by the
entry in <code>labels</code> that corresponds to the row. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>

<hr>
<h2 id='labeledHeatmap'> Produce a labeled heatmap plot </h2><span id='topic+labeledHeatmap'></span>

<h3>Description</h3>

<p>Plots a heatmap plot with color legend, row and column annotation, and optional text within th heatmap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labeledHeatmap(
  Matrix, 
  xLabels, yLabels = NULL, 
  xSymbols = NULL, ySymbols = NULL, 
  colorLabels = NULL, 
  xColorLabels = FALSE, yColorLabels = FALSE, 
  checkColorsValid = TRUE,
  invertColors = FALSE, 
  setStdMargins = TRUE, 
  xLabelsPosition = "bottom",
  xLabelsAngle = 45,
  xLabelsAdj = 1,
  yLabelsPosition = "left",
  xColorWidth = 2 * strheight("M"),
  yColorWidth = 2 * strwidth("M"), 
  xColorOffset = strheight("M")/3, 
  yColorOffset = strwidth("M")/3,
  colorMatrix = NULL,
  colors = NULL, 
  naColor = "grey",
  textMatrix = NULL, 
  cex.text = NULL, 
  textAdj = c(0.5, 0.5),
  cex.lab = NULL, 
  cex.lab.x = cex.lab,
  cex.lab.y = cex.lab,
  colors.lab.x = 1,
  colors.lab.y = 1,
  font.lab.x = 1,
  font.lab.y = 1,

  bg.lab.x = NULL,
  bg.lab.y = NULL,
  x.adj.lab.y = 1,

  plotLegend = TRUE, 
  keepLegendSpace = plotLegend,
  legendLabel = "",
  cex.legendLabel = 1,

  # Separator line specification                   
  verticalSeparator.x = NULL,
  verticalSeparator.col = 1,
  verticalSeparator.lty = 1,
  verticalSeparator.lwd = 1,
  verticalSeparator.ext = 0,
  verticalSeparator.interval = 0,

  horizontalSeparator.y = NULL,
  horizontalSeparator.col = 1,
  horizontalSeparator.lty = 1,
  horizontalSeparator.lwd = 1,
  horizontalSeparator.ext = 0,
  horizontalSeparator.interval = 0,
  # optional restrictions on which rows and columns to actually show
  showRows = NULL,
  showCols = NULL,
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labeledHeatmap_+3A_matrix">Matrix</code></td>
<td>
<p> numerical matrix to be plotted in the heatmap. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xlabels">xLabels</code></td>
<td>
<p> labels for the columns. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ylabels">yLabels</code></td>
<td>
<p> labels for the rows. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xsymbols">xSymbols</code></td>
<td>
<p> additional labels used when <code>xLabels</code> are interpreted as colors. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ysymbols">ySymbols</code></td>
<td>
<p> additional labels used when <code>yLabels</code> are interpreted as colors. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_colorlabels">colorLabels</code></td>
<td>
<p> logical: should <code>xLabels</code> and <code>yLabels</code> be interpreted as colors? If
given, overrides <code>xColorLabels</code> and <code>yColorLabels</code> below.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xcolorlabels">xColorLabels</code></td>
<td>
<p> logical: should <code>xLabels</code> be interpreted as colors? </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ycolorlabels">yColorLabels</code></td>
<td>
<p> logical: should <code>yLabels</code> be interpreted as colors? </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_checkcolorsvalid">checkColorsValid</code></td>
<td>
<p> logical: should given colors be checked for validity 
against the output of <code>colors()</code> ? If this argument is <code>FALSE</code>, invalid color specification
will trigger an error.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_invertcolors">invertColors</code></td>
<td>
<p> logical: should the color order be inverted? </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_setstdmargins">setStdMargins</code></td>
<td>
<p> logical: should standard margins be set before calling the plot function?
Standard margins depend on <code>colorLabels</code>: they are wider for text labels and narrower for color
labels. The defaults are static, that is the function does not attempt to guess the optimal margins. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xlabelsposition">xLabelsPosition</code></td>
<td>
<p> a character string specifying the position of labels for the columns.
Recognized values are (unique abbreviations of) <code>"top", "bottom"</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xlabelsangle">xLabelsAngle</code></td>
<td>
<p> angle by which the column labels should be rotated. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xlabelsadj">xLabelsAdj</code></td>
<td>
<p> justification parameter for column labels. See <code><a href="graphics.html#topic+par">par</a></code> and the
description of parameter <code>"adj"</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ylabelsposition">yLabelsPosition</code></td>
<td>
<p> a character string specifying the position of labels for the columns.
Recognized values are (unique abbreviations of) <code>"left", "right"</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xcolorwidth">xColorWidth</code></td>
<td>
<p> width of the color labels for the x axis expressed in user corrdinates.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ycolorwidth">yColorWidth</code></td>
<td>
<p> width of the color labels for the y axis expressed in user coordinates.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_xcoloroffset">xColorOffset</code></td>
<td>
<p> gap between the y axis and color labels, in user coordinates.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_ycoloroffset">yColorOffset</code></td>
<td>
<p> gap between the x axis and color labels, in user coordinates.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_colormatrix">colorMatrix</code></td>
<td>
<p> optional explicit specification for the color of the heatmap cells. If given, overrides values
specified in <code>colors</code> and <code>naColor</code>.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_colors">colors</code></td>
<td>
<p> color pallette to be used in the heatmap. Defaults to <code><a href="grDevices.html#topic+heat.colors">heat.colors</a></code>. Only used if
<code>colorMatrix</code> is not given. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_nacolor">naColor</code></td>
<td>
<p> color to be used for encoding missing data. Only used if <code>colorMatrix</code> is not used.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_textmatrix">textMatrix</code></td>
<td>
<p> optional text entries for each cell. Either a matrix of the same dimensions as
<code>Matrix</code> or a vector of the same length as the number of entries in <code>Matrix</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_cex.text">cex.text</code></td>
<td>
<p> character expansion factor for <code>textMatrix</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_textadj">textAdj</code></td>
<td>
<p>Adjustment for the entries in the text matrix. See the <code>adj</code> argument to
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_cex.lab">cex.lab</code></td>
<td>
<p> character expansion factor for text labels labeling the axes. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_cex.lab.x">cex.lab.x</code></td>
<td>
<p> character expansion factor for text labels labeling the x axis. Overrides <code>cex.lab</code>
above. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_cex.lab.y">cex.lab.y</code></td>
<td>
<p> character expansion factor for text labels labeling the y axis. Overrides <code>cex.lab</code>  
above. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_colors.lab.x">colors.lab.x</code></td>
<td>
<p>colors for character labels or symbols along x axis.</p>
</td></tr> 
<tr><td><code id="labeledHeatmap_+3A_colors.lab.y">colors.lab.y</code></td>
<td>
<p>colors for character labels or symbols along y axis.</p>
</td></tr> 
<tr><td><code id="labeledHeatmap_+3A_font.lab.x">font.lab.x</code></td>
<td>
<p>integer specifying font for labels or symbols along x axis. See <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_font.lab.y">font.lab.y</code></td>
<td>
<p>integer specifying font for labels or symbols along y axis. See <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_bg.lab.x">bg.lab.x</code></td>
<td>
<p>background color for the margin along the x axis.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_bg.lab.y">bg.lab.y</code></td>
<td>
<p>background color for the margin along the y axs.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_x.adj.lab.y">x.adj.lab.y</code></td>
<td>
<p>Justification of labels for the y axis along the x direction. A value of 0
produces left-justified text, 0.5 (the default) centered
text and 1 right-justified text. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_plotlegend">plotLegend</code></td>
<td>
<p> logical: should a color legend be plotted? </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_keeplegendspace">keepLegendSpace</code></td>
<td>
<p> logical: if the color legend is not drawn, should the space be left empty
(<code>TRUE</code>), or should the heatmap fill the space (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_legendlabel">legendLabel</code></td>
<td>
<p>character string to be shown next to the label analogous to an axis label.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_cex.legendlabel">cex.legendLabel</code></td>
<td>
<p>character expansion factor for the legend label.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.x">verticalSeparator.x</code></td>
<td>
<p>indices of columns in input <code>Matrix</code> after 
which separator lines (vertical lines between columns) 
should be drawn. <code>NULL</code> means no lines will be drawn.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.col">verticalSeparator.col</code></td>
<td>
<p>color(s) of the vertical separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.lty">verticalSeparator.lty</code></td>
<td>
<p>line type of the vertical separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.lwd">verticalSeparator.lwd</code></td>
<td>
<p>line width of the vertical separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.ext">verticalSeparator.ext</code></td>
<td>
<p>number giving the extension of the separator line into the margin as a fraction
of the margin width. 0 means no extension, 1 means extend all the way through the margin. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_verticalseparator.interval">verticalSeparator.interval</code></td>
<td>
<p>number giving the interval for vertical separators. If larger than zero, vertical
separators will be drawn after every <code>verticalSeparator.interval</code> of displayed columns. 
Used only when length of <code>verticalSeparator.x</code> is zero. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.y">horizontalSeparator.y</code></td>
<td>
<p>indices of columns in input <code>Matrix</code> after which separator lines (horizontal lines
between columns) should be drawn. <code>NULL</code> means no lines will be drawn.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.col">horizontalSeparator.col</code></td>
<td>
<p> color(s) of the horizontal separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.lty">horizontalSeparator.lty</code></td>
<td>
<p>line type of the horizontal separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.lwd">horizontalSeparator.lwd</code></td>
<td>
<p>line width of the horizontal separator lines. Recycled if need be. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.ext">horizontalSeparator.ext</code></td>
<td>
<p>number giving the extension of the separator line into the margin as a
fraction of the margin width. 0 means no extension, 1 means extend all the way through the margin. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_horizontalseparator.interval">horizontalSeparator.interval</code></td>
<td>
<p>number giving the interval for horizontal separators. If larger than zero, horizontal
separators will be drawn after every <code>horizontalSeparator.interval</code> of displayed rows. 
Used only when length of <code>horizontalSeparator.y</code> is zero. </p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_showrows">showRows</code></td>
<td>
<p>A numeric vector giving the indices of rows that are actually to be shown. Defaults to all rows.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_showcols">showCols</code></td>
<td>
<p>A numeric vector giving the indices of columns that are actually to be shown. Defaults to all columns.</p>
</td></tr>
<tr><td><code id="labeledHeatmap_+3A_...">...</code></td>
<td>
<p> other arguments to function <code><a href="stats.html#topic+heatmap">heatmap</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function basically plots a standard heatmap plot of the given <code>Matrix</code> and embellishes it with
row and column labels and/or with text within the heatmap entries. Row and column labels can be either
character strings or color squares, or both. 
</p>
<p>To get simple text labels, use <code>colorLabels=FALSE</code> and pass the desired row and column labels in
<code>yLabels</code> and <code>xLabels</code>, respectively. 
</p>
<p>To label rows and columns by color squares, use
<code>colorLabels=TRUE</code>; <code>yLabels</code> and <code>xLabels</code> are then expected to represent valid colors.
For reasons of compatibility with other functions, each entry in <code>yLabels</code> and <code>xLabels</code> is
expected to consist of a color designation preceded by 2 characters: an example would be
<code>MEturquoise</code>. The first two characters can be arbitrary, they are stripped. 
Any labels that do not represent valid colors will be considered text labels and printed in full,
allowing the user to mix text and color labels.
</p>
<p>It is also possible to label rows and columns by both color squares and additional text annotation. To
achieve this, use the above technique to get color labels and, additionally, pass the desired text
annotation in the <code>xSymbols</code> and <code>ySymbols</code> arguments. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+heatmap">heatmap</a></code>, <code><a href="grDevices.html#topic+colors">colors</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# This example illustrates 4 main ways of annotating columns and rows of a heatmap.
# Copy and paste the whole example into an R session with an interactive plot window;
# alternatively, you may replace the command sizeGrWindow below by opening 
# another graphical device such as pdf.

# Generate a matrix to be plotted

nCol = 8; nRow = 7;
mat = matrix(runif(nCol*nRow, min = -1, max = 1), nRow, nCol);

rowColors = standardColors(nRow);
colColors = standardColors(nRow + nCol)[(nRow+1):(nRow + nCol)];

rowColors;
colColors;

sizeGrWindow(9,7)
par(mfrow = c(2,2))
par(mar = c(4, 5, 4, 6));

# Label rows and columns by text:

labeledHeatmap(mat, xLabels = colColors, yLabels = rowColors, 
               colors = greenWhiteRed(50),
               setStdMargins = FALSE, 
               textMatrix = signif(mat, 2),
               main = "Text-labeled heatmap");

# Label rows and columns by colors:

rowLabels = paste("ME", rowColors, sep="");
colLabels = paste("ME", colColors, sep="");

labeledHeatmap(mat, xLabels = colLabels, yLabels = rowLabels,
               colorLabels = TRUE,
               colors = greenWhiteRed(50),
               setStdMargins = FALSE,
               textMatrix = signif(mat, 2),
               main = "Color-labeled heatmap");

# Mix text and color labels:

rowLabels[3] = "Row 3";
colLabels[1] = "Column 1";

labeledHeatmap(mat, xLabels = colLabels, yLabels = rowLabels,
               colorLabels = TRUE,
               colors = greenWhiteRed(50),
               setStdMargins = FALSE,
               textMatrix = signif(mat, 2), 
               main = "Mix-labeled heatmap");

# Color labels and additional text labels

rowLabels = paste("ME", rowColors, sep="");
colLabels = paste("ME", colColors, sep="");

extraRowLabels = paste("Row", c(1:nRow));
extraColLabels = paste("Column", c(1:nCol));

# Extend margins to fit all labels
par(mar = c(6, 6, 4, 6));
labeledHeatmap(mat, xLabels = colLabels, yLabels = rowLabels,
               xSymbols = extraColLabels,
               ySymbols = extraRowLabels,
               colorLabels = TRUE,
               colors = greenWhiteRed(50),
               setStdMargins = FALSE,
               textMatrix = signif(mat, 2),
               main = "Text- + color-labeled heatmap");

</code></pre>

<hr>
<h2 id='labeledHeatmap.multiPage'>
Labeled heatmap divided into several separate plots.
</h2><span id='topic+labeledHeatmap.multiPage'></span>

<h3>Description</h3>

<p>This function produces labaled heatmaps divided into several plots. This is useful for large heatmaps where
labels on individual columns and rows may become unreadably small (or overlap).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labeledHeatmap.multiPage(
   # Input data and ornaments
   Matrix, 
   xLabels, yLabels = NULL,
   xSymbols = NULL, ySymbols = NULL,
   textMatrix = NULL, 

   # Paging options
   rowsPerPage = NULL, maxRowsPerPage = 20, 
   colsPerPage = NULL, maxColsPerPage = 10, 
   addPageNumberToMain = TRUE, 

   # Further arguments to labeledHeatmap
   zlim = NULL,
   signed = TRUE, 
   main = "", 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labeledHeatmap.multiPage_+3A_matrix">Matrix</code></td>
<td>
<p> numerical matrix to be plotted in the heatmap. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_xlabels">xLabels</code></td>
<td>
<p> labels for the columns. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_ylabels">yLabels</code></td>
<td>
<p> labels for the rows. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_xsymbols">xSymbols</code></td>
<td>
<p> additional labels used when <code>xLabels</code> are interpreted as colors. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_ysymbols">ySymbols</code></td>
<td>
<p> additional labels used when <code>yLabels</code> are interpreted as colors. See Details. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_textmatrix">textMatrix</code></td>
<td>
<p> optional text entries for each cell. Either a matrix of the same dimensions as 
<code>Matrix</code> or a vector of the same length as the number of entries in <code>Matrix</code>. </p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_rowsperpage">rowsPerPage</code></td>
<td>
<p> optional list in which each component is a vector specifying which rows should appear
together in each plot. If not given, will be generated automatically based on <code>maxRowsPerPage</code> below
and the number of rows in <code>Matrix</code>.
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_maxrowsperpage">maxRowsPerPage</code></td>
<td>
<p> integer giving maximum number of rows appearing on each plot (page).  
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_colsperpage">colsPerPage</code></td>
<td>
<p> optional list in which each component is a vector specifying which columns should appear 
together in each plot. If not given, will be generated automatically based on <code>maxColsPerPage</code> below
and the number of rows in <code>Matrix</code>.
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_maxcolsperpage">maxColsPerPage</code></td>
<td>

<p>integer giving maximum number of columns appearing on each plot (page).
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_addpagenumbertomain">addPageNumberToMain</code></td>
<td>

<p>logical: should plot/page number be added to the <code>main</code> title of each plot?
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_zlim">zlim</code></td>
<td>

<p>Optional specification of the extreme values for the color scale. If not given, will be determined from the
input <code>Matrix</code>.
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_signed">signed</code></td>
<td>

<p>logical: should the input <code>Matrix</code> be converted to colors using a scale centered at zero?
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_main">main</code></td>
<td>

<p>Main title for each plot/page, optionally with the plot/page number added.
</p>
</td></tr>
<tr><td><code id="labeledHeatmap.multiPage_+3A_...">...</code></td>
<td>

<p>other arguments to function <code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code> is used to produce each plot/page; most arguments are described
in more detail in the help file for that function.
</p>
<p>In each plot/page <code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code> plots a standard heatmap plot of an appropriate 
sub-rectangle of <code>Matrix</code> and embellishes it with
row and column labels and/or with text within the heatmap entries. Row and column labels can be either
character strings or color squares, or both.
</p>
<p>To get simple text labels, use <code>colorLabels=FALSE</code> and pass the desired row and column labels in
<code>yLabels</code> and <code>xLabels</code>, respectively.
</p>
<p>To label rows and columns by color squares, use
<code>colorLabels=TRUE</code>; <code>yLabels</code> and <code>xLabels</code> are then expected to represent valid colors.
For reasons of compatibility with other functions, each entry in <code>yLabels</code> and <code>xLabels</code> is
expected to consist of a color designation preceded by 2 characters: an example would be
<code>MEturquoise</code>. The first two characters can be arbitrary, they are stripped.
Any labels that do not represent valid colors will be considered text labels and printed in full,
allowing the user to mix text and color labels.
</p>
<p>It is also possible to label rows and columns by both color squares and additional text annotation. To
achieve this, use the above technique to get color labels and, additionally, pass the desired text
annotation in the <code>xSymbols</code> and <code>ySymbols</code> arguments.
</p>
<p>If <code>rowsPerPage</code> (<code>colsPerPage</code>) is not given, rows (columns) are allocated automatically as
uniformly as possible, in contiguous blocks of size at most <code>maxRowsPerPage</code> (<code>maxColsPerPage</code>). 
The allocation is performed by the function <code><a href="#topic+allocateJobs">allocateJobs</a></code>.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The workhorse function <code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code> for the actual heatmap plot;
</p>
<p>function <code><a href="#topic+allocateJobs">allocateJobs</a></code> for the allocation of rows/columns to each plot.
</p>

<hr>
<h2 id='labelPoints'>
Label scatterplot points 
</h2><span id='topic+labelPoints'></span>

<h3>Description</h3>

<p>Given scatterplot point coordinates, the function tries to place labels near the points such that the
labels overlap as little as possible. User beware: the algorithm implemented here is quite primitive and
while it will help in many cases, it is by no means perfect. Consider this function experimental. We hope to
improve the algorithm in the future to make it useful in a broader range of situations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labelPoints(
   x, y, labels, 
   cex = 0.7, offs = 0.01, xpd = TRUE, 
   jiggle = 0, protectEdges = TRUE, 
   doPlot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labelPoints_+3A_x">x</code></td>
<td>

<p>a vector of x coordinates of the points
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_y">y</code></td>
<td>

<p>a vector of y coordinates of the points
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_labels">labels</code></td>
<td>

<p>labels to be placed next to the points
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_cex">cex</code></td>
<td>

<p>character expansion factor for the labels
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_offs">offs</code></td>
<td>

<p>offset of the labels from the plotted coordinates in inches
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_xpd">xpd</code></td>
<td>

<p>logical: controls truncating labels to fit within the plotting region. See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_jiggle">jiggle</code></td>
<td>

<p>amount of random noise to be added to the coordinates. This may be useful if the scatterplot is too
regular (such as all points on one straight line). 
</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_protectedges">protectEdges</code></td>
<td>
<p> logical: should labels be shifted inside the (actual or virtual) frame of the plot? </p>
</td></tr>
<tr><td><code id="labelPoints_+3A_doplot">doPlot</code></td>
<td>
<p>logical: should the labels be actually added to the plot? Value <code>FALSE</code> may be useful if
the user would like to simply compute the best label positions the function can come up with.</p>
</td></tr>
<tr><td><code id="labelPoints_+3A_...">...</code></td>
<td>

<p>other arguments to function <code><a href="graphics.html#topic+text">text</a></code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm basically works by finding the direction of most surrounding points, and attempting to place
the label in the opposite direction. There are (not uncommon) situations in which this placement is
suboptimal; the author promises to further develop the function sometime in the future.
</p>
<p>Note that this function does not plot the actual scatterplot; only the labels are plotted. Plotting the
scatterplot is the responsibility of the user. 
</p>
<p>The argument <code>offs</code> needs to be carefully tuned to the size of the plotted symbols. Sorry, no automation
here yet.
</p>
<p>The argument <code>protectEdges</code> can be used to shift labels that would otherwise extend beyond the plot to
within the plot. Sometimes this may cause some overlapping with other points or labels; use with care.
</p>


<h3>Value</h3>

<p>Invisibly, a data frame with 3 columns, giving the x and y positions of the labels, and the labels themselves.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+plot.default">plot.default</a></code>, <code><a href="graphics.html#topic+text">text</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate some random points
   set.seed(11);
   n = 20;
   x = runif(n);
   y = runif(n);

# Create a basic scatterplot
   col = standardColors(n);
   plot(x,y, pch = 21, col =1, bg = col, cex = 2.6, 
        xlim = c(-0.1, 1.1), ylim = c(-0.1, 1.0));
   labelPoints(x, y, paste("Pt", c(1:n), sep=""), offs = 0.10, cex = 1);

# label points using longer text labels. Note the positioning is not perfect, but close enough.

   plot(x,y, pch = 21, col =1, bg = col, cex = 2.6, 
        xlim = c(-0.1, 1.1), ylim = c(-0.1, 1.0));
   labelPoints(x, y, col, offs = 0.10, cex = 0.8);
</code></pre>

<hr>
<h2 id='labels2colors'>Convert numerical labels to colors. </h2><span id='topic+labels2colors'></span>

<h3>Description</h3>

<p>Converts a vector or array of numerical labels into a corresponding vector or array of colors corresponding to the labels. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>labels2colors(labels, zeroIsGrey = TRUE, colorSeq = NULL, naColor = "grey",
              commonColorCode = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="labels2colors_+3A_labels">labels</code></td>
<td>
<p>Vector or matrix of non-negative integer or other (such as character) labels. See details.</p>
</td></tr>
<tr><td><code id="labels2colors_+3A_zeroisgrey">zeroIsGrey</code></td>
<td>
<p>If TRUE, labels 0 will be assigned color grey. Otherwise, labels below 1 will trigger
an error.</p>
</td></tr>
<tr><td><code id="labels2colors_+3A_colorseq">colorSeq</code></td>
<td>
<p>Color sequence corresponding to labels. If not given, a standard sequence will be
used.</p>
</td></tr>
<tr><td><code id="labels2colors_+3A_nacolor">naColor</code></td>
<td>
<p>Color that will encode missing values. </p>
</td></tr>
<tr><td><code id="labels2colors_+3A_commoncolorcode">commonColorCode</code></td>
<td>
<p>logical: if <code>labels</code> is a matrix, should each column have its own colors? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>labels</code> is numeric, it is used directly as index to the standard color sequence. If 0 is present
among the labels and <code>zeroIsGrey=TRUE</code>, labels 0 are given grey color.
</p>
<p>If <code>labels</code> is not numeric, its columns are turned into factors and the numeric representation of each
factor is used to assign the corresponding colors. In this case <code>commonColorCode</code> governs whether each
column gets its own color code, or whether the color code will be universal.
</p>
<p>The standard sequence start with well-distinguishable colors, and after about 40 turns into a
quasi-random sampling of all colors available in R with the exception of all shades of grey (and gray).
</p>
<p>If the input <code>labels</code> have a dimension attribute, it is copied into the output, meaning the
dimensions of the returned value are the same as those of the input <code>labels</code>.
</p>


<h3>Value</h3>

<p>A vector or array of character strings of the same length or dimensions as <code>labels</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>labels = c(0:20);
labels2colors(labels);
labels = matrix(letters[1:9], 3,3);
labels2colors(labels)
# Note the difference when commonColorCode = FALSE
labels2colors(labels, commonColorCode = FALSE)
</code></pre>

<hr>
<h2 id='list2multiData'>
Convert a list to a multiData structure and vice-versa.
</h2><span id='topic+list2multiData'></span><span id='topic+multiData2list'></span>

<h3>Description</h3>

<p><code>list2multiData</code> converts a list to a multiData structure; <code>multiData2list</code> does the inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list2multiData(data)
multiData2list(multiData)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list2multiData_+3A_data">data</code></td>
<td>

<p>A list to be converted to a multiData structure.
</p>
</td></tr>
<tr><td><code id="list2multiData_+3A_multidata">multiData</code></td>
<td>
<p> A multiData structure to be converted to a list. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is a vector of lists (one list for each set) where each list has a
component <code>data</code> containing some useful information. 
</p>


<h3>Value</h3>

<p>For <code>list2multiData</code>, a multiData structure; for <code>multiData2list</code>, the corresponding list.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='lowerTri2matrix'>
Reconstruct a symmetric matrix from a distance (lower-triangular) representation
</h2><span id='topic+lowerTri2matrix'></span>

<h3>Description</h3>

<p>Assuming the input vector contains a vectorized form of the distance representation of a symmetric matrix,
this function creates the corresponding matrix. This is useful when re-forming symmetric matrices that have
been vectorized to save storage space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lowerTri2matrix(x, diag = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lowerTri2matrix_+3A_x">x</code></td>
<td>

<p>a numeric vector 
</p>
</td></tr>
<tr><td><code id="lowerTri2matrix_+3A_diag">diag</code></td>
<td>

<p>value to be put on the diagonal. Recycled if necessary.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function assumes that <code>x</code> contains the vectorized form of the distance representation of a
symmetric matrix. In particular, <code>x</code> must have a length that can be expressed as n*(n-1)/2, with n an
integer. The result of the function is then an n times n matrix. 
</p>


<h3>Value</h3>

<p>A symmetric matrix whose lower triangle is given by <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Create a symmetric matrix
  m = matrix(c(1:16), 4,4)
  mat = (m + t(m));
  diag(mat) = 0;

  # Print the matrix
  mat

  # Take the lower triangle and vectorize it (in two ways)
  x1 = mat[lower.tri(mat)]
  x2 = as.vector(as.dist(mat))

  all.equal(x1, x2) # The vectors are equal

  # Turn the vectors back into matrices
  new.mat = lowerTri2matrix(x1, diag = 0);

  # Did we get back the same matrix?

  all.equal(mat, new.mat)

</code></pre>

<hr>
<h2 id='matchLabels'> Relabel module labels to best match the given reference labels </h2><span id='topic+matchLabels'></span>

<h3>Description</h3>

<p>Given a <code>source</code> and  <code>reference</code> vectors of module labels, the function produces a module
labeling that is equivalent to <code>source</code>, but individual modules are re-labeled so that modules with
significant overlap in <code>source</code> and <code>reference</code> have the same labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchLabels(source, 
            reference, 
            pThreshold = 5e-2,
            na.rm = TRUE,
            ignoreLabels = if (is.numeric(reference)) 0 else "grey",
            extraLabels = if (is.numeric(reference)) c(1:1000) else standardColors()
            )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matchLabels_+3A_source">source</code></td>
<td>
<p> a vector or a matrix of reference labels. The labels may be numeric or character. </p>
</td></tr>
<tr><td><code id="matchLabels_+3A_reference">reference</code></td>
<td>
<p> a vector of reference labels. </p>
</td></tr>
<tr><td><code id="matchLabels_+3A_pthreshold">pThreshold</code></td>
<td>
<p> threshold of Fisher's exact test for considering modules to have a significant
overlap. </p>
</td></tr>
<tr><td><code id="matchLabels_+3A_na.rm">na.rm</code></td>
<td>
<p>logical: should missing values in either <code>source</code> or <code>reference</code> be removed? If
not, missing values may be treated as a standard label or the function may throw an error 
(exact behaviour depends on whether the input labels
are numeric or not).</p>
</td></tr>
<tr><td><code id="matchLabels_+3A_ignorelabels">ignoreLabels</code></td>
<td>
<p>labels in <code>source</code> and <code>reference</code> to be considered unmatchable. These
labels are excluded from the re-labeling procedure.</p>
</td></tr>
<tr><td><code id="matchLabels_+3A_extralabels">extraLabels</code></td>
<td>
<p>a vector of labels for modules in <code>source</code> that cannot be matched to any modules
in <code>reference</code>. The user should ensure that this vector contains enough labels since the function
automatically removes a values that occur in either <code>source</code>, <code>reference</code> or <code>ignoreLabels</code>,
to avoid possible confusion. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each column of <code>source</code> is treated separately. Unlike in previous version of this function, source
and reference labels can be any labels, not necessarily of the same type.
</p>
<p>The function calculates the overlap of the <code>source</code> and <code>reference</code> modules using Fisher's
exact test. It then attempts to relabel <code>source</code> modules such that each <code>source</code> module gets the
label of the <code>reference</code> module that it overlaps most with, subject to not renaming two <code>source</code>
modules to the same <code>reference</code> module. (If two <code>source</code> modules point to the same
<code>reference</code> module, the one with the more significant overlap is chosen.)
</p>
<p>Those <code>source</code> modules that cannot be matched to a <code>reference</code> module are labeled using
those labels from <code>extraLabels</code> that do not occur in either of <code>source</code>, <code>reference</code> or
<code>ignoreLabels</code>.
</p>


<h3>Value</h3>

<p>A vector (if the input <code>source</code> labels are a vector) or a matrix (if the input <code>source</code>
labels are a matrix) of the new labels.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+overlapTable">overlapTable</a></code> for calculation of overlap counts and p-values;
</p>
<p><code><a href="#topic+standardColors">standardColors</a></code> for standard non-numeric WGCNA labels.
</p>

<hr>
<h2 id='matrixToNetwork'>
Construct a network from a matrix
</h2><span id='topic+matrixToNetwork'></span>

<h3>Description</h3>

<p>Constructs a network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrixToNetwork(
    mat, 
    symmetrizeMethod = c("average", "min", "max"), 
    signed = TRUE, 
    min = NULL, max = NULL, 
    power = 12,
    diagEntry = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrixToNetwork_+3A_mat">mat</code></td>
<td>
<p>matrix to be turned into a network. Must be square.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_symmetrizemethod">symmetrizeMethod</code></td>
<td>

<p>method for symmetrizing the matrix. The method will be applied to each component of mat and its transpose.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_signed">signed</code></td>
<td>

<p>logical: should the resulting network be signed? Unsigned networks are constructed from <code>abs(mat)</code>.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_min">min</code></td>
<td>

<p>minimum allowed value for <code>mat</code>. If <code>NULL</code>, the actual attained minimum of <code>mat</code> will be used.
Missing data are ignored. Values below <code>min</code> are truncated to <code>min</code>.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_max">max</code></td>
<td>

<p>maximum allowed value for <code>mat</code>. If <code>NULL</code>, the actual attained maximum of <code>mat</code> will be used.
Missing data are ignored. Values below <code>max</code> are truncated to <code>max</code>.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_power">power</code></td>
<td>

<p>the soft-thresholding power.
</p>
</td></tr>
<tr><td><code id="matrixToNetwork_+3A_diagentry">diagEntry</code></td>
<td>

<p>the value of the entries on the diagonal in the result. This is usally 1 but some applications may require
a zero (or even NA) diagonal.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>signed</code> is <code>FALSE</code>, the matrix <code>mat</code> is first converted to its absolute value.
</p>
<p>This function then symmetrizes the matrix using the <code>symmetrizeMethod</code> component-wise on <code>mat</code>
and <code>t(mat)</code> (i.e., the transpose of <code>mat</code>). 
</p>
<p>In the next step, the symmetrized matrix is linearly scaled to the interval [0,1] using either <code>min</code>
and <code>max</code> (each either supplied or determined from the matrix). Values outside of the [min, max] range
are truncated to <code>min</code> or <code>max</code>. 
</p>
<p>Lastly, the adjacency is calculated by rasing the matrix to <code>power</code>. 
The diagonal of the result is set to
<code>diagEntry</code>. Note that most WGCNA functions expect the diagonal of an adjacency matrix to be 1. 
</p>


<h3>Value</h3>

<p>The adjacency matrix that encodes the network.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code>adjacency</code> for calculation of a correlation network (adjacency) from a numeric matrix such as
expression data 
</p>
<p><code>adjacency.fromSimilarity</code> for simpler calculation of a network from a symmetric similarity matrix.
</p>

<hr>
<h2 id='mergeCloseModules'>Merge close modules in gene expression data</h2><span id='topic+mergeCloseModules'></span>

<h3>Description</h3>

<p>Merges modules in gene expression networks that are too close as measured by the correlation of their
eigengenes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeCloseModules(
 # input data
  exprData, colors,

  # Optional starting eigengenes
  MEs = NULL,

  # Optional restriction to a subset of all sets
  useSets = NULL,

  # If missing data are present, impute them?
  impute = TRUE,

  # Input handling options
  checkDataFormat = TRUE,
  unassdColor = if (is.numeric(colors)) 0 else "grey",

  # Options for eigengene network construction
  corFnc = cor, corOptions = list(use = 'p'),
  useAbs = FALSE,

  # Options for constructing the consensus
  equalizeQuantiles = FALSE,
  quantileSummary = "mean",
  consensusQuantile = 0,

  # Merging options
  cutHeight = 0.2,
  iterate = TRUE,

  # Output options
  relabel = FALSE,
  colorSeq = NULL,
  getNewMEs = TRUE,
  getNewUnassdME = TRUE,

  # Options controlling behaviour of the function
  trapErrors = FALSE,
  verbose = 1, indent = 0)


</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mergeCloseModules_+3A_exprdata">exprData</code></td>
<td>
<p>Expression data, either a single data frame with rows corresponding to samples and
columns to genes, or in a multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). See
<code>checkDataStructure</code> below.  </p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_colors">colors</code></td>
<td>
<p>A vector (numeric, character or a factor) giving module colors for genes. 
The method only makes sense when genes have the
same color label in all sets, hence a single vector. </p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_mes">MEs</code></td>
<td>
<p>If module eigengenes have been calculated before, the user can save some computational time
by inputting them. <code>MEs</code> should have the same format as <code>exprData</code>. 
If they are not given, they will be calculated.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_usesets">useSets</code></td>
<td>
<p>A vector of scalar allowing the user to specify which sets will be used to calculate the
consensus dissimilarity of module eigengenes. Defaults to all given sets. </p>
</td></tr> 
<tr><td><code id="mergeCloseModules_+3A_impute">impute</code></td>
<td>
<p>Should missing values be imputed in eigengene calculation? If imputation is disabled, the
presence of <code>NA</code> entries will cause the eigengene calculation to fail and eigengenes will be
replaced by their hubgene approximation. See <code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_checkdataformat">checkDataFormat</code></td>
<td>
<p>If TRUE, the function will check <code>exprData</code> and <code>MEs</code> for correct
multi-set structure. If single set data is given, it will be converted into a format usable for the
function. If FALSE, incorrect structure of input data will trigger an error.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_unassdcolor">unassdColor</code></td>
<td>
<p>Specifies the string that labels unassigned genes. Module of this color will
not enter the module eigengene clustering and will not be merged with other modules.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_corfnc">corFnc</code></td>
<td>
<p>Correlation function to be used to calculate correlation of module eigengenes. </p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_coroptions">corOptions</code></td>
<td>
<p>Can be used to specify options to the correlation function, in addition to argument
<code>x</code> which is used to pass the actual data to calculate the correlation of.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_useabs">useAbs</code></td>
<td>
<p>Specifies whether absolute value of correlation or plain correlation (of module
eigengenes) should be used in calculating module dissimilarity.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_equalizequantiles">equalizeQuantiles</code></td>
<td>
<p>Logical: should quantiles of the eigengene dissimilarity matrix be equalized
(&quot;quantile normalized&quot;)? The default is <code>FALSE</code> for reproducibility of old code; when there are many
eigengenes (e.g., at least 50), better results may be achieved if quantile equalization is used.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_quantilesummary">quantileSummary</code></td>
<td>
<p>One of <code>"mean"</code> or <code>"median"</code>. Controls how a reference dissimilarity
is computed from the input ones (using mean or median, respectively).</p>
</td></tr> 
<tr><td><code id="mergeCloseModules_+3A_consensusquantile">consensusQuantile</code></td>
<td>
<p>A number giving the desired quantile to use in the consensus similarity
calculation (see details).</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_cutheight">cutHeight</code></td>
<td>
<p>Maximum dissimilarity (i.e., 1-correlation) that qualifies modules for merging.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_iterate">iterate</code></td>
<td>
<p>Controls whether the merging procedure should be repeated until there is no change. If
FALSE, only one iteration will be executed.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_relabel">relabel</code></td>
<td>
<p>Controls whether, after merging, color labels should be ordered by module size.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_colorseq">colorSeq</code></td>
<td>
<p>Color labels to be used for relabeling. Defaults to the standard color order used
in this package if <code>colors</code> are not numeric, and to integers starting from 1 if
<code>colors</code> is numeric.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_getnewmes">getNewMEs</code></td>
<td>
<p>Controls whether module eigengenes of merged modules should be calculated and
returned.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_getnewunassdme">getNewUnassdME</code></td>
<td>
<p>When doing module eigengene manipulations, the function does not normally
calculate the eigengene of the 'module' of unassigned ('grey') genes. Setting this option to
<code>TRUE</code> will force the calculation of the unassigned eigengene in the returned newMEs, but not
in the returned oldMEs.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_traperrors">trapErrors</code></td>
<td>
<p>Controls whether computational errors in calculating module eigengenes, their
dissimilarity, and merging trees should be trapped. If <code>TRUE</code>, errors will be trapped and the
function will return the input colors. If <code>FALSE</code>, errors will cause the function to stop.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity of printed progress messages. 0 means silent, up to (about) 5 the
verbosity gradually increases.</p>
</td></tr>
<tr><td><code id="mergeCloseModules_+3A_indent">indent</code></td>
<td>
<p>A single non-negative integer controlling indentation of printed messages. 0 means no
indentation, each unit above that adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function merges input modules                                 
that are closely related. The similarities are measured by correlations of module eigengenes; a
&ldquo;consensus&rdquo; measure is defined as the &ldquo;consensus quantile&rdquo; 
over the corresponding relationship in each set. Once the
(dis-)similarity is calculated, average linkage hierarchical clustering of the module eigengenes is
performed, the dendrogram is cut at the height <code>cutHeight</code> and modules on each branch are merged.
The process is (optionally) repeated until no more modules are merged.
</p>
<p>If, for a particular module, the module eigengene calculation fails, a hubgene approximation will be
used. 
</p>
<p>The user should be aware that if a computational error occurs and <code>trapErrors==TRUE</code>, 
the returned list (see below) will not contain all of the components returned upon normal execution.
</p>


<h3>Value</h3>

<p>If no errors occurred, a list with components
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p>Color labels for the genes corresponding to merged modules. The function attempts to
mimic the mode of the input <code>colors</code>: if the input <code>colors</code> is numeric, character and
factor, respectively, so is the output. Note, however, that if the fnction performs relabeling, a
standard sequence of labels will be used: integers starting at 1 if the input <code>colors</code> is
numeric, and a sequence of color labels otherwise (see <code>colorSeq</code> above).</p>
</td></tr>
<tr><td><code>dendro</code></td>
<td>
<p>Hierarchical clustering dendrogram (average linkage) of the eigengenes of the most
recently computed tree. If <code>iterate</code> was set TRUE, this will be the dendrogram of the merged
modules, otherwise it will be the dendrogram of the original modules.</p>
</td></tr>
<tr><td><code>oldDendro</code></td>
<td>
<p>Hierarchical clustering dendrogram (average linkage) of the eigengenes of the original
modules.</p>
</td></tr>
<tr><td><code>cutHeight</code></td>
<td>
<p>The input cutHeight.</p>
</td></tr>
<tr><td><code>oldMEs</code></td>
<td>
<p>Module eigengenes of the original modules in the sets given by <code>useSets</code>.</p>
</td></tr>
<tr><td><code>newMEs</code></td>
<td>
<p>Module eigengenes of the merged modules in the sets given by <code>useSets</code>.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>A boolean set to <code>TRUE</code>.</p>
</td></tr>
</table>
<p>If an error occurred and <code>trapErrors==TRUE</code>, the list only contains these components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p>A copy of the input colors.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>a boolean set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>

<hr>
<h2 id='metaAnalysis'>
Meta-analysis of binary and continuous variables
</h2><span id='topic+metaAnalysis'></span>

<h3>Description</h3>

<p>This is a meta-analysis complement to functions <code><a href="#topic+standardScreeningBinaryTrait">standardScreeningBinaryTrait</a></code> and
<code><a href="#topic+standardScreeningNumericTrait">standardScreeningNumericTrait</a></code>. Given expression (or other) data from multiple independent
data sets, and the corresponding clinical traits or outcomes, the function calculates multiple screening
statistics in each data set, then calculates meta-analysis Z scores, p-values, and optionally q-values
(False Discovery Rates). Three different ways of calculating the meta-analysis Z scores are provided: the
Stouffer method, weighted Stouffer method, and using user-specified weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metaAnalysis(multiExpr, multiTrait, 
             binary = NULL, 
             metaAnalysisWeights = NULL, 
             corFnc = cor, corOptions = list(use = "p"), 
             getQvalues = FALSE, 
             getAreaUnderROC = FALSE,
             useRankPvalue = TRUE,
             rankPvalueOptions = list(),
             setNames = NULL, 
             kruskalTest = FALSE, var.equal = FALSE, 
             metaKruskal = kruskalTest, na.action = "na.exclude")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metaAnalysis_+3A_multiexpr">multiExpr</code></td>
<td>

<p>Expression data (or other data) in multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of lists; in
each list there must be a component named <code>data</code> whose content
is a matrix or dataframe or array of dimension 2.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_multitrait">multiTrait</code></td>
<td>

<p>Trait or ourcome data in multi-set format. Only one trait is allowed; consequesntly, the <code>data</code>
component of each component list can be either a vector or a data frame (matrix, array of dimension 2).
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_binary">binary</code></td>
<td>

<p>Logical: is the trait binary (<code>TRUE</code>) or continuous (<code>FALSE</code>)? If not given, the decision will
be made based on the content of <code>multiTrait</code>.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_metaanalysisweights">metaAnalysisWeights</code></td>
<td>

<p>Optional specification of set weights for meta-analysis. If given, must be a vector of non-negative
weights, one entry for each set contained in <code>multiExpr</code>.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_corfnc">corFnc</code></td>
<td>

<p>Correlation function to be used for screening. Should be either the default <code><a href="#topic+cor">cor</a></code> or its
robust alternative, <code><a href="#topic+bicor">bicor</a></code>.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_coroptions">corOptions</code></td>
<td>

<p>A named list giving extra arguments to be passed to the correlation function.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_getqvalues">getQvalues</code></td>
<td>

<p>Logical: should q-values (FDRs) be calculated?
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_getareaunderroc">getAreaUnderROC</code></td>
<td>

<p>Logical: should area under the ROC be calculated? 
Caution, enabling the calculation will slow the function down considerably for large data sets.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_userankpvalue">useRankPvalue</code></td>
<td>
<p> Logical: should the <code><a href="#topic+rankPvalue">rankPvalue</a></code> function be used to obtain alternative
meta-analysis statistics?</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_rankpvalueoptions">rankPvalueOptions</code></td>
<td>
<p> Additional options for function <code><a href="#topic+rankPvalue">rankPvalue</a></code>. These include
<code>na.last</code> (default <code>"keep"</code>), <code>ties.method</code> (default <code>"average"</code>), 
<code>calculateQvalue</code> (default copied from input <code>getQvalues</code>), 
and <code>pValueMethod</code> (default <code>"all"</code>). 
See the help file for <code><a href="#topic+rankPvalue">rankPvalue</a></code> for full details.</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_setnames">setNames</code></td>
<td>

<p>Optional specification of set names (labels). These are used to label the corresponding components of the
output. If not given, will be taken from the <code>names</code> attribute of <code>multiExpr</code>. If
<code>names(multiExpr)</code> is <code>NULL</code>, generic names of the form <code>Set_1, Set2, ...</code> will be used.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_kruskaltest">kruskalTest</code></td>
<td>

<p>Logical: should the Kruskal test be performed in addition to t-test? Only applies to binary traits.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_var.equal">var.equal</code></td>
<td>

<p>Logical: should the t-test assume equal variance in both groups? If <code>TRUE</code>, the function will warn
the user that the returned test statistics will be different from the results of the standard
<code><a href="stats.html#topic+t.test">t.test</a></code> function.
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_metakruskal">metaKruskal</code></td>
<td>

<p>Logical: should the meta-analysis be based on the results of Kruskal test (<code>TRUE</code>) or Student t-test
(<code>FALSE</code>)?
</p>
</td></tr>
<tr><td><code id="metaAnalysis_+3A_na.action">na.action</code></td>
<td>

<p>Specification of what should happen to missing values in <code><a href="stats.html#topic+t.test">t.test</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Stouffer method of combines Z statistics by simply taking a mean of input Z statistics and multiplying
it by <code>sqrt(n)</code>, where <code>n</code> is the number of input data sets. We refer to this method as
<code>Stouffer.equalWeights</code>. In general, a better (i.e., more powerful) method of combining Z statistics is
to weigh them by the number of degrees of freedom (which approximately equals <code>n</code>). We refer to this
method as <code>weightedStouffer</code>. Finally, the user can also specify custom weights, for example if a data
set needs to be downweighted due to technical concerns; however, specifying own weights by hand should be
done carefully to avoid possible selection biases.
</p>


<h3>Value</h3>

<p>Data frame with the following components:
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p> Identifier of the input genes (or other variables) </p>
</td></tr>
<tr><td><code>Z.equalWeights</code></td>
<td>
<p> Meta-analysis Z statistics obtained using Stouffer's method with equal
weights</p>
</td></tr>
<tr><td><code>p.equalWeights</code></td>
<td>
<p> p-values corresponding to <code>Z.Stouffer.equalWeights</code> </p>
</td></tr>
<tr><td><code>q.equalWeights</code></td>
<td>
<p> q-values corresponding to <code>p.Stouffer.equalWeights</code>, only present if
<code>getQvalues</code> is <code>TRUE</code>.</p>
</td></tr> 
<tr><td><code>Z.RootDoFWeights</code></td>
<td>
<p> Meta-analysis Z statistics obtained using Stouffer's method with weights given by
the square root of the number of (non-missing) samples in each data set</p>
</td></tr>
<tr><td><code>p.RootDoFWeights</code></td>
<td>
<p> p-values corresponding to <code>Z.DoFWeights</code> </p>
</td></tr>
<tr><td><code>q.RootDoFWeights</code></td>
<td>
<p> q-values corresponding to <code>p.DoFWeights</code>, only present if
<code>getQvalues</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code>Z.DoFWeights</code></td>
<td>
<p> Meta-analysis Z statistics obtained using Stouffer's method with weights given by
the number of (non-missing) samples in each data set</p>
</td></tr>
<tr><td><code>p.DoFWeights</code></td>
<td>
<p> p-values corresponding to <code>Z.DoFWeights</code> </p>
</td></tr>
<tr><td><code>q.DoFWeights</code></td>
<td>
<p> q-values corresponding to <code>p.DoFWeights</code>, only present if
<code>getQvalues</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code>Z.userWeights</code></td>
<td>
<p> Meta-analysis Z statistics
obtained using Stouffer's method with user-defined weights. Only present if input <code>metaAnalysisWeights</code>
are present.</p>
</td></tr>
<tr><td><code>p.userWeights</code></td>
<td>
<p> p-values corresponding to <code>Z.userWeights</code> </p>
</td></tr>
<tr><td><code>q.userWeights</code></td>
<td>
<p> q-values corresponding to <code>p.userWeights</code>, only present if
<code>getQvalues</code> is <code>TRUE</code>. </p>
</td></tr>
</table>
<p>The next set of columns is present only if input <code>useRankPvalue</code> is <code>TRUE</code> and contain the output
of the function <code><a href="#topic+rankPvalue">rankPvalue</a></code> with the same column weights as the above meta-analysis. Depending
on the input options <code>calculateQvalue</code> and <code>pValueMethod</code> in <code>rankPvalueOptions</code>, some
columns may be missing. The following columns are calculated using equal weights for each data set.
</p>
<table role = "presentation">
<tr><td><code>pValueExtremeRank.equalWeights</code></td>
<td>
<p>This is the minimum between pValueLowRank and
pValueHighRank, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowRank.equalWeights</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the rank method.</p>
</td></tr>
<tr><td><code>pValueHighRank.equalWeights</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the rank method.</p>
</td></tr>
<tr><td><code>pValueExtremeScale.equalWeights</code></td>
<td>
<p>This is the minimum between pValueLowScale and
pValueHighScale, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowScale.equalWeights</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the Scale method.</p>
</td></tr>
<tr><td><code>pValueHighScale.equalWeights</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the Scale method.</p>
</td></tr>
<tr><td><code>qValueExtremeRank.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueExtremeRank</p>
</td></tr>
<tr><td><code>qValueLowRank.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueLowRank</p>
</td></tr>
<tr><td><code>qValueHighRank.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueHighRank</p>
</td></tr>
<tr><td><code>qValueExtremeScale.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueExtremeScale</p>
</td></tr>
<tr><td><code>qValueLowScale.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueLowScale</p>
</td></tr>
<tr><td><code>qValueHighScale.equalWeights</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueHighScale</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>Analogous columns calculated by weighting each input set using the square root of the number of
samples, number of samples, and user weights (if given). The corresponding column names carry the suffixes
<code>RootDofWeights</code>, <code>DoFWeights</code>, <code>userWeights</code>.</p>
</td></tr>
</table>
<p>The following columns contain results returned by <code><a href="#topic+standardScreeningBinaryTrait">standardScreeningBinaryTrait</a></code> or
<code><a href="#topic+standardScreeningNumericTrait">standardScreeningNumericTrait</a></code> (depending on whether the input trait is binary or continuous).
</p>
<p>For binary traits, the following information is returned for each set:
</p>
<table role = "presentation">
<tr><td><code>corPearson.Set_1</code>, <code>corPearson.Set_2</code>, <code>...</code></td>
<td>
<p>Pearson correlation with a binary numeric version of the
input variable. The numeric variable equals 1 for level 1 and 2 for level 2. The levels are given by
levels(factor(y)).</p>
</td></tr>  
<tr><td><code>t.Student.Set_1</code>, <code>t.Student.Set_2</code>, <code>...</code></td>
<td>
<p>Student t-test statistic</p>
</td></tr>
<tr><td><code>pvalueStudent.Set_1</code>, <code>pvalueStudent.Set_2</code>, <code>...</code></td>
<td>
<p>two-sided Student t-test p-value.</p>
</td></tr>
<tr><td><code>qvalueStudent.Set_1</code>, <code>qvalueStudent.Set_2</code>, <code>...</code></td>
<td>
<p>(if input <code>qValues==TRUE</code>)
q-value (local false discovery rate) based on the Student T-test p-value (Storey et al 2004).</p>
</td></tr>
<tr><td><code>foldChange.Set_1</code>, <code>foldChange.Set_2</code>, <code>...</code></td>
<td>
<p>a (signed) ratio of mean values. If the mean in the first
group (corresponding to level 1) is larger than that of the second group, it equals
meanFirstGroup/meanSecondGroup. 
But if the mean of the second group is larger than that of the first group it equals
-meanSecondGroup/meanFirstGroup (notice the minus sign).</p>
</td></tr>
<tr><td><code>meanFirstGroup.Set_1</code>, <code>meanSecondGroup.Set_2</code>, <code>...</code></td>
<td>
<p>means of columns in input <code>datExpr</code> across
samples in the second group.</p>
</td></tr>
<tr><td><code>SE.FirstGroup.Set_1</code>, <code>SE.FirstGroup.Set_2</code>, <code>...</code></td>
<td>
<p>standard errors of columns in input <code>datExpr</code>
across samples in the 
first group.  Recall that SE(x)=sqrt(var(x)/n) where n is the number of non-missing values of x. </p>
</td></tr> 
<tr><td><code>SE.SecondGroup.Set_1</code>, <code>SE.SecondGroup.Set_2</code>, <code>...</code></td>
<td>
<p>standard errors of columns in input <code>datExpr</code>
across samples in the second group.</p>
</td></tr> 
<tr><td><code>areaUnderROC.Set_1</code>, <code>areaUnderROC.Set_2</code>, <code>...</code></td>
<td>
<p>the area under the ROC, also known as the concordance
index or C.index.  This is a measure of discriminatory power. The measure lies between 0 and 1 where 0.5
indicates no discriminatory power. 0 indicates that the &quot;opposite&quot; predictor has perfect discriminatory
power. To compute it we use the function <a href="Hmisc.html#topic+rcorr.cens">rcorr.cens</a> with <code>outx=TRUE</code> (from Frank Harrel's
package Hmisc).</p>
</td></tr>  
<tr><td><code>nPresentSamples.Set_1</code>, <code>nPresentSamples.Set_2</code>, <code>...</code></td>
<td>
<p>number of samples with finite measurements for
each gene.</p>
</td></tr>  
</table>
<p>If input <code>kruskalTest</code> is <code>TRUE</code>, the following columns further summarize results of 
Kruskal-Wallis test:
</p>
<table role = "presentation">
<tr><td><code>stat.Kruskal.Set_1</code>, <code>stat.Kruskal.Set_2</code>, <code>...</code></td>
<td>
<p>Kruskal-Wallis test statistic.</p>
</td></tr>
<tr><td><code>stat.Kruskal.signed.Set_1</code>, <code>stat.Kruskal.signed.Set_2</code>, <code>...</code></td>
<td>
<p>(Warning: experimental) Kruskal-Wallis
test statistic including a sign that indicates whether the average rank is higher in second group (positive)
or first group (negative). 
</p>
</td></tr> 
<tr><td><code>pvaluekruskal.Set_1</code>, <code>pvaluekruskal.Set_2</code>, <code>...</code></td>
<td>
<p>Kruskal-Wallis test p-value.</p>
</td></tr>
<tr><td><code>qkruskal.Set_1</code>, <code>qkruskal.Set_2</code>, <code>...</code></td>
<td>
<p>q-values corresponding to the Kruskal-Wallis test p-value (if
input <code>qValues==TRUE</code>).</p>
</td></tr> 
<tr><td><code>Z.Set1</code>, <code>Z.Set2</code>, <code>...</code></td>
<td>
<p>Z statistics obtained from <code>pvalueStudent.Set1, pvalueStudent.Set2, ...</code>
or from <code>pvaluekruskal.Set1, pvaluekruskal.Set2, ...</code>, depending on input <code>metaKruskal</code>.</p>
</td></tr>
</table>
<p>For numeric traits, the following columns are returned:
</p>
<table role = "presentation">
<tr><td><code>cor.Set_1</code>, <code>cor.Set_2</code>, <code>...</code></td>
<td>
<p>correlations of all genes with the trait</p>
</td></tr>
<tr><td><code>Z.Set1</code>, <code>Z.Set2</code>, <code>...</code></td>
<td>
<p>Fisher Z statistics corresponding to the correlations</p>
</td></tr>
<tr><td><code>pvalueStudent.Set_1</code>, <code>pvalueStudent.Set_2</code>, <code>...</code></td>
<td>
<p>Student p-values of the correlations</p>
</td></tr>
<tr><td><code>qvalueStudent.Set_1</code>, <code>qvalueStudent.Set_1</code>, <code>...</code></td>
<td>
<p>(if input <code>qValues==TRUE</code>) q-values of the
correlations calculated from the p-values</p>
</td></tr>
<tr><td><code>AreaUnderROC.Set_1</code>, <code>AreaUnderROC.Set_2</code>, <code>...</code></td>
<td>
<p>area under the ROC</p>
</td></tr>
<tr><td><code>nPresentSamples.Set_1</code>, <code>nPresentSamples.Set_2</code>, <code>...</code></td>
<td>
<p>number of samples present for the calculation of each association. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>For Stouffer's method, see
</p>
<p>Stouffer, S.A., Suchman, E.A., DeVinney, L.C., Star, S.A. &amp; Williams, R.M. Jr. 1949. The American
Soldier, Vol. 1: Adjustment during Army Life. Princeton University Press, Princeton. 
</p>
<p>A discussion of weighted Stouffer's method can be found in 
</p>
<p>Whitlock, M. C., Combining probability from independent tests: the weighted Z-method is superior to Fisher's
approach, Journal of Evolutionary Biology 18:5 1368 (2005)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standardScreeningBinaryTrait">standardScreeningBinaryTrait</a></code>, <code><a href="#topic+standardScreeningNumericTrait">standardScreeningNumericTrait</a></code> for screening
functions for individual data sets
</p>

<hr>
<h2 id='metaZfunction'>
Meta-analysis Z statistic
</h2><span id='topic+metaZfunction'></span>

<h3>Description</h3>

<p>The function calculates a meta analysis Z statistic based on an input data frame of Z statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metaZfunction(datZ, columnweights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metaZfunction_+3A_datz">datZ</code></td>
<td>

<p>Matrix or data frame of Z statistics (assuming standard normal distribution under the null hypothesis). Rows
correspond to genes, columns to independent data sets.  </p>
</td></tr>
<tr><td><code id="metaZfunction_+3A_columnweights">columnweights</code></td>
<td>

<p>optional vector of non-negative numbers for weighing the columns of datZ.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, if datZ has 3 columns whose columns are labelled Z1,Z2,Z3  then ZMeta= (Z1+Z2+Z3)/sqrt(3).
Under the null hypothesis (where all Z statistics follow a standard normal distribution and the Z statistics
are independent), ZMeta also follows a standard normal distribution.  To calculate a 2 sided p-value, one an
use the following code
pvalue=2*pnorm(-abs(ZMeta) ) 
</p>


<h3>Value</h3>

<p>Vector of meta analysis Z statistic. Under the null hypothesis this should follow a standard normal
distribution. 
</p>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>

<hr>
<h2 id='minWhichMin'>
Fast joint calculation of row- or column-wise minima and indices of minimum elements
</h2><span id='topic+minWhichMin'></span>

<h3>Description</h3>

<p>Fast joint calculation of row- or column-wise minima and indices of minimum elements. Missing data are
removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minWhichMin(x, byRow = FALSE, dims = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minWhichMin_+3A_x">x</code></td>
<td>

<p>A numeric matrix or array.
</p>
</td></tr>
<tr><td><code id="minWhichMin_+3A_byrow">byRow</code></td>
<td>

<p>Logical: should the minima and indices be found for columns (<code>FALSE</code>) or rows (<code>TRUE</code>)?
</p>
</td></tr>
<tr><td><code id="minWhichMin_+3A_dims">dims</code></td>
<td>

<p>Specifies dimensions for which to find the minima and indices. For <code>byRow = FALSE</code>, they are calculated for
dimensions <code>dims+1</code> to <code>n=length(dim(x))</code>; for For <code>byRow = TRUE</code>, they are calculated for dimensions
1,...,<code>dims</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components, <code>min</code> and <code>which</code>; each is a vector or array with dimensions 
</p>
<p><code>dim(x)[(dims+1):n]</code> (with <code>n=length(dim(x))</code>) if <code>byRow = FALSE</code>, and
</p>
<p><code>dim(x)[1:dims]</code> if <code>byRow = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='modifiedBisquareWeights'>
Modified Bisquare Weights 
</h2><span id='topic+modifiedBisquareWeights'></span>

<h3>Description</h3>

<p>Calculation of bisquare weights and the intermediate weight factors
similar to those used in the calculation of biweight midcovariance and midcorrelation. The
weights are designed such that outliers get smaller weights; the weights become zero for data points more than
9 median absolute deviations from the median.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modifiedBisquareWeights(
  x,
  removedCovariates = NULL,
  pearsonFallback = TRUE,
  maxPOutliers = 0.05,
  outlierReferenceWeight = 0.1,
  groupsForMinWeightRestriction = NULL,
  minWeightInGroups = 0,
  maxPropUnderMinWeight = 1,
  defaultWeight = 1,
  getFactors = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modifiedBisquareWeights_+3A_x">x</code></td>
<td>

<p>A matrix of numeric observations with variables (features) in columns and observations (samples) in rows. 
Weights will be calculated separately for each column.
</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_removedcovariates">removedCovariates</code></td>
<td>

<p>Optional matrix or data frame of variables that are to be regressed out of each column
of <code>x</code> before calculating the weights. If given, must have the same number of rows as <code>x</code>. </p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_pearsonfallback">pearsonFallback</code></td>
<td>

<p>Logical: for columns of <code>x</code> that have zero median absolute deviation (MAD), should the appropriately scaled standard
deviation be used instead?</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_maxpoutliers">maxPOutliers</code></td>
<td>

<p>Optional numeric scalar between 0 and 1. Specifies the maximum proportion of outliers in each column, 
i.e., data with weights equal to
<code>outlierReferenceWeight</code> below.  </p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_outlierreferenceweight">outlierReferenceWeight</code></td>
<td>
<p>A number between 0 and 1 specifying what is to be considered an outlier when
calculating the proportion of outliers.</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_groupsforminweightrestriction">groupsForMinWeightRestriction</code></td>
<td>

<p>An optional vector with length equal to the number of samples (rows) in <code>x</code> giving a categorical variable. The
output factors and weights are adjusted such that in samples at each level of the variable, the weight is below
<code>minWeightInGroups</code> in a fraction of samples that is at most <code>maxPropUnderMinWeight</code>.</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_minweightingroups">minWeightInGroups</code></td>
<td>

<p>A threshold weight, see <code>groupsForMinWeightRestriction</code> and details.
</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_maxpropunderminweight">maxPropUnderMinWeight</code></td>
<td>

<p>A proportion (number between 0 and 1). See  <code>groupsForMinWeightRestriction</code> and details.
</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_defaultweight">defaultWeight</code></td>
<td>
<p>Value used for weights that would be undefined or not finite, for example, when a 
column in <code>x</code> is constant.</p>
</td></tr>
<tr><td><code id="modifiedBisquareWeights_+3A_getfactors">getFactors</code></td>
<td>

<p>Logical: should the intermediate weight factors be returned as well?  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Weights are calculated independently for each column of <code>x</code>. Denoting a column of <code>x</code> as <code>y</code>, the weights
are calculated as <code class="reqn">(1-u^2)^2</code> where <code>u</code> is defined as 
<code class="reqn">\min(1, |y-m|/(9MMAD))</code>. Here <code>m</code> is the median
of the column <code>y</code> and <code>MMAD</code> is the modified median absolute deviation. We call the expression 
<code class="reqn">|y-m|/(9 MMAD)</code> 
the weight factors. Note that outliers are observations with high (&gt;1) weight factors for outliers but low (zero) weights.
</p>
<p>The calculation of <code>MMAD</code> starts
with calculating the (unscaled) median absolute deviation of the column <code>x</code>. If the median absolute deviation is
zero and <code>pearsonFallback</code> is TRUE, it is replaced by the standard deviation 
(multiplied by <code>qnorm(0.75)</code> to make it asymptotically consistent with
MAD). The following two conditions are then
checked: (1) The proportion of weights below <code>outlierReferenceWeight</code> is at most <code>maxPOutliers</code> 
and (2) if <code>groupsForMinWeightRestriction</code> has non-zero length, then for each individual level in
<code>groupsForMinWeightRestriction</code>, the proportion of samples with weights less than <code>minWeightInGroups</code> is at
most <code>maxPropUnderMinWeight</code>. (If <code>groupsForMinWeightRestriction</code> is zero-length, the second condition is
considered trivially satisfied.) If both conditions are met, <code>MMAD</code> equals the median absolute deviation, MAD. If
either condition is not met, MMAD equals the lowest number for which both conditions are met.   
</p>


<h3>Value</h3>

<p>When the input <code>getFactors</code> is <code>TRUE</code>, a list with two components:
</p>
<table role = "presentation">
<tr><td><code>weights</code></td>
<td>
<p>A matrix of the same dimensions and <code>dimnames</code> as the input <code>x</code> giving the weights of the
individual observations in <code>x</code>.</p>
</td></tr>
<tr><td><code>factors</code></td>
<td>
<p>A matrix of the same form as <code>weights</code> giving the weight factors.</p>
</td></tr>
</table>
<p>When the input <code>getFactors</code> is <code>FALSE</code>, the function returns the matrix of weights.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>A full description of the weight calculation can be found, e.g., in Methods section of 
</p>
<p>Wang N, Langfelder P, et al (2022) 
Mapping brain gene coexpression in daytime transcriptomes unveils diurnal 
molecular networks and deciphers perturbation gene signatures. Neuron. 2022 Oct 19;110(20):3318-3338.e9. 
PMID: 36265442; PMCID: PMC9665885.
<a href="https://doi.org/10.1016/j.neuron.2022.09.028">doi:10.1016/j.neuron.2022.09.028</a>
</p>
<p>Other references include, in reverse chronological order, 
</p>
<p>Peter Langfelder, Steve Horvath (2012)
Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software, 46(11), 1-17.
<a href="https://www.jstatsoft.org/v46/i11/">https://www.jstatsoft.org/v46/i11/</a>
</p>
<p>&quot;Introduction to Robust Estimation and Hypothesis Testing&quot;, Rand Wilcox, Academic Press, 1997.
</p>
<p>&quot;Data Analysis and Regression: A Second Course in Statistics&quot;, Mosteller and Tukey, Addison-Wesley,
1977, pp. 203-209.
</p>


<h3>See Also</h3>

<p><code>bicovWeights</code> for a simpler, less flexible calculation. 
</p>

<hr>
<h2 id='moduleColor.getMEprefix'>Get the prefix used to label module eigengenes.</h2><span id='topic+moduleColor.getMEprefix'></span>

<h3>Description</h3>

<p>Returns the currently used prefix used to label module eigengenes. 
When returning module eigengenes in a dataframe,
names of the corresponding columns will start with the given prefix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moduleColor.getMEprefix()
</code></pre>


<h3>Details</h3>

<p>Returns the prefix used to label module eigengenes. When returning module eigengenes in a dataframe,
names of the corresponding columns will consist of the corresponfing color label preceded by the
given prefix. For example, if the prefix is &quot;PC&quot; and the module is turquoise, the corresponding
module eigengene will be labeled &quot;PCturquoise&quot;. Most of old code assumes &quot;PC&quot;, but &quot;ME&quot; is more
instructive and used in some newer analyses.
</p>


<h3>Value</h3>

<p>A character string.
</p>


<h3>Note</h3>

<p>Currently the standard prefix is <code>"ME"</code> and there is no way to change it.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code>
</p>

<hr>
<h2 id='moduleEigengenes'>Calculate module eigengenes.</h2><span id='topic+moduleEigengenes'></span>

<h3>Description</h3>

<p>Calculates module eigengenes (1st principal component) of modules in a given single dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moduleEigengenes(expr, 
                 colors, 
                 impute = TRUE, 
                 nPC = 1, 
                 align = "along average", 
                 excludeGrey = FALSE, 
                 grey = if (is.numeric(colors)) 0 else "grey",
                 subHubs = TRUE,
                 trapErrors = FALSE, 
                 returnValidOnly = trapErrors, 
                 softPower = 6,
                 scale = TRUE,
                 verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moduleEigengenes_+3A_expr">expr</code></td>
<td>
<p>Expression data for a single set in the form of a data frame where rows are samples and
columns are genes (probes).</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_colors">colors</code></td>
<td>
<p>A vector of the same length as the number of probes in <code>expr</code>, giving module color
for all probes (genes). Color <code>"grey"</code> is reserved for unassigned genes. </p>
</td></tr> 
<tr><td><code id="moduleEigengenes_+3A_impute">impute</code></td>
<td>
<p>If <code>TRUE</code>, expression data will be checked for the presence of <code>NA</code> entries and
if the latter are present, numerical data will be imputed, using function <code>impute.knn</code> and probes from
the same module as the missing datum. The function <code>impute.knn</code> uses a fixed random seed giving
repeatable results.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_npc">nPC</code></td>
<td>
<p>Number of principal components and variance explained entries to be calculated. Note
that only the first principal component is returned; the rest are used only for the calculation of
proportion of variance explained. The number of returned variance explained entries is
currently <code>min(nPC, 10)</code>. If given <code>nPC</code> is greater than 10, a warning is issued.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_align">align</code></td>
<td>
<p>Controls whether eigengenes, whose orientation is undetermined, should be aligned with
average expression (<code>align = "along average"</code>, the default) or left as they are (<code>align = ""</code>).
Any other value will trigger an error.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_excludegrey">excludeGrey</code></td>
<td>
<p>Should the improper module consisting of 'grey' genes be excluded from the
eigengenes?</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_grey">grey</code></td>
<td>
<p>Value of <code>colors</code> designating the improper module. Note that if <code>colors</code> is a
factor of numbers, the default value will be incorrect.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_subhubs">subHubs</code></td>
<td>
<p>Controls whether hub genes should be substituted for missing eigengenes. If
<code>TRUE</code>, each missing eigengene (i.e., eigengene whose calculation failed and the error
was trapped) will be replaced by a weighted average of the most connected hub genes in the
corresponding module. If this calculation fails, or if <code>subHubs==FALSE</code>, the value of
<code>trapErrors</code> will determine whether the offending module
will be removed or whether the function will issue an error and stop.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_traperrors">trapErrors</code></td>
<td>
<p>Controls handling of errors from that may arise when there are too many
<code>NA</code> entries in expression data. If <code>TRUE</code>, errors from calling these functions will be
trapped without abnormal exit. 
If <code>FALSE</code>, errors will cause the function to stop. Note, however, that <code>subHubs</code> takes
precedence in the sense that if <code>subHubs==TRUE</code> and <code>trapErrors==FALSE</code>, an error will be
issued only if both the principal component and the hubgene calculations have failed. </p>
</td></tr> 
<tr><td><code id="moduleEigengenes_+3A_returnvalidonly">returnValidOnly</code></td>
<td>
<p>logical; controls whether the returned data frame of module eigengenes 
contains columns
corresponding only to modules whose eigengenes or hub genes could be calculated correctly 
(<code>TRUE</code>), or whether
the data frame should have columns for each of the input color labels (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_softpower">softPower</code></td>
<td>
<p>The power used in soft-thresholding the adjacency matrix. Only used when the
hubgene approximation is necessary because the principal component calculation failed. It must be
non-negative. The default
value should only be changed if there is a clear indication that it leads to incorrect results.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_scale">scale</code></td>
<td>
<p>logical; can be used to turn off scaling of the expression data before calculating the
singular value decomposition. The scaling should only be turned off if the data has been scaled
previously, in which case the function can run a bit faster. Note however that the function first
imputes, then scales the expression data in each module. If the expression contain missing data, scaling
outside of the function and letting the function impute missing data may lead to slightly different
results than if the data is scaled within the function.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity of printed progress messages. 0 means silent, up to (about) 5 the
verbosity gradually increases.</p>
</td></tr>
<tr><td><code id="moduleEigengenes_+3A_indent">indent</code></td>
<td>
<p>A single non-negative integer controlling indentation of printed messages. 0 means no
indentation, each unit above that adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Module eigengene is defined as the first principal component of the expression matrix of the
corresponding module. The calculation may fail if the expression data has too many missing entries.
Handling of such errors is controlled by the arguments <code>subHubs</code> and 
<code>trapErrors</code>. 
If <code>subHubs==TRUE</code>, errors in principal component calculation will be trapped and a substitute
calculation of hubgenes will be attempted. If this fails as well, behaviour depends on
<code>trapErrors</code>: if <code>TRUE</code>, the offending 
module will be ignored and the return value will allow the user to remove the module from further
analysis; if <code>FALSE</code>, the function will stop. 
</p>
<p>From the user's point of view, setting <code>trapErrors=FALSE</code> ensures that if the function returns
normally, there will be a valid eigengene (principal component or hubgene) for each of the input
colors. If the user sets <code>trapErrors=TRUE</code>, all calculational (but not input) errors will be
trapped, but the user should check the output (see below) to make sure all modules have a valid
returned eigengene. 
</p>
<p>While the principal component calculation can fail even on relatively sound data 
(it does not take all that many &quot;well-placed&quot; <code>NA</code> to torpedo the
calculation), 
it takes many more irregularities in the data for the hubgene calculation to
fail. In fact such a failure signals there likely is something seriously wrong with the data.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eigengenes</code></td>
<td>
<p>Module eigengenes in a dataframe, with each column corresponding to one eigengene.
The columns are named by the corresponding color with an <code>"ME"</code> prepended, e.g., <code>MEturquoise</code>
etc. If <code>returnValidOnly==FALSE</code>, module eigengenes whose calculation failed have 
all components set to <code>NA</code>.</p>
</td></tr>
<tr><td><code>averageExpr</code></td>
<td>
<p>If <code>align == "along average"</code>, a dataframe containing average normalized
expression in each module. The columns are named by the corresponding color with an <code>"AE"</code>
prepended, e.g., <code>AEturquoise</code> etc.</p>
</td></tr>
<tr><td><code>varExplained</code></td>
<td>
<p>A dataframe in which each column corresponds to a module, with the component
<code>varExplained[PC, module]</code> giving the variance of module <code>module</code> explained by the principal
component no. <code>PC</code>. The calculation is exact irrespective of the number of computed principal
components. At most 10 variance explained values are recorded in this dataframe.</p>
</td></tr>
<tr><td><code>nPC</code></td>
<td>
<p>A copy of the input <code>nPC</code>.</p>
</td></tr> 
<tr><td><code>validMEs</code></td>
<td>
<p>A boolean vector. Each component (corresponding to the columns in <code>data</code>)
is <code>TRUE</code> if the corresponding eigengene is valid, and <code>FALSE</code>
if it is invalid. Valid eigengenes include both principal components and their hubgene
approximations.
When <code>returnValidOnly==FALSE</code>, by definition all returned eigengenes are valid and the
entries of <code>validMEs</code> are all <code>TRUE</code>. </p>
</td></tr>
<tr><td><code>validColors</code></td>
<td>
<p>A copy of the input colors with entries corresponding to invalid modules set to
<code>grey</code> if given, otherwise 0 if <code>colors</code> is numeric and &quot;grey&quot; otherwise.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>Boolean flag signalling whether all eigengenes have been calculated correctly, either
as principal components or as the hubgene average approximation.</p>
</td></tr>
<tr><td><code>allPC</code></td>
<td>
<p>Boolean flag signalling whether all returned eigengenes are principal components.</p>
</td></tr>
<tr><td><code>isPC</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding eigengene is the first principal component and <code>FALSE</code> if it
is the hubgene approximation or is invalid.</p>
</td></tr>
<tr><td><code>isHub</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding eigengene is the hubgene approximation and <code>FALSE</code> if it
is the first principal component or is invalid.</p>
</td></tr>
<tr><td><code>validAEs</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding module average expression is valid.</p>
</td></tr>
<tr><td><code>allAEOK</code></td>
<td>
<p>Boolean flag signalling whether all returned module average expressions contain
valid data. Note that <code>returnValidOnly==TRUE</code> does not imply <code>allAEOK==TRUE</code>: 
some invalid average expressions may be
returned if their corresponding eigengenes have been calculated correctly.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Steve Horvath <a href="mailto:SHorvath@mednet.ucla.edu">SHorvath@mednet.ucla.edu</a>, Peter Langfelder
<a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a> </p>


<h3>References</h3>

 
<p>Zhang, B. and Horvath, S. (2005), &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>, <code>impute.knn</code></p>

<hr>
<h2 id='moduleMergeUsingKME'> Merge modules and reassign genes using kME.  </h2><span id='topic+moduleMergeUsingKME'></span>

<h3>Description</h3>

<p>This function takes an expression data matrix (and other user-defined parameters), calculates the module membership (kME) values, and adjusts the module assignments, merging modules that are not sufficiently distinct and reassigning modules that were originally assigned suboptimally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moduleMergeUsingKME(
   datExpr, colorh, ME = NULL, 
   threshPercent = 50, mergePercent = 25, 
   reassignModules = TRUE, 
   convertGrey = TRUE, 
   omitColors = "grey", 
   reassignScale = 1,  
   threshNumber = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moduleMergeUsingKME_+3A_datexpr">datExpr</code></td>
<td>

<p>An expression data matrix, with samples as rows, genes (or probes) as column.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_colorh">colorh</code></td>
<td>

<p>The color vector (module assignments) corresponding to the columns of datExpr.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_me">ME</code></td>
<td>

<p>Either NULL (default), at which point the module eigengenes will be calculated, or pre-calculated module eigengenes for each of the modules, with samples as rows (corresponding to datExpr), and modules corresponding to columns (column names MUST be module colors or module colors prefixed by &quot;ME&quot; or &quot;PC&quot;).
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_threshpercent">threshPercent</code></td>
<td>

<p>Threshold percent of the number of genes in the module that should be included for the various analyses. For example, in a module with 200 genes, if threshPercent=50 (default), then 50 genes will be checked for reassignment and used to test whether two modules should be merged.  See also threshNumber.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_mergepercent">mergePercent</code></td>
<td>

<p>If greater than this percent of the assigned genes are above the threshold are in a module other than the assigned module, then these two modules will be merged.  For example, if mergePercent=25 (default), and the 70 out of 200 genes in the blue module were more highly correlated with the black module eigengene, then all genes in the blue module would be reassigned to the black module.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_reassignmodules">reassignModules</code></td>
<td>

<p>If TRUE (default), genes are resassigned to the module with which they have the highest module membership (kME), but only if their kME is above the threshPercent (or threshNumber) threshold of that module.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_convertgrey">convertGrey</code></td>
<td>

<p>If TRUE (default), unassigned (grey) genes are assigned as in &quot;reassignModules&quot;
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_omitcolors">omitColors</code></td>
<td>

<p>These are all of the module assignments which indicate genes that are not assigned to modules (default=&quot;grey&quot;).  These genes will all be assigned as &quot;grey&quot; by this function.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_reassignscale">reassignScale</code></td>
<td>

<p>A value between 0 and 1 (default) which determines how the threshPercent gets scaled for reassigning genes.  Smaller values reassign more genes, but does not affect the merging process.
</p>
</td></tr>
<tr><td><code id="moduleMergeUsingKME_+3A_threshnumber">threshNumber</code></td>
<td>

<p>Either NULL (default) or, if entered, every module is counted as having exactly threshNumber genes, and threshPercent it ignored.  This parameter should have the effect of 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>moduleColors</code></td>
<td>

<p>The NEW color vector (module assignments) corresponding to the columns of datExpr, after module merging and reassignments.
</p>
</td></tr>
<tr><td><code>mergeLog</code></td>
<td>

<p>A log of the order in which modules were merged, for reference.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that this function should be considered &quot;experimental&quot; as it has only been beta tested.  Please e-mail jeremyinla@gmail.com if you have any issues with the function.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## First simulate some data and the resulting network dendrogram
set.seed(100)
MEturquoise = sample(1:100,50)
MEblue      = sample(1:100,50)
MEbrown     = sample(1:100,50)
MEyellow    = sample(1:100,50) 
MEgreen     = c(MEyellow[1:30], sample(1:100,20))
MEred	    = c(MEbrown [1:20], sample(1:100,30))
#MEblack	    = c(MEblue  [1:25], sample(1:100,25))
ME   = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen, MEred)#, MEblack)
dat1 = simulateDatExpr(ME, 300, c(0.15,0.13,0.12,0.10,0.09,0.09,0.1), signed=TRUE)
TOM1  = TOMsimilarityFromExpr(dat1$datExpr, networkType="signed", nThreads = 1)
tree1 = fastcluster::hclust(as.dist(1-TOM1),method="average")

## Here is an example using different mergePercentages, 
# setting an inclusive threshPercent (91)
colorh1  &lt;- colorPlot &lt;- labels2colors(dat1$allLabels)
merges = c(65,40,20,5)
for (m in merges)  
   colorPlot = cbind(colorPlot, 
                     moduleMergeUsingKME(dat1$datExpr,colorh1,
                        threshPercent=91, mergePercent=m)$moduleColors)
plotDendroAndColors(tree1, colorPlot, c("ORIG",merges), dendroLabels=FALSE)

## Here is an example using a lower reassignScale (so that more genes get reassigned)
colorh1  &lt;- colorPlot &lt;- labels2colors(dat1$allLabels)
merges = c(65,40,20,5)
for (m in merges)  colorPlot = cbind(colorPlot, 
  moduleMergeUsingKME(dat1$datExpr,colorh1,threshPercent=91, 
                      reassignScale=0.7, mergePercent=m)$moduleColors)
plotDendroAndColors(tree1, colorPlot, c("ORIG",merges), dendroLabels=FALSE)

## Here is an example using a less-inclusive threshPercent (75), 
# little if anything is merged.

colorh1  &lt;- colorPlot &lt;- labels2colors(dat1$allLabels)
merges = c(65,40,20,5)
for (m in merges)  colorPlot = cbind(colorPlot, 
  moduleMergeUsingKME(dat1$datExpr,colorh1,
                      threshPercent=75, mergePercent=m)$moduleColors)
plotDendroAndColors(tree1, colorPlot, c("ORIG",merges), dendroLabels=FALSE)
# (Note that with real data, the default threshPercent=50 usually results 
# in some modules being merged)

</code></pre>

<hr>
<h2 id='moduleNumber'>Fixed-height cut of a dendrogram.</h2><span id='topic+moduleNumber'></span>

<h3>Description</h3>

<p>Detects branches of on the input dendrogram by performing a fixed-height cut.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moduleNumber(dendro, cutHeight = 0.9, minSize = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moduleNumber_+3A_dendro">dendro</code></td>
<td>
<p>a hierarchical clustering dendorgram such as one returned by <code>hclust</code>.  </p>
</td></tr>
<tr><td><code id="moduleNumber_+3A_cutheight">cutHeight</code></td>
<td>
<p>Maximum joining heights that will be considered.  </p>
</td></tr>
<tr><td><code id="moduleNumber_+3A_minsize">minSize</code></td>
<td>
<p>Minimum cluster size.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>All contiguous branches below the height <code>cutHeight</code> that contain at least <code>minSize</code> objects
are assigned unique positive numerical labels; all unassigned objects are assigned label 0.
</p>


<h3>Value</h3>

<p>A vector of numerical labels giving the assigment of each object.
</p>


<h3>Note</h3>

<p>The numerical labels may not be sequential. See <code><a href="#topic+normalizeLabels">normalizeLabels</a></code> for a way to put the
labels into a standard order.</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="stats.html#topic+cutree">cutree</a></code>, <code><a href="#topic+normalizeLabels">normalizeLabels</a></code>
</p>

<hr>
<h2 id='modulePreservation'> Calculation of module preservation statistics </h2><span id='topic+modulePreservation'></span>

<h3>Description</h3>

<p>Calculations of module preservation statistics between independent data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modulePreservation(
   multiData,
   multiColor,
   multiWeights = NULL,
   dataIsExpr = TRUE,
   networkType = "unsigned", 
   corFnc = "cor",
   corOptions = "use = 'p'",
   referenceNetworks = 1, 
   testNetworks = NULL,
   nPermutations = 100, 
   includekMEallInSummary = FALSE,
   restrictSummaryForGeneralNetworks = TRUE,
   calculateQvalue = FALSE,
   randomSeed = 12345, 
   maxGoldModuleSize = 1000, 
   maxModuleSize = 1000, 
   quickCor = 1, 
   ccTupletSize = 2, 
   calculateCor.kIMall = FALSE,
   calculateClusterCoeff = FALSE,
   useInterpolation = FALSE, 
   checkData = TRUE, 
   greyName = NULL, 
   goldName = NULL,
   savePermutedStatistics = TRUE, 
   loadPermutedStatistics = FALSE, 
   permutedStatisticsFile = if (useInterpolation) "permutedStats-intrModules.RData" 
                                   else "permutedStats-actualModules.RData", 
   plotInterpolation = TRUE, 
   interpolationPlotFile = "modulePreservationInterpolationPlots.pdf", 
   discardInvalidOutput = TRUE,
   parallelCalculation = FALSE,
   verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modulePreservation_+3A_multidata">multiData</code></td>
<td>
<p>  expression data or adjacency data 
in multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression or adjacency
data.
If expression data are used,
rows correspond to samples and columns to genes or probes. In case of adjacencies, each <code>data</code> matrix
should be a symmetric matrix ith entries between 0 and 1 and unit diagonal. 
Each component of the outermost list should be
named. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_multicolor">multiColor</code></td>
<td>
<p> a list in which every component is a vector giving the module labels of genes in
<code>multiExpr</code>. The components must be named using the same names that are used in <code>multiExpr</code>; these
names are used top match labels to expression data sets. See details. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_multiweights">multiWeights</code></td>
<td>
<p>optional weights, only when <code>multiData</code> contains expression data. 
If given, must be in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>) and
weights for each set must have the same dimensions as the corresponding set in <code>multiData</code>. The weights are used in
correlation calculations that involve <code>multiData</code>, and are supplied as argument <code>weights.x</code> and possibly
<code>weights.y</code> (where appropriate) to the correlation function specified by <code>corFnc</code>.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_dataisexpr">dataIsExpr</code></td>
<td>
<p> logical: if <code>TRUE</code>, <code>multiData</code> will be interpreted as expression data; if
<code>FALSE</code>, <code>multiData</code> will be interpreted as adjacencies. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_corfnc">corFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity. Defaults to Pearson correlation. Another useful choice is <code><a href="#topic+bicor">bicor</a></code>.
More generally, any function returning values between -1 and 1 can be used. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_coroptions">corOptions</code></td>
<td>
<p> character string specifying additional arguments to be passed to the function given
by <code>corFnc</code>. Use <code>"use = 'p', method = 'spearman'"</code> to obtain Spearman correlation.   </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_referencenetworks">referenceNetworks</code></td>
<td>
<p> a vector giving the indices of expression data to be used as reference networks.
Reference networks must have their module labels given in <code>multiColor</code>. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_testnetworks">testNetworks</code></td>
<td>
<p>a list with one component per each entry in <code>referenceNetworks</code> above, giving
the test networks in which to evaluate module preservation for the corresponding reference network. If not
given, preservation will be evaluated in all networks (except each reference network). If
<code>referenceNetworks</code> is of length 1, <code>testNetworks</code> can also be a vector (instead of a list
containing the single vector).</p>
</td></tr> 
<tr><td><code id="modulePreservation_+3A_npermutations">nPermutations</code></td>
<td>
<p> specifies the number of permutations that will be calculated in the permutation test. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_includekmeallinsummary">includekMEallInSummary</code></td>
<td>
<p> logical: should cor.kMEall be included in the calculated summary statistics?
Because kMEall takes into account all genes in the network, this statistic measures preservation of the full
network with respect to the eigengene of the module. This may be undesirable, hence the default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_restrictsummaryforgeneralnetworks">restrictSummaryForGeneralNetworks</code></td>
<td>
<p> logical: should the summary statistics for general (not
correlation) networks be restricted (density to meanAdj, connectivity to cor.kIM and cor.Adj)? The default
<code>TRUE</code> corresponds to published work. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_calculateqvalue">calculateQvalue</code></td>
<td>
<p> logical: should q-values (local FDR estimates) be calculated? Package qvalue must
be installed for this calculation. Note that q-values may not be meaningful when the number of modules is
small and/or most modules are preserved. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_randomseed">randomSeed</code></td>
<td>
<p> seed for the random number generator. If <code>NULL</code>, the seed will not be set. If
non-<code>NULL</code> and the random generator has been initialized prior to the function call, the latter's state
is saved and restored upon exit</p>
</td></tr> 
<tr><td><code id="modulePreservation_+3A_maxgoldmodulesize">maxGoldModuleSize</code></td>
<td>
<p> maximum size of the &quot;gold&quot; module, i.e., the random sample of all network genes. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_maxmodulesize">maxModuleSize</code></td>
<td>
<p> maximum module size used for calculations. Modules larger than <code>maxModuleSize</code>
will be reduced by randomly sampling <code>maxModuleSize</code> genes. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_quickcor">quickCor</code></td>
<td>
<p> number between 0 and 1 specifying the handling of missing data in calculation of
correlation. Zero means exact but potentially slower calculations; one means potentially faster
calculations, but with potentially inaccurate results if the proportion of missing data is large. See
<code><a href="#topic+cor">cor</a></code> for more details. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_cctupletsize">ccTupletSize</code></td>
<td>
<p> tuplet size for co-clustering calculations. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_calculatecor.kimall">calculateCor.kIMall</code></td>
<td>
<p> logical: should cor.kMEall be calculated? This option is only valid for
adjacency input. If <code>FALSE</code>, cor.kIMall will not be calculated, potentially saving significant amount
of time if the input adjacencies are large and contain many modules. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_calculateclustercoeff">calculateClusterCoeff</code></td>
<td>
<p> logical: should statistics based on the clustering coefficient be
calculated? While these statistics may be interesting, the calculations are also computationally expensive.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_checkdata">checkData</code></td>
<td>
<p> logical: should data be checked for excessive number of missing entries? See
<code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code> for details. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_greyname">greyName</code></td>
<td>
<p> label used for unassigned genes. Traditionally such genes are labeled by grey color or
numeric label 0. These values are the default when <code>multiColor</code> contains character or numeric vectors,
respectively. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_goldname">goldName</code></td>
<td>
<p> label used for the &quot;module&quot; representing a random sample of the whole network. 
Traditionally such genes are labeled by gold color or
numeric label 0.1. These values are the default when <code>greyName</code> is character and numeric,
respectively. If these values conflict with the module labels in <code>multiColor</code>, they should be set to something not present
in <code>multiColor</code>.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_savepermutedstatistics">savePermutedStatistics</code></td>
<td>
<p> logical: should calculated permutation statistics be saved? Saved
statistics may be re-used if the calculation needs to be repeated.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_permutedstatisticsfile">permutedStatisticsFile</code></td>
<td>
<p> file name to save the permutation statistics into. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_loadpermutedstatistics">loadPermutedStatistics</code></td>
<td>
<p> logical: should permutation statistics be loaded? If a previously executed
calculation needs to be repeated, loading permutation study results can cut the calculation time many-fold. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_useinterpolation">useInterpolation</code></td>
<td>
<p> logical: should permutation statistics be calculated by interpolating an artificial
set of evenly spaced modules? This option may potentially speed up the calculations, but it restricts
calculations to density measures.  </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_plotinterpolation">plotInterpolation</code></td>
<td>
<p> logical: should interpolation plots be saved? If interpolation is used (see
<code>useInterpolation</code> above), the function can optionally generate diagnostic plots that can be used to
assess whether the interpolation makes sense. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_interpolationplotfile">interpolationPlotFile</code></td>
<td>
<p> file name to save the interpolation plots into. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_discardinvalidoutput">discardInvalidOutput</code></td>
<td>
<p>logical: should output columns containing no valid data be discarded? This
option may be useful when input <code>dataIsExpr</code> is <code>FALSE</code> and some of the output statistics cannot
be calculated. This option causes such statistics to be dropped from output.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_parallelcalculation">parallelCalculation</code></td>
<td>
<p>logical: should calculations be done in parallel? Note that parallel
calculations are turned off by default and will lead to somewhat DIFFERENT results than serial calculations
because the random seed is set differently. For the calculation to actually run in parallel mode, a call to
<code><a href="#topic+enableWGCNAThreads">enableWGCNAThreads</a></code> must be made before this function is called.</p>
</td></tr> 
<tr><td><code id="modulePreservation_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates module preservation statistics pair-wise between given reference sets and all
other sets in <code>multiExpr</code>. Reference sets must have their corresponding module assignment specified in
<code>multiColor</code>; module assignment is optional for test sets. Individual expression sets and their module
labels are matched using <code>names</code> of the corresponding components in <code>multiExpr</code> and
<code>multiColor</code>. 
</p>
<p>For each reference-test pair, the function calculates module preservation statistics that
measure how well the modules of the reference set are preserved in the test set. 
If the <code>multiColor</code> also contains module assignment for the test set, the calculated statistics also
include cross-tabulation statistics that make use of the test module assignment. 
</p>
<p>For each reference-test pair, the function only uses genes (columns of the <code>data</code> component of each
component of <code>multiExpr</code>) that are in common between the reference and test set. Columns are matched by
column names, so column names must be valid.  
</p>
<p>In addition to preservation statistics, the function also calculates several statistics of module quality,
that is measures of how well-defined modules are in the reference set. The quality statistics are calculated
with respect to genes in common with with a test set; thus the function calculates a set of quality
statistics for each reference-test pair. This may be somewhat counter-intuitive, but it allows a direct
comparison of corresponding quality and preservation statistics.
</p>
<p>The calculated p-values are determined from the Z scores of individual measures under assumption of
normality. No p-value is calculated for the Zsummary measures. Bonferoni correction to the number of tested
modules. Because the p-values for strongly preserved modules are often extremely low, the function reports
natural logarithms (base e) of the p-values. However, q-values are reported untransformed since they are
calculated that way in package qvalue.
</p>
<p>Missing data are removed (but see <code>quickCor</code> above). 
</p>


<h3>Value</h3>

<p>The function returns a nested list of preservation statistics. At the top level, the list components are:
</p>
<table role = "presentation">
<tr><td><code>quality</code></td>
<td>
<p>observed values, Z scores, log p-values, Bonferoni-corrected log p-values, and (optionally)
q-values of quality statistics. All logarithms are in base 10.</p>
</td></tr>
<tr><td><code>preservation</code></td>
<td>
<p>observed values, Z scores, log p-values, Bonferoni-corrected log p-values, and
(optionally) q-values of density and connectivity preservation statistics. All logarithms are in base 10.</p>
</td></tr>
<tr><td><code>accuracy</code></td>
<td>
<p>observed values, Z scores, log p-values, Bonferoni-corrected log p-values, and
(optionally) q-values of cross-tabulation statistics. All logarithms are in base 10.</p>
</td></tr>
<tr><td><code>referenceSeparability</code></td>
<td>
<p>observed values, Z scores, log p-values, Bonferoni-corrected log p-values, and (optionally)
q-values of module separability in the reference network. All logarithms are in base 10.</p>
</td></tr>
<tr><td><code>testSeparability</code></td>
<td>
<p>observed values, Z scores, p-values, Bonferoni-corrected p-values, and (optionally)
q-values of module separability in the test network. All logarithms are in base 10.</p>
</td></tr>
<tr><td><code>permutationDetails</code></td>
<td>
<p>results of individual permutations, useful for diagnostics</p>
</td></tr>
</table>
<p>All of the above are lists. The lists <code>quality</code>, <code>preservation</code>, <code>referenceSeparability</code>,
and <code>testSeparability</code> each contain 4 or 5 components: <code>observed</code> contains observed values, 
<code>Z</code> contains the corresponding Z scores, <code>log.p</code> contains base 10 logarithms of the p-values,
<code>log.pBonf</code>  contains base 10 logarithms of the Bonferoni corrected p-values, and optionally <code>q</code>
contains the associated q-values. The list <code>accuracy</code> contains <code>observed</code>, <code>Z</code>, <code>log.p</code>,
<code>log.pBonf</code>, optionally <code>q</code>, 
and additional components <code>observedOverlapCounts</code> and <code>observedFisherPvalues</code> that contain the
observed matrices of overlap counts and Fisher test p-values. 
</p>
<p>Each of the lists <code>observed</code>, <code>Z</code>, <code>log.p</code>,
<code>log.pBonf</code>, optionally <code>q</code>, <code>observedOverlapCounts</code> and <code>observedFisherPvalues</code>
is structured as a 2-level list where the outer components correspond to reference sets and the inner
components to tests sets. As an example, <code>preservation$observed[[1]][[2]]</code> contains the density and
connectivity preservation statistics for the preservation of set 1 modules in set 2, that is set 1 is the
reference set and set 2 is the test set. <code>preservation$observed[[1]][[2]]</code> is a data frame in which
each row corresponds to a module in the reference network 1 plus one row for the unassigned objects, and
one row for a &quot;module&quot; that contains randomly sampled objects and that represents a whole-network average.
Each column corresponds to a statistic as indicated by the column name. 
</p>


<h3>Note</h3>

 
<p>For large data sets, the permutation study may take a while (typically on the order of several hours). Use
<code>verbose = 3</code> to get detailed progress report as the calculations advance.
</p>


<h3>Author(s)</h3>

<p> Rui Luo and Peter Langfelder </p>


<h3>References</h3>

<p> Peter Langfelder, Rui Luo, Michael C. Oldham, and Steve Horvath, to appear </p>


<h3>See Also</h3>

<p> Network construction and module detection functions in the WGCNA package such as
<code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+blockwiseModules">blockwiseModules</a></code>; rudimentary cleaning in
<code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>; the WGCNA implementation of correlation in <code><a href="#topic+cor">cor</a></code>.
</p>

<hr>
<h2 id='mtd.apply'>
Apply a function to each set in a multiData structure.
</h2><span id='topic+mtd.apply'></span><span id='topic+mtd.applyToSubset'></span>

<h3>Description</h3>

<p>Inspired by <code><a href="base.html#topic+lapply">lapply</a></code>, these functions apply a given function to each <code>data</code> component in
the input <code>multiData</code> structure, and optionally simplify the result to an array if possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.apply(
    # What to do
    multiData, FUN, ..., 

    # Pre-existing results and update options
    mdaExistingResults = NULL, mdaUpdateIndex = NULL,
    mdaCopyNonData = FALSE,

    # Output formatting options
    mdaSimplify = FALSE, 
    returnList = FALSE,

    # Internal behaviour options
    mdaVerbose = 0, mdaIndent = 0)

mtd.applyToSubset(
    # What to do
    multiData, FUN, ..., 

    # Which rows and cols to keep
    mdaRowIndex = NULL, mdaColIndex = NULL, 

    # Pre-existing results and update options
    mdaExistingResults = NULL, mdaUpdateIndex = NULL,
    mdaCopyNonData = FALSE,

    # Output formatting options
    mdaSimplify = FALSE, 
    returnList = FALSE,

    # Internal behaviour options
    mdaVerbose = 0, mdaIndent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.apply_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure to apply the function over
</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_fun">FUN</code></td>
<td>
<p>Function to be applied. </p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_...">...</code></td>
<td>

<p>Other arguments to the function <code>FUN</code>.
</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdarowindex">mdaRowIndex</code></td>
<td>
<p>If given, must be a list of the same length as <code>multiData</code>. Each element must be
a logical or numeric vector that specifies rows in each <code>data</code> component 
to select before applying the function.</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdacolindex">mdaColIndex</code></td>
<td>
<p>A logical or numeric vector that specifies columns in each <code>data</code> component 
to select before applying the function.</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdaexistingresults">mdaExistingResults</code></td>
<td>
<p>Optional list that contains previously calculated results. This can be useful
if only a few sets in <code>multiData</code> have changed and recalculating the unchanged ones is computationally
expensive. If not given, all calculations will be performed. If given, components of this list are copied
into the output. See <code>mdmUpdateIndex</code> for which components are re-calculated by default. </p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdaupdateindex">mdaUpdateIndex</code></td>
<td>
<p>Optional specification of which sets in <code>multiData</code> the calculation should
actually be carried out. This argument has an effect only if <code>mdaExistingResults</code> is non-NULL. If the
length of <code>mdaExistingResults</code> (call the length &lsquo;k&rsquo;) 
is less than the number of sets in <code>multiData</code>, the function
assumes that the existing results correspond to the first &lsquo;k&rsquo; sets in <code>multiData</code> and the rest of the
sets are automatically calculated, irrespective of the setting of <code>mdaUpdateIndex</code>. The argument
<code>mdaUpdateIndex</code> can be used to specify re-calculation of some (or all) of the results that already
exist in <code>mdaExistingResults</code>. </p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdacopynondata">mdaCopyNonData</code></td>
<td>
<p>Logical: should non-data components of <code>multiData</code> be copied into the output?
Note that the copying is incompatible with simplification; enabling both will trigger an error.</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdasimplify">mdaSimplify</code></td>
<td>

<p>Logical: should the result be simplified to an array, if possible? Note that this may lead to errors; if
so, disable simplification.
</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_returnlist">returnList</code></td>
<td>
<p>Logical: should the result be turned into a list (rather than a multiData structure)?
Note that this is incompatible with simplification: if <code>mdaSimplify</code> is <code>TRUE</code>, this argument is
ignored.</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdaverbose">mdaVerbose</code></td>
<td>
<p>Integer specifying whether progress diagnistics should be printed out. Zero means
silent, increasing values will lead to more diagnostic messages.</p>
</td></tr>
<tr><td><code id="mtd.apply_+3A_mdaindent">mdaIndent</code></td>
<td>
<p>Integer specifying the indentation of the printed progress messages. Each unit equals
two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

  
<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p><code>mtd.apply</code> works on any &quot;loose&quot; multiData structure; <code>mtd.applyToSubset</code> assumes (and checks
for) a &quot;strict&quot; multiData structure.
</p>


<h3>Value</h3>

<p>A multiData structure containing the results of the supplied function on each <code>data</code> component in the
input multiData structure. Other components are simply copied.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure;
<code><a href="#topic+mtd.applyToSubset">mtd.applyToSubset</a></code> for applying a function to a subset of a multiData structure;
<code><a href="#topic+mtd.mapply">mtd.mapply</a></code> for vectorizing over several arguments.
</p>

<hr>
<h2 id='mtd.mapply'>
Apply a function to elements of given multiData structures.
</h2><span id='topic+mtd.mapply'></span>

<h3>Description</h3>

<p>Inspired by <code><a href="base.html#topic+mapply">mapply</a></code>, this function applies a given function to each <code>data</code> component in
the input multiData arguments, and optionally simplify the result to an array if possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.mapply(

  # What to do
  FUN, ..., MoreArgs = NULL, 

  # How to interpret the input
  mdma.argIsMultiData = NULL,

  # Copy previously known results?
  mdmaExistingResults = NULL, mdmaUpdateIndex = NULL,

  # How to format output
  mdmaSimplify = FALSE, 
  returnList = FALSE,
  
  # Options controlling internal behaviour
  mdma.doCollectGarbage = FALSE, 
  mdmaVerbose = 0, mdmaIndent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.mapply_+3A_fun">FUN</code></td>
<td>
<p>Function to be applied. </p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_...">...</code></td>
<td>

<p>Arguments to be vectorized over. These can be multiData structures or simple vectors (e.g., lists). 
</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_moreargs">MoreArgs</code></td>
<td>

<p>A named list that specifies the scalar arguments (if any) to <code>FUN</code>.
</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdma.argismultidata">mdma.argIsMultiData</code></td>
<td>

<p>Optional specification whether arguments are multiData structures. A logical vector where each component
corresponds to one entry of <code>...</code>. If not given, multiData status will be determined using
<code><a href="#topic+isMultiData">isMultiData</a></code> with argument <code>strict=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdmaexistingresults">mdmaExistingResults</code></td>
<td>
<p>Optional list that contains previously calculated results. This can be useful
if only a few sets in <code>multiData</code> have changed and recalculating the unchanged ones is computationally
expensive. If not given, all calculations will be performed. If given, components of this list are copied
into the output. See <code>mdmUpdateIndex</code> for which components are re-calculated by default. </p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdmaupdateindex">mdmaUpdateIndex</code></td>
<td>
<p>Optional specification of which sets in <code>multiData</code> the calculation should 
actually be carried out. This argument has an effect only if <code>mdmaExistingResults</code> is non-NULL. If the
length of <code>mdmaExistingResults</code> (call the length &lsquo;k&rsquo;) 
is less than the number of sets in <code>multiData</code>, the function
assumes that the existing results correspond to the first &lsquo;k&rsquo; sets in <code>multiData</code> and the rest of the
sets are automatically calculated, irrespective of the setting of <code>mdmaUpdateIndex</code>. The argument
<code>mdmaUpdateIndex</code> can be used to specify re-calculation of some (or all) of the results that already
exist in <code>mdmaExistingResults</code>. </p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdmasimplify">mdmaSimplify</code></td>
<td>

<p>Logical: should simplification of the result to an array be attempted? The simplification is fragile and
can produce unexpected errors; use the default <code>FALSE</code> if that happens.
</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_returnlist">returnList</code></td>
<td>
<p>Logical: should the result be turned into a list (rather than a multiData structure)?
Note that this is incompatible with simplification: if <code>mdaSimplify</code> is <code>TRUE</code>, this argument is
ignored.</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdma.docollectgarbage">mdma.doCollectGarbage</code></td>
<td>

<p>Should garbage collection be forced after each application of <code>FUN</code>?
</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdmaverbose">mdmaVerbose</code></td>
<td>
<p>Integer specifying whether progress diagnistics should be printed out. Zero means
silent, increasing values will lead to more diagnostic messages.</p>
</td></tr>
<tr><td><code id="mtd.mapply_+3A_mdmaindent">mdmaIndent</code></td>
<td>
<p>Integer specifying the indentation of the printed progress messages. Each unit equals
two spaces.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>This function applies the function <code>FUN</code> to each <code>data</code> component of those arguments in
<code>...</code> that are multiData structures in the &quot;loose&quot; sense, 
and to each component of those arguments in <code>...</code> that are
not multiData structures.
</p>


<h3>Value</h3>

<p>A multiData structure containing (as the <code>data</code> components) the results of <code>FUN</code>. If
simplification is successful, an array instead.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure;
</p>
<p><code>multiData.apply</code> for application of a function to a single multiData structure.
</p>

<hr>
<h2 id='mtd.rbindSelf'>
Turn a multiData structure into a single matrix or data frame.
</h2><span id='topic+mtd.rbindSelf'></span>

<h3>Description</h3>

<p>This function &quot;rbinds&quot; the <code>data</code> components of all sets in the input into a single matrix or data
frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.rbindSelf(multiData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.rbindSelf_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>This function requires a &quot;strict&quot; multiData structure.
</p>


<h3>Value</h3>

<p>A single matrix or data frame containing the &quot;rbinded&quot; result.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure;
</p>
<p><code><a href="base.html#topic+rbind">rbind</a></code> for various subtleties of the row binding operation.
</p>

<hr>
<h2 id='mtd.setAttr'>
Set attributes on each component of a multiData structure
</h2><span id='topic+mtd.setAttr'></span>

<h3>Description</h3>

<p>Set attributes on each <code>data</code> component of a multiData structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.setAttr(multiData, attribute, valueList)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.setAttr_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure.
</p>
</td></tr>
<tr><td><code id="mtd.setAttr_+3A_attribute">attribute</code></td>
<td>

<p>Name for the attribute to be set
</p>
</td></tr>
<tr><td><code id="mtd.setAttr_+3A_valuelist">valueList</code></td>
<td>

<p>List that gives the attribute value for each set in the multiData structure.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input multiData with the attribute set on each <code>data</code> component.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure;
</p>
<p><code>isMultiData</code> for a description of the multiData structure.
</p>

<hr>
<h2 id='mtd.setColnames'>
Get and set column names in a multiData structure.
</h2><span id='topic+mtd.setColnames'></span><span id='topic+mtd.colnames'></span>

<h3>Description</h3>

<p>Get and set column names on each <code>data</code> component in a multiData structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.colnames(multiData)
mtd.setColnames(multiData, colnames)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.setColnames_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure
</p>
</td></tr>
<tr><td><code id="mtd.setColnames_+3A_colnames">colnames</code></td>
<td>

<p>A vector (coercible to character) of column names. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>The <code>mtd.colnames</code> and <code>mtd.setColnames</code> assume (and checks for) a &quot;strict&quot; multiData structure.
</p>


<h3>Value</h3>

<p><code>mtd.colnames</code> returns the vector of column names of the <code>data</code> component. The function assumes
the column names in all sets are the same. 
</p>
<p><code>mtd.setColnames</code> returns the multiData structure with the column names set in all <code>data</code>
components.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure.
</p>

<hr>
<h2 id='mtd.simplify'>
If possible, simplify a multiData structure to a 3-dimensional array.
</h2><span id='topic+mtd.simplify'></span>

<h3>Description</h3>

<p>This function attempts to put all <code>data</code> components into a 3-dimensional array, with the last
dimension corresponding to the sets. This is only possible if all <code>data</code> components are matrices or
data frames with the same dimensiosn. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.simplify(multiData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.simplify_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure in the &quot;strict&quot; sense (see below).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>This function assumes a &quot;strict&quot; multiData structure.
</p>


<h3>Value</h3>

<p>A 3-dimensional array collecting all <code>data</code> components.
</p>


<h3>Note</h3>

<p>The function is relatively fragile and may fail. Use at your own risk.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure;
</p>
<p><code><a href="#topic+multiData2list">multiData2list</a></code> for converting multiData structures to plain lists.
</p>

<hr>
<h2 id='mtd.subset'>
Subset rows and columns in a multiData structure
</h2><span id='topic+mtd.subset'></span>

<h3>Description</h3>

<p>The function restricts each <code>data</code> component to the given columns and rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtd.subset(
  # Input
  multiData, 

  # Rows and columns to keep
  rowIndex = NULL, colIndex = NULL, 
  invert = FALSE,

  # Strict or permissive checking of structure?
  permissive = FALSE, 

  # Output formatting options
  drop = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mtd.subset_+3A_multidata">multiData</code></td>
<td>

<p>A multiData structure.
</p>
</td></tr>
<tr><td><code id="mtd.subset_+3A_rowindex">rowIndex</code></td>
<td>

<p>A list in which each component corresponds to a set and is a vector giving the rows to be retained in that
set. All indexing methods recognized by R can be used (numeric,
logical, negative indexing, etc). If <code>NULL</code>, all columns will be retained in each set. Note that
setting individual elements of <code>rowIndex</code> to <code>NULL</code> will lead to errors. 
</p>
</td></tr>
<tr><td><code id="mtd.subset_+3A_colindex">colIndex</code></td>
<td>

<p>A vector giving the columns to be retained. All indexing methods recognized by R can be used (numeric,
logical, negative indexing, etc). In addition, column names of the retained columns may be given; if a given
name cannot be matched to a column, an error will be thrown. If <code>NULL</code>, all columns will be retained.
</p>
</td></tr>
<tr><td><code id="mtd.subset_+3A_invert">invert</code></td>
<td>
<p>Logical: should the selection be inverted?</p>
</td></tr>
<tr><td><code id="mtd.subset_+3A_permissive">permissive</code></td>
<td>
<p>Logical: should the function tolerate &quot;loose&quot; <code>multiData</code> input? Note that the subsetting
may lead to cryptic errors if the input <code>multiData</code> does not follow the &quot;strict&quot; format. </p>
</td></tr>
<tr><td><code id="mtd.subset_+3A_drop">drop</code></td>
<td>
<p>Logical: should dimensions with extent 1 be dropped? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>
<p>This function assumes a &quot;strict&quot; multiData structure unless <code>permissive</code> is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>A multiData structure containing the selected rows and columns. Attributes (except possibly dimensions and the
corresponding dimnames) are retained.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code> to create a multiData structure.
</p>

<hr>
<h2 id='multiData'>
Create a multiData structure.
</h2><span id='topic+multiData'></span>

<h3>Description</h3>

<p>This function creates a multiData structure by storing its input arguments as the 'data' components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiData(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiData_+3A_...">...</code></td>
<td>

<p>Arguments to be stored in the multiData structure.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A multiData structure is intended to store (the same type of) data for multiple, possibly independent,
realizations
(for example, expression data for several independent experiments). It is a list where
each component corresponds to an (independent) data set. Each component is in turn a list that can hold
various types of information but must have a <code>data</code> component. In a &quot;strict&quot; multiData structure, the
<code>data</code> components are required to each be a matrix or a data frame and have the same number of
columns. In a &quot;loose&quot; multiData structure, the <code>data</code> components can be anything (but for most
purposes should be of comparable type and content).
</p>


<h3>Value</h3>

<p>The resulting multiData structure. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData2list">multiData2list</a></code> for converting a multiData structure to a list;
<code><a href="#topic+list2multiData">list2multiData</a></code> for an alternative way of creating a multiData structure;
<code><a href="#topic+mtd.apply">mtd.apply</a>, <a href="#topic+mtd.applyToSubset">mtd.applyToSubset</a>, <a href="#topic+mtd.mapply">mtd.mapply</a></code> for ways of applying a function to
each component of a multiData structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1 = matrix(rnorm(100), 20, 5);
data2 = matrix(rnorm(50), 10, 5);

md = multiData(Set1 = data1, Set2 = data2);

checkSets(md)
</code></pre>

<hr>
<h2 id='multiData.eigengeneSignificance'>
Eigengene significance across multiple sets
</h2><span id='topic+multiData.eigengeneSignificance'></span>

<h3>Description</h3>

<p>This function calculates eigengene significance and the associated significance statistics (p-values,
q-values etc) across several data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiData.eigengeneSignificance(
  multiData, multiTrait, 
  moduleLabels, multiEigengenes = NULL, 
  useModules = NULL, 
  corAndPvalueFnc = corAndPvalue, corOptions = list(), 
  corComponent = "cor", 
  getQvalues = FALSE, setNames = NULL, 
  excludeGrey = TRUE, greyLabel = ifelse(is.numeric(moduleLabels), 0, "grey"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiData.eigengeneSignificance_+3A_multidata">multiData</code></td>
<td>

<p>Expression data (or other data) in multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of lists; in
each list there must be a component named <code>data</code> whose content
is a matrix or dataframe or array of dimension 2.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_multitrait">multiTrait</code></td>
<td>

<p>Trait or ourcome data in multi-set format. Only one trait is allowed; consequesntly, the <code>data</code>
component of each component list can be either a vector or a data frame (matrix, array of dimension 2).
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_modulelabels">moduleLabels</code></td>
<td>

<p>Module labels: one label for each gene in <code>multiExpr</code>.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_multieigengenes">multiEigengenes</code></td>
<td>

<p>Optional eigengenes of modules specified in <code>moduleLabels</code>. If not given, will be calculated from
<code>multiExpr</code>.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_usemodules">useModules</code></td>
<td>

<p>Optional specification of module labels to which the analysis should be restricted. This could be useful
if there are many modules, most of which are not interesting. Note that the &quot;grey&quot; module cannot be used
with <code>useModules</code>.</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_corandpvaluefnc">corAndPvalueFnc</code></td>
<td>

<p>Function that calculates associations between expression profiles and eigengenes. See details.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_coroptions">corOptions</code></td>
<td>

<p>List giving additional arguments to function <code>corAndPvalueFnc</code>. See details.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_corcomponent">corComponent</code></td>
<td>

<p>Name of the component of output of <code>corAndPvalueFnc</code> that contains the actual correlation.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_getqvalues">getQvalues</code></td>
<td>

<p>logical: should q-values (estimates of FDR) be calculated?
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_setnames">setNames</code></td>
<td>

<p>names for the input sets. If not given, will be taken from <code>names(multiExpr)</code>. If those are
<code>NULL</code> as well, the names will be <code>"Set_1", "Set_2", ...</code>.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_excludegrey">excludeGrey</code></td>
<td>

<p>logical: should the grey module be excluded from the kME tables? Since the grey module is typically not a
real module, it makes little sense to report kME values for it.
</p>
</td></tr>
<tr><td><code id="multiData.eigengeneSignificance_+3A_greylabel">greyLabel</code></td>
<td>

<p>label that labels the grey module.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a convenience function that calculates module eigengene significances (i.e., correlations of module
eigengenes with a given trait) across all sets in a multi-set analysis. Also returned are p-values, Z
scores, numbers of present (i.e., non-missing) observations for each significance, and optionally the
q-values (false discovery rates) corresponding to the p-values.
</p>
<p>The function <code>corAndPvalueFnc</code> is currently
is expected to accept arguments <code>x</code> (gene expression profiles) and <code>y</code> (eigengene expression
profiles).  Any additional arguments can be passed via <code>corOptions</code>. 
</p>
<p>The function <code>corAndPvalueFnc</code> should return a list which at the least contains (1) a matrix
of associations of genes and eigengenes (this component should have the name given by <code>corComponent</code>), 
and (2) a matrix of the corresponding p-values, named &quot;p&quot; or &quot;p.value&quot;. Other components are optional but
for full functionality should include
(3) <code>nObs</code> giving the number of observations for each association (which is the number of samples less
number of missing data - this can in principle vary from association to association), and (4) <code>Z</code>
giving a Z static for each observation. If these are missing, <code>nObs</code> is calculated in the main
function, and calculations using the Z statistic are skipped.
</p>


<h3>Value</h3>

<p>A list containing the following components. Each component is a matrix in which the rows correspond to
module eigengenes and columns to data sets. Row and column names are set appropriately.
</p>
<table role = "presentation">
<tr><td><code>eigengeneSignificance</code></td>
<td>
<p>Module eigengene significance.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-values (returned by <code>corAndPvalueFnc</code>). </p>
</td></tr>
<tr><td><code>q.value</code></td>
<td>
<p>q-values corresponding to the p-values above. Only returned in input <code>getWvalues</code> is
<code>TRUE</code>. </p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Z statistics (if returned by <code>corAndPvalueFnc</code>). </p>
</td></tr>
<tr><td><code>nObservations</code></td>
<td>
<p>Number of non-missing observations in each correlation/p-value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='multiGSub'>
Analogs of grep(l) and (g)sub for multiple patterns and relacements
</h2><span id='topic+multiGSub'></span><span id='topic+multiSub'></span><span id='topic+multiGrep'></span><span id='topic+multiGrepl'></span>

<h3>Description</h3>

<p>These functions provide convenient pattern finding and substitution for multiple patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiGSub(patterns, replacements, x, ...)
multiSub(patterns, replacements, x, ...)
multiGrep(patterns, x, ..., sort = TRUE, value = FALSE, invert = FALSE)
multiGrepl(patterns, x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiGSub_+3A_patterns">patterns</code></td>
<td>

<p>A character vector of patterns.
</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_replacements">replacements</code></td>
<td>

<p>A character vector of replacements; must be of the same length as <code>patterns</code>.
</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_x">x</code></td>
<td>

<p>Character vector of strings in which the pattern finding and replacements should be carried out.
</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_sort">sort</code></td>
<td>
<p>Logical: should the output indices be sorted in increasing order?</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_value">value</code></td>
<td>
<p>Logical: should value rather than the index of the value be returned?</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_invert">invert</code></td>
<td>
<p>Logical: should the search be inverted and only indices of elements of <code>x</code> matching none
of the patterns be returned?</p>
</td></tr>
<tr><td><code id="multiGSub_+3A_...">...</code></td>
<td>

<p>Other arguments to <code><a href="base.html#topic+sub">sub</a></code> or <code><a href="base.html#topic+grep">grep</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each element of <code>x</code>, patterns are sequentiall searched for and (for <code>multiSub</code> and
<code>multiGSub</code> substituted with the corresponding replacement.
</p>


<h3>Value</h3>

<p><code>multiSub</code> and <code>multiGSub</code> return a character vector of the same length as <code>x</code>, with all
patterns replaces by their replacements in each element of <code>x</code>. <code>multiSub</code> replaces each pattern in
each element of <code>x</code> only once, <code>multiGSub</code> as many times as the pattern is found.
</p>
<p><code>multiGrep</code> returns the indices of those elements in <code>x</code> in which at least one of <code>patterns</code>
was found, or, if <code>invert</code> is TRUE, the indices of elements in which none of the patterns were found. If <code>value</code>
is TRUE, values rather than indices are returned.
</p>
<p><code>multiGrepl</code> returns a logical vector of the same length as <code>x</code>, with <code>TRUE</code> is any of the
patterns matched the element of <code>x</code>, and <code>FALSE</code> otherwise. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The workhorse functions <code><a href="base.html#topic+sub">sub</a></code>, <code><a href="base.html#topic+gsub">gsub</a></code>, <code><a href="base.html#topic+grep">grep</a></code> and <code><a href="base.html#topic+grepl">grepl</a></code>.
</p>

<hr>
<h2 id='multiSetMEs'>Calculate module eigengenes. </h2><span id='topic+multiSetMEs'></span>

<h3>Description</h3>

<p>Calculates module eigengenes for several sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiSetMEs(exprData, 
            colors, 
            universalColors = NULL, 
            useSets = NULL, 
            useGenes = NULL,
            impute = TRUE, 
            nPC = 1, 
            align = "along average", 
            excludeGrey = FALSE,
            grey = if (is.null(universalColors)) {
                       if (is.numeric(colors)) 0 else "grey"
                   } else
                       if (is.numeric(universalColors)) 0 else "grey",
            subHubs = TRUE,
            trapErrors = FALSE, 
            returnValidOnly = trapErrors,
            softPower = 6,
            verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiSetMEs_+3A_exprdata">exprData</code></td>
<td>
<p>Expression data in a multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of lists,
with each list corresponding to one microarray dataset and expression data in the component <code>data</code>,
that is <code>expr[[set]]$data[sample, probe]</code> is the expression of probe <code>probe</code> in sample
<code>sample</code> in dataset <code>set</code>. The number of samples can be different between the sets, but the
probes must be the same. </p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_colors">colors</code></td>
<td>
<p>A matrix of dimensions (number of probes, number of sets) giving the module assignment of
each gene in each set. The color &quot;grey&quot; is interpreted as unassigned.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_universalcolors">universalColors</code></td>
<td>
<p>Alternative specification of module assignment. A single vector of length
(number of probes) giving the module assignment of each gene in all sets (that is the modules are common
to all sets). If given, takes precedence over <code>color</code>.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_usesets">useSets</code></td>
<td>
<p>If calculations are requested in (a) selected set(s) only, the set(s) can be specified
here. Defaults to all sets.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_usegenes">useGenes</code></td>
<td>
<p>Can be used to restrict calculation to a subset of genes (the same subset in all
sets). If given, <code>validColors</code> in the returned list will only contain colors for the genes
specified in <code>useGenes</code>.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_impute">impute</code></td>
<td>
<p>Logical. If <code>TRUE</code>, expression data will be checked for the presence of <code>NA</code>
entries and if the latter are present, numerical data will be imputed, using function <code>impute.knn</code>
and probes from the same module as the missing datum. The function <code>impute.knn</code> uses a fixed random
seed giving repeatable results.</p>
</td></tr> 
<tr><td><code id="multiSetMEs_+3A_npc">nPC</code></td>
<td>
<p>Number of principal components to be calculated. If only eigengenes are needed, it is best
to set it to 1 (default). If variance explained is needed as well, use value <code>NULL</code>. This will cause
all principal components to be computed, which is slower.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_align">align</code></td>
<td>
<p>Controls whether eigengenes, whose orientation is undetermined, should be aligned with
average expression (<code>align = "along average"</code>, the default) or left as they are (<code>align = ""</code>).
Any other value will trigger an error.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_excludegrey">excludeGrey</code></td>
<td>
<p>Should the improper module consisting of 'grey' genes be excluded from the
eigengenes?</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_grey">grey</code></td>
<td>
<p>Value of <code>colors</code> or <code>universalColors</code> (whichever applies)
designating the improper module. Note that if the appropriate colors argument is a
factor of numbers, the default value will be incorrect.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_subhubs">subHubs</code></td>
<td>
<p>Controls whether hub genes should be substituted for missing eigengenes. If
<code>TRUE</code>, each missing eigengene (i.e., eigengene whose calculation failed and the error
was trapped) will be replaced by a weighted average of the most connected hub genes in the
corresponding module. If this calculation fails, or if <code>subHubs==FALSE</code>, the value of
<code>trapErrors</code> will determine whether the offending module
will be removed or whether the function will issue an error and stop.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_traperrors">trapErrors</code></td>
<td>
<p>Controls handling of errors from that may arise when there are too many
<code>NA</code> entries in expression data. If <code>TRUE</code>, errors from calling these functions will be
trapped without abnormal exit.
If <code>FALSE</code>, errors will cause the function to stop. Note, however, that <code>subHubs</code> takes
precedence in the sense that if <code>subHubs==TRUE</code> and <code>trapErrors==FALSE</code>, an error will be
issued only if both the principal component and the hubgene calculations have failed. </p>
</td></tr> 
<tr><td><code id="multiSetMEs_+3A_returnvalidonly">returnValidOnly</code></td>
<td>
<p>Boolean. Controls whether the returned data frames of module eigengenes 
contain columns
corresponding only to modules whose eigengenes or hub genes could be calculated correctly in every
set (<code>TRUE</code>), or whether
the data frame should have columns for each of the input color labels (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_softpower">softPower</code></td>
<td>
<p>The power used in soft-thresholding the adjacency matrix. Only used when the
hubgene approximation is necessary because the principal component calculation failed. It must be
non-negative. The default
value should only be changed if there is a clear indication that it leads to incorrect results.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity of printed progress messages. 0 means silent, up to (about) 5 the
verbosity gradually increases.</p>
</td></tr>
<tr><td><code id="multiSetMEs_+3A_indent">indent</code></td>
<td>
<p>A single non-negative integer controlling indentation of printed messages. 0 means no
indentation, each unit above that adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls <code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for each set in <code>exprData</code>.
</p>
<p>Module eigengene is defined as the first principal component of the expression matrix of the
corresponding module. The calculation may fail if the expression data has too many missing entries.
Handling of such errors is controlled by the arguments <code>subHubs</code> and
<code>trapErrors</code>.
If <code>subHubs==TRUE</code>, errors in principal component calculation will be trapped and a substitute
calculation of hubgenes will be attempted. If this fails as well, behaviour depends on
<code>trapErrors</code>: if <code>TRUE</code>, the offending
module will be ignored and the return value will allow the user to remove the module from further
analysis; if <code>FALSE</code>, the function will stop.
If <code>universalColors</code> is given, any offending
module will be removed from all sets (see <code>validMEs</code> in return value below). 
</p>
<p>From the user's point of view, setting <code>trapErrors=FALSE</code> ensures that if the function returns
normally, there will be a valid eigengene (principal component or hubgene) for each of the input
colors. If the user sets <code>trapErrors=TRUE</code>, all calculational (but not input) errors will be
trapped, but the user should check the output (see below) to make sure all modules have a valid
returned eigengene.
</p>
<p>While the principal component calculation can fail even on relatively sound data
(it does not take all that many &quot;well-placed&quot; <code>NA</code> to torpedo the
calculation),
it takes many more irregularities in the data for the hubgene calculation to
fail. In fact such a failure signals there likely is something seriously wrong with the data.
</p>


<h3>Value</h3>

<p>A vector of lists similar in spirit to the input <code>exprData</code>. For each set there is a list with the
following components:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Module eigengenes in a data frame, with each column corresponding to one eigengene.
The columns are named by the corresponding color with an <code>"ME"</code> prepended, e.g., <code>MEturquoise</code>
etc. Note that, when <code>trapErrors == TRUE</code> and <code>returnValidOnly==FALSE</code>, 
this data frame also contains entries corresponding to 
removed modules, if any. (<code>validMEs</code> below indicates which eigengenes are valid and <code>allOK</code>
whether all module eigengens were successfully calculated.) </p>
</td></tr>
<tr><td><code>averageExpr</code></td>
<td>
<p>If <code>align == "along average"</code>, a dataframe containing average normalized
expression in each module. The columns are named by the corresponding color with an <code>"AE"</code>
prepended, e.g., <code>AEturquoise</code> etc.</p>
</td></tr>
<tr><td><code>varExplained</code></td>
<td>
<p>A dataframe in which each column corresponds to a module, with the component
<code>varExplained[PC, module]</code> giving the variance of module <code>module</code> explained by the principal
component no. <code>PC</code>. This is only accurate if all principal components have been computed (input
<code>nPC = NULL</code>). At most 5 principal components are recorded in this dataframe.</p>
</td></tr>
<tr><td><code>nPC</code></td>
<td>
<p>A copy of the input <code>nPC</code>.</p>
</td></tr>
<tr><td><code>validMEs</code></td>
<td>
<p>A boolean vector. Each component (corresponding to the columns in <code>data</code>)
is <code>TRUE</code> if the corresponding eigengene is valid, and <code>FALSE</code>
if it is invalid. Valid eigengenes include both principal components and their hubgene
approximations.
When <code>returnValidOnly==FALSE</code>, by definition all returned eigengenes are valid and the
entries of <code>validMEs</code> are all <code>TRUE</code>. </p>
</td></tr>
<tr><td><code>validColors</code></td>
<td>
<p>A copy of the input colors (<code>universalColors</code> if set, otherwise 
<code>colors[, set]</code>) with entries corresponding to invalid modules set to
<code>grey</code> if given, otherwise 0 if the appropriate input colors are numeric and &quot;grey&quot; otherwise.</p>
</td></tr>
<tr><td><code>allOK</code></td>
<td>
<p>Boolean flag signalling whether all eigengenes have been calculated correctly, either
as principal components or as the hubgene approximation. If <code>universalColors</code> is set, this flag
signals whether all eigengenes are valid in all sets.</p>
</td></tr>
<tr><td><code>allPC</code></td>
<td>
<p>Boolean flag signalling whether all returned eigengenes are principal components.
This flag (as well as the subsequent ones) is set independently for each set.</p>
</td></tr>
<tr><td><code>isPC</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding eigengene is the first principal component and <code>FALSE</code> if it
is the hubgene approximation or is invalid. </p>
</td></tr>
<tr><td><code>isHub</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding eigengene is the hubgene approximation and <code>FALSE</code> if it
is the first principal component or is invalid.</p>
</td></tr>
<tr><td><code>validAEs</code></td>
<td>
<p>Boolean vector. Each component (corresponding to the columns in <code>eigengenes</code>) is
<code>TRUE</code> if the corresponding module average expression is valid.</p>
</td></tr>
<tr><td><code>allAEOK</code></td>
<td>
<p>Boolean flag signalling whether all returned module average expressions contain
valid data. Note that <code>returnValidOnly==TRUE</code> does not imply <code>allAEOK==TRUE</code>: 
some invalid average expressions may be
returned if their corresponding eigengenes have been calculated correctly.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code></p>

<hr>
<h2 id='multiUnion'>
Union and intersection of multiple sets
</h2><span id='topic+multiUnion'></span><span id='topic+multiIntersect'></span>

<h3>Description</h3>

<p>Union and intersection of multiple sets. These function generalize the standard functions
<code><a href="base.html#topic+union">union</a></code> and <code><a href="base.html#topic+intersect">intersect</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiUnion(setList)
multiIntersect(setList)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiUnion_+3A_setlist">setList</code></td>
<td>

<p>A list containing the sets to be performed upon.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The union or intersection of the given sets.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The &quot;standard&quot; functions <code><a href="base.html#topic+union">union</a></code> and <code><a href="base.html#topic+intersect">intersect</a></code>.
</p>

<hr>
<h2 id='mutualInfoAdjacency'>Calculate weighted adjacency matrices based on mutual information</h2><span id='topic+mutualInfoAdjacency'></span>

<h3>Description</h3>

<p>The function calculates different types of weighted adjacency matrices based on the mutual information
between vectors (corresponding to the columns of the input data frame datE).  The mutual information between
pairs of vectors is divided by an upper bound so that the resulting normalized measure lies between 0 and 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mutualInfoAdjacency(
   datE, 
   discretizeColumns = TRUE, 
   entropyEstimationMethod = "MM", 
   numberBins = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mutualInfoAdjacency_+3A_date">datE</code></td>
<td>
 <p><code>datE</code> is a data frame or matrix whose columns correspond to variables and whose rows correspond to measurements. For example, the columns may correspond to genes while the rows correspond to microarrays. The number of nodes in the mutual information network equals the number of columns of <code>datE</code>.
</p>
</td></tr>
<tr><td><code id="mutualInfoAdjacency_+3A_discretizecolumns">discretizeColumns</code></td>
<td>
<p> is a logical variable. If it is set to TRUE then the columns of <code>datE</code>  will be discretized into a user-defined number of bins (see <code>numberBins</code>).  
</p>
</td></tr>
<tr><td><code id="mutualInfoAdjacency_+3A_entropyestimationmethod">entropyEstimationMethod</code></td>
<td>
<p> takes a text string for specifying the entropy and mutual information estimation method. If <code>entropyEstimationMethod="MM"</code> then the Miller-Madow asymptotic bias corrected empirical estimator is used. 
If <code>entropyEstimationMethod="ML"</code> the maximum likelihood estimator (also known as plug-in or empirical estimator) is used.
If  <code>entropyEstimationMethod="shrink"</code>, the shrinkage estimator of a Dirichlet probability distribution is used.
If  <code>entropyEstimationMethod="SG"</code>, the Schurmann-Grassberger estimator of the entropy of a Dirichlet probability distribution is used.
</p>
</td></tr>
<tr><td><code id="mutualInfoAdjacency_+3A_numberbins">numberBins</code></td>
<td>
<p> is an integer larger than 0 which specifies how many bins are used for the discretization step. This argument is only relevant if <code>discretizeColumns</code> has been set to TRUE. By default <code>numberBins</code> is set to sqrt(m) where m is the number of samples, i.e. the number of rows of <code>datE</code>. Thus the default is <code>numberBins</code>=sqrt(nrow(datE)).   
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function inputs a data frame <code>datE</code> and outputs a list whose components correspond to different weighted network adjacency measures defined beteween the columns of <code>datE</code>. Make sure to install the following R packages <code>entropy</code>, <code>minet</code>, <code>infotheo</code> since 
the function <code>mutualInfoAdjacency</code> makes use of the <code>entropy</code> function from the R package <code>entropy</code> (Hausser and Strimmer 2008) and functions from the <code>minet</code> and <code>infotheo</code> package (Meyer et al 2008). 
A weighted network adjacency matrix is a symmetric matrix whose entries take on values between 0 and 1. Each weighted adjacency matrix contains scaled versions of the mutual information between the columns of the input data frame <code>datE</code>.
We assume that datE contains numeric values which will be discretized unless the user chooses the option <code>discretizeColumns=FALSE</code>.
The raw (unscaled) mutual information and entropy measures have units &quot;nat&quot;, i.e. natural logarithms are used in their definition (base e=2.71..).  
Several mutual information estimation methods have been proposed in the literature (reviewed in Hausser and Strimmer 2008, Meyer et al 2008). 
While mutual information networks allows one to detect non-linear relationships between the columns of <code>datE</code>, they may overfit the data if relatively few observations are available. Thus, if the number of rows of <code>datE</code> is smaller than say 200, it may be better to fit a correlation using the function <code>adjacency</code>.
</p>


<h3>Value</h3>

<p>The function outputs a list with the following components:
</p>
<table role = "presentation">
<tr><td><code>Entropy</code></td>
<td>
<p>   is a vector whose components report entropy estimates of each column of <code>datE</code>. The natural logarithm (base e) is used in the definition. Using the notation from the Wikipedia entry (http://en.wikipedia.org/wiki/Mutual_information), this vector contains the values Hx where x corresponds to a column in <code>datE</code>.
</p>
</td></tr>
<tr><td><code>MutualInformation</code></td>
<td>
<p>   is a symmetric matrix whose entries contain the pairwise mutual information
measures between the columns of <code>datE</code>. The diagonal of the matrix <code>MutualInformation</code> equals
<code>Entropy</code>. In general, the entries of this matrix can be larger than 1, i.e. this is not an adjacency
matrix. Using the notation from the Wikipedia entry, this matrix contains the mutual information estimates
I(X;Y)  </p>
</td></tr> 
<tr><td><code>AdjacencySymmetricUncertainty</code></td>
<td>
<p>   is a weighted adjacency matrix whose entries are based on the mutual
information. Using the notation from the Wikipedia entry, this matrix contains the mutual information
estimates <code>AdjacencySymmetricUncertainty</code>=2*I(X;Y)/(H(X)+H(Y)). Since I(X;X)=H(X), the diagonal
elements of <code>AdjacencySymmetricUncertainty</code> equal 1. In general the entries of this symmetric matrix
<code>AdjacencySymmetricUncertainty</code> lie between 0 and 1. 
</p>
</td></tr> 
<tr><td><code>AdjacencyUniversalVersion1</code></td>
<td>
<p> is a weighted adjacency matrix that is a simple function of the
<code>AdjacencySymmetricUncertainty</code>. Specifically, <code>AdjacencyUniversalVersion1=
AdjacencySymmetricUncertainty/(2- AdjacencySymmetricUncertainty)</code>. Note that f(x)= x/(2-x) is a
monotonically increasing function on the unit interval [0,1] whose values lie between 0 and 1. The reason
why we call it the universal adjacency is that dissUA=1-<code>AdjacencyUniversalVersion1</code> turns out to be
a universal distance function, i.e. it satisfies the properties of a distance (including the triangle
inequality) and it takes on a small value if any other distance measure takes on a small value (Kraskov et
al 2003). 
</p>
</td></tr>
<tr><td><code>AdjacencyUniversalVersion2</code></td>
<td>
<p> is a weighted adjacency matrix for which dissUAversion2=1-<code>AdjacencyUniversalVersion2</code> is also a universal distance measure. Using the notation from Wikipedia, the entries of the symmetric matrix AdjacencyUniversalVersion2 are defined as follows
<code>AdjacencyUniversalVersion2</code>=I(X;Y)/max(H(X),H(Y)).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath, Lin Song, Peter Langfelder
</p>


<h3>References</h3>

<p>Hausser J, Strimmer K (2008) Entropy inference and the James-Stein 	estimator, with application to nonlinear gene association networks. See 	http://arxiv.org/abs/0811.3579
</p>
<p>Patrick E. Meyer, Frederic Lafitte, and Gianluca Bontempi. minet: A R/Bioconductor Package for Inferring Large Transcriptional Networks Using Mutual Information. BMC Bioinformatics, Vol 9, 2008
</p>
<p>Kraskov A, Stoegbauer H, Andrzejak RG, Grassberger P (2003) Hierarchical Clustering Based on Mutual Information. ArXiv q-bio/0311039
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjacency">adjacency</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load requisite packages. These packages are considered "optional", 
# so WGCNA does not load them automatically.

if (require(infotheo, quietly = TRUE) &amp;&amp; 
    require(minet, quietly = TRUE) &amp;&amp; 
    require(entropy, quietly = TRUE))
{
  # Example can be executed.
  #Simulate a data frame datE which contains 5 columns and 50 observations
  m=50
  x1=rnorm(m)
  r=.5; x2=r*x1+sqrt(1-r^2)*rnorm(m)
  r=.3; x3=r*(x1-.5)^2+sqrt(1-r^2)*rnorm(m)
  x4=rnorm(m)
  r=.3; x5=r*x4+sqrt(1-r^2)*rnorm(m)
  datE=data.frame(x1,x2,x3,x4,x5)
  
  #calculate entropy, mutual information matrix and weighted adjacency 
  # matrices based on mutual information.
  MIadj=mutualInfoAdjacency(datE=datE)
} else 
  printFlush(paste("Please install packages infotheo, minet and entropy",
                   "before running this example."));

</code></pre>

<hr>
<h2 id='nearestCentroidPredictor'>
Nearest centroid predictor
</h2><span id='topic+nearestCentroidPredictor'></span>

<h3>Description</h3>

<p>Nearest centroid predictor for binary (i.e., two-outcome) data. Implements a whole host of options and
improvements such as accounting for within-class heterogeneity using sample networks, 
various ways of feature selection and weighing etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearestCentroidPredictor(

    # Input training and test data
    x, y, 
    xtest = NULL, 

    # Feature weights and selection criteria
    featureSignificance = NULL, 
    assocFnc = "cor", assocOptions = "use = 'p'", 
    assocCut.hi = NULL, assocCut.lo = NULL, 
    nFeatures.hi = 10, nFeatures.lo = 10,
    weighFeaturesByAssociation = 0, 
    scaleFeatureMean = TRUE, scaleFeatureVar = TRUE, 

    # Predictor options 
    centroidMethod = c("mean", "eigensample"), 
    simFnc = "cor", simOptions = "use = 'p'", 
    useQuantile = NULL, 
    sampleWeights = NULL, 
    weighSimByPrediction = 0, 

    # What should be returned
    CVfold = 0, returnFactor = FALSE, 

    # General options
    randomSeed = 12345, 
    verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nearestCentroidPredictor_+3A_x">x</code></td>
<td>

<p>Training features (predictive variables). Each column corresponds to a feature and each row to an
observation.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_y">y</code></td>
<td>

<p>The response variable. Can be a single vector or a matrix with arbitrary many columns. Number of rows
(observations) must equal to the number of rows (observations) in x.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_xtest">xtest</code></td>
<td>

<p>Optional test set data. A matrix of the same number of columns (i.e., features) as <code>x</code>.
If test set data are not given, only the prediction on training data will be returned.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_featuresignificance">featureSignificance</code></td>
<td>

<p>Optional vector of feature significance for the response variable. If given, it is used for feature
selection (see details). Should preferably be signed, that is features can have high negative significance.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_assocfnc">assocFnc</code></td>
<td>

<p>Character string specifying the association function. The association function should behave roughly as
<code>link{cor}</code> in that it takes two arguments
(a matrix and a vector) plus options 
and returns the vector of associations between the columns of the matrix and the
vector. The associations may be signed (i.e., negative or positive). 
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_assocoptions">assocOptions</code></td>
<td>

<p>Character string specifying options to the association function.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_assoccut.hi">assocCut.hi</code></td>
<td>

<p>Association (or featureSignificance) threshold for including features in the predictor. Features with
associtation higher than <code>assocCut.hi</code> will be included. If not given, the threshold method will not be
used; instead, a fixed number of features will be included as specified by <code>nFeatures.hi</code>
and <code>nFeatures.lo</code>.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_assoccut.lo">assocCut.lo</code></td>
<td>

<p>Association (or featureSignificance) threshold for including features in the predictor. Features with 
associtation lower than <code>assocCut.lo</code> will be included. If not given, defaults to <code>-assocCut.hi</code>.
If <code>assocCut.hi</code> is <code>NULL</code>, the threshold method will not be
used; instead, a fixed number of features will be included as specified by <code>nFeatures.hi</code> and
<code>nFeatures.lo</code>. 
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_nfeatures.hi">nFeatures.hi</code></td>
<td>

<p>Number of highest-associated features (or features with highest <code>featureSignificance</code>) to include in the
predictor. Only used if <code>assocCut.hi</code> is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_nfeatures.lo">nFeatures.lo</code></td>
<td>

<p>Number of lowest-associated features (or features with highest <code>featureSignificance</code>) to include in
the predictor. Only used if <code>assocCut.hi</code> is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_weighfeaturesbyassociation">weighFeaturesByAssociation</code></td>
<td>

<p>(Optional) power to downweigh features that are less associated with the response. See details.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_scalefeaturemean">scaleFeatureMean</code></td>
<td>

<p>Logical: should the training features be scaled to mean zero? Unless there are good reasons not to scale,
the features should be scaled.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_scalefeaturevar">scaleFeatureVar</code></td>
<td>

<p>Logical: should the training features be scaled to unit variance? Again, unless there are good reasons not
to scale, the features should be scaled.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_centroidmethod">centroidMethod</code></td>
<td>

<p>One of <code>"mean"</code> and <code>"eigensample"</code>, specifies how the centroid should be calculated.
<code>"mean"</code> takes the mean across all samples (or all samples within a sample module, if sample networks
are used), whereas <code>"eigensample"</code> calculates the first principal component of the feature matrix and
uses that as the centroid.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_simfnc">simFnc</code></td>
<td>

<p>Character string giving the similarity function for measuring the similarity between test samples and
centroids. This function should
behave roughly like the function <code><a href="#topic+cor">cor</a></code> in that it takes two arguments (<code>x</code>, <code>y</code>)
and calculates the pair-wise similarities between columns of <code>x</code> and <code>y</code>. For convenience, the
value <code>"dist"</code> is treated specially: the Euclidean distance between the columns of <code>x</code> and
<code>y</code> is calculated and its negative is returned (so that smallest distance corresponds to highest
similarity). Since values of this function are only used for ranking centroids, its values are not
restricted to be positive or within certain bounds.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_simoptions">simOptions</code></td>
<td>

<p>Character string specifying the options to the similarity function.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_usequantile">useQuantile</code></td>
<td>

<p>If non-NULL, the &quot;nearest quantiloid&quot; will be used instead of the nearest centroid. See details.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_sampleweights">sampleWeights</code></td>
<td>

<p>Optional specification of sample weights. Useful for example if one wants to explore boosting.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_weighsimbyprediction">weighSimByPrediction</code></td>
<td>

<p>(Optional) power to downweigh features that are not well predicted between training and test sets. See
details.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_cvfold">CVfold</code></td>
<td>

<p>Non-negative integer specifying cross-validation. Zero means no cross-validation will be performed. values
above zero specify the number of samples to be considered test data for each step of cross-validation.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_returnfactor">returnFactor</code></td>
<td>

<p>Logical: should a factor be returned?
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_randomseed">randomSeed</code></td>
<td>

<p>Integere specifying the seed for the random number generator. If <code>NULL</code>, the seed will not be set. See
<code><a href="base.html#topic+set.seed">set.seed</a></code>.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_verbose">verbose</code></td>
<td>

<p>Integer controling how verbose the diagnostic messages should be. Zero means silent.
</p>
</td></tr>
<tr><td><code id="nearestCentroidPredictor_+3A_indent">indent</code></td>
<td>

<p>Indentation for the diagnostic messages. Zero means no indentation, each unit adds two spaces.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nearest centroid predictor works by forming a representative profile (centroid) 
across features for each class from
the training data, then assigning each test sample to the class of the nearest representative profile. The
representative profile can be formed either as mean or as athe first principal component (&quot;eigensample&quot;;
this choice is governed by the option <code>centroidMethod</code>).
</p>
<p>When the number of features is large and only a small fraction is likely to be associated with the outcome, 
feature selection can be used to restrict the features that actually enter the centroid. Feature selection
can be based either on their association with the outcome
calculated from the training data using <code>assocFnc</code>, or on user-supplied feature significance (e.g.,
derived from literature, argument
<code>featureSignificance</code>). In either case, features can be selected by high and low association tresholds 
or by taking a fixed number of highest- and lowest-associated features. 
</p>
<p>As an alternative to centroids, the predictor can also assign test samples based on a given quantile of the
distances from the training samples in each class (argument <code>useQuantile</code>). This may be advantageous if
the samples in each class form irregular clusters. Note that setting <code>useQuantile=0</code> (i.e., using
minimum distance in each class) essentially gives a nearest neighbor predictor: each test sample will be
assigned to the class of its nearest training neighbor.
</p>
<p>If features exhibit non-trivial correlations among themselves (such as, for example, in gene expression
data), one can attempt to down-weigh features that do not exhibit the same correlation in the test set.
This is done by using essentially the same predictor to predict _features_ from all other features in the
test data (using the training data to train the feature predictor). Because test features are known, the
prediction accuracy can be evaluated. If a feature is predicted badly (meaning the error in the test set is
much larger than the error in the cross-validation prediction in training data),
it may mean that its quality in the
training or test data is low (for example, due to excessive noise or outliers).
Such features can be downweighed using the argument <code>weighByPrediction</code>. The extra factor is
min(1, (root mean square prediction error in test set)/(root mean square cross-validation prediction error
in
the trainig data)^weighByPrediction), that is it is never bigger than 1.
</p>
<p>Unless the features' mean and variance can be ascribed clear meaning, the (training) features should be
scaled to mean 0 and variance 1 before the centroids are formed. 
</p>
<p>The function implements a basic option for removal of spurious effects in the training and test data, by
removng a fixed number of leading principal components from the features. This sometimes leads to better
prediction accuracy but should be used with caution.
</p>
<p>If samples within each class are heterogenous, a single centroid may not represent each class well. This
function can deal with within-class heterogeneity by clustering samples (separately in each class), then
using a one representative (mean, eigensample) or quantile for each cluster in each class to assign test
samples. Various similarity measures, specified by <code>adjFnc</code>, can be used to construct the sample network
adjacency. Similarly, the user can specify a clustering function using <code>clusteringFnc</code>. The
requirements on the clustering function are described in a separate section below.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>predicted</code></td>
<td>
<p>The back-substitution prediction in the training set.</p>
</td></tr>
<tr><td><code>predictedTest</code></td>
<td>
<p>Prediction in the test set.</p>
</td></tr>
<tr><td><code>featureSignificance</code></td>
<td>
<p>A vector of feature significance calculated by <code>assocFnc</code> or a copy of the
input <code>featureSignificance</code> if the latter is non-NULL.</p>
</td></tr>
<tr><td><code>selectedFeatures</code></td>
<td>
<p>A vector giving the indices of the features that were selected for the predictor.</p>
</td></tr>
<tr><td><code>centroidProfile</code></td>
<td>
<p>The representative profiles of each class (or cluster). Only returned in
<code>useQuntile</code> is <code>NULL</code>. </p>
</td></tr>
<tr><td><code>testSample2centroidSimilarities</code></td>
<td>
<p>A matrix of calculated similarities between the test samples and
class/cluster centroids.</p>
</td></tr>
<tr><td><code>featureValidationWeights</code></td>
<td>
<p>A vector of validation weights (see Details) for the selected features. If
<code>weighFeaturesByValidation</code> is 0, a unit vector is used and returned.</p>
</td></tr>
<tr><td><code>CVpredicted</code></td>
<td>
<p>Cross-validation prediction on the training data. Present only if <code>CVfold</code> is
non-zero.</p>
</td></tr>
<tr><td><code>sampleClusterLabels</code></td>
<td>
<p>A list with two components (one per class). Each component is a vector of sample
cluster labels for samples in the class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+votingLinearPredictor">votingLinearPredictor</a></code>
</p>

<hr>
<h2 id='nearestNeighborConnectivity'> Connectivity to a constant number of nearest neighbors </h2><span id='topic+nearestNeighborConnectivity'></span>

<h3>Description</h3>

<p>Given expression data and basic network parameters, the function calculates connectivity of each gene
to a given number of nearest neighbors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearestNeighborConnectivity(datExpr, 
         nNeighbors = 50, power = 6, type = "unsigned", 
         corFnc = "cor", corOptions = "use = 'p'", 
         blockSize = 1000,
         sampleLinks = NULL, nLinks = 5000, setSeed = 38457,
         verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nearestNeighborConnectivity_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing expression data, with rows corresponding to samples and columns
to genes. Missing values are allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_nneighbors">nNeighbors</code></td>
<td>
<p> number of nearest neighbors to use. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_power">power</code></td>
<td>
<p> soft thresholding power for network construction. Should be a number greater than 1. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_type">type</code></td>
<td>
<p> a character string encoding network type. Recognized values are (unique abbreviations of) 
<code>"unsigned"</code>, <code>"signed"</code>, and <code>"signed hybrid"</code>. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_corfnc">corFnc</code></td>
<td>
<p> character string containing the name of the function to calculate correlation. Suggested
functions include <code>"cor"</code> and <code>"bicor"</code>. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_coroptions">corOptions</code></td>
<td>
<p> further argument to the correlation function. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_blocksize">blockSize</code></td>
<td>
<p> correlation calculations will be split into square blocks of this size, to prevent
running out of memory for large gene sets.  </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_samplelinks">sampleLinks</code></td>
<td>
<p> logical: should network connections be sampled (<code>TRUE</code>) or should all
connections be used systematically (<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_nlinks">nLinks</code></td>
<td>
<p> number of links to be sampled. Should be set such that <code>nLinks * nNeighbors</code> be
several times larger than the number of genes. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_setseed">setSeed</code></td>
<td>
<p> seed to be used for sampling, for repeatability. If a seed already exists, it is saved
before the sampling starts and restored upon exit. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_verbose">verbose</code></td>
<td>
<p> integer controlling the level of verbosity. 0 means silent.</p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivity_+3A_indent">indent</code></td>
<td>
<p> integer controlling indentation of output. Each unit above 0 adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Connectivity of gene <code>i</code> is the sum of adjacency strengths between gene <code>i</code> 
and other genes; in
this case we take the <code>nNeighbors</code> nodes with the highest connection strength to gene <code>i</code>. The
adjacency strengths are calculated by correlating the given expression data using the function supplied
in <code>corFNC</code> and transforming them into adjacency according to the given network <code>type</code> and
<code>power</code>. 
</p>


<h3>Value</h3>

<p>A vector with one component for each gene containing the nearest neighbor connectivity. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+softConnectivity">softConnectivity</a></code> </p>

<hr>
<h2 id='nearestNeighborConnectivityMS'> Connectivity to a constant number of nearest neighbors across multiple data sets </h2><span id='topic+nearestNeighborConnectivityMS'></span>

<h3>Description</h3>

<p>Given expression data from several sets and basic network parameters, the function calculates
connectivity of each gene to a given number of nearest neighbors in each set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearestNeighborConnectivityMS(multiExpr, nNeighbors = 50, power = 6, 
          type = "unsigned", corFnc = "cor", corOptions = "use = 'p'", 
          blockSize = 1000,
          sampleLinks = NULL, nLinks = 5000, setSeed = 36492,
          verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nearestNeighborConnectivityMS_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in multi-set format. A vector of lists, one list per set. In each list
there must be a component named <code>data</code> whose content
is a matrix or dataframe or array of dimension 2 containing the expression data. Rows correspond to
samples and columns to genes (probes). </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_nneighbors">nNeighbors</code></td>
<td>
<p> number of nearest neighbors to use. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_power">power</code></td>
<td>
<p> soft thresholding power for network construction. Should be a number greater than 1. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_type">type</code></td>
<td>
<p> a character string encoding network type. Recognized values are (unique abbreviations of)
<code>"unsigned"</code>, <code>"signed"</code>, and <code>"signed hybrid"</code>. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_corfnc">corFnc</code></td>
<td>
<p> character string containing the name of the function to calculate correlation. Suggested
functions include <code>"cor"</code> and <code>"bicor"</code>. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_coroptions">corOptions</code></td>
<td>
<p> further argument to the correlation function. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_blocksize">blockSize</code></td>
<td>
<p> correlation calculations will be split into square blocks of this size, to prevent
running out of memory for large gene sets.  </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_samplelinks">sampleLinks</code></td>
<td>
<p> logical: should network connections be sampled (<code>TRUE</code>) or should all
connections be used systematically (<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_nlinks">nLinks</code></td>
<td>
<p> number of links to be sampled. Should be set such that <code>nLinks * nNeighbors</code> be
several times larger than the number of genes. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_setseed">setSeed</code></td>
<td>
<p> seed to be used for sampling, for repeatability. If a seed already exists, it is saved
before the sampling starts and restored after. </p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_verbose">verbose</code></td>
<td>
<p> integer controlling the level of verbosity. 0 means silent.</p>
</td></tr>
<tr><td><code id="nearestNeighborConnectivityMS_+3A_indent">indent</code></td>
<td>
<p> integer controlling indentation of output. Each unit above 0 adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Connectivity of gene <code>i</code> is the sum of adjacency strengths between gene <code>i</code>           
and other genes; in
this case we take the <code>nNeighbors</code> nodes with the highest connection strength to gene <code>i</code>. The
adjacency strengths are calculated by correlating the given expression data using the function supplied
in <code>corFNC</code> and transforming them into adjacency according to the given network <code>type</code> and
<code>power</code>.
</p>


<h3>Value</h3>

<p>A matrix in which columns correspond to sets and rows to genes; each entry contains the nearest
neighbor connectivity of the corresponding gene.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+softConnectivity">softConnectivity</a></code>, 
<code><a href="#topic+nearestNeighborConnectivity">nearestNeighborConnectivity</a></code> </p>

<hr>
<h2 id='networkConcepts'> Calculations of network concepts</h2><span id='topic+networkConcepts'></span>

<h3>Description</h3>

<p>This functions calculates various network concepts (topological properties, network indices) of a
network calculated from expression data. See details for a detailed description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>networkConcepts(datExpr, power = 1, trait = NULL, networkType = "unsigned")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="networkConcepts_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containg the expression data, with rows corresponding to samples and
columns to genes (nodes). </p>
</td></tr>
<tr><td><code id="networkConcepts_+3A_power">power</code></td>
<td>
<p> soft thresholding power.</p>
</td></tr>
<tr><td><code id="networkConcepts_+3A_trait">trait</code></td>
<td>
<p>optional specification of a sample trait. A vector of length equal the number of samples
in <code>datExpr</code>. </p>
</td></tr>
<tr><td><code id="networkConcepts_+3A_networktype">networkType</code></td>
<td>
<p> network type. Recognized values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, and <code>"signed hybrid"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes various network concepts (also known as network statistics, topological
properties, or network indices) for a weighted correlation network. The nodes of the weighted correlation
network will be constructed between the columns (interpreted as nodes) of the input <code>datExpr</code>. 
If the option
<code>networkType="unsigned"</code> then the adjacency between nodes i and j is defined as
<code>A[i,j]=abs(cor(datExpr[,i],datExpr[,j]))^power</code>.
In the following, we use the term gene and node interchangeably since these methods were originally
developed for gene networks. The function computes the following
4 types of network concepts (introduced in Horvath and Dong 2008):
</p>
<p>Type I: fundamental network concepts are defined as a function of the off-diagonal elements of an
adjacency matrix A and/or a node significance measure GS. These network concepts can be defined for  any
network (not just correlation networks).
The adjacency matrix of an unsigned weighted correlation network is given by
<code>A=abs(cor(datExpr,use="p"))^power</code> and the trait based gene significance measure is given by 
<code>GS= abs(cor(datExpr,trait, use="p"))^power</code> where <code>datExpr</code>, <code>trait</code>, <code>power</code>
are input parameters.
</p>
<p>Type II: conformity-based network concepts are functions of the off-diagonal elements of the conformity
based adjacency matrix <code>A.CF=CF*t(CF)</code> and/or the node significance measure. These network concepts
are
defined for any network for which a conformity vector can be defined. Details: For any adjacency matrix
<code>A</code>, the conformity vector <code>CF</code> is calculated by requiring that <code>A[i,j]</code> is 
approximately equal to <code>CF[i]*CF[j]</code>.
Using the conformity one can define the matrix <code>A.CF=CF*t(CF)</code> which is the outer product of 
the conformity
vector with itself. In general, <code>A.CF</code> is not an adjacency matrix since its diagonal elements 
are different
from 1. If the off-diagonal elements of <code>A.CF</code> are similar to those of <code>A</code>
according to the Frobenius matrix
norm, then <code>A</code> is approximately factorizable. To measure the factorizability of a network, one can
calculate the <code>Factorizability</code>, which is a number between 0 and 1 (Dong and Horvath 2007). T
he conformity
is defined using a monotonic, iterative algorithm that maximizes the factorizability measure. 
</p>
<p>Type III: approximate conformity based network concepts are functions of all elements of the conformity
based adjacency matrix <code>A.CF</code> (including the diagonal) and/or the node significance measure
<code>GS</code>. These
network concepts are very useful for deriving relationships between network concepts in networks that are
approximately factorizable.
</p>
<p>Type IV: eigengene-based (also known as eigennode-based) network concepts are functions of the
eigengene-based adjacency matrix <code>A.E=ConformityE*t(ConformityE)</code> (diagonal included) and/or the
corresponding eigengene-based gene significance measure <code>GSE</code>.  These network concepts can only be 
defined
for correlation networks. Details: The columns (nodes) of <code>datExpr</code> can be summarized with the 
first principal
component, which is referred to as Eigengene in coexpression network analysis. In general correlation
networks, it is called eigennode. The eigengene-based conformity <code>ConformityE[i]</code> is defined as
<code>abs(cor(datE[,i], Eigengene))^power</code> where the power corresponds to the power used for defining the
weighted adjacency matrix <code>A</code>. The eigengene-based conformity can also be used to define an 
eigengene-based
adjacency matrix <code>A.E=ConformityE*t(ConformityE)</code>. 
The eigengene based factorizability <code>EF(datE)</code> is a number between 0 and 1 that measures how well
<code>A.E</code>
approximates <code>A</code> when the power parameter equals 1. <code>EF(datE)</code> is defined with respect to the
singular values
of <code>datExpr</code>. For a trait based node significance measure <code>GS=abs(cor(datE,trait))^power</code>, 
one can also define
an eigengene-based node significance measure <code>GSE[i]=ConformityE[i]*EigengeneSignificance</code> where the
eigengene significance <code>abs(cor(Eigengene,trait))^power</code> is defined as power of the absolute value
of the
correlation between eigengene and trait.
Eigengene-based network concepts are very useful for providing a geometric interpretation of network
concepts and for deriving relationships between network concepts. For example, the hub gene significance
measure and its eigengene-based analog have been used to characterize networks where highly connected hub
genes are important with regard to a trait based gene significance measure (Horvath and Dong 2008).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>Summary</code></td>
<td>
<p>a data frame whose rows report network concepts that only depend on the adjacency
matrix.
Density (mean adjacency), Centralization , Heterogeneity (coefficient of variation of the connectivity),
Mean ClusterCoef, Mean Connectivity.
The columns of the data frame report the 4 types of network concepts mentioned in the description:
Fundamental concepts, eigengene-based concepts, conformity-based concepts, and approximate
conformity-based concepts.</p>
</td></tr>
<tr><td><code>Size</code></td>
<td>
<p>reports the network size, i.e. the number of nodes, which equals the number of columns of
the input data frame <code>datExpr</code>.</p>
</td></tr>
<tr><td><code>Factorizability</code></td>
<td>
<p>a number between 0 and 1. The closer it is to 1, the better the off-diagonal
elements of the conformity based network <code>A.CF</code> approximate those of <code>A</code> 
(according to the Frobenius norm). </p>
</td></tr>
<tr><td><code>Eigengene</code></td>
<td>
<p>the first principal component of the standardized columns of <code>datExpr</code>. The
number of
components of this vector equals the number of rows of <code>datExpr</code>.</p>
</td></tr>
<tr><td><code>VarExplained</code></td>
<td>
<p>the proportion of variance explained by the first principal component (the
<code>Eigengene</code>). It is numerically different from the eigengene based factorizability. 
While <code>VarExplained</code> is
based on the squares of the singular values of <code>datExpr</code>, 
the eigengene-based factorizability is based on
fourth powers of the singular values. </p>
</td></tr>
<tr><td><code>Conformity</code></td>
<td>
<p>numerical vector giving the conformity. 
The number of components of the conformity vector equals the number of columns in
<code>datExpr</code>. The conformity is often highly correlated with the vector of node connectivities. The
conformity is computed using an iterative algorithm for maximizing the factorizability measure. The
algorithm and related network concepts are described in Dong and Horvath 2007.</p>
</td></tr> 
<tr><td><code>ClusterCoef</code></td>
<td>
<p>a numerical vector that reports the cluster coefficient for each node. This
fundamental network concept measures the cliquishness of each node.</p>
</td></tr>
<tr><td><code>Connectivity</code></td>
<td>
<p>a numerical vector that reports the connectivity (also known as degree) of each
node. This fundamental network concept is also known as whole network connectivity. One can also define
the scaled connectivity <code>K=Connectivity/max(Connectivity)</code> which is used for computing the hub gene
significance.</p>
</td></tr>
<tr><td><code>MAR</code></td>
<td>
<p>a numerical vector that reports the maximum adjacency ratio for each node. <code>MAR[i]</code>
equals 1
if all non-zero adjacencies between node <code>i</code> and the remaining network nodes equal 1. This
fundamental
network concept is always 1 for nodes of an unweighted network.  This is a useful measure for weighted
networks since it allows one to determine whether a node has high connectivity because of many weak
connections (small MAR) or because of strong (but few) connections (high MAR), see Horvath and Dong 2008.
</p>
</td></tr>
<tr><td><code>ConformityE</code></td>
<td>
<p>a numerical vector that reports the eigengene based (aka eigenenode based)
conformity for the correlation network. The number of components equals the number of columns of
<code>datExpr</code>.</p>
</td></tr>
<tr><td><code>GS</code></td>
<td>
<p>a numerical vector that encodes the node (gene) significance. The i-th component equals the
node significance of the i-th column of <code>datExpr</code> if a sample trait was supplied to the function
(input
trait). <code>GS[i]=abs(cor(datE[,i], trait, use="p"))^power</code> </p>
</td></tr>
<tr><td><code>GSE</code></td>
<td>
<p>a numerical vector that reports the eigengene based gene significance measure.  Its i-th
component is given by <code>GSE[i]=ConformityE[i]*EigengeneSignificance</code> where the eigengene significance
<code>abs(cor(Eigengene,trait))^power</code> is defined as power of the absolute value of the correlation
between
eigengene and trait.</p>
</td></tr>
<tr><td><code>Significance</code></td>
<td>
<p>a data frame whose rows report network concepts that also depend on the trait based
node significance measure. The rows correspond to network concepts and the columns correspond to the type
of network concept (fundamental versus eigengene based). The first row of the data frame reports the
network significance. The fundamental version of this network concepts is the average gene
significance=mean(GS). The eigengene based analog of this concept is defined as mean(GSE). The second row
reports the hub gene significance which is defined as slope of the intercept only regression model that
regresses the gene significance on the scaled network connectivity K. The third row reports the eigengene
significance <code>abs(cor(Eigengene,trait))^power</code>. More details can be found in Horvath and Dong
(2008).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Jun Dong, Steve Horvath, Peter Langfelder </p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology 2007, 1:24
</p>
<p>Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+conformityBasedNetworkConcepts">conformityBasedNetworkConcepts</a></code> for approximate conformity-based network concepts
</p>
<p><code><a href="#topic+fundamentalNetworkConcepts">fundamentalNetworkConcepts</a></code> for calculation of fundamental network concepts only.
</p>

<hr>
<h2 id='networkScreening'> Identification of genes related to a trait </h2><span id='topic+networkScreening'></span>

<h3>Description</h3>

<p>This function blends standard and network approaches to selecting genes (or variables in general) highly
related to a given trait.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>networkScreening(y, datME, datExpr, 
                 corFnc = "cor", corOptions = "use = 'p'",
                 oddPower = 3, 
                 blockSize = 1000, 
                 minimumSampleSize = ..minNSamples,
                 addMEy = TRUE, removeDiag = FALSE, 
                 weightESy = 0.5, getQValues = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="networkScreening_+3A_y">y</code></td>
<td>
<p> clinical trait given as a numeric vector (one value per sample) </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_datme">datME</code></td>
<td>
<p> data frame of module eigengenes </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame of expression data </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_corfnc">corFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity. Defaults to Pearson correlation. Any function returning values between -1 and 1 can be used. </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_coroptions">corOptions</code></td>
<td>
<p> character string specifying additional arguments to be passed to the function given
by <code>corFnc</code>. Use <code>"use = 'p', method = 'spearman'"</code> to obtain Spearman correlation.   </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_oddpower">oddPower</code></td>
<td>
<p> odd integer used as a power to raise module memberships and significances </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_blocksize">blockSize</code></td>
<td>
<p> block size to use for calculations with large data sets </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_minimumsamplesize">minimumSampleSize</code></td>
<td>
<p> minimum acceptable number of samples. Defaults to the default minimum number of
samples used throughout the WGCNA package, currently 4.</p>
</td></tr>
<tr><td><code id="networkScreening_+3A_addmey">addMEy</code></td>
<td>
<p> logical: should the trait be used as an additional &quot;module eigengene&quot;?</p>
</td></tr>
<tr><td><code id="networkScreening_+3A_removediag">removeDiag</code></td>
<td>
<p> logical: remove the diagonal? </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_weightesy">weightESy</code></td>
<td>
<p> weight to use for the trait as an additional eigengene; should be between 0 and 1 </p>
</td></tr>
<tr><td><code id="networkScreening_+3A_getqvalues">getQValues</code></td>
<td>
<p> logical: should q-values be calculated? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should be considered experimental. It takes into account both the &quot;standard&quot; and the network
measures of gene importance for the trait.
</p>


<h3>Value</h3>

<p>datout = data.frame(p.Weighted, q.Weighted, Cor.Weighted,
Z.Weighted, p.Standard, q.Standard, Cor.Standard, Z.Standard)
Data frame reporting the following quantities for each given gene:
</p>
<table role = "presentation">
<tr><td><code>p.Weighted</code></td>
<td>
<p>weighted p-value of association with the trait</p>
</td></tr>
<tr><td><code>q.Weighted</code></td>
<td>
<p>q-value (local FDR) calculated from <code>p.Weighted</code></p>
</td></tr>
<tr><td><code>cor.Weighted</code></td>
<td>
<p>correlation of trait with gene expression weighted by a network term</p>
</td></tr>
<tr><td><code>Z.Weighted</code></td>
<td>
<p> Fisher Z score of the weighted correlation</p>
</td></tr>
<tr><td><code>p.Standard</code></td>
<td>
<p> standard Student p-value of association of the gene with the trait</p>
</td></tr>
<tr><td><code>q.Standard</code></td>
<td>
<p> q-value (local FDR) calculated from <code>p.Standard</code></p>
</td></tr>
<tr><td><code>cor.Standard</code></td>
<td>
<p> correlation of gene with the trait</p>
</td></tr>
<tr><td><code>Z.Standard</code></td>
<td>
<p> Fisher Z score of the standard correlation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='networkScreeningGS'> Network gene screening with an external gene significance measure </h2><span id='topic+networkScreeningGS'></span>

<h3>Description</h3>

<p>This function blends standard and network approaches to selecting genes (or variables in general) with
high gene significance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>networkScreeningGS(
  datExpr,
  datME,
  GS,
  oddPower = 3,
  blockSize = 1000,
  minimumSampleSize = ..minNSamples, 
  addGS = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="networkScreeningGS_+3A_datexpr">datExpr</code></td>
<td>
<p> data frame of expression data </p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_datme">datME</code></td>
<td>
<p> data frame of module eigengenes </p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_gs">GS</code></td>
<td>
<p> numeric vector of gene significances </p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_oddpower">oddPower</code></td>
<td>
<p> odd integer used as a power to raise module memberships and significances </p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_blocksize">blockSize</code></td>
<td>
<p> block size to use for calculations with large data sets </p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_minimumsamplesize">minimumSampleSize</code></td>
<td>
<p> minimum acceptable number of samples. Defaults to the default minimum number of
samples used throughout the WGCNA package, currently 4.</p>
</td></tr>
<tr><td><code id="networkScreeningGS_+3A_addgs">addGS</code></td>
<td>
<p> logical: should gene significances be added to the screening statistics?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should be considered experimental. It takes into account both the &quot;standard&quot; and the network
measures of gene importance for the trait.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>GS.Weighted</code></td>
<td>
<p>weighted gene significance </p>
</td></tr>
<tr><td><code>GS</code></td>
<td>
<p>copy of the input gene significances (only if <code>addGS=TRUE</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

<p><code><a href="#topic+networkScreening">networkScreening</a></code>, <code><a href="#topic+automaticNetworkScreeningGS">automaticNetworkScreeningGS</a></code></p>

<hr>
<h2 id='newBlockInformation'>
Create a list holding information about dividing data into blocks
</h2><span id='topic+newBlockInformation'></span><span id='topic+BlockInformation'></span>

<h3>Description</h3>

<p>This function creates a list storing information about dividing data into blocks, as well as about possibly
excluding genes or samples with excessive numbers of missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newBlockInformation(blocks, goodSamplesAndGenes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newBlockInformation_+3A_blocks">blocks</code></td>
<td>

<p>A vector giving block labels. It is assumed to be a numeric vector with block labels consecutive integers
starting at 1. 
</p>
</td></tr>
<tr><td><code id="newBlockInformation_+3A_goodsamplesandgenes">goodSamplesAndGenes</code></td>
<td>

<p>A list returned by <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code> or <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with <code>class</code> attribute set to <code>BlockInformation</code>, with the following componens:
</p>
<table role = "presentation">
<tr><td><code>blocks</code></td>
<td>
<p>A copy of the input <code>blocks</code>.</p>
</td></tr>
<tr><td><code>blockGenes</code></td>
<td>
<p>A list with one component per block, giving the indices of elements in <code>block</code> whose
value is the same.</p>
</td></tr>
<tr><td><code>goodSamplesAndGenes</code></td>
<td>
<p>A copy of input <code>goodSamplesAndGenes</code>.</p>
</td></tr>
<tr><td><code>nGGenes</code></td>
<td>
<p>Number of &lsquo;good&rsquo; genes in <code>goodSamplesAndGenes</code>.</p>
</td></tr>
<tr><td><code>gBlocks</code></td>
<td>
<p>The input <code>blocks</code> restricted to &lsquo;good&rsquo; genes in <code>goodSamplesAndGenes</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code>, <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>.
</p>

<hr>
<h2 id='newBlockwiseData'>
Create, merge and expand BlockwiseData objects 
</h2><span id='topic+newBlockwiseData'></span><span id='topic+BlockwiseData'></span><span id='topic+mergeBlockwiseData'></span><span id='topic+addBlockToBlockwiseData'></span>

<h3>Description</h3>

<p>These functions create, merge and expand BlockwiseData objects for holding in-memory or disk-backed blockwise
data. Blockwise here means
that the data is too large to be loaded or processed in one piece and is therefore split into blocks that can
be handled one by one in a divide-and-conquer manner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newBlockwiseData(
   data, 
   external = FALSE, 
   fileNames = NULL, 
   doSave = external, 
   recordAttributes = TRUE, 
   metaData = list())

mergeBlockwiseData(...)

addBlockToBlockwiseData(
   bwData,
   blockData,
   external = bwData$external,
   blockFile = NULL,
   doSave = external,
   recordAttributes = !is.null(bwData$attributes),
   metaData = NULL)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newBlockwiseData_+3A_data">data</code></td>
<td>

<p>A list in which each component carries the data of a single block.
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_external">external</code></td>
<td>

<p>Logical: should the data be disk-backed (<code>TRUE</code>) or in-memory (<code>FALSE</code>)?
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_filenames">fileNames</code></td>
<td>

<p>When <code>external</code> is <code>TRUE</code>, this argument must be a 
character vector of the same length as <code>data</code>, giving the file names for the data to be saved to, or
where the data is already located.
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_dosave">doSave</code></td>
<td>

<p>Logical: should data be saved? If this is <code>FALSE</code>, it is the user's responsibility to ensure the files
supplied in <code>fileNames</code> already exist and contain the expected data.
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_recordattributes">recordAttributes</code></td>
<td>

<p>Logical: should <code>attributes</code> of the given data be recorded within the object?
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_metadata">metaData</code></td>
<td>

<p>A list giving any additional meta-data for <code>data</code> that should be attached to the object.
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_bwdata">bwData</code></td>
<td>
<p>An existing <code>BlockwiseData</code> object.</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_blockdata">blockData</code></td>
<td>
<p>A vector, matrix or array carrying the data of a single block.</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_blockfile">blockFile</code></td>
<td>

<p>File name where data contained in <code>blockData</code> should be saved.
</p>
</td></tr>
<tr><td><code id="newBlockwiseData_+3A_...">...</code></td>
<td>
<p>One or more objects of class <code>BlockwiseData</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several functions in this package use the concept of blockwise, or &quot;divide-and-conquer&quot;, analysis. The
BlockwiseData class is meant to hold the blockwise data, or all necessary information about blockwise data
that is saved in disk files. 
</p>
<p>The data can be stored in disk files (one file per block) or in-memory. In memory storage is provided so that
same code can be used for both smaller (single-block) data where disk storage could slow down operations as
well as larger data sets where disk storage and block by block analysis are necessary.
</p>


<h3>Value</h3>

<p>All three functions return a list with the class set to <code>"BlockwiseData"</code>, containing the following components:
</p>
<table role = "presentation">
<tr><td><code>external</code></td>
<td>
<p>Copy of the input argument <code>external</code></p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>If <code>external</code> is <code>TRUE</code>, an empty list, otherwise a copy of the input <code>data</code>.</p>
</td></tr>
<tr><td><code>fileNames</code></td>
<td>
<p>Copy of the input argument <code>fileNames</code>.</p>
</td></tr>
<tr><td><code>lengths</code></td>
<td>
<p>A vector of lengths (results of <code><a href="base.html#topic+length">length</a></code>) of elements of <code>data</code>.</p>
</td></tr>
<tr><td><code>attributes</code></td>
<td>
<p>If input <code>recordAttributes</code> is <code>TRUE</code>, a list with one component per block
(component of <code>data</code>); each component is in turn a list of attributes of that component of <code>data</code>.</p>
</td></tr>
<tr><td><code>metaData</code></td>
<td>
<p>A copy of the input <code>metaData</code>.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The definition of <code>BlockwiseData</code> should be considered experimental and may change in
the future.</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>Other functions on <code>BlockwiseData</code>: 
</p>
<p><code><a href="#topic+BD.getData">BD.getData</a></code> for retrieving data
</p>
<p><code><a href="#topic+BD.actualFileNames">BD.actualFileNames</a></code> for retrieving file names of files containing data;
</p>
<p><code><a href="#topic+BD.nBlocks">BD.nBlocks</a></code> for retrieving the number of blocks;
</p>
<p><code><a href="#topic+BD.blockLengths">BD.blockLengths</a></code> for retrieving block lengths;
</p>
<p><code><a href="#topic+BD.getMetaData">BD.getMetaData</a></code> for retrieving metadata;
</p>
<p><code><a href="#topic+BD.checkAndDeleteFiles">BD.checkAndDeleteFiles</a></code> for deleting files of an unneeded object.
</p>

<hr>
<h2 id='newConsensusOptions'>
Create a list holding consensus calculation options.
</h2><span id='topic+newConsensusOptions'></span><span id='topic+ConsensusOptions'></span>

<h3>Description</h3>

<p>This function creates a list of class <code>ConsensusOptions</code> that holds options for consensus calculations.
This list holds options for a single-level analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newConsensusOptions(
      calibration = c("full quantile", "single quantile", "none"),

      # Simple quantile scaling options
      calibrationQuantile = 0.95,
      sampleForCalibration = TRUE, 
      sampleForCalibrationFactor = 1000,

      # Consensus definition
      consensusQuantile = 0,
      useMean = FALSE,
      setWeights = NULL,
      suppressNegativeResults = FALSE,
      # Name to prevent files clashes
      analysisName = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newConsensusOptions_+3A_calibration">calibration</code></td>
<td>

<p>Calibration method. One of <code>"full quantile", "single quantile", "none"</code>
(or a unique abbreviation of one of them).</p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_calibrationquantile">calibrationQuantile</code></td>
<td>

<p>if <code>calibration</code> is <code>"single quantile"</code>,
input data to a consensus calculation 
will be scaled such that their <code>calibrationQuantile</code> quantiles will agree. </p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_sampleforcalibration">sampleForCalibration</code></td>
<td>
<p> if <code>TRUE</code>, calibration quantiles will be determined from a sample of
network
similarities. Note that using all data can double the memory footprint of the function and the function
may fail. </p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_sampleforcalibrationfactor">sampleForCalibrationFactor</code></td>
<td>
<p> Determines the number of samples for calibration: the number is
<code>1/calibrationQuantile * sampleForCalibrationFactor</code>. Should be set well above 1 to ensure accuracy of
the sampled quantile. </p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_consensusquantile">consensusQuantile</code></td>
<td>
<p>Quantile at which consensus is to be defined. See details. 
</p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_usemean">useMean</code></td>
<td>

<p>Logical: should the consensus be calculated using (weighted) mean rather than a quantile?
</p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_setweights">setWeights</code></td>
<td>

<p>Optional specification of weights when <code>useMean</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_suppressnegativeresults">suppressNegativeResults</code></td>
<td>
<p>Logical: should negative consensus results be replaced by 0? In a typical network
connstruction, negative topological overlap values may results with <code>TOMType = "signed Nowick"</code>.</p>
</td></tr>
<tr><td><code id="newConsensusOptions_+3A_analysisname">analysisName</code></td>
<td>

<p>Optional character string naming the consensus analysis. Useful for identifying partial consensus calculation
in hierarchical consensus analysis.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of type <code>ConsensusOptions</code> that holds copies of the input arguments.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='newConsensusTree'>
Create a new consensus tree
</h2><span id='topic+newConsensusTree'></span><span id='topic+ConsensusTree'></span>

<h3>Description</h3>

<p>This function creates a new consensus tree, a class for representing &quot;recipes&quot; for hierarchical consensus
calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newConsensusTree(
   consensusOptions = newConsensusOptions(), 
   inputs, 
   analysisName = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newConsensusTree_+3A_consensusoptions">consensusOptions</code></td>
<td>

<p>An object of class <code>ConsensusOptions</code>, usually obtained by calling <code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>.
</p>
</td></tr>
<tr><td><code id="newConsensusTree_+3A_inputs">inputs</code></td>
<td>

<p>A vector (or list) of inputs. Each component can be either a character string giving a names of a data set,
or another <code>ConsensusTree</code> object.
</p>
</td></tr>
<tr><td><code id="newConsensusTree_+3A_analysisname">analysisName</code></td>
<td>

<p>Optional specification of a name for this consensus analysis. While this has no effect on the actual
consensus calculation, some functions use this character string to make certain file names unique.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consensus trees specify a &quot;recipe&quot; for the calculation of hierarchical consensus in
<code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> and other functions. 
</p>


<h3>Value</h3>

<p>A list with class set to <code>"ConsensusTree"</code> with these components:
</p>
<table role = "presentation">
<tr><td><code>consensusOptions</code></td>
<td>
<p>A copy of the input <code>consensusOptions</code>.</p>
</td></tr>
<tr><td><code>inputs</code></td>
<td>
<p>A copy of the input <code>inputs</code>.</p>
</td></tr>
<tr><td><code>analysisName</code></td>
<td>
<p>A copy of the input <code>analysisName</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> for hierarchical consensus calculation for which a
<code>ConsensusTree</code> object specifies the recipe
</p>

<hr>
<h2 id='newCorrelationOptions'>
Creates a list of correlation options.
</h2><span id='topic+newCorrelationOptions'></span><span id='topic+CorrelationOptions'></span>

<h3>Description</h3>

<p>Convenience function to create a re-usable list of correlation options. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newCorrelationOptions(
      corType = c("pearson", "bicor"),
      maxPOutliers = 0.05,
      quickCor = 0,
      pearsonFallback = "individual",
      cosineCorrelation = FALSE,
      nThreads = 0,
      corFnc = if (corType=="bicor") "bicor" else "cor",
      corOptions = c(
        list(use = 'p', 
             cosine = cosineCorrelation, 
             quick = quickCor,
             nThreads = nThreads),
        if (corType=="bicor") 
           list(maxPOutliers = maxPOutliers, 
                pearsonFallback = pearsonFallback) else NULL))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newCorrelationOptions_+3A_cortype">corType</code></td>
<td>

<p>Character specifying the type of correlation function. Currently supported options are <code>"pearson",
"bicor"</code>.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_maxpoutliers">maxPOutliers</code></td>
<td>

<p>Maximum proportion of outliers for biweight mid-correlation. See <code><a href="#topic+bicor">bicor</a></code>.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_quickcor">quickCor</code></td>
<td>

<p>Real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See <code><a href="#topic+bicor">bicor</a></code>.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_pearsonfallback">pearsonFallback</code></td>
<td>

<p>Specifies whether the bicor calculation should revert to Pearson when median
absolute deviation (mad) is zero. Recongnized values are (abbreviations of)
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation.
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad.
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). 
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>

<p>Logical: calculate cosine biweight midcorrelation?
Cosine bicorrelation is similar to standard bicorrelation but the median subtraction is not performed.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_nthreads">nThreads</code></td>
<td>

<p>A non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_corfnc">corFnc</code></td>
<td>

<p>Correlation function to be called in R code. Should correspoind to the value of <code>corType</code> above.
</p>
</td></tr>
<tr><td><code id="newCorrelationOptions_+3A_coroptions">corOptions</code></td>
<td>

<p>A list of options to be supplied to the correlation function (in addition to appropriate arguments <code>x</code>
and <code>y</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a copy of the input arguments. The output has class <code>CorrelationOptions</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='newNetworkOptions'>
Create a list of network construction arguments (options).
</h2><span id='topic+newNetworkOptions'></span><span id='topic+NetworkOptions'></span>

<h3>Description</h3>

<p>This function creates a reusable list of network calculation arguments/options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newNetworkOptions(
    correlationOptions = newCorrelationOptions(),

    # Adjacency options
    replaceMissingAdjacencies = TRUE,
    power = 6,
    networkType = c("signed hybrid", "signed", "unsigned"),
    checkPower = TRUE,

    # Topological overlap options
    TOMType = c("signed", "signed Nowick", "unsigned", "none",
                "signed 2", "signed Nowick 2", "unsigned 2"),
    TOMDenom = c("mean", "min"),
    suppressTOMForZeroAdjacencies = FALSE,
    suppressNegativeTOM = FALSE,

    # Internal behavior options
    useInternalMatrixAlgebra = FALSE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="newNetworkOptions_+3A_correlationoptions">correlationOptions</code></td>
<td>

<p>A list of correlation options. See <code><a href="#topic+newCorrelationOptions">newCorrelationOptions</a></code>.
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>Logical: should missing adjacencies be replaced by zero? 
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_power">power</code></td>
<td>
<p> Soft-thresholding power for network construction. 
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. 
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_checkpower">checkPower</code></td>
<td>
<p>Logicel: should the power be checked for sanity? 
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_tomtype">TOMType</code></td>
<td>
<p>One of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_tomdenom">TOMDenom</code></td>
<td>
<p>Character string specifying the TOM variant to be used. Recognized values are
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce
better results but at this time should be considered experimental.
</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_suppresstomforzeroadjacencies">suppressTOMForZeroAdjacencies</code></td>
<td>
<p>logical: for those components that have zero adjacency, should TOM be
set to zero as well?</p>
</td></tr>
<tr><td><code id="newNetworkOptions_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? Negative TOM values can occur when
<code>TOMType</code> is <code>"signed Nowick"</code>.</p>
</td></tr>
</table>
<p>newNetworkOptions
</p>
<table role = "presentation">
<tr><td><code id="newNetworkOptions_+3A_useinternalmatrixalgebra">useInternalMatrixAlgebra</code></td>
<td>
<p>logical: should internal implementation of matrix multiplication be used
instead of R-provided BLAS? The internal implementation is slow and this option should only be used if one
suspects a bug in R-provided BLAS.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>NetworkOptions</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+newCorrelationOptions">newCorrelationOptions</a></code>
</p>

<hr>
<h2 id='normalizeLabels'>Transform numerical labels into normal order. </h2><span id='topic+normalizeLabels'></span>

<h3>Description</h3>

<p>Transforms numerical labels into normal order, that is the largest group will be labeled 1, next
largest 2 etc. Label 0 is optionally preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizeLabels(labels, keepZero = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalizeLabels_+3A_labels">labels</code></td>
<td>
<p>Numerical labels.</p>
</td></tr>
<tr><td><code id="normalizeLabels_+3A_keepzero">keepZero</code></td>
<td>
<p>If <code>TRUE</code> (the default), labels 0 are preserved.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the same length as input, containing the normalized labels.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>

<hr>
<h2 id='nPresent'> Number of present data entries. </h2><span id='topic+nPresent'></span>

<h3>Description</h3>

<p>A simple sum of present entries in the argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nPresent(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nPresent_+3A_x">x</code></td>
<td>
<p> data in which to count number of present entries. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single number giving the number of present entries in <code>x</code>.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='nSets'> Number of sets in a multi-set variable
</h2><span id='topic+nSets'></span>

<h3>Description</h3>

<p>A convenience function that returns the number of sets in a multi-set variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nSets(multiData, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nSets_+3A_multidata">multiData</code></td>
<td>

<p>vector of lists; in each list there must be a component named <code>data</code> whose content
is a matrix or dataframe or array of dimension 2. </p>
</td></tr>
<tr><td><code id="nSets_+3A_...">...</code></td>
<td>

<p>Other arguments to function <code><a href="#topic+checkSets">checkSets</a></code>. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single integer that equals the number of sets given in the input <code>multiData</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkSets">checkSets</a></code>
</p>

<hr>
<h2 id='numbers2colors'> Color representation for a numeric variable </h2><span id='topic+numbers2colors'></span>

<h3>Description</h3>

<p>The function creates a color represenation for the given numeric input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numbers2colors(
   x, 
   signed = NULL, 
   centered = signed, 
   lim = NULL, 
   commonLim = FALSE,
   colors = if (signed) blueWhiteRed(100) else blueWhiteRed(100)[51:100],
   naColor = "grey")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="numbers2colors_+3A_x">x</code></td>
<td>
<p> a vector or matrix of numbers. Missing values are allowed and will be assigned the color
given in <code>naColor</code>. If a matrix, each column of the matrix is processed separately and the return
value will be a matrix of colors. </p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_signed">signed</code></td>
<td>
<p> logical: should <code>x</code> be considered signed? If <code>TRUE</code>, the default setting is to
use to use a palette that starts with green for the most negative values, continues with white for
values around zero and turns red for positive values. If <code>FALSE</code>, the default palette ranges from 
white for minimum values to red for maximum values. If not given, the behaviour is controlled by values in
<code>x</code>: if there are both positive and negative values, <code>signed</code> will be considered <code>TRUE</code>,
otherwise <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_centered">centered</code></td>
<td>
<p> logical. If <code>TRUE</code> and <code>signed==TRUE</code>, numeric value zero will
correspond to the middle of the color palette. If <code>FALSE</code> or <code>signed==FALSE</code>, the middle of
the color palette will correspond to the average of the minimum and maximum value. If neither <code>signed</code>
nor <code>centered</code> are given, <code>centered</code> will follow <code>signed</code> (see above).</p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_lim">lim</code></td>
<td>
<p> optional specification of limits, that is numeric values that should correspond to the
first and last entry of <code>colors</code>. </p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_commonlim">commonLim</code></td>
<td>
<p>logical: should limits be calculated separately for each column of x, or should the
limits be the same for all columns? Only applies if <code>lim</code> is <code>NULL</code>. </p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_colors">colors</code></td>
<td>
<p> color palette to represent the given numbers. </p>
</td></tr>
<tr><td><code id="numbers2colors_+3A_nacolor">naColor</code></td>
<td>
<p> color to represent missing values in <code>x</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each column of <code>x</code> is processed individually, meaning that the color palette is adjusted
individually for each column of <code>x</code>.
</p>


<h3>Value</h3>

<p>A vector or matrix (of the same dimensions as <code>x</code>) of colors.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+labels2colors">labels2colors</a></code> for color coding of ordinal labels. </p>

<hr>
<h2 id='orderBranchesUsingHubGenes'> Optimize dendrogram using branch swaps and reflections.  </h2><span id='topic+orderBranchesUsingHubGenes'></span>

<h3>Description</h3>

<p>This function takes as input the hierarchical clustering tree as well as a subset of genes in the network (generally corresponding to branches in the tree), then returns a semi-optimally ordered tree.  The idea is to maximize the correlations between adjacent branches in the dendrogram, in as much as that is possible by adjusting the arbitrary positionings of the branches by swapping and reflecting branches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderBranchesUsingHubGenes(
  hierTOM, 
  datExpr = NULL, colorh = NULL, 
  type = "signed", adj = NULL, iter = NULL, 
  useReflections = FALSE, allowNonoptimalSwaps = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="orderBranchesUsingHubGenes_+3A_hiertom">hierTOM</code></td>
<td>

<p>A hierarchical clustering object (or gene tree) that is used to plot the dendrogram.  For example, the output object from the function hclust or fastcluster::hclust.  Note that elements of hierTOM$order MUST be named (for example, with the corresponding gene name).
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_datexpr">datExpr</code></td>
<td>

<p>Gene expression data with rows as samples and columns as genes, or NULL if a pre-made adjacency is entered.  Column names of datExpr must be a subset of gene names of hierTOM$order.
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_colorh">colorh</code></td>
<td>

<p>The module assignments (color vectors) corresponding to the rows in datExpr, or NULL if a pre-made adjacency is entered.
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_type">type</code></td>
<td>

<p>What type of network is being entered.  Common choices are &quot;signed&quot; (default) and &quot;unsigned&quot;.  With &quot;signed&quot; negative correlations count against, whereas with &quot;unsigned&quot; negative correlations are treated identically as positive correlations.
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_adj">adj</code></td>
<td>

<p>Either NULL (default) or an adjacency (or any other square) matrix with rows and columns corresponding to a subset of the genes in hierTOM$order.  If entered, datExpr, colorh, and type are all ignored.  Typically, this would be left blank but could include correlations between module eigengenes, with rows and columns renamed as genes in the corresponding modules, for example.
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_iter">iter</code></td>
<td>

<p>The number of iterations to run the function in search of optimal branch ordering.  The default is the square of the number of modules (or the quare of the number of genes in the adjacency matrix).
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_usereflections">useReflections</code></td>
<td>

<p>If TRUE, both reflections and branch swapping will be used to optimize dendrogram.  If FALSE (default) only branch swapping will be used. 
</p>
</td></tr>
<tr><td><code id="orderBranchesUsingHubGenes_+3A_allownonoptimalswaps">allowNonoptimalSwaps</code></td>
<td>

<p>If TRUE, there is chance (that decreases with each iteration) of swapping / reflecting branches whether or not the new correlation between expression of genes in adjacent branches is better or worse.  The idea (which has not been sufficiently tested), is that this would prevent the function from getting stuck at a local maxima of correlation.  If FALSE (default), the swapping / reflection of branches only occurs if it results in a higher correlation between adjacent branches.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>hierTOM</code></td>
<td>

<p>A hierarchical clustering object with the hierTOM$order variable properly adjusted, but all other variables identical as the heirTOM input.
</p>
</td></tr>
<tr><td><code>changeLog</code></td>
<td>

<p>A log of all of the changes that were made to the dendrogram, including what change was made, on what iteration, and the Old and New scores based on correlation.  These scores have arbitrary units, but higher is better.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is very slow and is still in an *experimental* function.  We have not had problems with ~10 modules across ~5000 genes, although theoretically it should work for many more genes and modules, depending upon the speed of the computer running R.  Please address any problems or suggestions to jeremyinla@gmail.com.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Example: first simulate some data.

MEturquoise = sample(1:100,50)
MEblue      = c(MEturquoise[1:25], sample(1:100,25))
MEbrown     = sample(1:100,50)
MEyellow    = sample(1:100,50) 
MEgreen     = c(MEyellow[1:30], sample(1:100,20))
MEred	    = c(MEbrown [1:20], sample(1:100,30))
ME     = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen, MEred)
dat1   = simulateDatExpr(ME,400,c(0.16,0.12,0.11,0.10,0.10,0.10,0.1), signed=TRUE)
TOM1   = TOMsimilarityFromExpr(dat1$datExpr, networkType="signed")
colnames(TOM1) &lt;- rownames(TOM1) &lt;- colnames(dat1$datExpr)
tree1  = fastcluster::hclust(as.dist(1-TOM1),method="average")
colorh = labels2colors(dat1$allLabels)

plotDendroAndColors(tree1,colorh,dendroLabels=FALSE)

## Reassign modules using the selectBranch and chooseOneHubInEachModule functions

datExpr = dat1$datExpr
hubs    = chooseOneHubInEachModule(datExpr, colorh)
colorh2 = rep("grey", length(colorh))
colorh2 [selectBranch(tree1,hubs["blue"],hubs["turquoise"])] = "blue"
colorh2 [selectBranch(tree1,hubs["turquoise"],hubs["blue"])] = "turquoise"
colorh2 [selectBranch(tree1,hubs["green"],hubs["yellow"])]   = "green"
colorh2 [selectBranch(tree1,hubs["yellow"],hubs["green"])]   = "yellow"
colorh2 [selectBranch(tree1,hubs["red"],hubs["brown"])]      = "red"
colorh2 [selectBranch(tree1,hubs["brown"],hubs["red"])]      = "brown"
plotDendroAndColors(tree1,cbind(colorh,colorh2),c("Old","New"),dendroLabels=FALSE)

## Now swap and reflect some branches, then optimize the order of the branches 
# and output pdf with resulting images

pdf("DENDROGRAM_PLOTS.pdf",width=10,height=5)
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Starting Dendrogram")

tree1 = swapTwoBranches(tree1,hubs["red"],hubs["turquoise"])
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Swap blue/turquoise and red/brown")

tree1 = reflectBranch(tree1,hubs["blue"],hubs["green"])
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Reflect turquoise/blue")

# (This function will take a few minutes)
out = orderBranchesUsingHubGenes(tree1,datExpr,colorh2,useReflections=TRUE,iter=100)
tree1 = out$geneTree
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Semi-optimal branch order")

out$changeLog

dev.off()

## End(Not run)
</code></pre>

<hr>
<h2 id='orderMEs'>Put close eigenvectors next to each other</h2><span id='topic+orderMEs'></span>

<h3>Description</h3>

<p>Reorder given (eigen-)vectors such that similar ones (as measured by correlation) are next to each
other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderMEs(MEs, greyLast = TRUE, 
         greyName = paste(moduleColor.getMEprefix(), "grey", sep=""), 
         orderBy = 1, order = NULL, 
         useSets = NULL,  verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="orderMEs_+3A_mes">MEs</code></td>
<td>
<p>Module eigengenes in a multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of lists,
with each list corresponding to one dataset and the module eigengenes in the component <code>data</code>,
that is <code>MEs[[set]]$data[sample, module]</code> is the expression of the eigengene of module <code>module</code>
in sample
<code>sample</code> in dataset <code>set</code>. The number of samples can be different between the sets, but the
modules must be the same. </p>
</td></tr>
<tr><td><code id="orderMEs_+3A_greylast">greyLast</code></td>
<td>
<p>Normally the color grey is reserved for unassigned genes; hence the grey module is not
a proper module and it is conventional to put it last. If this is not desired, set the parameter to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_greyname">greyName</code></td>
<td>
<p>Name of the grey module eigengene.</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_orderby">orderBy</code></td>
<td>
<p>Specifies the set by which the eigengenes are to be ordered (in all other sets as well).
Defaults to the first set in <code>useSets</code> (or the first set, if <code>useSets</code> is not given).</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_order">order</code></td>
<td>
<p>Allows the user to specify a custom ordering.</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_usesets">useSets</code></td>
<td>
<p>Allows the user to specify for which sets the eigengene ordering is to be performed.</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbostity of printed progress messages. 0 means silent, nonzero verbose.</p>
</td></tr>
<tr><td><code id="orderMEs_+3A_indent">indent</code></td>
<td>
<p>A single non-negative integer controling indentation of printed messages. 0 means no
indentation, each unit above zero adds two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ordering module eigengenes is useful for plotting purposes. For this function the order can be
specified explicitly, or a set can be given in which the correlations of the eigengenes will determine
the order. For the latter, a hierarchical dendrogram is calculated and the order given by the dendrogram is
used for the eigengenes in all other sets.
</p>


<h3>Value</h3>

<p>A vector of lists of the same type as <code>MEs</code> containing the re-ordered eigengenes.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code>, <code><a href="#topic+multiSetMEs">multiSetMEs</a></code>, <code><a href="#topic+consensusOrderMEs">consensusOrderMEs</a></code></p>

<hr>
<h2 id='orderMEsByHierarchicalConsensus'>
Order module eigengenes by their hierarchical consensus similarity
</h2><span id='topic+orderMEsByHierarchicalConsensus'></span>

<h3>Description</h3>

<p>This function calculates a hiearchical consensus similarity of the input eigengenes, clusters the eigengenes
according to the similarity and returns the input module eigengenes ordered by the order of resulting
dendrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderMEsByHierarchicalConsensus(
    MEs, 
    networkOptions, 
    consensusTree, 
    greyName = "ME0", 
    calibrate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="orderMEsByHierarchicalConsensus_+3A_mes">MEs</code></td>
<td>

<p>Module eigengenes, or more generally, vectors, to be ordered, in a <code><a href="#topic+multiData">multiData</a></code> format: A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the module eigenegens or
general vectors, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="orderMEsByHierarchicalConsensus_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="orderMEsByHierarchicalConsensus_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See <code><a href="#topic+newConsensusTree">newConsensusTree</a></code> for details.
</p>
</td></tr>
<tr><td><code id="orderMEsByHierarchicalConsensus_+3A_greyname">greyName</code></td>
<td>

<p>Specifies the column name of eigengene of the &quot;module&quot; that contains unassigned genes. This eigengene
(column) will be excluded from the clustering and will be put last in the order.
</p>
</td></tr>
<tr><td><code id="orderMEsByHierarchicalConsensus_+3A_calibrate">calibrate</code></td>
<td>

<p>Logical: should module eigengene similarities be calibrated? This setting overrides the calibration options
in <code>consensusTree</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+multiData">multiData</a></code> structure of the same format as the input <code>MEs</code>, with columns ordered
by the calculated dendrogram.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusMEDissimilarity">hierarchicalConsensusMEDissimilarity</a></code> for calculating the consensus ME dissimilarity
</p>

<hr>
<h2 id='overlapTable'> Calculate overlap of modules </h2><span id='topic+overlapTable'></span>

<h3>Description</h3>

<p>The function calculates overlap counts and Fisher exact test p-values for the given two sets of module
assignments. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overlapTable(
    labels1, labels2, 
    na.rm = TRUE, ignore = NULL, 
    levels1 = NULL, levels2 = NULL,
    log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overlapTable_+3A_labels1">labels1</code></td>
<td>
<p> a vector containing module labels. </p>
</td></tr>
<tr><td><code id="overlapTable_+3A_labels2">labels2</code></td>
<td>
<p> a vector containing module labels to be compared to <code>labels1</code>. </p>
</td></tr>
<tr><td><code id="overlapTable_+3A_na.rm">na.rm</code></td>
<td>
<p>logical: should entries missing in either <code>labels1</code> or <code>labels2</code> be removed?</p>
</td></tr>
<tr><td><code id="overlapTable_+3A_ignore">ignore</code></td>
<td>
<p>an optional vector giving label levels that are to be ignored.</p>
</td></tr>
<tr><td><code id="overlapTable_+3A_levels1">levels1</code></td>
<td>
<p>optional vector giving levels for <code>labels1</code>. Defaults to sorted unique non-missing
values in <code>labels1</code> that are not present in <code>ignore</code>.</p>
</td></tr>
<tr><td><code id="overlapTable_+3A_levels2">levels2</code></td>
<td>
<p>optional vector giving levels for <code>labels2</code>. Defaults to sorted unique non-missing
values in <code>labels2</code> that are not present in <code>ignore</code>.</p>
</td></tr>
<tr><td><code id="overlapTable_+3A_log.p">log.p</code></td>
<td>
<p>logical: should (natural) logarithms of the p-values be returned instead of the p-values?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>countTable</code></td>
<td>
<p>a matrix whose rows correspond to modules (unique labels) in <code>labels1</code> and whose
columns correspond to modules (unique labels) in <code>labels2</code>, giving the number of objects in the
intersection of the two respective modules. </p>
</td></tr>
<tr><td><code>pTable</code></td>
<td>
<p>a matrix whose rows correspond to modules (unique labels) in <code>labels1</code> and whose
columns correspond to modules (unique labels) in <code>labels2</code>, giving Fisher's exact test 
significance p-values (or their logarithms) for the overlap of the two respective modules. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+fisher.test">fisher.test</a></code>, <code><a href="#topic+matchLabels">matchLabels</a></code> </p>

<hr>
<h2 id='overlapTableUsingKME'> Determines significant overlap between modules in two networks based on kME tables.  </h2><span id='topic+overlapTableUsingKME'></span>

<h3>Description</h3>

<p>Takes two sets of expression data (or kME tables) as input and returns a table listing the significant overlap between each module in each data set, as well as the actual genes in common for every module pair.  Modules can be defined in several ways (generally involving kME) based on user input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overlapTableUsingKME(
   dat1, dat2, 
   colorh1, colorh2, 
   MEs1 = NULL, MEs2 = NULL, 
   name1 = "MM1", name2 = "MM2", 
   cutoffMethod = "assigned", cutoff = 0.5, 
   omitGrey = TRUE, datIsExpression = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overlapTableUsingKME_+3A_dat1">dat1</code>, <code id="overlapTableUsingKME_+3A_dat2">dat2</code></td>
<td>

<p>Either expression data sets (with samples as rows and genes as columns) or module membership (kME) tables (with genes as rows and modules as columns).  Function reads these inputs based on whether datIsExpression=TRUE or FALSE.  ***Be sure that these inputs include relevant row and column names, or else the function will not work properly.***
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_colorh1">colorh1</code>, <code id="overlapTableUsingKME_+3A_colorh2">colorh2</code></td>
<td>

<p>Color vector (module assignments) corresponding to the genes from dat1/2.  This vector must be the same length as the Gene dimension from dat1/2.
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_mes1">MEs1</code>, <code id="overlapTableUsingKME_+3A_mes2">MEs2</code></td>
<td>

<p>If entered (default=NULL), these are the module eigengenes that will be used to form the kME tables. Rows are samples and columns are module assignments.  Note that if datIsExpression=FALSE, these inputs are ignored.
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_name1">name1</code>, <code id="overlapTableUsingKME_+3A_name2">name2</code></td>
<td>

<p>The names of the two data sets being compared.  These names affect the output parameters.
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_cutoffmethod">cutoffMethod</code></td>
<td>

<p>This variable is used to determine how modules are defined in each data set.  Must be one of four options:
(1) &quot;assigned&quot; -&gt; use the module assignments in colorh (default); (2) &quot;kME&quot; -&gt; any gene with kME &gt; cutoff is
in the module; (3) &quot;numGenes&quot; -&gt; the top cutoff number of genes based on kME is in the module; and (4)
&quot;pvalue&quot; -&gt; any gene with correlation pvalue &lt; cutoff is in the module (this includes both positively and
negatively-correlated genes). 
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_cutoff">cutoff</code></td>
<td>

<p>For all cutoffMethods other than &quot;assigned&quot;, this parameter is used as the described cutoff value.
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_omitgrey">omitGrey</code></td>
<td>

<p>If TRUE the grey modules (non-module genes) for both networks are not returned.
</p>
</td></tr>
<tr><td><code id="overlapTableUsingKME_+3A_datisexpression">datIsExpression</code></td>
<td>

<p>If TRUE (default), dat1/2 is assumed to be expression data.  If FALSE, dat1/2 is assumed to be a table of kME values.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>PvaluesHypergeo</code></td>
<td>

<p>A table of p-values showing significance of module overlap based on the hypergeometric test. Note that these p-values are not corrected for multiple comparisons.
</p>
</td></tr>
<tr><td><code>AllCommonGenes</code></td>
<td>

<p>A character vector of all genes in common between the two data sets.
</p>
</td></tr>
<tr><td><code>Genes&lt;name1/2&gt;</code></td>
<td>

<p>A list of character vectors of all genes in each module in both data sets.  All genes in the MOD module in data set MM1 could be found using &quot;&lt;outputVariableName&gt;$GenesMM1$MM1_MOD&quot;
</p>
</td></tr>
<tr><td><code>OverlappingGenes</code></td>
<td>

<p>A list of character vectors of all genes for each between-set comparison from PvaluesHypergeo.  All genes in MOD.A from MM1 that are also in MOD.B from MM2 could be found using &quot;&lt;outputVariableName&gt;$OverlappingGenes$MM1_MOD.A_MM2_MOD.B&quot;
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+overlapTable">overlapTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: first generate simulated data.

set.seed(100)
ME.A = sample(1:100,50);  ME.B = sample(1:100,50)
ME.C = sample(1:100,50);  ME.D = sample(1:100,50) 
ME.E = sample(1:100,50);  ME.F = sample(1:100,50) 
ME.G = sample(1:100,50);  ME.H = sample(1:100,50) 
ME1     = data.frame(ME.A, ME.B, ME.C, ME.D, ME.E)
ME2     = data.frame(ME.A, ME.C, ME.D, ME.E, ME.F, ME.G, ME.H)
simDat1 = simulateDatExpr(ME1,1000,c(0.2,0.1,0.08,0.05,0.04,0.3), signed=TRUE)
simDat2 = simulateDatExpr(ME2,1000,c(0.2,0.1,0.08,0.05,0.04,0.03,0.02,0.3), 
                          signed=TRUE)

# Now run the function using assigned genes
results = overlapTableUsingKME(simDat1$datExpr, simDat2$datExpr, 
                   labels2colors(simDat1$allLabels), labels2colors(simDat2$allLabels), 
                   cutoffMethod="assigned")
results$PvaluesHypergeo

# Now run the function using a p-value cutoff, and inputting the original MEs
colnames(ME1) = standardColors(5);  colnames(ME2) = standardColors(7)
results = overlapTableUsingKME(simDat1$datExpr, simDat2$datExpr, 
                      labels2colors(simDat1$allLabels), 
                      labels2colors(simDat2$allLabels), 
                      ME1, ME2, cutoffMethod="pvalue", cutoff=0.05)
results$PvaluesHypergeo

# Check which genes are in common between the black modules from set 1 and 
# the green module from set 2
results$OverlappingGenes$MM1_green_MM2_black
</code></pre>

<hr>
<h2 id='pickHardThreshold'> Analysis of scale free topology for hard-thresholding. </h2><span id='topic+pickHardThreshold'></span><span id='topic+pickHardThreshold.fromSimilarity'></span>

<h3>Description</h3>

<p>Analysis of scale free topology for multiple hard thresholds. The aim is to help the
user pick an appropriate threshold for network construction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickHardThreshold(
  data, 
  dataIsExpr,
  RsquaredCut = 0.85, 
  cutVector = seq(0.1, 0.9, by = 0.05), 
  moreNetworkConcepts = FALSE,
  removeFirst = FALSE, nBreaks = 10, 
  corFnc = "cor", corOptions = "use = 'p'")

pickHardThreshold.fromSimilarity(
    similarity,
    RsquaredCut = 0.85, 
    cutVector = seq(0.1, 0.9, by = 0.05),
    moreNetworkConcepts=FALSE, 
    removeFirst = FALSE, nBreaks = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pickHardThreshold_+3A_data">data</code></td>
<td>
<p> expression data in a matrix or data frame. Rows correspond to samples and columns to
genes. </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_dataisexpr">dataIsExpr</code></td>
<td>
<p> logical: should the data be interpreted as expression (or other numeric) data, or as a
similarity matrix of network nodes? </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_similarity">similarity</code></td>
<td>
<p> similarity matrix: a symmetric matrix with entries between -1 and 1 and unit diagonal.</p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_rsquaredcut">RsquaredCut</code></td>
<td>
<p> desired minimum scale free topology fitting index <code class="reqn">R^2</code>. </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_cutvector">cutVector</code></td>
<td>
<p>  a vector of hard threshold cuts for which the scale free topology fit indices
are to be calculated. </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_morenetworkconcepts">moreNetworkConcepts</code></td>
<td>
<p>logical: should additional network concepts be calculated? If <code>TRUE</code>,
the function will calculate how the network density, the network heterogeneity, and the network
centralization depend on the power. For the definition of these additional network concepts, see Horvath and
Dong (2008).  PloS Comp Biol.  </p>
</td></tr> 
<tr><td><code id="pickHardThreshold_+3A_removefirst">removeFirst</code></td>
<td>
<p> should the first bin be removed from the connectivity histogram? </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_nbreaks">nBreaks</code></td>
<td>
<p> number of bins in connectivity histograms </p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_corfnc">corFnc</code></td>
<td>
<p> a character string giving the correlation function to be used in adjacency calculation.
</p>
</td></tr>
<tr><td><code id="pickHardThreshold_+3A_coroptions">corOptions</code></td>
<td>
<p> further options to the correlation function specified in <code>corFnc</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates unsigned networks by thresholding the correlation matrix using thresholds given
in <code>cutVector</code>. For each power the scale free topology fit index is calculated
and returned along with other information on connectivity.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>cutEstimate</code></td>
<td>
<p> estimate of an appropriate hard-thresholding cut: the lowest cut for which
the scale free topology fit <code class="reqn">R^2</code> exceeds <code>RsquaredCut</code>. If <code class="reqn">R^2</code> is below <code>RsquaredCut</code> for all
cuts, <code>NA</code> is returned. </p>
</td></tr>
<tr><td><code>fitIndices</code></td>
<td>
<p> a data frame containing the fit indices for scale free topology. The columns
contain the hard threshold, Student p-value for the correlation threshold, 
adjusted <code class="reqn">R^2</code> for the linear fit, the linear coefficient, adjusted
<code class="reqn">R^2</code> for a more complicated fit models, mean connectivity, median connectivity and maximum
connectivity.  If input <code>moreNetworkConcepts</code> is <code>TRUE</code>, 3 additional columns containing network
density, centralization, and heterogeneity.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath</p>


<h3>References</h3>

<p> Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+signumAdjacencyFunction">signumAdjacencyFunction</a></code> </p>

<hr>
<h2 id='pickSoftThreshold'> Analysis of scale free topology for soft-thresholding </h2><span id='topic+pickSoftThreshold'></span><span id='topic+pickSoftThreshold.fromSimilarity'></span>

<h3>Description</h3>

<p>Analysis of scale free topology for multiple soft thresholding powers. The aim is to help the user pick
an appropriate soft-thresholding power for network construction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickSoftThreshold(
  data, 
  dataIsExpr = TRUE,
  weights = NULL,
  RsquaredCut = 0.85, 
  powerVector = c(seq(1, 10, by = 1), seq(12, 20, by = 2)), 
  removeFirst = FALSE, nBreaks = 10, blockSize = NULL, 
  corFnc = cor, corOptions = list(use = 'p'), 
  networkType = "unsigned",
  moreNetworkConcepts = FALSE,
  gcInterval = NULL,
  verbose = 0, indent = 0)

pickSoftThreshold.fromSimilarity(
    similarity,
    RsquaredCut = 0.85, 
    powerVector = c(seq(1, 10, by = 1), seq(12, 20, by = 2)),
    removeFirst = FALSE, nBreaks = 10, blockSize = 1000,
    moreNetworkConcepts=FALSE, 
    verbose = 0, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pickSoftThreshold_+3A_data">data</code></td>
<td>
<p> expression data in a matrix or data frame. Rows correspond to samples and columns to
genes. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_dataisexpr">dataIsExpr</code></td>
<td>
<p> logical: should the data be interpreted as expression (or other numeric) data, or as a
similarity matrix of network nodes? </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>data</code> to be used in correlation calculation.
A matrix of the same dimensions as <code>datExpr</code>, containing non-negative weights. Only used with Pearson
correlation.</p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_similarity">similarity</code></td>
<td>
<p> similarity matrix: a symmetric matrix with entries between 0 and 1 and unit diagonal. The only
transformation applied to <code>similarity</code> is raising it to a power. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_rsquaredcut">RsquaredCut</code></td>
<td>
<p> desired minimum scale free topology fitting index <code class="reqn">R^2</code>. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_powervector">powerVector</code></td>
<td>
<p> a vector of soft thresholding powers for which the scale free topology fit indices
are to be calculated. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_removefirst">removeFirst</code></td>
<td>
<p> should the first bin be removed from the connectivity histogram? </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_nbreaks">nBreaks</code></td>
<td>
<p> number of bins in connectivity histograms </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_blocksize">blockSize</code></td>
<td>
<p> block size into which the calculation of connectivity should be broken up. If not given,
a suitable value will be calculated using function <code>blockSize</code> and printed if <code>verbose&gt;0</code>. If R runs
into memory problems, decrease this value. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_corfnc">corFnc</code></td>
<td>
<p>the correlation function to be used in adjacency calculation. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_coroptions">corOptions</code></td>
<td>
<p> a list giving further options to the correlation function specified in <code>corFnc</code>. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_morenetworkconcepts">moreNetworkConcepts</code></td>
<td>
<p>logical: should additional network concepts be calculated? If <code>TRUE</code>, the
function will calculate how the network density, the network heterogeneity, and the network centralization
depend on the power. For the definition of these additional network concepts, see Horvath and Dong (2008).
PloS Comp Biol.  </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_gcinterval">gcInterval</code></td>
<td>
<p>a number specifying in interval (in terms of individual genes) in which garbage
collection will be performed. The actual interval will never be less than <code>blockSize</code>.</p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="pickSoftThreshold_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates weighted networks either by
interpreting <code>data</code> directly as similarity, or first transforming it to similarity of the type
specified by <code>networkType</code>.
The weighted networks are obtained by raising the similarity to the powers given in <code>powerVector</code>. 
For each power the scale free topology fit index is calculated
and returned along with other information on connectivity.
</p>
<p>On systems with multiple cores or processors, 
the function pickSoftThreshold takes advantage of parallel processing if the function 
<code><a href="#topic+enableWGCNAThreads">enableWGCNAThreads</a></code> has been called to allow parallel processing and set up the parallel
calculation back-end.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>powerEstimate</code></td>
<td>
<p> estimate of an appropriate soft-thresholding power: the lowest power for which
the scale free topology fit <code class="reqn">R^2</code> exceeds <code>RsquaredCut</code>. If <code class="reqn">R^2</code> is below <code>RsquaredCut</code> 
for all powers, <code>NA</code> is returned. </p>
</td></tr>
<tr><td><code>fitIndices</code></td>
<td>
<p> a data frame containing the fit indices for scale free topology. The columns
contain the soft-thresholding power, adjusted <code class="reqn">R^2</code> for the linear fit, the linear coefficient, adjusted
<code class="reqn">R^2</code> for a more complicated fit models, mean connectivity, median connectivity and maximum
connectivity. If input <code>moreNetworkConcepts</code> is <code>TRUE</code>, 3 additional columns containing network
density, centralization, and heterogeneity.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>


<h3>References</h3>

<p> Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+softConnectivity">softConnectivity</a></code> </p>

<hr>
<h2 id='plotClusterTreeSamples'> Annotated clustering dendrogram of microarray samples </h2><span id='topic+plotClusterTreeSamples'></span>

<h3>Description</h3>

<p>This function plots an annotated clustering dendorgram of microarray samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotClusterTreeSamples(
  datExpr, 
  y = NULL, 
  traitLabels = NULL, 
  yLabels = NULL,
  main = if (is.null(y)) "Sample dendrogram" else 
                         "Sample dendrogram and trait indicator", 
  setLayout = TRUE, autoColorHeight = TRUE, colorHeight = 0.3,
  dendroLabels = NULL, 
  addGuide = FALSE, guideAll = TRUE, 
  guideCount = NULL, guideHang = 0.2, 
  cex.traitLabels = 0.8, 
  cex.dendroLabels = 0.9, 
  marAll = c(1, 5, 3, 1), 
  saveMar = TRUE, 
  abHeight = NULL, abCol = "red", 
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotClusterTreeSamples_+3A_datexpr">datExpr</code></td>
<td>
<p>  a data frame containing expression data, with rows corresponding to samples and
columns to genes. Missing values are allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_y">y</code></td>
<td>
<p> microarray sample trait. Either a vector with one entry per sample, or a matrix in which each
column corresponds to a (different) trait and each row to a sample. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_traitlabels">traitLabels</code></td>
<td>
<p> labels to be printed next to the color rows depicting sample traits. Defaults to
column names of <code>y</code>.</p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_ylabels">yLabels</code></td>
<td>
<p>Optional labels to identify colors in the row identifying the sample classes.
If given, must be of the same dimensions as <code>y</code>. Each label that occurs will be displayed
once.</p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_main">main</code></td>
<td>
<p> title for the plot. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_setlayout">setLayout</code></td>
<td>
<p> logical: should the plotting device be partitioned into a standard layout? 
If <code>FALSE</code>, the user is responsible for partitioning. The function expects two regions of the same
width, the first one immediately above the second one. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_autocolorheight">autoColorHeight</code></td>
<td>
<p> logical: should the height of the color area below the dendrogram be
automatically adjusted for the number of traits? Only effective if <code>setLayout</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_colorheight">colorHeight</code></td>
<td>
<p> Specifies the height of the color area under dendrogram as a fraction of the
height of the dendrogram area. Only effective when <code>autoColorHeight</code> above is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_dendrolabels">dendroLabels</code></td>
<td>
<p> dendrogram labels. Set to <code>FALSE</code> to disable dendrogram labels altogether;
set to <code>NULL</code> to use row labels of <code>datExpr</code>. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_addguide">addGuide</code></td>
<td>
<p> logical: should vertical &quot;guide lines&quot; be added to the dendrogram plot? The lines make
it easier to identify color codes with individual samples. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_guideall">guideAll</code></td>
<td>
<p> logical: add a guide line for every sample? Only effective for <code>addGuide</code> set
<code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_guidecount">guideCount</code></td>
<td>
<p> number of guide lines to be plotted. Only effective when <code>addGuide</code> is
<code>TRUE</code> and <code>guideAll</code> is <code>FALSE</code>.  </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_guidehang">guideHang</code></td>
<td>
<p> fraction of the dendrogram height to leave between the top end of the guide line and
the dendrogram merge height. If the guide lines overlap with dendrogram labels, increase <code>guideHang</code>
to leave more space for the labels. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_cex.traitlabels">cex.traitLabels</code></td>
<td>
<p> character expansion factor for trait labels. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_cex.dendrolabels">cex.dendroLabels</code></td>
<td>
<p> character expansion factor for dendrogram (sample) labels. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_marall">marAll</code></td>
<td>
<p> a 4-element vector giving the bottom, left, top and right margins around the combined
plot. Note that this is not the same as setting the margins via a call to <code><a href="graphics.html#topic+par">par</a></code>, because the
bottom margin of the dendrogram and the top margin of the color underneath are always zero. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_savemar">saveMar</code></td>
<td>
<p> logical: save margins setting before starting the plot and restore on exit? </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_abheight">abHeight</code></td>
<td>
<p> optional specification of the height for a horizontal line in the dendrogram, see
<code><a href="graphics.html#topic+abline">abline</a></code>. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_abcol">abCol</code></td>
<td>
<p> color for plotting the horizontal line. </p>
</td></tr>
<tr><td><code id="plotClusterTreeSamples_+3A_...">...</code></td>
<td>
<p> other graphical parameters to <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates an average linkage hierarchical clustering dendrogram (see
<code><a href="stats.html#topic+hclust">hclust</a></code>) of samples from the given expression data, using Eclidean distance of
samples. The dendrogram is plotted together with color annotation for the samples. 
</p>
<p>The trait <code>y</code> must be numeric. If <code>y</code> is integer, the colors will correspond to values. If
<code>y</code> is continouos, it will be dichotomized to two classes, below and above median.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="#topic+plotDendroAndColors">plotDendroAndColors</a></code> </p>

<hr>
<h2 id='plotColorUnderTree'>Plot color rows in a given order, for example under a dendrogram</h2><span id='topic+plotColorUnderTree'></span><span id='topic+plotOrderedColors'></span>

<h3>Description</h3>

<p>Plot color rows encoding information about objects in a given order, for example the order of 
a clustering dendrogram, 
usually below the dendrogram or a barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotOrderedColors(
   order, 
   colors, 
   main = "",
   rowLabels = NULL, 
   rowWidths = NULL, 
   rowText = NULL,
   rowTextAlignment = c("left", "center", "right"),
   rowTextIgnore = NULL,
   textPositions = NULL, 
   addTextGuide = TRUE,
   cex.rowLabels = 1, 
   cex.rowText = 0.8,
   startAt = 0,
   align = c("center", "edge"),
   separatorLine.col = "black",
   ...)

plotColorUnderTree(
   dendro, 
   colors,
   rowLabels = NULL,
   rowWidths = NULL,
   rowText = NULL,
   rowTextAlignment = c("left", "center", "right"),
   rowTextIgnore = NULL,
   textPositions = NULL,
   addTextGuide = TRUE,
   cex.rowLabels = 1,
   cex.rowText = 0.8,
   separatorLine.col = "black",
   ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotColorUnderTree_+3A_order">order</code></td>
<td>
<p>A vector giving the order of the objects. Must have the same length as <code>colors</code> if
<code>colors</code> is a vector, or as the number of rows if <code>colors</code> is a matrix or data frame.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_dendro">dendro</code></td>
<td>
<p>A hierarchical clustering dendrogram such one returned by <code><a href="stats.html#topic+hclust">hclust</a></code>.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_colors">colors</code></td>
<td>
<p>Coloring of objects on the dendrogram. Either a vector (one color per object) or a
matrix (can also be an array or a data frame)
with each column giving one color per object. Each column will be plotted as a horizontal row of colors
under the dendrogram.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_main">main</code></td>
<td>
<p>Optional main title.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_rowlabels">rowLabels</code></td>
<td>
<p>Labels for the colorings given in <code>colors</code>. The labels will be printed to the
left of the color rows in the plot. If the argument is given, it must be a vector of length
equal to the number of columns in <code>colors</code>. If not given, <code>names(colors)</code>
will be used if available. If not, sequential numbers
starting from 1 will be used.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_rowwidths">rowWidths</code></td>
<td>
<p> Optional specification of relative row widths for the color and text (if given) rows.
Need not sum to 1. </p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_rowtext">rowText</code></td>
<td>
<p>Optional labels to identify colors in the color rows. 
If given, must be of the same dimensions as <code>colors</code>. Each label that occurs will be displayed
once.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_rowtextalignment">rowTextAlignment</code></td>
<td>
<p>Character string specifying whether the labels should be left-justified to the
start of the largest block of each label, centered in the middle, or right-justified to the end of the
largest block.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_rowtextignore">rowTextIgnore</code></td>
<td>
<p>Optional specifications of labels that should be ignored when displaying them using
<code>rowText</code> above. </p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_textpositions">textPositions</code></td>
<td>
<p>optional numeric vector of the same length as the number of columns in <code>rowText</code>
giving the color rows under which the text rows should appear.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_addtextguide">addTextGuide</code></td>
<td>
<p> logical: should guide lines be added for the text rows (if given)? </p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_cex.rowlabels">cex.rowLabels</code></td>
<td>
<p>Font size scale factor for the row labels. See <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_cex.rowtext">cex.rowText</code></td>
<td>
<p> character expansion factor for text rows (if given). </p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_startat">startAt</code></td>
<td>
<p>A numeric value indicating where in relationship to the left edge of the plot the center
of the first rectangle should be. Useful values are 0 if ploting color under a dendrogram, and 0.5 if
ploting colors under a barplot. </p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_align">align</code></td>
<td>
<p>Controls the alignment of the color rectangles. <code>"center"</code> means aligning centers of the rectangles on
equally spaced values; <code>"edge"</code> means aligning edges of the first and last rectangles on the edges of the plot
region.</p>
</td></tr>
<tr><td><code id="plotColorUnderTree_+3A_separatorline.col">separatorLine.col</code></td>
<td>
<p>Color of the line separating rows of color rectangles. If <code>NA</code>, no lines will be drawn.</p>
</td></tr> 
<tr><td><code id="plotColorUnderTree_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed on to the plotting method (such as <code>main</code> for the main
title etc).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is often useful to plot dendrograms or other plots (e.g., barplots) 
of objects together with additional information about the
objects, for example module assignment (by color) that was obtained by cutting a hierarchical
dendrogram or external color-coded measures such as gene significance.
This function provides a way to do so. The calling code should section the screen into two 
(or more) parts, plot the dendrogram (via <code>plot(hclust)</code>) or other information 
in the upper section and use this function
to plot color annotation in the order corresponding to the dendrogram in the lower section. 
</p>


<h3>Value</h3>

<p> A list with the following components
</p>
<table role = "presentation">
<tr><td><code>colorRectangles</code></td>
<td>
<p>A list with one component per color row. Each component
is a list with 4 elements <code>xl, yb, xr, yt</code> giving the left, bottom, right and top coordinates of the rectangles in
that row.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function replaces <code>plotHclustColors</code> in package <code>moduleColor</code>.
</p>


<h3>Author(s)</h3>

<p>Steve Horvath <a href="mailto:SHorvath@mednet.ucla.edu">SHorvath@mednet.ucla.edu</a> and Peter Langfelder <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for module detection in a dendrogram;
</p>
<p><code><a href="#topic+plotDendroAndColors">plotDendroAndColors</a></code> for automated plotting of dendrograms and colors in one step.</p>

<hr>
<h2 id='plotCor'>Red and Green Color Image of Correlation Matrix</h2><span id='topic+plotCor'></span>

<h3>Description</h3>

<p>This function produces a red and green color image of a correlation
matrix using an RGB color specification. Increasingly positive
correlations are represented with reds of increasing intensity, and
increasingly negative correlations are represented with greens of
increasing intensity.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCor(x, new=FALSE, nrgcols=50, labels=FALSE, labcols=1, title="", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCor_+3A_x">x</code></td>
<td>
<p>a matrix of numerical values.</p>
</td></tr>
<tr><td><code id="plotCor_+3A_new">new</code></td>
<td>
<p>If <code>new=F</code>, <code>x</code> must already be a correlation
matrix. If <code>new=T</code>, the correlation matrix for the columns of
<code>x</code> is computed and displayed in the image.</p>
</td></tr> 
<tr><td><code id="plotCor_+3A_nrgcols">nrgcols</code></td>
<td>
<p>the number of colors (&gt;= 1) to be used in the red
and green palette.</p>
</td></tr> 
<tr><td><code id="plotCor_+3A_labels">labels</code></td>
<td>
<p>vector of character strings to be placed at the
tickpoints, labels for the columns of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotCor_+3A_labcols">labcols</code></td>
<td>
<p>colors to be used for the labels of the columns of
<code>x</code>. <code>labcols</code> can have either length 1, in which case
all the labels are displayed using the same color, or the same
length as <code>labels</code>, in which case a color is specified for the
label of each column of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotCor_+3A_title">title</code></td>
<td>
<p>character string, overall title for the plot.</p>
</td></tr>
<tr><td><code id="plotCor_+3A_...">...</code></td>
<td>
<p>graphical parameters may also be supplied as arguments to
the function (see <code><a href="graphics.html#topic+par">par</a></code>). For comparison purposes, 
it is good to set <code>zlim=c(-1,1)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sandrine Dudoit, <a href="mailto:sandrine@stat.berkeley.edu">sandrine@stat.berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotMat">plotMat</a></code>,<code><a href="#topic+rgcolors.func">rgcolors.func</a></code>,
<code><a href="#topic+cor">cor</a></code>, <code><a href="graphics.html#topic+image">image</a></code>,
<code><a href="grDevices.html#topic+rgb">rgb</a></code>.</p>

<hr>
<h2 id='plotDendroAndColors'> Dendrogram plot with color annotation of objects </h2><span id='topic+plotDendroAndColors'></span>

<h3>Description</h3>

<p>This function plots a hierarchical clustering dendrogram and color annotation(s) of objects in the
dendrogram underneath.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDendroAndColors(
  dendro, 
  colors, 
  groupLabels = NULL, 
  rowText = NULL,
  rowTextAlignment = c("left", "center", "right"),
  rowTextIgnore = NULL,
  textPositions = NULL,
  setLayout = TRUE, 
  autoColorHeight = TRUE, 
  colorHeight = 0.2, 
  colorHeightBase = 0.2, 
  colorHeightMax = 0.6,
  rowWidths = NULL, 
  dendroLabels = NULL, 
  addGuide = FALSE, guideAll = FALSE, 
  guideCount = 50, guideHang = 0.2, 
  addTextGuide = FALSE,
  cex.colorLabels = 0.8, cex.dendroLabels = 0.9, 
  cex.rowText = 0.8,
  marAll = c(1, 5, 3, 1), saveMar = TRUE, 
  abHeight = NULL, abCol = "red", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDendroAndColors_+3A_dendro">dendro</code></td>
<td>
<p> a hierarchical clustering dendrogram such as one produced by
<code><a href="stats.html#topic+hclust">hclust</a></code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_colors">colors</code></td>
<td>
<p> Coloring of objects on the dendrogram. Either a vector (one color per object) or a
matrix (can also be an array or a data frame)
with each column giving one color per object. Each column will be plotted as a horizontal row of colors
under the dendrogram. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_grouplabels">groupLabels</code></td>
<td>
<p> Labels for the colorings given in <code>colors</code>. The labels will be printed to the
left of the color rows in the plot. If the argument is given, it must be a vector of length
equal to the number of columns in <code>colors</code>. If not given, <code>names(colors)</code>
will be used if available. If not, sequential numbers starting from 1 will be used.</p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_rowtext">rowText</code></td>
<td>
<p>Optional labels to identify colors in the color rows. 
If given, must be either the same dimensions as <code>colors</code> or must have the same number of rows and
<code>textPositions</code> must be used to specify which columns of <code>colors</code> each column of <code>rowText</code>
corresponds to. Each label that occurs will be displayed 
once, under the largest continuous block of the corresponding <code>colors</code>.</p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_rowtextalignment">rowTextAlignment</code></td>
<td>
<p>Character string specifying whether the labels should be left-justified to the
start of the largest block of each label, centered in the middle, or right-justified to the end of the 
largest block.</p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_rowtextignore">rowTextIgnore</code></td>
<td>
<p>Optional specifications of labels that should be ignored when displaying them using 
<code>rowText</code> above. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_textpositions">textPositions</code></td>
<td>
<p>optional numeric vector of the same length as the number of columns in <code>rowText</code>
giving the color rows under which the text rows should appear.</p>
</td></tr> 
<tr><td><code id="plotDendroAndColors_+3A_setlayout">setLayout</code></td>
<td>
<p> logical: should the plotting device be partitioned into a standard layout?
If <code>FALSE</code>, the user is responsible for partitioning. The function expects two regions of the same
width, the first one immediately above the second one. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_autocolorheight">autoColorHeight</code></td>
<td>
<p> logical: should the height of the color area below the dendrogram be
automatically adjusted for the number of traits? Only effective if <code>setLayout</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_colorheight">colorHeight</code></td>
<td>
<p> specifies the height of the color area under dendrogram as a fraction of the
height of the dendrogram area. Only effective when <code>autoColorHeight</code> above is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_colorheightbase">colorHeightBase</code></td>
<td>
<p>when <code>autoColorHeight</code> is <code>TRUE</code>, this specifies the minimum height of the color
area (the height when there is one color row).</p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_colorheightmax">colorHeightMax</code></td>
<td>
<p>when <code>autoColorHeight</code> is <code>TRUE</code>, this specifies the maximum height of the color
area (the height when there are many color rows).</p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_rowwidths">rowWidths</code></td>
<td>
<p> optional specification of relative row widths for the color and text (if given) rows.
Need not sum to 1. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_dendrolabels">dendroLabels</code></td>
<td>
<p> dendrogram labels. Set to <code>FALSE</code> to disable dendrogram labels altogether;
set to <code>NULL</code> to use row labels of <code>datExpr</code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_addguide">addGuide</code></td>
<td>
<p> logical: should vertical &quot;guide lines&quot; be added to the dendrogram plot? The lines make
it easier to identify color codes with individual samples. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_guideall">guideAll</code></td>
<td>
<p> logical: add a guide line for every sample? Only effective for <code>addGuide</code> set
<code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_guidecount">guideCount</code></td>
<td>
<p> number of guide lines to be plotted. Only effective when <code>addGuide</code> is
<code>TRUE</code> and <code>guideAll</code> is <code>FALSE</code>.  </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_guidehang">guideHang</code></td>
<td>
<p> fraction of the dendrogram height to leave between the top end of the guide line and
the dendrogram merge height. If the guide lines overlap with dendrogram labels, increase <code>guideHang</code>
to leave more space for the labels. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_addtextguide">addTextGuide</code></td>
<td>
<p> logical: should guide lines be added for the text rows (if given)? </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_cex.colorlabels">cex.colorLabels</code></td>
<td>
<p> character expansion factor for trait labels. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_cex.dendrolabels">cex.dendroLabels</code></td>
<td>
<p> character expansion factor for dendrogram (sample) labels. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_cex.rowtext">cex.rowText</code></td>
<td>
<p> character expansion factor for text rows (if given). </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_marall">marAll</code></td>
<td>
<p> a vector of length 4 giving the bottom, left, top and right margins of the combined
plot. There is no margin between the dendrogram and the color plot underneath. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_savemar">saveMar</code></td>
<td>
<p> logical: save margins setting before starting the plot and restore on exit? </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_abheight">abHeight</code></td>
<td>
<p> optional specification of the height for a horizontal line in the dendrogram, see
<code><a href="graphics.html#topic+abline">abline</a></code>. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_abcol">abCol</code></td>
<td>
<p> color for plotting the horizontal line. </p>
</td></tr>
<tr><td><code id="plotDendroAndColors_+3A_...">...</code></td>
<td>
<p> other graphical parameters to <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function slits the plotting device into two regions, plots the given dendrogram in the upper
region, then plots color rows in the region below the dendrogram. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+plotColorUnderTree">plotColorUnderTree</a></code> </p>

<hr>
<h2 id='plotEigengeneNetworks'> Eigengene network plot </h2><span id='topic+plotEigengeneNetworks'></span>

<h3>Description</h3>

<p>This function plots dendrogram and eigengene representations of (consensus) eigengenes networks. 
In the case of conensus eigengene networks the function also plots pairwise preservation  measures
between consensus networks in different sets. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotEigengeneNetworks(
  multiME, 
  setLabels, 
  letterSubPlots = FALSE, Letters = NULL, 
  excludeGrey = TRUE, greyLabel = "grey", 
  plotDendrograms = TRUE, plotHeatmaps = TRUE, 
  setMargins = TRUE, marDendro = NULL, marHeatmap = NULL,
  colorLabels = TRUE, signed = TRUE, 
  heatmapColors = NULL, 
  plotAdjacency = TRUE,
  printAdjacency = FALSE, cex.adjacency = 0.9,
  coloredBarplot = TRUE, barplotMeans = TRUE, barplotErrors = FALSE, 
  plotPreservation = "standard",
  zlimPreservation = c(0, 1), 
  printPreservation = FALSE, cex.preservation = 0.9, 
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotEigengeneNetworks_+3A_multime">multiME</code></td>
<td>
<p> either a single data frame containing the module eigengenes, or 
module eigengenes in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). The multi-set format is a vector of
lists, one per set. Each set must contain a component <code>data</code> whose
rows correspond to samples and columns to eigengenes. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_setlabels">setLabels</code></td>
<td>
<p> A vector of character strings that label sets in <code>multiME</code>. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_lettersubplots">letterSubPlots</code></td>
<td>
<p> logical: should subplots be lettered? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_letters">Letters</code></td>
<td>
<p>optional specification of a sequence of letters for lettering. Defaults to &quot;ABCD&quot;... </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_excludegrey">excludeGrey</code></td>
<td>
<p> logical: should the grey module eigengene be excluded from the plots? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_greylabel">greyLabel</code></td>
<td>
<p> label for the grey module. Usually either &quot;grey&quot; or the number 0. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_plotdendrograms">plotDendrograms</code></td>
<td>
<p> logical: should eigengene dendrograms be plotted? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_plotheatmaps">plotHeatmaps</code></td>
<td>
<p> logical: should eigengene network heatmaps be plotted? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_setmargins">setMargins</code></td>
<td>
<p> logical: should margins be set? See <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_mardendro">marDendro</code></td>
<td>
<p> a vector of length 4 giving the margin setting for dendrogram plots. See
<code><a href="graphics.html#topic+par">par</a></code>. If <code>setMargins</code> is <code>TRUE</code> and <code>marDendro</code> is not given, the
function will provide reasonable default values. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_marheatmap">marHeatmap</code></td>
<td>
<p> a vector of length 4 giving the margin setting for heatmap plots. See 
<code><a href="graphics.html#topic+par">par</a></code>. If <code>setMargins</code> is <code>TRUE</code> and <code>marDendro</code> is not given, the  
function will provide reasonable default values. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_colorlabels">colorLabels</code></td>
<td>
<p> logical: should module eigengene names be interpreted as color names and the colors
used to label heatmap plots and barplots? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_signed">signed</code></td>
<td>
<p> logical: should eigengene networks be constructed as signed? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_heatmapcolors">heatmapColors</code></td>
<td>
<p> color palette for heatmaps. Defaults to <code><a href="grDevices.html#topic+heat.colors">heat.colors</a></code> when
<code>signed</code> is <code>FALSE</code>, and to <code><a href="#topic+redWhiteGreen">redWhiteGreen</a></code> when <code>signed</code> is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_plotadjacency">plotAdjacency</code></td>
<td>
<p> logical: should module eigengene heatmaps plot adjacency (ranging from 0 to 1),
or correlation (ranging from -1 to 1)? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_printadjacency">printAdjacency</code></td>
<td>
<p> logical: should the numerical values be printed into the adjacency or
correlation heatmap? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_cex.adjacency">cex.adjacency</code></td>
<td>
<p> character expansion factor for printing of numerical values into the adjacency or 
correlation heatmap </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_coloredbarplot">coloredBarplot</code></td>
<td>
<p> logical: should the barplot of eigengene adjacency preservation distinguish
individual contributions by color? This is possible only if <code>colorLabels</code> is <code>TRUE</code> and module
eigengene names encode valid colors. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_barplotmeans">barplotMeans</code></td>
<td>
<p> logical: plot mean preservation in the barplot? This option effectively rescales
the preservation by the number of eigengenes in the network. If means are plotted, the barplot is not
colored. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_barploterrors">barplotErrors</code></td>
<td>
<p> logical: should standard errors of the mean preservation be plotted? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_plotpreservation">plotPreservation</code></td>
<td>
<p> a character string specifying which type of preservation measure to plot.
Allowed values are (unique abbreviations of)  <code>"standard"</code>, <code>"hyperbolic"</code>, <code>"both"</code>. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_zlimpreservation">zlimPreservation</code></td>
<td>
<p> a vector of length 2 giving the value limits for the preservation heatmaps. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_printpreservation">printPreservation</code></td>
<td>
<p> logical: should preservation values be printed within the heatmap? </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_cex.preservation">cex.preservation</code></td>
<td>
<p> character expansion factor for preservation display. </p>
</td></tr>
<tr><td><code id="plotEigengeneNetworks_+3A_...">...</code></td>
<td>
<p> other graphical arguments to function <code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consensus eigengene networks consist of a fixed set of eigengenes &quot;expressed&quot; in several different
sets. Network connection strengths are given by eigengene correlations. This function aims to visualize
the networks as well as their similarities and differences across sets. 
</p>
<p>The function partitions the screen appropriately and plots eigengene dendrograms in the top row, then a
square matrix of plots: heatmap plots of eigengene networks in each set on the diagonal, heatmap plots of
pairwise preservation networks below the diagonal, and barplots of aggregate network preservation of
individual eigengenes above the diagonal. A preservation plot or barplot in the row i and column j of the
square matrix represents the preservation between sets i and j. 
</p>
<p>Individual eigengenes are labeled by their name in the dendrograms; in the heatmaps and barplots they
can optionally be labeled by color squares. For compatibility with other functions, the color labels are
encoded in the eigengene names by prefixing the color with two letters, such as <code>"MEturquoise"</code>.  
</p>
<p>Two types of network preservation can be plotted: the <code>"standard"</code> is simply the difference
between adjacencies in the two compared sets. The <code>"hyperbolic"</code> difference de-emphasizes the
preservation of low adjacencies. When <code>"both"</code> is specified, standard preservation is plotted in the
lower triangle and hyperbolic in the upper triangle of each preservation heatmap. 
</p>
<p>If the eigengenes are labeled by color, the bars in the barplot can be split into segments representing
the contribution of each eigengene and labeled by the contribution. For example, a yellow segment in a
bar labeled by a turquoise square represents the preservation of the adjacency between the yellow and
turquoise eigengenes in the two networks compared by the barplot. 
</p>
<p>For large numbers of eigengenes and/or sets, it may be difficult to get a meaningful plot fit a
standard computer screen. In such cases we recommend using a device such as <code><a href="grDevices.html#topic+postscript">postscript</a></code> or
<code><a href="grDevices.html#topic+pdf">pdf</a></code> where the user can specify large dimensions; such plots can be conveniently viewed in
standard pdf or postscript viewers.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

 
<p>For theory and applications of consensus eigengene networks, see
</p>
<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression
modules. BMC Systems Biology 2007, 1:54
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+labeledHeatmap">labeledHeatmap</a></code>, <code><a href="#topic+labeledBarplot">labeledBarplot</a></code> for annotated heatmaps and barplots;
</p>
<p><code><a href="stats.html#topic+hclust">hclust</a></code> for hierarchical clustering and dendrogram plots
</p>

<hr>
<h2 id='plotMat'>Red and Green Color Image of Data Matrix</h2><span id='topic+plotMat'></span>

<h3>Description</h3>

<p>This function produces a red and green color image of a
data matrix using an RGB color specification. Larger entries are
represented with reds of increasing intensity, and smaller entries
are represented with greens of increasing intensity.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMat(x, nrgcols=50, rlabels=FALSE, clabels=FALSE, rcols=1, ccols=1, title="",...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMat_+3A_x">x</code></td>
<td>
<p>a matrix of numbers.</p>
</td></tr>
<tr><td><code id="plotMat_+3A_nrgcols">nrgcols</code></td>
<td>
<p>the number of colors (&gt;= 1) to be used in the red
and green palette.</p>
</td></tr> 
<tr><td><code id="plotMat_+3A_rlabels">rlabels</code></td>
<td>
<p>vector of character strings to be placed at the row
tickpoints, labels for the rows of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotMat_+3A_clabels">clabels</code></td>
<td>
<p>vector of character strings to be placed at the
column tickpoints, labels for the columns of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotMat_+3A_rcols">rcols</code></td>
<td>
<p>colors to be used for the labels of the rows of
<code>x</code>. <code>rcols</code> can have either length 1, in which case
all the labels are displayed using the same color, or the same
length as <code>rlabels</code>, in which case a color is specified for the
label of each row of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotMat_+3A_ccols">ccols</code></td>
<td>
<p>colors to be used for the labels of the columns of
<code>x</code>. <code>ccols</code> can have either length 1, in which case
all the labels are displayed using the same color, or the same
length as <code>clabels</code>, in which case a color is specified for the
label of each column of <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plotMat_+3A_title">title</code></td>
<td>
<p>character string, overall title for the plot.</p>
</td></tr>
<tr><td><code id="plotMat_+3A_...">...</code></td>
<td>
<p>graphical parameters may also be supplied as arguments  to
the function (see <code><a href="graphics.html#topic+par">par</a></code>).  E.g. <code>zlim=c(-3,3)</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sandrine Dudoit, <a href="mailto:sandrine@stat.berkeley.edu">sandrine@stat.berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCor">plotCor</a></code>, <code><a href="#topic+rgcolors.func">rgcolors.func</a></code>,
<code><a href="#topic+cor">cor</a></code>, <code><a href="graphics.html#topic+image">image</a></code>,
<code><a href="grDevices.html#topic+rgb">rgb</a></code>.</p>

<hr>
<h2 id='plotMEpairs'> Pairwise scatterplots of eigengenes</h2><span id='topic+plotMEpairs'></span>

<h3>Description</h3>

<p>The function produces a matrix of plots containing pairwise scatterplots of given eigengenes, the
distribution of their values and their pairwise correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMEpairs(
   datME, 
   y = NULL, 
   main = "Relationship between module eigengenes", 
   clusterMEs = TRUE, 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMEpairs_+3A_datme">datME</code></td>
<td>
<p>  a data frame containing expression data, with rows corresponding to samples and columns
to genes. Missing values are allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="plotMEpairs_+3A_y">y</code></td>
<td>
<p> optional microarray sample trait vector. Will be treated as an additional eigengene. </p>
</td></tr>
<tr><td><code id="plotMEpairs_+3A_main">main</code></td>
<td>
<p> main title for the plot. </p>
</td></tr>
<tr><td><code id="plotMEpairs_+3A_clustermes">clusterMEs</code></td>
<td>
<p> logical: should the module eigengenes be ordered by their dendrogram? </p>
</td></tr>
<tr><td><code id="plotMEpairs_+3A_...">...</code></td>
<td>
<p> additional graphical parameters to the function <code><a href="graphics.html#topic+pairs">pairs</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces an NxN matrix of plots, where N is the number of eigengenes. In the upper
traingle it plots pairwise scatterplots of module eigengenes (plus the trait <code>y</code>, if given). On the
diagonal it plots histograms of sample values for each eigengene. Below the diagonal, it displays the
pairwise correlations of the eigengenes.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+pairs">pairs</a></code> </p>

<hr>
<h2 id='plotModuleSignificance'> Barplot of module significance </h2><span id='topic+plotModuleSignificance'></span>

<h3>Description</h3>

<p>Plot a barplot of gene significance. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotModuleSignificance(
  geneSignificance, 
  colors, 
  boxplot = FALSE, 
  main = "Gene significance across modules,", 
  ylab = "Gene Significance", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotModuleSignificance_+3A_genesignificance">geneSignificance</code></td>
<td>
<p> a numeric vector giving gene significances. </p>
</td></tr>
<tr><td><code id="plotModuleSignificance_+3A_colors">colors</code></td>
<td>
<p> a character vector specifying module assignment for the genes whose significance is
given in <code>geneSignificance </code>. The modules should be labeled by colors. </p>
</td></tr>
<tr><td><code id="plotModuleSignificance_+3A_boxplot">boxplot</code></td>
<td>
<p> logical: should a boxplot be produced instead of a barplot? </p>
</td></tr>
<tr><td><code id="plotModuleSignificance_+3A_main">main</code></td>
<td>
<p> main title for the plot. </p>
</td></tr>
<tr><td><code id="plotModuleSignificance_+3A_ylab">ylab</code></td>
<td>
<p> y axis label for the plot. </p>
</td></tr>
<tr><td><code id="plotModuleSignificance_+3A_...">...</code></td>
<td>
<p> other graphical parameters to <code><a href="base.html#topic+plot">plot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given individual gene significances and their module assigment, the function calculates the module
significance for each module as the average gene significance of the genes within the module. The result
is plotted in a barplot or boxplot form. Each bar or box is labeled by the corresponding module color.
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology 2007, 1:24
</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="graphics.html#topic+boxplot">boxplot</a></code> </p>

<hr>
<h2 id='plotMultiHist'>
Plot multiple histograms in a single plot 
</h2><span id='topic+plotMultiHist'></span>

<h3>Description</h3>

<p>This function plots density or cumulative distribution function of multiple histograms in a single plot, using
lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMultiHist(
   data, 
   nBreaks = 100, 
   col = 1:length(data), 
   scaleBy = c("area", "max", "none"), 
   cumulative = FALSE, 
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMultiHist_+3A_data">data</code></td>
<td>

<p>A list in which each component corresponds to a separate histogram and is a vector of values to be shown in
each histogram.
</p>
</td></tr>
<tr><td><code id="plotMultiHist_+3A_nbreaks">nBreaks</code></td>
<td>

<p>Number of breaks in the combined plot.
</p>
</td></tr>
<tr><td><code id="plotMultiHist_+3A_col">col</code></td>
<td>

<p>Color of the lines. Should be a vector of the same length as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="plotMultiHist_+3A_scaleby">scaleBy</code></td>
<td>

<p>Method to make the different histograms comparable. The counts are scaled such that either the total area or
the maximum are the same for all histograms, or the histograms are shown without scaling.
</p>
</td></tr>
<tr><td><code id="plotMultiHist_+3A_cumulative">cumulative</code></td>
<td>

<p>Logical: should the cumulative distribution be shown instead of the density?
</p>
</td></tr>
<tr><td><code id="plotMultiHist_+3A_...">...</code></td>
<td>

<p>Other graphical arguments.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, 
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>A list with one component per histogram (component of <code>data</code>), giving the bin midpoints</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>A list with one component per histogram (component of <code>data</code>), giving the scaled bin counts</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is still experimental and behavior may change in the future.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = list(rnorm(1000), rnorm(10000) + 2);
plotMultiHist(data, xlab = "value", ylab = "scaled density")
</code></pre>

<hr>
<h2 id='plotNetworkHeatmap'> Network heatmap plot </h2><span id='topic+plotNetworkHeatmap'></span>

<h3>Description</h3>

<p>Network heatmap plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNetworkHeatmap(
  datExpr, 
  plotGenes, 
  weights = NULL,
  useTOM = TRUE, 
  power = 6, 
  networkType = "unsigned", 
  main = "Heatmap of the network")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotNetworkHeatmap_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing expression data, with rows corresponding to samples and columns
to genes. Missing values are allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_plotgenes">plotGenes</code></td>
<td>
<p> a character vector giving the names of genes to be included in the plot. The names
will be matched against <code>names(datExpr)</code>. </p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>datExpr</code> to be used in correlation calculation.
A matrix of the same dimensions as <code>datExpr</code>, containing non-negative weights. Only used with Pearson
correlation.</p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_usetom">useTOM</code></td>
<td>
<p> logical: should TOM be plotted (<code>TRUE</code>), or correlation-based adjacency
(<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_networktype">networkType</code></td>
<td>
<p> a character string giving the newtork type. Recognized values are (unique
abbreviations of) <code>"unsigned"</code>, <code>"signed"</code>, and <code>"signed hybrid"</code>. </p>
</td></tr>
<tr><td><code id="plotNetworkHeatmap_+3A_main">main</code></td>
<td>
<p> main title for the plot. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function constructs a network from the given expression data (selected by <code>plotGenes</code>) using
the soft-thresholding procedure, optionally calculates Topological Overlap (TOM) and plots a heatmap of
the network. 
</p>
<p>Note that all network calculations are done in one block and may fail due to memory allocation issues for
large numbers of genes. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code>, <code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> </p>

<hr>
<h2 id='populationMeansInAdmixture'>Estimate the population-specific mean values in an admixed population.
</h2><span id='topic+populationMeansInAdmixture'></span>

<h3>Description</h3>

<p>Uses the expression values from an admixed population and estimates of the proportions of
sub-populations to estimate the population specific mean values. For example, this function can be used to
estimate the cell type specific mean gene expression values based on expression values from a mixture of
cells. The method is described in Shen-Orr et al (2010) where it was used to estimate cell type specific
gene expression levels based on a mixture sample. </p>


<h3>Usage</h3>

<pre><code class='language-R'> populationMeansInAdmixture(
    datProportions, datE.Admixture, 
    scaleProportionsTo1 = TRUE,
    scaleProportionsInCelltype = TRUE, 
    setMissingProportionsToZero = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="populationMeansInAdmixture_+3A_datproportions">datProportions</code></td>
<td>
<p>a matrix of non-negative numbers (ideally proportions) where the rows correspond to the samples (rows of <code>datE.Admixture</code>) and the columns correspond to the sub-populations of the mixture. The function calculates a mean expression value for each column of <code>datProportions</code>.
Negative entries in datProportions lead to an error message. But the rows of
<code>datProportions</code> do not have to sum to 1, see the argument <code>scaleProportionsTo1</code>.
</p>
</td></tr>
<tr><td><code id="populationMeansInAdmixture_+3A_date.admixture">datE.Admixture</code></td>
<td>
<p>a matrix of numbers. The rows correspond to samples (mixtures of populations). The columns contain the variables (e.g. genes) for which the means should be estimated.  
</p>
</td></tr>
<tr><td><code id="populationMeansInAdmixture_+3A_scaleproportionsto1">scaleProportionsTo1</code></td>
<td>
<p>logical. If set to TRUE (default) then the proportions in each row of <code>datProportions</code> are scaled so that they sum to 1, i.e. datProportions[i,]=datProportions[i,]/max(datProportions[i,]).
In general, we recommend to set it to TRUE.
</p>
</td></tr>
<tr><td><code id="populationMeansInAdmixture_+3A_scaleproportionsincelltype">scaleProportionsInCelltype</code></td>
<td>

<p>logical. If set to TRUE (default) then the proportions in each cell types are recaled and make the mean to
0.
</p>
</td></tr>
<tr><td><code id="populationMeansInAdmixture_+3A_setmissingproportionstozero">setMissingProportionsToZero</code></td>
<td>
<p>logical. Default is FALSE. If set to TRUE then it sets missing values in <code>datProportions</code> to zero.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function outputs a matrix of coefficients resulting from fitting a regression model. If the proportions sum to 1, then i-th row of the output matrix reports the coefficients  of the following model
<code>lm(datE.Admixture[,i]~.-1,data=datProportions)</code>. Aside, the minus 1 in the formula indicates that no intercept term will be fit.
Under certain assumptions, the coefficients can be interpreted as the mean expression values in the sub-populations (Shen-Orr  2010).
</p>


<h3>Value</h3>

<p> a numeric matrix whose rows correspond to the columns of <code>datE.Admixture</code> (e.g. to genes) and whose columns correspond to the columns of <code>datProportions</code> (e.g. sub populations or cell types).
</p>


<h3>Note</h3>

<p>This can be considered a wrapper of the <code>lm</code> function.
</p>


<h3>Author(s)</h3>

<p>Steve Horvath, Chaochao Cai
</p>


<h3>References</h3>

<p>Shen-Orr SS, Tibshirani R, Khatri P, Bodian DL, Staedtler F, Perry NM,
Hastie T, Sarwal MM, Davis MM, Butte AJ (2010)  
Cell type-specific gene expression differences in complex
tissues.  Nature Methods,  vol 7 no.4 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
# this is the number of complex (mixed) tissue samples, e.g. arrays
m=10
# true count data (e.g. pure cells in the mixed sample)
datTrueCounts=as.matrix(data.frame(TrueCount1=rpois(m,lambda=16),
TrueCount2=rpois(m,lambda=8),TrueCount3=rpois(m,lambda=4),
TrueCount4=rpois(m,lambda=2)))
no.pure=dim(datTrueCounts)[[2]]

# now we transform the counts into proportions
divideBySum=function(x) t(x)/sum(x)
datProportions= t(apply(datTrueCounts,1,divideBySum))
dimnames(datProportions)[[2]]=paste("TrueProp",1:dim(datTrueCounts)[[2]],sep=".")

# number of genes that are highly expressed in each pure population
no.genesPerPure=rep(5, no.pure)
no.genes= sum(no.genesPerPure)
GeneIndicator=rep(1:no.pure, no.genesPerPure)
# true mean values of the genes in the pure populations
# in the end we hope to estimate them from the mixed samples
datTrueMeans0=matrix( rnorm(no.genes*no.pure,sd=.3), nrow= no.genes,ncol=no.pure)
for (i in 1:no.pure ){
datTrueMeans0[GeneIndicator==i,i]= datTrueMeans0[GeneIndicator==i,i]+1
}
dimnames(datTrueMeans0)[[1]]=paste("Gene",1:dim(datTrueMeans0)[[1]],sep="." )
dimnames(datTrueMeans0)[[2]]=paste("MeanPureCellType",1:dim(datTrueMeans0)[[2]],
                                   sep=".")
# plot.mat(datTrueMeans0)
# simulate the (expression) values of the admixed population samples

noise=matrix(rnorm(m*no.genes,sd=.1),nrow=m,ncol= no.genes)
datE.Admixture= as.matrix(datProportions) %*% t(datTrueMeans0) + noise
dimnames(datE.Admixture)[[1]]=paste("MixedTissue",1:m,sep=".")

datPredictedMeans=populationMeansInAdmixture(datProportions,datE.Admixture)

par(mfrow=c(2,2))
for (i in 1:4 ){
verboseScatterplot(datPredictedMeans[,i],datTrueMeans0[,i],
xlab="predicted mean",ylab="true mean",main="all populations")
abline(0,1)
}

#assume we only study 2 populations (ie we ignore the others)
selectPopulations=c(1,2)
datPredictedMeansTooFew=populationMeansInAdmixture(datProportions[,selectPopulations],
                                                   datE.Admixture)

par(mfrow=c(2,2))
for (i in 1:length(selectPopulations) ){
verboseScatterplot(datPredictedMeansTooFew[,i],datTrueMeans0[,i],
xlab="predicted mean",ylab="true mean",main="too few populations")
abline(0,1)
}

#assume we erroneously add a population
datProportionsTooMany=data.frame(datProportions,WrongProp=sample(datProportions[,1]))
datPredictedMeansTooMany=populationMeansInAdmixture(datProportionsTooMany,
                                 datE.Admixture)

par(mfrow=c(2,2))
for (i in 1:4 ){
  verboseScatterplot(datPredictedMeansTooMany[,i],datTrueMeans0[,i],
  xlab="predicted mean",ylab="true mean",main="too many populations")
  abline(0,1)
}

</code></pre>

<hr>
<h2 id='pquantile'> Parallel quantile, median, mean </h2><span id='topic+pquantile'></span><span id='topic+pquantile.fromList'></span><span id='topic+pmedian'></span><span id='topic+pmean'></span><span id='topic+pmean.fromList'></span><span id='topic+pminWhich.fromList'></span>

<h3>Description</h3>

<p>Calculation of &ldquo;parallel&rdquo; quantiles, minima, maxima, medians, and means, across given arguments or across lists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pquantile(prob, ...)
pquantile.fromList(dataList, prob)
pmedian(...)
pmean(..., weights = NULL)
pmean.fromList(dataList, weights = NULL)
pminWhich.fromList(dataList)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pquantile_+3A_prob">prob</code></td>
<td>

<p>A single probability at which to calculate the quantile. See <code><a href="stats.html#topic+quantile">quantile</a></code>. 
</p>
</td></tr>
<tr><td><code id="pquantile_+3A_datalist">dataList</code></td>
<td>
<p>A list of numeric vectors or arrays, all of the same length and dimensions, over which to
calculate &ldquo;parallel&rdquo; quantiles.</p>
</td></tr>
<tr><td><code id="pquantile_+3A_weights">weights</code></td>
<td>
<p>Optional vector of the same length as <code>dataList</code>, giving the weights to be used in the
weighted mean. If not given, unit weights will be used.</p>
</td></tr>
<tr><td><code id="pquantile_+3A_...">...</code></td>
<td>

<p>Numeric arguments. All arguments must have the same dimensions. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given numeric arguments, say x,y,z, of equal dimensions (and length), the <code>pquantile</code> 
calculates and returns the quantile of the first components of x,y,z, then the second components, etc.
Similarly, <code>pmedian</code> and <code>pmean</code> calculate the median and mean, respectively.
The funtion <code>pquantile.fromList</code> is identical to <code>pquantile</code> except that the argument
<code>dataList</code> replaces the ... in holding the numeric vectors over which to calculate the quantiles.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>pquantile</code>, <code>pquantile.fromList</code></td>
<td>
<p>A vector or array containing quantiles.</p>
</td></tr>
<tr><td><code>pmean</code>, <code>pmean.fromList</code></td>
<td>
<p>A vector or array containing means. </p>
</td></tr>
<tr><td><code>pmedian</code></td>
<td>
<p>A vector or array containing  medians.</p>
</td></tr>
<tr><td><code>pminWhich.fromList</code></td>
<td>
<p>A list with two components: <code>min</code> gives the minima, <code>which</code> gives the
indices of the elements that are the minima.</p>
</td></tr>
</table>
<p>Dimensions are copied from dimensions of the input arguments.
If any of the input variables have <code>dimnames</code>, the first non-NULL dimnames are copied into the output.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder and Steve Horvath
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code>, <code><a href="stats.html#topic+median">median</a></code>, <code><a href="base.html#topic+mean">mean</a></code> for the underlying statistics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate 2 simple matrices
a = matrix(c(1:12), 3, 4);
b = a+ 1;
c = a + 2;

# Set the colnames on matrix a

colnames(a) = spaste("col_", c(1:4));

# Example use

pquantile(prob = 0.5, a, b, c)

pmean(a,b,c)
pmedian(a,b,c)

</code></pre>

<hr>
<h2 id='prepComma'>
Prepend a comma to a non-empty string
</h2><span id='topic+prepComma'></span>

<h3>Description</h3>

<p>Utility function that prepends a comma before the input string if the string is non-empty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepComma(s)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prepComma_+3A_s">s</code></td>
<td>
<p>Character string.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>s</code> is non-empty, returns <code>paste(",", s)</code>, otherwise returns s.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prepComma("abc");
prepComma("");
</code></pre>

<hr>
<h2 id='prependZeros'>
Pad numbers with leading zeros to specified total width
</h2><span id='topic+prependZeros'></span><span id='topic+prependZeros.int'></span>

<h3>Description</h3>

<p>These functions pad the specified numbers with zeros to a specified total width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prependZeros(x, width = max(nchar(x)))
prependZeros.int(x, width = max(nchar(as.integer(x))))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prependZeros_+3A_x">x</code></td>
<td>

<p>Vector of numbers to be padded. For <code>prependZeros</code>, the vector may be real (non-integer) or even character (and
not necessarily representing numbers). For <code>prependZeros</code>, the vector must be numeric and non-integers get rounded
down to the nearest integer.
</p>
</td></tr>
<tr><td><code id="prependZeros_+3A_width">width</code></td>
<td>

<p>Width to pad the numbers to.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>prependZeros.int</code> version works better with numbers such as 100000 which may get converted to character as 1e5 and
hence be incorrectly padded in the <code>prependZeros</code> function. On the flip side, prependZeros works also for non-integer
inputs.
</p>


<h3>Value</h3>

<p>Character vector with the 0-padded numbers.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prependZeros(1:10)
prependZeros(1:10, 4)
# more exotic examples
prependZeros(c(1, 100000), width = 6) ### Produces incorrect output
prependZeros.int(c(1, 100000))  ### Correct output
prependZeros(c("a", "b", "aa")) ### pads the shorter strings using zeros.
</code></pre>

<hr>
<h2 id='preservationNetworkConnectivity'> Network preservation calculations </h2><span id='topic+preservationNetworkConnectivity'></span>

<h3>Description</h3>

<p>This function calculates several measures of gene network preservation. Given gene expression data in
several individual data sets, it calculates the individual adjacency matrices, forms the preservation
network and finally forms several summary measures of adjacency preservation for each node (gene) in the
network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preservationNetworkConnectivity(
   multiExpr,
   useSets = NULL, useGenes = NULL,
   corFnc = "cor", corOptions = "use='p'",
   networkType = "unsigned",
   power = 6,
   sampleLinks = NULL, nLinks = 5000,
   blockSize = 1000,
   setSeed = 12345,
   weightPower = 2,
   verbose = 2, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preservationNetworkConnectivity_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_usesets">useSets</code></td>
<td>
<p> optional specification of sets to be used for the preservation calculation. Defaults to
using all sets. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_usegenes">useGenes</code></td>
<td>
<p> optional specification of genes to be used for the preservation calculation. Defaults
to all genes. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_corfnc">corFnc</code></td>
<td>
<p> character string containing the name of the function to calculate correlation. Suggested
functions include <code>"cor"</code> and <code>"bicor"</code>. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_coroptions">corOptions</code></td>
<td>
<p> further argument to the correlation function. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_networktype">networkType</code></td>
<td>
<p> a character string encoding network type. Recognized values are (unique
abbreviations of) <code>"unsigned"</code>, <code>"signed"</code>, and <code>"signed hybrid"</code>. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_power">power</code></td>
<td>
<p> soft thresholding power for network construction. Should be a number greater than 1. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_samplelinks">sampleLinks</code></td>
<td>
<p> logical: should network connections be sampled (<code>TRUE</code>) or should all
connections be used systematically (<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_nlinks">nLinks</code></td>
<td>
<p> number of links to be sampled. Should be set such that <code>nLinks * nNeighbors</code> be
several times larger than the number of genes. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_blocksize">blockSize</code></td>
<td>
<p> correlation calculations will be split into square blocks of this size, to prevent
running out of memory for large gene sets.  </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_setseed">setSeed</code></td>
<td>
<p>  seed to be used for sampling, for repeatability. If a seed already exists, it is saved
before the sampling starts and restored upon exit. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_weightpower">weightPower</code></td>
<td>
<p> power with which higher adjacencies will be weighted in weighted means </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="preservationNetworkConnectivity_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The preservation network is formed from adjacencies of compared sets. For 'complete' preservations, all
given sets are compared at once; for 'pairwise' preservations, the sets are compared in pairs. Unweighted
preservations are simple mean preservations for each node; their weighted counterparts are weighted
averages in which a preservation of adjacencies <code class="reqn">A^{(1)}_{ij}</code> and 
<code class="reqn">A^{(2)}_{ij}</code> of nodes <code class="reqn">i,j</code> between sets 1 and 2
is weighted by 
<code class="reqn">[ (A^{(1)}_{ij} + A^{(2)}_{ij} )/2]^weightPower</code>.
The hyperbolic preservation is based on 
<code class="reqn">tanh[( max - min)/(max+min)^2]</code>, where <code class="reqn">max</code> and
<code class="reqn">min</code> are the componentwise maximum and minimum of the compared adjacencies, respectively.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>pairwise</code></td>
<td>
<p> a matrix with rows corresponding to genes and columns to unique pairs of given sets,
giving the pairwise preservation of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
<tr><td><code>complete</code></td>
<td>
<p> a vector with one entry for each input gene containing the complete mean preservation
of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
<tr><td><code>pairwiseWeighted</code></td>
<td>
<p> a matrix with rows corresponding to genes and columns to unique pairs of given
sets, giving the pairwise weighted preservation of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
<tr><td><code>completeWeighted</code></td>
<td>
<p> a vector with one entry for each input gene containing the complete weighted 
mean preservation of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
<tr><td><code>pairwiseHyperbolic</code></td>
<td>
<p> a matrix with rows corresponding to genes and columns to unique 
pairs of given sets, giving the pairwise hyperbolic preservation of the adjacencies connecting the gene
to all other genes.</p>
</td></tr>
<tr><td><code>completeHyperbolic</code></td>
<td>
<p> a vector with one entry for each input gene containing the complete mean
hyperbolic preservation of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
<tr><td><code>pairwiseWeightedHyperbolic</code></td>
<td>
<p> a matrix with rows corresponding to genes and columns to unique
pairs of given sets, giving the pairwise weighted hyperbolic preservation of the adjacencies connecting
the gene to all other genes.</p>
</td></tr> 
<tr><td><code>completeWeightedHyperbolic</code></td>
<td>
<p> a vector with one entry for each input gene containing the complete
weighted hyperbolic  mean preservation of the adjacencies connecting the gene to all other genes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between
co-expression modules. BMC Systems Biology 2007, 1:54 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+adjacency">adjacency</a></code> for calculation of adjacency; 
</p>

<hr>
<h2 id='projectiveKMeans'> Projective K-means (pre-)clustering of expression data </h2><span id='topic+projectiveKMeans'></span>

<h3>Description</h3>

<p>Implementation of a variant of K-means clustering for expression data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>projectiveKMeans(
  datExpr, 
  preferredSize = 5000, 
  nCenters = as.integer(min(ncol(datExpr)/20, preferredSize^2/ncol(datExpr))),
  sizePenaltyPower = 4, 
  networkType = "unsigned",  
  randomSeed = 54321,
  checkData = TRUE,
  imputeMissing = TRUE,
  maxIterations = 1000, 
  verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="projectiveKMeans_+3A_datexpr">datExpr</code></td>
<td>
<p>  expression data. A data frame in which columns are genes and rows ar samples. NAs are
allowed, but not too many. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_preferredsize">preferredSize</code></td>
<td>
<p> preferred maximum size of clusters. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_ncenters">nCenters</code></td>
<td>
<p> number of initial clusters. Empirical evidence suggests that more centers will give a
better preclustering; the default is an attempt to arrive at a reasonable number. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_sizepenaltypower">sizePenaltyPower</code></td>
<td>
<p> parameter specifying how severe is the penalty for clusters that exceed
<code>preferredSize</code>. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_randomseed">randomSeed</code></td>
<td>
<p> integer to be used as seed for the random number generator before the function
starts. If a current seed exists, it is saved and restored upon exit. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_checkdata">checkData</code></td>
<td>
<p> logical: should data be checked for genes with zero variance and 
genes and samples with excessive numbers of missing samples? Bad samples are ignored; returned cluster
assignment for bad genes will be <code>NA</code>. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_imputemissing">imputeMissing</code></td>
<td>
<p> logical: should missing values in <code>datExpr</code> be imputed before the calculations
start? The early imputation makes the code run faster but may produce slightly different results if re-running
older calculations.</p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_maxiterations">maxIterations</code></td>
<td>
<p> maximum iterations to be attempted. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="projectiveKMeans_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The principal aim of this function within WGCNA is to pre-cluster a large number of genes into smaller blocks
that can be handled using standard WGCNA techniques.
</p>
<p>This function implements a variant of K-means clustering that is suitable for co-expression analysis.
Cluster centers are defined by the first principal component, and distances by correlation (more
precisely, 1-correlation). The distance between a gene and a cluster is multiplied by a factor of
<code class="reqn">max(clusterSize/preferredSize, 1)^{sizePenaltyPower}</code>, thus penalizing clusters whose size exceeds
<code>preferredSize</code>. The function starts with randomly generated cluster assignment (hence the need to
set the random seed for repeatability) and executes interations of calculating new centers and
reassigning genes to nearest center until the clustering becomes stable. Before returning, nearby
clusters are iteratively combined if their combined size is below <code>preferredSize</code>.
</p>
<p>The standard principal component calculation via the function <code>svd</code> fails from time to time
(likely a convergence problem of the underlying lapack functions). Such errors are trapped and the
principal component is approximated by a weighted average of expression profiles in the cluster. If
<code>verbose</code> is set above 2, an informational message is printed whenever this approximation is used.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>clusters</code></td>
<td>
<p>A numerical vector with one component per input gene, giving the cluster number in
which the gene is assigned. </p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>Cluster centers, that is their first principal components. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+sizeRestrictedClusterMerge">sizeRestrictedClusterMerge</a></code> which implements the last step of merging smaller clusters.</p>

<hr>
<h2 id='proportionsInAdmixture'>Estimate the proportion of pure populations in an admixed population based on marker expression
values.  </h2><span id='topic+proportionsInAdmixture'></span>

<h3>Description</h3>

<p>Assume that <code>datE.Admixture</code> provides the expression values from a mixture of cell types (admixed
population) and you want to estimate the proportion of each pure cell type in the mixed samples (rows of
<code>datE.Admixture</code>).  The function allows you to do this as long as you provide a data frame
<code>MarkerMeansPure</code> that reports the mean expression values of markers in each of the pure cell types.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportionsInAdmixture(
  MarkerMeansPure, 
  datE.Admixture, 
  calculateConditionNumber = FALSE, 
  coefToProportion = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proportionsInAdmixture_+3A_markermeanspure">MarkerMeansPure</code></td>
<td>
<p> is a data frame whose first column reports the name of the marker and the
remaining columns report the mean values of the markers in each of the pure populations. The function will
estimate the proportion of pure cells which correspond to columns 2 through of
<code>dim(MarkerMeansPure)[[2]]</code> of <code>MarkerMeansPure</code>. Rows that contain missing values (NA) will be
removed.  </p>
</td></tr> 
<tr><td><code id="proportionsInAdmixture_+3A_date.admixture">datE.Admixture</code></td>
<td>
<p>is a data frame of expression data, e.g. the columns of <code>datE.Admixture</code> could
correspond to thousands of genes.  The rows of <code>datE.Admixture</code> correspond to the admixed samples for
which the function estimates the proportions of pure populations.  Some of the markers specified in the
first column of <code>MarkerMeansPure</code> should correspond to column names of <code>datE.Admixture</code>. 
</p>
</td></tr>
<tr><td><code id="proportionsInAdmixture_+3A_calculateconditionnumber">calculateConditionNumber</code></td>
<td>
<p>logical. Default is FALSE. If set to TRUE then it uses the <code>kappa</code>
function to  calculates the condition number of the matrix <code>MarkerMeansPure[,-1]</code>.  This allows one to
determine whether the linear model for estimating the proportions is well specified. Type <code>help(kappa)</code>
to learn more.  <code>kappa()</code> computes by default (an estimate of) the 2-norm condition number of a matrix
or of the R matrix of a QR decomposition, perhaps of a linear fit. 
</p>
</td></tr> 
<tr><td><code id="proportionsInAdmixture_+3A_coeftoproportion">coefToProportion</code></td>
<td>
<p>logical. By default, it is set to TRUE. When estimating the proportions the
function fits a multivariate linear model. Ideally, the coefficients of the linear model correspond to the
proportions in the admixed samples. But sometimes the coefficients take on negative values or do not sum to
1. If <code>coefToProportion=TRUE</code> then negative coefficients will be set to 0 and the remaining
coefficients will be scaled so that they sum to 1. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods implemented in this function were motivated by
the gene expression deconvolution approach described by Abbas et al (2009), Lu  et al (2003), Wang  et al (2006). This  approach can be used to predict the proportions of (pure) cells in a complex tissue, e.g. the proportion of blood cell types in whole blood. To define the markers, you may need to have expression data from pure populations. Then you can define markers based on a significant t-test or ANOVA across the pure populations. Next use the pure population data to estimate corresponding mean expression values. Hopefully, the array platforms and normalization methods for <code>datE.MarkersAdmixtureTranspose</code>  and <code>MarkerMeansPure</code> are comparable. When dealing with Affymetrix data: we have successfully used it on untransformed MAS5 data.
For statisticians: To estimate the proportions, we use the coefficients
of a linear model. Specifically: 
<code>datCoef= t(lm(datE.MarkersAdmixtureTranspose ~MarkerMeansPure[,-1])$coefficients[-1,])</code>
where <code>datCoef</code> is a matrix whose rows correspond to the mixed samples (rows of <code>datE.Admixture</code>)  and the columns correspond to pure populations (e.g. cell types), i.e. the columns of <code>MarkerMeansPure[,-1]</code>.
More details can be found in Abbas et al (2009).
</p>


<h3>Value</h3>

<p>A list with the following components
</p>
<table role = "presentation">
<tr><td><code>PredictedProportions</code></td>
<td>
<p>data frame that contains the predicted proportions. The rows of <code>PredictedProportions</code> correspond to the admixed samples, i.e. the rows of <code>datE.Admixture</code>. The columns of <code>PredictedProportions</code>  correspond to the pure populations, i.e. the columns of <code>MarkerMeansPure[,-1].</code> </p>
</td></tr>
<tr><td><code>datCoef=datCoef</code></td>
<td>
<p>data frame of numbers that is analogous to
<code>PredictedProportions</code>. In general, <code>datCoef</code> will only be different from <code>PredictedProportions</code> if <code>coefToProportion=TRUE</code>. See the description of <code>coefToProportion</code>
</p>
</td></tr>
<tr><td><code>conditionNumber</code></td>
<td>
<p>This is the condition number resulting from the <code>kappa</code> function. See the description of calculateConditionNumber. </p>
</td></tr>
<tr><td><code>markersUsed</code></td>
<td>
<p>vector of character strings that contains the subset of marker names (specified in the first column of <code>MarkerMeansPure</code>) that match column names of <code>datE.Admixture</code> and that contain non-missing pure mean values. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function can be considered a wrapper of the <code>lm</code> function.
</p>


<h3>Author(s)</h3>

<p>Steve Horvath, Chaochao Cai
</p>


<h3>References</h3>

<p>Abbas AR, Wolslegel K, Seshasayee D, Modrusan Z, Clark HF (2009) Deconvolution of Blood Microarray Data Identifies Cellular Activation Patterns in
Systemic Lupus Erythematosus. PLoS ONE 4(7): e6098. doi:10.1371/journal.pone.0006098
</p>
<p>Lu P, Nakorchevskiy A, Marcotte EM (2003) Expression deconvolution: a
reinterpretation of DNA microarray data reveals dynamic changes in cell
populations. Proc Natl Acad Sci U S A 100: 10370-10375.
</p>
<p>Wang M, Master SR, Chodosh LA (2006) Computational expression
deconvolution in a complex mammalian organ. BMC Bioinformatics 7: 328.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="base.html#topic+kappa">kappa</a></code>
</p>

<hr>
<h2 id='propVarExplained'> Proportion of variance explained by eigengenes. </h2><span id='topic+propVarExplained'></span>

<h3>Description</h3>

<p>This function calculates the proportion of variance of genes in each module explained by the respective
module eigengene. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propVarExplained(datExpr, colors, MEs, corFnc = "cor", corOptions = "use = 'p'")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="propVarExplained_+3A_datexpr">datExpr</code></td>
<td>
<p>  expression data. A data frame in which columns are genes and rows ar samples. NAs are
allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="propVarExplained_+3A_colors">colors</code></td>
<td>
<p> a vector giving module assignment for genes given in <code>datExpr</code>. Unique values
should correspond to the names of the eigengenes in <code>MEs</code>. </p>
</td></tr>
<tr><td><code id="propVarExplained_+3A_mes">MEs</code></td>
<td>
<p> a data frame of module eigengenes in which each column is an eigengene and each row
corresponds to a sample.  </p>
</td></tr>
<tr><td><code id="propVarExplained_+3A_corfnc">corFnc</code></td>
<td>
<p> character string containing the name of the function to calculate correlation. Suggested
functions include <code>"cor"</code> and <code>"bicor"</code>. </p>
</td></tr>
<tr><td><code id="propVarExplained_+3A_coroptions">corOptions</code></td>
<td>
<p> further argument to the correlation function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For compatibility with other functions, entries in <code>color</code> are matched to a substring of
<code>names(MEs)</code> starting at position 3. For example, the entry <code>"turquoise"</code> in <code>colors</code> will
be matched to the eigengene named <code>"MEturquoise"</code>. The first two characters of the eigengene name
are ignored and can be arbitrary.
</p>


<h3>Value</h3>

<p>A vector with one entry per eigengene containing the proportion of variance of the module explained by
the eigengene. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> </p>

<hr>
<h2 id='pruneAndMergeConsensusModules'>
Iterative pruning and merging of (hierarchical) consensus modules
</h2><span id='topic+pruneAndMergeConsensusModules'></span>

<h3>Description</h3>

<p>This function prunes genes with low consensus eigengene-based intramodular connectivity (kME) from modules
and merges modules whose consensus similarity is high. The process is repeated until the modules become
stable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pruneAndMergeConsensusModules(
  multiExpr,
  multiWeights = NULL,
  multiExpr.imputed = NULL,
  labels,
  unassignedLabel = if (is.numeric(labels)) 0 else "grey",
  networkOptions,
  consensusTree,

  # Pruning options
  minModuleSize,
  minCoreKMESize = minModuleSize/3,
  minCoreKME = 0.5, 
  minKMEtoStay = 0.2,

  # Module eigengene calculation and merging options
  impute = TRUE,
  trapErrors = FALSE,
  calibrateMergingSimilarities = FALSE,
  mergeCutHeight = 0.15,

  # Behavior
  iterate = TRUE,
  collectGarbage = FALSE,
  getDetails = TRUE,
  verbose = 1, indent=0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pruneAndMergeConsensusModules_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_multiexpr.imputed">multiExpr.imputed</code></td>
<td>
<p>If <code>multiExpr</code> contain missing data, this argument can be used to supply the
expression data with missing data imputed. If not given, the <code><a href="impute.html#topic+impute.knn">impute.knn</a></code> function will
be used to impute the missing data.</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_labels">labels</code></td>
<td>

<p>A vector (numeric, character or a factor) giving module labels for each variable (gene) in multiExpr.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_unassignedlabel">unassignedLabel</code></td>
<td>

<p>The label (value in <code>labels</code>)
that represents unassigned genes. Module of this label will
not enter the module eigengene clustering and will not be merged with other modules.</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list of class <code><a href="#topic+ConsensusTree">ConsensusTree</a></code> specifying the consensus calculation.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p>Minimum number of genes in a module. Modules that have fewer genes (after trimming)
will be removed (i.e., their genes will be given the unassigned label).</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with consensus eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled).</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose consensus eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_calibratemergingsimilarities">calibrateMergingSimilarities</code></td>
<td>

<p>Logical: should module eigengene similarities be calibrated before calculating the consensus? Although
calibration is in principle desirable, the calibration methods currently available assume large data and do
not work very well on eigengene similarities.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_mergecutheight">mergeCutHeight</code></td>
<td>

<p>Dendrogram cut height for module merging.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_iterate">iterate</code></td>
<td>

<p>Logical: should the pruning and merging process be iterated until no changes occur? If <code>FALSE</code>, only one
iteration will be carried out.
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage be collected after some of the memory-intensive steps?
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_getdetails">getDetails</code></td>
<td>

<p>Logical: should certain intermediate results be returned? These include labels and module merging information
at each iteration (see return value).
</p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="pruneAndMergeConsensusModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>If input <code>getDetails</code> is <code>FALSE</code>, a vector the resulting module labels. If <code>getDetails</code> is
<code>TRUE</code>, a list with these components:
</p>
<table role = "presentation">
<tr><td><code>labels</code></td>
<td>
<p>The resulting module labels</p>
</td></tr>
<tr><td><code>details</code></td>
<td>
<p>A list. The first component, named <code>originalLabels</code>, contains a copy of the input labels.
The following components are named <code>Iteration.1</code>, <code>Iteration.2</code> etc and contain, for each iteration,
components <code>prunedLabels</code> (the result of pruning in that iteration) and <code>mergeInfo</code> (result of the
call to <code><a href="#topic+hierarchicalMergeCloseModules">hierarchicalMergeCloseModules</a></code> in that iteration).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The underlying functions <code><a href="#topic+pruneConsensusModules">pruneConsensusModules</a></code> and <code><a href="#topic+hierarchicalMergeCloseModules">hierarchicalMergeCloseModules</a></code>.
</p>

<hr>
<h2 id='pruneConsensusModules'>
Prune (hierarchical) consensus modules by removing genes with low eigengene-based intramodular connectivity
</h2><span id='topic+pruneConsensusModules'></span>

<h3>Description</h3>

<p>This function prunes (hierarchical) consensus modules by removing genes with low eigengene-based intramodular
connectivity (KME) and by removing modules that do not have a certain minimum number of genes with a required
minimum KME.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pruneConsensusModules(  multiExpr,
  multiWeights = NULL,
  multiExpr.imputed = NULL,
  MEs = NULL,
  labels,

  unassignedLabel = if (is.numeric(labels)) 0 else "grey",

  networkOptions,
  consensusTree,

  minModuleSize,
  minCoreKMESize = minModuleSize/3,
  minCoreKME = 0.5, 
  minKMEtoStay = 0.2,

  # Module eigengene calculation options
  impute = TRUE, 
  collectGarbage = FALSE,
  checkWeights = TRUE,

  verbose = 1, indent=0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pruneConsensusModules_+3A_multiexpr">multiExpr</code></td>
<td>
<p> Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_multiexpr.imputed">multiExpr.imputed</code></td>
<td>
<p>If <code>multiExpr</code> contain missing data, this argument can be used to supply the
expression data with missing data imputed. If not given, the <code><a href="impute.html#topic+impute.knn">impute.knn</a></code> function will
be used to impute the missing data.</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_mes">MEs</code></td>
<td>
<p>Optional consensus module eigengenes, in multi-set format analogous to that of <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_labels">labels</code></td>
<td>

<p>A vector (numeric, character or a factor) giving module labels for each variable (gene) in multiExpr.
</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_unassignedlabel">unassignedLabel</code></td>
<td>

<p>The label (value in <code>labels</code>)
that represents unassigned genes. Module of this label will
not enter the module eigengene clustering and will not be merged with other modules.</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list of class <code><a href="#topic+ConsensusTree">ConsensusTree</a></code> specifying the consensus calculation.
</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p>Minimum number of genes in a module. Modules that have fewer genes (after trimming)
will be removed (i.e., their genes will be given the unassigned label).</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with consensus eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled).</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose consensus eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_collectgarbage">collectGarbage</code></td>
<td>

<p>Logical: should garbage be collected after some of the memory-intensive steps?
</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_checkweights">checkWeights</code></td>
<td>
<p>Logical: should <code>multiWeights</code> be checked to make sure their dimensions are
concordant with <code>multiExpr</code> and the weights are valid?</p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="pruneConsensusModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The pruned module labels: a vector of the same form as the input <code>labels</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>

<hr>
<h2 id='PWLists'>Pathways with Corresponding Gene Markers - Compiled by Mike Palazzolo and Jim Wang from CHDI</h2><span id='topic+PWLists'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of marker genes for many immune response pathways, as assembled by Mike Palazzolo and Jim Wang from CHDI, and colleagues.  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PWLists)</code></pre>


<h3>Format</h3>

<p>A 124350 x 2 matrix of characters containing 2724 Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;gene set&gt;__&lt;reference&gt;.  
</p>


<h3>Source</h3>

<p>For more information about this list, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(PWLists)
head(PWLists)
</code></pre>

<hr>
<h2 id='qvalue'>Estimate the q-values for a given set of p-values</h2><span id='topic+qvalue'></span>

<h3>Description</h3>

<p>Estimate the q-values for a given set of p-values.  The q-value of a
test measures the proportion of false positives incurred (called the
false discovery rate) when that particular test is called significant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qvalue(p, lambda=seq(0,0.90,0.05), pi0.method="smoother", fdr.level=NULL, robust=FALSE,
  smooth.df=3, smooth.log.pi0=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qvalue_+3A_p">p</code></td>
<td>
<p>A vector of p-values (only necessary input)</p>
</td></tr>
<tr><td><code id="qvalue_+3A_lambda">lambda</code></td>
<td>
<p>The value of the tuning parameter to estimate
<code class="reqn">\pi_0</code>. Must be in [0,1). Optional, see Storey (2002).</p>
</td></tr>
<tr><td><code id="qvalue_+3A_pi0.method">pi0.method</code></td>
<td>
<p>Either &quot;smoother&quot; or &quot;bootstrap&quot;; the method for
automatically choosing tuning parameter in the estimation of <code class="reqn">\pi_0</code>, 
the proportion of true null hypotheses</p>
</td></tr>
<tr><td><code id="qvalue_+3A_fdr.level">fdr.level</code></td>
<td>
<p>A level at which to control the FDR. Must be in (0,1]. Optional; if this is
selected, a vector of TRUE and FALSE is returned that specifies
whether each q-value is less than fdr.level or not.</p>
</td></tr>
<tr><td><code id="qvalue_+3A_robust">robust</code></td>
<td>
<p>An indicator of whether it is desired to make the
estimate more robust for small p-values and a direct finite sample 
estimate of pFDR. Optional.</p>
</td></tr>
<tr><td><code id="qvalue_+3A_smooth.df">smooth.df</code></td>
<td>
<p>Number of degrees-of-freedom to use when estimating <code class="reqn">\pi_0</code> 
with a smoother. Optional.</p>
</td></tr>
<tr><td><code id="qvalue_+3A_smooth.log.pi0">smooth.log.pi0</code></td>
<td>
<p>If TRUE and <code>pi0.method</code> = &quot;smoother&quot;, <code class="reqn">\pi_0</code> will be 
estimated by applying a smoother to a scatterplot of <code class="reqn">log</code> <code class="reqn">\pi_0</code> estimates 
against the tuning parameter <code class="reqn">\lambda</code>. Optional.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no options are selected, then the method used to estimate <code class="reqn">\pi_0</code> is
the smoother method described in Storey and Tibshirani (2003). The
bootstrap method is described in Storey, Taylor &amp; Siegmund (2004).
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>function call</p>
</td></tr>
<tr><td><code>pi0</code></td>
<td>
<p>an estimate of the proportion of null p-values</p>
</td></tr>
<tr><td><code>qvalues</code></td>
<td>
<p>a vector of the estimated q-values (the main quantity of
interest)</p>
</td></tr> 
<tr><td><code>pvalues</code></td>
<td>
<p>a vector of the original p-values</p>
</td></tr>
<tr><td><code>significant</code></td>
<td>
<p>if fdr.level is specified, and indicator of whether the
q-value fell below fdr.level (taking all such q-values to be significant
controls FDR at level fdr.level)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is adapted from package qvalue. The reason we provide our own copy is that 
package qvalue contains additional functionality that relies on Tcl/Tk which has led to multiple problems.
Our copy does not require Tcl/Tk.</p>


<h3>Author(s)</h3>

<p>John D. Storey <a href="mailto:jstorey@u.washington.edu">jstorey@u.washington.edu</a>, adapted for WGCNA by Peter Langfelder</p>


<h3>References</h3>

<p>Storey JD. (2002) A direct approach to false discovery rates. Journal
of the Royal Statistical Society, Series B, 64: 479-498.
</p>
<p>Storey JD and Tibshirani R. (2003) Statistical significance for
genome-wide experiments. Proceedings of the National Academy of Sciences, 
100: 9440-9445. 
</p>
<p>Storey JD. (2003) The positive false discovery rate: A Bayesian
interpretation and the q-value. Annals of Statistics, 31: 2013-2035.  
</p>
<p>Storey JD, Taylor JE, and Siegmund D. (2004) Strong control,
conservative point estimation, and simultaneous conservative
consistency of false discovery rates: A unified approach. Journal of
the Royal Statistical Society, Series B, 66: 187-205.
</p>

<hr>
<h2 id='qvalue.restricted'>
qvalue convenience wrapper
</h2><span id='topic+qvalue.restricted'></span>

<h3>Description</h3>

<p>This function calls <code><a href="#topic+qvalue">qvalue</a></code> on finite input p-values, optionally traps errors from the q-value
calculation, and returns just the q values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qvalue.restricted(p, trapErrors = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qvalue.restricted_+3A_p">p</code></td>
<td>

<p>a vector of p-values. Missing data are allowed and will be removed.
</p>
</td></tr>
<tr><td><code id="qvalue.restricted_+3A_traperrors">trapErrors</code></td>
<td>

<p>logical: should errors generated by function <code><a href="#topic+qvalue">qvalue</a></code> trapped? If <code>TRUE</code>, the errors will be
silently ignored and the returned q-values will all be <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="qvalue.restricted_+3A_...">...</code></td>
<td>

<p>other arguments to function <code><a href="#topic+qvalue">qvalue</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of q-values. Entries whose corresponding p-values were not finite will be <code>NA</code>.  
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qvalue">qvalue</a></code>
</p>

<hr>
<h2 id='randIndex'> Rand index of two partitions</h2><span id='topic+randIndex'></span>

<h3>Description</h3>

<p>Computes the Rand index, a measure of the similarity between two clusterings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randIndex(tab, adjust = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="randIndex_+3A_tab">tab</code></td>
<td>
<p> a matrix giving the cross-tabulation table of two clusterings. </p>
</td></tr>
<tr><td><code id="randIndex_+3A_adjust">adjust</code></td>
<td>
<p>logical: should the &quot;adjusted&quot; version be computed? </p>
</td></tr>
</table>


<h3>Value</h3>

<p>the Rand index of the input table.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath</p>


<h3>References</h3>

<p> W. M. Rand (1971). &quot;Objective criteria for the evaluation of clustering methods&quot;. Journal of the
American Statistical Association 66: 846-850</p>

<hr>
<h2 id='rankPvalue'>
Estimate the p-value for ranking consistently high (or low) on multiple lists
</h2><span id='topic+rankPvalue'></span>

<h3>Description</h3>

<p>The function rankPvalue calculates the p-value for observing that an object (corresponding to a row of the input
data frame <code>datS</code>) has a consistently high ranking (or low ranking) according to multiple ordinal scores
(corresponding to the columns of the input data frame <code>datS</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankPvalue(datS, columnweights = NULL, 
           na.last = "keep", ties.method = "average", 
           calculateQvalue = TRUE, pValueMethod = "all")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rankPvalue_+3A_dats">datS</code></td>
<td>

<p>a data frame whose rows represent objects that will be ranked. Each column of <code>datS</code> represents an
ordinal variable (which can take on negative values). The columns correspond to (possibly signed) object
significance measures, e.g., statistics (such as Z statistics), ranks, or correlations. 
</p>
</td></tr>
<tr><td><code id="rankPvalue_+3A_columnweights">columnweights</code></td>
<td>

<p>allows the user to input a vector of non-negative numbers reflecting weights for the different columns of
<code>datZ</code>.
If it is set to <code>NULL</code> then all weights are equal.
</p>
</td></tr>
<tr><td><code id="rankPvalue_+3A_na.last">na.last</code></td>
<td>

<p>controls the treatment of missing values (NAs) in the rank function. If <code>TRUE</code>, missing values in the data are
put last (i.e. they get the highest rank values). If <code>FALSE</code>, they are put first; 
if <code>NA</code>, they are removed; if
<code>"keep"</code> they are kept with rank NA. See <code><a href="base.html#topic+rank">rank</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="rankPvalue_+3A_ties.method">ties.method</code></td>
<td>

<p>represents the ties method used in the rank function for the percentile rank method. See <code><a href="base.html#topic+rank">rank</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="rankPvalue_+3A_calculateqvalue">calculateQvalue</code></td>
<td>
<p> logical: should q-values be calculated? If set to TRUE then the function calculates
corresponding q-values (local false discovery rates) using the qvalue package, see Storey JD and Tibshirani R.
(2003). This option assumes that qvalue package has been installed. </p>
</td></tr>
<tr><td><code id="rankPvalue_+3A_pvaluemethod">pValueMethod</code></td>
<td>

<p>determines which method is used for calculating p-values. By default it is set to &quot;all&quot;, i.e. both methods are
used. If it is set to &quot;rank&quot; then only the percentile rank method is used. If it set to &quot;scale&quot; then only the
scale method will be used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates asymptotic p-values (and optionally q-values) for testing the null hypothesis that the
values in the columns of datS are independent. This allows us to find objects (rows) with consistently high (or
low) values across the columns.
</p>
<p>Example: Imagine you have 5 vectors of Z statistics corresponding to the columns of datS. Further assume that a
gene has ranks 1,1,1,1,20 in the 5 lists. It seems very significant that the gene ranks number 1 in 4 out of the
5 lists. The function rankPvalue can be used to calculate a p-value for this occurrence.
</p>
<p>The function uses the central limit theorem to calculate asymptotic p-values for two types of test statistics
that measure consistently high or low ordinal values.
The first method (referred to as percentile rank method) leads to accurate estimates of p-values if datS has at
least 4 columns but it can be overly conservative. 
The percentile rank method replaces each column datS by the ranked version rank(datS[,i]) (referred to ask low
ranking) and by rank(-datS[,i]) (referred to as high ranking). Low ranking and high ranking allow one to find
consistently small values or  consistently large values of datS, respectively.  All ranks are divided by the
maximum rank so that the result lies in the unit interval [0,1]. In the following, we refer to rank/max(rank) as
percentile rank. For a given object (corresponding to a row of datS) the observed percentile rank follows
approximately a uniform distribution under the null hypothesis. The test statistic is defined as the sum of the
percentile ranks (across the columns of datS). Under the null hypothesis that there is no relationship between
the rankings of the columns of datS, this (row sum) test statistic follows a distribution that is given by the
convolution of random uniform distributions. Under the null hypothesis, the individual percentile ranks are
independent and one can invoke the central limit theorem to argue that the row sum test statistic follows
asymptotically a normal distribution.  It is well-known that the speed of convergence to the normal distribution
is extremely fast in case of  identically distributed uniform distributions. Even when datS has only  4 columns,
the difference between the normal approximation and the exact distribution is negligible in practice (Killmann
et al 2001).
In summary, we use the central limit theorem to argue that the sum of the percentile ranks follows a normal
distribution whose mean and variance can be calculated using the fact that the mean value of a uniform random
variable (on the unit interval) equals 0.5 and its variance equals 1/12.
</p>
<p>The second method for calculating p-values is referred to as scale method. It is often more powerful but its
asymptotic p-value can only be trusted if either datS has a lot of columns or if the ordinal scores (columns of
datS)  follow an approximate normal distribution.  The scale method scales (or standardizes) each ordinal
variable (column of datS) so that it has mean 0 and variance 1. Under the null hypothesis of independence, the
row sum follows approximately a normal distribution if the assumptions of  the central limit theorem are met.
In practice, we find that the second approach is often more powerful but it makes more distributional
assumptions (if datS has few columns).
</p>


<h3>Value</h3>

<p>A list whose actual content depends on which p-value methods is selected, and whether q0values are calculated.
The following inner components are calculated, organized in outer components <code>datoutrank</code> and
<code>datoutscale</code>,:
</p>
<table role = "presentation">
<tr><td><code>pValueExtremeRank</code></td>
<td>
<p>This is the minimum between pValueLowRank and
pValueHighRank, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowRank</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the rank method.</p>
</td></tr>
<tr><td><code>pValueHighRank</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the rank method.</p>
</td></tr>
<tr><td><code>pValueExtremeScale</code></td>
<td>
<p>This is the minimum between pValueLowScale and
pValueHighScale, i.e. min(pValueLow, pValueHigh)</p>
</td></tr>
<tr><td><code>pValueLowScale</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the Scale method.</p>
</td></tr>
<tr><td><code>pValueHighScale</code></td>
<td>
<p>Asymptotic p-value for observing a consistently low value across
the columns of datS based on the Scale method.</p>
</td></tr>
<tr><td><code>qValueExtremeRank</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueExtremeRank</p>
</td></tr>
<tr><td><code>qValueLowRank</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueLowRank</p>
</td></tr>
<tr><td><code>qValueHighRank</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueHighRank</p>
</td></tr>
<tr><td><code>qValueExtremeScale</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueExtremeScale</p>
</td></tr>
<tr><td><code>qValueLowScale</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueLowScale</p>
</td></tr>
<tr><td><code>qValueHighScale</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the p-value
pValueHighScale</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>


<h3>References</h3>

<p>Killmann F,  VonCollani E (2001) A Note on the Convolution of the Uniform and Related Distributions and Their
Use in Quality Control. Economic Quality Control Vol 16 (2001), No. 1, 17-41.ISSN 0940-5151
</p>
<p>Storey JD and Tibshirani R. (2003) Statistical significance for genome-wide experiments. Proceedings of the
National Academy of Sciences, 100: 9440-9445. </p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+rank">rank</a></code>, <code><a href="#topic+qvalue">qvalue</a></code>
</p>

<hr>
<h2 id='recutBlockwiseTrees'> Repeat blockwise module detection from pre-calculated data </h2><span id='topic+recutBlockwiseTrees'></span>

<h3>Description</h3>

<p>Given consensus networks constructed for example using <code><a href="#topic+blockwiseModules">blockwiseModules</a></code>, this
function (re-)detects modules in them by branch cutting of the corresponding dendrograms. If repeated
branch cuts of the same gene network dendrograms are desired, this function can save substantial time by
re-using already calculated networks and dendrograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recutBlockwiseTrees(
  datExpr,
  goodSamples, goodGenes,
  blocks,
  TOMFiles,
  dendrograms,
  corType = "pearson",
  networkType = "unsigned",
  deepSplit = 2,
  detectCutHeight = 0.995, minModuleSize = min(20, ncol(datExpr)/2 ),
  maxCoreScatter = NULL, minGap = NULL,
  maxAbsCoreScatter = NULL, minAbsGap = NULL,
  minSplitHeight = NULL, minAbsSplitHeight = NULL,

  useBranchEigennodeDissim = FALSE,
  minBranchEigennodeDissim = mergeCutHeight,

  pamStage = TRUE, pamRespectsDendro = TRUE,
  minCoreKME = 0.5, minCoreKMESize = minModuleSize/3,
  minKMEtoStay = 0.3,
  reassignThreshold = 1e-6,
  mergeCutHeight = 0.15, impute = TRUE,
  trapErrors = FALSE, numericLabels = FALSE,
  verbose = 0, indent = 0,
  ...)


</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recutBlockwiseTrees_+3A_datexpr">datExpr</code></td>
<td>
<p> expression data. A data frame in which columns are genes and rows ar samples. NAs are
allowed, but not too many. </p>
</td></tr> 
<tr><td><code id="recutBlockwiseTrees_+3A_goodsamples">goodSamples</code></td>
<td>
<p> a logical vector specifying
which samples are considered &quot;good&quot; for the analysis. See <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code>. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_goodgenes">goodGenes</code></td>
<td>
<p> a logical vector with length equal number of genes in <code>multiExpr</code> that
specifies which genes are considered &quot;good&quot; for the analysis. See <code><a href="#topic+goodSamplesGenes">goodSamplesGenes</a></code>.  </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_blocks">blocks</code></td>
<td>
<p> specification of blocks in which hierarchical clustering and module detection
should be performed. A numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_tomfiles">TOMFiles</code></td>
<td>
<p> a vector of character strings specifying file names in which the block-wise
topological overlaps are saved. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_dendrograms">dendrograms</code></td>
<td>
<p> a list of length equal the number of blocks, in which each component is a
hierarchical clustering dendrograms of the genes that belong to the block. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pariwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_deepsplit">deepSplit</code></td>
<td>
<p> integer value between 0 and 4. Provides a simplified control over how sensitive
module detection should be to module splitting, with 0 least and 4 most sensitive. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> dendrogram cut height for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_maxcorescatter">maxCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster, given as the fraction
of <code>cutHeight</code> relative to the 5th percentile of joining heights. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_mingap">minGap</code></td>
<td>
<p> minimum cluster gap given as the fraction of the difference between <code>cutHeight</code> and
the 5th percentile of joining heights. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr> 
<tr><td><code id="recutBlockwiseTrees_+3A_maxabscorescatter">maxAbsCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster given as absolute
heights. If given, overrides <code>maxCoreScatter</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minabsgap">minAbsGap</code></td>
<td>
<p> minimum cluster gap given as absolute height difference. If given, overrides
<code>minGap</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minsplitheight">minSplitHeight</code></td>
<td>
<p>Minimum split height given as the fraction of the difference between
<code>cutHeight</code> and the 5th percentile of joining heights. Branches merging below this height will
automatically be merged. Defaults to zero but is used only if <code>minAbsSplitHeight</code> below is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minabssplitheight">minAbsSplitHeight</code></td>
<td>
<p>Minimum split height given as an absolute height.
Branches merging below this height will automatically be merged. If not given (default), will be determined
from <code>minSplitHeight</code> above.</p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_usebrancheigennodedissim">useBranchEigennodeDissim</code></td>
<td>
<p>Logical: should branch eigennode (eigengene) dissimilarity be considered
when merging branches in Dynamic Tree Cut?</p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minbrancheigennodedissim">minBranchEigennodeDissim</code></td>
<td>
<p>Minimum consensus branch eigennode (eigengene) dissimilarity for
branches to be considerd separate. The branch eigennode dissimilarity in individual sets
is simly 1-correlation of the
eigennodes; the consensus is defined as quantile with probability <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_pamstage">pamStage</code></td>
<td>
<p> logical.  If TRUE, the second (PAM-like) stage of module detection will be performed.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_pamrespectsdendro">pamRespectsDendro</code></td>
<td>
<p>Logical, only used when <code>pamStage</code> is <code>TRUE</code>.
If <code>TRUE</code>, the PAM stage will
respect the dendrogram in the sense an object can be PAM-assigned only to clusters that lie below it on
the branch that the object is merged into.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled and returned to the pool of genes waiting for mofule detection). </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_reassignthreshold">reassignThreshold</code></td>
<td>
<p> p-value ratio threshold for reassigning genes between modules. See Details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_mergecutheight">mergeCutHeight</code></td>
<td>
<p> dendrogram cut height for module merging. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_numericlabels">numericLabels</code></td>
<td>
<p> logical: should the returned modules be labeled by colors (<code>FALSE</code>), or by
numbers (<code>TRUE</code>)? </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="recutBlockwiseTrees_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on blockwise module detection, see <code><a href="#topic+blockwiseModules">blockwiseModules</a></code>. This
function implements the module detection subset of the functionality of
<code><a href="#topic+blockwiseModules">blockwiseModules</a></code>; network construction and clustering must be performed in
advance. The primary use of this function is to experiment with module detection settings without having
to re-execute long network and clustering calculations whose results are not affected by the cutting
parameters.
</p>
<p>This function takes as input the networks and dendrograms that are produced by
<code><a href="#topic+blockwiseModules">blockwiseModules</a></code>.  Working block by block,
modules are identified in the
dendrogram by the Dynamic Hybrid Tree Cut algorithm. Found modules are trimmed of genes whose
correlation with module eigengene (KME) is less than <code>minKMEtoStay</code>. Modules in which
fewer than <code>minCoreKMESize</code> genes have KME higher than <code>minCoreKME</code> 
are disbanded, i.e., their constituent genes are pronounced
unassigned. 
</p>
<p>After all blocks have been processed, the function checks whether there are genes whose KME in the module
they assigned is lower than KME to another module. If p-values of the higher correlations are smaller
than those of the native module by the factor <code>reassignThresholdPS</code>,
the gene is re-assigned to the closer module.
</p>
<p>In the last step, modules whose eigengenes are highly correlated are merged. This is achieved by
clustering module eigengenes using the dissimilarity given by one minus their correlation,
cutting the dendrogram at the height <code>mergeCutHeight</code> and merging all modules on each branch. The
process is iterated until no modules are merged. See <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for more details on
module merging.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p> a vector of color or numeric module labels for all genes.</p>
</td></tr>
<tr><td><code>unmergedColors</code></td>
<td>
<p> a vector of color or numeric module labels for all genes before module merging.</p>
</td></tr>
<tr><td><code>MEs</code></td>
<td>
<p> a data frame containing module eigengenes of the found modules (given by <code>colors</code>).</p>
</td></tr>
<tr><td><code>MEsOK</code></td>
<td>
<p>logical indicating whether the module eigengenes were calculated without errors. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+blockwiseModules">blockwiseModules</a></code> for full module calculation; 
</p>
<p><code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for adaptive branch cutting in hierarchical clustering
dendrograms;
</p>
<p><code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for merging of close modules.
</p>

<hr>
<h2 id='recutConsensusTrees'> Repeat blockwise consensus module detection from pre-calculated data </h2><span id='topic+recutConsensusTrees'></span>

<h3>Description</h3>

<p>Given consensus networks constructed for example using <code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>, this
function (re-)detects modules in them by branch cutting of the corresponding dendrograms. If repeated
branch cuts of the same gene network dendrograms are desired, this function can save substantial time by
re-using already calculated networks and dendrograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recutConsensusTrees(
  multiExpr,
  goodSamples, goodGenes,
  blocks,
  TOMFiles,
  dendrograms,
  corType = "pearson",
  networkType = "unsigned",
  deepSplit = 2,
  detectCutHeight = 0.995, minModuleSize = 20,
  checkMinModuleSize = TRUE,
  maxCoreScatter = NULL, minGap = NULL,
  maxAbsCoreScatter = NULL, minAbsGap = NULL,
  minSplitHeight = NULL, minAbsSplitHeight = NULL,

  useBranchEigennodeDissim = FALSE,
  minBranchEigennodeDissim = mergeCutHeight,

  pamStage = TRUE, pamRespectsDendro = TRUE,
  trimmingConsensusQuantile = 0,
  minCoreKME = 0.5, minCoreKMESize = minModuleSize/3,
  minKMEtoStay = 0.2,
  reassignThresholdPS = 1e-4,
  mergeCutHeight = 0.15,
  mergeConsensusQuantile = trimmingConsensusQuantile,
  impute = TRUE,
  trapErrors = FALSE,
  numericLabels = FALSE,
  verbose = 2, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recutConsensusTrees_+3A_multiexpr">multiExpr</code></td>
<td>
<p> expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_goodsamples">goodSamples</code></td>
<td>
<p> a list with one component per set. Each component is a logical vector specifying
which samples are considered &quot;good&quot; for the analysis. See <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_goodgenes">goodGenes</code></td>
<td>
<p> a logical vector with length equal number of genes in <code>multiExpr</code> that
specifies which genes are considered &quot;good&quot; for the analysis. See <code><a href="#topic+goodSamplesGenesMS">goodSamplesGenesMS</a></code>.  </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_blocks">blocks</code></td>
<td>
<p> specification of blocks in which hierarchical clustering and module detection
should be performed. A numeric vector with one entry per gene
of <code>multiExpr</code> giving the number of the block to which the corresponding gene belongs. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_tomfiles">TOMFiles</code></td>
<td>
<p> a vector of character strings specifying file names in which the block-wise
topological overlaps are saved. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_dendrograms">dendrograms</code></td>
<td>
<p> a list of length equal the number of blocks, in which each component is a
hierarchical clustering dendrograms of the genes that belong to the block. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pariwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. Note that while no new networks are
computed in this function, this parameter affects the interpretation of correlations in this function. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_deepsplit">deepSplit</code></td>
<td>
<p> integer value between 0 and 4. Provides a simplified control over how sensitive
module detection should be to module splitting, with 0 least and 4 most sensitive. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_detectcutheight">detectCutHeight</code></td>
<td>
<p> dendrogram cut height for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minmodulesize">minModuleSize</code></td>
<td>
<p> minimum module size for module detection. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_checkminmodulesize">checkMinModuleSize</code></td>
<td>
<p> logical: should sanity checks be performed on <code>minModuleSize</code>?</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_maxcorescatter">maxCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster, given as the fraction
of <code>cutHeight</code> relative to the 5th percentile of joining heights. See
<code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details.  </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_mingap">minGap</code></td>
<td>
<p> minimum cluster gap given as the fraction of the difference between <code>cutHeight</code> and
the 5th percentile of joining heights. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr> 
<tr><td><code id="recutConsensusTrees_+3A_maxabscorescatter">maxAbsCoreScatter</code></td>
<td>
<p> maximum scatter of the core for a branch to be a cluster given as absolute
heights. If given, overrides <code>maxCoreScatter</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minabsgap">minAbsGap</code></td>
<td>
<p> minimum cluster gap given as absolute height difference. If given, overrides
<code>minGap</code>. See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minsplitheight">minSplitHeight</code></td>
<td>
<p>Minimum split height given as the fraction of the difference between
<code>cutHeight</code> and the 5th percentile of joining heights. Branches merging below this height will
automatically be merged. Defaults to zero but is used only if <code>minAbsSplitHeight</code> below is
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minabssplitheight">minAbsSplitHeight</code></td>
<td>
<p>Minimum split height given as an absolute height.
Branches merging below this height will automatically be merged. If not given (default), will be determined
from <code>minSplitHeight</code> above.</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_usebrancheigennodedissim">useBranchEigennodeDissim</code></td>
<td>
<p>Logical: should branch eigennode (eigengene) dissimilarity be considered
when merging branches in Dynamic Tree Cut?</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minbrancheigennodedissim">minBranchEigennodeDissim</code></td>
<td>
<p>Minimum consensus branch eigennode (eigengene) dissimilarity for
branches to be considerd separate. The branch eigennode dissimilarity in individual sets
is simly 1-correlation of the
eigennodes; the consensus is defined as quantile with probability <code>consensusQuantile</code>.</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_pamstage">pamStage</code></td>
<td>
<p> logical.  If TRUE, the second (PAM-like) stage of module detection will be performed.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_pamrespectsdendro">pamRespectsDendro</code></td>
<td>
<p>Logical, only used when <code>pamStage</code> is <code>TRUE</code>.
If <code>TRUE</code>, the PAM stage will
respect the dendrogram in the sense an object can be PAM-assigned only to clusters that lie below it on
the branch that the object is merged into.
See <code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_trimmingconsensusquantile">trimmingConsensusQuantile</code></td>
<td>
<p>a number between 0 and 1 specifying the consensus quantile used for kME
calculation that determines module trimming according to the arguments below.</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_mincorekme">minCoreKME</code></td>
<td>
<p> a number between 0 and 1. If a detected module does not have at least
<code>minModuleKMESize</code> genes with eigengene connectivity at least <code>minCoreKME</code>, the module is
disbanded (its genes are unlabeled and returned to the pool of genes waiting for mofule detection). </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_mincorekmesize">minCoreKMESize</code></td>
<td>
<p> see <code>minCoreKME</code> above. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_minkmetostay">minKMEtoStay</code></td>
<td>
<p> genes whose eigengene connectivity to their module eigengene is lower than
<code>minKMEtoStay</code> are removed from the module.</p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_reassignthresholdps">reassignThresholdPS</code></td>
<td>
<p> per-set p-value ratio threshold for reassigning genes between modules. 
See Details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_mergecutheight">mergeCutHeight</code></td>
<td>
<p> dendrogram cut height for module merging. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_mergeconsensusquantile">mergeConsensusQuantile</code></td>
<td>
<p>consensus quantile for module merging. See <code>mergeCloseModules</code> for
details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_impute">impute</code></td>
<td>
<p> logical: should imputation be used for module eigengene calculation? See
<code><a href="#topic+moduleEigengenes">moduleEigengenes</a></code> for more details. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_traperrors">trapErrors</code></td>
<td>
<p> logical: should errors in calculations be trapped? </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_numericlabels">numericLabels</code></td>
<td>
<p> logical: should the returned modules be labeled by colors (<code>FALSE</code>), or by
numbers (<code>TRUE</code>)? </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="recutConsensusTrees_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on blockwise consensus module detection, see <code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>. This
function implements the module detection subset of the functionality of 
<code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>; network construction and clustering must be performed in
advance. The primary use of this function is to experiment with module detection settings without having
to re-execute long network and clustering calculations whose results are not affected by the cutting
parameters. 
</p>
<p>This function takes as input the networks and dendrograms that are produced by
<code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code>.  Working block by block, 
modules are identified in the
dendrograms by the Dynamic Hybrid tree cut. 
Found modules are trimmed of genes whose
consensus module membership kME (that is, correlation with module eigengene) 
is less than <code>minKMEtoStay</code>.
Modules in which
fewer than <code>minCoreKMESize</code> genes have consensus KME higher than <code>minCoreKME</code>
are disbanded, i.e., their constituent genes are pronounced
unassigned. 
</p>
<p>After all blocks have been processed, the function checks whether there are genes whose KME in the module
they assigned is lower than KME to another module. If p-values of the higher correlations are smaller
than those of the native module by the factor <code>reassignThresholdPS</code> (in every set), 
the gene is re-assigned to the closer module. 
</p>
<p>In the last step, modules whose eigengenes are highly correlated are merged. This is achieved by
clustering module eigengenes using the dissimilarity given by one minus their correlation, 
cutting the dendrogram at the height <code>mergeCutHeight</code> and merging all modules on each branch. The
process is iterated until no modules are merged. See <code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for more details on
module merging.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>colors</code></td>
<td>
<p> module assignment of all input genes. A vector containing either character strings with
module colors (if input <code>numericLabels</code> was unset) or numeric module labels (if <code>numericLabels</code>
was set to <code>TRUE</code>). The color &quot;grey&quot; and the numeric label 0 are reserved for unassigned genes.  </p>
</td></tr>
<tr><td><code>unmergedColors</code></td>
<td>
<p> module colors or numeric labels before the module merging step. </p>
</td></tr>
<tr><td><code>multiMEs</code></td>
<td>
<p> module eigengenes corresponding to the modules returned in <code>colors</code>, in multi-set
format. A vector of lists, one per set, containing eigengenes, proportion of variance explained and other
information. See <code><a href="#topic+multiSetMEs">multiSetMEs</a></code> for a detailed description. </p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>Basic sanity checks are performed on given arguments, but it is left to the user's responsibility to
provide valid input.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder</p>


<h3>References</h3>

<p> Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between
co-expression modules. BMC Systems Biology 2007, 1:54 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+blockwiseConsensusModules">blockwiseConsensusModules</a></code> for the full blockwise modules calculation. Parts of its output
are natural input for this function.
</p>
<p><code><a href="dynamicTreeCut.html#topic+cutreeDynamic">cutreeDynamic</a></code> for adaptive branch cutting in hierarchical clustering
dendrograms; 
</p>
<p><code><a href="#topic+mergeCloseModules">mergeCloseModules</a></code> for merging of close modules.
</p>

<hr>
<h2 id='redWhiteGreen'> Red-white-green color sequence </h2><span id='topic+redWhiteGreen'></span>

<h3>Description</h3>

<p>Generate a red-white-green color sequence of a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>redWhiteGreen(n, gamma = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="redWhiteGreen_+3A_n">n</code></td>
<td>
<p> number of colors to be returned </p>
</td></tr>
<tr><td><code id="redWhiteGreen_+3A_gamma">gamma</code></td>
<td>
<p> color correction power </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a color vector that starts with pure green, gradually turns into white and then to
red. The power <code>gamma</code> can be used to control the behaviour of the quarter- and three quarter-values
(between red and white, and white and green, respectively). Higher powers will make the mid-colors more
white, while lower powers will make the colors more saturated, respectively.
</p>


<h3>Value</h3>

<p>A vector of colors of length <code>n</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>Examples</h3>

<pre><code class='language-R'>  par(mfrow = c(3, 1))
  displayColors(redWhiteGreen(50));
  displayColors(redWhiteGreen(50, 3));
  displayColors(redWhiteGreen(50, 0.5));
</code></pre>

<hr>
<h2 id='relativeCorPredictionSuccess'> Compare prediction success </h2><span id='topic+relativeCorPredictionSuccess'></span>

<h3>Description</h3>

<p>Compare prediction success of several gene screening methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relativeCorPredictionSuccess(
  corPredictionNew, 
  corPredictionStandard, 
  corTestSet, 
  topNumber = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="relativeCorPredictionSuccess_+3A_corpredictionnew">corPredictionNew</code></td>
<td>
<p> Matrix of predictor statistics </p>
</td></tr>
<tr><td><code id="relativeCorPredictionSuccess_+3A_corpredictionstandard">corPredictionStandard</code></td>
<td>
<p> Reference presdictor statistics</p>
</td></tr>
<tr><td><code id="relativeCorPredictionSuccess_+3A_cortestset">corTestSet</code></td>
<td>
<p> Correlations of predictor variables with trait in test set</p>
</td></tr>
<tr><td><code id="relativeCorPredictionSuccess_+3A_topnumber">topNumber</code></td>
<td>
<p> A vector giving the numbers of top genes to consider </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with components
</p>
<table role = "presentation">
<tr><td><code>topNumber</code></td>
<td>
<p>copy of the input <code>topNumber</code></p>
</td></tr>
<tr><td><code>kruskalp</code></td>
<td>
<p>Kruskal-Wallis p-values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>See Also</h3>

 <p><code><a href="#topic+corPredictionSuccess">corPredictionSuccess</a></code> </p>

<hr>
<h2 id='removeGreyME'>Removes the grey eigengene from a given collection of eigengenes. </h2><span id='topic+removeGreyME'></span>

<h3>Description</h3>

<p>Given module eigengenes either in a single data frame or in a multi-set format, removes the grey
eigengenes from each set. If the grey eigengenes are not found, a warning is issued.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeGreyME(MEs, greyMEName = paste(moduleColor.getMEprefix(), "grey", sep=""))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="removeGreyME_+3A_mes">MEs</code></td>
<td>
<p>Module eigengenes, either in a single data frame (typicaly for a single set), or in a
multi-set format. See <code><a href="#topic+checkSets">checkSets</a></code> for a description of the multi-set format.</p>
</td></tr>
<tr><td><code id="removeGreyME_+3A_greymename">greyMEName</code></td>
<td>
<p>Name of the module eigengene (in each corresponding data frame) that corresponds to
the grey color. This will typically be &quot;PCgrey&quot; or &quot;MEgrey&quot;. If the module eigengenes were calculated
using standard functions in this library, the default should work.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Module eigengenes in the same format as input (either a single data frame or a vector of lists) with the
grey eigengene removed. 
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>

<hr>
<h2 id='removePrincipalComponents'>
Remove leading principal components from data
</h2><span id='topic+removePrincipalComponents'></span>

<h3>Description</h3>

<p>This function calculates a fixed number of the first principal components of the given data and returns the
residuals of a linear regression of each column on the principal components. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removePrincipalComponents(x, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="removePrincipalComponents_+3A_x">x</code></td>
<td>

<p>Input data, a numeric matrix. All entries must be non-missing and finite.
</p>
</td></tr>
<tr><td><code id="removePrincipalComponents_+3A_n">n</code></td>
<td>

<p>Number of principal components to remove. This must be smaller than the smaller of the number of rows and
columns in <code>x</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of residuals of the same dimensions as <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code> for singular value decomposition, 
<code><a href="stats.html#topic+lm">lm</a></code> for linear regression
</p>

<hr>
<h2 id='replaceMissing'>
Replace missing values with a constant.
</h2><span id='topic+replaceMissing'></span>

<h3>Description</h3>

<p>A convenience function for replacing missing values with a (non-missing) constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replaceMissing(x, replaceWith)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="replaceMissing_+3A_x">x</code></td>
<td>

<p>An atomic vector or array.
</p>
</td></tr>
<tr><td><code id="replaceMissing_+3A_replacewith">replaceWith</code></td>
<td>

<p>Value to replace missing entries in <code>x</code>. The default is <code>FALSE</code> for logical vectors, 
0 for numeric vectors, and empty string &quot;&quot; for character vectors.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>x</code> with missing data replaced.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logVec = c(TRUE, FALSE, NA, TRUE);
replaceMissing(logVec)

numVec = c(1,2,3,4,NA,2)
replaceMissing(numVec)

</code></pre>

<hr>
<h2 id='returnGeneSetsAsList'>
Return pre-defined gene lists in several biomedical categories.
</h2><span id='topic+returnGeneSetsAsList'></span>

<h3>Description</h3>

<p>This function returns gene sets for use with other R functions.  These gene sets can include inputted lists of genes and files containing user-defined lists of genes, as well as a pre-made collection of brain, blood, and other biological lists.  The function returns gene lists associated with each category for use with other enrichment strategies (i.e., GSVA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>returnGeneSetsAsList(
   fnIn = NULL, catNmIn = fnIn, 
   useBrainLists = FALSE, useBloodAtlases = FALSE, 
   useStemCellLists = FALSE, useBrainRegionMarkers = FALSE, 
   useImmunePathwayLists = FALSE, geneSubset=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="returnGeneSetsAsList_+3A_fnin">fnIn</code></td>
<td>

<p>A vector of file names containing user-defined lists.  These files must be in one of three specific formats (see details section).  The default (NULL) may only be used if one of the &quot;use_____&quot; parameters is TRUE.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_catnmin">catNmIn</code></td>
<td>

<p>A vector of category names corresponding to each fnIn.  This name will be appended to each overlap corresponding to that filename.  The default sets the category names as the corresponding file names.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_usebrainlists">useBrainLists</code></td>
<td>

<p>If TRUE, a pre-made set of brain-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_usebloodatlases">useBloodAtlases</code></td>
<td>

<p>If TRUE, a pre-made set of blood-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_usestemcelllists">useStemCellLists</code></td>
<td>

<p>If TRUE, a pre-made set of stem cell (SC)-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_usebrainregionmarkers">useBrainRegionMarkers</code></td>
<td>

<p>If TRUE, a pre-made set of enrichment lists for human brain regions will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  These lists are derived from data from the Allen Human Brain Atlas (https://human.brain-map.org/).  See references section for more details.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_useimmunepathwaylists">useImmunePathwayLists</code></td>
<td>

<p>If TRUE, a pre-made set of enrichment lists for immune system pathways will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  These lists are derived from the lab of Daniel R Saloman.  See references section for more details.
</p>
</td></tr>
<tr><td><code id="returnGeneSetsAsList_+3A_genesubset">geneSubset</code></td>
<td>

<p>A vector of gene (or other) identifiers.  If entered, only genes in this list will be returned in the output, otherwise all genes in each category will be returned (default, geneSubset=NULL).  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>User-inputted files for fnIn can be in one of three formats:
</p>
<p>1) Text files (must end in &quot;.txt&quot;) with one list per file, where the first line is the list descriptor and the remaining lines are gene names corresponding to that list, with one gene per line.  For example
Ribosome
RPS4
RPS8
...
</p>
<p>2) Gene / category files (must be csv files), where the first line is the column headers corresponding to Genes and Lists, and the remaining lines correspond to the genes in each list, for any number of genes and lists.  For example:
Gene, Category
RPS4, Ribosome
RPS8, Ribosome
...
NDUF1, Mitohcondria
NDUF3, Mitochondria
...
MAPT, AlzheimersDisease
PSEN1, AlzheimersDisease
PSEN2, AlzheimersDisease
...
</p>
<p>3) Module membership (kME) table in csv format.  Currently, the module assignment is the only thing that is used, so as long as the Gene column is 2nd and the Module column is 3rd, it doesn't matter what is in the other columns.  For example,
PSID, Gene, Module, &lt;other columns&gt;
&lt;psid&gt;, RPS4, blue, &lt;other columns&gt;
&lt;psid&gt;, NDUF1, red, &lt;other columns&gt;
&lt;psid&gt;, RPS8, blue, &lt;other columns&gt;
&lt;psid&gt;, NDUF3, red, &lt;other columns&gt;
&lt;psid&gt;, MAPT, green, &lt;other columns&gt;
...
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>geneSets</code></td>
<td>

<p>A list of categories in alphabetical order, where each compnent of the list is a character vector of all genes corresponding to the named category.  For example: geneSets = list(category1=c(&quot;gene1&quot;,&quot;gene2&quot;),category2=c(&quot;gene3&quot;,&quot;gene4&quot;,&quot;gene5&quot;))
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>References</h3>

<p>Please see the help file for userListEnrichment in the WGCNA library for references for the pre-defined lists.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: Return a list of genes for various immune pathways
geneSets   = returnGeneSetsAsList(useImmunePathwayLists=TRUE)
geneSets[7:8]
</code></pre>

<hr>
<h2 id='rgcolors.func'>Red and Green Color Specification</h2><span id='topic+rgcolors.func'></span>

<h3>Description</h3>

<p>This function creates a vector of n &ldquo;contiguous&rdquo; colors,
corresponding to n intensities (between 0 and 1) of the red, green
and blue primaries, with the blue intensities set to zero. The
values returned by <code>rgcolors.func</code> can be used with a
<code>col=</code> specification in graphics functions or in
<code><a href="graphics.html#topic+par">par</a></code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgcolors.func(n=50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgcolors.func_+3A_n">n</code></td>
<td>
<p>the number of colors (&gt;= 1) to be used in the red and
green palette. </p>
</td></tr> 
</table>


<h3>Value</h3>

<p>a character vector of color names. Colors are specified
directly in terms of their RGB components with a string of the form
&quot;#RRGGBB&quot;, where each of the pairs RR, GG, BB consist of two
hexadecimal digits giving a value in the range 00 to FF. 
</p>


<h3>Author(s)</h3>

<p>Sandrine Dudoit, <a href="mailto:sandrine@stat.berkeley.edu">sandrine@stat.berkeley.edu</a> <br />
Jane Fridlyand, <a href="mailto:janef@stat.berkeley.edu">janef@stat.berkeley.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotCor">plotCor</a></code>, <code><a href="#topic+plotMat">plotMat</a></code>,
<code><a href="grDevices.html#topic+colors">colors</a></code>, <code><a href="grDevices.html#topic+rgb">rgb</a></code>, <code><a href="graphics.html#topic+image">image</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>rgcolors.func(n=5)
</code></pre>

<hr>
<h2 id='sampledBlockwiseModules'>
Blockwise module identification in sampled data
</h2><span id='topic+sampledBlockwiseModules'></span>

<h3>Description</h3>

<p>This function repeatedly resamples the samples (rows) in supplied data and identifies 
modules on the resampled data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampledBlockwiseModules(
  datExpr,
  nRuns,
  startRunIndex = 1,
  endRunIndex = startRunIndex + nRuns - skipUnsampledCalculation,
  replace = FALSE,
  fraction = if (replace) 1.0 else 0.63,
  randomSeed = 12345,
  checkSoftPower = TRUE,
  nPowerCheckSamples = 2000,
  skipUnsampledCalculation = FALSE,
  corType = "pearson",
  power = 6,
  networkType = "unsigned",
  saveTOMs = FALSE,
  saveTOMFileBase = "TOM",
  ...,
  verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampledBlockwiseModules_+3A_datexpr">datExpr</code></td>
<td>

<p>Expression data. A matrix (preferred) or 
data frame in which columns are genes and rows ar samples. 
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_nruns">nRuns</code></td>
<td>

<p>Number of sampled network construction and module identification runs. If <code>skipUnsampledCalculation</code> is <code>FALSE</code>,
one extra calculation (the first) will contain the unsampled calculation.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_startrunindex">startRunIndex</code></td>
<td>

<p>Number to be assigned to the start run. The run number or index is used to make saved files unique. It is also used in
setting the seed for each run to allow the runs to be replicated in smaller or larger batches.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_endrunindex">endRunIndex</code></td>
<td>

<p>Number (index) of the last run. If given, <code>nRuns</code> is ignored.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_replace">replace</code></td>
<td>

<p>Logical: should samples (observations or rows in entries in <code>multiExpr</code>) be sampled with replacement?
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_fraction">fraction</code></td>
<td>

<p>Fraction of samples to sample for each run.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_randomseed">randomSeed</code></td>
<td>

<p>Integer specifying the random seed. If non-NULL, the random number generator state is saved before the seed is set
and restored at the end of the function. If <code>NULL</code>, the random number generator state is not saved nor
changed at the start, and not restored at the end.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_checksoftpower">checkSoftPower</code></td>
<td>

<p>Logical: should the soft-tresholding power be adjusted to approximately match the connectivity distribution
of the sampled data set and the full data set?
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_npowerchecksamples">nPowerCheckSamples</code></td>
<td>

<p>Number of genes to be sampled from the full data set to calculate connectivity and match soft-tresholding
powers.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_skipunsampledcalculation">skipUnsampledCalculation</code></td>
<td>

<p>Logical: should a calculation on original (not resampled) data be skipped?
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_cortype">corType</code></td>
<td>
<p>Character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pairwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_power">power</code></td>
<td>
<p> Soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_savetoms">saveTOMs</code></td>
<td>

<p>Logical: should the networks (topological overlaps) be saved for each run? Note
that for large data sets (tens of thousands of nodes) the TOM files are rather large.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_savetomfilebase">saveTOMFileBase</code></td>
<td>

<p>Character string giving the base of the file names for TOMs. The actual file names will consist of a
concatenation of <code>saveTOMFileBase</code> and <code>"-run-&lt;run
number&gt;-Block-&lt;block number&gt;.RData"</code>. 
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_...">...</code></td>
<td>

<p>Other arguments to <code><a href="#topic+blockwiseModules">blockwiseModules</a></code>.
</p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="sampledBlockwiseModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each run, samples (but not genes) are randomly sampled to obtain a perturbed data set; a full network
analysis and module identification is carried out, and the results are returned in a list with one component
per run.
</p>
<p>For each run, the soft-thresholding power can optionally be adjusted such that the mean adjacency in the
re-sampled data set equals the mean adjacency in the original data. 
</p>


<h3>Value</h3>

<p>A list with one component per run. Each component is a list with the following components:
</p>
<table role = "presentation">
<tr><td><code>mods</code></td>
<td>
<p>The output of the function <code><a href="#topic+blockwiseModules">blockwiseModules</a></code> applied to a resampled data set.</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>Indices of the samples selected for the resampled data step for this run.</p>
</td></tr>
<tr><td><code>powers</code></td>
<td>
<p>Actual soft-thresholding powers used in this run.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>An application of this function is described in the motivational example section of 
</p>
<p>Langfelder P, Horvath S (2012) Fast R Functions for Robust Correlations and Hierarchical Clustering.
Journal of Statistical Software 46(11) 1-17; PMID: 23050260 PMCID: PMC3465711 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockwiseModules">blockwiseModules</a></code> for the underlying network analysis and module identification;
</p>
<p><code><a href="#topic+sampledHierarchicalConsensusModules">sampledHierarchicalConsensusModules</a></code> for a similar resampling analysis of consensus networks.
</p>

<hr>
<h2 id='sampledHierarchicalConsensusModules'>
Hierarchical consensus module identification in sampled data
</h2><span id='topic+sampledHierarchicalConsensusModules'></span>

<h3>Description</h3>

<p>This function repeatedly resamples the samples (rows) in supplied data and identifies hierarchical consensus 
modules on the resampled data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampledHierarchicalConsensusModules(
  multiExpr,
  multiWeights = NULL,

  networkOptions,
  consensusTree,

  nRuns,
  startRunIndex = 1,
  endRunIndex = startRunIndex + nRuns -1,
  replace = FALSE,
  fraction = if (replace) 1.0 else 0.63,
  randomSeed = 12345,
  checkSoftPower = TRUE,
  nPowerCheckSamples = 2000,
  individualTOMFilePattern = "individualTOM-Run.%r-Set%s-Block.%b.RData",
  keepConsensusTOMs = FALSE,
  consensusTOMFilePattern = "consensusTOM-Run.%r-%a-Block.%b.RData",
  skipUnsampledCalculation = FALSE,
  ...,
  verbose = 2, indent = 0,
  saveRunningResults = TRUE,
  runningResultsFile = "results.tmp.RData")

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_multiexpr">multiExpr</code></td>
<td>

<p>Expression data in the multi-set format (see <code><a href="#topic+checkSets">checkSets</a></code>). A vector of
lists, one per set. Each set must contain a component <code>data</code> that contains the expression data, with
rows corresponding to samples and columns to genes or probes.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_multiweights">multiWeights</code></td>
<td>
<p> optional observation weights in the same format (and dimensions) as <code>multiExpr</code>.
These weights are used for correlation calculations with data in  <code>multiExpr</code>.</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_networkoptions">networkOptions</code></td>
<td>

<p>A single list of class <code><a href="#topic+NetworkOptions">NetworkOptions</a></code> giving options for network calculation for all of the
networks, or a <code><a href="#topic+multiData">multiData</a></code> structure containing one such list for each input data set.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_nruns">nRuns</code></td>
<td>

<p>Number of network construction and module identification runs.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_startrunindex">startRunIndex</code></td>
<td>

<p>Number to be assigned to the start run. The run number or index is used to make saved files unique; it has no
effect on the actual results of the run.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_endrunindex">endRunIndex</code></td>
<td>

<p>Number (index) of the last run. If given, <code>nRuns</code> is ignored.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_replace">replace</code></td>
<td>

<p>Logical: should samples (observations or rows in entries in <code>multiExpr</code>) be sampled with replacement?
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_fraction">fraction</code></td>
<td>

<p>Fraction of samples to sample for each run.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_randomseed">randomSeed</code></td>
<td>

<p>Integer specifying the random seed. If non-NULL, the random number generator state is saved before the seed is set
and restored at the end of the function. If <code>NULL</code>, the random number generator state is not changed nor
saved at the start, and not restored at the end. 
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_checksoftpower">checkSoftPower</code></td>
<td>

<p>Logical: should the soft-tresholding power be adjusted to approximately match the connectivity distribution
of the sampled data set and the full data set?
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_npowerchecksamples">nPowerCheckSamples</code></td>
<td>

<p>Number of genes to be sampled from the full data set to calculate connectivity and match soft-tresholding
powers.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_individualtomfilepattern">individualTOMFilePattern</code></td>
<td>
<p>Pattern for file names for files holding individual TOMs. The tags 
<code>"%r, %a, %b"</code> are replaced by run number, analysis name and block number, respectively. The TOM files are usually
temporary but can be retained, see <code>keepConsensusTOM</code> below.</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_keepconsensustoms">keepConsensusTOMs</code></td>
<td>

<p>Logical: should the (final) consensus TOMs of each sampled calculation be retained after the run ends? Note
that for large data sets (tens of thousands of nodes) the TOM files are rather large.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_consensustomfilepattern">consensusTOMFilePattern</code></td>
<td>
<p>Pattern for file names for files holding consensus TOMs. The tags 
<code>"%r, %a, %b"</code> are replaced by run number, analysis name and block number, respectively. The TOM files are usually
temporary but can be retained, see <code>keepConsensusTOM</code> above.</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_skipunsampledcalculation">skipUnsampledCalculation</code></td>
<td>

<p>Logical: should a calculation on original (not resampled) data be skipped?
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_...">...</code></td>
<td>

<p>Other arguments to <code><a href="#topic+hierarchicalConsensusModules">hierarchicalConsensusModules</a></code>.
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_saverunningresults">saveRunningResults</code></td>
<td>

<p>Logical: should the cumulative results be saved after each run on resampled data? 
</p>
</td></tr>
<tr><td><code id="sampledHierarchicalConsensusModules_+3A_runningresultsfile">runningResultsFile</code></td>
<td>

<p>File name of file in which to save running results into. In case of a parallel execution (say on several
nodes of a cluster), one should choose a unique name for each process to avoid overwriting the same file. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each run, samples (but not genes) are randomly sampled to obtain a perturbed data set; a full network
analysis and module identification is carried out, and the results are returned in a list with one component
per run.
</p>
<p>For each run, the soft-thresholding power can optionally be adjusted such that the mean adjacency in the
re-sampled data set equals the mean adjacency in the original data.
</p>


<h3>Value</h3>

<p>A list with one component per run. Each component is a list with the following components: 
</p>
<table role = "presentation">
<tr><td><code>mods</code></td>
<td>
<p>The output of the function <code><a href="#topic+hierarchicalConsensusModules">hierarchicalConsensusModules</a></code> on the resampled data.</p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>Indices of the samples selected for the resampled data step for this run.</p>
</td></tr>
<tr><td><code>powers</code></td>
<td>
<p>Actual soft-thresholding powers used in this run.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hierarchicalConsensusModules">hierarchicalConsensusModules</a></code> for consensus networ analysis and module identification;
</p>
<p><code><a href="#topic+sampledBlockwiseModules">sampledBlockwiseModules</a></code> for a similar resampling analysis for a single data set.
</p>

<hr>
<h2 id='scaleFreeFitIndex'>
Calculation of fitting statistics for evaluating scale free topology fit.
</h2><span id='topic+scaleFreeFitIndex'></span>

<h3>Description</h3>

<p>The function scaleFreeFitIndex calculates several indices (fitting statistics) for evaluating scale free
topology fit.  The input is a vector (of connectivities) k. Next k is discretized into nBreaks number of
equal-width bins.  Let's denote the resulting vector dk.  The relative frequency for each bin is denoted
p.dk. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaleFreeFitIndex(k, nBreaks = 10, removeFirst = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scaleFreeFitIndex_+3A_k">k</code></td>
<td>

<p>numeric vector whose components contain non-negative values
</p>
</td></tr>
<tr><td><code id="scaleFreeFitIndex_+3A_nbreaks">nBreaks</code></td>
<td>

<p>positive integer. This determines the number of equal width bins.
</p>
</td></tr>
<tr><td><code id="scaleFreeFitIndex_+3A_removefirst">removeFirst</code></td>
<td>

<p>logical. If TRUE then the first bin will be removed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame with columns
</p>
<table role = "presentation">
<tr><td><code>Rsquared.SFT</code></td>
<td>
<p>the model fitting index (R.squared) from the following model lm(log.p.dk ~ log.dk)</p>
</td></tr>
<tr><td><code>slope.SFT</code></td>
<td>
<p>the slope estimate from model lm(log(p(k))~log(k))</p>
</td></tr>
<tr><td><code>truncatedExponentialAdjRsquared</code></td>
<td>
<p>the adjusted R.squared measure from the truncated exponential model
given by lm2 = lm(log.p.dk ~ log.dk + dk).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>

<hr>
<h2 id='scaleFreePlot'> Visual check of scale-free topology </h2><span id='topic+scaleFreePlot'></span>

<h3>Description</h3>

<p>A simple visula check of scale-free network ropology. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaleFreePlot(
  connectivity, 
  nBreaks = 10, 
  truncated = FALSE,  
  removeFirst = FALSE, 
  main = "", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scaleFreePlot_+3A_connectivity">connectivity</code></td>
<td>
<p> vector containing network connectivities. </p>
</td></tr>
<tr><td><code id="scaleFreePlot_+3A_nbreaks">nBreaks</code></td>
<td>
<p> number of breaks in the connectivity dendrogram. </p>
</td></tr>
<tr><td><code id="scaleFreePlot_+3A_truncated">truncated</code></td>
<td>
<p> logical: should a truncated exponential fit be calculated and plotted in addition to
the linear one? </p>
</td></tr>
<tr><td><code id="scaleFreePlot_+3A_removefirst">removeFirst</code></td>
<td>
<p> logical: should the first bin be removed from the fit? </p>
</td></tr>
<tr><td><code id="scaleFreePlot_+3A_main">main</code></td>
<td>
<p> main title for the plot. </p>
</td></tr>
<tr><td><code id="scaleFreePlot_+3A_...">...</code></td>
<td>
<p> other graphical parameter to the <code>plot</code> function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function plots a log-log plot of a histogram of the given <code>connectivities</code>, and fits a linear
model plus optionally a truncated exponential model. The <code class="reqn">R^2</code> of the fit can be considered an index
of the scale freedom of the network topology. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+softConnectivity">softConnectivity</a></code> for connectivity calculation in weigheted networks. </p>

<hr>
<h2 id='SCsLists'>Stem Cell-Related Genes with Corresponding Gene Markers</h2><span id='topic+SCsLists'></span>

<h3>Description</h3>

<p>This matrix gives a predefined set of genes related to several stem cell (SC) types, as reported in two previously-published studies.  It is used with userListEnrichment to search user-defined gene lists for enrichment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SCsLists)</code></pre>


<h3>Format</h3>

<p>A 14003 x 2 matrix of characters containing Gene / Category pairs.  The first column (Gene) lists genes corresponding to a given category (second column).  Each Category entry is of the form &lt;Stem cell-related category&gt;__&lt;reference&gt;, where the references can be found at <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>.  Note that the matrix is sorted first by Category and then by Gene, such that all genes related to the same category are listed sequentially.
</p>


<h3>Source</h3>

<p>For references used in this variable, please see <code><a href="#topic+userListEnrichment">userListEnrichment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SCsLists)
head(SCsLists)
</code></pre>

<hr>
<h2 id='selectFewestConsensusMissing'>
Select columns with the lowest consensus number of missing data
</h2><span id='topic+selectFewestConsensusMissing'></span>

<h3>Description</h3>

<p>Given a <code><a href="#topic+multiData">multiData</a></code> structure, this function calculates the consensus number of present
(non-missing) data
for each variable (column) across the data sets, forms the consensus and for each group selects variables
whose consensus proportion of present data is at least <code>selectFewestMissing</code> (see usage below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectFewestConsensusMissing(
    mdx, 
    colID, 
    group, 
    minProportionPresent = 1, 
    consensusQuantile = 0, 
    verbose = 0,
    ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selectFewestConsensusMissing_+3A_mdx">mdx</code></td>
<td>

<p>A <code><a href="#topic+multiData">multiData</a></code> structure. All sets must have the same columns.
</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_colid">colID</code></td>
<td>
<p> Character vector of column identifiers.  This must include all the column names from
<code>mdx</code>, but can include other values as well. Its entries must be unique (no duplicates) and no
missing values are permitted. 
</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_group">group</code></td>
<td>

<p>Character vector whose components contain the group label (e.g. a character string) for
each entry of <code>colID</code>. This vector must be of the same length as the vector <code>colID</code>. In gene
expression applications, this vector could contain the gene symbol (or a co-expression module label).
</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_minproportionpresent">minProportionPresent</code></td>
<td>
<p>A numeric value between 0 and 1 (logical values will be coerced to numeric). 
Denotes the minimum consensus 
fraction of present data in each column that will result in the column being retained.
</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_consensusquantile">consensusQuantile</code></td>
<td>
<p>A number between 0 and 1 giving the quantile probability for consensus calculation.
0 means the minimum value (true consensus) will be used.</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_verbose">verbose</code></td>
<td>

<p>Level of verbosity; 0 means silent, larger values will cause progress messages to be printed.
</p>
</td></tr>
<tr><td><code id="selectFewestConsensusMissing_+3A_...">...</code></td>
<td>
<p>Other arguments that should be considered undocumented and subject to change.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A 'consensus' of a vector (say 'x') is simply defined as the quantile with probability
<code>consensusQuantile</code> of the vector x. This function calculates, for each variable in <code>mdx</code>, its
proportion of present (i.e., non-NA and non-NaN) 
values in each of the data sets in <code>mdx</code>, and forms the consensus. Only
variables whose consensus proportion of present data is at least <code>selectFewestMissing</code> are retained.
</p>


<h3>Value</h3>

<p>A logical vector with one element per variable in <code>mdx</code>, giving <code>TRUE</code> for the retained
variables.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller and Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiData">multiData</a></code>
</p>

<hr>
<h2 id='setCorrelationPreservation'> Summary correlation preservation measure </h2><span id='topic+setCorrelationPreservation'></span>

<h3>Description</h3>

<p>Given consensus eigengenes, the function calculates the average correlation preservation pair-wise for
all pairs of sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setCorrelationPreservation(
   multiME, 
   setLabels, 
   excludeGrey = TRUE, greyLabel = "grey", 
   method = "absolute")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setCorrelationPreservation_+3A_multime">multiME</code></td>
<td>
<p> consensus module eigengenes in a multi-set format. A vector of lists with one list
corresponding to each set. Each list must contain a component <code>data</code> that is a data frame whose
columns are consensus module eigengenes. </p>
</td></tr>
<tr><td><code id="setCorrelationPreservation_+3A_setlabels">setLabels</code></td>
<td>
<p>names to be used for the sets represented in <code>multiME</code>.</p>
</td></tr>
<tr><td><code id="setCorrelationPreservation_+3A_excludegrey">excludeGrey</code></td>
<td>
<p>logical: exclude the 'grey' eigengene from preservation measure?</p>
</td></tr>
<tr><td><code id="setCorrelationPreservation_+3A_greylabel">greyLabel</code></td>
<td>
<p>module label corresponding to the 'grey' module. Usually this will be the
character string <code>"grey"</code> if the labels are colors, and the number 0 if the labels are numeric.</p>
</td></tr>
<tr><td><code id="setCorrelationPreservation_+3A_method">method</code></td>
<td>
<p> character string giving the correlation preservation measure to use. Recognized values
are (unique abbreviations of) <code>"absolute"</code>, <code>"hyperbolic"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each pair of sets, the function calculates the average preservation of correlation among the
eigengenes. Two preservation measures are available, the abosolute preservation (high if the two
correlations are similar and low if they are different), and the hyperbolically scaled preservation,
which de-emphasizes preservation of low correlation values.
</p>


<h3>Value</h3>

<p>A data frame with each row and column corresponding to a set given in <code>multiME</code>, containing the
pairwise average correlation preservation values. Names and rownames are set to entries of <code>setLabels</code>. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between
co-expression modules. BMC Systems Biology 2007, 1:54 </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+multiSetMEs">multiSetMEs</a></code> for module eigengene calculation;
</p>
<p><code><a href="#topic+plotEigengeneNetworks">plotEigengeneNetworks</a></code> for eigengene network visualization.
</p>

<hr>
<h2 id='shortenStrings'>
Shorten given character strings by truncating at a suitable separator.
</h2><span id='topic+shortenStrings'></span>

<h3>Description</h3>

<p>This function shortens given character strings so they are not longer than a given maximum length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shortenStrings(strings, maxLength = 25, minLength = 10, 
              split = " ", fixed = TRUE,
              ellipsis = "...", countEllipsisInLength = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shortenStrings_+3A_strings">strings</code></td>
<td>

<p>Character strings to be shortened.
</p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_maxlength">maxLength</code></td>
<td>

<p>Maximum length (number of characters) in the strings to be retained. See details for when the returned
strings can exceed this length.
</p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_minlength">minLength</code></td>
<td>

<p>Minimum length of the returned strings. See details.
</p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_split">split</code></td>
<td>

<p>Character string giving the split at which the strings can be truncated. This can be a literal string or a 
regular expression (if the latter, <code>fixed</code> below must be set to <code>FALSE</code>).
</p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_fixed">fixed</code></td>
<td>

<p>Logical: should <code>split</code> be interpreted as a literal specification (<code>TRUE</code>) or as a regular
expression (<code>FALSE</code>)? </p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_ellipsis">ellipsis</code></td>
<td>

<p>Character string that will be appended to every shorten string, to indicate that the string has been
shortened. </p>
</td></tr>
<tr><td><code id="shortenStrings_+3A_countellipsisinlength">countEllipsisInLength</code></td>
<td>

<p>Logical: should the length of the ellipsis count toward the minimum and maximum length?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Strings whose length (number of characters) is at most <code>maxLength</code> are returned unchanged. For those
that are longer, the function uses <code><a href="base.html#topic+gregexpr">gregexpr</a></code> to search for the occurrences of <code>split</code> in
each given 
character string. If such occurrences are found at positions between <code>minLength</code> and <code>maxLength</code>,
the string will be truncated at the last such <code>split</code>; otherwise, the string will be truncated at
<code>maxLength</code>. The <code>ellipsis</code> is appended to each truncated string.
</p>


<h3>Value</h3>

<p>A character vector of strings, shortened as necessary. If the input <code>strings</code> had non-NULL dimensions
and dimnames, these are copied to the output.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gregexpr">gregexpr</a></code>, the workhorse pattern matching function
<code><a href="#topic+formatLabels">formatLabels</a></code> for splitting strings into multiple lines
</p>

<hr>
<h2 id='sigmoidAdjacencyFunction'> Sigmoid-type adacency function. </h2><span id='topic+sigmoidAdjacencyFunction'></span>

<h3>Description</h3>

<p>Sigmoid-type function that converts a similarity to a weighted network adjacency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoidAdjacencyFunction(ss, mu = 0.8, alpha = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sigmoidAdjacencyFunction_+3A_ss">ss</code></td>
<td>
<p> similarity, a number between 0 and 1. Can be given as a scalar, vector or a matrix. </p>
</td></tr>
<tr><td><code id="sigmoidAdjacencyFunction_+3A_mu">mu</code></td>
<td>
<p> shift parameter. </p>
</td></tr>
<tr><td><code id="sigmoidAdjacencyFunction_+3A_alpha">alpha</code></td>
<td>
<p> slope parameter. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sigmoid adjacency function is defined as <code class="reqn">1/(1+\exp[-\alpha(ss - \mu)])</code>.
</p>


<h3>Value</h3>

<p>Adjacencies returned in the same form as the input <code>ss</code>
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

<p> Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>

<hr>
<h2 id='signedKME'> Signed eigengene-based connectivity </h2><span id='topic+signedKME'></span>

<h3>Description</h3>

<p>Calculation of (signed) eigengene-based connectivity, also known as module membership.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signedKME(
  datExpr, 
  datME, 
  exprWeights = NULL,
  MEWeights = NULL,
  outputColumnName = "kME", 
  corFnc = "cor", 
  corOptions = "use = 'p'")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="signedKME_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing the gene expression data. Rows correspond to samples and
columns to genes. Missing values are allowed and will be ignored. </p>
</td></tr>
<tr><td><code id="signedKME_+3A_datme">datME</code></td>
<td>
<p> a data frame containing module eigengenes. Rows  correspond to samples and columns to
module eigengenes. </p>
</td></tr>
<tr><td><code id="signedKME_+3A_exprweights">exprWeights</code></td>
<td>
<p> optional weight matrix of observation weights for <code>datExpr</code>, of the same dimensions as
<code>datExpr</code>. If given, the weights must be non-negative and will be passed on to the correlation function given in
argument <code>corFnc</code> as argument <code>weights.x</code>.</p>
</td></tr>
<tr><td><code id="signedKME_+3A_meweights">MEWeights</code></td>
<td>
<p> optional weight matrix of observation weights for <code>datME</code>, of the same dimensions as
<code>datME</code>. If given, the weights must be non-negative and will be passed on to the correlation function given in
argument <code>corFnc</code> as argument <code>weights.y</code>.</p>
</td></tr>
<tr><td><code id="signedKME_+3A_outputcolumnname">outputColumnName</code></td>
<td>
<p> a character string specifying the prefix of column names of the output. </p>
</td></tr>
<tr><td><code id="signedKME_+3A_corfnc">corFnc</code></td>
<td>
<p> character string specifying the function to be used to calculate co-expression
similarity. Defaults to Pearson correlation. Any function returning values between -1 and 1 can be used. </p>
</td></tr>
<tr><td><code id="signedKME_+3A_coroptions">corOptions</code></td>
<td>
<p> character string specifying additional arguments to be passed to the function given
by <code>corFnc</code>. Use <code>"use = 'p', method = 'spearman'"</code> to obtain Spearman correlation.   </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Signed eigengene-based connectivity of a gene in a module is defined as the correlation of the gene
with the corresponding module eigengene.  The samples in <code>datExpr</code> and <code>datME</code> must be the
same.
</p>


<h3>Value</h3>

<p>A data frame in which rows correspond to input genes and columns to module eigengenes, giving the
signed eigengene-based connectivity of each gene with respect to each eigengene.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Dong J, Horvath S (2007) Understanding Network Concepts in Modules, BMC Systems Biology 2007, 1:24
</p>
<p>Horvath S, Dong J (2008) Geometric Interpretation of Gene Coexpression Network Analysis. PLoS Comput Biol
4(8): e1000117
</p>

<hr>
<h2 id='signifNumeric'>
Round numeric columns to given significant digits.
</h2><span id='topic+signifNumeric'></span>

<h3>Description</h3>

<p>This function applies <code>link{signif}</code> (or possibly other rounding function) to numeric, non-integer
columns of a given data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signifNumeric(x, digits, fnc = "signif")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="signifNumeric_+3A_x">x</code></td>
<td>

<p>Input data frame, matrix or matrix-like object that can be coerced to a data frame.
</p>
</td></tr>
<tr><td><code id="signifNumeric_+3A_digits">digits</code></td>
<td>

<p>Significant digits to retain.
</p>
</td></tr>
<tr><td><code id="signifNumeric_+3A_fnc">fnc</code></td>
<td>

<p>The rounding function. Typically either <code><a href="base.html#topic+signif">signif</a></code> or <code><a href="base.html#topic+round">round</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>fnc</code> is applied to each numeric column that contains at least one non-integer (i.e., at
least one element that does not equal its own <code>round</code>).
</p>


<h3>Value</h3>

<p>The transformed data frame.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The rounding functions <code><a href="base.html#topic+signif">signif</a></code> and <code><a href="base.html#topic+round">round</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  df = data.frame(text = letters[1:3], ints = c(1:3)+234, nonints = c(0:2) + 0.02345);
  df;
  signifNumeric(df, 2);
  signifNumeric(df, 2, fnc = "round");
</code></pre>

<hr>
<h2 id='signumAdjacencyFunction'> Hard-thresholding adjacency function </h2><span id='topic+signumAdjacencyFunction'></span>

<h3>Description</h3>

<p>This function transforms correlations or other measures of similarity into an unweighted network
adjacency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signumAdjacencyFunction(corMat, threshold)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="signumAdjacencyFunction_+3A_cormat">corMat</code></td>
<td>
<p> a matrix of correlations or other measures of similarity. </p>
</td></tr>
<tr><td><code id="signumAdjacencyFunction_+3A_threshold">threshold</code></td>
<td>
<p> threshold for connecting nodes: all nodes whose <code>corMat</code> is above the threshold
will be connected in the resulting network. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An unweighted adjacency matrix of the same dimensions as the input <code>corMat</code>.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code> for soft-thresholding and creating weighted networks. </p>

<hr>
<h2 id='simpleConsensusCalculation'>
Simple calculation of a single consenus
</h2><span id='topic+simpleConsensusCalculation'></span>

<h3>Description</h3>

<p>This function calculates a single consensus from given individual data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpleConsensusCalculation(
  individualData, 
  consensusOptions, 
  verbose = 1, 
  indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simpleConsensusCalculation_+3A_individualdata">individualData</code></td>
<td>

<p>Individual data from which the consensus is to be calculated. It can be either a list or a
<code><a href="#topic+multiData">multiData</a></code> structure in which each element is a numeric vector or array.
</p>
</td></tr>
<tr><td><code id="simpleConsensusCalculation_+3A_consensusoptions">consensusOptions</code></td>
<td>

<p>A list of class <code>ConsensusOptions</code> that contains options for the consensus calculation. A suitable list
can be obtained by calling function <code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>.
</p>
</td></tr>
<tr><td><code id="simpleConsensusCalculation_+3A_verbose">verbose</code></td>
<td>
<p>Integer level of verbosity of diagnostic messages. Zero means silent, higher values make the
output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="simpleConsensusCalculation_+3A_indent">indent</code></td>
<td>
<p>Indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consensus is defined as the element-wise (also known as &quot;parallel&quot;) quantile of of the individual data at
probability given by the <code>consensusQuantile</code> element of <code>consensusOptions</code>. 
</p>


<h3>Value</h3>

<p>A numeric vector or array of the same dimensions as each element of <code>individualData</code>
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>References</h3>

<p>Consensus network analysis was originally described in
Langfelder P, Horvath S. Eigengene networks for studying the relationships
between co-expression modules. BMC Systems Biology 2007, 1:54
https://bmcsystbiol.biomedcentral.com/articles/10.1186/1752-0509-1-54
</p>


<h3>See Also</h3>

<p><code><a href="#topic+consensusCalculation">consensusCalculation</a></code> for consensus calculation that can work with <code><a href="#topic+BlockwiseData">BlockwiseData</a></code>
and can calibrate data before calculating consensus.
</p>

<hr>
<h2 id='simpleHierarchicalConsensusCalculation'>
Simple hierarchical consensus calculation
</h2><span id='topic+simpleHierarchicalConsensusCalculation'></span>

<h3>Description</h3>

<p>Hierarchical consensus calculation without calibration. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpleHierarchicalConsensusCalculation(individualData, consensusTree, level = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simpleHierarchicalConsensusCalculation_+3A_individualdata">individualData</code></td>
<td>

<p>Individual data from which the consensus is to be calculated. It can be either a list or a
<code><a href="#topic+multiData">multiData</a></code> structure. Each element in <code>individulData</code> should be a numeric
object (vector, matrix or array).
</p>
</td></tr>
<tr><td><code id="simpleHierarchicalConsensusCalculation_+3A_consensustree">consensusTree</code></td>
<td>

<p>A list specifying the consensus calculation. See details.
</p>
</td></tr>
<tr><td><code id="simpleHierarchicalConsensusCalculation_+3A_level">level</code></td>
<td>

<p>Integer which the user should leave at 1.  This serves to keep default set names unique.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates consensus in a hierarchical manner, using a separate (and possibly different) set of
consensus options at each step. The &quot;recipe&quot; for the consensus calculation is supplied in the argument
<code>consensusTree</code>.
</p>
<p>The argument <code>consensusTree</code> should have the following components: (1) <code>inputs</code> must be either a
character vector whose components match <code>names(inputData)</code>, or consensus trees in the own right.
(2) <code>consensusOptions</code> must be a list of class <code>"ConsensusOptions"</code> that specifies options for
calculating the consensus. A suitable set of options can be obtained by calling
<code><a href="#topic+newConsensusOptions">newConsensusOptions</a></code>. (3) Optionally, the component <code>analysisName</code> can be a single
character string giving the name for the analysis. When intermediate results are returned, they are returned
in a list whose names will be set from <code>analysisName</code> components, if they exist.
</p>
<p>Unlike the similar function <code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code>, this function ignores the
calibration settings in the <code>consensusOptions</code> component of <code>consensusTree</code>; no calibration of
input data is performed.
</p>
<p>The actual consensus calculation at each level of the consensus tree
is carried out in function <code><a href="#topic+simpleConsensusCalculation">simpleConsensusCalculation</a></code>. The consensus options for each individual
consensus calculation are independent from one another, i.e., the consensus options for different steps can
be different.
</p>


<h3>Value</h3>

<p>A list with a single component  <code>consensus</code>, containing the consensus data of the same dimensions as the
individual entries in the input <code>individualData</code>. This perhaps somewhat cumbersome convention is used to
make the output compatible with that of <code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code>.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simpleConsensusCalculation">simpleConsensusCalculation</a></code> for a &quot;single-level&quot; consensus calculation;
</p>
<p><code><a href="#topic+hierarchicalConsensusCalculation">hierarchicalConsensusCalculation</a></code> for hierarchical consensus calculation with calibration
</p>

<hr>
<h2 id='simulateDatExpr'> Simulation of expression data</h2><span id='topic+simulateDatExpr'></span>

<h3>Description</h3>

<p>Simulation of expression data with a customizable modular structure and several different types of
noise. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateDatExpr(
  eigengenes, 
  nGenes, 
  modProportions, 
  minCor = 0.3, 
  maxCor = 1, 
  corPower = 1, 
  signed = FALSE, 
  propNegativeCor = 0.3, 
  geneMeans = NULL,
  backgroundNoise = 0.1, 
  leaveOut = NULL, 
  nSubmoduleLayers = 0, 
  nScatteredModuleLayers = 0, 
  averageNGenesInSubmodule = 10, 
  averageExprInSubmodule = 0.2, 
  submoduleSpacing = 2, 
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateDatExpr_+3A_eigengenes">eigengenes</code></td>
<td>
<p> a data frame containing the seed eigengenes for the simulated modules. Rows
correspond to samples and columns to modules. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_ngenes">nGenes</code></td>
<td>
<p> total number of genes to be simulated. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_modproportions">modProportions</code></td>
<td>
<p> a numeric vector with length equal the number of eigengenes in <code>eigengenes</code>
plus one, containing fractions of the total number of genes to be put into each of the modules and into
the &quot;grey module&quot;, which means genes not related to any of the modules. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_mincor">minCor</code></td>
<td>
<p> minimum correlation of module genes with the corresponding eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_maxcor">maxCor</code></td>
<td>
<p> maximum correlation of module genes with the corresponding eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_corpower">corPower</code></td>
<td>
<p> controls the dropoff of gene-eigengene correlation. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_signed">signed</code></td>
<td>
<p> logical: should the genes be simulated as belonging to a signed network? If <code>TRUE</code>,
all genes will be simulated to have positive correlation with the eigengene. If <code>FALSE</code>, a
proportion given by <code>propNegativeCor</code> will be simulated with negative correlations of the same
absolute values. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_propnegativecor">propNegativeCor</code></td>
<td>
<p> proportion of genes to be simulated with negative gene-eigengene correlations.
Only effective if <code>signed</code> is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_genemeans">geneMeans</code></td>
<td>
<p> optional vector of length <code>nGenes</code> giving desired mean expression for each gene. If
not given, the returned expression profiles will have mean zero. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_backgroundnoise">backgroundNoise</code></td>
<td>
<p> amount of background noise to be added to the simulated expression data. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_leaveout">leaveOut</code></td>
<td>
<p> optional specification of modules that should be left out of the simulation, that is
their genes will be simulated as unrelated (&quot;grey&quot;). This can
be useful when simulating several sets, in some which a module is present while in others it is absent. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_nsubmodulelayers">nSubmoduleLayers</code></td>
<td>
<p> number of layers of ordered submodules to be added. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_nscatteredmodulelayers">nScatteredModuleLayers</code></td>
<td>
<p> number of layers of scattered submodules to be added. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_averagengenesinsubmodule">averageNGenesInSubmodule</code></td>
<td>
<p> average number of genes in a submodule. See details. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_averageexprinsubmodule">averageExprInSubmodule</code></td>
<td>
<p> average strength of submodule expression vectors. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_submodulespacing">submoduleSpacing</code></td>
<td>
<p> a number giving submodule spacing: this multiple of the submodule size will
lie between the submodule and the next one.  </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="simulateDatExpr_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code>eigengenes</code> can be unrelated or they can exhibit non-trivial correlations. Each module is
simulated separately from others. The expression profiles are chosen such that their
correlations with the eigengene run from just below <code>maxCor</code> to <code>minCor</code> (hence minCor must be
between 0 and 1, not including the bounds). The parameter <code>corPower</code> can be chosen to control the
behaviour of the simulated correlation with the gene index; values higher than 1 will result in the
correlation approaching <code>minCor</code> faster and lower than 1 slower. 
</p>
<p>Numbers of genes in each module are specified (as fractions of the total number of genes <code>nGenes</code>)
by <code>modProportions</code>. The last entry in <code>modProportions</code> corresponds to the genes that will be
simulated as unrelated to anything else (&quot;grey&quot; genes). The proportion must add up to 1 or less. If the
sum is less than one, the remaining genes will be partitioned into groups and simulated to be &quot;close&quot; to
the proper modules, that is with small but non-zero correlations (between <code>minCor</code> and 0)
with the module eigengene. 
</p>
<p>If <code>signed</code> is set <code>FALSE</code>, the correlation for
some of the module genes is chosen negative (but the absolute values remain the same as they would be for
positively correlated genes). To ensure consistency for simulations of multiple sets, the indices of the
negatively correlated genes are fixed and distributed evenly. 
</p>
<p>In addition to the primary module structure, a secondary structure can be optionally simulated. Modules
in the secondary structure have sizes chosen from an exponential distribution with mean equal
<code>averageNGenesInSubmodule</code>. Expression vectors simulated in the secondary structure are simulated
with expected standard deviation chosen from an exponential distribution with mean equal
<code>averageExprInSubmodule</code>; the higher this coefficient, the
more pronounced will the submodules be in the main modules. The secondary structure can be simulated in
several layers; their number is given by <code>SubmoduleLayers</code>. Genes in these submodules are ordered in
the same order as in the main modules. 
</p>
<p>In addition to the ordered submodule structure, a scattered submodule structure can be simulated as well.
This structure can be viewed as noise that tends to correlate random groups of genes. The size and effect 
parameters are the same as for the ordered submodules, and the number of layers added is controlled by
<code>nScatteredModuleLayers</code>. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>datExpr</code></td>
<td>
<p> simulated expression data in a data frame whose columns correspond genes and rows to
samples. </p>
</td></tr>
<tr><td><code>setLabels</code></td>
<td>
<p> simulated module assignment. Module labels are numeric, starting from 1. Genes
simulated to be outside of proper modules have label 0. 
Modules that are left out (specified in <code>leaveOut</code>)
are indicated as 0 here. </p>
</td></tr>
<tr><td><code>allLabels</code></td>
<td>
<p> simulated module assignment. Genes that belong to leftout modules (specified in
<code>leaveOut</code>) are indicated by their would-be  assignment here. </p>
</td></tr>
<tr><td><code>labelOrder</code></td>
<td>
<p> a vector specifying the order in which labels correspond to the given eigengenes,
that is <code>labelOrder[1]</code> is the label assigned to module whose seed is <code>eigengenes[, 1]</code> etc.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> A short description of the simulation method can also be found in the Supplementary Material
to the article
</p>
<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression
modules. BMC Systems Biology 2007, 1:54.
</p>
<p>The material is posted at
http://horvath.genetics.ucla.edu/html/CoexpressionNetwork/EigengeneNetwork/SupplementSimulations.pdf.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+simulateEigengeneNetwork">simulateEigengeneNetwork</a></code> for a simulation of eigengenes with a given causal structure;
</p>
<p><code><a href="#topic+simulateModule">simulateModule</a></code> for simulations of individual modules;
</p>
<p><code><a href="#topic+simulateDatExpr5Modules">simulateDatExpr5Modules</a></code> for a simplified interface to expression simulations;
</p>
<p><code><a href="#topic+simulateMultiExpr">simulateMultiExpr</a></code> for a simulation of several related data sets. 
</p>

<hr>
<h2 id='simulateDatExpr5Modules'> Simplified simulation of expression data</h2><span id='topic+simulateDatExpr5Modules'></span>

<h3>Description</h3>

<p>This function provides a simplified interface to the expression data simulation, at the cost of
considerably less flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateDatExpr5Modules(
  nGenes = 2000,
  colorLabels = c("turquoise", "blue", "brown", "yellow", "green"),
  simulateProportions = c(0.1, 0.08, 0.06, 0.04, 0.02),
  MEturquoise, MEblue, MEbrown, MEyellow, MEgreen,
  SDnoise = 1, backgroundCor = 0.3)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateDatExpr5Modules_+3A_ngenes">nGenes</code></td>
<td>
<p> total number of genes to be simulated. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_colorlabels">colorLabels</code></td>
<td>
<p> labels for simulated modules. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_simulateproportions">simulateProportions</code></td>
<td>
<p> a vector of length 5 giving proportions of the total number of genes to be
placed in each individual module. The entries must be positive and sum to at most 1. If the sum is less
than 1, the leftover genes will be simulated outside of modules. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_meturquoise">MEturquoise</code></td>
<td>
<p> seed module eigengene for the first module. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_meblue">MEblue</code></td>
<td>
<p> seed module eigengene for the second module.  </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_mebrown">MEbrown</code></td>
<td>
<p> seed module eigengene for the third module.  </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_meyellow">MEyellow</code></td>
<td>
<p> seed module eigengene for the fourth module. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_megreen">MEgreen</code></td>
<td>
<p> seed module eigengene for the fifth module.  </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_sdnoise">SDnoise</code></td>
<td>
<p> level of noise to be added to the simulated expressions. </p>
</td></tr>
<tr><td><code id="simulateDatExpr5Modules_+3A_backgroundcor">backgroundCor</code></td>
<td>
<p> backgrond correlation. If non-zero, a component will be added to all genes such
that the average correlation of otherwise unrelated genes will be <code>backgroundCor</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Roughly one-third of the genes are simulated with a negative correlation to their seed eigengene. See
the functions <code><a href="#topic+simulateModule">simulateModule</a></code> and <code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code> for more details.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>datExpr</code></td>
<td>
<p> the simulated expression data in a data frame, with rows corresponding to samples and
columns to genes. </p>
</td></tr>
<tr><td><code>truemodule</code></td>
<td>
<p> a vector with one entry per gene containing the simulated module membership. </p>
</td></tr>
<tr><td><code>datME</code></td>
<td>
<p>a data frame containing a copy of the input module eigengenes. </p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+simulateModule">simulateModule</a></code> for simulation of individual modules;
</p>
<p><code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code> for a more comprehensive data simulation interface. 
</p>

<hr>
<h2 id='simulateEigengeneNetwork'> Simulate eigengene network from a causal model </h2><span id='topic+simulateEigengeneNetwork'></span>

<h3>Description</h3>

<p>Simulates a set of eigengenes (vectors) from a given set of causal anchors and a causal matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateEigengeneNetwork(
  causeMat, 
  anchorIndex, anchorVectors, 
  noise = 1, 
  verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateEigengeneNetwork_+3A_causemat">causeMat</code></td>
<td>
<p> causal matrix. The entry <code>[i,j]</code> is the influence (path coefficient) of
vector <code>j</code> on vector <code>i</code>. </p>
</td></tr>  
<tr><td><code id="simulateEigengeneNetwork_+3A_anchorindex">anchorIndex</code></td>
<td>
<p> specifies the indices of the anchor vectors. </p>
</td></tr>
<tr><td><code id="simulateEigengeneNetwork_+3A_anchorvectors">anchorVectors</code></td>
<td>
<p> a matrix giving the actual anchor vectors as columns. Their number must
equal the length of <code>anchorIndex</code>. </p>
</td></tr>
<tr><td><code id="simulateEigengeneNetwork_+3A_noise">noise</code></td>
<td>
<p> standard deviation of the noise added to each simulated vector. </p>
</td></tr>
<tr><td><code id="simulateEigengeneNetwork_+3A_verbose">verbose</code></td>
<td>
<p> level of verbosity. 0 means silent. </p>
</td></tr>
<tr><td><code id="simulateEigengeneNetwork_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation; each unit adds two
spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm starts with the anchor vectors and iteratively generates the rest from the path
coefficients given in the matrix <code>causeMat</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eigengenes</code></td>
<td>
<p> generated eigengenes. </p>
</td></tr>
<tr><td><code>causeMat</code></td>
<td>
<p> a copy of the input causal matrix</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p> useful for debugging. A vector with one entry for each eigengene giving the number
of generations of parents of the eigengene. Anchors have level 0, their direct causal children have
level 1 etc.</p>
</td></tr>
<tr><td><code>anchorIndex</code></td>
<td>
<p>a copy of the input <code>anchorIndex</code>. </p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>

<hr>
<h2 id='simulateModule'> Simulate a gene co-expression module</h2><span id='topic+simulateModule'></span>

<h3>Description</h3>

<p>Simulation of a single gene co-expression module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateModule(
  ME, 
  nGenes, 
  nNearGenes = 0, 
  minCor = 0.3, maxCor = 1, corPower = 1, 
  signed = FALSE, propNegativeCor = 0.3, 
  geneMeans = NULL,
  verbose = 0, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateModule_+3A_me">ME</code></td>
<td>
<p> seed module eigengene. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_ngenes">nGenes</code></td>
<td>
<p> number of genes in the module to be simulated. Must be non-zero. </p>
</td></tr> 
<tr><td><code id="simulateModule_+3A_nneargenes">nNearGenes</code></td>
<td>
<p> number of genes to be simulated with low correlation with the seed eigengene. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_mincor">minCor</code></td>
<td>
<p> minimum correlation of module genes with the eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_maxcor">maxCor</code></td>
<td>
<p> maximum correlation of module genes with the eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_corpower">corPower</code></td>
<td>
<p>  controls the dropoff of gene-eigengene correlation. See details.  </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_signed">signed</code></td>
<td>
<p> logical: should the genes be simulated as belonging to a signed network? If <code>TRUE</code>,
all genes will be simulated to have positive correlation with the eigengene. If <code>FALSE</code>, a
proportion given by <code>propNegativeCor</code> will be simulated with negative correlations of the same
absolute values.  </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_propnegativecor">propNegativeCor</code></td>
<td>
<p> proportion of genes to be simulated with negative gene-eigengene correlations.
Only effective if <code>signed</code> is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_genemeans">geneMeans</code></td>
<td>
<p> optional vector of length <code>nGenes</code> giving desired mean expression for each gene. If
not given, the returned expression profiles will have mean zero. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="simulateModule_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Module genes are simulated around the eigengene by choosing them such that their (expected)
correlations with the seed eigengene decrease progressively from (just below) <code>maxCor</code> to <code>minCor</code>.
The genes are otherwise independent from one another. The variable <code>corPower</code> determines how fast
the correlation drops towards <code>minCor</code>. Higher powers lead to a faster frop-off; <code>corPower</code> must be
above zero but need not be integer.
</p>
<p>If <code>signed</code> is <code>FALSE</code>, the genes are simulated so as to be part of an unsigned network module,
that is some genes will be simulated with a negative correlation with the seed eigengene (but of the same
absolute value that a positively correlated gene would be simulated with). The proportion of genes with
negative correlation is controlled by <code>propNegativeCor</code>. 
</p>
<p>Optionally, the function can also simulate genes that are &quot;near&quot; the module, meaning they are
simulated with a  low but non-zero correlation with the seed eigengene. The correlations run between
<code>minCor</code> and zero. 
</p>


<h3>Value</h3>

  
<p>A matrix containing the expression data with rows corresponding to samples and columns to genes. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> A short description of the simulation method can also be found in the Supplementary Material
to the article
</p>
<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression
modules. BMC Systems Biology 2007, 1:54.
</p>
<p>The material is posted at
http://horvath.genetics.ucla.edu/html/CoexpressionNetwork/EigengeneNetwork/SupplementSimulations.pdf.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+simulateEigengeneNetwork">simulateEigengeneNetwork</a></code> for a simulation of eigengenes with a given causal structure;
</p>
<p><code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code> for simulations of whole datasets consisting of multiple modules;
</p>
<p><code><a href="#topic+simulateDatExpr5Modules">simulateDatExpr5Modules</a></code> for a simplified interface to expression simulations;
</p>
<p><code><a href="#topic+simulateMultiExpr">simulateMultiExpr</a></code> for a simulation of several related data sets.
</p>

<hr>
<h2 id='simulateMultiExpr'> Simulate multi-set expression data</h2><span id='topic+simulateMultiExpr'></span>

<h3>Description</h3>

<p>Simulation of expression data in several sets with relate module structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateMultiExpr(eigengenes, 
                  nGenes, 
                  modProportions, 
                  minCor = 0.5, maxCor = 1, 
                  corPower = 1, 
                  backgroundNoise = 0.1, 
                  leaveOut = NULL, 
                  signed = FALSE, 
                  propNegativeCor = 0.3, 
                  geneMeans = NULL,
                  nSubmoduleLayers = 0, 
                  nScatteredModuleLayers = 0, 
                  averageNGenesInSubmodule = 10, 
                  averageExprInSubmodule = 0.2, 
                  submoduleSpacing = 2, 
                  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateMultiExpr_+3A_eigengenes">eigengenes</code></td>
<td>
<p>  the seed eigengenes for the simulated modules in a multi-set format. A list with one
component per set. Each component is again a list that must contain a component <code>data</code>. This is a data
frame of seed eigengenes for the corresponding data set. Columns correspond to modules, rows to samples.
Number of samples in the simulated data is determined from the number of samples of the eigengenes. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_ngenes">nGenes</code></td>
<td>
<p> integer specifyin the number of simulated genes. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_modproportions">modProportions</code></td>
<td>
<p>  a numeric vector with length equal the number of eigengenes in <code>eigengenes</code>
plus one, containing fractions of the total number of genes to be put into each of the modules and into
the &quot;grey module&quot;, which means genes not related to any of the modules. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_mincor">minCor</code></td>
<td>
<p> minimum correlation of module genes with the corresponding eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_maxcor">maxCor</code></td>
<td>
<p> maximum correlation of module genes with the corresponding eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_corpower">corPower</code></td>
<td>
<p> controls the dropoff of gene-eigengene correlation. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_backgroundnoise">backgroundNoise</code></td>
<td>
<p> amount of background noise to be added to the simulated expression data. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_leaveout">leaveOut</code></td>
<td>
<p> optional specification of modules that should be left out of the simulation, that is
their genes will be simulated as unrelated (&quot;grey&quot;). A logical matrix in which columns correspond to sets
and rows to modules. Wherever <code>TRUE</code>, the corresponding module in the corresponding data set will not
be simulated, that is its genes will be simulated independently of the eigengene. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_signed">signed</code></td>
<td>
<p> logical: should the genes be simulated as belonging to a signed network? If <code>TRUE</code>,
all genes will be simulated to have positive correlation with the eigengene. If <code>FALSE</code>, a
proportion given by <code>propNegativeCor</code> will be simulated with negative correlations of the same
absolute values. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_propnegativecor">propNegativeCor</code></td>
<td>
<p> proportion of genes to be simulated with negative gene-eigengene correlations.
Only effective if <code>signed</code> is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_genemeans">geneMeans</code></td>
<td>
<p> optional vector of length <code>nGenes</code> giving desired mean expression for each gene. If
not given, the returned expression profiles will have mean zero. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_nsubmodulelayers">nSubmoduleLayers</code></td>
<td>
<p> number of layers of ordered submodules to be added. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_nscatteredmodulelayers">nScatteredModuleLayers</code></td>
<td>
<p> number of layers of scattered submodules to be added. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_averagengenesinsubmodule">averageNGenesInSubmodule</code></td>
<td>
<p> average number of genes in a submodule. See details. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_averageexprinsubmodule">averageExprInSubmodule</code></td>
<td>
<p> average strength of submodule expression vectors. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_submodulespacing">submoduleSpacing</code></td>
<td>
<p> a number giving submodule spacing: this multiple of the submodule size will
lie between the submodule and the next one.  </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="simulateMultiExpr_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details of simulation of individual data sets and the meaning of individual set simulation arguments, 
see <code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code>. This function
simulates several data sets at a time and puts the result in a multi-set format. The number of genes is the
same for all data sets. Module memberships are also the same, but modules can optionally be &ldquo;dissolved&rdquo;,
that is their genes will be simulated as unassigned. Such &ldquo;dissolved&rdquo;, or left out, modules can be
specified in the matrix <code>leaveOut</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>multiExpr</code></td>
<td>
<p>simulated expression data in multi-set format analogous to that of the input
<code>eigengenes</code>.  A list with one
component per set. Each component is again a list that must contains a component <code>data</code>. This is a data
frame of expression data for the corresponding data set. Columns correspond to genes, rows to samples.</p>
</td></tr>
<tr><td><code>setLabels</code></td>
<td>
<p>a matrix of dimensions (number of genes) times (number of sets) that contains module
labels for each genes in each simulated data set. </p>
</td></tr>
<tr><td><code>allLabels</code></td>
<td>
<p>a matrix of dimensions (number of genes) times (number of sets) that contains the module
labels that would be simulated if no module were left out using <code>leaveOut</code>. This means that all columns
of the matrix are equal; the columns are repeated for convenience so <code>allLabels</code> has the same
dimensions as <code>setLabels</code>. </p>
</td></tr>
<tr><td><code>labelOrder</code></td>
<td>
<p>a matrix of dimensions (number of modules) times (number of sets) that contains the 
order in which module labels were assigned to genes in each set. The first label is assigned to genes
1...(module size of module labeled by first label), the second label to the following batch of genes etc.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>References</h3>

 
<p>A short description of the simulation method can also be found in the Supplementary Material
to the article
</p>
<p>Langfelder P, Horvath S (2007) Eigengene networks for studying the relationships between co-expression
modules. BMC Systems Biology 2007, 1:54.
</p>
<p>The material is posted at
http://horvath.genetics.ucla.edu/html/CoexpressionNetwork/EigengeneNetwork/SupplementSimulations.pdf.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+simulateEigengeneNetwork">simulateEigengeneNetwork</a></code> for a simulation of eigengenes with a given causal structure;
</p>
<p><code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code> for simulation of individual data sets; 
</p>
<p><code><a href="#topic+simulateDatExpr5Modules">simulateDatExpr5Modules</a></code> for a simple simulation of a data set consisting of 5 modules;
</p>
<p><code><a href="#topic+simulateModule">simulateModule</a></code> for simulations of individual modules;
</p>

<hr>
<h2 id='simulateSmallLayer'> Simulate small modules </h2><span id='topic+simulateSmallLayer'></span>

<h3>Description</h3>

<p>This function simulates a set of small modules. The primary purpose is to add a submodule structure to
the main module structure simulated by <code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateSmallLayer(
  order, 
  nSamples, 
  minCor = 0.3, maxCor = 0.5, corPower = 1, 
  averageModuleSize, 
  averageExpr, 
  moduleSpacing, 
  verbose = 4, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateSmallLayer_+3A_order">order</code></td>
<td>
<p> a vector giving the simulation order for vectors. See details. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_nsamples">nSamples</code></td>
<td>
<p> integer giving the number of samples to be simulated. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_mincor">minCor</code></td>
<td>
<p> a multiple of <code>maxCor</code> (see below) giving the minimum correlation of module genes
with the corresponding eigengene. See details. </p>
</td></tr> 
<tr><td><code id="simulateSmallLayer_+3A_maxcor">maxCor</code></td>
<td>
<p> maximum correlation of module genes with the corresponding eigengene. See details. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_corpower">corPower</code></td>
<td>
<p> controls the dropoff of gene-eigengene correlation. See details. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_averagemodulesize">averageModuleSize</code></td>
<td>
<p>  average number of genes in a module. See details. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_averageexpr">averageExpr</code></td>
<td>
<p> average strength of module expression vectors. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_modulespacing">moduleSpacing</code></td>
<td>
<p> a number giving module spacing: this multiple of the module size will
lie between the module and the next one.  </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="simulateSmallLayer_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Module eigenvectors are chosen randomly and independently. Module sizes are chosen randomly from an
exponential distribution with mean equal <code>averageModuleSize</code>. Two thirds of genes in 
each module are simulated
as proper module genes and one third as near-module genes (see <code><a href="#topic+simulateModule">simulateModule</a></code> for details). 
Between each successive pairs of
modules a number of genes given by <code>moduleSpacing</code> will be left unsimulated (zero expression).
Module expression, that is the
expected standard deviation of the module expression vectors, is chosen randomly from an exponential
distribution with mean equal <code>averageExpr</code>. The expression profiles are chosen such that their
correlations with the eigengene run from just below <code>maxCor</code> to <code>minCor * maxCor</code> 
(hence minCor must be
between 0 and 1, not including the bounds). The parameter <code>corPower</code> can be chosen to control the
behaviour of the simulated correlation with the gene index; values higher than 1 will result in the
correlation approaching <code>minCor * maxCor</code> faster and lower than 1 slower. 
</p>
<p>The simulated genes will be returned in the order given in <code>order</code>. 
</p>


<h3>Value</h3>

<p>A matrix of simulated gene expressions, with dimension <code>(nSamples, length(order))</code>. 
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+simulateModule">simulateModule</a></code> for simulation of individual modules;
</p>
<p><code><a href="#topic+simulateDatExpr">simulateDatExpr</a></code> for the main gene expression simulation function.
</p>

<hr>
<h2 id='sizeGrWindow'> Opens a graphics window with specified dimensions </h2><span id='topic+sizeGrWindow'></span>

<h3>Description</h3>

<p>If a graphic device window is already open, it is closed and re-opened with specified dimensions (in
inches); otherwise a new window is opened.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sizeGrWindow(width, height)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sizeGrWindow_+3A_width">width</code></td>
<td>
<p> desired width of the window, in inches. </p>
</td></tr>
<tr><td><code id="sizeGrWindow_+3A_height">height</code></td>
<td>
<p> desired heigh of the window, in inches. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>

<hr>
<h2 id='sizeRestrictedClusterMerge'>
Cluter merging with size restrictions
</h2><span id='topic+sizeRestrictedClusterMerge'></span>

<h3>Description</h3>

<p>This function merges clusters by correlation of the first principal components such that the resulting merged clusters do
not exceed a given maximum size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sizeRestrictedClusterMerge(
    datExpr,
    clusters,
    clusterSizes = NULL,
    centers = NULL,
    maxSize,
    networkType = "unsigned",
    verbose = 0,
    indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sizeRestrictedClusterMerge_+3A_datexpr">datExpr</code></td>
<td>

<p>Data on which the clustering is based (e.g., expression data). Variables are in columns and observations (samples) in
rows.
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_clusters">clusters</code></td>
<td>

<p>A vector with element per variable (column) in <code>datExpr</code> giving the cluster label for the corresponding variable.
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_clustersizes">clusterSizes</code></td>
<td>

<p>Optional pre-calculated cluster sizes. If not given, will be determined from given <code>clusters</code>.
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_centers">centers</code></td>
<td>

<p>Optional pre-calculaed cluster centers (first principal components/singular vectors). 
If not given, will be calculated from given data and
cluster assignments.
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_maxsize">maxSize</code></td>
<td>

<p>Maximum allowed size of merged clusters. If any of the given <code>clusters</code> are larger than <code>maxSize</code>, they will not
be changed.
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_networktype">networkType</code></td>
<td>

<p>One of <code>"unsigned"</code> and <code>"signed"</code>. Determines whether clusters with negatively correlated representatives will
be considered similar (<code>"unsigned"</code>) or dis-similar (<code>"signed"</code>). 
</p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="sizeRestrictedClusterMerge_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function iteratively merges two closest clusters subject to the constraint that the merged cluster size cannot exceed
maxSize. Merging stops when no two clusters can be merged without exceeding the maximum size.
</p>


<h3>Value</h3>

<p>A list with two components
</p>
<table role = "presentation">
<tr><td><code>clusters</code></td>
<td>
<p>A numeric vector with one component per input gene, giving the cluster number in
which the gene is assigned. </p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>Cluster centers, that is their first principal components/singular vectors. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p>The last step in <code><a href="#topic+projectiveKMeans">projectiveKMeans</a></code> uses this function.
</p>

<hr>
<h2 id='softConnectivity'> Calculates connectivity of a weighted network. </h2><span id='topic+softConnectivity'></span><span id='topic+softConnectivity.fromSimilarity'></span>

<h3>Description</h3>

<p>Given expression data or a similarity, the function constructs the adjacency matrix and for each
node calculates its connectivity, that is the sum of the adjacency to the other nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softConnectivity(
  datExpr, 
  corFnc = "cor", corOptions = "use = 'p'", 
  weights = NULL,
  type = "unsigned",
  power = if (type == "signed") 15 else 6, 
  blockSize = 1500, 
  minNSamples = NULL, 
  verbose = 2, indent = 0)

softConnectivity.fromSimilarity(
  similarity, 
  type = "unsigned",
  power = if (type == "signed") 15 else 6,
  blockSize = 1500, 
  verbose = 2, indent = 0)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softConnectivity_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing the expression data, with rows corresponding to samples and
columns to genes. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_similarity">similarity</code></td>
<td>
<p> a similarity matrix: a square symmetric matrix with entries between -1 and 1. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_corfnc">corFnc</code></td>
<td>
<p> character string giving the correlation function to be used for the adjacency
calculation. Recommended choices are <code>"cor"</code> and <code>"bicor"</code>, but other functions can be used as
well. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_coroptions">corOptions</code></td>
<td>
<p>  character string giving further options to be passed to the correlation function. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>datExpr</code> to be used in correlation calculation.
A matrix of the same dimensions as <code>datExpr</code>, containing non-negative weights. Only used with Pearson
correlation.</p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_type">type</code></td>
<td>
<p>network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_power">power</code></td>
<td>
<p> soft thresholding power. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_blocksize">blockSize</code></td>
<td>
<p> block size in which adjacency is to be calculated. Too low (say below 100) may make
the calculation inefficient, while too high may cause R to run out of physical memory and slow down the
computer. Should be chosen such that an array of doubles of size (number of genes) * (block size) fits
into available physical memory.</p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_minnsamples">minNSamples</code></td>
<td>
<p> minimum number of samples available for the calculation of adjacency for the
adjacency to be considered valid.  If not given, defaults to the greater of <code>..minNSamples</code>
(currently 4) and number of samples divided by 3.  If the number of samples falls below this threshold,
the connectivity of the corresponding gene will be returned as <code>NA</code>. </p>
</td></tr> 
<tr><td><code id="softConnectivity_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="softConnectivity_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with one entry per gene giving the connectivity of each gene in the weighted network.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>


<h3>References</h3>

 
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code> </p>

<hr>
<h2 id='spaste'>
Space-less paste
</h2><span id='topic+spaste'></span>

<h3>Description</h3>

<p>A convenient wrapper for the <code><a href="base.html#topic+paste">paste</a></code> function with <code>sep=""</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaste(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spaste_+3A_...">...</code></td>
<td>

<p>standard arguments to function <code><a href="base.html#topic+paste">paste</a></code> except <code>sep</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of the corresponding <code><a href="base.html#topic+paste">paste</a></code>.
</p>


<h3>Note</h3>

<p>Do not use the <code>sep</code> argument. Using will lead to an error.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+paste">paste</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  a = 1;
  paste("a=", a);
  spaste("a=", a);
</code></pre>

<hr>
<h2 id='standardColors'>Colors this library uses for labeling modules.</h2><span id='topic+standardColors'></span>

<h3>Description</h3>

<p>Returns the vector of color names in the order they are assigned by other functions in this library.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardColors(n = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardColors_+3A_n">n</code></td>
<td>
<p>Number of colors requested. If <code>NULL</code>, all (approx. 450) colors will be returned. Any
other invalid argument such as less than one or more than maximum (<code>length(standardColors())</code>) will
trigger an error. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of character color names of the requested length.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder, <a href="mailto:Peter.Langfelder@gmail.com">Peter.Langfelder@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>standardColors(10);
</code></pre>

<hr>
<h2 id='standardScreeningBinaryTrait'>
Standard screening for binatry traits
</h2><span id='topic+standardScreeningBinaryTrait'></span>

<h3>Description</h3>

<p>The function standardScreeningBinaryTrait computes widely used statistics for relating the columns of the
input data frame (argument datE) to a binary sample trait (argument y). The statistics include Student
t-test p-value and the corresponding local false discovery rate (known as q-value, Storey et al 2004),
the fold change, the area under the ROC curve (also known as C-index), mean values etc. If the input
option KruskalTest is set to TRUE, it also computes the Kruskal Wallist test p-value and corresponding
q-value. The Kruskal Wallis test is a non-parametric, rank-based group comparison test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardScreeningBinaryTrait(
     datExpr, y, 
     corFnc = cor, corOptions = list(use = 'p'),
     kruskalTest = FALSE, qValues = FALSE,
     var.equal=FALSE, na.action="na.exclude",
     getAreaUnderROC = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardScreeningBinaryTrait_+3A_datexpr">datExpr</code></td>
<td>

<p>a data frame or matrix whose columns will be related to the binary trait
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_y">y</code></td>
<td>

<p>a binary vector whose length (number of components) equals the number of rows of datE
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_corfnc">corFnc</code></td>
<td>
<p> correlation function. Defaults to Pearson correlation. 
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_coroptions">corOptions</code></td>
<td>
<p> a list specifying options to corFnc. An empty list must be specified as <code>list()</code>
(supplying <code>NULL</code> instead will trigger an error). 
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_kruskaltest">kruskalTest</code></td>
<td>

<p>logical: should the Kruskal test be performed?
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_qvalues">qValues</code></td>
<td>

<p>logical: should the q-values be calculated?
</p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_var.equal">var.equal</code></td>
<td>

<p>logical input parameter for the Student t-test. It indicates whether to treat the two variances
(corresponding to the binary grouping) are being equal. If TRUE then the pooled variance is used to estimate
the variance otherwise the Welch (or Satterthwaite) approximation to the degrees of freedom is used.
Warning: here the default value is TRUE which is different from the default value of t.test. Type help(t.test)
for more details. </p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_na.action">na.action</code></td>
<td>

<p>character string for the Student t-test: indicates what should happen when the data contain missing
values NAs. </p>
</td></tr>
<tr><td><code id="standardScreeningBinaryTrait_+3A_getareaunderroc">getAreaUnderROC</code></td>
<td>
<p>logical: should area under the ROC curve be calculated? The calculation slows the
function down somewhat. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame whose rows correspond to the columns of datE and whose
columns report
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p>column names of the input <code>datExpr</code>.</p>
</td></tr>
<tr><td><code>corPearson</code></td>
<td>
<p>pearson correlation with a binary numeric version of the input variable. The numeric
variable equals 1 for level 1 and 2 for level 2. The levels are given by levels(factor(y)).</p>
</td></tr>
<tr><td><code>t.Student</code></td>
<td>
<p>Student's t-test statistic</p>
</td></tr>
<tr><td><code>pvalueStudent</code></td>
<td>
<p>two-sided Student t-test p-value.</p>
</td></tr>
<tr><td><code>qvalueStudent</code></td>
<td>
<p>(if input <code>qValues==TRUE</code>) 
q-value (local false discovery rate) based on the Student T-test p-value (Storey et al 2004).</p>
</td></tr>
<tr><td><code>foldChange</code></td>
<td>
<p>a (signed) ratio of mean values. If the mean in the first group (corresponding to
level 1) is larger than that of the second group, it equals meanFirstGroup/meanSecondGroup.
But if the mean of the second group is larger than that of the first group it equals
-meanSecondGroup/meanFirstGroup (notice the minus sign).</p>
</td></tr>
<tr><td><code>meanFirstGroup</code></td>
<td>
<p>means of columns in input <code>datExpr</code> across samples in the first group.</p>
</td></tr>
<tr><td><code>meanSecondGroup</code></td>
<td>
<p>means of columns in input <code>datExpr</code> across samples in the second group.</p>
</td></tr>
<tr><td><code>SE.FirstGroup</code></td>
<td>
<p>standard errors of columns in input <code>datExpr</code> across samples in the first group. Recall that SE(x)=sqrt(var(x)/n) where n is the number of non-missing values of x. </p>
</td></tr>
<tr><td><code>SE.SecondGroup</code></td>
<td>
<p>standard errors of columns in input <code>datExpr</code> across samples in the second group.</p>
</td></tr>
<tr><td><code>areaUnderROC</code></td>
<td>
<p>the area under the ROC, also known as the concordance index or C.index. This is a
measure of discriminatory power. The measure lies between 0 and 1 where 0.5 indicates no discriminatory
power. 0 indicates that the &quot;opposite&quot; predictor has perfect discriminatory power. To compute it we use
the function <a href="Hmisc.html#topic+rcorr.cens">rcorr.cens</a> with <code>outx=TRUE</code> (from Frank Harrel's package Hmisc).
Only present if input <code>getAreUnderROC</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code>nPresentSamples</code></td>
<td>
<p>number of samples with finite measurements for each gene.</p>
</td></tr>
</table>
<p>If input <code>kruskalTest</code> is <code>TRUE</code>, the following columns further summarize results of
Kruskal-Wallis test:
</p>
<table role = "presentation">
<tr><td><code>stat.Kruskal</code></td>
<td>
<p>Kruskal-Wallis test statistic.</p>
</td></tr>
<tr><td><code>stat.Kruskal.signed</code></td>
<td>
<p>(Warning: experimental) Kruskal-Wallis test statistic including a sign that
indicates whether the average rank is higher in second group (positive) or first group (negative). </p>
</td></tr>
<tr><td><code>pvaluekruskal</code></td>
<td>
<p>Kruskal-Wallis test p-values.</p>
</td></tr>
<tr><td><code>qkruskal</code></td>
<td>
<p>q-values corresponding to the Kruskal-Wallis test p-value (if input <code>qValues==TRUE</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>


<h3>References</h3>

<p>Storey JD, Taylor JE, and Siegmund D. (2004) Strong control, conservative point estimation, and
simultaneous conservative consistency of false discovery rates: A unified approach. Journal of the Royal
Statistical Society, Series B, 66: 187-205. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(survival) # For is.Surv in rcorr.cens
m=50
y=sample(c(1,2),m,replace=TRUE)
datExprSignal=simulateModule(scale(y),30)
datExprNoise=simulateModule(rnorm(m),150)
datExpr=data.frame(datExprSignal,datExprNoise)

Result1=standardScreeningBinaryTrait(datExpr,y)
Result1[1:5,]



# use unequal variances and calculate q-values
Result2=standardScreeningBinaryTrait(datExpr,y, var.equal=FALSE,qValue=TRUE)
Result2[1:5,]

# calculate Kruskal Wallis test and q-values
Result3=standardScreeningBinaryTrait(datExpr,y,kruskalTest=TRUE,qValue=TRUE)
Result3[1:5,]

</code></pre>

<hr>
<h2 id='standardScreeningCensoredTime'>
Standard Screening with regard to a Censored Time Variable 
</h2><span id='topic+standardScreeningCensoredTime'></span>

<h3>Description</h3>

<p>The function standardScreeningCensoredTime computes association measures between the columns of the input
data datE and a censored time variable (e.g. survival time). The censored time is specified using two input
variables &quot;time&quot; and &quot;event&quot;. The event variable is binary where 1 indicates that the event took place (e.g.
the person died) and 0 indicates censored (i.e. lost to follow up).  The function fits univariate Cox
regression models (one for each column of datE) and outputs a Wald test p-value, a logrank p-value,
corresponding local false discovery rates (known as q-values, Storey et al 2004), hazard ratios. Further it
reports the concordance index (also know as area under the ROC curve) and optionally results from
dichotomizing the columns of datE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardScreeningCensoredTime(
   time, 
   event, 
   datExpr, 
   percentiles = seq(from = 0.1, to = 0.9, by = 0.2), 
   dichotomizationResults = FALSE, 
   qValues = TRUE,
   fastCalculation = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardScreeningCensoredTime_+3A_time">time</code></td>
<td>

<p>numeric variable showing time to event or time to last follow up.
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_event">event</code></td>
<td>

<p>Input variable <code>time</code> specifies the time to event or time to last follow up. Input variable
<code>event</code> indicates whether the event happend (=1) or whether there was censoring (=0). 
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_datexpr">datExpr</code></td>
<td>

<p>a data frame or matrix whose columns will be related to the censored time.
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_percentiles">percentiles</code></td>
<td>

<p>numeric vector which is only used when dichotomizationResults=T. Each value should lie between 0 and 1. For
each value specified in the vector percentiles, a binary vector will be defined by dichotomizing the column
value according to the corresponding quantile. Next a corresponding p-value will be calculated.
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_dichotomizationresults">dichotomizationResults</code></td>
<td>

<p>logical. If this option is set to TRUE then the values of the columns of datE will be dichotomized and
corresponding Cox regression p-values will be calculated. 
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_qvalues">qValues</code></td>
<td>

<p>logical. If this option is set to TRUE (default) then q-values will be calculated for the Cox regression
p-values.
</p>
</td></tr>
<tr><td><code id="standardScreeningCensoredTime_+3A_fastcalculation">fastCalculation</code></td>
<td>

<p>logical. If set to TRUE, the function outputs correlation test p-values (and q-values) for correlating the
columns of datE with the expected hazard (if no covariate is fit). Specifically, the expected hazard is
defined as the deviance residual of an intercept only Cox regression model. The results are very similar to
those resulting from a univariate Cox model where the censored time is regressed on the columns of dat.
Specifically, this computational speed up is facilitated by the insight that the p-values resulting from a
univariate Cox regression coxph(Surv(time,event)~datE[,i]) are very similar to those from
corPvalueFisher(cor(devianceResidual,datE[,i]), nSamples).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If input option fastCalculation=TRUE, then the function outputs correlation test p-values (and q-values) for
correlating the columns of datE with the expected hazard (if no covariate is fit). Specifically, the
expected hazard is defined as the deviance residual of an intercept only Cox regression model. The results
are very similar to those resulting from a univariate Cox model where the censored time is regressed on the
columns of dat. Specifically, this computational speed up is facilitated by the insight that the p-values
resulting from a univariate Cox regression coxph(Surv(time,event)~datE[,i]) are very similar to those from
corPvalueFisher(cor(devianceResidual,datE[,i]), nSamples)
</p>


<h3>Value</h3>

<p>If <code>fastCalculation</code> is <code>FALSE</code>, 
the function outputs a data frame whose rows correspond to the columns of datE and whose columns report 
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p>column names of the input data datExpr.</p>
</td></tr>
<tr><td><code>pvalueWald</code></td>
<td>
<p>Wald test p-value from fitting a univariate Cox regression model where the censored time
is regressed on each column of datExpr.</p>
</td></tr>
<tr><td><code>qValueWald</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the Wald test p-value. </p>
</td></tr>
<tr><td><code>pvalueLogrank</code></td>
<td>
<p>Logrank p-value resulting from the Cox regression model. Also known as score test
p-value. For large sample sizes this sould be similar to the Wald test p-value. </p>
</td></tr>
<tr><td><code>qValueLogrank</code></td>
<td>
<p>local false discovery rate (q-value) corresponding to the Logrank test p-value. </p>
</td></tr>
<tr><td><code>HazardRatio</code></td>
<td>
<p>hazard ratio resulting from the Cox model. If the value is larger than 1, then high
values of the column are associated with shorter time, e.g. increased hazard of death. A hazard ratio equal
to 1 means no relationship between the column and time. HR&lt;1 means that high values are associated with
longer time, i.e. lower hazard.</p>
</td></tr>
<tr><td><code>CI.LowerLimitHR</code></td>
<td>
<p>Lower bound of the 95 percent confidence interval of the hazard ratio. </p>
</td></tr>
<tr><td><code>CI.UpperLimitHR</code></td>
<td>
<p>Upper bound of the 95 percent confidence interval of the hazard ratio. </p>
</td></tr>
<tr><td><code>C.index</code></td>
<td>
<p>concordance index, also known as C-index or area under the ROC curve. Calculated with the
rcorr.cens option outx=TRUE (ties are ignored).</p>
</td></tr>
<tr><td><code>MinimumDichotPvalue</code></td>
<td>
<p>This is the smallest p-value from the dichotomization results. To see which
dichotomized variable (and percentile) corresponds to the minimum, study the following columns. </p>
</td></tr>
<tr><td><code>pValueDichot0.1</code></td>
<td>
<p>This columns report the p-value when the column is dichotomized according to the
specified percentile (here 0.1). The percentiles are specified in the input option percentiles. </p>
</td></tr>
<tr><td><code>pvalueDeviance</code></td>
<td>
<p>The p-value resulting from using a correlation test to relate the expected hazard
(deviance residual) with each (undichotomized) column of datE. Specifically, the Fisher transformation is
used to calculate the p-value for the Pearson correlation. The resulting p-value should be very similar to
that of a univariate Cox regression model.</p>
</td></tr>
<tr><td><code>qvalueDeviance</code></td>
<td>
<p>Local false discovery rate (q-value) corresponding to pvalueDeviance.</p>
</td></tr>
<tr><td><code>corDeviance</code></td>
<td>
<p>Pearson correlation between the expected hazard (deviance residual) with each
(undichotomized) column of datExpr.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>

<hr>
<h2 id='standardScreeningNumericTrait'>
Standard screening for numeric traits
</h2><span id='topic+standardScreeningNumericTrait'></span>

<h3>Description</h3>

<p>Standard screening for numeric traits based on Pearson correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardScreeningNumericTrait(datExpr, yNumeric, corFnc = cor,
                              corOptions = list(use = 'p'),
                              alternative = c("two.sided", "less", "greater"),
                              qValues = TRUE,
                              areaUnderROC = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardScreeningNumericTrait_+3A_datexpr">datExpr</code></td>
<td>

<p>data frame containing expression data (or more generally variables to be screened), with rows corresponding
to samples and columns to genes (variables)
</p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_ynumeric">yNumeric</code></td>
<td>

<p>a numeric vector giving the trait measurements for each sample
</p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_corfnc">corFnc</code></td>
<td>
<p> correlation function. 
Defaults to Pearson correlation but can also be <code><a href="#topic+bicor">bicor</a></code>. </p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_coroptions">corOptions</code></td>
<td>
<p> list specifying additional arguments to be passed to the correlation function given
by <code>corFnc</code>. </p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_alternative">alternative</code></td>
<td>
<p>alternative hypothesis for the correlation test</p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_qvalues">qValues</code></td>
<td>
<p> logical: should q-values be calculated?</p>
</td></tr>
<tr><td><code id="standardScreeningNumericTrait_+3A_areaunderroc">areaUnderROC</code></td>
<td>
<p> logical: should are under the receiver-operating curve be calculated?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the correlations, associated p-values, area under the ROC, and q-values
</p>


<h3>Value</h3>

<p>Data frame with the following components:
</p>
<table role = "presentation">
<tr><td><code>ID</code></td>
<td>
<p>Gene (or variable) identifiers copied from <code>colnames(datExpr)</code></p>
</td></tr>
<tr><td><code>cor</code></td>
<td>
<p>correlations of all genes with the trait</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>Fisher Z statistics corresponding to the correlations</p>
</td></tr>
<tr><td><code>pvalueStudent</code></td>
<td>
<p>Student p-values of the correlations</p>
</td></tr>
<tr><td><code>qvalueStudent</code></td>
<td>
<p>(if input <code>qValues==TRUE</code>) q-values of the correlations calculated from the p-values</p>
</td></tr>
<tr><td><code>AreaUnderROC</code></td>
<td>
<p>(if input <code>areaUnderROC==TRUE</code>) area under the ROC</p>
</td></tr>
<tr><td><code>nPresentSamples</code></td>
<td>
<p>number of samples present for the calculation of each association. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standardScreeningBinaryTrait">standardScreeningBinaryTrait</a></code>, <code><a href="#topic+standardScreeningCensoredTime">standardScreeningCensoredTime</a></code>
</p>

<hr>
<h2 id='stdErr'> Standard error of the mean of a given vector. </h2><span id='topic+stdErr'></span>

<h3>Description</h3>

<p>Returns the standard error of the mean of a given vector. Missing values are ignored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdErr(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stdErr_+3A_x">x</code></td>
<td>
<p> a numeric vector </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Standard error of the mean of x.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='stratifiedBarplot'> Bar plots of data across two splitting parameters </h2><span id='topic+stratifiedBarplot'></span>

<h3>Description</h3>

<p>This function takes an expression matrix which can be split using two separate splitting parameters (ie, control vs AD with multiple brain regions), and plots the results as a barplot. Group average, standard deviations, and relevant Kruskal-Wallis p-values are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stratifiedBarplot(
  expAll, 
  groups, split, subset, 
  genes = NA, 
  scale = "N", graph = TRUE, 
  las1 = 2, cex1 = 1.5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stratifiedBarplot_+3A_expall">expAll</code></td>
<td>

<p>An expression matrix, with rows as samples and genes/probes as columns.  If genes=NA, then column names must be included.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_groups">groups</code></td>
<td>

<p>A character vector corresponding to the samples in expAll, with each element the group name of the relevant sample or NA for samples not in any group.  For, example: NA, NA, NA, Con, Con, Con, Con, AD, AD, AD, AD, NA, NA.  This trait will be plotted as adjacent bars for each split.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_split">split</code></td>
<td>

<p>A character vector corresponding to the samples in expAll, with each element the group splitting name of the relevant sample or NA for samples not in any group.  For, example: NA, NA, NA, Hip, Hip, EC, EC, Hip, Hip, EC, EC, NA, NA.  This trait will be plotted as the same color across each split of the barplot.  For the function to work properly, the same split values should be inputted for each group.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_subset">subset</code></td>
<td>

<p>A list of one or more genes to compare the expression with.  If the list contains more than one gene, the first element contains the group name. For example, Ribosomes, RPL3, RPL4, RPS3.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_genes">genes</code></td>
<td>

<p>If entered, this parameter is a list of gene/probe identifiers corresponding to the columns in expAll.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_scale">scale</code></td>
<td>

<p>For subsets of genes that include more than one gene, this parameter determines how the genes are combined into a single value.  Currently, there are five options: 1) (&quot;N&quot;)o scaling (default); 2) first divide each gene by the (&quot;A&quot;)verage across samples; 3) first scale genes to (&quot;Z&quot;)-score across samples; 4) only take the top (&quot;H&quot;)ub gene (ignore all but the highest-connected gene); and 5) take the (&quot;M&quot;)odule eigengene.  Note that these scaling methods have not been sufficiently tested, and should be considered experimental.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_graph">graph</code></td>
<td>

<p>If TRUE (default), bar plot is made.  If FALSE, only the results are returned, and no plot is made.
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_cex1">cex1</code></td>
<td>

<p>Sets the graphing parameters of cex.axis and cex.names (default=1.5)
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_las1">las1</code></td>
<td>

<p>Sets the graphing parameter las (default=2).
</p>
</td></tr>
<tr><td><code id="stratifiedBarplot_+3A_...">...</code></td>
<td>

<p>Other graphing parameters allowed in the barplot function.  Note that the parameters for cex.axis, cex.names, and las are superseded by cex1 and las1 and will therefore be ignored.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>splitGroupMeans</code></td>
<td>

<p>The group/split averaged expression across each group and split combination.  This is the height of the bars in the graph.
</p>
</td></tr>
<tr><td><code>splitGroupSDs</code></td>
<td>

<p>The standard deviation of group/split expression across each group and split combination.  This is the height of the error bars in the graph.
</p>
</td></tr>
<tr><td><code>splitPvals</code></td>
<td>

<p>Kruskal-Wallis p-values for each splitting parameter across groups.
</p>
</td></tr>
<tr><td><code>groupPvals</code></td>
<td>

<p>Kruskal-Wallis p-values for each group parameter across splits.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="#topic+verboseBarplot">verboseBarplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: first simulate some data
set.seed(100)
ME.A = sample(1:100,50);  ME.B = sample(1:100,50)
ME.C = sample(1:100,50);  ME.D = sample(1:100,50)  
ME1     = data.frame(ME.A, ME.B, ME.C, ME.D)
simDatA = simulateDatExpr(ME1,1000,c(0.2,0.1,0.08,0.05,0.3), signed=TRUE)
datExpr = simDatA$datExpr+5
datExpr[1:10,]  = datExpr[1:10,]+2
datExpr[41:50,] = datExpr[41:50,]-1

# Now split up the data and plot it!
subset  = c("Random Genes", "Gene.1", "Gene.234", "Gene.56", "Gene.789")
groups  = rep(c("A","A","A","B","B","B","C","C","C","C"),5)
split   = c(rep("ZZ",10), rep("YY",10), rep("XX",10), rep("WW",10), rep("VV",10))
par(mfrow = c(1,1))
results = stratifiedBarplot(datExpr, groups, split, subset)
results

# Now plot it the other way
results = stratifiedBarplot(datExpr, split, groups, subset)

</code></pre>

<hr>
<h2 id='subsetTOM'> Topological overlap for a subset of a whole set of genes </h2><span id='topic+subsetTOM'></span>

<h3>Description</h3>

<p>This function calculates topological overlap of a subset of vectors with respect to a whole data
set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsetTOM(
  datExpr, 
  subset,
  corFnc = "cor", corOptions = "use = 'p'", 
  weights = NULL,  
  networkType = "unsigned", 
  power = 6, 
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="subsetTOM_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing the expression data of the whole set, 
with rows corresponding to samples and columns to genes. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_subset">subset</code></td>
<td>
<p> a single logical or numeric vector giving the indices of the nodes for which the TOM is to
be calculated. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_corfnc">corFnc</code></td>
<td>
<p> character string giving the correlation function to be used for the adjacency
calculation. Recommended choices are <code>"cor"</code> and <code>"bicor"</code>, but other functions can be used as
well. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_coroptions">corOptions</code></td>
<td>
<p>  character string giving further options to be passed to the correlation function. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>datExpr</code> to be used in correlation calculation.
A matrix of the same dimensions as <code>datExpr</code>, containing non-negative weights. Only used with Pearson
correlation.</p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_networktype">networkType</code></td>
<td>
<p> character string giving network type. Allowed values are (unique abbreviations of)
<code>"unsigned"</code>, <code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="subsetTOM_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to calculated topological overlaps of small subsets of large expression data sets,
for example in individual modules.
</p>


<h3>Value</h3>

<p>A matrix of dimensions <code>n*n</code>, where <code>n</code> is the number of entries selected by <code>block</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> for standard calculation of topological overlap. </p>

<hr>
<h2 id='swapTwoBranches'> Select, swap, or reflect branches in a dendrogram.  </h2><span id='topic+swapTwoBranches'></span><span id='topic+reflectBranch'></span><span id='topic+selectBranch'></span>

<h3>Description</h3>

<p>swapTwoBranches takes the a gene tree object and two genes as input, and swaps the branches containing these two genes at the nearest branch point of the dendrogram.
</p>
<p>reflectBranch takes the a gene tree object and two genes as input, and reflects the branch containing the first gene at the nearest branch point of the dendrogram.
</p>
<p>selectBranch takes the a gene tree object and two genes as input, and outputs indices for all genes in the branch containing the first gene, up to the nearest branch point of the dendrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>swapTwoBranches(hierTOM, g1, g2)
reflectBranch(hierTOM, g1, g2, both = FALSE)
selectBranch(hierTOM, g1, g2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="swapTwoBranches_+3A_hiertom">hierTOM</code></td>
<td>

<p>A hierarchical clustering object (or gene tree) that is used to plot the dendrogram.  For example, the output object from the function hclust or fastcluster::hclust.  Note that elements of hierTOM$order MUST be named (for example, with the corresponding gene name).
</p>
</td></tr>
<tr><td><code id="swapTwoBranches_+3A_g1">g1</code></td>
<td>

<p>Any gene in the branch of interest.
</p>
</td></tr>
<tr><td><code id="swapTwoBranches_+3A_g2">g2</code></td>
<td>

<p>Any gene in a branch directly adjacent to the branch of interest.
</p>
</td></tr>
<tr><td><code id="swapTwoBranches_+3A_both">both</code></td>
<td>

<p>Logical: should the selection include the branch gene <code>g2</code>?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>swapTwoBranches and reflectBranch return a hierarchical clustering object with the hierTOM$order variable properly adjusted, but all other variables identical as the heirTOM input.
</p>
<p>selectBranch returns a numeric vector corresponding to all genes in the requested branch.
</p>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example: first simulate some data.
n = 30;
n2 = 2*n;
n.3 = 20;
n.5 = 10;
MEturquoise = sample(1:(2*n),n)
MEblue      = c(MEturquoise[1:(n/2)], sample(1:(2*n),n/2))
MEbrown     = sample(1:n2,n)
MEyellow    = sample(1:n2,n) 
MEgreen     = c(MEyellow[1:n.3], sample(1:n2,n.5))
MEred	    = c(MEbrown [1:n.5], sample(1:n2,n.3))

ME     = data.frame(MEturquoise, MEblue, MEbrown, MEyellow, MEgreen, MEred)
dat1   = simulateDatExpr(ME,8*n ,c(0.16,0.12,0.11,0.10,0.10,0.09,0.15), 
                         signed=TRUE)
TOM1   = TOMsimilarityFromExpr(dat1$datExpr, networkType="signed")
colnames(TOM1) &lt;- rownames(TOM1) &lt;- colnames(dat1$datExpr)
tree1  = fastcluster::hclust(as.dist(1-TOM1),method="average")
colorh = labels2colors(dat1$allLabels)

plotDendroAndColors(tree1,colorh,dendroLabels=FALSE)

## Reassign modules using the selectBranch and chooseOneHubInEachModule functions

datExpr = dat1$datExpr
hubs    = chooseOneHubInEachModule(datExpr, colorh)
colorh2 = rep("grey", length(colorh))
colorh2 [selectBranch(tree1,hubs["blue"],hubs["turquoise"])] = "blue"
colorh2 [selectBranch(tree1,hubs["turquoise"],hubs["blue"])] = "turquoise"
colorh2 [selectBranch(tree1,hubs["green"],hubs["yellow"])]   = "green"
colorh2 [selectBranch(tree1,hubs["yellow"],hubs["green"])]   = "yellow"
colorh2 [selectBranch(tree1,hubs["red"],hubs["brown"])]      = "red"
colorh2 [selectBranch(tree1,hubs["brown"],hubs["red"])]      = "brown"
plotDendroAndColors(tree1,cbind(colorh,colorh2),c("Old","New"),dendroLabels=FALSE)

## Now swap and reflect some branches, then optimize the order of the branches

# Open a suitably sized graphics window

sizeGrWindow(12,9);

# partition the screen for 3 dendrogram + module color plots

layout(matrix(c(1:6), 6, 1), heights = c(0.8, 0.2, 0.8, 0.2, 0.8, 0.2));

plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Starting Dendrogram", 
                    setLayout = FALSE)

tree1 = swapTwoBranches(tree1,hubs["red"],hubs["turquoise"])
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Swap blue/turquoise and red/brown", 
                    setLayout = FALSE)

tree1 = reflectBranch(tree1,hubs["blue"],hubs["green"])
plotDendroAndColors(tree1,colorh2,dendroLabels=FALSE,main="Reflect turquoise/blue", 
                    setLayout = FALSE)


## End(Not run)</code></pre>

<hr>
<h2 id='TOMplot'> Graphical representation of the Topological Overlap Matrix </h2><span id='topic+TOMplot'></span>

<h3>Description</h3>

<p>Graphical representation of the Topological Overlap Matrix using a heatmap plot combined with
the corresponding hierarchical clustering dendrogram and module colors. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TOMplot(
   dissim, 
   dendro, 
   Colors = NULL, 
   ColorsLeft = Colors, 
   terrainColors = FALSE, 
   setLayout = TRUE,
   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TOMplot_+3A_dissim">dissim</code></td>
<td>
<p> a matrix containing the topological overlap-based dissimilarity </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_dendro">dendro</code></td>
<td>
<p> the corresponding hierarchical clustering dendrogram </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_colors">Colors</code></td>
<td>
<p> optional specification of module colors to be plotted on top </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_colorsleft">ColorsLeft</code></td>
<td>
<p> optional specification of module colors on the left side. If <code>NULL</code>,
<code>Colors</code> will be used.  </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_terraincolors">terrainColors</code></td>
<td>
<p> logical: should terrain colors be used? </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_setlayout">setLayout</code></td>
<td>
<p> logical: should layout be set? If <code>TRUE</code>, standard layout for one plot will be
used. Note that this precludes multiple plots on one page. If <code>FALSE</code>, the user is responsible for
setting the correct layout. </p>
</td></tr>
<tr><td><code id="TOMplot_+3A_...">...</code></td>
<td>
<p> other graphical parameters to <code><a href="stats.html#topic+heatmap">heatmap</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard <code>heatmap</code> function uses the <code><a href="graphics.html#topic+layout">layout</a></code> function to set the following
layout (when <code>Colors</code> is given):
</p>
<pre>
0 0 5
0 0 2
4 1 3
</pre>
<p>To get a meaningful heatmap plot, user-set layout must respect this geometry. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+heatmap">heatmap</a></code>, the workhorse function doing the plotting. </p>

<hr>
<h2 id='TOMsimilarity'> Topological overlap matrix similarity and dissimilarity</h2><span id='topic+TOMsimilarity'></span><span id='topic+TOMdist'></span>

<h3>Description</h3>

<p>Calculation of the topological overlap matrix, and the corresponding dissimilarity, 
from a given adjacency matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TOMsimilarity(
    adjMat,
    TOMType = "unsigned",
    TOMDenom = "min",
    suppressTOMForZeroAdjacencies = FALSE,
    suppressNegativeTOM = FALSE,
    useInternalMatrixAlgebra = FALSE,
    verbose = 1,
    indent = 0)
TOMdist(
    adjMat,
    TOMType = "unsigned",
    TOMDenom = "min",
    suppressTOMForZeroAdjacencies = FALSE,
    suppressNegativeTOM = FALSE,
    useInternalMatrixAlgebra = FALSE,
    verbose = 1,
    indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TOMsimilarity_+3A_adjmat">adjMat</code></td>
<td>
<p> adjacency matrix, that is a square, symmetric matrix with entries between 0 and 1 
(negative values are allowed if <code>TOMType=="signed"</code>).  </p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details.</p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce 
better results but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_suppresstomforzeroadjacencies">suppressTOMForZeroAdjacencies</code></td>
<td>
<p>Logical: should the results be set to zero for zero adjacencies?</p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative? </p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_useinternalmatrixalgebra">useInternalMatrixAlgebra</code></td>
<td>
<p>Logical: should WGCNA's own, slow, matrix multiplication be used instead of
R-wide BLAS? Only useful for debugging.</p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="TOMsimilarity_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions perform basically the same calculations of topological overlap. <code>TOMdist</code> turns the
overlap (which is a measure of similarity) into a measure of dissimilarity by subtracting it from 1. 
</p>
<p>Basic checks on the adjacency matrix are performed and missing entries are replaced by zeros.
</p>
<p>See <code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> for details on the various TOM types.
</p>
<p>The underlying C code assumes that the diagonal of the adjacency matrix equals 1. If this is not the case,
the diagonal of the input is set to 1 before the calculation begins.
</p>


<h3>Value</h3>

<p>A matrix holding the topological overlap.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

 
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>
<p>For the Nowick-type signed TOM (referred to as weighted TO, wTO, by Nowick et al.), see 
</p>
<p>Nowick K, Gernat T, Almaas E, Stubbs L. Differences in human and chimpanzee gene expression patterns define an evolving network of transcription factors in brain. Proc Natl Acad Sci U S A. 2009 Dec 29;106(52):22358-63. doi: 10.1073/pnas.0911376106. Epub 2009 Dec 10.
</p>
<p>or
Gysi DM, Voigt A, Fragoso TM, Almaas E, Nowick K.
wTO: an R package for computing weighted topological overlap and a consensus network with integrated visualization tool.
BMC Bioinformatics. 2018 Oct 24;19(1):392. doi: 10.1186/s12859-018-2351-7.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TOMsimilarityFromExpr">TOMsimilarityFromExpr</a></code> </p>

<hr>
<h2 id='TOMsimilarityFromExpr'> Topological overlap matrix </h2><span id='topic+TOMsimilarityFromExpr'></span>

<h3>Description</h3>

<p>Calculation of the topological overlap matrix from given expression data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TOMsimilarityFromExpr(
  datExpr, 
  weights = NULL,
  corType = "pearson", 
  networkType = "unsigned", 
  power = 6, 
  TOMType = "signed", 
  TOMDenom = "min",
  maxPOutliers = 1,
  quickCor = 0,
  pearsonFallback = "individual",
  cosineCorrelation = FALSE, 
  replaceMissingAdjacencies = FALSE,
  suppressTOMForZeroAdjacencies = FALSE,
  suppressNegativeTOM = FALSE,
  useInternalMatrixAlgebra = FALSE,
  nThreads = 0,
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TOMsimilarityFromExpr_+3A_datexpr">datExpr</code></td>
<td>
<p> expression data. A data frame in which columns are genes and rows ar samples. NAs are
allowed, but not too many. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_weights">weights</code></td>
<td>
<p>optional observation weights for <code>datExpr</code> to be used in correlation calculation. 
A matrix of the same dimensions as
<code>datExpr</code>, containing non-negative weights.</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_cortype">corType</code></td>
<td>
<p> character string specifying the correlation to be used. Allowed values are (unique
abbreviations of) <code>"pearson"</code> and <code>"bicor"</code>, corresponding to Pearson and bidweight
midcorrelation, respectively. Missing values are handled using the <code>pairwise.complete.obs</code> option. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_networktype">networkType</code></td>
<td>
<p> network type. Allowed values are (unique abbreviations of) <code>"unsigned"</code>,
<code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for netwoek construction. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_tomtype">TOMType</code></td>
<td>
<p> one of <code>"none"</code>, <code>"unsigned"</code>, <code>"signed"</code>, <code>"signed Nowick"</code>,
<code>"unsigned 2"</code>, <code>"signed 2"</code> and <code>"signed Nowick 2"</code>. If <code>"none"</code>, adjacency
will be used for clustering. See details and keep in mind that the &quot;2&quot; versions should be considered experimental and are
subject to change.</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_tomdenom">TOMDenom</code></td>
<td>
<p> a character string specifying the TOM variant to be used. Recognized values are 
<code>"min"</code> giving the standard TOM described in Zhang and Horvath (2005), and <code>"mean"</code> in which 
the <code>min</code> function in the denominator is replaced by <code>mean</code>. The <code>"mean"</code> may produce
better results but at this time should be considered experimental.</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_maxpoutliers">maxPOutliers</code></td>
<td>
<p> only used for <code>corType=="bicor"</code>. Specifies the maximum percentile of data
that can be considered outliers on either 
side of the median separately. For each side of the median, if
higher percentile than <code>maxPOutliers</code> is considered an outlier by the weight function based on
<code>9*mad(x)</code>, the width of the weight function is increased such that the percentile of outliers on
that side of the median equals <code>maxPOutliers</code>. Using <code>maxPOutliers=1</code> will effectively disable
all weight function broadening; using <code>maxPOutliers=0</code> will give results that are quite similar (but
not equal to) Pearson correlation. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_quickcor">quickCor</code></td>
<td>
<p> real number between 0 and 1 that controls the handling of missing data in the
calculation of correlations. See details. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_pearsonfallback">pearsonFallback</code></td>
<td>
<p>Specifies whether the bicor calculation, if used, should revert to Pearson when median 
absolute deviation (mad) is zero. Recongnized values are (abbreviations of) 
<code>"none", "individual", "all"</code>. If set to
<code>"none"</code>, zero mad will result in <code>NA</code> for the corresponding correlation. 
If set to <code>"individual"</code>, Pearson calculation will be used only for columns that have zero mad. 
If set to <code>"all"</code>, the presence of a single zero mad will cause the whole variable to be treated in 
Pearson correlation manner (as if the corresponding <code>robust</code> option was set to <code>FALSE</code>). Has no
effect for Pearson correlation. See <code><a href="#topic+bicor">bicor</a></code>.</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_cosinecorrelation">cosineCorrelation</code></td>
<td>
<p>logical: should the cosine version of the correlation calculation be used? The 
cosine calculation differs from the standard one in that it does not subtract the mean. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_replacemissingadjacencies">replaceMissingAdjacencies</code></td>
<td>
<p>logical: should missing values in the calculation of adjacency be
replaced by 0?</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_suppresstomforzeroadjacencies">suppressTOMForZeroAdjacencies</code></td>
<td>
<p>Logical: should the result be set to zero for zero adjacencies?</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_suppressnegativetom">suppressNegativeTOM</code></td>
<td>
<p>Logical: should the result be set to zero when negative?</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_useinternalmatrixalgebra">useInternalMatrixAlgebra</code></td>
<td>
<p>Logical: should WGCNA's own, slow, matrix multiplication be used instead of
R-wide BLAS? Only useful for debugging.</p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_nthreads">nThreads</code></td>
<td>
<p> non-negative integer specifying the number of parallel threads to be used by certain
parts of correlation calculations. This option only has an effect on systems on which a POSIX thread
library is available (which currently includes Linux and Mac OSX, but excludes Windows).
If zero, the number of online processors will be used if it can be determined dynamically, otherwise
correlation calculations will use 2 threads. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="TOMsimilarityFromExpr_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several alternate definitions of topological overlap are available. The oldest version is now called &quot;unsigned&quot;; in this
version, all adjacencies are assumed to be non-negative and the topological overlap of nodes <code class="reqn">i,j</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">TOM_{ij} = \frac{a_{ij} + \sum_{k\neq i,j} a_{ik}a_{kj} }{f(k_i, k_j) + 1 - a_{ij}} \, ,</code>
</p>

<p>where the sum is over <code class="reqn">k</code> not equal to either <code class="reqn">i</code> or <code class="reqn">j</code>, the function <code class="reqn">f</code> in the denominator can be
either min or mean (goverened by argument <code>TOMDenom</code>), and <code class="reqn">k_i = \sum_{j\neq i} a_{ij}</code> is
the connectivity of node <code class="reqn">i</code>. The signed versions assume that the adjacency matrix was obtained from an underlying
correlation matrix, and the element <code class="reqn">a_{ij}</code> carries the sign of the underlying correlation of the two
vectors. (Within WGCNA, this can really only apply to the unsigned adjacency since signed adjacencies are (essentially)
zero when the underlying correlation is negative.) The signed and signed Nowick versions are similar to the above unsigned
version, differing only in absolute
values placed in the expression: the signed Nowick expression is
</p>
<p style="text-align: center;"><code class="reqn">TOM_{ij} = \frac{a_{ij} + \sum_{k\neq i,j} a_{ik}a_{kj} }{f(k_i, k_j) + 1 - |a_{ij}|} \, .</code>
</p>

<p>This TOM lies between -1 and 1, and typically is negative when the underlying adjacency is negative. The signed TOM is
simply the absolute value of the signed Nowick TOM and is hence always non-negative. For non-negative
adjacencies, all 3 version give the same result. 
</p>
<p>A brief note on terminology: the original article by Nowick et al use the name &quot;weighted TO&quot; or wTO; since all of the
topological overlap versions calculated in this function are weighted, we use the name signed to indicate that this TOM
keeps track of the sign of the underlying correlation.
</p>
<p>The &quot;2&quot; versions of all 3 adjacency types have a somewhat different form in which the adjacency and the product are
normalized separately. Thus, the &quot;unsigned 2&quot; version is 
</p>
<p style="text-align: center;"><code class="reqn">TOM^{(2)}_{ij} = \frac{1}{2}\left[a_{ij} + \frac{\sum_{k\neq i,j} a_{ik}a_{kj} }{f(k_i, k_j) - a_{ij}}\right] \, .</code>
</p>

<p>At present the relative weight of the adjacency and the normalized product term are equal and fixed; in the future a
user-specified or automatically determined weight may be implemented. The &quot;signed Nowick 2&quot; and &quot;signed 2&quot; are defined
analogously to their original versions. The adjacency is assumed to be signed, and the expression for &quot;signed Nowick 2&quot;
TOM is
</p>
<p style="text-align: center;"><code class="reqn">TOM^{(2)}_{ij} = \frac{1}{2}\left[a_{ij} + \frac{\sum_{k\neq i,j} a_{ik}a_{kj} }{f(k_i, k_j) - |a_{ij}| } \right] \, .</code>
</p>

<p>Analogously to &quot;signed&quot; TOM, &quot;signed 2&quot; differs from &quot;signed Nowick 2&quot; TOM only in taking the absolute value of the result.
</p>
<p>At present the &quot;2&quot; versions should all be considered experimental and are subject to change.
</p>


<h3>Value</h3>

<p>A matrix holding the topological overlap.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder</p>


<h3>References</h3>

  
<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> </p>

<hr>
<h2 id='transposeBigData'>Transpose a big matrix or data frame
</h2><span id='topic+transposeBigData'></span>

<h3>Description</h3>

<p>This transpose command partitions a big matrix (or data frame) into blocks and applies the t() function to
each block separately.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transposeBigData(x, blocksize = 20000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transposeBigData_+3A_x">x</code></td>
<td>
<p>a matrix or data frame
</p>
</td></tr>
<tr><td><code id="transposeBigData_+3A_blocksize">blocksize</code></td>
<td>
<p>a positive integer larger than 1, which determines the block size. Default is 20k.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume you have a very large matrix with say 500k columns. In this case, the standard transpose function of
R <code>t()</code> can take a long time. Solution: Split the original matrix into sub-matrices by dividing the
columns into blocks. Next apply  <code>t()</code> to each sub-matrix. The same holds if the large matrix contains
a large number of rows.  The function <code>transposeBigData</code> automatically checks whether the large matrix
contains more rows or more columns. If the number of columns is larger than or equal to the number of rows
then the block wise splitting will be applied to columns otherwise to the rows.  </p>


<h3>Value</h3>

<p>A matrix or data frame (depending on the input <code>x</code> ) which is the transpose of <code>x</code>. 
</p>


<h3>Note</h3>

<p>This function can be considered a wrapper of <code><a href="base.html#topic+t">t</a>()</code>
</p>


<h3>Author(s)</h3>

<p>Steve Horvath, UCLA
</p>


<h3>References</h3>

<p>Any linear algebra book will explain the transpose.
</p>


<h3>See Also</h3>

<p>The standard function <code><a href="base.html#topic+t">t</a></code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=data.frame(matrix(1:10000,nrow=4,ncol=2500))
dimnames(x)[[2]]=paste("Y",1:2500,sep="")
xTranspose=transposeBigData(x)
x[1:4,1:4]
xTranspose[1:4,1:4]

</code></pre>

<hr>
<h2 id='TrueTrait'>Estimate the true trait underlying a list of surrogate markers.</h2><span id='topic+TrueTrait'></span>

<h3>Description</h3>

<p>Assume an imprecisely measured trait <code>y</code> that is related to  the true, unobserved trait yTRUE as follows yTRUE=y+noise where noise is assumed to have mean zero and a constant variance. Assume you have 1 or more surrogate markers for yTRUE corresponding to the columns of <code>datX</code>. The function implements several approaches for estimating yTRUE based on the inputs <code>y</code> and/or <code>datX</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> TrueTrait(datX, y, datXtest=NULL, 
        corFnc = "bicor", corOptions = "use = 'pairwise.complete.obs'",
        LeaveOneOut.CV=FALSE, skipMissingVariables=TRUE, 
        addLinearModel=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TrueTrait_+3A_datx">datX</code></td>
<td>
<p> is a vector or data frame whose columns correspond to the surrogate markers (variables) for the true underlying trait. The number of rows of <code>datX</code> equals the number of observations, i.e. it should equal the length of <code>y</code> </p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_y">y</code></td>
<td>
<p>is a numeric vector which specifies the observed trait.
</p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_datxtest">datXtest</code></td>
<td>
<p>can be set as a matrix or data frame of a second, independent test data set. Its columns should correspond to those of <code>datX</code>, i.e. the two data sets should have the same number of columns but the number or rows (test set observations) can be different.</p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_corfnc">corFnc</code></td>
<td>
<p>Character string specifying the correlation function to be used in the calculations. 
Recomended values are the default Pearson
correlation <code>"cor"</code> or biweight mid-correlation <code>"bicor"</code>. Additional arguments to the correlation
function can be specified using <code>corOptions</code>.</p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_coroptions">corOptions</code></td>
<td>
<p>Character string giving additional arguments to the function specified in <code>corFnc</code>. </p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_leaveoneout.cv">LeaveOneOut.CV</code></td>
<td>
<p>logical. If TRUE then leave one out cross validation estimates will be calculated for <code>y.true1</code> and <code>y.true2</code> based on <code>datX</code>.</p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_skipmissingvariables">skipMissingVariables</code></td>
<td>
<p>logical. If  TRUE then variables whose values are missing for a given observation will be skipped when estimating the true trait of that particular observation. Thus, the estimate of a particular observation are determined by all the variables whose values are non-missing.</p>
</td></tr>
<tr><td><code id="TrueTrait_+3A_addlinearmodel">addLinearModel</code></td>
<td>
<p>logical. If TRUE then the function also estimates the true trait based on the predictions of the linear model <code>lm(y~., data=datX)</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This R function implements formulas described in Klemera and Doubal  (2006). The assumptions underlying these formulas are described in Klemera et al. But briefly,
the function provides several estimates of the true underlying trait under the following assumptions:
1) There is a true underlying trait that affects <code>y</code> and a list of surrogate markers corresponding to the columns of <code>datX</code>.
2) There is a linear relationship between the true underlying trait and <code>y</code> and the surrogate markers.
3)  yTRUE =y +Noise where the Noise term has a mean of zero and a fixed variance.
4) Weighted least squares estimation is used to relate the surrogate markers to the underlying trait where the weights are proportional to 1/ssq.j where ssq.j is the noise variance of the j-th marker.
</p>
<p>Specifically,
output <code>y.true1</code> corresponds to formula 31,  <code>y.true2</code> corresponds to formula 25, and <code>y.true3</code> corresponds to formula 34. 
</p>
<p>Although the true underlying trait yTRUE is not known, one can estimate the standard deviation between the
estimate <code>y.true2</code> and yTRUE using formula 33. Similarly, one can estimate the SD for the estimate
<code>y.true3</code> using formula 42. These estimated SDs correspond to output components 2 and 3, respectively.
These SDs are valuable since they provide a sense of how accurate the measure is.  
</p>
<p>To estimate the correlations between <code>y</code> and the surrogate markers, one can specify different
correlation measures. The default method is based on the Person correlation but one can also specify the
biweight midcorrelation by choosing &quot;bicor&quot;, see help(bicor) to learn more. 
</p>
<p>When the <code>datX</code> is comprised of observations measured in different strata (e.g. different batches or
independent data sets) then one can obtain stratum specific estimates by specifying the strata using the
argument <code>Strata</code>. In this case, the estimation focuses on one stratum at a time.  
</p>


<h3>Value</h3>

<p>A list with the following components.
</p>
<table role = "presentation">
<tr><td><code>datEstimates</code></td>
<td>
<p>is a data frame whose columns corresponds to estimates of the true underlying trait. The number of rows equals the number of observations, i.e. the length of <code>y</code>.
The first column <code>y.true1</code> is the average value of standardized columns of <code>datX</code> where standardization subtracts out the intercept term and divides by the slope of the linear regression model lm(marker~y). Since this estimate ignores the fact that the surrogate markers have different correlations with <code>y</code>, it is typically inferior to <code>y.true2</code>. 
The second column <code>y.true2</code> equals the weighted average value of standardized columns of <code>datX</code>. The standardization is described in section 2.4 of Klemera et al. The weights are proportional to r^2/(1+r^2) where r denotes the correlation between the surrogate marker and <code>y</code>. Since this estimate does not include <code>y</code> as additional surrogate marker, it may be slightly inferior to <code>y.true3</code>. Having said this, the difference between <code>y.true2</code> and <code>y.true3</code> is often negligible. 
An additional column called <code>y.lm</code> is added if <code>addLinearModel=TRUE</code>. In this case, <code>y.lm</code> reports the linear model predictions.
Finally, the column <code>y.true3</code> is very similar to <code>y.true2</code> but it includes <code>y</code> as additional surrogate marker. It is expected to be the best estimate of the underlying true trait (see Klemera et al 2006).
</p>
</td></tr>
<tr><td><code>datEstimatestest</code></td>
<td>
<p>is output only if a test data set has been specified in the argument
<code>datXtest</code>. In this case, it contains a data frame with columns <code>ytrue1</code> and <code>ytrue2</code>. The
number of rows equals the number of test set observations, i.e the number of rows of <code>datXtest</code>. Since
the value of <code>y</code> is not known in case of a test data set, one cannot calculate <code>y.true3</code>. An
additional column with linear model predictions <code>y.lm</code> is added if <code>addLinearModel=TRUE</code>.  </p>
</td></tr>
<tr><td><code>datEstimates.LeaveOneOut.CV</code></td>
<td>
<p>is output only if the argument <code>LeaveOneOut.CV</code> has been set to <code>TRUE</code>.
In this case, it contains a data frame with leave-one-out cross validation estimates of <code>ytrue1</code> and <code>ytrue2</code>. The number of rows equals the length of <code>y</code>. Since the value of <code>y</code> is not known in case of a test data set, one cannot calculate <code>y.true3</code>
</p>
</td></tr>
<tr><td><code>SD.ytrue2</code></td>
<td>
<p>is a scalar. This is an estimate of the standard deviation between the estimate <code>y.true2</code> and the true (unobserved) yTRUE. It corresponds to formula 33.</p>
</td></tr>
<tr><td><code>SD.ytrue3</code></td>
<td>
<p>is a scalar. This is an estimate of the standard deviation between <code>y.true3</code> and the true (unobserved) yTRUE. It corresponds to formula 42.</p>
</td></tr> 
<tr><td><code>datVariableInfo</code></td>
<td>
<p>is a data frame that reports information for each variable (column of <code>datX</code>) when it comes to the definition of <code>y.true2</code>. The rows correspond to the number of variables. Columns report the variable name, the center (intercept that is subtracted to scale each variable), the scale (i.e. the slope that is used in the denominator), and finally the weights used in the weighted sum of the scaled variables.</p>
</td></tr>
<tr><td><code>datEstimatesByStratum</code></td>
<td>
<p> a data frame that will only be output if <code>Strata</code> is different from NULL. In this case, it is has the same dimensions as <code>datEstimates</code> but the estimates were calculated separately for each level of <code>Strata</code>.</p>
</td></tr>
<tr><td><code>SD.ytrue2ByStratum</code></td>
<td>
<p> a vector of length equal to the different levels of <code>Strata</code>. Each component reports the estimate of <code>SD.ytrue2</code> for observations in the stratum specified by unique(Strata).</p>
</td></tr>
<tr><td><code>datVariableInfoByStratum</code></td>
<td>
<p> a list whose components are matrices with variable information. Each list
component reports the variable information in the stratum specified by unique(Strata). </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steve Horvath</p>


<h3>References</h3>

<p>Klemera P, Doubal S (2006) A new approach to the concept and computation of biological age. Mechanisms of
Ageing and Development 127 (2006) 240-248
</p>
<p>Choa IH, Parka KS, Limb CJ (2010)  An Empirical Comparative Study on Validation of Biological Age Estimation Algorithms with an Application of Work Ability Index. Mechanisms of Ageing and Development
Volume 131, Issue 2, February 2010, Pages 69-78 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># observed trait
y=rnorm(1000,mean=50,sd=20)
# unobserved, true trait
yTRUE =y +rnorm(100,sd=10)
# now we simulate surrogate markers around the true trait
datX=simulateModule(yTRUE,nGenes=20, minCor=.4,maxCor=.9,geneMeans=rnorm(20,50,30)  )
True1=TrueTrait(datX=datX,y=y)
datTrue=True1$datEstimates
par(mfrow=c(2,2))
for (i in 1:dim(datTrue)[[2]] ){
  meanAbsDev= mean(abs(yTRUE-datTrue[,i]))
  verboseScatterplot(datTrue[,i],yTRUE,xlab=names(datTrue)[i],  
                     main=paste(i, "MeanAbsDev=", signif(meanAbsDev,3))); 
  abline(0,1)
}
#compare the estimated standard deviation of y.true2
True1[[2]]
# with the true SD
sqrt(var(yTRUE-datTrue$y.true2))
#compare the estimated standard deviation of y.true3
True1[[3]]
# with the true SD
sqrt(var(yTRUE-datTrue$y.true3))
</code></pre>

<hr>
<h2 id='unsignedAdjacency'> Calculation of unsigned adjacency </h2><span id='topic+unsignedAdjacency'></span>

<h3>Description</h3>

<p>Calculation of the unsigned network adjacency from expression data. The restricted set of parameters
for this function should allow a faster and less memory-hungry calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unsignedAdjacency(
  datExpr, 
  datExpr2 = NULL, 
  power = 6, 
  corFnc = "cor", corOptions = "use = 'p'")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unsignedAdjacency_+3A_datexpr">datExpr</code></td>
<td>
<p> expression data. A data frame in which columns are genes and rows ar
samples. Missing values are ignored. </p>
</td></tr>
<tr><td><code id="unsignedAdjacency_+3A_datexpr2">datExpr2</code></td>
<td>
<p> optional specification of a second set of expression data. See details. </p>
</td></tr>
<tr><td><code id="unsignedAdjacency_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="unsignedAdjacency_+3A_corfnc">corFnc</code></td>
<td>
<p> character string giving the correlation function to be used for the adjacency
calculation. Recommended choices are <code>"cor"</code> and <code>"bicor"</code>, but other functions can be used as
well. </p>
</td></tr>
<tr><td><code id="unsignedAdjacency_+3A_coroptions">corOptions</code></td>
<td>
<p>  character string giving further options to be passed to the correlation function </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation function will be called with arguments <code>datExpr, datExpr2</code> plus any extra
arguments given in <code>corOptions</code>. If <code>datExpr2</code> is <code>NULL</code>, 
the standard correlation functions will calculate the corelation of columns in <code>datExpr</code>.
</p>


<h3>Value</h3>

<p>Adjacency matrix of dimensions <code>n*n</code>, where <code>n</code> is the number of genes in <code>datExpr</code>.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>


<h3>References</h3>

<p>Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression Network
Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+adjacency">adjacency</a></code> </p>

<hr>
<h2 id='userListEnrichment'>
Measure enrichment between inputted and user-defined lists
</h2><span id='topic+userListEnrichment'></span>

<h3>Description</h3>

<p>This function measures list enrichment between inputted lists of genes and files containing user-defined lists of genes.  Significant enrichment is measured using a hypergeometric test.  A pre-made collection of brain-related lists can also be loaded.  The function writes the significant enrichments to a file, but also returns all overlapping genes across all comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>userListEnrichment(
  geneR, labelR, 
  fnIn = NULL, catNmIn = fnIn, 
  nameOut = "enrichment.csv", 
  useBrainLists = FALSE, useBloodAtlases = FALSE, omitCategories = "grey", 
  outputCorrectedPvalues = TRUE, useStemCellLists = FALSE, 
  outputGenes = FALSE, 
  minGenesInCategory = 1, 
  useBrainRegionMarkers = FALSE, useImmunePathwayLists = FALSE,
  usePalazzoloWang = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="userListEnrichment_+3A_gener">geneR</code></td>
<td>

<p>A vector of gene (or other) identifiers.  This vector should include ALL genes in your analysis (i.e., the genes correspoding to your labeled lists AND the remaining background reference genes).  
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_labelr">labelR</code></td>
<td>

<p>A vector of labels (for example, module assignments) corresponding to the geneR list.  NOTE: For all background reference genes that have no corresponding label, use the label &quot;background&quot; (or any label included in the omitCategories parameter).
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_fnin">fnIn</code></td>
<td>

<p>A vector of file names containing user-defined lists.  These files must be in one of three specific formats (see details section).  The default (NULL) may only be used if one of the &quot;use_____&quot; parameters is TRUE.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_catnmin">catNmIn</code></td>
<td>

<p>A vector of category names corresponding to each fnIn.  This name will be appended to each overlap corresponding to that filename.  The default sets the category names as the corresponding file names.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_nameout">nameOut</code></td>
<td>

<p>Name of the file where the output enrichment information will be written.  (Note that this file includes only a subset of
what is returned by the function.) If <code>NULL</code> (or zero-length), no output will be written out.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_usebrainlists">useBrainLists</code></td>
<td>

<p>If TRUE, a pre-made set of brain-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_usebloodatlases">useBloodAtlases</code></td>
<td>

<p>If TRUE, a pre-made set of blood-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_omitcategories">omitCategories</code></td>
<td>

<p>Any labelR entries corresponding to these categories will be ignored.  The default (&quot;grey&quot;) will ignore unassigned genes in a standard WGCNA network.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_outputcorrectedpvalues">outputCorrectedPvalues</code></td>
<td>

<p>If TRUE (default) only pvalues that are significant after correcting for multiple comparisons (using Bonferroni method) will be outputted to nameOut.  Otherwise the uncorrected p-values will be outputted to the file.  Note that both sets of p-values for all comparisons are reported in the returned &quot;pValues&quot; parameter.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_usestemcelllists">useStemCellLists</code></td>
<td>

<p>If TRUE, a pre-made set of stem cell (SC)-derived enrichment lists will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for related references.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_outputgenes">outputGenes</code></td>
<td>

<p>If TRUE, will output a list of all genes in each returned category, as well as a count of the number of genes in each category.  The default is FALSE.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_mingenesincategory">minGenesInCategory</code></td>
<td>

<p>Will omit all significant categories with fewer than minGenesInCategory genes (default is 1).
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_usebrainregionmarkers">useBrainRegionMarkers</code></td>
<td>

<p>If TRUE, a pre-made set of enrichment lists for human brain regions will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  These lists are derived from data from the Allen Human Brain Atlas (https://human.brain-map.org/).  See references section for more details.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_useimmunepathwaylists">useImmunePathwayLists</code></td>
<td>

<p>If TRUE, a pre-made set of enrichment lists for immune system pathways will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  These lists are derived from the lab of Daniel R Saloman.  See references section for more details.
</p>
</td></tr>
<tr><td><code id="userListEnrichment_+3A_usepalazzolowang">usePalazzoloWang</code></td>
<td>

<p>If TRUE, a pre-made set of enrichment lists compiled by Mike Palazzolo and Jim Wang from CHDI will be added to any user-defined lists for enrichment comparison.  The default is FALSE.  See references section for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>User-inputted files for fnIn can be in one of three formats:
</p>
<p>1) Text files (must end in &quot;.txt&quot;) with one list per file, where the first line is the list descriptor and the remaining lines are gene names corresponding to that list, with one gene per line.  For example
Ribosome
RPS4
RPS8
...
</p>
<p>2) Gene / category files (must be csv files), where the first line is the column headers corresponding to Genes and Lists, and the remaining lines correspond to the genes in each list, for any number of genes and lists.  For example:
Gene, Category
RPS4, Ribosome
RPS8, Ribosome
...
NDUF1, Mitohcondria
NDUF3, Mitochondria
...
MAPT, AlzheimersDisease
PSEN1, AlzheimersDisease
PSEN2, AlzheimersDisease
...
</p>
<p>3) Module membership (kME) table in csv format.  Currently, the module assignment is the only thing that is used, so as long as the Gene column is 2nd and the Module column is 3rd, it doesn't matter what is in the other columns.  For example,
PSID, Gene, Module, &lt;other columns&gt;
&lt;psid&gt;, RPS4, blue, &lt;other columns&gt;
&lt;psid&gt;, NDUF1, red, &lt;other columns&gt;
&lt;psid&gt;, RPS8, blue, &lt;other columns&gt;
&lt;psid&gt;, NDUF3, red, &lt;other columns&gt;
&lt;psid&gt;, MAPT, green, &lt;other columns&gt;
...
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>pValues</code></td>
<td>

<p>A data frame showing, for each comparison, the input category, user defined category, type, the number of overlapping genes and both the uncorrected and Bonferroni corrected p-values for every pair of list overlaps tested.
</p>
</td></tr>
<tr><td><code>ovGenes</code></td>
<td>

<p>A list of character vectors corresponding to the overlapping genes for every pair of list overlaps tested.  Specific overlaps can be found by typing &lt;variableName&gt;$ovGenes$'&lt;labelR&gt; &ndash; &lt;comparisonCategory&gt;'.  See example below.
</p>
</td></tr>
<tr><td><code>sigOverlaps</code></td>
<td>

<p>Identical information that is written to nameOut. A data frame ith columns giving the input category, user
defined category, type, and P-values (corrected or uncorrected, depending on outputCorrectedPvalues) corresponding to all significant enrichments.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeremy Miller
</p>


<h3>References</h3>

<p>The primary reference for this function is: Miller JA, Cai C, Langfelder P, Geschwind DH, Kurian SM, Salomon DR, Horvath S. (2011) Strategies for aggregating gene expression data: the collapseRows R function. BMC Bioinformatics 12:322.
</p>
<p>If you have any suggestions for lists to add to this function, please e-mail Jeremy Miller at jeremyinla@gmail.com
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
References for the pre-defined brain lists (useBrainLists=TRUE, in alphabetical order by category descriptor) are as follows:
</p>
<p>ABA ==&gt; Cell type markers from: Lein ES, et al. (2007) Genome-wide atlas of gene expression in the adult mouse brain. Nature 445:168-176.
</p>
<p>ADvsCT_inCA1  ==&gt; Lists of genes found to be increasing or decreasing with Alzheimer's disease in 3 studies:
1. Blalock =&gt; Blalock E, Geddes J, Chen K, Porter N, Markesbery W, Landfield P (2004) Incipient Alzheimer's disease: microarray correlation analyses reveal major transcriptional and tumor suppressor responses. PNAS 101:2173-2178.
2. Colangelo =&gt; Colangelo V, Schurr J, Ball M, Pelaez R, Bazan N, Lukiw W (2002) Gene expression profiling of 12633 genes in Alzheimer hippocampal CA1: transcription and neurotrophic factor down-regulation and up-regulation of apoptotic and pro-inflammatory signaling. J Neurosci Res 70:462-473. 
3. Liang =&gt; Liang WS, et al (2008) Altered neuronal gene expression in brain regions differentially affected by Alzheimer's disease: a reference data set. Physiological genomics 33:240-56.
</p>
<p>Bayes ==&gt; Postsynaptic Density Proteins from: Bayes A, et al. (2011) Characterization of the proteome, diseases and evolution of the human postsynaptic density. Nat Neurosci. 14(1):19-21.
</p>
<p>Blalock_AD ==&gt; Modules from a network using the data from: Blalock E, Geddes J, Chen K, Porter N, Markesbery W, Landfield P (2004) Incipient Alzheimer's disease: microarray correlation analyses reveal major transcriptional and tumor suppressor responses. PNAS 101:2173-2178. 
</p>
<p>CA1vsCA3 ==&gt; Lists of genes enriched in CA1 and CA3 relative to other each and to other areas of the brain, from several studies:
1. Ginsberg =&gt; Ginsberg SD, Che S (2005) Expression profile analysis within the human hippocampus: comparison of CA1 and CA3 pyramidal neurons. J Comp Neurol 487:107-118.
2. Lein =&gt; Lein E, Zhao X, Gage F (2004) Defining a molecular atlas of the hippocampus using DNA microarrays and high-throughput in situ hybridization. J Neurosci 24:3879-3889.
3. Newrzella =&gt; Newrzella D, et al (2007) The functional genome of CA1 and CA3 neurons under native conditions and in response to ischemia. BMC Genomics 8:370.
4. Torres =&gt; Torres-Munoz JE, Van Waveren C, Keegan MG, Bookman RJ, Petito CK (2004) Gene expression profiles in microdissected neurons from human hippocampal subregions. Brain Res Mol Brain Res 127:105-114.
5. GorLorT =&gt; In either Ginsberg or Lein or Torres list.
</p>
<p>Cahoy ==&gt; Definite (10+ fold) and probable (1.5+ fold) enrichment from: Cahoy JD, et al. (2008) A transcriptome database for astrocytes, neurons, and oligodendrocytes: A new resource for understanding brain development and function. J Neurosci 28:264-278.
</p>
<p>CTX ==&gt; Modules from the CTX (cortex) network from: Oldham MC, et al. (2008) Functional organization of the transcriptome in human brain. Nat Neurosci 11:1271-1282.
</p>
<p>DiseaseGenes ==&gt; Probable (C or better rating as of 16 Mar 2011) and possible (all genes in database as of ~2008) genetics-based disease genes from: http://www.alzforum.org/
</p>
<p>EarlyAD ==&gt; Genes whose expression is related to cognitive markers of early Alzheimer's disease vs. non-demented controls with AD pathology, from: Parachikova, A., et al (2007) Inflammatory changes parallel the early stages of Alzheimer disease. Neurobiology of Aging 28:1821-1833.
</p>
<p>HumanChimp ==&gt; Modules showing region-specificity in both human and chimp from: Oldham MC, Horvath S, Geschwind DH (2006) Conservation and evolution of gene coexpression networks in human and chimpanzee brains. Proc Natl Acad Sci USA 103: 17973-17978.
</p>
<p>HumanMeta ==&gt; Modules from the human network from: Miller J, Horvath S, Geschwind D (2010) Divergence of human and mouse brain transcriptome highlights Alzheimer disease pathways. Proc Natl Acad Sci 107:12698-12703.
</p>
<p>JAXdiseaseGene ==&gt; Genes where mutations in mouse and/or human are known to cause any disease.  WARNING: this list represents an oversimplification of data!  This list was created from the Jackson Laboratory: Bult CJ, Eppig JT, Kadin JA, Richardson JE, Blake JA; Mouse Genome Database Group (2008) The Mouse Genome Database (MGD): Mouse biology and model systems. Nucleic Acids Res 36 (database issue):D724-D728.
</p>
<p>Lu_Aging ==&gt; Modules from a network using the data from: Lu T, Pan Y, Kao S-Y, Li C, Kohane I, Chan J, Yankner B (2004) Gene regulation and DNA damage in the ageing human brain. Nature 429:883-891.
</p>
<p>MicroglialMarkers ==&gt; Markers for microglia and macrophages from several studies: 
1. GSE772 =&gt; Gan L, et al. (2004) Identification of cathepsin B as a mediator of neuronal death induced by Abeta-activated microglial cells using a functional genomics approach. J Biol Chem 279:5565-5572.
2. GSE1910 =&gt; Albright AV, Gonzalez-Scarano F (2004) Microarray analysis of activated mixed glial (microglia) and monocyte-derived macrophage gene expression. J Neuroimmunol 157:27-38.
3. AitGhezala =&gt; Ait-Ghezala G, Mathura VS, Laporte V, Quadros A, Paris D, Patel N, et al. Genomic regulation after CD40 stimulation in microglia: relevance to Alzheimer's disease. Brain Res Mol Brain Res 2005;140(1-2):73-85.
4. 3treatments_Thomas =&gt; Thomas, DM, Francescutti-Verbeem, DM, Kuhn, DM (2006) Gene expression profile of activated microglia under conditions associated with dopamine neuronal damage. The FASEB Journal 20:515-517.
</p>
<p>MitochondrialType ==&gt; Mitochondrial genes from the somatic vs. synaptic fraction of mouse cells from: Winden KD, et al. (2009) The organization of the transcriptional network in specific neuronal classes. Mol Syst Biol 5:291.
</p>
<p>MO ==&gt; Markers for many different things provided to my by Mike Oldham.  These were originally from several sources:
1. 2+_26Mar08 =&gt; Genetics-based disease genes in two or more studies from http://www.alzforum.org/ (compiled by Mike Oldham).
2. Bachoo =&gt; Bachoo, R.M. et al. (2004) Molecular diversity of astrocytes with implications for neurological disorders. PNAS 101, 8384-8389.
3. Foster =&gt; Foster, LJ, de Hoog, CL, Zhang, Y, Zhang, Y, Xie, X, Mootha, VK, Mann, M. (2006) A Mammalian Organelle Map by Protein Correlation Profiling. Cell 125(1): 187-199.
4. Morciano =&gt; Morciano, M. et al. Immunoisolation of two synaptic vesicle pools from synaptosomes: a proteomics analysis. J. Neurochem. 95, 1732-1745 (2005).
5. Sugino =&gt; Sugino, K. et al. Molecular taxonomy of major neuronal classes in the adult mouse forebrain. Nat. Neurosci. 9, 99-107 (2006).
</p>
<p>MouseMeta ==&gt; Modules from the mouse network from: Miller J, Horvath S, Geschwind D (2010) Divergence of human and mouse brain transcriptome highlights Alzheimer disease pathways. Proc Natl Acad Sci 107:12698-12703.
</p>
<p>Sugino/Winden ==&gt; Conservative list of genes in modules from the network from: Winden K, Oldham M, Mirnics K, Ebert P, Swan C, Levitt P, Rubenstein J, Horvath S, Geschwind D (2009). The organization of the transcriptional network in specific neuronal classes. Molecular systems biology 5.
NOTE: Original data came from this neuronal-cell-type-selection experiment in mouse: Sugino K, Hempel C, Miller M, Hattox A, Shapiro P, Wu C, Huang J, Nelson S (2006). Molecular taxonomy of major neuronal classes in the adult mouse forebrain. Nat Neurosci 9:99-107
</p>
<p>Voineagu ==&gt; Several Autism-related gene categories from: Voineagu I, Wang X, Johnston P, Lowe JK, Tian Y, Horvath S, Mill J, Cantor RM, Blencowe BJ, Geschwind DH. (2011). Transcriptomic analysis of autistic brain reveals convergent molecular pathology. Nature 474(7351):380-4
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
References for the pre-defined blood atlases (useBloodAtlases=TRUE, in alphabetical order by category descriptor) are as follows:
</p>
<p>Blood(composite) ==&gt; Lists for blood cell types with this label are made from combining marker genes from the following three publications:
1. Abbas AB, Baldwin D, Ma Y, Ouyang W, Gurney A, et al. (2005). Immune response in silico (IRIS): immune-specific genes identified from a compendium of microarray expression data.  Genes Immun. 6(4):319-31.
2. Grigoryev YA, Kurian SM, Avnur Z, Borie D, Deng J, et al. (2010).  Deconvoluting post-transplant immunity: cell subset-specific mapping reveals pathways for activation and expansion of memory T, monocytes and B cells.  PLoS One. 5(10):e13358.
3. Watkins NA, Gusnanto A, de Bono B, De S, Miranda-Saavedra D, et al. (2009). A HaemAtlas: characterizing gene expression in differentiated human blood cells. Blood. 113(19):e1-9. 
</p>
<p>Gnatenko ==&gt; Top 50 marker genes for platelets from: Gnatenko DV, et al. (2009) Transcript profiling of human platelets using microarray and serial analysis of gene expression (SAGE). Methods Mol Biol. 496:245-72.
</p>
<p>Gnatenko2 ==&gt; Platelet-specific genes on a custom microarray from: Gnatenko DV, et al. (2010) Class prediction models of thrombocytosis using genetic biomarkers. Blood. 115(1):7-14.
</p>
<p>Kabanova ==&gt; Red blood cell markers from: Kabanova S, et al. (2009) Gene expression analysis of human red blood cells. Int J Med Sci. 6(4):156-9.
</p>
<p>Whitney ==&gt; Genes corresponding to individual variation in blood from: Whitney AR, et al. (2003) Individuality and variation in gene expression patterns in human blood. PNAS. 100(4):1896-1901.
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
References for the pre-defined stem cell (SC) lists (useStemCellLists=TRUE, in alphabetical order by category descriptor) are as follows:
</p>
<p>Cui ==&gt; genes differentiating erythrocyte precursors (CD36+ cells) from multipotent human primary
hematopoietic stem cells/progenitor cells (CD133+ cells), from: Cui K, Zang C, Roh TY, Schones DE, Childs
RW, Peng W, Zhao K. (2009). Chromatin signatures in multipotent human hematopoietic stem cells indicate the
fate of bivalent genes during differentiation. Cell Stem Cell 4:80-93
</p>
<p>Lee ==&gt; gene lists related to Polycomb proteins in human embryonic SCs, from (a highly-cited paper!): Lee
TI, Jenner RG, Boyer LA, Guenther MG, Levine SS, Kumar RM, Chevalier B, Johnstone SE, Cole MF, Isono K, et
al. (2006) Control of developmental regulators by polycomb in human embryonic stem cells. Cell 125:301-313
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
References and more information for the pre-defined human brain region lists (useBrainRegionMarkers=TRUE):
</p>
<p>HBA ==&gt; Hawrylycz MJ, Lein ES, Guillozet-Bongaarts AL, Shen EH, Ng L, Miller JA, et al. (2012) An Anatomically Comprehensive Atlas of the Adult Human Brain Transcriptome. Nature (in press)
Three categories of marker genes are presented:
1. globalMarker(top200) = top 200 global marker genes for 22 large brain structures. Genes are ranked based on fold change enrichment (expression in region vs. expression in rest of brain) and the ranks are averaged between brains 2001 and 2002 (human.brain-map.org).
2. localMarker(top200) =  top 200 local marker genes for 90 large brain structures.  Same as 1, except fold change is defined as expression in region vs. expression in larger region (format: &lt;region&gt;_IN_&lt;largerRegion&gt;).  For example, enrichment in CA1 is relative to other subcompartments of the hippocampus.
3. localMarker(FC&gt;2) = same as #2, but only local marker genes with fold change &gt; 2 in both brains are included.  Regions with &lt;10 marker genes are omitted.
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
More information for the pre-defined immune pathways lists (useImmunePathwayLists=TRUE):
</p>
<p>ImmunePathway ==&gt; These lists were created by Brian Modena (a member of Daniel R Salomon's lab at Scripps Research Institute), with input from Sunil M Kurian and Dr. Salomon, using Ingenuity, WikiPathways and literature search to assemble them.  They reflect knowledge-based immune pathways and were in part informed by Dr. Salomon and colleague's work in expression profiling of biopsies and peripheral blood but not in some highly organized process.  These lists are not from any particular publication, but are culled to include only genes of reasonably high confidence.
</p>
<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
References for the pre-defined lists from CHDI (usePalazzoloWang=TRUE, in alphabetical order by category descriptor) are as follows:
</p>
<p>Biocyc NCBI Biosystems ==&gt; Several gene sets from the &quot;Biocyc&quot; component of NCBI Biosystems: Geer LY, Marchler-Bauer A, Geer RC, Han L, He J, He S, Liu C, Shi W, Bryant SH (2010) The NCBI BioSystems database. Nucleic Acids Res. 38(Database issue):D492-6. 
</p>
<p>Kegg NCBI Biosystems ==&gt; Several gene sets from the &quot;Kegg&quot; component of NCBI Biosystems: Geer LY et al 2010 (full citation above).
</p>
<p>Palazzolo and Wang ==&gt; These gene sets were compiled from a variety of sources by Mike Palazzolo and Jim Wang at CHDI.
</p>
<p>Pathway Interaction Database NCBI Biosystems ==&gt; Several gene sets from the &quot;Pathway Interaction Database&quot; component of NCBI Biosystems: Geer LY et al 2010 (full citation above). 
</p>
<p>PMID 17500595 Kaltenbach 2007 ==&gt; Several gene sets from: Kaltenbach LS, Romero E, Becklin RR, Chettier R, Bell R, Phansalkar A, et al. (2007) Huntingtin interacting proteins are genetic modifiers of neurodegeneration. PLoS Genet. 3(5):e82
</p>
<p>PMID 22348130 Schaefer 2012 ==&gt; Several gene sets from: Schaefer MH, Fontaine JF, Vinayagam A, Porras P, Wanker EE, Andrade-Navarro MA (2012) HIPPIE: Integrating protein interaction networks with experiment based quality scores. PLoS One. 7(2):e31826
</p>
<p>PMID 22556411 Culver 2012 ==&gt; Several gene sets from: Culver BP, Savas JN, Park SK, Choi JH, Zheng S, Zeitlin SO, Yates JR 3rd, Tanese N. (2012) Proteomic analysis of wild-type and mutant huntingtin-associated proteins in mouse brains identifies unique interactions and involvement in protein synthesis. J Biol Chem. 287(26):21599-614
</p>
<p>PMID 22578497 Cajigas 2012 ==&gt; Several gene sets from: Cajigas IJ, Tushev G, Will TJ, tom Dieck S, Fuerst N, Schuman EM. (2012) The local transcriptome in the synaptic neuropil revealed by deep sequencing and high-resolution imaging. Neuron. 74(3):453-66
</p>
<p>Reactome NCBI Biosystems ==&gt; Several gene sets from the &quot;Reactome&quot; component of NCBI Biosystems: Geer LY et al 2010 (full citation above). 
</p>
<p>Wiki Pathways NCBI Biosystems ==&gt; Several gene sets from the &quot;Wiki Pathways&quot; component of NCBI Biosystems: Geer LY et al 2010 (full citation above). 
</p>
<p>Yang ==&gt; These gene sets were compiled from a variety of sources by Mike Palazzolo and Jim Wang at CHDI.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: first, read in some gene names and split them into categories
data(BrainLists);
listGenes = unique(as.character(BrainLists[,1]))
set.seed(100)
geneR = sort(sample(listGenes,2000))
categories = sort(rep(standardColors(10),200))
categories[sample(1:2000,200)] = "grey"
file1 = tempfile();
file2 = tempfile();
write(c("TESTLIST1",geneR[300:400], sep="\n"), file1)
write(c("TESTLIST2",geneR[800:1000],sep="\n"), file2)

# Now run the function!
testResults = userListEnrichment(
   geneR, labelR=categories, 
   fnIn=c(file1, file2),
   catNmIn=c("TEST1","TEST2"), 
   nameOut = NULL, useBrainLists=TRUE, omitCategories ="grey")

# To see a list of all significant enrichments type:
testResults$sigOverlaps

# To see all of the overlapping genes between two categories 
#(whether or not the p-value is significant), type 
#restResults$ovGenes$'&lt;labelR&gt; -- &lt;comparisonCategory&gt;'.  For example:

testResults$ovGenes$"black -- TESTLIST1__TEST1"
testResults$ovGenes$"red -- salmon_M12_Ribosome__HumanMeta"

# More detailed overlap information is in the pValue output.  For example:
head(testResults$pValue)

# Clean up the temporary files
unlink(file1);
unlink(file2)
</code></pre>

<hr>
<h2 id='vectorizeMatrix'> Turn a matrix into a vector of non-redundant components </h2><span id='topic+vectorizeMatrix'></span>

<h3>Description</h3>

<p>A convenient function to turn a matrix into a vector of non-redundant components. If the matrix is
non-symmetric, returns a vector containing all entries of the matrix. If the matrix is symmetric, only
returns the upper triangle and optionally the diagonal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vectorizeMatrix(M, diag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vectorizeMatrix_+3A_m">M</code></td>
<td>
<p> the matrix or data frame to be vectorized. </p>
</td></tr>
<tr><td><code id="vectorizeMatrix_+3A_diag">diag</code></td>
<td>
<p> logical: should the diagonal be included in the output? </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the non-redundant entries of the input matrix.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath </p>

<hr>
<h2 id='vectorTOM'> Topological overlap for a subset of the whole set of genes </h2><span id='topic+vectorTOM'></span>

<h3>Description</h3>

<p>This function calculates topological overlap of a small set of vectors with respect to a whole data
set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vectorTOM(
  datExpr, 
  vect, 
  subtract1 = FALSE, 
  blockSize = 2000, 
  corFnc = "cor", corOptions = "use = 'p'", 
  networkType = "unsigned", 
  power = 6, 
  verbose = 1, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vectorTOM_+3A_datexpr">datExpr</code></td>
<td>
<p> a data frame containing the expression data of the whole set, 
with rows corresponding to samples and columns to genes. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_vect">vect</code></td>
<td>
<p> a single vector or a matrix-like object containing vectors whose topological overlap is to
be calculated. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_subtract1">subtract1</code></td>
<td>
<p> logical: should calculation be corrected for self-correlation? Set this to
<code>TRUE</code> if <code>vect</code> contains a subset of <code>datExpr</code>. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_blocksize">blockSize</code></td>
<td>
<p> maximum block size for correlation calculations. Only important if <code>vect</code>
contains a large number of columns. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_corfnc">corFnc</code></td>
<td>
<p> character string giving the correlation function to be used for the adjacency
calculation. Recommended choices are <code>"cor"</code> and <code>"bicor"</code>, but other functions can be used as
well. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_coroptions">corOptions</code></td>
<td>
<p>  character string giving further options to be passed to the correlation function. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_networktype">networkType</code></td>
<td>
<p> character string giving network type. Allowed values are (unique abbreviations of)
<code>"unsigned"</code>, <code>"signed"</code>, <code>"signed hybrid"</code>. See <code><a href="#topic+adjacency">adjacency</a></code>. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_power">power</code></td>
<td>
<p> soft-thresholding power for network construction. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_verbose">verbose</code></td>
<td>
<p> integer level of verbosity. Zero means silent, higher values make the output
progressively more and more verbose. </p>
</td></tr>
<tr><td><code id="vectorTOM_+3A_indent">indent</code></td>
<td>
<p> indentation for diagnostic messages. Zero means no indentation, each unit adds
two spaces. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Topological overlap can be viewed as the normalized count of shared neighbors encoded in an adjacency
matrix. In this case, the adjacency matrix is calculated between the columns of <code>vect</code> and
<code>datExpr</code> and the topological overlap of vectors in <code>vect</code> measures the number of shared
neighbors in <code>datExpr</code> that vectors of <code>vect</code> share. 
</p>


<h3>Value</h3>

<p>A matrix of dimensions <code>n*n</code>, where <code>n</code> is the number of columns in <code>vect</code>.
</p>


<h3>Author(s)</h3>

<p> Peter Langfelder </p>


<h3>References</h3>

<p> Bin Zhang and Steve Horvath (2005) &quot;A General Framework for Weighted Gene Co-Expression
Network Analysis&quot;, Statistical Applications in Genetics and Molecular Biology: Vol. 4: No. 1, Article 17
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TOMsimilarity">TOMsimilarity</a></code> for standard calculation of topological overlap. </p>

<hr>
<h2 id='verboseBarplot'> Barplot with error bars, annotated by Kruskal-Wallis or ANOVA p-value</h2><span id='topic+verboseBarplot'></span>

<h3>Description</h3>

<p>Produce a barplot with error bars, annotated by Kruskal-Wallis or ANOVA p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verboseBarplot(x, g, 
               main = "", xlab = NA, ylab = NA, 
               cex = 1, cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5, 
               color = "grey", numberStandardErrors = 1, 
               KruskalTest = TRUE, AnovaTest = FALSE, two.sided = TRUE, 
               addCellCounts=FALSE, horiz = FALSE, ylim = NULL, ...,
               addScatterplot = FALSE,
               pt.cex = 0.8, pch = 21, pt.col = "blue", pt.bg = "skyblue",
               randomSeed = 31425, jitter = 0.6,
               pointLabels = NULL,
               label.cex = 0.8,
               label.offs = 0.06,
               adjustYLim = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="verboseBarplot_+3A_x">x</code></td>
<td>
<p> numerical or binary vector of data whose group means are to be plotted </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_g">g</code></td>
<td>
<p> a factor or a an object coercible to a factor giving the groups whose means are to be
calculated. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_main">main</code></td>
<td>
<p> main title for the plot.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_xlab">xlab</code></td>
<td>
<p> label for the x-axis. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_ylab">ylab</code></td>
<td>
<p> label for the y-axis. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_cex">cex</code></td>
<td>
<p> character expansion factor for plot annotations. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_cex.axis">cex.axis</code></td>
<td>
<p> character expansion factor for axis annotations. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_cex.lab">cex.lab</code></td>
<td>
<p> character expansion factor for axis labels. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_cex.main">cex.main</code></td>
<td>
<p> character expansion factor for the main title. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_color">color</code></td>
<td>
<p> a vector giving the colors of the bars in the barplot. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_numberstandarderrors">numberStandardErrors</code></td>
<td>
<p> size of the error bars in terms of standard errors. See details. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_kruskaltest">KruskalTest</code></td>
<td>
<p>logical: should Kruskal-Wallis test be performed? See details. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_anovatest">AnovaTest</code></td>
<td>
<p> logical: should ANOVA be performed? See details.  </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_two.sided">two.sided</code></td>
<td>
<p> logical: should the printed p-value be two-sided? See details. </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_addcellcounts">addCellCounts</code></td>
<td>
<p> logical: should counts be printed above each bar? </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_horiz">horiz</code></td>
<td>
<p> logical: should the bars be drawn horizontally? </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_ylim">ylim</code></td>
<td>
<p>optional specification of the limits for the y axis. If not given, they will be determined
automatically.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_...">...</code></td>
<td>
<p> other parameters to function <code><a href="graphics.html#topic+barplot">barplot</a></code>.  </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_addscatterplot">addScatterplot</code></td>
<td>
<p>logical: should a scatterplot of the data be overlaid? </p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_pt.cex">pt.cex</code></td>
<td>
<p>character expansion factor for the points.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_pch">pch</code></td>
<td>
<p>shape code for the points.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_pt.col">pt.col</code></td>
<td>
<p>color for the points.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_pt.bg">pt.bg</code></td>
<td>
<p>background color for the points.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_randomseed">randomSeed</code></td>
<td>
<p>integer random seed to make plots reproducible.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_jitter">jitter</code></td>
<td>
<p>amount of random jitter to add to the position of the points along the x axis.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_pointlabels">pointLabels</code></td>
<td>
<p>Optional text labels for the points displayed using the scatterplot. If given, should be a character
vector of the same length as x. See <code><a href="#topic+labelPoints">labelPoints</a></code>.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_label.cex">label.cex</code></td>
<td>
<p>Character expansion (size) factor for <code>pointLabels</code>.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_label.offs">label.offs</code></td>
<td>
<p>Offset for <code>pointLabels</code>, as a fraction of the plot width.</p>
</td></tr>
<tr><td><code id="verboseBarplot_+3A_adjustylim">adjustYLim</code></td>
<td>
<p>logical: should the limits of the y axis be set so as to accomodate the individual points?
The adjustment is only carried out if input <code>ylim</code> is <code>NULL</code> and <code>addScatterplot</code> is
<code>TRUE</code>. In particular, if the user supplies <code>ylim</code>, it is not touched.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a barplot of a numeric variable (input <code>x</code>) across the levels of a grouping
variable (input <code>g</code>). The height of the bars equals the mean value of <code>x</code> across the
observations with a given level of <code>g</code>. By default, the barplot also shows plus/minus one standard
error. If you want only plus one standard error (not minus) choose <code>two.sided=TRUE</code>.  But the number
of standard errors can be determined with the input <code>numberStandardErrors</code>. For example, if you want
a 95% confidence interval around the mean, choose <code>numberStandardErrors=2</code>. If you don't want any
standard errors set <code>numberStandardErrors=-1</code>.  The function also outputs the p-value of a Kruskal
Wallis test (Fisher test for binary input data), 
which is a non-parametric multi group comparison test. Alternatively, one can use Analysis
of Variance (Anova) to compute a p-value by setting <code>AnovaTest=TRUE</code>.  Anova is a generalization of
the Student t-test to multiple groups. In case of two groups, the Anova p-value equals the Student t-test
p-value. Anova should only be used if <code>x</code> follows a normal distribution. Anova also assumes
homoscedasticity (equal variances). The Kruskal Wallis test is often advantageous since it makes no
distributional assumptions.  Since the Kruskal Wallis test is based on the ranks of <code>x</code>, it is more
robust with regard to outliers. All p-values are two-sided. 
</p>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath, with contributions from Zhijin (Jean) Wu and Peter Langfelder</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+barplot">barplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
   group=sample(c(1,2),100,replace=TRUE)

   height=rnorm(100,mean=group)

   par(mfrow=c(2,2))
   verboseBarplot(height,group, main="1 SE, Kruskal Test")

   verboseBarplot(height,group,numberStandardErrors=2, 
                  main="2 SE, Kruskal Test")

   verboseBarplot(height,group,numberStandardErrors=2,AnovaTest=TRUE, 
                  main="2 SE, Anova")

   verboseBarplot(height,group,numberStandardErrors=2,AnovaTest=TRUE, 
                  main="2 SE, Anova, only plus SE", two.sided=FALSE)

</code></pre>

<hr>
<h2 id='verboseBoxplot'> Boxplot annotated by a Kruskal-Wallis p-value</h2><span id='topic+verboseBoxplot'></span>

<h3>Description</h3>

<p>Plot a boxplot annotated by the Kruskal-Wallis p-value. Uses the function <code><a href="graphics.html#topic+boxplot">boxplot</a></code>
for the actual drawing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verboseBoxplot(x, g, main = "", xlab = NA, ylab = NA, 
               cex = 1, cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5, 
               notch = TRUE, varwidth = TRUE, ...,
               addScatterplot = FALSE,
               pt.cex = 0.8, pch = 21, pt.col = "blue", pt.bg = "skyblue",
               randomSeed = 31425, jitter = 0.6)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="verboseBoxplot_+3A_x">x</code></td>
<td>
<p> numerical vector of data whose group means are to be plotted </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_g">g</code></td>
<td>
<p> a factor or a an object coercible to a factor giving the groups that will go into each box.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_main">main</code></td>
<td>
<p> main title for the plot.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_xlab">xlab</code></td>
<td>
<p> label for the x-axis. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_ylab">ylab</code></td>
<td>
<p> label for the y-axis. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_cex">cex</code></td>
<td>
<p> character expansion factor for plot annotations. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_cex.axis">cex.axis</code></td>
<td>
<p> character expansion factor for axis annotations. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_cex.lab">cex.lab</code></td>
<td>
<p> character expansion factor for axis labels. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_cex.main">cex.main</code></td>
<td>
<p> character expansion factor for the main title. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_notch">notch</code></td>
<td>
<p>logical: should the notches be drawn? See <code><a href="graphics.html#topic+boxplot">boxplot</a></code> and
<code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code> for details. </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_varwidth">varwidth</code></td>
<td>
<p>logical: if <code>TRUE</code>, the boxes are drawn with widths
proportional to the square-roots of the number of
observations in the groups.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_...">...</code></td>
<td>
<p> other arguments to the function <code><a href="graphics.html#topic+boxplot">boxplot</a></code>. Of note is the argument <code>las</code>
that specifies label orientation. Value <code>las=1</code> will result in horizontal labels (the default), while
<code>las=2</code> will result in vertical labels, useful when the labels are long.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_addscatterplot">addScatterplot</code></td>
<td>
<p>logical: should a scatterplot of the data be overlaid? </p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_pt.cex">pt.cex</code></td>
<td>
<p>character expansion factor for the points.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_pch">pch</code></td>
<td>
<p>shape code for the points.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_pt.col">pt.col</code></td>
<td>
<p>color for the points.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_pt.bg">pt.bg</code></td>
<td>
<p>background color for the points.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_randomseed">randomSeed</code></td>
<td>
<p>integer random seed to make plots reproducible.</p>
</td></tr>
<tr><td><code id="verboseBoxplot_+3A_jitter">jitter</code></td>
<td>
<p>amount of random jitter to add to the position of the points along the x axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the value returned by the function <code><a href="graphics.html#topic+boxplot">boxplot</a></code>.  
</p>


<h3>Author(s)</h3>

<p> Steve Horvath, with contributions from Zhijin (Jean) Wu and Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+boxplot">boxplot</a></code> </p>

<hr>
<h2 id='verboseIplot'>
Scatterplot with density 
</h2><span id='topic+verboseIplot'></span>

<h3>Description</h3>

<p>Produce a scatterplot that shows density with color and is annotated by the correlation, MSE, and regression line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verboseIplot(
             x, y, 
             xlim = NA, ylim = NA, 
             nBinsX = 150, nBinsY = 150, 
             ztransf = function(x) {x}, gamma = 1, 
             sample = NULL, corFnc = "cor", corOptions = "use = 'p'", 
             main = "", xlab = NA, ylab = NA, cex = 1, 
             cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5, 
             abline = FALSE, abline.color = 1, abline.lty = 1, 
             corLabel = corFnc, showMSE = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="verboseIplot_+3A_x">x</code></td>
<td>

<p>numerical vector to be plotted along the x axis.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_y">y</code></td>
<td>

<p>numerical vector to be plotted along the y axis.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_xlim">xlim</code></td>
<td>

<p>define the range in x axis
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_ylim">ylim</code></td>
<td>

<p>define the range in y axis
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_nbinsx">nBinsX</code></td>
<td>

<p>number of bins along the x axis
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_nbinsy">nBinsY</code></td>
<td>

<p>number of bins along the y axis
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_ztransf">ztransf</code></td>
<td>

<p>Function to transform the number of counts per pixel, which will be mapped by the function in colramp to well defined colors. The user has to make sure that the transformed density lies in the range [0,zmax], where zmax is any positive number (&gt;=2). 
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_gamma">gamma</code></td>
<td>

<p>color correction power 
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_sample">sample</code></td>
<td>

<p>either a number of points to be sampled or a vector of indices input <code>x</code> and <code>y</code> 
for points to be plotted.  Useful when the input vectors are large and plotting all points is not practical.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_corfnc">corFnc</code></td>
<td>

<p>character string giving the correlation function to annotate the plot.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_coroptions">corOptions</code></td>
<td>

<p>character string giving further options to the correlation function.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_main">main</code></td>
<td>

<p>main title for the plot.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_xlab">xlab</code></td>
<td>

<p>label for the x-axis.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_ylab">ylab</code></td>
<td>

<p>label for the y-axis.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_cex">cex</code></td>
<td>

<p>character expansion factor for plot annotations.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_cex.axis">cex.axis</code></td>
<td>

<p>character expansion factor for axis annotations.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_cex.lab">cex.lab</code></td>
<td>

<p>character expansion factor for axis labels.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_cex.main">cex.main</code></td>
<td>

<p>character expansion factor for the main title.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_abline">abline</code></td>
<td>

<p>logical: should the linear regression fit line be plotted?
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_abline.color">abline.color</code></td>
<td>

<p>color specification for the fit line.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_abline.lty">abline.lty</code></td>
<td>

<p>line type for the fit line.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_corlabel">corLabel</code></td>
<td>

<p>character string to be used as the label for the correlation value printed in the main title.
</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_showmse">showMSE</code></td>
<td>

<p>logical: should the MSE be added to the main title?</p>
</td></tr>
<tr><td><code id="verboseIplot_+3A_...">...</code></td>
<td>

<p>other arguments to the function plot.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Irrespective of the specified correlation function, the MSE is always calculated based on the residuals of a
linear model.
</p>


<h3>Value</h3>

<p>If sample above is given, the indices of the plotted points are returned invisibly.
</p>


<h3>Note</h3>

<p>This funtion is based on verboseScatterplot (Steve Horvath and Peter Langfelder), iplot (Andreas Ruckstuhl, Rene Locher) and greenWhiteRed(Peter Langfelder )
</p>


<h3>Author(s)</h3>

<p>Chaochao Cai, Steve Horvath
</p>


<h3>See Also</h3>

<p><a href="graphics.html#topic+image">image</a> for more parameters
</p>

<hr>
<h2 id='verboseScatterplot'> Scatterplot annotated by regression line and p-value</h2><span id='topic+verboseScatterplot'></span>

<h3>Description</h3>

<p>Produce a scatterplot annotated by the correlation, p-value, and regression line. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verboseScatterplot(x, y, 
                   sample = NULL,
                   corFnc = "cor", corOptions = "use = 'p'", 
                   main = "", xlab = NA, ylab = NA, 
                   cex = 1, cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5, 
                   abline = FALSE, abline.color = 1, abline.lty = 1,
                   corLabel = corFnc, 
                   displayAsZero = 1e-5,
                   col = 1, bg = 0, pch = 1,
                   lmFnc = lm,
                   plotPriority = NULL,
                   showPValue = TRUE,
                   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="verboseScatterplot_+3A_x">x</code></td>
<td>
<p>  numerical vector to be plotted along the x axis. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_y">y</code></td>
<td>
<p>  numerical vector to be plotted along the y axis. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_sample">sample</code></td>
<td>
<p> determines whether <code>x</code> and <code>y</code> should be sampled for plotting, useful 
to keep the plot manageable when <code>x</code> and <code>y</code> are large vectors.
The default <code>NULL</code> value implies no sampling. A single numeric value will be interpreted as the
number of points to sample randomly. If a vector is given, it will be interpreted as the indices of the
entries in <code>x</code> and <code>y</code> that should be plotted. In either case, the correlation and p value will
be determined from the full vectors <code>x</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_corfnc">corFnc</code></td>
<td>
<p> character string giving the correlation function to annotate the plot. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_coroptions">corOptions</code></td>
<td>
<p> character string giving further options to the correlation function. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_main">main</code></td>
<td>
<p> main title for the plot.</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_xlab">xlab</code></td>
<td>
<p> label for the x-axis. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_ylab">ylab</code></td>
<td>
<p> label for the y-axis. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_cex">cex</code></td>
<td>
<p> character expansion factor for plot annotations, recycled as necessary. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_cex.axis">cex.axis</code></td>
<td>
<p> character expansion factor for axis annotations. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_cex.lab">cex.lab</code></td>
<td>
<p> character expansion factor for axis labels. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_cex.main">cex.main</code></td>
<td>
<p> character expansion factor for the main title. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_abline">abline</code></td>
<td>
<p> logical: should the linear regression fit line be plotted? </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_abline.color">abline.color</code></td>
<td>
<p> color specification for the fit line.</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_abline.lty">abline.lty</code></td>
<td>
<p> line type for the fit line.</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_corlabel">corLabel</code></td>
<td>
<p> character string to be used as the label for the correlation value printed in the main
title. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_displayaszero">displayAsZero</code></td>
<td>
<p> Correlations whose absolute value is smaller than this number will be displayed as
zero. This can result in a more intuitive display (for example, cor=0 instead of cor=2.6e-17).</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_col">col</code></td>
<td>
<p>color of the plotted symbols. Recycled as necessary. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_bg">bg</code></td>
<td>
<p>fill color of the plotted symbols (used for certain symbols). Recycled as necessary. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_pch">pch</code></td>
<td>
<p>Integer code for plotted symbols (see <code>link{plot.default}</code>). Recycled as necessary. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_lmfnc">lmFnc</code></td>
<td>
<p>linear model fit function. Used to calculate the linear model fit line if <code>'abline'</code> is
<code>TRUE</code>. For example, robust linear models are implemented in the 
function <code><a href="MASS.html#topic+rlm">rlm</a></code>. </p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_plotpriority">plotPriority</code></td>
<td>
<p>Optional numeric vector of same length as <code>x</code>. Points with higher plot priority
will be plotted later, making them more visible if points overlap.</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_showpvalue">showPValue</code></td>
<td>
<p>Logical: should the p-value corresponding to the correlation be added to the title?</p>
</td></tr>
<tr><td><code id="verboseScatterplot_+3A_...">...</code></td>
<td>
<p> other arguments to the function <code><a href="base.html#topic+plot">plot</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Irrespective of the specified correlation function, the p-value is always calculated for pearson
correlation. 
</p>


<h3>Value</h3>

<p>If <code>sample</code> above is given, the indices of the plotted points are returned invisibly.
</p>


<h3>Author(s)</h3>

<p> Steve Horvath and Peter Langfelder </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+plot.default">plot.default</a></code> for standard scatterplots </p>

<hr>
<h2 id='votingLinearPredictor'> Voting linear predictor </h2><span id='topic+votingLinearPredictor'></span>

<h3>Description</h3>

<p>Predictor based on univariate regression on all or selected given features 
that pools all predictions using weights
derived from the univariate linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>votingLinearPredictor(
         x, y, xtest = NULL, 
         classify = FALSE, 
         CVfold = 0, 
         randomSeed = 12345, 
         assocFnc = "cor", assocOptions = "use = 'p'", 
         featureWeightPowers = NULL, priorWeights = NULL, 
         weighByPrediction = 0, 
         nFeatures.hi = NULL, nFeatures.lo = NULL, 
         dropUnusedDimensions = TRUE, 
         verbose = 2, indent = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="votingLinearPredictor_+3A_x">x</code></td>
<td>

<p>Training features (predictive variables). Each column corresponds to a feature and each row to an
observation. 
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_y">y</code></td>
<td>

<p>The response variable. Can be a single vector or a matrix with arbitrary many columns. Number of rows
(observations) must equal to the number of rows (observations) in x.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_xtest">xtest</code></td>
<td>

<p>Optional test set data. A matrix of the same number of columns (i.e., features) as <code>x</code>. 
If test set data are not given, only the prediction on training data will be returned. 
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_classify">classify</code></td>
<td>

<p>Should the response be treated as a categorical variable? Classification really only works with two classes.
(The function will run for multiclass problems as well, but the results will be sub-optimal.)
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_cvfold">CVfold</code></td>
<td>

<p>Optional specification of cross-validation fold. If 0 (the default), no cross-validation is performed.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_randomseed">randomSeed</code></td>
<td>

<p>Random seed, used for observation selection for cross-validation. If <code>NULL</code>, the random generator is
not reset.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_assocfnc">assocFnc</code></td>
<td>

<p>Function to measure association. Usually a measure of correlation, for example Pearson correlation or
<code><a href="#topic+bicor">bicor</a></code>. 
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_assocoptions">assocOptions</code></td>
<td>

<p>Character string specifying the options to be passed to the association function.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_featureweightpowers">featureWeightPowers</code></td>
<td>

<p>Powers to which to raise the result of <code>assocFnc</code> to obtain weights. Can be a single number or a vector
of arbitrary length; the returned value will contain one prediction per power.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_priorweights">priorWeights</code></td>
<td>

<p>Prior weights for the features. If given, must be either (1) a vector of the same length as the number of
features (columns in <code>x</code>); (2) a matrix of dimensions length(featureWeightPowers)x(number of features);
or (3) array of dimensions (number of response variables)xlength(featureWeightPowers)x(number of features).
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_weighbyprediction">weighByPrediction</code></td>
<td>

<p>(Optional) power to downweigh features that are not well predicted between training and test sets. See
details. 
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_nfeatures.hi">nFeatures.hi</code></td>
<td>

<p>Optional restriction of the number of features to use. If given, this many features with the highest association
and lowest association (if <code>nFeatures.lo</code> is not given) will be used for prediction.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_nfeatures.lo">nFeatures.lo</code></td>
<td>

<p>Optional restriction of the number of lowest (i.e., most negatively) associated features to use. 
Only used if <code>nFeatures.hi</code> is also non-NULL.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_dropunuseddimensions">dropUnusedDimensions</code></td>
<td>

<p>Logical: should unused dimensions be dropped from the result?
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_verbose">verbose</code></td>
<td>

<p>Integer controling how verbose the diagnostic messages should be. Zero means silent.
</p>
</td></tr>
<tr><td><code id="votingLinearPredictor_+3A_indent">indent</code></td>
<td>

<p>Indentation for the diagnostic messages. Zero means no indentation, each unit adds two spaces.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predictor calculates the association of each (selected) feature with the response and uses the
association to calculate the weight of the feature as <code>sign(association) *
(association)^featureWeightPower</code>. Optionally, this weight is multiplied by <code>priorWeights</code>. Further, a
feature prediction weight can be used to downweigh features that are not well predicted by other features
(see below).
</p>
<p>For classification, the (continuous) result of the above calculation is turned into ordinal values
essentially by rounding. 
</p>
<p>If features exhibit non-trivial correlations among themselves (such as, for example, in gene expression
data), one can attempt to down-weigh features that do not exhibit the same correlation in the test set.
This is done by using essentially the same predictor to predict _features_ from all other features in the
test data (using the training data to train the feature predictor). Because test features are known, the
prediction accuracy can be evaluated. If a feature is predicted badly (meaning the error in the test set is
much larger than the error in the cross-validation prediction in training data), 
it may mean that its quality in the
training or test data is low (for example, due to excessive noise or outliers). 
Such features can be downweighed using the argument <code>weighByPrediction</code>. The extra factor is 
min(1, (root mean square prediction error in test set)/(root mean square cross-validation prediction error in
the trainig data)^weighByPrediction), that is it is never bigger than 1.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>predicted</code></td>
<td>
<p>The back-substitution prediction on the training data. Normally an array of dimensions
(number of observations) x (number of response variables) x length(featureWeightPowers), but unused
are dropped unless <code>dropUnusedDimensions = FALSE</code>.</p>
</td></tr>
<tr><td><code>weightBase</code></td>
<td>
<p>Absolute value of the associations of each feature with each response.</p>
</td></tr>
<tr><td><code>variableImportance</code></td>
<td>
<p>The weight of each feature in the prediction (including the sign).</p>
</td></tr>
<tr><td><code>predictedTest</code></td>
<td>
<p>If input <code>xtest</code> is non-NULL, the predicted test response, in format analogous to <code>predicted</code> above.</p>
</td></tr>
<tr><td><code>CVpredicted</code></td>
<td>
<p>If input <code>CVfold</code> is non-zero, cross-validation prediction on the training data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It makes little practical sense to supply neither <code>xtest</code> nor <code>CVfold</code> since the prediction
accuracy on training data will be highly biased.
</p>


<h3>Author(s)</h3>

<p>Peter Langfelder
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bicor">bicor</a></code> for robust correlation that can be used as an association measure
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
