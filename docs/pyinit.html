<!DOCTYPE html><html><head><title>Help for package pyinit</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pyinit}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mscale'><p>Robust M-estimate of Scale</p></a></li>
<li><a href='#pyinit'><p>PY (Pena-Yohai) initial estimates for S-estimates of regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Pena-Yohai Initial Estimator for Robust S-Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-26</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Kepplinger &lt;david.kepplinger@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Deterministic Pena-Yohai initial estimator for robust S estimators
    of regression. The procedure is described in detail in
    Pena, D., &amp; Yohai, V. (1999) &lt;<a href="https://doi.org/10.2307%2F2670164">doi:10.2307/2670164</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>robustbase</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/dakep/pyinit">https://github.com/dakep/pyinit</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dakep/pyinit/issues">https://github.com/dakep/pyinit/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Copyright:</td>
<td>See the file COPYRIGHTS for copyright details on some of the
functions.</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-26 14:44:36 UTC; david</td>
</tr>
<tr>
<td>Author:</td>
<td>David Kepplinger [aut, cre],
  Matias Salibian-Barrera [aut],
  Gabriela Cohen Freue [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-26 20:50:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='mscale'>Robust M-estimate of Scale</h2><span id='topic+mscale'></span>

<h3>Description</h3>

<p>Compute the M-estimate of scale using the MAD as initial estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mscale(
  x,
  delta = 0.5,
  rho = c("bisquare", "huber", "gauss"),
  cc,
  eps = 1e-08,
  maxit = 200
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mscale_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="mscale_+3A_delta">delta</code></td>
<td>
<p>desired value for the right-hand side of the M-estimation equation.</p>
</td></tr>
<tr><td><code id="mscale_+3A_rho">rho</code></td>
<td>
<p>rho function to use in the M-estimation equation. Valid options
are <code>bisquare</code>, <code>huber</code> and <code>gauss</code>.</p>
</td></tr>
<tr><td><code id="mscale_+3A_cc">cc</code></td>
<td>
<p>non-negative constant for the chosen rho function. If missing, it will be
chosen such that the expected value of the rho function under the normal model
is equal to <code>delta</code>.</p>
</td></tr>
<tr><td><code id="mscale_+3A_eps">eps</code></td>
<td>
<p>threshold for convergence. Defaults to <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="mscale_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations. Defaults to <code>200</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This solves the M-estimation equation given by
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^n \rho( x_i / s_n; cc ) = n delta</code>
</p>

<p>All <code>NA</code> values in <code>x</code> are removed before calculating the scale.
</p>


<h3>Value</h3>

<p>Numeric vector of length one containing the solution <code>s_n</code> to
the equation above.
</p>

<hr>
<h2 id='pyinit'>PY (Pena-Yohai) initial estimates for S-estimates of regression</h2><span id='topic+pyinit'></span>

<h3>Description</h3>

<p>Computes the PY initial estimates for S-estimates of regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pyinit(
  x,
  y,
  intercept = TRUE,
  delta = 0.5,
  cc,
  maxit = 10,
  psc_keep,
  resid_keep_method = c("threshold", "proportion"),
  resid_keep_prop,
  resid_keep_thresh,
  eps = 1e-08,
  mscale_maxit = 200,
  mscale_tol = eps,
  mscale_rho_fun = c("bisquare", "huber", "gauss")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pyinit_+3A_x">x</code></td>
<td>
<p>a matrix with the data, each observation in a row.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_y">y</code></td>
<td>
<p>the response vector.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_intercept">intercept</code></td>
<td>
<p>logical, should an intercept be included in the model? Defaults to
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_delta">delta</code>, <code id="pyinit_+3A_cc">cc</code></td>
<td>
<p>parameters for the M-scale estimator equation. If <code>cc</code> is
missing it will be set to yield consistency under the Normal model for the
given <code>delta</code> (right-hand side of the M-scale equation).</p>
</td></tr>
<tr><td><code id="pyinit_+3A_maxit">maxit</code></td>
<td>
<p>the maximum number of iterations to perform.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_psc_keep">psc_keep</code></td>
<td>
<p>proportion of observations to keep based on PSCs.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_resid_keep_method">resid_keep_method</code></td>
<td>
<p>how to clean the data based on large residuals.
If <code>"threshold"</code>, all observations with scaled residuals larger
than <code>resid_keep_thresh</code> will be removed (<code>resid_keep_thresh</code>
corresponds to the constant <code class="reqn">C_1</code> from equation (21) in Pena &amp; Yohai
(1999). If <code>"proportion"</code>, observations with the largest
<code>resid_keep_prop</code> residuals will be removed.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_resid_keep_prop">resid_keep_prop</code>, <code id="pyinit_+3A_resid_keep_thresh">resid_keep_thresh</code></td>
<td>
<p>see parameter
<code>resid_keep_method</code> for details.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_eps">eps</code></td>
<td>
<p>the relative tolerance for convergence. Defaults to <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_mscale_maxit">mscale_maxit</code></td>
<td>
<p>maximum number of iterations allowed for the M-scale
algorithm. Defaults to <code>200</code>.</p>
</td></tr>
<tr><td><code id="pyinit_+3A_mscale_tol">mscale_tol</code></td>
<td>
<p>convergence threshold for the m-scale</p>
</td></tr>
<tr><td><code id="pyinit_+3A_mscale_rho_fun">mscale_rho_fun</code></td>
<td>
<p>A string containing the name of the rho
function to use for the M-scale. Valid options
are <code>bisquare</code>, <code>huber</code> and <code>gauss</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric matrix with coefficient vectors in columns. These
are regression estimators based on &quot;cleaned&quot; subsets of the data. The
M-scales of the corresponding residuals are returned in the entry
<code>objective</code>. The regression coefficients with smallest estimated
residual scale is in the first column, but the others need not be ordered.</p>
</td></tr>
<tr><td><code>objective</code></td>
<td>
<p>vector of values of the M-scale estimate of the residuals
associated with each vector of regression coefficients in the columns of
<code>coefficients</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Pena, D., &amp; Yohai, V.. (1999). A Fast Procedure for Outlier Diagnostics in Large
Regression Problems. <em>Journal of the American Statistical Association</em>, 94(446),
434-445. &lt;doi:10.2307/2670164&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate a simple synthetic data set for a linear regression model
# with true regression coefficients all equal to one "(1, 1, 1, 1, 1)"
set.seed(123)
x &lt;- matrix(rnorm(100*4), 100, 4)
y &lt;- rnorm(100) + rowSums(x) + 1
# add masked outliers
a &lt;- svd(var(x))$v[,4]
x &lt;- rbind(x, t(outer(a, rnorm(20, mean=4, sd=1))))
y &lt;- c(y, rnorm(20, mean=-2, sd=.2))

# these outliers are difficult to find
plot(lm(y~x), ask=FALSE)

# use pyinit to obtain estimated regression coefficients
tmp &lt;- pyinit(x=x, y=y, resid_keep_method='proportion', psc_keep = .5, resid_keep_prop=.5)
# the vector of regression coefficients with smallest residuals scale
# is returned in the first column of the "coefficients" element
tmp$coefficients[,1]
# compare that with the LS estimator on the clean data
coef(lm(y~x, subset=1:100))
# compare it with the LS estimator on the full data
coef(lm(y~x))


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
