<!DOCTYPE html><html lang="en"><head><title>Help for package first</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {first}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#first'><p>Factor Importance Ranking and Selection using Total (Sobol') indices</p></a></li>
<li><a href='#totalsobol.knn'><p>Estimating Total Sobol' Indices from Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Factor Importance Ranking and Selection using Total Indices</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, parallel, FNN, twinning</td>
</tr>
<tr>
<td>Description:</td>
<td>A model-independent factor importance ranking and selection procedure that is based on total Sobol' indices. Please see Huang and Joseph (2024) &lt;<a href="https://doi.org/10.48550/arXiv.2401.00800">doi:10.48550/arXiv.2401.00800</a>&gt;. This research is supported by U.S. National Science Foundation grants DMS-2310637 and DMREF-1921873.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-16 01:55:15 UTC; billhuang</td>
</tr>
<tr>
<td>Author:</td>
<td>Chaofan Huang [aut, cre],
  V. Roshan Joseph [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chaofan Huang &lt;chaofan.huang@gatech.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-16 04:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='first'>Factor Importance Ranking and Selection using Total (Sobol') indices</h2><span id='topic+first'></span>

<h3>Description</h3>

<p><code>first</code> implements the <em><strong>model-independent</strong></em> factor importance and selection procedure proposed in Huang and Joseph (2024).
The importance measure is based on total Sobol' indices from global sensitivity analysis.
Factor importance computation and selection are performed directly from the noisy data.
Parallel computations are available to accelerate the estimation.
For categorical data inputs, please convert them to factor type before calling the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>first(
  X,
  y,
  n.knn = NULL,
  n.mc = nrow(X),
  twin.mc = FALSE,
  rescale = TRUE,
  n.forward = 2,
  parl = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="first_+3A_x">X</code></td>
<td>
<p>a matrix or data frame for the factors / predictors.</p>
</td></tr>
<tr><td><code id="first_+3A_y">y</code></td>
<td>
<p>a vector for the responses.</p>
</td></tr>
<tr><td><code id="first_+3A_n.knn">n.knn</code></td>
<td>
<p>number of nearest-neighbors for the inner loop conditional variance estimation. <code>n.knn=2</code> is recommended for regression, and <code>n.knn=3</code> for binary classification.</p>
</td></tr>
<tr><td><code id="first_+3A_n.mc">n.mc</code></td>
<td>
<p>number of Monte Carlo samples for the outer loop expectation estimation.</p>
</td></tr>
<tr><td><code id="first_+3A_twin.mc">twin.mc</code></td>
<td>
<p>a logical indicating whether to use twinning subsamples, otherwise random subsamples are used. It is supported when the reduction ratio is at least 2.</p>
</td></tr>
<tr><td><code id="first_+3A_rescale">rescale</code></td>
<td>
<p>a logical logical indicating whether to standardize the factors / predictors.</p>
</td></tr>
<tr><td><code id="first_+3A_n.forward">n.forward</code></td>
<td>
<p>number of times to run the forward selection phase to tradeoff between efficiency and accuracy. <code>n_forward=2</code> is recommended. To run the complete forward selection, please set <code>n_forward</code> to the number of factors / predictors.</p>
</td></tr>
<tr><td><code id="first_+3A_parl">parl</code></td>
<td>
<p>number of cores on which to parallelize the computation. If <code>NULL</code>, then no parallelization is done.</p>
</td></tr>
<tr><td><code id="first_+3A_verbose">verbose</code></td>
<td>
<p>a logical indicating whether to display intermediate results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>first</code> provides factor importance ranking and selection directly from scattered data without any model fitting.
Factor importance is computed based on total Sobol' indices (Sobol', 2001),
which is connected to the approximation error introduced by excluding the factor of interest (Huang and Joseph, 2024).
The estimation procedure adapts from the Nearest-Neighbor estimator in Broto et al. (2020) to account for the noisy data.
Integrating it with forward selection and backward elimination allows for factor selection.
</p>
<p><code>first</code> belongs to the class of forward-backward selection with early dropping algorithm (Borboudakis and Tsamardinos, 2019).
In forward selection, each time we find the candidate that maximizes the output variance that can be explained.
For candidates that cannot improve the variance explained conditional on the selected factors, they are removed from the candidate set.
This forward selection step is run <code>n_forward</code> times to tradeoff between accuracy and efficiency. <code>n_forward=2</code> is recommended in Yu et al. (2020).
To run the complete forward selection, please set <code>n_forward</code> to the number of factors / predictors.
In backward elimination, we again remove one factor at a time, starting with the factor that can improve the explained variance most, till no factor can further improve.
</p>
<p><code>n.knn=2</code> nearest-neighbors is recommended for integer/numeric output, and <code>n.knn=3</code> is suggested for binary output.
For numeric inputs, it is recommended to standardize them via setting the argument <code>rescale=TRUE</code>.
Categorical inputs are transformed via one-hot encoding for the nearest-neighbor search.
To speed up the nearest-neighbor search, k-d tree from the <span class="pkg">FNN</span> package is used.
Also, parallel computation is also supported via the <span class="pkg">parallel</span> package.
</p>
<p>For large datasets, we support the use of subsamples for further acceleration.
Use argument <code>n.mc</code> to specify the number of subsamples.
Two options are available for finding the subsamples: random and twinning (Vakayil and Joseph, 2022).
Twinning is able to find subsamples that better represent the big data, i.e.,
providing a more accurate estimation, but at a slightly higher computational cost.
For more details, please see the <span class="pkg">twinning</span> package.
</p>


<h3>Value</h3>

<p>A numeric vector of the factor importance, with zero indicating that the factor is not important to the prediction of the response.
</p>


<h3>Author(s)</h3>

<p>Chaofan Huang <a href="mailto:chaofan.huang@gatech.edu">chaofan.huang@gatech.edu</a> and V. Roshan Joseph <a href="mailto:roshan@gatech.edu">roshan@gatech.edu</a>
</p>


<h3>References</h3>

<p>Huang, C., &amp; Joseph, V. R. (2024). Factor Importance Ranking and Selection using Total Indices. arXiv preprint arXiv:2401.00800.
</p>
<p>Sobol', I. M. (2001). Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates. Mathematics and computers in simulation, 55(1-3), 271-280.
</p>
<p>Broto, B., Bachoc, F., &amp; Depecker, M. (2020). Variance reduction for estimation of Shapley effects and adaptation to unknown input distribution. SIAM/ASA Journal on Uncertainty Quantification, 8(2), 693-716.
</p>
<p>Borboudakis, G., &amp; Tsamardinos, I. (2019). Forward-backward selection with early dropping. The Journal of Machine Learning Research, 20(1), 276-314.
</p>
<p>Yu, K., Guo, X., Liu, L., Li, J., Wang, H., Ling, Z., &amp; Wu, X. (2020). Causality-based feature selection: Methods and evaluations. ACM Computing Surveys (CSUR), 53(5), 1-36.
</p>
<p>Vakayil, A., &amp; Joseph, V. R. (2022). Data twinning. Statistical Analysis and Data Mining: The ASA Data Science Journal, 15(5), 598-610.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ishigami &lt;- function(x) {
  x &lt;- -pi + 2*pi*x
  y &lt;- sin(x[1]) + 7*sin(x[2])^2 + 0.1*x[3]^4*sin(x[1])
  return (y)
} 
set.seed(123)
n &lt;- 1000
p &lt;- 6
X &lt;- matrix(runif(n*p), ncol=p)
y &lt;- apply(X,1,ishigami) + rnorm(n)
imp &lt;- first(X, y, n.knn=2, rescale=FALSE, verbose=TRUE)
print(round(imp,3)) # Only first 3 factors are important

</code></pre>

<hr>
<h2 id='totalsobol.knn'>Estimating Total Sobol' Indices from Data</h2><span id='topic+totalsobol.knn'></span>

<h3>Description</h3>

<p><code>totalsobol.knn</code> implements the estimation of the total Sobol' indices directly from scattered data.
Parallel computation is available to accelerate the estimation.
For categorical inputs, please convert them to factor before calling this function.
For large datasets, we support the use of subsample to reduce the computational cost.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>totalsobol.knn(
  X,
  y,
  noise,
  n.knn = NULL,
  n.mc = nrow(X),
  twin.mc = FALSE,
  rescale = TRUE,
  parl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="totalsobol.knn_+3A_x">X</code></td>
<td>
<p>a matrix or data frame for the factors / predictors.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_y">y</code></td>
<td>
<p>a vector for the responses.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_noise">noise</code></td>
<td>
<p>a logical indicating whether the responses are noisy.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_n.knn">n.knn</code></td>
<td>
<p>number of nearest-neighbors for the inner loop conditional variance estimation. <code>n.knn=2</code> is recommended for regression, and <code>n.knn=3</code> for binary classification.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_n.mc">n.mc</code></td>
<td>
<p>number of Monte Carlo samples for the outer loop expectation estimation.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_twin.mc">twin.mc</code></td>
<td>
<p>a logical indicating whether to use twinning subsamples, otherwise random subsamples are used. It is supported when the reduction ratio is at least 2.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_rescale">rescale</code></td>
<td>
<p>a logical logical indicating whether to standardize the factors / predictors.</p>
</td></tr>
<tr><td><code id="totalsobol.knn_+3A_parl">parl</code></td>
<td>
<p>number of cores on which to parallelize the computation. If <code>NULL</code>, then no parallelization is done.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>totalsobol.knn</code> provides consistent estimation of the total Sobol' indices (Sobol, 1993) from scattered data.
When the output is clean/noiseless (<code>noise=FALSE</code>), <code>totalsobol.knn</code> implements the Nearest-Neighbor estimator proposed in Broto et al. (2020).
See <code>shapleysobol_knn</code> from the <span class="pkg">sensitivity</span> package for another implementation of the nearest-neighbor estimator.
When the output is noisy (<code>noise=TRUE</code>), <code>totalsobol.knn</code> implements the Noise-Adjusted Nearest-Neighbor (NANNE) estimator (Huang and Joseph, 2024).
NANNE estimator can correct the estimation bias of the nearest-neighbor estimator caused by the random noise.
Please see Huang and Joseph (2024) for a more detailed discussion and comparison.
</p>
<p>For integer/numeric output, <code>n.knn=2</code> nearest-neighbors is recommended for the noisy data (Huang and Joseph, 2024),
and <code>n.knn=3</code> nearest-neighbors is suggested for the clean/noiseless data (Broto et al., 2020).
For numeric inputs, it is recommended to standardize them via setting the argument <code>rescale=TRUE</code>.
Categorical inputs are transformed via one-hot encoding for the nearest-neighbor search.
To speed up the nearest-neighbor search, k-d tree from the <span class="pkg">FNN</span> package is used.
Also, parallel computation is also supported via the <span class="pkg">parallel</span> package.
</p>
<p>Last, for large datasets, we support the use of subsamples for further acceleration.
Use argument <code>n.mc</code> to specify the number of subsamples.
Two options are available for finding the subsamples: random and twinning (Vakayil and Joseph, 2022).
Twinning is able to find subsamples that better represent the big data, i.e.,
providing a more accurate estimation, but at a slightly higher computational cost.
For more details, please see the <span class="pkg">twinning</span> package.
</p>


<h3>Value</h3>

<p>A numeric vector of the total Sobol' indices estimation.
</p>


<h3>Author(s)</h3>

<p>Chaofan Huang <a href="mailto:chaofan.huang@gatech.edu">chaofan.huang@gatech.edu</a> and V. Roshan Joseph <a href="mailto:roshan@gatech.edu">roshan@gatech.edu</a>
</p>


<h3>References</h3>

<p>Huang, C., &amp; Joseph, V. R. (2024). Factor Importance Ranking and Selection using Total Indices. arXiv preprint arXiv:2401.00800.
</p>
<p>Sobol', I. M. (2001). Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates. Mathematics and computers in simulation, 55(1-3), 271-280.
</p>
<p>Broto, B., Bachoc, F., &amp; Depecker, M. (2020). Variance reduction for estimation of Shapley effects and adaptation to unknown input distribution. SIAM/ASA Journal on Uncertainty Quantification, 8(2), 693-716.
</p>
<p>Vakayil, A., &amp; Joseph, V. R. (2022). Data twinning. Statistical Analysis and Data Mining: The ASA Data Science Journal, 15(5), 598-610.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ishigami &lt;- function(x) {
  x &lt;- -pi + 2*pi*x
  y &lt;- sin(x[1]) + 7*sin(x[2])^2 + 0.1*x[3]^4*sin(x[1])
  return (y)
}

set.seed(123)
n &lt;- 10000
p &lt;- 3
X &lt;- matrix(runif(n*p), ncol=p)
y &lt;- apply(X,1,ishigami) + rnorm(n)
tsi &lt;- totalsobol.knn(X, y, noise=TRUE, n.knn=2, rescale=FALSE)
print(round(tsi,3)) # Analytical Total Sobol' Indices: 0.558, 0.442, 0.244

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
