<!DOCTYPE html><html><head><title>Help for package DALEX</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DALEX}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#apartments'><p>Apartments Data</p></a></li>
<li><a href='#colors_discrete_drwhy'><p>DrWhy color palettes for ggplot objects</p></a></li>
<li><a href='#covid'><p>Data for early COVID mortality</p></a></li>
<li><a href='#dragons'><p>Dragon Data</p></a></li>
<li><a href='#explain.default'><p>Create Model Explainer</p></a></li>
<li><a href='#fifa'><p>FIFA 20 preprocessed data</p></a></li>
<li><a href='#happiness'><p>World Happiness Report data</p></a></li>
<li><a href='#HR'><p>Human Resources Data</p></a></li>
<li><a href='#install_dependencies'><p>Install all dependencies for the DALEX package</p></a></li>
<li><a href='#loss_cross_entropy'><p>Calculate Loss Functions</p></a></li>
<li><a href='#loss_yardstick'><p>Wrapper for Loss Functions from the yardstick Package</p></a></li>
<li><a href='#model_diagnostics'><p>Dataset Level Model Diagnostics</p></a></li>
<li><a href='#model_info'><p>Exract info from model</p></a></li>
<li><a href='#model_parts'><p>Dataset Level Variable Importance as Change in Loss Function after Variable Permutations</p></a></li>
<li><a href='#model_performance'><p>Dataset Level Model Performance Measures</p></a></li>
<li><a href='#model_profile'><p>Dataset Level Variable Profile as Partial Dependence or Accumulated Local Dependence Explanations</p></a></li>
<li><a href='#plot.list'><p>Plot List of Explanations</p></a></li>
<li><a href='#plot.model_diagnostics'><p>Plot Dataset Level Model Diagnostics</p></a></li>
<li><a href='#plot.model_parts'><p>Plot Variable Importance Explanations</p></a></li>
<li><a href='#plot.model_performance'><p>Plot Dataset Level Model Performance Explanations</p></a></li>
<li><a href='#plot.model_profile'><p>Plot Dataset Level Model Profile Explanations</p></a></li>
<li><a href='#plot.predict_diagnostics'><p>Plot Instance Level Residual Diagnostics</p></a></li>
<li><a href='#plot.predict_parts'><p>Plot Variable Attribution Explanations</p></a></li>
<li><a href='#plot.predict_profile'><p>Plot Variable Profile Explanations</p></a></li>
<li><a href='#plot.shap_aggregated'><p>Plot Generic for Break Down Objects</p></a></li>
<li><a href='#predict_diagnostics'><p>Instance Level Residual Diagnostics</p></a></li>
<li><a href='#predict_parts'><p>Instance Level Parts of the Model Predictions</p></a></li>
<li><a href='#predict_profile'><p>Instance Level Profile as Ceteris Paribus</p></a></li>
<li><a href='#predict.explainer'><p>Predictions for the Explainer</p></a></li>
<li><a href='#print.description'><p>Print Natural Language Descriptions</p></a></li>
<li><a href='#print.explainer'><p>Print Explainer Summary</p></a></li>
<li><a href='#print.model_diagnostics'><p>Print Dataset Level Model Diagnostics</p></a></li>
<li><a href='#print.model_info'><p>Print model_info</p></a></li>
<li><a href='#print.model_performance'><p>Print Dataset Level Model Performance Summary</p></a></li>
<li><a href='#print.model_profile'><p>Print Dataset Level Model Profile</p></a></li>
<li><a href='#print.predict_diagnostics'><p>Print Instance Level Residual Diagnostics</p></a></li>
<li><a href='#set_theme_dalex'><p>Default Theme for DALEX plots</p></a></li>
<li><a href='#shap_aggregated'><p>SHAP aggregated values</p></a></li>
<li><a href='#theme_drwhy'><p>DrWhy Theme for ggplot objects</p></a></li>
<li><a href='#titanic'><p>Passengers and Crew on the RMS Titanic Data</p></a></li>
<li><a href='#update_data'><p>Update data of an explainer object</p></a></li>
<li><a href='#update_label'><p>Update label of explainer object</p></a></li>
<li><a href='#variable_effect'><p>Dataset Level Variable Effect as Partial Dependency Profile or Accumulated Local Effects</p></a></li>
<li><a href='#yhat'><p>Wrap Various Predict Functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>moDel Agnostic Language for Exploration and eXplanation</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Any unverified black box model is the path to failure. Opaqueness leads to distrust. 
  Distrust leads to ignoration. Ignoration leads to rejection. 
  DALEX package xrays any model and helps to explore and explain its behaviour.
  Machine Learning (ML) models are widely used and have various applications in classification 
  or regression. Models created with boosting, bagging, stacking or similar techniques are often
  used due to their high performance. But such black-box models usually lack direct interpretability.
  DALEX package contains various methods that help to understand the link between input variables 
  and model output. Implemented methods help to explore the model on the level of a single instance 
  as well as a level of the whole dataset.
  All model explainers are model agnostic and can be compared across different models.
  DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration.
  Find more details in (Biecek 2018) &lt;<a href="https://arxiv.org/abs/1806.08915">arXiv:1806.08915</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, iBreakDown (&ge; 1.3.1), ingredients (&ge; 2.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gower, ranger, testthat, methods</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://modeloriented.github.io/DALEX/">https://modeloriented.github.io/DALEX/</a>, <a href="https://dalex.drwhy.ai">https://dalex.drwhy.ai</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ModelOriented/DALEX/issues">https://github.com/ModelOriented/DALEX/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-15 18:32:55 UTC; pbiecek</td>
</tr>
<tr>
<td>Author:</td>
<td>Przemyslaw Biecek <a href="https://orcid.org/0000-0001-8423-1823"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Szymon Maksymiuk <a href="https://orcid.org/0000-0002-3120-1601"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Hubert Baniecki <a href="https://orcid.org/0000-0001-6661-5364"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Przemyslaw Biecek &lt;przemyslaw.biecek@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-15 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='apartments'>Apartments Data</h2><span id='topic+apartments'></span><span id='topic+apartments_test'></span><span id='topic+apartmentsTest'></span>

<h3>Description</h3>

<p>Datasets <code>apartments</code> and <code>apartments_test</code> are artificial,
generated form the same model.
Structure of the dataset is copied from real dataset from <code>PBImisc</code> package,
but they were generated in a way to mimic effect of Anscombe quartet for complex black box models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(apartments)
</code></pre>


<h3>Format</h3>

<p>a data frame with 1000 rows and 6 columns
</p>


<h3>Details</h3>


<ul>
<li><p> m2.price - price per square meter
</p>
</li>
<li><p> surface - apartment area in square meters
</p>
</li>
<li><p> n.rooms - number of rooms (correlated with surface)
</p>
</li>
<li><p> district - district in which apartment is located, factor with 10 levels
</p>
</li>
<li><p> floor - floor
</p>
</li>
<li><p> construction.date - construction year
</p>
</li></ul>


<hr>
<h2 id='colors_discrete_drwhy'>DrWhy color palettes for ggplot objects</h2><span id='topic+colors_discrete_drwhy'></span><span id='topic+colors_diverging_drwhy'></span><span id='topic+colors_breakdown_drwhy'></span>

<h3>Description</h3>

<p>DrWhy color palettes for ggplot objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colors_discrete_drwhy(n = 2)

colors_diverging_drwhy()

colors_breakdown_drwhy()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colors_discrete_drwhy_+3A_n">n</code></td>
<td>
<p>number of colors for color palette</p>
</td></tr>
</table>


<h3>Value</h3>

<p>color palette as vector of charactes
</p>

<hr>
<h2 id='covid'>Data for early COVID mortality</h2><span id='topic+covid'></span><span id='topic+covid_summer'></span><span id='topic+covid_spring'></span>

<h3>Description</h3>

<p>Two datasets of characteristics of patients infected with COVID. It is important to note that these are not real patient data. This is simulated data, generated to have relationships consistent with real data (obtained from NIH), but the data itself is not real. Fortunately, they are sufficient for the purposes of our exercise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(covid_summer)
data(covid_spring)
</code></pre>


<h3>Format</h3>

<p>a data frame with 10 000 rows each and 12 columns
</p>


<h3>Details</h3>

<p>The data is divided into two sets covid_spring and covid_summer. The first is acquired in spring 2020 and will be used as training data while the second dataset is acquired in summer and will be used for validation. In machine learning, model validation is performed on a separate data set. This controls the risk of overfitting an elastic model to the data. If we do not have a separate set then it is generated using cross-validation, out of sample or out of time techniques.
</p>
<p>It contains 20 000 rows related fo COVID mortality. it contains 11 variables such as: Gender, Age, Cardiovascular.Diseases, Diabetes, Neurological.Diseases, Kidney.Diseases.
</p>
<p>Source: <a href="https://github.com/BetaAndBit/RML">https://github.com/BetaAndBit/RML</a>
</p>


<h3>Source</h3>

<p><a href="https://github.com/BetaAndBit/RML">https://github.com/BetaAndBit/RML</a>
</p>

<hr>
<h2 id='dragons'>Dragon Data</h2><span id='topic+dragons'></span><span id='topic+dragons_test'></span>

<h3>Description</h3>

<p>Datasets <code>dragons</code> and <code>dragons_test</code> are artificial, generated form the same ground truth model,
but with sometimes different data distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dragons)
</code></pre>


<h3>Format</h3>

<p>a data frame with 2000 rows and 8 columns
</p>


<h3>Details</h3>

<p>Values are generated in a way to:
- have nonlinearity in year_of_birth and height
- have concept drift in the test set
</p>

<ul>
<li><p> year_of_birth - year in which the dragon was born. Negative year means year BC, eg: -1200 = 1201 BC
</p>
</li>
<li><p> year_of_discovery - year in which the dragon was found.
</p>
</li>
<li><p> height - height of the dragon in yards.
</p>
</li>
<li><p> weight - weight of the dragon in tons.
</p>
</li>
<li><p> scars - number of scars.
</p>
</li>
<li><p> colour - colour of the dragon.
</p>
</li>
<li><p> number_of_lost_teeth - number of teeth that the dragon lost.
</p>
</li>
<li><p> life_length - life length of the dragon.
</p>
</li></ul>


<hr>
<h2 id='explain.default'>Create Model Explainer</h2><span id='topic+explain.default'></span><span id='topic+explain'></span>

<h3>Description</h3>

<p>Black-box models may have very different structures.
This function creates a unified representation of a model, which can be further processed by functions for explanations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain.default(
  model,
  data = NULL,
  y = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  weights = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)

explain(
  model,
  data = NULL,
  y = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  weights = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explain.default_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain.default_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain.default_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain.default_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain.default_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain.default_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain.default_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain.default_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please NOTE that the <code>model</code> is the only required argument.
But some explanations may expect that other arguments will be provided too.
</p>


<h3>Value</h3>

<p>An object of the class <code>explainer</code>.
</p>
<p>It's a list with the following fields:
</p>

<ul>
<li> <p><code>model</code> the explained model.
</p>
</li>
<li> <p><code>data</code> the dataset used for training.
</p>
</li>
<li> <p><code>y</code> response for observations from <code>data</code>.
</p>
</li>
<li> <p><code>weights</code> sample weights for <code>data</code>. <code>NULL</code> if weights are not specified.
</p>
</li>
<li> <p><code>y_hat</code> calculated predictions.
</p>
</li>
<li> <p><code>residuals</code> calculated residuals.
</p>
</li>
<li> <p><code>predict_function</code> function that may be used for model predictions, shall return a single numerical value for each observation.
</p>
</li>
<li> <p><code>residual_function</code> function that returns residuals, shall return a single numerical value for each observation.
</p>
</li>
<li> <p><code>class</code> class/classes of a model.
</p>
</li>
<li> <p><code>label</code> label of explainer.
</p>
</li>
<li> <p><code>model_info</code> named list contating basic information about model, like package, version of package and type.
</p>
</li></ul>



<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple explainer for regression problem
aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v")
aps_lm_explainer4

# various parameters for the explain function
# all defaults
aps_lm &lt;- explain(aps_lm_model4)

# silent execution
aps_lm &lt;- explain(aps_lm_model4, verbose = FALSE)

# set target variable
aps_lm &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v", y = apartments$m2.price)
aps_lm &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v", y = apartments$m2.price,
                                   predict_function = predict)


# user provided predict_function
aps_ranger &lt;- ranger::ranger(m2.price~., data = apartments, num.trees = 50)
custom_predict &lt;- function(X.model, newdata) {
   predict(X.model, newdata)$predictions
}
aps_ranger_exp &lt;- explain(aps_ranger, data = apartments, y = apartments$m2.price,
                          predict_function = custom_predict)


# user provided residual_function
aps_ranger &lt;- ranger::ranger(m2.price~., data = apartments, num.trees = 50)
custom_residual &lt;- function(X.model, newdata, y, predict_function) {
   abs(y - predict_function(X.model, newdata))
}
aps_ranger_exp &lt;- explain(aps_ranger, data = apartments,
                          y = apartments$m2.price,
                          residual_function = custom_residual)

# binary classification
titanic_ranger &lt;- ranger::ranger(as.factor(survived)~., data = titanic_imputed, num.trees = 50,
                                 probability = TRUE)
# keep in mind that for binary classification y parameter has to be numeric  with 0 and 1 values
titanic_ranger_exp &lt;- explain(titanic_ranger, data = titanic_imputed, y = titanic_imputed$survived)

# multiclass task
hr_ranger &lt;- ranger::ranger(status~., data = HR, num.trees = 50, probability = TRUE)
# keep in mind that for multiclass y parameter has to be a factor,
# with same levels as in training data
hr_ranger_exp &lt;- explain(hr_ranger, data = HR, y = HR$status)

# set model_info
model_info &lt;- list(package = "stats", ver = "3.6.2", type = "regression")
aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v",
                             model_info = model_info)

# simple function
aps_fun &lt;- function(x) 58*x$surface
aps_fun_explainer &lt;- explain(aps_fun, data = apartments, y = apartments$m2.price, label="sfun")
model_performance(aps_fun_explainer)

# set model_info
model_info &lt;- list(package = "stats", ver = "3.6.2", type = "regression")
aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v",
                             model_info = model_info)

aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v",
                             weights = as.numeric(apartments$construction.year &gt; 2000))

# more complex model
library("ranger")
aps_ranger_model4 &lt;- ranger(m2.price ~., data = apartments, num.trees = 50)
aps_ranger_explainer4 &lt;- explain(aps_ranger_model4, data = apartments, label = "model_ranger")
aps_ranger_explainer4
 

</code></pre>

<hr>
<h2 id='fifa'>FIFA 20 preprocessed data</h2><span id='topic+fifa'></span>

<h3>Description</h3>

<p>The <code>fifa</code> dataset is a preprocessed <code>players_20.csv</code> dataset which comes as
a part of &quot;FIFA 20 complete player dataset&quot; at Kaggle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fifa)
</code></pre>


<h3>Format</h3>

<p>a data frame with 5000 rows, 42 columns and rownames
</p>


<h3>Details</h3>

<p>It contains 5000 'overall' best players and 43 variables. These are:
</p>

<ul>
<li><p> short_name (rownames)
</p>
</li>
<li><p> nationality of the player (not used in modeling)
</p>
</li>
<li><p> overall, potential, value_eur, wage_eur (4 potential target variables)
</p>
</li>
<li><p> age, height, weight, attacking skills, defending skills, goalkeeping skills (37 variables)
</p>
</li></ul>

<p>It is advised to leave only one target variable for modeling.
</p>
<p>Source: <a href="https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset">https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset</a>
</p>
<p>All transformations:
</p>

<ol>
<li><p> take 43 columns: <code>[3, 5, 7:9, 11:14, 45:78]</code> (R indexing)
</p>
</li>
<li><p> take rows with <code>value_eur &gt; 0</code>
</p>
</li>
<li><p> convert <code>short_name</code> to ASCII
</p>
</li>
<li><p> remove rows with duplicated <code>short_name</code> (keep first)
</p>
</li>
<li><p> sort rows on <code>overall</code> and take top <code>5000</code>
</p>
</li>
<li><p> set <code>short_name</code> column as rownames
</p>
</li>
<li><p> transform <code>nationality</code> to factor
</p>
</li>
<li><p> reorder columns
</p>
</li></ol>



<h3>Source</h3>

<p>The <code>players_20.csv</code> dataset was downloaded from the Kaggle site and went through few transformations.
The complete dataset was obtained from
<a href="https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset#players_20.csv">https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset#players_20.csv</a> on January 1, 2020.
</p>

<hr>
<h2 id='happiness'>World Happiness Report data</h2><span id='topic+happiness'></span><span id='topic+happiness_test'></span><span id='topic+happiness_train'></span>

<h3>Description</h3>

<p>The <code>happiness_train</code> and <code>happiness_test</code> datasets are generated
based on the &quot;World Happiness Report&quot; at Kaggle <a href="https://www.kaggle.com/datasets/unsdsn/world-happiness">https://www.kaggle.com/datasets/unsdsn/world-happiness</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(happiness_train)
data(happiness_test)
</code></pre>


<h3>Format</h3>

<p>two data frames with total 781 rows, 7 columns ech and rownames
</p>


<h3>Details</h3>

<p>It contains data for 781 countries and 7 variables. These are:
</p>

<ul>
<li><p> score - Happiness score
</p>
</li>
<li><p> gdp_per_capita -  GDP per capita
</p>
</li>
<li><p> social_support - Social support
</p>
</li>
<li><p> healthy_life_expectancy - Healthy life expectancy
</p>
</li>
<li><p> freedom_life_choices - Freedom to make life choices
</p>
</li>
<li><p> generosity - Generosity
</p>
</li>
<li><p> perceptions_of_corruption - Perceptions of corruption
</p>
</li></ul>



<h3>Source</h3>

<p>World Happiness Report data <a href="https://worldhappiness.report/">https://worldhappiness.report/</a>
</p>

<hr>
<h2 id='HR'>Human Resources Data</h2><span id='topic+HR'></span><span id='topic+HRTest'></span><span id='topic+HR_test'></span>

<h3>Description</h3>

<p>Datasets <code>HR</code> and <code>HR_test</code> are artificial, generated form the same model.
Structure of the dataset is based on a real data, from Human Resources department with
information which employees were promoted, which were fired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HR)
</code></pre>


<h3>Format</h3>

<p>a data frame with 10000 rows and 6 columns
</p>


<h3>Details</h3>

<p>Values are generated in a way to:
- have interaction between age and gender for the 'fired' variable
- have non monotonic relation for the salary variable
- have linear effects for hours and evaluation.
</p>

<ul>
<li><p> gender - gender of an employee.
</p>
</li>
<li><p> age - age of an employee in the moment of evaluation.
</p>
</li>
<li><p> hours - average number of working hours per week.
</p>
</li>
<li><p> evaluation - evaluation in the scale 2 (bad) - 5 (very good).
</p>
</li>
<li><p> salary - level of salary in the scale 0 (lowest) - 5 (highest).
</p>
</li>
<li><p> status - target variable, either 'fired' or 'promoted' or 'ok'.
</p>
</li></ul>


<hr>
<h2 id='install_dependencies'>Install all dependencies for the DALEX package</h2><span id='topic+install_dependencies'></span>

<h3>Description</h3>

<p>By default 'heavy' dependencies are not installed along DALEX.
This function silently install all required packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_dependencies(packages = c("ingredients", "iBreakDown", "ggpubr"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_dependencies_+3A_packages">packages</code></td>
<td>
<p>which packages shall be installed?</p>
</td></tr>
</table>

<hr>
<h2 id='loss_cross_entropy'>Calculate Loss Functions</h2><span id='topic+loss_cross_entropy'></span><span id='topic+loss_sum_of_squares'></span><span id='topic+loss_root_mean_square'></span><span id='topic+loss_accuracy'></span><span id='topic+loss_one_minus_auc'></span><span id='topic+loss_default'></span>

<h3>Description</h3>

<p>Calculate Loss Functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_cross_entropy(observed, predicted, p_min = 1e-04, na.rm = TRUE)

loss_sum_of_squares(observed, predicted, na.rm = TRUE)

loss_root_mean_square(observed, predicted, na.rm = TRUE)

loss_accuracy(observed, predicted, na.rm = TRUE)

loss_one_minus_auc(observed, predicted)

loss_default(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_cross_entropy_+3A_observed">observed</code></td>
<td>
<p>observed scores or labels, these are supplied as explainer specific <code>y</code></p>
</td></tr>
<tr><td><code id="loss_cross_entropy_+3A_predicted">predicted</code></td>
<td>
<p>predicted scores, either vector of matrix, these are returned from the model specific <code>predict_function()</code></p>
</td></tr>
<tr><td><code id="loss_cross_entropy_+3A_p_min">p_min</code></td>
<td>
<p>for cross entropy, minimal value for probability to make sure that <code>log</code> will not explode</p>
</td></tr>
<tr><td><code id="loss_cross_entropy_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should missing values be removed?</p>
</td></tr>
<tr><td><code id="loss_cross_entropy_+3A_x">x</code></td>
<td>
<p>either an explainer or type of the model. One of &quot;regression&quot;, &quot;classification&quot;, &quot;multiclass&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric - value of the loss function
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
loss_one_minus_auc(titanic_imputed$survived, yhat(titanic_ranger_model, titanic_imputed))

HR_ranger_model_multi &lt;- ranger(status~., data = HR, num.trees = 50, probability = TRUE)
loss_cross_entropy(as.numeric(HR$status), yhat(HR_ranger_model_multi, HR))

 
</code></pre>

<hr>
<h2 id='loss_yardstick'>Wrapper for Loss Functions from the yardstick Package</h2><span id='topic+loss_yardstick'></span>

<h3>Description</h3>

<p>The yardstick package provides many auxiliary functions for calculating
the predictive performance of the model. However, they have an interface
that is consistent with the tidyverse philosophy. The loss_yardstick
function adapts loss functions from the yardstick package to functions
understood by DALEX. Type compatibility for y-values and for predictions
must be guaranteed by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_yardstick(loss, reverse = FALSE, reference = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_yardstick_+3A_loss">loss</code></td>
<td>
<p>loss function from the yardstick package</p>
</td></tr>
<tr><td><code id="loss_yardstick_+3A_reverse">reverse</code></td>
<td>
<p>shall the metric be reversed? for loss metrics lower values are better. <code>reverse = TRUE</code> is useful for accuracy-like metrics</p>
</td></tr>
<tr><td><code id="loss_yardstick_+3A_reference">reference</code></td>
<td>
<p>if the metric is reverse then it is calculated as <code>reference - loss</code>. The default value is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>loss function that can be used in the model_parts function
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
 titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
 explainer_glm &lt;- DALEX::explain(titanic_glm_model,
                                 data = titanic_imputed[,-8],
                                 y = factor(titanic_imputed$survived))
 # See the 'How to use DALEX with the yardstick package' vignette
 # which explains this model with measures implemented in the 'yardstick' package


</code></pre>

<hr>
<h2 id='model_diagnostics'>Dataset Level Model Diagnostics</h2><span id='topic+model_diagnostics'></span>

<h3>Description</h3>

<p>This function performs model diagnostic of residuals.
Residuals are calculated and plotted against predictions, true y values or selected variables.
Find information how to use this function here: <a href="https://ema.drwhy.ai/residualDiagnostic.html">https://ema.drwhy.ai/residualDiagnostic.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_diagnostics(explainer, variables = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_diagnostics_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="model_diagnostics_+3A_variables">variables</code></td>
<td>
<p>character - name of variables to be explained. Default <code>NULL</code> stands for all variables</p>
</td></tr>
<tr><td><code id="model_diagnostics_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>model_diagnostics</code>.
It's a data frame with residuals and selected variables.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DALEX)
apartments_lm_model &lt;- lm(m2.price ~ ., data = apartments)
explainer_lm &lt;- explain(apartments_lm_model,
                         data = apartments,
                         y = apartments$m2.price)
diag_lm &lt;- model_diagnostics(explainer_lm)
diag_lm
plot(diag_lm)

library("ranger")
apartments_ranger_model &lt;- ranger(m2.price ~ ., data = apartments)
explainer_ranger &lt;- explain(apartments_ranger_model,
                         data = apartments,
                         y = apartments$m2.price)
diag_ranger &lt;- model_diagnostics(explainer_ranger)
diag_ranger
plot(diag_ranger)
plot(diag_ranger, diag_lm)
plot(diag_ranger, diag_lm, variable = "y")
plot(diag_ranger, diag_lm, variable = "construction.year")
plot(diag_ranger, variable = "y", yvariable = "y_hat")
plot(diag_ranger, variable = "y", yvariable = "abs_residuals")
plot(diag_ranger, variable = "ids")

</code></pre>

<hr>
<h2 id='model_info'>Exract info from model</h2><span id='topic+model_info'></span><span id='topic+model_info.lm'></span><span id='topic+model_info.randomForest'></span><span id='topic+model_info.svm'></span><span id='topic+model_info.glm'></span><span id='topic+model_info.lrm'></span><span id='topic+model_info.glmnet'></span><span id='topic+model_info.cv.glmnet'></span><span id='topic+model_info.ranger'></span><span id='topic+model_info.gbm'></span><span id='topic+model_info.model_fit'></span><span id='topic+model_info.train'></span><span id='topic+model_info.rpart'></span><span id='topic+model_info.default'></span>

<h3>Description</h3>

<p>This generic function let user extract base information about model. The function returns a named list of class <code>model_info</code> that
contain about package of model, version and task type. For wrappers like <code>mlr</code> or <code>caret</code> both, package and wrapper inforamtion
are stored
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'lm'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'randomForest'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'svm'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'glm'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'lrm'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'glmnet'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'cv.glmnet'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'ranger'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'gbm'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'model_fit'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'train'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'rpart'
model_info(model, is_multiclass = FALSE, ...)

## Default S3 method:
model_info(model, is_multiclass = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_info_+3A_model">model</code></td>
<td>
<p>- model object</p>
</td></tr>
<tr><td><code id="model_info_+3A_is_multiclass">is_multiclass</code></td>
<td>
<p>- if TRUE and task is classification, then multitask classification is set. Else is omitted. If <code>model_info</code>
was executed withing <code>explain</code> function. DALEX will recognize subtype on it's own.</p>
</td></tr>
<tr><td><code id="model_info_+3A_...">...</code></td>
<td>
<p>- another arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently supported packages are:
</p>

<ul>
<li><p> class <code>cv.glmnet</code> and <code>glmnet</code> - models created with <span class="pkg">glmnet</span> package
</p>
</li>
<li><p> class <code>glm</code> - generalized linear models
</p>
</li>
<li><p> class <code>lrm</code> - models created with <span class="pkg">rms</span> package,
</p>
</li>
<li><p> class <code>model_fit</code> - models created with <span class="pkg">parsnip</span> package
</p>
</li>
<li><p> class <code>lm</code> - linear models created with <code>stats::lm</code>
</p>
</li>
<li><p> class <code>ranger</code> - models created with <span class="pkg">ranger</span> package
</p>
</li>
<li><p> class <code>randomForest</code> - random forest models created with <span class="pkg">randomForest</span> package
</p>
</li>
<li><p> class <code>svm</code> - support vector machines models created with the <span class="pkg">e1071</span> package
</p>
</li>
<li><p> class <code>train</code> - models created with <span class="pkg">caret</span> package
</p>
</li>
<li><p> class <code>gbm</code> - models created with <span class="pkg">gbm</span> package
</p>
</li></ul>



<h3>Value</h3>

<p>A named list of class <code>model_info</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
model_info(aps_lm_model4)


library("ranger")
model_regr_rf &lt;- ranger::ranger(status~., data = HR, num.trees = 50, probability = TRUE)
model_info(model_regr_rf, is_multiclass = TRUE)


</code></pre>

<hr>
<h2 id='model_parts'>Dataset Level Variable Importance as Change in Loss Function after Variable Permutations</h2><span id='topic+model_parts'></span><span id='topic+variable_importance'></span><span id='topic+feature_importance'></span>

<h3>Description</h3>

<p>From DALEX version 1.0 this function calls the <code><a href="ingredients.html#topic+feature_importance">feature_importance</a></code>
Find information how to use this function here: <a href="https://ema.drwhy.ai/featureImportance.html">https://ema.drwhy.ai/featureImportance.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_parts(
  explainer,
  loss_function = loss_default(explainer$model_info$type),
  ...,
  type = "variable_importance",
  N = n_sample,
  n_sample = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parts_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="model_parts_+3A_loss_function">loss_function</code></td>
<td>
<p>a function that will be used to assess variable importance. By default it is 1-AUC for classification, cross entropy for multilabel classification and RMSE for regression. Custom, user-made loss function should accept two obligatory parameters (observed, predicted), where <code>observed</code> states for actual values of the target, while <code>predicted</code> for predicted values. If attribute &quot;loss_accuracy&quot; is associated with function object, then it will be plotted as name of the loss function.</p>
</td></tr>
<tr><td><code id="model_parts_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="model_parts_+3A_type">type</code></td>
<td>
<p>character, type of transformation that should be applied for dropout loss. <code>variable_importance</code> and <code>raw</code> results raw drop lossess, <code>ratio</code> returns <code>drop_loss/drop_loss_full_model</code> while <code>difference</code> returns <code>drop_loss - drop_loss_full_model</code></p>
</td></tr>
<tr><td><code id="model_parts_+3A_n">N</code></td>
<td>
<p>number of observations that should be sampled for calculation of variable importance. If <code>NULL</code> then variable importance will be calculated on whole dataset (no sampling).</p>
</td></tr>
<tr><td><code id="model_parts_+3A_n_sample">n_sample</code></td>
<td>
<p>alias for <code>N</code> held for backwards compatibility. number of observations that should be sampled for calculation of variable importance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>feature_importance</code>.
It's a data frame with calculated average response.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# regression

library("ranger")
apartments_ranger_model &lt;- ranger(m2.price~., data = apartments, num.trees = 50)
explainer_ranger  &lt;- explain(apartments_ranger_model, data = apartments[,-1],
                             y = apartments$m2.price, label = "Ranger Apartments")
model_parts_ranger_aps &lt;- model_parts(explainer_ranger, type = "raw")
head(model_parts_ranger_aps, 8)
plot(model_parts_ranger_aps)

# binary classification

titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm_titanic &lt;- explain(titanic_glm_model, data = titanic_imputed[,-8],
                         y = titanic_imputed$survived)
logit &lt;- function(x) exp(x)/(1+exp(x))
custom_loss &lt;- function(observed, predicted){
   sum((observed - logit(predicted))^2)
}
attr(custom_loss, "loss_name") &lt;- "Logit residuals"
model_parts_glm_titanic &lt;- model_parts(explainer_glm_titanic, type = "raw",
                                       loss_function = custom_loss)
head(model_parts_glm_titanic, 8)
plot(model_parts_glm_titanic)

# multilabel classification

HR_ranger_model_HR &lt;- ranger(status~., data = HR, num.trees = 50,
                               probability = TRUE)
explainer_ranger_HR  &lt;- explain(HR_ranger_model_HR, data = HR[,-6],
                             y = HR$status, label = "Ranger HR")
model_parts_ranger_HR &lt;- model_parts(explainer_ranger_HR, type = "raw")
head(model_parts_ranger_HR, 8)
plot(model_parts_ranger_HR)



</code></pre>

<hr>
<h2 id='model_performance'>Dataset Level Model Performance Measures</h2><span id='topic+model_performance'></span>

<h3>Description</h3>

<p>Function <code>model_performance()</code> calculates various performance measures for classification and regression models.
For classification models following measures are calculated: F1, accuracy, recall, precision and AUC.
For regression models following measures are calculated: mean squared error, R squared, median absolute deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_performance(explainer, ..., cutoff = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_performance_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code><a href="#topic+explain">explain</a></code> function</p>
</td></tr>
<tr><td><code id="model_performance_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="model_performance_+3A_cutoff">cutoff</code></td>
<td>
<p>a cutoff for classification models, needed for measures like recall, precision, ACC, F1. By default 0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>model_performance</code>.
</p>
<p>It's a list with following fields:
</p>

<ul>
<li> <p><code>residuals</code> - data frame that contains residuals for each observation
</p>
</li>
<li> <p><code>measures</code> - list with calculated measures that are dedicated for the task, whether it is regression, binary classification or multiclass classification.
</p>
</li>
<li> <p><code>type</code> - character that specifies type of the task.
</p>
</li></ul>



<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# regression

library("ranger")
apartments_ranger_model &lt;- ranger(m2.price~., data = apartments, num.trees = 50)
explainer_ranger_apartments  &lt;- explain(apartments_ranger_model, data = apartments[,-1],
                             y = apartments$m2.price, label = "Ranger Apartments")
model_performance_ranger_aps &lt;- model_performance(explainer_ranger_apartments )
model_performance_ranger_aps
plot(model_performance_ranger_aps)
plot(model_performance_ranger_aps, geom = "boxplot")
plot(model_performance_ranger_aps, geom = "histogram")

# binary classification

titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm_titanic &lt;- explain(titanic_glm_model, data = titanic_imputed[,-8],
                         y = titanic_imputed$survived)
model_performance_glm_titanic &lt;- model_performance(explainer_glm_titanic)
model_performance_glm_titanic
plot(model_performance_glm_titanic)
plot(model_performance_glm_titanic, geom = "boxplot")
plot(model_performance_glm_titanic, geom = "histogram")

# multilabel classification

HR_ranger_model &lt;- ranger(status~., data = HR, num.trees = 50,
                               probability = TRUE)
explainer_ranger_HR  &lt;- explain(HR_ranger_model, data = HR[,-6],
                             y = HR$status, label = "Ranger HR")
model_performance_ranger_HR &lt;- model_performance(explainer_ranger_HR)
model_performance_ranger_HR
plot(model_performance_ranger_HR)
plot(model_performance_ranger_HR, geom = "boxplot")
plot(model_performance_ranger_HR, geom = "histogram")



</code></pre>

<hr>
<h2 id='model_profile'>Dataset Level Variable Profile as Partial Dependence or Accumulated Local Dependence Explanations</h2><span id='topic+model_profile'></span><span id='topic+variable_profile'></span><span id='topic+single_variable'></span>

<h3>Description</h3>

<p>This function calculates explanations on a dataset level set that explore model response as a function of selected variables.
The explanations can be calulated as Partial Dependence Profile or  Accumulated Local Dependence Profile.
Find information how to use this function here: <a href="https://ema.drwhy.ai/partialDependenceProfiles.html">https://ema.drwhy.ai/partialDependenceProfiles.html</a>.
The <code>variable_profile</code> function is a copy of <code>model_profile</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_profile(
  explainer,
  variables = NULL,
  N = 100,
  ...,
  groups = NULL,
  k = NULL,
  center = TRUE,
  type = "partial"
)

variable_profile(
  explainer,
  variables = NULL,
  N = 100,
  ...,
  groups = NULL,
  k = NULL,
  center = TRUE,
  type = "partial"
)

single_variable(explainer, variable, type = "pdp", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_profile_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="model_profile_+3A_variables">variables</code></td>
<td>
<p>character - names of variables to be explained</p>
</td></tr>
<tr><td><code id="model_profile_+3A_n">N</code></td>
<td>
<p>number of observations used for calculation of aggregated profiles. By default <code>100</code>. Use <code>NULL</code> to use all observations.</p>
</td></tr>
<tr><td><code id="model_profile_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to <code>ingredients::aggregate_profiles</code></p>
</td></tr>
<tr><td><code id="model_profile_+3A_groups">groups</code></td>
<td>
<p>a variable name that will be used for grouping.
By default <code>NULL</code> which means that no groups shall be calculated</p>
</td></tr>
<tr><td><code id="model_profile_+3A_k">k</code></td>
<td>
<p>number of clusters for the hclust function (for clustered profiles)</p>
</td></tr>
<tr><td><code id="model_profile_+3A_center">center</code></td>
<td>
<p>shall profiles be centered before clustering</p>
</td></tr>
<tr><td><code id="model_profile_+3A_type">type</code></td>
<td>
<p>the type of variable profile. Either <code>partial</code>, <code>conditional</code> or <code>accumulated</code>.</p>
</td></tr>
<tr><td><code id="model_profile_+3A_variable">variable</code></td>
<td>
<p>deprecated, use variables instead</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Underneath this function calls the <code><a href="ingredients.html#topic+partial_dependence">partial_dependence</a></code> or
<code><a href="ingredients.html#topic+accumulated_dependence">accumulated_dependence</a></code> functions from the <code>ingredients</code> package.
</p>


<h3>Value</h3>

<p>An object of the class <code>model_profile</code>.
It's a data frame with calculated average model responses.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm &lt;- explain(titanic_glm_model, data = titanic_imputed)
model_profile_glm_fare &lt;- model_profile(explainer_glm, "fare")
plot(model_profile_glm_fare)

 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed)
model_profile_ranger &lt;- model_profile(explainer_ranger)
plot(model_profile_ranger, geom = "profiles")

model_profile_ranger_1 &lt;- model_profile(explainer_ranger, type = "partial",
                                        variables = c("age", "fare"))
plot(model_profile_ranger_1 , variables = c("age", "fare"), geom = "points")

model_profile_ranger_2  &lt;- model_profile(explainer_ranger, type = "partial", k = 3)
plot(model_profile_ranger_2 , geom = "profiles")

model_profile_ranger_3  &lt;- model_profile(explainer_ranger, type = "partial", groups = "gender")
plot(model_profile_ranger_3 , geom = "profiles")

model_profile_ranger_4  &lt;- model_profile(explainer_ranger, type = "accumulated")
plot(model_profile_ranger_4 , geom = "profiles")

# Multiple profiles
model_profile_ranger_fare &lt;- model_profile(explainer_ranger, "fare")
plot(model_profile_ranger_fare, model_profile_glm_fare)
 

</code></pre>

<hr>
<h2 id='plot.list'>Plot List of Explanations</h2><span id='topic+plot.list'></span>

<h3>Description</h3>

<p>Plot List of Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'list'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.list_+3A_x">x</code></td>
<td>
<p>a list of explanations of the same class</p>
</td></tr>
<tr><td><code id="plot.list_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ggplot</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed[,-8],
                             y = titanic_imputed$survived)
mp_ranger &lt;- model_performance(explainer_ranger)

titanic_ranger_model2 &lt;- ranger(survived~gender + fare, data = titanic_imputed,
                                num.trees = 50, probability = TRUE)
explainer_ranger2  &lt;- explain(titanic_ranger_model2, data = titanic_imputed[,-8],
                              y = titanic_imputed$survived,
                              label = "ranger2")
mp_ranger2 &lt;- model_performance(explainer_ranger2)

plot(list(mp_ranger, mp_ranger2), geom = "prc")
plot(list(mp_ranger, mp_ranger2), geom = "roc")
tmp &lt;- list(mp_ranger, mp_ranger2)
names(tmp) &lt;- c("ranger", "ranger2")
plot(tmp)


</code></pre>

<hr>
<h2 id='plot.model_diagnostics'>Plot Dataset Level Model Diagnostics</h2><span id='topic+plot.model_diagnostics'></span>

<h3>Description</h3>

<p>Plot Dataset Level Model Diagnostics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_diagnostics'
plot(x, ..., variable = "y_hat", yvariable = "residuals", smooth = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.model_diagnostics_+3A_x">x</code></td>
<td>
<p>a data.frame to be explained, preprocessed by the <code><a href="#topic+model_diagnostics">model_diagnostics</a></code> function</p>
</td></tr>
<tr><td><code id="plot.model_diagnostics_+3A_...">...</code></td>
<td>
<p>other object to be included to the plot</p>
</td></tr>
<tr><td><code id="plot.model_diagnostics_+3A_variable">variable</code></td>
<td>
<p>character - name of the variable on OX axis to be explained, by default <code>y_hat</code></p>
</td></tr>
<tr><td><code id="plot.model_diagnostics_+3A_yvariable">yvariable</code></td>
<td>
<p>character - name of the variable on OY axis, by default <code>residuals</code></p>
</td></tr>
<tr><td><code id="plot.model_diagnostics_+3A_smooth">smooth</code></td>
<td>
<p>logical shall the smooth line be added</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of the class <code>model_diagnostics_explainer</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>apartments_lm_model &lt;- lm(m2.price ~ ., data = apartments)
explainer_lm &lt;- explain(apartments_lm_model,
                         data = apartments,
                         y = apartments$m2.price)
diag_lm &lt;- model_diagnostics(explainer_lm)
diag_lm
plot(diag_lm)

library("ranger")
apartments_ranger_model &lt;- ranger(m2.price ~ ., data = apartments)
explainer_ranger &lt;- explain(apartments_ranger_model,
                         data = apartments,
                         y = apartments$m2.price)
diag_ranger &lt;- model_diagnostics(explainer_ranger)
diag_ranger
plot(diag_ranger)
plot(diag_ranger, diag_lm)
plot(diag_ranger, diag_lm, variable = "y")
plot(diag_ranger, diag_lm, variable = "construction.year")
plot(diag_ranger, variable = "y", yvariable = "y_hat")

</code></pre>

<hr>
<h2 id='plot.model_parts'>Plot Variable Importance Explanations</h2><span id='topic+plot.model_parts'></span>

<h3>Description</h3>

<p>Plot Variable Importance Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_parts'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.model_parts_+3A_x">x</code></td>
<td>
<p>an object of the class <code>model_parts</code></p>
</td></tr>
<tr><td><code id="plot.model_parts_+3A_...">...</code></td>
<td>
<p>other parameters described below</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ggplot</code>.
</p>


<h3>Plot options</h3>



<h4>variable_importance</h4>


<ul>
<li><p><code>max_vars</code> maximal number of features to be included in the plot. default value is <code>10</code>
</p>
</li>
<li><p><code>show_boxplots</code> logical if <code>TRUE</code> (default) boxplot will be plotted to show permutation data.
</p>
</li>
<li><p><code>bar_width</code> width of bars. By default <code>10</code>
</p>
</li>
<li><p><code>desc_sorting</code> logical. Should the bars be sorted descending? By default <code>TRUE</code>
</p>
</li>
<li><p><code>title</code> the plot's title, by default <code>'Feature Importance'</code>
</p>
</li>
<li><p><code>subtitle</code> a character. Plot subtitle. By default <code>NULL</code> - then subtitle is set to &quot;created for the XXX, YYY model&quot;,
where XXX, YYY are labels of given explainers.
</p>
</li></ul>



<hr>
<h2 id='plot.model_performance'>Plot Dataset Level Model Performance Explanations</h2><span id='topic+plot.model_performance'></span>

<h3>Description</h3>

<p>Plot Dataset Level Model Performance Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_performance'
plot(
  x,
  ...,
  geom = "ecdf",
  show_outliers = 0,
  ptlabel = "name",
  lossFunction = loss_function,
  loss_function = function(x) sqrt(mean(x^2))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.model_performance_+3A_x">x</code></td>
<td>
<p>a model to be explained, preprocessed by the <code><a href="#topic+explain">explain</a></code> function</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_geom">geom</code></td>
<td>
<p>either <code>"prc"</code>, <code>"roc"</code>, <code>"ecdf"</code>, <code>"boxplot"</code>, <code>"gain"</code>, <code>"lift"</code> or <code>"histogram"</code> determines how residuals shall be summarized</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_show_outliers">show_outliers</code></td>
<td>
<p>number of largest residuals to be presented (only when geom = boxplot).</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_ptlabel">ptlabel</code></td>
<td>
<p>either <code>"name"</code> or <code>"index"</code> determines the naming convention of the outliers</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_lossfunction">lossFunction</code></td>
<td>
<p>alias for <code>loss_function</code> held for backwards compatibility.</p>
</td></tr>
<tr><td><code id="plot.model_performance_+3A_loss_function">loss_function</code></td>
<td>
<p>function that calculates the loss for a model based on model residuals. By default it's the root mean square. NOTE that this argument was called <code>lossFunction</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>model_performance</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed[,-8],
                             y = titanic_imputed$survived)
mp_ranger &lt;- model_performance(explainer_ranger)
plot(mp_ranger)
plot(mp_ranger, geom = "boxplot", show_outliers = 1)

titanic_ranger_model2 &lt;- ranger(survived~gender + fare, data = titanic_imputed,
                                num.trees = 50, probability = TRUE)
explainer_ranger2  &lt;- explain(titanic_ranger_model2, data = titanic_imputed[,-8],
                              y = titanic_imputed$survived,
                              label = "ranger2")
mp_ranger2 &lt;- model_performance(explainer_ranger2)
plot(mp_ranger, mp_ranger2, geom = "prc")
plot(mp_ranger, mp_ranger2, geom = "roc")
plot(mp_ranger, mp_ranger2, geom = "lift")
plot(mp_ranger, mp_ranger2, geom = "gain")
plot(mp_ranger, mp_ranger2, geom = "boxplot")
plot(mp_ranger, mp_ranger2, geom = "histogram")
plot(mp_ranger, mp_ranger2, geom = "ecdf")

titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm &lt;- explain(titanic_glm_model, data = titanic_imputed[,-8],
                         y = titanic_imputed$survived, label = "glm",
                    predict_function = function(m,x) predict.glm(m,x,type = "response"))
mp_glm &lt;- model_performance(explainer_glm)
plot(mp_glm)

titanic_lm_model &lt;- lm(survived~., data = titanic_imputed)
explainer_lm &lt;- explain(titanic_lm_model, data = titanic_imputed[,-8],
                        y = titanic_imputed$survived, label = "lm")
mp_lm &lt;- model_performance(explainer_lm)
plot(mp_lm)

plot(mp_ranger, mp_glm, mp_lm)
plot(mp_ranger, mp_glm, mp_lm, geom = "boxplot")
plot(mp_ranger, mp_glm, mp_lm, geom = "boxplot", show_outliers = 1)


</code></pre>

<hr>
<h2 id='plot.model_profile'>Plot Dataset Level Model Profile Explanations</h2><span id='topic+plot.model_profile'></span>

<h3>Description</h3>

<p>Plot Dataset Level Model Profile Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_profile'
plot(x, ..., geom = "aggregates")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.model_profile_+3A_x">x</code></td>
<td>
<p>a variable profile explanation, created with the <code><a href="#topic+model_profile">model_profile</a></code> function</p>
</td></tr>
<tr><td><code id="plot.model_profile_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="plot.model_profile_+3A_geom">geom</code></td>
<td>
<p>either <code>"aggregates"</code>, <code>"profiles"</code>, <code>"points"</code> determines which will be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ggplot</code>.
</p>


<h4>aggregates</h4>


<ul>
<li><p><code>color</code> a character. Either name of a color, or hex code for a color,
or <code>_label_</code> if models shall be colored, or <code>_ids_</code> if instances shall be colored
</p>
</li>
<li><p><code>size</code> a numeric. Size of lines to be plotted
</p>
</li>
<li><p><code>alpha</code> a numeric between <code>0</code> and <code>1</code>. Opacity of lines
</p>
</li>
<li><p><code>facet_ncol</code> number of columns for the <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>
</p>
</li>
<li><p><code>variables</code> if not <code>NULL</code> then only <code>variables</code> will be presented
</p>
</li>
<li><p><code>title</code> a character. Partial and accumulated dependence explainers have deafult value.
</p>
</li>
<li><p><code>subtitle</code> a character. If <code>NULL</code> value will be dependent on model usage.
</p>
</li></ul>




<h3>Examples</h3>

<pre><code class='language-R'>titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm &lt;- explain(titanic_glm_model, data = titanic_imputed)
expl_glm &lt;- model_profile(explainer_glm, "fare")
plot(expl_glm)

 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed)
expl_ranger &lt;- model_profile(explainer_ranger)
plot(expl_ranger)
plot(expl_ranger, geom = "aggregates")

vp_ra &lt;- model_profile(explainer_ranger, type = "partial", variables = c("age", "fare"))
plot(vp_ra, variables = c("age", "fare"), geom = "points")

vp_ra &lt;- model_profile(explainer_ranger, type = "partial", k = 3)
plot(vp_ra)
plot(vp_ra, geom = "profiles")
plot(vp_ra, geom = "points")

vp_ra &lt;- model_profile(explainer_ranger, type = "partial", groups = "gender")
plot(vp_ra)
plot(vp_ra, geom = "profiles")
plot(vp_ra, geom = "points")

vp_ra &lt;- model_profile(explainer_ranger, type = "accumulated")
plot(vp_ra)
plot(vp_ra, geom = "profiles")
plot(vp_ra, geom = "points")
 

</code></pre>

<hr>
<h2 id='plot.predict_diagnostics'>Plot Instance Level Residual Diagnostics</h2><span id='topic+plot.predict_diagnostics'></span>

<h3>Description</h3>

<p>Plot Instance Level Residual Diagnostics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predict_diagnostics'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.predict_diagnostics_+3A_x">x</code></td>
<td>
<p>an object with instance level residual diagnostics created with <code><a href="#topic+predict_diagnostics">predict_diagnostics</a></code> function</p>
</td></tr>
<tr><td><code id="plot.predict_diagnostics_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to <code>plot.ceteris_paribus_explaine</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>ggplot2</code> object of the class <code>gg</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("ranger")
titanic_glm_model &lt;- ranger(survived ~ gender + age + class + fare + sibsp + parch,
                     data = titanic_imputed)
explainer_glm &lt;- explain(titanic_glm_model,
                         data = titanic_imputed,
                         y = titanic_imputed$survived)
johny_d &lt;- titanic_imputed[24, c("gender", "age", "class", "fare", "sibsp", "parch")]

pl &lt;- predict_diagnostics(explainer_glm, johny_d, variables = NULL)
plot(pl)

pl &lt;- predict_diagnostics(explainer_glm, johny_d,
                       neighbors = 10,
                       variables = c("age", "fare"))
plot(pl)

pl &lt;- predict_diagnostics(explainer_glm,
                       johny_d,
                       neighbors = 10,
                       variables = c("class", "gender"))
plot(pl)


</code></pre>

<hr>
<h2 id='plot.predict_parts'>Plot Variable Attribution Explanations</h2><span id='topic+plot.predict_parts'></span>

<h3>Description</h3>

<p>Plot Variable Attribution Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predict_parts'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.predict_parts_+3A_x">x</code></td>
<td>
<p>an object of the class <code>predict_parts</code></p>
</td></tr>
<tr><td><code id="plot.predict_parts_+3A_...">...</code></td>
<td>
<p>other parameters described below</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ggplot</code>.
</p>


<h3>Plot options</h3>



<h4>break_down</h4>


<ul>
<li><p><code>max_features</code> maximal number of features to be included in the plot. default value is <code>10</code>
</p>
</li>
<li><p><code>min_max</code> a range of OX axis. By default <code>NA</code>, therefore it will be extracted from the contributions of <code>x</code>.
But it can be set to some constants, useful if these plots are to be used for comparisons.
</p>
</li>
<li><p><code>add_contributions</code> if <code>TRUE</code>, variable contributions will be added to the plot.
</p>
</li>
<li><p><code>shift_contributions</code> number describing how much labels should be shifted to the right, as a fraction of range. By default equal to <code>0.05</code>.
</p>
</li>
<li><p><code>vcolors</code> If <code>NA</code> (default), DrWhy colors are used.
</p>
</li>
<li><p><code>vnames</code> a character vector, if specified then will be used as labels on OY axis. By default <code>NULL</code>.
</p>
</li>
<li><p><code>digits</code> number of decimal places (<code><a href="base.html#topic+round">round</a></code>) or significant digits (<code><a href="base.html#topic+signif">signif</a></code>) to be used.
</p>
</li>
<li><p><code>rounding_function</code> a function to be used for rounding numbers.
</p>
</li>
<li><p><code>plot_distributions</code> if <code>TRUE</code> then distributions of conditional propotions will be plotted. This requires <code>keep_distributions=TRUE</code> in the
<code><a href="iBreakDown.html#topic+break_down">break_down</a></code>, <code><a href="iBreakDown.html#topic+local_attributions">local_attributions</a></code>, or <code><a href="iBreakDown.html#topic+local_interactions">local_interactions</a></code>.
</p>
</li>
<li><p><code>baseline</code> if numeric then veritical line starts in <code>baseline</code>.
</p>
</li>
<li><p><code>title</code> a character. Plot title. By default <code>"Break Down profile"</code>.
</p>
</li>
<li><p><code>subtitle</code> a character. Plot subtitle. By default <code>NULL</code> - then subtitle is set to &quot;created for the XXX, YYY model&quot;,
where XXX, YYY are labels of given explainers.
</p>
</li>
<li><p><code>max_vars</code> alias for the <code>max_features</code> parameter.
</p>
</li></ul>




<h4>shap</h4>


<ul>
<li><p><code>show_boxplots</code> logical if <code>TRUE</code> (default) boxplot will be plotted to show uncertanity of attributions.
</p>
</li>
<li><p><code>vcolors</code> If <code>NA</code> (default), DrWhy colors are used.
</p>
</li>
<li><p><code>max_features</code> maximal number of features to be included in the plot. default value is <code>10</code>
</p>
</li>
<li><p><code>max_vars</code> alias for the <code>max_features</code> parameter.
</p>
</li></ul>




<h4>oscillations</h4>


<ul>
<li><p><code>bar_width</code> width of bars. By default <code>10</code>
</p>
</li></ul>



<hr>
<h2 id='plot.predict_profile'>Plot Variable Profile Explanations</h2><span id='topic+plot.predict_profile'></span>

<h3>Description</h3>

<p>Plot Variable Profile Explanations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predict_profile'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.predict_profile_+3A_x">x</code></td>
<td>
<p>an object of the class <code>predict_profile</code></p>
</td></tr>
<tr><td><code id="plot.predict_profile_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ggplot</code>.
</p>


<h3>Plot options</h3>



<h4>ceteris_paribus</h4>


<ul>
<li><p><code>color</code> a character. Either name of a color or name of a variable that should be used for coloring
</p>
</li>
<li><p><code>size</code> a numeric. Size of lines to be plotted
</p>
</li>
<li><p><code>alpha</code> a numeric between <code>0</code> and <code>1</code>. Opacity of lines
</p>
</li>
<li><p><code>facet_ncol</code> number of columns for the <code><a href="ggplot2.html#topic+facet_wrap">facet_wrap</a></code>
</p>
</li>
<li><p><code>variables</code> if not <code>NULL</code> then only <code>variables</code> will be presented
</p>
</li>
<li><p><code>variable_type</code> a character. If <code>numerical</code> then only numerical variables will be plotted.
If <code>categorical</code> then only categorical variables will be plotted.
</p>
</li>
<li><p><code>title</code> a character. Plot title. By default <code>"Ceteris Paribus profile"</code>.
</p>
</li>
<li><p><code>subtitle</code> a character. Plot subtitle. By default <code>NULL</code> - then subtitle is set to &quot;created for the XXX, YYY model&quot;,
where XXX, YYY are labels of given explainers.
</p>
</li>
<li><p><code>categorical_type</code> a character. How categorical variables shall be plotted? Either <code>"lines"</code> (default) or <code>"bars"</code>.
</p>
</li></ul>



<hr>
<h2 id='plot.shap_aggregated'>Plot Generic for Break Down Objects</h2><span id='topic+plot.shap_aggregated'></span>

<h3>Description</h3>

<p>Displays a waterfall aggregated shap plot for objects of <code>shap_aggregated</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'shap_aggregated'
plot(
  x,
  ...,
  shift_contributions = 0.05,
  add_contributions = TRUE,
  add_boxplots = TRUE,
  max_features = 10,
  title = "Aggregated SHAP"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.shap_aggregated_+3A_x">x</code></td>
<td>
<p>an explanation object created with function <code><a href="#topic+explain">explain</a></code>.</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_...">...</code></td>
<td>
<p>other parameters like <code>vcolors</code>, <code>vnames</code>, <code>min_max</code>, <code>digits</code>, <code>rounding_function</code>, <code>baseline</code>, <code>subtitle</code>, <code>baseline</code>, <code>max_vars</code>.</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_shift_contributions">shift_contributions</code></td>
<td>
<p>number describing how much labels should be shifted to the right, as a fraction of range. By default equal to <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_add_contributions">add_contributions</code></td>
<td>
<p>if <code>TRUE</code>, variable contributions will be added to the plot</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_add_boxplots">add_boxplots</code></td>
<td>
<p>if <code>TRUE</code>, boxplots of SHAP will be shown</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_max_features">max_features</code></td>
<td>
<p>maximal number of features to be included in the plot. default value is <code>10</code>.</p>
</td></tr>
<tr><td><code id="plot.shap_aggregated_+3A_title">title</code></td>
<td>
<p>a character. Plot title. By default <code>"Break Down profile"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>ggplot2</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("DALEX")
set.seed(1313)
model_titanic_glm &lt;- glm(survived ~ gender + age + fare,
                       data = titanic_imputed, family = "binomial")
explain_titanic_glm &lt;- explain(model_titanic_glm,
                           data = titanic_imputed,
                           y = titanic_imputed$survived,
                           label = "glm")


bd_glm &lt;- shap_aggregated(explain_titanic_glm, titanic_imputed[1:10, ])
bd_glm
plot(bd_glm)
plot(bd_glm, max_features = 3)
plot(bd_glm, max_features = 3,
     vnames = c("average","+ male","+ young","+ cheap ticket", "+ other factors", "final"))


</code></pre>

<hr>
<h2 id='predict_diagnostics'>Instance Level Residual Diagnostics</h2><span id='topic+predict_diagnostics'></span><span id='topic+individual_diagnostics'></span>

<h3>Description</h3>

<p>This function performs local diagnostic of residuals.
For a single instance its neighbors are identified in the validation data.
Residuals are calculated for neighbors and plotted against residuals for all data.
Find information how to use this function here: <a href="https://ema.drwhy.ai/localDiagnostics.html">https://ema.drwhy.ai/localDiagnostics.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_diagnostics(
  explainer,
  new_observation,
  variables = NULL,
  ...,
  nbins = 20,
  neighbors = 50,
  distance = gower::gower_dist
)

individual_diagnostics(
  explainer,
  new_observation,
  variables = NULL,
  ...,
  nbins = 20,
  neighbors = 50,
  distance = gower::gower_dist
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_diagnostics_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the 'explain' function</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_new_observation">new_observation</code></td>
<td>
<p>a new observation for which predictions need to be explained</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_variables">variables</code></td>
<td>
<p>character - name of variables to be explained</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_nbins">nbins</code></td>
<td>
<p>number of bins for the histogram. By default 20</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_neighbors">neighbors</code></td>
<td>
<p>number of neighbors for histogram. By default 50.</p>
</td></tr>
<tr><td><code id="predict_diagnostics_+3A_distance">distance</code></td>
<td>
<p>the distance function, by default the <code>gower_dist()</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class 'predict_diagnostics'.
It's a data frame with calculated distribution of residuals.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("ranger")
titanic_glm_model &lt;- ranger(survived ~ gender + age + class + fare + sibsp + parch,
                     data = titanic_imputed)
explainer_glm &lt;- explain(titanic_glm_model,
                         data = titanic_imputed,
                         y = titanic_imputed$survived)
johny_d &lt;- titanic_imputed[24, c("gender", "age", "class", "fare", "sibsp", "parch")]

id_johny &lt;- predict_diagnostics(explainer_glm, johny_d, variables = NULL)
id_johny
plot(id_johny)

id_johny &lt;- predict_diagnostics(explainer_glm, johny_d,
                       neighbors = 10,
                       variables = c("age", "fare"))
id_johny
plot(id_johny)

id_johny &lt;- predict_diagnostics(explainer_glm,
                       johny_d,
                       neighbors = 10,
                       variables = c("class", "gender"))
id_johny
plot(id_johny)


</code></pre>

<hr>
<h2 id='predict_parts'>Instance Level Parts of the Model Predictions</h2><span id='topic+predict_parts'></span><span id='topic+predict_parts_break_down'></span><span id='topic+predict_parts_ibreak_down'></span><span id='topic+predict_parts_shap'></span><span id='topic+predict_parts_oscillations'></span><span id='topic+predict_parts_oscillations_uni'></span><span id='topic+predict_parts_oscillations_emp'></span><span id='topic+predict_parts_break_down_interactions'></span><span id='topic+predict_parts_shap_aggregated'></span><span id='topic+variable_attribution'></span>

<h3>Description</h3>

<p>Instance Level Variable Attributions as Break Down, SHAP, aggregated SHAP or Oscillations explanations.
Model prediction is decomposed into parts that are attributed for particular variables.
From DALEX version 1.0 this function calls the <code><a href="iBreakDown.html#topic+break_down">break_down</a></code> or
<code><a href="iBreakDown.html#topic+break_down_uncertainty">shap</a></code> functions from the <code>iBreakDown</code> package or
<code><a href="ingredients.html#topic+ceteris_paribus">ceteris_paribus</a></code> from the <code>ingredients</code> package.
Find information how to use the <code>break_down</code> method here: <a href="https://ema.drwhy.ai/breakDown.html">https://ema.drwhy.ai/breakDown.html</a>.
Find information how to use the <code>shap</code> method here: <a href="https://ema.drwhy.ai/shapley.html">https://ema.drwhy.ai/shapley.html</a>.
Find information how to use the <code>oscillations</code> method here: <a href="https://ema.drwhy.ai/ceterisParibusOscillations.html">https://ema.drwhy.ai/ceterisParibusOscillations.html</a>.
aSHAP method provides explanations for a set of observations based on SHAP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_parts(
  explainer,
  new_observation,
  ...,
  N = if (substr(type, 1, 4) == "osci") 500 else NULL,
  type = "break_down"
)

predict_parts_oscillations(explainer, new_observation, ...)

predict_parts_oscillations_uni(
  explainer,
  new_observation,
  variable_splits_type = "uniform",
  ...
)

predict_parts_oscillations_emp(
  explainer,
  new_observation,
  variable_splits = NULL,
  variables = colnames(explainer$data),
  ...
)

predict_parts_break_down(explainer, new_observation, ...)

predict_parts_break_down_interactions(explainer, new_observation, ...)

predict_parts_shap(explainer, new_observation, ...)

predict_parts_shap_aggregated(explainer, new_observation, ...)

variable_attribution(
  explainer,
  new_observation,
  ...,
  N = if (substr(type, 1, 4) == "osci") 500 else NULL,
  type = "break_down"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_parts_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_new_observation">new_observation</code></td>
<td>
<p>a new observation for which predictions need to be explained</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to <code>iBreakDown::break_down</code></p>
</td></tr>
<tr><td><code id="predict_parts_+3A_n">N</code></td>
<td>
<p>the maximum number of observations used for calculation of attributions. By default NULL (use all) or 500 (for oscillations).</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_type">type</code></td>
<td>
<p>the type of variable attributions. Either <code>shap</code>, <code>aggregated_shap</code>, <code>oscillations</code>, <code>oscillations_uni</code>,
<code>oscillations_emp</code>, <code>break_down</code> or <code>break_down_interactions</code>.</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_variable_splits_type">variable_splits_type</code></td>
<td>
<p>how variable grids shall be calculated? Will be passed to <code><a href="ingredients.html#topic+ceteris_paribus">ceteris_paribus</a></code>.</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_variable_splits">variable_splits</code></td>
<td>
<p>named list of splits for variables. It is used by oscillations based measures. Will be passed to <code><a href="ingredients.html#topic+ceteris_paribus">ceteris_paribus</a></code>.</p>
</td></tr>
<tr><td><code id="predict_parts_+3A_variables">variables</code></td>
<td>
<p>names of variables for which splits shall be calculated. Will be passed to <code><a href="ingredients.html#topic+ceteris_paribus">ceteris_paribus</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the <code>type</code> there are different classes of the resulting object.
It's a data frame with calculated average response.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DALEX)

new_dragon &lt;- data.frame(
    year_of_birth = 200,
    height = 80,
    weight = 12.5,
    scars = 0,
    number_of_lost_teeth  = 5
)

model_lm &lt;- lm(life_length ~ year_of_birth + height +
               weight + scars + number_of_lost_teeth,
               data = dragons)

explainer_lm &lt;- explain(model_lm,
                        data = dragons,
                        y = dragons$year_of_birth,
                        label = "model_lm")

bd_lm &lt;- predict_parts_break_down(explainer_lm, new_observation = new_dragon)
head(bd_lm)
plot(bd_lm)


library("ranger")
model_ranger &lt;- ranger(life_length ~ year_of_birth + height +
                       weight + scars + number_of_lost_teeth,
                       data = dragons, num.trees = 50)

explainer_ranger &lt;- explain(model_ranger,
                            data = dragons,
                            y = dragons$year_of_birth,
                            label = "model_ranger")

bd_ranger &lt;- predict_parts_break_down(explainer_ranger, new_observation = new_dragon)
head(bd_ranger)
plot(bd_ranger)


</code></pre>

<hr>
<h2 id='predict_profile'>Instance Level Profile as Ceteris Paribus</h2><span id='topic+predict_profile'></span><span id='topic+individual_profile'></span>

<h3>Description</h3>

<p>This function calculated individual profiles aka Ceteris Paribus Profiles.
From DALEX version 1.0 this function calls the <code><a href="ingredients.html#topic+ceteris_paribus">ceteris_paribus</a></code> from the <code>ingredients</code> package.
Find information how to use this function here: <a href="https://ema.drwhy.ai/ceterisParibus.html">https://ema.drwhy.ai/ceterisParibus.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_profile(
  explainer,
  new_observation,
  variables = NULL,
  ...,
  type = "ceteris_paribus",
  variable_splits_type = "uniform"
)

individual_profile(
  explainer,
  new_observation,
  variables = NULL,
  ...,
  type = "ceteris_paribus",
  variable_splits_type = "uniform"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_profile_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="predict_profile_+3A_new_observation">new_observation</code></td>
<td>
<p>a new observation for which predictions need to be explained</p>
</td></tr>
<tr><td><code id="predict_profile_+3A_variables">variables</code></td>
<td>
<p>character - names of variables to be explained</p>
</td></tr>
<tr><td><code id="predict_profile_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="predict_profile_+3A_type">type</code></td>
<td>
<p>character, currently only the <code>ceteris_paribus</code> is implemented</p>
</td></tr>
<tr><td><code id="predict_profile_+3A_variable_splits_type">variable_splits_type</code></td>
<td>
<p>how variable grids shall be calculated? Use &quot;quantiles&quot; (default) for percentiles or &quot;uniform&quot; to get uniform grid of points. Will be passed to 'ingredients'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>ceteris_paribus_explainer</code>.
It's a data frame with calculated average response.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>new_dragon &lt;- data.frame(year_of_birth = 200,
     height = 80,
     weight = 12.5,
     scars = 0,
     number_of_lost_teeth  = 5)

dragon_lm_model4 &lt;- lm(life_length ~ year_of_birth + height +
                                     weight + scars + number_of_lost_teeth,
                       data = dragons)
dragon_lm_explainer4 &lt;- explain(dragon_lm_model4, data = dragons, y = dragons$year_of_birth,
                                label = "model_4v")
dragon_lm_predict4 &lt;- predict_profile(dragon_lm_explainer4,
                new_observation = new_dragon,
                variables = c("year_of_birth", "height", "scars"))
head(dragon_lm_predict4)
plot(dragon_lm_predict4,
    variables = c("year_of_birth", "height", "scars"))


library("ranger")
dragon_ranger_model4 &lt;- ranger(life_length ~ year_of_birth + height +
                                               weight + scars + number_of_lost_teeth,
                                 data = dragons, num.trees = 50)
dragon_ranger_explainer4 &lt;- explain(dragon_ranger_model4, data = dragons, y = dragons$year_of_birth,
                                label = "model_ranger")
dragon_ranger_predict4 &lt;- predict_profile(dragon_ranger_explainer4,
                                           new_observation = new_dragon,
                                           variables = c("year_of_birth", "height", "scars"))
head(dragon_ranger_predict4)
plot(dragon_ranger_predict4,
    variables = c("year_of_birth", "height", "scars"))
 

</code></pre>

<hr>
<h2 id='predict.explainer'>Predictions for the Explainer</h2><span id='topic+predict.explainer'></span><span id='topic+model_prediction'></span>

<h3>Description</h3>

<p>This is a generic <code>predict()</code> function works for <code>explainer</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explainer'
predict(object, newdata, ...)

model_prediction(explainer, new_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.explainer_+3A_object">object</code></td>
<td>
<p>a model to be explained, object of the class <code>explainer</code></p>
</td></tr>
<tr><td><code id="predict.explainer_+3A_newdata">newdata</code></td>
<td>
<p>data.frame or matrix - observations for prediction</p>
</td></tr>
<tr><td><code id="predict.explainer_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to the predict function</p>
</td></tr>
<tr><td><code id="predict.explainer_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, object of the class <code>explainer</code></p>
</td></tr>
<tr><td><code id="predict.explainer_+3A_new_data">new_data</code></td>
<td>
<p>data.frame or matrix - observations for prediction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An numeric matrix of predictions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HR_glm_model &lt;- glm(status == "fired"~., data = HR, family = "binomial")
explainer_glm &lt;- explain(HR_glm_model, data = HR)
predict(explainer_glm, HR[1:3,])

 
library("ranger")
HR_ranger_model &lt;- ranger(status~., data = HR, num.trees = 50, probability = TRUE)
explainer_ranger  &lt;- explain(HR_ranger_model, data = HR)
predict(explainer_ranger, HR[1:3,])

model_prediction(explainer_ranger, HR[1:3,])
 
</code></pre>

<hr>
<h2 id='print.description'>Print Natural Language Descriptions</h2><span id='topic+print.description'></span>

<h3>Description</h3>

<p>Generic function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'description'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.description_+3A_x">x</code></td>
<td>
<p>an individual explainer produced with the 'describe()' function</p>
</td></tr>
<tr><td><code id="print.description_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>

<hr>
<h2 id='print.explainer'>Print Explainer Summary</h2><span id='topic+print.explainer'></span>

<h3>Description</h3>

<p>Print Explainer Summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explainer'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.explainer_+3A_x">x</code></td>
<td>
<p>a model explainer created with the 'explain' function</p>
</td></tr>
<tr><td><code id="print.explainer_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
aps_lm_model4 &lt;- lm(m2.price~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, y = apartments$m2.price,
                             label = "model_4v")
aps_lm_explainer4

 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed[,-8],
                             y = titanic_imputed$survived,
                             label = "model_ranger")
explainer_ranger
 

</code></pre>

<hr>
<h2 id='print.model_diagnostics'>Print Dataset Level Model Diagnostics</h2><span id='topic+print.model_diagnostics'></span>

<h3>Description</h3>

<p>Generic function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_diagnostics'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.model_diagnostics_+3A_x">x</code></td>
<td>
<p>an object with dataset level residual diagnostics created with <code><a href="#topic+model_diagnostics">model_diagnostics</a></code> function</p>
</td></tr>
<tr><td><code id="print.model_diagnostics_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>

<hr>
<h2 id='print.model_info'>Print model_info</h2><span id='topic+print.model_info'></span>

<h3>Description</h3>

<p>Function prints object of class <code>model_info</code> created with <code><a href="#topic+model_info">model_info</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_info'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.model_info_+3A_x">x</code></td>
<td>
<p>- an object of class <code>model_info</code></p>
</td></tr>
<tr><td><code id="print.model_info_+3A_...">...</code></td>
<td>
<p>- other parameters</p>
</td></tr>
</table>

<hr>
<h2 id='print.model_performance'>Print Dataset Level Model Performance Summary</h2><span id='topic+print.model_performance'></span>

<h3>Description</h3>

<p>Print Dataset Level Model Performance Summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_performance'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.model_performance_+3A_x">x</code></td>
<td>
<p>a model to be explained, object of the class 'model_performance_explainer'</p>
</td></tr>
<tr><td><code id="print.model_performance_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'> 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 100,
                               probability = TRUE)
# It's a good practice to pass data without target variable
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed[,-8],
                             y = titanic_imputed$survived)
# resulting dataframe has predicted values and residuals
mp_ex_rn &lt;- model_performance(explainer_ranger)
mp_ex_rn
plot(mp_ex_rn)
 

</code></pre>

<hr>
<h2 id='print.model_profile'>Print Dataset Level Model Profile</h2><span id='topic+print.model_profile'></span>

<h3>Description</h3>

<p>Generic function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model_profile'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.model_profile_+3A_x">x</code></td>
<td>
<p>an object with dataset level profile created with <code><a href="#topic+model_profile">model_profile</a></code> function</p>
</td></tr>
<tr><td><code id="print.model_profile_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>

<hr>
<h2 id='print.predict_diagnostics'>Print Instance Level Residual Diagnostics</h2><span id='topic+print.predict_diagnostics'></span>

<h3>Description</h3>

<p>Generic function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predict_diagnostics'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.predict_diagnostics_+3A_x">x</code></td>
<td>
<p>an object with instance level residual diagnostics created with <code><a href="#topic+predict_diagnostics">predict_diagnostics</a></code> function</p>
</td></tr>
<tr><td><code id="print.predict_diagnostics_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>

<hr>
<h2 id='set_theme_dalex'>Default Theme for DALEX plots</h2><span id='topic+set_theme_dalex'></span><span id='topic+theme_default_dalex'></span><span id='topic+theme_vertical_default_dalex'></span>

<h3>Description</h3>

<p>Default Theme for DALEX plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_theme_dalex(
  default_theme = "drwhy",
  default_theme_vertical = default_theme
)

theme_default_dalex()

theme_vertical_default_dalex()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_theme_dalex_+3A_default_theme">default_theme</code></td>
<td>
<p>object - string (&quot;drwhy&quot; or &quot;ema&quot;) or an object of ggplot theme class. Will be applied by default by DALEX to all horizontal plots</p>
</td></tr>
<tr><td><code id="set_theme_dalex_+3A_default_theme_vertical">default_theme_vertical</code></td>
<td>
<p>object - string (&quot;drwhy&quot; or &quot;ema&quot;) or an object of ggplot theme class. Will be applied by default by DALEX to all vertical plots</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with current default themes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>old &lt;- set_theme_dalex("ema")

library("ranger")
apartments_ranger_model &lt;- ranger(m2.price~., data = apartments, num.trees = 50)
explainer_ranger  &lt;- explain(apartments_ranger_model, data = apartments[,-1],
                             y = apartments$m2.price, label = "Ranger Apartments")
model_parts_ranger_aps &lt;- model_parts(explainer_ranger, type = "raw")
head(model_parts_ranger_aps, 8)
plot(model_parts_ranger_aps)

old &lt;- set_theme_dalex(ggplot2::theme_void(), ggplot2::theme_void())
plot(model_parts_ranger_aps)

old &lt;- set_theme_dalex("drwhy")
plot(model_parts_ranger_aps)
old &lt;- set_theme_dalex(ggplot2::theme_void(), ggplot2::theme_void())
plot(model_parts_ranger_aps)


</code></pre>

<hr>
<h2 id='shap_aggregated'>SHAP aggregated values</h2><span id='topic+shap_aggregated'></span>

<h3>Description</h3>

<p>This function works in a similar way to shap function from <code>iBreakDown</code> but it calculates explanations for a set of observation and then aggregates them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shap_aggregated(explainer, new_observations, order = NULL, B = 25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shap_aggregated_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the <code>explain</code> function</p>
</td></tr>
<tr><td><code id="shap_aggregated_+3A_new_observations">new_observations</code></td>
<td>
<p>a set of new observations with columns that correspond to variables used in the model.</p>
</td></tr>
<tr><td><code id="shap_aggregated_+3A_order">order</code></td>
<td>
<p>if not <code>NULL</code>, then it will be a fixed order of variables. It can be a numeric vector or vector with names of variables.</p>
</td></tr>
<tr><td><code id="shap_aggregated_+3A_b">B</code></td>
<td>
<p>number of random paths</p>
</td></tr>
<tr><td><code id="shap_aggregated_+3A_...">...</code></td>
<td>
<p>other parameters like <code>label</code>, <code>predict_function</code>, <code>data</code>, <code>x</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of the <code>shap_aggregated</code> class.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain and Examine Predictive Models. <a href="https://ema.drwhy.ai">https://ema.drwhy.ai</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("DALEX")
set.seed(1313)
model_titanic_glm &lt;- glm(survived ~ gender + age + fare,
                       data = titanic_imputed, family = "binomial")
explain_titanic_glm &lt;- explain(model_titanic_glm,
                           data = titanic_imputed,
                           y = titanic_imputed$survived,
                           label = "glm")


bd_glm &lt;- shap_aggregated(explain_titanic_glm, titanic_imputed[1:10, ])
bd_glm
plot(bd_glm, max_features = 3)

</code></pre>

<hr>
<h2 id='theme_drwhy'>DrWhy Theme for ggplot objects</h2><span id='topic+theme_drwhy'></span><span id='topic+theme_ema'></span><span id='topic+theme_drwhy_vertical'></span><span id='topic+theme_ema_vertical'></span>

<h3>Description</h3>

<p>DrWhy Theme for ggplot objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_drwhy()

theme_ema()

theme_drwhy_vertical()

theme_ema_vertical()
</code></pre>


<h3>Value</h3>

<p>theme for ggplot2 objects
</p>

<hr>
<h2 id='titanic'>Passengers and Crew on the RMS Titanic Data</h2><span id='topic+titanic'></span><span id='topic+titanic_imputed'></span>

<h3>Description</h3>

<p>The <code>titanic</code> data is a complete list of passengers and crew members on  the RMS Titanic.
It includes a variable indicating whether a person did  survive the sinking of the RMS
Titanic on April 15, 1912.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(titanic)
data(titanic_imputed)
</code></pre>


<h3>Format</h3>

<p>a data frame with 2207 rows and 9 columns
</p>


<h3>Details</h3>

<p>This dataset was copied from the <code>stablelearner</code> package and went through few variable
transformations. Levels in <code>embarked</code> was replaced with full names, <code>sibsp</code>, <code>parch</code> and <code>fare</code>
were converted to numerical variables and values for crew were replaced with 0.
If you use this dataset please cite the original package.
</p>
<p>From <code>stablelearner</code>: The website <a href="https://www.encyclopedia-titanica.org">https://www.encyclopedia-titanica.org</a> offers detailed  information about passengers and crew
members on the RMS Titanic. According to the website 1317 passengers and 890 crew member were abord.
8 musicians and 9 employees of the shipyard company are listed as passengers, but travelled with a
free ticket, which is why they have <code>NA</code> values in <code>fare</code>. In addition to that, <code>fare</code>
is truely missing for a few regular passengers.
</p>

<ul>
<li><p> gender a factor with levels <code>male</code> and <code>female</code>.
</p>
</li>
<li><p> age a numeric value with the persons age on the day of the sinking.
</p>
</li>
<li><p> class a factor specifying the class for passengers or the type of service aboard for crew members.
</p>
</li>
<li><p> embarked a factor with the persons place of of embarkment (Belfast/Cherbourg/Queenstown/Southampton).
</p>
</li>
<li><p> country a factor with the persons home country.
</p>
</li>
<li><p> fare a numeric value with the ticket price (<code>0</code> for crew members, musicians and employees of the shipyard company).
</p>
</li>
<li><p> sibsp an ordered factor specifying the number if siblings/spouses aboard; adopted from Vanderbild data set (see below).
</p>
</li>
<li><p> parch an ordered factor specifying the number of parents/children aboard; adopted from Vanderbild data set (see below).
</p>
</li>
<li><p> survived a factor with two levels (<code>no</code> and <code>yes</code>) specifying whether the person has survived the sinking.
</p>
</li></ul>

<p>NOTE: The <code>titanic_imputed</code> dataset use following imputation rules.
</p>

<ul>
<li><p> Missing 'age' is replaced with the mean of the observed ones, i.e., 30.
</p>
</li>
<li><p> For sibsp and parch, missing values are replaced by the most frequently observed value, i.e., 0.
</p>
</li>
<li><p> For fare, mean fare for a given class is used, i.e., 0 pounds for crew, 89 pounds for the 1st, 22 pounds for the 2nd, and 13 pounds for the 3rd class.
</p>
</li></ul>



<h3>Source</h3>

<p>This dataset was copied from the <code>stablelearner</code> package and went through few variable
transformations. The complete list of persons on the RMS titanic was downloaded from
<a href="https://www.encyclopedia-titanica.org">https://www.encyclopedia-titanica.org</a> on April 5, 2016. The  information given
in <code>sibsp</code> and <code>parch</code> was adopoted from a data set obtained from <a href="https://biostat.app.vumc.org/wiki/Main/DataSets">https://biostat.app.vumc.org/wiki/Main/DataSets</a>.
</p>


<h3>References</h3>

<p><a href="https://www.encyclopedia-titanica.org">https://www.encyclopedia-titanica.org</a> and <a href="https://CRAN.R-project.org/package=stablelearner">https://CRAN.R-project.org/package=stablelearner</a>
</p>

<hr>
<h2 id='update_data'>Update data of an explainer object</h2><span id='topic+update_data'></span>

<h3>Description</h3>

<p>Function allows users to update data an y of any explainer in a unified way. It doesn't require knowledge about structre of an explainer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_data(explainer, data, y = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_data_+3A_explainer">explainer</code></td>
<td>
<p>- explainer object that is supposed to be updated.</p>
</td></tr>
<tr><td><code id="update_data_+3A_data">data</code></td>
<td>
<p>- new data, is going to be passed to an explainer</p>
</td></tr>
<tr><td><code id="update_data_+3A_y">y</code></td>
<td>
<p>- new y, is going to be passed to an explainer</p>
</td></tr>
<tr><td><code id="update_data_+3A_verbose">verbose</code></td>
<td>
<p>- logical, indicates if information about update should be printed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>updated explainer object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v")
explainer &lt;- update_data(aps_lm_explainer4, data = apartmentsTest, y = apartmentsTest$m2.price)

</code></pre>

<hr>
<h2 id='update_label'>Update label of explainer object</h2><span id='topic+update_label'></span>

<h3>Description</h3>

<p>Function allows users to update label of any explainer in a unified way. It doesn't require knowledge about structre of an explainer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_label(explainer, label, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_label_+3A_explainer">explainer</code></td>
<td>
<p>- explainer object that is supposed to be updated.</p>
</td></tr>
<tr><td><code id="update_label_+3A_label">label</code></td>
<td>
<p>- new label, is going to be passed to an explainer</p>
</td></tr>
<tr><td><code id="update_label_+3A_verbose">verbose</code></td>
<td>
<p>- logical, indicates if information about update should be printed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>updated explainer object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aps_lm_model4 &lt;- lm(m2.price ~., data = apartments)
aps_lm_explainer4 &lt;- explain(aps_lm_model4, data = apartments, label = "model_4v")
explainer &lt;- update_label(aps_lm_explainer4, label = "lm")
</code></pre>

<hr>
<h2 id='variable_effect'>Dataset Level Variable Effect as Partial Dependency Profile or Accumulated Local Effects</h2><span id='topic+variable_effect'></span><span id='topic+variable_effect_partial_dependency'></span><span id='topic+variable_effect_accumulated_dependency'></span>

<h3>Description</h3>

<p>From DALEX version 1.0 this function calls the <code><a href="ingredients.html#topic+accumulated_dependence">accumulated_dependence</a></code> or
<code><a href="ingredients.html#topic+partial_dependence">partial_dependence</a></code> from the <code>ingredients</code> package.
Find information how to use this function here: <a href="https://ema.drwhy.ai/partialDependenceProfiles.html">https://ema.drwhy.ai/partialDependenceProfiles.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_effect(explainer, variables, ..., type = "partial_dependency")

variable_effect_partial_dependency(explainer, variables, ...)

variable_effect_accumulated_dependency(explainer, variables, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_effect_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the 'explain' function</p>
</td></tr>
<tr><td><code id="variable_effect_+3A_variables">variables</code></td>
<td>
<p>character - names of variables to be explained</p>
</td></tr>
<tr><td><code id="variable_effect_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="variable_effect_+3A_type">type</code></td>
<td>
<p>character - type of the response to be calculated.
Currently following options are implemented: 'partial_dependency' for Partial Dependency and 'accumulated_dependency' for Accumulated Local Effects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class 'aggregated_profiles_explainer'.
It's a data frame with calculated average response.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>titanic_glm_model &lt;- glm(survived~., data = titanic_imputed, family = "binomial")
explainer_glm &lt;- explain(titanic_glm_model, data = titanic_imputed)
expl_glm &lt;- variable_effect(explainer_glm, "fare", "partial_dependency")
plot(expl_glm)

 
library("ranger")
titanic_ranger_model &lt;- ranger(survived~., data = titanic_imputed, num.trees = 50,
                               probability = TRUE)
explainer_ranger  &lt;- explain(titanic_ranger_model, data = titanic_imputed)
expl_ranger  &lt;- variable_effect(explainer_ranger, variables = "fare",
                            type = "partial_dependency")
plot(expl_ranger)
plot(expl_ranger, expl_glm)

# Example for factor variable (with factorMerger)
expl_ranger_factor  &lt;- variable_effect(explainer_ranger, variables =  "class")
plot(expl_ranger_factor)
 

</code></pre>

<hr>
<h2 id='yhat'>Wrap Various Predict Functions</h2><span id='topic+yhat'></span><span id='topic+yhat.lm'></span><span id='topic+yhat.randomForest'></span><span id='topic+yhat.svm'></span><span id='topic+yhat.gbm'></span><span id='topic+yhat.glm'></span><span id='topic+yhat.cv.glmnet'></span><span id='topic+yhat.glmnet'></span><span id='topic+yhat.ranger'></span><span id='topic+yhat.model_fit'></span><span id='topic+yhat.train'></span><span id='topic+yhat.lrm'></span><span id='topic+yhat.rpart'></span><span id='topic+yhat.function'></span><span id='topic+yhat.party'></span><span id='topic+yhat.default'></span>

<h3>Description</h3>

<p>This function is a wrapper over various predict functions for different models and differnt model structures.
The wrapper returns a single numeric score for each new observation.
To do this it uses different extraction techniques for models from different classes,
like for classification random forest is forces the output to be probabilities
not classes itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yhat(X.model, newdata, ...)

## S3 method for class 'lm'
yhat(X.model, newdata, ...)

## S3 method for class 'randomForest'
yhat(X.model, newdata, ...)

## S3 method for class 'svm'
yhat(X.model, newdata, ...)

## S3 method for class 'gbm'
yhat(X.model, newdata, ...)

## S3 method for class 'glm'
yhat(X.model, newdata, ...)

## S3 method for class 'cv.glmnet'
yhat(X.model, newdata, ...)

## S3 method for class 'glmnet'
yhat(X.model, newdata, ...)

## S3 method for class 'ranger'
yhat(X.model, newdata, ...)

## S3 method for class 'model_fit'
yhat(X.model, newdata, ...)

## S3 method for class 'train'
yhat(X.model, newdata, ...)

## S3 method for class 'lrm'
yhat(X.model, newdata, ...)

## S3 method for class 'rpart'
yhat(X.model, newdata, ...)

## S3 method for class ''function''
yhat(X.model, newdata, ...)

## S3 method for class 'party'
yhat(X.model, newdata, ...)

## Default S3 method:
yhat(X.model, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yhat_+3A_x.model">X.model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="yhat_+3A_newdata">newdata</code></td>
<td>
<p>data.frame or matrix - observations for prediction</p>
</td></tr>
<tr><td><code id="yhat_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to the predict function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently supported packages are:
</p>

<ul>
<li><p> class <code>cv.glmnet</code> and <code>glmnet</code> - models created with <span class="pkg">glmnet</span> package,
</p>
</li>
<li><p> class <code>glm</code> - generalized linear models created with <a href="stats.html#topic+glm">glm</a>,
</p>
</li>
<li><p> class <code>model_fit</code> - models created with <span class="pkg">parsnip</span> package,
</p>
</li>
<li><p> class <code>lm</code> - linear models created with <a href="stats.html#topic+lm">lm</a>,
</p>
</li>
<li><p> class <code>ranger</code> - models created with <span class="pkg">ranger</span> package,
</p>
</li>
<li><p> class <code>randomForest</code> - random forest models created with <span class="pkg">randomForest</span> package,
</p>
</li>
<li><p> class <code>svm</code> - support vector machines models created with the <span class="pkg">e1071</span> package,
</p>
</li>
<li><p> class <code>train</code> - models created with <span class="pkg">caret</span> package,
</p>
</li>
<li><p> class <code>gbm</code> - models created with <span class="pkg">gbm</span> package,
</p>
</li>
<li><p> class <code>lrm</code> - models created with <span class="pkg">rms</span> package,
</p>
</li>
<li><p> class <code>rpart</code> - models created with <span class="pkg">rpart</span> package.
</p>
</li></ul>



<h3>Value</h3>

<p>An numeric matrix of predictions
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
