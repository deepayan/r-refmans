<!DOCTYPE html><html><head><title>Help for package ivaBSS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ivaBSS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ivaBSS-package'>
<p>Tools for Independent Vector Analysis</p></a></li>
<li><a href='#avg_ISI'>
<p>Average Intersymbol Inference</p></a></li>
<li><a href='#coef.iva'>
<p>Coefficient of the Object of Class iva</p></a></li>
<li><a href='#components.iva'>
<p>Components of the Object of Class iva</p></a></li>
<li><a href='#fastIVA'>
<p>Fast Fixed-point IVA Algorithm</p></a></li>
<li><a href='#jbss_achieved'>
<p>JBSS Achieved</p></a></li>
<li><a href='#joint_ISI'>
<p>Joint Intersymbol Inference</p></a></li>
<li><a href='#NewtonIVA'>
<p>Newton Update Based IVA Algorithm</p></a></li>
<li><a href='#plot.iva'>
<p>Plotting an Object of Class iva</p></a></li>
<li><a href='#predict.iva'>
<p>Predict Method for Object of Class iva</p></a></li>
<li><a href='#print.iva'>
<p>Print an Object of Class iva</p></a></li>
<li><a href='#summary.iva'>
<p>Summarize an Object of Class iva</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Independent Vector Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-03</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, BSSprep</td>
</tr>
<tr>
<td>Suggests:</td>
<td>LaplacesDemon</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mika Sipilä &lt;mika.e.sipila@student.jyu.fi&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Independent vector analysis (IVA) is a blind source separation (BSS) model where several datasets are jointly unmixed. This package provides several methods for the unmixing together with some performance measures. For details, see Anderson et al. (2011) &lt;<a href="https://doi.org/10.1109%2FTSP.2011.2181836">doi:10.1109/TSP.2011.2181836</a>&gt; and Lee et al. (2007) &lt;<a href="https://doi.org/10.1016%2Fj.sigpro.2007.01.010">doi:10.1016/j.sigpro.2007.01.010</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-19 08:16:26 UTC; developer</td>
</tr>
<tr>
<td>Author:</td>
<td>Mika Sipilä [aut, cre],
  Klaus Nordhausen <a href="https://orcid.org/0000-0002-3758-8501"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Sara Taskinen <a href="https://orcid.org/0000-0001-9470-7258"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-19 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ivaBSS-package'>
Tools for Independent Vector Analysis
</h2><span id='topic+ivaBSS-package'></span><span id='topic+ivaBSS'></span>

<h3>Description</h3>

<p>Independent vector analysis (IVA) is a blind source separation (BSS) model where several datasets are jointly unmixed. This package provides several methods for the unmixing together with some performance measures. For details, see Anderson et al. (2011) &lt;doi:10.1109/TSP.2011.2181836&gt; and Lee et al. (2007) &lt;doi:10.1016/j.sigpro.2007.01.010&gt;.
</p>


<h3>Details</h3>

<p>The package contains tools for independent vector analysis. The main functions to perform IVA are <code>"IVANewton"</code> and <code>"fastIVA"</code>. <code>"NewtonIVA"</code> performs Newton update based IVA and <code>"fastIVA"</code> performs fixed-point iteration based IVA. Both of the algorithms have multiple options for source density models.
</p>


<h3>Author(s)</h3>

<p>Authors: Mika Sipilä, Klaus Nordhausen, Sara Taskinen
</p>
<p>Maintainer: Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Anderson, M., Adalı, T., &amp; Li, X.-L. (2011). Joint blind source separation with multivariate
Gaussian model: Algorithms and performance analysis. IEEE Transactions on Signal
Processing, 60, 1672–1683. &lt;doi:10.1109/TSP.2011.2181836&gt;</cite>
</p>
<p><cite>Anderson, M. (2013). Independent vector analysis: Theory, algorithms, and applications.
PhD dissertation, University of Maryland, Baltimore County.</cite>
</p>

<hr>
<h2 id='avg_ISI'>
Average Intersymbol Inference
</h2><span id='topic+avg_ISI'></span>

<h3>Description</h3>

<p>Calculates the average intersymbol inference for two sets of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avg_ISI(W, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avg_ISI_+3A_w">W</code></td>
<td>

<p>Array of unmixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
<tr><td><code id="avg_ISI_+3A_a">A</code></td>
<td>

<p>Array of true mixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the average intersymbol inference for the set of estimated unmixing matrices and the set of true mixing matrices. The average ISI gets the value between 0 and 1, where 0 is the optimal result. The average ISI is calculated as the mean ISI over each dataset separately. The average ISI does not take the permutation of the estimated sources into account.
</p>


<h3>Value</h3>

<p>Numeric value between 0 and 1, where 0 is the optimal result indicating that the sources are separated perfectly in each dataset.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Anderson, M. (2013). Independent vector analysis: Theory, algorithms, and applications.
PhD dissertation, University of Maryland, Baltimore County.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+joint_ISI">joint_ISI</a></code>, <code><a href="#topic+jbss_achieved">jbss_achieved</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixing matrices and unmixing matrices generated
# from standard normal distribution
P &lt;- 4; D &lt;- 4;
W &lt;- array(rnorm(P * P * D), c(P, P, D))
A &lt;- array(rnorm(P * P * D), c(P, P, D))

avg_ISI(W, A)

if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
  avg_ISI(coef(res_G), A)
}
</code></pre>

<hr>
<h2 id='coef.iva'>
Coefficient of the Object of Class iva
</h2><span id='topic+coef.iva'></span>

<h3>Description</h3>

<p><code>coef</code> method for class <code>"iva"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'iva'
coef(object, which.dataset = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.iva_+3A_object">object</code></td>
<td>

<p>an object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="coef.iva_+3A_which.dataset">which.dataset</code></td>
<td>

<p>positive integer. Provides the index in case the unmixing matrix only for a specific data set is desired. Default is to return all unmixing matrices.
</p>
</td></tr>
<tr><td><code id="coef.iva_+3A_...">...</code></td>
<td>

<p>further arguments are not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the unmixing matrices for all datasets or only for the requested dataset.
</p>


<h3>Value</h3>

<p>Unmixing matrix or all unmixing matrices of the object of class <code>"iva"</code>. If a single unmixing matrix is requested, it is an array with dimension <code>[P, P]</code> and if all unmixing matrices are requested, it is an array with dimension <code>[P, P, D]</code>.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")


  # All D unmixing matrices
  coef(res_G)

  # The unmixing matrix for the second dataset
  coef(res_G, 2)
}
</code></pre>

<hr>
<h2 id='components.iva'>
Components of the Object of Class iva
</h2><span id='topic+components.iva'></span>

<h3>Description</h3>

<p>Returns the estimated source components of object of class <code>"iva"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  components.iva(object, which.dataset = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="components.iva_+3A_object">object</code></td>
<td>

<p>an object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="components.iva_+3A_which.dataset">which.dataset</code></td>
<td>

<p>positive integer. Provides the index in case the unmixing matrix only for a specific data set is desired. Default is to return all unmixing matrices.
</p>
</td></tr>
<tr><td><code id="components.iva_+3A_...">...</code></td>
<td>

<p>further arguments are not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the estimated source components for all datasets or only for the requested dataset.
</p>


<h3>Value</h3>

<p>Estimated source components for requested dataset or for all datasets of the object of class <code>"iva"</code>. If a single dataset is requested, it is an array with dimension <code>[P, N]</code> and if all datasets are requested, it is an array with dimension <code>[P, N, D]</code>.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")


  # Source estimates for all D datasets
  components.iva(res_G)

  # Source estimates for the second dataset
  components.iva(res_G, 2)
}
</code></pre>

<hr>
<h2 id='fastIVA'>
Fast Fixed-point IVA Algorithm
</h2><span id='topic+fastIVA'></span>

<h3>Description</h3>

<p>The algorithm estimates the sources from multiple dependent datasets
jointly using their observed mixtures. The estimation is done by
maximizing the independence between the sources, when the estimated unmixing matrices are restricted to be orthogonal. The options for different source densities are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastIVA(X, source_density="laplace_diag", student_df=1,
max_iter = 1024, eps = 1e-6, W_init = NA, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastIVA_+3A_x">X</code></td>
<td>
<p>numeric data array containing the observed mixtures with dimension <code>[P, N, D]</code>,
where <code>P</code> is the dimension of the observed dataset, <code>N</code> is the number of the observations
and <code>D</code> is the number of the datasets. The number of datasets <code>D</code> should be at least 2. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_source_density">source_density</code></td>
<td>

<p>string to determine which source density model should be used. The options are <code>"laplace_diag"</code>, <code>"student"</code> or <code>"entropic"</code>. For more information see the details section.
</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_student_df">student_df</code></td>
<td>
<p>integer.
The degree of freedom for multivariate Student's distribution. Used only if <code>source_denisty = "student"</code>.
</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_max_iter">max_iter</code></td>
<td>
<p>positive integer, used to define the maximum number of iterations for algorithm to run. If <code>max_iter</code> is reached, the unmixing matrices of the last iteration are used.
</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_eps">eps</code></td>
<td>

<p>convergence tolerance, when the convergence measure is smaller than <code>eps</code>, the algorithm stops.
</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_w_init">W_init</code></td>
<td>

<p>numeric array of dimension <code>[P, P, D]</code> containing initial unmixing matrices. If not set, initialized with identity matrices.
</p>
</td></tr>
<tr><td><code id="fastIVA_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code> the convergence measure is printed during the learning process.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm uses fixed-point iteration to estimate to estimate the multivariate source signals from their observed mixtures. The elements of the source signals, or the datasets, should be dependent of each other to achieve the estimates where the sources are aligned in same order for each dataset. If the datasets are not dependent, the sources can still be separated but not necessarily aligned. This algorithm restricts the estimates unmixing matrices to be orthogonal. For more of the fast fixed-point IVA algorithm, see Lee, I. et al (2007).
</p>
<p>The source density model should be selected to match the density of the true source signals. When <code>source_density = "laplace_diag"</code>, the multivariate Laplace source density model with diagonal covariance structure is used. When <code>source_density = "entropic"</code>, the approximated entropy based source density model is used. For more about multivariate Laplace and entropic source density models, see Lee, I. et al (2007).
When <code>source_density = "student"</code> the multivariate Student's source density model is used, for more see Liang, Y. et al (2013).
</p>
<p>The algorithm assumes that observed signals are multivariate, i.e. the number of datasets <code>D &gt;= 2</code>. The estimated signals are zero mean and scaled to unit variance.
</p>


<h3>Value</h3>

<p>An object of class <code>"iva"</code>.
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>The estimated source signals with dimension <code>[P, N, D]</code>. The estimated source signals are zero mean with unit variance.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The estimated unmixing matrices with dimension <code>[P, P, D]</code>.</p>
</td></tr>
<tr><td><code>W_whitened</code></td>
<td>
<p>The estimated unmixing matrices with dimension <code>[P, P, D]</code> for whitened data.</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>The whitening matrices with dimension <code>[P, P, D]</code>.</p>
</td></tr>
<tr><td><code>X_means</code></td>
<td>
<p>The means for each observed mixture with dimension <code>[P, D]</code>.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>The number of iterations that the algorithm did run.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical value which tells if the algorithm converged.</p>
</td></tr>
<tr><td><code>source_density</code></td>
<td>
<p>The source density model used.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The number of datasets.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The number of sources.</p>
</td></tr>
<tr><td><code>student_df</code></td>
<td>
<p>The degree of freedom for Student's source density model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call.</p>
</td></tr>
<tr><td><code>DNAME</code></td>
<td>
<p>The name of the variable containing the observed mixtures.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Lee, I., Kim, T., &amp; Lee, T.-W. (2007). Fast fixed-point independent vector analysis algorithms
for convolutive blind source separation. Signal Processing, 87, 1859–1871.
&lt;doi:10.1016/j.sigpro.2007.01.010&gt;</cite>
</p>
<p><cite>Liang, Y., Chen, G., Naqvi, S., &amp; Chambers, J. A. (2013). Independent vector analysis
with multivariate Student’s t-distribution source prior for speech separation. Electronics
Letters, 49, 1035–1036. &lt;doi:10.1049/el.2013.1999&gt;</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 2; N &lt;- 1000; D &lt;- 5;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    S[i, , ] &lt;- rmvl(N, rep(0, D), diag(D))
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res &lt;- fastIVA(X)
}
</code></pre>

<hr>
<h2 id='jbss_achieved'>
JBSS Achieved
</h2><span id='topic+jbss_achieved'></span>

<h3>Description</h3>

<p>The function calculates if the joint blind source separation (JBSS) is achieved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbss_achieved(W, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbss_achieved_+3A_w">W</code></td>
<td>

<p>Array of unmixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
<tr><td><code id="jbss_achieved_+3A_a">A</code></td>
<td>

<p>Array of true mixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates if the joint blind source separation is achieved. JBSS is considered achieved when the the location of maximum absolute values of each row of gain matrix
<code>G[,,d] = W[,,d] %*% A[,,d]</code> is unique within the dataset, but shared between the datasets <code>1, ...,D</code>. The first indicates that the sources are separated within dataset and the second indicates that the estimated sources are aligned in same order for each dataset.
</p>


<h3>Value</h3>

<p>Logical. If <code>TRUE</code> the JBSS is considered achieved.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Anderson, M. (2013). Independent vector analysis: Theory, algorithms, and applications.
PhD dissertation, University of Maryland, Baltimore County.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+joint_ISI">joint_ISI</a></code>, <code><a href="#topic+avg_ISI">avg_ISI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixing matrices and unmixing matrices generated
# from standard normal distribution
P &lt;- 4; D &lt;- 4;
W &lt;- array(rnorm(P * P * D), c(P, P, D))
A &lt;- array(rnorm(P * P * D), c(P, P, D))

jbss_achieved(W, A)

if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
  jbss_achieved(coef(res_G), A)
}
</code></pre>

<hr>
<h2 id='joint_ISI'>
Joint Intersymbol Inference
</h2><span id='topic+joint_ISI'></span>

<h3>Description</h3>

<p>Calculates the joint intersymbol inference for two sets of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint_ISI(W, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="joint_ISI_+3A_w">W</code></td>
<td>

<p>Array of unmixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
<tr><td><code id="joint_ISI_+3A_a">A</code></td>
<td>

<p>Array of true mixing matrices with dimension <code>[P, P, D]</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the joint intersymbol inference for the set of estimated unmixing matrices and the set of true mixing matrices. The joint ISI gets the value between 0 and 1, where 0 is the optimal result. The joint ISI calculates the average intersymbol inference over each dataset as well as penalizes if the sources are not aligned in same order for each dataset.
</p>


<h3>Value</h3>

<p>Numeric value between 0 and 1, where 0 is the optimal result indicating that the sources are separated perfectly and aligned in same order in each dataset.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Anderson, M. (2013). Independent vector analysis: Theory, algorithms, and applications.
PhD dissertation, University of Maryland, Baltimore County. </cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+avg_ISI">avg_ISI</a></code>, <code><a href="#topic+jbss_achieved">jbss_achieved</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixing matrices and unmixing matrices generated
# from standard normal distribution
P &lt;- 4; D &lt;- 4;
W &lt;- array(rnorm(P * P * D), c(P, P, D))
A &lt;- array(rnorm(P * P * D), c(P, P, D))

joint_ISI(W, A)

if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
  joint_ISI(coef(res_G), A)
}
</code></pre>

<hr>
<h2 id='NewtonIVA'>
Newton Update Based IVA Algorithm
</h2><span id='topic+NewtonIVA'></span>

<h3>Description</h3>

<p>The algorithm estimates the sources from multiple dependent datasets
jointly using their observed mixtures. The estimation is done by
maximizing the independence between the sources. The options for different source densities are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NewtonIVA(X, source_density="laplace", student_df=1,
init = "default", max_iter = 1024, eps = 1e-6, W_init = NA,
step_size=1, step_size_min = 0.1, alpha = 0.9, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NewtonIVA_+3A_x">X</code></td>
<td>
<p>numeric data array containing the observed mixtures with dimension <code>[P, N, D]</code>,
where <code>P</code> is the dimension of the observed dataset, <code>N</code> is the number of the observations
and <code>D</code> is the number of the datasets. The number of datasets <code>D</code> should be at least 2. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_source_density">source_density</code></td>
<td>

<p>string to determine which source density model should be used. The options are <code>"laplace"</code>, <code>"laplace_diag"</code>, <code>"gaussian"</code> or <code>"student"</code>. For more information see the details section.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_student_df">student_df</code></td>
<td>
<p>integer.
The degree of freedom for multivariate Student's distribution. Used only if <code>source_denisty = "student"</code>.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_init">init</code></td>
<td>
<p>string, to determine how to initialize the algorithm. The options are
<code>"default"</code>, <code>"IVA-G+fastIVA"</code>, <code>"IVA-G"</code>, <code>"fastIVA"</code> or <code>"none"</code>. For more information see the details section.</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_max_iter">max_iter</code></td>
<td>
<p>positive integer, used to define the maximum number of iterations for algorithm to run. If <code>max_iter</code> is reached, the unmixing matrices of the last iteration are used.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_eps">eps</code></td>
<td>

<p>convergence tolerance, when the convergence measure is smaller than <code>eps</code>, the algorithm stops.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_w_init">W_init</code></td>
<td>

<p>numeric array of dimension <code>[P, P, D]</code> containing initial unmixing matrices. If not set, initialized with identity matrices.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_step_size">step_size</code></td>
<td>

<p>initial step size for Newton step, should be between 0 and 1, default is 1.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_step_size_min">step_size_min</code></td>
<td>

<p>the minimum step size.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_alpha">alpha</code></td>
<td>

<p>multiplier for how much to decrease step size when convergence is not getting smaller.
</p>
</td></tr>
<tr><td><code id="NewtonIVA_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code> the convergence measure is printed during the learning process.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm uses Newton update together with decoupling trick to estimate the multivariate source signals from their observed mixtures. The elements of the source signals, or the datasets, should be dependent of each other to achieve the estimates where the sources are aligned in same order for each dataset. If the datasets are not dependent, the sources can still be separated but not necessarily aligned. The algorithm does not assume the unmixing matrices to be orthogonal. For more of the nonorthogonal Newton update based IVA algorithm, see Anderson, M. et al (2011) and Anderson, M. (2013).
</p>
<p>The source density model should be selected to match the density of the true source signals. When <code>source_density = "laplace"</code>, the multivariate Laplace source density model is used. This is the most flexible choice as it takes both second-order and higher-order dependence into account.
</p>
<p>When <code>source_density = "laplace_diag"</code>, the multivariate Laplace source density model with diagonal covariance structure is used. Multivariate diagonal Laplace source density model should be considered only when the sources are mainly higher-order dependent. It works best when the number of sources is significantly less than the number of datasets.
</p>
<p>When <code>source_density = "gaussian"</code> the multivariate Gaussian source density model is used. This is the superior choice in terms of computation power and should be used when the sources are mostly second-order dependent.
</p>
<p>When <code>source_density = "student"</code> the multivariate Student's source density model is used. Multivariate Student's source density model should be considered only when the sources are mainly higher-order dependent. It works best when the number of sources is significantly less than the number of datasets.
</p>
<p>The <code>init</code> parameter defines how the algorithm is initialized. When <code>init = "default"</code>, the default initialization is used. As default the algorithm is initialized using <code>init = "IVA-G+fastIVA"</code> when <code>source_density</code> is <code>"laplace"</code>, <code>"laplace_diag"</code> or <code>"student"</code>, and using <code>init = "none"</code> when <code>source_density = "gaussian"</code>.
</p>
<p>When <code>init = "IVA-G+fastIVA"</code>, the algorithm is initialized using first the estimated unmixing matrices of IVA-G, which is <code>NewtonIVA</code> with <code>source_density = "gaussian"</code>, to initialize <code>fastIVA</code> algorithm. Then the estimated unmixing matrices <code>W</code> of <code>fastIVA</code> are used as initial unmixing matrices for <code>NewtonIVA</code>. IVA-G is used to solve the permutation problem of aligning the source estimates when ever the true sources are second-order dependent. If the true sources are not second-order dependent, <code>fastIVA</code> is used as backup as it solves the permutation problem more regularly than <code>NewtonIVA</code> when the sources are purely higher-order dependent. When the sources possess any second-order dependence, IVA-G also speeds the computation time up a lot. This option should be used whenever there is no prior information about the sources and <code>source_density</code> is either <code>"laplace"</code>, <code>"laplace_diag"</code> or <code>"student"</code>.
</p>
<p>When <code>init = "IVA-G"</code>, the estimated unmixing matrices of IVA-G are used to initialize this algorithm. This option should be used if the true sources are expected to possess any second-order dependence and <code>source_density</code> is not <code>"gaussian"</code>.
</p>
<p>When <code>init = "fastIVA"</code>, the estimated unmixing matrices of <code>fastIVA</code> algorithm is used to initialize this algorithm. This option should be used if the true sources are expected to possess only higher-order dependence. For more details, see <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
<p>When <code>init = "none"</code>, the unmixing matrices are initialized randomly from standard normal distribution.
</p>
<p>The algorithm assumes that observed signals are multivariate, i.e. the number of datasets <code>D &gt;= 2</code>. The estimated signals are zero mean and scaled to unit variance.
</p>


<h3>Value</h3>

<p>An object of class <code>"iva"</code>.
</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>The estimated source signals with dimension <code>[P, N, D]</code>. The estimated source signals are zero mean with unit variance.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The estimated unmixing matrices with dimension <code>[P, P, D]</code>.</p>
</td></tr>
<tr><td><code>W_whitened</code></td>
<td>
<p>The estimated unmixing matrices with dimension <code>[P, P, D]</code> for whitened data.</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>The whitening matrices with dimension <code>[P, P, D]</code>.</p>
</td></tr>
<tr><td><code>X_means</code></td>
<td>
<p>The means for each observed mixture with dimension <code>[P, D]</code>.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>The number of iterations that the algorithm did run.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Logical value which tells if the algorithm converged.</p>
</td></tr>
<tr><td><code>source_density</code></td>
<td>
<p>The source density model used.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The number of datasets.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>The number of sources.</p>
</td></tr>
<tr><td><code>student_df</code></td>
<td>
<p>The degree of freedom for Student's source density model.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call.</p>
</td></tr>
<tr><td><code>DNAME</code></td>
<td>
<p>The name of the variable containing the observed mixtures.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>References</h3>

<p><cite>Anderson, M., Adalı, T., &amp; Li, X.-L. (2011). Joint blind source separation with multivariate
Gaussian model: Algorithms and performance analysis. IEEE Transactions on Signal
Processing, 60, 1672–1683. &lt;doi:10.1109/TSP.2011.2181836&gt;</cite>
</p>
<p><cite>Anderson, M. (2013). Independent vector analysis: Theory, algorithms, and applications.
PhD dissertation, University of Maryland, Baltimore County. </cite>
</p>
<p><cite>Liang, Y., Chen, G., Naqvi, S., &amp; Chambers, J. A. (2013). Independent vector analysis
with multivariate Student’s t-distribution source prior for speech separation. Electronics
Letters, 49, 1035–1036. &lt;doi:10.1049/el.2013.1999&gt;</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
}
</code></pre>

<hr>
<h2 id='plot.iva'>
Plotting an Object of Class iva
</h2><span id='topic+plot.iva'></span>

<h3>Description</h3>

<p><code>plot</code> method for the class <code>"iva"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'iva'
plot(x, which.dataset = NA, which.source = NA,
type = "l", xlabs = c(), ylabs = c(), colors = c(),
oma = c(1, 1, 0, 0), mar = c(2, 2, 1, 1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.iva_+3A_x">x</code></td>
<td>

<p>An object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_which.dataset">which.dataset</code></td>
<td>

<p>Positive integer to determine which dataset is returned. If not set, returns all datasets.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_which.source">which.source</code></td>
<td>

<p>Positive integer to determine which dataset is returned. If not set, returns all datasets.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_type">type</code></td>
<td>

<p>1-character string giving the type of plot desired. For details, see <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_xlabs">xlabs</code></td>
<td>

<p>Vector containing the labels for x-axis.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_ylabs">ylabs</code></td>
<td>

<p>Vector containing the labels for y-axis.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_colors">colors</code></td>
<td>

<p>Vector containing the colors for each plot.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_oma">oma</code></td>
<td>

<p>A vector of the form <code>c(bottom, left, top, right)</code> giving the size of the outer margins in lines of text. For more details, see <code><a href="stats.html#topic+stats">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_mar">mar</code></td>
<td>

<p>A numerical vector of the form <cite>c(bottom, left, top, right)</cite> which gives the number of lines of margin to be specified on the four sides of the plot. For more details, see <code><a href="stats.html#topic+stats">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.iva_+3A_...">...</code></td>
<td>

<p>Further arguments passed to <code><a href="stats.html#topic+stats">plot</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots either all estimated sources of the object of class <code>"iva"</code> or the estimates for specific dataset and/or source.
</p>


<h3>Value</h3>

<p>No return value, called for plotting the estimated sources of the object of class <code>"iva"</code>.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")

  # Plot all estimated sources
  plot(res_G)

  # Plot the source estimates for the first dataset only
  plot(res_G, which.dataset = 1)

  # Plot the source estimates for the second source only
  plot(res_G, which.source = 2)

  # Plot the source estimate of the second dataset and third source
  plot(res_G, which.dataset = 2, which.source = 3, type = "p")

  # Plot all source estimates with custom colors and labels
  plot(res_G, col=c(rep(1, 4), rep(2, 4), rep(3, 4), rep(4, 4)),
      xlabs = c("Subject 1", "Subject 2", "Subject 3", "Subject 4"),
      ylabs = c("Channel 1", "Channel 2", "Channel 3", "Channel 4"))
}
</code></pre>

<hr>
<h2 id='predict.iva'>
Predict Method for Object of Class iva
</h2><span id='topic+predict.iva'></span>

<h3>Description</h3>

<p>Predict the new source estimates best on fitted object of <code>"iva"</code> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'iva'
predict(object, newdata, which.dataset = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.iva_+3A_object">object</code></td>
<td>

<p>An object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.iva_+3A_newdata">newdata</code></td>
<td>

<p>A numeric data array containing new observed mixtures. Either with dimension <code>[P, N, D]</code> (if <code>which.dataset = NA</code>) or <code>[P, N]</code>, where <code>P</code> is the number of sources, <code>N</code> is the number of observations and <code>D</code> is the number of datasets.
</p>
</td></tr>
<tr><td><code id="predict.iva_+3A_which.dataset">which.dataset</code></td>
<td>

<p>Positive integer to determine which dataset is returned. If not set, returns all datasets.
</p>
</td></tr>
<tr><td><code id="predict.iva_+3A_...">...</code></td>
<td>

<p>further arguments are not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the source estimates for new observed mixtures based on the model fitted originally. The estimates are zero mean and scaled to unit variance.
</p>


<h3>Value</h3>

<p>Numeric array containing the estimated sources with dimension <code>[P, N]</code> if <code>which.dataset</code> is provided and with dimension <code>[P, N, D]</code> if <code>which.dataset</code> is not provided.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))
  sigmas &lt;- list()

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    sigmas[[i]] &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), sigmas[[i]])
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")

  # Generate new observarions
  N_new &lt;- 10
  S_new &lt;- array(NA, c(P, N_new, D))
  for (i in 1:P) {
    S_new[i, , ] &lt;- rmvl(N_new, rep(0, D), sigmas[[i]])
  }
  X_new &lt;- array(NaN, c(P, N_new, D))
  for (d in 1:D) {
    X_new[, , d] &lt;- A[, , d] %*% S_new[, , d]
  }

  # Get source estimates for the new observations
  pred &lt;- predict(res_G, X_new)

  # Get source estimates for only the second dataset
  pred2 &lt;- predict(res_G, X_new[, , 2], which.dataset = 2)
}
</code></pre>

<hr>
<h2 id='print.iva'>
Print an Object of Class iva
</h2><span id='topic+print.iva'></span>

<h3>Description</h3>

<p><code>print</code> method for the class <code>"iva"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'iva'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.iva_+3A_x">x</code></td>
<td>

<p>An object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="print.iva_+3A_...">...</code></td>
<td>

<p>Further arguments are not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function prints all information of <code>"iva"</code> object, except the estimated source signals.
</p>


<h3>Value</h3>

<p>No return value, called for printing information of the object of class <code>"iva"</code>.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
  print(res_G)
}
</code></pre>

<hr>
<h2 id='summary.iva'>
Summarize an Object of Class iva
</h2><span id='topic+summary.iva'></span>

<h3>Description</h3>

<p><code>summary</code> method for the class <code>"iva"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'iva'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.iva_+3A_object">object</code></td>
<td>

<p>An object of class <code>"iva"</code>, usually the result of a call to <code><a href="#topic+NewtonIVA">NewtonIVA</a></code> or <code><a href="#topic+fastIVA">fastIVA</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.iva_+3A_...">...</code></td>
<td>

<p>Further arguments are not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function print all the information of the <code>"iva"</code> object except the estimated sources and the estimated unmixing matrices.
</p>


<h3>Value</h3>

<p>No return value, called for summarizing the object of class <code>"iva"</code>.
</p>


<h3>Author(s)</h3>

<p>Mika Sipilä
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NewtonIVA">NewtonIVA</a></code>, <code><a href="#topic+fastIVA">fastIVA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("LaplacesDemon")) {
  # Generate sources from multivariate Laplace distribution
  P &lt;- 4; N &lt;- 1000; D &lt;- 4;
  S &lt;- array(NA, c(P, N, D))

  for (i in 1:P) {
    U &lt;- array(rnorm(D * D), c(D, D))
    Sigma &lt;- crossprod(U)
    S[i, , ] &lt;- rmvl(N, rep(0, D), Sigma)
  }

  # Generate mixing matrices from standard normal distribution
  A &lt;- array(rnorm(P * P * D), c(P, P, D))

  # Generate mixtures
  X &lt;- array(NaN, c(P, N, D))
  for (d in 1:D) {
    X[, , d] &lt;- A[, , d] %*% S[, , d]
  }

  # Estimate sources and unmixing matrices
  res_G &lt;- NewtonIVA(X, source_density = "gaussian")
  summary(res_G)
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
