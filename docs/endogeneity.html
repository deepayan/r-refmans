<!DOCTYPE html><html><head><title>Help for package endogeneity</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {endogeneity}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bilinear'><p>Recusrive Bivariate Linear Model</p></a></li>
<li><a href='#biprobit'><p>Recusrive Bivariate Probit Model</p></a></li>
<li><a href='#biprobit_latent'><p>Recursive Bivariate Probit Model with Latent First Stage</p></a></li>
<li><a href='#biprobit_partial'><p>Recursive Bivariate Probit Model with Partially Observed First Stage</p></a></li>
<li><a href='#endogeneity'><p>Recursive two-stage models to address endogeneity</p></a></li>
<li><a href='#linear_probit'><p>Recursive Linear-Probit Model</p></a></li>
<li><a href='#pln'><p>Poisson Lognormal Model</p></a></li>
<li><a href='#pln_linear'><p>Recursive PLN-Linear Model</p></a></li>
<li><a href='#pln_probit'><p>Recursive PLN-Probit Model</p></a></li>
<li><a href='#probit_linear'><p>Recursive Probit-Linear Model</p></a></li>
<li><a href='#probit_linear_latent'><p>Recursive Probit-Linear Model with Latent First Stage</p></a></li>
<li><a href='#probit_linear_partial'><p>Recursive Probit-Linear Model with Partially Observed First Stage</p></a></li>
<li><a href='#probit_linearRE'><p>Recursive Probit-LinearRE Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Recursive Two-Stage Models to Address Endogeneity</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Jing Peng</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jing Peng &lt;jing.peng@uconn.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various recursive two-stage models to address the endogeneity issue of treatment variables in observational study or mediators in experiments. The details of the models are discussed in Peng (2023) &lt;<a href="https://doi.org/10.1287%2Fisre.2022.1113">doi:10.1287/isre.2022.1113</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, pbivnorm, maxLik, statmod, MASS, data.table</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-21 00:21:59 UTC; pengj</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-21 04:02:35 UTC</td>
</tr>
</table>
<hr>
<h2 id='bilinear'>Recusrive Bivariate Linear Model</h2><span id='topic+bilinear'></span>

<h3>Description</h3>

<p>Estimate two linear models with bivariate normally distributed error terms.<br /><br />
First stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">m_i=\boldsymbol{\alpha}'\mathbf{w_i}+\lambda u_i</code>
</p>

<p>Second stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">y_i = \boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
The identification of this model requires an instrumental variable that appears in w but not x. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bilinear(form1, form2, data = NULL, par = NULL, method = "BFGS", verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bilinear_+3A_form1">form1</code></td>
<td>
<p>Formula for the first linear model</p>
</td></tr>
<tr><td><code id="bilinear_+3A_form2">form2</code></td>
<td>
<p>Formula for the second linear model</p>
</td></tr>
<tr><td><code id="bilinear_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="bilinear_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="bilinear_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="bilinear_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;1&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> var_bhhh: BHHH covariance matrix, inverse of the outer product of gradient at the maximum
</p>
</li>
<li><p> se_bhhh: BHHH standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = -1 + x + z + e1
y = -1 + x + m + e2

est = bilinear(m~x+z, y~x+m)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='biprobit'>Recusrive Bivariate Probit Model</h2><span id='topic+biprobit'></span>

<h3>Description</h3>

<p>Estimate two probit models with bivariate normally distributed error terms.<br /><br />
First stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">m_i=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">y_i = 1(\boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i&gt;0)</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
w and x can be the same set of variables. Identification can be weak if w are not good predictors of m. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biprobit(form1, form2, data = NULL, par = NULL, method = "BFGS", verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biprobit_+3A_form1">form1</code></td>
<td>
<p>Formula for the first probit model</p>
</td></tr>
<tr><td><code id="biprobit_+3A_form2">form2</code></td>
<td>
<p>Formula for the second probit model</p>
</td></tr>
<tr><td><code id="biprobit_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="biprobit_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="biprobit_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="biprobit_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;1&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> var_bhhh: BHHH covariance matrix, inverse of the outer product of gradient at the maximum
</p>
</li>
<li><p> se_bhhh: BHHH standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + z + e1 &gt; 0)
y = as.numeric(1 + x + z + m + e2 &gt; 0)

est = biprobit(m~x+z, y~x+z+m)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='biprobit_latent'>Recursive Bivariate Probit Model with Latent First Stage</h2><span id='topic+biprobit_latent'></span>

<h3>Description</h3>

<p>Estimate two probit models with bivariate normally distributed error terms, in which the dependent variable of the first stage model is unobserved.<br /><br />
First stage (Probit, <code class="reqn">m_i^*</code> is unobserved):
</p>
<p style="text-align: center;"><code class="reqn">m_i^*=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">y_i = 1(\boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i^* + \sigma v_i&gt;0)</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
w and x can be the same set of variables. The identification of this model is generally weak, especially if w are not good predictors of m. <code class="reqn">\gamma</code> is assumed to be positive to ensure that the model estimates are unique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biprobit_latent(
  form1,
  form2,
  data = NULL,
  EM = FALSE,
  par = NULL,
  method = "BFGS",
  verbose = 0,
  maxIter = 500,
  tol = 1e-05,
  tol_LL = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biprobit_latent_+3A_form1">form1</code></td>
<td>
<p>Formula for the first probit model, in which the dependent variable is unobserved. Use a formula like ~w to avoid specifying the dependent variable.</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_form2">form2</code></td>
<td>
<p>Formula for the second probit model, the latent dependent variable of the first stage is automatically added as a regressor in this model</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_em">EM</code></td>
<td>
<p>Whether to maximize likelihood use the Expectation-Maximization (EM) algorithm, which is slower but more robust. Defaults to FLASE, but should change to TRUE is the model has convergence issues.</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_maxiter">maxIter</code></td>
<td>
<p>max iterations for EM algorithm</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_tol">tol</code></td>
<td>
<p>tolerance for convergence of EM algorithm</p>
</td></tr>
<tr><td><code id="biprobit_latent_+3A_tol_ll">tol_LL</code></td>
<td>
<p>tolerance for convergence of likelihood</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;1&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + z + e1 &gt; 0)
y = as.numeric(1 + x + z + m + e2 &gt; 0)

est = biprobit(m~x+z, y~x+z+m)
print(est$estimates, digits=3)

est_latent = biprobit_latent(~x+z, y~x+z)
print(est_latent$estimates, digits=3)

</code></pre>

<hr>
<h2 id='biprobit_partial'>Recursive Bivariate Probit Model with Partially Observed First Stage</h2><span id='topic+biprobit_partial'></span>

<h3>Description</h3>

<p>Estimate two probit models with bivariate normally distributed error terms, in which the dependent variable of the first stage model is partially observed (or unobserved).<br /><br />
First stage (Probit, <code class="reqn">m_i</code> is partially observed):
</p>
<p style="text-align: center;"><code class="reqn">m_i=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">y_i = 1(\boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i&gt;0)</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
Unobserved <code class="reqn">m_i</code> should be coded as NA. w and x can be the same set of variables. Identification can be weak if w are not good predictors of m.
Observing <code class="reqn">m_i</code> for 10%~20% of observations can significantly improve the identification of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biprobit_partial(
  form1,
  form2,
  data = NULL,
  EM = FALSE,
  par = NULL,
  method = "BFGS",
  verbose = 0,
  maxIter = 500,
  tol = 1e-05,
  tol_LL = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biprobit_partial_+3A_form1">form1</code></td>
<td>
<p>Formula for the first probit model, in which the dependent variable is partially observed.</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_form2">form2</code></td>
<td>
<p>Formula for the second probit model, the partially observed dependent variable of the first stage is automatically added as a regressor in this model (do not add manually)</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_em">EM</code></td>
<td>
<p>Whether to maximize likelihood use the Expectation-Maximization (EM) algorithm, which is slower but more robust. Defaults to FLASE, but should change to TRUE is the model has convergence issues.</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_maxiter">maxIter</code></td>
<td>
<p>max iterations for EM algorithm</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_tol">tol</code></td>
<td>
<p>tolerance for convergence of EM algorithm</p>
</td></tr>
<tr><td><code id="biprobit_partial_+3A_tol_ll">tol_LL</code></td>
<td>
<p>tolerance for convergence of likelihood</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;1&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
N = 5000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + 3*z + e1 &gt; 0)
y = as.numeric(1 + x + z + m + e2 &gt; 0)

est = biprobit(m~x+z, y~x+z+m)
print(est$estimates, digits=3)

# partially observed version of m
observed_pct = 0.2
m_p = m
m_p[sample(N, N*(1-observed_pct))] = NA
est_partial = biprobit_partial(m_p~x+z, y~x+z)
print(est_partial$estimates, digits=3)

</code></pre>

<hr>
<h2 id='endogeneity'>Recursive two-stage models to address endogeneity</h2><span id='topic+endogeneity'></span>

<h3>Description</h3>

<p>This package supports various recursive two-stage models to address the endogeneity issue. The details of the implemented models are discussed in Peng (2022). In a recursive two-stage model, the dependent variable of the first stage is also the endogenous variable of interest in the second stage. The endogeneity is captured by the correlation in the error terms of the two stages. <br /><br />
Recursive two-stage models can be used to address the endogeneity of treatment variables in observational study and the endogeneity of mediators in experiments. <br /><br />
The first-stage supports linear model, probit model, and Poisson lognormal model. The second-stage supports linear and probit models. These models can be used to address the endogeneity of continuous, binary, and count variables. When the endogenous variable is binary, it can be unobserved or partially unobserved, but the identification can be weak. <br /><br />
</p>


<h3>Functions</h3>

<p>bilinear: recursive bivariate linear model <br /> <br />
biprobit: recursive bivariate probit model <br /> <br />
biprobit_latent: recursive bivariate probit model with latent first stage <br /> <br />
biprobit_partial: recursive bivariate probit model with partially observed first stage <br /> <br />
linear-probit: recursive linear-probit model <br /> <br />
probit_linear: recursive probit-linear model <br /> <br />
probit_linear_latent: recursive probit-linear model with latent first stage <br /> <br />
probit_linear_partial: recursive probit-linear model with partially observed first stage <br /> <br />
probit_linearRE: recursive probit-linearRE model in which the second stage is a panel linear model with random effects <br /> <br />
pln: Poisson lognormal (PLN) model <br /> <br />
pln_linear: recursive PLN-linear model <br /> <br />
pln_probit: recursive PLN-probit model <br /> <br />
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>

<hr>
<h2 id='linear_probit'>Recursive Linear-Probit Model</h2><span id='topic+linear_probit'></span>

<h3>Description</h3>

<p>Estimate linear and probit models with bivariate normally distributed error terms.<br /><br />
First stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">m_i=\boldsymbol{\alpha}'\mathbf{w_i}+\sigma u_i</code>
</p>

<p>Second stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">y_i = 1(\boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + v_i&gt;0)</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
The identification of this model requires an instrumental variable that appears in w but not x. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear_probit(
  form_linear,
  form_probit,
  data = NULL,
  par = NULL,
  method = "BFGS",
  init = c("zero", "unif", "norm", "default")[4],
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear_probit_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the linear model</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the probit model</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="linear_probit_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> var_bhhh: BHHH covariance matrix, inverse of the outer product of gradient at the maximum
</p>
</li>
<li><p> se_bhhh: BHHH standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = 1 + x + z + e1
y = as.numeric(1 + x + m + e2 &gt; 0)

est = linear_probit(m~x+z, y~x+m)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='pln'>Poisson Lognormal Model</h2><span id='topic+pln'></span>

<h3>Description</h3>

<p>Estimate a Poisson model with a log-normally distributed heterogeneity term, which is also referred to as the Poisson-Normal model.<br /><br />
</p>
<p style="text-align: center;"><code class="reqn">E[y_i|x_i,u_i]=exp(\boldsymbol{\alpha}'\mathbf{x_i}+\lambda u_i)</code>
</p>

<p>The estimates of this model are often similar to those of a negative binomial model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pln(
  form,
  data = NULL,
  par = NULL,
  method = "BFGS",
  init = c("zero", "unif", "norm", "default")[4],
  H = 20,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pln_+3A_form">form</code></td>
<td>
<p>Formula</p>
</td></tr>
<tr><td><code id="pln_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="pln_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="pln_+3A_method">method</code></td>
<td>
<p>Optimization algorithm.</p>
</td></tr>
<tr><td><code id="pln_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="pln_+3A_h">H</code></td>
<td>
<p>Number of quadrature points</p>
</td></tr>
<tr><td><code id="pln_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for the heterogeneity term <code class="reqn">\lambda=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
set.seed(1)

# Works well when the variance of the normal term is not overly large
# When the variance is very large, it tends to be underestimated
x = rbinom(N, 1, 0.5)
z = rnorm(N)
y = rpois(N, exp(-1 + x + z + 0.5 * rnorm(N)))
est = pln(y~x+z)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='pln_linear'>Recursive PLN-Linear Model</h2><span id='topic+pln_linear'></span>

<h3>Description</h3>

<p>Estimate a Poisson Lognormal model and a linear model with bivariate normally distributed error/heterogeneity terms.<br /><br />
First stage (Poisson Lognormal):
</p>
<p style="text-align: center;"><code class="reqn">E[m_i|w_i,u_i]=exp(\boldsymbol{\alpha}'\mathbf{w_i}+\lambda u_i)</code>
</p>

<p>Second stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">y_i = \boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
This model is typically well-identified even if w and x are the same set of variables. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pln_linear(
  form_pln,
  form_linear,
  data = NULL,
  par = NULL,
  method = "BFGS",
  init = c("zero", "unif", "norm", "default")[4],
  H = 20,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pln_linear_+3A_form_pln">form_pln</code></td>
<td>
<p>Formula for the first-stage Poisson lognormal model</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the second-stage linear model</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_method">method</code></td>
<td>
<p>Optimization algorithm.</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_h">H</code></td>
<td>
<p>Number of quadrature points</p>
</td></tr>
<tr><td><code id="pln_linear_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;pln&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = rpois(N, exp(1 + x + z + e1))
y = 1 + x + m + e2

est = pln_linear(m~x+z, y~x+m)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='pln_probit'>Recursive PLN-Probit Model</h2><span id='topic+pln_probit'></span>

<h3>Description</h3>

<p>Estimate a Poisson Lognormal model and a Probit model with bivariate normally distributed error/heterogeneity terms.<br /><br />
First stage (Poisson Lognormal):
</p>
<p style="text-align: center;"><code class="reqn">E[m_i|w_i,u_i]=exp(\boldsymbol{\alpha}'\mathbf{w_i}+\lambda u_i)</code>
</p>

<p>Second stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">y_i = 1(\boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i &gt; 0)</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
This model is typically well-identified even if w and x are the same set of variables. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pln_probit(
  form_pln,
  form_probit,
  data = NULL,
  par = NULL,
  method = "BFGS",
  init = c("zero", "unif", "norm", "default")[4],
  H = 20,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pln_probit_+3A_form_pln">form_pln</code></td>
<td>
<p>Formula for the first-stage Poisson lognormal model</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the second-stage probit model</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Without gradient, NM is much faster than BFGS</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_h">H</code></td>
<td>
<p>Number of quadrature points</p>
</td></tr>
<tr><td><code id="pln_probit_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals. Prefix &quot;pln&quot; means first stage variables.
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = rpois(N, exp(-1 + x + z + e1))
y = as.numeric(1 + x + z + log(1+m) + e2 &gt; 0)

est = pln_probit(m~x+z, y~x+z+log(1+m))
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='probit_linear'>Recursive Probit-Linear Model</h2><span id='topic+probit_linear'></span>

<h3>Description</h3>

<p>Estimate probit and linear models with bivariate normally distributed error terms.<br /><br />
First stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">m_i=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">y_i = \boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
w and x can be the same set of variables. Identification can be weak if w are not good predictors of m. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_linear(
  form_probit,
  form_linear,
  data = NULL,
  par = NULL,
  method = "BFGS",
  init = c("zero", "unif", "norm", "default")[4],
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit_linear_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the probit model</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the linear model</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="probit_linear_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> var_bhhh: BHHH covariance matrix, inverse of the outer product of gradient at the maximum
</p>
</li>
<li><p> se_bhhh: BHHH standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + z + e1 &gt; 0)
y = 1 + x + z + m + e2

est = probit_linear(m~x+z, y~x+z+m)
print(est$estimates, digits=3)
</code></pre>

<hr>
<h2 id='probit_linear_latent'>Recursive Probit-Linear Model with Latent First Stage</h2><span id='topic+probit_linear_latent'></span>

<h3>Description</h3>

<p>Latent version of the Probit-Linear Model. <br /><br />
First stage (Probit, <code class="reqn">m_i^*</code> is unobserved):
</p>
<p style="text-align: center;"><code class="reqn">m_i^*=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">y_i = \boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i^* + \sigma v_i</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
w and x can be the same set of variables. The identification of this model is generally weak, especially if w are not good predictors of m. <code class="reqn">\gamma</code> is assumed to be positive to ensure that the model estimates are unique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_linear_latent(
  form_probit,
  form_linear,
  data = NULL,
  EM = TRUE,
  par = NULL,
  method = "BFGS",
  verbose = 0,
  maxIter = 500,
  tol = 1e-06,
  tol_LL = 1e-08
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit_linear_latent_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the first-stage probit model, in which the dependent variable is latent</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the second stage linear model. The latent dependent variable of the first stage is automatically added as a regressor in this model</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_em">EM</code></td>
<td>
<p>Whether to maximize likelihood use the Expectation-Maximization (EM) algorithm, which is slower but more robust. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_maxiter">maxIter</code></td>
<td>
<p>max iterations for EM algorithm</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_tol">tol</code></td>
<td>
<p>tolerance for convergence of EM algorithm</p>
</td></tr>
<tr><td><code id="probit_linear_latent_+3A_tol_ll">tol_LL</code></td>
<td>
<p>tolerance for convergence of likelihood</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> iter: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
N = 2000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + z + e1 &gt; 0)
y = 1 + x + z + m + e2
est = probit_linear(m~x+z, y~x+z+m)
print(est$estimates, digits=3)

est_latent = probit_linear_latent(~x+z, y~x+z)
print(est_latent$estimates, digits=3)

</code></pre>

<hr>
<h2 id='probit_linear_partial'>Recursive Probit-Linear Model with Partially Observed First Stage</h2><span id='topic+probit_linear_partial'></span>

<h3>Description</h3>

<p>Partially observed version of the Probit-Linear Model. <br /><br />
First stage (Probit, <code class="reqn">m_i</code> is partially observed):
</p>
<p style="text-align: center;"><code class="reqn">m_i=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Linear):
</p>
<p style="text-align: center;"><code class="reqn">y_i = \boldsymbol{\beta}'\mathbf{x_i} + {\gamma}m_i + \sigma v_i</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
Unobserved <code class="reqn">m_i</code> should be coded as NA. w and x can be the same set of variables. Identification can be weak if w are not good predictors of m.
Observing <code class="reqn">m_i</code> for a small proportion of observations (e.g., 10~20%) can significantly improve the identification of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_linear_partial(
  form_probit,
  form_linear,
  data = NULL,
  EM = TRUE,
  par = NULL,
  method = "BFGS",
  verbose = 0,
  maxIter = 500,
  tol = 1e-06,
  tol_LL = 1e-08
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit_linear_partial_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the first-stage probit model, in which the dependent variable is partially observed</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the second stage linear model. The partially observed dependent variable of the first stage is automatically added as a regressor in this model (do not add manually)</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_data">data</code></td>
<td>
<p>Input data, a data frame</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_em">EM</code></td>
<td>
<p>Whether to maximize likelihood use the Expectation-Maximization (EM) algorithm, which is slower but more robust. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_maxiter">maxIter</code></td>
<td>
<p>max iterations for EM algorithm</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_tol">tol</code></td>
<td>
<p>tolerance for convergence of EM algorithm</p>
</td></tr>
<tr><td><code id="probit_linear_partial_+3A_tol_ll">tol_LL</code></td>
<td>
<p>tolerance for convergence of likelihood</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Peng, Jing. (2023) Identification of Causal Mechanisms from Randomized Experiments: A Framework for Endogenous Mediation Analysis. Information Systems Research, 34(1):67-84. Available at https://doi.org/10.1287/isre.2022.1113
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linearRE">probit_linearRE</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
N = 1000
rho = -0.5
set.seed(1)

x = rbinom(N, 1, 0.5)
z = rnorm(N)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

m = as.numeric(1 + x + z + e1 &gt; 0)
y = 1 + x + z + m + e2
est = probit_linear(m~x+z, y~x+z+m)
print(est$estimates, digits=3)

# partially observed version of m
observed_pct = 0.2
m_p = m
m_p[sample(N, N*(1-observed_pct))] = NA
est_latent = probit_linear_partial(m_p~x+z, y~x+z)
print(est_latent$estimates, digits=3)

</code></pre>

<hr>
<h2 id='probit_linearRE'>Recursive Probit-LinearRE Model</h2><span id='topic+probit_linearRE'></span>

<h3>Description</h3>

<p>A panel extension of the probit_linear model. The first stage is a probit model at the individual level. The second stage is a panel linear model at the individual-time level with individual-level random effects. The random effect is correlated with the error term in the first stage.<br /><br />
First stage (Probit):
</p>
<p style="text-align: center;"><code class="reqn">m_i=1(\boldsymbol{\alpha}'\mathbf{w_i}+u_i&gt;0)</code>
</p>

<p>Second stage (Panel linear model with individual-level random effects):
</p>
<p style="text-align: center;"><code class="reqn">y_{it} = \boldsymbol{\beta}'\mathbf{x_{it}} + {\gamma}m_i + \lambda v_i +\sigma \epsilon_{it}</code>
</p>

<p>Endogeneity structure:
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> are bivariate normally distributed with a correlation of <code class="reqn">\rho</code>. <br /><br />
This model uses Adaptive Gaussian Quadrature to overcome numerical challenges with long panels. w and x can be the same set of variables. Identification can be weak if w are not good predictors of m. This model still works if the first-stage dependent variable is not a regressor in the second stage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit_linearRE(
  form_probit,
  form_linear,
  id,
  data = NULL,
  par = NULL,
  method = "BFGS",
  H = 20,
  stopUpdate = F,
  init = c("zero", "unif", "norm", "default")[4],
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit_linearRE_+3A_form_probit">form_probit</code></td>
<td>
<p>Formula for the probit model at the individual level</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_form_linear">form_linear</code></td>
<td>
<p>Formula for the linear model at the individual-time level</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_id">id</code></td>
<td>
<p>group id, character if data  supplied or numerical vector if data not supplied</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_data">data</code></td>
<td>
<p>Input data, must be a data.table object</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_par">par</code></td>
<td>
<p>Starting values for estimates</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_method">method</code></td>
<td>
<p>Optimization algorithm. Default is BFGS</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_h">H</code></td>
<td>
<p>Number of quadrature points</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_stopupdate">stopUpdate</code></td>
<td>
<p>Adaptive Gaussian Quadrature disabled if TRUE</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_init">init</code></td>
<td>
<p>Initialization method</p>
</td></tr>
<tr><td><code id="probit_linearRE_+3A_verbose">verbose</code></td>
<td>
<p>A integer indicating how much output to display during the estimation process.
</p>

<ul>
<li><p> &lt;0 - No ouput
</p>
</li>
<li><p> 0 - Basic output (model estimates)
</p>
</li>
<li><p> 1 - Moderate output, basic ouput + parameter and likelihood in each iteration
</p>
</li>
<li><p> 2 - Extensive output, moderate output + gradient values on each call
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results of the estimated model, some of which are inherited from the return of maxLik
</p>

<ul>
<li><p> estimates: Model estimates with 95% confidence intervals
</p>
</li>
<li><p> estimate or par: Point estimates
</p>
</li>
<li><p> variance_type: covariance matrix used to calculate standard errors. Either BHHH or Hessian.
</p>
</li>
<li><p> var: covariance matrix
</p>
</li>
<li><p> se: standard errors
</p>
</li>
<li><p> var_bhhh: BHHH covariance matrix, inverse of the outer product of gradient at the maximum
</p>
</li>
<li><p> se_bhhh: BHHH standard errors
</p>
</li>
<li><p> gradient: Gradient function at maximum
</p>
</li>
<li><p> hessian: Hessian matrix at maximum
</p>
</li>
<li><p> gtHg: <code class="reqn">g'H^-1g</code>, where H^-1 is simply the covariance matrix. A value close to zero (e.g., &lt;1e-3 or 1e-6) indicates good convergence.
</p>
</li>
<li><p> LL or maximum: Likelihood
</p>
</li>
<li><p> AIC: AIC
</p>
</li>
<li><p> BIC: BIC
</p>
</li>
<li><p> n_obs: Number of observations
</p>
</li>
<li><p> n_par: Number of parameters
</p>
</li>
<li><p> time: Time takes to estimate the model
</p>
</li>
<li><p> LR_stat: Likelihood ratio test statistic for <code class="reqn">\rho=0</code>
</p>
</li>
<li><p> LR_p: p-value of likelihood ratio test
</p>
</li>
<li><p> iterations: number of iterations taken to converge
</p>
</li>
<li><p> message: Message regarding convergence status.
</p>
</li></ul>

<p>Note that the list inherits all the components in the output of maxLik. See the documentation of maxLik for more details.
</p>


<h3>References</h3>

<p>Chen, H., Peng, J., Li, H., &amp; Shankar, R. (2022). Impact of Refund Policy on Sales of Paid Information Services: The Moderating Role of Product Characteristics. Available at SSRN: https://ssrn.com/abstract=4114972.
</p>


<h3>See Also</h3>

<p>Other endogeneity: 
<code><a href="#topic+bilinear">bilinear</a>()</code>,
<code><a href="#topic+biprobit_latent">biprobit_latent</a>()</code>,
<code><a href="#topic+biprobit_partial">biprobit_partial</a>()</code>,
<code><a href="#topic+biprobit">biprobit</a>()</code>,
<code><a href="#topic+linear_probit">linear_probit</a>()</code>,
<code><a href="#topic+pln_linear">pln_linear</a>()</code>,
<code><a href="#topic+pln_probit">pln_probit</a>()</code>,
<code><a href="#topic+probit_linear_latent">probit_linear_latent</a>()</code>,
<code><a href="#topic+probit_linear_partial">probit_linear_partial</a>()</code>,
<code><a href="#topic+probit_linear">probit_linear</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
library(data.table)
N = 500
period = 5
obs = N*period
rho = -0.5
set.seed(100)

e = mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), nrow=2))
e1 = e[,1]
e2 = e[,2]

t = rep(1:period, N)
id = rep(1:N, each=period)
w = rnorm(N)
m = as.numeric(1+w+e1&gt;0)
m_long = rep(m, each=period)

x = rnorm(obs)
y = 1 + x + m_long + rep(e2, each=period) + rnorm(obs)

dt = data.table(y, x, id, t, m=rep(m, each=period), w=rep(w, each=period))

est = probit_linearRE(m~w, y~x+m, 'id', dt)
print(est$estimates, digits=3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
