<!DOCTYPE html><html><head><title>Help for package h2o</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {h2o}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#h2o-package'>
<p>H2O R Interface</p></a></li>
<li><a href='#.addParm'><p>TODO: No objects in this file are being used. Either remove file or use objects.</p></a></li>
<li><a href='#.check_for_ggplot2'><p>Stop with a user friendly message if a user is missing the ggplot2 package or has an old version of it.</p></a></li>
<li><a href='#.collapse'><p>Helper Collapse Function</p></a></li>
<li><a href='#.consolidate_varimps'><p>Consolidate variable importances</p></a></li>
<li><a href='#.create_leaderboard'><p>Create a leaderboard like data frame for <code>models</code></p></a></li>
<li><a href='#.customized_call'><p>A helper function that makes it easier to override/add params in a function call.</p></a></li>
<li><a href='#.find_appropriate_column_name'><p>Tries to match a <code>fuzzy_col_name</code> with a column name that exists in <code>cols</code>.</p></a></li>
<li><a href='#.get_algorithm'><p>Get the algoritm used by the model_or_model_id</p></a></li>
<li><a href='#.get_domain_mapping'><p>Get a mapping between columns and their domains</p></a></li>
<li><a href='#.get_feature_count'><p>Get feature count sorted by the count descending.</p></a></li>
<li><a href='#.get_first_of_family'><p>Get first of family models</p></a></li>
<li><a href='#.h2o.__ALL_CAPABILITIES'><p>Capabilities endpoints</p></a></li>
<li><a href='#.h2o.__checkConnectionHealth'><p>Check H2O Server Health</p></a></li>
<li><a href='#.h2o.__CREATE_FRAME'><p>H2OFrame Manipulation</p></a></li>
<li><a href='#.h2o.__DECRYPTION_SETUP'><p>Decryption Endpoints</p></a></li>
<li><a href='#.h2o.__DKV'><p>Removal Endpoints</p></a></li>
<li><a href='#.h2o.__EXPORT_FILES'><p>Export Files Endpoint Generator</p></a></li>
<li><a href='#.h2o.__FRAMES'><p>Inspect/Summary Endpoints</p></a></li>
<li><a href='#.h2o.__IMPORT'><p>Import/Export Endpoints</p></a></li>
<li><a href='#.h2o.__JOBS'><p>Administrative Endpoints</p></a></li>
<li><a href='#.h2o.__LOGANDECHO'><p>Log and Echo Endpoint</p></a></li>
<li><a href='#.h2o.__MODEL_BUILDERS'><p>Model Builder Endpoint Generator</p></a></li>
<li><a href='#.h2o.__MODEL_METRICS'><p>Model Metrics Endpoint</p></a></li>
<li><a href='#.h2o.__MODELS'><p>Model Endpoint</p></a></li>
<li><a href='#.h2o.__PARSE_SETUP'><p>Parse Endpoints</p></a></li>
<li><a href='#.h2o.__RAPIDS'><p>Rapids Endpoint</p></a></li>
<li><a href='#.h2o.__REST_API_VERSION'><p>H2O Package Constants</p></a></li>
<li><a href='#.h2o.__SEGMENT_MODELS_BUILDERS'><p>Segment Models Builder Endpoint Generator</p></a></li>
<li><a href='#.h2o.__W2V_SYNONYMS'><p>Word2Vec Endpoints</p></a></li>
<li><a href='#.h2o.doGET'><p>Just like doRawGET but fills in the default h2oRestApiVersion if none is provided</p></a></li>
<li><a href='#.h2o.doPOST'><p>Just like doRawPOST but fills in the default h2oRestApiVersion if none is provided</p></a></li>
<li><a href='#.h2o.doRawGET'><p>Perform a low-level HTTP GET operation on an H2O instance</p></a></li>
<li><a href='#.h2o.doRawPOST'><p>Perform a low-level HTTP POST operation on an H2O instance</p></a></li>
<li><a href='#.h2o.doSafeGET'><p>Perform a safe (i.e. error-checked) HTTP GET request to an H2O cluster.</p></a></li>
<li><a href='#.h2o.doSafePOST'><p>Perform a safe (i.e. error-checked) HTTP POST request to an H2O cluster.</p></a></li>
<li><a href='#.h2o.is_progress'><p>Check if Progress Bar is Enabled</p></a></li>
<li><a href='#.h2o.locate'><p>Locate a file given the pattern &lt;bucket&gt;/&lt;path/to/file&gt;</p>
e.g. h2o:::.h2o.locate(&quot;smalldata/iris/iris22.csv&quot;) returns the absolute path to iris22.csv</a></li>
<li><a href='#.h2o.perfect_auc'><p>Internal function that calculates a precise AUC from given</p>
probabilities and actual responses.</a></li>
<li><a href='#.h2o.primitives'><p>Map of operations known to H2O</p></a></li>
<li><a href='#.has_model_coefficients'><p>Has the <code>model</code> coefficients?</p></a></li>
<li><a href='#.has_varimp'><p>Has the model variable importance?</p></a></li>
<li><a href='#.interpretable'><p>Is the model considered to be interpretable, i.e., simple enough.</p></a></li>
<li><a href='#.is_h2o_model'><p>Is the <code>model</code> an H2O model?</p></a></li>
<li><a href='#.is_h2o_tree_model'><p>Is the <code>model</code> a Tree-based H2O Model?</p></a></li>
<li><a href='#.is_plotting_to_rnotebook'><p>Check if we are plotting in to r notebook.</p></a></li>
<li><a href='#.leaderboard_for_row'><p>Enhance leaderboard with per-model predictions.</p></a></li>
<li><a href='#.min_max'><p>Min-max normalization.</p></a></li>
<li><a href='#.model_ids'><p>Get Model Ids</p></a></li>
<li><a href='#.pkg.env'><p>The H2O Package Environment</p></a></li>
<li><a href='#.plot_varimp'><p>Plot variable importances with ggplot2</p></a></li>
<li><a href='#.process_models_or_automl'><p>Do basic validation and transform <code>object</code> to a &quot;standardized&quot; list containing models, and</p>
their properties such as <code>x</code>, <code>y</code>, whether it is a (multinomial) clasification or not etc.</a></li>
<li><a href='#.shorten_model_ids'><p>Shortens model ids if possible (iff there will be same amount of unique model_ids as before)</p></a></li>
<li><a href='#.skip_if_not_developer'><p>H2O &lt;-&gt; R Communication and Utility Methods</p></a></li>
<li><a href='#.uniformize'><p>Convert to quantiles when provided with numeric vector.</p>
When col is a factor vector assign uniformly value between 0 and 1 to each level.</a></li>
<li><a href='#.varimp'><p>Get variable importance in a standardized way.</p></a></li>
<li><a href='#.verify_dataxy'><p>Used to verify data, x, y and turn into the appropriate things</p></a></li>
<li><a href='#+26amp+3B+26amp+3B'><p>Logical and for H2OFrames</p></a></li>
<li><a href='#aaa'><p>Starting H2O For examples</p></a></li>
<li><a href='#apply'><p>Apply on H2O Datasets</p></a></li>
<li><a href='#as.character.H2OFrame'><p>Convert an H2OFrame to a String</p></a></li>
<li><a href='#as.data.frame.H2OFrame'><p>Converts parsed H2O data into an R data frame</p></a></li>
<li><a href='#as.data.frame.H2OSegmentModels'><p>Converts a collection of Segment Models to a data.frame</p></a></li>
<li><a href='#as.factor'><p>Convert H2O Data to Factors</p></a></li>
<li><a href='#as.h2o'><p>Create H2OFrame</p></a></li>
<li><a href='#as.matrix.H2OFrame'><p>Convert an H2OFrame to a matrix</p></a></li>
<li><a href='#as.numeric'><p>Convert H2O Data to Numeric</p></a></li>
<li><a href='#as.vector.H2OFrame'><p>Convert an H2OFrame to a vector</p></a></li>
<li><a href='#australia'><p>Australia Coastal Data</p></a></li>
<li><a href='#case_insensitive_match_arg'><p>Works like match.arg but ignores case</p></a></li>
<li><a href='#colnames'><p>Returns the column names of an H2OFrame</p></a></li>
<li><a href='#dim.H2OFrame'><p>Returns the Dimensions of an H2OFrame</p></a></li>
<li><a href='#dimnames.H2OFrame'><p>Column names of an H2OFrame</p></a></li>
<li><a href='#feature_frequencies.H2OModel'><p>Retrieve the number of occurrences of each feature for given observations</p>
Available for GBM, Random Forest and Isolation Forest models.</a></li>
<li><a href='#generate_col_ind'><p>CHeck to see if the column names/indices entered is valid for the dataframe given.  This is an internal function</p></a></li>
<li><a href='#get_seed.H2OModel'><p>Get the seed from H2OModel which was used during training.</p>
If a user does not set the seed parameter before training, the seed is autogenerated.
It returns seed as the string if the value is bigger than the integer.
For example, an autogenerated seed is always long so that the seed in R is a string.</a></li>
<li><a href='#h2o.abs'><p>Compute the absolute value of x</p></a></li>
<li><a href='#h2o.acos'><p>Compute the arc cosine of x</p></a></li>
<li><a href='#h2o.adaBoost'><p>Build an AdaBoost model</p></a></li>
<li><a href='#h2o.aecu'><p>Retrieve the default AECU (Average Excess Cumulative Uplift = area between AUUC and random AUUC)</p></a></li>
<li><a href='#h2o.aecu_table'><p>Retrieve the all types of AECU (average excess cumulative uplift) value in a table</p></a></li>
<li><a href='#h2o.aggregated_frame'><p>Retrieve an aggregated frame from an Aggregator model</p></a></li>
<li><a href='#h2o.aggregator'><p>Build an Aggregated Frame</p></a></li>
<li><a href='#h2o.aic'><p>Retrieve the Akaike information criterion (AIC) value</p></a></li>
<li><a href='#h2o.all'><p>Given a set of logical vectors, are all of the values true?</p></a></li>
<li><a href='#h2o.anomaly'><p>Anomaly Detection via H2O Deep Learning Model</p></a></li>
<li><a href='#h2o.anovaglm'><p>H2O ANOVAGLM is used to calculate Type III SS which is used to evaluate the contributions of individual predictors</p>
and their interactions to a model.  Predictors or interactions with negligible contributions to the model will have
high p-values while those with more contributions will have low p-values.</a></li>
<li><a href='#h2o.any'><p>Given a set of logical vectors, is at least one of the values true?</p></a></li>
<li><a href='#h2o.anyFactor'><p>Check H2OFrame columns for factors</p></a></li>
<li><a href='#h2o.api'><p>Perform a REST API request to a previously connected server.</p></a></li>
<li><a href='#h2o.arrange'><p>Sorts an H2O frame by columns</p></a></li>
<li><a href='#h2o.as_date'><p>Convert between character representations and objects of Date class</p></a></li>
<li><a href='#h2o.ascharacter'><p>Convert H2O Data to Characters</p></a></li>
<li><a href='#h2o.asfactor'><p>Convert H2O Data to Factors</p></a></li>
<li><a href='#h2o.asnumeric'><p>Convert H2O Data to Numerics</p></a></li>
<li><a href='#h2o.assign'><p>Rename an H2O object.</p></a></li>
<li><a href='#h2o.atc'><p>Retrieve Average Treatment Effect on the Control</p></a></li>
<li><a href='#h2o.ate'><p>Retrieve Average Treatment Effect</p></a></li>
<li><a href='#h2o.att'><p>Retrieve Average Treatment Effect on the Treated</p></a></li>
<li><a href='#h2o.auc'><p>Retrieve the AUC</p></a></li>
<li><a href='#h2o.aucpr'><p>Retrieve the AUCPR (Area Under Precision Recall Curve)</p></a></li>
<li><a href='#h2o.automl'><p>Automatic Machine Learning</p></a></li>
<li><a href='#h2o.auuc'><p>Retrieve AUUC</p></a></li>
<li><a href='#h2o.auuc_normalized'><p>Retrieve normalized AUUC</p></a></li>
<li><a href='#h2o.auuc_table'><p>Retrieve the all types of AUUC in a table</p></a></li>
<li><a href='#h2o.average_objective'><p>Extracts the final training average objective function of a GLM model.</p></a></li>
<li><a href='#h2o.betweenss'><p>Get the between cluster sum of squares</p></a></li>
<li><a href='#h2o.biases'><p>Return the respective bias vector</p></a></li>
<li><a href='#h2o.bottomN'><p>H2O bottomN</p></a></li>
<li><a href='#h2o.calculate_fairness_metrics'><p>Calculate intersectional fairness metrics.</p></a></li>
<li><a href='#h2o.cbind'><p>Combine H2O Datasets by Columns</p></a></li>
<li><a href='#h2o.ceiling'><p>Take a single numeric argument and return a numeric vector with the smallest integers</p></a></li>
<li><a href='#h2o.centers'><p>Retrieve the Model Centers</p></a></li>
<li><a href='#h2o.centersSTD'><p>Retrieve the Model Centers STD</p></a></li>
<li><a href='#h2o.centroid_stats'><p>Retrieve centroid statistics</p></a></li>
<li><a href='#h2o.clearLog'><p>Delete All H2O R Logs</p></a></li>
<li><a href='#h2o.cluster_sizes'><p>Retrieve the cluster sizes</p></a></li>
<li><a href='#h2o.clusterInfo'><p>Print H2O cluster info</p></a></li>
<li><a href='#h2o.clusterIsUp'><p>Determine if an H2O cluster is up or not</p></a></li>
<li><a href='#h2o.clusterStatus'><p>Return the status of the cluster</p></a></li>
<li><a href='#h2o.coef'><p>Return the coefficients that can be applied to the non-standardized data.</p></a></li>
<li><a href='#h2o.coef_norm'><p>Return coefficients fitted on the standardized data (requires standardize = True, which is on by default). These coefficients can be used to evaluate variable importance.</p></a></li>
<li><a href='#h2o.coef_with_p_values'><p>Return the coefficients table with coefficients, standardized coefficients, p-values, z-values and std-error for GLM models</p></a></li>
<li><a href='#h2o.colnames'><p>Return column names of an H2OFrame</p></a></li>
<li><a href='#h2o.columns_by_type'><p>Obtain a list of columns that are specified by 'coltype'</p></a></li>
<li><a href='#h2o.computeGram'><p>Compute weighted gram matrix.</p></a></li>
<li><a href='#h2o.confusionMatrix'><p>Access H2O Confusion Matrices</p></a></li>
<li><a href='#h2o.connect'><p>Connect to a running H2O instance.</p></a></li>
<li><a href='#h2o.cor'><p>Correlation of columns.</p></a></li>
<li><a href='#h2o.cos'><p>Compute the cosine of x</p></a></li>
<li><a href='#h2o.cosh'><p>Compute the hyperbolic cosine of x</p></a></li>
<li><a href='#h2o.coxph'><p>Trains a Cox Proportional Hazards Model (CoxPH) on an H2O dataset</p></a></li>
<li><a href='#h2o.createFrame'><p>Data H2OFrame Creation in H2O</p></a></li>
<li><a href='#h2o.cross_validation_fold_assignment'><p>Retrieve the cross-validation fold assignment</p></a></li>
<li><a href='#h2o.cross_validation_holdout_predictions'><p>Retrieve the cross-validation holdout predictions</p></a></li>
<li><a href='#h2o.cross_validation_models'><p>Retrieve the cross-validation models</p></a></li>
<li><a href='#h2o.cross_validation_predictions'><p>Retrieve the cross-validation predictions</p></a></li>
<li><a href='#h2o.cummax'><p>Return the cumulative max over a column or across a row</p></a></li>
<li><a href='#h2o.cummin'><p>Return the cumulative min over a column or across a row</p></a></li>
<li><a href='#h2o.cumprod'><p>Return the cumulative product over a column or across a row</p></a></li>
<li><a href='#h2o.cumsum'><p>Return the cumulative sum over a column or across a row</p></a></li>
<li><a href='#h2o.cut'><p>Cut H2O Numeric Data to Factor</p></a></li>
<li><a href='#h2o.day'><p>Convert Milliseconds to Day of Month in H2O Datasets</p></a></li>
<li><a href='#h2o.dayOfWeek'><p>Convert Milliseconds to Day of Week in H2O Datasets</p></a></li>
<li><a href='#h2o.dct'><p>Compute DCT of an H2OFrame</p></a></li>
<li><a href='#h2o.ddply'><p>Split H2O Dataset, Apply Function, and Return Results</p></a></li>
<li><a href='#h2o.decision_tree'><p>Build a Decision Tree model</p></a></li>
<li><a href='#h2o.decryptionSetup'><p>Setup a Decryption Tool</p></a></li>
<li><a href='#h2o.deepfeatures'><p>Feature Generation via H2O Deep Learning</p></a></li>
<li><a href='#h2o.deeplearning'><p>Build a Deep Neural Network model using CPUs</p></a></li>
<li><a href='#h2o.describe'><p>H2O Description of A Dataset</p></a></li>
<li><a href='#h2o.difflag1'><p>Conduct a lag 1 transform on a numeric H2OFrame column</p></a></li>
<li><a href='#h2o.dim'><p>Returns the number of rows and columns for an H2OFrame object.</p></a></li>
<li><a href='#h2o.dimnames'><p>Column names of an H2OFrame</p></a></li>
<li><a href='#h2o.disparate_analysis'><p>Create a frame containing aggregations of intersectional fairness across the models.</p></a></li>
<li><a href='#h2o.distance'><p>Compute a pairwise distance measure between all rows of two numeric H2OFrames.</p></a></li>
<li><a href='#h2o.download_model'><p>Download the model in binary format.</p>
The owner of the file saved is the user by which python session was executed.</a></li>
<li><a href='#h2o.download_mojo'><p>Download the model in MOJO format.</p></a></li>
<li><a href='#h2o.download_pojo'><p>Download the Scoring POJO (Plain Old Java Object) of an H2O Model</p></a></li>
<li><a href='#h2o.downloadAllLogs'><p>Download H2O Log Files to Disk</p></a></li>
<li><a href='#h2o.downloadCSV'><p>Download H2O Data to Disk</p></a></li>
<li><a href='#h2o.drop_duplicates'><p>Drops duplicated rows.</p></a></li>
<li><a href='#h2o.entropy'><p>Shannon entropy</p></a></li>
<li><a href='#h2o.exp'><p>Compute the exponential function of x</p></a></li>
<li><a href='#h2o.explain'><p>Generate Model Explanations</p></a></li>
<li><a href='#h2o.explain_row'><p>Generate Model Explanations for a single row</p></a></li>
<li><a href='#h2o.exportFile'><p>Export an H2O Data Frame (H2OFrame) to a File or to a collection of Files.</p></a></li>
<li><a href='#h2o.exportHDFS'><p>Export a Model to HDFS</p></a></li>
<li><a href='#h2o.extendedIsolationForest'><p>Trains an Extended Isolation Forest model</p></a></li>
<li><a href='#h2o.fair_pd_plot'><p>Partial dependence plot per protected group.</p></a></li>
<li><a href='#h2o.fair_pr_plot'><p>Plot PR curve per protected group.</p></a></li>
<li><a href='#h2o.fair_roc_plot'><p>Plot ROC curve per protected group.</p></a></li>
<li><a href='#h2o.fair_shap_plot'><p>SHAP summary plot for one feature with protected groups on y-axis.</p></a></li>
<li><a href='#h2o.feature_interaction'><p>Feature interactions and importance, leaf statistics and split value histograms in a tabular form.</p>
Available for XGBoost and GBM.</a></li>
<li><a href='#h2o.fillna'><p>fillNA</p></a></li>
<li><a href='#h2o.filterNACols'><p>Filter NA Columns</p></a></li>
<li><a href='#h2o.find_row_by_threshold'><p>Find the threshold, give the max metric. No duplicate thresholds allowed</p></a></li>
<li><a href='#h2o.find_threshold_by_max_metric'><p>Find the threshold, give the max metric</p></a></li>
<li><a href='#h2o.findSynonyms'><p>Find synonyms using a word2vec model.</p></a></li>
<li><a href='#h2o.floor'><p>Take a single numeric argument and return a numeric vector with the largest integers</p></a></li>
<li><a href='#h2o.flow'><p>Open H2O Flow</p></a></li>
<li><a href='#h2o.gains_lift_plot'><p>Plot Gains/Lift curves</p></a></li>
<li><a href='#h2o.gains_lift_plot+2CH2OModel-method'><p>Plot Gains/Lift curves</p></a></li>
<li><a href='#h2o.gains_lift_plot+2CH2OModelMetrics-method'><p>Plot Gains/Lift curves</p></a></li>
<li><a href='#h2o.gainsLift'><p>Access H2O Gains/Lift Tables</p></a></li>
<li><a href='#h2o.gam'><p>Fit a General Additive Model</p></a></li>
<li><a href='#h2o.gbm'><p>Build gradient boosted classification or regression trees</p></a></li>
<li><a href='#h2o.generic'><p>Imports a generic model into H2O. Such model can be used then used for scoring and obtaining</p>
additional information about the model. The imported model has to be supported by H2O.</a></li>
<li><a href='#h2o.genericModel'><p>Imports a model under given path, creating a Generic model with it.</p></a></li>
<li><a href='#h2o.get_automl'><p>Get an R object that is a subclass of H2OAutoML</p></a></li>
<li><a href='#h2o.get_best_model'><p>Get best model of a given family/algorithm for a given criterion from an AutoML object.</p></a></li>
<li><a href='#h2o.get_best_model_predictors'><p>Extracts the subset of predictor names that yield the best R2 value for each predictor subset size.</p></a></li>
<li><a href='#h2o.get_best_r2_values'><p>Extracts the best R2 values for all predictor subset size.</p></a></li>
<li><a href='#h2o.get_gam_knot_column_names'><p>Extracts the gam column names corresponding to the knot locations from model output if it is enabled.</p></a></li>
<li><a href='#h2o.get_knot_locations'><p>Extracts the knot locations from model output if it is enabled.</p></a></li>
<li><a href='#h2o.get_leaderboard'><p>Retrieve the leaderboard from the AutoML instance.</p></a></li>
<li><a href='#h2o.get_ntrees_actual'><p>Retrieve actual number of trees for tree algorithms</p></a></li>
<li><a href='#h2o.get_predictors_added_per_step'><p>Extracts the predictor added to model at each step.</p></a></li>
<li><a href='#h2o.get_predictors_removed_per_step'><p>Extracts the predictor removed to model at each step.</p></a></li>
<li><a href='#h2o.get_regression_influence_diagnostics'><p>Extracts a list of H2OFrames containing regression influence diagnostics for predictor subsets of various sizes or</p>
just one H2OFrame containing regression influence diagnostics for predictor subsets of one fixed size</a></li>
<li><a href='#h2o.get_segment_models'><p>Retrieves an instance of H2OSegmentModels for a given id.</p></a></li>
<li><a href='#h2o.get_variable_inflation_factors'><p>Return the variable inflation factors associated with numerical predictors for GLM models.</p></a></li>
<li><a href='#h2o.getAlphaBest'><p>Extract best alpha value found from glm model.</p></a></li>
<li><a href='#h2o.getConnection'><p>Retrieve an H2O Connection</p></a></li>
<li><a href='#h2o.getFrame'><p>Get an R Reference to an H2O Dataset, that will NOT be GC'd by default</p></a></li>
<li><a href='#h2o.getGLMFullRegularizationPath'><p>Extract full regularization path from a GLM model</p></a></li>
<li><a href='#h2o.getGrid'><p>Get a grid object from H2O distributed K/V store.</p></a></li>
<li><a href='#h2o.getId'><p>Get back-end distributed key/value store id from an H2OFrame.</p></a></li>
<li><a href='#h2o.getLambdaBest'><p>Extract best lambda value found from glm model.</p></a></li>
<li><a href='#h2o.getLambdaMax'><p>Extract the maximum lambda value used during lambda search from glm model.</p></a></li>
<li><a href='#h2o.getLambdaMin'><p>Extract the minimum lambda value calculated during lambda search from glm model.</p>
Note that due to early stop, this minimum lambda value may not be used in the actual lambda search.</a></li>
<li><a href='#h2o.getModel'><p>Get an R reference to an H2O model</p></a></li>
<li><a href='#h2o.getModelTree'><p>Fetchces a single tree of a H2O model. This function is intended to be used on Gradient Boosting Machine models or Distributed Random Forest models.</p></a></li>
<li><a href='#h2o.getTimezone'><p>Get the Time Zone on the H2O cluster</p>
Returns a string</a></li>
<li><a href='#h2o.getTypes'><p>Get the types-per-column</p></a></li>
<li><a href='#h2o.getVersion'><p>Get h2o version</p></a></li>
<li><a href='#h2o.giniCoef'><p>Retrieve the GINI Coefficcient</p></a></li>
<li><a href='#h2o.glm'><p>Fit a generalized linear model</p></a></li>
<li><a href='#h2o.glrm'><p>Generalized low rank decomposition of an H2O data frame</p></a></li>
<li><a href='#h2o.grep'><p>Search for matches to an argument pattern</p></a></li>
<li><a href='#h2o.grid'><p>H2O Grid Support</p></a></li>
<li><a href='#h2o.group_by'><p>Group and Apply by Column</p></a></li>
<li><a href='#h2o.gsub'><p>String Global Substitute</p></a></li>
<li><a href='#h2o.h'><p>Calculates Friedman and Popescu's H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.</p>
H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a
stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.</a></li>
<li><a href='#h2o.head'><p>Return the Head or Tail of an H2O Dataset.</p></a></li>
<li><a href='#h2o.HGLMMetrics'><p>Retrieve HGLM ModelMetrics</p></a></li>
<li><a href='#h2o.hist'><p>Compute A Histogram</p></a></li>
<li><a href='#h2o.hit_ratio_table'><p>Retrieve the Hit Ratios</p></a></li>
<li><a href='#h2o.hour'><p>Convert Milliseconds to Hour of Day in H2O Datasets</p></a></li>
<li><a href='#h2o.ice_plot'><p>Plot Individual Conditional Expectation (ICE) for each decile</p></a></li>
<li><a href='#h2o.ifelse'><p>H2O Apply Conditional Statement</p></a></li>
<li><a href='#h2o.import_hive_table'><p>Import Hive Table into H2O</p></a></li>
<li><a href='#h2o.import_mojo'><p>Imports a MOJO under given path, creating a Generic model with it.</p></a></li>
<li><a href='#h2o.import_sql_select'><p>Import SQL table that is result of SELECT SQL query into H2O</p></a></li>
<li><a href='#h2o.import_sql_table'><p>Import SQL Table into H2O</p></a></li>
<li><a href='#h2o.importFile'><p>Import Files into H2O</p></a></li>
<li><a href='#h2o.impute'><p>Basic Imputation of H2O Vectors</p></a></li>
<li><a href='#h2o.infogram'><p>H2O Infogram</p></a></li>
<li><a href='#h2o.infogram_train_subset_models'><p>Train models over subsets selected using infogram</p></a></li>
<li><a href='#h2o.init'><p>Initialize and Connect to H2O</p></a></li>
<li><a href='#h2o.insertMissingValues'><p>Insert Missing Values into an H2OFrame</p></a></li>
<li><a href='#h2o.inspect_model_fairness'><p>Produce plots and dataframes related to a single model fairness.</p></a></li>
<li><a href='#h2o.interaction'><p>Categorical Interaction Feature Creation in H2O</p></a></li>
<li><a href='#h2o.is_client'><p>Check Client Mode Connection</p></a></li>
<li><a href='#h2o.isax'><p>iSAX</p></a></li>
<li><a href='#h2o.ischaracter'><p>Check if character</p></a></li>
<li><a href='#h2o.isfactor'><p>Check if factor</p></a></li>
<li><a href='#h2o.isnumeric'><p>Check if numeric</p></a></li>
<li><a href='#h2o.isolationForest'><p>Trains an Isolation Forest model</p></a></li>
<li><a href='#h2o.isotonicregression'><p>Build an Isotonic Regression model</p></a></li>
<li><a href='#h2o.keyof'><p>Method on <code>Keyed</code> objects allowing to obtain their key.</p></a></li>
<li><a href='#h2o.kfold_column'><p>Produce a k-fold column vector.</p></a></li>
<li><a href='#h2o.killMinus3'><p>Dump the stack into the JVM's stdout.</p></a></li>
<li><a href='#h2o.kmeans'><p>Performs k-means clustering on an H2O dataset</p></a></li>
<li><a href='#h2o.kolmogorov_smirnov'><p>Kolmogorov-Smirnov metric for binomial models</p></a></li>
<li><a href='#h2o.kurtosis'><p>Kurtosis of a column</p></a></li>
<li><a href='#h2o.learning_curve_plot'><p>Learning Curve Plot</p></a></li>
<li><a href='#h2o.levels'><p>Return the levels from the column requested column.</p></a></li>
<li><a href='#h2o.list_all_extensions'><p>List all H2O registered extensions</p></a></li>
<li><a href='#h2o.list_api_extensions'><p>List registered API extensions</p></a></li>
<li><a href='#h2o.list_core_extensions'><p>List registered core extensions</p></a></li>
<li><a href='#h2o.list_jobs'><p>Return list of jobs performed by the H2O cluster</p></a></li>
<li><a href='#h2o.list_models'><p>Get an list of all model ids present in the cluster</p></a></li>
<li><a href='#h2o.listTimezones'><p>List all of the Time Zones Acceptable by the H2O cluster.</p></a></li>
<li><a href='#h2o.load_frame'><p>Load frame previously stored in H2O's native format.</p></a></li>
<li><a href='#h2o.loadGrid'><p>Loads previously saved grid with all it's models from the same folder</p></a></li>
<li><a href='#h2o.loadModel'><p>Load H2O Model from HDFS or Local Disk</p></a></li>
<li><a href='#h2o.log'><p>Compute the logarithm of x</p></a></li>
<li><a href='#h2o.log10'><p>Compute the log10 of x</p></a></li>
<li><a href='#h2o.log1p'><p>Compute the log1p of x</p></a></li>
<li><a href='#h2o.log2'><p>Compute the log2 of x</p></a></li>
<li><a href='#h2o.logAndEcho'><p>Log a message on the server-side logs</p></a></li>
<li><a href='#h2o.loglikelihood'><p>Retrieve the log likelihood value</p></a></li>
<li><a href='#h2o.logloss'><p>Retrieve the Log Loss Value</p></a></li>
<li><a href='#h2o.ls'><p>List Keys on an H2O Cluster</p></a></li>
<li><a href='#h2o.lstrip'><p>Strip set from left</p></a></li>
<li><a href='#h2o.mae'><p>Retrieve the Mean Absolute Error Value</p></a></li>
<li><a href='#h2o.make_leaderboard'><p>Create a leaderboard from a list of models, grids and/or automls.</p></a></li>
<li><a href='#h2o.make_metrics'><p>Create Model Metrics from predicted and actual values in H2O</p></a></li>
<li><a href='#h2o.makeGLMModel'><p>Set betas of an existing H2O GLM Model</p></a></li>
<li><a href='#h2o.match'><p>Value Matching in H2O</p></a></li>
<li><a href='#h2o.max'><p>Returns the maxima of the input values.</p></a></li>
<li><a href='#h2o.mean'><p>Compute the frame's mean by-column (or by-row).</p></a></li>
<li><a href='#h2o.mean_per_class_error'><p>Retrieve the mean per class error</p></a></li>
<li><a href='#h2o.mean_residual_deviance'><p>Retrieve the Mean Residual Deviance value</p></a></li>
<li><a href='#h2o.median'><p>H2O Median</p></a></li>
<li><a href='#h2o.melt'><p>Converts a frame to key-value representation while optionally skipping NA values.</p>
Inverse operation to h2o.pivot.</a></li>
<li><a href='#h2o.merge'><p>Merge Two H2O Data Frames</p></a></li>
<li><a href='#h2o.metric'><p>H2O Model Metric Accessor Functions</p></a></li>
<li><a href='#h2o.min'><p>Returns the minima of the input values.</p></a></li>
<li><a href='#h2o.mktime'><p>Compute msec since the Unix Epoch</p></a></li>
<li><a href='#h2o.model_correlation'><p>Model Prediction Correlation</p></a></li>
<li><a href='#h2o.model_correlation_heatmap'><p>Model Prediction Correlation Heatmap</p></a></li>
<li><a href='#h2o.modelSelection'><p>H2O ModelSelection is used to build the best model with one predictor, two predictors, ... up to max_predictor_number</p>
specified in the algorithm parameters when mode=allsubsets.  The best model is the one with the highest R2 value.  When
mode=maxr, the model returned is no longer guaranteed to have the best R2 value.</a></li>
<li><a href='#h2o.mojo_predict_csv'><p>H2O Prediction from R without having H2O running</p></a></li>
<li><a href='#h2o.mojo_predict_df'><p>H2O Prediction from R without having H2O running</p></a></li>
<li><a href='#h2o.month'><p>Convert Milliseconds to Months in H2O Datasets</p></a></li>
<li><a href='#h2o.mse'><p>Retrieves Mean Squared Error Value</p></a></li>
<li><a href='#h2o.multinomial_auc_table'><p>Retrieve the all AUC values in a table (One to Rest, One to One, macro and weighted average)</p>
for mutlinomial classification.</a></li>
<li><a href='#h2o.multinomial_aucpr_table'><p>Retrieve the all PR AUC values in a table (One to Rest, One to One, macro and weighted average)</p>
for mutlinomial classification.</a></li>
<li><a href='#h2o.na_omit'><p>Remove Rows With NAs</p></a></li>
<li><a href='#h2o.nacnt'><p>Count of NAs per column</p></a></li>
<li><a href='#h2o.naiveBayes'><p>Compute naive Bayes probabilities on an H2O dataset.</p></a></li>
<li><a href='#h2o.names'><p>Column names of an H2OFrame</p></a></li>
<li><a href='#h2o.nchar'><p>String length</p></a></li>
<li><a href='#h2o.ncol'><p>Return the number of columns present in x.</p></a></li>
<li><a href='#h2o.negative_log_likelihood'><p>Extracts the final training negative log likelihood of a GLM model.</p></a></li>
<li><a href='#h2o.networkTest'><p>View Network Traffic Speed</p></a></li>
<li><a href='#h2o.nlevels'><p>Get the number of factor levels for this frame.</p></a></li>
<li><a href='#h2o.no_progress'><p>Disable Progress Bar</p></a></li>
<li><a href='#h2o.nrow'><p>Return the number of rows present in x.</p></a></li>
<li><a href='#h2o.null_deviance'><p>Retrieve the null deviance</p></a></li>
<li><a href='#h2o.null_dof'><p>Retrieve the null degrees of freedom</p></a></li>
<li><a href='#h2o.num_iterations'><p>Retrieve the number of iterations.</p></a></li>
<li><a href='#h2o.num_valid_substrings'><p>Count of substrings &gt;= 2 chars that are contained in file</p></a></li>
<li><a href='#h2o.openLog'><p>View H2O R Logs</p></a></li>
<li><a href='#h2o.pareto_front'><p>Plot Pareto front</p></a></li>
<li><a href='#h2o.parseRaw'><p>H2O Data Parsing</p></a></li>
<li><a href='#h2o.parseSetup'><p>Get a parse setup back for the staged data.</p></a></li>
<li><a href='#h2o.partialPlot'><p>Partial Dependence Plots</p></a></li>
<li><a href='#h2o.pd_multi_plot'><p>Plot partial dependencies for a variable across multiple models</p></a></li>
<li><a href='#h2o.pd_plot'><p>Plot partial dependence for a variable</p></a></li>
<li><a href='#h2o.performance'><p>Model Performance Metrics in H2O</p></a></li>
<li><a href='#h2o.permutation_importance'><p>Calculate Permutation Feature Importance.</p></a></li>
<li><a href='#h2o.permutation_importance_plot'><p>Plot Permutation Variable Importances.</p></a></li>
<li><a href='#h2o.pivot'><p>Pivot a frame</p></a></li>
<li><a href='#h2o.prcomp'><p>Principal component analysis of an H2O data frame</p></a></li>
<li><a href='#h2o.predict'><p>Predict on an H2O Model</p></a></li>
<li><a href='#h2o.predict_json'><p>H2O Prediction from R without having H2O running</p></a></li>
<li><a href='#h2o.predict_rules'><p>Evaluates validity of the given rules on the given data. Returns a frame with a column per each input rule id,</p>
representing a flag whether given rule is applied to the observation or not.</a></li>
<li><a href='#h2o.predicted_vs_actual_by_variable'><p>Calculates per-level mean of predicted value vs actual value for a given variable.</p></a></li>
<li><a href='#h2o.print'><p>Print An H2OFrame</p></a></li>
<li><a href='#h2o.prod'><p>Return the product of all the values present in its arguments.</p></a></li>
<li><a href='#h2o.proj_archetypes'><p>Convert Archetypes to Features from H2O GLRM Model</p></a></li>
<li><a href='#h2o.psvm'><p>Trains a Support Vector Machine model on an H2O dataset</p></a></li>
<li><a href='#h2o.qini'><p>Retrieve the default Qini value</p></a></li>
<li><a href='#h2o.quantile'><p>Quantiles of H2O Frames.</p></a></li>
<li><a href='#h2o.r2'><p>Retrieve the R2 value</p></a></li>
<li><a href='#h2o.randomForest'><p>Build a Random Forest model</p></a></li>
<li><a href='#h2o.range'><p>Returns a vector containing the minimum and maximum of all the given arguments.</p></a></li>
<li><a href='#h2o.rank_within_group_by'><p>This function will add a new column rank where the ranking is produced as follows:</p>
1. sorts the H2OFrame by columns sorted in by columns specified in group_by_cols and sort_cols in the directions
specified by the ascending for the sort_cols.  The sort directions for the group_by_cols are ascending only.
2. A new rank column is added to the frame which will contain a rank assignment performed next.  The user can
choose to assign a name to this new column.  The default name is New_Rank_column.
3. For each groupby groups, a rank is assigned to the row starting from 1, 2, ... to the end of that group.
4. If sort_cols_sorted is TRUE, a final sort on the frame will be performed frame according to the sort_cols and
the sort directions in ascending.  If sort_cols_sorted is FALSE (by default), the frame from step 3 will be
returned as is with no extra sort.  This may provide a small speedup if desired.</a></li>
<li><a href='#h2o.rapids'><p>Execute a Rapids expression.</p></a></li>
<li><a href='#h2o.rbind'><p>Combine H2O Datasets by Rows</p></a></li>
<li><a href='#h2o.reconstruct'><p>Reconstruct Training Data via H2O GLRM Model</p></a></li>
<li><a href='#h2o.relevel'><p>Reorders levels of an H2O factor, similarly to standard R's relevel.</p></a></li>
<li><a href='#h2o.relevel_by_frequency'><p>Reorders levels of factor columns by the frequencies for the individual levels.</p></a></li>
<li><a href='#h2o.removeAll'><p>Remove All Objects on the H2O Cluster</p></a></li>
<li><a href='#h2o.removeVecs'><p>Delete Columns from an H2OFrame</p></a></li>
<li><a href='#h2o.rep_len'><p>Replicate Elements of Vectors or Lists into H2O</p></a></li>
<li><a href='#h2o.reset_threshold'><p>Reset model threshold and return old threshold value.</p></a></li>
<li><a href='#h2o.residual_analysis_plot'><p>Residual Analysis</p></a></li>
<li><a href='#h2o.residual_deviance'><p>Retrieve the residual deviance</p></a></li>
<li><a href='#h2o.residual_dof'><p>Retrieve the residual degrees of freedom</p></a></li>
<li><a href='#h2o.result'><p>Retrieve the results to view the best predictor subsets.</p></a></li>
<li><a href='#h2o.resume'><p>Triggers auto-recovery resume - this will look into configured recovery dir and resume and</p>
tasks that were interrupted by unexpected cluster stopping.</a></li>
<li><a href='#h2o.resumeGrid'><p>Resume previously stopped grid training.</p></a></li>
<li><a href='#h2o.rm'><p>Delete Objects In H2O</p></a></li>
<li><a href='#h2o.rmse'><p>Retrieves Root Mean Squared Error Value</p></a></li>
<li><a href='#h2o.rmsle'><p>Retrieve the Root Mean Squared Log Error</p></a></li>
<li><a href='#h2o.round'><p>Round doubles/floats to the given number of decimal places.</p></a></li>
<li><a href='#h2o.rstrip'><p>Strip set from right</p></a></li>
<li><a href='#h2o.rule_importance'><p>This function returns the table with estimated coefficients and language representations (in case it is a rule)</p>
for each of the significant baselearners.</a></li>
<li><a href='#h2o.rulefit'><p>Build a RuleFit Model</p></a></li>
<li><a href='#h2o.runif'><p>Produce a Vector of Random Uniform Numbers</p></a></li>
<li><a href='#h2o.save_frame'><p>Store frame data in H2O's native format.</p></a></li>
<li><a href='#h2o.save_mojo'><p>Save an H2O Model Object as Mojo to Disk</p></a></li>
<li><a href='#h2o.save_to_hive'><p>Save contents of this data frame into a Hive table</p></a></li>
<li><a href='#h2o.saveGrid'><p>Saves an existing Grid of models into a given folder.</p></a></li>
<li><a href='#h2o.saveModel'><p>Save an H2O Model Object to Disk</p></a></li>
<li><a href='#h2o.saveModelDetails'><p>Save an H2O Model Details</p></a></li>
<li><a href='#h2o.saveMojo'><p>Deprecated - use h2o.save_mojo instead. Save an H2O Model Object as Mojo to Disk</p></a></li>
<li><a href='#h2o.scale'><p>Scaling and Centering of an H2OFrame</p></a></li>
<li><a href='#h2o.scoreHistory'><p>Retrieve Model Score History</p></a></li>
<li><a href='#h2o.scoreHistoryGAM'><p>Retrieve GLM Model Score History buried in GAM model</p></a></li>
<li><a href='#h2o.screeplot'><p>Scree Plot</p></a></li>
<li><a href='#h2o.sd'><p>Standard Deviation of a column of data.</p></a></li>
<li><a href='#h2o.sdev'><p>Retrieve the standard deviations of principal components</p></a></li>
<li><a href='#h2o.set_s3_credentials'><p>Creates a new Amazon S3 client internally with specified credentials.</p></a></li>
<li><a href='#h2o.setLevels'><p>Set Levels of H2O Factor Column</p></a></li>
<li><a href='#h2o.setTimezone'><p>Set the Time Zone on the H2O cluster</p></a></li>
<li><a href='#h2o.shap_explain_row_plot'><p>SHAP Local Explanation</p></a></li>
<li><a href='#h2o.shap_summary_plot'><p>SHAP Summary Plot</p></a></li>
<li><a href='#h2o.show_progress'><p>Enable Progress Bar</p></a></li>
<li><a href='#h2o.shutdown'><p>Shut Down H2O Instance</p></a></li>
<li><a href='#h2o.signif'><p>Round doubles/floats to the given number of significant digits.</p></a></li>
<li><a href='#h2o.sin'><p>Compute the sine of x</p></a></li>
<li><a href='#h2o.skewness'><p>Skewness of a column</p></a></li>
<li><a href='#h2o.splitFrame'><p>Split an H2O Data Set</p></a></li>
<li><a href='#h2o.sqrt'><p>Compute the square root of x</p></a></li>
<li><a href='#h2o.stackedEnsemble'><p>Builds a Stacked Ensemble</p></a></li>
<li><a href='#h2o.startLogging'><p>Start Writing H2O R Logs</p></a></li>
<li><a href='#h2o.std_coef_plot'><p>Plot Standardized Coefficient Magnitudes</p></a></li>
<li><a href='#h2o.stopLogging'><p>Stop Writing H2O R Logs</p></a></li>
<li><a href='#h2o.str'><p>Display the structure of an H2OFrame object</p></a></li>
<li><a href='#h2o.stringdist'><p>Compute element-wise string distances between two H2OFrames</p></a></li>
<li><a href='#h2o.strsplit'><p>String Split</p></a></li>
<li><a href='#h2o.sub'><p>String Substitute</p></a></li>
<li><a href='#h2o.substring'><p>Substring</p></a></li>
<li><a href='#h2o.sum'><p>Compute the frame's sum by-column (or by-row).</p></a></li>
<li><a href='#h2o.summary'><p>Summarizes the columns of an H2OFrame.</p></a></li>
<li><a href='#h2o.svd'><p>Singular value decomposition of an H2O data frame using the power method</p></a></li>
<li><a href='#h2o.table'><p>Cross Tabulation and Table Creation in H2O</p></a></li>
<li><a href='#h2o.tabulate'><p>Tabulation between Two Columns of an H2OFrame</p></a></li>
<li><a href='#h2o.tan'><p>Compute the tangent of x</p></a></li>
<li><a href='#h2o.tanh'><p>Compute the hyperbolic tangent of x</p></a></li>
<li><a href='#h2o.target_encode_apply'><p>Apply Target Encoding Map to Frame</p></a></li>
<li><a href='#h2o.target_encode_create'><p>Create Target Encoding Map</p></a></li>
<li><a href='#h2o.targetencoder'><p>Transformation of a categorical variable with a mean value of the target variable</p></a></li>
<li><a href='#h2o.tf_idf'><p>Computes TF-IDF values for each word in given documents.</p></a></li>
<li><a href='#h2o.thresholds_and_metric_scores'><p>Retrieve the thresholds and metric scores table</p></a></li>
<li><a href='#h2o.toFrame'><p>Convert a word2vec model into an H2OFrame</p></a></li>
<li><a href='#h2o.tokenize'><p>Tokenize String</p></a></li>
<li><a href='#h2o.tolower'><p>Convert strings to lowercase</p></a></li>
<li><a href='#h2o.topBottomN'><p>H2O topBottomN</p></a></li>
<li><a href='#h2o.topN'><p>H2O topN</p></a></li>
<li><a href='#h2o.tot_withinss'><p>Get the total within cluster sum of squares.</p></a></li>
<li><a href='#h2o.totss'><p>Get the total sum of squares.</p></a></li>
<li><a href='#h2o.toupper'><p>Convert strings to uppercase</p></a></li>
<li><a href='#h2o.train_segments'><p>H2O Segmented-Data Bulk Model Training</p></a></li>
<li><a href='#h2o.transform'><p>Use H2O Transformation model and apply the underlying transformation</p></a></li>
<li><a href='#h2o.transform_frame'><p>Use GRLM to transform a frame.</p></a></li>
<li><a href='#h2o.transform_word2vec'><p>Transform words (or sequences of words) to vectors using a word2vec model.</p></a></li>
<li><a href='#h2o.transform+2CH2OTargetEncoderModel-method'><p>Applies target encoding to a given dataset</p></a></li>
<li><a href='#h2o.transform+2CH2OWordEmbeddingModel-method'><p>Transform words (or sequences of words) to vectors using a word2vec model.</p></a></li>
<li><a href='#h2o.trim'><p>Trim Space</p></a></li>
<li><a href='#h2o.trunc'><p>Truncate values in x toward 0</p></a></li>
<li><a href='#h2o.unique'><p>H2O Unique</p></a></li>
<li><a href='#h2o.upliftRandomForest'><p>Build a Uplift Random Forest model</p></a></li>
<li><a href='#h2o.upload_model'><p>Upload a binary model from the provided local path to the H2O cluster.</p>
(H2O model can be saved in a binary form either by saveModel() or by download_model() function.)</a></li>
<li><a href='#h2o.upload_mojo'><p>Imports a MOJO from a local filesystem, creating a Generic model with it.</p></a></li>
<li><a href='#h2o.var'><p>Variance of a column or covariance of columns.</p></a></li>
<li><a href='#h2o.varimp'><p>Retrieve the variable importance.</p></a></li>
<li><a href='#h2o.varimp_heatmap'><p>Variable Importance Heatmap across multiple models</p></a></li>
<li><a href='#h2o.varimp_plot'><p>Plot Variable Importances</p></a></li>
<li><a href='#h2o.varimp+2CH2OAutoML-method'><p>Retrieve the variable importance.</p></a></li>
<li><a href='#h2o.varimp+2CH2OFrame-method'><p>Retrieve the variable importance.</p></a></li>
<li><a href='#h2o.varimp+2CH2OModel-method'><p>Retrieve the variable importance.</p></a></li>
<li><a href='#h2o.varsplits'><p>Retrieve per-variable split information for a given Isolation Forest model.</p>
Output will include:
- count - The number of times a variable was used to make a split.
- aggregated_split_ratios - The split ratio is defined as &quot;abs(#left_observations - #right_observations) / #before_split&quot;.
Even splits (#left_observations approx the same as #right_observations) contribute
less to the total aggregated split ratio value for the given feature;
highly imbalanced splits (eg. #left_observations &gt;&gt; #right_observations) contribute more.
- aggregated_split_depths - The sum of all depths of a variable used to make a split. (If a variable is used
on level N of a tree, then it contributes with N to the total aggregate.)</a></li>
<li><a href='#h2o.week'><p>Convert Milliseconds to Week of Week Year in H2O Datasets</p></a></li>
<li><a href='#h2o.weights'><p>Retrieve the respective weight matrix</p></a></li>
<li><a href='#h2o.which'><p>Which indices are TRUE?</p></a></li>
<li><a href='#h2o.which_max'><p>Which indice contains the max value?</p></a></li>
<li><a href='#h2o.which_min'><p>Which index contains the min value?</p></a></li>
<li><a href='#h2o.withinss'><p>Get the Within SS</p></a></li>
<li><a href='#h2o.word2vec'><p>Trains a word2vec model on a String column of an H2O data frame</p></a></li>
<li><a href='#h2o.xgboost'><p>Build an eXtreme Gradient Boosting model</p></a></li>
<li><a href='#h2o.xgboost.available'><p>Determines whether an XGBoost model can be built</p></a></li>
<li><a href='#h2o.year'><p>Convert Milliseconds to Years in H2O Datasets</p></a></li>
<li><a href='#H2OAutoML-class'><p>The H2OAutoML class</p></a></li>
<li><a href='#H2OClusteringModel-class'><p>The H2OClusteringModel object.</p></a></li>
<li><a href='#H2OConnection-class'><p>The H2OConnection class.</p></a></li>
<li><a href='#H2OConnectionMutableState'><p>The H2OConnectionMutableState class</p></a></li>
<li><a href='#H2OCoxPHModel-class'><p>The H2OCoxPHModel object.</p></a></li>
<li><a href='#H2OCoxPHModelSummary-class'><p>The H2OCoxPHModelSummary object.</p></a></li>
<li><a href='#H2OFrame-class'><p>The H2OFrame class</p></a></li>
<li><a href='#H2OFrame-Extract'><p>Extract or Replace Parts of an H2OFrame Object</p></a></li>
<li><a href='#H2OGrid-class'><p>H2O Grid</p></a></li>
<li><a href='#H2OInfogram'><p>wrapper function for instantiating H2OInfogram</p></a></li>
<li><a href='#H2OInfogram-class'><p>H2OInfogram class</p></a></li>
<li><a href='#H2OLeafNode-class'><p>The H2OLeafNode class.</p></a></li>
<li><a href='#H2OModel-class'><p>The H2OModel object.</p></a></li>
<li><a href='#H2OModelFuture-class'><p>H2O Future Model</p></a></li>
<li><a href='#H2OModelMetrics-class'><p>The H2OModelMetrics Object.</p></a></li>
<li><a href='#H2ONode-class'><p>The H2ONode class.</p></a></li>
<li><a href='#H2OSegmentModels-class'><p>H2O Segment Models</p></a></li>
<li><a href='#H2OSegmentModelsFuture-class'><p>H2O Future Segment Models</p></a></li>
<li><a href='#H2OSplitNode-class'><p>The H2OSplitNode class.</p></a></li>
<li><a href='#H2OTree-class'><p>The H2OTree class.</p></a></li>
<li><a href='#housevotes'><p>United States Congressional Voting Records 1984</p></a></li>
<li><a href='#initialize+2CH2OInfogram-method'><p>Method on <code>H2OInfogram</code> object which in this case is to instantiate and initialize it</p></a></li>
<li><a href='#iris'><p>Edgar Anderson's Iris Data</p></a></li>
<li><a href='#is.character'><p>Check if character</p></a></li>
<li><a href='#is.factor'><p>Check if factor</p></a></li>
<li><a href='#is.h2o'><p>Is H2O Frame object</p></a></li>
<li><a href='#is.numeric'><p>Check if numeric</p></a></li>
<li><a href='#Keyed-class'><p>Virtual Keyed class</p></a></li>
<li><a href='#length+2CH2OTree-method'><p>Overrides the behavior of length() function on H2OTree class. Returns number of nodes in an <code>H2OTree</code></p></a></li>
<li><a href='#Logical-or'><p>Logical or for H2OFrames</p></a></li>
<li><a href='#model_cache-class'><p>Needed to be able to memoise the models</p></a></li>
<li><a href='#ModelAccessors'><p>Accessor Methods for H2OModel Object</p></a></li>
<li><a href='#names.H2OFrame'><p>Column names of an H2OFrame</p></a></li>
<li><a href='#Ops.H2OFrame'><p>S3 Group Generic Functions for H2O</p></a></li>
<li><a href='#plot+2CH2OParetoFront-method'><p>Plot Pareto front</p></a></li>
<li><a href='#plot.H2OInfogram'><p>Plot an H2O Infogram</p></a></li>
<li><a href='#plot.H2OModel'><p>Plot an H2O Model</p></a></li>
<li><a href='#plot.H2OTabulate'><p>Plot an H2O Tabulate Heatmap</p></a></li>
<li><a href='#predict_contributions.H2OModel'><p>Predict feature contributions - SHAP values on an H2O Model (only DRF, GBM, XGBoost models and equivalent imported MOJOs).</p></a></li>
<li><a href='#predict_leaf_node_assignment.H2OModel'><p>Predict the Leaf Node Assignment on an H2O Model</p></a></li>
<li><a href='#predict.H2OAutoML'><p>Predict on an AutoML object</p></a></li>
<li><a href='#predict.H2OModel'><p>Predict on an H2O Model</p></a></li>
<li><a href='#print.H2OFrame'><p>Print An H2OFrame</p></a></li>
<li><a href='#print.H2OTable'><p>Print method for H2OTable objects</p></a></li>
<li><a href='#prostate'><p>Prostate Cancer Study</p></a></li>
<li><a href='#range.H2OFrame'><p>Range of an H2O Column</p></a></li>
<li><a href='#row_to_tree_assignment.H2OModel'><p>Output row to tree assignment for the model and provided training data.</p></a></li>
<li><a href='#scale'><p>Scaling and Centering of an H2OFrame</p></a></li>
<li><a href='#show+2CH2OAutoML-method'><p>Format AutoML object in user-friendly way</p></a></li>
<li><a href='#show+2CH2OParetoFront-method'><p>Show H2OParetoFront</p></a></li>
<li><a href='#staged_predict_proba.H2OModel'><p>Predict class probabilities at each stage of an H2O Model</p></a></li>
<li><a href='#str.H2OFrame'><p>Display the structure of an H2OFrame object</p></a></li>
<li><a href='#summary+2CH2OAutoML-method'><p>Format AutoML object in user-friendly way</p></a></li>
<li><a href='#summary+2CH2OCoxPHModel-method'><p>Summary method for H2OCoxPHModel objects</p></a></li>
<li><a href='#summary+2CH2OGrid-method'><p>Format grid object in user-friendly way</p></a></li>
<li><a href='#summary+2CH2OModel-method'><p>Print the Model Summary</p></a></li>
<li><a href='#use.package'><p>Use optional package</p></a></li>
<li><a href='#walking'><p>Muscular Actuations for Walking Subject</p></a></li>
<li><a href='#zzz'><p>Shutdown H2O cluster after examples run</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>3.44.0.3</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Interface for the 'H2O' Scalable Machine Learning Platform</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-20</td>
</tr>
<tr>
<td>Description:</td>
<td>R interface for 'H2O', the scalable open source machine learning
    platform that offers parallelized implementations of many supervised and
    unsupervised machine learning algorithms such as Generalized Linear
    Models (GLM), Gradient Boosting Machines (including XGBoost), Random Forests,
    Deep Neural Networks (Deep Learning), Stacked Ensembles, Naive Bayes,
    Generalized Additive Models (GAM), ANOVA GLM, Cox Proportional Hazards, K-Means, PCA, ModelSelection,
    Word2Vec, as well as a fully automatic machine learning algorithm (H2O AutoML).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License (== 2.0)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/h2oai/h2o-3">https://github.com/h2oai/h2o-3</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/h2oai/h2o-3/issues">https://github.com/h2oai/h2o-3/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Java (&gt;= 8, &lt;= 17)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.13.0), methods, stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, tools, utils, RCurl, jsonlite</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2 (&ge; 3.3.0), mlbench, Matrix, slam, bit64 (&ge; 0.9.7),
data.table (&ge; 1.9.8), rgl (&ge; 0.100.19), plot3Drgl (&ge; 1.0.1),
survival, DT, IRdisplay, htmltools, plotly, repr, curl, scales</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Collate:</td>
<td>'adaboost.R' 'admissibleml.R' 'aggregator.R' 'anovaglm.R'
'astfun.R' 'automl.R' 'classes.R' 'communication.R' 'config.R'
'connection.R' 'constants.R' 'coxph.R' 'coxphutils.R'
'datasets.R' 'decisiontree.R' 'deeplearning.R' 'edicts.R'
'explain.R' 'export.R' 'extendedisolationforest.R' 'frame.R'
'gam.R' 'gbm.R' 'generic.R' 'glm.R' 'glrm.R' 'grid.R'
'import.R' 'infogram.R' 'isolationforest.R'
'isotonicregression.R' 'kmeans.R' 'kvstore.R' 'locate.R'
'logging.R' 'models.R' 'modelselection.R' 'naivebayes.R'
'parse.R' 'pca.R' 'permutation_varimp.R' 'predict.R' 'psvm.R'
'randomforest.R' 'rulefit.R' 'segment.R' 'stackedensemble.R'
'svd.R' 'targetencoder.R' 'tf-idf.R' 'upliftrandomforest.R'
'w2vutils.R' 'word2vec.R' 'xgboost.R' 'zzz.R'</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-10 12:15:19 UTC; tomasfryda</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomas Fryda [aut, cre],
  Erin LeDell [aut],
  Navdeep Gill [aut],
  Spencer Aiello [aut],
  Anqi Fu [aut],
  Arno Candel [aut],
  Cliff Click [aut],
  Tom Kraljevic [aut],
  Tomas Nykodym [aut],
  Patrick Aboyoun [aut],
  Michal Kurka [aut],
  Michal Malohlava [aut],
  Sebastien Poirier [aut],
  Wendy Wong [aut],
  Ludi Rehak [ctb],
  Eric Eckstrand [ctb],
  Brandon Hill [ctb],
  Sebastian Vidrio [ctb],
  Surekha Jadhawani [ctb],
  Amy Wang [ctb],
  Raymond Peck [ctb],
  Jan Gorecki [ctb],
  Matt Dowle [ctb],
  Yuan Tang [ctb],
  Lauren DiPerna [ctb],
  Veronika Maurerova [ctb],
  Yuliia Syzon [ctb],
  Adam Valenta [ctb],
  Marek Novotny [ctb],
  H2O.ai [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomas Fryda &lt;tomas.fryda@h2o.ai&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-11 11:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='h2o-package'>
H2O R Interface
</h2><span id='topic+h2o-package'></span><span id='topic+h2o'></span>

<h3>Description</h3>

<p>This is a package for running H2O via its REST API from within R. To communicate with a H2O instance, the version of the R package must match the version of H2O. When connecting to a new H2O cluster, it is necessary to re-run the initializer.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> h2o</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 3.44.0.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Branch: </td><td style="text-align: left;"> rel-3.44.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> Wed Dec 20 16:35:40 UTC 2023</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> Apache License (== 2.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.13.0), RCurl, jsonlite, statmod, tools, methods, utils</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>H2O is the scalable open source machine learning platform that offers parallelized implementations of many supervised and unsupervised machine learning algorithms such as Generalized Linear Models (GLM), Gradient Boosting Machines (including XGBoost), Random Forests, Deep Neural Networks (Deep Learning), Stacked Ensembles, Naive Bayes, Generalized Additive Models (GAM), ANOVA GLM, Maximum R GLM (maxrglm), Cox Proportional Hazards, K-Means, PCA, Word2Vec, as well as a fully automatic machine learning algorithm (H2O AutoML).  As an example, to run GLM, call <code><a href="#topic+h2o.glm">h2o.glm</a></code> with the H2O parsed data and parameters (response variable, error distribution, etc.) as arguments.
</p>
<p>This package enables the use of the H2O machine learning platform commands in R.  To use H2O from R, you must start or connect to the &quot;H2O cluster&quot;, the term we use to describe the backend H2O Java engine. To run H2O on your local machine, call <code><a href="#topic+h2o.init">h2o.init</a></code> without any arguments, and H2O will be automatically launched at localhost:54321, where the IP is &quot;127.0.0.1&quot; and the port is 54321. If you have the H2O cluster running on a remote machine (e.g. AWS EC2), you must provide the IP and port of the remote machine as arguments to the <code><a href="#topic+h2o.init">h2o.init</a></code> call.
</p>
<p>Note that no actual data is stored in the R workspace; and no actual work is carried out by R. R only saves the named objects, which uniquely identify the data set, model, etc on the server. When the user makes a request, R queries the server via the REST API, which returns a JSON file with the relevant information that R then displays in the console.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Tomas Fryda &lt;tomas.fryda@h2o.ai&gt;
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://h2o.ai">H2O.ai Homepage</a>
</p>
</li>
<li> <p><a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html">H2O User Guide</a>
</p>
</li>
<li> <p><a href="https://github.com/h2oai/h2o-3">H2O on GitHub</a>
</p>
</li></ul>


<hr>
<h2 id='.addParm'>TODO: No objects in this file are being used. Either remove file or use objects.</h2><span id='topic+.addParm'></span>

<h3>Description</h3>

<p>Append a &lt;key,value&gt; pair to a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.addParm(parms, k, v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".addParm_+3A_parms">parms</code></td>
<td>
<p>a list to add the &lt;k,v&gt; pair to</p>
</td></tr>
<tr><td><code id=".addParm_+3A_k">k</code></td>
<td>
<p>a key, typically the name of some algorithm parameter</p>
</td></tr>
<tr><td><code id=".addParm_+3A_v">v</code></td>
<td>
<p>a value, the value of the algorithm parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Contained here are a set of helper methods that perform type checking on the value passed in.
</p>

<hr>
<h2 id='.check_for_ggplot2'>Stop with a user friendly message if a user is missing the ggplot2 package or has an old version of it.</h2><span id='topic+.check_for_ggplot2'></span>

<h3>Description</h3>

<p>Stop with a user friendly message if a user is missing the ggplot2 package or has an old version of it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.check_for_ggplot2(version = "3.0.0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".check_for_ggplot2_+3A_version">version</code></td>
<td>
<p>minimal required ggplot2 version</p>
</td></tr>
</table>

<hr>
<h2 id='.collapse'>Helper Collapse Function</h2><span id='topic+.collapse'></span>

<h3>Description</h3>

<p>Collapse a character vector into a ','-sep array of the form: [thing1,thing2,...]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.collapse(v)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".collapse_+3A_v">v</code></td>
<td>
<p>Character vector.</p>
</td></tr>
</table>

<hr>
<h2 id='.consolidate_varimps'>Consolidate variable importances</h2><span id='topic+.consolidate_varimps'></span>

<h3>Description</h3>

<p>Consolidation works in the following way:
1. if varimp variable is in x =&gt; add it to consolidated_varimps
2. for all remaining varimp variables:
1. find the longest prefix of varimp variable that is in x and add it to the consolidated varimp
2. if there was no match, throw an error
3. normalize the consolidated_varimps so they sum up to 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.consolidate_varimps(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".consolidate_varimps_+3A_model">model</code></td>
<td>
<p>H2OModel</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sorted named vector
</p>

<hr>
<h2 id='.create_leaderboard'>Create a leaderboard like data frame for <code>models</code></h2><span id='topic+.create_leaderboard'></span>

<h3>Description</h3>

<p>Create a leaderboard like data frame for <code>models</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.create_leaderboard(models_info, leaderboard_frame, top_n = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".create_leaderboard_+3A_models_info">models_info</code></td>
<td>
<p>H2OAutoML object or list of models</p>
</td></tr>
<tr><td><code id=".create_leaderboard_+3A_leaderboard_frame">leaderboard_frame</code></td>
<td>
<p>when provided with list of models, use this frame to calculate metrics</p>
</td></tr>
<tr><td><code id=".create_leaderboard_+3A_top_n">top_n</code></td>
<td>
<p>create leaderboard with just top_n models</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame
</p>

<hr>
<h2 id='.customized_call'>A helper function that makes it easier to override/add params in a function call.</h2><span id='topic+.customized_call'></span>

<h3>Description</h3>

<p>A helper function that makes it easier to override/add params in a function call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.customized_call(fun, ..., overridable_defaults = NULL, overrides = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".customized_call_+3A_fun">fun</code></td>
<td>
<p>Function to be called</p>
</td></tr>
<tr><td><code id=".customized_call_+3A_...">...</code></td>
<td>
<p>Parameters that can't be overridden</p>
</td></tr>
<tr><td><code id=".customized_call_+3A_overridable_defaults">overridable_defaults</code></td>
<td>
<p>List of parameters and values that can be overridden</p>
</td></tr>
<tr><td><code id=".customized_call_+3A_overrides">overrides</code></td>
<td>
<p>Parameters to add/override.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result of <code>fun</code>
</p>

<hr>
<h2 id='.find_appropriate_column_name'>Tries to match a <code>fuzzy_col_name</code> with a column name that exists in <code>cols</code>.</h2><span id='topic+.find_appropriate_column_name'></span>

<h3>Description</h3>

<p>Tries to match a <code>fuzzy_col_name</code> with a column name that exists in <code>cols</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.find_appropriate_column_name(fuzzy_col_name, cols)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".find_appropriate_column_name_+3A_fuzzy_col_name">fuzzy_col_name</code></td>
<td>
<p>a name to be decoded</p>
</td></tr>
<tr><td><code id=".find_appropriate_column_name_+3A_cols">cols</code></td>
<td>
<p>vector of columns that contain all possible column names, i.e., decode
fuzzy_col_name must be in cols</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a correct column name
</p>

<hr>
<h2 id='.get_algorithm'>Get the algoritm used by the model_or_model_id</h2><span id='topic+.get_algorithm'></span>

<h3>Description</h3>

<p>Get the algoritm used by the model_or_model_id
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_algorithm(model_or_model_id, treat_xrt_as_algorithm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_algorithm_+3A_model_or_model_id">model_or_model_id</code></td>
<td>
<p>Model object or a string containing model id</p>
</td></tr>
<tr><td><code id=".get_algorithm_+3A_treat_xrt_as_algorithm">treat_xrt_as_algorithm</code></td>
<td>
<p>Try to find out if a model is XRT and if so report it as xrt</p>
</td></tr>
</table>


<h3>Value</h3>

<p>algorithm name
</p>

<hr>
<h2 id='.get_domain_mapping'>Get a mapping between columns and their domains</h2><span id='topic+.get_domain_mapping'></span>

<h3>Description</h3>

<p>Get a mapping between columns and their domains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_domain_mapping(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_domain_mapping_+3A_model">model</code></td>
<td>
<p>an h2o model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing a mapping from column to its domains (levels)
</p>

<hr>
<h2 id='.get_feature_count'>Get feature count sorted by the count descending.</h2><span id='topic+.get_feature_count'></span>

<h3>Description</h3>

<p>Get feature count sorted by the count descending.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_feature_count(column)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_feature_count_+3A_column">column</code></td>
<td>
<p>H2OFrame column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named vector with feature counts
</p>

<hr>
<h2 id='.get_first_of_family'>Get first of family models</h2><span id='topic+.get_first_of_family'></span>

<h3>Description</h3>

<p>Get first of family models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_first_of_family(models, all_stackedensembles = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_first_of_family_+3A_models">models</code></td>
<td>
<p>models or model ids</p>
</td></tr>
<tr><td><code id=".get_first_of_family_+3A_all_stackedensembles">all_stackedensembles</code></td>
<td>
<p>if TRUE, select all stacked ensembles</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.__ALL_CAPABILITIES'>Capabilities endpoints</h2><span id='topic+.h2o.__ALL_CAPABILITIES'></span>

<h3>Description</h3>

<p>Capabilities endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__ALL_CAPABILITIES
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__checkConnectionHealth'>Check H2O Server Health</h2><span id='topic+.h2o.__checkConnectionHealth'></span>

<h3>Description</h3>

<p>Warn if there are sick nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__checkConnectionHealth()
</code></pre>

<hr>
<h2 id='.h2o.__CREATE_FRAME'>H2OFrame Manipulation</h2><span id='topic+.h2o.__CREATE_FRAME'></span>

<h3>Description</h3>

<p>H2OFrame Manipulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__CREATE_FRAME
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__DECRYPTION_SETUP'>Decryption Endpoints</h2><span id='topic+.h2o.__DECRYPTION_SETUP'></span>

<h3>Description</h3>

<p>Decryption Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__DECRYPTION_SETUP
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__DKV'>Removal Endpoints</h2><span id='topic+.h2o.__DKV'></span>

<h3>Description</h3>

<p>Removal Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__DKV
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__EXPORT_FILES'>Export Files Endpoint Generator</h2><span id='topic+.h2o.__EXPORT_FILES'></span>

<h3>Description</h3>

<p>Export Files Endpoint Generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__EXPORT_FILES(frame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.__EXPORT_FILES_+3A_frame">frame</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.__FRAMES'>Inspect/Summary Endpoints</h2><span id='topic+.h2o.__FRAMES'></span>

<h3>Description</h3>

<p>Inspect/Summary Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__FRAMES
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__IMPORT'>Import/Export Endpoints</h2><span id='topic+.h2o.__IMPORT'></span>

<h3>Description</h3>

<p>Import/Export Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__IMPORT
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__JOBS'>Administrative Endpoints</h2><span id='topic+.h2o.__JOBS'></span>

<h3>Description</h3>

<p>Administrative Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__JOBS
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__LOGANDECHO'>Log and Echo Endpoint</h2><span id='topic+.h2o.__LOGANDECHO'></span>

<h3>Description</h3>

<p>Log and Echo Endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__LOGANDECHO
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__MODEL_BUILDERS'>Model Builder Endpoint Generator</h2><span id='topic+.h2o.__MODEL_BUILDERS'></span>

<h3>Description</h3>

<p>Model Builder Endpoint Generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__MODEL_BUILDERS(algo)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.__MODEL_BUILDERS_+3A_algo">algo</code></td>
<td>
<p>Cannonical identifier of H2O algorithm.</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.__MODEL_METRICS'>Model Metrics Endpoint</h2><span id='topic+.h2o.__MODEL_METRICS'></span>

<h3>Description</h3>

<p>Model Metrics Endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__MODEL_METRICS(model, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.__MODEL_METRICS_+3A_model">model</code></td>
<td>
<p>H2OModel.</p>
</td></tr>
<tr><td><code id=".h2o.__MODEL_METRICS_+3A_data">data</code></td>
<td>
<p>H2OFrame.</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.__MODELS'>Model Endpoint</h2><span id='topic+.h2o.__MODELS'></span>

<h3>Description</h3>

<p>Model Endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__MODELS
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__PARSE_SETUP'>Parse Endpoints</h2><span id='topic+.h2o.__PARSE_SETUP'></span>

<h3>Description</h3>

<p>Parse Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__PARSE_SETUP
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__RAPIDS'>Rapids Endpoint</h2><span id='topic+.h2o.__RAPIDS'></span>

<h3>Description</h3>

<p>Rapids Endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__RAPIDS
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.__REST_API_VERSION'>H2O Package Constants</h2><span id='topic+.h2o.__REST_API_VERSION'></span>

<h3>Description</h3>

<p>The API endpoints for interacting with H2O via REST are named here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__REST_API_VERSION
</code></pre>


<h3>Format</h3>

<p>An object of class <code>integer</code> of length 1.
</p>


<h3>Details</h3>

<p>Additionally, environment variables for the H2O package are named here.
Endpoint Version
</p>

<hr>
<h2 id='.h2o.__SEGMENT_MODELS_BUILDERS'>Segment Models Builder Endpoint Generator</h2><span id='topic+.h2o.__SEGMENT_MODELS_BUILDERS'></span>

<h3>Description</h3>

<p>Segment Models Builder Endpoint Generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__SEGMENT_MODELS_BUILDERS(algo)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.__SEGMENT_MODELS_BUILDERS_+3A_algo">algo</code></td>
<td>
<p>Cannonical identifier of H2O algorithm.</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.__W2V_SYNONYMS'>Word2Vec Endpoints</h2><span id='topic+.h2o.__W2V_SYNONYMS'></span>

<h3>Description</h3>

<p>Word2Vec Endpoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.__W2V_SYNONYMS
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='.h2o.doGET'>Just like doRawGET but fills in the default h2oRestApiVersion if none is provided</h2><span id='topic+.h2o.doGET'></span>

<h3>Description</h3>

<p>Just like doRawGET but fills in the default h2oRestApiVersion if none is provided
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doGET(h2oRestApiVersion, urlSuffix, parms, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doGET_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, a default version is chosen for you.</p>
</td></tr>
<tr><td><code id=".h2o.doGET_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doGET_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doGET_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object as described above
</p>

<hr>
<h2 id='.h2o.doPOST'>Just like doRawPOST but fills in the default h2oRestApiVersion if none is provided</h2><span id='topic+.h2o.doPOST'></span>

<h3>Description</h3>

<p>Just like doRawPOST but fills in the default h2oRestApiVersion if none is provided
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doPOST(h2oRestApiVersion, urlSuffix, parms, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doPOST_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, a default version is chosen for you.</p>
</td></tr>
<tr><td><code id=".h2o.doPOST_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doPOST_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doPOST_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object as described above
</p>

<hr>
<h2 id='.h2o.doRawGET'>Perform a low-level HTTP GET operation on an H2O instance</h2><span id='topic+.h2o.doRawGET'></span>

<h3>Description</h3>

<p>Does not do any I/O level error checking.  Caller must do its own validations.
Does not modify the response payload in any way.
Log the request and response if h2o.startLogging() has been called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doRawGET(
  conn = h2o.getConnection(),
  h2oRestApiVersion,
  urlSuffix,
  parms,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doRawGET_+3A_conn">conn</code></td>
<td>
<p>H2OConnection</p>
</td></tr>
<tr><td><code id=".h2o.doRawGET_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, the version prefix is skipped.</p>
</td></tr>
<tr><td><code id=".h2o.doRawGET_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doRawGET_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doRawGET_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The return value is a list as follows:
$url                &ndash; Final calculated URL.
$postBody           &ndash; The body of the POST request from client to server.
$curlError          &ndash; TRUE if a socket-level error occurred.  FALSE otherwise.
$curlErrorMessage   &ndash; If curlError is TRUE a message about the error.
$httpStatusCode     &ndash; The HTTP status code.  Usually 200 if the request succeeded.
$httpStatusMessage  &ndash; A string describing the httpStatusCode.
$payload            &ndash; The raw response payload as a character vector.
</p>


<h3>Value</h3>

<p>A list object as described above
</p>

<hr>
<h2 id='.h2o.doRawPOST'>Perform a low-level HTTP POST operation on an H2O instance</h2><span id='topic+.h2o.doRawPOST'></span>

<h3>Description</h3>

<p>Does not do any I/O level error checking.  Caller must do its own validations.
Does not modify the response payload in any way.
Log the request and response if h2o.startLogging() has been called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doRawPOST(
  conn = h2o.getConnection(),
  h2oRestApiVersion,
  urlSuffix,
  parms,
  fileUploadInfo,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doRawPOST_+3A_conn">conn</code></td>
<td>
<p>H2OConnection</p>
</td></tr>
<tr><td><code id=".h2o.doRawPOST_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, the version prefix is skipped.</p>
</td></tr>
<tr><td><code id=".h2o.doRawPOST_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doRawPOST_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doRawPOST_+3A_fileuploadinfo">fileUploadInfo</code></td>
<td>
<p>(Optional) Information to POST (NOTE: changes Content-type from XXX-www-url-encoded to multi-part).  Use fileUpload(normalizePath(&quot;/path/to/file&quot;)).</p>
</td></tr>
<tr><td><code id=".h2o.doRawPOST_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The return value is a list as follows:
$url                &ndash; Final calculated URL.
$postBody           &ndash; The body of the POST request from client to server.
$curlError          &ndash; TRUE if a socket-level error occurred.  FALSE otherwise.
$curlErrorMessage   &ndash; If curlError is TRUE a message about the error.
$httpStatusCode     &ndash; The HTTP status code.  Usually 200 if the request succeeded.
$httpStatusMessage  &ndash; A string describing the httpStatusCode.
$payload            &ndash; The raw response payload as a character vector.
</p>


<h3>Value</h3>

<p>A list object as described above
</p>

<hr>
<h2 id='.h2o.doSafeGET'>Perform a safe (i.e. error-checked) HTTP GET request to an H2O cluster.</h2><span id='topic+.h2o.doSafeGET'></span>

<h3>Description</h3>

<p>This function validates that no CURL error occurred and that the HTTP response code is successful.
If a failure occurred, then stop() is called with an error message.
Since all necessary error checking is done inside this call, the valid payload is directly returned if the function successfully finishes without calling stop().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doSafeGET(h2oRestApiVersion, urlSuffix, parms, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doSafeGET_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, a default version is chosen for you.</p>
</td></tr>
<tr><td><code id=".h2o.doSafeGET_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doSafeGET_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doSafeGET_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The raw response payload as a character vector
</p>

<hr>
<h2 id='.h2o.doSafePOST'>Perform a safe (i.e. error-checked) HTTP POST request to an H2O cluster.</h2><span id='topic+.h2o.doSafePOST'></span>

<h3>Description</h3>

<p>This function validates that no CURL error occurred and that the HTTP response code is successful.
If a failure occurred, then stop() is called with an error message.
Since all necessary error checking is done inside this call, the valid payload is directly returned if the function successfully finishes without calling stop().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.doSafePOST(h2oRestApiVersion, urlSuffix, parms, fileUploadInfo, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.doSafePOST_+3A_h2orestapiversion">h2oRestApiVersion</code></td>
<td>
<p>(Optional) A version number to prefix to the urlSuffix.  If no version is provided, a default version is chosen for you.</p>
</td></tr>
<tr><td><code id=".h2o.doSafePOST_+3A_urlsuffix">urlSuffix</code></td>
<td>
<p>The partial URL suffix to add to the calculated base URL for the instance</p>
</td></tr>
<tr><td><code id=".h2o.doSafePOST_+3A_parms">parms</code></td>
<td>
<p>(Optional) Parameters to include in the request</p>
</td></tr>
<tr><td><code id=".h2o.doSafePOST_+3A_fileuploadinfo">fileUploadInfo</code></td>
<td>
<p>(Optional) Information to POST (NOTE: changes Content-type from XXX-www-url-encoded to multi-part).  Use fileUpload(normalizePath(&quot;/path/to/file&quot;)).</p>
</td></tr>
<tr><td><code id=".h2o.doSafePOST_+3A_...">...</code></td>
<td>
<p>(Optional) Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The raw response payload as a character vector
</p>

<hr>
<h2 id='.h2o.is_progress'>Check if Progress Bar is Enabled</h2><span id='topic+.h2o.is_progress'></span>

<h3>Description</h3>

<p>Check if Progress Bar is Enabled
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.is_progress()
</code></pre>

<hr>
<h2 id='.h2o.locate'>Locate a file given the pattern &lt;bucket&gt;/&lt;path/to/file&gt;
e.g. h2o:::.h2o.locate(&quot;smalldata/iris/iris22.csv&quot;) returns the absolute path to iris22.csv</h2><span id='topic+.h2o.locate'></span>

<h3>Description</h3>

<p>Locate a file given the pattern &lt;bucket&gt;/&lt;path/to/file&gt;
e.g. h2o:::.h2o.locate(&quot;smalldata/iris/iris22.csv&quot;) returns the absolute path to iris22.csv
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.locate(pathStub, root.parent = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.locate_+3A_pathstub">pathStub</code></td>
<td>
<p>relative path</p>
</td></tr>
<tr><td><code id=".h2o.locate_+3A_root.parent">root.parent</code></td>
<td>
<p>search root directory</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.perfect_auc'>Internal function that calculates a precise AUC from given
probabilities and actual responses.</h2><span id='topic+.h2o.perfect_auc'></span>

<h3>Description</h3>

<p>Note: The underlying implementation is not distributed and can
only handle limited size of data. For internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.perfect_auc(probs, acts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".h2o.perfect_auc_+3A_probs">probs</code></td>
<td>
<p>An <a href="#topic+H2OFrame-class">H2OFrame</a> holding vector of probabilities.</p>
</td></tr>
<tr><td><code id=".h2o.perfect_auc_+3A_acts">acts</code></td>
<td>
<p>An <a href="#topic+H2OFrame-class">H2OFrame</a> holding vector of actuals.</p>
</td></tr>
</table>

<hr>
<h2 id='.h2o.primitives'>Map of operations known to H2O</h2><span id='topic+.h2o.primitives'></span>

<h3>Description</h3>

<p>Map of operations known to H2O
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.h2o.primitives
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 39.
</p>

<hr>
<h2 id='.has_model_coefficients'>Has the <code>model</code> coefficients?</h2><span id='topic+.has_model_coefficients'></span>

<h3>Description</h3>

<p>Has the <code>model</code> coefficients?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.has_model_coefficients(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".has_model_coefficients_+3A_model">model</code></td>
<td>
<p>Either a linear model with coefficients =&gt; TRUE, or something else =&gt; FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.has_varimp'>Has the model variable importance?</h2><span id='topic+.has_varimp'></span>

<h3>Description</h3>

<p>Has the model variable importance?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.has_varimp(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".has_varimp_+3A_model">model</code></td>
<td>
<p>model or a string containing model id</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.interpretable'>Is the model considered to be interpretable, i.e., simple enough.</h2><span id='topic+.interpretable'></span>

<h3>Description</h3>

<p>Is the model considered to be interpretable, i.e., simple enough.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.interpretable(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".interpretable_+3A_model">model</code></td>
<td>
<p>model or a string containing model id</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.is_h2o_model'>Is the <code>model</code> an H2O model?</h2><span id='topic+.is_h2o_model'></span>

<h3>Description</h3>

<p>Is the <code>model</code> an H2O model?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.is_h2o_model(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".is_h2o_model_+3A_model">model</code></td>
<td>
<p>Either H2O model/model id =&gt; TRUE, or something else =&gt; FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.is_h2o_tree_model'>Is the <code>model</code> a Tree-based H2O Model?</h2><span id='topic+.is_h2o_tree_model'></span>

<h3>Description</h3>

<p>Is the <code>model</code> a Tree-based H2O Model?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.is_h2o_tree_model(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".is_h2o_tree_model_+3A_model">model</code></td>
<td>
<p>Either tree-based H2O model/model id =&gt; TRUE, or something else =&gt; FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.is_plotting_to_rnotebook'>Check if we are plotting in to r notebook.</h2><span id='topic+.is_plotting_to_rnotebook'></span>

<h3>Description</h3>

<p>Check if we are plotting in to r notebook.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.is_plotting_to_rnotebook()
</code></pre>


<h3>Value</h3>

<p>boolean
</p>

<hr>
<h2 id='.leaderboard_for_row'>Enhance leaderboard with per-model predictions.</h2><span id='topic+.leaderboard_for_row'></span>

<h3>Description</h3>

<p>Enhance leaderboard with per-model predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.leaderboard_for_row(models_info, newdata, row_index, top_n = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".leaderboard_for_row_+3A_models_info">models_info</code></td>
<td>
<p>models_info object</p>
</td></tr>
<tr><td><code id=".leaderboard_for_row_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id=".leaderboard_for_row_+3A_row_index">row_index</code></td>
<td>
<p>index of the inspected row</p>
</td></tr>
<tr><td><code id=".leaderboard_for_row_+3A_top_n">top_n</code></td>
<td>
<p>leaderboard will contain top_n models</p>
</td></tr>
</table>


<h3>Value</h3>

<p>H2OFrame
</p>

<hr>
<h2 id='.min_max'>Min-max normalization.</h2><span id='topic+.min_max'></span>

<h3>Description</h3>

<p>Min-max normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.min_max(col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".min_max_+3A_col">col</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalized numeric vector
</p>

<hr>
<h2 id='.model_ids'>Get Model Ids</h2><span id='topic+.model_ids'></span>

<h3>Description</h3>

<p>When provided with list of models it will extract model ids.
When provided with model ids it won't change anything.
Works for mixed list as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.model_ids(models)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".model_ids_+3A_models">models</code></td>
<td>
<p>list or vector of models/model_ids</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of <code>model_id</code>s
</p>

<hr>
<h2 id='.pkg.env'>The H2O Package Environment</h2><span id='topic+.pkg.env'></span>

<h3>Description</h3>

<p>The H2O Package Environment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.pkg.env
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 4.
</p>

<hr>
<h2 id='.plot_varimp'>Plot variable importances with ggplot2</h2><span id='topic+.plot_varimp'></span>

<h3>Description</h3>

<p>Plot variable importances with ggplot2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.plot_varimp(model, top_n = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".plot_varimp_+3A_model">model</code></td>
<td>
<p>H2OModel</p>
</td></tr>
<tr><td><code id=".plot_varimp_+3A_top_n">top_n</code></td>
<td>
<p>Plot just top_n features</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of variable importance, groupped variable importance, and variable importance plot
</p>

<hr>
<h2 id='.process_models_or_automl'>Do basic validation and transform <code>object</code> to a &quot;standardized&quot; list containing models, and
their properties such as <code>x</code>, <code>y</code>, whether it is a (multinomial) clasification or not etc.</h2><span id='topic+.process_models_or_automl'></span>

<h3>Description</h3>

<p>Do basic validation and transform <code>object</code> to a &quot;standardized&quot; list containing models, and
their properties such as <code>x</code>, <code>y</code>, whether it is a (multinomial) clasification or not etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.process_models_or_automl(
  object,
  newdata,
  require_single_model = FALSE,
  require_multiple_models = FALSE,
  top_n_from_AutoML = NA,
  only_with_varimp = FALSE,
  best_of_family = FALSE,
  require_newdata = TRUE,
  check_x_y_consistency = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".process_models_or_automl_+3A_object">object</code></td>
<td>
<p>Can be a single model/model_id, vector of model_id, list of models, H2OAutoML object</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame with the same format as training frame</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_require_single_model">require_single_model</code></td>
<td>
<p>If true, make sure we were provided only one model</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_require_multiple_models">require_multiple_models</code></td>
<td>
<p>If true, make sure we were provided at least two models</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_top_n_from_automl">top_n_from_AutoML</code></td>
<td>
<p>If set, don't return more than top_n models (applies only for AutoML object)</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_only_with_varimp">only_with_varimp</code></td>
<td>
<p>If TRUE, return only models that have variable importance</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_best_of_family">best_of_family</code></td>
<td>
<p>If TRUE, return only the best of family models; if FALSE return all models in <code>object</code></p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_require_newdata">require_newdata</code></td>
<td>
<p>If TRUE, require newdata to be specified; otherwise allow NULL instead, this can be used when
there is no need to know if the problem is (multinomial) classification.</p>
</td></tr>
<tr><td><code id=".process_models_or_automl_+3A_check_x_y_consistency">check_x_y_consistency</code></td>
<td>
<p>If TRUE, make sure that when given a list of models all models have the same X and y. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following names <code>leader</code>, <code>is_automl</code>, <code>models</code>,
<code>is_classification</code>, <code>is_multinomial_classification</code>, <code>x</code>, <code>y</code>, <code>model</code>
</p>

<hr>
<h2 id='.shorten_model_ids'>Shortens model ids if possible (iff there will be same amount of unique model_ids as before)</h2><span id='topic+.shorten_model_ids'></span>

<h3>Description</h3>

<p>Shortens model ids if possible (iff there will be same amount of unique model_ids as before)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.shorten_model_ids(model_ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".shorten_model_ids_+3A_model_ids">model_ids</code></td>
<td>
<p>character vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector
</p>

<hr>
<h2 id='.skip_if_not_developer'>H2O &lt;-&gt; R Communication and Utility Methods</h2><span id='topic+.skip_if_not_developer'></span>

<h3>Description</h3>

<p>Collected here are the various methods used by the h2o-R package to communicate with the H2O
backend. There are methods for checking cluster health, polling, and inspecting objects in
the H2O store.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.skip_if_not_developer()
</code></pre>

<hr>
<h2 id='.uniformize'>Convert to quantiles when provided with numeric vector.
When col is a factor vector assign uniformly value between 0 and 1 to each level.</h2><span id='topic+.uniformize'></span>

<h3>Description</h3>

<p>Convert to quantiles when provided with numeric vector.
When col is a factor vector assign uniformly value between 0 and 1 to each level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.uniformize(col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".uniformize_+3A_col">col</code></td>
<td>
<p>vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with values between 0 and 1
</p>

<hr>
<h2 id='.varimp'>Get variable importance in a standardized way.</h2><span id='topic+.varimp'></span>

<h3>Description</h3>

<p>Get variable importance in a standardized way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.varimp(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".varimp_+3A_model">model</code></td>
<td>
<p>H2OModel</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named vector
</p>

<hr>
<h2 id='.verify_dataxy'>Used to verify data, x, y and turn into the appropriate things</h2><span id='topic+.verify_dataxy'></span>

<h3>Description</h3>

<p>Used to verify data, x, y and turn into the appropriate things
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.verify_dataxy(data, x, y, autoencoder = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".verify_dataxy_+3A_data">data</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id=".verify_dataxy_+3A_x">x</code></td>
<td>
<p>features</p>
</td></tr>
<tr><td><code id=".verify_dataxy_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id=".verify_dataxy_+3A_autoencoder">autoencoder</code></td>
<td>
<p>autoencoder flag</p>
</td></tr>
</table>

<hr>
<h2 id='+26amp+3B+26amp+3B'>Logical and for H2OFrames</h2><span id='topic++26+26'></span>

<h3>Description</h3>

<p>Logical and for H2OFrames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>`&amp;&amp;`(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26amp+2B3B+2B26amp+2B3B_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="+2B26amp+2B3B+2B26amp+2B3B_+3A_y">y</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
</table>

<hr>
<h2 id='aaa'>Starting H2O For examples</h2><span id='topic+aaa'></span>

<h3>Description</h3>

<p>Starting H2O For examples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if (Sys.info()['sysname'] == "Darwin" &amp;&amp; Sys.info()['release'] == '13.4.0') {
  quit(save = "no")
} else {
 h2o.init(nthreads = 2)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='apply'>Apply on H2O Datasets</h2><span id='topic+apply'></span>

<h3>Description</h3>

<p>Method for apply on H2OFrame objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply(X, MARGIN, FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply_+3A_x">X</code></td>
<td>
<p>an H2OFrame object on which <code>apply</code> will operate.</p>
</td></tr>
<tr><td><code id="apply_+3A_margin">MARGIN</code></td>
<td>
<p>the vector on which the function will be applied over, either
<code>1</code> for rows or <code>2</code> for columns.</p>
</td></tr>
<tr><td><code id="apply_+3A_fun">FUN</code></td>
<td>
<p>the function to be applied.</p>
</td></tr>
<tr><td><code id="apply_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Produces a new H2OFrame of the output of the applied
function. The output is stored in H2O so that it can be used in
subsequent H2O processes.
</p>


<h3>See Also</h3>

<p><a href="base.html#topic+apply">apply</a> for the base generic
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
summary(apply(iris_hf, 2, sum))

## End(Not run)
</code></pre>

<hr>
<h2 id='as.character.H2OFrame'>Convert an H2OFrame to a String</h2><span id='topic+as.character.H2OFrame'></span>

<h3>Description</h3>

<p>Convert an H2OFrame to a String
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
as.character(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.character.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="as.character.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
pretrained &lt;- as.h2o(data.frame(
       C1 = c("a", "b"), C2 = c(0, 1), C3 = c(1, 0), C4 = c(0.2, 0.8),
       stringsAsFactors = FALSE))
pretrained_w2v &lt;- h2o.word2vec(pre_trained = pretrained, vec_size = 3)
words &lt;- as.character(as.h2o(c("b", "a", "c", NA, "a")))
vecs &lt;- h2o.transform(pretrained_w2v, words = words)

## End(Not run)
</code></pre>

<hr>
<h2 id='as.data.frame.H2OFrame'>Converts parsed H2O data into an R data frame</h2><span id='topic+as.data.frame.H2OFrame'></span>

<h3>Description</h3>

<p>Downloads the H2O data and then scans it in to an R data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="as.data.frame.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed down from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method <code>as.data.frame.H2OFrame</code> will use <code><a href="data.table.html#topic+fread">fread</a></code> if data.table package is installed in required version.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+use.package">use.package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
as.data.frame(prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='as.data.frame.H2OSegmentModels'>Converts a collection of Segment Models to a data.frame</h2><span id='topic+as.data.frame.H2OSegmentModels'></span>

<h3>Description</h3>

<p>Converts a collection of Segment Models to a data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OSegmentModels'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame.H2OSegmentModels_+3A_x">x</code></td>
<td>
<p>Object of class <a href="#topic+H2OSegmentModels-class">H2OSegmentModels</a>.</p>
</td></tr>
<tr><td><code id="as.data.frame.H2OSegmentModels_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed down from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data.frame with result of segment model training.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
models &lt;- h2o.train_segments(algorithm = "gbm",
                             segment_columns = "Species",
                             x = c(1:3), y = 4,
                             training_frame = iris_hf,
                             ntrees = 5,
                             max_depth = 4)
as.data.frame(models)

## End(Not run)
</code></pre>

<hr>
<h2 id='as.factor'>Convert H2O Data to Factors</h2><span id='topic+as.factor'></span>

<h3>Description</h3>

<p>Convert column/columns in the current frame to categoricals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.factor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.factor_+3A_x">x</code></td>
<td>
<p>a column from an H2OFrame data set.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+as.factor">as.factor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Single column
cars &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
df &lt;- h2o.importFile(cars)
df["cylinders"] &lt;- as.factor(df["cylinders"])
h2o.describe(df["cylinders"])

# Multiple columns
cars &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
df &lt;- h2o.importFile(cars)
df[c("cylinders","economy_20mpg")] &lt;- as.factor(df[c("cylinders","economy_20mpg")])
h2o.describe(df[c("cylinders","economy_20mpg")])

## End(Not run)
</code></pre>

<hr>
<h2 id='as.h2o'>Create H2OFrame</h2><span id='topic+as.h2o'></span><span id='topic+as.h2o.default'></span><span id='topic+as.h2o.H2OFrame'></span><span id='topic+as.h2o.data.frame'></span><span id='topic+as.h2o.Matrix'></span>

<h3>Description</h3>

<p>Import R object to the H2O cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.h2o(x, destination_frame = "", ...)

## Default S3 method:
as.h2o(x, destination_frame = "", ...)

## S3 method for class 'H2OFrame'
as.h2o(x, destination_frame = "", ...)

## S3 method for class 'data.frame'
as.h2o(x, destination_frame = "", use_datatable = TRUE, ...)

## S3 method for class 'Matrix'
as.h2o(x, destination_frame = "", use_datatable = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.h2o_+3A_x">x</code></td>
<td>
<p>An <code>R</code> object.</p>
</td></tr>
<tr><td><code id="as.h2o_+3A_destination_frame">destination_frame</code></td>
<td>
<p>A string with the desired name for the H2OFrame</p>
</td></tr>
<tr><td><code id="as.h2o_+3A_...">...</code></td>
<td>
<p>arguments passed to method arguments.</p>
</td></tr>
<tr><td><code id="as.h2o_+3A_use_datatable">use_datatable</code></td>
<td>
<p>allow usage of data.table</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method <code>as.h2o.data.frame</code> will use <code><a href="data.table.html#topic+fwrite">fwrite</a></code> if data.table package is installed in required version.
</p>
<p>To speedup execution time for large sparse matrices, use h2o datatable.  Make sure you have installed and imported data.table and slam packages.
Turn on h2o datatable by options(&quot;h2o.use.data.table&quot;=TRUE)
</p>


<h3>References</h3>

<p><a href="https://h2o.ai/blog/2016/fast-csv-writing-for-r/">https://h2o.ai/blog/2016/fast-csv-writing-for-r/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+use.package">use.package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
euro_hf &lt;- as.h2o(euro)
letters_hf &lt;- as.h2o(letters)
state_hf &lt;- as.h2o(state.x77)
iris_hf_2 &lt;- as.h2o(iris_hf)
stopifnot(is.h2o(iris_hf), dim(iris_hf) == dim(iris),
          is.h2o(euro_hf), dim(euro_hf) == c(length(euro), 1L),
          is.h2o(letters_hf), dim(letters_hf) == c(length(letters), 1L),
          is.h2o(state_hf), dim(state_hf) == dim(state.x77),
          is.h2o(iris_hf_2), dim(iris_hf_2) == dim(iris_hf))
if (requireNamespace("Matrix", quietly=TRUE)) {
  data &lt;- rep(0, 100)
  data[(1:10) ^ 2] &lt;- 1:10 * pi
  m &lt;- matrix(data, ncol = 20, byrow = TRUE)
  m &lt;- Matrix::Matrix(m, sparse = TRUE)
  m_hf &lt;- as.h2o(m)
  stopifnot(is.h2o(m_hf), dim(m_hf) == dim(m))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='as.matrix.H2OFrame'>Convert an H2OFrame to a matrix</h2><span id='topic+as.matrix.H2OFrame'></span>

<h3>Description</h3>

<p>Convert an H2OFrame to a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="as.matrix.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed down from other methods.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
describe &lt;- h2o.describe(iris_hf)
mins = as.matrix(apply(iris_hf, 2, min))
print(mins)

## End(Not run)
</code></pre>

<hr>
<h2 id='as.numeric'>Convert H2O Data to Numeric</h2><span id='topic+as.numeric'></span>

<h3>Description</h3>

<p>Converts an H2O column into a numeric value column. If the column type is enum and you want to convert it to numeric, you should first convert it 
to character then convert it to numeric. Otherwise, the values may be converted to underlying factor values, not the expected mapped values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.numeric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.numeric_+3A_x">x</code></td>
<td>
<p>a column from an H2OFrame data set.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate[, 2] &lt;- as.factor (prostate[, 2])
prostate[, 2] &lt;- as.numeric(prostate[, 2])

## End(Not run)
</code></pre>

<hr>
<h2 id='as.vector.H2OFrame'>Convert an H2OFrame to a vector</h2><span id='topic+as.vector.H2OFrame'></span>

<h3>Description</h3>

<p>Convert an H2OFrame to a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
as.vector(x,mode)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.vector.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="as.vector.H2OFrame_+3A_mode">mode</code></td>
<td>
<p>Mode to coerce vector to</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
cor_R &lt;- cor(as.matrix(iris[, 1]))
cor_h2o &lt;- cor(iris_hf[, 1])
iris_R_cor &lt;- cor(iris[, 1:4])
iris_H2O_cor &lt;- as.data.frame(cor(iris_hf[, 1:4]))
h2o_vec &lt;- as.vector(unlist(iris_H2O_cor))
r_vec &lt;- as.vector(unlist(iris_R_cor))

## End(Not run)
</code></pre>

<hr>
<h2 id='australia'>Australia Coastal Data</h2><span id='topic+australia'></span>

<h3>Description</h3>

<p>Temperature, soil moisture, runoff, and other environmental measurements from
the Australia coast. The data is available from https://cs.colby.edu/courses/S11/cs251/labs/lab07/AustraliaSubset.csv.
</p>


<h3>Format</h3>

<p>A data frame with 251 rows and 8 columns
</p>

<hr>
<h2 id='case_insensitive_match_arg'>Works like match.arg but ignores case</h2><span id='topic+case_insensitive_match_arg'></span>

<h3>Description</h3>

<p>Works like match.arg but ignores case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>case_insensitive_match_arg(arg, choices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="case_insensitive_match_arg_+3A_arg">arg</code></td>
<td>
<p>argument to match that should be declared as a character vector containing possible values</p>
</td></tr>
<tr><td><code id="case_insensitive_match_arg_+3A_choices">choices</code></td>
<td>
<p>argument to choose from (OPTIONAL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matched arg
</p>

<hr>
<h2 id='colnames'>Returns the column names of an H2OFrame</h2><span id='topic+colnames'></span>

<h3>Description</h3>

<p>Returns the column names of an H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colnames(x, do.NULL = TRUE, prefix = "col")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colnames_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="colnames_+3A_do.null">do.NULL</code></td>
<td>
<p>logical. If FALSE and names are NULL, names are created.</p>
</td></tr>
<tr><td><code id="colnames_+3A_prefix">prefix</code></td>
<td>
<p>for created names.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
colnames(iris_hf)  # Returns "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"

## End(Not run)
</code></pre>

<hr>
<h2 id='dim.H2OFrame'>Returns the Dimensions of an H2OFrame</h2><span id='topic+dim.H2OFrame'></span>

<h3>Description</h3>

<p>Returns the number of rows and columns for an H2OFrame object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+dim">dim</a></code> for the base R method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
dim(iris_hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='dimnames.H2OFrame'>Column names of an H2OFrame</h2><span id='topic+dimnames.H2OFrame'></span>

<h3>Description</h3>

<p>Set column names of an H2O Frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
dimnames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimnames.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

n &lt;- 2000
#  Generate variables V1, ... V10
X &lt;- matrix(rnorm(10 * n), n, 10)
#  y = +1 if sum_i x_{ij}^2 &gt; chisq median on 10 df
y &lt;- rep(-1, n)
y[apply(X*X, 1, sum) &gt; qchisq(.5, 10)] &lt;- 1
#  Assign names to the columns of X:
dimnames(X)[[2]] &lt;- c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10")

## End(Not run)
</code></pre>

<hr>
<h2 id='feature_frequencies.H2OModel'>Retrieve the number of occurrences of each feature for given observations 
Available for GBM, Random Forest and Isolation Forest models.</h2><span id='topic+feature_frequencies.H2OModel'></span><span id='topic+h2o.feature_frequencies'></span>

<h3>Description</h3>

<p>Retrieve the number of occurrences of each feature for given observations 
Available for GBM, Random Forest and Isolation Forest models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature_frequencies.H2OModel(object, newdata, ...)

h2o.feature_frequencies(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="feature_frequencies.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="feature_frequencies.H2OModel_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="feature_frequencies.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame contain per-feature frequencies on the predict path for each input row.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.gbm">h2o.gbm</a></code> and  <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>

<hr>
<h2 id='generate_col_ind'>CHeck to see if the column names/indices entered is valid for the dataframe given.  This is an internal function</h2><span id='topic+generate_col_ind'></span>

<h3>Description</h3>

<p>CHeck to see if the column names/indices entered is valid for the dataframe given.  This is an internal function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_col_ind(data, by)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_col_ind_+3A_data">data</code></td>
<td>
<p>The H2OFrame whose column names or indices are entered as a list</p>
</td></tr>
<tr><td><code id="generate_col_ind_+3A_by">by</code></td>
<td>
<p>The column names/indices in a list.</p>
</td></tr>
</table>

<hr>
<h2 id='get_seed.H2OModel'>Get the seed from H2OModel which was used during training.
If a user does not set the seed parameter before training, the seed is autogenerated.
It returns seed as the string if the value is bigger than the integer.
For example, an autogenerated seed is always long so that the seed in R is a string.</h2><span id='topic+get_seed.H2OModel'></span><span id='topic+h2o.get_seed'></span>

<h3>Description</h3>

<p>Get the seed from H2OModel which was used during training.
If a user does not set the seed parameter before training, the seed is autogenerated.
It returns seed as the string if the value is bigger than the integer.
For example, an autogenerated seed is always long so that the seed in R is a string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_seed.H2OModel(object)

h2o.get_seed(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_seed.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns seed to be used during training a model. Could be numeric or string.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
prostate_gbm &lt;- h2o.gbm(3:9, "CAPSULE", prostate)
seed &lt;- h2o.get_seed(prostate_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.abs'>Compute the absolute value of x</h2><span id='topic+h2o.abs'></span>

<h3>Description</h3>

<p>Compute the absolute value of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.abs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.abs_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+MathFun">MathFun</a></code> for the base R implementation, <code>abs()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
url &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/smtrees.csv"
smtrees_hf &lt;- h2o.importFile(url)
smtrees_df &lt;- read.csv(
  "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/smtrees.csv")
model &lt;- h2o.gbm(x = c("girth", "height"), y = "vol", ntrees = 3, max_depth = 1,
                 distribution = "gaussian", min_rows = 2, learn_rate = .1,
                 training_frame = smtrees_hf)
pred &lt;- as.data.frame(predict(model, newdata = smtrees_hf))
diff &lt;- pred - smtrees_df[, 4]
diff_abs &lt;- abs(diff)
print(diff_abs)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.acos'>Compute the arc cosine of x</h2><span id='topic+h2o.acos'></span>

<h3>Description</h3>

<p>Compute the arc cosine of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.acos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.acos_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Trig">Trig</a></code> for the base R implementation, <code>acos()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.acos(prostate[, 2])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.adaBoost'>Build an AdaBoost model</h2><span id='topic+h2o.adaBoost'></span>

<h3>Description</h3>

<p>Builds an AdaBoost model on an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.adaBoost(
  x,
  y,
  training_frame,
  model_id = NULL,
  ignore_const_cols = TRUE,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  weights_column = NULL,
  nlearners = 50,
  weak_learner = c("AUTO", "DRF", "GLM", "GBM", "DEEP_LEARNING"),
  learn_rate = 0.5,
  weak_learner_params = NULL,
  seed = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.adaBoost_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_nlearners">nlearners</code></td>
<td>
<p>Number of AdaBoost weak learners. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_weak_learner">weak_learner</code></td>
<td>
<p>Choose a weak learner type. Defaults to AUTO, which means DRF. Must be one of: &quot;AUTO&quot;, &quot;DRF&quot;, &quot;GLM&quot;, &quot;GBM&quot;,
&quot;DEEP_LEARNING&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_learn_rate">learn_rate</code></td>
<td>
<p>Learning rate (from 0.0 to 1.0) Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_weak_learner_params">weak_learner_params</code></td>
<td>
<p>Customized parameters for the weak_learner algorithm. E.g list(ntrees=3, max_depth=2, histogram_type='UniformAdaptive'))</p>
</td></tr>
<tr><td><code id="h2o.adaBoost_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a <a href="#topic+H2OModel-class">H2OModel</a> object of the right type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the airlines dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"
data &lt;- h2o.importFile(f)

# Set predictors and response; set response as a factor
data["CAPSULE"] &lt;- as.factor(data["CAPSULE"])
predictors &lt;- c("AGE","RACE","DPROS","DCAPS","PSA","VOL","GLEASON")
response &lt;- "CAPSULE"

# Train the AdaBoost model
h2o_adaboost &lt;- h2o.adaBoost(x = predictors, y = response, training_frame = data, seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aecu'>Retrieve the default AECU (Average Excess Cumulative Uplift = area between AUUC and random AUUC)</h2><span id='topic+h2o.aecu'></span>

<h3>Description</h3>

<p>Retrieves the AECU value from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>. You need to specificy the type of AECU
using metric parameter. Defaults &quot;qini&quot;. Qini AECU equals the Qini value.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training AECU value is returned. If more
than one parameter is set to TRUE, then a named vector of AECUs are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aecu(object, train = FALSE, valid = FALSE, metric = "qini")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aecu_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.aecu_+3A_train">train</code></td>
<td>
<p>Retrieve the training AECU</p>
</td></tr>
<tr><td><code id="h2o.aecu_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AECU</p>
</td></tr>
<tr><td><code id="h2o.aecu_+3A_metric">metric</code></td>
<td>
<p>Specify metric of AECU. Posibilities are &quot;qini&quot;, &quot;lift&quot;, &quot;gain&quot;, defaults &quot;qini&quot;.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.aecu(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aecu_table'>Retrieve the all types of AECU (average excess cumulative uplift) value in a table</h2><span id='topic+h2o.aecu_table'></span>

<h3>Description</h3>

<p>Retrieves the all types of AECU value in a table from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training AECU values are returned. If more
than one parameter is set to TRUE, then a named vector of AECU values are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aecu_table(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aecu_table_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.aecu_table_+3A_train">train</code></td>
<td>
<p>Retrieve the training AECU values table</p>
</td></tr>
<tr><td><code id="h2o.aecu_table_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AECU values table</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.aecu_table(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aggregated_frame'>Retrieve an aggregated frame from an Aggregator model</h2><span id='topic+h2o.aggregated_frame'></span>

<h3>Description</h3>

<p>Retrieve an aggregated frame from the Aggregator model and use it to create a new frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aggregated_frame(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aggregated_frame_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> corresponding from a <code>h2o.aggregator</code> call.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- h2o.createFrame(rows = 100, 
                      cols = 5, 
                      categorical_fraction = 0.6, 
                      integer_fraction = 0,
                      binary_fraction = 0, 
                      real_range = 100, 
                      integer_range = 100, 
                      missing_fraction = 0)
target_num_exemplars = 1000
rel_tol_num_exemplars = 0.5
encoding = "Eigen"
agg &lt;- h2o.aggregator(training_frame = df,
                     target_num_exemplars = target_num_exemplars,
                     rel_tol_num_exemplars = rel_tol_num_exemplars,
                     categorical_encoding = encoding)
# Use the aggregated frame to create a new dataframe
new_df &lt;- h2o.aggregated_frame(agg)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aggregator'>Build an Aggregated Frame</h2><span id='topic+h2o.aggregator'></span>

<h3>Description</h3>

<p>Builds an Aggregated Frame of an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aggregator(
  training_frame,
  x,
  model_id = NULL,
  ignore_const_cols = TRUE,
  target_num_exemplars = 5000,
  rel_tol_num_exemplars = 0.5,
  transform = c("NONE", "STANDARDIZE", "NORMALIZE", "DEMEAN", "DESCALE"),
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  save_mapping_frame = FALSE,
  num_iteration_without_new_exemplar = 500,
  export_checkpoints_dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aggregator_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_target_num_exemplars">target_num_exemplars</code></td>
<td>
<p>Targeted number of exemplars Defaults to 5000.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_rel_tol_num_exemplars">rel_tol_num_exemplars</code></td>
<td>
<p>Relative tolerance for number of exemplars (e.g, 0.5 is +/- 50 percents) Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_transform">transform</code></td>
<td>
<p>Transformation of training data Must be one of: &quot;NONE&quot;, &quot;STANDARDIZE&quot;, &quot;NORMALIZE&quot;, &quot;DEMEAN&quot;, &quot;DESCALE&quot;.
Defaults to NORMALIZE.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_save_mapping_frame">save_mapping_frame</code></td>
<td>
<p><code>Logical</code>. Whether to export the mapping of the aggregated frame Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_num_iteration_without_new_exemplar">num_iteration_without_new_exemplar</code></td>
<td>
<p>The number of iterations to run before aggregator exits if the number of exemplars collected didn't change
Defaults to 500.</p>
</td></tr>
<tr><td><code id="h2o.aggregator_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- h2o.createFrame(rows = 100, 
                      cols = 5, 
                      categorical_fraction = 0.6, 
                      integer_fraction = 0,
                      binary_fraction = 0, 
                      real_range = 100, 
                      integer_range = 100, 
                      missing_fraction = 0)
target_num_exemplars = 1000
rel_tol_num_exemplars = 0.5
encoding = "Eigen"
agg &lt;- h2o.aggregator(training_frame = df,
                     target_num_exemplars = target_num_exemplars,
                     rel_tol_num_exemplars = rel_tol_num_exemplars,
                     categorical_encoding = encoding)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aic'>Retrieve the Akaike information criterion (AIC) value</h2><span id='topic+h2o.aic'></span>

<h3>Description</h3>

<p>Retrieves the AIC value.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training AIC value is returned. If more
than one parameter is set to TRUE, then a named vector of AICs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aic(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aic_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>.</p>
</td></tr>
<tr><td><code id="h2o.aic_+3A_train">train</code></td>
<td>
<p>Retrieve the training AIC</p>
</td></tr>
<tr><td><code id="h2o.aic_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AIC</p>
</td></tr>
<tr><td><code id="h2o.aic_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation AIC</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
p_sid &lt;- h2o.runif(prostate)
prostate_train &lt;- prostate[p_sid &gt; .2,]
prostate_glm &lt;- h2o.glm(x = 3:7, y = 2, training_frame = prostate_train)
aic_basic &lt;- h2o.aic(prostate_glm)
print(aic_basic)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.all'>Given a set of logical vectors, are all of the values true?</h2><span id='topic+h2o.all'></span>

<h3>Description</h3>

<p>Given a set of logical vectors, are all of the values true?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.all(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.all_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+all">all</a></code> for the base R implementation.
</p>

<hr>
<h2 id='h2o.anomaly'>Anomaly Detection via H2O Deep Learning Model</h2><span id='topic+h2o.anomaly'></span>

<h3>Description</h3>

<p>Detect anomalies in an H2O dataset using an H2O deep learning model with
auto-encoding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.anomaly(object, data, per_feature = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.anomaly_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OAutoEncoderModel-class">H2OAutoEncoderModel</a> object that represents the
model to be used for anomaly detection.</p>
</td></tr>
<tr><td><code id="h2o.anomaly_+3A_data">data</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.anomaly_+3A_per_feature">per_feature</code></td>
<td>
<p>Whether to return the per-feature squared reconstruction error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the
reconstruction MSE or the per-feature squared error.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.deeplearning">h2o.deeplearning</a></code> for making an H2OAutoEncoderModel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
prostate_dl = h2o.deeplearning(x = 3:9, training_frame = prostate, autoencoder = TRUE,
                               hidden = c(10, 10), epochs = 5, seed = 1)
prostate_anon = h2o.anomaly(prostate_dl, prostate)
head(prostate_anon)
prostate_anon_per_feature = h2o.anomaly(prostate_dl, prostate, per_feature = TRUE)
head(prostate_anon_per_feature)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.anovaglm'>H2O ANOVAGLM is used to calculate Type III SS which is used to evaluate the contributions of individual predictors 
and their interactions to a model.  Predictors or interactions with negligible contributions to the model will have 
high p-values while those with more contributions will have low p-values.</h2><span id='topic+h2o.anovaglm'></span>

<h3>Description</h3>

<p>H2O ANOVAGLM is used to calculate Type III SS which is used to evaluate the contributions of individual predictors 
and their interactions to a model.  Predictors or interactions with negligible contributions to the model will have 
high p-values while those with more contributions will have low p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.anovaglm(
  x,
  y,
  training_frame,
  model_id = NULL,
  seed = -1,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  offset_column = NULL,
  weights_column = NULL,
  family = c("AUTO", "gaussian", "binomial", "fractionalbinomial", "quasibinomial",
    "poisson", "gamma", "tweedie", "negativebinomial"),
  tweedie_variance_power = 0,
  tweedie_link_power = 1,
  theta = 0,
  solver = c("AUTO", "IRLSM", "L_BFGS", "COORDINATE_DESCENT_NAIVE", "COORDINATE_DESCENT",
    "GRADIENT_DESCENT_LH", "GRADIENT_DESCENT_SQERR"),
  missing_values_handling = c("MeanImputation", "Skip", "PlugValues"),
  plug_values = NULL,
  compute_p_values = TRUE,
  standardize = TRUE,
  non_negative = FALSE,
  max_iterations = 0,
  link = c("family_default", "identity", "logit", "log", "inverse", "tweedie", "ologit"),
  prior = 0,
  alpha = NULL,
  lambda = c(0),
  lambda_search = FALSE,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  early_stopping = FALSE,
  stopping_tolerance = 0.001,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = 0,
  save_transformed_framekeys = FALSE,
  highest_interaction_term = 0,
  nparallelism = 4,
  type = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.anovaglm_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_family">family</code></td>
<td>
<p>Family. Use binomial for classification with logistic regression, others are for regression problems. Must be
one of: &quot;AUTO&quot;, &quot;gaussian&quot;, &quot;binomial&quot;, &quot;fractionalbinomial&quot;, &quot;quasibinomial&quot;, &quot;poisson&quot;, &quot;gamma&quot;, &quot;tweedie&quot;,
&quot;negativebinomial&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_tweedie_variance_power">tweedie_variance_power</code></td>
<td>
<p>Tweedie variance power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_tweedie_link_power">tweedie_link_power</code></td>
<td>
<p>Tweedie link power Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_theta">theta</code></td>
<td>
<p>Theta Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_solver">solver</code></td>
<td>
<p>AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small
number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many
columns. Must be one of: &quot;AUTO&quot;, &quot;IRLSM&quot;, &quot;L_BFGS&quot;, &quot;COORDINATE_DESCENT_NAIVE&quot;, &quot;COORDINATE_DESCENT&quot;,
&quot;GRADIENT_DESCENT_LH&quot;, &quot;GRADIENT_DESCENT_SQERR&quot;. Defaults to IRLSM.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_missing_values_handling">missing_values_handling</code></td>
<td>
<p>Handling of missing values. Either MeanImputation, Skip or PlugValues. Must be one of: &quot;MeanImputation&quot;,
&quot;Skip&quot;, &quot;PlugValues&quot;. Defaults to MeanImputation.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_plug_values">plug_values</code></td>
<td>
<p>Plug Values (a single row frame containing values that will be used to impute missing values of the
training/validation frame, use with conjunction missing_values_handling = PlugValues)</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_compute_p_values">compute_p_values</code></td>
<td>
<p><code>Logical</code>. Request p-values computation, p-values work only with IRLSM solver and no regularization
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize numeric columns to have zero mean and unit variance Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_non_negative">non_negative</code></td>
<td>
<p><code>Logical</code>. Restrict coefficients (not intercept) to be non-negative Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_link">link</code></td>
<td>
<p>Link function. Must be one of: &quot;family_default&quot;, &quot;identity&quot;, &quot;logit&quot;, &quot;log&quot;, &quot;inverse&quot;, &quot;tweedie&quot;, &quot;ologit&quot;.
Defaults to family_default.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_prior">prior</code></td>
<td>
<p>Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean
of response does not reflect reality. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_alpha">alpha</code></td>
<td>
<p>Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha
represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the
amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_lambda">lambda</code></td>
<td>
<p>Regularization strength Defaults to c(0.0).</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_lambda_search">lambda_search</code></td>
<td>
<p><code>Logical</code>. Use lambda search starting at lambda max, given lambda is then interpreted as lambda min
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_early_stopping">early_stopping</code></td>
<td>
<p><code>Logical</code>. Stop early when there is no more relative improvement on train or validation (if provided).
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_save_transformed_framekeys">save_transformed_framekeys</code></td>
<td>
<p><code>Logical</code>. true to save the keys of transformed predictors and interaction column. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_highest_interaction_term">highest_interaction_term</code></td>
<td>
<p>Limit the number of interaction terms, if 2 means interaction between 2 columns only, 3 for three columns and
so on...  Default to 2. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_nparallelism">nparallelism</code></td>
<td>
<p>Number of models to build in parallel.  Default to 4.  Adjust according to your system. Defaults to 4.</p>
</td></tr>
<tr><td><code id="h2o.anovaglm_+3A_type">type</code></td>
<td>
<p>Refer to the SS type 1, 2, 3, or 4.  We are currently only supporting 3 Defaults to 0.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Run ANOVA GLM of VOL ~ CAPSULE + RACE
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
model &lt;- h2o.anovaglm(y = "VOL", x = c("CAPSULE","RACE"), training_frame = prostate)


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.any'>Given a set of logical vectors, is at least one of the values true?</h2><span id='topic+h2o.any'></span>

<h3>Description</h3>

<p>Given a set of logical vectors, is at least one of the values true?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.any(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.any_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+all">all</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.any(iris[, 1] &lt; 1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.anyFactor'>Check H2OFrame columns for factors</h2><span id='topic+h2o.anyFactor'></span>

<h3>Description</h3>

<p>Determines if any column of an H2OFrame object contains categorical data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.anyFactor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.anyFactor_+3A_x">x</code></td>
<td>
<p>An <code>H2OFrame</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a logical value indicating whether any of the columns in <code>x</code> are factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
h2o.anyFactor(iris_hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.api'>Perform a REST API request to a previously connected server.</h2><span id='topic+h2o.api'></span>

<h3>Description</h3>

<p>This function is mostly for internal purposes, but may occasionally be useful for direct access to the backend H2O server.
It has same parameters as :meth:<code style="white-space: pre;">&#8288;H2OConnection.request &lt;h2o.backend.H2OConnection.request&gt;&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.api(endpoint, params = NULL, json = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.api_+3A_endpoint">endpoint</code></td>
<td>
<p>A H2O REST API endpoint.</p>
</td></tr>
<tr><td><code id="h2o.api_+3A_params">params</code></td>
<td>
<p>A list of params passed in the url.</p>
</td></tr>
<tr><td><code id="h2o.api_+3A_json">json</code></td>
<td>
<p>A list of params passed as a json payload.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>REST API endpoints can be obtained using:
</p>
<div class="sourceCode"><pre>endpoints &lt;- sapply(h2o.api("GET /3/Metadata/endpoints")$routes, function(r) paste(r$http_method, r$url_pattern))
</pre></div>
<p>For a given route, the supported params can be otained using:
</p>
<div class="sourceCode"><pre>parameters &lt;- sapply(h2o.api("GET /3/Metadata/schemas/{route$input_schema}")$schemas[[1]]$fields, function(f) { l &lt;-list(); l[f$name] &lt;- f$help; l })
</pre></div>


<h3>Value</h3>

<p>The parsed response.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res &lt;- h2o.api("GET /3/NetworkTest")
res$table

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.arrange'>Sorts an H2O frame by columns</h2><span id='topic+h2o.arrange'></span>

<h3>Description</h3>

<p>Sorts H2OFrame by the columns specified. H2OFrame can contain String columns but should not sort on any
String columns.  Otherwise, an error will
be thrown.  To sort column c1 in descending order, do desc(c1).  Returns a new H2OFrame, like dplyr::arrange.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.arrange(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.arrange_+3A_x">x</code></td>
<td>
<p>The H2OFrame input to be sorted.</p>
</td></tr>
<tr><td><code id="h2o.arrange_+3A_...">...</code></td>
<td>
<p>The column names to sort by.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.arrange(iris, "species","petal_len","petal_wid")

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.as_date'>Convert between character representations and objects of Date class</h2><span id='topic+h2o.as_date'></span>

<h3>Description</h3>

<p>Functions to convert between character representations and objects of class &quot;Date&quot; representing calendar dates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.as_date(x, format, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.as_date_+3A_x">x</code></td>
<td>
<p>H2OFrame column of strings or factors to be converted</p>
</td></tr>
<tr><td><code id="h2o.as_date_+3A_format">format</code></td>
<td>
<p>A character string indicating date pattern</p>
</td></tr>
<tr><td><code id="h2o.as_date_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.as_date(hdf["ds5"], "%d.%m.%y %H:%M")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ascharacter'>Convert H2O Data to Characters</h2><span id='topic+h2o.ascharacter'></span>

<h3>Description</h3>

<p>Convert H2O Data to Characters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ascharacter(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ascharacter_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.ascharacter(iris["species"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.asfactor'>Convert H2O Data to Factors</h2><span id='topic+h2o.asfactor'></span>

<h3>Description</h3>

<p>Convert H2O Data to Factors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.asfactor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.asfactor_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factor">factor</a></code> for the base R implementation, <code>as.factor()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.asfactor(cars["cylinders"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.asnumeric'>Convert H2O Data to Numerics</h2><span id='topic+h2o.asnumeric'></span>

<h3>Description</h3>

<p>If the column type is enum and you want to convert it to numeric, you should first convert it to character then convert it to numeric. 
Otherwise, the values may be converted to underlying factor values, not the expected mapped values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.asnumeric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.asnumeric_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+numeric">numeric</a></code> for the base R implementation, <code>as.numeric()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.ascharacter(cars)
h2o.asnumeric(cars)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.assign'>Rename an H2O object.</h2><span id='topic+h2o.assign'></span>

<h3>Description</h3>

<p>Makes a copy of the data frame and gives it the desired key.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.assign(data, key)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.assign_+3A_data">data</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="h2o.assign_+3A_key">key</code></td>
<td>
<p>The key to be associated with the H2O parsed data object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
dim(cars)
split &lt;- h2o.splitFrame(data = cars, ratios = 0.8)
train &lt;- h2o.assign(split[[1]], key = "train")
test &lt;- h2o.assign(split[[2]], key = "test")
dim(train)
dim(test)

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.atc'>Retrieve Average Treatment Effect on the Control</h2><span id='topic+h2o.atc'></span>

<h3>Description</h3>

<p>Retrieves ATC from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training ATC is returned. If more
than one parameter is set to TRUE, then a named vector of ATC values are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.atc(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.atc_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> or</p>
</td></tr>
<tr><td><code id="h2o.atc_+3A_train">train</code></td>
<td>
<p>Retrieve the training ATC value</p>
</td></tr>
<tr><td><code id="h2o.atc_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation ATC value</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.atc(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ate'>Retrieve Average Treatment Effect</h2><span id='topic+h2o.ate'></span>

<h3>Description</h3>

<p>Retrieves ATE from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training ATE is returned. If more
than one parameter is set to TRUE, then a named vector of ATE values are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ate(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ate_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> or</p>
</td></tr>
<tr><td><code id="h2o.ate_+3A_train">train</code></td>
<td>
<p>Retrieve the training ATE value</p>
</td></tr>
<tr><td><code id="h2o.ate_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation ATE value</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.ate(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.att'>Retrieve Average Treatment Effect on the Treated</h2><span id='topic+h2o.att'></span>

<h3>Description</h3>

<p>Retrieves ATE from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training ATT is returned. If more
than one parameter is set to TRUE, then a named vector of ATT values are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.att(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.att_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> or</p>
</td></tr>
<tr><td><code id="h2o.att_+3A_train">train</code></td>
<td>
<p>Retrieve the training ATT value</p>
</td></tr>
<tr><td><code id="h2o.att_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation ATT value</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.att(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.auc'>Retrieve the AUC</h2><span id='topic+h2o.auc'></span>

<h3>Description</h3>

<p>Retrieves the AUC value from an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training AUC value is returned. If more
than one parameter is set to TRUE, then a named vector of AUCs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.auc(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.auc_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> or <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.auc_+3A_train">train</code></td>
<td>
<p>Retrieve the training AUC</p>
</td></tr>
<tr><td><code id="h2o.auc_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AUC</p>
</td></tr>
<tr><td><code id="h2o.auc_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation AUC</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the Gini coefficient,
<code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the
various threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for
creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.auc(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.aucpr'>Retrieve the AUCPR (Area Under Precision Recall Curve)</h2><span id='topic+h2o.aucpr'></span><span id='topic+h2o.pr_auc'></span>

<h3>Description</h3>

<p>Retrieves the AUCPR value from an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training AUCPR value is returned. If more
than one parameter is set to TRUE, then a named vector of AUCPRs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.aucpr(object, train = FALSE, valid = FALSE, xval = FALSE)

h2o.pr_auc(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.aucpr_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.aucpr_+3A_train">train</code></td>
<td>
<p>Retrieve the training aucpr</p>
</td></tr>
<tr><td><code id="h2o.aucpr_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation aucpr</p>
</td></tr>
<tr><td><code id="h2o.aucpr_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation aucpr</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the Gini coefficient,
<code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the
various threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for
creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.aucpr(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.automl'>Automatic Machine Learning</h2><span id='topic+h2o.automl'></span>

<h3>Description</h3>

<p>The Automatic Machine Learning (AutoML) function automates the supervised machine learning model training process.
AutoML finds the best model, given a training frame and response, and returns an H2OAutoML object,
which contains a leaderboard of all the models that were trained in the process, ranked by a default model performance metric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.automl(
  x,
  y,
  training_frame,
  validation_frame = NULL,
  leaderboard_frame = NULL,
  blending_frame = NULL,
  nfolds = -1,
  fold_column = NULL,
  weights_column = NULL,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = NULL,
  max_runtime_secs_per_model = NULL,
  max_models = NULL,
  distribution = c("AUTO", "bernoulli", "ordinal", "multinomial", "gaussian", "poisson",
    "gamma", "tweedie", "laplace", "quantile", "huber", "custom"),
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error"),
  stopping_tolerance = NULL,
  stopping_rounds = 3,
  seed = NULL,
  project_name = NULL,
  exclude_algos = NULL,
  include_algos = NULL,
  modeling_plan = NULL,
  preprocessing = NULL,
  exploitation_ratio = -1,
  monotone_constraints = NULL,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_models = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  sort_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE", "AUC",
    "AUCPR", "mean_per_class_error"),
  export_checkpoints_dir = NULL,
  verbosity = "warn",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.automl_+3A_x">x</code></td>
<td>
<p>A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_y">y</code></td>
<td>
<p>The name or index of the response variable in the model. For classification, the y column must be a
factor, otherwise regression will be performed. Indexes are 1-based in R.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_training_frame">training_frame</code></td>
<td>
<p>Training frame (H2OFrame or ID).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Validation frame (H2OFrame or ID); Optional.  This argument is ignored unless the user sets nfolds = 0.
If cross-validation is turned off, then a validation frame can be specified and used for early stopping of individual models and early
stopping of the grid searches.  By default and when nfolds &gt; 1, cross-validation metrics will be used for early stopping and thus
validation_frame will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_leaderboard_frame">leaderboard_frame</code></td>
<td>
<p>Leaderboard frame (H2OFrame or ID); Optional.  If provided, the Leaderboard will be scored using
this data frame intead of using cross-validation metrics, which is the default.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_blending_frame">blending_frame</code></td>
<td>
<p>Blending frame (H2OFrame or ID) used to train the the metalearning algorithm in Stacked Ensembles (instead of relying on cross-validated predicted values); Optional.
When provided, it also is recommended to disable cross validation by setting <code>nfolds=0</code> and to provide a leaderboard frame for scoring purposes.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for k-fold cross-validation. Must be &gt;= 2; defaults to 5. Use 0 to disable cross-validation;
this will also disable Stacked Ensemble (thus decreasing the overall model performance).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation; used to override the default, randomized, 5-fold cross-validation scheme for individual models in the AutoML run.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative weights are not allowed.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Specify whether to oversample the minority classes to balance the class distribution; only applicable to classification. If the oversampled size of the
dataset exceeds the maximum size calculated during <code>max_after_balance_size</code> parameter, then the majority class will be undersampled to satisfy the size limit. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires <code>balance_classes</code>.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
<code>balance_classes</code>. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>This argument specifies the maximum time that the AutoML process will run for.
If both <code>max_runtime_secs</code> and <code>max_models</code> are specified, then the AutoML run will stop as soon as it hits either of these limits.
If neither <code>max_runtime_secs</code> nor <code>max_models</code> are specified by the user, then <code>max_runtime_secs</code> defaults to 3600 seconds (1 hour).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_max_runtime_secs_per_model">max_runtime_secs_per_model</code></td>
<td>
<p>Maximum runtime in seconds dedicated to each individual model training process. Use 0 to disable. Defaults to 0.
Note that models constrained by a time budget are not guaranteed reproducible.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_max_models">max_models</code></td>
<td>
<p>Maximum number of models to build in the AutoML process (does not include Stacked Ensembles). Defaults to NULL (no strict limit).
Always set this parameter to ensure AutoML reproducibility: all models are then trained until convergence and none is constrained by a time budget.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function used by algorithms that support it; other algorithms use their defaults. Possible values: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;, &quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;, &quot;custom&quot;, and for parameterized distributions list form is used to specify the parameter, e.g., <code>list(type = "tweedie", tweedie_power = 1.5)</code>. Defaults to &quot;AUTO&quot;.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (&quot;AUTO&quot; is logloss for classification, deviance for regression).
Must be one of &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;, &quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;. Defaults to &quot;AUTO&quot;.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much). This value defaults to 0.001 if the
dataset is at least 1 million rows; otherwise it defaults to a bigger value determined by the size of the dataset and the non-NA-rate.  In that case, the value is computed
as 1/sqrt(nrows * non-NA-rate).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Integer. Early stopping based on convergence of <code>stopping_metric</code>. Stop if simple moving average of length k of the <code>stopping_metric</code>
does not improve for k (<code>stopping_rounds</code>) scoring events. Defaults to 3 and must be an non-zero integer.  Use 0 to disable early stopping.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_seed">seed</code></td>
<td>
<p>Integer. Set a seed for reproducibility. AutoML can only guarantee reproducibility if <code>max_models</code> or early stopping is used
because <code>max_runtime_secs</code> is resource limited, meaning that if the resources are not the same between runs, AutoML may be able to train more models on one run vs another.
In addition, H2O Deep Learning models are not reproducible by default for performance reasons, so if the user requires reproducibility, then <code>exclude_algos</code> must
contain &quot;DeepLearning&quot;.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_project_name">project_name</code></td>
<td>
<p>Character string to identify an AutoML project.  Defaults to NULL, which means a project name will be auto-generated. More models can be trained and added to an existing
AutoML project by specifying the same project name in multiple calls to the AutoML function (as long as the same training frame is used in subsequent runs).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_exclude_algos">exclude_algos</code></td>
<td>
<p>Vector of character strings naming the algorithms to skip during the model-building phase.  An example use is <code>exclude_algos = c("GLM", "DeepLearning", "DRF")</code>,
and the full list of options is: &quot;DRF&quot; (Random Forest and Extremely-Randomized Trees), &quot;GLM&quot;, &quot;XGBoost&quot;, &quot;GBM&quot;, &quot;DeepLearning&quot; and &quot;StackedEnsemble&quot;.
Defaults to NULL, which means that all appropriate H2O algorithms will be used, if the search stopping criteria allow. Optional.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_include_algos">include_algos</code></td>
<td>
<p>Vector of character strings naming the algorithms to restrict to during the model-building phase. This can't be used in combination with <code>exclude_algos</code> param.
Defaults to NULL, which means that all appropriate H2O algorithms will be used, if the search stopping criteria allow. Optional.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_modeling_plan">modeling_plan</code></td>
<td>
<p>List. The list of modeling steps to be used by the AutoML engine (they may not all get executed, depending on other constraints). Optional (Expert usage only).</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_preprocessing">preprocessing</code></td>
<td>
<p>List. The list of preprocessing steps to run. Only 'target_encoding' is currently supported.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_exploitation_ratio">exploitation_ratio</code></td>
<td>
<p>The budget ratio (between 0 and 1) dedicated to the exploitation (vs exploration) phase. By default, this is set to AUTO (exploitation_ratio=-1) as this is still experimental; to activate it, it is recommended to try a ratio around 0.1. Note that the current exploitation phase only tries to fine-tune the best XGBoost and the best GBM found during exploration.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_monotone_constraints">monotone_constraints</code></td>
<td>
<p>List. A mapping representing monotonic constraints.
Use +1 to enforce an increasing constraint and -1 to specify a decreasing constraint.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation predictions. This needs to be set to TRUE if running the same AutoML object for repeated runs because CV predictions are required to build additional Stacked Ensemble models in AutoML. This option defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validated models. Keeping cross-validation models may consume significantly more memory in the H2O cluster. This option defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep fold assignments in the models. Deleting them will save memory in the H2O cluster. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_sort_metric">sort_metric</code></td>
<td>
<p>Metric to sort the leaderboard by. For binomial classification choose between &quot;AUC&quot;, &quot;AUCPR&quot;, &quot;logloss&quot;, &quot;mean_per_class_error&quot;, &quot;RMSE&quot;, &quot;MSE&quot;.
For regression choose between &quot;mean_residual_deviance&quot;, &quot;RMSE&quot;, &quot;MSE&quot;, &quot;MAE&quot;, and &quot;RMSLE&quot;. For multinomial classification choose between
&quot;mean_per_class_error&quot;, &quot;logloss&quot;, &quot;RMSE&quot;, &quot;MSE&quot;. Default is &quot;AUTO&quot;. If set to &quot;AUTO&quot;, then &quot;AUC&quot; will be used for binomial classification,
&quot;mean_per_class_error&quot; for multinomial classification, and &quot;mean_residual_deviance&quot; for regression.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>(Optional) Path to a directory where every model will be stored in binary form.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_verbosity">verbosity</code></td>
<td>
<p>Verbosity of the backend messages printed during training; Optional.
Must be one of NULL (live log disabled), &quot;debug&quot;, &quot;info&quot;, &quot;warn&quot;, &quot;error&quot;. Defaults to &quot;warn&quot;.</p>
</td></tr>
<tr><td><code id="h2o.automl_+3A_...">...</code></td>
<td>
<p>Additional (experimental) arguments to be passed through; Optional.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AutoML trains several models, cross-validated by default, by using the following available algorithms:
</p>

<ul>
<li><p> XGBoost
</p>
</li>
<li><p> GBM (Gradient Boosting Machine)
</p>
</li>
<li><p> GLM (Generalized Linear Model)
</p>
</li>
<li><p> DRF (Distributed Random Forest)
</p>
</li>
<li><p> XRT (eXtremely Randomized Trees)
</p>
</li>
<li><p> DeepLearning (Fully Connected Deep Neural Network)
</p>
</li></ul>

<p>It also applies HPO on the following algorithms:
</p>

<ul>
<li><p> XGBoost
</p>
</li>
<li><p> GBM
</p>
</li>
<li><p> DeepLearning
</p>
</li></ul>

<p>In some cases, there will not be enough time to complete all the algorithms, so some may be missing from the leaderboard.
</p>
<p>Finally, AutoML also trains several Stacked Ensemble models at various stages during the run.
Mainly two kinds of Stacked Ensemble models are trained:
</p>

<ul>
<li><p> one of all available models at time t.
</p>
</li>
<li><p> one of only the best models of each kind at time t.
</p>
</li></ul>

<p>Note that Stacked Ensemble models are trained only if there isn't another stacked ensemble with the same base models.
</p>


<h3>Value</h3>

<p>An <a href="#topic+H2OAutoML-class">H2OAutoML</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 30)
lb &lt;- h2o.get_leaderboard(aml)
head(lb)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.auuc'>Retrieve AUUC</h2><span id='topic+h2o.auuc'></span>

<h3>Description</h3>

<p>Retrieves the AUUC value from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>. If the metric parameter is &quot;AUTO&quot;, 
the type of AUUC depends on auuc_type which was set before training. If you need specific AUUC, set metric parameter.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training AUUC value is returned. If more
than one parameter is set to TRUE, then a named vector of AUUCs are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.auuc(object, train = FALSE, valid = FALSE, metric = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.auuc_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.auuc_+3A_train">train</code></td>
<td>
<p>Retrieve the training AUUC</p>
</td></tr>
<tr><td><code id="h2o.auuc_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AUUC</p>
</td></tr>
<tr><td><code id="h2o.auuc_+3A_metric">metric</code></td>
<td>
<p>Specify the AUUC metric to get specific AUUC. Possibilities are NULL, &quot;qini&quot;, &quot;lift&quot;, &quot;gain&quot;.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment", 
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.auuc(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.auuc_normalized'>Retrieve normalized AUUC</h2><span id='topic+h2o.auuc_normalized'></span>

<h3>Description</h3>

<p>Retrieves the AUUC value from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>. If the metric parameter is &quot;AUTO&quot;, 
the type of AUUC depends on auuc_type which was set before training. If you need specific normalized AUUC, 
set metric parameter. If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training normalized AUUC 
value is returned. If more than one parameter is set to TRUE, then a named vector of normalized AUUCs are returned, 
where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.auuc_normalized(object, train = FALSE, valid = FALSE, metric = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.auuc_normalized_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.auuc_normalized_+3A_train">train</code></td>
<td>
<p>Retrieve the training AUUC</p>
</td></tr>
<tr><td><code id="h2o.auuc_normalized_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AUUC</p>
</td></tr>
<tr><td><code id="h2o.auuc_normalized_+3A_metric">metric</code></td>
<td>
<p>Specify the AUUC metric to get specific AUUC. Possibilities are NULL, &quot;qini&quot;, &quot;lift&quot;, &quot;gain&quot;.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment", 
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.auuc_normalized(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.auuc_table'>Retrieve the all types of AUUC in a table</h2><span id='topic+h2o.auuc_table'></span>

<h3>Description</h3>

<p>Retrieves the all types of AUUC in a table from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training AUUC values are returned. If more
than one parameter is set to TRUE, then a named vector of AUUCs are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.auuc_table(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.auuc_table_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.auuc_table_+3A_train">train</code></td>
<td>
<p>Retrieve the training AUUC table</p>
</td></tr>
<tr><td><code id="h2o.auuc_table_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AUUC table</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                       ntrees=10, max_depth=5, treatment_column="treatment", 
                                       auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.auuc_table(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.average_objective'>Extracts the final training average objective function of a GLM model.</h2><span id='topic+h2o.average_objective'></span>

<h3>Description</h3>

<p>Extracts the final training average objective function of a GLM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.average_objective(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.average_objective_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The final training average objective of a GLM model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "acceleration"
cars_model &lt;- h2o.glm(y=response, 
                       x=predictors, 
                       training_frame = cars, 
                       family="gaussian",
                       generate_scoring_history=TRUE)
objValue &lt;- h2o.average_objective(cars_model)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.betweenss'>Get the between cluster sum of squares</h2><span id='topic+h2o.betweenss'></span>

<h3>Description</h3>

<p>Get the between cluster sum of squares.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training betweenss value is returned. If more
than one parameter is set to TRUE, then a named vector of betweenss' are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.betweenss(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.betweenss_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.betweenss_+3A_train">train</code></td>
<td>
<p>Retrieve the training between cluster sum of squares</p>
</td></tr>
<tr><td><code id="h2o.betweenss_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation between cluster sum of squares</p>
</td></tr>
<tr><td><code id="h2o.betweenss_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation between cluster sum of squares</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.betweenss(km, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.biases'>Return the respective bias vector</h2><span id='topic+h2o.biases'></span>

<h3>Description</h3>

<p>Return the respective bias vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.biases(object, vector_id = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.biases_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.biases_+3A_vector_id">vector_id</code></td>
<td>
<p>An integer, ranging from 1 to number of layers + 1, that specifies the bias vector to return.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/chicago/chicagoCensus.csv"
census &lt;- h2o.importFile(f)
census[, 1] &lt;- as.factor(census[, 1])

dl_model &lt;- h2o.deeplearning(x = c(1:3), y = 4, training_frame = census,
                            hidden = c(17, 191),
                            epochs = 1, 
                            balance_classes = FALSE, 
                            export_weights_and_biases = TRUE)
h2o.biases(dl_model, vector_id = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.bottomN'>H2O bottomN</h2><span id='topic+h2o.bottomN'></span>

<h3>Description</h3>

<p>bottomN function will will grab the bottom N percent of values of a column and return it in a H2OFrame.
Extract the top N percent of values of a column and return it in a H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.bottomN(x, column, nPercent)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.bottomN_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.bottomN_+3A_column">column</code></td>
<td>
<p>is a column name or column index to grab the top N percent value from</p>
</td></tr>
<tr><td><code id="h2o.bottomN_+3A_npercent">nPercent</code></td>
<td>
<p>is a bottom percentage value to grab</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with 2 columns.  The first column is the original row indices, second column contains the bottomN values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f1 &lt;- "https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/jira/TopBottomNRep4.csv.zip"
f2 &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/Bottom20Per.csv.zip"
data_Frame &lt;- h2o.importFile(f1)
bottom_Answer &lt;- h2o.importFile(f2)
nPercent &lt;- c(1, 2, 3, 4)
frame_Names &lt;- names(data_Frame)
nP &lt;- nPercent[sample(1:length(nPercent), 1, replace = FALSE)]
col_Index &lt;- sample(1:length(frame_Names), 1, replace = FALSE)
h2o.bottomN(data_Frame, frame_Names[col_Index], nP)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.calculate_fairness_metrics'>Calculate intersectional fairness metrics.</h2><span id='topic+h2o.calculate_fairness_metrics'></span>

<h3>Description</h3>

<p>Calculate intersectional fairness metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.calculate_fairness_metrics(
  model,
  frame,
  protected_columns,
  reference,
  favorable_class
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.calculate_fairness_metrics_+3A_model">model</code></td>
<td>
<p>H2O Model</p>
</td></tr>
<tr><td><code id="h2o.calculate_fairness_metrics_+3A_frame">frame</code></td>
<td>
<p>Frame used to calculate the metrics.</p>
</td></tr>
<tr><td><code id="h2o.calculate_fairness_metrics_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.calculate_fairness_metrics_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.calculate_fairness_metrics_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dictionary of frames. One frame is the overview, other frames contain dependence
of performance on threshold for each protected group.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.calculate_fairness_metrics(gbm, test, protected_columns = protected_columns,
                               reference = reference, favorable_class = favorable_class)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cbind'>Combine H2O Datasets by Columns</h2><span id='topic+h2o.cbind'></span>

<h3>Description</h3>

<p>Takes a sequence of H2O data sets and combines them by column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cbind(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cbind_+3A_...">...</code></td>
<td>
<p>A sequence of H2OFrame arguments. All datasets must exist on the same H2O instance
(IP and port) and contain the same number of rows.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the combined ... arguments column-wise.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cbind">cbind</a></code> for the base <code>R</code> method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate_cbind &lt;- h2o.cbind(prostate, prostate)
head(prostate_cbind)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ceiling'>Take a single numeric argument and return a numeric vector with the smallest integers</h2><span id='topic+h2o.ceiling'></span>

<h3>Description</h3>

<p>ceiling takes a single numeric argument x and returns a
numeric vector containing the smallest integers not less than the
corresponding elements of x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ceiling(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ceiling_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for the base R implementation, <code>ceiling()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.ceiling(iris[, 1])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.centers'>Retrieve the Model Centers</h2><span id='topic+h2o.centers'></span>

<h3>Description</h3>

<p>Retrieve the Model Centers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.centers(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.centers_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
h2o.ceiling(fr[, 1])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.centersSTD'>Retrieve the Model Centers STD</h2><span id='topic+h2o.centersSTD'></span>

<h3>Description</h3>

<p>Retrieve the Model Centers STD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.centersSTD(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.centersSTD_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.centersSTD(km)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.centroid_stats'>Retrieve centroid statistics</h2><span id='topic+h2o.centroid_stats'></span>

<h3>Description</h3>

<p>Retrieve the centroid statistics.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training centroid stats value is returned. If more
than one parameter is set to TRUE, then a named list of centroid stats data frames are returned, where the names are &quot;train&quot; or &quot;valid&quot;
For cross validation metrics this statistics are not available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.centroid_stats(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.centroid_stats_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.centroid_stats_+3A_train">train</code></td>
<td>
<p>Retrieve the training centroid statistics</p>
</td></tr>
<tr><td><code id="h2o.centroid_stats_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation centroid statistics</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.centroid_stats(km, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.clearLog'>Delete All H2O R Logs</h2><span id='topic+h2o.clearLog'></span>

<h3>Description</h3>

<p>Clear all H2O R command and error response logs from the local disk. Used
primarily for debugging purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.clearLog()
</code></pre>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.startLogging">h2o.startLogging</a>, <a href="#topic+h2o.stopLogging">h2o.stopLogging</a>,
         <a href="#topic+h2o.openLog">h2o.openLog</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.startLogging()
australia_path = system.file("extdata", "australia.csv", package = "h2o")
australia = h2o.importFile(path = australia_path)
h2o.stopLogging()
h2o.clearLog()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cluster_sizes'>Retrieve the cluster sizes</h2><span id='topic+h2o.cluster_sizes'></span>

<h3>Description</h3>

<p>Retrieve the cluster sizes.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training cluster sizes value is returned. If more
than one parameter is set to TRUE, then a named list of cluster size vectors are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cluster_sizes(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cluster_sizes_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.cluster_sizes_+3A_train">train</code></td>
<td>
<p>Retrieve the training cluster sizes</p>
</td></tr>
<tr><td><code id="h2o.cluster_sizes_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation cluster sizes</p>
</td></tr>
<tr><td><code id="h2o.cluster_sizes_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation cluster sizes</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.cluster_sizes(km, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.clusterInfo'>Print H2O cluster info</h2><span id='topic+h2o.clusterInfo'></span>

<h3>Description</h3>

<p>Print H2O cluster info
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.clusterInfo()
</code></pre>

<hr>
<h2 id='h2o.clusterIsUp'>Determine if an H2O cluster is up or not</h2><span id='topic+h2o.clusterIsUp'></span>

<h3>Description</h3>

<p>Determine if an H2O cluster is up or not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.clusterIsUp(conn = h2o.getConnection())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.clusterIsUp_+3A_conn">conn</code></td>
<td>
<p>H2OConnection object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if the cluster is up; FALSE otherwise
</p>

<hr>
<h2 id='h2o.clusterStatus'>Return the status of the cluster</h2><span id='topic+h2o.clusterStatus'></span>

<h3>Description</h3>

<p>Retrieve information on the status of the cluster running H2O.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.clusterStatus()
</code></pre>


<h3>See Also</h3>

<p><a href="#topic+H2OConnection-class">H2OConnection</a>, <code><a href="#topic+h2o.init">h2o.init</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
h2o.clusterStatus()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.coef'>Return the coefficients that can be applied to the non-standardized data.</h2><span id='topic+h2o.coef'></span>

<h3>Description</h3>

<p>Note: standardize = True by default. If set to False, then coef() returns the coefficients that are fit directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.coef(object, predictorSize = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.coef_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.coef_+3A_predictorsize">predictorSize</code></td>
<td>
<p>predictor subset size.  If specified, will only return model coefficients of that subset size.  If
not specified will return a lists of model coefficient dicts for all predictor subset size.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "cylinders"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_glm &lt;- h2o.glm(balance_classes = TRUE, 
                    seed = 1234, 
                    x = predictors, 
                    y = response, 
                    training_frame = train, 
                    validation_frame = valid)
h2o.coef(cars_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.coef_norm'>Return coefficients fitted on the standardized data (requires standardize = True, which is on by default). These coefficients can be used to evaluate variable importance.</h2><span id='topic+h2o.coef_norm'></span>

<h3>Description</h3>

<p>Return coefficients fitted on the standardized data (requires standardize = True, which is on by default). These coefficients can be used to evaluate variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.coef_norm(object, predictorSize = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.coef_norm_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.coef_norm_+3A_predictorsize">predictorSize</code></td>
<td>
<p>predictor subset size.  If specified, will only return model coefficients of that subset size.  If
not specified will return a lists of model coefficient dicts for all predictor subset size.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "cylinders"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_glm &lt;- h2o.glm(balance_classes = TRUE, 
                    seed = 1234, 
                    x = predictors, 
                    y = response, 
                    training_frame = train, 
                    validation_frame = valid)
h2o.coef_norm(cars_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.coef_with_p_values'>Return the coefficients table with coefficients, standardized coefficients, p-values, z-values and std-error for GLM models</h2><span id='topic+h2o.coef_with_p_values'></span>

<h3>Description</h3>

<p>Return the coefficients table with coefficients, standardized coefficients, p-values, z-values and std-error for GLM models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.coef_with_p_values(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.coef_with_p_values_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "cylinders"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_glm &lt;- h2o.glm(seed = 1234, 
                    lambda=0.0,
                    compute_p_values=TRUE,
                    x = predictors, 
                    y = response, 
                    training_frame = train, 
                    validation_frame = valid)
h2o.coef_with_p_values(cars_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.colnames'>Return column names of an H2OFrame</h2><span id='topic+h2o.colnames'></span>

<h3>Description</h3>

<p>Return column names of an H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.colnames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.colnames_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+colnames">colnames</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.colnames(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.columns_by_type'>Obtain a list of columns that are specified by 'coltype'</h2><span id='topic+h2o.columns_by_type'></span>

<h3>Description</h3>

<p>Obtain a list of columns that are specified by 'coltype'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.columns_by_type(object, coltype = "numeric", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.columns_by_type_+3A_object">object</code></td>
<td>
<p>H2OFrame object</p>
</td></tr>
<tr><td><code id="h2o.columns_by_type_+3A_coltype">coltype</code></td>
<td>
<p>A character string indicating which column type to filter by. This must be one of the following:
&quot;numeric&quot;      - Numeric, but not categorical or time
&quot;categorical&quot;  - Integer, with a categorical/factor String mapping
&quot;string&quot;       - String column
&quot;time&quot;         - Long msec since the Unix Epoch - with a variety of display/parse options
&quot;uuid&quot;         - UUID
&quot;bad&quot;          - No none-NA rows (triple negative! all NAs or zero rows)</p>
</td></tr>
<tr><td><code id="h2o.columns_by_type_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of column indices that correspond to &quot;type&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.columns_by_type(prostate, coltype = "numeric")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.computeGram'>Compute weighted gram matrix.</h2><span id='topic+h2o.computeGram'></span>

<h3>Description</h3>

<p>Compute weighted gram matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.computeGram(
  X,
  weights = "",
  use_all_factor_levels = FALSE,
  standardize = TRUE,
  skip_missing = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.computeGram_+3A_x">X</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding to H2O framel.</p>
</td></tr>
<tr><td><code id="h2o.computeGram_+3A_weights">weights</code></td>
<td>
<p>character corresponding to name of weight vector in frame.</p>
</td></tr>
<tr><td><code id="h2o.computeGram_+3A_use_all_factor_levels">use_all_factor_levels</code></td>
<td>
<p>logical flag telling h2o whether or not to skip first level of categorical variables during one-hot encoding.</p>
</td></tr>
<tr><td><code id="h2o.computeGram_+3A_standardize">standardize</code></td>
<td>
<p>logical flag telling h2o whether or not to standardize data</p>
</td></tr>
<tr><td><code id="h2o.computeGram_+3A_skip_missing">skip_missing</code></td>
<td>
<p>logical flag telling h2o whether skip rows with missing data or impute them with mean</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.confusionMatrix'>Access H2O Confusion Matrices</h2><span id='topic+h2o.confusionMatrix'></span><span id='topic+h2o.confusionMatrix+2CH2OModel-method'></span><span id='topic+h2o.confusionMatrix+2CH2OModelMetrics-method'></span>

<h3>Description</h3>

<p>Retrieve either a single or many confusion matrices from H2O objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.confusionMatrix(object, ...)

## S4 method for signature 'H2OModel'
h2o.confusionMatrix(object, newdata, valid = FALSE, xval = FALSE, ...)

## S4 method for signature 'H2OModelMetrics'
h2o.confusionMatrix(object, thresholds = NULL, metrics = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.confusionMatrix_+3A_object">object</code></td>
<td>
<p>Either an <a href="#topic+H2OModel-class">H2OModel</a> object or an
<a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_...">...</code></td>
<td>
<p>Extra arguments for extracting train or valid confusion matrices.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object that can be scored on.
Requires a valid response column.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation metric.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation metric.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) A value or a list of valid values between 0.0 and 1.0.
This value is only used in the case of
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> objects.</p>
</td></tr>
<tr><td><code id="h2o.confusionMatrix_+3A_metrics">metrics</code></td>
<td>
<p>(Optional) A metric or a list of valid metrics (&quot;min_per_class_accuracy&quot;, &quot;absolute_mcc&quot;, &quot;tnr&quot;, &quot;fnr&quot;, &quot;fpr&quot;, &quot;tpr&quot;, &quot;precision&quot;, &quot;accuracy&quot;, &quot;f0point5&quot;, &quot;f2&quot;, &quot;f1&quot;).
This value is only used in the case of
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> objects.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> version of this function will only take
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> or <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a>
objects. If no threshold is specified, all possible thresholds are selected.
</p>


<h3>Value</h3>

<p>Calling this function on <a href="#topic+H2OModel-class">H2OModel</a> objects returns a
confusion matrix corresponding to the <code><a href="stats.html#topic+predict">predict</a></code> function.
If used on an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> object, returns a list
of matrices corresponding to the number of thresholds specified.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict</a></code> for generating prediction frames,
<code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating
<a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
h2o.confusionMatrix(model, prostate)
# Generating a ModelMetrics object
perf &lt;- h2o.performance(model, prostate)
h2o.confusionMatrix(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.connect'>Connect to a running H2O instance.</h2><span id='topic+h2o.connect'></span>

<h3>Description</h3>

<p>Connect to a running H2O instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.connect(
  ip = "localhost",
  port = 54321,
  strict_version_check = TRUE,
  proxy = NA_character_,
  https = FALSE,
  cacert = NA_character_,
  insecure = FALSE,
  username = NA_character_,
  password = NA_character_,
  use_spnego = FALSE,
  cookies = NA_character_,
  context_path = NA_character_,
  config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.connect_+3A_ip">ip</code></td>
<td>
<p>Object of class <code>character</code> representing the IP address of the server where H2O is running.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_port">port</code></td>
<td>
<p>Object of class <code>numeric</code> representing the port number of the H2O server.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_strict_version_check">strict_version_check</code></td>
<td>
<p>(Optional) Setting this to FALSE is unsupported and should only be done when advised by technical support.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_proxy">proxy</code></td>
<td>
<p>(Optional) A <code>character</code> string specifying the proxy path.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_https">https</code></td>
<td>
<p>(Optional) Set this to TRUE to use https instead of http.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_cacert">cacert</code></td>
<td>
<p>Path to a CA bundle file with root and intermediate certificates of trusted CAs.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_insecure">insecure</code></td>
<td>
<p>(Optional) Set this to TRUE to disable SSL certificate checking.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_username">username</code></td>
<td>
<p>(Optional) Username to login with.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_password">password</code></td>
<td>
<p>(Optional) Password to login with.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_use_spnego">use_spnego</code></td>
<td>
<p>(Optional) Set this to TRUE to enable SPNEGO authentication.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_cookies">cookies</code></td>
<td>
<p>(Optional) Vector(or list) of cookies to add to request.</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_context_path">context_path</code></td>
<td>
<p>(Optional) The last part of connection URL: http://&lt;ip&gt;:&lt;port&gt;/&lt;context_path&gt;</p>
</td></tr>
<tr><td><code id="h2o.connect_+3A_config">config</code></td>
<td>
<p>(Optional) A <code>list</code> describing connection parameters. Using <code>config</code> makes <code>h2o.connect</code> ignore
other parameters and collect named list members instead (see examples).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an instance of <code>H2OConnection</code> object representing a connection to the running H2O instance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
# Try to connect to a H2O instance running at http://localhost:54321/cluster_X
#h2o.connect(ip = "localhost", port = 54321, context_path = "cluster_X")
# Or
#config = list(ip = "localhost", port = 54321, context_path = "cluster_X")
#h2o.connect(config = config)

# Skip strict version check during connecting to the instance
#h2o.connect(config = c(strict_version_check = FALSE, config))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cor'>Correlation of columns.</h2><span id='topic+h2o.cor'></span><span id='topic+cor'></span>

<h3>Description</h3>

<p>Compute the correlation matrix of one or two H2OFrames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cor(x, y = NULL, na.rm = FALSE, use, method = "Pearson")

cor(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cor_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.cor_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or an H2OFrame. The default is equivalent to y = x.</p>
</td></tr>
<tr><td><code id="h2o.cor_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="h2o.cor_+3A_use">use</code></td>
<td>
<p>An optional character string indicating how to handle missing values. This must be one of the following:
&quot;everything&quot;            - outputs NaNs whenever one of its contributing observations is missing
&quot;all.obs&quot;               - presence of missing observations will throw an error
&quot;complete.obs&quot;          - discards missing values along with all observations in their rows so that only complete observations are used</p>
</td></tr>
<tr><td><code id="h2o.cor_+3A_method">method</code></td>
<td>
<p><code>str</code> Method of correlation computation. Allowed values are:
&quot;Pearson&quot; - Pearson's correlation coefficient
&quot;Spearman&quot; - Spearman's correlation coefficient (Spearman's Rho)
Defaults to &quot;Pearson&quot;</p>
</td></tr>
<tr><td><code id="h2o.cor_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed down from other methods.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
cor(prostate$AGE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cos'>Compute the cosine of x</h2><span id='topic+h2o.cos'></span>

<h3>Description</h3>

<p>Compute the cosine of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cos(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cos_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Trig">Trig</a></code> for the base R implementation, <code>cos()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cos(frame["C1"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cosh'>Compute the hyperbolic cosine of x</h2><span id='topic+h2o.cosh'></span>

<h3>Description</h3>

<p>Compute the hyperbolic cosine of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cosh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cosh_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Hyperbolic">Hyperbolic</a></code> for the base R implementation, <code>cosh()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cosh(frame["C1"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.coxph'>Trains a Cox Proportional Hazards Model (CoxPH) on an H2O dataset</h2><span id='topic+h2o.coxph'></span>

<h3>Description</h3>

<p>Trains a Cox Proportional Hazards Model (CoxPH) on an H2O dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.coxph(
  x,
  event_column,
  training_frame,
  model_id = NULL,
  start_column = NULL,
  stop_column = NULL,
  weights_column = NULL,
  offset_column = NULL,
  stratify_by = NULL,
  ties = c("efron", "breslow"),
  init = 0,
  lre_min = 9,
  max_iterations = 20,
  interactions = NULL,
  interaction_pairs = NULL,
  interactions_only = NULL,
  use_all_factor_levels = FALSE,
  export_checkpoints_dir = NULL,
  single_node_mode = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.coxph_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except event_column, start_column and stop_column are used.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_event_column">event_column</code></td>
<td>
<p>The name of binary data column in the training frame indicating the occurrence of an event.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_start_column">start_column</code></td>
<td>
<p>Start Time Column.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_stop_column">stop_column</code></td>
<td>
<p>Stop Time Column.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_stratify_by">stratify_by</code></td>
<td>
<p>List of columns to use for stratification.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_ties">ties</code></td>
<td>
<p>Method for Handling Ties. Must be one of: &quot;efron&quot;, &quot;breslow&quot;. Defaults to efron.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_init">init</code></td>
<td>
<p>Coefficient starting value. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_lre_min">lre_min</code></td>
<td>
<p>Minimum log-relative error. Defaults to 9.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations. Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_interactions">interactions</code></td>
<td>
<p>A list of predictor column indices to interact. All pairwise combinations will be computed for the list.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_interaction_pairs">interaction_pairs</code></td>
<td>
<p>A list of pairwise (first order) column interactions.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_interactions_only">interactions_only</code></td>
<td>
<p>A list of columns that should only be used to create interactions but should not itself participate in model
training.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_use_all_factor_levels">use_all_factor_levels</code></td>
<td>
<p><code>Logical</code>. (Internal. For development only!) Indicates whether to use all factor levels. Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.coxph_+3A_single_node_mode">single_node_mode</code></td>
<td>
<p><code>Logical</code>. Run on a single node to reduce the effect of network overhead (for smaller datasets) Defaults
to FALSE.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the heart dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv"
heart &lt;- h2o.importFile(f)

# Set the predictor and response
predictor &lt;- "age"
response &lt;- "event"

# Train a Cox Proportional Hazards model 
heart_coxph &lt;- h2o.coxph(x = predictor, training_frame = heart,
                         event_column = "event",
                         start_column = "start", 
                         stop_column = "stop")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.createFrame'>Data H2OFrame Creation in H2O</h2><span id='topic+h2o.createFrame'></span>

<h3>Description</h3>

<p>Creates a data frame in H2O with real-valued, categorical, integer, and binary columns specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.createFrame(
  rows = 10000,
  cols = 10,
  randomize = TRUE,
  value = 0,
  real_range = 100,
  categorical_fraction = 0.2,
  factors = 100,
  integer_fraction = 0.2,
  integer_range = 100,
  binary_fraction = 0.1,
  binary_ones_fraction = 0.02,
  time_fraction = 0,
  string_fraction = 0,
  missing_fraction = 0.01,
  response_factors = 2,
  has_response = FALSE,
  seed,
  seed_for_column_types
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.createFrame_+3A_rows">rows</code></td>
<td>
<p>The number of rows of data to generate.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_cols">cols</code></td>
<td>
<p>The number of columns of data to generate. Excludes the response column if <code>has_response = TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_randomize">randomize</code></td>
<td>
<p>A logical value indicating whether data values should be randomly generated. This must be TRUE if either <code>categorical_fraction</code> or <code>integer_fraction</code> is non-zero.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_value">value</code></td>
<td>
<p>If <code>randomize = FALSE</code>, then all real-valued entries will be set to this value.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_real_range">real_range</code></td>
<td>
<p>The range of randomly generated real values.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_categorical_fraction">categorical_fraction</code></td>
<td>
<p>The fraction of total columns that are categorical.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_factors">factors</code></td>
<td>
<p>The number of (unique) factor levels in each categorical column.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_integer_fraction">integer_fraction</code></td>
<td>
<p>The fraction of total columns that are integer-valued.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_integer_range">integer_range</code></td>
<td>
<p>The range of randomly generated integer values.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_binary_fraction">binary_fraction</code></td>
<td>
<p>The fraction of total columns that are binary-valued.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_binary_ones_fraction">binary_ones_fraction</code></td>
<td>
<p>The fraction of values in a binary column that are set to 1.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_time_fraction">time_fraction</code></td>
<td>
<p>The fraction of randomly created date/time columns.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_string_fraction">string_fraction</code></td>
<td>
<p>The fraction of randomly created string columns.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_missing_fraction">missing_fraction</code></td>
<td>
<p>The fraction of total entries in the data frame that are set to NA.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_response_factors">response_factors</code></td>
<td>
<p>If <code>has_response = TRUE</code>, then this is the number of factor levels in the response column.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_has_response">has_response</code></td>
<td>
<p>A logical value indicating whether an additional response column should be pre-pended to the final H2O data frame. If set to TRUE, the total number of columns will be <code>cols+1</code>.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_seed">seed</code></td>
<td>
<p>A seed used to generate random values when <code>randomize = TRUE</code>.</p>
</td></tr>
<tr><td><code id="h2o.createFrame_+3A_seed_for_column_types">seed_for_column_types</code></td>
<td>
<p>A seed used to generate random column types when <code>randomize = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
hf &lt;- h2o.createFrame(rows = 1000, cols = 100, categorical_fraction = 0.1,
                      factors = 5, integer_fraction = 0.5, integer_range = 1,
                      has_response = TRUE)
head(hf)
summary(hf)

hf &lt;- h2o.createFrame(rows = 100, cols = 10, randomize = FALSE, value = 5,
                      categorical_fraction = 0, integer_fraction = 0)
summary(hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cross_validation_fold_assignment'>Retrieve the cross-validation fold assignment</h2><span id='topic+h2o.cross_validation_fold_assignment'></span>

<h3>Description</h3>

<p>Retrieve the cross-validation fold assignment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cross_validation_fold_assignment(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cross_validation_fold_assignment_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a H2OFrame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, training_frame = train,
                    nfolds = 5,  keep_cross_validation_fold_assignment = TRUE, seed = 1234)
h2o.cross_validation_fold_assignment(cars_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cross_validation_holdout_predictions'>Retrieve the cross-validation holdout predictions</h2><span id='topic+h2o.cross_validation_holdout_predictions'></span>

<h3>Description</h3>

<p>Retrieve the cross-validation holdout predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cross_validation_holdout_predictions(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cross_validation_holdout_predictions_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a H2OFrame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement","power","weight","acceleration","year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars,ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, training_frame = train, 
                    nfolds = 5,  keep_cross_validation_predictions = TRUE, seed = 1234)
h2o.cross_validation_holdout_predictions(cars_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cross_validation_models'>Retrieve the cross-validation models</h2><span id='topic+h2o.cross_validation_models'></span>

<h3>Description</h3>

<p>Retrieve the cross-validation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cross_validation_models(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cross_validation_models_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of H2OModel objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, training_frame = train, 
                    nfolds = 5,  keep_cross_validation_models = TRUE, seed = 1234)
h2o.cross_validation_models(cars_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cross_validation_predictions'>Retrieve the cross-validation predictions</h2><span id='topic+h2o.cross_validation_predictions'></span>

<h3>Description</h3>

<p>Retrieve the cross-validation predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cross_validation_predictions(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cross_validation_predictions_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of H2OFrame objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, training_frame = train, 
                    nfolds = 5,  keep_cross_validation_predictions = TRUE, seed = 1234)
h2o.cross_validation_predictions(cars_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cummax'>Return the cumulative max over a column or across a row</h2><span id='topic+h2o.cummax'></span>

<h3>Description</h3>

<p>Return the cumulative max over a column or across a row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cummax(x, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cummax_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.cummax_+3A_axis">axis</code></td>
<td>
<p>An int that indicates whether to do down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cumsum">cumsum</a></code> for the base R implementation, <code>cummax()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cummax(frame, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cummin'>Return the cumulative min over a column or across a row</h2><span id='topic+h2o.cummin'></span>

<h3>Description</h3>

<p>Return the cumulative min over a column or across a row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cummin(x, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cummin_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.cummin_+3A_axis">axis</code></td>
<td>
<p>An int that indicates whether to do down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cumsum">cumsum</a></code> for the base R implementation, <code>cummin()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cummin(frame, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cumprod'>Return the cumulative product over a column or across a row</h2><span id='topic+h2o.cumprod'></span>

<h3>Description</h3>

<p>Return the cumulative product over a column or across a row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cumprod(x, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cumprod_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.cumprod_+3A_axis">axis</code></td>
<td>
<p>An int that indicates whether to do down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cumsum">cumsum</a></code> for the base R implementation, <code>cumprod()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cumprod(frame, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cumsum'>Return the cumulative sum over a column or across a row</h2><span id='topic+h2o.cumsum'></span>

<h3>Description</h3>

<p>Return the cumulative sum over a column or across a row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cumsum(x, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cumsum_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.cumsum_+3A_axis">axis</code></td>
<td>
<p>An int that indicates whether to do down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cumsum">cumsum</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.cumsum(frame, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.cut'>Cut H2O Numeric Data to Factor</h2><span id='topic+h2o.cut'></span><span id='topic+cut.H2OFrame'></span>

<h3>Description</h3>

<p>Divides the range of the H2O data into intervals and codes the values according to which interval they fall in. The
leftmost interval corresponds to the level one, the next is level two, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.cut(
  x,
  breaks,
  labels = NULL,
  include.lowest = FALSE,
  right = TRUE,
  dig.lab = 3,
  ...
)

## S3 method for class 'H2OFrame'
cut(
  x,
  breaks,
  labels = NULL,
  include.lowest = FALSE,
  right = TRUE,
  dig.lab = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.cut_+3A_x">x</code></td>
<td>
<p>An H2OFrame object with a single numeric column.</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_breaks">breaks</code></td>
<td>
<p>A numeric vector of two or more unique cut points.</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_labels">labels</code></td>
<td>
<p>Labels for the levels of the resulting category. By default, labels are constructed sing &quot;(a,b]&quot;
interval notation.</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_include.lowest">include.lowest</code></td>
<td>
<p><code>Logical</code>, indicationg if an 'x[i]' equal to the lowest (or highest, for <code>right =
FALSE</code> 'breaks' value should be included</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_right">right</code></td>
<td>
<p><code>Logical</code>, indicating if the intervals should be closed on the right (opened on the left) or vice
versa.</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_dig.lab">dig.lab</code></td>
<td>
<p>Integer which is used when labels are not given, determines the number of digits used in formatting
the break numbers.</p>
</td></tr>
<tr><td><code id="h2o.cut_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the factored data with intervals as levels.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
summary(iris_hf)

# Cut sepal length column into intervals determined by min/max/quantiles
sepal_len_cut &lt;- cut(iris_hf$Sepal.Length, c(4.2, 4.8, 5.8, 6, 8))
head(sepal_len_cut)
summary(sepal_len_cut)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.day'>Convert Milliseconds to Day of Month in H2O Datasets</h2><span id='topic+h2o.day'></span><span id='topic+day'></span><span id='topic+day.H2OFrame'></span>

<h3>Description</h3>

<p>Converts the entries of an H2OFrame object from milliseconds to days of the month
(on a 1 to 31 scale).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.day(x)

day(x)

## S3 method for class 'H2OFrame'
day(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.day_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to days of
the month.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.month">h2o.month</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.day(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.dayOfWeek'>Convert Milliseconds to Day of Week in H2O Datasets</h2><span id='topic+h2o.dayOfWeek'></span><span id='topic+dayOfWeek'></span><span id='topic+dayOfWeek.H2OFrame'></span>

<h3>Description</h3>

<p>Converts the entries of an H2OFrame object from milliseconds to days of the week
(on a 0 to 6 scale).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.dayOfWeek(x)

dayOfWeek(x)

## S3 method for class 'H2OFrame'
dayOfWeek(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.dayOfWeek_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to days of
the week.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.day">h2o.day</a>, <a href="#topic+h2o.month">h2o.month</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.dayOfWeek(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.dct'>Compute DCT of an H2OFrame</h2><span id='topic+h2o.dct'></span>

<h3>Description</h3>

<p>Compute the Discrete Cosine Transform of every row in the H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.dct(data, destination_frame, dimensions, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.dct_+3A_data">data</code></td>
<td>
<p>An H2OFrame object representing the dataset to transform</p>
</td></tr>
<tr><td><code id="h2o.dct_+3A_destination_frame">destination_frame</code></td>
<td>
<p>A frame ID for the result</p>
</td></tr>
<tr><td><code id="h2o.dct_+3A_dimensions">dimensions</code></td>
<td>
<p>An array containing the 3 integer values for height, width, depth of each sample.
The product of HxWxD must total up to less than the number of columns.
For 1D, use c(L,1,1), for 2D, use C(N,M,1).</p>
</td></tr>
<tr><td><code id="h2o.dct_+3A_inverse">inverse</code></td>
<td>
<p>Whether to perform the inverse transform</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(h2o)
  h2o.init()
  df &lt;- h2o.createFrame(rows = 1000, cols = 8 * 16 * 24,
                        categorical_fraction = 0, integer_fraction = 0, missing_fraction = 0)
  df1 &lt;- h2o.dct(data = df, dimensions = c(8 * 16 * 24, 1, 1))
  df2 &lt;- h2o.dct(data = df1, dimensions = c(8 * 16 * 24, 1, 1), inverse = TRUE)
  max(abs(df1 - df2))

  df1 &lt;- h2o.dct(data = df, dimensions = c(8 * 16, 24, 1))
  df2 &lt;- h2o.dct(data = df1, dimensions = c(8 * 16, 24, 1), inverse = TRUE)
  max(abs(df1 - df2))

  df1 &lt;- h2o.dct(data = df, dimensions = c(8, 16, 24))
  df2 &lt;- h2o.dct(data = df1, dimensions = c(8, 16, 24), inverse = TRUE)
  max(abs(df1 - df2))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ddply'>Split H2O Dataset, Apply Function, and Return Results</h2><span id='topic+h2o.ddply'></span>

<h3>Description</h3>

<p>For each subset of an H2O data set, apply a user-specified function, then combine the results.  
This is an experimental feature based on plyr::ddply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ddply(X, .variables, FUN, ..., .progress = "none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ddply_+3A_x">X</code></td>
<td>
<p>An H2OFrame object to be processed.</p>
</td></tr>
<tr><td><code id="h2o.ddply_+3A_.variables">.variables</code></td>
<td>
<p>Variables to split <code>X</code> by, either the indices or names of a set of columns.</p>
</td></tr>
<tr><td><code id="h2o.ddply_+3A_fun">FUN</code></td>
<td>
<p>Function to apply to each subset grouping.</p>
</td></tr>
<tr><td><code id="h2o.ddply_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="h2o.ddply_+3A_.progress">.progress</code></td>
<td>
<p>Name of the progress bar to use. #TODO: (Currently unimplemented)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the results from the split/apply operation, arranged
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import iris dataset to H2O
iris_hf &lt;- as.h2o(iris)
# Add function taking mean of Sepal.Length column
fun &lt;- function(df) { sum(df[, 1], na.rm = TRUE) / nrow(df) }
# Apply function to groups by flower specie
# uses h2o's ddply, since iris_hf is an H2OFrame object
res &lt;- h2o.ddply(iris_hf, "Species", fun)
head(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.decision_tree'>Build a Decision Tree model</h2><span id='topic+h2o.decision_tree'></span>

<h3>Description</h3>

<p>Builds a Decision Tree model on an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.decision_tree(
  x,
  y,
  training_frame,
  model_id = NULL,
  ignore_const_cols = TRUE,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  seed = -1,
  max_depth = 20,
  min_rows = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.decision_tree_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_max_depth">max_depth</code></td>
<td>
<p>Max depth of tree. Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.decision_tree_+3A_min_rows">min_rows</code></td>
<td>
<p>Fewest allowed (weighted) observations in a leaf. Defaults to 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a <a href="#topic+H2OModel-class">H2OModel</a> object of the right type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the airlines dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv"
data &lt;- h2o.importFile(f)

# Set predictors and response; set response as a factor
data["CAPSULE"] &lt;- as.factor(data["CAPSULE"])
predictors &lt;- c("AGE","RACE","DPROS","DCAPS","PSA","VOL","GLEASON")
response &lt;- "CAPSULE"

# Train the DT model
h2o_dt &lt;- h2o.decision_tree(x = predictors, y = response, training_frame = data, seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.decryptionSetup'>Setup a Decryption Tool</h2><span id='topic+h2o.decryptionSetup'></span>

<h3>Description</h3>

<p>If your source file is encrypted - setup a Decryption Tool and then provide
the reference (result of this function) to the import functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.decryptionSetup(
  keystore,
  keystore_type = "JCEKS",
  key_alias = NA_character_,
  password = NA_character_,
  decrypt_tool = "",
  decrypt_impl = "water.parser.GenericDecryptionTool",
  cipher_spec = NA_character_
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.decryptionSetup_+3A_keystore">keystore</code></td>
<td>
<p>An H2OFrame object referencing a loaded Java Keystore (see example).</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_keystore_type">keystore_type</code></td>
<td>
<p>(Optional) Specification of Keystore type, defaults to JCEKS.</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_key_alias">key_alias</code></td>
<td>
<p>Which key from the keystore to use for decryption.</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_password">password</code></td>
<td>
<p>Password to the keystore and the key.</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_decrypt_tool">decrypt_tool</code></td>
<td>
<p>(Optional) Name of the decryption tool.</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_decrypt_impl">decrypt_impl</code></td>
<td>
<p>(Optional) Java class name implementing the Decryption Tool.</p>
</td></tr>
<tr><td><code id="h2o.decryptionSetup_+3A_cipher_spec">cipher_spec</code></td>
<td>
<p>Specification of a cipher (eg.: AES/ECB/PKCS5Padding).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+h2o.importFile">h2o.importFile</a>, <a href="#topic+h2o.parseSetup">h2o.parseSetup</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
ks_path &lt;- system.file("extdata", "keystore.jks", package = "h2o")
keystore &lt;- h2o.importFile(path = ks_path, parse = FALSE) # don't parse, keep as a binary file
cipher &lt;- "AES/ECB/PKCS5Padding"
pwd &lt;- "Password123"
alias &lt;- "secretKeyAlias"
dt &lt;- h2o.decryptionSetup(keystore, key_alias = alias, password = pwd, cipher_spec = cipher)
data_path &lt;- system.file("extdata", "prostate.csv.aes", package = "h2o")
data &lt;- h2o.importFile(data_path, decrypt_tool = dt)
summary(data)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.deepfeatures'>Feature Generation via H2O Deep Learning</h2><span id='topic+h2o.deepfeatures'></span>

<h3>Description</h3>

<p>Extract the non-linear feature from an H2O data set using an H2O deep learning
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.deepfeatures(object, data, layer)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.deepfeatures_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object that represents the deep
learning model to be used for feature extraction.</p>
</td></tr>
<tr><td><code id="h2o.deepfeatures_+3A_data">data</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.deepfeatures_+3A_layer">layer</code></td>
<td>
<p>Index (integer) of the hidden layer to extract</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with as many features as the
number of units in the hidden layer of the specified index.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.deeplearning">h2o.deeplearning</a></code> for making H2O Deep Learning models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
prostate_dl = h2o.deeplearning(x = 3:9, y = 2, training_frame = prostate,
                               hidden = c(100, 200), epochs = 5)
prostate_deepfeatures_layer1 = h2o.deepfeatures(prostate_dl, prostate, layer = 1)
prostate_deepfeatures_layer2 = h2o.deepfeatures(prostate_dl, prostate, layer = 2)
head(prostate_deepfeatures_layer1)
head(prostate_deepfeatures_layer2)


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.deeplearning'>Build a Deep Neural Network model using CPUs</h2><span id='topic+h2o.deeplearning'></span>

<h3>Description</h3>

<p>Builds a feed-forward multilayer artificial neural network on an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.deeplearning(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  weights_column = NULL,
  offset_column = NULL,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  checkpoint = NULL,
  pretrained_autoencoder = NULL,
  overwrite_with_best_model = TRUE,
  use_all_factor_levels = TRUE,
  standardize = TRUE,
  activation = c("Tanh", "TanhWithDropout", "Rectifier", "RectifierWithDropout",
    "Maxout", "MaxoutWithDropout"),
  hidden = c(200, 200),
  epochs = 10,
  train_samples_per_iteration = -2,
  target_ratio_comm_to_comp = 0.05,
  seed = -1,
  adaptive_rate = TRUE,
  rho = 0.99,
  epsilon = 1e-08,
  rate = 0.005,
  rate_annealing = 1e-06,
  rate_decay = 1,
  momentum_start = 0,
  momentum_ramp = 1e+06,
  momentum_stable = 0,
  nesterov_accelerated_gradient = TRUE,
  input_dropout_ratio = 0,
  hidden_dropout_ratios = NULL,
  l1 = 0,
  l2 = 0,
  max_w2 = 3.4028235e+38,
  initial_weight_distribution = c("UniformAdaptive", "Uniform", "Normal"),
  initial_weight_scale = 1,
  initial_weights = NULL,
  initial_biases = NULL,
  loss = c("Automatic", "CrossEntropy", "Quadratic", "Huber", "Absolute", "Quantile"),
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  quantile_alpha = 0.5,
  tweedie_power = 1.5,
  huber_alpha = 0.9,
  score_interval = 5,
  score_training_samples = 10000,
  score_validation_samples = 0,
  score_duty_cycle = 0.1,
  classification_stop = 0,
  regression_stop = 1e-06,
  stopping_rounds = 5,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0,
  max_runtime_secs = 0,
  score_validation_sampling = c("Uniform", "Stratified"),
  diagnostics = TRUE,
  fast_mode = TRUE,
  force_load_balance = TRUE,
  variable_importances = TRUE,
  replicate_training_data = TRUE,
  single_node_mode = FALSE,
  shuffle_training_data = FALSE,
  missing_values_handling = c("MeanImputation", "Skip"),
  quiet_mode = FALSE,
  autoencoder = FALSE,
  sparse = FALSE,
  col_major = FALSE,
  average_activation = 0,
  sparsity_beta = 0,
  max_categorical_features = 2147483647,
  reproducible = FALSE,
  export_weights_and_biases = FALSE,
  mini_batch_size = 1,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  elastic_averaging = FALSE,
  elastic_averaging_moving_rate = 0.9,
  elastic_averaging_regularization = 0.001,
  export_checkpoints_dir = NULL,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  custom_metric_func = NULL,
  gainslift_bins = -1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.deeplearning_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Model checkpoint to resume training with.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_pretrained_autoencoder">pretrained_autoencoder</code></td>
<td>
<p>Pretrained autoencoder model to initialize this model with.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_overwrite_with_best_model">overwrite_with_best_model</code></td>
<td>
<p><code>Logical</code>. If enabled, override the final model with the best model found during training. Defaults to
TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_use_all_factor_levels">use_all_factor_levels</code></td>
<td>
<p><code>Logical</code>. Use all factor levels of categorical variables. Otherwise, the first factor level is omitted
(without loss of accuracy). Useful for variable importances and auto-enabled for autoencoder. Defaults to
TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. If enabled, automatically standardize the data. If disabled, the user must provide properly
scaled input data. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_activation">activation</code></td>
<td>
<p>Activation function. Must be one of: &quot;Tanh&quot;, &quot;TanhWithDropout&quot;, &quot;Rectifier&quot;, &quot;RectifierWithDropout&quot;, &quot;Maxout&quot;,
&quot;MaxoutWithDropout&quot;. Defaults to Rectifier.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_hidden">hidden</code></td>
<td>
<p>Hidden layer sizes (e.g. [100, 100]). Defaults to c(200, 200).</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_epochs">epochs</code></td>
<td>
<p>How many times the dataset should be iterated (streamed), can be fractional. Defaults to 10.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_train_samples_per_iteration">train_samples_per_iteration</code></td>
<td>
<p>Number of training samples (globally) per MapReduce iteration. Special values are 0: one epoch, -1: all
available data (e.g., replicated training data), -2: automatic. Defaults to -2.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_target_ratio_comm_to_comp">target_ratio_comm_to_comp</code></td>
<td>
<p>Target ratio of communication overhead to computation. Only for multi-node operation and
train_samples_per_iteration = -2 (auto-tuning). Defaults to 0.05.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Note: only reproducible when running single threaded.
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_adaptive_rate">adaptive_rate</code></td>
<td>
<p><code>Logical</code>. Adaptive learning rate. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_rho">rho</code></td>
<td>
<p>Adaptive learning rate time decay factor (similarity to prior updates). Defaults to 0.99.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_epsilon">epsilon</code></td>
<td>
<p>Adaptive learning rate smoothing factor (to avoid divisions by zero and allow progress). Defaults to 1e-08.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_rate">rate</code></td>
<td>
<p>Learning rate (higher =&gt; less stable, lower =&gt; slower convergence). Defaults to 0.005.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_rate_annealing">rate_annealing</code></td>
<td>
<p>Learning rate annealing: rate / (1 + rate_annealing * samples). Defaults to 1e-06.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_rate_decay">rate_decay</code></td>
<td>
<p>Learning rate decay factor between layers (N-th layer: rate * rate_decay ^ (n - 1). Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_momentum_start">momentum_start</code></td>
<td>
<p>Initial momentum at the beginning of training (try 0.5). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_momentum_ramp">momentum_ramp</code></td>
<td>
<p>Number of training samples for which momentum increases. Defaults to 1000000.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_momentum_stable">momentum_stable</code></td>
<td>
<p>Final momentum after the ramp is over (try 0.99). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_nesterov_accelerated_gradient">nesterov_accelerated_gradient</code></td>
<td>
<p><code>Logical</code>. Use Nesterov accelerated gradient (recommended). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_input_dropout_ratio">input_dropout_ratio</code></td>
<td>
<p>Input layer dropout ratio (can improve generalization, try 0.1 or 0.2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_hidden_dropout_ratios">hidden_dropout_ratios</code></td>
<td>
<p>Hidden layer dropout ratios (can improve generalization), specify one value per hidden layer, defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_l1">l1</code></td>
<td>
<p>L1 regularization (can add stability and improve generalization, causes many weights to become 0). Defaults to
0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_l2">l2</code></td>
<td>
<p>L2 regularization (can add stability and improve generalization, causes many weights to be small. Defaults to
0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_max_w2">max_w2</code></td>
<td>
<p>Constraint for squared sum of incoming weights per unit (e.g. for Rectifier). Defaults to 3.4028235e+38.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_initial_weight_distribution">initial_weight_distribution</code></td>
<td>
<p>Initial weight distribution. Must be one of: &quot;UniformAdaptive&quot;, &quot;Uniform&quot;, &quot;Normal&quot;. Defaults to
UniformAdaptive.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_initial_weight_scale">initial_weight_scale</code></td>
<td>
<p>Uniform: -value...value, Normal: stddev. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_initial_weights">initial_weights</code></td>
<td>
<p>A list of H2OFrame ids to initialize the weight matrices of this model with.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_initial_biases">initial_biases</code></td>
<td>
<p>A list of H2OFrame ids to initialize the bias vectors of this model with.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_loss">loss</code></td>
<td>
<p>Loss function. Must be one of: &quot;Automatic&quot;, &quot;CrossEntropy&quot;, &quot;Quadratic&quot;, &quot;Huber&quot;, &quot;Absolute&quot;, &quot;Quantile&quot;.
Defaults to Automatic.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_quantile_alpha">quantile_alpha</code></td>
<td>
<p>Desired quantile for Quantile regression, must be between 0 and 1. Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_tweedie_power">tweedie_power</code></td>
<td>
<p>Tweedie power for Tweedie regression, must be between 1 and 2. Defaults to 1.5.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_huber_alpha">huber_alpha</code></td>
<td>
<p>Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and
1). Defaults to 0.9.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_interval">score_interval</code></td>
<td>
<p>Shortest time interval (in seconds) between model scoring. Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_training_samples">score_training_samples</code></td>
<td>
<p>Number of training set samples for scoring (0 for all). Defaults to 10000.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_validation_samples">score_validation_samples</code></td>
<td>
<p>Number of validation set samples for scoring (0 for all). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_duty_cycle">score_duty_cycle</code></td>
<td>
<p>Maximum duty cycle fraction for scoring (lower: more training, higher: more scoring). Defaults to 0.1.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_classification_stop">classification_stop</code></td>
<td>
<p>Stopping criterion for classification error fraction on training data (-1 to disable). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_regression_stop">regression_stop</code></td>
<td>
<p>Stopping criterion for regression error (MSE) on training data (-1 to disable). Defaults to 1e-06.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_score_validation_sampling">score_validation_sampling</code></td>
<td>
<p>Method used to sample validation dataset for scoring. Must be one of: &quot;Uniform&quot;, &quot;Stratified&quot;. Defaults to
Uniform.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_diagnostics">diagnostics</code></td>
<td>
<p><code>Logical</code>. Enable diagnostics for hidden layers. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_fast_mode">fast_mode</code></td>
<td>
<p><code>Logical</code>. Enable fast mode (minor approximation in back-propagation). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_force_load_balance">force_load_balance</code></td>
<td>
<p><code>Logical</code>. Force extra load balancing to increase training speed for small datasets (to keep all cores
busy). Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_variable_importances">variable_importances</code></td>
<td>
<p><code>Logical</code>. Compute variable importances for input features (Gedeon method) - can be slow for large
networks. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_replicate_training_data">replicate_training_data</code></td>
<td>
<p><code>Logical</code>. Replicate the entire training dataset onto every node for faster training on small datasets.
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_single_node_mode">single_node_mode</code></td>
<td>
<p><code>Logical</code>. Run on a single node for fine-tuning of model parameters. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_shuffle_training_data">shuffle_training_data</code></td>
<td>
<p><code>Logical</code>. Enable shuffling of training data (recommended if training data is replicated and
train_samples_per_iteration is close to #nodes x #rows, of if using balance_classes). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_missing_values_handling">missing_values_handling</code></td>
<td>
<p>Handling of missing values. Either MeanImputation or Skip. Must be one of: &quot;MeanImputation&quot;, &quot;Skip&quot;. Defaults
to MeanImputation.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_quiet_mode">quiet_mode</code></td>
<td>
<p><code>Logical</code>. Enable quiet mode for less output to standard output. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_autoencoder">autoencoder</code></td>
<td>
<p><code>Logical</code>. Auto-Encoder. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_sparse">sparse</code></td>
<td>
<p><code>Logical</code>. Sparse data handling (more efficient for data with lots of 0 values). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_col_major">col_major</code></td>
<td>
<p><code>Logical</code>. #DEPRECATED Use a column major weight matrix for input layer. Can speed up forward
propagation, but might slow down backpropagation. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_average_activation">average_activation</code></td>
<td>
<p>Average activation for sparse auto-encoder. #Experimental Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_sparsity_beta">sparsity_beta</code></td>
<td>
<p>Sparsity regularization. #Experimental Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_max_categorical_features">max_categorical_features</code></td>
<td>
<p>Max. number of categorical features, enforced via hashing. #Experimental Defaults to 2147483647.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_reproducible">reproducible</code></td>
<td>
<p><code>Logical</code>. Force reproducibility on small data (will be slow - only uses 1 thread). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_export_weights_and_biases">export_weights_and_biases</code></td>
<td>
<p><code>Logical</code>. Whether to export Neural Network weights and biases to H2O Frames. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_mini_batch_size">mini_batch_size</code></td>
<td>
<p>Mini-batch size (smaller leads to better fit, larger can speed up and generalize better). Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_elastic_averaging">elastic_averaging</code></td>
<td>
<p><code>Logical</code>. Elastic averaging between compute nodes can improve distributed model convergence.
#Experimental Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_elastic_averaging_moving_rate">elastic_averaging_moving_rate</code></td>
<td>
<p>Elastic averaging moving rate (only if elastic averaging is enabled). Defaults to 0.9.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_elastic_averaging_regularization">elastic_averaging_regularization</code></td>
<td>
<p>Elastic averaging regularization strength (only if elastic averaging is enabled). Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.deeplearning_+3A_verbose">verbose</code></td>
<td>
<p><code>Logical</code>. Print scoring history to the console (Metrics per epoch). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
iris_dl &lt;- h2o.deeplearning(x = 1:4, y = 5, training_frame = iris_hf, seed=123456)

# now make a prediction
predictions &lt;- h2o.predict(iris_dl, iris_hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.describe'>H2O Description of A Dataset</h2><span id='topic+h2o.describe'></span>

<h3>Description</h3>

<p>Reports the &quot;Flow&quot; style summary rollups on an instance of H2OFrame. Includes
information about column types, mins/maxs/missing/zero counts/stds/number of levels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.describe(frame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.describe_+3A_frame">frame</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with the Frame stats.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path)
h2o.describe(prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.difflag1'>Conduct a lag 1 transform on a numeric H2OFrame column</h2><span id='topic+h2o.difflag1'></span>

<h3>Description</h3>

<p>Conduct a lag 1 transform on a numeric H2OFrame column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.difflag1(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.difflag1_+3A_object">object</code></td>
<td>
<p>H2OFrame object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "cylinders"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, training_frame = train, 
                    validation_frame = valid, nfolds = 5, seed = 1234)
h2o.difflag1(cars["cylinders"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.dim'>Returns the number of rows and columns for an H2OFrame object.</h2><span id='topic+h2o.dim'></span>

<h3>Description</h3>

<p>Returns the number of rows and columns for an H2OFrame object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.dim_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+dim">dim</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.dim(cars)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.dimnames'>Column names of an H2OFrame</h2><span id='topic+h2o.dimnames'></span>

<h3>Description</h3>

<p>Column names of an H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.dimnames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.dimnames_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+dimnames">dimnames</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.dimnames(cars)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.disparate_analysis'>Create a frame containing aggregations of intersectional fairness across the models.</h2><span id='topic+h2o.disparate_analysis'></span>

<h3>Description</h3>

<p>Create a frame containing aggregations of intersectional fairness across the models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.disparate_analysis(
  models,
  newdata,
  protected_columns,
  reference,
  favorable_class,
  air_metric = "selectedRatio",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.disparate_analysis_+3A_models">models</code></td>
<td>
<p>List of H2O Models</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_air_metric">air_metric</code></td>
<td>
<p>Metric used for Adverse Impact Ratio calculation. Defaults to &ldquo;selectedRatio&ldquo;.</p>
</td></tr>
<tr><td><code id="h2o.disparate_analysis_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level is the probability of rejecting the null hypothesis that the protected group
and the reference came from the same population when the null hypothesis is true.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>frame containing aggregations of intersectional fairness across the models
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

aml &lt;- h2o.automl(x, y, training_frame = train, max_models = 3)

h2o.disparate_analysis(aml, test, protected_columns = protected_columns,
                       reference = reference, favorable_class = favorable_class)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.distance'>Compute a pairwise distance measure between all rows of two numeric H2OFrames.</h2><span id='topic+h2o.distance'></span>

<h3>Description</h3>

<p>Compute a pairwise distance measure between all rows of two numeric H2OFrames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.distance(x, y, measure)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.distance_+3A_x">x</code></td>
<td>
<p>An H2OFrame object (large, references).</p>
</td></tr>
<tr><td><code id="h2o.distance_+3A_y">y</code></td>
<td>
<p>An H2OFrame object (small, queries).</p>
</td></tr>
<tr><td><code id="h2o.distance_+3A_measure">measure</code></td>
<td>
<p>An optional string indicating what distance measure to use. Must be one of:
&quot;l1&quot;                   - Absolute distance (L1-norm, &gt;=0)
&quot;l2&quot;                   - Euclidean distance (L2-norm, &gt;=0)
&quot;cosine&quot;               - Cosine similarity (-1...1)
&quot;cosine_sq&quot;            - Squared Cosine similarity (0...1)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.distance(prostate[11:30, ], prostate[1:10, ], "cosine")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.download_model'>Download the model in binary format.
The owner of the file saved is the user by which python session was executed.</h2><span id='topic+h2o.download_model'></span>

<h3>Description</h3>

<p>Download the model in binary format.
The owner of the file saved is the user by which python session was executed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.download_model(
  model,
  path = NULL,
  export_cross_validation_predictions = FALSE,
  filename = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.download_model_+3A_model">model</code></td>
<td>
<p>An H2OModel</p>
</td></tr>
<tr><td><code id="h2o.download_model_+3A_path">path</code></td>
<td>
<p>The path where binary file should be downloaded. Downloaded to current directory by default.</p>
</td></tr>
<tr><td><code id="h2o.download_model_+3A_export_cross_validation_predictions">export_cross_validation_predictions</code></td>
<td>
<p>A boolean flag indicating whether the download model should be
saved with CV Holdout Frame predictions. Default is not to export the predictions.</p>
</td></tr>
<tr><td><code id="h2o.download_model_+3A_filename">filename</code></td>
<td>
<p>string indicating the file name.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h &lt;- h2o.init()
fr &lt;- as.h2o(iris)
my_model &lt;- h2o.gbm(x = 1:4, y = 5, training_frame = fr)
h2o.download_model(my_model)  # save to the current working directory

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.download_mojo'>Download the model in MOJO format.</h2><span id='topic+h2o.download_mojo'></span>

<h3>Description</h3>

<p>Download the model in MOJO format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.download_mojo(
  model,
  path = getwd(),
  get_genmodel_jar = FALSE,
  genmodel_name = "",
  genmodel_path = "",
  filename = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.download_mojo_+3A_model">model</code></td>
<td>
<p>An H2OModel</p>
</td></tr>
<tr><td><code id="h2o.download_mojo_+3A_path">path</code></td>
<td>
<p>The path where MOJO file should be saved. Saved to current directory by default.</p>
</td></tr>
<tr><td><code id="h2o.download_mojo_+3A_get_genmodel_jar">get_genmodel_jar</code></td>
<td>
<p>If TRUE, then also download h2o-genmodel.jar and store it in either in the same folder
as the MOJO or in &ldquo;genmodel_path&ldquo; if specified.</p>
</td></tr>
<tr><td><code id="h2o.download_mojo_+3A_genmodel_name">genmodel_name</code></td>
<td>
<p>Custom name of genmodel jar.</p>
</td></tr>
<tr><td><code id="h2o.download_mojo_+3A_genmodel_path">genmodel_path</code></td>
<td>
<p>Path to store h2o-genmodel.jar. If left blank and &ldquo;get_genmodel_jar&ldquo; is TRUE, then the h2o-genmodel.jar
is saved to &ldquo;path&ldquo;.</p>
</td></tr>
<tr><td><code id="h2o.download_mojo_+3A_filename">filename</code></td>
<td>
<p>string indicating the file name. (Type of file is always .zip)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Name of the MOJO file written to the path.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h &lt;- h2o.init()
fr &lt;- as.h2o(iris)
my_model &lt;- h2o.gbm(x = 1:4, y = 5, training_frame = fr)
h2o.download_mojo(my_model)  # save to the current working directory

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.download_pojo'>Download the Scoring POJO (Plain Old Java Object) of an H2O Model</h2><span id='topic+h2o.download_pojo'></span>

<h3>Description</h3>

<p>Download the Scoring POJO (Plain Old Java Object) of an H2O Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.download_pojo(
  model,
  path = NULL,
  getjar = NULL,
  get_jar = TRUE,
  jar_name = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.download_pojo_+3A_model">model</code></td>
<td>
<p>An H2OModel</p>
</td></tr>
<tr><td><code id="h2o.download_pojo_+3A_path">path</code></td>
<td>
<p>The path to the directory to store the POJO (no trailing slash). If NULL, then print to
to console. The file name will be a compilable java file name.</p>
</td></tr>
<tr><td><code id="h2o.download_pojo_+3A_getjar">getjar</code></td>
<td>
<p>(DEPRECATED) Whether to also download the h2o-genmodel.jar file needed to compile the POJO. This argument is now called 'get_jar'.</p>
</td></tr>
<tr><td><code id="h2o.download_pojo_+3A_get_jar">get_jar</code></td>
<td>
<p>Whether to also download the h2o-genmodel.jar file needed to compile the POJO</p>
</td></tr>
<tr><td><code id="h2o.download_pojo_+3A_jar_name">jar_name</code></td>
<td>
<p>Custom name of genmodel jar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If path is NULL, then pretty print the POJO to the console.
Otherwise save it to the specified directory and return POJO file name.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h &lt;- h2o.init()
fr &lt;- as.h2o(iris)
my_model &lt;- h2o.gbm(x = 1:4, y = 5, training_frame = fr)

h2o.download_pojo(my_model)  # print the model to screen
# h2o.download_pojo(my_model, getwd())  # save the POJO and jar file to the current working
#                                         directory, NOT RUN
# h2o.download_pojo(my_model, getwd(), get_jar = FALSE )  # save only the POJO to the current
#                                                           working directory, NOT RUN
h2o.download_pojo(my_model, getwd())  # save to the current working directory

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.downloadAllLogs'>Download H2O Log Files to Disk</h2><span id='topic+h2o.downloadAllLogs'></span>

<h3>Description</h3>

<p><code>h2o.downloadAllLogs</code> downloads all H2O log files to local disk in .zip format. Generally used for debugging purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.downloadAllLogs(dirname = ".", filename = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.downloadAllLogs_+3A_dirname">dirname</code></td>
<td>
<p>(Optional) A character string indicating the directory that the log file should be saved in.</p>
</td></tr>
<tr><td><code id="h2o.downloadAllLogs_+3A_filename">filename</code></td>
<td>
<p>(Optional) A character string indicating the name that the log file should be saved to. Note that the saved format is .zip, so the file name must include the .zip extension.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.downloadAllLogs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.downloadCSV'>Download H2O Data to Disk</h2><span id='topic+h2o.downloadCSV'></span>

<h3>Description</h3>

<p>Download an H2O data set to a CSV file on the local disk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.downloadCSV(data, filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.downloadCSV_+3A_data">data</code></td>
<td>
<p>an H2OFrame object to be downloaded.</p>
</td></tr>
<tr><td><code id="h2o.downloadCSV_+3A_filename">filename</code></td>
<td>
<p>A string indicating the name that the CSV file should be
should be saved to.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Files located on the H2O server may be very large! Make
sure you have enough hard drive space to accomodate the entire file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)

file_path &lt;- paste(getwd(), "my_iris_file.csv", sep = .Platform$file.sep)
h2o.downloadCSV(iris_hf, file_path)
file.info(file_path)
file.remove(file_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.drop_duplicates'>Drops duplicated rows.</h2><span id='topic+h2o.drop_duplicates'></span>

<h3>Description</h3>

<p>Drops duplicated rows across specified columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.drop_duplicates(frame, columns, keep = "first")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.drop_duplicates_+3A_frame">frame</code></td>
<td>
<p>An H2OFrame object to drop duplicates on.</p>
</td></tr>
<tr><td><code id="h2o.drop_duplicates_+3A_columns">columns</code></td>
<td>
<p>Columns to compare during the duplicate detection process.</p>
</td></tr>
<tr><td><code id="h2o.drop_duplicates_+3A_keep">keep</code></td>
<td>
<p>Which rows to keep. The &quot;first&quot; value (default) keeps the first row and deletes the rest. 
The &quot;last&quot; keeps the last row.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

data &lt;- as.h2o(iris)
deduplicated_data &lt;- h2o.drop_duplicates(data, c("Species", "Sepal.Length"), keep = "first")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.entropy'>Shannon entropy</h2><span id='topic+h2o.entropy'></span>

<h3>Description</h3>

<p>Return the Shannon entropy of a string column. If the string is empty, the entropy is 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.entropy(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.entropy_+3A_x">x</code></td>
<td>
<p>The column on which to calculate the entropy.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
buys &lt;- as.h2o(c("no", "no", "yes", "yes", "yes", "no", "yes", "no", "yes", "yes","no"))
buys_entropy &lt;- h2o.entropy(buys)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.exp'>Compute the exponential function of x</h2><span id='topic+h2o.exp'></span>

<h3>Description</h3>

<p>Compute the exponential function of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.exp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.exp_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Log">Log</a></code> for the base R implementation, <code>exp()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.exp(frame["C1"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.explain'>Generate Model Explanations</h2><span id='topic+h2o.explain'></span>

<h3>Description</h3>

<p>The H2O Explainability Interface is a convenient wrapper to a number of explainabilty
methods and visualizations in H2O.  The function can be applied to a single model or group
of models and returns a list of explanations, which are individual units of explanation
such as a partial dependence plot or a variable importance plot.  Most of the explanations
are visual (ggplot plots).  These plots can also be created by individual utility functions
as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.explain(
  object,
  newdata,
  columns = NULL,
  top_n_features = 5,
  include_explanations = "ALL",
  exclude_explanations = NULL,
  plot_overrides = NULL,
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.explain_+3A_object">object</code></td>
<td>
<p>A list of H2O models, an H2O AutoML instance, or an H2OFrame with a 'model_id' column (e.g. H2OAutoML leaderboard).</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_columns">columns</code></td>
<td>
<p>A vector of column names or column indices to create plots with. If specified
parameter top_n_features will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_top_n_features">top_n_features</code></td>
<td>
<p>An integer specifying the number of columns to use, ranked by variable importance
(where applicable).</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_include_explanations">include_explanations</code></td>
<td>
<p>If specified, return only the specified model explanations.
(Mutually exclusive with exclude_explanations)</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_exclude_explanations">exclude_explanations</code></td>
<td>
<p>Exclude specified model explanations.</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_plot_overrides">plot_overrides</code></td>
<td>
<p>Overrides for individual model explanations, e.g.
<code>list(shap_summary_plot = list(columns = 50))</code>.</p>
</td></tr>
<tr><td><code id="h2o.explain_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.
Setting it enables calculating SHAP in more models but it can be more time and memory consuming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of outputs with class &quot;H2OExplanation&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the explanation for whole H2OAutoML object
exa &lt;- h2o.explain(aml, test)
print(exa)

# Create the explanation for the leader model
exm &lt;- h2o.explain(aml@leader, test)
print(exm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.explain_row'>Generate Model Explanations for a single row</h2><span id='topic+h2o.explain_row'></span>

<h3>Description</h3>

<p>Explain the behavior of a model or group of models with respect to a single row of data.
The function returns a list of explanations, which are individual units of explanation
such as a partial dependence plot or a variable importance plot.  Most of the explanations
are visual (ggplot plots).  These plots can also be created by individual utility functions
as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.explain_row(
  object,
  newdata,
  row_index,
  columns = NULL,
  top_n_features = 5,
  include_explanations = "ALL",
  exclude_explanations = NULL,
  plot_overrides = NULL,
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.explain_row_+3A_object">object</code></td>
<td>
<p>A list of H2O models, an H2O AutoML instance, or an H2OFrame with a 'model_id' column (e.g. H2OAutoML leaderboard).</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_row_index">row_index</code></td>
<td>
<p>A row index of the instance to explain.</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_columns">columns</code></td>
<td>
<p>A vector of column names or column indices to create plots with. If specified
parameter top_n_features will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_top_n_features">top_n_features</code></td>
<td>
<p>An integer specifying the number of columns to use, ranked by variable importance
(where applicable).</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_include_explanations">include_explanations</code></td>
<td>
<p>If specified, return only the specified model explanations.
(Mutually exclusive with exclude_explanations)</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_exclude_explanations">exclude_explanations</code></td>
<td>
<p>Exclude specified model explanations.</p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_plot_overrides">plot_overrides</code></td>
<td>
<p>Overrides for individual model explanations, e.g.,
<code>list(shap_explain_row = list(columns = 5))</code></p>
</td></tr>
<tr><td><code id="h2o.explain_row_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.
Setting it enables calculating SHAP in more models but it can be more time and memory consuming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of outputs with class &quot;H2OExplanation&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the explanation for whole H2OAutoML object
exa &lt;- h2o.explain_row(aml, test, row_index = 1)
print(exa)

# Create the explanation for the leader model
exm &lt;- h2o.explain_row(aml@leader, test, row_index = 1)
print(exm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.exportFile'>Export an H2O Data Frame (H2OFrame) to a File or to a collection of Files.</h2><span id='topic+h2o.exportFile'></span>

<h3>Description</h3>

<p>Exports an H2OFrame (which can be either VA or FV) to a file.
This file may be on the H2O instace's local filesystem, or to HDFS (preface
the path with hdfs://) or to S3N (preface the path with s3n://).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.exportFile(
  data,
  path,
  force = FALSE,
  sep = ",",
  compression = NULL,
  parts = 1,
  header = TRUE,
  quote_header = TRUE,
  format = "csv",
  write_checksum = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.exportFile_+3A_data">data</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_path">path</code></td>
<td>
<p>The path to write the file to. Must include the directory and
also filename if exporting to a single file. May be prefaced with
hdfs:// or s3n://. Each row of data appears as line of the file.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_sep">sep</code></td>
<td>
<p>The field separator character. Values on each line of
the file will be separated by this character (default &quot;,&quot;).</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_compression">compression</code></td>
<td>
<p>How to compress the exported dataset
(default none; gzip, bzip2 and snappy available)</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_parts">parts</code></td>
<td>
<p>integer, number of part files to export to. Default is to
write to a single file. Large data can be exported to multiple
'part' files, where each part file contains subset of the data.
User can specify the maximum number of part files or use value
-1 to indicate that H2O should itself determine the optimal
number of files.
Parameter path will be considered to be a path to a directory
if export to multiple part files is desired. Part files conform
to naming scheme 'part-m-?????'.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_header">header</code></td>
<td>
<p>logical, indicates whether to write the header line.
Default is to include the header in the output file.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_quote_header">quote_header</code></td>
<td>
<p>logical, indicates whether column names should be
quoted. Default is to use quotes.</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_format">format</code></td>
<td>
<p>string, one of &quot;csv&quot; or &quot;parquet&quot;. Default is &quot;csv&quot;. Export
to parquet is multipart and H2O itself determines the optimal number
of files (1 file per chunk).</p>
</td></tr>
<tr><td><code id="h2o.exportFile_+3A_write_checksum">write_checksum</code></td>
<td>
<p>logical, if supported by the format (e.g. 'parquet'), 
export will include a checksum file for each exported data file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of existing files <code>force = TRUE</code> will overwrite the file.
Otherwise, the operation will fail.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)

# These aren't real paths
# h2o.exportFile(iris_hf, path = "/path/on/h2o/server/filesystem/iris.csv")
# h2o.exportFile(iris_hf, path = "hdfs://path/in/hdfs/iris.csv")
# h2o.exportFile(iris_hf, path = "s3n://path/in/s3/iris.csv")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.exportHDFS'>Export a Model to HDFS</h2><span id='topic+h2o.exportHDFS'></span>

<h3>Description</h3>

<p>Exports an <a href="#topic+H2OModel-class">H2OModel</a> to HDFS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.exportHDFS(object, path, force = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.exportHDFS_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> class object.</p>
</td></tr>
<tr><td><code id="h2o.exportHDFS_+3A_path">path</code></td>
<td>
<p>The path to write the model to. Must include the driectory and
filename.</p>
</td></tr>
<tr><td><code id="h2o.exportHDFS_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_train.csv"
train &lt;- h2o.importFile(f)
h2o.exportHDFS(train, path = " ", force = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.extendedIsolationForest'>Trains an Extended Isolation Forest model</h2><span id='topic+h2o.extendedIsolationForest'></span>

<h3>Description</h3>

<p>Trains an Extended Isolation Forest model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.extendedIsolationForest(
  training_frame,
  x,
  model_id = NULL,
  ignore_const_cols = TRUE,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  score_each_iteration = FALSE,
  score_tree_interval = 0,
  ntrees = 100,
  sample_size = 256,
  extension_level = 0,
  seed = -1,
  disable_training_metrics = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.extendedIsolationForest_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of Extended Isolation Forest trees. Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_sample_size">sample_size</code></td>
<td>
<p>Number of randomly sampled observations used to train each Extended Isolation Forest tree. Defaults to 256.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_extension_level">extension_level</code></td>
<td>
<p>Maximum is N - 1 (N = numCols). Minimum is 0. Extended Isolation Forest with extension_Level = 0 behaves like
Isolation Forest. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.extendedIsolationForest_+3A_disable_training_metrics">disable_training_metrics</code></td>
<td>
<p><code>Logical</code>. Disable calculating training metrics (expensive on large datasets) Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the prostate dataset
p &lt;- h2o.importFile(path="https://raw.github.com/h2oai/h2o/master/smalldata/logreg/prostate.csv")

# Set the predictors
predictors &lt;- c("AGE","RACE","DPROS","DCAPS","PSA","VOL","GLEASON")

# Build an Extended Isolation forest model
model &lt;- h2o.extendedIsolationForest(x = predictors,
                                     training_frame = p,
                                     model_id = "eif.hex",
                                     ntrees = 100,
                                     sample_size = 256,
                                     extension_level = length(predictors) - 1)

# Calculate score
score &lt;- h2o.predict(model, p)
anomaly_score &lt;- score$anomaly_score

# Number in [0, 1] explicitly defined in Equation (1) from Extended Isolation Forest paper
# or in paragraph '2 Isolation and Isolation Trees' of Isolation Forest paper
anomaly_score &lt;- score$anomaly_score

# Average path length of the point in Isolation Trees from root to the leaf
mean_length &lt;- score$mean_length

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.fair_pd_plot'>Partial dependence plot per protected group.</h2><span id='topic+h2o.fair_pd_plot'></span>

<h3>Description</h3>

<p>Partial dependence plot per protected group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.fair_pd_plot(model, newdata, protected_columns, column, autoscale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.fair_pd_plot_+3A_model">model</code></td>
<td>
<p>H2O Model Object</p>
</td></tr>
<tr><td><code id="h2o.fair_pd_plot_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.fair_pd_plot_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.fair_pd_plot_+3A_column">column</code></td>
<td>
<p>String containing column name.</p>
</td></tr>
<tr><td><code id="h2o.fair_pd_plot_+3A_autoscale">autoscale</code></td>
<td>
<p>If &ldquo;True&ldquo;, try to guess when to use log transformation on X axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.fair_pd_plot(gbm, test, protected_columns, "AGE")

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.fair_pr_plot'>Plot PR curve per protected group.</h2><span id='topic+h2o.fair_pr_plot'></span>

<h3>Description</h3>

<p>Plot PR curve per protected group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.fair_pr_plot(model, newdata, protected_columns, reference, favorable_class)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.fair_pr_plot_+3A_model">model</code></td>
<td>
<p>H2O Model Object</p>
</td></tr>
<tr><td><code id="h2o.fair_pr_plot_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.fair_pr_plot_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.fair_pr_plot_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.fair_pr_plot_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.fair_pr_plot(gbm, test, protected_columns = protected_columns,
                 reference = reference, favorable_class = favorable_class)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.fair_roc_plot'>Plot ROC curve per protected group.</h2><span id='topic+h2o.fair_roc_plot'></span>

<h3>Description</h3>

<p>Plot ROC curve per protected group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.fair_roc_plot(
  model,
  newdata,
  protected_columns,
  reference,
  favorable_class
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.fair_roc_plot_+3A_model">model</code></td>
<td>
<p>H2O Model Object</p>
</td></tr>
<tr><td><code id="h2o.fair_roc_plot_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.fair_roc_plot_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.fair_roc_plot_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.fair_roc_plot_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.fair_roc_plot(gbm, test, protected_columns = protected_columns,
                  reference = reference, favorable_class = favorable_class)

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.fair_shap_plot'>SHAP summary plot for one feature with protected groups on y-axis.</h2><span id='topic+h2o.fair_shap_plot'></span>

<h3>Description</h3>

<p>SHAP summary plot for one feature with protected groups on y-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.fair_shap_plot(
  model,
  newdata,
  protected_columns,
  column,
  autoscale = TRUE,
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.fair_shap_plot_+3A_model">model</code></td>
<td>
<p>H2O Model Object</p>
</td></tr>
<tr><td><code id="h2o.fair_shap_plot_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.fair_shap_plot_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.fair_shap_plot_+3A_column">column</code></td>
<td>
<p>String containing column name.</p>
</td></tr>
<tr><td><code id="h2o.fair_shap_plot_+3A_autoscale">autoscale</code></td>
<td>
<p>If TRUE, try to guess when to use log transformation on X axis.</p>
</td></tr>
<tr><td><code id="h2o.fair_shap_plot_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of ggplot2 objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.fair_shap_plot(gbm, test, protected_columns, "AGE")

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.feature_interaction'>Feature interactions and importance, leaf statistics and split value histograms in a tabular form.
Available for XGBoost and GBM.</h2><span id='topic+h2o.feature_interaction'></span>

<h3>Description</h3>

<p>Metrics:
Gain - Total gain of each feature or feature interaction.
FScore - Amount of possible splits taken on a feature or feature interaction.
wFScore - Amount of possible splits taken on a feature or feature interaction weighed by 
the probability of the splits to take place.
Average wFScore - wFScore divided by FScore.
Average Gain - Gain divided by FScore.
Expected Gain - Total gain of each feature or feature interaction weighed by the probability to gather the gain.
Average Tree Index
Average Tree Depth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.feature_interaction(
  model,
  max_interaction_depth = 100,
  max_tree_depth = 100,
  max_deepening = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.feature_interaction_+3A_model">model</code></td>
<td>
<p>A trained xgboost model.</p>
</td></tr>
<tr><td><code id="h2o.feature_interaction_+3A_max_interaction_depth">max_interaction_depth</code></td>
<td>
<p>Upper bound for extracted feature interactions depth. Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.feature_interaction_+3A_max_tree_depth">max_tree_depth</code></td>
<td>
<p>Upper bound for tree depth. Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.feature_interaction_+3A_max_deepening">max_deepening</code></td>
<td>
<p>Upper bound for interaction start deepening (zero deepening =&gt; interactions 
starting at root only). Defaults to -1.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
boston &lt;- h2o.importFile(
       "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/BostonHousing.csv",
        destination_frame="boston"
        )
boston_xgb &lt;- h2o.xgboost(training_frame = boston, y = "medv", seed = 1234)
feature_interactions &lt;- h2o.feature_interaction(boston_xgb)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.fillna'>fillNA</h2><span id='topic+h2o.fillna'></span>

<h3>Description</h3>

<p>Fill NA's in a sequential manner up to a specified limit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.fillna(x, method = "forward", axis = 1, maxlen = 1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.fillna_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.fillna_+3A_method">method</code></td>
<td>
<p>A String: &quot;forward&quot; or &quot;backward&quot;</p>
</td></tr>
<tr><td><code id="h2o.fillna_+3A_axis">axis</code></td>
<td>
<p>An Integer 1 for row-wise fill (default), 2 for column-wise fill</p>
</td></tr>
<tr><td><code id="h2o.fillna_+3A_maxlen">maxlen</code></td>
<td>
<p>An Integer for maximum number of consecutive NA's to fill</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame after filling missing values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame_with_nas &lt;- h2o.createFrame(rows = 6, cols = 2,
                                  categorical_fraction = 0.0, 
                                  missing_fraction = 0.7, 
                                  seed = 123)
frame &lt;- h2o.fillna(frame_with_nas, "forward", axis = 1, maxlen = 2L)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.filterNACols'>Filter NA Columns</h2><span id='topic+h2o.filterNACols'></span>

<h3>Description</h3>

<p>Filter NA Columns
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.filterNACols(data, frac = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.filterNACols_+3A_data">data</code></td>
<td>
<p>A dataset to filter on.</p>
</td></tr>
<tr><td><code id="h2o.filterNACols_+3A_frac">frac</code></td>
<td>
<p>The threshold of NAs to allow per column (columns &gt;= this threshold are filtered)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of indexes that pertain to non-NA columns
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.filterNACols(frame, frac = 0.5)
h2o.filterNACols(frame, frac = 0.6)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.find_row_by_threshold'>Find the threshold, give the max metric. No duplicate thresholds allowed</h2><span id='topic+h2o.find_row_by_threshold'></span>

<h3>Description</h3>

<p>Find the threshold, give the max metric. No duplicate thresholds allowed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.find_row_by_threshold(object, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.find_row_by_threshold_+3A_object">object</code></td>
<td>
<p>H2OBinomialMetrics</p>
</td></tr>
<tr><td><code id="h2o.find_row_by_threshold_+3A_threshold">threshold</code></td>
<td>
<p>number between 0 and 1</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, 
                    training_frame = train, validation_frame = valid, 
                    build_tree_one_node = TRUE , seed = 1234)
perf &lt;- h2o.performance(cars_gbm, cars)
h2o.find_row_by_threshold(perf, 0.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.find_threshold_by_max_metric'>Find the threshold, give the max metric</h2><span id='topic+h2o.find_threshold_by_max_metric'></span>

<h3>Description</h3>

<p>Find the threshold, give the max metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.find_threshold_by_max_metric(object, metric)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.find_threshold_by_max_metric_+3A_object">object</code></td>
<td>
<p>H2OBinomialMetrics</p>
</td></tr>
<tr><td><code id="h2o.find_threshold_by_max_metric_+3A_metric">metric</code></td>
<td>
<p>&quot;F1,&quot; for example</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, 
                    training_frame = train, validation_frame = valid, 
                    build_tree_one_node = TRUE , seed = 1234)
perf &lt;- h2o.performance(cars_gbm, cars)
h2o.find_threshold_by_max_metric(perf, "fnr")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.findSynonyms'>Find synonyms using a word2vec model.</h2><span id='topic+h2o.findSynonyms'></span>

<h3>Description</h3>

<p>Find synonyms using a word2vec model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.findSynonyms(word2vec, word, count = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.findSynonyms_+3A_word2vec">word2vec</code></td>
<td>
<p>A word2vec model.</p>
</td></tr>
<tr><td><code id="h2o.findSynonyms_+3A_word">word</code></td>
<td>
<p>A single word to find synonyms for.</p>
</td></tr>
<tr><td><code id="h2o.findSynonyms_+3A_count">count</code></td>
<td>
<p>The top 'count' synonyms will be returned.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

job_titles &lt;- h2o.importFile(
    "https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv", 
    col.names = c("category", "jobtitle"), col.types = c("String", "String"), header = TRUE
)
words &lt;- h2o.tokenize(job_titles, " ")
vec &lt;- h2o.word2vec(training_frame = words)
h2o.findSynonyms(vec, "teacher", count = 20)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.floor'>Take a single numeric argument and return a numeric vector with the largest integers</h2><span id='topic+h2o.floor'></span>

<h3>Description</h3>

<p>floor takes a single numeric argument x and returns a numeric
vector containing the largest integers not greater than the
corresponding elements of x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.floor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.floor_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for the base R implementation, <code>floor()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.floor(frame["C2"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.flow'>Open H2O Flow</h2><span id='topic+h2o.flow'></span>

<h3>Description</h3>

<p>Open H2O Flow in your browser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.flow()
</code></pre>

<hr>
<h2 id='h2o.gains_lift_plot'>Plot Gains/Lift curves</h2><span id='topic+h2o.gains_lift_plot'></span>

<h3>Description</h3>

<p>Plot Gains/Lift curves
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.gains_lift_plot(object, type = c("both", "gains", "lift"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gains_lift_plot_+3A_object">object</code></td>
<td>
<p>Either an H2OModel or H2OModelMetrics</p>
</td></tr>
<tr><td><code id="h2o.gains_lift_plot_+3A_type">type</code></td>
<td>
<p>What curve to plot. One of &quot;both&quot;, &quot;gains&quot;, &quot;lift&quot;.</p>
</td></tr>
<tr><td><code id="h2o.gains_lift_plot_+3A_...">...</code></td>
<td>
<p>Optional arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(
path = "https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip")
model &lt;- h2o.gbm(x = c("Origin", "Distance"), y = "IsDepDelayed", training_frame = data, ntrees = 1)
h2o.gains_lift_plot(model)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.gains_lift_plot+2CH2OModel-method'>Plot Gains/Lift curves</h2><span id='topic+h2o.gains_lift_plot+2CH2OModel-method'></span>

<h3>Description</h3>

<p>Plot Gains/Lift curves
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModel'
h2o.gains_lift_plot(object, type = c("both", "gains", "lift"), xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gains_lift_plot+2B2CH2OModel-method_+3A_object">object</code></td>
<td>
<p>H2OModel object</p>
</td></tr>
<tr><td><code id="h2o.gains_lift_plot+2B2CH2OModel-method_+3A_type">type</code></td>
<td>
<p>What curve to plot. One of &quot;both&quot;, &quot;gains&quot;, &quot;lift&quot;.</p>
</td></tr>
<tr><td><code id="h2o.gains_lift_plot+2B2CH2OModel-method_+3A_xval">xval</code></td>
<td>
<p>if TRUE, use cross-validation metrics</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.gains_lift_plot+2CH2OModelMetrics-method'>Plot Gains/Lift curves</h2><span id='topic+h2o.gains_lift_plot+2CH2OModelMetrics-method'></span>

<h3>Description</h3>

<p>Plot Gains/Lift curves
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModelMetrics'
h2o.gains_lift_plot(object, type = c("both", "gains", "lift"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gains_lift_plot+2B2CH2OModelMetrics-method_+3A_object">object</code></td>
<td>
<p>H2OModelMetrics object</p>
</td></tr>
<tr><td><code id="h2o.gains_lift_plot+2B2CH2OModelMetrics-method_+3A_type">type</code></td>
<td>
<p>What curve to plot. One of &quot;both&quot;, &quot;gains&quot;, &quot;lift&quot;.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.gainsLift'>Access H2O Gains/Lift Tables</h2><span id='topic+h2o.gainsLift'></span><span id='topic+h2o.gains_lift'></span><span id='topic+h2o.gainsLift+2CH2OModel-method'></span><span id='topic+h2o.gainsLift+2CH2OModelMetrics-method'></span>

<h3>Description</h3>

<p>Retrieve either a single or many Gains/Lift tables from H2O objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.gainsLift(object, ...)

h2o.gains_lift(object, ...)

## S4 method for signature 'H2OModel'
h2o.gainsLift(object, newdata, valid = FALSE, xval = FALSE, ...)

## S4 method for signature 'H2OModelMetrics'
h2o.gainsLift(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gainsLift_+3A_object">object</code></td>
<td>
<p>Either an <a href="#topic+H2OModel-class">H2OModel</a> object or an
<a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.gainsLift_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to/from this method.</p>
</td></tr>
<tr><td><code id="h2o.gainsLift_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object that can be scored on.
Requires a valid response column.</p>
</td></tr>
<tr><td><code id="h2o.gainsLift_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation metric.</p>
</td></tr>
<tr><td><code id="h2o.gainsLift_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation metric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> version of this function will only take
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> objects.
</p>


<h3>Value</h3>

<p>Calling this function on <a href="#topic+H2OModel-class">H2OModel</a> objects returns a
Gains/Lift table corresponding to the <code><a href="stats.html#topic+predict">predict</a></code> function.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict</a></code> for generating prediction frames,
<code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating
<a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, distribution = "bernoulli",
                 training_frame = prostate, validation_frame = prostate, nfolds = 3)
h2o.gainsLift(model)              ## extract training metrics
h2o.gainsLift(model, valid = TRUE)  ## extract validation metrics (here: the same)
h2o.gainsLift(model, xval = TRUE)  ## extract cross-validation metrics
h2o.gainsLift(model, newdata = prostate) ## score on new data (here: the same)
# Generating a ModelMetrics object
perf &lt;- h2o.performance(model, prostate)
h2o.gainsLift(perf)               ## extract from existing metrics object

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.gam'>Fit a General Additive Model</h2><span id='topic+h2o.gam'></span>

<h3>Description</h3>

<p>Creates a generalized additive model, specified by a response variable, a set of predictors, and a
description of the error distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.gam(
  x,
  y,
  training_frame,
  gam_columns,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  seed = -1,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  offset_column = NULL,
  weights_column = NULL,
  family = c("AUTO", "gaussian", "binomial", "quasibinomial", "ordinal", "multinomial",
    "poisson", "gamma", "tweedie", "negativebinomial", "fractionalbinomial"),
  tweedie_variance_power = 0,
  tweedie_link_power = 0,
  theta = 0,
  solver = c("AUTO", "IRLSM", "L_BFGS", "COORDINATE_DESCENT_NAIVE", "COORDINATE_DESCENT",
    "GRADIENT_DESCENT_LH", "GRADIENT_DESCENT_SQERR"),
  alpha = NULL,
  lambda = NULL,
  lambda_search = FALSE,
  early_stopping = TRUE,
  nlambdas = -1,
  standardize = FALSE,
  missing_values_handling = c("MeanImputation", "Skip", "PlugValues"),
  plug_values = NULL,
  compute_p_values = FALSE,
  remove_collinear_columns = FALSE,
  splines_non_negative = NULL,
  intercept = TRUE,
  non_negative = FALSE,
  max_iterations = -1,
  objective_epsilon = -1,
  beta_epsilon = 1e-04,
  gradient_epsilon = -1,
  link = c("family_default", "identity", "logit", "log", "inverse", "tweedie", "ologit"),
  startval = NULL,
  prior = -1,
  cold_start = FALSE,
  lambda_min_ratio = -1,
  beta_constraints = NULL,
  max_active_predictors = -1,
  interactions = NULL,
  interaction_pairs = NULL,
  obj_reg = -1,
  export_checkpoints_dir = NULL,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = 0,
  custom_metric_func = NULL,
  num_knots = NULL,
  spline_orders = NULL,
  knot_ids = NULL,
  standardize_tp_gam_cols = FALSE,
  scale_tp_penalty_mat = FALSE,
  bs = NULL,
  scale = NULL,
  keep_gam_cols = FALSE,
  store_knot_locations = FALSE,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  gainslift_bins = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gam_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_gam_columns">gam_columns</code></td>
<td>
<p>Arrays of predictor column names for gam for smoothers using single or multiple predictors like
{{'c1'},{'c2','c3'},{'c4'},...}</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_family">family</code></td>
<td>
<p>Family. Use binomial for classification with logistic regression, others are for regression problems. Must be
one of: &quot;AUTO&quot;, &quot;gaussian&quot;, &quot;binomial&quot;, &quot;quasibinomial&quot;, &quot;ordinal&quot;, &quot;multinomial&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;negativebinomial&quot;, &quot;fractionalbinomial&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_tweedie_variance_power">tweedie_variance_power</code></td>
<td>
<p>Tweedie variance power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_tweedie_link_power">tweedie_link_power</code></td>
<td>
<p>Tweedie link power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_theta">theta</code></td>
<td>
<p>Theta Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_solver">solver</code></td>
<td>
<p>AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small
number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many
columns. Must be one of: &quot;AUTO&quot;, &quot;IRLSM&quot;, &quot;L_BFGS&quot;, &quot;COORDINATE_DESCENT_NAIVE&quot;, &quot;COORDINATE_DESCENT&quot;,
&quot;GRADIENT_DESCENT_LH&quot;, &quot;GRADIENT_DESCENT_SQERR&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_alpha">alpha</code></td>
<td>
<p>Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha
represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the
amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_lambda">lambda</code></td>
<td>
<p>Regularization strength</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_lambda_search">lambda_search</code></td>
<td>
<p><code>Logical</code>. Use lambda search starting at lambda max, given lambda is then interpreted as lambda min
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_early_stopping">early_stopping</code></td>
<td>
<p><code>Logical</code>. Stop early when there is no more relative improvement on train or validation (if provided)
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_nlambdas">nlambdas</code></td>
<td>
<p>Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,
the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.
Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize numeric columns to have zero mean and unit variance Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_missing_values_handling">missing_values_handling</code></td>
<td>
<p>Handling of missing values. Either MeanImputation, Skip or PlugValues. Must be one of: &quot;MeanImputation&quot;,
&quot;Skip&quot;, &quot;PlugValues&quot;. Defaults to MeanImputation.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_plug_values">plug_values</code></td>
<td>
<p>Plug Values (a single row frame containing values that will be used to impute missing values of the
training/validation frame, use with conjunction missing_values_handling = PlugValues)</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_compute_p_values">compute_p_values</code></td>
<td>
<p><code>Logical</code>. Request p-values computation, p-values work only with IRLSM solver and no regularization
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_remove_collinear_columns">remove_collinear_columns</code></td>
<td>
<p><code>Logical</code>. In case of linearly dependent columns, remove some of the dependent columns Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_splines_non_negative">splines_non_negative</code></td>
<td>
<p>Valid for I-spline (bs=2) only.  True if the I-splines are monotonically increasing (and monotonically non-
decreasing) and False if the I-splines are monotonically decreasing (and monotonically non-increasing).  If
specified, must be the same size as gam_columns.  Values for other spline types will be ignored.  Default to
true.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_intercept">intercept</code></td>
<td>
<p><code>Logical</code>. Include constant term in the model Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_non_negative">non_negative</code></td>
<td>
<p><code>Logical</code>. Restrict coefficients (not intercept) to be non-negative Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_objective_epsilon">objective_epsilon</code></td>
<td>
<p>Converge if  objective value changes less than this. Default indicates: If lambda_search is set to True the
value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal to zero,
the value of objective_epsilon is set to .000001, for any other value of lambda the default value of
objective_epsilon is set to .0001. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_beta_epsilon">beta_epsilon</code></td>
<td>
<p>Converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver
Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_gradient_epsilon">gradient_epsilon</code></td>
<td>
<p>Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default
indicates: If lambda_search is set to False and lambda is equal to zero, the default value of gradient_epsilon
is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True, the conditional
values above are 1E-8 and 1E-6 respectively. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_link">link</code></td>
<td>
<p>Link function. Must be one of: &quot;family_default&quot;, &quot;identity&quot;, &quot;logit&quot;, &quot;log&quot;, &quot;inverse&quot;, &quot;tweedie&quot;, &quot;ologit&quot;.
Defaults to family_default.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_startval">startval</code></td>
<td>
<p>double array to initialize coefficients for GAM.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_prior">prior</code></td>
<td>
<p>Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean
of response does not reflect reality. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_cold_start">cold_start</code></td>
<td>
<p><code>Logical</code>. Only applicable to multiple alpha/lambda values when calling GLM from GAM.  If false, build
the next model for next set of alpha/lambda values starting from the values provided by current model.  If
true will start GLM model from scratch. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>Minimum lambda used in lambda search, specified as a ratio of lambda_max (the smallest lambda that drives all
coefficients to zero). Default indicates: if the number of observations is greater than the number of
variables, then lambda_min_ratio is set to 0.0001; if the number of observations is less than the number of
variables, then lambda_min_ratio is set to 0.01. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_beta_constraints">beta_constraints</code></td>
<td>
<p>Beta constraints</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_max_active_predictors">max_active_predictors</code></td>
<td>
<p>Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model
building with many predictors. Default indicates: If the IRLSM solver is used, the value of
max_active_predictors is set to 5000 otherwise it is set to 100000000. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_interactions">interactions</code></td>
<td>
<p>A list of predictor column indices to interact. All pairwise combinations will be computed for the list.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_interaction_pairs">interaction_pairs</code></td>
<td>
<p>A list of pairwise (first order) column interactions.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_obj_reg">obj_reg</code></td>
<td>
<p>Likelihood divider in objective value computation, default is 1/nobs Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_num_knots">num_knots</code></td>
<td>
<p>Number of knots for gam predictors.  If specified, must specify one for each gam predictor.  For monotone
I-splines, mininum = 2, for cs spline, minimum = 3.  For thin plate, minimum is size of polynomial basis + 2.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_spline_orders">spline_orders</code></td>
<td>
<p>Order of I-splines or NBSplineTypeI M-splines used for gam predictors. If specified, must be the same size as
gam_columns.  For I-splines, the spline_orders will be the same as the polynomials used to generate the
splines.  For M-splines, the polynomials used to generate the splines will be spline_order-1.  Values for bs=0
or 1 will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_knot_ids">knot_ids</code></td>
<td>
<p>Array storing frame keys of knots.  One for each gam column set specified in gam_columns</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_standardize_tp_gam_cols">standardize_tp_gam_cols</code></td>
<td>
<p><code>Logical</code>. standardize tp (thin plate) predictor columns Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_scale_tp_penalty_mat">scale_tp_penalty_mat</code></td>
<td>
<p><code>Logical</code>. Scale penalty matrix for tp (thin plate) smoothers as in R Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_bs">bs</code></td>
<td>
<p>Basis function type for each gam predictors, 0 for cr, 1 for thin plate regression with knots, 2 for monotone
I-splines, 3 for NBSplineTypeI M-splines (refer to doc here: https://github.com/h2oai/h2o-3/issues/6926).  If
specified, must be the same size as gam_columns</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_scale">scale</code></td>
<td>
<p>Smoothing parameter for gam predictors.  If specified, must be of the same length as gam_columns</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_keep_gam_cols">keep_gam_cols</code></td>
<td>
<p><code>Logical</code>. Save keys of model matrix Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_store_knot_locations">store_knot_locations</code></td>
<td>
<p><code>Logical</code>. If set to true, will return knot locations as double[][] array for gam column names found
knots_for_gam.  Default to false. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gam_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Run GAM of CAPSULE ~ AGE + RACE + PSA + DCAPS
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
h2o.gam(y = "CAPSULE", x = c("RACE"), gam_columns = c("PSA"),
     training_frame = prostate, family = "binomial")


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.gbm'>Build gradient boosted classification or regression trees</h2><span id='topic+h2o.gbm'></span>

<h3>Description</h3>

<p>Builds gradient boosted classification trees and gradient boosted regression trees on a parsed data set.
The default distribution function will guess the model type based on the response column type.
In order to run properly, the response column must be an numeric for &quot;gaussian&quot; or an
enum for &quot;bernoulli&quot; or &quot;multinomial&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.gbm(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  score_each_iteration = FALSE,
  score_tree_interval = 0,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  offset_column = NULL,
  weights_column = NULL,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  ntrees = 50,
  max_depth = 5,
  min_rows = 10,
  nbins = 20,
  nbins_top_level = 1024,
  nbins_cats = 1024,
  r2_stopping = Inf,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  max_runtime_secs = 0,
  seed = -1,
  build_tree_one_node = FALSE,
  learn_rate = 0.1,
  learn_rate_annealing = 1,
  distribution = c("AUTO", "bernoulli", "quasibinomial", "multinomial", "gaussian",
    "poisson", "gamma", "tweedie", "laplace", "quantile", "huber", "custom"),
  quantile_alpha = 0.5,
  tweedie_power = 1.5,
  huber_alpha = 0.9,
  checkpoint = NULL,
  sample_rate = 1,
  sample_rate_per_class = NULL,
  col_sample_rate = 1,
  col_sample_rate_change_per_level = 1,
  col_sample_rate_per_tree = 1,
  min_split_improvement = 1e-05,
  histogram_type = c("AUTO", "UniformAdaptive", "Random", "QuantilesGlobal",
    "RoundRobin", "UniformRobust"),
  max_abs_leafnode_pred = Inf,
  pred_noise_bandwidth = 0,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  calibrate_model = FALSE,
  calibration_frame = NULL,
  calibration_method = c("AUTO", "PlattScaling", "IsotonicRegression"),
  custom_metric_func = NULL,
  custom_distribution_func = NULL,
  export_checkpoints_dir = NULL,
  in_training_checkpoints_dir = NULL,
  in_training_checkpoints_tree_interval = 1,
  monotone_constraints = NULL,
  check_constant_response = TRUE,
  gainslift_bins = -1,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  interaction_constraints = NULL,
  auto_rebalance = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gbm_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of trees. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum tree depth (0 for unlimited). Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_min_rows">min_rows</code></td>
<td>
<p>Fewest allowed (weighted) observations in a leaf. Defaults to 10.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_nbins">nbins</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point
Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_nbins_top_level">nbins_top_level</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then
decrease by factor of two per level Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_nbins_cats">nbins_cats</code></td>
<td>
<p>For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher
values can lead to more overfitting. Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_r2_stopping">r2_stopping</code></td>
<td>
<p>r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric
and stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or
exceeds this Defaults to 1.797693135e+308.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_build_tree_one_node">build_tree_one_node</code></td>
<td>
<p><code>Logical</code>. Run on one node only; no network overhead but fewer cpus used. Suitable for small datasets.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_learn_rate">learn_rate</code></td>
<td>
<p>Learning rate (from 0.0 to 1.0) Defaults to 0.1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_learn_rate_annealing">learn_rate_annealing</code></td>
<td>
<p>Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999)  Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;quasibinomial&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;,
&quot;poisson&quot;, &quot;gamma&quot;, &quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;, &quot;custom&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_quantile_alpha">quantile_alpha</code></td>
<td>
<p>Desired quantile for Quantile regression, must be between 0 and 1. Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_tweedie_power">tweedie_power</code></td>
<td>
<p>Tweedie power for Tweedie regression, must be between 1 and 2. Defaults to 1.5.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_huber_alpha">huber_alpha</code></td>
<td>
<p>Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and
1). Defaults to 0.9.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Model checkpoint to resume training with.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_sample_rate">sample_rate</code></td>
<td>
<p>Row sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_sample_rate_per_class">sample_rate_per_class</code></td>
<td>
<p>A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_col_sample_rate">col_sample_rate</code></td>
<td>
<p>Column sample rate (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_col_sample_rate_change_per_level">col_sample_rate_change_per_level</code></td>
<td>
<p>Relative change of the column sampling rate for every level (must be &gt; 0.0 and &lt;= 2.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_col_sample_rate_per_tree">col_sample_rate_per_tree</code></td>
<td>
<p>Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_min_split_improvement">min_split_improvement</code></td>
<td>
<p>Minimum relative improvement in squared error reduction for a split to happen Defaults to 1e-05.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_histogram_type">histogram_type</code></td>
<td>
<p>What type of histogram to use for finding optimal split points Must be one of: &quot;AUTO&quot;, &quot;UniformAdaptive&quot;,
&quot;Random&quot;, &quot;QuantilesGlobal&quot;, &quot;RoundRobin&quot;, &quot;UniformRobust&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_max_abs_leafnode_pred">max_abs_leafnode_pred</code></td>
<td>
<p>Maximum absolute value of a leaf node prediction Defaults to 1.797693135e+308.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_pred_noise_bandwidth">pred_noise_bandwidth</code></td>
<td>
<p>Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_calibrate_model">calibrate_model</code></td>
<td>
<p><code>Logical</code>. Use Platt Scaling (default) or Isotonic Regression to calculate calibrated class
probabilities. Calibration can provide more accurate estimates of class probabilities. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_calibration_frame">calibration_frame</code></td>
<td>
<p>Data for model calibration</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_calibration_method">calibration_method</code></td>
<td>
<p>Calibration method to use Must be one of: &quot;AUTO&quot;, &quot;PlattScaling&quot;, &quot;IsotonicRegression&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_custom_distribution_func">custom_distribution_func</code></td>
<td>
<p>Reference to custom distribution, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_in_training_checkpoints_dir">in_training_checkpoints_dir</code></td>
<td>
<p>Create checkpoints into defined directory while training process is still running. In case of cluster
shutdown, this checkpoint can be used to restart training.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_in_training_checkpoints_tree_interval">in_training_checkpoints_tree_interval</code></td>
<td>
<p>Checkpoint the model after every so many trees. Parameter is used only when in_training_checkpoints_dir is
defined Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_monotone_constraints">monotone_constraints</code></td>
<td>
<p>A mapping representing monotonic constraints. Use +1 to enforce an increasing constraint and -1 to specify a
decreasing constraint.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_check_constant_response">check_constant_response</code></td>
<td>
<p><code>Logical</code>. Check if response column is constant. If enabled, then an exception is thrown if the response
column is a constant value.If disabled, then model will train regardless of the response column being a
constant value or not. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_interaction_constraints">interaction_constraints</code></td>
<td>
<p>A set of allowed column interactions.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_auto_rebalance">auto_rebalance</code></td>
<td>
<p><code>Logical</code>. Allow automatic rebalancing of training and validation datasets Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.gbm_+3A_verbose">verbose</code></td>
<td>
<p><code>Logical</code>. Print scoring history to the console (Metrics per tree). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Run regression GBM on australia data
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.uploadFile(path = australia_path)
independent &lt;- c("premax", "salmax", "minairtemp", "maxairtemp", "maxsst",
                 "maxsoilmoist", "Max_czcs")
dependent &lt;- "runoffnew"
h2o.gbm(y = dependent, x = independent, training_frame = australia,
        ntrees = 3, max_depth = 3, min_rows = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.generic'>Imports a generic model into H2O. Such model can be used then used for scoring and obtaining
additional information about the model. The imported model has to be supported by H2O.</h2><span id='topic+h2o.generic'></span>

<h3>Description</h3>

<p>Imports a generic model into H2O. Such model can be used then used for scoring and obtaining
additional information about the model. The imported model has to be supported by H2O.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.generic(model_id = NULL, model_key = NULL, path = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.generic_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.generic_+3A_model_key">model_key</code></td>
<td>
<p>Key to the self-contained model archive already uploaded to H2O.</p>
</td></tr>
<tr><td><code id="h2o.generic_+3A_path">path</code></td>
<td>
<p>Path to file with self-contained model archive.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()

# generic_model &lt;- h2o.genericModel(path="/path/to/model.zip", model_id="my_model")
# predictions &lt;- h2o.predict(generic_model, dataset)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.genericModel'>Imports a model under given path, creating a Generic model with it.</h2><span id='topic+h2o.genericModel'></span>

<h3>Description</h3>

<p>Usage example:
generic_model &lt;- h2o.genericModel(model_file_path = &quot;/path/to/mojo.zip&quot;)
predictions &lt;- h2o.predict(generic_model, dataset)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.genericModel(mojo_file_path, model_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.genericModel_+3A_mojo_file_path">mojo_file_path</code></td>
<td>
<p>Filesystem path to the model imported</p>
</td></tr>
<tr><td><code id="h2o.genericModel_+3A_model_id">model_id</code></td>
<td>
<p>Model ID, default is NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns H2O Generic Model based on given embedded model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Import default Iris dataset as H2O frame
data &lt;- as.h2o(iris)

# Train a very simple GBM model
features &lt;- c("Sepal.Length", "Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")
original_model &lt;- h2o.gbm(x = features, y = "Species", training_frame = data)

# Download the trained GBM model as MOJO (temporary directory used in this example)
mojo_original_name &lt;- h2o.download_mojo(model = original_model, path = tempdir())
mojo_original_path &lt;- paste0(tempdir(), "/", mojo_original_name)

# Import the MOJO as Generic model
generic_model &lt;- h2o.genericModel(mojo_original_path)

# Perform scoring with the generic model
generic_model_predictions  &lt;- h2o.predict(generic_model, data)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_automl'>Get an R object that is a subclass of <a href="#topic+H2OAutoML-class">H2OAutoML</a></h2><span id='topic+h2o.get_automl'></span><span id='topic+h2o.getAutoML'></span>

<h3>Description</h3>

<p>Get an R object that is a subclass of <a href="#topic+H2OAutoML-class">H2OAutoML</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_automl(project_name)

h2o.getAutoML(project_name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_automl_+3A_project_name">project_name</code></td>
<td>
<p>A string indicating the project_name of the automl instance to retrieve.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object that is a subclass of <a href="#topic+H2OAutoML-class">H2OAutoML</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, 
                  max_runtime_secs = 30, project_name = "prostate")
aml2 &lt;- h2o.get_automl("prostate")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_best_model'>Get best model of a given family/algorithm for a given criterion from an AutoML object.</h2><span id='topic+h2o.get_best_model'></span>

<h3>Description</h3>

<p>Get best model of a given family/algorithm for a given criterion from an AutoML object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_best_model(
  object,
  algorithm = c("any", "basemodel", "deeplearning", "drf", "gbm", "glm",
    "stackedensemble", "xgboost"),
  criterion = c("AUTO", "AUC", "AUCPR", "logloss", "MAE", "mean_per_class_error",
    "deviance", "MSE", "predict_time_per_row_ms", "RMSE", "RMSLE", "training_time_ms")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_best_model_+3A_object">object</code></td>
<td>
<p>H2OAutoML object</p>
</td></tr>
<tr><td><code id="h2o.get_best_model_+3A_algorithm">algorithm</code></td>
<td>
<p>One of &quot;any&quot;, &quot;basemodel&quot;, &quot;deeplearning&quot;, &quot;drf&quot;, &quot;gbm&quot;, &quot;glm&quot;, &quot;stackedensemble&quot;, &quot;xgboost&quot;</p>
</td></tr>
<tr><td><code id="h2o.get_best_model_+3A_criterion">criterion</code></td>
<td>
<p>Criterion can be one of the metrics reported in the leaderboard. If set to NULL, the same ordering
as in the leaderboard will be used.
Avaliable criteria:
</p>

<ul>
<li><p>Regression metrics: deviance, RMSE, MSE, MAE, RMSLE
</p>
</li>
<li><p>Binomial metrics: AUC, logloss, AUCPR, mean_per_class_error, RMSE, MSE
</p>
</li>
<li><p>Multinomial metrics: mean_per_class_error, logloss, RMSE, MSE
</p>
</li></ul>

<p>The following additional leaderboard information can be also used as a criterion:
</p>

<ul>
<li><p>'training_time_ms': column providing the training time of each model in milliseconds (doesn't include the training of cross validation models).
</p>
</li>
<li><p>'predict_time_per_row_ms': column providing the average prediction time by the model for a single row.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OModel or NULL if no model of a given family is present
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 30)
gbm &lt;- h2o.get_best_model(aml, "gbm")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_best_model_predictors'>Extracts the subset of predictor names that yield the best R2 value for each predictor subset size.</h2><span id='topic+h2o.get_best_model_predictors'></span>

<h3>Description</h3>

<p>Extracts the subset of predictor names that yield the best R2 value for each predictor subset size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_best_model_predictors(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_best_model_predictors_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of modelselection</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_best_r2_values'>Extracts the best R2 values for all predictor subset size.</h2><span id='topic+h2o.get_best_r2_values'></span>

<h3>Description</h3>

<p>Extracts the best R2 values for all predictor subset size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_best_r2_values(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_best_r2_values_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of modelselection</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_gam_knot_column_names'>Extracts the gam column names corresponding to the knot locations from model output if it is enabled.</h2><span id='topic+h2o.get_gam_knot_column_names'></span>

<h3>Description</h3>

<p>Extracts the gam column names corresponding to the knot locations from model output if it is enabled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_gam_knot_column_names(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_gam_knot_column_names_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of gam</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_knot_locations'>Extracts the knot locations from model output if it is enabled.</h2><span id='topic+h2o.get_knot_locations'></span>

<h3>Description</h3>

<p>Extracts the knot locations from model output if it is enabled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_knot_locations(model, gam_column = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_knot_locations_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of gam</p>
</td></tr>
<tr><td><code id="h2o.get_knot_locations_+3A_gam_column">gam_column</code></td>
<td>
<p>will only extract the knot locations for the specific gam_columns.  Else, return all.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_leaderboard'>Retrieve the leaderboard from the AutoML instance.</h2><span id='topic+h2o.get_leaderboard'></span>

<h3>Description</h3>

<p>Contrary to the default leaderboard attached to the automl instance, this one can return columns other than the metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_leaderboard(object, extra_columns = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_leaderboard_+3A_object">object</code></td>
<td>
<p>The object for which to return the leaderboard. Currently, only H2OAutoML instances are supported.</p>
</td></tr>
<tr><td><code id="h2o.get_leaderboard_+3A_extra_columns">extra_columns</code></td>
<td>
<p>A string or a list of string specifying which optional columns should be added to the leaderboard. Defaults to None.
Currently supported extensions are:
</p>

<ul>
<li><p>'ALL': adds all columns below.
</p>
</li>
<li><p>'training_time_ms': column providing the training time of each model in milliseconds (doesn't include the training of cross validation models).
</p>
</li>
<li><p>'predict_time_per_row_ms': column providing the average prediction time by the model for a single row.
</p>
</li>
<li><p>'algo': column providing the algorithm name for each model.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame representing the leaderboard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 30)
lb &lt;- h2o.get_leaderboard(aml)
head(lb)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_ntrees_actual'>Retrieve actual number of trees for tree algorithms</h2><span id='topic+h2o.get_ntrees_actual'></span>

<h3>Description</h3>

<p>Retrieve actual number of trees for tree algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_ntrees_actual(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_ntrees_actual_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_predictors_added_per_step'>Extracts the predictor added to model at each step.</h2><span id='topic+h2o.get_predictors_added_per_step'></span>

<h3>Description</h3>

<p>Extracts the predictor added to model at each step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_predictors_added_per_step(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_predictors_added_per_step_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of modelselection</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_predictors_removed_per_step'>Extracts the predictor removed to model at each step.</h2><span id='topic+h2o.get_predictors_removed_per_step'></span>

<h3>Description</h3>

<p>Extracts the predictor removed to model at each step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_predictors_removed_per_step(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_predictors_removed_per_step_+3A_model">model</code></td>
<td>
<p>is a H2OModel with algorithm name of modelselection</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.get_regression_influence_diagnostics'>Extracts a list of H2OFrames containing regression influence diagnostics for predictor subsets of various sizes or
just one H2OFrame containing regression influence diagnostics for predictor subsets of one fixed size</h2><span id='topic+h2o.get_regression_influence_diagnostics'></span>

<h3>Description</h3>

<p>Extracts a list of H2OFrames containing regression influence diagnostics for predictor subsets of various sizes or
just one H2OFrame containing regression influence diagnostics for predictor subsets of one fixed size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_regression_influence_diagnostics(model, predictorSize = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_regression_influence_diagnostics_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.get_regression_influence_diagnostics_+3A_predictorsize">predictorSize</code></td>
<td>
<p>predictor subset size.  If specified, will only return model coefficients of that subset size.  If
not specified will return a lists of model coefficient dicts for all predictor subset size.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "acceleration"
cars_model &lt;- h2o.modelSelection(y=response, 
                                 x=predictors, 
                                 training_frame = cars, 
                                 min_predictor_number=2, 
                                 mode="backward", 
                                 influence="dfbetas",
                                 lambda=0.0,
                                 family="gaussian")
rid_frame &lt;- h2o.get_regression_influence_diagnostics(cars_model, predictorSize=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_segment_models'>Retrieves an instance of <a href="#topic+H2OSegmentModels-class">H2OSegmentModels</a> for a given id.</h2><span id='topic+h2o.get_segment_models'></span>

<h3>Description</h3>

<p>Retrieves an instance of <a href="#topic+H2OSegmentModels-class">H2OSegmentModels</a> for a given id.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_segment_models(segment_models_id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_segment_models_+3A_segment_models_id">segment_models_id</code></td>
<td>
<p>A string indicating the unique segment_models_id</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object that is a subclass of <a href="#topic+H2OSegmentModels-class">H2OSegmentModels</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
h2o.train_segments(algorithm = "gbm",
                   segment_columns = "Species", segment_models_id="models_by_species",
                   x = c(1:3), y = 4, training_frame = iris_hf, ntrees = 5, max_depth = 4)
models &lt;- h2o.get_segment_models("models_by_species")
as.data.frame(models)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.get_variable_inflation_factors'>Return the variable inflation factors associated with numerical predictors for GLM models.</h2><span id='topic+h2o.get_variable_inflation_factors'></span>

<h3>Description</h3>

<p>Return the variable inflation factors associated with numerical predictors for GLM models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_variable_inflation_factors(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.get_variable_inflation_factors_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "cylinders"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_glm &lt;- h2o.glm(seed = 1234, 
                    lambda=0.0,
                    compute_p_values=TRUE,
                    generate_variable_inflation_factors=TRUE,     
                    x = predictors, 
                    y = response, 
                    training_frame = train, 
                    validation_frame = valid)
h2o.get_variable_inflation_factors(cars_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getAlphaBest'>Extract best alpha value found from glm model.</h2><span id='topic+h2o.getAlphaBest'></span>

<h3>Description</h3>

<p>This function allows setting betas of an existing glm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getAlphaBest(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getAlphaBest_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.getConnection'>Retrieve an H2O Connection</h2><span id='topic+h2o.getConnection'></span>

<h3>Description</h3>

<p>Attempt to recover an h2o connection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getConnection()
</code></pre>


<h3>Value</h3>

<p>Returns an <a href="#topic+H2OConnection-class">H2OConnection</a> object.
</p>

<hr>
<h2 id='h2o.getFrame'>Get an R Reference to an H2O Dataset, that will NOT be GC'd by default</h2><span id='topic+h2o.getFrame'></span>

<h3>Description</h3>

<p>Get the reference to a frame with the given id in the H2O instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getFrame(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getFrame_+3A_id">id</code></td>
<td>
<p>A string indicating the unique frame of the dataset to retrieve.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
train &lt;- h2o.importFile(f)
y &lt;- "species"
x &lt;- setdiff(names(train), y)
train[, y] &lt;- as.factor(train[, y])
nfolds &lt;- 5
num_base_models &lt;- 2
my_gbm &lt;- h2o.gbm(x = x, y = y, training_frame = train, 
                  distribution = "multinomial", ntrees = 10, 
                  max_depth = 3, min_rows = 2, learn_rate = 0.2, 
                  nfolds = nfolds, fold_assignment = "Modulo", 
                  keep_cross_validation_predictions = TRUE, seed = 1)
my_rf &lt;- h2o.randomForest(x = x, y = y, training_frame = train, 
                          ntrees = 50, nfolds = nfolds, fold_assignment = "Modulo", 
                          keep_cross_validation_predictions = TRUE, seed = 1)
stack &lt;- h2o.stackedEnsemble(x = x, y = y, training_frame = train, 
                             model_id = "my_ensemble_l1", 
                             base_models = list(my_gbm@model_id, my_rf@model_id), 
                             keep_levelone_frame = TRUE)
h2o.getFrame(stack@model$levelone_frame_id$name)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getGLMFullRegularizationPath'>Extract full regularization path from a GLM model</h2><span id='topic+h2o.getGLMFullRegularizationPath'></span>

<h3>Description</h3>

<p>Extract the full regularization path from a GLM model (assuming it was run with the lambda search option).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getGLMFullRegularizationPath(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getGLMFullRegularizationPath_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.getGrid'>Get a grid object from H2O distributed K/V store.</h2><span id='topic+h2o.getGrid'></span>

<h3>Description</h3>

<p>Note that if neither cross-validation nor a 
validation frame is used in the grid search, then the training metrics will display in the 
&quot;get grid&quot; output. If a validation frame is passed to the grid, and nfolds = 0, then the 
validation metrics will display. However, if nfolds &gt; 1, then cross-validation metrics will 
display even if a validation frame is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getGrid(grid_id, sort_by, decreasing, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getGrid_+3A_grid_id">grid_id</code></td>
<td>
<p>ID of existing grid object to fetch</p>
</td></tr>
<tr><td><code id="h2o.getGrid_+3A_sort_by">sort_by</code></td>
<td>
<p>Sort the models in the grid space by a metric. Choices are &quot;logloss&quot;, &quot;residual_deviance&quot;, &quot;mse&quot;, &quot;auc&quot;, &quot;accuracy&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;f1&quot;, etc.</p>
</td></tr>
<tr><td><code id="h2o.getGrid_+3A_decreasing">decreasing</code></td>
<td>
<p>Specify whether sort order should be decreasing</p>
</td></tr>
<tr><td><code id="h2o.getGrid_+3A_verbose">verbose</code></td>
<td>
<p>Controls verbosity of the output, if enabled prints out error messages for failed models (default: FALSE)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
library(jsonlite)
h2o.init()
iris_hf &lt;- as.h2o(iris)
h2o.grid("gbm", grid_id = "gbm_grid_id", x = c(1:4), y = 5,
         training_frame = iris_hf, hyper_params = list(ntrees = c(1, 2, 3)))
grid &lt;- h2o.getGrid("gbm_grid_id")
# Get grid summary
summary(grid)
# Fetch grid models
model_ids &lt;- grid@model_ids
models &lt;- lapply(model_ids, function(id) { h2o.getModel(id)})

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getId'>Get back-end distributed key/value store id from an H2OFrame.</h2><span id='topic+h2o.getId'></span>

<h3>Description</h3>

<p>Get back-end distributed key/value store id from an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getId(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getId_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The id of the H2OFrame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.getId(iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getLambdaBest'>Extract best lambda value found from glm model.</h2><span id='topic+h2o.getLambdaBest'></span>

<h3>Description</h3>

<p>This function allows setting betas of an existing glm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getLambdaBest(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getLambdaBest_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.getLambdaMax'>Extract the maximum lambda value used during lambda search from glm model.</h2><span id='topic+h2o.getLambdaMax'></span>

<h3>Description</h3>

<p>This function allows setting betas of an existing glm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getLambdaMax(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getLambdaMax_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.getLambdaMin'>Extract the minimum lambda value calculated during lambda search from glm model.
Note that due to early stop, this minimum lambda value may not be used in the actual lambda search.</h2><span id='topic+h2o.getLambdaMin'></span>

<h3>Description</h3>

<p>This function allows setting betas of an existing glm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getLambdaMin(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getLambdaMin_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.getModel'>Get an R reference to an H2O model</h2><span id='topic+h2o.getModel'></span>

<h3>Description</h3>

<p>Returns a reference to an existing model in the H2O instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getModel(model_id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getModel_+3A_model_id">model_id</code></td>
<td>
<p>A string indicating the unique model_id of the model to retrieve.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object that is a subclass of <a href="#topic+H2OModel-class">H2OModel</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
model_id &lt;- h2o.gbm(x = 1:4, y = 5, training_frame = iris_hf)@model_id
model_retrieved &lt;- h2o.getModel(model_id)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getModelTree'>Fetchces a single tree of a H2O model. This function is intended to be used on Gradient Boosting Machine models or Distributed Random Forest models.</h2><span id='topic+h2o.getModelTree'></span>

<h3>Description</h3>

<p>Fetchces a single tree of a H2O model. This function is intended to be used on Gradient Boosting Machine models or Distributed Random Forest models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getModelTree(
  model,
  tree_number,
  tree_class = NA,
  plain_language_rules = "AUTO"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getModelTree_+3A_model">model</code></td>
<td>
<p>Model with trees</p>
</td></tr>
<tr><td><code id="h2o.getModelTree_+3A_tree_number">tree_number</code></td>
<td>
<p>Number of the tree in the model to fetch, starting with 1</p>
</td></tr>
<tr><td><code id="h2o.getModelTree_+3A_tree_class">tree_class</code></td>
<td>
<p>Name of the class of the tree (if applicable). This value is ignored for regression and binomial response column, as there is only one tree built.
As there is exactly one class per categorical level, name of tree's class equals to the corresponding categorical level of response column.</p>
</td></tr>
<tr><td><code id="h2o.getModelTree_+3A_plain_language_rules">plain_language_rules</code></td>
<td>
<p>(Optional) Whether to generate plain language rules. AUTO by default, meaning FALSE for big trees and TRUE for small trees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OTree object with detailed information about a tree.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
gbm_model &lt;- h2o.gbm(y = "species", training_frame = iris)
tree &lt;- h2o.getModelTree(gbm_model, 1, "Iris-setosa")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getTimezone'>Get the Time Zone on the H2O cluster
Returns a string</h2><span id='topic+h2o.getTimezone'></span>

<h3>Description</h3>

<p>Get the Time Zone on the H2O cluster
Returns a string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getTimezone()
</code></pre>

<hr>
<h2 id='h2o.getTypes'>Get the types-per-column</h2><span id='topic+h2o.getTypes'></span>

<h3>Description</h3>

<p>Get the types-per-column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getTypes(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.getTypes_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of types per column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.getTypes(iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.getVersion'>Get h2o version</h2><span id='topic+h2o.getVersion'></span>

<h3>Description</h3>

<p>Get h2o version
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.getVersion()
</code></pre>

<hr>
<h2 id='h2o.giniCoef'>Retrieve the GINI Coefficcient</h2><span id='topic+h2o.giniCoef'></span>

<h3>Description</h3>

<p>Retrieves the GINI coefficient from an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training GINIvalue is returned. If more
than one parameter is set to TRUE, then a named vector of GINIs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.giniCoef(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.giniCoef_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.giniCoef_+3A_train">train</code></td>
<td>
<p>Retrieve the training GINI Coefficcient</p>
</td></tr>
<tr><td><code id="h2o.giniCoef_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation GINI Coefficcient</p>
</td></tr>
<tr><td><code id="h2o.giniCoef_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation GINI Coefficcient</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.auc">h2o.auc</a></code> for AUC,  <code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the
GINI coefficient, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the various
threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating 
H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.giniCoef(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.glm'>Fit a generalized linear model</h2><span id='topic+h2o.glm'></span>

<h3>Description</h3>

<p>Fits a generalized linear model, specified by a response variable, a set of predictors, and a
description of the error distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.glm(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  checkpoint = NULL,
  export_checkpoints_dir = NULL,
  seed = -1,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  random_columns = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  score_iteration_interval = -1,
  offset_column = NULL,
  weights_column = NULL,
  family = c("AUTO", "gaussian", "binomial", "fractionalbinomial", "quasibinomial",
    "ordinal", "multinomial", "poisson", "gamma", "tweedie", "negativebinomial"),
  rand_family = c("[gaussian]"),
  tweedie_variance_power = 0,
  tweedie_link_power = 1,
  theta = 1e-10,
  solver = c("AUTO", "IRLSM", "L_BFGS", "COORDINATE_DESCENT_NAIVE", "COORDINATE_DESCENT",
    "GRADIENT_DESCENT_LH", "GRADIENT_DESCENT_SQERR"),
  alpha = NULL,
  lambda = NULL,
  lambda_search = FALSE,
  early_stopping = TRUE,
  nlambdas = -1,
  standardize = TRUE,
  missing_values_handling = c("MeanImputation", "Skip", "PlugValues"),
  plug_values = NULL,
  compute_p_values = FALSE,
  dispersion_parameter_method = c("deviance", "pearson", "ml"),
  init_dispersion_parameter = 1,
  remove_collinear_columns = FALSE,
  intercept = TRUE,
  non_negative = FALSE,
  max_iterations = -1,
  objective_epsilon = -1,
  beta_epsilon = 1e-04,
  gradient_epsilon = -1,
  link = c("family_default", "identity", "logit", "log", "inverse", "tweedie", "ologit"),
  rand_link = c("[identity]", "[family_default]"),
  startval = NULL,
  calc_like = FALSE,
  HGLM = FALSE,
  prior = -1,
  cold_start = FALSE,
  lambda_min_ratio = -1,
  beta_constraints = NULL,
  max_active_predictors = -1,
  interactions = NULL,
  interaction_pairs = NULL,
  obj_reg = -1,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = 0,
  custom_metric_func = NULL,
  generate_scoring_history = FALSE,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  dispersion_epsilon = 1e-04,
  tweedie_epsilon = 8e-17,
  max_iterations_dispersion = 3000,
  build_null_model = FALSE,
  fix_dispersion_parameter = FALSE,
  generate_variable_inflation_factors = FALSE,
  fix_tweedie_variance_power = TRUE,
  dispersion_learning_rate = 0.5,
  influence = c("dfbetas"),
  gainslift_bins = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.glm_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Model checkpoint to resume training with.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_random_columns">random_columns</code></td>
<td>
<p>random columns indices for HGLM.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_score_iteration_interval">score_iteration_interval</code></td>
<td>
<p>Perform scoring for every score_iteration_interval iterations Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_family">family</code></td>
<td>
<p>Family. Use binomial for classification with logistic regression, others are for regression problems. Must be
one of: &quot;AUTO&quot;, &quot;gaussian&quot;, &quot;binomial&quot;, &quot;fractionalbinomial&quot;, &quot;quasibinomial&quot;, &quot;ordinal&quot;, &quot;multinomial&quot;,
&quot;poisson&quot;, &quot;gamma&quot;, &quot;tweedie&quot;, &quot;negativebinomial&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_rand_family">rand_family</code></td>
<td>
<p>Random Component Family array.  One for each random component. Only support gaussian for now. Must be one of:
&quot;[gaussian]&quot;.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_tweedie_variance_power">tweedie_variance_power</code></td>
<td>
<p>Tweedie variance power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_tweedie_link_power">tweedie_link_power</code></td>
<td>
<p>Tweedie link power Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_theta">theta</code></td>
<td>
<p>Theta Defaults to 1e-10.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_solver">solver</code></td>
<td>
<p>AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small
number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many
columns. Must be one of: &quot;AUTO&quot;, &quot;IRLSM&quot;, &quot;L_BFGS&quot;, &quot;COORDINATE_DESCENT_NAIVE&quot;, &quot;COORDINATE_DESCENT&quot;,
&quot;GRADIENT_DESCENT_LH&quot;, &quot;GRADIENT_DESCENT_SQERR&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_alpha">alpha</code></td>
<td>
<p>Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha
represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the
amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_lambda">lambda</code></td>
<td>
<p>Regularization strength</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_lambda_search">lambda_search</code></td>
<td>
<p><code>Logical</code>. Use lambda search starting at lambda max, given lambda is then interpreted as lambda min
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_early_stopping">early_stopping</code></td>
<td>
<p><code>Logical</code>. Stop early when there is no more relative improvement on train or validation (if provided)
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_nlambdas">nlambdas</code></td>
<td>
<p>Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,
the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.
Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize numeric columns to have zero mean and unit variance Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_missing_values_handling">missing_values_handling</code></td>
<td>
<p>Handling of missing values. Either MeanImputation, Skip or PlugValues. Must be one of: &quot;MeanImputation&quot;,
&quot;Skip&quot;, &quot;PlugValues&quot;. Defaults to MeanImputation.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_plug_values">plug_values</code></td>
<td>
<p>Plug Values (a single row frame containing values that will be used to impute missing values of the
training/validation frame, use with conjunction missing_values_handling = PlugValues)</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_compute_p_values">compute_p_values</code></td>
<td>
<p><code>Logical</code>. Request p-values computation, p-values work only with IRLSM solver and no regularization
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_dispersion_parameter_method">dispersion_parameter_method</code></td>
<td>
<p>Method used to estimate the dispersion parameter for Tweedie, Gamma and Negative Binomial only. Must be one
of: &quot;deviance&quot;, &quot;pearson&quot;, &quot;ml&quot;. Defaults to pearson.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_init_dispersion_parameter">init_dispersion_parameter</code></td>
<td>
<p>Only used for Tweedie, Gamma and Negative Binomial GLM.  Store the initial value of dispersion parameter.  If
fix_dispersion_parameter is set, this value will be used in the calculation of p-values.Default to 1.0.
Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_remove_collinear_columns">remove_collinear_columns</code></td>
<td>
<p><code>Logical</code>. In case of linearly dependent columns, remove some of the dependent columns Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_intercept">intercept</code></td>
<td>
<p><code>Logical</code>. Include constant term in the model Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_non_negative">non_negative</code></td>
<td>
<p><code>Logical</code>. Restrict coefficients (not intercept) to be non-negative Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_objective_epsilon">objective_epsilon</code></td>
<td>
<p>Converge if  objective value changes less than this. Default (of -1.0) indicates: If lambda_search is set to
True the value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal
to zero, the value of objective_epsilon is set to .000001, for any other value of lambda the default value of
objective_epsilon is set to .0001. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_beta_epsilon">beta_epsilon</code></td>
<td>
<p>Converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver
Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_gradient_epsilon">gradient_epsilon</code></td>
<td>
<p>Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default
(of -1.0) indicates: If lambda_search is set to False and lambda is equal to zero, the default value of
gradient_epsilon is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True,
the conditional values above are 1E-8 and 1E-6 respectively. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_link">link</code></td>
<td>
<p>Link function. Must be one of: &quot;family_default&quot;, &quot;identity&quot;, &quot;logit&quot;, &quot;log&quot;, &quot;inverse&quot;, &quot;tweedie&quot;, &quot;ologit&quot;.
Defaults to family_default.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_rand_link">rand_link</code></td>
<td>
<p>Link function array for random component in HGLM. Must be one of: &quot;[identity]&quot;, &quot;[family_default]&quot;.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_startval">startval</code></td>
<td>
<p>double array to initialize fixed and random coefficients for HGLM, coefficients for GLM.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_calc_like">calc_like</code></td>
<td>
<p><code>Logical</code>. if true, will return likelihood function value. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_hglm">HGLM</code></td>
<td>
<p><code>Logical</code>. If set to true, will return HGLM model.  Otherwise, normal GLM model will be returned Defaults
to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_prior">prior</code></td>
<td>
<p>Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean
of response does not reflect reality. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_cold_start">cold_start</code></td>
<td>
<p><code>Logical</code>. Only applicable to multiple alpha/lambda values.  If false, build the next model for next set
of alpha/lambda values starting from the values provided by current model.  If true will start GLM model from
scratch. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>Minimum lambda used in lambda search, specified as a ratio of lambda_max (the smallest lambda that drives all
coefficients to zero). Default indicates: if the number of observations is greater than the number of
variables, then lambda_min_ratio is set to 0.0001; if the number of observations is less than the number of
variables, then lambda_min_ratio is set to 0.01. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_beta_constraints">beta_constraints</code></td>
<td>
<p>Beta constraints</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_max_active_predictors">max_active_predictors</code></td>
<td>
<p>Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model
building with many predictors. Default indicates: If the IRLSM solver is used, the value of
max_active_predictors is set to 5000 otherwise it is set to 100000000. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_interactions">interactions</code></td>
<td>
<p>A list of predictor column indices to interact. All pairwise combinations will be computed for the list.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_interaction_pairs">interaction_pairs</code></td>
<td>
<p>A list of pairwise (first order) column interactions.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_obj_reg">obj_reg</code></td>
<td>
<p>Likelihood divider in objective value computation, default (of -1.0) will set it to 1/nobs Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_generate_scoring_history">generate_scoring_history</code></td>
<td>
<p><code>Logical</code>. If set to true, will generate scoring history for GLM.  This may significantly slow down the
algo. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_dispersion_epsilon">dispersion_epsilon</code></td>
<td>
<p>If changes in dispersion parameter estimation or loglikelihood value is smaller than dispersion_epsilon, will
break out of the dispersion parameter estimation loop using maximum likelihood. Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_tweedie_epsilon">tweedie_epsilon</code></td>
<td>
<p>In estimating tweedie dispersion parameter using maximum likelihood, this is used to choose the lower and
upper indices in the approximating of the infinite series summation. Defaults to 8e-17.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_max_iterations_dispersion">max_iterations_dispersion</code></td>
<td>
<p>Control the maximum number of iterations in the dispersion parameter estimation loop using maximum likelihood.
Defaults to 3000.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_build_null_model">build_null_model</code></td>
<td>
<p><code>Logical</code>. If set, will build a model with only the intercept.  Default to false. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_fix_dispersion_parameter">fix_dispersion_parameter</code></td>
<td>
<p><code>Logical</code>. Only used for Tweedie, Gamma and Negative Binomial GLM.  If set, will use the dispsersion
parameter in init_dispersion_parameter as the standard error and use it to calculate the p-values. Default to
false. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_generate_variable_inflation_factors">generate_variable_inflation_factors</code></td>
<td>
<p><code>Logical</code>. if true, will generate variable inflation factors for numerical predictors.  Default to false.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_fix_tweedie_variance_power">fix_tweedie_variance_power</code></td>
<td>
<p><code>Logical</code>. If true, will fix tweedie variance power value to the value set in tweedie_variance_power.
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_dispersion_learning_rate">dispersion_learning_rate</code></td>
<td>
<p>Dispersion learning rate is only valid for tweedie family dispersion parameter estimation using ml. It must be
&gt; 0.  This controls how much the dispersion parameter estimate is to be changed when the calculated
loglikelihood actually decreases with the new dispersion.  In this case, instead of setting new dispersion =
dispersion + change, we set new dispersion = dispersion + dispersion_learning_rate * change. Defaults to 0.5.
Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_influence">influence</code></td>
<td>
<p>If set to dfbetas will calculate the difference in beta when a datarow is included and excluded in the
dataset. Must be one of: &quot;dfbetas&quot;.</p>
</td></tr>
<tr><td><code id="h2o.glm_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A subclass of <code><a href="#topic+H2OModel-class">H2OModel</a></code> is returned. The specific subclass depends on the machine
learning task at hand (if it's binomial classification, then an <code><a href="#topic+H2OBinomialModel-class">H2OBinomialModel</a></code> is
returned, if it's regression then a <code><a href="#topic+H2ORegressionModel-class">H2ORegressionModel</a></code> is returned). The default print-
out of the models is shown, but further GLM-specifc information can be queried out of the object. To access
these various items, please refer to the seealso section below. Upon completion of the GLM, the resulting
object has coefficients, normalized coefficients, residual/null deviance, aic, and a host of model metrics
including MSE, AUC (for logistic regression), degrees of freedom, and confusion matrices. Please refer to the
more in-depth GLM documentation available here:
<a href="https://h2o-release.s3.amazonaws.com/h2o-dev/rel-shannon/2/docs-website/h2o-docs/index.html#Data+Science+Algorithms-GLM">https://h2o-release.s3.amazonaws.com/h2o-dev/rel-shannon/2/docs-website/h2o-docs/index.html#Data+Science+Algorithms-GLM</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction, <code><a href="#topic+h2o.mse">h2o.mse</a></code>, <code><a href="#topic+h2o.auc">h2o.auc</a></code>,
<code><a href="#topic+h2o.confusionMatrix">h2o.confusionMatrix</a></code>, <code><a href="#topic+h2o.performance">h2o.performance</a></code>, <code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code>,
<code><a href="#topic+h2o.logloss">h2o.logloss</a></code>, <code><a href="#topic+h2o.varimp">h2o.varimp</a></code>, <code><a href="#topic+h2o.scoreHistory">h2o.scoreHistory</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Run GLM of CAPSULE ~ AGE + RACE + PSA + DCAPS
prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), training_frame = prostate,
        family = "binomial", nfolds = 0, alpha = 0.5, lambda_search = FALSE)

# Run GLM of VOL ~ CAPSULE + AGE + RACE + PSA + GLEASON
predictors = setdiff(colnames(prostate), c("ID", "DPROS", "DCAPS", "VOL"))
h2o.glm(y = "VOL", x = predictors, training_frame = prostate, family = "gaussian",
        nfolds = 0, alpha = 0.1, lambda_search = FALSE)


# GLM variable importance
# Also see:
#   https://github.com/h2oai/h2o/blob/master/R/tests/testdir_demos/runit_demo_VI_all_algos.R
bank = h2o.importFile(
  path="https://s3.amazonaws.com/h2o-public-test-data/smalldata/demos/bank-additional-full.csv"
)
predictors = 1:20
target = "y"
glm = h2o.glm(x = predictors, 
              y = target, 
              training_frame = bank, 
              family = "binomial", 
              standardize = TRUE,
              lambda_search = TRUE)
h2o.std_coef_plot(glm, num_of_features = 20)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.glrm'>Generalized low rank decomposition of an H2O data frame</h2><span id='topic+h2o.glrm'></span>

<h3>Description</h3>

<p>Builds a generalized low rank decomposition of an H2O data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.glrm(
  training_frame,
  cols = NULL,
  model_id = NULL,
  validation_frame = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  representation_name = NULL,
  loading_name = NULL,
  transform = c("NONE", "STANDARDIZE", "NORMALIZE", "DEMEAN", "DESCALE"),
  k = 1,
  loss = c("Quadratic", "Absolute", "Huber", "Poisson", "Hinge", "Logistic", "Periodic"),
  loss_by_col = c("Quadratic", "Absolute", "Huber", "Poisson", "Hinge", "Logistic",
    "Periodic", "Categorical", "Ordinal"),
  loss_by_col_idx = NULL,
  multi_loss = c("Categorical", "Ordinal"),
  period = 1,
  regularization_x = c("None", "Quadratic", "L2", "L1", "NonNegative", "OneSparse",
    "UnitOneSparse", "Simplex"),
  regularization_y = c("None", "Quadratic", "L2", "L1", "NonNegative", "OneSparse",
    "UnitOneSparse", "Simplex"),
  gamma_x = 0,
  gamma_y = 0,
  max_iterations = 1000,
  max_updates = 2000,
  init_step_size = 1,
  min_step_size = 1e-04,
  seed = -1,
  init = c("Random", "SVD", "PlusPlus", "User"),
  svd_method = c("GramSVD", "Power", "Randomized"),
  user_y = NULL,
  user_x = NULL,
  expand_user_y = TRUE,
  impute_original = FALSE,
  recover_svd = FALSE,
  max_runtime_secs = 0,
  export_checkpoints_dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.glrm_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_cols">cols</code></td>
<td>
<p>(Optional) A vector containing the data columns on which k-means operates.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_representation_name">representation_name</code></td>
<td>
<p>Frame key to save resulting X</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_loading_name">loading_name</code></td>
<td>
<p>[Deprecated] Use representation_name instead.  Frame key to save resulting X.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_transform">transform</code></td>
<td>
<p>Transformation of training data Must be one of: &quot;NONE&quot;, &quot;STANDARDIZE&quot;, &quot;NORMALIZE&quot;, &quot;DEMEAN&quot;, &quot;DESCALE&quot;.
Defaults to NONE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_k">k</code></td>
<td>
<p>Rank of matrix approximation Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_loss">loss</code></td>
<td>
<p>Numeric loss function Must be one of: &quot;Quadratic&quot;, &quot;Absolute&quot;, &quot;Huber&quot;, &quot;Poisson&quot;, &quot;Hinge&quot;, &quot;Logistic&quot;,
&quot;Periodic&quot;. Defaults to Quadratic.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_loss_by_col">loss_by_col</code></td>
<td>
<p>Loss function by column (override) Must be one of: &quot;Quadratic&quot;, &quot;Absolute&quot;, &quot;Huber&quot;, &quot;Poisson&quot;, &quot;Hinge&quot;,
&quot;Logistic&quot;, &quot;Periodic&quot;, &quot;Categorical&quot;, &quot;Ordinal&quot;.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_loss_by_col_idx">loss_by_col_idx</code></td>
<td>
<p>Loss function by column index (override)</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_multi_loss">multi_loss</code></td>
<td>
<p>Categorical loss function Must be one of: &quot;Categorical&quot;, &quot;Ordinal&quot;. Defaults to Categorical.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_period">period</code></td>
<td>
<p>Length of period (only used with periodic loss function) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_regularization_x">regularization_x</code></td>
<td>
<p>Regularization function for X matrix Must be one of: &quot;None&quot;, &quot;Quadratic&quot;, &quot;L2&quot;, &quot;L1&quot;, &quot;NonNegative&quot;,
&quot;OneSparse&quot;, &quot;UnitOneSparse&quot;, &quot;Simplex&quot;. Defaults to None.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_regularization_y">regularization_y</code></td>
<td>
<p>Regularization function for Y matrix Must be one of: &quot;None&quot;, &quot;Quadratic&quot;, &quot;L2&quot;, &quot;L1&quot;, &quot;NonNegative&quot;,
&quot;OneSparse&quot;, &quot;UnitOneSparse&quot;, &quot;Simplex&quot;. Defaults to None.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_gamma_x">gamma_x</code></td>
<td>
<p>Regularization weight on X matrix Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_gamma_y">gamma_y</code></td>
<td>
<p>Regularization weight on Y matrix Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations Defaults to 1000.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_max_updates">max_updates</code></td>
<td>
<p>Maximum number of updates, defaults to 2*max_iterations Defaults to 2000.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_init_step_size">init_step_size</code></td>
<td>
<p>Initial step size Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_min_step_size">min_step_size</code></td>
<td>
<p>Minimum step size Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_init">init</code></td>
<td>
<p>Initialization mode Must be one of: &quot;Random&quot;, &quot;SVD&quot;, &quot;PlusPlus&quot;, &quot;User&quot;. Defaults to PlusPlus.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_svd_method">svd_method</code></td>
<td>
<p>Method for computing SVD during initialization (Caution: Randomized is currently experimental and unstable)
Must be one of: &quot;GramSVD&quot;, &quot;Power&quot;, &quot;Randomized&quot;. Defaults to Randomized.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_user_y">user_y</code></td>
<td>
<p>User-specified initial Y</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_user_x">user_x</code></td>
<td>
<p>User-specified initial X</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_expand_user_y">expand_user_y</code></td>
<td>
<p><code>Logical</code>. Expand categorical columns in user-specified initial Y Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_impute_original">impute_original</code></td>
<td>
<p><code>Logical</code>. Reconstruct original training data by reversing transform Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_recover_svd">recover_svd</code></td>
<td>
<p><code>Logical</code>. Recover singular values and eigenvectors of XY Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.glrm_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a>.
</p>


<h3>References</h3>

<p>M. Udell, C. Horn, R. Zadeh, S. Boyd (2014). Generalized Low Rank Models[https://arxiv.org/abs/1410.0342]. Unpublished manuscript, Stanford Electrical Engineering Department.
N. Halko, P.G. Martinsson, J.A. Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions[https://arxiv.org/abs/0909.4061]. SIAM Rev., Survey and Review section, Vol. 53, num. 2, pp. 217-288, June 2011.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.kmeans">h2o.kmeans</a>, <a href="#topic+h2o.svd">h2o.svd</a></code>, <code><a href="#topic+h2o.prcomp">h2o.prcomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.uploadFile(path = australia_path)
h2o.glrm(training_frame = australia, k = 5, loss = "Quadratic", regularization_x = "L1",
         gamma_x = 0.5, gamma_y = 0, max_iterations = 1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.grep'>Search for matches to an argument pattern</h2><span id='topic+h2o.grep'></span>

<h3>Description</h3>

<p>Searches for matches to argument 'pattern' within each element
of a string column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.grep(
  pattern,
  x,
  ignore.case = FALSE,
  invert = FALSE,
  output.logical = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.grep_+3A_pattern">pattern</code></td>
<td>
<p>A character string containing a regular expression.</p>
</td></tr>
<tr><td><code id="h2o.grep_+3A_x">x</code></td>
<td>
<p>An H2O frame that wraps a single string column.</p>
</td></tr>
<tr><td><code id="h2o.grep_+3A_ignore.case">ignore.case</code></td>
<td>
<p>If TRUE case is ignored during matching.</p>
</td></tr>
<tr><td><code id="h2o.grep_+3A_invert">invert</code></td>
<td>
<p>Identify elements that do not match the pattern.</p>
</td></tr>
<tr><td><code id="h2o.grep_+3A_output.logical">output.logical</code></td>
<td>
<p>If TRUE returns logical vector of indicators instead of list of matching positions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has similar semantics as R's native grep function
and it supports a subset of its parameters. Default behavior is
to return indices of the elements matching the pattern. Parameter
'output.logical' can be used to return a logical vector indicating
if the element matches the pattern (1) or not (0).
</p>


<h3>Value</h3>

<p>H2OFrame holding the matching positions or a logical vector
if 'output.logical' is enabled.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
addresses &lt;- as.h2o(c("2307", "Leghorn St", "Mountain View", "CA", "94043"))
zip_codes &lt;- addresses[h2o.grep("[0-9]{5}", addresses, output.logical = TRUE),]

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.grid'>H2O Grid Support</h2><span id='topic+h2o.grid'></span>

<h3>Description</h3>

<p>Provides a set of functions to launch a grid search and get
its results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.grid(
  algorithm,
  grid_id,
  x,
  y,
  training_frame,
  ...,
  hyper_params = list(),
  is_supervised = NULL,
  do_hyper_params_check = FALSE,
  search_criteria = NULL,
  export_checkpoints_dir = NULL,
  recovery_dir = NULL,
  parallelism = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.grid_+3A_algorithm">algorithm</code></td>
<td>
<p>Name of algorithm to use in grid search (gbm, randomForest, kmeans, glm, deeplearning, naivebayes, pca).</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_grid_id">grid_id</code></td>
<td>
<p>(Optional) ID for resulting grid search. If it is not specified then it is autogenerated.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. The response must be either a numeric or a
categorical/factor variable. If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_...">...</code></td>
<td>
<p>arguments describing parameters to use with algorithm (i.e., x, y, training_frame).
Look at the specific algorithm - h2o.gbm, h2o.glm, h2o.kmeans, h2o.deepLearning - for available parameters.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_hyper_params">hyper_params</code></td>
<td>
<p>List of lists of hyper parameters (i.e., <code>list(ntrees=c(1,2), max_depth=c(5,7))</code>).</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_is_supervised">is_supervised</code></td>
<td>
<p>[Deprecated] It is not possible to override default behaviour. (Optional) If specified then override the default heuristic which decides if the given algorithm
name and parameters specify a supervised or unsupervised algorithm.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_do_hyper_params_check">do_hyper_params_check</code></td>
<td>
<p>Perform client check for specified hyper parameters. It can be time expensive for
large hyper space.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_search_criteria">search_criteria</code></td>
<td>
<p>(Optional)  List of control parameters for smarter hyperparameter search.  The list can 
include values for: strategy, max_models, max_runtime_secs, stopping_metric, stopping_tolerance, stopping_rounds and
seed.  The default strategy 'Cartesian' covers the entire space of hyperparameter combinations.  If you want to use
cartesian grid search, you can leave the search_criteria argument unspecified. Specify the &quot;RandomDiscrete&quot; strategy
to get random search of all the combinations of your hyperparameters with three ways of specifying when to stop the
search: max number of models, max time, and metric-based early stopping (e.g., stop if MSE has not improved by 0.0001
over the 5 best models). Examples below:
<code>list(strategy = "RandomDiscrete", max_runtime_secs = 600, max_models = 100, stopping_metric = "AUTO",
stopping_tolerance = 0.00001, stopping_rounds = 5, seed = 123456)</code> or <code>list(strategy = "RandomDiscrete", 
max_models = 42, max_runtime_secs = 28800)</code> or <code>list(strategy = "RandomDiscrete", stopping_metric = "AUTO", 
stopping_tolerance = 0.001, stopping_rounds = 10)</code> or <code>list(strategy = "RandomDiscrete", stopping_metric = 
"misclassification", stopping_tolerance = 0.00001, stopping_rounds = 5)</code>.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Directory to automatically export grid and its models to.</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_recovery_dir">recovery_dir</code></td>
<td>
<p>When specified the grid and all necessary data (frames, models) will be saved to this
directory (use HDFS or other distributed file-system). Should the cluster crash during training, the grid
can be reloaded from this directory via <code>h2o.loadGrid</code> and training can be resumed</p>
</td></tr>
<tr><td><code id="h2o.grid_+3A_parallelism">parallelism</code></td>
<td>
<p>Level of Parallelism during grid model building. 1 = sequential building (default).
Use the value of 0 for adaptive parallelism - decided by H2O. Any number &gt; 1 sets the exact number of models built in parallel.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Launch grid search with given algorithm and parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
library(jsonlite)
h2o.init()
iris_hf &lt;- as.h2o(iris)
grid &lt;- h2o.grid("gbm", x = c(1:4), y = 5, training_frame = iris_hf,
                 hyper_params = list(ntrees = c(1, 2, 3)))
# Get grid summary
summary(grid)
# Fetch grid models
model_ids &lt;- grid@model_ids
models &lt;- lapply(model_ids, function(id) { h2o.getModel(id)})

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.group_by'>Group and Apply by Column</h2><span id='topic+h2o.group_by'></span>

<h3>Description</h3>

<p>Performs a group by and apply similar to ddply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.group_by(
  data,
  by,
  ...,
  gb.control = list(na.methods = NULL, col.names = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.group_by_+3A_data">data</code></td>
<td>
<p>an H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.group_by_+3A_by">by</code></td>
<td>
<p>a list of column names</p>
</td></tr>
<tr><td><code id="h2o.group_by_+3A_...">...</code></td>
<td>
<p>any supported aggregate function. See <code>Details:</code> for more help.</p>
</td></tr>
<tr><td><code id="h2o.group_by_+3A_gb.control">gb.control</code></td>
<td>
<p>a list of how to handle <code>NA</code> values in the dataset as well as how to name
output columns. The method is specified using the <code>rm.method</code> argument. See 
<code>Details:</code> for more help.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of <code>na.methods</code> within <code>gb.control</code>, there are three possible settings.
<code>"all"</code> will include <code>NAs</code> in computation of functions. <code>"rm"</code> will completely
remove all <code>NA</code> fields. <code>"ignore"</code> will remove <code>NAs</code> from the numerator but keep
the rows for computational purposes. If a list smaller than the number of columns groups is
supplied, the list will be padded by <code>"ignore"</code>. 
</p>
<p>Note that to specify a list of column names in the <code>gb.control</code> list, you must add the 
<code>col.names</code> argument. Similar to <code>na.methods</code>, <code>col.names</code> will pad the list with 
the default column names if the length is less than the number of colums groups supplied. 
</p>
<p>Supported functions include <code>nrow</code>. This function is required and accepts a string for the 
name of the generated column. Other supported aggregate functions accept <code>col</code> and <code>na</code> 
arguments for specifying columns and the handling of NAs (<code>"all"</code>, <code>"ignore"</code>, and 
GroupBy object; <code>max</code> calculates the maximum of each column specified in <code>col</code> for each 
group of a GroupBy object; <code>mean</code> calculates the mean of each column specified in <code>col</code> 
for each group of a GroupBy object; <code>min</code> calculates the minimum of each column specified in 
<code>col</code> for each group of a GroupBy object; <code>mode</code> calculates the mode of each column 
specified in <code>col</code> for each group of a GroupBy object; <code>sd</code> calculates the standard 
deviation of each column specified in <code>col</code> for each group of a GroupBy object; <code>ss</code> 
calculates the sum of squares of each column specified in <code>col</code> for each group of a GroupBy 
object; <code>sum</code> calculates the sum of each column specified in <code>col</code> for each group of a 
GroupBy object; and <code>var</code> calculates the variance of each column specified in <code>col</code> for 
each group of a GroupBy object. If an aggregate is provided without a value (for example, as 
<code>max</code> in <code>sum(col="X1", na="all").mean(col="X5", na="all").max()</code>), then it is assumed 
that the aggregation should apply to all columns except the GroupBy columns. However, operations
will not be performed on String columns.  They will be skipped.  Note again that
<code>nrow</code> is required and cannot be empty.
</p>


<h3>Value</h3>

<p>Returns a new H2OFrame object with columns equivalent to the number of
groups created
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- h2o.importFile(paste("https://s3.amazonaws.com/h2o-public-test-data",
                           "/smalldata/prostate/prostate.csv", 
                           sep=""))
h2o.group_by(data = df, by = "RACE", nrow("VOL"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.gsub'>String Global Substitute</h2><span id='topic+h2o.gsub'></span>

<h3>Description</h3>

<p>Creates a copy of the target column in which each string has all occurence of
the regex pattern replaced with the replacement substring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.gsub(pattern, replacement, x, ignore.case = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.gsub_+3A_pattern">pattern</code></td>
<td>
<p>The pattern to replace.</p>
</td></tr>
<tr><td><code id="h2o.gsub_+3A_replacement">replacement</code></td>
<td>
<p>The replacement pattern.</p>
</td></tr>
<tr><td><code id="h2o.gsub_+3A_x">x</code></td>
<td>
<p>The column on which to operate.</p>
</td></tr>
<tr><td><code id="h2o.gsub_+3A_ignore.case">ignore.case</code></td>
<td>
<p>Case sensitive or not</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_gsub &lt;- as.h2o("r tutorial")
sub_string &lt;- h2o.gsub("r ", "H2O ", string_to_gsub)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.h'>Calculates Friedman and Popescu's H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.
H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a 
stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.</h2><span id='topic+h2o.h'></span>

<h3>Description</h3>

<p>This statistic can be calculated only for numerical variables. Missing values are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.h(model, frame, variables)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.h_+3A_model">model</code></td>
<td>
<p>A trained gradient-boosting model.</p>
</td></tr>
<tr><td><code id="h2o.h_+3A_frame">frame</code></td>
<td>
<p>A frame that current model has been fitted to.</p>
</td></tr>
<tr><td><code id="h2o.h_+3A_variables">variables</code></td>
<td>
<p>Variables of the interest.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Jerome H. Friedman and Bogdan E. Popescu, 2008, &quot;Predictive learning via rule ensembles&quot;, *Ann. Appl. Stat.*
**2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate.hex &lt;- h2o.importFile(
       "https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate.csv",
        destination_frame="prostate.hex"
        )
prostate.hex$CAPSULE &lt;- as.factor(prostate.hex$CAPSULE)
prostate.hex$RACE &lt;- as.factor(prostate.hex$RACE)
prostate.h2o &lt;- h2o.gbm(x = 3:9, y = "CAPSULE", training_frame = prostate.hex, 
distribution = "bernoulli", ntrees = 100, max_depth = 5, min_rows = 10, learn_rate = 0.1)
h_val &lt;- h2o.h(prostate.h2o, prostate.hex, c('DPROS','DCAPS'))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.head'>Return the Head or Tail of an H2O Dataset.</h2><span id='topic+h2o.head'></span><span id='topic+head.H2OFrame'></span><span id='topic+h2o.tail'></span><span id='topic+tail.H2OFrame'></span>

<h3>Description</h3>

<p>Returns the first or last rows of an H2OFrame object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.head(x, n = 6L, m = 200L, ...)

## S3 method for class 'H2OFrame'
head(x, n = 6L, m = 200L, ...)

h2o.tail(x, n = 6L, m = 200L, ...)

## S3 method for class 'H2OFrame'
tail(x, n = 6L, m = 200L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.head_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.head_+3A_n">n</code></td>
<td>
<p>(Optional) A single integer. If positive, number of rows in x to return. If negative, all but the n first/last number of rows in x.</p>
</td></tr>
<tr><td><code id="h2o.head_+3A_m">m</code></td>
<td>
<p>(Optional) A single integer. If positive, number of columns in x to return. If negative, all but the m first/last number of columns in x.</p>
</td></tr>
<tr><td><code id="h2o.head_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame containing the first or last n rows and m columns of an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init(ip &lt;- "localhost", port = 54321, startH2O = TRUE)
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.uploadFile(path = australia_path)
# Return the first 10 rows and 6 columns
h2o.head(australia, n = 10L, m = 6L)
# Return the last 10 rows and 6 columns
h2o.tail(australia, n = 10L, m = 6L)

# For Jupyter notebook with an R kernel,
# view all rows of a data frame
options(repr.matrix.max.rows = 600, repr.matrix.max.cols = 200)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.HGLMMetrics'>Retrieve HGLM ModelMetrics</h2><span id='topic+h2o.HGLMMetrics'></span>

<h3>Description</h3>

<p>Retrieve HGLM ModelMetrics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.HGLMMetrics(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.HGLMMetrics_+3A_object">object</code></td>
<td>
<p>an H2OModel object or H2OModelMetrics.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.hist'>Compute A Histogram</h2><span id='topic+h2o.hist'></span>

<h3>Description</h3>

<p>Compute a histogram over a numeric column. If breaks==&quot;FD&quot;, the MAD is used over the IQR
in computing bin width. Note that we do not beautify the breakpoints as R does.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.hist(x, breaks = "Sturges", plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.hist_+3A_x">x</code></td>
<td>
<p>A single numeric column from an H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.hist_+3A_breaks">breaks</code></td>
<td>
<p>Can be one of the following:
A string: &quot;Sturges&quot;, &quot;Rice&quot;, &quot;sqrt&quot;, &quot;Doane&quot;, &quot;FD&quot;, &quot;Scott&quot;
A single number for the number of breaks splitting the range of the vec into number of breaks bins of equal width
A vector of numbers giving the split points, e.g., c(-50,213.2123,9324834)</p>
</td></tr>
<tr><td><code id="h2o.hist_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether or not a plot should be generated (default is TRUE).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.asnumeric(iris["petal_len"])
h2o.hist(iris["petal_len"], breaks = "Sturges", plot = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.hit_ratio_table'>Retrieve the Hit Ratios</h2><span id='topic+h2o.hit_ratio_table'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training Hit Ratios value is returned. If more
than one parameter is set to TRUE, then a named list of Hit Ratio tables are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.hit_ratio_table(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.hit_ratio_table_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.hit_ratio_table_+3A_train">train</code></td>
<td>
<p>Retrieve the training Hit Ratio</p>
</td></tr>
<tr><td><code id="h2o.hit_ratio_table_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation Hit Ratio</p>
</td></tr>
<tr><td><code id="h2o.hit_ratio_table_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation Hit Ratio</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
iris_split &lt;- h2o.splitFrame(data = iris, ratios = 0.8, seed = 1234)
train &lt;- iris_split[[1]]
valid &lt;- iris_split[[2]]

iris_xgb &lt;- h2o.xgboost(x = 1:4, y = 5, training_frame = train, validation_frame = valid)
hrt_iris &lt;- h2o.hit_ratio_table(iris_xgb, valid = TRUE)
hrt_iris

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.hour'>Convert Milliseconds to Hour of Day in H2O Datasets</h2><span id='topic+h2o.hour'></span><span id='topic+hour'></span><span id='topic+hour.H2OFrame'></span>

<h3>Description</h3>

<p>Converts the entries of an H2OFrame object from milliseconds to hours of the day
(on a 0 to 23 scale).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.hour(x)

hour(x)

## S3 method for class 'H2OFrame'
hour(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.hour_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to hours of
the day.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.day">h2o.day</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.hour(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ice_plot'>Plot Individual Conditional Expectation (ICE) for each decile</h2><span id='topic+h2o.ice_plot'></span>

<h3>Description</h3>

<p>Individual Conditional Expectation (ICE) plot gives a graphical depiction of the marginal
effect of a variable on the response. ICE plots are similar to partial dependence plots (PDP);
PDP shows the average effect of a feature while ICE plot shows the effect for a single
instance. This function will plot the effect for each decile. In contrast to the PDP,
ICE plots can provide more insight, especially when there is stronger feature interaction.
Also, the plot shows the original observation values marked by semi-transparent circle on each ICE line.
Please note, that the score of the original observation value may differ from score value of underlying
ICE line at original observation point as ICE line is drawn as an interpolation of several points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ice_plot(
  model,
  newdata,
  column,
  target = NULL,
  max_levels = 30,
  show_pdp = TRUE,
  binary_response_scale = c("response", "logodds"),
  centered = FALSE,
  grouping_column = NULL,
  output_graphing_data = FALSE,
  nbins = 100,
  show_rug = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ice_plot_+3A_model">model</code></td>
<td>
<p>An H2OModel.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_column">column</code></td>
<td>
<p>A feature column name to inspect.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_target">target</code></td>
<td>
<p>If multinomial, plot PDP just for <code>target</code> category.  Character string.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_max_levels">max_levels</code></td>
<td>
<p>An integer specifying the maximum number of factor levels to show.
Defaults to 30.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_show_pdp">show_pdp</code></td>
<td>
<p>Option to turn on/off PDP line. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_binary_response_scale">binary_response_scale</code></td>
<td>
<p>Option for binary model to display (on the y-axis) the logodds instead of the actual
score. Can be one of: &quot;response&quot;, &quot;logodds&quot;. Defaults to &quot;response&quot;.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_centered">centered</code></td>
<td>
<p>A boolean whether to center curves around 0 at the first valid x value or not. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_grouping_column">grouping_column</code></td>
<td>
<p>A feature column name to group the data and provide separate sets of plots
by grouping feature values</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_output_graphing_data">output_graphing_data</code></td>
<td>
<p>A bool whether to output final graphing data to a frame. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_nbins">nbins</code></td>
<td>
<p>A number of bins used. Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_show_rug">show_rug</code></td>
<td>
<p>Show rug to visualize the density of the column. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.ice_plot_+3A_...">...</code></td>
<td>
<p>Custom parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the individual conditional expectations plot
ice &lt;- h2o.ice_plot(gbm, test, column = "alcohol")
print(ice)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ifelse'>H2O Apply Conditional Statement</h2><span id='topic+h2o.ifelse'></span><span id='topic+ifelse'></span>

<h3>Description</h3>

<p>Applies conditional statements to numeric vectors in H2O parsed data objects when the data are
numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ifelse(test, yes, no)

ifelse(test, yes, no)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ifelse_+3A_test">test</code></td>
<td>
<p>A logical description of the condition to be met (&gt;, &lt;, =, etc...)</p>
</td></tr>
<tr><td><code id="h2o.ifelse_+3A_yes">yes</code></td>
<td>
<p>The value to return if the condition is TRUE.</p>
</td></tr>
<tr><td><code id="h2o.ifelse_+3A_no">no</code></td>
<td>
<p>The value to return if the condition is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both numeric and categorical values can be tested. However when returning a yes and no condition
both conditions must be either both categorical or numeric.
</p>


<h3>Value</h3>

<p>Returns a vector of new values matching the conditions stated in the ifelse call.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.importFile(path = australia_path)
australia[, 9] &lt;- ifelse(australia[, 3] &lt; 279.9, 1, 0)
summary(australia)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.import_hive_table'>Import Hive Table into H2O</h2><span id='topic+h2o.import_hive_table'></span>

<h3>Description</h3>

<p>Import Hive table to H2OFrame in memory.
Make sure to start H2O with Hive on classpath. Uses hive-site.xml on classpath to connect to Hive.
When database is specified as jdbc URL uses Hive JDBC driver to obtain table metadata. then 
uses direct HDFS access to import data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.import_hive_table(
  database,
  table,
  partitions = NULL,
  allow_multi_format = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.import_hive_table_+3A_database">database</code></td>
<td>
<p>Name of Hive database (default database will be used by default), can be also a JDBC URL</p>
</td></tr>
<tr><td><code id="h2o.import_hive_table_+3A_table">table</code></td>
<td>
<p>name of Hive table to import</p>
</td></tr>
<tr><td><code id="h2o.import_hive_table_+3A_partitions">partitions</code></td>
<td>
<p>a list of lists of strings - partition key column values of partitions you want to import.</p>
</td></tr>
<tr><td><code id="h2o.import_hive_table_+3A_allow_multi_format">allow_multi_format</code></td>
<td>
<p>enable import of partitioned tables with different storage formats used. WARNING:
this may fail on out-of-memory for tables with a large number of small partitions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, 
my_citibike_data = h2o.import_hive_table(&quot;default&quot;, &quot;citibike20k&quot;, partitions = list(c(&quot;2017&quot;, &quot;01&quot;), c(&quot;2017&quot;, &quot;02&quot;)))
my_citibike_data = h2o.import_hive_table(&quot;jdbc:hive2://hive-server:10000/default&quot;, &quot;citibike20k&quot;, allow_multi_format = TRUE)
</p>

<hr>
<h2 id='h2o.import_mojo'>Imports a MOJO under given path, creating a Generic model with it.</h2><span id='topic+h2o.import_mojo'></span>

<h3>Description</h3>

<p>Usage example:
mojo_model &lt;- h2o.import_mojo(model_file_path = &quot;/path/to/mojo.zip&quot;)
predictions &lt;- h2o.predict(mojo_model, dataset)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.import_mojo(mojo_file_path, model_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.import_mojo_+3A_mojo_file_path">mojo_file_path</code></td>
<td>
<p>Filesystem path to the model imported</p>
</td></tr>
<tr><td><code id="h2o.import_mojo_+3A_model_id">model_id</code></td>
<td>
<p>Model ID, default is NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns H2O Generic Model embedding given MOJO model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Import default Iris dataset as H2O frame
data &lt;- as.h2o(iris)

# Train a very simple GBM model
features &lt;- c("Sepal.Length", "Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")
original_model &lt;- h2o.gbm(x = features, y = "Species", training_frame = data)

# Download the trained GBM model as MOJO (temporary directory used in this example)
mojo_original_path &lt;- h2o.save_mojo(original_model, path = tempdir())

# Import the MOJO and obtain a Generic model
mojo_model &lt;- h2o.import_mojo(mojo_original_path)

# Perform scoring with the generic model
predictions  &lt;- h2o.predict(mojo_model, data)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.import_sql_select'>Import SQL table that is result of SELECT SQL query into H2O</h2><span id='topic+h2o.import_sql_select'></span>

<h3>Description</h3>

<p>Creates a temporary SQL table from the specified sql_query.
Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.
Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath:
'java -cp &lt;path_to_h2o_jar&gt;:&lt;path_to_jdbc_driver_jar&gt; water.H2OApp'
Also see h2o.import_sql_table.
Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle and Microsoft SQL Server.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.import_sql_select(
  connection_url,
  select_query,
  username,
  password,
  use_temp_table = NULL,
  temp_table_name = NULL,
  optimize = NULL,
  fetch_mode = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.import_sql_select_+3A_connection_url">connection_url</code></td>
<td>
<p>URL of the SQL database connection as specified by the Java Database Connectivity (JDBC) Driver.
For example, &quot;jdbc:mysql://localhost:3306/menagerie?&amp;useSSL=false&quot;</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_select_query">select_query</code></td>
<td>
<p>SQL query starting with 'SELECT' that returns rows from one or more database tables.</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_username">username</code></td>
<td>
<p>Username for SQL server</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_password">password</code></td>
<td>
<p>Password for SQL server</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_use_temp_table">use_temp_table</code></td>
<td>
<p>Whether a temporary table should be created from select_query</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_temp_table_name">temp_table_name</code></td>
<td>
<p>Name of temporary table to be created from select_query</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_optimize">optimize</code></td>
<td>
<p>(Optional) Optimize import of SQL table for faster imports. Experimental. Default is true.</p>
</td></tr>
<tr><td><code id="h2o.import_sql_select_+3A_fetch_mode">fetch_mode</code></td>
<td>
<p>(Optional) Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read
from the database
Can be used for databases that do not support OFFSET-like clauses in SQL statements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, 
my_sql_conn_url &lt;- &quot;jdbc:mysql://172.16.2.178:3306/ingestSQL?&amp;useSSL=false&quot;
select_query &lt;- &quot;SELECT bikeid from citibike20k&quot;
username &lt;- &quot;root&quot;
password &lt;- &quot;abc123&quot;
my_citibike_data &lt;- h2o.import_sql_select(my_sql_conn_url, select_query, username, password)
</p>

<hr>
<h2 id='h2o.import_sql_table'>Import SQL Table into H2O</h2><span id='topic+h2o.import_sql_table'></span>

<h3>Description</h3>

<p>Imports SQL table into an H2O cluster. Assumes that the SQL table is not being updated and is stable.
Runs multiple SELECT SQL queries concurrently for parallel ingestion.
Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath:
'java -cp &lt;path_to_h2o_jar&gt;:&lt;path_to_jdbc_driver_jar&gt; water.H2OApp'
Also see h2o.import_sql_select.
Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, Hive, Oracle and Microsoft SQL Server.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.import_sql_table(
  connection_url,
  table,
  username,
  password,
  columns = NULL,
  optimize = NULL,
  fetch_mode = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.import_sql_table_+3A_connection_url">connection_url</code></td>
<td>
<p>URL of the SQL database connection as specified by the Java Database Connectivity (JDBC) Driver.
For example, &quot;jdbc:mysql://localhost:3306/menagerie?&amp;useSSL=false&quot;</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_table">table</code></td>
<td>
<p>Name of SQL table</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_username">username</code></td>
<td>
<p>Username for SQL server</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_password">password</code></td>
<td>
<p>Password for SQL server</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_columns">columns</code></td>
<td>
<p>(Optional) Character vector of column names to import from SQL table. Default is to import all columns.</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_optimize">optimize</code></td>
<td>
<p>(Optional) Optimize import of SQL table for faster imports. Default is true.
Ignored - use fetch_mode instead.</p>
</td></tr>
<tr><td><code id="h2o.import_sql_table_+3A_fetch_mode">fetch_mode</code></td>
<td>
<p>(Optional) Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read
from the database
Can be used for databases that do not support OFFSET-like clauses in SQL statements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, 
my_sql_conn_url &lt;- &quot;jdbc:mysql://172.16.2.178:3306/ingestSQL?&amp;useSSL=false&quot;
table &lt;- &quot;citibike20k&quot;
username &lt;- &quot;root&quot;
password &lt;- &quot;abc123&quot;
my_citibike_data &lt;- h2o.import_sql_table(my_sql_conn_url, table, username, password)
</p>

<hr>
<h2 id='h2o.importFile'>Import Files into H2O</h2><span id='topic+h2o.importFile'></span><span id='topic+h2o.importFolder'></span><span id='topic+h2o.importHDFS'></span><span id='topic+h2o.uploadFile'></span>

<h3>Description</h3>

<p>Imports files into an H2O cluster. The default behavior is to pass-through to the parse phase
automatically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.importFile(
  path,
  destination_frame = "",
  parse = TRUE,
  header = NA,
  sep = "",
  col.names = NULL,
  col.types = NULL,
  na.strings = NULL,
  decrypt_tool = NULL,
  skipped_columns = NULL,
  force_col_types = FALSE,
  custom_non_data_line_markers = NULL,
  partition_by = NULL,
  quotechar = NULL,
  escapechar = ""
)

h2o.importFolder(
  path,
  pattern = "",
  destination_frame = "",
  parse = TRUE,
  header = NA,
  sep = "",
  col.names = NULL,
  col.types = NULL,
  na.strings = NULL,
  decrypt_tool = NULL,
  skipped_columns = NULL,
  force_col_types = FALSE,
  custom_non_data_line_markers = NULL,
  partition_by = NULL,
  quotechar = NULL,
  escapechar = "\\"
)

h2o.importHDFS(
  path,
  pattern = "",
  destination_frame = "",
  parse = TRUE,
  header = NA,
  sep = "",
  col.names = NULL,
  na.strings = NULL
)

h2o.uploadFile(
  path,
  destination_frame = "",
  parse = TRUE,
  header = NA,
  sep = "",
  col.names = NULL,
  col.types = NULL,
  na.strings = NULL,
  progressBar = FALSE,
  parse_type = NULL,
  decrypt_tool = NULL,
  skipped_columns = NULL,
  force_col_types = FALSE,
  quotechar = NULL,
  escapechar = "\\"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.importFile_+3A_path">path</code></td>
<td>
<p>The complete URL or normalized file path of the file to be
imported. Each row of data appears as one line of the file.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_destination_frame">destination_frame</code></td>
<td>
<p>(Optional) The unique hex key assigned to the imported file. If none
is given, a key will automatically be generated based on the URL path.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_parse">parse</code></td>
<td>
<p>(Optional) A logical value indicating whether the file should be
parsed after import, for details see <a href="#topic+h2o.parseRaw">h2o.parseRaw</a>.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_header">header</code></td>
<td>
<p>(Optional) A logical value indicating whether the first line of
the file contains column headers. If left empty, the parser will try
to automatically detect this.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_sep">sep</code></td>
<td>
<p>(Optional) The field separator character. Values on each line of
the file are separated by this character. If <code>sep = ""</code>, the
parser will automatically detect the separator.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_col.names">col.names</code></td>
<td>
<p>(Optional) An H2OFrame object containing a single
delimited line with the column names for the file.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_col.types">col.types</code></td>
<td>
<p>(Optional) A vector to specify whether columns should be
forced to a certain type upon import parsing.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_na.strings">na.strings</code></td>
<td>
<p>(Optional) H2O will interpret these strings as missing.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_decrypt_tool">decrypt_tool</code></td>
<td>
<p>(Optional) Specify a Decryption Tool (key-reference
acquired by calling <a href="#topic+h2o.decryptionSetup">h2o.decryptionSetup</a>.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_skipped_columns">skipped_columns</code></td>
<td>
<p>a list of column indices to be skipped during parsing.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_force_col_types">force_col_types</code></td>
<td>
<p>(Optional) If TRUE, will force the column types to be either the ones in Parquet 
schema for Parquet files or the ones specified in column_types.  This parameter is used for 
numerical columns only.  Other column settings will happen without setting this parameter.  
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_custom_non_data_line_markers">custom_non_data_line_markers</code></td>
<td>
<p>(Optional) If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, NULL means that default behaviour for given format will be used</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_partition_by">partition_by</code></td>
<td>
<p>names of the columns the persisted dataset has been partitioned by.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_quotechar">quotechar</code></td>
<td>
<p>A hint for the parser which character to expect as quoting character. None (default) means autodetection.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_escapechar">escapechar</code></td>
<td>
<p>(Optional) One ASCII character used to escape other characters.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_pattern">pattern</code></td>
<td>
<p>(Optional) Character string containing a regular expression to match file(s) in
the folder.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_progressbar">progressBar</code></td>
<td>
<p>(Optional) When FALSE, tell H2O parse call to block
synchronously instead of polling.  This can be faster for small
datasets but loses the progress bar.</p>
</td></tr>
<tr><td><code id="h2o.importFile_+3A_parse_type">parse_type</code></td>
<td>
<p>(Optional) Specify which parser type H2O will use.
Valid types are &quot;ARFF&quot;, &quot;XLS&quot;, &quot;CSV&quot;, &quot;SVMLight&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>h2o.importFile</code> is a parallelized reader and pulls information from the server from a location specified
by the client. The path is a server-side path. This is a fast, scalable, highly optimized way to read data. H2O
pulls the data from a data store and initiates the data transfer as a read operation.
</p>
<p>Unlike the import function, which is a parallelized reader, <code>h2o.uploadFile</code> is a push from
the client to the server. The specified path must be a client-side path. This is not scalable and is only
intended for smaller data sizes. The client pushes the data from a local filesystem (for example,
on your machine where R is running) to H2O. For big-data operations, you don't want the data
stored on or flowing through the client.
</p>
<p><code>h2o.importFolder</code> imports an entire directory of files. If the given path is relative, then it
will be relative to the start location of the H2O instance. The default
behavior is to pass-through to the parse phase automatically.
</p>
<p><code>h2o.importHDFS</code> is deprecated. Instead, use <code>h2o.importFile</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+h2o.import_sql_select">h2o.import_sql_select</a>, <a href="#topic+h2o.import_sql_table">h2o.import_sql_table</a>, <a href="#topic+h2o.parseRaw">h2o.parseRaw</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init(ip = "localhost", port = 54321, startH2O = TRUE)
prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
class(prostate)
summary(prostate)

#Import files with a certain regex pattern by utilizing h2o.importFolder()
#In this example we import all .csv files in the directory prostate_folder
prostate_path = system.file("extdata", "prostate_folder", package = "h2o")
prostate_pattern = h2o.importFolder(path = prostate_path, pattern = ".*.csv")
class(prostate_pattern)
summary(prostate_pattern)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.impute'>Basic Imputation of H2O Vectors</h2><span id='topic+h2o.impute'></span>

<h3>Description</h3>

<p>Perform inplace imputation by filling missing values with aggregates
computed on the &quot;na.rm'd&quot; vector. Additionally, it's possible to perform imputation
based on groupings of columns from within data; these columns can be passed by index or
name to the by parameter. If a factor column is supplied, then the method must be
&quot;mode&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.impute(
  data,
  column = 0,
  method = c("mean", "median", "mode"),
  combine_method = c("interpolate", "average", "lo", "hi"),
  by = NULL,
  groupByFrame = NULL,
  values = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.impute_+3A_data">data</code></td>
<td>
<p>The dataset containing the column to impute.</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_column">column</code></td>
<td>
<p>A specific column to impute, default of 0 means impute the whole frame.</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_method">method</code></td>
<td>
<p>&quot;mean&quot; replaces NAs with the column mean; &quot;median&quot; replaces NAs with the column median;
&quot;mode&quot; replaces with the most common factor (for factor columns only);</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_combine_method">combine_method</code></td>
<td>
<p>If method is &quot;median&quot;, then choose how to combine quantiles on even sample sizes. This parameter is ignored in all other cases.</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_by">by</code></td>
<td>
<p>group by columns</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_groupbyframe">groupByFrame</code></td>
<td>
<p>Impute the column col with this pre-computed grouped frame.</p>
</td></tr>
<tr><td><code id="h2o.impute_+3A_values">values</code></td>
<td>
<p>A vector of impute values (one per column). NaN indicates to skip the column</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default method is selected based on the type of the column to impute. If the column
is numeric then &quot;mean&quot; is selected; if it is categorical, then &quot;mode&quot; is selected. Other
column types (e.g. String, Time, UUID) are not supported.
</p>


<h3>Value</h3>

<p>an H2OFrame with imputed values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 h2o.init()
 iris_hf &lt;- as.h2o(iris)
 iris_hf[sample(nrow(iris_hf), 40), 5] &lt;- NA  # randomly replace 50 values with NA
 # impute with a group by
 iris_hf &lt;- h2o.impute(iris_hf, "Species", "mode", by = c("Sepal.Length", "Sepal.Width"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.infogram'>H2O Infogram</h2><span id='topic+h2o.infogram'></span>

<h3>Description</h3>

<p>The infogram is a graphical information-theoretic interpretability tool which allows the user to quickly spot the core, decision-making variables 
that uniquely and safely drive the response, in supervised classification problems. The infogram can significantly cut down the number of predictors needed to build 
a model by identifying only the most valuable, admissible features. When protected variables such as race or gender are present in the data, the admissibility 
of a variable is determined by a safety and relevancy index, and thus serves as a diagnostic tool for fairness. The safety of each feature can be quantified and 
variables that are unsafe will be considered inadmissible. Models built using only admissible features will naturally be more interpretable, given the reduced 
feature set.  Admissible models are also less susceptible to overfitting and train faster, while providing similar accuracy as models built using all available features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.infogram(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  seed = -1,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  nfolds = 0,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  offset_column = NULL,
  weights_column = NULL,
  standardize = FALSE,
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  plug_values = NULL,
  max_iterations = 0,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = 0,
  custom_metric_func = NULL,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  algorithm = c("AUTO", "deeplearning", "drf", "gbm", "glm", "xgboost"),
  algorithm_params = NULL,
  protected_columns = NULL,
  total_information_threshold = -1,
  net_information_threshold = -1,
  relevance_index_threshold = -1,
  safety_index_threshold = -1,
  data_fraction = 1,
  top_n_features = 50
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.infogram_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize numeric columns to have zero mean and unit variance. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_plug_values">plug_values</code></td>
<td>
<p>Plug Values (a single row frame containing values that will be used to impute missing values of the
training/validation frame, use with conjunction missing_values_handling = PlugValues).</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_algorithm">algorithm</code></td>
<td>
<p>Type of machine learning algorithm used to build the infogram. Options include 'AUTO' (gbm), 'deeplearning'
(Deep Learning with default parameters), 'drf' (Random Forest with default parameters), 'gbm' (GBM with
default parameters), 'glm' (GLM with default parameters), or 'xgboost' (if available, XGBoost with default
parameters). Must be one of: &quot;AUTO&quot;, &quot;deeplearning&quot;, &quot;drf&quot;, &quot;gbm&quot;, &quot;glm&quot;, &quot;xgboost&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_algorithm_params">algorithm_params</code></td>
<td>
<p>Customized parameters for the machine learning algorithm specified in the algorithm parameter.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_protected_columns">protected_columns</code></td>
<td>
<p>Columns that contain features that are sensitive and need to be protected (legally, or otherwise), if
applicable. These features (e.g. race, gender, etc) should not drive the prediction of the response.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_total_information_threshold">total_information_threshold</code></td>
<td>
<p>A number between 0 and 1 representing a threshold for total information, defaulting to 0.1. For a specific
feature, if the total information is higher than this threshold, and the corresponding net information is also
higher than the threshold &ldquo;net_information_threshold&ldquo;, that feature will be considered admissible. The total
information is the x-axis of the Core Infogram. Default is -1 which gets set to 0.1. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_net_information_threshold">net_information_threshold</code></td>
<td>
<p>A number between 0 and 1 representing a threshold for net information, defaulting to 0.1.  For a specific
feature, if the net information is higher than this threshold, and the corresponding total information is also
higher than the total_information_threshold, that feature will be considered admissible. The net information
is the y-axis of the Core Infogram. Default is -1 which gets set to 0.1. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_relevance_index_threshold">relevance_index_threshold</code></td>
<td>
<p>A number between 0 and 1 representing a threshold for the relevance index, defaulting to 0.1.  This is only
used when &ldquo;protected_columns&ldquo; is set by the user.  For a specific feature, if the relevance index value is
higher than this threshold, and the corresponding safety index is also higher than the
safety_index_threshold&ldquo;, that feature will be considered admissible.  The relevance index is the x-axis of
the Fair Infogram. Default is -1 which gets set to 0.1. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_safety_index_threshold">safety_index_threshold</code></td>
<td>
<p>A number between 0 and 1 representing a threshold for the safety index, defaulting to 0.1.  This is only used
when protected_columns is set by the user.  For a specific feature, if the safety index value is higher than
this threshold, and the corresponding relevance index is also higher than the relevance_index_threshold, that
feature will be considered admissible.  The safety index is the y-axis of the Fair Infogram. Default is -1
which gets set to 0.1. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_data_fraction">data_fraction</code></td>
<td>
<p>The fraction of training frame to use to build the infogram model. Defaults to 1.0, and any value greater than
0 and less than or equal to 1.0 is acceptable. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.infogram_+3A_top_n_features">top_n_features</code></td>
<td>
<p>An integer specifying the number of columns to evaluate in the infogram.  The columns are ranked by variable
importance, and the top N are evaluated.  Defaults to 50. Defaults to 50.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The infogram allows the user to quickly spot the admissible decision-making variables that are driving the response.  
There are two types of infogram plots: Core and Fair Infogram.
</p>
<p>The Core Infogram plots all the variables as points on two-dimensional grid of total vs net information.  The x-axis is total information, 
a measure of how much the variable drives the response (the more predictive, the higher the total information). 
The y-axis is net information, a measure of how unique the variable is.  The top right quadrant of the infogram plot is the admissible section; the variables
located in this quadrant are the admissible features.  In the Core Infogram, the admissible features are the strongest, unique drivers of 
the response.
</p>
<p>If sensitive or protected variables are present in data, the user can specify which attributes should be protected while training using the <code>protected_columns</code> 
argument. All non-protected predictor variables will be checked to make sure that there's no information pathway to the response through a protected feature, and 
deemed inadmissible if they possess little or no informational value beyond their use as a dummy for protected attributes. The Fair Infogram plots all the features 
as points on two-dimensional grid of relevance vs safety.  The x-axis is relevance index, a measure of how much the variable drives the response (the more predictive, 
the higher the relevance). The y-axis is safety index, a measure of how much extra information the variable has that is not acquired through the protected variables.  
In the Fair Infogram, the admissible features are the strongest, safest drivers of the response.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Convert iris dataset to an H2OFrame    
df &lt;- as.h2o(iris)

# Infogram
ig &lt;- h2o.infogram(y = "Species", training_frame = df) 
plot(ig)


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.infogram_train_subset_models'>Train models over subsets selected using infogram</h2><span id='topic+h2o.infogram_train_subset_models'></span>

<h3>Description</h3>

<p>Train models over subsets selected using infogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.infogram_train_subset_models(
  ig,
  model_fun,
  training_frame,
  test_frame,
  y,
  protected_columns,
  reference,
  favorable_class,
  feature_selection_metrics = c("safety_index"),
  metric = "euclidean",
  air_metric = "selectedRatio",
  alpha = 0.05,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_ig">ig</code></td>
<td>
<p>Infogram object trained with the same protected columns</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_model_fun">model_fun</code></td>
<td>
<p>Function that creates models. This can be something like h2o.automl, h2o.gbm, etc.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_training_frame">training_frame</code></td>
<td>
<p>Training frame</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_test_frame">test_frame</code></td>
<td>
<p>Test frame</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_y">y</code></td>
<td>
<p>Response column</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_protected_columns">protected_columns</code></td>
<td>
<p>Protected columns</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_feature_selection_metrics">feature_selection_metrics</code></td>
<td>
<p>One or more columns from the infogram@admissible_score.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_metric">metric</code></td>
<td>
<p>Metric supported by stats::dist which is used to sort the features.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_air_metric">air_metric</code></td>
<td>
<p>Metric used for Adverse Impact Ratio calculation. Defaults to &ldquo;selectedRatio&ldquo;.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level is the probability of rejecting the null hypothesis that the protected group
and the reference came from the same population when the null hypothesis is true.</p>
</td></tr>
<tr><td><code id="h2o.infogram_train_subset_models_+3A_...">...</code></td>
<td>
<p>Parameters that are passed to the model_fun.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>frame containing aggregations of intersectional fairness across the models
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.connect()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

ig &lt;- h2o.infogram(x, y, train, protected_columns = protected_columns)
print(ig@admissible_score)
plot(ig)

infogram_models &lt;- h2o.infogram_train_subset_models(ig, h2o.gbm, train, test, y,
                                                    protected_columns, reference,
                                                    favorable_class)

pf &lt;- h2o.pareto_front(infogram_models, x_metric = "air_min",
                       y_metric = "AUC", optimum = "top right")
plot(pf)
pf@pareto_front

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.init'>Initialize and Connect to H2O</h2><span id='topic+h2o.init'></span>

<h3>Description</h3>

<p>Attempts to start and/or connect to and H2O instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.init(
  ip = "localhost",
  port = 54321,
  name = NA_character_,
  startH2O = TRUE,
  forceDL = FALSE,
  enable_assertions = TRUE,
  license = NULL,
  nthreads = -1,
  max_mem_size = NULL,
  min_mem_size = NULL,
  ice_root = tempdir(),
  log_dir = NA_character_,
  log_level = NA_character_,
  strict_version_check = TRUE,
  proxy = NA_character_,
  https = FALSE,
  cacert = NA_character_,
  insecure = FALSE,
  username = NA_character_,
  password = NA_character_,
  use_spnego = FALSE,
  cookies = NA_character_,
  context_path = NA_character_,
  ignore_config = FALSE,
  extra_classpath = NULL,
  jvm_custom_args = NULL,
  bind_to_localhost = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.init_+3A_ip">ip</code></td>
<td>
<p>Object of class <code>character</code> representing the IP address of the server where H2O is running.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_port">port</code></td>
<td>
<p>Object of class <code>numeric</code> representing the port number of the H2O server.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_name">name</code></td>
<td>
<p>(Optional) A <code>character</code> string representing the H2O cluster name.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_starth2o">startH2O</code></td>
<td>
<p>(Optional) A <code>logical</code> value indicating whether to try to start H2O from R if no connection with H2O is detected. This is only possible if <code>ip = "localhost"</code> or <code>ip = "127.0.0.1"</code>.  If an existing connection is detected, R does not start H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_forcedl">forceDL</code></td>
<td>
<p>(Optional) A <code>logical</code> value indicating whether to force download of the H2O executable. Defaults to FALSE, so the executable will only be downloaded if it does not already exist in the h2o R library resources directory <code>h2o/java/h2o.jar</code>.  This value is only used when R starts H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_enable_assertions">enable_assertions</code></td>
<td>
<p>(Optional) A <code>logical</code> value indicating whether H2O should be launched with assertions enabled. Used mainly for error checking and debugging purposes.  This value is only used when R starts H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_license">license</code></td>
<td>
<p>(Optional) A <code>character</code> string value specifying the full path of the license file.  This value is only used when R starts H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_nthreads">nthreads</code></td>
<td>
<p>(Optional) Number of threads in the thread pool.  This relates very closely to the number of CPUs used. -1 means use all CPUs on the host (Default).  A positive integer specifies the number of CPUs directly.  This value is only used when R starts H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_max_mem_size">max_mem_size</code></td>
<td>
<p>(Optional) A <code>character</code> string specifying the maximum size, in bytes, of the memory allocation pool to H2O. This value must a multiple of 1024 greater than 2MB. Append the letter m or M to indicate megabytes, or g or G to indicate gigabytes.  This value is only used when R starts H2O. If max_mem_size is not defined, then the amount of memory that H2O allocates will be determined by the default memory of Java Virtual Machine. This amount is dependent on the Java version, but it will generally be 25 percent of the machine's physical memory.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_min_mem_size">min_mem_size</code></td>
<td>
<p>(Optional) A <code>character</code> string specifying the minimum size, in bytes, of the memory allocation pool to H2O. This value must a multiple of 1024 greater than 2MB. Append the letter m or M to indicate megabytes, or g or G to indicate gigabytes.  This value is only used when R starts H2O.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_ice_root">ice_root</code></td>
<td>
<p>(Optional) A directory to handle object spillage. The defaul varies by OS.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_log_dir">log_dir</code></td>
<td>
<p>(Optional) A directory where H2O server logs are stored. The default varies by OS.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_log_level">log_level</code></td>
<td>
<p>(Optional) The level of logging of H2O server. The default is INFO.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_strict_version_check">strict_version_check</code></td>
<td>
<p>(Optional) Setting this to FALSE is unsupported and should only be done when advised by technical support.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_proxy">proxy</code></td>
<td>
<p>(Optional) A <code>character</code> string specifying the proxy path.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_https">https</code></td>
<td>
<p>(Optional) Set this to TRUE to use https instead of http.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_cacert">cacert</code></td>
<td>
<p>(Optional) Path to a CA bundle file with root and intermediate certificates of trusted CAs.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_insecure">insecure</code></td>
<td>
<p>(Optional) Set this to TRUE to disable SSL certificate checking.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_username">username</code></td>
<td>
<p>(Optional) Username to login with.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_password">password</code></td>
<td>
<p>(Optional) Password to login with.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_use_spnego">use_spnego</code></td>
<td>
<p>(Optional) Set this to TRUE to enable SPNEGO authentication.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_cookies">cookies</code></td>
<td>
<p>(Optional) Vector(or list) of cookies to add to request.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_context_path">context_path</code></td>
<td>
<p>(Optional) The last part of connection URL: http://&lt;ip&gt;:&lt;port&gt;/&lt;context_path&gt;</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_ignore_config">ignore_config</code></td>
<td>
<p>(Optional) A <code>logical</code> value indicating whether a search for a .h2oconfig file should be conducted or not. Default value is FALSE.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_extra_classpath">extra_classpath</code></td>
<td>
<p>(Optional) A vector of paths to libraries to be added to the Java classpath when H2O is started from R.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_jvm_custom_args">jvm_custom_args</code></td>
<td>
<p>(Optional) A <code>character</code> list of custom arguments for the JVM where new H2O instance is going to run, if started. Ignored when connecting to an existing instance.</p>
</td></tr>
<tr><td><code id="h2o.init_+3A_bind_to_localhost">bind_to_localhost</code></td>
<td>
<p>(Optional) A <code>logical</code> flag indicating whether access to the H2O instance should be restricted to the local machine (default) or if it can be reached from other computers on the network. Only applicable when H2O is started from R.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this method first checks if an H2O instance is connectible. If it cannot connect and <code>start = TRUE</code> with <code>ip = "localhost"</code>, it will attempt to start and instance of H2O at localhost:54321.
If an open ip and port of your choice are passed in, then this method will attempt to start an H2O instance at that specified ip  port.
</p>
<p>When initializing H2O locally, this method searches for h2o.jar in the R library resources (<code>system.file("java", "h2o.jar", package = "h2o")</code>), and if the file does not exist, it will automatically attempt to download the correct version from Amazon S3. The user must have Internet access for this process to be successful.
</p>
<p>Once connected, the method checks to see if the local H2O R package version matches the version of H2O running on the server. If there is a mismatch and the user indicates she wishes to upgrade, it will remove the local H2O R package and download/install the H2O R package from the server.
</p>


<h3>Value</h3>

<p>this method will load it and return a <code>H2OConnection</code> object containing the IP address and port number of the H2O server.
</p>


<h3>Note</h3>

<p>Users may wish to manually upgrade their package (rather than waiting until being prompted), which requires
that they fully uninstall and reinstall the H2O package, and the H2O client package. You must unload packages running
in the environment before upgrading. It's recommended that users restart R or R studio after upgrading
</p>


<h3>See Also</h3>

<p><a href="https://docs.h2o.ai/h2o/latest-stable/h2o-r/h2o_package.pdf">H2O R package documentation</a> for more details. <code><a href="#topic+h2o.shutdown">h2o.shutdown</a></code> for shutting down from R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Try to connect to a local H2O instance that is already running.
# If not found, start a local H2O instance from R with the default settings.
h2o.init()

# Try to connect to a local H2O instance.
# If not found, raise an error.
h2o.init(startH2O = FALSE)

# Try to connect to a local H2O instance that is already running.
# If not found, start a local H2O instance from R with 5 gigabytes of memory.
h2o.init(max_mem_size = "5g")

# Try to connect to a local H2O instance that is already running.
# If not found, start a local H2O instance from R that uses 5 gigabytes of memory.
h2o.init(max_mem_size = "5g")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.insertMissingValues'>Insert Missing Values into an H2OFrame</h2><span id='topic+h2o.insertMissingValues'></span>

<h3>Description</h3>

<p>Randomly replaces a user-specified fraction of entries in an H2O dataset with missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.insertMissingValues(data, fraction = 0.1, seed = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.insertMissingValues_+3A_data">data</code></td>
<td>
<p>An H2OFrame object representing the dataset.</p>
</td></tr>
<tr><td><code id="h2o.insertMissingValues_+3A_fraction">fraction</code></td>
<td>
<p>A number between 0 and 1 indicating the fraction of entries
to replace with missing.</p>
</td></tr>
<tr><td><code id="h2o.insertMissingValues_+3A_seed">seed</code></td>
<td>
<p>A random number used to select which entries to replace with
missing values. Default of <code>seed = -1</code> will automatically
generate a seed in H2O.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>WARNING</h3>

<p>This will modify the original dataset. Unless this is intended,
this function should only be called on a subset of the original.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
summary(iris_hf)

iris_miss &lt;- h2o.insertMissingValues(iris_hf, fraction = 0.25)
head(iris_miss)
summary(iris_miss)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.inspect_model_fairness'>Produce plots and dataframes related to a single model fairness.</h2><span id='topic+h2o.inspect_model_fairness'></span>

<h3>Description</h3>

<p>Produce plots and dataframes related to a single model fairness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.inspect_model_fairness(
  model,
  newdata,
  protected_columns,
  reference,
  favorable_class,
  metrics = c("auc", "aucpr", "f1", "p.value", "selectedRatio", "total"),
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.inspect_model_fairness_+3A_model">model</code></td>
<td>
<p>H2O Model Object</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_newdata">newdata</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_protected_columns">protected_columns</code></td>
<td>
<p>List of categorical columns that contain sensitive information
such as race, gender, age etc.</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_reference">reference</code></td>
<td>
<p>List of values corresponding to a reference for each protected columns.
If set to NULL, it will use the biggest group as the reference.</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_favorable_class">favorable_class</code></td>
<td>
<p>Positive/favorable outcome class of the response.</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_metrics">metrics</code></td>
<td>
<p>Character vector of metrics to show.</p>
</td></tr>
<tr><td><code id="h2o.inspect_model_fairness_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.
Setting it enables calculating SHAP in more models but it can be more time and memory consuming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>H2OExplanation object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(paste0("https://s3.amazonaws.com/h2o-public-test-data/smalldata/",
                              "admissibleml_test/taiwan_credit_card_uci.csv"))
x &lt;- c('LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',
       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',
       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6')
y &lt;- "default payment next month"
protected_columns &lt;- c('SEX', 'EDUCATION')

for (col in c(y, protected_columns))
  data[[col]] &lt;- as.factor(data[[col]])

splits &lt;- h2o.splitFrame(data, 0.8)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
reference &lt;- c(SEX = "1", EDUCATION = "2")  # university educated man
favorable_class &lt;- "0" # no default next month

gbm &lt;- h2o.gbm(x, y, training_frame = train)

h2o.inspect_model_fairness(gbm, test, protected_columns = protected_columns,
                           reference = reference, favorable_class = favorable_class)

## End(Not run)

</code></pre>

<hr>
<h2 id='h2o.interaction'>Categorical Interaction Feature Creation in H2O</h2><span id='topic+h2o.interaction'></span>

<h3>Description</h3>

<p>Creates a data frame in H2O with n-th order interaction features between categorical columns, as specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.interaction(
  data,
  destination_frame,
  factors,
  pairwise,
  max_factors,
  min_occurrence
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.interaction_+3A_data">data</code></td>
<td>
<p>An H2OFrame object containing the categorical columns.</p>
</td></tr>
<tr><td><code id="h2o.interaction_+3A_destination_frame">destination_frame</code></td>
<td>
<p>A string indicating the destination key. If empty, this will be auto-generated by H2O.</p>
</td></tr>
<tr><td><code id="h2o.interaction_+3A_factors">factors</code></td>
<td>
<p>Factor columns (either indices or column names).</p>
</td></tr>
<tr><td><code id="h2o.interaction_+3A_pairwise">pairwise</code></td>
<td>
<p>Whether to create pairwise interactions between factors (otherwise create one higher-order interaction). Only applicable if there are 3 or more factors.</p>
</td></tr>
<tr><td><code id="h2o.interaction_+3A_max_factors">max_factors</code></td>
<td>
<p>Max. number of factor levels in pair-wise interaction terms (if enforced, one extra catch-all factor will be made)</p>
</td></tr>
<tr><td><code id="h2o.interaction_+3A_min_occurrence">min_occurrence</code></td>
<td>
<p>Min. occurrence threshold for factor levels in pair-wise interaction terms</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Create some random data
my_frame &lt;- h2o.createFrame(rows = 20, cols = 5,
                           seed = -12301283, randomize = TRUE, value = 0,
                           categorical_fraction = 0.8, factors = 10, real_range = 1,
                           integer_fraction = 0.2, integer_range = 10,
                           binary_fraction = 0, binary_ones_fraction = 0.5,
                           missing_fraction = 0.2,
                           response_factors = 1)
# Turn integer column into a categorical
my_frame[,5] &lt;- as.factor(my_frame[,5])
head(my_frame, 20)

# Create pairwise interactions
pairwise &lt;- h2o.interaction(my_frame,
                            factors = list(c(1, 2), c("C2", "C3", "C4")),
                            pairwise = TRUE, max_factors = 10, min_occurrence = 1)
head(pairwise, 20)
h2o.levels(pairwise, 2)

# Create 5-th order interaction
higherorder &lt;- h2o.interaction(my_frame, factors = c(1, 2, 3, 4, 5),
                               pairwise = FALSE, max_factors = 10000, min_occurrence = 1)
head(higherorder, 20)

# Limit the number of factors of the "categoricalized" integer column
# to at most 3 factors, and only if they occur at least twice
head(my_frame[,5], 20)
trim_integer_levels &lt;- h2o.interaction(my_frame, factors = "C5", pairwise = FALSE, max_factors = 3,
                                       min_occurrence = 2)
head(trim_integer_levels, 20)

# Put all together
my_frame &lt;- h2o.cbind(my_frame, pairwise, higherorder, trim_integer_levels)
my_frame
head(my_frame, 20)
summary(my_frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.is_client'>Check Client Mode Connection</h2><span id='topic+h2o.is_client'></span>

<h3>Description</h3>

<p>Check Client Mode Connection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.is_client()
</code></pre>

<hr>
<h2 id='h2o.isax'>iSAX</h2><span id='topic+h2o.isax'></span>

<h3>Description</h3>

<p>Compute the iSAX index for a DataFrame which is assumed to be numeric time series data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.isax(x, num_words, max_cardinality, optimize_card = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.isax_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.isax_+3A_num_words">num_words</code></td>
<td>
<p>Number of iSAX words for the timeseries. ie granularity along the time series</p>
</td></tr>
<tr><td><code id="h2o.isax_+3A_max_cardinality">max_cardinality</code></td>
<td>
<p>Maximum cardinality of the iSAX word. Each word can have less than the max</p>
</td></tr>
<tr><td><code id="h2o.isax_+3A_optimize_card">optimize_card</code></td>
<td>
<p>An optimization flag that will find the max cardinality regardless of what is passed in for max_cardinality.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with the name of time series, string representation of iSAX word, followed by binary representation
</p>


<h3>References</h3>

<p>https://www.cs.ucr.edu/~eamonn/iSAX_2.0.pdf
</p>
<p>https://www.cs.ucr.edu/~eamonn/SAX.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- h2o.createFrame(rows = 1, cols = 256, randomize = TRUE, value = 0, 
                      real_range = 100, categorical_fraction = 0, factors = 0, 
                      integer_fraction = 0, integer_range = 100, binary_fraction = 0, 
                      binary_ones_fraction = 0, time_fraction = 0, string_fraction = 0, 
                      missing_fraction = 0, has_response = FALSE, seed = 123)
df2 &lt;- h2o.cumsum(df, axis = 1)
h2o.isax(df2, num_words = 10, max_cardinality = 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ischaracter'>Check if character</h2><span id='topic+h2o.ischaracter'></span>

<h3>Description</h3>

<p>Check if character
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ischaracter(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ischaracter_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+character">character</a></code> for the base R implementation, <code>is.character()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
iris_char &lt;- h2o.ascharacter(iris["class"])
h2o.ischaracter(iris_char)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.isfactor'>Check if factor</h2><span id='topic+h2o.isfactor'></span>

<h3>Description</h3>

<p>Check if factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.isfactor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.isfactor_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factor">factor</a></code> for the base R implementation, <code>is.factor()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
h2o.isfactor(cars["economy_20mpg"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.isnumeric'>Check if numeric</h2><span id='topic+h2o.isnumeric'></span>

<h3>Description</h3>

<p>Check if numeric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.isnumeric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.isnumeric_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+numeric">numeric</a></code> for the base R implementation, <code>is.numeric()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
h2o.isnumeric(iris["sepal_len"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.isolationForest'>Trains an Isolation Forest model</h2><span id='topic+h2o.isolationForest'></span>

<h3>Description</h3>

<p>Trains an Isolation Forest model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.isolationForest(
  training_frame,
  x,
  model_id = NULL,
  score_each_iteration = FALSE,
  score_tree_interval = 0,
  ignore_const_cols = TRUE,
  ntrees = 50,
  max_depth = 8,
  min_rows = 1,
  max_runtime_secs = 0,
  seed = -1,
  build_tree_one_node = FALSE,
  mtries = -1,
  sample_size = 256,
  sample_rate = -1,
  col_sample_rate_change_per_level = 1,
  col_sample_rate_per_tree = 1,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "anomaly_score"),
  stopping_tolerance = 0.01,
  export_checkpoints_dir = NULL,
  contamination = -1,
  validation_frame = NULL,
  validation_response_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.isolationForest_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of trees. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum tree depth (0 for unlimited). Defaults to 8.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_min_rows">min_rows</code></td>
<td>
<p>Fewest allowed (weighted) observations in a leaf. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_build_tree_one_node">build_tree_one_node</code></td>
<td>
<p><code>Logical</code>. Run on one node only; no network overhead but fewer cpus used. Suitable for small datasets.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_mtries">mtries</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split. If set to -1, defaults (number of
predictors)/3. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_sample_size">sample_size</code></td>
<td>
<p>Number of randomly sampled observations used to train each Isolation Forest tree. Only one of parameters
sample_size and sample_rate should be defined. If sample_rate is defined, sample_size will be ignored.
Defaults to 256.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_sample_rate">sample_rate</code></td>
<td>
<p>Rate of randomly sampled observations used to train each Isolation Forest tree. Needs to be in range from 0.0
to 1.0. If set to -1, sample_rate is disabled and sample_size will be used instead. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_col_sample_rate_change_per_level">col_sample_rate_change_per_level</code></td>
<td>
<p>Relative change of the column sampling rate for every level (must be &gt; 0.0 and &lt;= 2.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_col_sample_rate_per_tree">col_sample_rate_per_tree</code></td>
<td>
<p>Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;anomaly_score&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.01.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_contamination">contamination</code></td>
<td>
<p>Contamination ratio - the proportion of anomalies in the input dataset. If undefined (-1) the predict function
will not mark observations as anomalies and only anomaly score will be returned. Defaults to -1 (undefined).
Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.isolationForest_+3A_validation_response_column">validation_response_column</code></td>
<td>
<p>(experimental) Name of the response column in the validation frame. Response column should be binary and
indicate not anomaly/anomaly.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the cars dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)

# Set the predictors
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")

# Train the IF model
cars_if &lt;- h2o.isolationForest(x = predictors, training_frame = cars,
                               seed = 1234, stopping_metric = "anomaly_score",
                               stopping_rounds = 3, stopping_tolerance = 0.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.isotonicregression'>Build an Isotonic Regression model</h2><span id='topic+h2o.isotonicregression'></span>

<h3>Description</h3>

<p>Builds an Isotonic Regression model on an H2OFrame with a single feature (univariate regression).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.isotonicregression(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  weights_column = NULL,
  out_of_bounds = c("NA", "clip"),
  custom_metric_func = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.isotonicregression_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_out_of_bounds">out_of_bounds</code></td>
<td>
<p>Method of handling values of X predictor that are outside of the bounds seen in training. Must be one of:
&quot;NA&quot;, &quot;clip&quot;. Defaults to NA.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.isotonicregression_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a <a href="#topic+H2OModel-class">H2OModel</a> object of the right type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

N &lt;- 100
x &lt;- seq(N)
y &lt;- sample(-50:50, N, replace=TRUE) + 50 * log1p(x)

train &lt;- as.h2o(data.frame(x = x, y = y))
isotonic &lt;- h2o.isotonicregression(x = "x", y = "y", training_frame = train)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.keyof'>Method on <code>Keyed</code> objects allowing to obtain their key.</h2><span id='topic+h2o.keyof'></span><span id='topic+h2o.keyof+2CKeyed-method'></span><span id='topic+h2o.keyof+2CH2OModel-method'></span><span id='topic+h2o.keyof+2CH2OGrid-method'></span><span id='topic+h2o.keyof+2CH2OFrame-method'></span><span id='topic+h2o.keyof+2CH2OAutoML-method'></span>

<h3>Description</h3>

<p>Method on <code>Keyed</code> objects allowing to obtain their key.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.keyof(object)

## S4 method for signature 'Keyed'
h2o.keyof(object)

## S4 method for signature 'H2OModel'
h2o.keyof(object)

## S4 method for signature 'H2OGrid'
h2o.keyof(object)

## S4 method for signature 'H2OFrame'
h2o.keyof(object)

## S4 method for signature 'H2OAutoML'
h2o.keyof(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.keyof_+3A_object">object</code></td>
<td>
<p>A <code>Keyed</code> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the string key holding the persistent object.
</p>

<hr>
<h2 id='h2o.kfold_column'>Produce a k-fold column vector.</h2><span id='topic+h2o.kfold_column'></span>

<h3>Description</h3>

<p>Create a k-fold vector useful for H2O algorithms that take a fold_assignments argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.kfold_column(data, nfolds, seed = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.kfold_column_+3A_data">data</code></td>
<td>
<p>A dataframe against which to create the fold column.</p>
</td></tr>
<tr><td><code id="h2o.kfold_column_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of desired folds.</p>
</td></tr>
<tr><td><code id="h2o.kfold_column_+3A_seed">seed</code></td>
<td>
<p>A random seed, -1 indicates that H2O will choose one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with fold assignments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
kfolds &lt;- h2o.kfold_column(iris, nfolds = 5, seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.killMinus3'>Dump the stack into the JVM's stdout.</h2><span id='topic+h2o.killMinus3'></span>

<h3>Description</h3>

<p>A poor man's profiler, but effective.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.killMinus3()
</code></pre>

<hr>
<h2 id='h2o.kmeans'>Performs k-means clustering on an H2O dataset</h2><span id='topic+h2o.kmeans'></span>

<h3>Description</h3>

<p>Performs k-means clustering on an H2O dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.kmeans(
  training_frame,
  x,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  k = 1,
  estimate_k = FALSE,
  user_points = NULL,
  max_iterations = 10,
  standardize = TRUE,
  seed = -1,
  init = c("Random", "PlusPlus", "Furthest", "User"),
  max_runtime_secs = 0,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  export_checkpoints_dir = NULL,
  cluster_size_constraints = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.kmeans_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_k">k</code></td>
<td>
<p>The max. number of clusters. If estimate_k is disabled, the model will find k centroids, otherwise it will
find up to k centroids. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_estimate_k">estimate_k</code></td>
<td>
<p><code>Logical</code>. Whether to estimate the number of clusters (&lt;=k) iteratively and deterministically. Defaults
to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_user_points">user_points</code></td>
<td>
<p>This option allows you to specify a dataframe, where each row represents an initial cluster center. The user-
specified points must have the same number of columns as the training observations. The number of rows must
equal the number of clusters</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum training iterations (if estimate_k is enabled, then this is for each inner Lloyds iteration) Defaults
to 10.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize columns before computing distances Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_init">init</code></td>
<td>
<p>Initialization mode Must be one of: &quot;Random&quot;, &quot;PlusPlus&quot;, &quot;Furthest&quot;, &quot;User&quot;. Defaults to Furthest.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.kmeans_+3A_cluster_size_constraints">cluster_size_constraints</code></td>
<td>
<p>An array specifying the minimum number of points that should be in each cluster. The length of the constraints
array has to be the same as the number of clusters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.cluster_sizes">h2o.cluster_sizes</a></code>, <code><a href="#topic+h2o.totss">h2o.totss</a></code>, <code><a href="#topic+h2o.num_iterations">h2o.num_iterations</a></code>, <code><a href="#topic+h2o.betweenss">h2o.betweenss</a></code>, <code><a href="#topic+h2o.tot_withinss">h2o.tot_withinss</a></code>, <code><a href="#topic+h2o.withinss">h2o.withinss</a></code>, <code><a href="#topic+h2o.centersSTD">h2o.centersSTD</a></code>, <code><a href="#topic+h2o.centers">h2o.centers</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.kmeans(training_frame = prostate, k = 10, x = c("AGE", "RACE", "VOL", "GLEASON"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.kolmogorov_smirnov'>Kolmogorov-Smirnov metric for binomial models</h2><span id='topic+h2o.kolmogorov_smirnov'></span><span id='topic+h2o.kolmogorov_smirnov+2CH2OModelMetrics-method'></span><span id='topic+h2o.kolmogorov_smirnov+2CH2OModel-method'></span>

<h3>Description</h3>

<p>Retrieves a Kolmogorov-Smirnov metric for given binomial model. The number returned is in range between 0 and 1.
K-S metric represents the degree of separation between the positive (1) and negative (0) cumulative distribution
functions. Detailed metrics per each group are to be found in the gains-lift table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.kolmogorov_smirnov(object)

## S4 method for signature 'H2OModelMetrics'
h2o.kolmogorov_smirnov(object)

## S4 method for signature 'H2OModel'
h2o.kolmogorov_smirnov(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.kolmogorov_smirnov_+3A_object">object</code></td>
<td>
<p>Either an <a href="#topic+H2OModel-class">H2OModel</a> object or an
<a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> version of this function will only take
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> objects.
</p>


<h3>Value</h3>

<p>Kolmogorov-Smirnov metric, a number between 0 and 1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.gainsLift">h2o.gainsLift</a></code> to see detailed K-S metrics per group
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
data &lt;- h2o.importFile(
path = "https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip")
model &lt;- h2o.gbm(x = c("Origin", "Distance"), y = "IsDepDelayed", 
                       training_frame = data, ntrees = 1)
h2o.kolmogorov_smirnov(model)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.kurtosis'>Kurtosis of a column</h2><span id='topic+h2o.kurtosis'></span><span id='topic+kurtosis.H2OFrame'></span>

<h3>Description</h3>

<p>Obtain the kurtosis of a column of a parsed H2O data object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.kurtosis(x, ..., na.rm = TRUE)

kurtosis.H2OFrame(x, ..., na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.kurtosis_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.kurtosis_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
<tr><td><code id="h2o.kurtosis_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> or missing values should be stripped before the computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the kurtosis for each column (NaN for non-numeric columns).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.kurtosis(prostate$AGE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.learning_curve_plot'>Learning Curve Plot</h2><span id='topic+h2o.learning_curve_plot'></span>

<h3>Description</h3>

<p>Create learning curve plot for an H2O Model. Learning curves show error metric dependence on
learning progress, e.g., RMSE vs number of trees trained so far in GBM. There can be up to 4 curves
showing Training, Validation, Training on CV Models, and Cross-validation error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.learning_curve_plot(
  model,
  metric = c("AUTO", "auc", "aucpr", "mae", "rmse", "anomaly_score", "convergence",
    "custom", "custom_increasing", "deviance", "lift_top_group", "logloss",
    "misclassification", "negative_log_likelihood", "objective", "sumetaieta02",
    "loglik"),
  cv_ribbon = NULL,
  cv_lines = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.learning_curve_plot_+3A_model">model</code></td>
<td>
<p>an H2O model</p>
</td></tr>
<tr><td><code id="h2o.learning_curve_plot_+3A_metric">metric</code></td>
<td>
<p>Metric to be used for the learning curve plot. These should mostly correspond with stopping metric.</p>
</td></tr>
<tr><td><code id="h2o.learning_curve_plot_+3A_cv_ribbon">cv_ribbon</code></td>
<td>
<p>if True, plot the CV mean as a and CV standard deviation as a ribbon around the mean,
if NULL, it will attempt to automatically determine if this is suitable visualisation</p>
</td></tr>
<tr><td><code id="h2o.learning_curve_plot_+3A_cv_lines">cv_lines</code></td>
<td>
<p>if True, plot scoring history for individual CV models, if NULL, it will attempt to
automatically determine if this is suitable visualisation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the learning curve plot
learning_curve &lt;- h2o.learning_curve_plot(gbm)
print(learning_curve)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.levels'>Return the levels from the column requested column.</h2><span id='topic+h2o.levels'></span>

<h3>Description</h3>

<p>Return the levels from the column requested column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.levels(x, i)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.levels_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.levels_+3A_i">i</code></td>
<td>
<p>Optional, the index of the column whose domain is to be returned.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+levels">levels</a></code> for the base R method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
h2o.levels(iris_hf, 5)  # returns "setosa"     "versicolor" "virginica"

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.list_all_extensions'>List all H2O registered extensions</h2><span id='topic+h2o.list_all_extensions'></span>

<h3>Description</h3>

<p>List all H2O registered extensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.list_all_extensions()
</code></pre>

<hr>
<h2 id='h2o.list_api_extensions'>List registered API extensions</h2><span id='topic+h2o.list_api_extensions'></span>

<h3>Description</h3>

<p>List registered API extensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.list_api_extensions()
</code></pre>

<hr>
<h2 id='h2o.list_core_extensions'>List registered core extensions</h2><span id='topic+h2o.list_core_extensions'></span>

<h3>Description</h3>

<p>List registered core extensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.list_core_extensions()
</code></pre>

<hr>
<h2 id='h2o.list_jobs'>Return list of jobs performed by the H2O cluster</h2><span id='topic+h2o.list_jobs'></span>

<h3>Description</h3>

<p>Return list of jobs performed by the H2O cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.list_jobs()
</code></pre>

<hr>
<h2 id='h2o.list_models'>Get an list of all model ids present in the cluster</h2><span id='topic+h2o.list_models'></span>

<h3>Description</h3>

<p>Get an list of all model ids present in the cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.list_models()
</code></pre>


<h3>Value</h3>

<p>Returns a vector of model ids.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
model_id &lt;- h2o.gbm(x = 1:4, y = 5, training_frame = iris_hf)@model_id
model_id_list &lt;- h2o.list_models()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.listTimezones'>List all of the Time Zones Acceptable by the H2O cluster.</h2><span id='topic+h2o.listTimezones'></span>

<h3>Description</h3>

<p>List all of the Time Zones Acceptable by the H2O cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.listTimezones()
</code></pre>

<hr>
<h2 id='h2o.load_frame'>Load frame previously stored in H2O's native format.</h2><span id='topic+h2o.load_frame'></span>

<h3>Description</h3>

<p>Load frame previously stored in H2O's native format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.load_frame(frame_id, dir, force = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.load_frame_+3A_frame_id">frame_id</code></td>
<td>
<p>the frame ID of the original frame</p>
</td></tr>
<tr><td><code id="h2o.load_frame_+3A_dir">dir</code></td>
<td>
<p>a filesystem location where to look for frame data</p>
</td></tr>
<tr><td><code id="h2o.load_frame_+3A_force">force</code></td>
<td>
<p><code>logical</code>. overwrite an already existing frame (defaults to true)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
h2o.save_frame(prostate, "/tmp/prostate")
prostate.key &lt;- h2o.getId(prostate)
h2o.rm(prostate)
prostate &lt;- h2o.load_frame(prostate.key, "/tmp/prostate")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.loadGrid'>Loads previously saved grid with all it's models from the same folder</h2><span id='topic+h2o.loadGrid'></span>

<h3>Description</h3>

<p>Returns a reference to the loaded Grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.loadGrid(grid_path, load_params_references = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.loadGrid_+3A_grid_path">grid_path</code></td>
<td>
<p>A character string containing the path to the file with the grid saved.</p>
</td></tr>
<tr><td><code id="h2o.loadGrid_+3A_load_params_references">load_params_references</code></td>
<td>
<p>A logical which if true will attemt to reload saved objects referenced by 
grid parameters (e.g. training frame, calibration frame), will fail if grid was saved 
without referenced objects.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris &lt;- as.h2o(iris)

ntrees_opts = c(1, 5)
learn_rate_opts = c(0.1, 0.01)
size_of_hyper_space = length(ntrees_opts) * length(learn_rate_opts)

hyper_parameters = list(ntrees = ntrees_opts, learn_rate = learn_rate_opts)
# Tempdir is chosen arbitrarily. May be any valid folder on an H2O-supported filesystem.
baseline_grid &lt;- h2o.grid("gbm", grid_id="gbm_grid_test", x=1:4, y=5, training_frame=iris,
hyper_params = hyper_parameters, export_checkpoints_dir = tempdir())
# Remove everything from the cluster or restart it
h2o.removeAll()
grid &lt;- h2o.loadGrid(paste0(tempdir(),"/",baseline_grid@grid_id))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.loadModel'>Load H2O Model from HDFS or Local Disk</h2><span id='topic+h2o.loadModel'></span>

<h3>Description</h3>

<p>Load a saved H2O model from disk. (Note that ensemble binary models 
can now be loaded using this method.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.loadModel(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.loadModel_+3A_path">path</code></td>
<td>
<p>The path of the H2O Model to be imported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <a href="#topic+H2OModel-class">H2OModel</a> object of the class corresponding to the type of model
loaded.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.saveModel">h2o.saveModel</a>, <a href="#topic+H2OModel-class">H2OModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
# prostate = h2o.importFile(path = prostate_path)
# prostate_glm = h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
#   training_frame = prostate, family = "binomial", alpha = 0.5)
# glmmodel_path = h2o.saveModel(prostate_glm, dir = "/Users/UserName/Desktop")
# glmmodel_load = h2o.loadModel(glmmodel_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.log'>Compute the logarithm of x</h2><span id='topic+h2o.log'></span>

<h3>Description</h3>

<p>Compute the logarithm of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.log(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.log_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Log">Log</a></code> for the base R implementation, <code>log</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.log(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.log10'>Compute the log10 of x</h2><span id='topic+h2o.log10'></span>

<h3>Description</h3>

<p>Compute the log10 of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.log10(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.log10_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Log">Log</a></code> for the base R implementation, <code>log10()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.log10(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.log1p'>Compute the log1p of x</h2><span id='topic+h2o.log1p'></span>

<h3>Description</h3>

<p>Compute the log1p of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.log1p(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.log1p_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Log">Log</a></code> for the base R implementation, <code>log1p()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.log1p(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.log2'>Compute the log2 of x</h2><span id='topic+h2o.log2'></span>

<h3>Description</h3>

<p>Compute the log2 of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.log2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.log2_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Log">Log</a></code> for the base R implementation, <code>log2()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.log2(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.logAndEcho'>Log a message on the server-side logs</h2><span id='topic+h2o.logAndEcho'></span>

<h3>Description</h3>

<p>This is helpful when running several pieces of work one after the other on a single H2O
cluster and you want to make a notation in the H2O server side log where one piece of
work ends and the next piece of work begins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.logAndEcho(message)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.logAndEcho_+3A_message">message</code></td>
<td>
<p>A character string with the message to write to the log.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>h2o.logAndEcho</code> sends a message to H2O for logging. Generally used for debugging purposes.
</p>

<hr>
<h2 id='h2o.loglikelihood'>Retrieve the log likelihood value</h2><span id='topic+h2o.loglikelihood'></span>

<h3>Description</h3>

<p>Retrieves the log likelihood value.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training log likelihood value is returned. If more
than one parameter is set to TRUE, then a named vector of log likelihoods is returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.loglikelihood(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.loglikelihood_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>.</p>
</td></tr>
<tr><td><code id="h2o.loglikelihood_+3A_train">train</code></td>
<td>
<p>Retrieve the training log likelihood</p>
</td></tr>
<tr><td><code id="h2o.loglikelihood_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation log likelihood</p>
</td></tr>
<tr><td><code id="h2o.loglikelihood_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation log likelihood</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
p_sid &lt;- h2o.runif(prostate)
prostate_train &lt;- prostate[p_sid &gt; .2,]
prostate_glm &lt;- h2o.glm(x = 3:7, y = 2, training_frame = prostate_train)
ll_basic &lt;- h2o.loglikelihood(prostate_glm)
print(ll_basic)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.logloss'>Retrieve the Log Loss Value</h2><span id='topic+h2o.logloss'></span>

<h3>Description</h3>

<p>Retrieves the log loss output for a <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> or
<a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a> object
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training Log Loss value is returned. If more
than one parameter is set to TRUE, then a named vector of Log Losses are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.logloss(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.logloss_+3A_object">object</code></td>
<td>
<p>a <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object of the correct type.</p>
</td></tr>
<tr><td><code id="h2o.logloss_+3A_train">train</code></td>
<td>
<p>Retrieve the training Log Loss</p>
</td></tr>
<tr><td><code id="h2o.logloss_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation Log Loss</p>
</td></tr>
<tr><td><code id="h2o.logloss_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation Log Loss</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_splits &lt;- h2o.splitFrame(data =  cars, ratios = .8, seed = 1234)
train &lt;- cars_splits[[1]]
valid &lt;- cars_splits[[2]]
car_drf &lt;- h2o.randomForest(x = predictors, 
                            y = response, 
                            training_frame = train, 
                            validation_frame = valid)
h2o.logloss(car_drf, train = TRUE, valid = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ls'>List Keys on an H2O Cluster</h2><span id='topic+h2o.ls'></span>

<h3>Description</h3>

<p>Accesses a list of object keys in the running instance of H2O.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ls()
</code></pre>


<h3>Value</h3>

<p>Returns a list of hex keys in the current H2O instance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.ls()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.lstrip'>Strip set from left</h2><span id='topic+h2o.lstrip'></span>

<h3>Description</h3>

<p>Return a copy of the target column with leading characters removed. The set argument
is a string specifying the set of characters to be removed. If omitted, the set
argument defaults to removing whitespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.lstrip(x, set = " ")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.lstrip_+3A_x">x</code></td>
<td>
<p>The column whose strings should be lstrip-ed.</p>
</td></tr>
<tr><td><code id="h2o.lstrip_+3A_set">set</code></td>
<td>
<p>string of characters to be removed</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_lstrip &lt;- as.h2o("1234567890")
lstrip_string &lt;- h2o.lstrip(string_to_lstrip, "123") #Remove "123"

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mae'>Retrieve the Mean Absolute Error Value</h2><span id='topic+h2o.mae'></span>

<h3>Description</h3>

<p>Retrieves the mean absolute error (MAE) value from an H2O model.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training MAE value is returned. If more
than one parameter is set to TRUE, then a named vector of MAEs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mae(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mae_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.mae_+3A_train">train</code></td>
<td>
<p>Retrieve the training MAE</p>
</td></tr>
<tr><td><code id="h2o.mae_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation set MAE if a validation set was passed in during model build time.</p>
</td></tr>
<tr><td><code id="h2o.mae_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation MAE</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)

h &lt;- h2o.init()
fr &lt;- as.h2o(iris)

m &lt;- h2o.deeplearning(x = 2:5, y = 1, training_frame = fr)

h2o.mae(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.make_leaderboard'>Create a leaderboard from a list of models, grids and/or automls.</h2><span id='topic+h2o.make_leaderboard'></span>

<h3>Description</h3>

<p>Create a leaderboard from a list of models, grids and/or automls.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.make_leaderboard(
  object,
  leaderboard_frame,
  sort_metric = "AUTO",
  extra_columns = c(),
  scoring_data = c("AUTO", "train", "valid", "xval")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.make_leaderboard_+3A_object">object</code></td>
<td>
<p>List of models, automls, or grids; or just single automl/grid object.</p>
</td></tr>
<tr><td><code id="h2o.make_leaderboard_+3A_leaderboard_frame">leaderboard_frame</code></td>
<td>
<p>Frame used for generating the metrics (optional).</p>
</td></tr>
<tr><td><code id="h2o.make_leaderboard_+3A_sort_metric">sort_metric</code></td>
<td>
<p>Metric used for sorting the leaderboard.</p>
</td></tr>
<tr><td><code id="h2o.make_leaderboard_+3A_extra_columns">extra_columns</code></td>
<td>
<p>What extra columns should be calculated (might require leaderboard_frame). Use &quot;ALL&quot; for all available or list of extra columns.</p>
</td></tr>
<tr><td><code id="h2o.make_leaderboard_+3A_scoring_data">scoring_data</code></td>
<td>
<p>Metrics to be reported in the leaderboard (&quot;xval&quot;, &quot;train&quot;, or &quot;valid&quot;). Used if no leaderboard_frame is provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
grid &lt;- h2o.grid("gbm", x = c(1:4), y = 5, training_frame = iris_hf,
                 hyper_params = list(ntrees = c(1, 2, 3)))
h2o.make_leaderboard(grid, iris_hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.make_metrics'>Create Model Metrics from predicted and actual values in H2O</h2><span id='topic+h2o.make_metrics'></span>

<h3>Description</h3>

<p>Given predicted values (target for regression, class-1 probabilities or binomial
or per-class probabilities for multinomial), compute a model metrics object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.make_metrics(
  predicted,
  actuals,
  domain = NULL,
  distribution = NULL,
  weights = NULL,
  treatment = NULL,
  auc_type = "NONE",
  auuc_type = "AUTO",
  auuc_nbins = -1,
  custom_auuc_thresholds = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.make_metrics_+3A_predicted">predicted</code></td>
<td>
<p>An H2OFrame containing predictions</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_actuals">actuals</code></td>
<td>
<p>An H2OFrame containing actual values</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_domain">domain</code></td>
<td>
<p>Vector with response factors for classification.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_distribution">distribution</code></td>
<td>
<p>Distribution for regression.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_weights">weights</code></td>
<td>
<p>(optional) An H2OFrame containing observation weights.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_treatment">treatment</code></td>
<td>
<p>(optional, for uplift models only) An H2OFrame containing treatment column for uplift classification.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_auc_type">auc_type</code></td>
<td>
<p>(optional) For multinomial classification you have to specify which type of agregated AUC/AUCPR will be used to calculate this metric.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_auuc_type">auuc_type</code></td>
<td>
<p>(optional) For uplift binomial classification you have to specify which type of AUUC will be used to 
calculate this metric. Possibilities are gini, lift, gain, AUTO. Default is AUTO which means qini.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_auuc_nbins">auuc_nbins</code></td>
<td>
<p>(optional) For uplift binomial classification you can specify number of bins to be used 
for calculation the AUUC. Default is -1, which means 1000.</p>
</td></tr>
<tr><td><code id="h2o.make_metrics_+3A_custom_auuc_thresholds">custom_auuc_thresholds</code></td>
<td>
<p>(optional) For uplift binomial classification you can specify exact thresholds to 
calculate AUUC. Default is NULL. If the thresholds are not defined, auuc_nbins will be used to calculate 
new thresholds from the predicted data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of the <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> subclass.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
prostate_gbm &lt;- h2o.gbm(3:9, "CAPSULE", prostate)
pred &lt;- h2o.predict(prostate_gbm, prostate)[, 3] ## class-1 probability
h2o.make_metrics(pred, prostate$CAPSULE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.makeGLMModel'>Set betas of an existing H2O GLM Model</h2><span id='topic+h2o.makeGLMModel'></span>

<h3>Description</h3>

<p>This function allows setting betas of an existing glm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.makeGLMModel(model, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.makeGLMModel_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> corresponding from a <code>h2o.glm</code> call.</p>
</td></tr>
<tr><td><code id="h2o.makeGLMModel_+3A_beta">beta</code></td>
<td>
<p>a new set of betas (a named vector)</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.match'>Value Matching in H2O</h2><span id='topic+h2o.match'></span><span id='topic+match.H2OFrame'></span><span id='topic++25in+25'></span>

<h3>Description</h3>

<p><code>match</code> and <code>%in%</code> return values similar to the base R generic
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.match(x, table, nomatch = 0, incomparables = NULL)

match.H2OFrame(x, table, nomatch = 0, incomparables = NULL)

x %in% table
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.match_+3A_x">x</code></td>
<td>
<p>a categorical vector from an H2OFrame object with
values to be matched.</p>
</td></tr>
<tr><td><code id="h2o.match_+3A_table">table</code></td>
<td>
<p>an R object to match <code>x</code> against.</p>
</td></tr>
<tr><td><code id="h2o.match_+3A_nomatch">nomatch</code></td>
<td>
<p>the value to be returned in the case when no match is found.</p>
</td></tr>
<tr><td><code id="h2o.match_+3A_incomparables">incomparables</code></td>
<td>
<p>a vector of calues that cannot be matched. Any value in
<code>x</code> matching a value in this vector is assigned the
<code>nomatch</code> value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of the positions of (first) matches of its first argument in its second
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match">match</a></code> for base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
iris_hf &lt;- as.h2o(iris)
h2o.match(iris_hf[, 5], c("setosa", "versicolor"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.max'>Returns the maxima of the input values.</h2><span id='topic+h2o.max'></span>

<h3>Description</h3>

<p>Returns the maxima of the input values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.max(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.max_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.max_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. indicating whether missing values should be removed.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Extremes">Extremes</a></code> for the base R implementation, <code>max()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.max(iris["petal_len"], na.rm = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mean'>Compute the frame's mean by-column (or by-row).</h2><span id='topic+h2o.mean'></span><span id='topic+mean.H2OFrame'></span>

<h3>Description</h3>

<p>Compute the frame's mean by-column (or by-row).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mean(x, na.rm = FALSE, axis = 0, return_frame = FALSE, ...)

## S3 method for class 'H2OFrame'
mean(x, na.rm = FALSE, axis = 0, return_frame = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mean_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.mean_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Indicate whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="h2o.mean_+3A_axis">axis</code></td>
<td>
<p><code>integer</code>. Indicate whether to calculate the mean down a column (0) or across a row (1).
NOTE: This is only applied when return_frame is set to TRUE. Otherwise, this parameter
is ignored.</p>
</td></tr>
<tr><td><code id="h2o.mean_+3A_return_frame">return_frame</code></td>
<td>
<p><code>logical</code>. Indicate whether to return an H2O frame or a list. Default is FALSE (returns a list).</p>
</td></tr>
<tr><td><code id="h2o.mean_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the mean for each column (NaN for non-numeric columns) if return_frame is set to FALSE.
If return_frame is set to TRUE, then it will return an H2O frame with means per column or row (depends on axis argument).
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for base R implementation, <code>mean()</code> and <code><a href="base.html#topic+colSums">colSums</a></code> for the base R implementation, <code>colMeans()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
# Default behavior. Will return list of means per column.
h2o.mean(prostate$AGE)
# return_frame set to TRUE. This will return an H2O Frame
# with mean per row or column (depends on axis argument)
h2o.mean(prostate, na.rm = TRUE, axis = 1, return_frame = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mean_per_class_error'>Retrieve the mean per class error</h2><span id='topic+h2o.mean_per_class_error'></span>

<h3>Description</h3>

<p>Retrieves the mean per class error from an <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training mean per class error value is returned. If more
than one parameter is set to TRUE, then a named vector of mean per class errors are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mean_per_class_error(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mean_per_class_error_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.mean_per_class_error_+3A_train">train</code></td>
<td>
<p>Retrieve the training mean per class error</p>
</td></tr>
<tr><td><code id="h2o.mean_per_class_error_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation mean per class error</p>
</td></tr>
<tr><td><code id="h2o.mean_per_class_error_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation mean per class error</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the
various threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for
creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.mean_per_class_error(perf)
h2o.mean_per_class_error(model, train=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mean_residual_deviance'>Retrieve the Mean Residual Deviance value</h2><span id='topic+h2o.mean_residual_deviance'></span>

<h3>Description</h3>

<p>Retrieves the Mean Residual Deviance value from an H2O model.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training Mean Residual Deviance value is returned. If more
than one parameter is set to TRUE, then a named vector of Mean Residual Deviances are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mean_residual_deviance(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mean_residual_deviance_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.mean_residual_deviance_+3A_train">train</code></td>
<td>
<p>Retrieve the training Mean Residual Deviance</p>
</td></tr>
<tr><td><code id="h2o.mean_residual_deviance_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation Mean Residual Deviance</p>
</td></tr>
<tr><td><code id="h2o.mean_residual_deviance_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation Mean Residual Deviance</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)

h &lt;- h2o.init()
fr &lt;- as.h2o(iris)

m &lt;- h2o.deeplearning(x = 2:5, y = 1, training_frame = fr)

h2o.mean_residual_deviance(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.median'>H2O Median</h2><span id='topic+h2o.median'></span><span id='topic+median.H2OFrame'></span>

<h3>Description</h3>

<p>Compute the median of an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.median(x, na.rm = TRUE)

## S3 method for class 'H2OFrame'
median(x, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.median_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.median_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical, indicating whether na's are omitted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the median for each column (NaN for non-numeric columns)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.median(prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.melt'>Converts a frame to key-value representation while optionally skipping NA values.
Inverse operation to h2o.pivot.</h2><span id='topic+h2o.melt'></span>

<h3>Description</h3>

<p>Pivot the frame designated by the three columns: index, column, and value. Index and column should be
of type enum, int, or time.
For cases of multiple indexes for a column label, the aggregation method is to pick the first occurrence in the data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.melt(
  x,
  id_vars,
  value_vars = NULL,
  var_name = "variable",
  value_name = "value",
  skipna = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.melt_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.melt_+3A_id_vars">id_vars</code></td>
<td>
<p>the columns used as identifiers</p>
</td></tr>
<tr><td><code id="h2o.melt_+3A_value_vars">value_vars</code></td>
<td>
<p>what columns will be converted to key-value pairs (optional, if not specified complement to id_vars will be used)</p>
</td></tr>
<tr><td><code id="h2o.melt_+3A_var_name">var_name</code></td>
<td>
<p>name of the key-column (default: &quot;variable&quot;)</p>
</td></tr>
<tr><td><code id="h2o.melt_+3A_value_name">value_name</code></td>
<td>
<p>name of the value-column (default: &quot;value&quot;)</p>
</td></tr>
<tr><td><code id="h2o.melt_+3A_skipna">skipna</code></td>
<td>
<p>if enabled, do not include NAs in the result (default: FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an unpivoted H2OFrame
</p>

<hr>
<h2 id='h2o.merge'>Merge Two H2O Data Frames</h2><span id='topic+h2o.merge'></span>

<h3>Description</h3>

<p>Merges two H2OFrame objects with the same arguments and meanings
as merge() in base R.  However, we do not support all=TRUE, all.x=TRUE and all.y=TRUE.  The default method is auto
and it will default to the
radix method.  The radix method will return the correct merge result regardless of duplicated rows
in the right frame.  In addition, the radix method can perform merge even if you have string columns
in your frames.  If there are duplicated rows in your rite frame, they will not be included if you use
the hash method.  The hash method cannot perform merge if you have string columns in your left frame.
Hence, we consider the radix method superior to the hash method and is the default method to use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.merge(
  x,
  y,
  by = intersect(names(x), names(y)),
  by.x = by,
  by.y = by,
  all = FALSE,
  all.x = all,
  all.y = all,
  method = "auto"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.merge_+3A_x">x</code>, <code id="h2o.merge_+3A_y">y</code></td>
<td>
<p>H2OFrame objects</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_by">by</code></td>
<td>
<p>columns used for merging by default the common names</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_by.x">by.x</code></td>
<td>
<p>x columns used for merging by name or number</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_by.y">by.y</code></td>
<td>
<p>y columns used for merging by name or number</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_all">all</code></td>
<td>
<p>TRUE includes all rows in x and all rows in y even if there is no match to the other</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_all.x">all.x</code></td>
<td>
<p>If all.x is true, all rows in the x will be included, even if there is no matching
row in y, and vice-versa for all.y.</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_all.y">all.y</code></td>
<td>
<p>see all.x</p>
</td></tr>
<tr><td><code id="h2o.merge_+3A_method">method</code></td>
<td>
<p>auto(default), radix, hash</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
left &lt;- data.frame(fruit = c('apple', 'orange', 'banana', 'lemon', 'strawberry', 'blueberry'),
color &lt;- c('red', 'orange', 'yellow', 'yellow', 'red', 'blue'))
right &lt;- data.frame(fruit = c('apple', 'orange', 'banana', 'lemon', 'strawberry', 'watermelon'),
citrus &lt;- c(FALSE, TRUE, FALSE, TRUE, FALSE, FALSE))
left_hf &lt;- as.h2o(left)
right_hf &lt;- as.h2o(right)
merged &lt;- h2o.merge(left_hf, right_hf, all.x = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.metric'>H2O Model Metric Accessor Functions</h2><span id='topic+h2o.metric'></span><span id='topic+h2o.F0point5'></span><span id='topic+h2o.F1'></span><span id='topic+h2o.F2'></span><span id='topic+h2o.accuracy'></span><span id='topic+h2o.error'></span><span id='topic+h2o.maxPerClassError'></span><span id='topic+h2o.mean_per_class_accuracy'></span><span id='topic+h2o.mcc'></span><span id='topic+h2o.precision'></span><span id='topic+h2o.tpr'></span><span id='topic+h2o.fpr'></span><span id='topic+h2o.fnr'></span><span id='topic+h2o.tnr'></span><span id='topic+h2o.recall'></span><span id='topic+h2o.sensitivity'></span><span id='topic+h2o.fallout'></span><span id='topic+h2o.missrate'></span><span id='topic+h2o.specificity'></span>

<h3>Description</h3>

<p>A series of functions that retrieve model metric details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.metric(object, thresholds, metric, transform = NULL)

h2o.F0point5(object, thresholds)

h2o.F1(object, thresholds)

h2o.F2(object, thresholds)

h2o.accuracy(object, thresholds)

h2o.error(object, thresholds)

h2o.maxPerClassError(object, thresholds)

h2o.mean_per_class_accuracy(object, thresholds)

h2o.mcc(object, thresholds)

h2o.precision(object, thresholds)

h2o.tpr(object, thresholds)

h2o.fpr(object, thresholds)

h2o.fnr(object, thresholds)

h2o.tnr(object, thresholds)

h2o.recall(object, thresholds)

h2o.sensitivity(object, thresholds)

h2o.fallout(object, thresholds)

h2o.missrate(object, thresholds)

h2o.specificity(object, thresholds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.metric_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object of the correct type.</p>
</td></tr>
<tr><td><code id="h2o.metric_+3A_thresholds">thresholds</code></td>
<td>
<p>(Optional) A value or a list of values between 0.0 and 1.0.
If not set, then all thresholds will be returned.
If &quot;max&quot;, then the threshold maximizing the metric will be used.</p>
</td></tr>
<tr><td><code id="h2o.metric_+3A_metric">metric</code></td>
<td>
<p>(Optional) the metric to retrieve.
If not set, then all metrics will be returned.</p>
</td></tr>
<tr><td><code id="h2o.metric_+3A_transform">transform</code></td>
<td>
<p>(Optional) a list describing a transformer for the given metric, if any.
e.g. transform=list(op=foo_fn, name=&quot;foo&quot;) will rename the given metric to &quot;foo&quot;
and apply function foo_fn to the metric values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many of these functions have an optional thresholds parameter. Currently
only increments of 0.1 are allowed. If not specified, the functions will
return all possible values. Otherwise, the function will return the value for
the indicated threshold.
</p>
<p>Currently, the these functions are only supported by
<a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a> objects.
</p>


<h3>Value</h3>

<p>Returns either a single value, or a list of values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.auc">h2o.auc</a></code> for AUC, <code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the
GINI coefficient, and <code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE. See
<code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.F1(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.min'>Returns the minima of the input values.</h2><span id='topic+h2o.min'></span>

<h3>Description</h3>

<p>Returns the minima of the input values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.min(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.min_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.min_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. indicating whether missing values should be removed.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Extremes">Extremes</a></code> for the base R implementation, <code>min()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.min(iris["sepal_len"], na.rm = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mktime'>Compute msec since the Unix Epoch</h2><span id='topic+h2o.mktime'></span>

<h3>Description</h3>

<p>Compute msec since the Unix Epoch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mktime(
  year = 1970,
  month = 0,
  day = 0,
  hour = 0,
  minute = 0,
  second = 0,
  msec = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mktime_+3A_year">year</code></td>
<td>
<p>Defaults to 1970</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_month">month</code></td>
<td>
<p>zero based (months are 0 to 11)</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_day">day</code></td>
<td>
<p>zero based (days are 0 to 30)</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_hour">hour</code></td>
<td>
<p>hour</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_minute">minute</code></td>
<td>
<p>minute</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_second">second</code></td>
<td>
<p>second</p>
</td></tr>
<tr><td><code id="h2o.mktime_+3A_msec">msec</code></td>
<td>
<p>msec</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

x = as.h2o(c(2018, 3, 2, 6, 32, 0, 0))
h2o.mktime(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.model_correlation'>Model Prediction Correlation</h2><span id='topic+h2o.model_correlation'></span>

<h3>Description</h3>

<p>Get a data.frame containing the correlation between the predictions of the models.
For classification, frequency of identical predictions is used. By default, models
are ordered by their similarity (as computed by hierarchical clustering).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.model_correlation(object, newdata, top_n = 20, cluster_models = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.model_correlation_+3A_object">object</code></td>
<td>
<p>A list of H2O models, an H2O AutoML instance, or an H2OFrame with a 'model_id' column (e.g. H2OAutoML leaderboard)..</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_+3A_newdata">newdata</code></td>
<td>
<p>An H2O Frame.  Predictions from the models will be generated using this frame,
so this should be a holdout set.</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_+3A_top_n">top_n</code></td>
<td>
<p>(DEPRECATED) Integer specifying the number models shown in the heatmap (used only with an
AutoML object, and based on the leaderboard ranking.  Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_+3A_cluster_models">cluster_models</code></td>
<td>
<p>Logical.  Order models based on their similarity.  Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing variable importance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the model correlation
model_correlation &lt;- h2o.model_correlation(aml, test)
print(model_correlation)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.model_correlation_heatmap'>Model Prediction Correlation Heatmap</h2><span id='topic+h2o.model_correlation_heatmap'></span>

<h3>Description</h3>

<p>This plot shows the correlation between the predictions of the models.
For classification, frequency of identical predictions is used. By default, models
are ordered by their similarity (as computed by hierarchical clustering).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.model_correlation_heatmap(
  object,
  newdata,
  top_n = 20,
  cluster_models = TRUE,
  triangular = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.model_correlation_heatmap_+3A_object">object</code></td>
<td>
<p>A list of H2O models, an H2O AutoML instance, or an H2OFrame with a 'model_id' column (e.g. H2OAutoML leaderboard).</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_heatmap_+3A_newdata">newdata</code></td>
<td>
<p>An H2O Frame.  Predictions from the models will be generated using this frame,
so this should be a holdout set.</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_heatmap_+3A_top_n">top_n</code></td>
<td>
<p>Integer specifying the number models shown in the heatmap (used only with an
AutoML object, and based on the leaderboard ranking.  Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_heatmap_+3A_cluster_models">cluster_models</code></td>
<td>
<p>Logical.  Order models based on their similarity.  Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.model_correlation_heatmap_+3A_triangular">triangular</code></td>
<td>
<p>Print just the lower triangular part of correlation matrix.  Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the model correlation heatmap
model_correlation_heatmap &lt;- h2o.model_correlation_heatmap(aml, test)
print(model_correlation_heatmap)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.modelSelection'>H2O ModelSelection is used to build the best model with one predictor, two predictors, ... up to max_predictor_number 
specified in the algorithm parameters when mode=allsubsets.  The best model is the one with the highest R2 value.  When
mode=maxr, the model returned is no longer guaranteed to have the best R2 value.</h2><span id='topic+h2o.modelSelection'></span>

<h3>Description</h3>

<p>H2O ModelSelection is used to build the best model with one predictor, two predictors, ... up to max_predictor_number 
specified in the algorithm parameters when mode=allsubsets.  The best model is the one with the highest R2 value.  When
mode=maxr, the model returned is no longer guaranteed to have the best R2 value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.modelSelection(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  seed = -1,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  score_iteration_interval = 0,
  offset_column = NULL,
  weights_column = NULL,
  family = c("AUTO", "gaussian", "binomial", "fractionalbinomial", "quasibinomial",
    "poisson", "gamma", "tweedie", "negativebinomial"),
  link = c("family_default", "identity", "logit", "log", "inverse", "tweedie", "ologit"),
  tweedie_variance_power = 0,
  tweedie_link_power = 0,
  theta = 0,
  solver = c("AUTO", "IRLSM", "L_BFGS", "COORDINATE_DESCENT_NAIVE", "COORDINATE_DESCENT",
    "GRADIENT_DESCENT_LH", "GRADIENT_DESCENT_SQERR"),
  alpha = NULL,
  lambda = c(0),
  lambda_search = FALSE,
  early_stopping = FALSE,
  nlambdas = 0,
  standardize = TRUE,
  missing_values_handling = c("MeanImputation", "Skip", "PlugValues"),
  plug_values = NULL,
  compute_p_values = FALSE,
  remove_collinear_columns = FALSE,
  intercept = TRUE,
  non_negative = FALSE,
  max_iterations = 0,
  objective_epsilon = -1,
  beta_epsilon = 1e-04,
  gradient_epsilon = -1,
  startval = NULL,
  prior = 0,
  cold_start = FALSE,
  lambda_min_ratio = 0,
  beta_constraints = NULL,
  max_active_predictors = -1,
  obj_reg = -1,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  max_runtime_secs = 0,
  custom_metric_func = NULL,
  nparallelism = 0,
  max_predictor_number = 1,
  min_predictor_number = 1,
  mode = c("allsubsets", "maxr", "maxrsweep", "backward"),
  build_glm_model = FALSE,
  p_values_threshold = 0,
  influence = c("dfbetas"),
  multinode_mode = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.modelSelection_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_score_iteration_interval">score_iteration_interval</code></td>
<td>
<p>Perform scoring for every score_iteration_interval iterations Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_family">family</code></td>
<td>
<p>Family. For maxr/maxrsweep, only gaussian.  For backward, ordinal and multinomial families are not supported
Must be one of: &quot;AUTO&quot;, &quot;gaussian&quot;, &quot;binomial&quot;, &quot;fractionalbinomial&quot;, &quot;quasibinomial&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;negativebinomial&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_link">link</code></td>
<td>
<p>Link function. Must be one of: &quot;family_default&quot;, &quot;identity&quot;, &quot;logit&quot;, &quot;log&quot;, &quot;inverse&quot;, &quot;tweedie&quot;, &quot;ologit&quot;.
Defaults to family_default.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_tweedie_variance_power">tweedie_variance_power</code></td>
<td>
<p>Tweedie variance power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_tweedie_link_power">tweedie_link_power</code></td>
<td>
<p>Tweedie link power Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_theta">theta</code></td>
<td>
<p>Theta Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_solver">solver</code></td>
<td>
<p>AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small
number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many
columns. Must be one of: &quot;AUTO&quot;, &quot;IRLSM&quot;, &quot;L_BFGS&quot;, &quot;COORDINATE_DESCENT_NAIVE&quot;, &quot;COORDINATE_DESCENT&quot;,
&quot;GRADIENT_DESCENT_LH&quot;, &quot;GRADIENT_DESCENT_SQERR&quot;. Defaults to IRLSM.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_alpha">alpha</code></td>
<td>
<p>Distribution of regularization between the L1 (Lasso) and L2 (Ridge) penalties. A value of 1 for alpha
represents Lasso regression, a value of 0 produces Ridge regression, and anything in between specifies the
amount of mixing between the two. Default value of alpha is 0 when SOLVER = 'L-BFGS'; 0.5 otherwise.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_lambda">lambda</code></td>
<td>
<p>Regularization strength Defaults to c(0.0).</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_lambda_search">lambda_search</code></td>
<td>
<p><code>Logical</code>. Use lambda search starting at lambda max, given lambda is then interpreted as lambda min
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_early_stopping">early_stopping</code></td>
<td>
<p><code>Logical</code>. Stop early when there is no more relative improvement on train or validation (if provided)
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_nlambdas">nlambdas</code></td>
<td>
<p>Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,
the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.
Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_standardize">standardize</code></td>
<td>
<p><code>Logical</code>. Standardize numeric columns to have zero mean and unit variance Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_missing_values_handling">missing_values_handling</code></td>
<td>
<p>Handling of missing values. Either MeanImputation, Skip or PlugValues. Must be one of: &quot;MeanImputation&quot;,
&quot;Skip&quot;, &quot;PlugValues&quot;. Defaults to MeanImputation.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_plug_values">plug_values</code></td>
<td>
<p>Plug Values (a single row frame containing values that will be used to impute missing values of the
training/validation frame, use with conjunction missing_values_handling = PlugValues)</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_compute_p_values">compute_p_values</code></td>
<td>
<p><code>Logical</code>. Request p-values computation, p-values work only with IRLSM solver and no regularization
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_remove_collinear_columns">remove_collinear_columns</code></td>
<td>
<p><code>Logical</code>. In case of linearly dependent columns, remove some of the dependent columns Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_intercept">intercept</code></td>
<td>
<p><code>Logical</code>. Include constant term in the model Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_non_negative">non_negative</code></td>
<td>
<p><code>Logical</code>. Restrict coefficients (not intercept) to be non-negative Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iterations Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_objective_epsilon">objective_epsilon</code></td>
<td>
<p>Converge if  objective value changes less than this. Default (of -1.0) indicates: If lambda_search is set to
True the value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal
to zero, the value of objective_epsilon is set to .000001, for any other value of lambda the default value of
objective_epsilon is set to .0001. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_beta_epsilon">beta_epsilon</code></td>
<td>
<p>Converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver
Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_gradient_epsilon">gradient_epsilon</code></td>
<td>
<p>Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default
(of -1.0) indicates: If lambda_search is set to False and lambda is equal to zero, the default value of
gradient_epsilon is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True,
the conditional values above are 1E-8 and 1E-6 respectively. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_startval">startval</code></td>
<td>
<p>double array to initialize fixed and random coefficients for HGLM, coefficients for GLM.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_prior">prior</code></td>
<td>
<p>Prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean
of response does not reflect reality. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_cold_start">cold_start</code></td>
<td>
<p><code>Logical</code>. Only applicable to multiple alpha/lambda values.  If false, build the next model for next set
of alpha/lambda values starting from the values provided by current model.  If true will start GLM model from
scratch. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>Minimum lambda used in lambda search, specified as a ratio of lambda_max (the smallest lambda that drives all
coefficients to zero). Default indicates: if the number of observations is greater than the number of
variables, then lambda_min_ratio is set to 0.0001; if the number of observations is less than the number of
variables, then lambda_min_ratio is set to 0.01. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_beta_constraints">beta_constraints</code></td>
<td>
<p>Beta constraints</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_max_active_predictors">max_active_predictors</code></td>
<td>
<p>Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model
building with many predictors. Default indicates: If the IRLSM solver is used, the value of
max_active_predictors is set to 5000 otherwise it is set to 100000000. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_obj_reg">obj_reg</code></td>
<td>
<p>Likelihood divider in objective value computation, default (of -1.0) will set it to 1/nobs Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_nparallelism">nparallelism</code></td>
<td>
<p>number of models to build in parallel.  Defaults to 0.0 which is adaptive to the system capability Defaults to
0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_max_predictor_number">max_predictor_number</code></td>
<td>
<p>Maximum number of predictors to be considered when building GLM models.  Defaults to 1. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_min_predictor_number">min_predictor_number</code></td>
<td>
<p>For mode = 'backward' only.  Minimum number of predictors to be considered when building GLM models starting
with all predictors to be included.  Defaults to 1. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_mode">mode</code></td>
<td>
<p>Mode: Used to choose model selection algorithms to use.  Options include 'allsubsets' for all subsets, 'maxr'
that uses sequential replacement and GLM to build all models, slow but works with cross-validation, validation
frames for more robust results, 'maxrsweep' that uses sequential replacement and sweeping action, much faster
than 'maxr', 'backward' for backward selection. Must be one of: &quot;allsubsets&quot;, &quot;maxr&quot;, &quot;maxrsweep&quot;, &quot;backward&quot;.
Defaults to maxr.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_build_glm_model">build_glm_model</code></td>
<td>
<p><code>Logical</code>. For maxrsweep mode only.  If true, will return full blown GLM models with the desired
predictorsubsets.  If false, only the predictor subsets, predictor coefficients are returned.  This is
forspeeding up the model selection process.  The users can choose to build the GLM models themselvesby using
the predictor subsets themselves.  Defaults to false. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_p_values_threshold">p_values_threshold</code></td>
<td>
<p>For mode='backward' only.  If specified, will stop the model building process when all coefficientsp-values
drop below this threshold  Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_influence">influence</code></td>
<td>
<p>If set to dfbetas will calculate the difference in beta when a datarow is included and excluded in the
dataset. Must be one of: &quot;dfbetas&quot;.</p>
</td></tr>
<tr><td><code id="h2o.modelSelection_+3A_multinode_mode">multinode_mode</code></td>
<td>
<p><code>Logical</code>. For maxrsweep only.  If enabled, will attempt to perform sweeping action using multiple nodes
in the cluster.  Defaults to false. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
# Run ModelSelection of VOL ~ all predictors
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
model &lt;- h2o.modelSelection(y="VOL", x=c("RACE","AGE","RACE","DPROS"), training_frame=prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mojo_predict_csv'>H2O Prediction from R without having H2O running</h2><span id='topic+h2o.mojo_predict_csv'></span>

<h3>Description</h3>

<p>Provides the method h2o.mojo_predict_csv with which you can predict a MOJO model from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mojo_predict_csv(
  input_csv_path,
  mojo_zip_path,
  output_csv_path = NULL,
  genmodel_jar_path = NULL,
  classpath = NULL,
  java_options = NULL,
  verbose = F,
  setInvNumNA = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mojo_predict_csv_+3A_input_csv_path">input_csv_path</code></td>
<td>
<p>Path to input CSV file.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_mojo_zip_path">mojo_zip_path</code></td>
<td>
<p>Path to MOJO zip downloaded from H2O.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_output_csv_path">output_csv_path</code></td>
<td>
<p>Optional, path to the output CSV file with computed predictions. If NULL (default), then predictions will be saved as prediction.csv in the same folder as the MOJO zip.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_genmodel_jar_path">genmodel_jar_path</code></td>
<td>
<p>Optional, path to genmodel jar file. If NULL (default) then the h2o-genmodel.jar in the same folder as the MOJO zip will be used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_classpath">classpath</code></td>
<td>
<p>Optional, specifies custom user defined classpath which will be used when scoring. If NULL (default) then the default classpath for this MOJO model will be used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_java_options">java_options</code></td>
<td>
<p>Optional, custom user defined options for Java. By default '-Xmx4g -XX:ReservedCodeCacheSize=256m' is used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_verbose">verbose</code></td>
<td>
<p>Optional, if TRUE, then additional debug information will be printed. FALSE by default.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_csv_+3A_setinvnumna">setInvNumNA</code></td>
<td>
<p>Optional, if TRUE, then then for an string that cannot be parsed into a number an N/A value will be produced, if false the command will fail. FALSE by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame containing computed predictions
</p>

<hr>
<h2 id='h2o.mojo_predict_df'>H2O Prediction from R without having H2O running</h2><span id='topic+h2o.mojo_predict_df'></span>

<h3>Description</h3>

<p>Provides the method h2o.mojo_predict_df with which you can predict a MOJO model from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mojo_predict_df(
  frame,
  mojo_zip_path,
  genmodel_jar_path = NULL,
  classpath = NULL,
  java_options = NULL,
  verbose = F,
  setInvNumNA = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mojo_predict_df_+3A_frame">frame</code></td>
<td>
<p>data.frame to score.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_mojo_zip_path">mojo_zip_path</code></td>
<td>
<p>Path to MOJO zip downloaded from H2O.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_genmodel_jar_path">genmodel_jar_path</code></td>
<td>
<p>Optional, path to genmodel jar file. If NULL (default) then the h2o-genmodel.jar in the same folder as the MOJO zip will be used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_classpath">classpath</code></td>
<td>
<p>Optional, specifies custom user defined classpath which will be used when scoring. If NULL (default) then the default classpath for this MOJO model will be used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_java_options">java_options</code></td>
<td>
<p>Optional, custom user defined options for Java. By default '-Xmx4g -XX:ReservedCodeCacheSize=256m' is used.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_verbose">verbose</code></td>
<td>
<p>Optional, if TRUE, then additional debug information will be printed. FALSE by default.</p>
</td></tr>
<tr><td><code id="h2o.mojo_predict_df_+3A_setinvnumna">setInvNumNA</code></td>
<td>
<p>Optional, if TRUE, then then for an string that cannot be parsed into a number an N/A value will be produced, if false the command will fail. FALSE by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame containing computed predictions
</p>

<hr>
<h2 id='h2o.month'>Convert Milliseconds to Months in H2O Datasets</h2><span id='topic+h2o.month'></span><span id='topic+month'></span><span id='topic+month.H2OFrame'></span>

<h3>Description</h3>

<p>Converts the entries of an H2OFrame object from milliseconds to months (on a 1 to
12 scale).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.month(x)

month(x)

## S3 method for class 'H2OFrame'
month(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.month_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to months of
the year.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.year">h2o.year</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.month(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.mse'>Retrieves Mean Squared Error Value</h2><span id='topic+h2o.mse'></span>

<h3>Description</h3>

<p>Retrieves the mean squared error value from an <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>
object.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training MSEvalue is returned. If more
than one parameter is set to TRUE, then a named vector of MSEs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.mse(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.mse_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object of the correct type.</p>
</td></tr>
<tr><td><code id="h2o.mse_+3A_train">train</code></td>
<td>
<p>Retrieve the training MSE</p>
</td></tr>
<tr><td><code id="h2o.mse_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation MSE</p>
</td></tr>
<tr><td><code id="h2o.mse_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation MSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only supports <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>,
<a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a>, and <a href="#topic+H2ORegressionMetrics-class">H2ORegressionMetrics</a> objects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.auc">h2o.auc</a></code> for AUC, <code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and
<code><a href="#topic+h2o.metric">h2o.metric</a></code> for the various threshold metrics. See
<code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.mse(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.multinomial_auc_table'>Retrieve the all AUC values in a table (One to Rest, One to One, macro and weighted average) 
for mutlinomial classification.</h2><span id='topic+h2o.multinomial_auc_table'></span>

<h3>Description</h3>

<p>Retrieves the AUC table from an <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training AUC table is returned. If more
than one parameter is set to TRUE, then a named vector of AUC tables are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.multinomial_auc_table(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.multinomial_auc_table_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.multinomial_auc_table_+3A_train">train</code></td>
<td>
<p>Retrieve the training AUC table</p>
</td></tr>
<tr><td><code id="h2o.multinomial_auc_table_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation AUC table</p>
</td></tr>
<tr><td><code id="h2o.multinomial_auc_table_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation AUC table</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the Gini coefficient,
<code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the
various threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for
creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.multinomial_auc_table(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.multinomial_aucpr_table'>Retrieve the all PR AUC values in a table (One to Rest, One to One, macro and weighted average) 
for mutlinomial classification.</h2><span id='topic+h2o.multinomial_aucpr_table'></span>

<h3>Description</h3>

<p>Retrieves the PR AUC table from an <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a>.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training PR AUC table is returned. If more
than one parameter is set to TRUE, then a named vector of PR AUC tables are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.multinomial_aucpr_table(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.multinomial_aucpr_table_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a> object.</p>
</td></tr>
<tr><td><code id="h2o.multinomial_aucpr_table_+3A_train">train</code></td>
<td>
<p>Retrieve the training PR AUC table</p>
</td></tr>
<tr><td><code id="h2o.multinomial_aucpr_table_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation PR AUC table</p>
</td></tr>
<tr><td><code id="h2o.multinomial_aucpr_table_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation PR AUC table</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.giniCoef">h2o.giniCoef</a></code> for the Gini coefficient,
<code><a href="#topic+h2o.mse">h2o.mse</a></code> for MSE, and <code><a href="#topic+h2o.metric">h2o.metric</a></code> for the
various threshold metrics. See <code><a href="#topic+h2o.performance">h2o.performance</a></code> for
creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.multinomial_aucpr_table(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.na_omit'>Remove Rows With NAs</h2><span id='topic+h2o.na_omit'></span>

<h3>Description</h3>

<p>Remove Rows With NAs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.na_omit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.na_omit_+3A_object">object</code></td>
<td>
<p>H2OFrame object</p>
</td></tr>
<tr><td><code id="h2o.na_omit_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing non-NA rows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.na_omit(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.nacnt'>Count of NAs per column</h2><span id='topic+h2o.nacnt'></span>

<h3>Description</h3>

<p>Gives the count of NAs per column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.nacnt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.nacnt_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the count of NAs per column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
h2o.nacnt(iris_hf)  # should return all 0s
h2o.insertMissingValues(iris_hf)
h2o.nacnt(iris_hf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.naiveBayes'>Compute naive Bayes probabilities on an H2O dataset.</h2><span id='topic+h2o.naiveBayes'></span>

<h3>Description</h3>

<p>The naive Bayes classifier assumes independence between predictor variables conditional
on the response, and a Gaussian distribution of numeric predictors with mean and standard
deviation computed from the training dataset. When building a naive Bayes classifier,
every row in the training dataset that contains at least one NA will be skipped completely.
If the test dataset has missing values, then those predictors are omitted in the probability
calculation during prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.naiveBayes(
  x,
  y,
  training_frame,
  model_id = NULL,
  nfolds = 0,
  seed = -1,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  validation_frame = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  laplace = 0,
  threshold = 0.001,
  min_sdev = 0.001,
  eps = 0,
  eps_sdev = 0,
  min_prob = 0.001,
  eps_prob = 0,
  compute_metrics = TRUE,
  max_runtime_secs = 0,
  export_checkpoints_dir = NULL,
  gainslift_bins = -1,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.naiveBayes_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_laplace">laplace</code></td>
<td>
<p>Laplace smoothing parameter Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_threshold">threshold</code></td>
<td>
<p>This argument is deprecated, use 'min_sdev' instead. The minimum standard deviation to use for observations without enough data.
Must be at least 1e-10.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_min_sdev">min_sdev</code></td>
<td>
<p>The minimum standard deviation to use for observations without enough data.
Must be at least 1e-10.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_eps">eps</code></td>
<td>
<p>This argument is deprecated, use 'eps_sdev' instead. A threshold cutoff to deal with numeric instability, must be positive.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_eps_sdev">eps_sdev</code></td>
<td>
<p>A threshold cutoff to deal with numeric instability, must be positive.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_min_prob">min_prob</code></td>
<td>
<p>Min. probability to use for observations with not enough data.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_eps_prob">eps_prob</code></td>
<td>
<p>Cutoff below which probability is replaced with min_prob.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_compute_metrics">compute_metrics</code></td>
<td>
<p><code>Logical</code>. Compute metrics on training data Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.naiveBayes_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <a href="#topic+H2OBinomialModel-class">H2OBinomialModel</a> if the response has two categorical levels,
and <a href="#topic+H2OMultinomialModel-class">H2OMultinomialModel</a> otherwise.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
votes_path &lt;- system.file("extdata", "housevotes.csv", package = "h2o")
votes &lt;- h2o.uploadFile(path = votes_path, header = TRUE)
h2o.naiveBayes(x = 2:17, y = 1, training_frame = votes, laplace = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.names'>Column names of an H2OFrame</h2><span id='topic+h2o.names'></span>

<h3>Description</h3>

<p>Column names of an H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.names(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.names_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+names">names</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.names(iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.nchar'>String length</h2><span id='topic+h2o.nchar'></span>

<h3>Description</h3>

<p>String length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.nchar(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.nchar_+3A_x">x</code></td>
<td>
<p>The column whose string lengths will be returned.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_nchar &lt;- as.h2o("r tutorial")
nchar_string &lt;- h2o.nchar(string_to_nchar)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.ncol'>Return the number of columns present in x.</h2><span id='topic+h2o.ncol'></span>

<h3>Description</h3>

<p>Return the number of columns present in x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.ncol(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.ncol_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+nrow">nrow</a></code> for the base R implementation, <code>ncol()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.ncol(iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.negative_log_likelihood'>Extracts the final training negative log likelihood of a GLM model.</h2><span id='topic+h2o.negative_log_likelihood'></span>

<h3>Description</h3>

<p>Extracts the final training negative log likelihood of a GLM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.negative_log_likelihood(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.negative_log_likelihood_+3A_model">model</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The final training negative log likelihood of a GLM model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "acceleration"
cars_model &lt;- h2o.glm(y=response, 
                       x=predictors, 
                       training_frame = cars, 
                       family="gaussian",
                       generate_scoring_history=TRUE)
nllValue &lt;- h2o.negative_log_likelihood(cars_model)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.networkTest'>View Network Traffic Speed</h2><span id='topic+h2o.networkTest'></span>

<h3>Description</h3>

<p>View speed with various file sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.networkTest()
</code></pre>


<h3>Value</h3>

<p>Returns a table listing the network speed for 1B, 10KB, and 10MB.
</p>

<hr>
<h2 id='h2o.nlevels'>Get the number of factor levels for this frame.</h2><span id='topic+h2o.nlevels'></span>

<h3>Description</h3>

<p>Get the number of factor levels for this frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.nlevels(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.nlevels_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+nlevels">nlevels</a></code> for the base R method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.nlevels(cars)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.no_progress'>Disable Progress Bar</h2><span id='topic+h2o.no_progress'></span>

<h3>Description</h3>

<p>Disable Progress Bar
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.no_progress(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.no_progress_+3A_expr">expr</code></td>
<td>
<p>When specified, disable progress bar only for the evaluation of the expr and after the evaluation return to the previous setting (default is to show the progress bar), otherwise disable it globally.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of expr if specified, otherwise NULL.
</p>


<h3>See Also</h3>

<p><a href="#topic+h2o.show_progress">h2o.show_progress</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.no_progress()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
iris["class"] &lt;- as.factor(iris["class"])
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
splits &lt;- h2o.splitFrame(iris, ratios = 0.8, seed = 1234)
train &lt;- splits[[1]]
valid &lt;- splits[[2]]

iris_km &lt;- h2o.kmeans(x = predictors, 
                      training_frame = train, 
                      validation_frame = valid, 
                      k = 10, estimate_k = TRUE, 
                      standardize = FALSE, seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.nrow'>Return the number of rows present in x.</h2><span id='topic+h2o.nrow'></span>

<h3>Description</h3>

<p>Return the number of rows present in x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.nrow(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.nrow_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+nrow">nrow</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
h2o.nrow(cars)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.null_deviance'>Retrieve the null deviance</h2><span id='topic+h2o.null_deviance'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training null deviance value is returned. If more
than one parameter is set to TRUE, then a named vector of null deviances are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.null_deviance(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.null_deviance_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.null_deviance_+3A_train">train</code></td>
<td>
<p>Retrieve the training null deviance</p>
</td></tr>
<tr><td><code id="h2o.null_deviance_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation null deviance</p>
</td></tr>
<tr><td><code id="h2o.null_deviance_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation null deviance</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", nfolds = 0, 
                        alpha = 0.5, lambda_search = FALSE)
h2o.null_deviance(prostate_glm, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.null_dof'>Retrieve the null degrees of freedom</h2><span id='topic+h2o.null_dof'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training null degrees of freedom value is returned. If more
than one parameter is set to TRUE, then a named vector of null degrees of freedom are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.null_dof(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.null_dof_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.null_dof_+3A_train">train</code></td>
<td>
<p>Retrieve the training null degrees of freedom</p>
</td></tr>
<tr><td><code id="h2o.null_dof_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation null degrees of freedom</p>
</td></tr>
<tr><td><code id="h2o.null_dof_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation null degrees of freedom</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", nfolds = 0, 
                        alpha = 0.5, lambda_search = FALSE)
h2o.null_dof(prostate_glm, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.num_iterations'>Retrieve the number of iterations.</h2><span id='topic+h2o.num_iterations'></span>

<h3>Description</h3>

<p>Retrieve the number of iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.num_iterations(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.num_iterations_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", 
                        nfolds = 0, alpha = 0.5, lambda_search = FALSE)
h2o.num_iterations(prostate_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.num_valid_substrings'>Count of substrings &gt;= 2 chars that are contained in file</h2><span id='topic+h2o.num_valid_substrings'></span>

<h3>Description</h3>

<p>Find the count of all possible substrings &gt;= 2 chars that are contained in the specified line-separated text file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.num_valid_substrings(x, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.num_valid_substrings_+3A_x">x</code></td>
<td>
<p>The column on which to calculate the number of valid substrings.</p>
</td></tr>
<tr><td><code id="h2o.num_valid_substrings_+3A_path">path</code></td>
<td>
<p>Path to text file containing line-separated strings to be referenced.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.openLog'>View H2O R Logs</h2><span id='topic+h2o.openLog'></span>

<h3>Description</h3>

<p>Open existing logs of H2O R POST commands and error resposnes on local disk.
Used primarily for debugging purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.openLog(type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.openLog_+3A_type">type</code></td>
<td>
<p>Currently unimplemented.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.startLogging">h2o.startLogging</a>, <a href="#topic+h2o.stopLogging">h2o.stopLogging</a>,
         <a href="#topic+h2o.clearLog">h2o.clearLog</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

h2o.startLogging()
australia_path = system.file("extdata", "australia.csv", package = "h2o")
australia = h2o.importFile(path = australia_path)
h2o.stopLogging()

# Not run to avoid windows being opened during R CMD check
# h2o.openLog("Command")
# h2o.openLog("Error")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.pareto_front'>Plot Pareto front</h2><span id='topic+h2o.pareto_front'></span>

<h3>Description</h3>

<p>Create Pareto front and plot it. Pareto front contains models that are optimal in a sense that for each model in the
Pareto front there isn't a model that would be better in both criteria. For example, this can be useful in picking
models that are fast to predict and at the same time have high accuracy. For generic data.frames/H2OFrames input
the task is assumed to be minimization for both metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.pareto_front(
  object,
  leaderboard_frame = NULL,
  x_metric = c("AUTO", "AUC", "AUCPR", "logloss", "MAE", "mean_per_class_error",
    "mean_residual_deviance", "MSE", "predict_time_per_row_ms", "RMSE", "RMSLE",
    "training_time_ms"),
  y_metric = c("AUTO", "AUC", "AUCPR", "logloss", "MAE", "mean_per_class_error",
    "mean_residual_deviance", "MSE", "predict_time_per_row_ms", "RMSE", "RMSLE",
    "training_time_ms"),
  optimum = c("AUTO", "top left", "top right", "bottom left", "bottom right"),
  title = NULL,
  color_col = "algo"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.pareto_front_+3A_object">object</code></td>
<td>
<p>H2OAutoML or H2OGrid or a data.frame</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_leaderboard_frame">leaderboard_frame</code></td>
<td>
<p>a frame used for generating the leaderboard (used when <code>object</code> is not a frame)</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_x_metric">x_metric</code></td>
<td>
<p>one of the metrics present in the leaderboard</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_y_metric">y_metric</code></td>
<td>
<p>one of the metrics present in the leaderboard</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_optimum">optimum</code></td>
<td>
<p>location of the optimum on XY plane</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_title">title</code></td>
<td>
<p>title used for plotting</p>
</td></tr>
<tr><td><code id="h2o.pareto_front_+3A_color_col">color_col</code></td>
<td>
<p>categorical column in the leaderboard that should be used for coloring the points</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OParetoFront S4 object with plot method and 'pareto_front&ldquo; slot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
df &lt;-  h2o.importFile("h2o://prostate.csv")

# Set the response
response &lt;- "CAPSULE"
df[[response]] &lt;- as.factor(df[[response]])

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the Pareto front
pf &lt;- h2o.pareto_front(aml)
plot(pf)
pf@pareto_front # to retrieve the Pareto front subset of the leaderboard

aml2 &lt;- h2o.automl(y = response,
                   training_frame = train,
                   max_models = 10,
                   seed = 42)

combined_leaderboard &lt;- h2o.make_leaderboard(list(aml, aml2), test, extra_columns = "ALL")
pf_combined &lt;- h2o.pareto_front(combined_leaderboard, x_metric = "predict_time_per_row_ms",
                                y_metric = "rmse", optimum = "bottom left")
plot(pf_combined)
pf_combined@pareto_front

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.parseRaw'>H2O Data Parsing</h2><span id='topic+h2o.parseRaw'></span>

<h3>Description</h3>

<p>The second phase in the data ingestion step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.parseRaw(
  data,
  pattern = "",
  destination_frame = "",
  header = NA,
  sep = "",
  col.names = NULL,
  col.types = NULL,
  na.strings = NULL,
  blocking = FALSE,
  parse_type = NULL,
  chunk_size = NULL,
  decrypt_tool = NULL,
  skipped_columns = NULL,
  force_col_types = FALSE,
  custom_non_data_line_markers = NULL,
  partition_by = NULL,
  quotechar = NULL,
  escapechar = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.parseRaw_+3A_data">data</code></td>
<td>
<p>An H2OFrame object to be parsed.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_pattern">pattern</code></td>
<td>
<p>(Optional) Character string containing a regular expression to match file(s) in
the folder.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_destination_frame">destination_frame</code></td>
<td>
<p>(Optional) The hex key assigned to the parsed file.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_header">header</code></td>
<td>
<p>(Optional) A logical value indicating whether the first row is
the column header. If missing, H2O will automatically try to detect
the presence of a header.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_sep">sep</code></td>
<td>
<p>(Optional) The field separator character. Values on each line of
the file are separated by this character. If <code>sep = ""</code>, the
parser will automatically detect the separator.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_col.names">col.names</code></td>
<td>
<p>(Optional) An H2OFrame object containing a
single delimited line with the column names for the file.  If skipped_columns are specified,
only list column names of columns that are not skipped.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_col.types">col.types</code></td>
<td>
<p>(Optional) A vector specifying the types to attempt to force
over columns.  If skipped_columns are specified, only list column types of columns that are not skipped.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_na.strings">na.strings</code></td>
<td>
<p>(Optional) H2O will interpret these strings as missing.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_blocking">blocking</code></td>
<td>
<p>(Optional) Tell H2O parse call to block synchronously instead
of polling.  This can be faster for small datasets but loses the
progress bar.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_parse_type">parse_type</code></td>
<td>
<p>(Optional) Specify which parser type H2O will use.
Valid types are &quot;ARFF&quot;, &quot;XLS&quot;, &quot;CSV&quot;, &quot;SVMLight&quot;</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_chunk_size">chunk_size</code></td>
<td>
<p>size of chunk of (input) data in bytes</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_decrypt_tool">decrypt_tool</code></td>
<td>
<p>(Optional) Specify a Decryption Tool (key-reference
acquired by calling <a href="#topic+h2o.decryptionSetup">h2o.decryptionSetup</a>.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_skipped_columns">skipped_columns</code></td>
<td>
<p>a list of column indices to be excluded from parsing</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_force_col_types">force_col_types</code></td>
<td>
<p>(Optional) if true will force parser to return the exact column types specified in 
column_types.  For parquet, if column_types is not specified, the parquet schema will be used to determine 
the actual column type.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_custom_non_data_line_markers">custom_non_data_line_markers</code></td>
<td>
<p>(Optional) If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, NULL means that default behaviour for given format will be used</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_partition_by">partition_by</code></td>
<td>
<p>(Optional) Names of the columns the persisted dataset has been partitioned by.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_quotechar">quotechar</code></td>
<td>
<p>A hint for the parser which character to expect as quoting character. None (default) means autodetection.</p>
</td></tr>
<tr><td><code id="h2o.parseRaw_+3A_escapechar">escapechar</code></td>
<td>
<p>(Optional) One ASCII character used to escape other characters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parse the Raw Data produced by the import phase.
</p>


<h3>See Also</h3>

<p><a href="#topic+h2o.importFile">h2o.importFile</a>, <a href="#topic+h2o.parseSetup">h2o.parseSetup</a>
</p>

<hr>
<h2 id='h2o.parseSetup'>Get a parse setup back for the staged data.</h2><span id='topic+h2o.parseSetup'></span>

<h3>Description</h3>

<p>Get a parse setup back for the staged data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.parseSetup(
  data,
  pattern = "",
  destination_frame = "",
  header = NA,
  sep = "",
  col.names = NULL,
  col.types = NULL,
  na.strings = NULL,
  parse_type = NULL,
  chunk_size = NULL,
  decrypt_tool = NULL,
  skipped_columns = NULL,
  force_col_types = FALSE,
  custom_non_data_line_markers = NULL,
  partition_by = NULL,
  single_quotes = FALSE,
  escapechar = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.parseSetup_+3A_data">data</code></td>
<td>
<p>An H2OFrame object to be parsed.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_pattern">pattern</code></td>
<td>
<p>(Optional) Character string containing a regular expression to match file(s) in
the folder.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_destination_frame">destination_frame</code></td>
<td>
<p>(Optional) The hex key assigned to the parsed file.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_header">header</code></td>
<td>
<p>(Optional) A logical value indicating whether the first row is
the column header. If missing, H2O will automatically try to detect
the presence of a header.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_sep">sep</code></td>
<td>
<p>(Optional) The field separator character. Values on each line of
the file are separated by this character. If <code>sep = ""</code>, the
parser will automatically detect the separator.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_col.names">col.names</code></td>
<td>
<p>(Optional) An H2OFrame object containing a
single delimited line with the column names for the file.  If skipped_columns are specified,
only list column names of columns that are not skipped.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_col.types">col.types</code></td>
<td>
<p>(Optional) A vector specifying the types to attempt to force
over columns.  If skipped_columns are specified, only list column types of columns that are not skipped.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_na.strings">na.strings</code></td>
<td>
<p>(Optional) H2O will interpret these strings as missing.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_parse_type">parse_type</code></td>
<td>
<p>(Optional) Specify which parser type H2O will use.
Valid types are &quot;ARFF&quot;, &quot;XLS&quot;, &quot;CSV&quot;, &quot;SVMLight&quot;</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_chunk_size">chunk_size</code></td>
<td>
<p>size of chunk of (input) data in bytes</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_decrypt_tool">decrypt_tool</code></td>
<td>
<p>(Optional) Specify a Decryption Tool (key-reference
acquired by calling <a href="#topic+h2o.decryptionSetup">h2o.decryptionSetup</a>.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_skipped_columns">skipped_columns</code></td>
<td>
<p>a list of column indices to be excluded from parsing</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_force_col_types">force_col_types</code></td>
<td>
<p>(Optional) if true will force parser to return the exact column types specified in 
column_types.  For parquet, if column_types is not specified, the parquet schema will be used to determine 
the actual column type.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_custom_non_data_line_markers">custom_non_data_line_markers</code></td>
<td>
<p>(Optional) If a line in imported file starts with any character in given string it will NOT be imported. Empty string means all lines are imported, NULL means that default behaviour for given format will be used</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_partition_by">partition_by</code></td>
<td>
<p>(Optional) Names of the columns the persisted dataset has been partitioned by.</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_single_quotes">single_quotes</code></td>
<td>
<p>If set to true, the parser expects single quotes. False for double quotes (default).</p>
</td></tr>
<tr><td><code id="h2o.parseSetup_+3A_escapechar">escapechar</code></td>
<td>
<p>(Optional) One ASCII character used to escape other characters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+h2o.parseRaw">h2o.parseRaw</a>
</p>

<hr>
<h2 id='h2o.partialPlot'>Partial Dependence Plots</h2><span id='topic+h2o.partialPlot'></span>

<h3>Description</h3>

<p>Partial dependence plot gives a graphical depiction of the marginal effect of a variable on the response. The effect
of a variable is measured in change in the mean response. Note: Unlike randomForest's partialPlot when plotting
partial dependence the mean response (probabilities) is returned rather than the mean of the log class probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.partialPlot(
  object,
  newdata,
  cols,
  destination_key,
  nbins = 20,
  plot = TRUE,
  plot_stddev = TRUE,
  weight_column = -1,
  include_na = FALSE,
  user_splits = NULL,
  col_pairs_2dpdp = NULL,
  save_to = NULL,
  row_index = -1,
  targets = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.partialPlot_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object used for scoring and constructing the plot.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_cols">cols</code></td>
<td>
<p>Feature(s) for which partial dependence will be calculated.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_destination_key">destination_key</code></td>
<td>
<p>An key reference to the created partial dependence tables in H2O.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_nbins">nbins</code></td>
<td>
<p>Number of bins used. For categorical columns make sure the number of bins exceeds the level count.
If you enable add_missing_NA, the returned length will be nbin+1.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_plot">plot</code></td>
<td>
<p>A logical specifying whether to plot partial dependence table.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_plot_stddev">plot_stddev</code></td>
<td>
<p>A logical specifying whether to add std err to partial dependence plot.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_weight_column">weight_column</code></td>
<td>
<p>A string denoting which column of data should be used as the weight column.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_include_na">include_na</code></td>
<td>
<p>A logical specifying whether missing value should be included in the Feature values.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_user_splits">user_splits</code></td>
<td>
<p>A two-level nested list containing user defined split points for pdp plots for each column.
If there are two columns using user defined split points, there should be two lists in the nested list.
Inside each list, the first element is the column name followed by values defined by the user.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_col_pairs_2dpdp">col_pairs_2dpdp</code></td>
<td>
<p>A two-level nested list like this: col_pairs_2dpdp = list(c(&quot;col1_name&quot;, &quot;col2_name&quot;),
c(&quot;col1_name&quot;,&quot;col3_name&quot;), ...,) where a 2D partial plots will be generated for col1_name, col2_name pair, for
col1_name, col3_name pair and whatever other pairs that are specified in the nested list.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_save_to">save_to</code></td>
<td>
<p>Fully qualified prefix of the image files the resulting plots should be saved to, e.g. '/home/user/pdp'.
Plots for each feature are saved separately in PNG format, each file receives a suffix equal to the corresponding feature name, e.g. '/home/user/pdp_AGE.png'.
If the files already exists, they will be overridden. Files are only saves if plot = TRUE (default).</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_row_index">row_index</code></td>
<td>
<p>Row for which partial dependence will be calculated instead of the whole input frame.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_targets">targets</code></td>
<td>
<p>Target classes for multinomial model.</p>
</td></tr>
<tr><td><code id="h2o.partialPlot_+3A_...">...</code></td>
<td>
<p>Mainly used for backwards compatibility, to allow deprecated parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot and list of calculated mean response tables for each feature requested.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate[, "CAPSULE"] &lt;- as.factor(prostate[, "CAPSULE"] )
prostate[, "RACE"] &lt;- as.factor(prostate[, "RACE"] )
prostate_gbm &lt;- h2o.gbm(x = c("AGE", "RACE"),
                        y = "CAPSULE",
                        training_frame = prostate,
                        ntrees = 10,
                        max_depth = 5,
                        learn_rate = 0.1)
h2o.partialPlot(object = prostate_gbm, newdata = prostate, cols = c("AGE", "RACE"))

iris_hex &lt;- as.h2o(iris)
iris_gbm &lt;- h2o.gbm(x = c(1:4), y = 5, training_frame = iris_hex)

# one target class
h2o.partialPlot(object = iris_gbm, newdata = iris_hex, cols="Petal.Length", targets=c("setosa"))
# three target classes
h2o.partialPlot(object = iris_gbm, newdata = iris_hex, cols="Petal.Length", 
                 targets=c("setosa", "virginica", "versicolor"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.pd_multi_plot'>Plot partial dependencies for a variable across multiple models</h2><span id='topic+h2o.pd_multi_plot'></span>

<h3>Description</h3>

<p>Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable
on the response. The effect of a variable is measured in change in the mean response.
PDP assumes independence between the feature for which is the PDP computed and the rest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.pd_multi_plot(
  object,
  newdata,
  column,
  best_of_family = TRUE,
  target = NULL,
  row_index = NULL,
  max_levels = 30,
  show_rug = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.pd_multi_plot_+3A_object">object</code></td>
<td>
<p>Either a list of H2O models/model_ids or an H2OAutoML object.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_column">column</code></td>
<td>
<p>A feature column name to inspect.  Character string.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_best_of_family">best_of_family</code></td>
<td>
<p>If TRUE, plot only the best model of each algorithm family;
if FALSE, plot all models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_target">target</code></td>
<td>
<p>If multinomial, plot PDP just for <code>target</code> category.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_row_index">row_index</code></td>
<td>
<p>Optional. Calculate Individual Conditional Expectation (ICE) for row, <code>row_index</code>.  Integer.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_max_levels">max_levels</code></td>
<td>
<p>An integer specifying the maximum number of factor levels to show.
Defaults to 30.</p>
</td></tr>
<tr><td><code id="h2o.pd_multi_plot_+3A_show_rug">show_rug</code></td>
<td>
<p>Show rug to visualize the density of the column. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the partial dependence plot
pdp &lt;- h2o.pd_multi_plot(aml, test, column = "alcohol")
print(pdp)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.pd_plot'>Plot partial dependence for a variable</h2><span id='topic+h2o.pd_plot'></span>

<h3>Description</h3>

<p>Partial dependence plot (PDP) gives a graphical depiction of the marginal effect of a variable
on the response. The effect of a variable is measured in change in the mean response.
PDP assumes independence between the feature for which is the PDP computed and the rest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.pd_plot(
  object,
  newdata,
  column,
  target = NULL,
  row_index = NULL,
  max_levels = 30,
  binary_response_scale = c("response", "logodds"),
  grouping_column = NULL,
  nbins = 100,
  show_rug = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.pd_plot_+3A_object">object</code></td>
<td>
<p>An H2O model.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.  Used to generate predictions used in Partial Dependence calculations.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_column">column</code></td>
<td>
<p>A feature column name to inspect.  Character string.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_target">target</code></td>
<td>
<p>If multinomial, plot PDP just for <code>target</code> category.  Character string.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_row_index">row_index</code></td>
<td>
<p>Optional. Calculate Individual Conditional Expectation (ICE) for row, <code>row_index</code>.  Integer.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_max_levels">max_levels</code></td>
<td>
<p>An integer specifying the maximum number of factor levels to show.
Defaults to 30.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_binary_response_scale">binary_response_scale</code></td>
<td>
<p>Option for binary model to display (on the y-axis) the logodds instead of the actual
score. Can be one of: &quot;response&quot;, &quot;logodds&quot;. Defaults to &quot;response&quot;.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_grouping_column">grouping_column</code></td>
<td>
<p>A feature column name to group the data and provide separate sets of plots
by grouping feature values</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_nbins">nbins</code></td>
<td>
<p>A number of bins used. Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.pd_plot_+3A_show_rug">show_rug</code></td>
<td>
<p>Show rug to visualize the density of the column. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the partial dependence plot
pdp &lt;- h2o.pd_plot(gbm, test, column = "alcohol")
print(pdp)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.performance'>Model Performance Metrics in H2O</h2><span id='topic+h2o.performance'></span>

<h3>Description</h3>

<p>Given a trained h2o model, compute its performance on the given
dataset.  However, if the dataset does not contain the response/target column, no performance will be returned.
Instead, a warning message will be printed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.performance(
  model,
  newdata = NULL,
  train = FALSE,
  valid = FALSE,
  xval = FALSE,
  data = NULL,
  auc_type = "NONE",
  auuc_type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.performance_+3A_model">model</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame. The model will make predictions
on this dataset, and subsequently score them. The dataset should
match the dataset that was used to train the model, in terms of
column names, types, and dimensions. If newdata is passed in, then train, valid, and xval are ignored.</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_train">train</code></td>
<td>
<p>A logical value indicating whether to return the training metrics (constructed during training).
</p>
<p>Note: when the trained h2o model uses balance_classes, the training metrics constructed during training will be from the balanced training dataset.
For more information visit: <a href="https://github.com/h2oai/h2o-3/discussions/15518">https://github.com/h2oai/h2o-3/discussions/15518</a></p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_valid">valid</code></td>
<td>
<p>A logical value indicating whether to return the validation metrics (constructed during training).</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_xval">xval</code></td>
<td>
<p>A logical value indicating whether to return the cross-validation metrics (constructed during training).</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_data">data</code></td>
<td>
<p>(DEPRECATED) An H2OFrame. This argument is now called 'newdata'.</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_auc_type">auc_type</code></td>
<td>
<p>For multinomila model only. Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Default is &quot;NONE&quot;</p>
</td></tr>
<tr><td><code id="h2o.performance_+3A_auuc_type">auuc_type</code></td>
<td>
<p>For binomial model only. Set default AUUC type. Must be one of: &quot;AUTO&quot;, &quot;GINI&quot;, &quot;GAIN&quot;, &quot;LIFT&quot;. Default is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of the <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> subclass.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
prostate_gbm &lt;- h2o.gbm(3:9, "CAPSULE", prostate)
h2o.performance(model = prostate_gbm, newdata=prostate)

## If model uses balance_classes
## the results from train = TRUE will not match the results from newdata = prostate
prostate_gbm_balanced &lt;- h2o.gbm(3:9, "CAPSULE", prostate, balance_classes = TRUE)
h2o.performance(model = prostate_gbm_balanced, newdata = prostate)
h2o.performance(model = prostate_gbm_balanced, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.permutation_importance'>Calculate Permutation Feature Importance.</h2><span id='topic+h2o.permutation_importance'></span>

<h3>Description</h3>

<p>When n_repeats == 1, the result is similar to the one from h2o.varimp(), i.e., it contains
the following columns &quot;Relative Importance&quot;, &quot;Scaled Importance&quot;, and &quot;Percentage&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.permutation_importance(
  object,
  newdata,
  metric = c("AUTO", "AUC", "MAE", "MSE", "RMSE", "logloss", "mean_per_class_error",
    "PR_AUC"),
  n_samples = 10000,
  n_repeats = 1,
  features = NULL,
  seed = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.permutation_importance_+3A_object">object</code></td>
<td>
<p>A trained supervised H2O model.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_newdata">newdata</code></td>
<td>
<p>Training frame of the model which is going to be permuted</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_metric">metric</code></td>
<td>
<p>Metric to be used. One of &quot;AUTO&quot;, &quot;AUC&quot;, &quot;MAE&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;logloss&quot;, &quot;mean_per_class_error&quot;,
&quot;PR_AUC&quot;.  Defaults to &quot;AUTO&quot;.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_n_samples">n_samples</code></td>
<td>
<p>Number of samples to be evaluated. Use -1 to use the whole dataset. Defaults to 10 000.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_n_repeats">n_repeats</code></td>
<td>
<p>Number of repeated evaluations. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_features">features</code></td>
<td>
<p>Character vector of features to include in the permutation importance. Use NULL to include all.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_+3A_seed">seed</code></td>
<td>
<p>Seed for the random generator. Use -1 to pick a random seed. Defaults to -1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When n_repeats &gt; 1, the individual columns correspond to the permutation variable
importance values from individual runs which corresponds to the &quot;Relative Importance&quot; and also
to the distance between the original prediction error and prediction error using a frame with
a given feature permuted.
</p>


<h3>Value</h3>

<p>H2OTable with variable importance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
h2o.permutation_importance(model, prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.permutation_importance_plot'>Plot Permutation Variable Importances.</h2><span id='topic+h2o.permutation_importance_plot'></span>

<h3>Description</h3>

<p>This method plots either a bar plot or if n_repeats &gt; 1 a box plot and returns the variable importance table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.permutation_importance_plot(
  object,
  newdata,
  metric = c("AUTO", "AUC", "MAE", "MSE", "RMSE", "logloss", "mean_per_class_error",
    "PR_AUC"),
  n_samples = 10000,
  n_repeats = 1,
  features = NULL,
  seed = -1,
  num_of_features = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.permutation_importance_plot_+3A_object">object</code></td>
<td>
<p>A trained supervised H2O model.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_newdata">newdata</code></td>
<td>
<p>Training frame of the model which is going to be permuted</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_metric">metric</code></td>
<td>
<p>Metric to be used. One of &quot;AUTO&quot;, &quot;AUC&quot;, &quot;MAE&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;logloss&quot;, &quot;mean_per_class_error&quot;,
&quot;PR_AUC&quot;.  Defaults to &quot;AUTO&quot;.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_n_samples">n_samples</code></td>
<td>
<p>Number of samples to be evaluated. Use -1 to use the whole dataset. Defaults to 10 000.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_n_repeats">n_repeats</code></td>
<td>
<p>Number of repeated evaluations. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_features">features</code></td>
<td>
<p>Character vector of features to include in the permutation importance. Use NULL to include all.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_seed">seed</code></td>
<td>
<p>Seed for the random generator. Use -1 to pick a random seed. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.permutation_importance_plot_+3A_num_of_features">num_of_features</code></td>
<td>
<p>The number of features shown in the plot (default is 10 or all if less than 10).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>H2OTable with variable importance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
h2o.permutation_importance_plot(model, prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.pivot'>Pivot a frame</h2><span id='topic+h2o.pivot'></span>

<h3>Description</h3>

<p>Pivot the frame designated by the three columns: index, column, and value. Index and column should be
of type enum, int, or time.
For cases of multiple indexes for a column label, the aggregation method is to pick the first occurrence in the data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.pivot(x, index, column, value)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.pivot_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.pivot_+3A_index">index</code></td>
<td>
<p>the column where pivoted rows should be aligned on</p>
</td></tr>
<tr><td><code id="h2o.pivot_+3A_column">column</code></td>
<td>
<p>the column to pivot</p>
</td></tr>
<tr><td><code id="h2o.pivot_+3A_value">value</code></td>
<td>
<p>values of the pivoted table</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with columns from the columns arg, aligned on the index arg, with values from values arg
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

df = h2o.createFrame(rows = 1000, cols = 3, factors = 10, integer_fraction = 1.0/3, 
                     categorical_fraction = 1.0/3, missing_fraction = 0.0, seed = 123)
df$C3 = h2o.abs(df$C3)
h2o.pivot(df, index="C3", column="C2", value="C1")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.prcomp'>Principal component analysis of an H2O data frame</h2><span id='topic+h2o.prcomp'></span>

<h3>Description</h3>

<p>Principal components analysis of an H2O data frame using the power method
to calculate the singular value decomposition of the Gram matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.prcomp(
  training_frame,
  x,
  model_id = NULL,
  validation_frame = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  transform = c("NONE", "STANDARDIZE", "NORMALIZE", "DEMEAN", "DESCALE"),
  pca_method = c("GramSVD", "Power", "Randomized", "GLRM"),
  pca_impl = c("MTJ_EVD_DENSEMATRIX", "MTJ_EVD_SYMMMATRIX", "MTJ_SVD_DENSEMATRIX",
    "JAMA"),
  k = 1,
  max_iterations = 1000,
  use_all_factor_levels = FALSE,
  compute_metrics = TRUE,
  impute_missing = FALSE,
  seed = -1,
  max_runtime_secs = 0,
  export_checkpoints_dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.prcomp_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_transform">transform</code></td>
<td>
<p>Transformation of training data Must be one of: &quot;NONE&quot;, &quot;STANDARDIZE&quot;, &quot;NORMALIZE&quot;, &quot;DEMEAN&quot;, &quot;DESCALE&quot;.
Defaults to NONE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_pca_method">pca_method</code></td>
<td>
<p>Specify the algorithm to use for computing the principal components: GramSVD - uses a distributed computation
of the Gram matrix, followed by a local SVD; Power - computes the SVD using the power iteration method
(experimental); Randomized - uses randomized subspace iteration method; GLRM - fits a generalized low-rank
model with L2 loss function and no regularization and solves for the SVD using local matrix algebra
(experimental) Must be one of: &quot;GramSVD&quot;, &quot;Power&quot;, &quot;Randomized&quot;, &quot;GLRM&quot;. Defaults to GramSVD.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_pca_impl">pca_impl</code></td>
<td>
<p>Specify the implementation to use for computing PCA (via SVD or EVD): MTJ_EVD_DENSEMATRIX - eigenvalue
decompositions for dense matrix using MTJ; MTJ_EVD_SYMMMATRIX - eigenvalue decompositions for symmetric matrix
using MTJ; MTJ_SVD_DENSEMATRIX - singular-value decompositions for dense matrix using MTJ; JAMA - eigenvalue
decompositions for dense matrix using JAMA. References: JAMA - http://math.nist.gov/javanumerics/jama/; MTJ -
https://github.com/fommil/matrix-toolkits-java/ Must be one of: &quot;MTJ_EVD_DENSEMATRIX&quot;, &quot;MTJ_EVD_SYMMMATRIX&quot;,
&quot;MTJ_SVD_DENSEMATRIX&quot;, &quot;JAMA&quot;.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_k">k</code></td>
<td>
<p>Rank of matrix approximation Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum training iterations Defaults to 1000.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_use_all_factor_levels">use_all_factor_levels</code></td>
<td>
<p><code>Logical</code>. Whether first factor level is included in each categorical expansion Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_compute_metrics">compute_metrics</code></td>
<td>
<p><code>Logical</code>. Whether to compute metrics on the training data Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_impute_missing">impute_missing</code></td>
<td>
<p><code>Logical</code>. Whether to impute missing entries with the column mean Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.prcomp_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a>.
</p>


<h3>References</h3>

<p>N. Halko, P.G. Martinsson, J.A. Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions[http://arxiv.org/abs/0909.4061]. SIAM Rev., Survey and Review section, Vol. 53, num. 2, pp. 217-288, June 2011.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.svd">h2o.svd</a></code>, <code><a href="#topic+h2o.glrm">h2o.glrm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.uploadFile(path = australia_path)
h2o.prcomp(training_frame = australia, k = 8, transform = "STANDARDIZE")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.predict'>Predict on an H2O Model</h2><span id='topic+h2o.predict'></span>

<h3>Description</h3>

<p>Predict on an H2O Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.predict_+3A_object">object</code></td>
<td>
<p>a fitted model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="h2o.predict_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="h2o.predict_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with probabilites and
default predictions.
</p>

<hr>
<h2 id='h2o.predict_json'>H2O Prediction from R without having H2O running</h2><span id='topic+h2o.predict_json'></span>

<h3>Description</h3>

<p>Provides the method h2o.predict with which you can predict a MOJO or POJO Jar model
from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.predict_json(model, json, genmodelpath, labels, classpath, javaoptions)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.predict_json_+3A_model">model</code></td>
<td>
<p>String with file name of MOJO or POJO Jar</p>
</td></tr>
<tr><td><code id="h2o.predict_json_+3A_json">json</code></td>
<td>
<p>JSON String with inputs to model</p>
</td></tr>
<tr><td><code id="h2o.predict_json_+3A_genmodelpath">genmodelpath</code></td>
<td>
<p>(Optional) path name to h2o-genmodel.jar, if not set defaults to same dir as MOJO</p>
</td></tr>
<tr><td><code id="h2o.predict_json_+3A_labels">labels</code></td>
<td>
<p>(Optional) if TRUE then show output labels in result</p>
</td></tr>
<tr><td><code id="h2o.predict_json_+3A_classpath">classpath</code></td>
<td>
<p>(Optional) Extra items for the class path of where to look for Java classes, e.g., h2o-genmodel.jar</p>
</td></tr>
<tr><td><code id="h2o.predict_json_+3A_javaoptions">javaoptions</code></td>
<td>
<p>(Optional) Java options string, default if &quot;-Xmx4g&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object with the prediction result
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.predict_json('~/GBM_model_python_1473313897851_6.zip', '{"C7":1}')
h2o.predict_json('~/GBM_model_python_1473313897851_6.zip', '{"C7":1}', c(".", "lib"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.predict_rules'>Evaluates validity of the given rules on the given data. Returns a frame with a column per each input rule id, 
representing a flag whether given rule is applied to the observation or not.</h2><span id='topic+h2o.predict_rules'></span>

<h3>Description</h3>

<p>Evaluates validity of the given rules on the given data. Returns a frame with a column per each input rule id, 
representing a flag whether given rule is applied to the observation or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.predict_rules(model, frame, rule_ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.predict_rules_+3A_model">model</code></td>
<td>
<p>A trained rulefit model.</p>
</td></tr>
<tr><td><code id="h2o.predict_rules_+3A_frame">frame</code></td>
<td>
<p>A frame on which rule validity is to be evaluated</p>
</td></tr>
<tr><td><code id="h2o.predict_rules_+3A_rule_ids">rule_ids</code></td>
<td>
<p>Rule ids to be evaluated against the frame</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
titanic &lt;- h2o.importFile(
 "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv"
)
response = "survived"
predictors &lt;- c("age", "sibsp", "parch", "fare", "sex", "pclass")
titanic[,response] &lt;- as.factor(titanic[,response])
titanic[,"pclass"] &lt;- as.factor(titanic[,"pclass"])

splits &lt;- h2o.splitFrame(data = titanic, ratios = .8, seed = 1234)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

rfit &lt;- h2o.rulefit(y = response, x = predictors, training_frame = train, validation_frame = test, 
min_rule_length = 1, max_rule_length = 10, max_num_rules = 100, seed = 1, model_type="rules")
h2o.predict_rules(rfit, train, c("M1T0N7, M1T49N7, M1T16N7", "M1T36N7", "M2T19N19"))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.predicted_vs_actual_by_variable'>Calculates per-level mean of predicted value vs actual value for a given variable.</h2><span id='topic+h2o.predicted_vs_actual_by_variable'></span>

<h3>Description</h3>

<p>In the basic setting, this function is equivalent to doing group-by on variable and calculating
mean on predicted and actual. In addition to that it also handles NAs in response and weights
automatically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.predicted_vs_actual_by_variable(object, newdata, predicted, variable)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.predicted_vs_actual_by_variable_+3A_object">object</code></td>
<td>
<p>A trained supervised H2O model.</p>
</td></tr>
<tr><td><code id="h2o.predicted_vs_actual_by_variable_+3A_newdata">newdata</code></td>
<td>
<p>Input frame (can be training/test/.. frame).</p>
</td></tr>
<tr><td><code id="h2o.predicted_vs_actual_by_variable_+3A_predicted">predicted</code></td>
<td>
<p>Frame of predictions for the given input frame.</p>
</td></tr>
<tr><td><code id="h2o.predicted_vs_actual_by_variable_+3A_variable">variable</code></td>
<td>
<p>Name of variable to inspect.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>H2OTable
</p>

<hr>
<h2 id='h2o.print'>Print An H2OFrame</h2><span id='topic+h2o.print'></span>

<h3>Description</h3>

<p>Print An H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.print(x, n = 6L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.print_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="h2o.print_+3A_n">n</code></td>
<td>
<p>An (Optional) A single integer. If positive, number of rows in x to return. If negative, all but the n first/last number of rows in x.
Anything bigger than 20 rows will require asking the server (first 20 rows are cached on the client).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library()
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.print(iris["species"], n = 15)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.prod'>Return the product of all the values present in its arguments.</h2><span id='topic+h2o.prod'></span>

<h3>Description</h3>

<p>Return the product of all the values present in its arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.prod(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.prod_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+prod">prod</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.prod(iris["petal_len"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.proj_archetypes'>Convert Archetypes to Features from H2O GLRM Model</h2><span id='topic+h2o.proj_archetypes'></span>

<h3>Description</h3>

<p>Project each archetype in an H2O GLRM model into the corresponding feature
space from the H2O training frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.proj_archetypes(object, data, reverse_transform = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.proj_archetypes_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a> object that represents the
model containing archetypes to be projected.</p>
</td></tr>
<tr><td><code id="h2o.proj_archetypes_+3A_data">data</code></td>
<td>
<p>An H2OFrame object representing the training data for the H2O GLRM model.</p>
</td></tr>
<tr><td><code id="h2o.proj_archetypes_+3A_reverse_transform">reverse_transform</code></td>
<td>
<p>(Optional) A logical value indicating whether to reverse the
transformation from model-building by re-scaling columns and adding back the
offset to each column of the projected archetypes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the projection of the archetypes
down into the original feature space, where each row is one archetype.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.glrm">h2o.glrm</a></code> for making an H2ODimReductionModel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
iris_glrm &lt;- h2o.glrm(training_frame = iris_hf, k = 4, loss = "Quadratic",
                      multi_loss = "Categorical", max_iterations = 1000)
iris_parch &lt;- h2o.proj_archetypes(iris_glrm, iris_hf)
head(iris_parch)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.psvm'>Trains a Support Vector Machine model on an H2O dataset</h2><span id='topic+h2o.psvm'></span>

<h3>Description</h3>

<p>Alpha version. Supports only binomial classification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.psvm(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  ignore_const_cols = TRUE,
  hyper_param = 1,
  kernel_type = c("gaussian"),
  gamma = -1,
  rank_ratio = -1,
  positive_weight = 1,
  negative_weight = 1,
  disable_training_metrics = TRUE,
  sv_threshold = 1e-04,
  fact_threshold = 1e-05,
  feasible_threshold = 0.001,
  surrogate_gap_threshold = 0.001,
  mu_factor = 10,
  max_iterations = 200,
  seed = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.psvm_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. The response must be either a binary
categorical/factor variable or a numeric variable with values -1/1 (for compatibility with SVMlight format).</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_hyper_param">hyper_param</code></td>
<td>
<p>Penalty parameter C of the error term Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_kernel_type">kernel_type</code></td>
<td>
<p>Type of used kernel Must be one of: &quot;gaussian&quot;. Defaults to gaussian.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_gamma">gamma</code></td>
<td>
<p>Coefficient of the kernel (currently RBF gamma for gaussian kernel, -1 means 1/#features) Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_rank_ratio">rank_ratio</code></td>
<td>
<p>Desired rank of the ICF matrix expressed as an ration of number of input rows (-1 means use sqrt(#rows)).
Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_positive_weight">positive_weight</code></td>
<td>
<p>Weight of positive (+1) class of observations Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_negative_weight">negative_weight</code></td>
<td>
<p>Weight of positive (-1) class of observations Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_disable_training_metrics">disable_training_metrics</code></td>
<td>
<p><code>Logical</code>. Disable calculating training metrics (expensive on large datasets) Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_sv_threshold">sv_threshold</code></td>
<td>
<p>Threshold for accepting a candidate observation into the set of support vectors Defaults to 0.0001.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_fact_threshold">fact_threshold</code></td>
<td>
<p>Convergence threshold of the Incomplete Cholesky Factorization (ICF) Defaults to 1e-05.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_feasible_threshold">feasible_threshold</code></td>
<td>
<p>Convergence threshold for primal-dual residuals in the IPM iteration Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_surrogate_gap_threshold">surrogate_gap_threshold</code></td>
<td>
<p>Feasibility criterion of the surrogate duality gap (eta) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_mu_factor">mu_factor</code></td>
<td>
<p>Increasing factor mu Defaults to 10.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum number of iteration of the algorithm Defaults to 200.</p>
</td></tr>
<tr><td><code id="h2o.psvm_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the splice dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/splice/splice.svm"
splice &lt;- h2o.importFile(f)

# Train the Support Vector Machine model
svm_model &lt;- h2o.psvm(gamma = 0.01, rank_ratio = 0.1,
                      y = "C1", training_frame = splice,
                      disable_training_metrics = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.qini'>Retrieve the default Qini value</h2><span id='topic+h2o.qini'></span>

<h3>Description</h3>

<p>Retrieves the Qini value from an <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a>.
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training Qini value is returned. If more
than one parameter is set to TRUE, then a named vector of Qini values are returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.qini(object, train = FALSE, valid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.qini_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> or</p>
</td></tr>
<tr><td><code id="h2o.qini_+3A_train">train</code></td>
<td>
<p>Retrieve the training Qini value</p>
</td></tr>
<tr><td><code id="h2o.qini_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation Qini</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment",
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.qini(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.quantile'>Quantiles of H2O Frames.</h2><span id='topic+h2o.quantile'></span><span id='topic+quantile.H2OFrame'></span>

<h3>Description</h3>

<p>Obtain and display quantiles for H2O parsed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.quantile(
  x,
  probs = c(0.001, 0.01, 0.1, 0.25, 0.333, 0.5, 0.667, 0.75, 0.9, 0.99, 0.999),
  combine_method = c("interpolate", "average", "avg", "low", "high"),
  weights_column = NULL,
  ...
)

## S3 method for class 'H2OFrame'
quantile(
  x,
  probs = c(0.001, 0.01, 0.1, 0.25, 0.333, 0.5, 0.667, 0.75, 0.9, 0.99, 0.999),
  combine_method = c("interpolate", "average", "avg", "low", "high"),
  weights_column = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.quantile_+3A_x">x</code></td>
<td>
<p>An <code>H2OFrame</code> object with a single numeric column.</p>
</td></tr>
<tr><td><code id="h2o.quantile_+3A_probs">probs</code></td>
<td>
<p>Numeric vector of probabilities with values in [0,1].</p>
</td></tr>
<tr><td><code id="h2o.quantile_+3A_combine_method">combine_method</code></td>
<td>
<p>How to combine quantiles for even sample sizes. Default is to do linear interpolation.
E.g., If method is &quot;lo&quot;, then it will take the lo value of the quantile. Abbreviations for average, low, and high are acceptable (avg, lo, hi).</p>
</td></tr>
<tr><td><code id="h2o.quantile_+3A_weights_column">weights_column</code></td>
<td>
<p>(Optional) String name of the observation weights column in x or an <code>H2OFrame</code> object with a single numeric column of observation weights.</p>
</td></tr>
<tr><td><code id="h2o.quantile_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>quantile.H2OFrame</code>, a method for the <code><a href="stats.html#topic+quantile">quantile</a></code> generic. Obtain and return quantiles for
an <code>H2OFrame</code> object.
</p>


<h3>Value</h3>

<p>A vector describing the percentiles at the given cutoffs for the <code>H2OFrame</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Request quantiles for an H2O parsed data set:
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
# Request quantiles for a subset of columns in an H2O parsed data set
quantile(prostate[, 3])
for(i in 1:ncol(prostate))
   quantile(prostate[, i])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.r2'>Retrieve the R2 value</h2><span id='topic+h2o.r2'></span>

<h3>Description</h3>

<p>Retrieves the R2 value from an H2O model.
Will return R^2 for GLM Models.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training R2 value is returned. If more
than one parameter is set to TRUE, then a named vector of R2s are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.r2(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.r2_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.r2_+3A_train">train</code></td>
<td>
<p>Retrieve the training R2</p>
</td></tr>
<tr><td><code id="h2o.r2_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation set R2 if a validation set was passed in during model build time.</p>
</td></tr>
<tr><td><code id="h2o.r2_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation R2</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)

h &lt;- h2o.init()
fr &lt;- as.h2o(iris)

m &lt;- h2o.glm(x = 2:5, y = 1, training_frame = fr)

h2o.r2(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.randomForest'>Build a Random Forest model</h2><span id='topic+h2o.randomForest'></span>

<h3>Description</h3>

<p>Builds a Random Forest model on an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.randomForest(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  score_each_iteration = FALSE,
  score_tree_interval = 0,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  offset_column = NULL,
  weights_column = NULL,
  balance_classes = FALSE,
  class_sampling_factors = NULL,
  max_after_balance_size = 5,
  ntrees = 50,
  max_depth = 20,
  min_rows = 1,
  nbins = 20,
  nbins_top_level = 1024,
  nbins_cats = 1024,
  r2_stopping = Inf,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  max_runtime_secs = 0,
  seed = -1,
  build_tree_one_node = FALSE,
  mtries = -1,
  sample_rate = 0.632,
  sample_rate_per_class = NULL,
  binomial_double_trees = FALSE,
  checkpoint = NULL,
  col_sample_rate_change_per_level = 1,
  col_sample_rate_per_tree = 1,
  min_split_improvement = 1e-05,
  histogram_type = c("AUTO", "UniformAdaptive", "Random", "QuantilesGlobal",
    "RoundRobin", "UniformRobust"),
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  calibrate_model = FALSE,
  calibration_frame = NULL,
  calibration_method = c("AUTO", "PlattScaling", "IsotonicRegression"),
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  custom_metric_func = NULL,
  export_checkpoints_dir = NULL,
  check_constant_response = TRUE,
  gainslift_bins = -1,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.randomForest_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This argument is deprecated and has no use for Random Forest.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_balance_classes">balance_classes</code></td>
<td>
<p><code>Logical</code>. Balance training data class counts via over/under-sampling (for imbalanced data). Defaults to
FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_class_sampling_factors">class_sampling_factors</code></td>
<td>
<p>Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will
be automatically computed to obtain class balance during training. Requires balance_classes.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_max_after_balance_size">max_after_balance_size</code></td>
<td>
<p>Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires
balance_classes. Defaults to 5.0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of trees. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum tree depth (0 for unlimited). Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_min_rows">min_rows</code></td>
<td>
<p>Fewest allowed (weighted) observations in a leaf. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_nbins">nbins</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point
Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_nbins_top_level">nbins_top_level</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then
decrease by factor of two per level Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_nbins_cats">nbins_cats</code></td>
<td>
<p>For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher
values can lead to more overfitting. Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_r2_stopping">r2_stopping</code></td>
<td>
<p>r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric
and stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or
exceeds this Defaults to 1.797693135e+308.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_build_tree_one_node">build_tree_one_node</code></td>
<td>
<p><code>Logical</code>. Run on one node only; no network overhead but fewer cpus used. Suitable for small datasets.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_mtries">mtries</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for
classification and p/3 for regression (where p is the # of predictors Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_sample_rate">sample_rate</code></td>
<td>
<p>Row sample rate per tree (from 0.0 to 1.0) Defaults to 0.632.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_sample_rate_per_class">sample_rate_per_class</code></td>
<td>
<p>A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_binomial_double_trees">binomial_double_trees</code></td>
<td>
<p><code>Logical</code>. For binary classification: Build 2x as many trees (one per class) - can lead to higher
accuracy. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Model checkpoint to resume training with.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_col_sample_rate_change_per_level">col_sample_rate_change_per_level</code></td>
<td>
<p>Relative change of the column sampling rate for every level (must be &gt; 0.0 and &lt;= 2.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_col_sample_rate_per_tree">col_sample_rate_per_tree</code></td>
<td>
<p>Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_min_split_improvement">min_split_improvement</code></td>
<td>
<p>Minimum relative improvement in squared error reduction for a split to happen Defaults to 1e-05.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_histogram_type">histogram_type</code></td>
<td>
<p>What type of histogram to use for finding optimal split points Must be one of: &quot;AUTO&quot;, &quot;UniformAdaptive&quot;,
&quot;Random&quot;, &quot;QuantilesGlobal&quot;, &quot;RoundRobin&quot;, &quot;UniformRobust&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_calibrate_model">calibrate_model</code></td>
<td>
<p><code>Logical</code>. Use Platt Scaling (default) or Isotonic Regression to calculate calibrated class
probabilities. Calibration can provide more accurate estimates of class probabilities. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_calibration_frame">calibration_frame</code></td>
<td>
<p>Data for model calibration</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_calibration_method">calibration_method</code></td>
<td>
<p>Calibration method to use Must be one of: &quot;AUTO&quot;, &quot;PlattScaling&quot;, &quot;IsotonicRegression&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_distribution">distribution</code></td>
<td>
<p>Distribution. This argument is deprecated and has no use for Random Forest.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_check_constant_response">check_constant_response</code></td>
<td>
<p><code>Logical</code>. Check if response column is constant. If enabled, then an exception is thrown if the response
column is a constant value.If disabled, then model will train regardless of the response column being a
constant value or not. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.randomForest_+3A_verbose">verbose</code></td>
<td>
<p><code>Logical</code>. Print scoring history to the console (Metrics per tree). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a <a href="#topic+H2OModel-class">H2OModel</a> object of the right type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the cars dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)

# Set predictors and response; set response as a factor
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"

# Train the DRF model
cars_drf &lt;- h2o.randomForest(x = predictors, y = response,
                            training_frame = cars, nfolds = 5,
                            seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.range'>Returns a vector containing the minimum and maximum of all the given arguments.</h2><span id='topic+h2o.range'></span>

<h3>Description</h3>

<p>Returns a vector containing the minimum and maximum of all the given arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.range(x, na.rm = FALSE, finite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.range_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.range_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. indicating whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="h2o.range_+3A_finite">finite</code></td>
<td>
<p><code>logical</code>. indicating if all non-finite elements should be omitted.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+range">range</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.range(iris["petal_len"], na.rm = TRUE, finite = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rank_within_group_by'>This function will add a new column rank where the ranking is produced as follows:
1. sorts the H2OFrame by columns sorted in by columns specified in group_by_cols and sort_cols in the directions
specified by the ascending for the sort_cols.  The sort directions for the group_by_cols are ascending only.
2. A new rank column is added to the frame which will contain a rank assignment performed next.  The user can
choose to assign a name to this new column.  The default name is New_Rank_column.
3. For each groupby groups, a rank is assigned to the row starting from 1, 2, ... to the end of that group.
4. If sort_cols_sorted is TRUE, a final sort on the frame will be performed frame according to the sort_cols and
the sort directions in ascending.  If sort_cols_sorted is FALSE (by default), the frame from step 3 will be
returned as is with no extra sort.  This may provide a small speedup if desired.</h2><span id='topic+h2o.rank_within_group_by'></span>

<h3>Description</h3>

<p>This function will add a new column rank where the ranking is produced as follows:
1. sorts the H2OFrame by columns sorted in by columns specified in group_by_cols and sort_cols in the directions
specified by the ascending for the sort_cols.  The sort directions for the group_by_cols are ascending only.
2. A new rank column is added to the frame which will contain a rank assignment performed next.  The user can
choose to assign a name to this new column.  The default name is New_Rank_column.
3. For each groupby groups, a rank is assigned to the row starting from 1, 2, ... to the end of that group.
4. If sort_cols_sorted is TRUE, a final sort on the frame will be performed frame according to the sort_cols and
the sort directions in ascending.  If sort_cols_sorted is FALSE (by default), the frame from step 3 will be
returned as is with no extra sort.  This may provide a small speedup if desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rank_within_group_by(
  x,
  group_by_cols,
  sort_cols,
  ascending = NULL,
  new_col_name = "New_Rank_column",
  sort_cols_sorted = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rank_within_group_by_+3A_x">x</code></td>
<td>
<p>The H2OFrame input to be sorted.</p>
</td></tr>
<tr><td><code id="h2o.rank_within_group_by_+3A_group_by_cols">group_by_cols</code></td>
<td>
<p>a list of column names or indices to form the groupby groups</p>
</td></tr>
<tr><td><code id="h2o.rank_within_group_by_+3A_sort_cols">sort_cols</code></td>
<td>
<p>a list of column names or indices for sorting</p>
</td></tr>
<tr><td><code id="h2o.rank_within_group_by_+3A_ascending">ascending</code></td>
<td>
<p>a list of Boolean to determine if ascending sort (set to TRUE) is needed for each column in
sort_cols (optional).  Default is ascending sort for all.  To perform descending sort, set value to FALSE</p>
</td></tr>
<tr><td><code id="h2o.rank_within_group_by_+3A_new_col_name">new_col_name</code></td>
<td>
<p>new column name for the newly added rank column if specified (optional).  Default name is
New_Rank_column.</p>
</td></tr>
<tr><td><code id="h2o.rank_within_group_by_+3A_sort_cols_sorted">sort_cols_sorted</code></td>
<td>
<p>Boolean to determine if the final returned frame is to be sorted according to the sort_cols
and sort directions in ascending.  Default is FALSE.
</p>
<p>The following example is generated by Nidhi Mehta.
</p>
<p>If the input frame is train:
</p>
<p>ID Group_by_column        num data Column_to_arrange_by       num_1 fdata
12               1   2941.552    1                    3  -3177.9077     1
12               1   2941.552    1                    5 -13311.8247     1
12               2 -22722.174    1                    3  -3177.9077     1
12               2 -22722.174    1                    5 -13311.8247     1
13               3 -12776.884    1                    5 -18421.6171     0
13               3 -12776.884    1                    4  28080.1607     0
13               1  -6049.830    1                    5 -18421.6171     0
13               1  -6049.830    1                    4  28080.1607     0
15               3 -16995.346    1                    1  -9781.6373     0
16               1 -10003.593    0                    3 -61284.6900     0
16               3  26052.495    1                    3 -61284.6900     0
16               3 -22905.288    0                    3 -61284.6900     0
17               2 -13465.496    1                    2  12094.4851     1
17               2 -13465.496    1                    3 -11772.1338     1
17               2 -13465.496    1                    3   -415.1114     0
17               2  -3329.619    1                    2  12094.4851     1
17               2  -3329.619    1                    3 -11772.1338     1
17               2  -3329.619    1                    3   -415.1114     0
</p>
<p>If the following commands are issued:
rankedF1 &lt;- h2o.rank_within_group_by(train, c(&quot;Group_by_column&quot;), c(&quot;Column_to_arrange_by&quot;), c(TRUE))
h2o.summary(rankedF1)
</p>
<p>The returned frame rankedF1 will look like this:
ID Group_by_column        num fdata Column_to_arrange_by       num_1 fdata.1 New_Rank_column
12               1   2941.552     1                    3  -3177.9077       1               1
16               1 -10003.593     0                    3 -61284.6900       0               2
13               1  -6049.830     0                    4  28080.1607       0               3
12               1   2941.552     1                    5 -13311.8247       1               4
13               1  -6049.830     0                    5 -18421.6171       0               5
17               2 -13465.496     0                    2  12094.4851       1               1
17               2  -3329.619     0                    2  12094.4851       1               2
12               2 -22722.174     1                    3  -3177.9077       1               3
17               2 -13465.496     0                    3 -11772.1338       1               4
17               2 -13465.496     0                    3   -415.1114       0               5
17               2  -3329.619     0                    3 -11772.1338       1               6
17               2  -3329.619     0                    3   -415.1114       0               7
12               2 -22722.174     1                    5 -13311.8247       1               8
15               3 -16995.346     1                    1  -9781.6373       0               1
16               3  26052.495     0                    3 -61284.6900       0               2
16               3 -22905.288     1                    3 -61284.6900       0               3
13               3 -12776.884     1                    4  28080.1607       0               4
13               3 -12776.884     1                    5 -18421.6171       0               5
</p>
<p>If the following commands are issued:
rankedF1 &lt;- h2o.rank_within_group_by(train, c(&quot;Group_by_column&quot;), c(&quot;Column_to_arrange_by&quot;), c(TRUE), sort_cols_sorted=TRUE)
h2o.summary(rankedF1)
</p>
<p>The returned frame will be sorted according to sortCols and hence look like this instead:
ID Group_by_column        num fdata Column_to_arrange_by       num_1 fdata.1 New_Rank_column
15               3 -16995.346     1                    1  -9781.6373       0               1
17               2 -13465.496     0                    2  12094.4851       1               1
17               2  -3329.619     0                    2  12094.4851       1               2
12               1   2941.552     1                    3  -3177.9077       1               1
12               2 -22722.174     1                    3  -3177.9077       1               3
16               1 -10003.593     0                    3 -61284.6900       0               2
16               3  26052.495     0                    3 -61284.6900       0               2
16               3 -22905.288     1                    3 -61284.6900       0               3
17               2 -13465.496     0                    3 -11772.1338       1               4
17               2 -13465.496     0                    3   -415.1114       0               5
17               2  -3329.619     0                    3 -11772.1338       1               6
17               2  -3329.619     0                    3   -415.1114       0               7
13               3 -12776.884     1                    4  28080.1607       0               4
13               1  -6049.830     0                    4  28080.1607       0               3
12               1   2941.552     1                    5 -13311.8247       1               4
12               2 -22722.174     1                    5 -13311.8247       1               8
13               3 -12776.884     1                    5 -18421.6171       0               5
13               1  -6049.830     0                    5 -18421.6171       0               5</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip"
air &lt;- h2o.importFile(f)
group_cols &lt;- c("Distance")
sort_cols &lt;- c("IsArrDelayed", "IsDepDelayed")
sort_directions &lt;- c(TRUE, FALSE)
h2o.rank_within_group_by(x = air, group_by_cols = group_cols, 
                         sort_cols = sort_cols, 
                         ascending = sort_directions, 
                         new_col_name = "New_Rank", 
                         sort_cols_sorted = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rapids'>Execute a Rapids expression.</h2><span id='topic+h2o.rapids'></span>

<h3>Description</h3>

<p>Execute a Rapids expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rapids(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rapids_+3A_expr">expr</code></td>
<td>
<p>The rapids expression (ascii string)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.rapids('(setproperty "sys.ai.h2o.algos.evaluate_auto_model_parameters" "true")')

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rbind'>Combine H2O Datasets by Rows</h2><span id='topic+h2o.rbind'></span>

<h3>Description</h3>

<p>Takes a sequence of H2O data sets and combines them by rows
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rbind(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rbind_+3A_...">...</code></td>
<td>
<p>A sequence of H2OFrame arguments. All datasets must exist on the same H2O instance
(IP and port) and contain the same number and types of columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the combined ... arguments row-wise.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cbind">cbind</a></code> for the base <code>R</code> method, <code>rbind()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate_rbind &lt;- h2o.rbind(prostate, prostate)
head(prostate_rbind)
dim(prostate)
dim(prostate_rbind)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.reconstruct'>Reconstruct Training Data via H2O GLRM Model</h2><span id='topic+h2o.reconstruct'></span>

<h3>Description</h3>

<p>Reconstruct the training data and impute missing values from the H2O GLRM model
by computing the matrix product of X and Y, and transforming back to the original
feature space by minimizing each column's loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.reconstruct(object, data, reverse_transform = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.reconstruct_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a> object that represents the
model to be used for reconstruction.</p>
</td></tr>
<tr><td><code id="h2o.reconstruct_+3A_data">data</code></td>
<td>
<p>An H2OFrame object representing the training data for the H2O GLRM model.
Used to set the domain of each column in the reconstructed frame.</p>
</td></tr>
<tr><td><code id="h2o.reconstruct_+3A_reverse_transform">reverse_transform</code></td>
<td>
<p>(Optional) A logical value indicating whether to reverse the
transformation from model-building by re-scaling columns and adding back the
offset to each column of the reconstructed frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the approximate reconstruction of the
training data;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.glrm">h2o.glrm</a></code> for making an H2ODimReductionModel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
iris_glrm &lt;- h2o.glrm(training_frame = iris_hf, k = 4, transform = "STANDARDIZE",
                      loss = "Quadratic", multi_loss = "Categorical", max_iterations = 1000)
iris_rec &lt;- h2o.reconstruct(iris_glrm, iris_hf, reverse_transform = TRUE)
head(iris_rec)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.relevel'>Reorders levels of an H2O factor, similarly to standard R's relevel.</h2><span id='topic+h2o.relevel'></span>

<h3>Description</h3>

<p>The levels of a factor are reordered os that the reference level is at level 0, remaining levels are moved down as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.relevel(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.relevel_+3A_x">x</code></td>
<td>
<p>factor column in h2o frame</p>
</td></tr>
<tr><td><code id="h2o.relevel_+3A_y">y</code></td>
<td>
<p>reference level (string)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>new reordered factor column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Convert iris dataset to an H2OFrame
iris_hf &lt;- as.h2o(iris)
# Look at current ordering of the Species column levels
h2o.levels(iris_hf["Species"])
# "setosa"     "versicolor" "virginica" 
# Change the reference level to "virginica"
iris_hf["Species"] &lt;- h2o.relevel(x = iris_hf["Species"], y = "virginica")
# Observe new ordering
h2o.levels(iris_hf["Species"])
# "virginica"  "setosa"     "versicolor"

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.relevel_by_frequency'>Reorders levels of factor columns by the frequencies for the individual levels.</h2><span id='topic+h2o.relevel_by_frequency'></span>

<h3>Description</h3>

<p>The levels of a factor are reordered so that the most frequency level is at level 0, 
remaining levels are ordered from the second most frequent to the least frequent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.relevel_by_frequency(x, weights_column = NULL, top_n = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.relevel_by_frequency_+3A_x">x</code></td>
<td>
<p>H2O frame with some factor columns</p>
</td></tr>
<tr><td><code id="h2o.relevel_by_frequency_+3A_weights_column">weights_column</code></td>
<td>
<p>optional name of weights column</p>
</td></tr>
<tr><td><code id="h2o.relevel_by_frequency_+3A_top_n">top_n</code></td>
<td>
<p>optional number of most frequent levels to move to the top (eg.: for top_n=1 move only the most frequent level)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>new reordered frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Convert iris dataset to an H2OFrame
iris_hf &lt;- as.h2o(iris)
# Look at current ordering of the Species column levels
h2o.levels(iris_hf["Species"])
# "setosa"     "versicolor" "virginica" 
# Change the reference level to "virginica"
iris_hf["Species"] &lt;- h2o.relevel_by_frequency(x = iris_hf["Species"])
# Observe new ordering
h2o.levels(iris_hf["Species"])
# "virginica"  "versicolor" "setosa"

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.removeAll'>Remove All Objects on the H2O Cluster</h2><span id='topic+h2o.removeAll'></span>

<h3>Description</h3>

<p>Removes the data from the h2o cluster, but does not remove the local references.
Retains models, frames and vectors specified in retained_elements argument.
Retained elements must be instances/ids of models and frames only. For models retained, training and validation frames are retained as well.
Cross validation models of a retained model are NOT retained automatically, those must be specified explicitely.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.removeAll(timeout_secs = 0, retained_elements = c())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.removeAll_+3A_timeout_secs">timeout_secs</code></td>
<td>
<p>Timeout in seconds. Default is no timeout.</p>
</td></tr>
<tr><td><code id="h2o.removeAll_+3A_retained_elements">retained_elements</code></td>
<td>
<p>Instances or ids of models and frames to be retained. Combination of instances and ids in the same list is also a valid input.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.rm">h2o.rm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.ls()
h2o.removeAll()
h2o.ls()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.removeVecs'>Delete Columns from an H2OFrame</h2><span id='topic+h2o.removeVecs'></span>

<h3>Description</h3>

<p>Delete the specified columns from the H2OFrame.  Returns an H2OFrame without the specified
columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.removeVecs(data, cols)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.removeVecs_+3A_data">data</code></td>
<td>
<p>The H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.removeVecs_+3A_cols">cols</code></td>
<td>
<p>The columns to remove.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.rep_len'>Replicate Elements of Vectors or Lists into H2O</h2><span id='topic+h2o.rep_len'></span>

<h3>Description</h3>

<p><code>h2o.rep_len</code> performs just as <code>rep</code> does. It replicates the values in
<code>x</code> in the H2O backend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rep_len(x, length.out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rep_len_+3A_x">x</code></td>
<td>
<p>an H2O frame</p>
</td></tr>
<tr><td><code id="h2o.rep_len_+3A_length.out">length.out</code></td>
<td>
<p>non negative integer. The desired length of the output
vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates an H2OFrame of the same type as x
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv"
iris &lt;- h2o.importFile(f)
h2o.rep_len(iris, length.out = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.reset_threshold'>Reset model threshold and return old threshold value.</h2><span id='topic+h2o.reset_threshold'></span>

<h3>Description</h3>

<p>Reset model threshold and return old threshold value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.reset_threshold(object, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.reset_threshold_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.reset_threshold_+3A_threshold">threshold</code></td>
<td>
<p>A threshold value from 0 to 1 included.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the previous threshold used in the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", 
                        nfolds = 0, alpha = 0.5, lambda_search = FALSE)
old_threshold &lt;- h2o.reset_threshold(prostate_glm, 0.9)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.residual_analysis_plot'>Residual Analysis</h2><span id='topic+h2o.residual_analysis_plot'></span>

<h3>Description</h3>

<p>Do Residual Analysis and plot the fitted values vs residuals on a test dataset.
Ideally, residuals should be randomly distributed. Patterns in this plot can indicate
potential problems with the model selection, e.g., using simpler model than necessary,
not accounting for heteroscedasticity, autocorrelation, etc.  If you notice &quot;striped&quot;
lines of residuals, that is just an indication that your response variable was integer
valued instead of real valued.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.residual_analysis_plot(model, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.residual_analysis_plot_+3A_model">model</code></td>
<td>
<p>An H2OModel.</p>
</td></tr>
<tr><td><code id="h2o.residual_analysis_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame.  Used to calculate residuals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the residual analysis plot
residual_analysis_plot &lt;- h2o.residual_analysis_plot(gbm, test)
print(residual_analysis_plot)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.residual_deviance'>Retrieve the residual deviance</h2><span id='topic+h2o.residual_deviance'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training residual deviance value is returned. If more
than one parameter is set to TRUE, then a named vector of residual deviances are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.residual_deviance(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.residual_deviance_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.residual_deviance_+3A_train">train</code></td>
<td>
<p>Retrieve the training residual deviance</p>
</td></tr>
<tr><td><code id="h2o.residual_deviance_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation residual deviance</p>
</td></tr>
<tr><td><code id="h2o.residual_deviance_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation residual deviance</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", 
                        nfolds = 0, alpha = 0.5, lambda_search = FALSE)
h2o.residual_deviance(prostate_glm, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.residual_dof'>Retrieve the residual degrees of freedom</h2><span id='topic+h2o.residual_dof'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training residual degrees of freedom value is returned. If more
than one parameter is set to TRUE, then a named vector of residual degrees of freedom are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.residual_dof(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.residual_dof_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.residual_dof_+3A_train">train</code></td>
<td>
<p>Retrieve the training residual degrees of freedom</p>
</td></tr>
<tr><td><code id="h2o.residual_dof_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation residual degrees of freedom</p>
</td></tr>
<tr><td><code id="h2o.residual_dof_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation residual degrees of freedom</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"), 
                        training_frame = prostate, family = "binomial", 
                        nfolds = 0, alpha = 0.5, lambda_search = FALSE)
h2o.residual_dof(prostate_glm, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.result'>Retrieve the results to view the best predictor subsets.</h2><span id='topic+h2o.result'></span>

<h3>Description</h3>

<p>Retrieve the results to view the best predictor subsets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.result(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.result_+3A_model">model</code></td>
<td>
<p>H2OModelSelection  object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object
</p>

<hr>
<h2 id='h2o.resume'>Triggers auto-recovery resume - this will look into configured recovery dir and resume and
tasks that were interrupted by unexpected cluster stopping.</h2><span id='topic+h2o.resume'></span>

<h3>Description</h3>

<p>Triggers auto-recovery resume - this will look into configured recovery dir and resume and
tasks that were interrupted by unexpected cluster stopping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.resume(recovery_dir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.resume_+3A_recovery_dir">recovery_dir</code></td>
<td>
<p>A <code>character</code> path to where cluster recovery data is stored, if blank, will use
cluster's configuration.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.resumeGrid'>Resume previously stopped grid training.</h2><span id='topic+h2o.resumeGrid'></span>

<h3>Description</h3>

<p>Resume previously stopped grid training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.resumeGrid(grid_id, recovery_dir = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.resumeGrid_+3A_grid_id">grid_id</code></td>
<td>
<p>ID of existing grid search</p>
</td></tr>
<tr><td><code id="h2o.resumeGrid_+3A_recovery_dir">recovery_dir</code></td>
<td>
<p>When specified the grid and all necessary data (frames, models) will be saved to this
directory (use HDFS or other distributed file-system). Should the cluster crash during training, the grid
can be reloaded from this directory via <code>h2o.loadGrid</code> and training can be resumed</p>
</td></tr>
<tr><td><code id="h2o.resumeGrid_+3A_...">...</code></td>
<td>
<p>Additional parameters to modify the resumed Grid.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.rm'>Delete Objects In H2O</h2><span id='topic+h2o.rm'></span>

<h3>Description</h3>

<p>Remove the h2o Big Data object(s) having the key name(s) from ids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rm(ids, cascade = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rm_+3A_ids">ids</code></td>
<td>
<p>The object or hex key associated with the object to be removed or a vector/list of those things.</p>
</td></tr>
<tr><td><code id="h2o.rm_+3A_cascade">cascade</code></td>
<td>
<p>Boolean, if set to TRUE (default), the object dependencies (e.g. submodels) are also removed.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.assign">h2o.assign</a></code>, <code><a href="#topic+h2o.ls">h2o.ls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris &lt;- as.h2o(iris)
model &lt;- h2o.glm(1:4,5,training = iris, family = "multinomial")
h2o.rm(iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rmse'>Retrieves Root Mean Squared Error Value</h2><span id='topic+h2o.rmse'></span>

<h3>Description</h3>

<p>Retrieves the root mean squared error value from an <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a>
object.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training RMSEvalue is returned. If more
than one parameter is set to TRUE, then a named vector of RMSEs are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rmse(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rmse_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a> object of the correct type.</p>
</td></tr>
<tr><td><code id="h2o.rmse_+3A_train">train</code></td>
<td>
<p>Retrieve the training RMSE</p>
</td></tr>
<tr><td><code id="h2o.rmse_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation RMSE</p>
</td></tr>
<tr><td><code id="h2o.rmse_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation RMSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only supports <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>,
<a href="#topic+H2OMultinomialMetrics-class">H2OMultinomialMetrics</a>, and <a href="#topic+H2ORegressionMetrics-class">H2ORegressionMetrics</a> objects.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.auc">h2o.auc</a></code> for AUC, <code><a href="#topic+h2o.mse">h2o.mse</a></code> for RMSE, and
<code><a href="#topic+h2o.metric">h2o.metric</a></code> for the various threshold metrics. See
<code><a href="#topic+h2o.performance">h2o.performance</a></code> for creating H2OModelMetrics objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(prostate_path)

prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
perf &lt;- h2o.performance(model, prostate)
h2o.rmse(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rmsle'>Retrieve the Root Mean Squared Log Error</h2><span id='topic+h2o.rmsle'></span>

<h3>Description</h3>

<p>Retrieves the root mean squared log error (RMSLE) value from an H2O model.
If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training rmsle value is returned. If more
than one parameter is set to TRUE, then a named vector of rmsles are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rmsle(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rmsle_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.rmsle_+3A_train">train</code></td>
<td>
<p>Retrieve the training rmsle</p>
</td></tr>
<tr><td><code id="h2o.rmsle_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation set rmsle if a validation set was passed in during model build time.</p>
</td></tr>
<tr><td><code id="h2o.rmsle_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation rmsle</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)

h &lt;- h2o.init()
fr &lt;- as.h2o(iris)

m &lt;- h2o.deeplearning(x = 2:5, y = 1, training_frame = fr)

h2o.rmsle(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.round'>Round doubles/floats to the given number of decimal places.</h2><span id='topic+h2o.round'></span><span id='topic+round'></span>

<h3>Description</h3>

<p>Round doubles/floats to the given number of decimal places.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.round(x, digits = 0)

round(x, digits = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.round_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.round_+3A_digits">digits</code></td>
<td>
<p>Number of decimal places to round doubles/floats. Rounding to a negative number of decimal places is</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for the base R implementation, <code>round()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv"
heart &lt;- h2o.importFile(f)

h2o.round(heart["age"], digits = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rstrip'>Strip set from right</h2><span id='topic+h2o.rstrip'></span>

<h3>Description</h3>

<p>Return a copy of the target column with trailing characters removed. The set argument
is a string specifying the set of characters to be removed. If omitted, the set
argument defaults to removing whitespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rstrip(x, set = " ")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rstrip_+3A_x">x</code></td>
<td>
<p>The column whose strings should be rstrip-ed.</p>
</td></tr>
<tr><td><code id="h2o.rstrip_+3A_set">set</code></td>
<td>
<p>string of characters to be removed</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_rstrip &lt;- as.h2o("1234567890")
rstrip_string &lt;- h2o.rstrip(string_to_rstrip, "890") #Remove "890"

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.rule_importance'>This function returns the table with estimated coefficients and language representations (in case it is a rule) 
for each of the significant baselearners.</h2><span id='topic+h2o.rule_importance'></span>

<h3>Description</h3>

<p>This function returns the table with estimated coefficients and language representations (in case it is a rule) 
for each of the significant baselearners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rule_importance(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rule_importance_+3A_model">model</code></td>
<td>
<p>of the interest</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.rulefit'>Build a RuleFit Model</h2><span id='topic+h2o.rulefit'></span>

<h3>Description</h3>

<p>Builds a Distributed RuleFit model on a parsed dataset, for regression or 
classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.rulefit(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  seed = -1,
  algorithm = c("AUTO", "DRF", "GBM"),
  min_rule_length = 3,
  max_rule_length = 3,
  max_num_rules = -1,
  model_type = c("rules_and_linear", "rules", "linear"),
  weights_column = NULL,
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  rule_generation_ntrees = 50,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  remove_duplicates = TRUE,
  lambda = NULL,
  max_categorical_levels = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.rulefit_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_algorithm">algorithm</code></td>
<td>
<p>The algorithm to use to generate rules. Must be one of: &quot;AUTO&quot;, &quot;DRF&quot;, &quot;GBM&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_min_rule_length">min_rule_length</code></td>
<td>
<p>Minimum length of rules. Defaults to 3.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_max_rule_length">max_rule_length</code></td>
<td>
<p>Maximum length of rules. Defaults to 3.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_max_num_rules">max_num_rules</code></td>
<td>
<p>The maximum number of rules to return. defaults to -1 which means the number of rules is selected
by diminishing returns in model deviance. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_model_type">model_type</code></td>
<td>
<p>Specifies type of base learners in the ensemble. Must be one of: &quot;rules_and_linear&quot;, &quot;rules&quot;, &quot;linear&quot;. Defaults to rules_and_linear.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_rule_generation_ntrees">rule_generation_ntrees</code></td>
<td>
<p>Specifies the number of trees to build in the tree model. Defaults to 50. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_remove_duplicates">remove_duplicates</code></td>
<td>
<p><code>Logical</code>. Whether to remove rules which are identical to an earlier rule. Defaults to true. Defaults to
TRUE.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_lambda">lambda</code></td>
<td>
<p>Lambda for LASSO regressor.</p>
</td></tr>
<tr><td><code id="h2o.rulefit_+3A_max_categorical_levels">max_categorical_levels</code></td>
<td>
<p>For every categorical feature, only use this many most frequent categorical levels for model training. Only
used for categorical_encoding == EnumLimited. Defaults to 10.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the titanic dataset:
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv"
coltypes &lt;- list(by.col.name = c("pclass", "survived"), types=c("Enum", "Enum"))
df &lt;- h2o.importFile(f, col.types = coltypes)

# Split the dataset into train and test
splits &lt;- h2o.splitFrame(data = df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Set the predictors and response; set the factors:
response &lt;- "survived"
predictors &lt;- c("age", "sibsp", "parch", "fare", "sex", "pclass")

# Build and train the model:
rfit &lt;- h2o.rulefit(y = response,
                    x = predictors,
                    training_frame = train,
                    max_rule_length = 10,
                    max_num_rules = 100,
                    seed = 1)

# Retrieve the rule importance:
print(rfit@model$rule_importance)

# Predict on the test data:
h2o.predict(rfit, newdata = test)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.runif'>Produce a Vector of Random Uniform Numbers</h2><span id='topic+h2o.runif'></span>

<h3>Description</h3>

<p>Creates a vector of random uniform numbers equal in length to the length of the specified H2O
dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.runif(x, seed = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.runif_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.runif_+3A_seed">seed</code></td>
<td>
<p>A random seed used to generate draws from the uniform distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of random, uniformly distributed numbers. The elements are between 0 and 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path)
s &lt;- h2o.runif(prostate)
summary(s)

prostate_train &lt;- prostate[s &lt;= 0.8,]
prostate_test &lt;- prostate[s &gt; 0.8,]
nrow(prostate_train) + nrow(prostate_test)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.save_frame'>Store frame data in H2O's native format.</h2><span id='topic+h2o.save_frame'></span>

<h3>Description</h3>

<p>Store frame data in H2O's native format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.save_frame(x, dir, force = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.save_frame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="h2o.save_frame_+3A_dir">dir</code></td>
<td>
<p>a filesystem location where to write frame data (hdfs, nfs)</p>
</td></tr>
<tr><td><code id="h2o.save_frame_+3A_force">force</code></td>
<td>
<p><code>logical</code>. overwrite already existing files (defaults to true)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
prostate = h2o.importFile(path = prostate_path)
h2o.save_frame(prostate, "/tmp/prostate")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.save_mojo'>Save an H2O Model Object as Mojo to Disk</h2><span id='topic+h2o.save_mojo'></span>

<h3>Description</h3>

<p>Save an MOJO (Model Object, Optimized) to disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.save_mojo(object, path = "", force = FALSE, filename = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.save_mojo_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.save_mojo_+3A_path">path</code></td>
<td>
<p>string indicating the directory the model will be written to.</p>
</td></tr>
<tr><td><code id="h2o.save_mojo_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
<tr><td><code id="h2o.save_mojo_+3A_filename">filename</code></td>
<td>
<p>string indicating the file name. (Type of file is always .zip)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MOJO will download as a zip file. In the case of existing files <code>force = TRUE</code>
will overwrite the file. Otherwise, the operation will fail.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.saveModel">h2o.saveModel</a></code> for saving a model to disk as a binary object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate &lt;- h2o.uploadFile(path = system.file("extdata", "prostate.csv", package="h2o"))
# prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
#                         training_frame = prostate, family = "binomial", alpha = 0.5)
# h2o.save_mojo(object = prostate_glm, path = "/Users/UserName/Desktop", force = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.save_to_hive'>Save contents of this data frame into a Hive table</h2><span id='topic+h2o.save_to_hive'></span>

<h3>Description</h3>

<p>For example,
h2o.save_to_hive(data_frame, &quot;jdbc:hive2://host:10000/database&quot;, &quot;table_name&quot;)
h2o.save_to_hive(data_frame, &quot;jdbc:hive2://host:10000/&quot;, &quot;database.table_name&quot;, format = &quot;parquet&quot;)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.save_to_hive(
  data,
  jdbc_url,
  table_name,
  format = "csv",
  table_path = NULL,
  tmp_path = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.save_to_hive_+3A_data">data</code></td>
<td>
<p>A H2O Frame object to be saved.</p>
</td></tr>
<tr><td><code id="h2o.save_to_hive_+3A_jdbc_url">jdbc_url</code></td>
<td>
<p>Hive JDBC connection URL.</p>
</td></tr>
<tr><td><code id="h2o.save_to_hive_+3A_table_name">table_name</code></td>
<td>
<p>Table name into which to store the data. The table must not exist as it will be created</p>
</td></tr>
<tr><td><code id="h2o.save_to_hive_+3A_format">format</code></td>
<td>
<p>Storage format of created Hive table. (default csv, can be csv or parquet)</p>
</td></tr>
<tr><td><code id="h2o.save_to_hive_+3A_table_path">table_path</code></td>
<td>
<p>If specified, the table will be created as an external table and this is where the data</p>
</td></tr>
<tr><td><code id="h2o.save_to_hive_+3A_tmp_path">tmp_path</code></td>
<td>
<p>Path where to store temporary data.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.saveGrid'>Saves an existing Grid of models into a given folder.</h2><span id='topic+h2o.saveGrid'></span>

<h3>Description</h3>

<p>Returns a reference to the saved Grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.saveGrid(
  grid_directory,
  grid_id,
  save_params_references = FALSE,
  export_cross_validation_predictions = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.saveGrid_+3A_grid_directory">grid_directory</code></td>
<td>
<p>A character string containing the path to the folder for the grid to be saved to.</p>
</td></tr>
<tr><td><code id="h2o.saveGrid_+3A_grid_id">grid_id</code></td>
<td>
<p>A chracter string with identification of the grid to be saved.</p>
</td></tr>
<tr><td><code id="h2o.saveGrid_+3A_save_params_references">save_params_references</code></td>
<td>
<p>A logical indicating if objects referenced by grid parameters
(e.g. training frame, calibration frame) should also be saved.</p>
</td></tr>
<tr><td><code id="h2o.saveGrid_+3A_export_cross_validation_predictions">export_cross_validation_predictions</code></td>
<td>
<p>A logical indicating whether exported model
artifacts should also include CV holdout Frame predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object that is a subclass of <a href="#topic+H2OGrid-class">H2OGrid</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris &lt;- as.h2o(iris)

ntrees_opts = c(1, 5)
learn_rate_opts = c(0.1, 0.01)
size_of_hyper_space = length(ntrees_opts) * length(learn_rate_opts)

hyper_parameters = list(ntrees = ntrees_opts, learn_rate = learn_rate_opts)
# Tempdir is chosen arbitrarily. May be any valid folder on an H2O-supported filesystem.
baseline_grid &lt;- h2o.grid(algorithm = "gbm", 
                         grid_id = "gbm_grid_test", 
                         x = 1:4, 
                         y = 5, 
                         training_frame = iris,
                         hyper_params = hyper_parameters)

grid_path &lt;- h2o.saveGrid(grid_directory = tempdir(), grid_id = baseline_grid@grid_id)
# Remove everything from the cluster or restart it
h2o.removeAll()
grid &lt;- h2o.loadGrid(grid_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.saveModel'>Save an H2O Model Object to Disk</h2><span id='topic+h2o.saveModel'></span>

<h3>Description</h3>

<p>Save an <a href="#topic+H2OModel-class">H2OModel</a> to disk. (Note that ensemble binary models 
can be saved.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.saveModel(
  object,
  path = "",
  force = FALSE,
  export_cross_validation_predictions = FALSE,
  filename = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.saveModel_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.saveModel_+3A_path">path</code></td>
<td>
<p>string indicating the directory the model will be written to.</p>
</td></tr>
<tr><td><code id="h2o.saveModel_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
<tr><td><code id="h2o.saveModel_+3A_export_cross_validation_predictions">export_cross_validation_predictions</code></td>
<td>
<p>logical, indicates whether the exported model 
artifacts should also include CV Holdout Frame predictions.  Default is not to export 
the predictions.</p>
</td></tr>
<tr><td><code id="h2o.saveModel_+3A_filename">filename</code></td>
<td>
<p>string indicating the file name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of existing files <code>force = TRUE</code> will overwrite the file.
Otherwise, the operation will fail.
</p>
<p>The owner of the file saved is the user by which H2O cluster was executed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.loadModel">h2o.loadModel</a></code> for loading a model to H2O from disk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate &lt;- h2o.importFile(path = paste("https://raw.github.com",
#    "h2oai/h2o-2/master/smalldata/logreg/prostate.csv", sep = "/"))
# prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
#    training_frame = prostate, family = "binomial", alpha = 0.5)
# h2o.saveModel(object = prostate_glm, path = "/Users/UserName/Desktop", force = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.saveModelDetails'>Save an H2O Model Details</h2><span id='topic+h2o.saveModelDetails'></span>

<h3>Description</h3>

<p>Save Model Details of an H2O Model in JSON Format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.saveModelDetails(object, path = "", force = FALSE, filename = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.saveModelDetails_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.saveModelDetails_+3A_path">path</code></td>
<td>
<p>string indicating the directory the model details will be written to.</p>
</td></tr>
<tr><td><code id="h2o.saveModelDetails_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
<tr><td><code id="h2o.saveModelDetails_+3A_filename">filename</code></td>
<td>
<p>string indicating the file name. (Type of file is always .json)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model Details will download as a JSON file. In the case of existing files <code>force = TRUE</code>
will overwrite the file. Otherwise, the operation will fail.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate &lt;- h2o.uploadFile(path = system.file("extdata", "prostate.csv", package = "h2o"))
# prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
#                         training_frame = prostate, family = "binomial", alpha = 0.5)
# h2o.saveModelDetails(object = prostate_glm, path = "/Users/UserName/Desktop", force = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.saveMojo'>Deprecated - use h2o.save_mojo instead. Save an H2O Model Object as Mojo to Disk</h2><span id='topic+h2o.saveMojo'></span>

<h3>Description</h3>

<p>Save an MOJO (Model Object, Optimized) to disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.saveMojo(object, path = "", force = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.saveMojo_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.saveMojo_+3A_path">path</code></td>
<td>
<p>string indicating the directory the model will be written to.</p>
</td></tr>
<tr><td><code id="h2o.saveMojo_+3A_force">force</code></td>
<td>
<p>logical, indicates how to deal with files that already exist.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MOJO will download as a zip file. In the case of existing files <code>force = TRUE</code>
will overwrite the file. Otherwise, the operation will fail.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.saveModel">h2o.saveModel</a></code> for saving a model to disk as a binary object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate &lt;- h2o.uploadFile(path = system.file("extdata", "prostate.csv", package="h2o"))
# prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
#                         training_frame = prostate, family = "binomial", alpha = 0.5)
# h2o.saveMojo(object = prostate_glm, path = "/Users/UserName/Desktop", force = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.scale'>Scaling and Centering of an H2OFrame</h2><span id='topic+h2o.scale'></span>

<h3>Description</h3>

<p>Centers and/or scales the columns of an H2O dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.scale(x, center = TRUE, scale = TRUE, inplace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.scale_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.scale_+3A_center">center</code></td>
<td>
<p>either a <code>logical</code> value or numeric vector of length equal to the number of columns of x.</p>
</td></tr>
<tr><td><code id="h2o.scale_+3A_scale">scale</code></td>
<td>
<p>either a <code>logical</code> value or numeric vector of length equal to the number of columns of x.</p>
</td></tr>
<tr><td><code id="h2o.scale_+3A_inplace">inplace</code></td>
<td>
<p>a <code>logical</code> values indicating whether directly overwrite original data (disabled by default).
Exposed for backwards compatibility (prior versions of this functions were always doing an inplace update).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
summary(iris_hf)

# Scale and center all the numeric columns in iris data set
iris_scaled &lt;- h2o.scale(iris_hf[, 1:4])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.scoreHistory'>Retrieve Model Score History</h2><span id='topic+h2o.scoreHistory'></span>

<h3>Description</h3>

<p>Retrieve Model Score History
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.scoreHistory(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.scoreHistory_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
response &lt;- "economy_20mpg"
cars_split &lt;- h2o.splitFrame(data = cars, ratios = 0.8, seed = 1234)
train &lt;- cars_split[[1]]
valid &lt;- cars_split[[2]]
cars_gbm &lt;- h2o.gbm(x = predictors, y = response, 
                    training_frame = train, 
                    validation_frame = valid, 
                    seed = 1234)
h2o.scoreHistory(cars_gbm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.scoreHistoryGAM'>Retrieve GLM Model Score History buried in GAM model</h2><span id='topic+h2o.scoreHistoryGAM'></span>

<h3>Description</h3>

<p>Retrieve GLM Model Score History buried in GAM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.scoreHistoryGAM(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.scoreHistoryGAM_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.screeplot'>Scree Plot</h2><span id='topic+h2o.screeplot'></span>

<h3>Description</h3>

<p>Scree Plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.screeplot(model, type = c("barplot", "lines"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.screeplot_+3A_model">model</code></td>
<td>
<p>A PCA model</p>
</td></tr>
<tr><td><code id="h2o.screeplot_+3A_type">type</code></td>
<td>
<p>Type of the plot. Either &quot;barplot&quot; or &quot;lines&quot;.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.sd'>Standard Deviation of a column of data.</h2><span id='topic+h2o.sd'></span><span id='topic+sd'></span>

<h3>Description</h3>

<p>Obtain the standard deviation of a column of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sd(x, na.rm = FALSE)

sd(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sd_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.sd_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Should missing values be removed?</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.var">h2o.var</a></code> for variance, and <code><a href="stats.html#topic+sd">sd</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
sd(prostate$AGE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.sdev'>Retrieve the standard deviations of principal components</h2><span id='topic+h2o.sdev'></span>

<h3>Description</h3>

<p>Retrieve the standard deviations of principal components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sdev(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sdev_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
predictors &lt;- c("displacement", "power", "weight", "acceleration", "year")
cars_pca &lt;- h2o.prcomp(cars, transform = "STANDARDIZE", 
                       k = 3, x = predictors, seed = 12345)
h2o.sdev(cars_pca)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.set_s3_credentials'>Creates a new Amazon S3 client internally with specified credentials.</h2><span id='topic+h2o.set_s3_credentials'></span>

<h3>Description</h3>

<p>There are no validations done to the credentials. Incorrect credentials are thus revealed with first S3 import call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.set_s3_credentials(secretKeyId, secretAccessKey, sessionToken = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.set_s3_credentials_+3A_secretkeyid">secretKeyId</code></td>
<td>
<p>Amazon S3 Secret Key ID (provided by Amazon)</p>
</td></tr>
<tr><td><code id="h2o.set_s3_credentials_+3A_secretaccesskey">secretAccessKey</code></td>
<td>
<p>Amazon S3 Secret Access Key (provided by Amazon)</p>
</td></tr>
<tr><td><code id="h2o.set_s3_credentials_+3A_sessiontoken">sessionToken</code></td>
<td>
<p>Amazon Session Token (optional, only when using AWS Temporary Credentials)</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.setLevels'>Set Levels of H2O Factor Column</h2><span id='topic+h2o.setLevels'></span>

<h3>Description</h3>

<p>Works on a single categorical vector. New domains must be aligned with the old domains.
This call has SIDE EFFECTS and mutates the column in place (change of the levels will also affect all the frames
that are referencing this column). If you want to make a copy of the column instead, use parameter in.place = FALSE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.setLevels(x, levels, in.place = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.setLevels_+3A_x">x</code></td>
<td>
<p>A single categorical column.</p>
</td></tr>
<tr><td><code id="h2o.setLevels_+3A_levels">levels</code></td>
<td>
<p>A character vector specifying the new levels. The number of new levels must match the number of old levels.</p>
</td></tr>
<tr><td><code id="h2o.setLevels_+3A_in.place">in.place</code></td>
<td>
<p>Indicates whether new domain will be directly applied to the column (in place change) or if a copy
of the column will be created with the given domain levels.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
new_levels &lt;- c("setosa", "versicolor", "caroliniana")
iris_hf$Species &lt;- h2o.setLevels(iris_hf$Species, new_levels, in.place = FALSE)
h2o.levels(iris_hf$Species)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.setTimezone'>Set the Time Zone on the H2O cluster</h2><span id='topic+h2o.setTimezone'></span>

<h3>Description</h3>

<p>Set the Time Zone on the H2O cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.setTimezone(tz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.setTimezone_+3A_tz">tz</code></td>
<td>
<p>The desired timezone.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

h2o.setTimezone("America/Juneau")
h2o.getTimezone()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.shap_explain_row_plot'>SHAP Local Explanation</h2><span id='topic+h2o.shap_explain_row_plot'></span>

<h3>Description</h3>

<p>SHAP explanation shows contribution of features for a given instance. The sum
of the feature contributions and the bias term is equal to the raw prediction
of the model, i.e., prediction before applying inverse link function. H2O implements
TreeSHAP which when the features are correlated, can increase contribution of a feature
that had no influence on the prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.shap_explain_row_plot(
  model,
  newdata,
  row_index,
  columns = NULL,
  top_n_features = 10,
  plot_type = c("barplot", "breakdown"),
  contribution_type = c("both", "positive", "negative"),
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_model">model</code></td>
<td>
<p>An H2O tree-based model. This includes Random Forest, GBM and XGboost
only. Must be a binary classification or regression model.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2O Frame, used to determine feature contributions.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_row_index">row_index</code></td>
<td>
<p>Instance row index.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_columns">columns</code></td>
<td>
<p>List of columns or list of indices of columns to show.
If specified, then the <code>top_n_features</code> parameter will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_top_n_features">top_n_features</code></td>
<td>
<p>Integer specifying the maximum number of columns to show (ranked by their contributions).
When <code>plot_type = "barplot"</code>, then <code>top_n_features</code> features will be chosen
for each contribution_type.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_plot_type">plot_type</code></td>
<td>
<p>Either &quot;barplot&quot; or &quot;breakdown&quot;.  Defaults to &quot;barplot&quot;.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_contribution_type">contribution_type</code></td>
<td>
<p>When <code>plot_type == "barplot"</code>, plot one of &quot;negative&quot;,
&quot;positive&quot;, or &quot;both&quot; contributions.  Defaults to &quot;both&quot;.</p>
</td></tr>
<tr><td><code id="h2o.shap_explain_row_plot_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the SHAP row explanation plot
shap_explain_row_plot &lt;- h2o.shap_explain_row_plot(gbm, test, row_index = 1)
print(shap_explain_row_plot)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.shap_summary_plot'>SHAP Summary Plot</h2><span id='topic+h2o.shap_summary_plot'></span>

<h3>Description</h3>

<p>SHAP summary plot shows the contribution of the features for each instance (row of data).
The sum of the feature contributions and the bias term is equal to the raw prediction
of the model, i.e., prediction before applying inverse link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.shap_summary_plot(
  model,
  newdata,
  columns = NULL,
  top_n_features = 20,
  sample_size = 1000,
  background_frame = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.shap_summary_plot_+3A_model">model</code></td>
<td>
<p>An H2O tree-based model. This includes Random Forest, GBM and XGboost
only. Must be a binary classification or regression model.</p>
</td></tr>
<tr><td><code id="h2o.shap_summary_plot_+3A_newdata">newdata</code></td>
<td>
<p>An H2O Frame, used to determine feature contributions.</p>
</td></tr>
<tr><td><code id="h2o.shap_summary_plot_+3A_columns">columns</code></td>
<td>
<p>List of columns or list of indices of columns to show.
If specified, then the <code>top_n_features</code> parameter will be ignored.</p>
</td></tr>
<tr><td><code id="h2o.shap_summary_plot_+3A_top_n_features">top_n_features</code></td>
<td>
<p>Integer specifying the maximum number of columns to show (ranked by variable importance).</p>
</td></tr>
<tr><td><code id="h2o.shap_summary_plot_+3A_sample_size">sample_size</code></td>
<td>
<p>Integer specifying the maximum number of observations to be plotted.</p>
</td></tr>
<tr><td><code id="h2o.shap_summary_plot_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for the marginal SHAP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
gbm &lt;- h2o.gbm(y = response,
               training_frame = train)

# Create the SHAP summary plot
shap_summary_plot &lt;- h2o.shap_summary_plot(gbm, test)
print(shap_summary_plot)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.show_progress'>Enable Progress Bar</h2><span id='topic+h2o.show_progress'></span>

<h3>Description</h3>

<p>Enable Progress Bar
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.show_progress(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.show_progress_+3A_expr">expr</code></td>
<td>
<p>When specified enable progress only for the evaluation of the expr and after the evaluation return to the previous setting (default is to show the progress bar), otherwise enable it globally.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of expr if specified, otherwise NULL.
</p>


<h3>See Also</h3>

<p><a href="#topic+h2o.no_progress">h2o.no_progress</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.no_progress()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
iris["class"] &lt;- as.factor(iris["class"])
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
splits &lt;- h2o.splitFrame(iris, ratios = 0.8, seed = 1234)
train &lt;- splits[[1]]
valid &lt;- splits[[2]]
h2o.show_progress()

iris_km &lt;- h2o.kmeans(x = predictors, 
                      training_frame = train, 
                      validation_frame = valid, 
                      k = 10, estimate_k = TRUE, 
                      standardize = FALSE, seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.shutdown'>Shut Down H2O Instance</h2><span id='topic+h2o.shutdown'></span>

<h3>Description</h3>

<p>Shut down the specified instance. All data will be lost.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.shutdown(prompt = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.shutdown_+3A_prompt">prompt</code></td>
<td>
<p>A <code>logical</code> value indicating whether to prompt the user before shutting down the H2O server.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method checks if H2O is running at the specified IP address and port, and if it is, shuts down that H2O instance.
</p>


<h3>WARNING</h3>

<p>All data, models, and other values stored on the server will be lost! Only call this function if you and all other clients connected to the H2O server are finished and have saved your work.
</p>


<h3>Note</h3>

<p>Users must call h2o.shutdown explicitly in order to shut down the local H2O instance started by R. If R is closed before H2O, then an attempt will be made to automatically shut down H2O. This only applies to local instances started with h2o.init, not remote H2O servers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.init">h2o.init</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Don't run automatically to prevent accidentally shutting down a cluster
## Not run: 
library(h2o)
h2o.init()
h2o.shutdown()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.signif'>Round doubles/floats to the given number of significant digits.</h2><span id='topic+h2o.signif'></span><span id='topic+signif'></span>

<h3>Description</h3>

<p>Round doubles/floats to the given number of significant digits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.signif(x, digits = 6)

signif(x, digits = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.signif_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.signif_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits to round doubles/floats.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for the base R implementation, <code>signif()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv"
heart &lt;- h2o.importFile(f)

h2o.signif(heart["age"], digits = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.sin'>Compute the sine of x</h2><span id='topic+h2o.sin'></span>

<h3>Description</h3>

<p>Compute the sine of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sin(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sin_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Trig">Trig</a></code> for the base R implementation, <code>sin()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.sin(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.skewness'>Skewness of a column</h2><span id='topic+h2o.skewness'></span><span id='topic+skewness.H2OFrame'></span>

<h3>Description</h3>

<p>Obtain the skewness of a column of a parsed H2O data object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.skewness(x, ..., na.rm = TRUE)

skewness.H2OFrame(x, ..., na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.skewness_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.skewness_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
<tr><td><code id="h2o.skewness_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical value indicating whether <code>NA</code> or missing values should be stripped before the computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the skewness for each column (NaN for non-numeric columns).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
h2o.skewness(prostate$AGE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.splitFrame'>Split an H2O Data Set</h2><span id='topic+h2o.splitFrame'></span>

<h3>Description</h3>

<p>Split an existing H2O data set according to user-specified ratios. The number of
subsets is always 1 more than the number of given ratios. Note that this does not give
an exact split. H2O is designed to be efficient on big data using a probabilistic
splitting method rather than an exact split. For example, when specifying a split of
0.75/0.25, H2O will produce a test/train split with an expected value of 0.75/0.25
rather than exactly 0.75/0.25. On small datasets, the sizes of the resulting splits
will deviate from the expected value more than on big data, where they will be very
close to exact.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.splitFrame(data, ratios = 0.75, destination_frames, seed = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.splitFrame_+3A_data">data</code></td>
<td>
<p>An H2OFrame object, to be split.</p>
</td></tr>
<tr><td><code id="h2o.splitFrame_+3A_ratios">ratios</code></td>
<td>
<p>A numeric value or array indicating the ratio of total rows
contained in each split. Must total up to less than 1. e.g. c(0.8) for 80/20 split.</p>
</td></tr>
<tr><td><code id="h2o.splitFrame_+3A_destination_frames">destination_frames</code></td>
<td>
<p>An array of frame IDs equal to the number of values
specified in the ratios array, plus one.</p>
</td></tr>
<tr><td><code id="h2o.splitFrame_+3A_seed">seed</code></td>
<td>
<p>Random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of split H2OFrames
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
iris_split &lt;- h2o.splitFrame(iris_hf, ratios = c(0.2, 0.5))
head(iris_split[[1]])
summary(iris_split[[1]])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.sqrt'>Compute the square root of x</h2><span id='topic+h2o.sqrt'></span>

<h3>Description</h3>

<p>Compute the square root of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sqrt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sqrt_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+MathFun">MathFun</a></code> for the base R implementation, <code>sqrt()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.sqrt(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.stackedEnsemble'>Builds a Stacked Ensemble</h2><span id='topic+h2o.stackedEnsemble'></span>

<h3>Description</h3>

<p>Build a stacked ensemble (aka. Super Learner) using the H2O base
learning algorithms specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.stackedEnsemble(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  blending_frame = NULL,
  base_models = list(),
  metalearner_algorithm = c("AUTO", "deeplearning", "drf", "gbm", "glm", "naivebayes",
    "xgboost"),
  metalearner_nfolds = 0,
  metalearner_fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  metalearner_fold_column = NULL,
  metalearner_params = NULL,
  metalearner_transform = c("NONE", "Logit"),
  max_runtime_secs = 0,
  weights_column = NULL,
  offset_column = NULL,
  custom_metric_func = NULL,
  seed = -1,
  score_training_samples = 10000,
  keep_levelone_frame = FALSE,
  export_checkpoints_dir = NULL,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  gainslift_bins = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.stackedEnsemble_+3A_x">x</code></td>
<td>
<p>(Optional). A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.  Training frame is used only to compute ensemble training metrics.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_blending_frame">blending_frame</code></td>
<td>
<p>Frame used to compute the predictions that serve as the training frame for the metalearner (triggers blending
mode if provided)</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_base_models">base_models</code></td>
<td>
<p>List of models or grids (or their ids) to ensemble/stack together. Grids are expanded to individual models. If
not using blending frame, then models must have been cross-validated using nfolds &gt; 1, and folds must be
identical across models.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_algorithm">metalearner_algorithm</code></td>
<td>
<p>Type of algorithm to use as the metalearner. Options include 'AUTO' (GLM with non negative weights; if
validation_frame is present, a lambda search is performed), 'deeplearning' (Deep Learning with default
parameters), 'drf' (Random Forest with default parameters), 'gbm' (GBM with default parameters), 'glm' (GLM
with default parameters), 'naivebayes' (NaiveBayes with default parameters), or 'xgboost' (if available,
XGBoost with default parameters). Must be one of: &quot;AUTO&quot;, &quot;deeplearning&quot;, &quot;drf&quot;, &quot;gbm&quot;, &quot;glm&quot;, &quot;naivebayes&quot;,
&quot;xgboost&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_nfolds">metalearner_nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation of the metalearner algorithm (0 to disable or &gt;= 2). Defaults to
0.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_fold_assignment">metalearner_fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme for metalearner cross-validation.  Defaults to AUTO (which is
currently set to Random). The 'Stratified' option will stratify the folds based on the response variable, for
classification problems. Must be one of: &quot;AUTO&quot;, &quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_fold_column">metalearner_fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation for cross-validation of the metalearner.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_params">metalearner_params</code></td>
<td>
<p>Parameters for metalearner algorithm</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_metalearner_transform">metalearner_transform</code></td>
<td>
<p>Transformation used for the level one frame. Must be one of: &quot;NONE&quot;, &quot;Logit&quot;. Defaults to NONE.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers; passed through to the metalearner algorithm. Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_score_training_samples">score_training_samples</code></td>
<td>
<p>Specify the number of training set samples for scoring. The value must be &gt;= 0. To use all training samples,
enter 0. Defaults to 10000.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_keep_levelone_frame">keep_levelone_frame</code></td>
<td>
<p><code>Logical</code>. Keep level one frame used for metalearner training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.stackedEnsemble_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import a sample binary outcome train/test set
train &lt;- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv")
test &lt;- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv")

# Identify predictors and response
y &lt;- "response"
x &lt;- setdiff(names(train), y)

# For binary classification, response should be a factor
train[, y] &lt;- as.factor(train[, y])
test[, y] &lt;- as.factor(test[, y])

# Number of CV folds
nfolds &lt;- 5

# Train &amp; Cross-validate a GBM
my_gbm &lt;- h2o.gbm(x = x,
                  y = y,
                  training_frame = train,
                  distribution = "bernoulli",
                  ntrees = 10,
                  max_depth = 3,
                  min_rows = 2,
                  learn_rate = 0.2,
                  nfolds = nfolds,
                  fold_assignment = "Modulo",
                  keep_cross_validation_predictions = TRUE,
                  seed = 1)

# Train &amp; Cross-validate a RF
my_rf &lt;- h2o.randomForest(x = x,
                          y = y,
                          training_frame = train,
                          ntrees = 50,
                          nfolds = nfolds,
                          fold_assignment = "Modulo",
                          keep_cross_validation_predictions = TRUE,
                          seed = 1)

# Train a stacked ensemble using the GBM and RF above
ensemble &lt;- h2o.stackedEnsemble(x = x,
                                y = y,
                                training_frame = train,
                                model_id = "my_ensemble_binomial",
                                base_models = list(my_gbm, my_rf))

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.startLogging'>Start Writing H2O R Logs</h2><span id='topic+h2o.startLogging'></span>

<h3>Description</h3>

<p>Begin logging H2o R POST commands and error responses to local disk. Used
primarily for debuggin purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.startLogging(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.startLogging_+3A_file">file</code></td>
<td>
<p>a character string name for the file, automatically generated</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.stopLogging">h2o.stopLogging</a>, <a href="#topic+h2o.clearLog">h2o.clearLog</a>,
         <a href="#topic+h2o.openLog">h2o.openLog</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.startLogging()
australia_path = system.file("extdata", "australia.csv", package = "h2o")
australia = h2o.importFile(path = australia_path)
h2o.stopLogging()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.std_coef_plot'>Plot Standardized Coefficient Magnitudes</h2><span id='topic+h2o.std_coef_plot'></span>

<h3>Description</h3>

<p>Plot a GLM model's standardized coefficient magnitudes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.std_coef_plot(model, num_of_features = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.std_coef_plot_+3A_model">model</code></td>
<td>
<p>A trained generalized linear model</p>
</td></tr>
<tr><td><code id="h2o.std_coef_plot_+3A_num_of_features">num_of_features</code></td>
<td>
<p>The number of features to be shown in the plot</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.varimp_plot">h2o.varimp_plot</a></code> for variable importances plot of
random forest, GBM, deep learning.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
prostate_glm &lt;- h2o.glm(y = "CAPSULE", x = c("AGE", "RACE", "PSA", "DCAPS"),
                         training_frame = prostate, family = "binomial",
                         nfolds = 0, alpha = 0.5, lambda_search = FALSE)
h2o.std_coef_plot(prostate_glm)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.stopLogging'>Stop Writing H2O R Logs</h2><span id='topic+h2o.stopLogging'></span>

<h3>Description</h3>

<p>Halt logging of H2O R POST commands and error responses to local disk. Used
primarily for debugging purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.stopLogging()
</code></pre>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.startLogging">h2o.startLogging</a>, <a href="#topic+h2o.clearLog">h2o.clearLog</a>,
         <a href="#topic+h2o.openLog">h2o.openLog</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.startLogging()
australia_path = system.file("extdata", "australia.csv", package = "h2o")
australia = h2o.importFile(path = australia_path)
h2o.stopLogging()

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.str'>Display the structure of an H2OFrame object</h2><span id='topic+h2o.str'></span>

<h3>Description</h3>

<p>Display the structure of an H2OFrame object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.str(object, ..., cols = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.str_+3A_object">object</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="h2o.str_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
<tr><td><code id="h2o.str_+3A_cols">cols</code></td>
<td>
<p>Print the per-column str for the H2OFrame</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.str(frame, cols = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.stringdist'>Compute element-wise string distances between two H2OFrames</h2><span id='topic+h2o.stringdist'></span>

<h3>Description</h3>

<p>Compute element-wise string distances between two H2OFrames. Both frames need to have the same
shape (N x M) and only contain string/factor columns. Return a matrix (H2OFrame) of shape N x M.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.stringdist(
  x,
  y,
  method = c("lv", "lcs", "qgram", "jaccard", "jw", "soundex"),
  compare_empty = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.stringdist_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.stringdist_+3A_y">y</code></td>
<td>
<p>A comparison H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.stringdist_+3A_method">method</code></td>
<td>
<p>A string identifier indicating what string distance measure to use. Must be one of:
&quot;lv&quot;                   - Levenshtein distance
&quot;lcs&quot;                  - Longest common substring distance
&quot;qgram&quot;                - q-gram distance
&quot;jaccard&quot;              - Jaccard distance between q-gram profiles
&quot;jw&quot;                   - Jaro, or Jaro-Winker distance
&quot;soundex&quot;              - Distance based on soundex encoding</p>
</td></tr>
<tr><td><code id="h2o.stringdist_+3A_compare_empty">compare_empty</code></td>
<td>
<p>if set to FALSE, empty strings will be handled as NaNs</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()
x &lt;- as.h2o(c("Martha", "Dwayne", "Dixon"))
y &lt;- as.character(as.h2o(c("Marhta", "Duane", "Dicksonx")))
h2o.stringdist(x, y, method = "jw")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.strsplit'>String Split</h2><span id='topic+h2o.strsplit'></span>

<h3>Description</h3>

<p>String Split
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.strsplit(x, split)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.strsplit_+3A_x">x</code></td>
<td>
<p>The column whose strings must be split.</p>
</td></tr>
<tr><td><code id="h2o.strsplit_+3A_split">split</code></td>
<td>
<p>The pattern to split on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame where each column is the outcome of the string split.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_split &lt;- as.h2o("Split at every character.")
split_string &lt;- h2o.strsplit(string_to_split, "")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.sub'>String Substitute</h2><span id='topic+h2o.sub'></span>

<h3>Description</h3>

<p>Creates a copy of the target column in which each string has the first occurence of
the regex pattern replaced with the replacement substring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sub(pattern, replacement, x, ignore.case = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sub_+3A_pattern">pattern</code></td>
<td>
<p>The pattern to replace.</p>
</td></tr>
<tr><td><code id="h2o.sub_+3A_replacement">replacement</code></td>
<td>
<p>The replacement pattern.</p>
</td></tr>
<tr><td><code id="h2o.sub_+3A_x">x</code></td>
<td>
<p>The column on which to operate.</p>
</td></tr>
<tr><td><code id="h2o.sub_+3A_ignore.case">ignore.case</code></td>
<td>
<p>Case sensitive or not</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_sub &lt;- as.h2o("r tutorial")
sub_string &lt;- h2o.sub("r ", "H2O ", string_to_sub)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.substring'>Substring</h2><span id='topic+h2o.substring'></span><span id='topic+h2o.substr'></span>

<h3>Description</h3>

<p>Returns a copy of the target column that is a substring at the specified start 
and stop indices, inclusive. If the stop index is not specified, then the substring extends
to the end of the original string. If start is longer than the number of characters
in the original string, or is greater than stop, an empty string is returned. Negative start
is coerced to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.substring(x, start, stop = "[]")

h2o.substr(x, start, stop = "[]")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.substring_+3A_x">x</code></td>
<td>
<p>The column on which to operate.</p>
</td></tr>
<tr><td><code id="h2o.substring_+3A_start">start</code></td>
<td>
<p>The index of the first element to be included in the substring.</p>
</td></tr>
<tr><td><code id="h2o.substring_+3A_stop">stop</code></td>
<td>
<p>Optional, The index of the last element to be included in the substring.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_substring &lt;- as.h2o("1234567890")
substr &lt;- h2o.substring(string_to_substring, 2) #Get substring from second index onwards

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.sum'>Compute the frame's sum by-column (or by-row).</h2><span id='topic+h2o.sum'></span>

<h3>Description</h3>

<p>Compute the frame's sum by-column (or by-row).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.sum(x, na.rm = FALSE, axis = 0, return_frame = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.sum_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.sum_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. indicating whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="h2o.sum_+3A_axis">axis</code></td>
<td>
<p>An int that indicates whether to do down a column (0) or across a row (1). For row or column sums, the <code>return_frame</code> parameter must be TRUE.</p>
</td></tr>
<tr><td><code id="h2o.sum_+3A_return_frame">return_frame</code></td>
<td>
<p>A boolean that indicates whether to return an H2O frame or one single aggregated value. Default is FALSE.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sum">sum</a></code> for the base R implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.sum(frame["C1"], na.rm = TRUE, axis = 0, return_frame = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.summary'>Summarizes the columns of an H2OFrame.</h2><span id='topic+h2o.summary'></span><span id='topic+summary.H2OFrame'></span>

<h3>Description</h3>

<p>A method for the <code><a href="base.html#topic+summary">summary</a></code> generic. Summarizes the columns of an H2O data frame or subset of
columns and rows using vector notation (e.g. dataset[row, col]).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.summary(object, factors = 6L, exact_quantiles = FALSE, ...)

## S3 method for class 'H2OFrame'
summary(object, factors, exact_quantiles, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.summary_+3A_object">object</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.summary_+3A_factors">factors</code></td>
<td>
<p>The number of factors to return in the summary. Default is the top 6.</p>
</td></tr>
<tr><td><code id="h2o.summary_+3A_exact_quantiles">exact_quantiles</code></td>
<td>
<p>Compute exact quantiles or use approximation. Default is to use approximation.</p>
</td></tr>
<tr><td><code id="h2o.summary_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default it uses approximated version of quantiles computation, however, user can modify
this behavior by setting up exact_quantiles argument to true.
</p>


<h3>Value</h3>

<p>A table displaying the minimum, 1st quartile, median, mean, 3rd quartile and maximum for each
numeric column, and the levels and category counts of the levels in each categorical column.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path)
summary(prostate)
summary(prostate$GLEASON)
summary(prostate[, 4:6])
summary(prostate, exact_quantiles = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.svd'>Singular value decomposition of an H2O data frame using the power method</h2><span id='topic+h2o.svd'></span>

<h3>Description</h3>

<p>Singular value decomposition of an H2O data frame using the power method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.svd(
  training_frame,
  x,
  destination_key,
  model_id = NULL,
  validation_frame = NULL,
  ignore_const_cols = TRUE,
  score_each_iteration = FALSE,
  transform = c("NONE", "STANDARDIZE", "NORMALIZE", "DEMEAN", "DESCALE"),
  svd_method = c("GramSVD", "Power", "Randomized"),
  nv = 1,
  max_iterations = 1000,
  seed = -1,
  keep_u = TRUE,
  u_name = NULL,
  use_all_factor_levels = TRUE,
  max_runtime_secs = 0,
  export_checkpoints_dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.svd_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_x">x</code></td>
<td>
<p>A vector containing the <code>character</code> names of the predictors in the model.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_destination_key">destination_key</code></td>
<td>
<p>(Optional) The unique key assigned to the resulting model.
Automatically generated if none is provided.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_transform">transform</code></td>
<td>
<p>Transformation of training data Must be one of: &quot;NONE&quot;, &quot;STANDARDIZE&quot;, &quot;NORMALIZE&quot;, &quot;DEMEAN&quot;, &quot;DESCALE&quot;.
Defaults to NONE.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_svd_method">svd_method</code></td>
<td>
<p>Method for computing SVD (Caution: Randomized is currently experimental and unstable) Must be one of:
&quot;GramSVD&quot;, &quot;Power&quot;, &quot;Randomized&quot;. Defaults to GramSVD.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_nv">nv</code></td>
<td>
<p>Number of right singular vectors Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Maximum iterations Defaults to 1000.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_keep_u">keep_u</code></td>
<td>
<p><code>Logical</code>. Save left singular vectors? Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_u_name">u_name</code></td>
<td>
<p>Frame key to save left singular vectors</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_use_all_factor_levels">use_all_factor_levels</code></td>
<td>
<p><code>Logical</code>. Whether first factor level is included in each categorical expansion Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.svd_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <a href="#topic+H2ODimReductionModel-class">H2ODimReductionModel</a>.
</p>


<h3>References</h3>

<p>N. Halko, P.G. Martinsson, J.A. Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions[https://arxiv.org/abs/0909.4061]. SIAM Rev., Survey and Review section, Vol. 53, num. 2, pp. 217-288, June 2011.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
australia_path &lt;- system.file("extdata", "australia.csv", package = "h2o")
australia &lt;- h2o.uploadFile(path = australia_path)
h2o.svd(training_frame = australia, nv = 8)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.table'>Cross Tabulation and Table Creation in H2O</h2><span id='topic+h2o.table'></span><span id='topic+table.H2OFrame'></span>

<h3>Description</h3>

<p>Uses the cross-classifying factors to build a table of counts at each combination of factor levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.table(x, y = NULL, dense = TRUE)

table.H2OFrame(x, y = NULL, dense = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.table_+3A_x">x</code></td>
<td>
<p>An H2OFrame object with at most two columns.</p>
</td></tr>
<tr><td><code id="h2o.table_+3A_y">y</code></td>
<td>
<p>An H2OFrame similar to x, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="h2o.table_+3A_dense">dense</code></td>
<td>
<p>A logical for dense representation, which lists only non-zero counts, 1 combination per row. Set to 
FALSE to expand counts across all combinations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a tabulated H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
summary(prostate)

# Counts of the ages of all patients
head(h2o.table(prostate[, 3]))
h2o.table(prostate[, 3])

# Two-way table of ages (rows) and race (cols) of all patients
head(h2o.table(prostate[, c(3, 4)]))
h2o.table(prostate[, c(3, 4)])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tabulate'>Tabulation between Two Columns of an H2OFrame</h2><span id='topic+h2o.tabulate'></span>

<h3>Description</h3>

<p>Simple Co-Occurrence based tabulation of X vs Y, where X and Y are two Vecs in a given dataset.
Uses histogram of given resolution in X and Y.
Handles numerical/categorical data and missing values. Supports observation weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tabulate(data, x, y, weights_column = NULL, nbins_x = 50, nbins_y = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tabulate_+3A_data">data</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.tabulate_+3A_x">x</code></td>
<td>
<p>predictor column</p>
</td></tr>
<tr><td><code id="h2o.tabulate_+3A_y">y</code></td>
<td>
<p>response column</p>
</td></tr>
<tr><td><code id="h2o.tabulate_+3A_weights_column">weights_column</code></td>
<td>
<p>(optional) observation weights column</p>
</td></tr>
<tr><td><code id="h2o.tabulate_+3A_nbins_x">nbins_x</code></td>
<td>
<p>number of bins for predictor column</p>
</td></tr>
<tr><td><code id="h2o.tabulate_+3A_nbins_y">nbins_y</code></td>
<td>
<p>number of bins for response column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns two TwoDimTables of 3 columns each
count_table:    X     Y counts
response_table: X meanY counts
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- as.h2o(iris)
tab &lt;- h2o.tabulate(data = df, x = "Sepal.Length", y = "Petal.Width",
             weights_column = NULL, nbins_x = 10, nbins_y = 10)
plot(tab)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tan'>Compute the tangent of x</h2><span id='topic+h2o.tan'></span>

<h3>Description</h3>

<p>Compute the tangent of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tan(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tan_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Trig">Trig</a></code> for the base R implementation, <code>tan()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.tan(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tanh'>Compute the hyperbolic tangent of x</h2><span id='topic+h2o.tanh'></span>

<h3>Description</h3>

<p>Compute the hyperbolic tangent of x
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tanh(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tanh_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Hyperbolic">Hyperbolic</a></code> for the base R implementation, <code>tanh()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.tanh(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.target_encode_apply'>Apply Target Encoding Map to Frame</h2><span id='topic+h2o.target_encode_apply'></span>

<h3>Description</h3>

<p>Applies a target encoding map to an H2OFrame object.  Computing target encoding for high cardinality 
categorical columns can improve performance of supervised learning models. A Target Encoding tutorial 
is available here: <a href="https://github.com/h2oai/h2o-tutorials/blob/master/best-practices/categorical-predictors/target_encoding.md">https://github.com/h2oai/h2o-tutorials/blob/master/best-practices/categorical-predictors/target_encoding.md</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.target_encode_apply(
  data,
  x,
  y,
  target_encode_map,
  holdout_type,
  fold_column = NULL,
  blended_avg = TRUE,
  noise_level = NULL,
  seed = -1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.target_encode_apply_+3A_data">data</code></td>
<td>
<p>An H2OFrame object with which to apply the target encoding map.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_x">x</code></td>
<td>
<p>A list containing the names or indices of the variables to encode.  A target encoding column will be created for each element in the list.  Items in the list can be multiple columns.  For example, if 'x = list(c(&quot;A&quot;), c(&quot;B&quot;, &quot;C&quot;))', then the resulting frame will have a target encoding column for A and a target encoding column for B &amp; C (in this case, we group by two columns).</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. The response variable can be either numeric or binary.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_target_encode_map">target_encode_map</code></td>
<td>
<p>A list of H2OFrame objects that is the results of the <code><a href="#topic+h2o.target_encode_create">h2o.target_encode_create</a></code> function.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_holdout_type">holdout_type</code></td>
<td>
<p>The holdout type used. Must be one of: &quot;LeaveOneOut&quot;, &quot;KFold&quot;, &quot;None&quot;.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_fold_column">fold_column</code></td>
<td>
<p>(Optional) The name or column index of the fold column in the data. Defaults to NULL (no 'fold_column'). Only required if 'holdout_type' = &quot;KFold&quot;.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_blended_avg">blended_avg</code></td>
<td>
<p><code>Logical</code>. (Optional) Whether to perform blended average.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_noise_level">noise_level</code></td>
<td>
<p>(Optional) The amount of random noise added to the target encoding.  This helps prevent overfitting. Defaults to 0.01 * range of y.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_apply_+3A_seed">seed</code></td>
<td>
<p>(Optional) A random seed used to generate draws from the uniform distribution for random noise. Defaults to -1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object containing the target encoding per record.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.target_encode_create">h2o.target_encode_create</a></code> for creating the target encoding map
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Get Target Encoding Frame on bank-additional-full data with numeric `y`
data &lt;- h2o.importFile(
  path = "https://s3.amazonaws.com/h2o-public-test-data/smalldata/demos/bank-additional-full.csv")
splits &lt;- h2o.splitFrame(data, seed = 1234)
train &lt;- splits[[1]]
test &lt;- splits[[2]]
mapping &lt;- h2o.target_encode_create(data = train, x = list(c("job"), c("job", "marital")), 
                                    y = "age")

# Apply mapping to the training dataset
train_encode &lt;- h2o.target_encode_apply(data = train, x = list(c("job"), c("job", "marital")), 
                                        y = "age", mapping, holdout_type = "LeaveOneOut")
# Apply mapping to a test dataset
test_encode &lt;- h2o.target_encode_apply(data = test, x = list(c("job"), c("job", "marital")), 
                                       y = "age", target_encode_map = mapping,
                                       holdout_type = "None")


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.target_encode_create'>Create Target Encoding Map</h2><span id='topic+h2o.target_encode_create'></span>

<h3>Description</h3>

<p>Creates a target encoding map based on group-by columns ('x') and a numeric or binary target column ('y'). 
Computing target encoding for high cardinality categorical columns can improve performance of supervised 
learning models. A Target Encoding tutorial is available here: <a href="https://github.com/h2oai/h2o-tutorials/blob/master/best-practices/categorical-predictors/target_encoding.md">https://github.com/h2oai/h2o-tutorials/blob/master/best-practices/categorical-predictors/target_encoding.md</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.target_encode_create(data, x, y, fold_column = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.target_encode_create_+3A_data">data</code></td>
<td>
<p>An H2OFrame object with which to create the target encoding map.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_create_+3A_x">x</code></td>
<td>
<p>A list containing the names or indices of the variables to encode.  A target encoding map will be created for each element in the list.  Items in the list can be multiple columns.  For example, if 'x = list(c(&quot;A&quot;), c(&quot;B&quot;, &quot;C&quot;))', then there will be one mapping frame for A and one mapping frame for B &amp; C (in this case, we group by two columns).</p>
</td></tr>
<tr><td><code id="h2o.target_encode_create_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. The response variable can be either numeric or binary.</p>
</td></tr>
<tr><td><code id="h2o.target_encode_create_+3A_fold_column">fold_column</code></td>
<td>
<p>(Optional) The name or column index of the fold column in the data. Defaults to NULL (no 'fold_column').</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of H2OFrame objects containing the target encoding mapping for each column in 'x'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.target_encode_apply">h2o.target_encode_apply</a></code> for applying the target encoding mapping to a frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Get Target Encoding Map on bank-additional-full data with numeric response
data &lt;- h2o.importFile(
path = "https://s3.amazonaws.com/h2o-public-test-data/smalldata/demos/bank-additional-full.csv")
mapping_age &lt;- h2o.target_encode_create(data = data, x = list(c("job"), c("job", "marital")), 
                                        y = "age")
head(mapping_age)

# Get Target Encoding Map on bank-additional-full data with binary response
mapping_y &lt;- h2o.target_encode_create(data = data, x = list(c("job"), c("job", "marital")), 
                                      y = "y")
head(mapping_y)


## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.targetencoder'>Transformation of a categorical variable with a mean value of the target variable</h2><span id='topic+h2o.targetencoder'></span>

<h3>Description</h3>

<p>Transformation of a categorical variable with a mean value of the target variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.targetencoder(
  x,
  y,
  training_frame,
  model_id = NULL,
  fold_column = NULL,
  columns_to_encode = NULL,
  keep_original_categorical_columns = TRUE,
  blending = FALSE,
  inflection_point = 10,
  smoothing = 20,
  data_leakage_handling = c("leave_one_out", "k_fold", "none", "LeaveOneOut", "KFold",
    "None"),
  noise = 0.01,
  seed = -1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.targetencoder_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_columns_to_encode">columns_to_encode</code></td>
<td>
<p>List of categorical columns or groups of categorical columns to encode. When groups of columns are specified,
each group is encoded as a single column (interactions are created internally).</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_keep_original_categorical_columns">keep_original_categorical_columns</code></td>
<td>
<p><code>Logical</code>. If true, the original non-encoded categorical features will remain in the result frame.
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_blending">blending</code></td>
<td>
<p><code>Logical</code>. If true, enables blending of posterior probabilities (computed for a given categorical value)
with prior probabilities (computed on the entire set). This allows to mitigate the effect of categorical
values with small cardinality. The blending effect can be tuned using the 'inflection_point' and 'smoothing'
parameters. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_inflection_point">inflection_point</code></td>
<td>
<p>Inflection point of the sigmoid used to blend probabilities (see 'blending' parameter). For a given
categorical value, if it appears less that 'inflection_point' in a data sample, then the influence of the
posterior probability will be smaller than the prior. Defaults to 10.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_smoothing">smoothing</code></td>
<td>
<p>Smoothing factor corresponds to the inverse of the slope at the inflection point on the sigmoid used to blend
probabilities (see 'blending' parameter). If smoothing tends towards 0, then the sigmoid used for blending
turns into a Heaviside step function. Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_data_leakage_handling">data_leakage_handling</code></td>
<td>
<p>Data leakage handling strategy used to generate the encoding. Supported options are:
1) &quot;none&quot; (default) - no holdout, using the entire training frame.
2) &quot;leave_one_out&quot; - current row's response value is subtracted from the per-level frequencies pre-calculated
on the entire training frame.
3) &quot;k_fold&quot; - encodings for a fold are generated based on out-of-fold data.
Must be one of: &quot;leave_one_out&quot;, &quot;k_fold&quot;, &quot;none&quot;, &quot;LeaveOneOut&quot;, &quot;KFold&quot;, &quot;None&quot;. Defaults to None.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_noise">noise</code></td>
<td>
<p>The amount of noise to add to the encoded column. Use 0 to disable noise, and -1 (=AUTO) to let the algorithm
determine a reasonable amount of noise. Defaults to 0.01.</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.targetencoder_+3A_...">...</code></td>
<td>
<p>Mainly used for backwards compatibility, to allow deprecated parameters.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
#Import the titanic dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv"
titanic &lt;- h2o.importFile(f)

# Set response as a factor
response &lt;- "survived"
titanic[response] &lt;- as.factor(titanic[response])

# Split the dataset into train and test
splits &lt;- h2o.splitFrame(data = titanic, ratios = .8, seed = 1234)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Choose which columns to encode
encode_columns &lt;- c("home.dest", "cabin", "embarked")

# Train a TE model
te_model &lt;- h2o.targetencoder(x = encode_columns,
                              y = response, 
                              training_frame = train,
                              fold_column = "pclass", 
                              data_leakage_handling = "KFold")

# New target encoded train and test sets
train_te &lt;- h2o.transform(te_model, train)
test_te &lt;- h2o.transform(te_model, test)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tf_idf'>Computes TF-IDF values for each word in given documents.</h2><span id='topic+h2o.tf_idf'></span>

<h3>Description</h3>

<p>Computes TF-IDF values for each word in given documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tf_idf(
  frame,
  document_id_col,
  text_col,
  preprocess = TRUE,
  case_sensitive = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tf_idf_+3A_frame">frame</code></td>
<td>
<p>documents or words frame for which TF-IDF values should be computed.</p>
</td></tr>
<tr><td><code id="h2o.tf_idf_+3A_document_id_col">document_id_col</code></td>
<td>
<p>index or name of a column containing document IDs.</p>
</td></tr>
<tr><td><code id="h2o.tf_idf_+3A_text_col">text_col</code></td>
<td>
<p>index or name of a column containing documents if 'preprocess = TRUE'
or words if 'preprocess = FALSE'.</p>
</td></tr>
<tr><td><code id="h2o.tf_idf_+3A_preprocess">preprocess</code></td>
<td>
<p>whether input text data should be pre-processed. Defaults to 'TRUE'.</p>
</td></tr>
<tr><td><code id="h2o.tf_idf_+3A_case_sensitive">case_sensitive</code></td>
<td>
<p>whether input data should be treated as case sensitive. Defaults to 'TRUE'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>resulting frame with TF-IDF values.
Row format: documentID, word, TF, IDF, TF-IDF
</p>

<hr>
<h2 id='h2o.thresholds_and_metric_scores'>Retrieve the thresholds and metric scores table</h2><span id='topic+h2o.thresholds_and_metric_scores'></span>

<h3>Description</h3>

<p>Retrieves the thresholds and metric scores table from a <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> 
or a <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.thresholds_and_metric_scores(
  object,
  train = FALSE,
  valid = FALSE,
  xval = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.thresholds_and_metric_scores_+3A_object">object</code></td>
<td>
<p>A <a href="#topic+H2OBinomialUpliftMetrics-class">H2OBinomialUpliftMetrics</a> or a <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.thresholds_and_metric_scores_+3A_train">train</code></td>
<td>
<p>Retrieve the training thresholds and metric scores table</p>
</td></tr>
<tr><td><code id="h2o.thresholds_and_metric_scores_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation thresholds and metric scores table</p>
</td></tr>
<tr><td><code id="h2o.thresholds_and_metric_scores_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation thresholds and metric scores table (only for <a href="#topic+H2OBinomialMetrics-class">H2OBinomialMetrics</a>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The table contains indices, thresholds, all cumulative uplift values and cumulative number of observations for 
uplift binomial models or thresholds and maximal metric values for binomial models. 
If &quot;train&quot; and &quot;valid&quot; parameters are FALSE (default), then the training table is returned. If more
than one parameter is set to TRUE, then a named vector of tables is returned, where the names are &quot;train&quot;, &quot;valid&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/uplift/criteo_uplift_13k.csv"
train &lt;- h2o.importFile(f)
train$treatment &lt;- as.factor(train$treatment)
train$conversion &lt;- as.factor(train$conversion)

model &lt;- h2o.upliftRandomForest(training_frame=train, x=sprintf("f%s",seq(0:10)), y="conversion",
                                ntrees=10, max_depth=5, treatment_column="treatment", 
                                auuc_type="AUTO")
perf &lt;- h2o.performance(model, train=TRUE) 
h2o.thresholds_and_metric_scores(perf)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.toFrame'>Convert a word2vec model into an H2OFrame</h2><span id='topic+h2o.toFrame'></span>

<h3>Description</h3>

<p>Converts a given word2vec model into an H2OFrame. The frame represents learned word embeddings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.toFrame(word2vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.toFrame_+3A_word2vec">word2vec</code></td>
<td>
<p>A word2vec model.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Build a dummy word2vec model
data &lt;- as.character(as.h2o(c("a", "b", "a")))
w2v_model &lt;- h2o.word2vec(data, sent_sample_rate = 0, min_word_freq = 0, epochs = 1, vec_size = 2)

# Transform words to vectors and return average vector for each sentence
h2o.toFrame(w2v_model) # -&gt; Frame made of 2 rows and 2 columns

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tokenize'>Tokenize String</h2><span id='topic+h2o.tokenize'></span>

<h3>Description</h3>

<p>h2o.tokenize is similar to h2o.strsplit, the difference between them is that h2o.tokenize will store the tokenized
text into a single column making it easier for additional processing (filtering stop words, word2vec algo, ...).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tokenize(x, split)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tokenize_+3A_x">x</code></td>
<td>
<p>The column or columns whose strings to tokenize.</p>
</td></tr>
<tr><td><code id="h2o.tokenize_+3A_split">split</code></td>
<td>
<p>The regular expression to split on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with a single column representing the tokenized Strings. Original rows of the input DF are separated by NA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_tokenize &lt;- as.h2o("Split at every character and tokenize.")
tokenize_string &lt;- h2o.tokenize(as.character(string_to_tokenize), "")

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tolower'>Convert strings to lowercase</h2><span id='topic+h2o.tolower'></span>

<h3>Description</h3>

<p>Convert strings to lowercase
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tolower(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tolower_+3A_x">x</code></td>
<td>
<p>An H2OFrame object whose strings should be lower cased</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with all entries in lowercase format
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_lower &lt;- as.h2o("ABCDE")
lowered_string &lt;- h2o.tolower(string_to_lower)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.topBottomN'>H2O topBottomN</h2><span id='topic+h2o.topBottomN'></span>

<h3>Description</h3>

<p>topBottomN function will will grab the top N percent or botom N percent of values of a column and return it in a
H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.topBottomN(x, column, nPercent, grabTopN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.topBottomN_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.topBottomN_+3A_column">column</code></td>
<td>
<p>is a column name or column index to grab the top N percent value from</p>
</td></tr>
<tr><td><code id="h2o.topBottomN_+3A_npercent">nPercent</code></td>
<td>
<p>a top percentage values to grab</p>
</td></tr>
<tr><td><code id="h2o.topBottomN_+3A_grabtopn">grabTopN</code></td>
<td>
<p>if -1 grab bottom percentage, 1 grab top percentage</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with 2 columns: first column is the original row indices, second column contains the values
</p>

<hr>
<h2 id='h2o.topN'>H2O topN</h2><span id='topic+h2o.topN'></span>

<h3>Description</h3>

<p>Extract the top N percent  of values of a column and return it in a H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.topN(x, column, nPercent)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.topN_+3A_x">x</code></td>
<td>
<p>an H2OFrame</p>
</td></tr>
<tr><td><code id="h2o.topN_+3A_column">column</code></td>
<td>
<p>is a column name or column index to grab the top N percent value from</p>
</td></tr>
<tr><td><code id="h2o.topN_+3A_npercent">nPercent</code></td>
<td>
<p>is a top percentage value to grab</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with 2 columns.  The first column is the original row indices, second column contains the topN values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/bigdata/laptop/jira/TopBottomNRep4.csv.zip"
dataset &lt;- h2o.importFile(f)
frameNames &lt;- names(dataset)
nPercent &lt;- c(1, 2, 3, 4)
nP &lt;- nPercent[sample(1:length(nPercent), 1, replace = FALSE)]
colIndex &lt;- sample(1:length(frameNames), 1, replace = FALSE)
h2o.topN(dataset, frameNames[colIndex], nP)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.tot_withinss'>Get the total within cluster sum of squares.</h2><span id='topic+h2o.tot_withinss'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training tot_withinss value is returned. If more
than one parameter is set to TRUE, then a named vector of tot_withinss' are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.tot_withinss(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.tot_withinss_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.tot_withinss_+3A_train">train</code></td>
<td>
<p>Retrieve the training total within cluster sum of squares</p>
</td></tr>
<tr><td><code id="h2o.tot_withinss_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation total within cluster sum of squares</p>
</td></tr>
<tr><td><code id="h2o.tot_withinss_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation total within cluster sum of squares</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.tot_withinss(km, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.totss'>Get the total sum of squares.</h2><span id='topic+h2o.totss'></span>

<h3>Description</h3>

<p>If &quot;train&quot;, &quot;valid&quot;, and &quot;xval&quot; parameters are FALSE (default), then the training totss value is returned. If more
than one parameter is set to TRUE, then a named vector of totss' are returned, where the names are &quot;train&quot;, &quot;valid&quot;
or &quot;xval&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.totss(object, train = FALSE, valid = FALSE, xval = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.totss_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
<tr><td><code id="h2o.totss_+3A_train">train</code></td>
<td>
<p>Retrieve the training total sum of squares</p>
</td></tr>
<tr><td><code id="h2o.totss_+3A_valid">valid</code></td>
<td>
<p>Retrieve the validation total sum of squares</p>
</td></tr>
<tr><td><code id="h2o.totss_+3A_xval">xval</code></td>
<td>
<p>Retrieve the cross-validation total sum of squares</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

fr &lt;- h2o.importFile("https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv")
predictors &lt;- c("sepal_len", "sepal_wid", "petal_len", "petal_wid")
km &lt;- h2o.kmeans(x = predictors, training_frame = fr, k = 3, nfolds = 3)
h2o.totss(km, train = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.toupper'>Convert strings to uppercase</h2><span id='topic+h2o.toupper'></span>

<h3>Description</h3>

<p>Convert strings to uppercase
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.toupper(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.toupper_+3A_x">x</code></td>
<td>
<p>An H2OFrame object whose strings should be upper cased</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame with all entries in uppercase format
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_upper &lt;- as.h2o("abcde")
upper_string &lt;- h2o.toupper(string_to_upper)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.train_segments'>H2O Segmented-Data Bulk Model Training</h2><span id='topic+h2o.train_segments'></span>

<h3>Description</h3>

<p>Provides a set of functions to train a group of models on different
segments (subpopulations) of the training set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.train_segments(
  algorithm,
  segment_columns,
  segment_models_id,
  parallelism = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.train_segments_+3A_algorithm">algorithm</code></td>
<td>
<p>Name of algorithm to use in training segment models (gbm, randomForest, kmeans, glm, deeplearning, naivebayes, psvm,
xgboost, pca, svd, targetencoder, aggregator, word2vec, coxph, isolationforest, kmeans, stackedensemble, glrm, gam, anovaglm, modelselection).</p>
</td></tr>
<tr><td><code id="h2o.train_segments_+3A_segment_columns">segment_columns</code></td>
<td>
<p>A list of columns to segment-by. H2O will group the training (and validation) dataset by the segment-by columns
and train a separate model for each segment (group of rows).</p>
</td></tr>
<tr><td><code id="h2o.train_segments_+3A_segment_models_id">segment_models_id</code></td>
<td>
<p>Identifier for the returned collection of Segment Models. If not specified it will be automatically generated.</p>
</td></tr>
<tr><td><code id="h2o.train_segments_+3A_parallelism">parallelism</code></td>
<td>
<p>Level of parallelism of bulk model building, it is the maximum number of models each H2O node will be building in parallel, defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.train_segments_+3A_...">...</code></td>
<td>
<p>Use to pass along training_frame parameter, x, y, and all non-default parameter values to the algorithm 
Look at the specific algorithm - h2o.gbm, h2o.glm, h2o.kmeans, h2o.deepLearning - for available parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Start Segmented-Data bulk Model Training for a given algorithm and parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
models &lt;- h2o.train_segments(algorithm = "gbm", 
                             segment_columns = "Species",
                             x = c(1:3), y = 4, 
                             training_frame = iris_hf,
                             ntrees = 5, 
                             max_depth = 4)
as.data.frame(models)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.transform'>Use H2O Transformation model and apply the underlying transformation</h2><span id='topic+h2o.transform'></span>

<h3>Description</h3>

<p>Use H2O Transformation model and apply the underlying transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.transform(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.transform_+3A_model">model</code></td>
<td>
<p>A trained model representing the transformation strategy</p>
</td></tr>
<tr><td><code id="h2o.transform_+3A_...">...</code></td>
<td>
<p>Transformation model-specific parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with data transformed.
</p>

<hr>
<h2 id='h2o.transform_frame'>Use GRLM to transform a frame.</h2><span id='topic+h2o.transform_frame'></span>

<h3>Description</h3>

<p>Use GRLM to transform a frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.transform_frame(model, fr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.transform_frame_+3A_model">model</code></td>
<td>
<p>H2O GRLM model</p>
</td></tr>
<tr><td><code id="h2o.transform_frame_+3A_fr">fr</code></td>
<td>
<p>H2OFrame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a transformed frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the USArrests dataset into H2O:
arrests &lt;- h2o.importFile(
  "https://s3.amazonaws.com/h2o-public-test-data/smalldata/pca_test/USArrests.csv"
)

# Split the dataset into a train and valid set:
arrests_splits &lt;- h2o.splitFrame(data = arrests, ratios = 0.8, seed = 1234)
train &lt;- arrests_splits[[1]]
valid &lt;- arrests_splits[[2]]

# Build and train the model:
glrm_model = h2o.glrm(training_frame = train,
                      k = 4,
                      loss = "Quadratic",
                      gamma_x = 0.5,
                      gamma_y = 0.5,
                      max_iterations = 700,
                      recover_svd = TRUE,
                      init = "SVD",
                      transform = "STANDARDIZE")

# Eval performance:
arrests_perf &lt;- h2o.performance(glrm_model)

# Generate predictions on a validation set (if necessary):
arrests_pred &lt;- h2o.predict(glrm_model, newdata = valid)

# Transform the data using the dataset "valid" to retrieve the new coefficients:
glrm_transform &lt;- h2o.transform_frame(glrm_model, valid)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.transform_word2vec'>Transform words (or sequences of words) to vectors using a word2vec model.</h2><span id='topic+h2o.transform_word2vec'></span>

<h3>Description</h3>

<p>Transform words (or sequences of words) to vectors using a word2vec model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.transform_word2vec(
  word2vec,
  words,
  aggregate_method = c("NONE", "AVERAGE")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.transform_word2vec_+3A_word2vec">word2vec</code></td>
<td>
<p>A word2vec model.</p>
</td></tr>
<tr><td><code id="h2o.transform_word2vec_+3A_words">words</code></td>
<td>
<p>An H2OFrame made of a single column containing source words.</p>
</td></tr>
<tr><td><code id="h2o.transform_word2vec_+3A_aggregate_method">aggregate_method</code></td>
<td>
<p>Specifies how to aggregate sequences of words. If method is 'NONE'
then no aggregation is performed and each input word is mapped to a single word-vector.
If method is 'AVERAGE' then input is treated as sequences of words delimited by NA.
Each word of a sequences is internally mapped to a vector and vectors belonging to
the same sentence are averaged and returned in the result.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Build a dummy word2vec model
data &lt;- as.character(as.h2o(c("a", "b", "a")))
w2v_model &lt;- h2o.word2vec(data, sent_sample_rate = 0, min_word_freq = 0, epochs = 1, vec_size = 2)

# Transform words to vectors without aggregation
sentences &lt;- as.character(as.h2o(c("b", "c", "a", NA, "b")))
h2o.transform(w2v_model, sentences) # -&gt; 5 rows total, 2 rows NA ("c" is not in the vocabulary)

# Transform words to vectors and return average vector for each sentence
h2o.transform(w2v_model, sentences, aggregate_method = "AVERAGE") # -&gt; 2 rows

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.transform+2CH2OTargetEncoderModel-method'>Applies target encoding to a given dataset</h2><span id='topic+h2o.transform+2CH2OTargetEncoderModel-method'></span>

<h3>Description</h3>

<p>Applies target encoding to a given dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OTargetEncoderModel'
h2o.transform(
  model,
  data,
  blending = NULL,
  inflection_point = -1,
  smoothing = -1,
  noise = NULL,
  as_training = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_model">model</code></td>
<td>
<p>A trained model representing the transformation strategy</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_data">data</code></td>
<td>
<p>An H2OFrame with data to be transformed</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_blending">blending</code></td>
<td>
<p>Use blending during the transformation. Respects model settings when not set.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_inflection_point">inflection_point</code></td>
<td>
<p>Blending parameter. Only effective when blending is enabled.
By default, model settings are respected, if not overridden by this setting.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_smoothing">smoothing</code></td>
<td>
<p>Blending parameter. Only effective when blending is enabled.
By default, model settings are respected, if not overridden by this setting.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_noise">noise</code></td>
<td>
<p>An amount of random noise added to the encoding, this helps prevent overfitting.
By default, model settings are respected, if not overridden by this setting.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_as_training">as_training</code></td>
<td>
<p>Must be set to True when encoding the training frame. Defaults to False.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OTargetEncoderModel-method_+3A_...">...</code></td>
<td>
<p>Mainly used for backwards compatibility, to allow deprecated parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with data transformed.
</p>

<hr>
<h2 id='h2o.transform+2CH2OWordEmbeddingModel-method'>Transform words (or sequences of words) to vectors using a word2vec model.</h2><span id='topic+h2o.transform+2CH2OWordEmbeddingModel-method'></span>

<h3>Description</h3>

<p>Transform words (or sequences of words) to vectors using a word2vec model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OWordEmbeddingModel'
h2o.transform(model, words, aggregate_method = c("NONE", "AVERAGE"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.transform+2B2CH2OWordEmbeddingModel-method_+3A_model">model</code></td>
<td>
<p>A word2vec model.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OWordEmbeddingModel-method_+3A_words">words</code></td>
<td>
<p>An H2OFrame made of a single column containing source words.</p>
</td></tr>
<tr><td><code id="h2o.transform+2B2CH2OWordEmbeddingModel-method_+3A_aggregate_method">aggregate_method</code></td>
<td>
<p>Specifies how to aggregate sequences of words. If method is 'NONE'
then no aggregation is performed and each input word is mapped to a single word-vector.
If method is 'AVERAGE' then input is treated as sequences of words delimited by NA.
Each word of a sequences is internally mapped to a vector and vectors belonging to
the same sentence are averaged and returned in the result.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Build a simple word2vec model
data &lt;- as.character(as.h2o(c("a", "b", "a")))
w2v_model &lt;- h2o.word2vec(data, sent_sample_rate = 0, min_word_freq = 0, epochs = 1, vec_size = 2)

# Transform words to vectors without aggregation
sentences &lt;- as.character(as.h2o(c("b", "c", "a", NA, "b")))
h2o.transform(w2v_model, sentences) # -&gt; 5 rows total, 2 rows NA ("c" is not in the vocabulary)

# Transform words to vectors and return average vector for each sentence
h2o.transform(w2v_model, sentences, aggregate_method = "AVERAGE") # -&gt; 2 rows

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.trim'>Trim Space</h2><span id='topic+h2o.trim'></span>

<h3>Description</h3>

<p>Trim Space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.trim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.trim_+3A_x">x</code></td>
<td>
<p>The column whose strings should be trimmed.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
string_to_trim &lt;- as.h2o("r tutorial")
trim_string &lt;- h2o.trim(string_to_trim)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.trunc'>Truncate values in x toward 0</h2><span id='topic+h2o.trunc'></span>

<h3>Description</h3>

<p>trunc takes a single numeric argument x and returns a numeric vector containing the integers
formed by truncating the values in x toward 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.trunc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.trunc_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Round">Round</a></code> for the base R implementation, <code>trunc()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
h2o.trunc(frame["C1"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.unique'>H2O Unique</h2><span id='topic+h2o.unique'></span>

<h3>Description</h3>

<p>Extract unique values in the column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.unique(x, include_nas = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.unique_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.unique_+3A_include_nas">include_nas</code></td>
<td>
<p>If set to TRUE, NAs are included. FALSE (turned off) by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv"
iris &lt;- h2o.importFile(f)
h2o.unique(iris["class"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.upliftRandomForest'>Build a Uplift Random Forest model</h2><span id='topic+h2o.upliftRandomForest'></span>

<h3>Description</h3>

<p>Builds a Uplift Random Forest model on an H2OFrame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.upliftRandomForest(
  x,
  y,
  training_frame,
  treatment_column,
  model_id = NULL,
  validation_frame = NULL,
  score_each_iteration = FALSE,
  score_tree_interval = 0,
  ignore_const_cols = TRUE,
  ntrees = 50,
  max_depth = 20,
  min_rows = 1,
  nbins = 20,
  nbins_top_level = 1024,
  nbins_cats = 1024,
  max_runtime_secs = 0,
  seed = -1,
  mtries = -2,
  sample_rate = 0.632,
  sample_rate_per_class = NULL,
  col_sample_rate_change_per_level = 1,
  col_sample_rate_per_tree = 1,
  histogram_type = c("AUTO", "UniformAdaptive", "Random", "QuantilesGlobal",
    "RoundRobin", "UniformRobust"),
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  check_constant_response = TRUE,
  custom_metric_func = NULL,
  uplift_metric = c("AUTO", "KL", "Euclidean", "ChiSquared"),
  auuc_type = c("AUTO", "qini", "lift", "gain"),
  auuc_nbins = -1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.upliftRandomForest_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_treatment_column">treatment_column</code></td>
<td>
<p>Define the column which will be used for computing uplift gain to select best split for a tree. The column has
to divide the dataset into treatment (value 1) and control (value 0) groups. Defaults to treatment.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_ntrees">ntrees</code></td>
<td>
<p>Number of trees. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum tree depth (0 for unlimited). Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_min_rows">min_rows</code></td>
<td>
<p>Fewest allowed (weighted) observations in a leaf. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_nbins">nbins</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point
Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_nbins_top_level">nbins_top_level</code></td>
<td>
<p>For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then
decrease by factor of two per level Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_nbins_cats">nbins_cats</code></td>
<td>
<p>For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher
values can lead to more overfitting. Defaults to 1024.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_mtries">mtries</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for
classification and p/3 for regression (where p is the # of predictors Defaults to -2.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_sample_rate">sample_rate</code></td>
<td>
<p>Row sample rate per tree (from 0.0 to 1.0) Defaults to 0.632.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_sample_rate_per_class">sample_rate_per_class</code></td>
<td>
<p>A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_col_sample_rate_change_per_level">col_sample_rate_change_per_level</code></td>
<td>
<p>Relative change of the column sampling rate for every level (must be &gt; 0.0 and &lt;= 2.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_col_sample_rate_per_tree">col_sample_rate_per_tree</code></td>
<td>
<p>Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_histogram_type">histogram_type</code></td>
<td>
<p>What type of histogram to use for finding optimal split points Must be one of: &quot;AUTO&quot;, &quot;UniformAdaptive&quot;,
&quot;Random&quot;, &quot;QuantilesGlobal&quot;, &quot;RoundRobin&quot;, &quot;UniformRobust&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_check_constant_response">check_constant_response</code></td>
<td>
<p><code>Logical</code>. Check if response column is constant. If enabled, then an exception is thrown if the response
column is a constant value.If disabled, then model will train regardless of the response column being a
constant value or not. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_custom_metric_func">custom_metric_func</code></td>
<td>
<p>Reference to custom evaluation function, format: 'language:keyName=funcName'</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_uplift_metric">uplift_metric</code></td>
<td>
<p>Divergence metric used to find best split when building an uplift tree. Must be one of: &quot;AUTO&quot;, &quot;KL&quot;,
&quot;Euclidean&quot;, &quot;ChiSquared&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_auuc_type">auuc_type</code></td>
<td>
<p>Metric used to calculate Area Under Uplift Curve. Must be one of: &quot;AUTO&quot;, &quot;qini&quot;, &quot;lift&quot;, &quot;gain&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_auuc_nbins">auuc_nbins</code></td>
<td>
<p>Number of bins to calculate Area Under Uplift Curve. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.upliftRandomForest_+3A_verbose">verbose</code></td>
<td>
<p><code>Logical</code>. Print scoring history to the console (Metrics per tree). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a <a href="#topic+H2OModel-class">H2OModel</a> object of the right type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.H2OModel">predict.H2OModel</a></code> for prediction
</p>

<hr>
<h2 id='h2o.upload_model'>Upload a binary model from the provided local path to the H2O cluster.
(H2O model can be saved in a binary form either by saveModel() or by download_model() function.)</h2><span id='topic+h2o.upload_model'></span>

<h3>Description</h3>

<p>Upload a binary model from the provided local path to the H2O cluster.
(H2O model can be saved in a binary form either by saveModel() or by download_model() function.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.upload_model(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.upload_model_+3A_path">path</code></td>
<td>
<p>A path on the machine this python session is currently connected to, specifying the location of the model to upload.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a new <a href="#topic+H2OModel-class">H2OModel</a> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.saveModel">h2o.saveModel</a></code>, <code><a href="#topic+h2o.download_model">h2o.download_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# library(h2o)
# h2o.init()
# prostate_path = system.file("extdata", "prostate.csv", package = "h2o")
# prostate = h2o.importFile(path = prostate_path)
# prostate_glm = h2o.glm(y = "CAPSULE", x = c("AGE","RACE","PSA","DCAPS"),
#   training_frame = prostate, family = "binomial", alpha = 0.5)
# glmmodel_path = h2o.download_model(prostate_glm, dir = "/Users/UserName/Desktop")
# glmmodel_load = h2o.upload_model(glmmodel_path)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.upload_mojo'>Imports a MOJO from a local filesystem, creating a Generic model with it.</h2><span id='topic+h2o.upload_mojo'></span>

<h3>Description</h3>

<p>Usage example:
mojo_model &lt;- h2o.upload_mojo(model_file_path = &quot;/path/to/local/mojo.zip&quot;)
predictions &lt;- h2o.predict(mojo_model, dataset)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.upload_mojo(mojo_local_file_path, model_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.upload_mojo_+3A_mojo_local_file_path">mojo_local_file_path</code></td>
<td>
<p>Filesystem path to the model imported</p>
</td></tr>
<tr><td><code id="h2o.upload_mojo_+3A_model_id">model_id</code></td>
<td>
<p>Model ID, default is NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns H2O Generic Model embedding given MOJO model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Import default Iris dataset as H2O frame
data &lt;- as.h2o(iris)

# Train a very simple GBM model
features &lt;- c("Sepal.Length", "Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")
original_model &lt;- h2o.gbm(x = features, y = "Species", training_frame = data)

# Download the trained GBM model as MOJO (temporary directory used in this example)
mojo_original_name &lt;- h2o.download_mojo(model = original_model, path = tempdir())
mojo_original_path &lt;- paste0(tempdir(), "/", mojo_original_name)

# Upload the MOJO from local filesystem and obtain a Generic model
mojo_model &lt;- h2o.upload_mojo(mojo_original_path)

# Perform scoring with the generic model
predictions  &lt;- h2o.predict(mojo_model, data)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.var'>Variance of a column or covariance of columns.</h2><span id='topic+h2o.var'></span><span id='topic+var'></span>

<h3>Description</h3>

<p>Compute the variance or covariance matrix of one or two H2OFrames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.var(x, y = NULL, na.rm = FALSE, use)

var(x, y = NULL, na.rm = FALSE, use)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.var_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.var_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or an H2OFrame. The default is equivalent to y = x.</p>
</td></tr>
<tr><td><code id="h2o.var_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="h2o.var_+3A_use">use</code></td>
<td>
<p>An optional character string indicating how to handle missing values. This must be one of the following: 
&quot;everything&quot;            - outputs NaNs whenever one of its contributing observations is missing
&quot;all.obs&quot;               - presence of missing observations will throw an error
&quot;complete.obs&quot;          - discards missing values along with all observations in their rows so that only complete observations are used</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code> for the base R implementation, <code>var()</code>. <code><a href="#topic+h2o.sd">h2o.sd</a></code> for standard deviation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
var(prostate$AGE)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp'>Retrieve the variable importance.</h2><span id='topic+h2o.varimp'></span>

<h3>Description</h3>

<p>Retrieve the variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.varimp(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp_+3A_object">object</code></td>
<td>
<p>An H2O object.</p>
</td></tr>
<tr><td><code id="h2o.varimp_+3A_...">...</code></td>
<td>
<p>Additional arguments for specific use-cases.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate_complete.csv.zip"
pros &lt;- h2o.importFile(f)
response &lt;- "GLEASON"
predictors &lt;- c("ID", "AGE", "CAPSULE", "DCAPS", "PSA", "VOL", "DPROS")
aml &lt;- h2o.automl(x = predictors, y = response, training_frame = pros, max_runtime_secs = 60)

h2o.varimp(aml, top_n = 20)  # get variable importance matrix for the top 20 models

h2o.varimp(aml@leader)  # get variable importance for the leader model

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp_heatmap'>Variable Importance Heatmap across multiple models</h2><span id='topic+h2o.varimp_heatmap'></span>

<h3>Description</h3>

<p>Variable importance heatmap shows variable importance across multiple models.
Some models in H2O return variable importance for one-hot (binary indicator)
encoded versions of categorical columns (e.g. Deep Learning, XGBoost).  In order
for the variable importance of categorical columns to be compared across all model
types we compute a summarization of the the variable importance across all one-hot
encoded features and return a single variable importance for the original categorical
feature. By default, the models and variables are ordered by their similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.varimp_heatmap(object, top_n = 20, num_of_features = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp_heatmap_+3A_object">object</code></td>
<td>
<p>A list of H2O models, an H2O AutoML instance, or an H2OFrame with a 'model_id' column (e.g. H2OAutoML leaderboard).</p>
</td></tr>
<tr><td><code id="h2o.varimp_heatmap_+3A_top_n">top_n</code></td>
<td>
<p>Integer specifying the number models shown in the heatmap
(based on leaderboard ranking). Defaults to 20.</p>
</td></tr>
<tr><td><code id="h2o.varimp_heatmap_+3A_num_of_features">num_of_features</code></td>
<td>
<p>Integer specifying the number of features shown in the heatmap
based on the maximum variable importance across the models.
Use NULL for unlimited. Defaults to 20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the wine dataset into H2O:
f &lt;- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/wine/winequality-redwhite-no-BOM.csv"
df &lt;-  h2o.importFile(f)

# Set the response
response &lt;- "quality"

# Split the dataset into a train and test set:
splits &lt;- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train &lt;- splits[[1]]
test &lt;- splits[[2]]

# Build and train the model:
aml &lt;- h2o.automl(y = response,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# Create the variable importance heatmap
varimp_heatmap &lt;- h2o.varimp_heatmap(aml)
print(varimp_heatmap)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp_plot'>Plot Variable Importances</h2><span id='topic+h2o.varimp_plot'></span>

<h3>Description</h3>

<p>Plot Variable Importances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.varimp_plot(model, num_of_features = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp_plot_+3A_model">model</code></td>
<td>
<p>A trained model (accepts a trained random forest, GBM,
or deep learning model, will use <code><a href="#topic+h2o.std_coef_plot">h2o.std_coef_plot</a></code>
for a trained GLM</p>
</td></tr>
<tr><td><code id="h2o.varimp_plot_+3A_num_of_features">num_of_features</code></td>
<td>
<p>The number of features shown in the plot (default is 10 or all if less than 10).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.std_coef_plot">h2o.std_coef_plot</a></code> for GLM.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(prostate_path)
prostate[, 2] &lt;- as.factor(prostate[, 2])
model &lt;- h2o.gbm(x = 3:9, y = 2, training_frame = prostate, distribution = "bernoulli")
h2o.varimp_plot(model)

# for deep learning set the variable_importance parameter to TRUE
iris_hf &lt;- as.h2o(iris)
iris_dl &lt;- h2o.deeplearning(x = 1:4, y = 5, training_frame = iris_hf,
variable_importances = TRUE)
h2o.varimp_plot(iris_dl)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp+2CH2OAutoML-method'>Retrieve the variable importance.</h2><span id='topic+h2o.varimp+2CH2OAutoML-method'></span>

<h3>Description</h3>

<p>Retrieve the variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OAutoML'
h2o.varimp(object, top_n = 20, num_of_features = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp+2B2CH2OAutoML-method_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OAutoML-class">H2OAutoML</a> object.</p>
</td></tr>
<tr><td><code id="h2o.varimp+2B2CH2OAutoML-method_+3A_top_n">top_n</code></td>
<td>
<p>Show at most top_n models</p>
</td></tr>
<tr><td><code id="h2o.varimp+2B2CH2OAutoML-method_+3A_num_of_features">num_of_features</code></td>
<td>
<p>Integer specifying the number of features returned based on the maximum
importance across the models. Use NULL for unlimited. Defaults to NULL.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate_complete.csv.zip"
pros &lt;- h2o.importFile(f)
response &lt;- "GLEASON"
predictors &lt;- c("ID", "AGE", "CAPSULE", "DCAPS", "PSA", "VOL", "DPROS")
aml &lt;- h2o.automl(x = predictors, y = response, training_frame = pros, max_runtime_secs = 60)
h2o.varimp(aml)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp+2CH2OFrame-method'>Retrieve the variable importance.</h2><span id='topic+h2o.varimp+2CH2OFrame-method'></span>

<h3>Description</h3>

<p>Retrieve the variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OFrame'
h2o.varimp(object, num_of_features = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp+2B2CH2OFrame-method_+3A_object">object</code></td>
<td>
<p>A leaderboard frame.</p>
</td></tr>
<tr><td><code id="h2o.varimp+2B2CH2OFrame-method_+3A_num_of_features">num_of_features</code></td>
<td>
<p>Integer specifying the number of features returned based on the maximum
importance across the models. Use NULL for unlimited. Defaults to NULL.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate_complete.csv.zip"
pros &lt;- h2o.importFile(f)
response &lt;- "GLEASON"
predictors &lt;- c("ID", "AGE", "CAPSULE", "DCAPS", "PSA", "VOL", "DPROS")
aml &lt;- h2o.automl(x = predictors, y = response, training_frame = pros, max_runtime_secs = 60)
h2o.varimp(aml@leaderboard[1:5,])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varimp+2CH2OModel-method'>Retrieve the variable importance.</h2><span id='topic+h2o.varimp+2CH2OModel-method'></span>

<h3>Description</h3>

<p>Retrieve the variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModel'
h2o.varimp(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varimp+2B2CH2OModel-method_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate_complete.csv.zip"
pros &lt;- h2o.importFile(f)
response &lt;- "GLEASON"
predictors &lt;- c("ID", "AGE", "CAPSULE", "DCAPS", "PSA", "VOL", "DPROS")
model &lt;- h2o.glm(x = predictors, y = response, training_frame = pros)
h2o.varimp(model)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.varsplits'>Retrieve per-variable split information for a given Isolation Forest model.
Output will include:
- count - The number of times a variable was used to make a split.
- aggregated_split_ratios - The split ratio is defined as &quot;abs(#left_observations - #right_observations) / #before_split&quot;.
Even splits (#left_observations approx the same as #right_observations) contribute
less to the total aggregated split ratio value for the given feature;
highly imbalanced splits (eg. #left_observations &gt;&gt; #right_observations) contribute more.
- aggregated_split_depths - The sum of all depths of a variable used to make a split. (If a variable is used
on level N of a tree, then it contributes with N to the total aggregate.)</h2><span id='topic+h2o.varsplits'></span>

<h3>Description</h3>

<p>Retrieve per-variable split information for a given Isolation Forest model.
Output will include:
- count - The number of times a variable was used to make a split.
- aggregated_split_ratios - The split ratio is defined as &quot;abs(#left_observations - #right_observations) / #before_split&quot;.
Even splits (#left_observations approx the same as #right_observations) contribute
less to the total aggregated split ratio value for the given feature;
highly imbalanced splits (eg. #left_observations &gt;&gt; #right_observations) contribute more.
- aggregated_split_depths - The sum of all depths of a variable used to make a split. (If a variable is used
on level N of a tree, then it contributes with N to the total aggregate.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.varsplits(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.varsplits_+3A_object">object</code></td>
<td>
<p>An Isolation Forest model represented by <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.week'>Convert Milliseconds to Week of Week Year in H2O Datasets</h2><span id='topic+h2o.week'></span><span id='topic+week'></span><span id='topic+week.H2OFrame'></span>

<h3>Description</h3>

<p>Converts the entries of an H2OFrame object from milliseconds to weeks of the week
year (starting from 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.week(x)

week(x)

## S3 method for class 'H2OFrame'
week(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.week_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to weeks of
the week year.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.month">h2o.month</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.week(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.weights'>Retrieve the respective weight matrix</h2><span id='topic+h2o.weights'></span>

<h3>Description</h3>

<p>Retrieve the respective weight matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.weights(object, matrix_id = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.weights_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> or <a href="#topic+H2OModelMetrics-class">H2OModelMetrics</a></p>
</td></tr>
<tr><td><code id="h2o.weights_+3A_matrix_id">matrix_id</code></td>
<td>
<p>An integer, ranging from 1 to number of layers + 1, that specifies the weight matrix to return.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/chicago/chicagoCensus.csv"
census &lt;- h2o.importFile(f)
census[, 1] &lt;- as.factor(census[, 1])
dl_model &lt;- h2o.deeplearning(x = c(1:3), y = 4, training_frame = census,
                            hidden = c(17, 191), 
                            epochs = 1,
                            balance_classes = FALSE,
                            export_weights_and_biases = TRUE)
h2o.weights(dl_model, matrix_id = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.which'>Which indices are TRUE?</h2><span id='topic+h2o.which'></span>

<h3>Description</h3>

<p>Give the TRUE indices of a logical object, allowing for array indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.which(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.which_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+which">which</a></code> for the base R method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

iris_hf &lt;- as.h2o(iris)
h2o.which(iris_hf[, 1] == 4.4)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.which_max'>Which indice contains the max value?</h2><span id='topic+h2o.which_max'></span><span id='topic+which.max.H2OFrame'></span><span id='topic+which.min.H2OFrame'></span>

<h3>Description</h3>

<p>Get the index of the max value in a column or row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.which_max(x, na.rm = TRUE, axis = 0)

which.max.H2OFrame(x, na.rm = TRUE, axis = 0)

which.min.H2OFrame(x, na.rm = TRUE, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.which_max_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.which_max_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Indicate whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="h2o.which_max_+3A_axis">axis</code></td>
<td>
<p><code>integer</code>. Indicate whether to calculate the mean down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+which.min">which.min</a></code> for the base R method, <code>which.max()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/chicago/chicagoCensus.csv"
census &lt;- h2o.importFile(f)
census[, 1] &lt;- as.factor(census[, 1])
dl_model &lt;- h2o.deeplearning(x = c(1:3), y = 4, hidden = c(17, 191), 
                            epochs = 1, training_frame = census, 
                            balance_classes = FALSE,
                            export_weights_and_biases = TRUE)
h2o.which_max(census["PER CAPITA INCOME "], na.rm = FALSE, axis = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.which_min'>Which index contains the min value?</h2><span id='topic+h2o.which_min'></span>

<h3>Description</h3>

<p>Get the index of the min value in a column or row
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.which_min(x, na.rm = TRUE, axis = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.which_min_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="h2o.which_min_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Indicate whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="h2o.which_min_+3A_axis">axis</code></td>
<td>
<p><code>integer</code>. Indicate whether to calculate the mean down a column (0) or across a row (1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+which.min">which.min</a></code> for the base R method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/chicago/chicagoCensus.csv"
census &lt;- h2o.importFile(f)
dl_model &lt;- h2o.deeplearning(x = c(1:3), y = 4, hidden = c(17, 191), 
                            epochs = 1, training_frame = census, 
                            balance_classes = FALSE, 
                            export_weights_and_biases = TRUE)
h2o.which_min(census["PER CAPITA INCOME "], na.rm = FALSE, axis = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.withinss'>Get the Within SS</h2><span id='topic+h2o.withinss'></span>

<h3>Description</h3>

<p>Get the Within SS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.withinss(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.withinss_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OClusteringModel-class">H2OClusteringModel</a> object.</p>
</td></tr>
</table>

<hr>
<h2 id='h2o.word2vec'>Trains a word2vec model on a String column of an H2O data frame</h2><span id='topic+h2o.word2vec'></span>

<h3>Description</h3>

<p>Trains a word2vec model on a String column of an H2O data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.word2vec(
  training_frame = NULL,
  model_id = NULL,
  min_word_freq = 5,
  word_model = c("SkipGram", "CBOW"),
  norm_model = c("HSM"),
  vec_size = 100,
  window_size = 5,
  sent_sample_rate = 0.001,
  init_learning_rate = 0.025,
  epochs = 5,
  pre_trained = NULL,
  max_runtime_secs = 0,
  export_checkpoints_dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.word2vec_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_min_word_freq">min_word_freq</code></td>
<td>
<p>This will discard words that appear less than &lt;int&gt; times Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_word_model">word_model</code></td>
<td>
<p>The word model to use (SkipGram or CBOW) Must be one of: &quot;SkipGram&quot;, &quot;CBOW&quot;. Defaults to SkipGram.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_norm_model">norm_model</code></td>
<td>
<p>Use Hierarchical Softmax Must be one of: &quot;HSM&quot;. Defaults to HSM.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_vec_size">vec_size</code></td>
<td>
<p>Set size of word vectors Defaults to 100.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_window_size">window_size</code></td>
<td>
<p>Set max skip length between words Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_sent_sample_rate">sent_sample_rate</code></td>
<td>
<p>Set threshold for occurrence of words. Those that appear with higher frequency in the training data
will be randomly down-sampled; useful range is (0, 1e-5) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_init_learning_rate">init_learning_rate</code></td>
<td>
<p>Set the starting learning rate Defaults to 0.025.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_epochs">epochs</code></td>
<td>
<p>Number of training iterations to run Defaults to 5.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_pre_trained">pre_trained</code></td>
<td>
<p>Id of a data frame that contains a pre-trained (external) word2vec model</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.word2vec_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the CraigslistJobTitles dataset
job_titles &lt;- h2o.importFile(
    "https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv",
    col.names = c("category", "jobtitle"), col.types = c("String", "String"), header = TRUE
)

# Build and train the Word2Vec model
words &lt;- h2o.tokenize(job_titles, " ")
vec &lt;- h2o.word2vec(training_frame = words)
h2o.findSynonyms(vec, "teacher", count = 20)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.xgboost'>Build an eXtreme Gradient Boosting model</h2><span id='topic+h2o.xgboost'></span>

<h3>Description</h3>

<p>Builds a eXtreme Gradient Boosting model using the native XGBoost backend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.xgboost(
  x,
  y,
  training_frame,
  model_id = NULL,
  validation_frame = NULL,
  nfolds = 0,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_predictions = FALSE,
  keep_cross_validation_fold_assignment = FALSE,
  score_each_iteration = FALSE,
  fold_assignment = c("AUTO", "Random", "Modulo", "Stratified"),
  fold_column = NULL,
  ignore_const_cols = TRUE,
  offset_column = NULL,
  weights_column = NULL,
  stopping_rounds = 0,
  stopping_metric = c("AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
    "AUC", "AUCPR", "lift_top_group", "misclassification", "mean_per_class_error",
    "custom", "custom_increasing"),
  stopping_tolerance = 0.001,
  max_runtime_secs = 0,
  seed = -1,
  distribution = c("AUTO", "bernoulli", "multinomial", "gaussian", "poisson", "gamma",
    "tweedie", "laplace", "quantile", "huber"),
  tweedie_power = 1.5,
  categorical_encoding = c("AUTO", "Enum", "OneHotInternal", "OneHotExplicit", "Binary",
    "Eigen", "LabelEncoder", "SortByResponse", "EnumLimited"),
  quiet_mode = TRUE,
  checkpoint = NULL,
  export_checkpoints_dir = NULL,
  ntrees = 50,
  max_depth = 6,
  min_rows = 1,
  min_child_weight = 1,
  learn_rate = 0.3,
  eta = 0.3,
  sample_rate = 1,
  subsample = 1,
  col_sample_rate = 1,
  colsample_bylevel = 1,
  col_sample_rate_per_tree = 1,
  colsample_bytree = 1,
  colsample_bynode = 1,
  max_abs_leafnode_pred = 0,
  max_delta_step = 0,
  monotone_constraints = NULL,
  interaction_constraints = NULL,
  score_tree_interval = 0,
  min_split_improvement = 0,
  gamma = 0,
  nthread = -1,
  save_matrix_directory = NULL,
  build_tree_one_node = FALSE,
  parallelize_cross_validation = TRUE,
  calibrate_model = FALSE,
  calibration_frame = NULL,
  calibration_method = c("AUTO", "PlattScaling", "IsotonicRegression"),
  max_bins = 256,
  max_leaves = 0,
  sample_type = c("uniform", "weighted"),
  normalize_type = c("tree", "forest"),
  rate_drop = 0,
  one_drop = FALSE,
  skip_drop = 0,
  tree_method = c("auto", "exact", "approx", "hist"),
  grow_policy = c("depthwise", "lossguide"),
  booster = c("gbtree", "gblinear", "dart"),
  reg_lambda = 1,
  reg_alpha = 0,
  dmatrix_type = c("auto", "dense", "sparse"),
  backend = c("auto", "gpu", "cpu"),
  gpu_id = NULL,
  gainslift_bins = -1,
  auc_type = c("AUTO", "NONE", "MACRO_OVR", "WEIGHTED_OVR", "MACRO_OVO", "WEIGHTED_OVO"),
  scale_pos_weight = 1,
  eval_metric = NULL,
  score_eval_metric_only = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.xgboost_+3A_x">x</code></td>
<td>
<p>(Optional) A vector containing the names or indices of the predictor variables to use in building the model.
If x is missing, then all columns except y are used.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_y">y</code></td>
<td>
<p>The name or column index of the response variable in the data. 
The response must be either a numeric or a categorical/factor variable. 
If the response is numeric, then a regression model will be trained, otherwise it will train a classification model.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_training_frame">training_frame</code></td>
<td>
<p>Id of the training data frame.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_model_id">model_id</code></td>
<td>
<p>Destination id for this model; auto-generated if not specified.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_validation_frame">validation_frame</code></td>
<td>
<p>Id of the validation data frame.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds for K-fold cross-validation (0 to disable or &gt;= 2). Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_keep_cross_validation_models">keep_cross_validation_models</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation models. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_keep_cross_validation_predictions">keep_cross_validation_predictions</code></td>
<td>
<p><code>Logical</code>. Whether to keep the predictions of the cross-validation models. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_keep_cross_validation_fold_assignment">keep_cross_validation_fold_assignment</code></td>
<td>
<p><code>Logical</code>. Whether to keep the cross-validation fold assignment. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_score_each_iteration">score_each_iteration</code></td>
<td>
<p><code>Logical</code>. Whether to score during each iteration of model training. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_fold_assignment">fold_assignment</code></td>
<td>
<p>Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will
stratify the folds based on the response variable, for classification problems. Must be one of: &quot;AUTO&quot;,
&quot;Random&quot;, &quot;Modulo&quot;, &quot;Stratified&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_fold_column">fold_column</code></td>
<td>
<p>Column with cross-validation fold index assignment per observation.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_ignore_const_cols">ignore_const_cols</code></td>
<td>
<p><code>Logical</code>. Ignore constant columns. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_offset_column">offset_column</code></td>
<td>
<p>Offset column. This will be added to the combination of columns before applying the link function.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_weights_column">weights_column</code></td>
<td>
<p>Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from
the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative
weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the
data frame. This is typically the number of times a row is repeated, but non-integer values are supported as
well. During training, rows with higher weights matter more, due to the larger loss function pre-factor. If
you set weight = 0 for a row, the returned prediction frame at that row is zero and this is incorrect. To get
an accurate prediction, remove all rows with weight == 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_stopping_rounds">stopping_rounds</code></td>
<td>
<p>Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the
stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable) Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_stopping_metric">stopping_metric</code></td>
<td>
<p>Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anomaly_score
for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python
client. Must be one of: &quot;AUTO&quot;, &quot;deviance&quot;, &quot;logloss&quot;, &quot;MSE&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;RMSLE&quot;, &quot;AUC&quot;, &quot;AUCPR&quot;,
&quot;lift_top_group&quot;, &quot;misclassification&quot;, &quot;mean_per_class_error&quot;, &quot;custom&quot;, &quot;custom_increasing&quot;. Defaults to
AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_stopping_tolerance">stopping_tolerance</code></td>
<td>
<p>Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this
much) Defaults to 0.001.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_runtime_secs">max_runtime_secs</code></td>
<td>
<p>Maximum allowed runtime in seconds for model training. Use 0 to disable. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_seed">seed</code></td>
<td>
<p>Seed for random numbers (affects certain parts of the algo that are stochastic and those might or might not be enabled by default).
Defaults to -1 (time-based random number).</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_distribution">distribution</code></td>
<td>
<p>Distribution function Must be one of: &quot;AUTO&quot;, &quot;bernoulli&quot;, &quot;multinomial&quot;, &quot;gaussian&quot;, &quot;poisson&quot;, &quot;gamma&quot;,
&quot;tweedie&quot;, &quot;laplace&quot;, &quot;quantile&quot;, &quot;huber&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_tweedie_power">tweedie_power</code></td>
<td>
<p>Tweedie power for Tweedie regression, must be between 1 and 2. Defaults to 1.5.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_categorical_encoding">categorical_encoding</code></td>
<td>
<p>Encoding scheme for categorical features Must be one of: &quot;AUTO&quot;, &quot;Enum&quot;, &quot;OneHotInternal&quot;, &quot;OneHotExplicit&quot;,
&quot;Binary&quot;, &quot;Eigen&quot;, &quot;LabelEncoder&quot;, &quot;SortByResponse&quot;, &quot;EnumLimited&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_quiet_mode">quiet_mode</code></td>
<td>
<p><code>Logical</code>. Enable quiet mode Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Model checkpoint to resume training with.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_export_checkpoints_dir">export_checkpoints_dir</code></td>
<td>
<p>Automatically export generated models to this directory.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_ntrees">ntrees</code></td>
<td>
<p>(same as n_estimators) Number of trees. Defaults to 50.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum tree depth (0 for unlimited). Defaults to 6.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_min_rows">min_rows</code></td>
<td>
<p>(same as min_child_weight) Fewest allowed (weighted) observations in a leaf. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>(same as min_rows) Fewest allowed (weighted) observations in a leaf. Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_learn_rate">learn_rate</code></td>
<td>
<p>(same as eta) Learning rate (from 0.0 to 1.0) Defaults to 0.3.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_eta">eta</code></td>
<td>
<p>(same as learn_rate) Learning rate (from 0.0 to 1.0) Defaults to 0.3.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(same as subsample) Row sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_subsample">subsample</code></td>
<td>
<p>(same as sample_rate) Row sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_col_sample_rate">col_sample_rate</code></td>
<td>
<p>(same as colsample_bylevel) Column sample rate (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_colsample_bylevel">colsample_bylevel</code></td>
<td>
<p>(same as col_sample_rate) Column sample rate (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_col_sample_rate_per_tree">col_sample_rate_per_tree</code></td>
<td>
<p>(same as colsample_bytree) Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_colsample_bytree">colsample_bytree</code></td>
<td>
<p>(same as col_sample_rate_per_tree) Column sample rate per tree (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_colsample_bynode">colsample_bynode</code></td>
<td>
<p>Column sample rate per tree node (from 0.0 to 1.0) Defaults to 1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_abs_leafnode_pred">max_abs_leafnode_pred</code></td>
<td>
<p>(same as max_delta_step) Maximum absolute value of a leaf node prediction Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_delta_step">max_delta_step</code></td>
<td>
<p>(same as max_abs_leafnode_pred) Maximum absolute value of a leaf node prediction Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_monotone_constraints">monotone_constraints</code></td>
<td>
<p>A mapping representing monotonic constraints. Use +1 to enforce an increasing constraint and -1 to specify a
decreasing constraint.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_interaction_constraints">interaction_constraints</code></td>
<td>
<p>A set of allowed column interactions.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_score_tree_interval">score_tree_interval</code></td>
<td>
<p>Score the model after every so many trees. Disabled if set to 0. Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_min_split_improvement">min_split_improvement</code></td>
<td>
<p>(same as gamma) Minimum relative improvement in squared error reduction for a split to happen Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_gamma">gamma</code></td>
<td>
<p>(same as min_split_improvement) Minimum relative improvement in squared error reduction for a split to happen
Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_nthread">nthread</code></td>
<td>
<p>Number of parallel threads that can be used to run XGBoost. Cannot exceed H2O cluster limits (-nthreads
parameter). Defaults to maximum available Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_save_matrix_directory">save_matrix_directory</code></td>
<td>
<p>Directory where to save matrices passed to XGBoost library. Useful for debugging.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_build_tree_one_node">build_tree_one_node</code></td>
<td>
<p><code>Logical</code>. Run on one node only; no network overhead but fewer cpus used. Suitable for small datasets.
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_parallelize_cross_validation">parallelize_cross_validation</code></td>
<td>
<p><code>Logical</code>. Allow parallel training of cross-validation models Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_calibrate_model">calibrate_model</code></td>
<td>
<p><code>Logical</code>. Use Platt Scaling (default) or Isotonic Regression to calculate calibrated class
probabilities. Calibration can provide more accurate estimates of class probabilities. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_calibration_frame">calibration_frame</code></td>
<td>
<p>Data for model calibration</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_calibration_method">calibration_method</code></td>
<td>
<p>Calibration method to use Must be one of: &quot;AUTO&quot;, &quot;PlattScaling&quot;, &quot;IsotonicRegression&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_bins">max_bins</code></td>
<td>
<p>For tree_method=hist only: maximum number of bins Defaults to 256.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_max_leaves">max_leaves</code></td>
<td>
<p>For tree_method=hist only: maximum number of leaves Defaults to 0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_sample_type">sample_type</code></td>
<td>
<p>For booster=dart only: sample_type Must be one of: &quot;uniform&quot;, &quot;weighted&quot;. Defaults to uniform.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_normalize_type">normalize_type</code></td>
<td>
<p>For booster=dart only: normalize_type Must be one of: &quot;tree&quot;, &quot;forest&quot;. Defaults to tree.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_rate_drop">rate_drop</code></td>
<td>
<p>For booster=dart only: rate_drop (0..1) Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_one_drop">one_drop</code></td>
<td>
<p><code>Logical</code>. For booster=dart only: one_drop Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_skip_drop">skip_drop</code></td>
<td>
<p>For booster=dart only: skip_drop (0..1) Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_tree_method">tree_method</code></td>
<td>
<p>Tree method Must be one of: &quot;auto&quot;, &quot;exact&quot;, &quot;approx&quot;, &quot;hist&quot;. Defaults to auto.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_grow_policy">grow_policy</code></td>
<td>
<p>Grow policy - depthwise is standard GBM, lossguide is LightGBM Must be one of: &quot;depthwise&quot;, &quot;lossguide&quot;.
Defaults to depthwise.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_booster">booster</code></td>
<td>
<p>Booster type Must be one of: &quot;gbtree&quot;, &quot;gblinear&quot;, &quot;dart&quot;. Defaults to gbtree.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_reg_lambda">reg_lambda</code></td>
<td>
<p>L2 regularization Defaults to 1.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_reg_alpha">reg_alpha</code></td>
<td>
<p>L1 regularization Defaults to 0.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_dmatrix_type">dmatrix_type</code></td>
<td>
<p>Type of DMatrix. For sparse, NAs and 0 are treated equally. Must be one of: &quot;auto&quot;, &quot;dense&quot;, &quot;sparse&quot;.
Defaults to auto.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_backend">backend</code></td>
<td>
<p>Backend. By default (auto), a GPU is used if available. Must be one of: &quot;auto&quot;, &quot;gpu&quot;, &quot;cpu&quot;. Defaults to
auto.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_gpu_id">gpu_id</code></td>
<td>
<p>Which GPU(s) to use.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_gainslift_bins">gainslift_bins</code></td>
<td>
<p>Gains/Lift table number of bins. 0 means disabled.. Default value -1 means automatic binning. Defaults to -1.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_auc_type">auc_type</code></td>
<td>
<p>Set default multinomial AUC type. Must be one of: &quot;AUTO&quot;, &quot;NONE&quot;, &quot;MACRO_OVR&quot;, &quot;WEIGHTED_OVR&quot;, &quot;MACRO_OVO&quot;,
&quot;WEIGHTED_OVO&quot;. Defaults to AUTO.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_scale_pos_weight">scale_pos_weight</code></td>
<td>
<p>Controls the effect of observations with positive labels in relation to the observations with negative labels
on gradient calculation. Useful for imbalanced problems. Defaults to 1.0.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_eval_metric">eval_metric</code></td>
<td>
<p>Specification of evaluation metric that will be passed to the native XGBoost backend.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_score_eval_metric_only">score_eval_metric_only</code></td>
<td>
<p><code>Logical</code>. If enabled, score only the evaluation metric. This can make model training faster if scoring
is frequent (eg. each iteration). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="h2o.xgboost_+3A_verbose">verbose</code></td>
<td>
<p><code>Logical</code>. Print scoring history to the console (Metrics per tree). Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

# Import the titanic dataset
f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv"
titanic &lt;- h2o.importFile(f)

# Set predictors and response; set response as a factor
titanic['survived'] &lt;- as.factor(titanic['survived'])
predictors &lt;- setdiff(colnames(titanic), colnames(titanic)[2:3])
response &lt;- "survived"

# Split the dataset into train and valid
splits &lt;- h2o.splitFrame(data =  titanic, ratios = .8, seed = 1234)
train &lt;- splits[[1]]
valid &lt;- splits[[2]]

# Train the XGB model
titanic_xgb &lt;- h2o.xgboost(x = predictors, y = response,
                           training_frame = train, validation_frame = valid,
                           booster = "dart", normalize_type = "tree",
                           seed = 1234)

## End(Not run)
</code></pre>

<hr>
<h2 id='h2o.xgboost.available'>Determines whether an XGBoost model can be built</h2><span id='topic+h2o.xgboost.available'></span>

<h3>Description</h3>

<p>Ask the H2O server whether a XGBoost model can be built. (Depends on availability of native backend.)
Returns True if a XGBoost model can be built, or False otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.xgboost.available()
</code></pre>

<hr>
<h2 id='h2o.year'>Convert Milliseconds to Years in H2O Datasets</h2><span id='topic+h2o.year'></span><span id='topic+year'></span><span id='topic+year.H2OFrame'></span>

<h3>Description</h3>

<p>Convert the entries of an H2OFrame object from milliseconds to years, indexed
starting from 1900.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.year(x)

year(x)

## S3 method for class 'H2OFrame'
year(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h2o.year_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method calls the function of the MutableDateTime class in Java.
</p>


<h3>Value</h3>

<p>An H2OFrame object containing the entries of <code>x</code> converted to years
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.month">h2o.month</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/jira/v-11-eurodate.csv"
hdf &lt;- h2o.importFile(f)
h2o.year(hdf["ds9"])

## End(Not run)
</code></pre>

<hr>
<h2 id='H2OAutoML-class'>The H2OAutoML class</h2><span id='topic+H2OAutoML-class'></span>

<h3>Description</h3>

<p>This class represents an H2OAutoML object
</p>

<hr>
<h2 id='H2OClusteringModel-class'>The H2OClusteringModel object.</h2><span id='topic+H2OClusteringModel-class'></span>

<h3>Description</h3>

<p>This virtual class represents a clustering model built by H2O.
</p>


<h3>Details</h3>

<p>This object has slots for the key, which is a character string that points to the model key existing in the H2O cluster,
the data used to build the model (an object of class H2OFrame).
</p>


<h3>Slots</h3>


<dl>
<dt><code>model_id</code></dt><dd><p>A <code>character</code> string specifying the key for the model fit in the H2O cluster's key-value store.</p>
</dd>
<dt><code>algorithm</code></dt><dd><p>A <code>character</code> string specifying the algorithm that was used to fit the model.</p>
</dd>
<dt><code>parameters</code></dt><dd><p>A <code>list</code> containing the parameter settings that were used to fit the model that differ from the defaults.</p>
</dd>
<dt><code>allparameters</code></dt><dd><p>A <code>list</code> containing all parameters used to fit the model.</p>
</dd>
<dt><code>model</code></dt><dd><p>A <code>list</code> containing the characteristics of the model returned by the algorithm.
</p>

<dl>
<dt>size </dt><dd><p>The number of points in each cluster.</p>
</dd>
<dt>totss </dt><dd><p>Total sum of squared error to grand mean.</p>
</dd>
<dt>withinss </dt><dd><p>A vector of within-cluster sum of squared error.</p>
</dd>
<dt>tot_withinss </dt><dd><p>Total within-cluster sum of squared error.</p>
</dd>
<dt>betweenss </dt><dd><p>Between-cluster sum of squared error.</p>
</dd>
</dl>
</dd>
</dl>

<hr>
<h2 id='H2OConnection-class'>The H2OConnection class.</h2><span id='topic+H2OConnection-class'></span><span id='topic+H2OConnection'></span><span id='topic+show+2CH2OConnection-method'></span>

<h3>Description</h3>

<p>This class represents a connection to an H2O cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OConnection'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OConnection-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OConnection</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because H2O is not a master-slave architecture, there is no restriction on which H2O node
is used to establish the connection between R (the client) and H2O (the server).
</p>
<p>A new H2O connection is established via the h2o.init() function, which takes as parameters
the 'ip' and 'port' of the machine running an instance to connect with. The default behavior
is to connect with a local instance of H2O at port 54321, or to boot a new local instance if one
is not found at port 54321.
</p>


<h3>Slots</h3>


<dl>
<dt><code>ip</code></dt><dd><p>A <code>character</code> string specifying the IP address of the H2O cluster.</p>
</dd>
<dt><code>port</code></dt><dd><p>A <code>numeric</code> value specifying the port number of the H2O cluster.</p>
</dd>
<dt><code>name</code></dt><dd><p>A <code>character</code> value specifying the name of the H2O cluster.</p>
</dd>
<dt><code>proxy</code></dt><dd><p>A <code>character</code> specifying the proxy path of the H2O cluster.</p>
</dd>
<dt><code>https</code></dt><dd><p>Set this to TRUE to use https instead of http.</p>
</dd>
<dt><code>cacert</code></dt><dd><p>Path to a CA bundle file with root and intermediate certificates of trusted CAs.</p>
</dd>
<dt><code>insecure</code></dt><dd><p>Set this to TRUE to disable SSL certificate checking.</p>
</dd>
<dt><code>username</code></dt><dd><p>Username to login with.</p>
</dd>
<dt><code>password</code></dt><dd><p>Password to login with.</p>
</dd>
<dt><code>use_spnego</code></dt><dd><p>Set this to TRUE to use SPNEGO authentication.</p>
</dd>
<dt><code>cookies</code></dt><dd><p>Cookies to add to request</p>
</dd>
<dt><code>context_path</code></dt><dd><p>Context path which is appended to H2O server location.</p>
</dd>
<dt><code>mutable</code></dt><dd><p>An <code>H2OConnectionMutableState</code> object to hold the mutable state for the H2O connection.</p>
</dd>
</dl>

<hr>
<h2 id='H2OConnectionMutableState'>The H2OConnectionMutableState class</h2><span id='topic+H2OConnectionMutableState'></span>

<h3>Description</h3>

<p>This class represents the mutable aspects of a connection to an H2O cluster.
</p>


<h3>Slots</h3>


<dl>
<dt><code>session_id</code></dt><dd><p>A <code>character</code> string specifying the H2O session identifier.</p>
</dd>
<dt><code>key_count</code></dt><dd><p>A <code>integer</code> value specifying count for the number of keys generated for the <code>session_id</code>.</p>
</dd>
</dl>

<hr>
<h2 id='H2OCoxPHModel-class'>The H2OCoxPHModel object.</h2><span id='topic+H2OCoxPHModel-class'></span><span id='topic+H2OCoxPHModel'></span><span id='topic+show+2CH2OCoxPHModel-method'></span><span id='topic+coef.H2OCoxPHModel'></span><span id='topic+extractAIC.H2OCoxPHModel'></span><span id='topic+logLik.H2OCoxPHModel'></span><span id='topic+survfit.H2OCoxPHModel'></span><span id='topic+vcov.H2OCoxPHModel'></span>

<h3>Description</h3>

<p>Virtual object representing H2O's CoxPH Model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OCoxPHModel'
show(object)

## S3 method for class 'H2OCoxPHModel'
coef(object, ...)

## S3 method for class 'H2OCoxPHModel'
extractAIC(fit, scale, k = 2, ...)

## S3 method for class 'H2OCoxPHModel'
logLik(object, ...)

survfit.H2OCoxPHModel(formula, newdata, ...)

## S3 method for class 'H2OCoxPHModel'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OCoxPHModel-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OCoxPHModel</code> object.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_fit">fit</code></td>
<td>
<p>an <code>H2OCoxPHModel</code> object.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_scale">scale</code></td>
<td>
<p>optional numeric specifying the scale parameter of the model.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_k">k</code></td>
<td>
<p>numeric specifying the weight of the equivalent degrees of freedom.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_formula">formula</code></td>
<td>
<p>an <code>H2OCoxPHModel</code> object.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModel-class_+3A_newdata">newdata</code></td>
<td>
<p>an optional <code>H2OFrame</code> or <code>data.frame</code> with the same
variable names as those that appear in the <code>H2OCoxPHModel</code> object.</p>
</td></tr>
</table>

<hr>
<h2 id='H2OCoxPHModelSummary-class'>The H2OCoxPHModelSummary object.</h2><span id='topic+H2OCoxPHModelSummary-class'></span><span id='topic+H2OCoxPHModelSummary'></span><span id='topic+show+2CH2OCoxPHModelSummary-method'></span><span id='topic+coef.H2OCoxPHModelSummary'></span>

<h3>Description</h3>

<p>Wrapper object for summary information compatible with survival package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OCoxPHModelSummary'
show(object)

## S3 method for class 'H2OCoxPHModelSummary'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OCoxPHModelSummary-class_+3A_object">object</code></td>
<td>
<p>An <code>H2OCoxPHModelSummary</code> object.</p>
</td></tr>
<tr><td><code id="H2OCoxPHModelSummary-class_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>summary</code></dt><dd><p>A <code>list</code> containing the a summary compatible with CoxPH summary used in the survival package.</p>
</dd>
</dl>

<hr>
<h2 id='H2OFrame-class'>The H2OFrame class</h2><span id='topic+H2OFrame-class'></span>

<h3>Description</h3>

<p>This class represents an H2OFrame object
</p>

<hr>
<h2 id='H2OFrame-Extract'>Extract or Replace Parts of an H2OFrame Object</h2><span id='topic+H2OFrame-Extract'></span><span id='topic++5B.H2OFrame'></span><span id='topic++5B+2CH2OFrame-method'></span><span id='topic++24.H2OFrame'></span><span id='topic++5B+5B.H2OFrame'></span><span id='topic++5B+3C-.H2OFrame'></span><span id='topic++24+3C-.H2OFrame'></span><span id='topic++5B+5B+3C-.H2OFrame'></span>

<h3>Description</h3>

<p>Operators to extract or replace parts of H2OFrame objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
data[row, col, drop = TRUE]

## S3 method for class 'H2OFrame'
x$name

## S3 method for class 'H2OFrame'
x[[i, exact = TRUE]]

## S3 method for class 'H2OFrame'
x$name

## S3 method for class 'H2OFrame'
x[[i, exact = TRUE]]

## S3 replacement method for class 'H2OFrame'
data[row, col, ...] &lt;- value

## S3 replacement method for class 'H2OFrame'
data$name &lt;- value

## S3 replacement method for class 'H2OFrame'
data[[name]] &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OFrame-Extract_+3A_data">data</code></td>
<td>
<p>object from which to extract element(s) or in which to replace element(s).</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_row">row</code></td>
<td>
<p>index specifying row element(s) to extract or replace. Indices are numeric or
character vectors or empty (missing) or will be matched to the names.</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_col">col</code></td>
<td>
<p>index specifying column element(s) to extract or replace.</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_drop">drop</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_name">name</code></td>
<td>
<p>a literal character string or a name (possibly backtick quoted).</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_i">i</code></td>
<td>
<p>index</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_exact">exact</code></td>
<td>
<p>controls possible partial matching of <code>[[</code> when extracting
a character</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="H2OFrame-Extract_+3A_value">value</code></td>
<td>
<p>To be assigned</p>
</td></tr>
</table>

<hr>
<h2 id='H2OGrid-class'>H2O Grid</h2><span id='topic+H2OGrid-class'></span><span id='topic+H2OGrid'></span><span id='topic+show+2CH2OGrid-method'></span>

<h3>Description</h3>

<p>A class to contain the information about grid results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OGrid'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OGrid-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OGrid</code> object.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>grid_id</code></dt><dd><p>the final identifier of grid</p>
</dd>
<dt><code>model_ids</code></dt><dd><p>list of model IDs which are included in the grid object</p>
</dd>
<dt><code>hyper_names</code></dt><dd><p>list of parameter names used for grid search</p>
</dd>
<dt><code>failed_params</code></dt><dd><p>list of model parameters which caused a failure during model building,
it can contain a null value</p>
</dd>
<dt><code>failure_details</code></dt><dd><p>list of detailed messages which correspond to failed parameters field</p>
</dd>
<dt><code>failure_stack_traces</code></dt><dd><p>list of stack traces corresponding to model failures reported by
failed_params and failure_details fields</p>
</dd>
<dt><code>failed_raw_params</code></dt><dd><p>list of failed raw parameters</p>
</dd>
<dt><code>summary_table</code></dt><dd><p>table of models built with parameters and metric information.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+H2OModel-class">H2OModel</a> for the final model types.
</p>

<hr>
<h2 id='H2OInfogram'>wrapper function for instantiating H2OInfogram</h2><span id='topic+H2OInfogram'></span>

<h3>Description</h3>

<p>wrapper function for instantiating H2OInfogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>H2OInfogram(model_id, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OInfogram_+3A_model_id">model_id</code></td>
<td>
<p>is string of H2OModel object</p>
</td></tr>
<tr><td><code id="H2OInfogram_+3A_...">...</code></td>
<td>
<p>parameters to algorithm, admissible_features, ...</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>H2OInfogram</code> object
</p>

<hr>
<h2 id='H2OInfogram-class'>H2OInfogram class</h2><span id='topic+H2OInfogram-class'></span>

<h3>Description</h3>

<p>H2OInfogram class contains a subset of what a normal H2OModel will return
</p>


<h3>Slots</h3>


<dl>
<dt><code>model_id</code></dt><dd><p>string returned as part of every <code>H2OModel</code></p>
</dd>
<dt><code>algorithm</code></dt><dd><p>string denoting the algorithm used to build infogram</p>
</dd>
<dt><code>admissible_features</code></dt><dd><p>string array denoting all predictor names which pass the cmi and relelvance threshold</p>
</dd>
<dt><code>admissible_features_valid</code></dt><dd><p>string array denoting all predictor names which pass the cmi and relelvance threshold from validation frame</p>
</dd>
<dt><code>admissible_features_xval</code></dt><dd><p>string array denoting all predictor names which pass the cmi and relelvance threshold from cv holdout set</p>
</dd>
<dt><code>net_information_threshold</code></dt><dd><p>numeric value denoting threshold used for predictor selection</p>
</dd>
<dt><code>total_information_threshold</code></dt><dd><p>numeric value denoting threshold used for predictor selection</p>
</dd>
<dt><code>safety_index_threshold</code></dt><dd><p>numeric value denoting threshold used for predictor selection</p>
</dd>
<dt><code>relevance_index_threshold</code></dt><dd><p>numeric value denoting threshold used for predictor selection</p>
</dd>
<dt><code>admissible_score</code></dt><dd><p><code>H2OFrame</code> that contains columns, admissible, admissible_index, relevance, cmi, cmi_raw</p>
</dd>
<dt><code>admissible_score_valid</code></dt><dd><p><code>H2OFrame</code> that contains columns, admissible, admissible_index, relevance, cmi, cmi_raw from validation frame</p>
</dd>
<dt><code>admissible_score_xval</code></dt><dd><p><code>H2OFrame</code> that contains averages of columns, admissible, admissible_index, relevance, cmi, cmi_raw from cv hold-out</p>
</dd>
</dl>

<hr>
<h2 id='H2OLeafNode-class'>The H2OLeafNode class.</h2><span id='topic+H2OLeafNode-class'></span>

<h3>Description</h3>

<p>This class represents a single leaf node in an <code>H2OTree</code>.
</p>


<h3>Details</h3>

<p>#' @aliases H2OLeafNode
</p>

<hr>
<h2 id='H2OModel-class'>The H2OModel object.</h2><span id='topic+H2OModel-class'></span><span id='topic+H2OModel'></span><span id='topic+show+2CH2OModel-method'></span><span id='topic+H2OUnknownModel-class'></span><span id='topic+H2OBinomialModel-class'></span><span id='topic+H2OBinomialUpliftModel-class'></span><span id='topic+H2OMultinomialModel-class'></span><span id='topic+H2OOrdinalModel-class'></span><span id='topic+H2ORegressionModel-class'></span><span id='topic+H2OAutoEncoderModel-class'></span><span id='topic+H2ODimReductionModel-class'></span><span id='topic+H2OWordEmbeddingModel-class'></span><span id='topic+H2OAnomalyDetectionModel-class'></span><span id='topic+H2OTargetEncoderModel-class'></span>

<h3>Description</h3>

<p>This virtual class represents a model built by H2O.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModel'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OModel-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OModel</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This object has slots for the key, which is a character string that points to the model key existing in the H2O cluster,
the data used to build the model (an object of class H2OFrame).
</p>


<h3>Slots</h3>


<dl>
<dt><code>model_id</code></dt><dd><p>A <code>character</code> string specifying the key for the model fit in the H2O cluster's key-value store.</p>
</dd>
<dt><code>algorithm</code></dt><dd><p>A <code>character</code> string specifying the algorithm that were used to fit the model.</p>
</dd>
<dt><code>parameters</code></dt><dd><p>A <code>list</code> containing the parameter settings that were used to fit the model that differ from the defaults.</p>
</dd>
<dt><code>allparameters</code></dt><dd><p>A <code>list</code> containg all parameters used to fit the model.</p>
</dd>
<dt><code>params</code></dt><dd><p>A <code>list</code> containing default, set, and actual parameters.</p>
</dd>
<dt><code>have_pojo</code></dt><dd><p>A <code>logical</code> indicating whether export to POJO is supported</p>
</dd>
<dt><code>have_mojo</code></dt><dd><p>A <code>logical</code> indicating whether export to MOJO is supported</p>
</dd>
<dt><code>model</code></dt><dd><p>A <code>list</code> containing the characteristics of the model returned by the algorithm.</p>
</dd>
</dl>

<hr>
<h2 id='H2OModelFuture-class'>H2O Future Model</h2><span id='topic+H2OModelFuture-class'></span>

<h3>Description</h3>

<p>A class to contain the information for background model jobs.
</p>


<h3>Slots</h3>


<dl>
<dt><code>job_key</code></dt><dd><p>a character key representing the identification of the job process.</p>
</dd>
<dt><code>model_id</code></dt><dd><p>the final identifier for the model</p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+H2OModel-class">H2OModel</a> for the final model types.
</p>

<hr>
<h2 id='H2OModelMetrics-class'>The H2OModelMetrics Object.</h2><span id='topic+H2OModelMetrics-class'></span><span id='topic+H2OModelMetrics'></span><span id='topic+show+2CH2OModelMetrics-method'></span><span id='topic+H2OUnknownMetrics-class'></span><span id='topic+H2OBinomialMetrics-class'></span><span id='topic+show+2CH2OBinomialMetrics-method'></span><span id='topic+H2OBinomialUpliftMetrics-class'></span><span id='topic+show+2CH2OBinomialUpliftMetrics-method'></span><span id='topic+H2OMultinomialMetrics-class'></span><span id='topic+show+2CH2OMultinomialMetrics-method'></span><span id='topic+H2OOrdinalMetrics-class'></span><span id='topic+show+2CH2OOrdinalMetrics-method'></span><span id='topic+H2ORegressionMetrics-class'></span><span id='topic+show+2CH2ORegressionMetrics-method'></span><span id='topic+H2OClusteringMetrics-class'></span><span id='topic+show+2CH2OClusteringMetrics-method'></span><span id='topic+H2OAutoEncoderMetrics-class'></span><span id='topic+show+2CH2OAutoEncoderMetrics-method'></span><span id='topic+H2ODimReductionMetrics-class'></span><span id='topic+show+2CH2ODimReductionMetrics-method'></span><span id='topic+H2OWordEmbeddingMetrics-class'></span><span id='topic+H2OCoxPHMetrics-class'></span><span id='topic+H2OAnomalyDetectionMetrics-class'></span><span id='topic+show+2CH2OAnomalyDetectionMetrics-method'></span><span id='topic+H2OTargetEncoderMetrics-class'></span>

<h3>Description</h3>

<p>A class for constructing performance measures of H2O models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModelMetrics'
show(object)

## S4 method for signature 'H2OBinomialMetrics'
show(object)

## S4 method for signature 'H2OBinomialUpliftMetrics'
show(object)

## S4 method for signature 'H2OMultinomialMetrics'
show(object)

## S4 method for signature 'H2OOrdinalMetrics'
show(object)

## S4 method for signature 'H2ORegressionMetrics'
show(object)

## S4 method for signature 'H2OClusteringMetrics'
show(object)

## S4 method for signature 'H2OAutoEncoderMetrics'
show(object)

## S4 method for signature 'H2ODimReductionMetrics'
show(object)

## S4 method for signature 'H2OAnomalyDetectionMetrics'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OModelMetrics-class_+3A_object">object</code></td>
<td>
<p>An <code>H2OModelMetrics</code> object</p>
</td></tr>
</table>

<hr>
<h2 id='H2ONode-class'>The H2ONode class.</h2><span id='topic+H2ONode-class'></span><span id='topic+show+2CH2ONode-method'></span>

<h3>Description</h3>

<p>The H2ONode class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2ONode'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2ONode-class_+3A_object">object</code></td>
<td>
<p>an <code>H2ONode</code> object.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>id</code></dt><dd><p>An <code>integer</code> representing node's unique identifier. Generated by H2O.</p>
</dd>
<dt><code>levels</code></dt><dd><p>A <code>character</code> representing categorical levels on split from parent's node belonging into this node. NULL for root node or non-categorical splits.
</p>
<p>#' @aliases H2ONode</p>
</dd>
</dl>

<hr>
<h2 id='H2OSegmentModels-class'>H2O Segment Models</h2><span id='topic+H2OSegmentModels-class'></span><span id='topic+show+2CH2OSegmentModels-method'></span>

<h3>Description</h3>

<p>A class to contain the information for segment models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OSegmentModels'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OSegmentModels-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OModel</code> object.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>segment_models_id</code></dt><dd><p>the  identifier for the segment models collections</p>
</dd>
</dl>

<hr>
<h2 id='H2OSegmentModelsFuture-class'>H2O Future Segment Models</h2><span id='topic+H2OSegmentModelsFuture-class'></span>

<h3>Description</h3>

<p>A class to contain the information for background segment models jobs.
</p>


<h3>Slots</h3>


<dl>
<dt><code>job_key</code></dt><dd><p>a character key representing the identification of the job process.</p>
</dd>
<dt><code>segment_models_id</code></dt><dd><p>the final identifier for the segment models collections</p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+H2OSegmentModels-class">H2OSegmentModels</a> for the final segment models types.
</p>

<hr>
<h2 id='H2OSplitNode-class'>The H2OSplitNode class.</h2><span id='topic+H2OSplitNode-class'></span><span id='topic+H2OSplitNode'></span>

<h3>Description</h3>

<p>This class represents a single non-terminal node in an <code>H2OTree</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>threshold</code></dt><dd><p>A <code>numeric</code> split threshold, typically when the split column is numerical.</p>
</dd>
<dt><code>left_child</code></dt><dd><p>A <code>H2ONodeOrNULL</code> representing the left child node, if a node has one.</p>
</dd>
<dt><code>right_child</code></dt><dd><p>A <code>H2ONodeOrNULL</code> representing the right child node, if a node has one.</p>
</dd>
<dt><code>split_feature</code></dt><dd><p>A <code>character</code> representing the name of the column this node splits on.</p>
</dd>
<dt><code>left_levels</code></dt><dd><p>A <code>character</code> representing the levels of a categorical feature heading to the left child of this node. NA for non-categorical split.</p>
</dd>
<dt><code>right_levels</code></dt><dd><p>A <code>character</code> representing the levels of a categorical feature heading to the right child of this node. NA for non-categorical split.</p>
</dd>
<dt><code>na_direction</code></dt><dd><p>A <code>character</code> representing the direction of NA values. LEFT means NA values go to the left child node, RIGH means NA values go to the right child node.</p>
</dd>
</dl>

<hr>
<h2 id='H2OTree-class'>The H2OTree class.</h2><span id='topic+H2OTree-class'></span><span id='topic+H2OTree'></span><span id='topic+show+2CH2OTree-method'></span>

<h3>Description</h3>

<p>This class represents a model of a Tree built by one of H2O's algorithms (GBM, Random Forest).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OTree'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="H2OTree-class_+3A_object">object</code></td>
<td>
<p>an <code>H2OTree</code> object.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>root_node</code></dt><dd><p>A <code>H2ONode</code> representing the beginning of the tree behind the model. Allows further tree traversal.</p>
</dd>
<dt><code>left_children</code></dt><dd><p>An <code>integer</code> vector with left child nodes of tree's nodes</p>
</dd>
<dt><code>right_children</code></dt><dd><p>An <code>integer</code> vector with right child nodes of tree's nodes</p>
</dd>
<dt><code>node_ids</code></dt><dd><p>An <code>integer</code> representing identification number of a node. Node IDs are generated by H2O.</p>
</dd>
<dt><code>descriptions</code></dt><dd><p>A <code>character</code> vector with descriptions for each node to be found in the tree. Contains split threshold if the split is based on numerical column.
For cactegorical splits, it contains list of categorical levels for transition from the parent node.</p>
</dd>
<dt><code>model_id</code></dt><dd><p>A <code>character</code> with the name of the model this tree is related to.</p>
</dd>
<dt><code>tree_number</code></dt><dd><p>An <code>integer</code> representing the order in which the tree has been built in the model.</p>
</dd>
<dt><code>tree_class</code></dt><dd><p>A <code>character</code> representing name of tree's class. Number of tree classes equals to the number of levels in categorical response column.
As there is exactly one class per categorical level, name of tree's class equals to the corresponding categorical level of response column.
In case of regression and binomial, the name of the categorical level is ignored can be omitted, as there is exactly one tree built in both cases.</p>
</dd>
<dt><code>thresholds</code></dt><dd><p>A <code>numeric</code> split thresholds. Split thresholds are not only related to numerical splits, but might be present in case of categorical split as well.</p>
</dd>
<dt><code>features</code></dt><dd><p>A <code>character</code> with names of the feature/column used for the split.</p>
</dd>
<dt><code>levels</code></dt><dd><p>A <code>character</code> representing categorical levels on split from parent's node belonging into this node. NULL for root node or non-categorical splits.</p>
</dd>
<dt><code>nas</code></dt><dd><p>A <code>character</code> representing if NA values go to the left node or right node. May be NA if node is a leaf.</p>
</dd>
<dt><code>predictions</code></dt><dd><p>A <code>numeric</code> representing predictions for each node in the graph.</p>
</dd>
<dt><code>tree_decision_path</code></dt><dd><p>A <code>character</code>, plain language rules representation of a trained decision tree</p>
</dd>
<dt><code>decision_paths</code></dt><dd><p>A <code>character</code> representing plain language rules that were used in a particular prediction.</p>
</dd>
<dt><code>left_cat_split</code></dt><dd><p>A <code>character</code> list of categorical levels leading to the left child node. Only present when split is categorical, otherwise none.</p>
</dd>
<dt><code>right_cat_split</code></dt><dd><p>A <code>character</code> list of categorical levels leading to the right child node. Only present when split is categorical, otherwise none.</p>
</dd>
</dl>

<hr>
<h2 id='housevotes'>United States Congressional Voting Records 1984</h2><span id='topic+housevotes'></span>

<h3>Description</h3>

<p>This data set includes votes for each of the U.S. House of Representatives Congressmen on the 16 
key votes identified by the CQA. The CQA lists nine different types of votes: voted for, paired for, 
and announced for (these three simplified to yea), voted against, paired against, and announced 
against (these three simplified to nay), voted present, voted present to avoid conflict of interest, 
and did not vote or otherwise make a position known (these three simplified to an unknown disposition).
</p>


<h3>Format</h3>

<p>A data frame with 435 rows and 17 columns
</p>


<h3>Source</h3>

<p>Congressional Quarterly Almanac, 98th Congress, 2nd session 1984, Volume XL: Congressional Quarterly Inc., Washington, D.C., 1985
</p>


<h3>References</h3>

<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998). UCI Repository of machine 
learning databases [https://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University of 
California, Department of Information and Computer Science.
</p>

<hr>
<h2 id='initialize+2CH2OInfogram-method'>Method on <code>H2OInfogram</code> object which in this case is to instantiate and initialize it</h2><span id='topic+initialize+2CH2OInfogram-method'></span>

<h3>Description</h3>

<p>Method on <code>H2OInfogram</code> object which in this case is to instantiate and initialize it
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OInfogram'
initialize(.Object, model_id, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initialize+2B2CH2OInfogram-method_+3A_.object">.Object</code></td>
<td>
<p>An <code>H2OInfogram</code> object</p>
</td></tr>
<tr><td><code id="initialize+2B2CH2OInfogram-method_+3A_model_id">model_id</code></td>
<td>
<p>string returned as part of every H2OModel</p>
</td></tr>
<tr><td><code id="initialize+2B2CH2OInfogram-method_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>H2OInfogram</code> object
</p>

<hr>
<h2 id='iris'>Edgar Anderson's Iris Data</h2><span id='topic+iris'></span>

<h3>Description</h3>

<p>Measurements in centimeters of the sepal length and width and petal length and width, 
respectively, for three species of iris flowers.
</p>


<h3>Format</h3>

<p>A data frame with 150 rows and 5 columns
</p>


<h3>Source</h3>

<p>Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, Part II, 179-188.
</p>
<p>The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2-5.
</p>

<hr>
<h2 id='is.character'>Check if character</h2><span id='topic+is.character'></span>

<h3>Description</h3>

<p>Check if character
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.character(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.character_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv"
heart &lt;- h2o.importFile(f)

heart["transplant"] &lt;- as.character(heart["transplant"])
is.character(heart["transplant"])

## End(Not run)
</code></pre>

<hr>
<h2 id='is.factor'>Check if factor</h2><span id='topic+is.factor'></span>

<h3>Description</h3>

<p>Check if factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.factor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.factor_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
cars["economy_20mpg"] &lt;- as.factor(cars["economy_20mpg"])
is.factor(cars["economy_20mpg"])

## End(Not run)
</code></pre>

<hr>
<h2 id='is.h2o'>Is H2O Frame object</h2><span id='topic+is.h2o'></span>

<h3>Description</h3>

<p>Test if object is H2O Frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.h2o(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.h2o_+3A_x">x</code></td>
<td>
<p>An <code>R</code> object.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
is.h2o(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='is.numeric'>Check if numeric</h2><span id='topic+is.numeric'></span>

<h3>Description</h3>

<p>Check if numeric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.numeric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.numeric_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
</table>

<hr>
<h2 id='Keyed-class'>Virtual Keyed class</h2><span id='topic+Keyed-class'></span>

<h3>Description</h3>

<p>Base class for all objects having a persistent representation on backend.
</p>

<hr>
<h2 id='length+2CH2OTree-method'>Overrides the behavior of length() function on H2OTree class. Returns number of nodes in an <code>H2OTree</code></h2><span id='topic+length+2CH2OTree-method'></span>

<h3>Description</h3>

<p>Overrides the behavior of length() function on H2OTree class. Returns number of nodes in an <code>H2OTree</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OTree'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="length+2B2CH2OTree-method_+3A_x">x</code></td>
<td>
<p>An <code>H2OTree</code> to count nodes for.</p>
</td></tr>
</table>

<hr>
<h2 id='Logical-or'>Logical or for H2OFrames</h2><span id='topic+Logical-or'></span><span id='topic++7C+7C'></span>

<h3>Description</h3>

<p>Logical or for H2OFrames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>`||`(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Logical-or_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="Logical-or_+3A_y">y</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
</table>

<hr>
<h2 id='model_cache-class'>Needed to be able to memoise the models</h2><span id='topic+model_cache-class'></span><span id='topic+.model_cache'></span>

<h3>Description</h3>

<p>Needed to be able to memoise the models
</p>

<hr>
<h2 id='ModelAccessors'>Accessor Methods for H2OModel Object</h2><span id='topic+ModelAccessors'></span><span id='topic+getParms'></span><span id='topic+getParms+2CH2OModel-method'></span><span id='topic+getCenters'></span><span id='topic+getCentersStd'></span><span id='topic+getWithinSS'></span><span id='topic+getTotWithinSS'></span><span id='topic+getBetweenSS'></span><span id='topic+getTotSS'></span><span id='topic+getIterations'></span><span id='topic+getClusterSizes'></span><span id='topic+getCenters+2CH2OClusteringModel-method'></span><span id='topic+getCentersStd+2CH2OClusteringModel-method'></span><span id='topic+getWithinSS+2CH2OClusteringModel-method'></span><span id='topic+getTotWithinSS+2CH2OClusteringModel-method'></span><span id='topic+getBetweenSS+2CH2OClusteringModel-method'></span><span id='topic+getTotSS+2CH2OClusteringModel-method'></span><span id='topic+getIterations+2CH2OClusteringModel-method'></span><span id='topic+getClusterSizes+2CH2OClusteringModel-method'></span>

<h3>Description</h3>

<p>Function accessor methods for various H2O output fields.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getParms(object)

## S4 method for signature 'H2OModel'
getParms(object)

getCenters(object)

getCentersStd(object)

getWithinSS(object)

getTotWithinSS(object)

getBetweenSS(object)

getTotSS(object)

getIterations(object)

getClusterSizes(object)

## S4 method for signature 'H2OClusteringModel'
getCenters(object)

## S4 method for signature 'H2OClusteringModel'
getCentersStd(object)

## S4 method for signature 'H2OClusteringModel'
getWithinSS(object)

## S4 method for signature 'H2OClusteringModel'
getTotWithinSS(object)

## S4 method for signature 'H2OClusteringModel'
getBetweenSS(object)

## S4 method for signature 'H2OClusteringModel'
getTotSS(object)

## S4 method for signature 'H2OClusteringModel'
getIterations(object)

## S4 method for signature 'H2OClusteringModel'
getClusterSizes(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ModelAccessors_+3A_object">object</code></td>
<td>
<p>an <a href="#topic+H2OModel-class">H2OModel</a> class object.</p>
</td></tr>
</table>

<hr>
<h2 id='names.H2OFrame'>Column names of an H2OFrame</h2><span id='topic+names.H2OFrame'></span>

<h3>Description</h3>

<p>Column names of an H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
names(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="names.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
names(frame)

## End(Not run)
</code></pre>

<hr>
<h2 id='Ops.H2OFrame'>S3 Group Generic Functions for H2O</h2><span id='topic+Ops.H2OFrame'></span><span id='topic+Math.H2OFrame'></span><span id='topic+Summary.H2OFrame'></span><span id='topic++21.H2OFrame'></span><span id='topic+is.na.H2OFrame'></span><span id='topic+t.H2OFrame'></span><span id='topic+log'></span><span id='topic+log10'></span><span id='topic+log2'></span><span id='topic+log1p'></span><span id='topic+trunc'></span><span id='topic++25+2A+25'></span><span id='topic+nrow.H2OFrame'></span><span id='topic+ncol.H2OFrame'></span><span id='topic+length.H2OFrame'></span><span id='topic+h2o.length'></span><span id='topic+names+3C-.H2OFrame'></span><span id='topic+colnames+3C-'></span>

<h3>Description</h3>

<p>Methods for group generic functions and H2O objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
Ops(e1, e2)

## S3 method for class 'H2OFrame'
Math(x, ...)

## S3 method for class 'H2OFrame'
Math(x, ...)

## S3 method for class 'H2OFrame'
Math(x, ...)

## S3 method for class 'H2OFrame'
Summary(x, ..., na.rm)

## S3 method for class 'H2OFrame'
!x

## S3 method for class 'H2OFrame'
is.na(x)

## S3 method for class 'H2OFrame'
t(x)

log(x, ...)

log10(x)

log2(x)

log1p(x)

trunc(x, ...)

x %*% y

nrow.H2OFrame(x)

ncol.H2OFrame(x)

## S3 method for class 'H2OFrame'
length(x)

h2o.length(x)

## S3 replacement method for class 'H2OFrame'
names(x) &lt;- value

colnames(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ops.H2OFrame_+3A_e1">e1</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_e2">e2</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_x">x</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. whether or not missing values should be removed</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_y">y</code></td>
<td>
<p>object</p>
</td></tr>
<tr><td><code id="Ops.H2OFrame_+3A_value">value</code></td>
<td>
<p>To be assigned</p>
</td></tr>
</table>

<hr>
<h2 id='plot+2CH2OParetoFront-method'>Plot Pareto front</h2><span id='topic+plot+2CH2OParetoFront-method'></span>

<h3>Description</h3>

<p>Plot Pareto front
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OParetoFront'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B2CH2OParetoFront-method_+3A_x">x</code></td>
<td>
<p><code>H2OParetoFront</code> object</p>
</td></tr>
<tr><td><code id="plot+2B2CH2OParetoFront-method_+3A_y">y</code></td>
<td>
<p>missing</p>
</td></tr>
<tr><td><code id="plot+2B2CH2OParetoFront-method_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>

<hr>
<h2 id='plot.H2OInfogram'>Plot an H2O Infogram</h2><span id='topic+plot.H2OInfogram'></span>

<h3>Description</h3>

<p>Plots the Infogram for an H2OInfogram object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OInfogram'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.H2OInfogram_+3A_x">x</code></td>
<td>
<p>A fitted <a href="#topic+H2OInfogram-class">H2OInfogram</a> object.</p>
</td></tr>
<tr><td><code id="plot.H2OInfogram_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot2 object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.infogram">h2o.infogram</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
h2o.init()

# Convert iris dataset to an H2OFrame
train &lt;- as.h2o(iris)

# Create and plot infogram
ig &lt;- h2o.infogram(y = "Species", training_frame = train)
plot(ig)


## End(Not run)
</code></pre>

<hr>
<h2 id='plot.H2OModel'>Plot an H2O Model</h2><span id='topic+plot.H2OModel'></span>

<h3>Description</h3>

<p>Plots training set (and validation set if available) scoring history for an H2O Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OModel'
plot(x, timestep = "AUTO", metric = "AUTO", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.H2OModel_+3A_x">x</code></td>
<td>
<p>A fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which the scoring history plot is desired.</p>
</td></tr>
<tr><td><code id="plot.H2OModel_+3A_timestep">timestep</code></td>
<td>
<p>A unit of measurement for the x-axis.</p>
</td></tr>
<tr><td><code id="plot.H2OModel_+3A_metric">metric</code></td>
<td>
<p>A unit of measurement for the y-axis.</p>
</td></tr>
<tr><td><code id="plot.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method dispatches on the type of H2O model to select the correct
scoring history.  The <code>timestep</code> and <code>metric</code> arguments are restricted to what is
available in the scoring history for a particular type of model.
</p>


<h3>Value</h3>

<p>Returns a scoring history plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.deeplearning">h2o.deeplearning</a></code>, <code><a href="#topic+h2o.gbm">h2o.gbm</a></code>,
<code><a href="#topic+h2o.glm">h2o.glm</a></code>, <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if (requireNamespace("mlbench", quietly=TRUE)) {
    library(h2o)
    h2o.init()

    df &lt;- as.h2o(mlbench::mlbench.friedman1(10000, 1))
    rng &lt;- h2o.runif(df, seed = 1234)
    train &lt;- df[rng &lt; 0.8,]
    valid &lt;- df[rng &gt;= 0.8,]

    gbm &lt;- h2o.gbm(x = 1:10, y = "y", training_frame = train, validation_frame = valid,
                   ntrees = 500, learn_rate = 0.01, score_each_iteration = TRUE)
    plot(gbm)
    plot(gbm, timestep = "duration", metric = "deviance")
    plot(gbm, timestep = "number_of_trees", metric = "deviance")
    plot(gbm, timestep = "number_of_trees", metric = "rmse")
    plot(gbm, timestep = "number_of_trees", metric = "mae")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.H2OTabulate'>Plot an H2O Tabulate Heatmap</h2><span id='topic+plot.H2OTabulate'></span>

<h3>Description</h3>

<p>Plots the simple co-occurrence based tabulation of X vs Y as a heatmap, where X and Y are two Vecs in a given dataset. This function requires suggested ggplot2 package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OTabulate'
plot(x, xlab = x$cols[1], ylab = x$cols[2], base_size = 12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.H2OTabulate_+3A_x">x</code></td>
<td>
<p>An H2OTabulate object for which the heatmap plot is desired.</p>
</td></tr>
<tr><td><code id="plot.H2OTabulate_+3A_xlab">xlab</code></td>
<td>
<p>A title for the x-axis.  Defaults to what is specified in the given H2OTabulate object.</p>
</td></tr>
<tr><td><code id="plot.H2OTabulate_+3A_ylab">ylab</code></td>
<td>
<p>A title for the y-axis.  Defaults to what is specified in the given H2OTabulate object.</p>
</td></tr>
<tr><td><code id="plot.H2OTabulate_+3A_base_size">base_size</code></td>
<td>
<p>Base font size for plot.</p>
</td></tr>
<tr><td><code id="plot.H2OTabulate_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a ggplot2-based heatmap of co-occurance.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.tabulate">h2o.tabulate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
df &lt;- as.h2o(iris)
tab &lt;- h2o.tabulate(data = df, x = "Sepal.Length", y = "Petal.Width",
             weights_column = NULL, nbins_x = 10, nbins_y = 10)
plot(tab)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict_contributions.H2OModel'>Predict feature contributions - SHAP values on an H2O Model (only DRF, GBM, XGBoost models and equivalent imported MOJOs).</h2><span id='topic+predict_contributions.H2OModel'></span><span id='topic+h2o.predict_contributions'></span>

<h3>Description</h3>

<p>Default implemntation return H2OFrame shape (#rows, #features + 1) - there is a feature contribution column for each input
feature, the last column is the model bias (same value for each row). The sum of the feature contributions
and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum
of the predictions of the individual trees before the inverse link function is applied to get the actual
prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_contributions.H2OModel(
  object,
  newdata,
  output_format = c("compact", "original"),
  top_n = 0,
  bottom_n = 0,
  compare_abs = FALSE,
  background_frame = NULL,
  output_space = FALSE,
  output_per_reference = FALSE,
  ...
)

h2o.predict_contributions(
  object,
  newdata,
  output_format = c("compact", "original"),
  top_n = 0,
  bottom_n = 0,
  compare_abs = FALSE,
  background_frame = NULL,
  output_space = FALSE,
  output_per_reference = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_contributions.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_output_format">output_format</code></td>
<td>
<p>Specify how to output feature contributions in XGBoost - XGBoost by default outputs
contributions for 1-hot encoded features, specifying a compact output format will produce
a per-feature contribution. Defaults to original.</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_top_n">top_n</code></td>
<td>
<p>Return only #top_n highest contributions + bias
If top_n&lt;0 then sort all SHAP values in descending order
If top_n&lt;0 &amp;&amp; bottom_n&lt;0 then sort all SHAP values in descending order</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_bottom_n">bottom_n</code></td>
<td>
<p>Return only #bottom_n lowest contributions + bias
If top_n and bottom_n are defined together then return array of #top_n + #bottom_n + bias
If bottom_n&lt;0 then sort all SHAP values in ascending order
If top_n&lt;0 &amp;&amp; bottom_n&lt;0 then sort all SHAP values in descending order</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_compare_abs">compare_abs</code></td>
<td>
<p>True to compare absolute values of contributions</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_background_frame">background_frame</code></td>
<td>
<p>Optional frame, that is used as the source of baselines for
the baseline SHAP (when output_per_reference == TRUE) or for
the marginal SHAP (when output_per_reference == FALSE).</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_output_space">output_space</code></td>
<td>
<p>If TRUE, linearly scale the contributions so that they sum up to the prediction.
NOTE: This will result only in approximate SHAP values even if the model supports exact SHAP calculation.
NOTE: This will not have any effect if the estimator doesn't use a link function.</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_output_per_reference">output_per_reference</code></td>
<td>
<p>If TRUE, return baseline SHAP, i.e., contribution for each data point for each reference from the background_frame.
If FALSE, return TreeSHAP if no background_frame is provided, or marginal SHAP if background frame is provided.
Can be used only with background_frame.</p>
</td></tr>
<tr><td><code id="predict_contributions.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: Multinomial classification models are currently not supported.
</p>


<h3>Value</h3>

<p>Returns an H2OFrame contain feature contributions for each input row.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.gbm">h2o.gbm</a></code> and  <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate_gbm &lt;- h2o.gbm(3:9, "AGE", prostate)
h2o.predict(prostate_gbm, prostate)
# Compute SHAP
h2o.predict_contributions(prostate_gbm, prostate)
# Compute SHAP and pick the top two highest
h2o.predict_contributions(prostate_gbm, prostate, top_n=2)
# Compute SHAP and pick the top two lowest
h2o.predict_contributions(prostate_gbm, prostate, bottom_n=2)
# Compute SHAP and pick the top two highest regardless of the sign
h2o.predict_contributions(prostate_gbm, prostate, top_n=2, compare_abs=TRUE)
# Compute SHAP and pick the top two lowest regardless of the sign
h2o.predict_contributions(prostate_gbm, prostate, bottom_n=2, compare_abs=TRUE)
# Compute SHAP values and show them all in descending order
h2o.predict_contributions(prostate_gbm, prostate, top_n=-1)
# Compute SHAP and pick the top two highest and top two lowest
h2o.predict_contributions(prostate_gbm, prostate, top_n=2, bottom_n=2)

# Compute Marginal SHAP, this enables looking at the contributions against different
# baselines, e.g., older people in the following example
h2o.predict_contributions(prostate_gbm, prostate, background_frame=prostate[prostate$AGE &gt; 75, ])

## End(Not run)
</code></pre>

<hr>
<h2 id='predict_leaf_node_assignment.H2OModel'>Predict the Leaf Node Assignment on an H2O Model</h2><span id='topic+predict_leaf_node_assignment.H2OModel'></span><span id='topic+h2o.predict_leaf_node_assignment'></span>

<h3>Description</h3>

<p>Obtains leaf node assignment from fitted H2O model objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_leaf_node_assignment.H2OModel(
  object,
  newdata,
  type = c("Path", "Node_ID"),
  ...
)

h2o.predict_leaf_node_assignment(
  object,
  newdata,
  type = c("Path", "Node_ID"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_leaf_node_assignment.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="predict_leaf_node_assignment.H2OModel_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict_leaf_node_assignment.H2OModel_+3A_type">type</code></td>
<td>
<p>choice of either &quot;Path&quot; when tree paths are to be returned (default); or &quot;Node_ID&quot; when the output</p>
</td></tr>
<tr><td><code id="predict_leaf_node_assignment.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every row in the test set, return the leaf placements of the row in all the trees in the model.
Placements can be represented either by paths to the leaf nodes from the tree root or by H2O's internal identifiers.
The order of the rows in the results is the same as the order in which the
data was loaded
</p>


<h3>Value</h3>

<p>Returns an H2OFrame object with categorical leaf assignment identifiers for
each tree in the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.gbm">h2o.gbm</a></code> and  <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
prostate_gbm &lt;- h2o.gbm(3:9, "CAPSULE", prostate)
h2o.predict(prostate_gbm, prostate)
h2o.predict_leaf_node_assignment(prostate_gbm, prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.H2OAutoML'>Predict on an AutoML object</h2><span id='topic+predict.H2OAutoML'></span><span id='topic+h2o.predict.H2OAutoML'></span>

<h3>Description</h3>

<p>Obtains predictions from an AutoML object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OAutoML'
predict(object, newdata, ...)

## S3 method for class 'H2OAutoML'
h2o.predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.H2OAutoML_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OAutoML-class">H2OAutoML</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="predict.H2OAutoML_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.H2OAutoML_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method generated predictions on the leader model from an AutoML run.
The order of the rows in the results is the same as the order in which the
data was loaded, even if some rows fail (for example, due to missing
values or unseen factor levels).
</p>


<h3>Value</h3>

<p>Returns an H2OFrame object with probabilites and
default predictions.
</p>

<hr>
<h2 id='predict.H2OModel'>Predict on an H2O Model</h2><span id='topic+predict.H2OModel'></span><span id='topic+h2o.predict.H2OModel'></span>

<h3>Description</h3>

<p>Obtains predictions from various fitted H2O model objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OModel'
predict(object, newdata, ...)

## S3 method for class 'H2OModel'
h2o.predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="predict.H2OModel_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="predict.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method dispatches on the type of H2O model to select the correct
prediction/scoring algorithm.
The order of the rows in the results is the same as the order in which the
data was loaded, even if some rows fail (for example, due to missing
values or unseen factor levels).
</p>


<h3>Value</h3>

<p>Returns an H2OFrame object with probabilites and
default predictions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.deeplearning">h2o.deeplearning</a></code>, <code><a href="#topic+h2o.gbm">h2o.gbm</a></code>,
<code><a href="#topic+h2o.glm">h2o.glm</a></code>, <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/glm_test/insurance.csv"
insurance &lt;- h2o.importFile(f)
predictors &lt;- colnames(insurance)[1:4]
response &lt;- "Claims"
insurance['Group'] &lt;- as.factor(insurance['Group'])
insurance['Age'] &lt;- as.factor(insurance['Age'])
splits &lt;- h2o.splitFrame(data =  insurance, ratios = 0.8, seed = 1234)
train &lt;- splits[[1]]
valid &lt;- splits[[2]]
insurance_gbm &lt;- h2o.gbm(x = predictors, y = response, 
                         training_frame = train,
                         validation_frame = valid, 
                         distribution = "huber", 
                         huber_alpha = 0.9, seed = 1234)
h2o.predict(insurance_gbm, newdata = insurance)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.H2OFrame'>Print An H2OFrame</h2><span id='topic+print.H2OFrame'></span>

<h3>Description</h3>

<p>Print An H2OFrame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
print(x, n = 6L, m = 200L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.H2OFrame_+3A_x">x</code></td>
<td>
<p>An H2OFrame object</p>
</td></tr>
<tr><td><code id="print.H2OFrame_+3A_n">n</code></td>
<td>
<p>An (Optional) A single integer. If positive, number of rows in x to return. If negative, all but the n first/last number of rows in x.
Anything bigger than 20 rows will require asking the server (first 20 rows are cached on the client).</p>
</td></tr>
<tr><td><code id="print.H2OFrame_+3A_m">m</code></td>
<td>
<p>An (Optional) A single integer. If positive, number of columns in x to return. If negative, all but the m first/last number of columns in x.</p>
</td></tr>
<tr><td><code id="print.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
print(cars, n = 8)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.H2OTable'>Print method for H2OTable objects</h2><span id='topic+print.H2OTable'></span>

<h3>Description</h3>

<p>This will print a truncated view of the table if there are more than 20 rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OTable'
print(x, header = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.H2OTable_+3A_x">x</code></td>
<td>
<p>An H2OTable object</p>
</td></tr>
<tr><td><code id="print.H2OTable_+3A_header">header</code></td>
<td>
<p>A logical value dictating whether or not the table name should be printed.</p>
</td></tr>
<tr><td><code id="print.H2OTable_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original x object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

f &lt;- "https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv"
cars &lt;- h2o.importFile(f)
print(cars, header = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='prostate'>Prostate Cancer Study</h2><span id='topic+prostate'></span>

<h3>Description</h3>

<p>Baseline exam results on prostate cancer patients from Dr. Donn Young at The Ohio State 
University Comprehensive Cancer Center.
</p>


<h3>Format</h3>

<p>A data frame with 380 rows and 9 columns
</p>


<h3>Source</h3>

<p>Hosmer and Lemeshow (2000) Applied Logistic Regression: Second Edition.
</p>

<hr>
<h2 id='range.H2OFrame'>Range of an H2O Column</h2><span id='topic+range.H2OFrame'></span>

<h3>Description</h3>

<p>Range of an H2O Column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
range(..., na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="range.H2OFrame_+3A_...">...</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="range.H2OFrame_+3A_na.rm">na.rm</code></td>
<td>
<p>ignore missing values</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()

frame &lt;- h2o.createFrame(rows = 6, cols = 2,
                         categorical_fraction = 0.0, 
                         missing_fraction = 0.7, 
                         seed = 123)
range(frame, na.rm = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='row_to_tree_assignment.H2OModel'>Output row to tree assignment for the model and provided training data.</h2><span id='topic+row_to_tree_assignment.H2OModel'></span><span id='topic+h2o.row_to_tree_assignment'></span>

<h3>Description</h3>

<p>Output is frame of size nrow = nrow(original_training_data) and ncol = number_of_trees_in_model+1 in format: 
row_id    tree_1    tree_2    tree_3
0         0         1         1
1         1         1         1
2         1         0         0
3         1         1         0
4         0         1         1
5         1         1         1
6         1         0         0
7         0         1         0
8         0         1         1
9         1         0         0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>row_to_tree_assignment.H2OModel(object, original_training_data, ...)

h2o.row_to_tree_assignment(object, original_training_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="row_to_tree_assignment.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object</p>
</td></tr>
<tr><td><code id="row_to_tree_assignment.H2OModel_+3A_original_training_data">original_training_data</code></td>
<td>
<p>An H2OFrame object that was used for model training. Currently there is no validation of the input.</p>
</td></tr>
<tr><td><code id="row_to_tree_assignment.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Where 1 in the tree_{number} cols means row is used in the tree and 0 means that row is not used.
The structure of the output depends on sample_rate or sample_size parameter setup.
</p>
<p>Note: Multinomial classification generate tree for each category, each tree use the same sample of the data.
</p>


<h3>Value</h3>

<p>Returns an H2OFrame contain row to tree assignment for each tree and row.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate_gbm &lt;- h2o.gbm(4:9, "AGE", prostate, sample_rate = 0.6)
# Get row to tree assignment
h2o.row_to_tree_assignment(prostate_gbm, prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='scale'>Scaling and Centering of an H2OFrame</h2><span id='topic+scale'></span><span id='topic+scale.H2OFrame'></span>

<h3>Description</h3>

<p>Centers and/or scales the columns of an H2O dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
scale(x, center = TRUE, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scale_+3A_x">x</code></td>
<td>
<p>An H2OFrame object.</p>
</td></tr>
<tr><td><code id="scale_+3A_center">center</code></td>
<td>
<p>either a <code>logical</code> value or numeric vector of length equal to the number of columns of x.</p>
</td></tr>
<tr><td><code id="scale_+3A_scale">scale</code></td>
<td>
<p>either a <code>logical</code> value or numeric vector of length equal to the number of columns of x.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
iris_hf &lt;- as.h2o(iris)
summary(iris_hf)

# Scale and center all the numeric columns in iris data set
iris_scaled &lt;- scale(iris_hf[, 1:4])

## End(Not run)
</code></pre>

<hr>
<h2 id='show+2CH2OAutoML-method'>Format AutoML object in user-friendly way</h2><span id='topic+show+2CH2OAutoML-method'></span>

<h3>Description</h3>

<p>Format AutoML object in user-friendly way
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OAutoML'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2CH2OAutoML-method_+3A_object">object</code></td>
<td>
<p>an <code>H2OAutoML</code> object.</p>
</td></tr>
</table>

<hr>
<h2 id='show+2CH2OParetoFront-method'>Show H2OParetoFront</h2><span id='topic+show+2CH2OParetoFront-method'></span>

<h3>Description</h3>

<p>Show H2OParetoFront
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OParetoFront'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2CH2OParetoFront-method_+3A_object">object</code></td>
<td>
<p><code>H2OParetoFront</code> object</p>
</td></tr>
</table>

<hr>
<h2 id='staged_predict_proba.H2OModel'>Predict class probabilities at each stage of an H2O Model</h2><span id='topic+staged_predict_proba.H2OModel'></span><span id='topic+h2o.staged_predict_proba'></span>

<h3>Description</h3>

<p>The output structure is analogous to the output of <a href="#topic+h2o.predict_leaf_node_assignment">h2o.predict_leaf_node_assignment</a>. For each tree t and
class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding
predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models build
the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>staged_predict_proba.H2OModel(object, newdata, ...)

h2o.staged_predict_proba(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="staged_predict_proba.H2OModel_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+H2OModel-class">H2OModel</a> object for which prediction is
desired</p>
</td></tr>
<tr><td><code id="staged_predict_proba.H2OModel_+3A_newdata">newdata</code></td>
<td>
<p>An H2OFrame object in which to look for
variables with which to predict.</p>
</td></tr>
<tr><td><code id="staged_predict_proba.H2OModel_+3A_...">...</code></td>
<td>
<p>additional arguments to pass on.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an H2OFrame object with predicted probability for each tree in the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+h2o.gbm">h2o.gbm</a></code> and  <code><a href="#topic+h2o.randomForest">h2o.randomForest</a></code> for model
generation in h2o.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.uploadFile(path = prostate_path)
prostate$CAPSULE &lt;- as.factor(prostate$CAPSULE)
prostate_gbm &lt;- h2o.gbm(3:9, "CAPSULE", prostate)
h2o.predict(prostate_gbm, prostate)
h2o.staged_predict_proba(prostate_gbm, prostate)

## End(Not run)
</code></pre>

<hr>
<h2 id='str.H2OFrame'>Display the structure of an H2OFrame object</h2><span id='topic+str.H2OFrame'></span>

<h3>Description</h3>

<p>Display the structure of an H2OFrame object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'H2OFrame'
str(object, ..., cols = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="str.H2OFrame_+3A_object">object</code></td>
<td>
<p>An H2OFrame.</p>
</td></tr>
<tr><td><code id="str.H2OFrame_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.</p>
</td></tr>
<tr><td><code id="str.H2OFrame_+3A_cols">cols</code></td>
<td>
<p>Print the per-column str for the H2OFrame</p>
</td></tr>
</table>

<hr>
<h2 id='summary+2CH2OAutoML-method'>Format AutoML object in user-friendly way</h2><span id='topic+summary+2CH2OAutoML-method'></span>

<h3>Description</h3>

<p>Format AutoML object in user-friendly way
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OAutoML'
summary(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary+2B2CH2OAutoML-method_+3A_object">object</code></td>
<td>
<p>an <code>H2OAutoML</code> object.</p>
</td></tr>
</table>

<hr>
<h2 id='summary+2CH2OCoxPHModel-method'>Summary method for H2OCoxPHModel objects</h2><span id='topic+summary+2CH2OCoxPHModel-method'></span>

<h3>Description</h3>

<p>Summary method for H2OCoxPHModel objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OCoxPHModel'
summary(object, conf.int = 0.95, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary+2B2CH2OCoxPHModel-method_+3A_object">object</code></td>
<td>
<p>an <code>H2OCoxPHModel</code> object.</p>
</td></tr>
<tr><td><code id="summary+2B2CH2OCoxPHModel-method_+3A_conf.int">conf.int</code></td>
<td>
<p>a specification of the confidence interval.</p>
</td></tr>
<tr><td><code id="summary+2B2CH2OCoxPHModel-method_+3A_scale">scale</code></td>
<td>
<p>a scale.</p>
</td></tr>
</table>

<hr>
<h2 id='summary+2CH2OGrid-method'>Format grid object in user-friendly way</h2><span id='topic+summary+2CH2OGrid-method'></span>

<h3>Description</h3>

<p>Format grid object in user-friendly way
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OGrid'
summary(object, show_stack_traces = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary+2B2CH2OGrid-method_+3A_object">object</code></td>
<td>
<p>an <code>H2OGrid</code> object.</p>
</td></tr>
<tr><td><code id="summary+2B2CH2OGrid-method_+3A_show_stack_traces">show_stack_traces</code></td>
<td>
<p>a flag to show stack traces for model failures</p>
</td></tr>
</table>

<hr>
<h2 id='summary+2CH2OModel-method'>Print the Model Summary</h2><span id='topic+summary+2CH2OModel-method'></span>

<h3>Description</h3>

<p>Print the Model Summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'H2OModel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary+2B2CH2OModel-method_+3A_object">object</code></td>
<td>
<p>An <a href="#topic+H2OModel-class">H2OModel</a> object.</p>
</td></tr>
<tr><td><code id="summary+2B2CH2OModel-method_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on (currently unimplemented)</p>
</td></tr>
</table>

<hr>
<h2 id='use.package'>Use optional package</h2><span id='topic+use.package'></span>

<h3>Description</h3>

<p>Testing availability of optional package, its version, and extra global default.
This function is used internally. It is exported and documented because user can
control behavior of the function by global option.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>use.package(
  package,
  version = "1.9.8"[package == "data.table"],
  use = getOption("h2o.use.data.table", TRUE)[package == "data.table"]
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="use.package_+3A_package">package</code></td>
<td>
<p>character scalar name of a package that we Suggests or Enhances on.</p>
</td></tr>
<tr><td><code id="use.package_+3A_version">version</code></td>
<td>
<p>character scalar required version of a package.</p>
</td></tr>
<tr><td><code id="use.package_+3A_use">use</code></td>
<td>
<p>logical scalar, extra escape option, to be used as global option.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We use this function to control csv read/write with optional <a href="data.table.html#topic+data.table">data.table</a> package.
Currently data.table is enabled by default for some operations, to disable it set <code>options("h2o.use.data.table"=FALSE)</code>.
It is possible to control just <code><a href="data.table.html#topic+fread">fread</a></code> or <code><a href="data.table.html#topic+fwrite">fwrite</a></code> with <code>options("h2o.fread"=FALSE, "h2o.fwrite"=FALSE)</code>.
<code>h2o.fread</code> and <code>h2o.fwrite</code> options are not handled in this function but next to <em>fread</em> and <em>fwrite</em> calls.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.h2o.data.frame">as.h2o.data.frame</a></code>, <code><a href="#topic+as.data.frame.H2OFrame">as.data.frame.H2OFrame</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>op &lt;- options("h2o.use.data.table" = TRUE)
if (use.package("data.table")) {
  cat("optional package data.table 1.9.8+ is available\n")
} else {
  cat("optional package data.table 1.9.8+ is not available\n")
}
options(op)
</code></pre>

<hr>
<h2 id='walking'>Muscular Actuations for Walking Subject</h2><span id='topic+walking'></span>

<h3>Description</h3>

<p>The musculoskeletal model, experimental data, settings files, and results 
for three-dimensional, muscle-actuated simulations at walking speed as 
described in Hamner and Delp (2013). Simulations were generated using OpenSim 2.4.
The data is available from <a href="https://simtk.org/frs/index.php?group_id=603">https://simtk.org/frs/index.php?group_id=603</a>.
</p>


<h3>Format</h3>

<p>A data frame with 151 rows and 124 columns
</p>


<h3>References</h3>

<p>Hamner, S.R., Delp, S.L. Muscle contributions to fore-aft and vertical body mass center accelerations over a range of running speeds. Journal of Biomechanics, vol 46, pp 780-787. (2013)
</p>

<hr>
<h2 id='zzz'>Shutdown H2O cluster after examples run</h2><span id='topic+zzz'></span>

<h3>Description</h3>

<p>Shutdown H2O cluster after examples run
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(h2o)
h2o.init()
h2o.shutdown(prompt = FALSE)
Sys.sleep(3)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
