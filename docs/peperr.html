<!DOCTYPE html><html><head><title>Help for package peperr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {peperr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregation.brier'><p>Determine the Brier score for a fitted model</p></a></li>
<li><a href='#aggregation.misclass'><p>Determine the missclassification rate for a fitted model</p></a></li>
<li><a href='#aggregation.pmpec'><p>Determine the prediction error curve for a fitted model</p></a></li>
<li><a href='#complexity.LASSO'><p>Interface for selection of optimal parameter for lasso fit</p></a></li>
<li><a href='#extract.fun'><p>Extract functions, libraries and global variables to be loaded onto a compute cluster</p></a></li>
<li><a href='#fit.coxph'><p>Interface function for fitting a Cox proportional hazards model</p></a></li>
<li><a href='#fit.LASSO'><p>Interface function for fitting a generalised linear model with the lasso</p></a></li>
<li><a href='#ipec'><p>Integrated prediction error curve</p></a></li>
<li><a href='#peperr'><p>Parallelised Estimation of Prediction Error</p></a></li>
<li><a href='#perr'><p>Prediction error estimates</p></a></li>
<li><a href='#PLL'><p>Generic function for extracting the predictive partial log-likelihood</p></a></li>
<li><a href='#PLL.coxph'><p>Predictive partial log-likelihood for Cox poportional hazards model</p></a></li>
<li><a href='#plot.peperr'><p>Plot method for peperr object</p></a></li>
<li><a href='#pmpec'><p>Calculate prediction error curves</p></a></li>
<li><a href='#predictProb'><p>Generic function for extracting predicted survival probabilities</p></a></li>
<li><a href='#predictProb.coxph'><p>Extract predicted survival probabilities from a coxph object</p></a></li>
<li><a href='#predictProb.survfit'><p>Extract predicted survival probabilities from a survfit object</p></a></li>
<li><a href='#resample.indices'><p>Generation of indices for resampling Procedure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-21</td>
</tr>
<tr>
<td>Title:</td>
<td>Parallelised Estimation of Prediction Error</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5</td>
</tr>
<tr>
<td>Depends:</td>
<td>snowfall, survival, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>locfit, penalized, codetools</td>
</tr>
<tr>
<td>Author:</td>
<td>Christine Porzelius, Harald Binder</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Frederic Bertrand &lt;frederic.bertrand@utt.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Designed for prediction error estimation
        through resampling techniques, possibly accelerated by parallel
        execution on a compute cluster. Newly developed model fitting
        routines can be easily incorporated. Methods used in the package are detailed in
        Porzelius Ch., Binder H. and Schumacher M. (2009) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtp062">doi:10.1093/bioinformatics/btp062</a>&gt;
        and were used, for instance, in
        Porzelius Ch., Schumacher M.and  Binder H. (2011) &lt;<a href="https://doi.org/10.1007%2Fs00180-011-0236-6">doi:10.1007/s00180-011-0236-6</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/fbertran/peperr/">https://github.com/fbertran/peperr/</a>,
<a href="https://fbertran.github.io/peperr/">https://fbertran.github.io/peperr/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/fbertran/peperr/issues/">https://github.com/fbertran/peperr/issues/</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-21 21:53:08 UTC; fbertran</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-22 13:40:20 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregation.brier'>Determine the Brier score for a fitted model</h2><span id='topic+aggregation.brier'></span>

<h3>Description</h3>

<p>Evaluate the Brier score, i.e. prediction error, for a fitted model on new data. To be used as argument <code>aggregation.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregation.brier(full.data=NULL, response, x, model, cplx=NULL,  
type=c("apparent", "noinf"), fullsample.attr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregation.brier_+3A_full.data">full.data</code></td>
<td>
<p>passed from <code>peperr</code>, but not used for calculation of the Brier score.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_response">response</code></td>
<td>
<p>vector of binary response.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_model">model</code></td>
<td>
<p>model fitted as returned by a <code>fit.fun</code>, as used in a call to <code>peperr</code>.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_cplx">cplx</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation of the Brier score.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_type">type</code></td>
<td>
<p>character.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_fullsample.attr">fullsample.attr</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation of the Brier score.</p>
</td></tr>
<tr><td><code id="aggregation.brier_+3A_...">...</code></td>
<td>
<p>additional arguments, passed to <code>predict</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical Brier score is the mean of the squared difference of the risk prediction and the true value of all observations and takes values between 0 and 1, where small values indicate good prediction performance of the risk prediction model.
</p>


<h3>Value</h3>

<p>Scalar, indicating the empirical Brier score.
</p>

<hr>
<h2 id='aggregation.misclass'>Determine the missclassification rate for a fitted model</h2><span id='topic+aggregation.misclass'></span>

<h3>Description</h3>

<p>Evaluate the misclassification rate, i.e. prediction error, for a fitted model on new data. To use as argument <code>aggregation.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregation.misclass(full.data=NULL, response, x, model, cplx=NULL,  
type=c("apparent", "noinf"), fullsample.attr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregation.misclass_+3A_full.data">full.data</code></td>
<td>
<p>passed from <code>peperr</code>, but not used for calculation of the misclassification rate.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_response">response</code></td>
<td>
<p>vector of binary response.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_model">model</code></td>
<td>
<p>model fitted with <code>fit.fun</code>.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_cplx">cplx</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation of the misclassification rate.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_type">type</code></td>
<td>
<p>character.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_fullsample.attr">fullsample.attr</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation of the misclassification rate.</p>
</td></tr>
<tr><td><code id="aggregation.misclass_+3A_...">...</code></td>
<td>
<p>additional arguments, passed to <code>predict</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Misclassification rate is the ratio of observations for which prediction of response is wrong. 
</p>


<h3>Value</h3>

<p>Scalar, indicating the misclassification rate.
</p>

<hr>
<h2 id='aggregation.pmpec'>Determine the prediction error curve for a fitted model</h2><span id='topic+aggregation.pmpec'></span>

<h3>Description</h3>

<p>Interface to <code>pmpec</code>, for conforming to the structure required by the argument <code>aggregation.fun</code> in <code>peperr</code> call. Evaluates the prediction error curve, i.e. the Brier score tracked over time, for a fitted survival model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregation.pmpec(full.data, response, x, model, cplx=NULL, times = NULL, 
   type=c("apparent", "noinf"), fullsample.attr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregation.pmpec_+3A_full.data">full.data</code></td>
<td>
<p>data frame with full data set.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_response">response</code></td>
<td>
<p>Either a survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing event status, coded with 0 and 1) or a matrix with columns <code>time</code> containing survival times and <code>status</code> containing integers, where 0 indicates censoring, 1 the interesting event and larger numbers other competing risks.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_model">model</code></td>
<td>
<p>survival model as returned by <code>fit.fun</code> as used in call to <code>peperr</code>.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_cplx">cplx</code></td>
<td>
<p>numeric, number of boosting steps or list, containing number of boosting steps in argument <code>stepno</code>.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_times">times</code></td>
<td>
<p>vector of evaluation time points. If given, used as well as in calculation of full apparent and no-information error as in resampling procedure. Not used if <code>fullsample.attr</code> is specified.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_type">type</code></td>
<td>
<p>character.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_fullsample.attr">fullsample.attr</code></td>
<td>
<p>vector of evaluation time points, passed in resampling procedure. Either user-defined, if <code>times</code> were passed as <code>args.aggregation</code>, or the determined time points from the <code>aggregation.fun</code> call with the full data set.</p>
</td></tr>
<tr><td><code id="aggregation.pmpec_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>pmpec</code> call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If no evaluation time points are passed, they are generated using all uncensored time points if their number is smaller than 100, or 100 time points up to the 95% quantile of the uncensored time points are taken.
</p>
<p><code>pmpec</code> requires a <code>predictProb</code> method for the class of the fitted model, i.e. for a model of class <code>class</code> <code>predictProb.class</code>. 
</p>


<h3>Value</h3>

<p>A matrix with one row. Each column represents the estimated prediction error of the fit at the time points.
</p>


<h3>See Also</h3>

<p><code>peperr</code>, <code>predictProb</code>, <code>pmpec</code></p>

<hr>
<h2 id='complexity.LASSO'>Interface for selection of optimal parameter for lasso fit</h2><span id='topic+complexity.LASSO'></span>

<h3>Description</h3>

<p>Determines the optimal value for tuning parameter lambda for a regression model with lasso penalties via cross-validation. Conforming to the calling convention required by argument <code>complexity</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complexity.LASSO(response, x, full.data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complexity.LASSO_+3A_response">response</code></td>
<td>
<p>a survival object (<code>Surv(time, status)</code>).</p>
</td></tr>
<tr><td><code id="complexity.LASSO_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="complexity.LASSO_+3A_full.data">full.data</code></td>
<td>
<p>data frame containing response and covariates of the full data set.</p>
</td></tr>
<tr><td><code id="complexity.LASSO_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>optL1</code> of package <span class="pkg">penalized</span> call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function is basically a wrapper around <code>optL1</code> of package <span class="pkg">penalized</span>.  Calling <code>peperr</code>, default arguments of <code>optL1</code> can be changed by passing a named list containing these as argument <code>args.complexity</code>.
</p>


<h3>Value</h3>

<p>Scalar value giving the optimal value for lambda.
</p>


<h3>See Also</h3>

<p><code>peperr</code>, <code><a href="penalized.html#topic+optL1">optL1</a></code></p>

<hr>
<h2 id='extract.fun'>Extract functions, libraries and global variables to be loaded onto a compute cluster</h2><span id='topic+extract.fun'></span>

<h3>Description</h3>

<p>Automatic extraction of functions, libraries and global variables employed passed functions. Designed for <code>peperr</code> call, see Details section there.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.fun(funs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.fun_+3A_funs">funs</code></td>
<td>
<p>list of function names.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is necessary for compute cluster situations where for computation on nodes required functions, libraries and variables have to be loaded explicitly on each node. Avoids loading of whole global environment which might include the unnecessary loading of huge data sets. 
</p>
<p>It might have problems in some cases, especially it is not able to extract the library of a function that has no namespace. Similarly, it can only extract a required library if it is loaded, or if the function contains a require or library call. 
</p>


<h3>Value</h3>

<p>list containing
</p>
<table>
<tr><td><code>packages</code></td>
<td>
<p>vector containing quoted names of libraries</p>
</td></tr>
<tr><td><code>functions</code></td>
<td>
<p>vector containing quoted names of functions</p>
</td></tr>
<tr><td><code>variables</code></td>
<td>
<p>vector containing quoted names of global variables</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>peperr</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Simplified example for illustration
## Not run: 
library(CoxBoost)
a &lt;- function(){
# some calculation
}

b&lt;-function(){
# some other calculation
x &lt;- cv.CoxBoost()
# z is global variable
y &lt;- a(z)
}

# list with packages, functions and variables required for b:
extract.fun(list(b))

# 2. As called by default in peperr example
extract.fun(list(fit.CoxBoost, aggregation.pmpec))

## End(Not run)
</code></pre>

<hr>
<h2 id='fit.coxph'>Interface function for fitting a Cox proportional hazards model</h2><span id='topic+fit.coxph'></span>

<h3>Description</h3>

<p>Interface for fitting survival models by Cox proporional hazards model, conforming to the requirements for argument <code>fit.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.coxph(response, x, cplx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.coxph_+3A_response">response</code></td>
<td>
<p>a survival object (with <code>Surv(time, status)</code>).</p>
</td></tr>
<tr><td><code id="fit.coxph_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="fit.coxph_+3A_cplx">cplx</code></td>
<td>
<p>not used.</p>
</td></tr>
<tr><td><code id="fit.coxph_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>coxph</code> call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function is basically a wrapper around <code>coxph</code> of package <span class="pkg">survival</span>. 
</p>


<h3>Value</h3>

<p>CoxBoost object
</p>


<h3>See Also</h3>

 <p><code>peperr</code>, <code><a href="survival.html#topic+coxph">coxph</a></code></p>

<hr>
<h2 id='fit.LASSO'>Interface function for fitting a generalised linear model with the lasso</h2><span id='topic+fit.LASSO'></span>

<h3>Description</h3>

<p>Interface for fitting survival models with the lasso, conforming to the requirements of argument <code>fit.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.LASSO(response, x, cplx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.LASSO_+3A_response">response</code></td>
<td>
<p>response. Could be numeric vector for linear regression, <code>Surv</code> object for Cox regression or a binary vector for logistic regression.</p>
</td></tr>
<tr><td><code id="fit.LASSO_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="fit.LASSO_+3A_cplx">cplx</code></td>
<td>
<p>LASSO penalty. <code>lambda1</code> of <code>penalized</code> call.</p>
</td></tr>
<tr><td><code id="fit.LASSO_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>penalized</code> call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function is basically a wrapper around function <code>penalized</code> of package <code>penalized</code>. 
</p>


<h3>Value</h3>

<p>penfit object
</p>


<h3>See Also</h3>

 <p><code>peperr</code>, <code><a href="penalized.html#topic+penalized">penalized</a></code></p>

<hr>
<h2 id='ipec'>Integrated prediction error curve</h2><span id='topic+ipec'></span>

<h3>Description</h3>

<p>Summary measures of prediction error curves
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipec(pe, eval.times, type=c("Riemann", "Lebesgue", "relativeLebesgue"), response=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ipec_+3A_pe">pe</code></td>
<td>
<p>prediction error at different time points. Vector of length of <code>eval.times</code> or matrix (columns correspond to evaluation time points, rows to different prediction error estimates)</p>
</td></tr>
<tr><td><code id="ipec_+3A_eval.times">eval.times</code></td>
<td>
<p>evalutation time points</p>
</td></tr>
<tr><td><code id="ipec_+3A_type">type</code></td>
<td>
<p>type of integration. 'Riemann' estimates Riemann integral, 'Lebesgue' uses the probability density as weights, while 'relativeLebesgue' delivers the difference to the null model (using the same weights as for 'Lebesgue').</p>
</td></tr>
<tr><td><code id="ipec_+3A_response">response</code></td>
<td>
<p>survival object (<code>Surv(time, status)</code>), required only if <code>type</code> is 'Lebesgue' or 'relativeLebesgue'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For survival data, prediction error at each evaluation time point can be extracted of a <code>peperr</code> object by function <code>perr</code>. A summary measure can then be obtained via intgrating over time. Note that the time points used for evaluation are stored in list element <code>attribute</code> of the <code>peperr</code> object.
</p>


<h3>Value</h3>

<table>
<tr><td><code>ipec</code></td>
<td>
<p>Value of integrated prediction error curve. Integer or vector, if <code>pe</code> is vector or matrix, respectively, i.e. one entry per row of the passed matrix.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+perr">perr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n &lt;- 200
p &lt;- 100
beta &lt;- c(rep(1,10),rep(0,p-10))
x &lt;- matrix(rnorm(n*p),n,p)
real.time &lt;- -(log(runif(n)))/(10*exp(drop(x %*% beta)))
cens.time &lt;- rexp(n,rate=1/10)
status &lt;- ifelse(real.time &lt;= cens.time,1,0)
time &lt;- ifelse(real.time &lt;= cens.time,real.time,cens.time)

# Example:
# Obtain prediction error estimate fitting a Cox proportional hazards model
# using CoxBoost 
# through 10 bootstrap samples 
# with fixed complexity 50 and 75
# and aggregate using prediction error curves
peperr.object &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, complexity=c(50, 75), 
   indices=resample.indices(n=length(time), method="sub632", sample.n=10))
# 632+ estimate for both complexity values at each time point
prederr &lt;- perr(peperr.object)
# Integrated prediction error curve for both complexity values
ipec(prederr, eval.times=peperr.object$attribute, response=Surv(time, status))

## End(Not run)
</code></pre>

<hr>
<h2 id='peperr'>Parallelised Estimation of Prediction Error</h2><span id='topic+peperr'></span>

<h3>Description</h3>

<p>Prediction error estimation for regression models via resampling techniques. Potentially parallelised, if compute cluster is available. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>peperr(response, x, 
	indices = NULL, 
	fit.fun, complexity = NULL, args.fit = NULL, args.complexity = NULL,
	parallel = NULL, cpus = 2, clustertype=NULL, clusterhosts=NULL,
	noclusterstart = FALSE, noclusterstop=FALSE,
	aggregation.fun=NULL, args.aggregation = NULL, 
	load.list = extract.fun(list(fit.fun, complexity, aggregation.fun)),
	load.vars = NULL, load.all = FALSE, 
	trace = FALSE, debug = FALSE,
	peperr.lib.loc=NULL, 
        RNG=c("RNGstream", "SPRNG", "fixed", "none"), seed=NULL, 
        lb=FALSE, sr=FALSE, sr.name="default", sr.restore=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="peperr_+3A_response">response</code></td>
<td>
<p>Either a survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing event status, coded with 0 and 1) or a matrix with columns <code>time</code> containing survival times and <code>status</code> containing integers, where 0 indicates censoring, 1 the interesting event and larger numbers other competing risks. In case of binary response, vector with entries 0 and 1.</p>
</td></tr>
<tr><td><code id="peperr_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="peperr_+3A_indices">indices</code></td>
<td>
<p>named list, with two elements (both expected to be lists) <code>sample.index</code>, containing the vector of indices of observations used to fit the model, and list <code>not.in.sample</code>, containing the vector of indices of observations used for assessment. One list entry per split.
Function <code>resample.indices</code> provides the most common resampling methods. If argument <code>indices</code> is not specified (default), the indices are determined as follows: If number of observations in the passed data matrix is smaller than number of covariates, 500 bootstrap samples without replacement are generated (&quot;subsampling&quot;), else 500 bootstrap samples with replacement.</p>
</td></tr>
<tr><td><code id="peperr_+3A_fit.fun">fit.fun</code></td>
<td>
<p>function returning a fitted model, see Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_complexity">complexity</code></td>
<td>
<p>if the choice of a complexity parameter is necessary, for example the number of boosting steps in boosting techniques, a function returning complexity parameter for model fitted with fit.fun, see Details. Alternatively, one explicit value for the complexity or a vector of values can be passed. In the latter case, the model fit is carried out for each of the complexity parameters. Alternatively, a named list can be passed, if complexity is a tuple of different parameter values.</p>
</td></tr>
<tr><td><code id="peperr_+3A_args.fit">args.fit</code></td>
<td>
<p>named list of arguments to be passed to the function given in <code>fit.fun</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_args.complexity">args.complexity</code></td>
<td>
<p>if <code>complexity</code> is a function, a named list of arguments to be passed to this function.</p>
</td></tr>
<tr><td><code id="peperr_+3A_parallel">parallel</code></td>
<td>
<p>the default setting corresponds to the case that sfCluster is used or if R runs sequential, i.e. without any parallelisation. If sfCluster is used, settings from sfCluster commandline call are taken, i.e. the required number of nodes has to be specified as option of the sfCluster call (and not using argument <code>cpus</code>). 
If another cluster solution (specified by argument <code>clustertype</code>) shall be used, a cluster with <code>cpus</code> CPUs is started if <code>parallel=TRUE</code>. <code>parallel=FALSE</code> switches back to sequential execution. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_cpus">cpus</code></td>
<td>
<p>number of nodes, i.e., number of parallel running R processes, to be set up in a cluster, if not specified by commandline call. Only needed if <code>parallel=TRUE</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_clustertype">clustertype</code></td>
<td>
<p>type of cluster, character. 'SOCK' for socket cluster, 'MPI', 'PVM' or 'NWS'. Only considered if <code>parallel=TRUE</code>. If so, a socket cluster, which does not require any additional installation, is started as default.</p>
</td></tr>
<tr><td><code id="peperr_+3A_clusterhosts">clusterhosts</code></td>
<td>
<p>host list for socket and NWS clusters, if <code>parallel=TRUE</code>. Has to be specified only if using more than one machine.</p>
</td></tr>
<tr><td><code id="peperr_+3A_noclusterstart">noclusterstart</code></td>
<td>
<p>if function is used in already parallelised code. If set to TRUE, no cluster is initialised even if a compute cluster is available and function works in sequential mode. Additionally usable if calls on the slaves should be executed before calling function <code>peperr</code>, for example to load data on slaves, see Details.</p>
</td></tr> 
<tr><td><code id="peperr_+3A_noclusterstop">noclusterstop</code></td>
<td>
<p>if TRUE, cluster stop is suppressed. Useful for debugging of sessions on slaves. Note that the next <code>peperr</code> call forces cluster stop, except if called with <code>noclusterstart=TRUE</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_aggregation.fun">aggregation.fun</code></td>
<td>
<p>function that evaluates the prediction error for a model fitted by the function given in <code>fit.fun</code>, see Details. If not specified, function <code>aggregation.pmpec</code> is taken if response is survival object, in case of binary response function <code>aggregation.brier</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_args.aggregation">args.aggregation</code></td>
<td>
<p>named list of arguments to be passed to the function given in argument <code>aggregation.fun</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_load.list">load.list</code></td>
<td>
<p>a named list with element <code>packages</code>, <code>functions</code> and <code>variables</code> containing quoted names of libraries, functions and global variables required for computation on cluster nodes. The default extracts automatically the libraries, functions and global variables of the, potentially user-defined, functions <code>fit.fun</code>, <code>complexity</code> and <code>aggregation.fun</code>, see function <code>extract.fun</code>. Can be set to NULL, e.g. if no libraries, functions and variables are needed. Alternatively, use argument <code>load.all</code>. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_load.vars">load.vars</code></td>
<td>
<p>a named list with global variables required for computation on cluster nodes. See Details. Relict, global variabels can now be passed as list element <code>variables</code> of argument <code>load.list</code>.</p>
</td></tr>
<tr><td><code id="peperr_+3A_load.all">load.all</code></td>
<td>
<p>logical. If set to TRUE, all variables, functions and libraries of the current global environment are loaded on cluster nodes. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_trace">trace</code></td>
<td>
<p>logical. If TRUE, output about the current execution step is printed (if running parallel: printed on nodes, that means not visible in master R process, see Details).</p>
</td></tr>
<tr><td><code id="peperr_+3A_debug">debug</code></td>
<td>
<p>if TRUE, information concerning export of variables is given.</p>
</td></tr>
<tr><td><code id="peperr_+3A_peperr.lib.loc">peperr.lib.loc</code></td>
<td>
<p>location of package <span class="pkg">peperr</span> if not in standard library search path (<code>.libPaths()</code>), to be specified for loading <span class="pkg">peperr</span> onto the cluster nodes.</p>
</td></tr>
<tr><td><code id="peperr_+3A_rng">RNG</code></td>
<td>
<p>type of RNG. <code>"fixed"</code> requires a specified <code>seed</code>. <code>"RNGstream"</code> and <code>"SPRNG"</code> use default seeds, if not specified. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_seed">seed</code></td>
<td>
<p>seed to allow reproducibility of results. Only considered if argument <code>RNG</code> is not <code>"none"</code>. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_lb">lb</code></td>
<td>
<p>if TRUE and a compute cluster is used, computation of slaves is executed load balanced. See Details.</p>
</td></tr>
<tr><td><code id="peperr_+3A_sr">sr</code></td>
<td>
<p>if TRUE, intermediate results are saved. If execution is interrupted, they can be restored by setting argument sr.restore to TRUE. See documentation of package <span class="pkg">snowfall</span> for details</p>
</td></tr>
<tr><td><code id="peperr_+3A_sr.name">sr.name</code></td>
<td>
<p>if <code>sr</code> is set to TRUE and more than one computation runs simultaneously, unique names need to be used.</p>
</td></tr>
<tr><td><code id="peperr_+3A_sr.restore">sr.restore</code></td>
<td>
<p>if <code>sr</code> is set to TRUE, an interrupted computation is restarted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Validation of new model fitting approaches requires the proper use of resampling techniques for prediction error estimation. Especially in high-dimensional data situations the computational demand might be huge. <code>peperr</code> accelerates computation through automatically parallelisation of the resampling procedure, if a compute cluster is available. A noticeable speed-up is reached even when using a dual-core processor.
</p>
<p>Resampling based prediction error estimation requires for each split in training and test data the following steps: a) selection of model complexity (if desired), using the training data set, b) fitting the model with the selected (or a given) complexity on the training set and c) measurement of prediction error on the corresponding test set.
</p>
<p>Functions for fitting the model, determination of model complexity, if required by the fitting procedure, and aggregating the prediction error are passed as arguments <code>fit.fun</code>, <code>complexity</code> and <code>aggregation.fun</code>. Already available functions are 
</p>
<p>for model fit:
<code>fit.CoxBoost</code>, <code>fit.coxph</code>, <code>fit.LASSO</code>, <code>fit.rsf_mtry</code>
</p>
<p>to determine complexity:
<code>complexity.mincv.CoxBoost</code>, <code>complexity.ipec.CoxBoost</code>, <code>complexity.LASSO</code>, <code>complexity.ipec.rsf_mtry</code>
</p>
<p>to aggregate prediction error:
<code>aggregation.pmpec</code>, <code>aggregation.brier</code>, <code>aggregation.misclass</code>
</p>
<p>Function <code>peperr</code> is especially designed for evaluation of newly developed model fitting routines. For that, own routines can be passed as arguments to the <code>peperr</code> call. They are incorporated as follows (also compare existing functions, as named above):
</p>

<ol>
<li><p> Model fitting techniques, which require selection of one or more complexity parameters, often provide routines based on cross-validation or similar to determine this parameter. If this routine is already at hand, the complexity function needed for the <code>peperr</code> call is not more than a wrapper around that, which consists of providing the data in the required way, calling the routine and return the selected complexity value(s). 
</p>
</li>
<li><p> For a given model fitting routine the fitting function, which is passed to the <code>peperr</code> call as argument <code>fit.fun</code>, is not more than a wrapper around that. Explicitly, response and matrix of covariates have to be transformed to the required form, if necessary, the routine is called with the passed complexity value, if required, and the fitted prediction model is returned. 
</p>
</li>
<li><p> Prediction error is estimated using a fitted model and a data set, by any kind of comparison of the true and the predicted response values. In case of survival response, apparent error (type <code>apparent</code>), which means that the prediction error is estimated in the same data set as used for model fitting, and no-information error (type <code>noinf</code>), which calculates the prediction error in permuted data, have to be provided. Note that the aggregation function returns the error with an additional attribute called <code>addattr</code>. The evaluation time points have to be stored there to allow later access.  
</p>
</li>
<li><p> In case of survival response, the user may additionally provide a function for partial log likelihood calculation, if he uses an own function for model fit, called <code>PLL.class</code>. If prediction error curves are used for aggregation (<code>aggregation.pmpec</code>), a predictProb method has to be provided, i.e. for each model of class <code>class</code> <code>predictProb.class</code>, see there. 
</p>
</li></ol>

<p>Concerning parallelisation, there are three possibilities to run <code>peperr</code>:
</p>

<ul>
<li><p> Start R on commandline with sfCluster and preferred options, for example number of cpus. Leave the three arguments <code>parallel</code>, <code>clustertype</code> and <code>nodes</code> unchanged.
</p>
</li>
<li><p> Use any other cluster solution supported by <span class="pkg">snowfall</span>, i.e. LAM/MPI, socket, PVM, NWS (set argument <code>clustertype</code>). Argument <code>parallel</code> has to be set to TRUE and number of cpus can be chosen by argument <code>nodes</code>) 
</p>
</li>
<li><p> If no cluster is used, R works sequentially. Keep <code>parallel=NULL</code>. No parallelisation takes place and therefore no speed up can be obtained.
</p>
</li></ul>
 
<p>In general, if <code>parallel=NULL</code>, all information concerning the cluster set-up is taken from commandline, else, it can be specified using the three arguments <code>parallel</code>, <code>clustertype</code>, <code>nodes</code>, and, if necessary, <code>clusterhosts</code>. 
</p>
<p>sfCluster is a Unix tool for flexible and comfortable managment of parallel R processes. However, <span class="pkg">peperr</span> is usable with any other cluster solution supported by <span class="pkg">snowfall</span>, i.e. sfCluster has not to be installed to use package <span class="pkg">peperr</span>. Note that this may require cluster handling by the user, e.g. manually shut down with 'lamhalt' on commandline for <code>type="MPI"</code>. But, using a socket cluster (argument <code>parallel=TRUE</code> and <code>clustertype="SOCK"</code>), does not require any extra installation. 
</p>
<p>Note that the run time cannot speed up anymore if the number of nodes is chosen higher than the number of passed training/test samples plus one, as parallelisation takes place in the resampling procedure and one additional run is used for computation on the full sample.
</p>
<p>If not running in sequential mode, a specified number of R processes called nodes is spawned for parallel execution of the resampling procedure (see above). This requires to provide all variables, functions and libraries necessary for computation on each of these R processes, so explicitly all variables, functions and libraries required by the, potentially user-defined, functions <code>fit.fun</code>, <code>complexity</code> and <code>aggregation.fun</code>. The simplest possibility is to load the whole content of the global environment on each node and all loaded libraries. This is done by setting argument <code>load.all=TRUE</code>. This is not the default, as a huge amount of data is potentially loaded to each node unnecessarily. Function <code>extract.fun</code> is provided to extract the functions and libraries needed, automatically called at each call of function <code>peperr</code>. Note that all required libraries have to be located in the standard library search path (obtained by <code>.libPaths()</code>). Another alternative is to load required data manually on the slaves, using <span class="pkg">snowfall</span> functions <code>sfLibrary</code>, <code>sfExport</code> and <code>sfExportAll</code>. Then, argument <code>noclusterstart</code> has to be switched to TRUE. Additionally, argument <code>load.list</code> could be set to NULL, to avoid potentially overwriting of functions and variables loaded to the cluster nodes automatically.
</p>
<p>Note that a <code>set.seed</code> call before calling function <code>peperr</code> is not sufficient to allow reproducibility of results when running in parallel mode, as the slave R processes are not affected as they are own R instances. <code>peperr</code> provides two possibilities to make results reproducible: 
</p>

<ul>
<li><p> Use <code>RNG="RNGstream"</code> or <code>RNG="SPRNG"</code>. Independent parallel random number streams are initialized on the cluster nodes, using function <code>sfClusterSetupRNG</code> of package <span class="pkg">snowfall</span>. A seed can be specified using argument <code>seed</code>, else the default values are taken. A <code>set.seed</code> call on the master is required additionally and argument <code>lb=FALSE</code>, see below.
</p>
</li>
<li><p> If <code>RNG="fixed"</code>, a seed has to be specified. This can be either an integer or a vector of length number of samples +2.  In the second case, the first entry is used for the main R process, the next number of samples ones for each sample run (in parallel execution mode on slave R processes) and the last one for computation on full sample (as well on slave R process in parallel execution mode). Passing integer x is equivalent to passing vector <code>x+(0:(number of samples+1))</code>. This procedure allows reproducibility in any case, i.e. also if the number of parallel processes changes as well as in sequential execution.
</p>
</li></ul>
 
<p>Load balancing (argument <code>lb</code>) means, that a slave gets a new job immediately after the previous is finished. This speeds up computation, but may change the order of jobs. Due to that, results are only reproducible, if <code>RNG="fixed"</code> is used.
</p>


<h3>Value</h3>

<p>Object of class <code>peperr</code>
</p>
<table>
<tr><td><code>indices</code></td>
<td>
<p>list of resampling indices.</p>
</td></tr>
<tr><td><code>complexity</code></td>
<td>
<p>passed complexity. If argument <code>complexity</code> not specified, 0.</p>
</td></tr>
<tr><td><code>selected.complexity</code></td>
<td>
<p>selected complexity for the full data set, if <code>complexity</code> was passed as function. Else equal to value <code>complexity</code>.</p>
</td></tr>
<tr><td><code>response</code></td>
<td>
<p>passed response.</p>
</td></tr>
<tr><td><code>full.model.fit</code></td>
<td>
<p>List, one entry per complexity value. Fitted model of the full data set by passed <code>fit.fun</code>.</p>
</td></tr>
<tr><td><code>full.apparent</code></td>
<td>
<p>full apparent error of the full data set. Matrix: One row per complexity value. In case of survival response, columns correspond to evaluation timepoints, which are returned in value <code>attribute</code>.</p>
</td></tr>
<tr><td><code>noinf.error</code></td>
<td>
<p>No information error of the full data set, i. e. evaluation in permuted data. Matrix: One row per complexity value. Columns correspond to evaluation timepoints, which are returned in <code>attribute</code>.</p>
</td></tr>
<tr><td><code>attribute</code></td>
<td>
<p>if response is survival: Evaluation time points. Passed in <code>args.aggregation</code> or automatically determined by aggregation function. Otherwise, if available, extra attribute returned by aggregation function, else <code>NULL</code>, see Details.</p>
</td></tr>
<tr><td><code>sample.error</code></td>
<td>
<p>list. Each entry contains matrix of prediction error for one resampling test sample. One row per complexity value.</p>
</td></tr>
<tr><td><code>sample.complexity</code></td>
<td>
<p>vector of complexity values. Equals value <code>complexity</code>, if complexity value was passed explicitly, otherwise by function <code>complexity</code> selected complexity value for each resampling sample. If argument <code>complexity</code> not specified, 0.</p>
</td></tr>
<tr><td><code>sample.lipec</code></td>
<td>
<p>only, if response is survival. Lebesgue integrated prediction error curve for each sample. List with one entry per sample, each a matrix with one row per complexity value.</p>
</td></tr>
<tr><td><code>sample.pll</code></td>
<td>
<p>only, if response is survival and PLL.class function available. Predictive partial log likelihood for each sample. List with one entry per sample, each a matrix with one row per complexity value.</p>
</td></tr>
<tr><td><code>null.model.fit</code></td>
<td>
<p>only, if response is survival or binary. Fit of null model, i.e. fit without information of covariates. In case of survival response Kaplan-Meier, else logistic regression model.</p>
</td></tr>
<tr><td><code>null.model</code></td>
<td>
<p>only, if response is survival or binary. Vector or scalar: Prediction error of the null model, in case of survival response at each evaluation time point.</p>
</td></tr>
<tr><td><code>sample.null.model</code></td>
<td>
<p>list. Prediction error of the null model for one resampling test sample. Matrix, one row per complexity value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christine Porzelius <a href="mailto:cp@fdm.uni-freiburg.de">cp@fdm.uni-freiburg.de</a>, Harald Binder</p>


<h3>References</h3>

<p>Binder, H. and Schumacher, M. (2008) Adapting prediction error estimates for biased complexity selection in high-dimensional bootstrap samples. Statistical Applications in Genetics and Molecular Biology, 7:1.
</p>
<p>Porzelius, C., Binder, H., Schumacher, M. (2008) Parallelised prediction error estimation for evaluation of high-dimensional models. Manuscript.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perr">perr</a></code>, <code><a href="#topic+resample.indices">resample.indices</a></code>, <code><a href="#topic+extract.fun">extract.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate survival data with 10 informative covariates 
## Not run: 
n &lt;- 200
p &lt;- 100
beta &lt;- c(rep(1,10),rep(0,p-10))
x &lt;- matrix(rnorm(n*p),n,p)
real.time &lt;- -(log(runif(n)))/(10*exp(drop(x 
cens.time &lt;- rexp(n,rate=1/10)
status &lt;- ifelse(real.time &lt;= cens.time,1,0)
time &lt;- ifelse(real.time &lt;= cens.time,real.time,cens.time)

# A: R runs sequential or R is started on commandline with desired options 
# (for example using sfCluster: sfCluster -i --cpus=5)
# Example A1:
# Obtain prediction error estimate fitting a Cox proportional hazards model
# using CoxBoost 
# through 10 bootstrap samples 
# with fixed complexity 50 and 75
# and aggregate using prediction error curves (default setting)

peperr.object1 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, complexity=c(50, 75), 
   indices=resample.indices(n=length(time), method="sub632", sample.n=10))
peperr.object1

# Diagnostic plots
plot(peperr.object1)

# Extraction of prediction error curves (.632+ prediction error estimate), 
# blue line corresponds to complexity 50, 
# red one to complexity 75
plot(peperr.object1$attribute,
   perr(peperr.object1)[1,], type="l", col="blue",
   xlab="Evaluation time points", ylab="Prediction error")
lines(peperr.object1$attribute, 
   perr(peperr.object1)[2,], col="red")

# Example A2:
# As Example A1, but
# with complexity selected through a cross-validation procedure
# and extra argument 'penalty' passed to fit function and complexity function
peperr.object2 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, args.fit=list(penalty=100),
   complexity=complexity.mincv.CoxBoost, args.complexity=list(penalty=100),
   indices=resample.indices(n=length(time), method="sub632", sample.n=10),
   trace=TRUE)
peperr.object2

# Diagnostic plots
plot(peperr.object2)

# Example A3:
# As Example A2, but
# with extra argument 'times', specifying the evaluation times passed to aggregation.fun
# and seed, for reproducibility of results
# Note: set.seed() is required additional to argument 'seed', 
# as function 'resample.indices' is used in peperr call.
set.seed(123)
peperr.object3 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, args.fit=list(penalty=100),
   complexity=complexity.mincv.CoxBoost, args.complexity=list(penalty=100),
   indices=resample.indices(n=length(time), method="sub632", sample.n=10),
   args.aggregation=list(times=seq(0, quantile(time, probs=0.9), length.out=100)),
   trace=TRUE, RNG="fixed", seed=321)
peperr.object3

# Diagnostic plots
plot(peperr.object3)

# B: R is started sequential, desired cluster options are given as arguments
# Example B1:
# As example A1, but using a socket cluster and 3 CPUs
peperr.object4 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, complexity=c(50, 75), 
   indices=resample.indices(n=length(time), method="sub632", sample.n=10),
   parallel=TRUE, clustertype="SOCK", cpus=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='perr'>Prediction error estimates</h2><span id='topic+perr'></span>

<h3>Description</h3>

<p>Extracts prediction error estimates from <code>peperr</code> objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perr(peperrobject, 
    type = c("632p", "632", "apparent", "NoInf", "resample", "nullmodel"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perr_+3A_peperrobject">peperrobject</code></td>
<td>
<p>peperr object obtained by call to function <code>peperr</code>.</p>
</td></tr>
<tr><td><code id="perr_+3A_type">type</code></td>
<td>
<p><code>"632p"</code> for the .632+ prediction error estimate (default), <code>"632"</code> for the .632 prediction error estimate. <code>"apparent"</code>, <code>"NoInf"</code>, <code>"resample"</code> and <code>"nullmodel"</code> return the apparent error, the no-information error, the mean sample error and the nullmodel fit, see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The .632 and the .632+ prediction error estimates are weighted combinations of the apparent error and bootstrap cross-validation error estimate, for survival data at given time points.
</p>


<h3>Value</h3>

<p>If <code>type="632p"</code> or <code>type="632"</code>: Prediction error: Matrix, with one row per complexity value.
</p>
<p>If <code>type="apparent"</code>: Apparent error of the full data set. Matrix: One row per complexity value. In case of survival response, columns correspond to evaluation timepoints, which are given in attribute <code>addattr</code>.
</p>
<p>If <code>type="NoInf"</code>: No-information error of the full data set, i. e. evaluation in permuted data. Matrix: One row per complexity value. Columns correspond to evaluation timepoints, which are given in attribute <code>addattr</code>.
</p>
<p>If <code>type="resample"</code>: Matrix. Mean prediction error of resampling test samples, one row per complexity value.
</p>
<p>If <code>type="nullmodel"</code>: Vector or scalar: Null model prediction error, i.e. of fit without information of covariates. In case of survival response Kaplan-Meier estimate at each time point, if response is binary logistic regression model, else not available.
</p>


<h3>References</h3>

<p>Binder, H. and Schumacher, M. (2008) Adapting prediction error estimates for biased complexity selection in high-dimensional bootstrap samples. Statistical Applications in Genetics and Molecular Biology, 7:1.
</p>
<p>Gerds, T. and Schumacher, M. (2007) Efron-type measures of prediction error for survival analysis. Biometrics, 63, 1283&ndash;1287.
</p>
<p>Schumacher, M. and Binder, H., and Gerds, T. (2007) Assessment of Survival Prediction Models in High-Dimensional Settings. Bioinformatics, 23, 1768-1774.</p>


<h3>See Also</h3>

<p><code><a href="#topic+peperr">peperr</a></code>, <code><a href="#topic+ipec">ipec</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n &lt;- 200
p &lt;- 100
beta &lt;- c(rep(1,10),rep(0,p-10))
x &lt;- matrix(rnorm(n*p),n,p)
real.time &lt;- -(log(runif(n)))/(10*exp(drop(x %*% beta)))
cens.time &lt;- rexp(n,rate=1/10)
status &lt;- ifelse(real.time &lt;= cens.time,1,0)
time &lt;- ifelse(real.time &lt;= cens.time,real.time,cens.time)

# Example:
# Obtain prediction error estimate fitting a Cox proportional hazards model
# using CoxBoost 
# through 10 bootstrap samples 
# with fixed complexity 50 and 75
# and aggregate using prediction error curves
peperr.object &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, complexity=c(50, 75), 
   indices=resample.indices(n=length(time), method="sub632", sample.n=10))
# 632+ estimate for both complexity values at each time point
perr(peperr.object)


## End(Not run)
</code></pre>

<hr>
<h2 id='PLL'>Generic function for extracting the predictive partial log-likelihood</h2><span id='topic+PLL'></span>

<h3>Description</h3>

<p>Generic function for extracting th predictive partial log-likelihood from a fitted survival model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLL(object, newdata, newtime, newstatus, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLL_+3A_object">object</code></td>
<td>
<p>fitted model of class <code>class</code>.</p>
</td></tr>
<tr><td><code id="PLL_+3A_newdata">newdata</code></td>
<td>
<p><code>n_new*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="PLL_+3A_newtime">newtime</code></td>
<td>
<p><code>n_new</code>-vector of censored survival times.</p>
</td></tr>
<tr><td><code id="PLL_+3A_newstatus">newstatus</code></td>
<td>
<p><code>n_new</code>-vector of event status, coded with 0 for censoring and 1, if an event occurred.</p>
</td></tr>
<tr><td><code id="PLL_+3A_...">...</code></td>
<td>
<p>additional arguments, for example complexity value, if necessary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predictive partial log-likelihood measures the prediction performance of each model fitted in a boostrap sample, using the data not in this sample. Multiplying by (-2) leads to a deviance-like measure, which means that small values indicate good prediction performance.
</p>
<p><code>peperr</code> requires function <code>PLL.class</code> in case of survival response, for each model fit of class <code>class</code>.
At the time, <code>PLL.CoxBoost</code> is available.
</p>


<h3>Value</h3>

<p>Vector of length <code>n_new</code>
</p>

<hr>
<h2 id='PLL.coxph'>Predictive partial log-likelihood for Cox poportional hazards model</h2><span id='topic+PLL.coxph'></span>

<h3>Description</h3>

<p>Extracts the predictive partial log-likelihood from a coxph model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coxph'
PLL(object, newdata, newtime, newstatus, complexity, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLL.coxph_+3A_object">object</code></td>
<td>
<p>fitted model of class <code>coxph</code>.</p>
</td></tr>
<tr><td><code id="PLL.coxph_+3A_newdata">newdata</code></td>
<td>
<p><code>n_new*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="PLL.coxph_+3A_newtime">newtime</code></td>
<td>
<p><code>n_new</code>-vector of censored survival times.</p>
</td></tr>
<tr><td><code id="PLL.coxph_+3A_newstatus">newstatus</code></td>
<td>
<p><code>n_new</code>-vector of survival status, coded with 0 and .1</p>
</td></tr>
<tr><td><code id="PLL.coxph_+3A_complexity">complexity</code></td>
<td>
<p>not used.</p>
</td></tr>
<tr><td><code id="PLL.coxph_+3A_...">...</code></td>
<td>
<p>additional arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used by function <code>peperr</code>, if function <code>fit.coxph</code> is used for model fit.
</p>


<h3>Value</h3>

<p>Vector of length <code>n_new</code>
</p>

<hr>
<h2 id='plot.peperr'>Plot method for peperr object</h2><span id='topic+plot.peperr'></span>

<h3>Description</h3>

<p>Plots, allowing to get a first impression of the prediction error estimates and to check complexity selection in bootstrap samples.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'peperr'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.peperr_+3A_x">x</code></td>
<td>
<p><code>peperr</code> object.</p>
</td></tr>
<tr><td><code id="plot.peperr_+3A_y">y</code></td>
<td>
<p>not used.</p>
</td></tr>
<tr><td><code id="plot.peperr_+3A_...">...</code></td>
<td>
<p>additional arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots provide a simple and fast overview of the results of the estimation of the prediction error through resampling. Which plots are shown depends on if complexity was selected, i.e., a function was passed in the <code>peperr</code> call for <code>complexity</code>, or explicitly passed. In case of survival response, prediction error curves are shown. In case of binary response, where one complexity value is passed explicitly, no plot is available.
Especially in the case that complexity is selected in each bootstrap sample, these diagnostic plots help to check whether the resampling procedure works adequately and to detect specific problems due to high-dimensional data structures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n &lt;- 200
p &lt;- 100
beta &lt;- c(rep(1,10),rep(0,p-10))
x &lt;- matrix(rnorm(n*p),n,p)
real.time &lt;- -(log(runif(n)))/(10*exp(drop(x %*% beta)))
cens.time &lt;- rexp(n,rate=1/10)
status &lt;- ifelse(real.time &lt;= cens.time,1,0)
time &lt;- ifelse(real.time &lt;= cens.time,real.time,cens.time)

peperr.object1 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, complexity=c(50, 75), 
   indices=resample.indices(n=length(time), method="sub632", sample.n=10))
plot(peperr.object1)

peperr.object2 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, args.fit=list(penalty=100),
   complexity=complexity.mincv.CoxBoost, args.complexity=list(penalty=100),
   indices=resample.indices(n=length(time), method="sub632", sample.n=10),
   trace=TRUE)
plot(peperr.object2)

peperr.object3 &lt;- peperr(response=Surv(time, status), x=x, 
   fit.fun=fit.CoxBoost, args.fit=list(penalty=100),
   complexity=complexity.mincv.CoxBoost, args.complexity=list(penalty=100),
   indices=resample.indices(n=length(time), method="sub632", sample.n=10),
   args.aggregation=list(times=seq(0, quantile(time, probs=0.9), length.out=100)),
   trace=TRUE)
plot(peperr.object3)

## End(Not run)
</code></pre>

<hr>
<h2 id='pmpec'>Calculate prediction error curves</h2><span id='topic+pmpec'></span>

<h3>Description</h3>

<p>Calculation of prediction error curve from a survival response and predicted probabilities of survival.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmpec(object, response=NULL, x=NULL, times, model.args=NULL, 
    type=c("PErr","NoInf"), external.time=NULL, external.status=NULL, 
    data=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmpec_+3A_object">object</code></td>
<td>
<p>fitted model of a class for which the interface function <code>predictProb.class</code> is available.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_response">response</code></td>
<td>
<p>Either a survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing event status, coded with 0 and 1) or a matrix with columns <code>time</code> containing survival times and <code>status</code> containing integers, where 0 indicates censoring, 1 the interesting event and larger numbers other competing risks.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_times">times</code></td>
<td>
<p>vector of time points at which the prediction error is to be estimated.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_model.args">model.args</code></td>
<td>
<p>named list of additional arguments, e.g. complexity value, which are to be passed to <code>predictProb</code> function.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_type">type</code></td>
<td>
<p>type of output: Estimated prediction error (default) or no information error (prediction error obtained by permuting the data).</p>
</td></tr>
<tr><td><code id="pmpec_+3A_external.time">external.time</code></td>
<td>
<p>optional vector of time points, used for censoring distribution.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_external.status">external.status</code></td>
<td>
<p>optional vector of status values, used for censoring distribution.</p>
</td></tr>
<tr><td><code id="pmpec_+3A_data">data</code></td>
<td>
<p>Data frame containing <code>n</code>-vector of observed times ('time'), <code>n</code>-vector of event status ('status') and <code>n*p</code> matrix of covariates (remaining entries). Alternatively to <code>response</code> and <code>x</code>, for compatibility to <span class="pkg">pec</span>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prediction error of survival data is measured by the Brier score, which considers the squared difference of the true event status at a given time point and the predicted event status by a risk prediction model at that time. A prediction error curve is the weighted mean Brier score as a function of time at time points in <code>times</code> (see References).
</p>
<p><code>pmpec</code> requires a <code>predictProb</code> method for the class of the fitted model, i.e. for a model of class <code>class</code> <code>predictProb.class</code>. 
</p>
<p><code>pmpec</code> is implemented to behave similar to function <code>pec</code> of package <span class="pkg">pec</span>, which provides several <code>predictProb</code> methods.
</p>
<p>In bootstrap framework, <code>data</code> contains only a part of the full data set. For censoring distribution, the full data should be used to avoid extreme variance in case of small data sets. For that, the observed times and status values can be passed as argument <code>external.time</code> and <code>external.status</code>.
</p>


<h3>Value</h3>

<p>Vector of prediction error estimates at each time point given in <code>time</code>.
</p>


<h3>Author(s)</h3>

<p>Harald Binder</p>


<h3>References</h3>

<p>Gerds, A. and Schumacher, M. (2006) Consistent estimation of the expected Brier score in general survival models with right-censored event times. Biometrical Journal, 48, 1029&ndash;1040.
</p>
<p>Schoop, R. (2008) Predictive accuracy of failure time models with longitudinal covariates. PhD thesis, University of Freiburg.  http://www.freidok.uni-freiburg.de/volltexte/4995/.
</p>


<h3>See Also</h3>

<p><code>predictProb</code>, <span class="pkg">pec</span></p>

<hr>
<h2 id='predictProb'>Generic function for extracting predicted survival probabilities</h2><span id='topic+predictProb'></span>

<h3>Description</h3>

<p>Generic function for extraction of predicted survival probabilities from a fitted survival model conforming to the interface required by <code>pmpec</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictProb(object, response, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProb_+3A_object">object</code></td>
<td>
<p>a fitted survival model.</p>
</td></tr>
<tr><td><code id="predictProb_+3A_response">response</code></td>
<td>
<p>Either a survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing event status, coded with 0 and 1) or a matrix with columns <code>time</code> containing survival times and <code>status</code> containing integers, where 0 indicates censoring, 1 the interesting event and larger numbers other competing risks. In case of binary response, vector with entries 0 and 1.</p>
</td></tr>
<tr><td><code id="predictProb_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>	  
<tr><td><code id="predictProb_+3A_...">...</code></td>
<td>
<p>additional arguments, for example model complexity or, in case of survival response, argument <code>times</code>, a vector containing evaluation times. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pmpec</code> requires a <code>predictProb.class</code> function for each model fit of class <code>class</code>. It extracts the predicted probability of survival from this model.
</p>
<p>See existing <code>predictProb</code> functions, at the time <code>predictProb.CoxBoost</code>, <code>predictProb.coxph</code> and <code>predictProb.survfit</code>. 
</p>
<p>If desired <code>predictProb</code> function for class <code>class</code> is not available in <span class="pkg">peperr</span>, but implemented in package <span class="pkg">pec</span> as <code>predictSurvProb.class</code>, it can easily be transformed as <code>predictProb</code> method.
</p>


<h3>Value</h3>

<p>Matrix with predicted probabilities for each evaluation time point in <code>times</code> (columns) and each new observation (rows). 
</p>

<hr>
<h2 id='predictProb.coxph'>Extract predicted survival probabilities from a coxph object</h2><span id='topic+predictProb.coxph'></span>

<h3>Description</h3>

<p>Extracts predicted survival probabilities for survival models fitted by Cox proportional hazards model, providing an interface as required by <code>pmpec</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coxph'
predictProb(object, response, x, times, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProb.coxph_+3A_object">object</code></td>
<td>
<p>a fitted model of class <code>coxph</code>.</p>
</td></tr>
<tr><td><code id="predictProb.coxph_+3A_response">response</code></td>
<td>
<p>survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing survival status, coded with 0 and 1.</p>
</td></tr>
<tr><td><code id="predictProb.coxph_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="predictProb.coxph_+3A_times">times</code></td>
<td>
<p>vector of evaluation time points.</p>
</td></tr>
<tr><td><code id="predictProb.coxph_+3A_...">...</code></td>
<td>
<p>additional arguments, currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with probabilities for each evaluation time point in <code>times</code>(columns) and each new observation (rows). 
</p>

<hr>
<h2 id='predictProb.survfit'>Extract predicted survival probabilities from a survfit object</h2><span id='topic+predictProb.survfit'></span>

<h3>Description</h3>

<p>Extracts predicted survival probabilities for survival models fitted by <code>survfit</code>, providing an interface as required by <code>pmpec</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'survfit'
predictProb(object, response, x, times, train.data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProb.survfit_+3A_object">object</code></td>
<td>
<p>a fitted model of class <code>survfit</code>.</p>
</td></tr>
<tr><td><code id="predictProb.survfit_+3A_response">response</code></td>
<td>
<p>survival object (with <code>Surv(time, status)</code>, where time is an <code>n</code>-vector of censored survival times and status an <code>n</code>-vector containing survival status, coded with 0 and 1.</p>
</td></tr>
<tr><td><code id="predictProb.survfit_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="predictProb.survfit_+3A_times">times</code></td>
<td>
<p>vector of evaluation time points.</p>
</td></tr>
<tr><td><code id="predictProb.survfit_+3A_train.data">train.data</code></td>
<td>
<p>not used.</p>
</td></tr>
<tr><td><code id="predictProb.survfit_+3A_...">...</code></td>
<td>
<p>additional arguments, currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with probabilities for each evaluation time point in <code>times</code>(columns) and each new observation (rows). 
</p>

<hr>
<h2 id='resample.indices'>Generation of indices for resampling Procedure</h2><span id='topic+resample.indices'></span>

<h3>Description</h3>

<p>Generates training and test set indices for use in resampling estimation of prediction error, e.g. cross-validation or bootstrap (with and without replacement).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample.indices(n, sample.n = 100, method = c("no", "cv" ,"boot", "sub632"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resample.indices_+3A_n">n</code></td>
<td>
<p>number of observations of the full data set.</p>
</td></tr>
<tr><td><code id="resample.indices_+3A_sample.n">sample.n</code></td>
<td>
<p>the number of bootstrap samples in case of <code>method="boot"</code> and the number of cross-validation subsets in case of <code>method="cv"</code>, e.g. 10 for 10-fold cross-validation. Not considered if <code>method="no"</code>, where number of samples is one (the full data set) by definition.</p>
</td></tr>
<tr><td><code id="resample.indices_+3A_method">method</code></td>
<td>
<p>by default, the training set indices are the same as the test set indices, i.e. the model is assessed in the same data as fitted (<code>"no"</code>). <code>"cv"</code>: Cross-validation, <code>"boot"</code>: Bootstrap (with replacement), <code>"sub632"</code>: Boostrap without replacement, also called subsampling. In the latter case, the number of observations in each sample equals <code>round(0.632 * n)</code>, see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As each bootstrap sample should be taken as if new data, complexity selection should be carried out in each bootstrap sample. Binder and Schumacher show that when bootstrap samples are drawn with replacement, often too complex models are obtained in high-dimensional data settings. They recommend to draw bootstrap samples without replacement, each of size <code>round(0.632 * n)</code>, which equals the expected number of unique observations in one bootstrap sample drawn with replacement, to avoid biased complexity selection and improve predictive power of the resulting models. 
</p>


<h3>Value</h3>

<p>A list containing two lists of length <code>sample.n</code>:
</p>
<table>
<tr><td><code>sample.index</code></td>
<td>
<p>contains in each element the indices of observations of one training set.</p>
</td></tr>
<tr><td><code>not.in.sample</code></td>
<td>
<p>contains in each element the indices of observations of one test set, corresponding to the training set in listelement <code>sample.index</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Binder, H. and Schumacher, M. (2008) Adapting prediction error estimates for biased complexity selection in high-dimensional bootstrap samples. Statistical Applications in Genetics and Molecular Biology, 7:1.</p>


<h3>See Also</h3>

<p><code>peperr</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># generate dataset: 100 patients, 20 covariates
data &lt;- matrix(rnorm(2000), nrow=100)

# generate indices for training and test data for 10-fold cross-validation
indices &lt;- resample.indices(n=100, sample.n = 10, method = "cv")

# create training and test data via indices
trainingsample1 &lt;- data[indices$sample.index[[1]],]
testsample1 &lt;- data[indices$not.in.sample[[1]],]
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
