<!DOCTYPE html><html><head><title>Help for package PowerTOST</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PowerTOST}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bib.CL'>
<p>Design matrices of period balanced incomplete block designs</p></a></li>
<li><a href='#CI.BE'>
<p>1&ndash;2*alpha confidence interval given point estimate, CV, and n</p></a></li>
<li><a href='#CI.RatioF'>
<p>1&ndash;2*alpha Fieller CI given point estimate, CV (, CVb) and n</p></a></li>
<li><a href='#ct5.1+ct5.2+ct5.3+ct5.4.1'><p>Sample Size Tables for the Classical 2x2 Crossover Design</p></a></li>
<li><a href='#ct9.6.2+ct9.6.6'><p>Sample Size Tables for the 2x2x3 Replicate Crossover Design</p></a></li>
<li><a href='#ct9.6.4+ct9.6.8'><p>Sample Size Tables for the 2x4x4 Replicate Crossover Design</p></a></li>
<li><a href='#ctSJ.VIII.10+ctSJ.VIII.20+ctCW.III'><p>Sample Size Tables for the Parallel Group Design</p></a></li>
<li><a href='#CV2se+se2CV+CV2mse+mse2CV'><p>Helper functions</p></a></li>
<li><a href='#CVCL'>
<p>Confidence limits of a CV for log-normal data</p></a></li>
<li><a href='#CVfromCI'><p>CV from a given Confidence interval</p></a></li>
<li><a href='#CVp2CV'>
<p>Decompose CV(T) and CV(R) from 'pooled' CV of T/R</p></a></li>
<li><a href='#CVpooled'><p>Pooled CV from several studies</p></a></li>
<li><a href='#CVwRfromU'><p>CVwR from the upper expanded limit (ABEL)</p></a></li>
<li><a href='#defunct'><p>Removed functions in PowerTOST</p></a></li>
<li><a href='#deprecated'><p>Deprecated functions in PowerTOST</p></a></li>
<li><a href='#exppower.noninf'>
<p>Expected power of the non-inferiority test</p></a></li>
<li><a href='#exppower.TOST'>
<p>Expected power of the TOST procedure</p></a></li>
<li><a href='#expsampleN.noninf'>
<p>Sample size based on expected power for the non-inferiority test</p></a></li>
<li><a href='#expsampleN.TOST'>
<p>Sample size based on expected power</p></a></li>
<li><a href='#known.designs'><p>Show the 'known' designs</p></a></li>
<li><a href='#OwensQ'><p>Owen's Q-function</p></a></li>
<li><a href='#OwensQOwen'>
<p>Owen's Q-function via repeated integration by parts</p></a></li>
<li><a href='#OwensT'>
<p>Owen's T-function</p></a></li>
<li><a href='#pa.ABE'>
<p>Power analysis for average bioequivalence (ABE)</p></a></li>
<li><a href='#pa.NTID'>
<p>Power analysis for scaled ABE for NTIDs</p></a></li>
<li><a href='#pa.scABE'>
<p>Power analysis for scaled average bioequivalence (scABE)</p></a></li>
<li><a href='#power.2TOST'>
<p>Power for two simultaneous TOST procedures</p></a></li>
<li><a href='#power.dp'>
<p>Power of dose-proportionality studies evaluated via Power model</p></a></li>
<li><a href='#power.HVNTID'>
<p>(Empirical) Power for BE decision via FDA method for highly variable NTIDs</p></a></li>
<li><a href='#power.noninf'>
<p>Power of the one-sided non-inferiority t-test</p></a></li>
<li><a href='#power.NTID'>
<p>(Empirical) Power for BE decision via FDA method for NTIDs</p></a></li>
<li><a href='#power.RatioF'>
<p>Power for equivalence of the ratio of two means with normality on original scale</p></a></li>
<li><a href='#power.RSABE'>
<p>(Empirical) Power for BE decision via linearized scaled ABE criterion</p></a></li>
<li><a href='#power.RSABE2L.sdsims'>
<p>(Empirical) Power of BE Decision via Reference Scaled ABE</p></a></li>
<li><a href='#power.scABEL'>
<p>(Empirical) Power of BE decision via scaled (widened) BE acceptance limits</p></a></li>
<li><a href='#power.scABEL.sds'>
<p>(Empirical) Power of BE decision via scaled (widened) BE acceptance limits</p></a></li>
<li><a href='#power.TOST'>
<p>Power of the classical TOST procedure</p></a></li>
<li><a href='#power.TOST.sds'>
<p>Power calculation of the BE decision with models incorporating groups</p></a></li>
<li><a href='#power.TOST.sim'>
<p>Power of the TOST procedure obtained via simulations</p></a></li>
<li><a href='#pvalue.TOST'>
<p>p-value(s) of the TOST procedure</p></a></li>
<li><a href='#reg_const'>
<p>Constructor of an object with class 'regSet' containing the regulatory settings for ABEL</p></a></li>
<li><a href='#sampleN.2TOST'>
<p>Sample size based on power of two TOSTs</p></a></li>
<li><a href='#sampleN.dp'>
<p>Sample size estimation of dose-proportionality studies evaluated via the power model</p></a></li>
<li><a href='#sampleN.HVNTID'>
<p>Sample size estimation for BE decision via FDA method for highly variable (HV)</p>
narrow therapeutic index drugs (NTIDs)</a></li>
<li><a href='#sampleN.noninf'>
<p>Sample size for the non-inferiority t-test</p></a></li>
<li><a href='#sampleN.NTID'>
<p>Sample size estimation for BE decision via the FDA's method for narrow therapeutic index drugs (NTIDs)</p></a></li>
<li><a href='#sampleN.RatioF'>
<p>Sample size for equivalence of the ratio of two means with normality on original scale</p></a></li>
<li><a href='#sampleN.RSABE'>
<p>Sample size estimation for BE decision via linearized scaled ABE criterion</p></a></li>
<li><a href='#sampleN.RSABE2L.sdsims'>
<p>Sample size estimation for BE Decision via Reference Scaled ABE</p></a></li>
<li><a href='#sampleN.scABEL'>
<p>Sample size estimation for BE decision via scaled (expanded) BE acceptance limits</p></a></li>
<li><a href='#sampleN.scABEL.ad'>
<p>Sample size estimation for ABEL and iteratively adjusted alpha</p></a></li>
<li><a href='#sampleN.scABEL.sdsims'>
<p>Sample size estimation for BE decision via scaled (expanded) BE acceptance limits</p></a></li>
<li><a href='#sampleN.TOST'>
<p>Sample size based on power of TOST</p></a></li>
<li><a href='#scABEL'>
<p>Scaled (widened) BE Acceptance Limits</p></a></li>
<li><a href='#scABEL.ad'>
<p>Iteratively adjusted alpha for ABEL</p></a></li>
<li><a href='#type1error.2TOST'>
<p>Type I error rate for two simultaneous TOST procedures</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Power and Sample Size for (Bio)Equivalence Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5-6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-18</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions to calculate power and sample size for
    various study designs used in bioequivalence studies. Use known.designs() to
    see the designs supported. Power and sample size can be obtained based on
    different methods, amongst them prominently the TOST procedure (two one-sided
    t-tests). See README and NEWS for further information.</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm, stats, utils, graphics, grDevices, cubature (&ge;
1.3-6)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>crossdes, knitr, rmarkdown, tufte, emmeans</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Detlew/PowerTOST">https://github.com/Detlew/PowerTOST</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Detlew/PowerTOST/issues">https://github.com/Detlew/PowerTOST/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-18 18:49:54 UTC; Detlew</td>
</tr>
<tr>
<td>Author:</td>
<td>Detlew Labes <a href="https://orcid.org/0000-0003-2169-426X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Helmut Schütz <a href="https://orcid.org/0000-0002-1167-7880"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Benjamin Lang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Detlew Labes &lt;DetlewLabes@gmx.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-18 19:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='bib.CL'>
Design matrices of period balanced incomplete block designs
</h2><span id='topic+bib.CL'></span>

<h3>Description</h3>

<p>This function returns the &lsquo;design&rsquo; matrix of incomplete
block designs described by Chow &amp; Liu. The design matrices were
recoded <code style="white-space: pre;">&#8288;1=R&#8288;</code>, <code style="white-space: pre;">&#8288;2=T1&#8288;</code>, <code style="white-space: pre;">&#8288;3=T2&#8288;</code>, ...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bib.CL(trt, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bib.CL_+3A_trt">trt</code></td>
<td>

<p>Number of treatments (<code style="white-space: pre;">&#8288;3&#8288;</code> to <code style="white-space: pre;">&#8288;5&#8288;</code>). 
</p>
</td></tr>
<tr><td><code id="bib.CL_+3A_p">p</code></td>
<td>

<p>Number of periods (<code style="white-space: pre;">&#8288;2&#8288;</code> to <code style="white-space: pre;">&#8288;trt-1&#8288;</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix containing the sequences in rows and periods in columns.<br /> 
The entry <code style="white-space: pre;">&#8288;(i, j)&#8288;</code> of the matrix corresponds to the treatment or
dose (index) a subject within <em>i</em>-th sequence gets in the
<em>j</em>-th period.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Chow SC, Liu JP. <em>Design and Analysis of Bioavailability and Bioequivalence Studies.</em> Boca Raton: CRC Press; 3<sup>rd</sup> edition 2009. Chapter 2.6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 4 treatments/doses, 3 periods
bib.CL(4, 3)
# gives 4 sequences
# to see this in Chow &amp; Liu's coding
tmt &lt;- c("R", "T1", "T2", "T3")
matrix(tmt[bib.CL(4, 3)], ncol=3)
</code></pre>

<hr>
<h2 id='CI.BE'>
1&ndash;2*alpha confidence interval given point estimate, CV, and n
</h2><span id='topic+CI.BE'></span>

<h3>Description</h3>

<p>Utility function to calculate the
1&ndash;2&alpha;
CI given point estimate, CV, and n for the various designs
covered in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.BE(alpha = 0.05, pe, CV, n, design = "2x2", robust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.BE_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Defaults to 0.05.
</p>
</td></tr>
<tr><td><code id="CI.BE_+3A_pe">pe</code></td>
<td>

<p>Point estimate (GMR).
</p>
</td></tr>
<tr><td><code id="CI.BE_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation as ratio (not percent). 
</p>
</td></tr>
<tr><td><code id="CI.BE_+3A_n">n</code></td>
<td>

<p>Total number of subjects if a scalar is given.<br />
Number of subjects in (sequence) groups if given as vector.
</p>
</td></tr>
<tr><td><code id="CI.BE_+3A_design">design</code></td>
<td>

<p>Character string describing the study’s design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="CI.BE_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>.<br />
Setting to <code>TRUE</code> will use the degrees of freedom according
to the &lsquo;robust&rsquo; evaluation (aka Senn’s basic
estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the 1&ndash;2&alpha;
confidence interval.<br />
Returns a vector with named elements <code>lower</code>, <code>upper</code> if
arguments <code>pe</code> and <code>CV</code> are scalars, else a matrix with
columns <code>lower</code>, <code>upper</code> is returned.
</p>


<h3>Note</h3>

<p>The function assumes an evaluation using log-transformed data.<br />
The function assumes equal variances in case of <code>design="parallel"</code>
and the higher order crossover designs.<br />
The implemented formula covers balanced and unbalanced designs.<br /><br />
Whether the function vectorizes properly is not thoroughly tested.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 90% confidence interval for the 2x2 crossover
# n(total) = 24
CI.BE(pe = 0.95, CV = 0.3, n = 24)
# should give
#     lower     upper 
# 0.8213465 1.0988055 
# same total number but unequal sequences
CI.BE(pe = 0.95, CV = 0.3, n = c(13, 11))
#     lower     upper
# 0.8209294 1.0993637   
</code></pre>

<hr>
<h2 id='CI.RatioF'>
1&ndash;2*alpha Fieller CI given point estimate, CV (, CVb) and n
</h2><span id='topic+CI.RatioF'></span>

<h3>Description</h3>

<p>Utility function to calculate the
1&ndash;2&alpha;
Fieller confidence interval given the point estimate, 
CV (, CVb), and n for the parallel group and
2&times;2
crossover.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.RatioF(alpha = 0.025, pe, CV, CVb, n, design = c("2x2", "parallel"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.RatioF_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, aka significance level.<br />
Defaults here to 0.025 because this function is intended for studies
with clinical endpoints. 
</p>
</td></tr>
<tr><td><code id="CI.RatioF_+3A_pe">pe</code></td>
<td>

<p>Point estimate of T/R ratio.
</p>
</td></tr>
<tr><td><code id="CI.RatioF_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation as ratio (not percent). In case of <code>design="parallel"</code>
this is the CV of the total variability, in case of <code>design="2x2"</code>
the intra-subject CV.
</p>
</td></tr>
<tr><td><code id="CI.RatioF_+3A_cvb">CVb</code></td>
<td>

<p>CV of the between-subject variability. Only necessary for
<code>design="2x2"</code>.
</p>
</td></tr>
<tr><td><code id="CI.RatioF_+3A_n">n</code></td>
<td>

<p>Total number of subjects if a scalar is given.<br />
Number of subjects in (sequence) groups if given as vector.
</p>
</td></tr>
<tr><td><code id="CI.RatioF_+3A_design">design</code></td>
<td>

<p>A character string describing the study design.<br /> 
<code>design="parallel"</code> or <code>design="2x2"</code> allowed for a
parallel two-group design or a classical TR|RT crossover design.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CV(within) and CVb(etween) in case of <code>design="2x2"</code> are
obtainedvia an appropriate ANOVA from the error term and from the
difference <code>(MS(subject within sequence)-MS(error))/2</code>.
</p>


<h3>Value</h3>

<p>Returns the
1&ndash;2&alpha;
confidence interval.
</p>


<h3>Note</h3>

<p>The function assumes an evaluation using un-transformed data.<br />
The function assumes equal variances in case of <code>design="parallel"</code>.<br />
The formula implemented covers balanced and unbalanced designs.<br /><br />
Note that when the mean of the denominator of the ratio is close to zero, 
confidence intervals might be degenerated and are returned as <code>NA</code>. In such
a case a warning is issued.<br /><br />
Whether the function vectorizes properly is not thoroughly tested.<br /><br />
This function is intended for studies with clinical endpoints. In such
studies the 95% confidence intervals are usually used for equivalence 
testing. Therefore, alpha defaults here to 0.025 (see <abbr><span class="acronym">EMA</span></abbr> 2000).
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Locke CS. <em>An exact confidence interval from untransformed data for the ratio of 
two formulation means.</em> J Pharmacokin Biopharm. 1984;12(6):649&ndash;55. <a href="https://doi.org/10.1007/BF01059558">doi:10.1007/BF01059558</a>
</p>
<p>Hauschke D, Steinijans VW, Pigeot I. <em>Bioequivalence Studies in Drug Development.</em> Chichester: John Wiley; 2007. Chapter 10. <a href="https://doi.org/10.1002/9780470094778.fmatter">doi:10.1002/9780470094778.fmatter</a>
</p>
<p>European Medicines Agency, Committee for Proprietary Medicinal Products. <em>Points to consider on switching between superiority and non-inferiority.</em> London, 27 July 2000. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/points-consider-switching-between-superiority-and-non-inferiority_en.pdf">CPMP/EWP/482/99</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CI.BE">CI.BE</a></code>, <code><a href="#topic+power.RatioF">power.RatioF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 95% Fieller CI for the 2x2 crossover
CI.RatioF(pe = 0.95, CV = 0.3, CVb = 0.6, n = 32)
</code></pre>

<hr>
<h2 id='ct5.1+2Bct5.2+2Bct5.3+2Bct5.4.1'>Sample Size Tables for the Classical 2x2 Crossover Design</h2><span id='topic+data2x2'></span><span id='topic+ct5.1'></span><span id='topic+ct5.2'></span><span id='topic+ct5.3'></span><span id='topic+ct5.4.1'></span>

<h3>Description</h3>

<p>These data.frames give sample size tables calculated with 
<code>sampleN.TOST()</code> for the 2×2 design.</p>


<h3>Details</h3>

<p>The data.frames can be accessed by their names.<br />
</p>

<table>
<tr>
 <td style="text-align: center;">
    data.frame </td><td style="text-align: left;"> Description</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.1 </td><td style="text-align: left;"> Multiplicative model, theta1=0.8, theta2=1.25 (1/theta1), exact</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.2 </td><td style="text-align: left;"> Multiplicative model, theta1=0.75, theta2=1.3333 (1/theta1), exact</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.3 </td><td style="text-align: left;"> Multiplicative model, theta1=0.9, theta2=1.1111 (1/theta1), exact</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.4.1 </td><td style="text-align: left;"> Additive model, theta1=--0.2, theta2=+0.2 (BE limits 0.80 -- 1.20), exact
  </td>
</tr>

</table>



<h3>Note</h3>

<p>Scripts for creation of these data.frames can be found in the <code>/tests</code>
sub-directory of the package.<br />
Comparing the results of these scripts to the corresponding data.frames can 
be used for validation purposes.</p>


<h3>Author(s)</h3>

<p>PowerTOST</p>


<h3>Source</h3>


<table>
<tr>
 <td style="text-align: center;">
    data.frame </td><td style="text-align: left;"> Origin </td><td style="text-align: left;"> Details</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.1 </td><td style="text-align: left;"> Hauschke <em>et al.</em> </td><td style="text-align: left;"> Table 5.1 (p 113--114)</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.2 </td><td style="text-align: left;"> Hauschke <em>et al.</em> </td><td style="text-align: left;"> Table 5.2 (p 115--116) </td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.3 </td><td style="text-align: left;"> Hauschke <em>et al.</em> </td><td style="text-align: left;"> Table 5.3 (p 118)</td>
</tr>
<tr>
 <td style="text-align: center;">
    ct5.4.1 </td><td style="text-align: left;"> Chow &amp; Liu </td><td style="text-align: left;"> Table 5.4.1 (p 158)
  </td>
</tr>

</table>



<h3>References</h3>

<p>Hauschke D, Steinijans VW, Pigeot I. <em>Bioequivalence Studies in Drug Development.</em> Chichester: John Wiley; 2007.
</p>
<p>Chow SC, Liu JP. <em>Design and Analysis of Bioavailability and Bioequivalence Studies.</em> Boca Raton: CRC Press; 3<sup>rd</sup> edition 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ct5.1
ct5.2
ct5.3
ct5.4.1
</code></pre>

<hr>
<h2 id='ct9.6.2+2Bct9.6.6'>Sample Size Tables for the 2x2x3 Replicate Crossover Design</h2><span id='topic+data2x2x3'></span><span id='topic+ct9.6.2'></span><span id='topic+ct9.6.6'></span>

<h3>Description</h3>

<p>These data.frames give sample size tables calculated with 
<code>sampleN.TOST()</code> for the 2×2×3 replicate crossover design
(2-treatment 2-sequence 3-period design.</p>


<h3>Details</h3>

<p>The data.frames can be accessed by their names.<br />
</p>

<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: left;"> Description</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.2 </td><td style="text-align: left;"> Additive model, theta1=--0.2, theta2=+0.2 (BE limits 0.80 -- 1.20)</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via shifted non-central <em>t</em>-distribution</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.6 </td><td style="text-align: left;"> Multiplicative model, theta1=0.8, theta2=1.25 (1/theta1)</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via shifted non-central <em>t</em>-distribution
  </td>
</tr>

</table>

<p>Attention! CV is se (standard error) of residuals.
</p>


<h3>Note</h3>

<p>Scripts for creation of these data.frames can be found in the <code>/tests</code>
sub-directory of the package.<br />
Comparing the results of these scripts to the corresponding data.frames can 
be used for validation purposes.</p>


<h3>Author(s)</h3>

<p>PowerTOST</p>


<h3>Source</h3>


<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: center;"> Origin </td><td style="text-align: left;"> Details</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.2 </td><td style="text-align: center;"> Chow &amp; Liu </td><td style="text-align: left;"> Table 9.6.2 (p 292)</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.6 </td><td style="text-align: center;"> Chow &amp; Liu </td><td style="text-align: left;"> Table 9.6.6 (p 293)
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chow SC, Liu JP. <em>Design and Analysis of Bioavailability and Bioequivalence Studies.</em> Boca Raton: CRC Press; 3<sup>rd</sup> edition 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ct9.6.2
ct9.6.6
</code></pre>

<hr>
<h2 id='ct9.6.4+2Bct9.6.8'>Sample Size Tables for the 2x4x4 Replicate Crossover Design</h2><span id='topic+data2x4x4'></span><span id='topic+ct9.6.4'></span><span id='topic+ct9.6.8'></span>

<h3>Description</h3>

<p>These data.frames give sample size tables calculated with 
<code>sampleN.TOST()</code> for the 2×4×4 replicate crossover design
(2-treatment 4-sequence 4-period design).</p>


<h3>Details</h3>

<p>The data.frames can be accessed by their names.<br />
</p>

<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: left;"> Description</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.4 </td><td style="text-align: left;"> Additive model, theta1=--0.2, theta2=+0.2 (BE limits 0.80 -- 1.20)</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via shifted non-central <em>t</em>-distribution</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.8 </td><td style="text-align: left;"> Multiplicative model, theta1=0.8, theta2=1.25 (1/theta1)</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via shifted non-central <em>t</em>-distribution
  </td>
</tr>

</table>

<p>Attention! CV is se (standard error) of residuals.
</p>


<h3>Note</h3>

<p>Scripts for creation of these data.frames can be found in the <code>/tests</code>
sub-directory of the package.<br />
Comparing the results of these scripts to the corresponding data.frames can 
be used for validation purposes.</p>


<h3>Author(s)</h3>

<p>PowerTOST</p>


<h3>Source</h3>


<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: center;"> Origin </td><td style="text-align: left;"> Details</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.4 </td><td style="text-align: center;"> Chow &amp; Liu </td><td style="text-align: left;"> Table 9.6.4 (p 294)</td>
</tr>
<tr>
 <td style="text-align: left;">
    ct9.6.8 </td><td style="text-align: center;"> Chow &amp; Liu </td><td style="text-align: left;"> Table 9.6.8 (p 298)
  </td>
</tr>

</table>



<h3>References</h3>

<p>Chow SC, Liu JP. <em>Design and Analysis of Bioavailability and Bioequivalence Studies.</em> Boca Raton: CRC Press; 3<sup>rd</sup> edition 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ct9.6.4
ct9.6.8
</code></pre>

<hr>
<h2 id='ctSJ.VIII.10+2BctSJ.VIII.20+2BctCW.III'>Sample Size Tables for the Parallel Group Design</h2><span id='topic+data_parallel'></span><span id='topic+ctSJ.VIII.10'></span><span id='topic+ctSJ.VIII.20'></span><span id='topic+ctCW.III'></span>

<h3>Description</h3>

<p>These data.frames give sample size tables calculated with 
<code>sampleN.TOST()</code> for the parallel group design (2 groups).</p>


<h3>Details</h3>

<p>The data.frames can be accessed by their names.<br />
</p>

<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: left;"> Description</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctSJ.VIII.10 </td><td style="text-align: left;"> Multiplicative model, theta1=0.9, theta2=1.1111 (1/theta1), target power=90%</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via non-central <em>t</em>-distribution</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctSJ.VIII.20 </td><td style="text-align: left;"> Multiplicative model, theta1=0.8, theta2=1.25 (1/theta1), target power=90%</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> approximate power via non-central <em>t</em>-distribution</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctCW.III </td><td style="text-align: left;"> Additive model, theta1=--0.2, theta2=+0.2 (BE limits 0.80 -- 1.20), exact
  </td>
</tr>

</table>

<p>Attention! Julious gives sample size per group.
</p>


<h3>Note</h3>

<p>Scripts for creation of these data.frames can be found in the <code>/tests</code>
sub-directory of the package.<br />
Comparing the results of these scripts to the corresponding data.frames can 
be used for validation purposes.</p>


<h3>Author(s)</h3>

<p>PowerTOST</p>


<h3>Source</h3>


<table>
<tr>
 <td style="text-align: left;">
    data.frame </td><td style="text-align: center;"> Origin </td><td style="text-align: left;"> Details</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctSJ.VIII.10 </td><td style="text-align: center;"> Julious </td><td style="text-align: left;"> Table VIII (p. 1972), column &lsquo;Level of bioequivalence 10%&rsquo;</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctSJ.VIII.20 </td><td style="text-align: center;"> Julious </td><td style="text-align: left;"> Table VIII (p. 1972), column &lsquo;Level of bioequivalence 20%&rsquo;</td>
</tr>
<tr>
 <td style="text-align: left;">
    ctCW.III </td><td style="text-align: center;"> Chow &amp; Wang </td><td style="text-align: left;"> Table III (p. 164)
  </td>
</tr>

</table>

<p>Seems the last reference is not very reliable (compare to the table in the paper).
</p>


<h3>References</h3>

<p>Julious SA. <em>Tutorial in Biostatistics. Sample sizes for clinical trials with Normal data.</em> Stat Med. 2004;23(12):1921&ndash;86. <a href="https://doi.org/10.1002/sim.1783">doi:10.1002/sim.1783</a>
</p>
<p>Chow SC, Wang H. <em>On Sample Size Calculation in Bioequivalence Trials.</em> J Pharmacokinet Pharmacodyn. 2001;28(2):155&ndash;69. <a href="https://doi.org/10.1023/A%3A1011503032353">doi:10.1023/A:1011503032353</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ctSJ.VIII.10
ctSJ.VIII.20
ctCW.III
</code></pre>

<hr>
<h2 id='CV2se+2Bse2CV+2BCV2mse+2Bmse2CV'>Helper functions</h2><span id='topic+CV2se'></span><span id='topic+se2CV'></span><span id='topic+CV2mse'></span><span id='topic+mse2CV'></span>

<h3>Description</h3>

<p>Calculates the standard error or the mean squared error from a 
given CV and vice versa for log-normal data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV2se(CV)
se2CV(se)
CV2mse(CV)
mse2CV(mse)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV2se+2B2Bse2CV+2B2BCV2mse+2B2Bmse2CV_+3A_cv">CV</code></td>
<td>
<p>coefficient of variatio as ratio (not percent)</p>
</td></tr>
<tr><td><code id="CV2se+2B2Bse2CV+2B2BCV2mse+2B2Bmse2CV_+3A_se">se</code></td>
<td>
<p>standard error</p>
</td></tr>
<tr><td><code id="CV2se+2B2Bse2CV+2B2BCV2mse+2B2Bmse2CV_+3A_mse">mse</code></td>
<td>
<p>mean squared error (aka residual variance)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns<br />
<code style="white-space: pre;">&#8288;  se  = sqrt(log(CV^2+1))&#8288;</code><br />
<code style="white-space: pre;">&#8288;  CV  = sqrt(exp(se^2)-1)&#8288;</code><br />
<code style="white-space: pre;">&#8288;  mse = log(CV^2+1)&#8288;</code><br />
<code style="white-space: pre;">&#8288;  CV  = sqrt(exp(mse)-1)&#8288;</code>
</p>


<h3>Note</h3>

<p>These functions were originally intended for internal use only but may be useful for others.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>Examples</h3>

<pre><code class='language-R'># these functions are one liners:
CV2se &lt;- function(CV) return(sqrt(log(1.0 + CV^2)))
se2CV &lt;- function(se) return(sqrt(exp(se^2)-1))

CV2se(0.3)
# should give:
# [1] 0.2935604 

se2CV(0.2935604)
# [1] 0.3 
</code></pre>

<hr>
<h2 id='CVCL'>
Confidence limits of a CV for log-normal data
</h2><span id='topic+CVCL'></span>

<h3>Description</h3>

<p>The function calculates the 1&ndash;&alpha; confidence limits
(either 1-sided or 2-sided) via the &chi;<sup>2</sup>
distribution of the error variance the CV is based on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVCL(CV, df, side = c("upper", "lower", "2-sided"), alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVCL_+3A_cv">CV</code></td>
<td>
<p>Coefficient of variation as ratio (not percent)</p>
</td></tr>
<tr><td><code id="CVCL_+3A_df">df</code></td>
<td>
<p>degrees of freedom of the CV (error variance)</p>
</td></tr>
<tr><td><code id="CVCL_+3A_side">side</code></td>
<td>
<p>Side(s) to calculate the confidence limits for, defaults to <code>upper</code></p>
</td></tr>
<tr><td><code id="CVCL_+3A_alpha">alpha</code></td>
<td>
<p>Type I error probability, aka significance level</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector of the confidence limits named as <code>lower CL</code> and <code>upper CL</code>.<br />
In case of the one-sided upper confidence limit the <code>lower CL</code> is = 0.<br /> 
In case of the one-sided lower confidence limit the <code>upper CL</code> is = Inf. 
</p>


<h3>Author(s)</h3>

<p>D. Labes</p>


<h3>Examples</h3>

<pre><code class='language-R'># upper one-sided 95% CL of a CV=0.3 
# from a study with df=22 (f.i. a 2x2 crossover with n=24)
# default side="upper" since not explicitly given
CVCL(0.3, df = 22)
# should give:
#  lower CL  upper CL 
# 0.0000000 0.4075525 
</code></pre>

<hr>
<h2 id='CVfromCI'>CV from a given Confidence interval</h2><span id='topic+CVfromCI'></span><span id='topic+CI2CV'></span>

<h3>Description</h3>

<p>Calculates the CV (coefficient of variation) from a known confidence interval
of a BE study.<br /> 
Useful if no CV but the 90% CI was given in literature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVfromCI(pe, lower, upper, n, design = "2x2", alpha = 0.05, robust = FALSE)
CI2CV(pe, lower, upper, n, design = "2x2", alpha = 0.05, robust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVfromCI_+3A_pe">pe</code></td>
<td>

<p>Point estimate of the T/R ratio.<br />
The <code>pe</code> may be missing. In that case it will be calculated as geometric 
mean<br />
of <code>lower</code> and <code>upper</code>.
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_lower">lower</code></td>
<td>

<p>Lower confidence limit of the BE ratio.
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_upper">upper</code></td>
<td>

<p>Upper confidence limit of the BE ratio.
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_n">n</code></td>
<td>

<p>Total number of subjects under study if given as scalar.<br />
Number of subjects in (sequence) groups if given as vector.
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_alpha">alpha</code></td>
<td>

<p>Error probability. Set it to <code>(1-confidence)/2</code> (<em>i.e.</em> to 0.05 for the usual 90% confidence intervals).
</p>
</td></tr>
<tr><td><code id="CVfromCI_+3A_robust">robust</code></td>
<td>

<p>With <code>robust=FALSE</code> (the default) usual degrees of freedom of the designs are used.<br />
With <code>robust=TRUE</code> the degrees of freedom for the so-called robust
evaluation (df2 in known.designs()) will be used. This may be helpful
if the CI was evaluated via a mixed model or via intra-subject contrasts 
(aka Senn’s basic estimator).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Helmut Schütz’ <a href="https://bebac.at/lectures/Bucharest2013WS1.pdf#page=26">presentation</a> for the algebra underlying this function.
</p>


<h3>Value</h3>

<p>Numeric value of the CV as ratio.
</p>


<h3>Note</h3>

<p>The calculations are based on the assumption of evaluation via log-transformed values.<br />
The calculations are further based on a common variance of Test and Reference 
treatments in replicate crossover studies or parallel group study, respectively.<br /><br />
In case of argument <code>n</code> given as n(total) and is not divisible by the number
of (sequence) groups the total sample size is partitioned to the (sequence) groups
to have small imbalance only. A message is given in such cases.<br />
The estimated CV is conservative (<em>i.e.</em>, higher than actually observed) in case of 
unbalancedness.<br /><br />
<code>CI2CV()</code> is simply an alias to <code>CVfromCI()</code>.
</p>


<h3>Author(s)</h3>

<p>Original by D. Labes with suggestions by H. Schütz.<br />
Reworked and adapted to unbalanced studies by B. Lang.</p>


<h3>References</h3>

<p>Yuan J, Tong T, Tang M-L. <em>Sample Size Calculation for Bioequivalence Studies Assessing Drug Effect and Food Effect at the Same Time With a 3-Treatment Williams Design.</em> Regul Sci. 2013;47(2):242&ndash;7. <a href="https://doi.org/10.1177/2168479012474273">doi:10.1177/2168479012474273</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given a 90% confidence interval (without point estimate) 
# from a classical 2x2 crossover with 22 subjects
CVfromCI(lower=0.91, upper=1.15, n=22, design="2x2")
# will give [1] 0.2279405, i.e a CV ~ 23%
#
# unbalanced 2x2 crossover study, but not reported as  such
CI2CV(lower=0.89, upper=1.15, n=24)
# will give a CV ~ 26.3%
# unbalancedness accounted for
CI2CV(lower=0.89, upper=1.15, n=c(16,8))
# should give CV ~ 24.7%
</code></pre>

<hr>
<h2 id='CVp2CV'>
Decompose CV(T) and CV(R) from 'pooled' CV of T/R 
</h2><span id='topic+CVp2CV'></span>

<h3>Description</h3>

<p>Helper function to calculate CV(T) and CV(R) from a pooled CV(T/R)
assuming a ratio of the intra-subject variances. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVp2CV(CV, ratio = 1.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVp2CV_+3A_cv">CV</code></td>
<td>
<p>&lsquo;pooled&rsquo; CV of T and R (as ratio, not percent).
</p>
</td></tr>
<tr><td><code id="CVp2CV_+3A_ratio">ratio</code></td>
<td>

<p>Ratio of the intra-subject variances <code>s^2(T)/s^2(R)</code>.<br />
May be a vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In case of knowing only the CV(T/R) f.i. from an ordinary cross-over you can 
calculate the components CV(T) and CV(R) assuming a ratio of the 
intra-subject variances.<br />
The formula the function is based on:<br />
<code>log(1.0 + CV^2) = (sWT^2 + sWR^2)/2</code><br />
Insert <code>sWT^2 = ratio * sWR^2</code> and solve for <code>sWR^2</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric vector of the CV values for Test and Reference if only
one ratio is given.<br />
Returns a matrix with named columns <code>CVwT</code> and <code>CVwR</code> if ratio is given as vector.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CVp2CV(0.4, ratio=2)
# gives
# [1] 0.4677952 0.3225018
</code></pre>

<hr>
<h2 id='CVpooled'>Pooled CV from several studies</h2><span id='topic+CVpooled'></span><span id='topic+print.CVp'></span>

<h3>Description</h3>

<p>This function pools CVs of several studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVpooled(CVdata, alpha = 0.2, logscale = TRUE, robust = FALSE)
## S3 method for class 'CVp'
print(x, digits = 4, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVpooled_+3A_cvdata">CVdata</code></td>
<td>

<p>A data.frame that must contain the columns <code>CV</code>, <code>n</code> and <code>design</code> 
where <code>CV</code> are the error CVs from the studies, <code>n</code> the number of subjects 
and design is a character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.<br />
If the design column is missing the classical 2×2 crossover is assumed for each study.
A message is displayed under that circumstances.<br /><br />
A data.frame that contains the columns <code>CV</code> and giving the degrees of freedom 
<code>df</code> directly is also accepted as <code>CVdata</code>.
</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_alpha">alpha</code></td>
<td>

<p>Error probability for calculating an upper confidence limit of the pooled CV.<br />
Recommended 0.2&ndash;0.25 for use in subsequent sample size estimation.<br />
See f.i one of H. Schütz’ <a href="https://bebac.at/lectures/MU2010-CD2.pdf">presentations</a>.
</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_logscale">logscale</code></td>
<td>

<p>Should the calculations be done for log-transformed data? Defaults to <code style="white-space: pre;">&#8288;TRUE&#8288;</code>. 
</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code style="white-space: pre;">&#8288;FALSE&#8288;</code>.<br />
Set to <code style="white-space: pre;">&#8288;TRUE&#8288;</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’ basic estimator). These dfs are calculated as <code>n-seq</code>.<br />
They are also often more appropriate if the CV comes from a &lsquo;true&rsquo; mixed effects model 
evaluation (FDA model for average bioequivalence).<br />
See <code>known.designs()$df2</code> for the designs covered in this package.
</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_x">x</code></td>
<td>
<p>An object of class <code>"CVp"</code>.</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits for the <code>CV</code> and the <code>CL</code>.</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_verbose">verbose</code></td>
<td>
<p>Defaults to <code>FALSE</code>. Prints only the pooled <code>CV</code> and <code>df</code>.<br />
If set to <code style="white-space: pre;">&#8288;TRUE&#8288;</code> the upper confidence limit is also printed.
</p>
</td></tr>
<tr><td><code id="CVpooled_+3A_...">...</code></td>
<td>
<p>More args to print(). None used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The pooled CV is obtained from the weighted average of the error variances obtained from 
the CVs of the single studies, weights are the degrees of freedom <code>df</code>.<br />
If only <code>n</code> is given in the input <code>CVdata</code>, the dfs are calculated via
the formulas given in <code>known.designs()</code>. If both <code>n</code> and <code>df</code> are given
the <code>df</code> column precedes.<br /><br />
If <code>logscale=TRUE</code> the error variances are obtained via function <code>CV2se()</code>.
Otherwise the pooled CV is obtained via pooling the CV^2.
</p>


<h3>Value</h3>

<p>A list of class <code>"CVp"</code> with components
</p>
<table>
<tr><td><code>CV</code></td>
<td>
<p>value of the pooled CV</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>pooled degrees of freedom</p>
</td></tr>
<tr><td><code>CVupper</code></td>
<td>
<p>upper confidence interval of the pooled CV</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>input value</p>
</td></tr>
</table>
<p>The class <code>"CVp"</code> has a S3 methods <code>print.CVp</code>.
</p>


<h3>Warning</h3>

<p>Pooling of CVs from parallel group and crossover designs does not make any sense.<br />
Also the function <em>does not</em> throw an error if you do so.
</p>


<h3>Note</h3>

<p>The calculations for <code>logscale=FALSE</code> are not described in the references.
They are implemented by analogy to the case via log-transformed data.<br />
The calculations are based on a common variance of Test and Reference formulations 
in replicate crossover studies or a parallel group study, respectively.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>H. Schütz’ <a href="https://bebac.at:443/Lectures.phtml">presentations</a> about sample size challenges.
</p>
<p>Patterson S, Jones B. <em>Bioequivalence and Statistics in Clinical Pharmacology.</em> Boca Raton: Chapman &amp; Hall / CRC Press; 2<sup>nd</sup> edition 2017. Chapter 5.7 &ldquo;Determining Trial Size&rdquo;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+known.designs">known.designs</a>, <a href="#topic+CVfromCI">CVfromCI</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># some data:
# the values for AUC, study 1 and study 2 are Example 3 of H. Schuetz' presentation
CVs &lt;- ("
 PKmetric | CV   |  n |design| source
    AUC   | 0.20 | 24 | 2x2  | study 1
    Cmax  | 0.25 | 24 | 2x2  | study 1
    AUC   | 0.30 | 12 | 2x2  | study 2
    Cmax  | 0.31 | 12 | 2x2  | study 2
    AUC   | 0.25 | 12 | 2x2x4| study 3 (full replicate)
")
txtcon &lt;- textConnection(CVs)
CVdata &lt;- read.table(txtcon, header = TRUE, sep = "|",
                    strip.white = TRUE, as.is = TRUE)
close(txtcon)

# evaluation of the AUC CVs
CVsAUC &lt;- subset(CVdata, PKmetric == "AUC")
CVpooled(CVsAUC, alpha = 0.2, logscale = TRUE)
# df of the 'robust' evaluation
CVpooled(CVsAUC, alpha = 0.2, logscale = TRUE, robust = TRUE)
# print also the upper CL, data example 3
CVsAUC3 &lt;- subset(CVsAUC,design != "2x2x4")
print(CVpooled(CVsAUC3, alpha = 0.2, robust = TRUE), digits = 3, verbose = TRUE)
# will give the output:
# Pooled CV = 0.235 with 32 degrees of freedom (robust dfs)
# Upper 80% confidence limit of CV = 0.266
#
# Combining CVs from studies evaluated by ANOVA (robust=FALSE) and
# by a mixed effects model (robust=TRUE). dfs have to be provided!
CVs &lt;- ("
  CV    |  n |design| source  | model | df
  0.212 | 24 | 2x2  | study 1 | fixed | 22
  0.157 | 27 | 3x3  | study 2 | fixed | 50
  0.148 | 27 | 3x3  | study 3 | mixed | 24
")
txtcon &lt;- textConnection(CVs)
CVdata &lt;- read.table(txtcon, header = TRUE, sep = "|",
                     strip.white = TRUE, as.is = TRUE)
close(txtcon)
print(CVpooled(CVdata, alpha = 0.2), digits = 3, verbose = TRUE)
# will give the output:
# Pooled CV = 0.169 with 96 degrees of freedom
# Upper 80% confidence limit of CV = 0.181
</code></pre>

<hr>
<h2 id='CVwRfromU'>CVwR from the upper expanded limit (ABEL)</h2><span id='topic+CVwRfromU'></span><span id='topic+U2CVwR'></span>

<h3>Description</h3>

<p>Calculates the intra-subject CV (coefficient of variation) of the reference from
the upper expanded limit of a BE study (replicate design for ABEL).
Useful if no
<em>CV</em><sub>wR</sub> but the
expanded limits were given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVwRfromU(U, regulator = "EMA")
U2CVwR(U, regulator = "EMA")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVwRfromU_+3A_u">U</code></td>
<td>

<p>Upper expanded limit.<br />
Must be within {1.2500, 1.4319} if <code>regulator="EMA"</code> and within {1.2500, 1.5000}
if <code>regulator="HC"</code>.
</p>
</td></tr>
<tr><td><code id="CVwRfromU_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory body’s settings for expanding the BE acceptance limits,
given as a string from the choices <code>"EMA"</code> or <code>"HC"</code>. 
Defaults to <code>regulator="EMA"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only the upper expanded limit is supported since it offers one more 
significant digit than the lower expanded limit.
</p>


<h3>Value</h3>

<p>Numeric value of the <code>CVwR</code> as ratio, where
<code>CVwR = sqrt(exp((log(U)/r_const)^2)-1)</code>.
</p>


<h3>Note</h3>

<p><code>U2CVwR()</code> is simply an alias to <code>CVwRfromU()</code>.
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given the upper expanded limit and using the defaults
CVwRfromU(U = 1.38)
# should give [1] 0.44355, i.e., a CVwR ~ 44%
# Upper limit from a study according the Health Canada’s rules
CVwRfromU(U = 1.48, regulator = "HC")
# should give [1] 0.55214
</code></pre>

<hr>
<h2 id='defunct'>Removed functions in PowerTOST</h2><span id='topic+defunct'></span>

<h3>Description</h3>

<p>Details about removed functions in PowerTOST.
</p>


<h3>Details</h3>

<p><code>type1error.2TOST</code> was designed to calculate the type I error (<em>TIE</em>) rate of two simultaneous TOST procedures with some specified correlation of the parameters. It suffered from poor precision to obtain the <em>TIE</em> via simulations.<br />
Due to the intersection-union principle the <em>TIE</em> is always upper bounded to <em>&alpha;</em> by theory and hence, <code>type1error.2TOST</code> was removed in version 1.4-7.
</p>
<p><code>power.scABEL2</code> and <code>sampleN.scABEL2</code> were deprecated in version 1.4-1. In <code>power.scABEL</code> and <code>sampleN.scABEL</code> the regulator component <code>"est_method"</code> is used for switching between simulations based on the EMA’s ANOVA evaluation or ISC evaluation, respectively.<br />
<code>power.scABEL2</code> and <code>sampleN.scABEL2</code> were removed in version 1.4-3.
</p>
<p><code>power2.TOST</code> was deprecated in version 1.2-6 since <code>power.TOST</code> was modified in order to handle unbalanced sequences. <code>power2.TOST</code> was removed in version in version 1.2-7.
</p>
<p>The functions <code>power.NTIDFDA</code>, <code>sampleN.NTIDFDA</code> and <code>pa.NTIDFDA</code> were deprecated in 
version 1.5-4 and were removed in version 1.5-6.
</p>


<h3>References</h3>

<p>Berger RL, Hsu JC. <em>Bioequivalence Trials, Intersection-Union Tests and Equivalence Confidence Sets.</em> Stat Sci. 1996;11(4):283&ndash;302. <a href="https://www.jstor.org/stable/2246021">JSTOR:2246021</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.TOST">power.TOST</a></code>, <code><a href="#topic+power.scABEL">power.scABEL</a></code>, <code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a></code>, <code><a href="#topic+power.NTID">power.NTID</a></code>, <code><a href="#topic+sampleN.NTID">sampleN.NTID</a></code>, and <code><a href="#topic+pa.NTID">pa.NTID</a></code> for the new functions.
</p>

<hr>
<h2 id='deprecated'>Deprecated functions in PowerTOST</h2><span id='topic+deprecated'></span>

<h3>Description</h3>

<p>Details about deprecated functions in PowerTOST.
</p>


<h3>Details</h3>

<p>The functions <code>power.NTIDFDA</code>, <code>sampleN.NTIDFDA</code>, and <code>pa.NTIDFDA</code> were deprecated in version 1.5-4.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.NTID">power.NTID</a></code>, <code><a href="#topic+sampleN.NTID">sampleN.NTID</a></code>, <code><a href="#topic+pa.NTID">pa.NTID</a></code> for the new functions.
</p>

<hr>
<h2 id='exppower.noninf'>
Expected power of the non-inferiority test
</h2><span id='topic+exppower.noninf'></span>

<h3>Description</h3>

<p>Calculates the so-called expected, <em>i.e.</em>, unconditional, power for a variety of
study designs used in bioequivalence studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exppower.noninf(alpha = 0.025, logscale = TRUE, theta0, margin, CV, n,
                design = "2x2", robust = FALSE, 
                prior.type = c("CV", "theta0", "both"), prior.parm = list(), 
                method = c("exact", "approx"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exppower.noninf_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Defaults here to 0.025.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_logscale">logscale</code></td>
<td>

<p>Should the data be used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>  
<tr><td><code id="exppower.noninf_+3A_theta0">theta0</code></td>
<td>

<p>Assumed &lsquo;true&rsquo; (or &lsquo;observed&rsquo; in case of <code>prior.type != "CV"</code>) ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>margin</code> and <code>CV</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to -0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_margin">margin</code></td>
<td>

<p>Non-inferiority margin.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code> and <code>theta0</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of n has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_robust">robust</code></td>
<td>

<p>Defaults to FALSE. Set to <code>TRUE</code> will use the degrees of freedom according 
to the &lsquo;robust&rsquo; evaluation (aka Senn’s basic estimator). These degrees of freedom are calculated
as <code>n-seq</code>.<br /> 
See <code>known.designs()$df2</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_prior.type">prior.type</code></td>
<td>

<p>Specifies which parameter uncertainty should be accounted for. In case of 
<code>prior.type = "CV"</code> (the default), only the uncertainty with respect to the
CV will be considered (i.e. the given treatment effect is assumed to be fix).
In case of <code>prior.type = "theta0" </code> only uncertainty with respect to the
treatment ratio/difference will be accounted for (i.e. the given CV is assumed
to be fix). In case of <code>prior.type = "both"</code> the power value will be
unconditional with respect to both the <code>CV</code> and <code>theta0</code>.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_prior.parm">prior.parm</code></td>
<td>

<p>A list of parameters expressing the prior information about the 
variability and/or treatment effect. Possible components are <code>df</code>, 
<code>SEM</code>, <code>m</code> and <code>design</code>.<br />
For <code>prior.type = "CV"</code> the degrees of freedom from the prior trial are
required. This information can be provided by specifying the single component 
<code>df</code> or the combination consisting of <code>m</code> and <code>design</code>.<br />
For <code>prior.type = "theta0"</code> the standard error of the treatment difference 
from the prior trial is required. This information can be provided by specifying
the single component <code>SEM</code> or the combination consisting of 
<code>m</code> and <code>design</code>.<br />
For <code>prior.type = "both"</code> the degrees of freedom and the standard error of
the treatment difference are required. This information can be provided by 
specifying the combination consisting of <code>df</code> and <code>SEM</code> or via the 
combination <code>m</code> and <code>design</code>.<br />
See 'Details' for a technical description on each component.
</p>
</td></tr>
<tr><td><code id="exppower.noninf_+3A_method">method</code></td>
<td>

<p>Defaults to <code>method="exact"</code>.
In that case the expected power will be calculated as expected value of the
power with respect to the (prior) distribution of the respective parameter(s).<br />
Set to <code>method="approx"</code> the expected power according to the 
approximate formulas given in the book from Julious or in the Julious/Owen 
paper will be calculated (using non-central <em>t</em>); this only affects 
<code>prior.type = "CV"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the so-called expected power taking into account that
usually the parameters (CV and/or theta0) are not known but <em>estimated</em> 
from a prior study with some uncertainty. The expected power is an unconditional 
power and can therefore be seen as probability for success. See references for 
further details.<br /><br />
The <code>prior.parm</code> argument is a list that can supply any of the following 
components: 
</p>

<dl>
<dt><code>df</code></dt><dd><p>Error degrees of freedom from the prior trial (&gt;4, maybe non-integer). 
<code>df = Inf</code> is allowed and for <code>method = "exact"</code> the result will then
coincide with <code>power.noninf(...)</code>.<br />
Note: This corresponds to the df of both the CV and the difference of means.</p>
</dd>
<dt><code>SEM</code></dt><dd><p>Standard error of the difference of means from the prior trial; 
must always be on additive scale (<em>i.e.</em>, usually log-scale).</p>
</dd>
<dt><code>m</code></dt><dd><p>Number of subjects from prior trial. Specification is analogous to
the main argument <code>n</code>.</p>
</dd>
<dt><code>design</code></dt><dd><p>Study design of prior trial. Specification is analogous to the 
main argument <code>design</code>.</p>
</dd>
</dl>

<p>For <code>prior.parm</code>, the combination consisting of <code>df</code> and <code>SEM</code> 
requires a somewhat advanced knowledge of the prior trial (provided in the raw
output from for example the software <abbr><span class="acronym">SAS</span></abbr>, or may be obtained via
<code><a href="emmeans.html#topic+emmeans">emmeans</a></code> of package <code>emmeans</code>. However, it has the 
advantage that if there were missing data the exact degrees of freedom and 
standard error of the difference can be used, the former possibly being 
non-integer valued (<em>e.g.</em> if the Kenward-Roger method was used).
</p>
<p>Details on argument <code>prior.type</code>:
</p>

<dl>
<dt><code>CV</code></dt><dd><p>The expectation is calculated with respect to the 
Inverse-gamma distribution.</p>
</dd>
<dt><code>theta0</code></dt><dd><p>The expectation is calculated with respect to the
conditional distribution theta0 | <code class="reqn">\sigma^2</code> = s^2 
of the posteriori distribution of (theta0, <code class="reqn">\sigma^2</code>) from the prior
trial.</p>
</dd>
<dt><code>both</code></dt><dd><p>The expectation is calculated with respect to the posteriori
distribution of (theta0, <code class="reqn">\sigma^2</code>) from the prior trial. Numerical calculation
of the two-dimensional integral is performed via <code>cubature::hcubature</code>.</p>
</dd>
</dl>

<p><strong>Notes on the underlying hypotheses</strong><br />
If the supplied margin is &lt; 0 (<code>logscale=FALSE</code>) or &lt; 1 (<code>logscale=TRUE</code>), 
then it is assumed higher response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &lt;= margin vs. H1: theta0 &gt; margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &lt;= log(margin) vs. H1: log(theta0) &gt; log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
</p>
<p>If the supplied margin is &gt; 0 (<code>logscale=FALSE</code>) or &gt; 1 (<code>logscale=TRUE</code>), 
then it is assumed lower response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &gt;= margin vs. H1: theta0 &lt; margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or <br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &gt;= log(margin) vs. H1: log(theta0) &lt; log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
This latter case may also be considered as &lsquo;non-superiority&rsquo;.
</p>


<h3>Value</h3>

<p>Value of expected power according to the input.
</p>


<h3>Author(s)</h3>

<p>B. Lang, D. Labes
</p>


<h3>References</h3>

<p>Grieve AP. <em>Confidence Intervals and Sample Sizes.</em> Biometrics. 1991;47:1597&ndash;603. <a href="https://doi.org/10.2307/2532411">doi:10.2307/2532411</a>
</p>
<p>O’Hagan, Stevens, JW, Campell MJ. <em>Assurance in Clinical Trial Design.</em> Pharm Stat. 2005;4:187&ndash;201. <a href="https://doi.org/10.1002/pst.175">doi:10.1002/pst.175</a>
</p>
<p>Julious SA, Owen RJ. <em>Sample size calculations for clinical studies allowing for uncertainty in variance.</em> Pharm Stat. 2006;5:29&ndash;37. <a href="https://doi.org/10.1002/pst.197">doi:10.1002/pst.197</a>
</p>
<p>Julious SA. <em>Sample sizes for Clinical Trials.</em> Boca Raton: CRC Press / Chapman &amp; Hall; 2010.
</p>
<p>Bertsche A, Nehmitz G, Beyersmann J, Grieve AP. <em>The predictive distribution of the residual variability in
the linear-fixed effects model for clinical cross-over trials.</em> Biom J. 2016;58(4):797&ndash;809. <a href="https://doi.org/10.1002/bimj.201500245">doi:10.1002/bimj.201500245</a>
</p>
<p>Box GEP, Tiao GC. <em>Bayesian Inference in Statistical Analysis.</em> Boston: Addison-Wesley; 1992.
</p>
<p>Held L, Sabanes Bove D. <em>Applied Statistical Inference. Likelihood and Bayes.</em> Berlin, Heidelberg: Springer; 2014. <a href="https://doi.org/10.1007/978-3-642-37887-4">doi:10.1007/978-3-642-37887-4</a>
</p>
<p>Senn S. <em>Cross-over Trials in Clinical Research.</em> Chichester: John Wiley &amp; Sons; 2<sup>nd</sup> edition 2002.
</p>
<p>Zierhut ML, Bycott P, Gibbs MA, Smith BP, Vicini P. <em>Ignorance is not bliss: Statistical power is not probability of trial success.</em> Clin Pharmacol Ther. 2015;99:356&ndash;9. <a href="https://doi.org/10.1002/cpt.257">doi:10.1002/cpt.257</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expsampleN.noninf">expsampleN.noninf</a>, <a href="#topic+power.noninf">power.noninf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Expected power for non-inferiority test for a 2x2 crossover
# with 40 subjects. CV 30% known from a pilot 2x2 study with 
# 12 subjects 
# using all the defaults for other parameters (theta0 carved in stone)
# should give: [1] 0.6761068
exppower.noninf(CV = 0.3, n = 40, prior.parm = list(df = 12-2))
# or equivalently
exppower.noninf(CV = 0.3, n = 40, prior.parm = list(m = 12, design = "2x2"))

# May be also calculated via exppower.TOST() after setting upper acceptance limit 
# to Inf and alpha=0.025
exppower.TOST(CV = 0.3, n = 40, prior.parm = list(df = 10), theta2 = Inf, alpha=0.025)

# In contrast: Julious approximation
exppower.noninf(CV = 0.3, n = 40, prior.parm = list(df = 10), method = "approx")
# should give: [1] 0.6751358

# Compare this to the usual (conditional) power (CV known, "carved in stone")
power.noninf(CV = 0.3, n = 40)
# should give: [1] 0.7228685
# same as if setting df = Inf in function exppower.noninf()
exppower.noninf(CV = 0.3, n = 40, prior.parm = list(df = Inf))

# Expected power for a 2x2 crossover with 40 subjects
# CV 30% and theta0 = 0.95 known from a pilot 2x2 study with 12 subjects
# using uncertainty with respect to both CV and theta0
exppower.noninf(CV = 0.3, theta0 = 0.95, n = 40, 
                prior.parm = list(m = 12, design = "2x2"), prior.type = "both")
# should give a decrease of expected power to 0.5982852
</code></pre>

<hr>
<h2 id='exppower.TOST'>
Expected power of the TOST procedure
</h2><span id='topic+exppower.TOST'></span>

<h3>Description</h3>

<p>Calculates the so-called expected, <em>i.e.</em>, unconditional, power for a variety of
study designs used in bioequivalence studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exppower.TOST(alpha = 0.05, logscale = TRUE, theta0, theta1, theta2,  
              CV, n, design = "2x2", robust = FALSE, 
              prior.type = c("CV", "theta0", "both"), prior.parm = list(),
              method = c("exact", "approx"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exppower.TOST_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data be used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>  
<tr><td><code id="exppower.TOST_+3A_theta0">theta0</code></td>
<td>

<p>Assumed &lsquo;true&rsquo; (or &lsquo;observed&rsquo; in case of <code>prior.type != "CV"</code>) ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to 0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code> or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of n has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.
See <a href="#topic+known.designs">known.designs</a> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. Set to <code>TRUE</code> will use the degrees of freedom according 
to the &lsquo;robust&rsquo; evaluation (aka Senn’s basic estimator). These df are calculated
as <code>n-seq</code>.<br /> 
See <code>known.designs()$df2</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_prior.type">prior.type</code></td>
<td>

<p>Specifies which parameter uncertainty should be accounted for. In case of 
<code>prior.type = "CV"</code> (the default), only the uncertainty with respect to the
CV will be considered (i.e. the given treatment effect is assumed to be fix).
In case of <code>prior.type = "theta0" </code> only uncertainty with respect to the
treatment ratio/difference will be accounted for (i.e. the given CV is assumed
to be fix). In case of  <code>prior.type = "both"</code> the power value will be
unconditional with respect to both the <code>CV</code> and <code>theta0</code>.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_prior.parm">prior.parm</code></td>
<td>

<p>A list of parameters expressing the prior information about the 
variability and/or treatment effect. Possible components are <code>df</code>, 
<code>SEM</code>, <code>m</code> and <code>design</code>.<br />
For <code>prior.type = "CV"</code> the degrees of freedom from the prior trial are
required. This information can be provided by specifying the single component 
<code>df</code> or the combination consisting of <code>m</code> and <code>design</code>.<br />
For <code>prior.type = "theta0"</code> the standard error of the treatment difference 
from the prior trial is required. This information can be provided by specifying
the single component <code>SEM</code> or the combination consisting of 
<code>m</code> and <code>design</code>.<br />
For <code>prior.type = "both"</code> the degrees of freedom and the standard error of
the treatment difference are required. This information can be provided by 
specifying the combination consisting of <code>df</code> and <code>SEM</code> or via the 
combination <code>m</code> and <code>design</code>.<br />
See 'Details' for a technical description on each component.
</p>
</td></tr>
<tr><td><code id="exppower.TOST_+3A_method">method</code></td>
<td>

<p>Defaults to <code>method="exact"</code>.
In that case the expected power will be calculated as expected value of the
power with respect to the (prior) distribution of the respective parameter(s).<br />
Set to <code>method="approx"</code> the expected power according to the 
approximate formulas given in the book from Julious or in the Julious/Owen 
paper will be calculated (using non-central <em>t</em>); this only affects 
<code>prior.type = "CV"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the so-called expected power taking into account that
usually the parameters (CV and/or theta0) are not known but estimated from a
prior study with some uncertainty. The expected power is an unconditional power
and can therefore be seen as probability for success. See references for further
details.
</p>
<p>The <code>prior.parm</code> argument is a list that can supply any of the following 
components: 
</p>

<dl>
<dt><code>df</code></dt><dd><p>Error degrees of freedom from the prior trial (&gt;4, maybe non-integer). 
<code>df = Inf</code> is allowed and for <code>method = "exact"</code> the result will then
coincide with <code>power.TOST(...)</code>.<br />
Note: This corresponds to the df of both the CV and the difference of means.</p>
</dd>
<dt><code>SEM</code></dt><dd><p>Standard error of the difference of means from the prior trial; 
must always be on additive scale (<em>i.e.</em>, usually log-scale).</p>
</dd>
<dt><code>m</code></dt><dd><p>Number of subjects from prior trial. Specification is analogous to
the main argument <code>n</code>.</p>
</dd>
<dt><code>design</code></dt><dd><p>Study design of prior trial. Specification is analogous to the 
main argument <code>design</code>.</p>
</dd>
</dl>

<p>For <code>prior.parm</code>, the combination consisting of <code>df</code> and <code>SEM</code> 
requires a somewhat advanced knowledge of the prior trial (provided in the raw
output from for example the software <abbr><span class="acronym">SAS</span></abbr>, or may be obtained via
<code><a href="emmeans.html#topic+emmeans">emmeans</a></code> of package <code>emmeans</code>. 
However, it has the advantage that if there were 
missing data the exact degrees of freedom and standard error of the difference 
can be used, the former possibly being non-integer valued (<em>e.g.</em>, if the 
Kenward-Roger method was used).
</p>
<p>Details on argument <code>prior.type</code>:
</p>

<dl>
<dt><code>CV</code></dt><dd><p>The expectation is calculated with respect to the 
Inverse-gamma distribution.</p>
</dd>
<dt><code>theta0</code></dt><dd><p>The expectation is calculated with respect to the
conditional distribution theta0 | <code class="reqn">\sigma^2</code> = s^2 
of the posteriori distribution of (theta0, <code class="reqn">\sigma^2</code>) from the prior
trial.</p>
</dd>
<dt><code>both</code></dt><dd><p>The expectation is calculated with respect to the posteriori
distribution of (theta0, <code class="reqn">\sigma^2</code>) from the prior trial. Numerical calculation
of the two-dimensional integral is performed via <code><a href="cubature.html#topic+hcubature">hcubature</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Value of expected power according to the input.
</p>


<h3>Author(s)</h3>

<p>B. Lang (thanks to G. Nehmiz for the helpful discussions), D. Labes
</p>


<h3>References</h3>

<p>Grieve AP. <em>Confidence Intervals and Sample Sizes.</em> Biometrics. 1991;47:1597&ndash;603. <a href="https://doi.org/10.2307/2532411">doi:10.2307/2532411</a>
</p>
<p>O’Hagan, Stevens, JW, Campell MJ. <em>Assurance in Clinical Trial Design.</em> Pharm Stat. 2005;4:187&ndash;201. <a href="https://doi.org/10.1002/pst.175">doi:10.1002/pst.175</a>
</p>
<p>Julious SA, Owen RJ. <em>Sample size calculations for clinical studies allowing for 
uncertainty in variance.</em> Pharm Stat. 2006;5:29&ndash;37. <a href="https://doi.org/10.1002/pst.197">doi:10.1002/pst.197</a>
</p>
<p>Julious SA. <em>Sample sizes for Clinical Trials.</em> Boca Raton: CRC Press / Chapman &amp; Hall; 2010.
</p>
<p>Bertsche A, Nehmitz G, Beyersmann J, Grieve AP. <em>The predictive distribution of the residual variability in
the linear-fixed effects model for clinical cross-over trials.</em> Biom J. 2016;58(4):797&ndash;809. <a href="https://doi.org/10.1002/bimj.201500245">doi:10.1002/bimj.201500245</a>
</p>
<p>Box GEP, Tiao GC. <em>Bayesian Inference in Statistical Analysis.</em> Boston: Addison-Wesley; 1992.
</p>
<p>Held L, Sabanes Bove D. <em>Applied Statistical Inference. Likelihood and Bayes.</em> Berlin, Heidelberg: Springer; 2014. <a href="https://doi.org/10.1007/978-3-642-37887-4">doi:10.1007/978-3-642-37887-4</a>
</p>
<p>Senn S. <em>Cross-over Trials in Clinical Research.</em> Chichester: John Wiley &amp; Sons; 2<sup>nd</sup> edition 2002.
</p>
<p>Zierhut ML, Bycott P, Gibbs MA, Smith BP, Vicini P. <em>Ignorance is not bliss: Statistical power is not probability of trial success.</em> Clin Pharmacol Ther. 2015;99:356&ndash;9. <a href="https://doi.org/10.1002/cpt.257">doi:10.1002/cpt.257</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expsampleN.TOST">expsampleN.TOST</a>, <a href="#topic+power.TOST">power.TOST</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Expected power for a 2x2 crossover with 40 subjects
# CV 30% known from a pilot 2x2 study with 12 subjects
# using all the defaults for other parameters (theta0 carved in stone)
exppower.TOST(CV = 0.3, n = 40, prior.parm = list(df = 12-2))
# should give: [1] 0.7365519
# or equivalently
exppower.TOST(CV = 0.3, n = 40, prior.parm = list(m = 12, design = "2x2"))

# In contrast: Julious approximation
exppower.TOST(CV = 0.3, n = 40, prior.parm = list(df = 10), method = "approx")
# should give: [1] 0.7359771

# Compare this to the usual (conditional) power (CV known, "carved in stone")
power.TOST(CV = 0.3, n = 40)
# should give: [1] 0.8158453
# same as if setting df = Inf in function exppower.TOST()
exppower.TOST(CV = 0.3, n = 40, prior.parm = list(df = Inf))

# Expected power for a 2x2 crossover with 40 subjects
# CV 30% and theta0 = 0.95 known from a pilot 2x2 study with 12 subjects
# using uncertainty with respect to both CV and theta0
exppower.TOST(CV = 0.3, theta0 = 0.95, n = 40, 
              prior.parm = list(m = 12, design = "2x2"), prior.type = "both")
# should give [1] 0.5114685
</code></pre>

<hr>
<h2 id='expsampleN.noninf'>
Sample size based on expected power for the non-inferiority test
</h2><span id='topic+expsampleN.noninf'></span>

<h3>Description</h3>

<p>Estimates the sample size based on the expected power for a variety
of designs used in bioequivalence studies. See <a href="#topic+known.designs">known.designs</a>
for the study designs covered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expsampleN.noninf(alpha = 0.025, targetpower = 0.8, logscale = TRUE, 
                  theta0, margin, CV, design = "2x2", robust = FALSE, 
                  prior.type = c("CV", "theta0", "both"), prior.parm = list(),
                  method = c("exact", "approx"), print = TRUE, details)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expsampleN.noninf_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Defaults here to 0.025.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be <code style="white-space: pre;">&#8288;&gt;0&#8288;</code> and <code style="white-space: pre;">&#8288;&lt;1&#8288;</code>.
Typical values are <code style="white-space: pre;">&#8288;0.8&#8288;</code> or <code style="white-space: pre;">&#8288;0.9&#8288;</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale?
<code>TRUE</code> or <code>FALSE</code>.<br />
Defaults to <code>TRUE</code>.
</p>
</td></tr>  
<tr><td><code id="expsampleN.noninf_+3A_theta0">theta0</code></td>
<td>

<p>Assumed &lsquo;true&rsquo; (or &lsquo;observed&rsquo; in case of <code>prior.type != "CV"</code>) ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>margin</code> and <code>CV</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to -0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_margin">margin</code></td>
<td>

<p>Non-inferiority margin.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code> and <code>theta0</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>If <code>prior.type="CV"</code> may be given as vector: The CVs are then pooled (as a 
weighted mean with their degrees of freedoms as weights).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of
freedom will be used.<br />
Setting to <code>TRUE</code> will use the degrees of freedom according to
the &lsquo;robust&rsquo; evaluation (aka Senn’s basic estimator).
These df are calculated as <code>n-seq</code>.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_prior.type">prior.type</code></td>
<td>

<p>Specifies which parameter uncertainty should be accounted for.
In case of <code>prior.type="CV"</code> (the default), only the
uncertainty with respect to the CV will be considered (<em>i.e.</em>,
the given treatment effect is assumed to be fix). In case of
<code>prior.type="theta0"</code> only uncertainty with respect to the
treatment ratio/difference will be accounted for (<em>i.e.</em>, the
given CV is assumed to be fix). In case of <code>prior.type="both"</code>
the power value will be unconditional with respect to both the
<code>CV</code> and <code>theta0</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_prior.parm">prior.parm</code></td>
<td>

<p>A list of parameters expressing the prior information about the 
variability and/or treatment effect. Possible components are <code>df</code>, 
<code>SEM</code>, <code>m</code>, <code>design</code>.<br />
For <code>prior.type="CV"</code> the degrees of freedom from the prior trial
are required. This information can be provided by specifying the
single component<code>df</code> or the combination consisting of <code>m</code>
and <code>design</code>.<br />
For <code>prior.type = "theta0"</code> the standard error of the treatment difference 
from the prior trial is required. This information can be provided by specifying
the single component <code>SEM</code> or the combination consisting of 
<code>m</code> and <code>design</code>.<br />
For <code>prior.type = "both"</code> the degrees of freedom and the standard error of
the treatment difference are required. This information can be provided by 
specifying the combination consisting of <code>df</code> and <code>SEM</code> or via the 
combination <code>m</code> and <code>design</code>.<br />
See section &lsquo;Details&rsquo; for a technical description of each
component.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_method">method</code></td>
<td>

<p>Defaults to <code>method="exact"</code>. In that case the expected power
will be calculated as expected value of the power with respect to the
(prior) distribution of the respective parameter(s).<br />
Set to <code>method="approx"</code> the expected power according to the 
approximate formulas given by Julious or Julious &amp; Owen will be
calculated (using the non-central <em>t</em>); this only affects 
<code>prior.type = "CV"</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results.<br />
If <code>FALSE</code> only a data.frame with the results will be returned.
</p>
</td></tr>
<tr><td><code id="expsampleN.noninf_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the design characteristics and the steps during
sample size calculations will be shown.<br /> 
If not specified, the default value is <code>FALSE</code> for
<code>prior.type != "both"</code> and <code>TRUE</code> otherwise.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is estimated based on iterative evaluation of
expected power. The starting value of the sample size search is
taken from a large sample approximation if <code>prior.type="CV"</code>.
Else an empirical start value is obtained. Note that in case of
<code>prior.type="both"</code> the calculation may still take several seconds.
</p>
<p>Note also that the expected power is always bounded above by the
so-called probability of technical success (<abbr><span class="acronym">PTS</span></abbr>) which
may be a value less than 1.Therefore, it may be possible that it
is either not possible to calculate the required sample size at
all or that the sample size gets very large if the given targetpower
is less but close to the <abbr><span class="acronym">PTS</span></abbr>.<br />
</p>
<p><strong>Notes on the underlying hypotheses</strong><br />
If the supplied margin is <code style="white-space: pre;">&#8288;&lt; 0&#8288;</code> (<code>logscale=FALSE</code>) or
<code style="white-space: pre;">&#8288;&lt; 1&#8288;</code> (<code>logscale=TRUE</code>), then it is assumed <em>higher</em> response
values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &lt;= margin&#8288;</code><br />
<code style="white-space: pre;">&#8288;  H1: theta0 &gt;  margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &lt;= log(margin)&#8288;</code><br />
<code style="white-space: pre;">&#8288;  H1: log(theta0) &gt;  log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
</p>
<p>If the supplied margin is <code style="white-space: pre;">&#8288;&gt; 0&#8288;</code> (<code>logscale=FALSE</code>) or
<code style="white-space: pre;">&#8288;&gt; 1&#8288;</code> (<code>logscale=TRUE</code>), then it is assumed <em>lower</em> response
values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &gt;= margin&#8288;</code><br />
<code style="white-space: pre;">&#8288;  H1: theta0 &lt;  margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &gt;= log(margin)&#8288;</code><br />
<code style="white-space: pre;">&#8288;  H1: log(theta0) &lt;  log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
This latter case may also be considered as &lsquo;non-superiority&rsquo;.
</p>


<h3>Value</h3>

<p>A data.frame with the input values and the result of the sample
size estimation.<br />
The <code>Sample size</code> column contains the <em>total</em> sample
size in case of all designs implemented.
</p>


<h3>Author(s)</h3>

<p>B. Lang, D. Labes
</p>


<h3>References</h3>

<p>Grieve AP. <em>Confidence Intervals and Sample Sizes.</em> Biometrics. 1991;47:1597&ndash;603. <a href="https://doi.org/10.2307/2532411">doi:10.2307/2532411</a>
</p>
<p>O’Hagan, Stevens, JW, Campell MJ. <em>Assurance in Clinical Trial Design.</em> Pharm Stat. 2005;4:187&ndash;201. <a href="https://doi.org/10.1002/pst.175">doi:10.1002/pst.175</a>
</p>
<p>Julious SA, Owen RJ. <em>Sample size calculations for clinical studies allowing for uncertainty in variance.</em> Pharm Stat. 2006;5:29&ndash;37. <a href="https://doi.org/10.1002/pst.197">doi:10.1002/pst.197</a>
</p>
<p>Julious SA. <em>Sample sizes for Clinical Trials.</em> Boca Raton: CRC Press; 2010.
</p>
<p>Bertsche A, Nehmitz G, Beyersmann J, Grieve AP. <em>The predictive distribution of the residual variability in
the linear-fixed effects model for clinical cross-over trials.</em> Biom J. 2016;58(4):797&ndash;809. <a href="https://doi.org/10.1002/bimj.201500245">doi:10.1002/bimj.201500245</a>
</p>
<p>Box GEP, Tiao GC. <em>Bayesian Inference in Statistical Analysis.</em> Boston: Addison-Wesley; 1992.
</p>
<p>Held L, Sabanes Bove D. <em>Applied Statistical Inference. Likelihood and Bayes.</em> Berlin, Heidelberg: Springer; 2014. <a href="https://doi.org/10.1007/978-3-642-37887-4">doi:10.1007/978-3-642-37887-4</a>
</p>
<p>Senn S. <em>Cross-over Trials in Clinical Research.</em> Chichester: John Wiley &amp; Sons; 2<sup>nd</sup> edition 2002.
</p>
<p>Zierhut ML, Bycott P, Gibbs MA, Smith BP, Vicini P. <em>Ignorance is not bliss: Statistical power is not probability of trial success.</em> Clin Pharmacol Ther. 2015;99:356&ndash;9. <a href="https://doi.org/10.1002/cpt.257">doi:10.1002/cpt.257</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exppower.noninf">exppower.noninf</a>, <a href="#topic+known.designs">known.designs</a>, <a href="#topic+sampleN.noninf">sampleN.noninf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Classical 2x2 cross-over, target power = 80%,
# assumed true ratio = 95%, margin = 0.8,
# intra-subject CV=30% estimated from prior 2x2 trial 
# with m = 12 subjects
expsampleN.noninf(theta0 = 0.95, margin = 0.8, CV = 0.3, design = "2x2",
                  prior.parm = list(m = 12, design = "2x2"))
# gives n = 58 with achieved expected power 0.809148 
# Compare this to the usual sample size with CV assumed
# as 'carved in stone'
sampleN.noninf(theta0 = 0.95, margin = 0.8, CV = 0.3)

# Perform 'non-superiority' (lower is better) with assumed
# true ratio = 105% and margin 125%
expsampleN.noninf(theta0 = 1.05, margin = 1.25, CV = 0.3, design = "2x2",
                  prior.parm = list(m = 12, design = "2x2"))
# should give n = 56 with achieved expected power 0.806862

# More than one CV with corresponding degrees of freedom 
# other settings as above in first example
CVs &lt;- c(0.25, 0.3)
dfs &lt;- c(22, 10)
expsampleN.noninf(theta0 = 0.95, margin = 0.8, CV = CVs, 
                  prior.parm = list(df = dfs))
# should give a pooled CV=0.2664927 with 32 df and a sample
# size n=42 with achieved expected power 0.814073 exact
# achieved expected power 0.816163 approximate acc. to Julious

# Uncertainty is accounted for CV and theta0

expsampleN.noninf(CV = 0.3, prior.type = "both",
                  prior.parm = list(m = 12, design = "2x2"))
# gives a dramatic increase in sample size (n = 194)
# due to small pilot trial
</code></pre>

<hr>
<h2 id='expsampleN.TOST'>
Sample size based on expected power
</h2><span id='topic+expsampleN.TOST'></span>

<h3>Description</h3>

<p>Estimates the sample size based on the expected power for a variety of study 
designs used in bioequivalence studies. See <a href="#topic+known.designs">known.designs</a> for the study 
designs covered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expsampleN.TOST(alpha = 0.05, targetpower = 0.8, logscale=TRUE, theta0, 
                theta1, theta2, CV, design = "2x2", robust = FALSE, 
                prior.type = c("CV", "theta0", "both"), prior.parm = list(),
                method = c("exact", "approx"), print = TRUE, details)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expsampleN.TOST_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>  
<tr><td><code id="expsampleN.TOST_+3A_theta0">theta0</code></td>
<td>

<p>Assumed &lsquo;true&rsquo; (or &lsquo;observed&rsquo; in case of <code>prior.type != "CV"</code>) bioequivalence 
ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to 0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code> or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>If <code>prior.type="CV"</code> may be given as vector: The CVs are then pooled (as a 
weighted mean with their degrees of freedoms as weights).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <a href="#topic+known.designs">known.designs</a> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to FALSE. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These df are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_prior.type">prior.type</code></td>
<td>

<p>Specifies which parameter uncertainty should be accounted for. In case of 
<code>prior.type = "CV"</code> (the default), only the uncertainty with respect to the
CV will be considered (<em>i.e.</em>, the given treatment effect is assumed to be fix).
In case of <code>prior.type = "theta0" </code> only uncertainty with respect to the
treatment ratio/difference will be accounted for (<em>i.e.</em>, the given CV is assumed
to be fix). In case of  <code>prior.type = "both"</code> the power value will be
unconditional with respect to both the <code>CV</code> and <code>theta0</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_prior.parm">prior.parm</code></td>
<td>

<p>A list of parameters expressing the prior information about the 
variability and/or treatment effect. Possible components are <code>df</code>, 
<code>SEM</code>, <code>m</code>, <code>design</code>.<br />
For <code>prior.type = "CV"</code> the degrees of freedom from the prior trial are
required. This information can be provided by specifying the single component 
<code>df</code> or the combination consisting of <code>m</code> and <code>design</code>.<br />
For <code>prior.type = "theta0"</code> the standard error of the treatment difference 
from the prior trial is required. This information can be provided by specifying
the single component <code>SEM</code> or the combination consisting of 
<code>m</code> and <code>design</code>.<br />
For <code>prior.type = "both"</code> the degrees of freedom and the standard error of
the treatment difference are required. This information can be provided by 
specifying the combination consisting of <code>df</code> and <code>SEM</code> or via the 
combination <code>m</code> and <code>design</code>.<br />
See 'Details' for a technical description on each component.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_method">method</code></td>
<td>

<p>Defaults to <code>method="exact"</code>.
In that case the expected power will be calculated as expected value of the
power with respect to the (prior) distribution of the respective parameter(s).<br />
Set to <code>method="approx"</code> the expected power according to the 
approximate formulas given in the book from Julious or in the Julious/Owen 
paper will be calculated (using non-central <em>t</em>); this only affects 
<code>prior.type = "CV"</code>.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results. If <code>FALSE</code> only a data.frame with the results will be returned.
</p>
</td></tr>
<tr><td><code id="expsampleN.TOST_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the design characteristics and the steps during
sample size calculations will be shown.<br /> 
If not specified, the default value is <code>FALSE</code> for <code>prior.type != "both"</code>
and <code>TRUE</code> otherwise.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is calculated based on iterative evaluation of expected power.
The starting value of the sample size search is taken from a large sample 
approximation if <code>prior.type = "CV"</code>. Otherwise, an empirical start value is
obtained. Note that in case of <code>prior.type = "both"</code> the calculation may 
still take several seconds.
</p>
<p>Note also that the expected power is always bounded above by the so-called
probability of technical success (<abbr><span class="acronym">PTS</span></abbr>) which may be a value less than 1. 
Therefore, it may be possible that it is either not possible to calculate the 
required sample size at all or that the sample size gets very large 
if the given targetpower is less but close to the <abbr><span class="acronym">PTS</span></abbr>.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>A data.frame with the input values and the result of the sample size estimation.<br />
The <code>Sample size</code> column contains the total sample size in case of all
designs implemented.
</p>


<h3>Author(s)</h3>

<p>B. Lang, D. Labes
</p>


<h3>References</h3>

<p>Grieve AP. <em>Confidence Intervals and Sample Sizes.</em> Biometrics. 1991;47:1597&ndash;603. <a href="https://doi.org/10.2307/2532411">doi:10.2307/2532411</a>
</p>
<p>O’Hagan, Stevens, JW, Campell MJ. <em>Assurance in Clinical Trial Design.</em> Pharm Stat. 2005;4:187&ndash;201. <a href="https://doi.org/10.1002/pst.175">doi:10.1002/pst.175</a>
</p>
<p>Julious SA, Owen RJ. <em>Sample size calculations for clinical studies allowing for 
uncertainty in variance.</em> Pharm Stat. 2006;5:29&ndash;37. <a href="https://doi.org/10.1002/pst.197">doi:10.1002/pst.197</a>
</p>
<p>Julious SA. <em>Sample sizes for Clinical Trials.</em> Boca Raton: CRC Press / Chapman &amp; Hall; 2010.
</p>
<p>Bertsche A, Nehmitz G, Beyersmann J, Grieve AP. <em>The predictive distribution of the residual variability in
the linear-fixed effects model for clinical cross-over trials.</em> Biom J. 2016;58(4):797&ndash;809. <a href="https://doi.org/10.1002/bimj.201500245">doi:10.1002/bimj.201500245</a>
</p>
<p>Box GEP, Tiao GC. <em>Bayesian Inference in Statistical Analysis.</em> Boston: Addison-Wesley; 1992.
</p>
<p>Held L, Sabanes Bove D. <em>Applied Statistical Inference. Likelihood and Bayes.</em> Berlin, Heidelberg: Springer; 2014. <a href="https://doi.org/10.1007/978-3-642-37887-4">doi:10.1007/978-3-642-37887-4</a>
</p>
<p>Senn S. <em>Cross-over Trials in Clinical Research.</em> Chichester: John Wiley &amp; Sons; 2<sup>nd</sup> edition 2002.
</p>
<p>Zierhut ML, Bycott P, Gibbs MA, Smith BP, Vicini P. <em>Ignorance is not bliss: Statistical power is not probability of trial success.</em> Clin Pharmacol Ther. 2015;99:356&ndash;9. <a href="https://doi.org/10.1002/cpt.257">doi:10.1002/cpt.257</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exppower.TOST">exppower.TOST</a>, <a href="#topic+known.designs">known.designs</a>, <a href="#topic+sampleN.TOST">sampleN.TOST</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Classical 2x2 cross-over, target power = 80%,
# BE limits 80 ... 125%, assumed true BE ratio = 95%,
# intra-subject CV=30% estimated from prior 2x2 trial 
# with m = 30 subjects
expsampleN.TOST(CV=0.3, prior.parm = list(m = 30, design = "2x2"))
# -&gt; gives n = 42 with achieved expected power 0.806262
# Compare this to the usual sample size with CV assumed known ('carved in stone')
sampleN.TOST(CV=0.3)
# -&gt; gives n = 40 subjects
# Compare this to the case where uncertainty is accounted for CV and theta0
# Not run due to timing policy of CRAN - may run several seconds

expsampleN.TOST(CV=0.3, prior.parm = list(m = 30, design = "2x2"), 
                prior.type = "both")
# -&gt; gives n = 72 subjects

# More than one CV with corresponding degrees of freedom 
# other settings as above in first example
CVs &lt;- c(0.25, 0.3)
dfs &lt;- c(22, 10)
expsampleN.TOST(CV=CVs, prior.parm = list(df = dfs))
# -&gt; gives a pooled CV=0.2664927 with df=32
# and a sample size n=34 with achieved expected power 0.812653 exact
# achieved expected power 0.815019 approximate acc. Julious
</code></pre>

<hr>
<h2 id='known.designs'>Show the 'known' designs</h2><span id='topic+known.designs'></span>

<h3>Description</h3>

<p>Returns the known study designs for which power and sample size can be calculated within this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>known.designs()
</code></pre>


<h3>Details</h3>

<p>This function is for informal purposes and used internally for obtaining characteristics of the designs used in calculation formulas.
</p>


<h3>Value</h3>

<p>Returns a data.frame with <br />
</p>
<table>
<tr><td><code>no</code></td>
<td>
<p>number of the design</p>
</td></tr>
<tr><td><code>design</code></td>
<td>
<p>character string for identifying the design</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom of the design</p>
</td></tr>
<tr><td><code>df2</code></td>
<td>
<p>&lsquo;robust&rsquo; degrees of freedom of the design</p>
</td></tr>
<tr><td><code>steps</code></td>
<td>
<p>step width in the iterative sample size estimation</p>
</td></tr>
<tr><td><code>bk</code></td>
<td>
<p>so-called design constant in terms of total n</p>
</td></tr>
<tr><td><code>bkni</code></td>
<td>
<p>design constant in terms of number of subjects in (sequence) groups</p>
</td></tr>
</table>
<p>The design character string has to be used in the functions calls for power and sample size.
</p>


<h3>Note</h3>

<p>The design string for higher order crossover designs is named as:<br />
<code>treatments x sequences x periods</code> in case of replicate designs and<br />
<code>treatments x periods</code> in case of crossover designs for more then 2 treatments 
with number of sequences equal number of treatments.<br /><br />
The df for the replicate crossover designs are those without carry-over in the model.<br />
Chen <em>et al.</em> used models with carry-over, <em>i.e.</em>, one df lower than here.<br /><br />
The design constant bk in case of design 2x2x4 is here bk=1.<br />
Chen <em>et al.</em> used bk=1.1 due to carry-over in the model.<br /><br />
n is the <b>total</b> number of subjects for all designs implemented.<br />
df2 = degrees of freedom for the so-called &lsquo;robust&rsquo; analysis (aka Senn’s basic estimator).<br />
These degrees of freedom are often also more appropriate in case of evaluation via a &lsquo;true&rsquo; 
mixed model (<em>e.g.</em> the FDA’ for replicate designs).<br /><br />
The design <code>2x2x2r</code> is the 2-treatment-2-sequence-2-period design with 
2 repeated targets determined in each period (sequences TT|RR or RR|TT) described 
by Liu. Implemented are the characteristics of this design for the evaluation 
via assuming no S×F interaction and equal variabilities of Test and Reference.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Chen KW, Chow SC, Liu G. <em>A Note on Sample Size Determination for Bioequivalence Studies with 
Higher-order Crossover Designs.</em> J Pharmacokin Biopharm. 1997;25(6):753&ndash;65.
</p>
<p>Senn S. <em>Cross-over Trials in Clinical Research.</em> Chichester: John Wiley &amp; Sons; 2<sup>nd</sup> edition 2002.
</p>
<p>U.S. Department of Health and Human Services, Food and Drug Administration, Center for Drug Evaluation and Research (CDER). <em>Guidance for Industry. Statistical Approaches to Establishing Bioequivalence.</em> January 2001. <a href="https://www.fda.gov/media/70958/download">download</a>
</p>
<p>Liu J-p. <em>Use of the Repeated Crossover design in Assessing Bioequivalence.</em> Stat Med. 1995;14(9-10):1067&ndash;78.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>known.designs()
</code></pre>

<hr>
<h2 id='OwensQ'>Owen's Q-function</h2><span id='topic+OwensQ'></span>

<h3>Description</h3>

<p>Calculates Owen’s Q function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>OwensQ(nu, t, delta, a=0, b)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OwensQ_+3A_nu">nu</code></td>
<td>
<p>degree of Owen’s Q</p>
</td></tr>
<tr><td><code id="OwensQ_+3A_t">t</code></td>
<td>
<p>parameter t</p>
</td></tr>
<tr><td><code id="OwensQ_+3A_delta">delta</code></td>
<td>
<p>parameter delta</p>
</td></tr>
<tr><td><code id="OwensQ_+3A_a">a</code></td>
<td>
<p>lower integration limit, only a=0 implemented</p>
</td></tr>
<tr><td><code id="OwensQ_+3A_b">b</code></td>
<td>
<p>upper integration limit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the relationship to non-central <em>t</em>-distribution (see Chou)<br /><br />
<code style="white-space: pre;">&#8288;  OwensQ = pt(t, df=nu, ncp=delta) - Integal_b_Inf(Q_integrand)&#8288;</code><br /><br />
The definite integral is numerically evaluated using <code><a href="stats.html#topic+integrate">integrate</a></code>
after a variables transformation resulting in the integration range from 0 to 1
instead of the semi-infinite original range. 
This may result in higher precision and better numerical stability.<br /><br />
The arguments to the function must be scalars. No vectors allowed.
</p>


<h3>Value</h3>

<p>Numeric value of Owen’s Q-function at given input arguments.
</p>


<h3>Note</h3>

<p>This function is intended for internal use in the power calculations.<br />
But may be useful for others.
</p>


<h3>Author(s)</h3>

<p>D. Labes</p>


<h3>References</h3>

<p>Owen DB. <em>A special case of a bivariate non-central t-distribution.</em> Biometrika. 1965;52(3/4):437&ndash;46. <a href="https://doi.org/10.2307/2333696">doi:10.2307/2333696</a>
</p>
<p>Chou YM. <em>A bivariate noncentral T-distibution with applications.</em> Commun Stat Theory Methods. 1992;21(12):3427&ndash;62. <a href="https://doi.org/10.1080/03610929208830988">doi:10.1080/03610929208830988</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OwensQOwen">OwensQOwen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This function is mainly intended for internal use.
OwensQ(10, 2.5, 5, 0, 2)
#should give [1] 9.388137e-06 
OwensQ(10, -2.5, -5, 0, 2)
#should give [1] 0.05264363 
</code></pre>

<hr>
<h2 id='OwensQOwen'>
Owen's Q-function via repeated integration by parts
</h2><span id='topic+OwensQOwen'></span>

<h3>Description</h3>

<p>This is an implementation of the algorithm given by Owen via repeated integration by parts. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OwensQOwen(nu, t, delta, a=0, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OwensQOwen_+3A_nu">nu</code></td>
<td>
<p>degree of Owen’s Q</p>
</td></tr>
<tr><td><code id="OwensQOwen_+3A_t">t</code></td>
<td>
<p>parameter t</p>
</td></tr>
<tr><td><code id="OwensQOwen_+3A_delta">delta</code></td>
<td>
<p>parameter delta</p>
</td></tr>
<tr><td><code id="OwensQOwen_+3A_a">a</code></td>
<td>
<p>lower integration limit.<br />
Only <code>a=0</code> implemented, other values give an error.</p>
</td></tr>
<tr><td><code id="OwensQOwen_+3A_b">b</code></td>
<td>
<p>upper integration limit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value of Owen’s Q function.
</p>


<h3>Note</h3>

<p>The argument <code>a=0</code> could be dropped but is retained for sake of completeness. 
</p>


<h3>Note</h3>

<p>This function is mainly for comparative / validation purposes.<br />
The function requireds <code><a href="#topic+OwensT">OwensT</a></code> function.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Owen DB. <em>A special case of a bivariate non-central t-distribution.</em> Biometrika. 1965;52(3/4):437&ndash;46. <a href="https://doi.org/10.2307/2333696">doi:10.2307/2333696</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OwensQ">OwensQ</a></code>, <code><a href="#topic+OwensT">OwensT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># comparison of the results of both implementations
# both should give [1] 0.0731726
OwensQ(2, 2.92, 4.2135, 0, 2.0407)
OwensQOwen(2, 2.92, 4.2135, 0, 2.0407)
</code></pre>

<hr>
<h2 id='OwensT'>
Owen's T-function
</h2><span id='topic+OwensT'></span>

<h3>Description</h3>

<p>Calculates the definite integral from <code>0</code> to <code>a</code> of<br />
<code style="white-space: pre;">&#8288;  exp(-0.5*h^2*(1+x^2))/(1+x^2)/(2*pi)&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OwensT(h, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OwensT_+3A_h">h</code></td>
<td>
<p>parameter h</p>
</td></tr>
<tr><td><code id="OwensT_+3A_a">a</code></td>
<td>
<p>upper limit of integration</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is an R port of FORTRAN code given in the references and MATLAB 
code given by John Burkardt under the GNU LGPL license.<br /><br />
The arguments of <code>OwensT()</code> have to be scalars because the implementation 
doesn’t vectorize.
</p>


<h3>Value</h3>

<p>Numerical value of the definite integral.
</p>


<h3>Note</h3>

<p>This function is only needed as auxiliary in <code><a href="#topic+OwensQOwen">OwensQOwen</a></code>.<br />
But may be useful for others.
</p>


<h3>Author(s)</h3>

<p>MATLAB code by J. Burkardt, R port by D. Labes
</p>


<h3>References</h3>

<p>Goedhart PW, Jansen MJW. <em>Remark AS R89: A Remark on Algorithm AS 76: An Integral Useful in Calculating Central t and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1992;41(2):496&ndash;7. <a href="https://doi.org/10.2307/2347586">doi:10.2307/2347586</a>
</p>
<p>Boys R. <em>Algorithm AS R80: A Remark on Algorithm AS 76: An Integral Useful in Calculating Noncentral t and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1989;38(3):580&ndash;2. <a href="https://doi.org/10.2307/2347755">doi:10.2307/2347755</a>
</p>
<p>Thomas GE. <em>Remark ASR 65: A Remark on Algorithm AS76: An Integral Useful in Calculating Non-Central t and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1986;35(3):310&ndash;2. <a href="https://doi.org/10.2307/2348031">doi:10.2307/2348031</a>
</p>
<p>Chou Y-M. <em>Remark AS R55: A Remark on Algorithm AS 76: An Integral Useful in Calculating Noncentral T and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1985;34(1):100&ndash;1. <a href="https://doi.org/10.2307/2347894">doi:10.2307/2347894</a>
</p>
<p>Thomas GE. <em>Remark AS R30: A Remark on Algorithm AS 76: An Integral Useful in Calculating Non-Central t and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1979;28(1):113. <a href="https://doi.org/10.2307/2346833">doi:10.2307/2346833</a>
</p>
<p>Young JC, Minder C. <em>Algorithm AS 76: An Integral Useful in Calculating Non-Central t and Bivariate Normal Probabilities.</em> J Royal Stat Soc C. 1974;23(3):455&ndash;7. <a href="https://doi.org/10.2307/2347148">doi:10.2307/2347148</a>
</p>
<p>Burkardt J. <em>ASA076. Owen's T Function.</em> <a href="https://people.math.sc.edu/Burkardt/f_src/asa076/asa076.html">https://people.math.sc.edu/Burkardt/f_src/asa076/asa076.html</a>
</p>
<p>Owen DB. <em>Tables for Computing Bivariate Normal Probabilities.</em> Ann Math Stat. 1956;27(4):1075&ndash;90. <a href="https://doi.org/10.1214/aoms/1177728074">doi:10.1214/aoms/1177728074</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OwensQOwen">OwensQOwen</a>, <a href="#topic+OwensQ">OwensQ</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OwensT(2.5, 0.75)
# should give [1]  0.002986697
# value from Owen's tables is 0.002987
OwensT(2.5, -0.75)
# should give [1] -0.002986697
</code></pre>

<hr>
<h2 id='pa.ABE'>
Power analysis for average bioequivalence (ABE)
</h2><span id='topic+pa.ABE'></span><span id='topic+print.pwrA'></span><span id='topic+plot.pwrA'></span>

<h3>Description</h3>

<p>An analysis tool for exploration/visualization of the impact of expected values
(CV, theta0, reduced sample size due to drop-outs) on power of BE decision via ABE
if these values deviate from the ones assumed in planning the sample size of
the study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa.ABE(CV, theta0 = 0.95, targetpower = 0.8, minpower = 0.7, design = "2x2", ...)
## S3 method for class 'pwrA'
print(x, digits = 4, plotit = TRUE, ...)
## S3 method for class 'pwrA'
plot(x, pct = TRUE, ratiolabel = "theta0", cols = c("blue", "red"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pa.ABE_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation as ratio (not percent).<br />
In case of cross-over studies this is the within-subject CV.<br />
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Often named GMR.<br />
Must be given as ratio.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least in sample size estimation. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9. Defaults to 0.8.<br />
Note that targetpower &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_minpower">minpower</code></td>
<td>

<p>Minimum acceptable power to have if deviating from assumptions for sample size plan.<br />
Has to be lower than <code>targetpower</code>. Defaults to 0.7.<br />
<code>minpower</code> &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_...">...</code></td>
<td>

<p>More arguments to pass to <code>power.TOST()</code>.<br />
F.i. <code>alpha</code>, <code>theta1</code>, <code>theta2</code> or <code>robust</code> if other values
then the defaults for these arguments are needed. <br />
See man page of <code>power.TOST()</code>.<br /><br />
More arguments passed to the S3 methods. Here currently ignored.
</p>
</td></tr>
</table>
<p>Additional arguments of the S3 methods:
</p>
<table>
<tr><td><code id="pa.ABE_+3A_x">x</code></td>
<td>

<p>Object of class <code>'pwrA'</code>.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_digits">digits</code></td>
<td>

<p>Digits for rounding power in printing. The '...' argument is currently ignored
in <code>print()</code>.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_plotit">plotit</code></td>
<td>

<p>If set to <code>TRUE</code>, the default, the print method calls <code>plot(x)</code> if R
is running interactively.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_pct">pct</code></td>
<td>

<p>If set to <code>TRUE</code> (the default) scales CV, theta0, and power in percent in
<code>plot()</code>. Else they will be given as ratios, the usual standard in PowerTOST.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_ratiolabel">ratiolabel</code></td>
<td>

<p>Label of the T/R-ratio. Can be set to any string, e.g. to <code>"GMR"</code>.
Defaults to <code>"theta0"</code>, the usual standard in PowerTOST.
</p>
</td></tr>
<tr><td><code id="pa.ABE_+3A_cols">cols</code></td>
<td>

<p>Colors for the plots. <code>cols[1]</code> gives the color for plotting points
with <code>power&gt;targetpower</code>. From <code>targetpower</code> toward <code>minpower</code>
the color changes gradually to <code>cols[2]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Power calculations are done via <code>power.TOST()</code> and calculations of CV and theta0
which gave a power=<code>minpower</code> are derived via R base <code><a href="stats.html#topic+uniroot">uniroot</a></code>.
While one of the parameters (<code>CV</code>, <code>theta0</code>, <code>n</code>) is varied, the respective two others are
kept constant. The tool shows the relative impact of single parameters on power.<br />
The tool takes a minimum of 12 subjects as required in most BE guidances into account.<br /><br />
It should be kept in mind that this is <b>not</b> a substitute for the &lsquo;Sensitivity Analysis&rsquo;
recommended in ICH-E9. In a real study a combination of all effects occurs simultaneously.
It is up to <em>you</em> to decide on reasonable combinations and analyze their respective power.
</p>


<h3>Value</h3>

<p>Returns a list with class <code>"pwrA"</code> with the components
</p>
<table>
<tr><td><code>plan</code></td>
<td>
<p>A data.frame with the result of the sample size estimation.
See output of <code>sampleN.TOST()</code>.</p>
</td></tr>
<tr><td><code>paCV</code></td>
<td>
<p>A data.frame with value pairs CV, pwr for impact of
deviations from CV.</p>
</td></tr>
<tr><td><code>paGMR</code></td>
<td>
<p>A data.frame with value pairs theta0, pwr for impact of
deviations from theta0 (GMR).</p>
</td></tr>
<tr><td><code>paN</code></td>
<td>
<p>A data.frame with value pairs N, pwr for impact of
deviations from planned N (dropouts).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Method of BE decision. Here &quot;ABE&quot;.</p>
</td></tr>
<tr><td><code>minpower</code></td>
<td>
<p>Minimum acceptable power.</p>
</td></tr>
</table>
<p>The class <code>'pwrA'</code> has the S3 methods <code>print()</code> and <code>plot()</code>.
See <code><a href="#topic+pa.scABE">pa.scABE</a></code> for usage.
</p>


<h3>Note</h3>

<p>The code of deviations from planned sample size tries to keep the degree of
imbalance as low as possible between (sequence) groups.
This results in a lesser decrease of power than more extreme dropout-patterns.
</p>


<h3>Author(s)</h3>

<p>Idea and original code by H. Schütz with modifications by D. Labes to use PowerTOST infrastructure.
</p>


<h3>References</h3>

<p>Schütz H. <em>Deviating from assumptions.</em> August 08, 2014. <a href="https://forum.bebac.at/mix_entry.php?id=13353">BEBA Forum</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.TOST">power.TOST</a>, <a href="#topic+known.designs">known.designs</a>, <a href="#topic+pa.scABE">pa.scABE</a>, <a href="#topic+pa.NTIDFDA">pa.NTIDFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the defaults
# design="2x2", targetpower=0.8, minpower=0.7, theta0/GMR=0.95
# BE margins from defaults of sampleN.TOST() 0.8 ... 1.25
# print &amp; plot implicitly
pa.ABE(CV = 0.2)
# print &amp; plot

res &lt;- pa.ABE(CV = 0.2)
print(res, plotit = FALSE)                 # print only
plot(res, pct = FALSE, ratiolabel = "GMR") # changed from defaults
</code></pre>

<hr>
<h2 id='pa.NTID'>
Power analysis for scaled ABE for NTIDs
</h2><span id='topic+pa.NTID'></span><span id='topic+pa.NTIDFDA'></span>

<h3>Description</h3>

<p>An analysis tool for exploration/visualization of the impact of expected values
(CV, theta0, reduced sample size due to drop-outs) on power of BE decision via
scABE for narrow therapeutic drugs (NTIDs) if these values deviate from the ones
assumed in planning the sample size of the study.<br />
The only implemented design is the full replicate design <code>"2x2x4"</code> according to the
FDA’s warfarin guidance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa.NTID(CV, theta0 = 0.975, targetpower = 0.8, minpower = 0.7, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pa.NTID_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation of the intra-subject variabilities of Test and Reference
as ratio (not percent).<br />
Here only the case <code>CVwT == CVwR</code> is implemented, <em>i.e.</em>, CV has to be a scalar (<code>length(CV) == 1</code>).
</p>
</td></tr>
<tr><td><code id="pa.NTID_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Often named GMR.<br />
Must be given as ratio. Defaults here to 0.975.
</p>
</td></tr>
<tr><td><code id="pa.NTID_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least in sample size estimation. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9. Defaults to 0.8.<br />
Note that targetpower &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.NTID_+3A_minpower">minpower</code></td>
<td>

<p>Minimum acceptable power to have if deviating from assumptions for sample size plan.<br />
Has to be lower than <code>targetpower</code>. Defaults to 0.7.<br />
<code>minpower</code> &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.NTID_+3A_...">...</code></td>
<td>

<p>More arguments to pass to <code>power.NTID()</code>.<br />
F.i., <code>alpha</code>, <code>theta1</code>, <code>theta2</code> or <code>nsims</code> if other values
than the defaults for these arguments are needed. <br />
See man page of <code>power.NTID()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Power calculations are done via <code>power.NTID()</code> and
calculations of <code>CV</code> and <code>theta0</code> which result in <code>minpower</code> are obtained via <code>uniroot()</code>.<br />
While one of the parameters (<code>CV</code>, <code>theta0</code>, <code>n</code>) is varied, the respective two others are
kept constant. The tool shows the relative impact of single parameters on power.<br />
The tool takes a minimum of 12 subjects into account as demanded in most BE guidances.
However, it should be kept in mind that the FDA requires at least 24 subjects to be enrolled
in studies intended for reference-scaling.<br /><br />
It should be kept in mind that this is <b>not</b> a substitute for the &lsquo;Sensitivity Analysis&rsquo;
recommended in ICH-E9. In a real study a combination of all effects occurs simultaneously.
It is up to <em>you</em> to decide on reasonable combinations and analyze their respective power.
</p>


<h3>Value</h3>

<p>Returns a list with class <code>'pwrA'</code> with the components
</p>
<table>
<tr><td><code>plan</code></td>
<td>
<p>A data.frame with the result of the sample size estimation.
See output of <code>sampleN.NTID()</code>.</p>
</td></tr>
<tr><td><code>paCV</code></td>
<td>
<p>A data.frame with value pairs CV, pwr for impact of
deviations from CV.</p>
</td></tr>
<tr><td><code>paGMR</code></td>
<td>
<p>A data.frame with value pairs theta0, pwr for impact of
deviations from theta0 (GMR).</p>
</td></tr>
<tr><td><code>paN</code></td>
<td>
<p>A data.frame with value pairs N, pwr for impact of
deviations from planned N (dropouts).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Method of BE decision. Here &quot;NTID&quot;.</p>
</td></tr>
<tr><td><code>regulator</code></td>
<td>
<p>Here &quot;FDA&quot;.</p>
</td></tr>
<tr><td><code>minpower</code></td>
<td>
<p>Minimum acceptable power from the call of the function.</p>
</td></tr>
</table>
<p>The class <code>'pwrA'</code> has the S3 methods <code>print()</code> and <code>plot()</code>.
See <code><a href="#topic+pa.ABE">pa.ABE</a></code> for usage.
</p>


<h3>Warning </h3>

<p>Be extremly carefull if your sample size plan has extremly small CV near or
below 0.05 (5%). Adapt in that case your expected true ratio (<code>theta0</code>)
to values nearer to 1 to not run into errors and/or long execution times.
</p>


<h3>Note</h3>

<p>The code for impact of deviations from planned sample size tries
to keep the degree of imbalance as low as possible between (sequence) groups.
This results in a lesser decrease of power than more extreme dropout-patterns.
</p>


<h3>Author(s)</h3>

<p>D. Labes according to code by H. Schütz for <code>pa.ABE()</code> and <code>pa.scABE()</code>.
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Warfarin Sodium.</em> Recommended Dec 2012. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Warfarin_Sodium_tab_09218_RC12-12.pdf">download</a>
</p>
<p>Food and Drug Administration, Center for Drug Evaluation and Research (CDER). <em>Draft Guidance for Industry. Bioequivalence Studies with Pharmacokinetic Endpoints for Drugs Submitted Under an ANDA.</em> August 2021. <a href="https://www.fda.gov/media/87219/download">download</a>
</p>
<p>Yu LX, Jiang W, Zhang X, Lionberger R, Makhlouf F, Schuirmann DJ, Muldowney L, Chen ML, Davit B, Conner D, Woodcock J. <em>Novel bioequivalence approach for narrow therapeutic index drugs.</em> Clin Pharmacol Ther. 2015;97(3):286&ndash;91. <a href="https://doi.org/10.1002/cpt.28">doi:10.1002/cpt.28</a>
</p>
<p>Jiang W, Makhlouf F, Schuirmann DJ, Zhang X, Zheng N, Conner D, Yu LX, Lionberger R. <em>A Bioequivalence Approach for Generic Narrow Therapeutic Index Drugs: Evaluation of the Reference-Scaled Approach and Variability Comparison Criterion.</em> AAPS J. 2015;17(4):891&ndash;901. <a href="https://doi.org/10.1208/s12248-015-9753-5">doi:10.1208/s12248-015-9753-5</a>
</p>
<p>Endrényi L, Tóthfalusi L. <em>Determination of Bioequivalence for Drugs with Narrow Therapeutic Index: Reduction of the Regulatory Burden.</em> J Pharm Pharm Sci. 2013;16(5):676&ndash;82. <a href="https://journals.library.ualberta.ca/jpps/index.php/JPPS/article/download/20900/15927/0">open access</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.NTID">power.NTID</a>, <a href="#topic+print.pwrA">print.pwrA</a>, <a href="#topic+plot.pwrA">plot.pwrA</a>, <a href="#topic+pa.ABE">pa.ABE</a>, <a href="#topic+pa.scABE">pa.scABE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the defaults:
# targetpower=0.8, minpower=0.7, theta0/GMR=0.975
# BE margins from defaults of sampleN.NTID() 0.9002 ... 1.1108
# 1E5 sims in power.NTID()
# not run due to timing policy of CRAN for examples
# may run some ten seconds or more

plot(pa.NTID(CV=0.1))
</code></pre>

<hr>
<h2 id='pa.scABE'>
Power analysis for scaled average bioequivalence (scABE)
</h2><span id='topic+pa.scABE'></span>

<h3>Description</h3>

<p>An analysis tool for exploration/visualization of the impact of expected values
(CV, theta0, reduced sample size due to drop-outs) on power of BE decision via
scABE (for highly variable drugs) if these values deviate from the ones assumed
in planning the sample size of the study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa.scABE(CV, theta0 = 0.9, targetpower = 0.8, minpower = 0.7,
         design = c("2x3x3", "2x2x4", "2x2x3"),
         regulator = c("EMA", "HC", "FDA", "GCC"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pa.scABE_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation of the intra-subject variability as ratio (not percent).<br />
Here only the case CVwT=CVwR is implemented, <em>i.e.</em>, CV has to be a scalar.
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Often named GMR.<br />
Must be given as ratio. Defaults to 0.9 here since HVD have a greater scatter
in point estimates of T/R.
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least in sample size estimation. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9. Defaults to 0.8.<br />
Note that targetpower &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_minpower">minpower</code></td>
<td>

<p>Minimum acceptable power to have if deviating from assumptions for sample size plan.<br />
Has to lower than <code>targetpower</code>. Defaults to 0.7.<br />
<code>minpower</code> &lt; 0.5 doesn’t make much sense.
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
Defaults to <code>2x3x3</code>, the partial replicate design (TRR|RTR|RRT).
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_regulator">regulator</code></td>
<td>

<p>Character string describing the scaled ABE method recommended by the regulatory
bodies <code>"EMA"</code>, <code>"HC"</code>, <code>"FDA"</code> or <code>"GCC"</code>.<br />
Defaults to <code>"EMA"</code>, method of scaled (expanded) bioequivalence limits.
</p>
</td></tr>
<tr><td><code id="pa.scABE_+3A_...">...</code></td>
<td>

<p>More arguments to pass to <code>power.scABEL()</code> or <code>power.RSABE()</code>.<br />
F.i., <code>alpha</code>, <code>theta1</code>, <code>theta2</code> or <code>nsims</code> if other values
than the defaults for these arguments are needed.<br />
See man pages of <code>power.scABEL()</code> or <code>power.RSABE()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Power calculations are done via <code>power.scABEL()</code> or <code>power.RSABE()</code> and
calculations of CV and theta0 which result in <code>minpower</code> derived via R base <code><a href="stats.html#topic+uniroot">uniroot</a></code>.<br />
While one of the parameters (CV, GMR, N) is varied, the respective two others are
kept constant. The tool shows the relative impact of single parameters on power.<br /><br />
The tool takes a minimum of 12 subjects as required in most BE guidances into account. 
However, the sample size will be increased from the estimated one if one of the 
following conditions is applicable:
</p>

<ul>
<li><p> The FDA requires at least 24 subjects <em>enrolled</em> in studies intended for reference-scaling.
</p>
</li>
<li><p> The EMA requires at least 12 <em>eligible</em> subjects in the sequence RTR of the TRT|RTR-design (hence the minimum sample size is 24).
</p>
</li></ul>

<p>You should be aware that this is <b>not</b> a substitute for the &ldquo;Sensitivity Analysis&rdquo;
recommended in ICH-E9. In a real study a combination of all effects occurs simultaneously.
It is up to <em>you</em> to decide on reasonable combinations and analyze their respective power.
</p>


<h3>Value</h3>

<p>Returns a list with class <code>'pwrA'</code> with the components
</p>
<table>
<tr><td><code>plan</code></td>
<td>
<p>A data.frame with the result of the sample size estimation.<br />
See output of <code>sampleN.scABEL()</code> or <code>sampleN.RSABE()</code>.</p>
</td></tr>
<tr><td><code>paCV</code></td>
<td>
<p>A data.frame with value pairs CV, pwr for impact of
deviations from CV.</p>
</td></tr>
<tr><td><code>paGMR</code></td>
<td>
<p>A data.frame with value pairs theta0, pwr for impact of
deviations from theta0 (GMR).</p>
</td></tr>
<tr><td><code>paN</code></td>
<td>
<p>A data.frame with value pairs N, pwr for impact of
deviations from planned N (dropouts).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Method of BE decision. Here fix = &quot;scABE&quot;.</p>
</td></tr>
<tr><td><code>regulator</code></td>
<td>
<p>&quot;EMA&quot;, &quot;HC&quot;, or &quot;FDA&quot;.</p>
</td></tr>
<tr><td><code>minpower</code></td>
<td>
<p>Minimum acceptable power from the call of the function.</p>
</td></tr>
</table>
<p>The class <code>'pwrA'</code> has the S3 methods <code>print()</code> and <code>plot()</code>.
See <code><a href="#topic+pa.ABE">pa.ABE</a></code> for usage.
</p>


<h3>Note</h3>

<p>The code for impact of deviations from planned sample size tries to
keep the degree of imbalance as low as possible between (sequence) groups.
This results in a lesser decrease of power than more extreme dropout-patterns.
</p>


<h3>Author(s)</h3>

<p>Idea and original code by H. Schütz with modifications by D. Labes 
to use PowerTOST infrastructure.
</p>


<h3>References</h3>

<p>Schütz H. <em>Deviating from assumptions.</em> August 08, 2014. 
<a href="https://forum.bebac.at/mix_entry.php?id=13353">BEBA Forum</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.scABEL">power.scABEL</a>, <a href="#topic+power.RSABE">power.RSABE</a>, <a href="#topic+known.designs">known.designs</a>,
  <a href="#topic+print.pwrA">print.pwrA</a>, <a href="#topic+plot.pwrA">plot.pwrA</a>, <a href="#topic+pa.ABE">pa.ABE</a>, <a href="#topic+pa.NTIDFDA">pa.NTIDFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Implicitely using the defaults:
# design = "2x3x3", targetpower = 0.8, minpower = 0.7,
# theta0 = 0.9, GMR = 0.90, regulator = "EMA"
# widened BE margins from defaults of sampleN.scABEL() 0.7462 ... 1.3402
# 1E5 sims in power.scABEL()
# not run due to timing policy of CRAN, may run some ten seconds

# Implicit print &amp; plot
pa.scABE(CV = 0.4)
</code></pre>

<hr>
<h2 id='power.2TOST'>
Power for two simultaneous TOST procedures
</h2><span id='topic+power.2TOST'></span>

<h3>Description</h3>

<p>Calculates the exact power of two simultaneous TOST procedures (where
the two parameters of the two TOSTs are correlated with some correlation)
for various study designs used in BE studies 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.2TOST(alpha = c(0.05, 0.05), logscale = TRUE, theta0, theta1, theta2,  
            CV, n, rho, design = "2x2", robust = FALSE, nsims, setseed = TRUE,
            details = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.2TOST_+3A_alpha">alpha</code></td>
<td>

<p>Vector; contains one-sided significance level for each of the two TOSTs.<br />
For one TOST, by convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed (<code>TRUE</code>, default) or on original
scale (<code>FALSE</code>)?
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_theta1">theta1</code></td>
<td>

<p>Vector; contains lower bioequivalence limit for each of the two TOSTs.<br />
In case of <code>logscale=TRUE</code> it is given as ratio, otherwise as diff. to 1.<br />
Defaults to <code>c(0.8, 0.8)</code> if <code>logscale=TRUE</code> or to <code>c(-0.2, -0.2)</code>
if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_theta2">theta2</code></td>
<td>

<p>Vector; contains upper bioequivalence limit for each of the two TOSTS.<br />
If not given theta2 will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code><br />
or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_theta0">theta0</code></td>
<td>

<p>Vector; contains &lsquo;true&rsquo; assumed bioequivalence ratio for each of the two TOSTs.<br />
In case of <code>logscale=TRUE</code> each element must be given as ratio,<br />
otherwise as difference to 1. See examples.<br />
Defaults to <code>c(0.95, 0.95)</code> if <code>logscale=TRUE</code> or to 
<code>c(0.05, 0.05)</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_cv">CV</code></td>
<td>

<p>Vector of coefficient of variations (given as as ratio, <em>e.g.</em>, 0.2 for 20%).<br />
In case of cross-over studies this is the within-subject CV,<br />
in case of a parallel-group design the CV of the total variability.<br />
In case of <code>logscale=FALSE</code> CV is assumed to be the respective standard 
deviation.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of <code>n</code> vector has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_rho">rho</code></td>
<td>

<p>Correlation between the two PK metrics (<em>e.g.</em>, AUC and Cmax) under consideration.
This is defined as correlation between the estimator of the treatment difference of
PK metric one and the estimator of the treatment difference of PK metric two. Has to be within {&ndash;1, +1}.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.<br />
Setting to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; 
evaluation (aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_nsims">nsims</code></td>
<td>

<p>Number of studies to simulate. Defaults to 1E5.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_setseed">setseed</code></td>
<td>

<p>Logical; if <code>TRUE</code>, the default, a seed of 1234567 is set.
</p>
</td></tr>
<tr><td><code id="power.2TOST_+3A_details">details</code></td>
<td>

<p>Logical; if <code>TRUE</code>, run time will be printed. Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculations are based on simulations and follow the distributional
properties as described in Phillips. This is in contrast to the calculations
via the 4-dimensional non-central <em>t</em>-distribution as described in Hua <em>et al.</em>
which was implemented in versions up to 1.4-6.<br /><br />
The formulas cover balanced and unbalanced studies w.r.t (sequence) groups.<br /><br />
In case of parallel group design and higher order crossover designs 
(replicate crossover or crossover with more than two treatments) the calculations 
are based on the assumption of equal variances for Test and Reference products
under consideration.<br /><br />
The formulas for the paired means 'design' do not take an additional correlation
parameter into account. They are solely based on the paired <em>t</em>-test 
(TOST of differences = zero).
</p>


<h3>Value</h3>

<p>Value of power.
</p>


<h3>Note</h3>

<p>If <code style="white-space: pre;">&#8288;n&#8288;</code> is given as scalar (total sample size) and this number is not 
divisible by the number of (sequence) groups of the design an unbalanced design 
with small imbalance is assumed. A corresponding message is thrown showing the 
assumed numbers of subjects in (sequence) groups.<br />
The function does not vectorize properly if design is a vector. Moreover,
<code>theta0</code> and <code>CV</code> must be of length two, thus further vectorizing is not possible.<br />
Other vector input is not tested yet.<br /><br />
</p>


<h3>Author(s)</h3>

<p>B. Lang, D. Labes<br />
</p>


<h3>References</h3>

<p>Phillips KF. <em>Power for Testing Multiple Instances of the Two One-Sided Tests Procedure.</em> Int J Biostat. 2009;5(1):Article 15. 
</p>
<p>Hua SY, Xu S, D’Agostino RB Sr. <em>Multiplicity adjustments in testing for bioequivalence.</em> Stat Med. 2015;34(2):215&ndash;31. <a href="https://doi.org/10.1002/sim.6247">doi:10.1002/sim.6247</a>
</p>
<p>Lang B, Fleischer F. <em>Letter to the Editor: Comments on &lsquo;Multiplicity adjustments in testing for bioequivalence.&rsquo;</em> Stat Med. 2016;35(14):2479&ndash;80. <a href="https://doi.org/10.1002/sim.6488">doi:10.1002/sim.6488</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.2TOST">sampleN.2TOST</a>, <a href="#topic+known.designs">known.designs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Power for the 2x2x2 cross-over design with 24 subjects, intra-subject
# standard deviation of 0.3 (CV = 30.7%) and assumed ratios of 1.05 for both
# parameters, and correlation 0.75 between parameters (using all the other
# default values)
power.2TOST(theta0 = rep(1.05, 2), CV = rep(se2CV(0.3), 2),
            n = 24, rho = 0.75)
# should give: 0.38849

# Setting as before but use rho 1 and high number of simulations
# to reproduce result of power.TOST()
p1 &lt;- power.2TOST(theta0 = rep(1.05, 2), CV = rep(se2CV(0.3), 2),
                  n = 24, rho = 1, nsims=1E7)
p2 &lt;- power.TOST(theta0 = 1.05, CV = se2CV(0.3), n = 24)
all.equal(p1, p2, tolerance = 1e-04)
</code></pre>

<hr>
<h2 id='power.dp'>
Power of dose-proportionality studies evaluated via Power model
</h2><span id='topic+power.dp'></span>

<h3>Description</h3>

<p>Calculates the power of dose-proportionality studies using the power model for 
crossover (Latin square) or parallel group designs via a confidence interval
equivalence criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.dp(alpha = 0.05, CV, doses, n, beta0, theta1 = 0.8, theta2 = 1/theta1, 
         design = c("crossover", "parallel", "IBD"), dm = NULL, CVb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.dp_+3A_alpha">alpha</code></td>
<td>

<p>Type 1 error. Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation for intra-subject variability if <code>design="crossover"</code> 
or CV of total variability in case of <code>design="parallel"</code>.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_doses">doses</code></td>
<td>

<p>Vector of dose levels. At least two doses have to be given.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_n">n</code></td>
<td>

<p>Number of subjects. Is total number if given as scalar, else number of subjects
in the (sequence) groups. In the latter case the length of n vector has to be 
the same as length of vector doses.<br />
n has to be &gt;2.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_beta0">beta0</code></td>
<td>

<p>&lsquo;True&rsquo; slope of power model. If missing defaults to <code>1+log(0.95)/log(rd)</code>
where <code>rd</code> is the ratio of highest to lowest dose.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_theta1">theta1</code></td>
<td>

<p>Lower acceptance limit for the ratio of dose normalized means (Rdmn).<br />
Transformes into slope acceptance range as described under item <code>beta0</code>.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_theta2">theta2</code></td>
<td>

<p>Upper acceptance limit for the ratio of dose normalized means (Rdmn).
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_design">design</code></td>
<td>

<p>Crossover design (default), parallel group design or incomplete block design (IBD).<br />
Crossover design means Latin square design with number of doses as dimension.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_dm">dm</code></td>
<td>

<p>'Design matrix' of the incomplete block design (IBD) if <code>design="IBD"</code>.<br />
This matrix contains the sequences in rows and periods in columns. 
The entry (<em>i</em>, <em>j</em>) of the design matrix corresponds to the dose (index) a subject 
with <em>i</em>-th sequence gets in the <em>j</em>-th period.
Can be obtained f.i. via functions of package <code>crossdes</code> or via function 
<code>bib.CL()</code>.
</p>
</td></tr>
<tr><td><code id="power.dp_+3A_cvb">CVb</code></td>
<td>

<p>Coefficient of variation of the between-subject variability.<br />
Only necessary if <code>design="IBD"</code>. Will be set to 2*CV if missing.
This is only a crude rule of thumb. Better obtain an estimate of CVb from a 
previous crossover study.<br /><br />
Set <code>CVb=0</code> if an all-effects-fixed model shall be used. This model gives
higher power than the random subject effects model.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power calculations are based on TOST for testing equivalence of the slope 
of the power model with alternativ hypothesis slope = 1.<br />
Power is calculated via non-central t-approximation only.<br />
The calculations are based on mixed effects model (random intercept aka
random subject effect). For <code>design="cossover"</code> or <code>design="parallel"</code>
the results coincide with all-effects-fixed model.
</p>


<h3>Value</h3>

<p>Value of power according to the input arguments.
</p>


<h3>Warning </h3>

<p>This function is &lsquo;experimental&rsquo; only since it is not thorougly tested yet. 
Especially for <code>design="IBD"</code> reliable test cases are missing.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Patterson S, Jones B. <em>Bioequivalence and Statistics in Clinical Pharmacology.</em> Boca Raton: Chapman &amp; Hall/CRC: 2006. p. 239.<br />
(contains presumably a bug)
</p>
<p>Sethuraman VS, Leonov S, Squassante L, Mitchell TR, Hale MD. <em>Sample size calculation for the Power Model for dose proportionality studies.</em> Pharm Stat. 2007;6(1):35&ndash;41. <a href="https://doi.org/10.1002/pst.241">doi:10.1002/pst.241</a>
</p>
<p>Hummel J, McKendrick S, Brindley C, French R. <em>Exploratory assessment of dose proportionality: review of current approaches and proposal for a practical criterion.</em> Pharm. Stat. 2009;8(1):38&ndash;49. <a href="https://doi.org/10.1002/pst.326">doi:10.1002/pst.326</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.dp">sampleN.dp</a></code>, <code><a href="#topic+bib.CL">bib.CL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults, i.e. latin square crossover design, alpha=0.05, 
# beta0=1+log(0.95)/log(rd), theta1=0.8, theta2=1.25
power.dp(CV = 0.2, doses = c(1,2,8), n = 15)
#
# period balanced IBD with 3 doses, 2 periods and 3 sequences,
ibd &lt;- matrix(c(1, 2, 3, 2, 3, 1), nrow = 3, ncol = 2)
power.dp(CV = 0.2, doses = c(1,2,8), n = 12, design = "IBD", dm = ibd)
# considerably lower than 3x3 Latin square
</code></pre>

<hr>
<h2 id='power.HVNTID'>
(Empirical) Power for BE decision via FDA method for highly variable NTIDs
</h2><span id='topic+power.HVNTID'></span>

<h3>Description</h3>

<p>This function performs the power calculation of the BE decision via
the FDA’s method for highly variable narrow therapeutic index drugs (NTIDs)
as described in respective guidances based on simulations.
The study design could be the full replicate design 2x2x4 with 4-periods (TRTR|RTRT) or the
2x2x3 replicate design with 3-periods and sequences TRT|RTR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.HVNTID(alpha = 0.05, theta1, theta2, theta0, CV, n, design = c("2x2x4", "2x2x3"),
             nsims = 1e+05, details = FALSE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.HVNTID_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the FDA procedure.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the FDA procedure.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.95 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.HVNTID_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that <code>n</code> contains the number
of subjects per sequence groups.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes is important
if given as vector. <code>n[1]</code> is for sequence group 'TRT' and <code>n[2]</code> is for
sequence group 'RTR'.<br />
If <code>n</code> is given as single number (total sample size) and this number is not
divisible by the number of sequences of the design an unbalanced design is assumed.
A corresponding message is thrown showing the numbers of subjects in the sequence groups.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x2x4"</code> is the full replicate design with 2 sequences and 4 periods (TRTR|RTRT).<br />
<code>"2x2x3"</code> is the 3-period ful replicate design with sequences TRT|RTR.<br />
Defaults to <code>design="2x2x4"</code>.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+5.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> the computational time is shown as well as the components
for the BE decision.<br />
p(BE-ABE) is the simulated probability for the conventional ABE test.
p(BE-sratio) is the probability that the upper 90% confidence limit of the
ratio of sWT/sWR is &lt; 2.5.
</p>
</td></tr>
<tr><td><code id="power.HVNTID_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code>
is issued if <code>setseed=TRUE</code>, the default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For deciding BE the study must pass the conventional ABE test (90% CI within the
acceptance range) and additional the test that the ratio of sWT/sWR is &lt; 2.5.<br /><br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on this method.<br />
Details can be found in a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_sims&#8288;</code> located in
the <code>/doc</code> sub-directory of the package.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details=FALSE</code>.<br />
Returns a named vector if argument <code>details=TRUE</code>.<br />
p(BE) is the power, p(BE-ABE) is the power of the ABE test alone and p(BE-sratio)
is the power of the criterion 'ratio of sWT/sWR is &lt;= 2.5' alone.
</p>


<h3>Note</h3>

<p>The FD’s guidances recommend only the full replicate design &quot;2x2x4&quot; (TRTR|RTRT).
The results for the design &quot;2x2x3&quot; (TRT|RTR) are to be considered as experimental since
at present not thorougly tested.<br /><br />
The method is also required by China’s Center of Drug Evaluation.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Dabigatran Etexilate Mesylate.</em> Recommended Jun 2012; Revised Sep 2015, Jul 2017. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Dabigatran%20etexilate%20mesylate_oral%20capsule_NDA%20022512_RV05-17.pdf">download</a>
</p>
<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Rivaroxaban.</em> Recommended Sep 2015. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Rivaroxaban_oral%20tablet_22406_RC09-15.pdf">download</a>
</p>
<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Edoxaban Tosylate.</em> Recommended May 2017; Revised Mar 2020. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/PSG_206316.pdf">download</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.HVNTID">sampleN.HVNTID</a></code>
and <code><a href="#topic+power.NTIDFDA">power.NTIDFDA</a></code>, <code><a href="#topic+sampleN.NTIDFDA">sampleN.NTIDFDA</a></code> for NTIDs with
low variability
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the defaults:
# GMR=0.95, theta1=0.8, theta2=1.25, full replicate design 2x2x4, 100,000 simulations
# and a CV of 0.3 (=30%) for both Reference and Test, with 24 subjects, balanced
power.HVNTID(CV = 0.3, n = 24)
# should give a power of 0.86354
</code></pre>

<hr>
<h2 id='power.noninf'>
Power of the one-sided non-inferiority t-test
</h2><span id='topic+power.noninf'></span>

<h3>Description</h3>

<p>Function calculates of the power of the one-sided non-inferiority <em>t</em>-test
for normal or log-normal distributed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.noninf(alpha = 0.025, logscale = TRUE, margin, theta0, CV, n, 
             design = "2x2", robust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.noninf_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Defaults here to 0.025.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>margin</code> and <code>CV</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to -0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_margin">margin</code></td>
<td>

<p>Non-inferiority margin.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code> and <code>theta0</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of the <code>n</code> vector has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code><a href="#topic+known.designs">known.designs</a></code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="power.noninf_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power is calculated exact via non-central <em>t</em>-distribution.<br />
</p>
<p><strong>Notes on the underlying hypotheses</strong><br />
If the supplied margin is &lt; 0 (<code>logscale=FALSE</code>) or &lt; 1 (<code>logscale=TRUE</code>), 
then it is assumed higher response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &lt;= margin vs. H1: theta0 &gt; margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &lt;= log(margin) vs. H1: log(theta0) &gt; log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
</p>
<p>If the supplied margin is &gt; 0 (<code>logscale=FALSE</code>) or &gt; 1 (<code>logscale=TRUE</code>), 
then it is assumed lower response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &gt;= margin vs. H1: theta0 &lt; margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &gt;= log(margin) vs. H1: log(theta0) &lt; log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
This latter case may also be considered as &lsquo;non-superiority&rsquo;.
</p>


<h3>Value</h3>

<p>Value of power according to the input arguments.
</p>


<h3>Warning </h3>

<p>The function does not vectorize if design is a vector.<br />
The function vectorize properly if CV or theta0 are vectors.<br />
Other vector input is not tested yet.
</p>


<h3>Note</h3>

<p>This function does not rely on TOST but may be useful in planning BE studies 
if the question is not equivalence but &lsquo;non-superiority&rsquo;.<br />
Hint: Evaluation of Fluctuation in the <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/note-guidance-modified-release-oral-and-transdermal-dosage-forms-section-ii-pharmacokinetic-and-clinical-evaluation-superseded_en.pdf">EMEA’s Note for Guidance</a> between a modified release 
formulation and an immediate release product.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Julious SA. <em>Sample sizes for clinical trials with Normal data.</em> Stat Med. 2004;23(12):1921&ndash;86. <a href="https://doi.org/10.1002/sim.1783">doi:10.1002/sim.1783</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+known.designs">known.designs</a>, <a href="#topic+sampleN.noninf">sampleN.noninf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults: margin=0.8, theta0=0.95, alpha=0.025
# log-transformed, design="2x2"
# should give: 0.4916748
power.noninf(CV=0.3, n=24)
</code></pre>

<hr>
<h2 id='power.NTID'>
(Empirical) Power for BE decision via FDA method for NTIDs
</h2><span id='topic+power.NTID'></span><span id='topic+power.NTIDFDA'></span>

<h3>Description</h3>

<p>This function performs the power calculation of the BE decision via
the FDA’s method for narrow therapeutic index drugs (NTIDs) by simulations.
The study design could be the full replicate design 2x2x4 with 4-periods (TRTR|RTRT) or the
2x2x3 replicate design with sequences TRT|RTR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.NTID(alpha = 0.05, theta1, theta2, theta0, CV, n, design=c("2x2x4", "2x2x3"),
           nsims = 1e+05, details = FALSE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.NTID_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the FDA procedure.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the FDA procedure.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Attention! Defaults here to 0.975 if not given explicitly. The value was chosen
closer to 1 because the potency (contents) settings for NTIDs are tightened
by the FDA.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT == CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.NTID_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that n contains the number
of subjects per sequence groups.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes important
if given as vector. <code>n[1]</code> is for sequence group &lsquo;TRT&rsquo; and <code>n[2]</code> is for
sequence group &lsquo;RTR&rsquo;.<br /><br />
If <code>n</code> is given as single number (total sample size) and this number is not
divisible by the number of sequences of the design an unbalanced design is assumed.
A corresponding message is thrown showing the numbers of subjects in the sequence groups.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x2x4"</code> is the full replicate design with 2 sequences and 4 periods (TRTR|RTRT).<br />
<code>"2x2x3"</code> is the full replicate design with 2 sequences and 3 periods (TRT|RTR).<br />
Defaults to <code>design="2x2x4"</code>.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+5.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> the computational time is shown as well as the components
for the BE decision.<br />
<code style="white-space: pre;">&#8288;p(BE-ABE)&#8288;</code> is the simulated probability for the conventional ABE test.<br />
<code style="white-space: pre;">&#8288;p(BE-sABEc)&#8288;</code> is the probability that the 95% CI of the scaled ABE criterion is &leq;&nbsp;0.<br />
<code style="white-space: pre;">&#8288;p(BE-sratio)&#8288;</code> is the probability that the upper confidence limit of
<em>&sigma;</em><sub>wT</sub>/<em>&sigma;</em><sub>wR</sub>&nbsp;&leq;&nbsp;2.5.
</p>
</td></tr>
<tr><td><code id="power.NTID_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code>
is issued if <code>setseed = TRUE</code>, the default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linearized scaled ABE criterion is calculated according to the SAS code
given in the FDA’s guidances. For deciding BE the study must pass that criterion,
the conventional ABE test, and that the upper confidence limit of
<em>&sigma;</em><sub>wT</sub>/<em>&sigma;</em><sub>wR</sub>&nbsp;&leq;&nbsp;2.5.<br />
</p>
<p>The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on these method.<br />
Details can be found in a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_sims&#8288;</code> located in
the <code>/doc</code> sub-directory of the package.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details = FALSE</code>.<br />
Returns a named vector if argument <code>details = TRUE</code>, where
<code style="white-space: pre;">&#8288;p(BE)&#8288;</code> is the (overall) power, <code style="white-space: pre;">&#8288;p(BE-sABEc)&#8288;</code> is the power of the BE test via scaled ABE criterion alone,
<code style="white-space: pre;">&#8288;p(BE-ABE)&#8288;</code> is the power of the conventional ABE test alone, and <code style="white-space: pre;">&#8288;p(BE-sratio)&#8288;</code>
is the power of the criterion &lsquo;upper confidence limit of
&sigma;<sub>wT</sub>/&sigma;<sub>wR</sub>&nbsp;&leq;&nbsp;2.5&rsquo; alone.
</p>


<h3>Note</h3>

<p>The FDA’s method is described for the <abbr><span class="acronym">ABE</span></abbr> limits 0.8 ... 1.25 only. Setting <code>theta1</code>,
<code>theta2</code> to other values may not be reasonable and is not tested.<br />
The results for the design <code>"2x2x3"</code> are to be considered as experimental since at present not thorougly tested.<br /><br />
The method is also required by China’s Center of Drug Evaluation.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Warfarin Sodium.</em> Recommended Dec 2012. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Warfarin_Sodium_tab_09218_RC12-12.pdf">download</a>
</p>
<p>Food and Drug Administration, Center for Drug Evaluation and Research (CDER). <em>Draft Guidance for Industry. Bioequivalence Studies with Pharmacokinetic Endpoints for Drugs Submitted Under an ANDA.</em> August 2021. <a href="https://www.fda.gov/media/87219/download">download</a>
</p>
<p>Yu LX, Jiang W, Zhang X, Lionberger R, Makhlouf F, Schuirmann DJ, Muldowney L, Chen ML, Davit B, Conner D, Woodcock J. <em>Novel bioequivalence approach for narrow therapeutic index drugs.</em> Clin Pharmacol Ther. 2015;97(3):286&ndash;91. <a href="https://doi.org/10.1002/cpt.28">doi:10.1002/cpt.28</a>
</p>
<p>Jiang W, Makhlouf F, Schuirmann DJ, Zhang X, Zheng N, Conner D, Yu LX, Lionberger R. <em>A Bioequivalence Approach for Generic Narrow Therapeutic Index Drugs: Evaluation of the Reference-Scaled Approach and Variability Comparison Criterion.</em> AAPS J. 2015;17(4):891&ndash;901. <a href="https://doi.org/10.1208/s12248-015-9753-5">doi:10.1208/s12248-015-9753-5</a>
</p>
<p>Endrényi L, Tóthfalusi L. <em>Determination of Bioequivalence for Drugs with Narrow Therapeutic Index: Reduction of the Regulatory Burden.</em> J Pharm Pharm Sci. 2013;16(5):676&ndash;82. <a href="https://journals.library.ualberta.ca/jpps/index.php/JPPS/article/download/20900/15927/0">open access</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.NTID">sampleN.NTID</a></code><br />
and <code><a href="#topic+power.HVNTID">power.HVNTID</a></code>, <code><a href="#topic+sampleN.HVNTID">sampleN.HVNTID</a></code> for NTIDs with
high variability
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the all defaults:
# GMR=0.975, theta1=0.8, theta2=1.25, 100,000 simulations
# and a CV of 0.1 (= 10%) with 12 subjects, balanced
power.NTID(CV = 0.1, n = 12)
# should give a power of 0.62553
</code></pre>

<hr>
<h2 id='power.RatioF'>
Power for equivalence of the ratio of two means with normality on original scale
</h2><span id='topic+power.RatioF'></span>

<h3>Description</h3>

<p>Calculates the power of the test of equivalence of the ratio of two means 
with normality on original scale.<br /> 
This test is based on Fieller’s confidence (&lsquo;fiducial&rsquo;) interval and Sasabuchi’s 
test (a TOST procedure as well).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.RatioF(alpha = 0.025, theta1 = 0.8, theta2, theta0 = 0.95,
             CV, CVb, n, design = "2x2", setseed=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.RatioF_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, aka significance level.<br />
Defaults here to 0.025 because this function is intended for studies
with clinical endpoints. 
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_theta1">theta1</code></td>
<td>

<p>Lower bioequivalence limit. Typically 0.8 (default).
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_theta2">theta2</code></td>
<td>

<p>Upper bioequivalence limit. Typically 1.25.<br />
Is set to <code>1/theta1</code> if missing.
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Typically set to 0.95 for planning.
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation as ratio. In case of <code>design="parallel"</code> this is
the CV of the total variability, in case of <code>design="2x2"</code> the 
intra-subject CV (CVw in the reference).
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_cvb">CVb</code></td>
<td>

<p>CV of the between-subject variability. Only necessary for <code>design="2x2"</code>.
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_n">n</code></td>
<td>

<p>Number of subjects to be planned.<br />
<code>n</code> is for both designs implemented the <b>total</b> number of subjects.<br />
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_design">design</code></td>
<td>

<p>A character string describing the study design.<br /> 
<code>design="parallel"</code> or <code>design="2x2"</code> allowed for a two-parallel 
group design or a classical TR|RT crossover design.
</p>
</td></tr>
<tr><td><code id="power.RatioF_+3A_setseed">setseed</code></td>
<td>

<p>If set to <code>TRUE</code> the dependence of the power from the state of the random number
generator is avoided. With <code>setseed = FALSE</code> you may see the dependence
from the state of the random number generator.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power is calculated exact using the bivariate non-central <em>t</em>-distribution
via function <code><a href="mvtnorm.html#topic+pmvt">pmvt</a></code> of the package <code>mvtnorm</code>.<br />
Due to the calculation method of the used package mvtnorm &ndash; randomized 
Quasi-Monte-Carlo &ndash; these probabilities are dependent from the state of the 
random number generator within the precision of the power. 
See argument <code>setseed</code>.
</p>


<h3>Value</h3>

<p>Value of power according to the input.
</p>


<h3>Note</h3>

<p>This function is intended for studies with clinical endpoints where the 95% confidence intervals are usually used for equivalence testing.<br />
Therefore, alpha defaults here to 0.025 (see EMEA 2000).<br /><br />
The formulas given in the references rely on the assumption of equal variances
in the two treatment groups for the parallel group design or on assuming equal 
within-subject and between-subject variabilities for the 2×2 crossover design.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Fieller EC. <em>Some Problems in Interval Estimation.</em> J Royal Stat Soc B. 1954;16(2):175&ndash;85. <a href="https://doi.org/10.1111/j.2517-6161.1954.tb00159.x">doi:10.1111/j.2517-6161.1954.tb00159.x</a>
</p>
<p>Sasabuchi S. <em>A test of a multivariate normal mean with composite hypotheses determined by linear inequalities.</em> Biometrika. 1980;67(2):429&ndash;39. <a href="https://doi.org/10.1093/biomet/67.2.429">doi:10.1093/biomet/67.2.429</a>
</p>
<p>Hauschke D, Kieser M, Diletti E, Burke M. <em>Sample size determination for proving equivalence based on the ratio of two means for normally distributed data.</em> Stat Med. 1999;18(1):93&ndash;105.
</p>
<p>Hauschke D, Steinijans V, Pigeot I. <em>Bioequivalence Studies in Drug Development.</em> Chichester: Wiley; 2007. Chapter 10.
</p>
<p>European Agency for the Evaluation of Medicinal Products, CPMP. <em>Points to Consider on Switching between Superiority and Non-Inferiority.</em> London, 27 July 2000. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/points-consider-switching-between-superiority-and-non-inferiority_en.pdf">CPMP/EWP/482/99</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.RatioF">sampleN.RatioF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># power for alpha=0.025, ratio0=0.95, theta1=0.8, theta2=1/theta1=1.25
# within-subject CV=0.2, between-subject CV=0.4 
# 2x2 crossover study, n=24
# using all the defaults:
power.RatioF(CV = 0.2, CVb = 0.4, n = 24)
# gives [1] 0.7315357
</code></pre>

<hr>
<h2 id='power.RSABE'>
(Empirical) Power for BE decision via linearized scaled ABE criterion
</h2><span id='topic+power.RSABE'></span>

<h3>Description</h3>

<p>This function performs the power calculation of the BE decision via 
linearized scaled ABE criterion by simulations as recommended by the FDA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.RSABE(alpha = 0.05, theta1, theta2, theta0, CV, n, 
            design = c("2x3x3", "2x2x4", "2x2x3"), regulator,
            nsims = 1e+05, details = FALSE, setseed=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.RSABE_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.RSABE_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that n contains the number
of subjects in the sequence groups.<br /><br />
If <code>n</code> is given as single number (total sample size) and this number is not 
divisible by the number of sequences of the design an unbalanced design is 
assumed. A corresponding message is thrown showing the numbers of subjects 
in sequence groups used.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes / sequence is important if given as a vector. <code>n[1]</code> is for sequence group 'TRT' and <code>n[2]</code> is for 
sequence group 'RTR'. 
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_design">design</code></td>
<td>

<p>Design of the study.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for RSABE.<br />
May be given as character from the choices <code>"EMA"</code> or <code>"FDA"</code> or as an object of
class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="FDA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br /><br />
Also the linearized scaled ABE criterion is usually calculated with the FDA 
constant <code>r_const=log(1.25)/0.25</code> you can override this behavior to use the 
EMA setting <code>r_const=0.76</code> to avoid the discontinuity at CV=30% and be 
more stringent.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+5.<br />
If simulations are aimed for empirical alpha <code>nsims=1e+06</code> is recommended.
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_details">details</code></td>
<td>

<p>If set to <code style="white-space: pre;">&#8288;TRUE&#8288;</code> the computational time is shown as well as the components
for the BE decision.<br />
p(BE-sABEc) is the probability that the 95% CI of the ABE criterion is &lt;0.<br />
p(BE-PE) is the probability that the point estimate is within theta1 ... theta2.<br />
p(BE-ABE) is the simulated probability for the conventional ABE test given for
comparision purposes.<br />
</p>
</td></tr>
<tr><td><code id="power.RSABE_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed()</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linearized scaled ABE criterion is calculated according to the SAS code
given in the FDA’s progesterone guidance.<br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on scaled ABE criterion.<br />
Details can be found in a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_simsVx.yy.pdf&#8288;</code> 
located in the <code>/doc</code> sub-directory of the package.<br />
If a CVcap is defined for the regulator, the BE decision is based on the inclusion
of the CI in the capped widened acceptance limits in case of <code>CVwR &gt; CVcap</code>. This
resembles method &lsquo;Howe-EMA&rsquo; in Muñoz <em>et al.</em> and is the standard behavior now if
<code>regulator="EMA"</code> is choosen.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details=FALSE</code>.<br />
Returns a named vector if argument <code>details=TRUE</code>.<br />
p(BE) is the power, p(BE-sABEc) is the power of the scaled ABE criterion alone 
and p(BE-pe) is the power of the criterion &lsquo;point estimat within acceptance 
range&rsquo; alone.<br />
p(BE-ABE) is the power of the conventional ABE test given for comparative purposes.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, power calculations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>In case of the design <code>"2x2x3"</code>&quot; heteroscedasticity (<em>i.e.</em>, CVwT != CVwR) may 
lead to poor agreement of the power values compared to those calculated via the 
&lsquo;classical&rsquo; way of subject data simulations if the design is unbalanced in respect
to the number of subjects in the sequence groups. Therefore, the function 
issues a warning for that cases.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Progesterone.</em> Recommended Apr 2010. Revised Feb 2011. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Progesterone_caps_19781_RC02-11.pdf">download</a>
</p>
<p>Tóthfalusi, L, Endrényi, L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. 
<a href="https://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>
<p>Tóthfalusi L, Endrényi L, García Arieta A. <em>Evaluation of Bioequivalence for Highly Variable Drugs with Scaled Average Bioequivalence.</em> Clin Pharmacokin. 2009;48(11):725&ndash;43. <a href="https://doi.org/10.2165/11318040-000000000-00000">doi:10.2165/11318040-000000000-00000</a>
</p>
<p>Muñoz J, Alcaide D, Ocaña J. <em>Consumer’s risk in the EMA and FDA regulatory approaches for bioequivalence in highly variable drugs.</em> Stat Med. 2015;35(12):1933&ndash;43. <a href="https://doi.org/10.1002/sim.6834">doi:10.1002/sim.6834</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.RSABE">sampleN.RSABE</a></code>, <code><a href="#topic+power.scABEL">power.scABEL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults:
# design="2x3x3" = partial replicate
# ABE limits, PE constraint 0.8-1.25
# true ratio = 0.90, 1E+5 simulations
power.RSABE(CV = 0.4, n = 36)
# should give
# [1] 0.83634
#
# to explore the simulation error due to the state of the
# random number generator
power.RSABE(CV = 0.4, n = 36, setseed = FALSE)
# will give something like
# [1] 0.83725
#
# explore pure RSABE (without mixed method, without pe constraint)
rs           &lt;- reg_const("FDA")
rs$CVswitch  &lt;- 0
rs$pe_constr &lt;- FALSE
power.RSABE(CV = 0.4, n = 36, regulator = rs)
# should give
# [1] 0.84644
</code></pre>

<hr>
<h2 id='power.RSABE2L.sdsims'>
(Empirical) Power of BE Decision via Reference Scaled ABE
</h2><span id='topic+power.RSABE2L.sdsims'></span><span id='topic+power.RSABE2L.sds'></span>

<h3>Description</h3>

<p>These function performs the power calculation of the BE decision via 
the reference scaled ABE based on <b>subject data</b> simulations.
Implemented are the methods ABEL, Hyslop and &lsquo;exact&rsquo; as described in the 
references.<br />
The estimation method of the key statistics needed to perform the <abbr><span class="acronym">RSABE</span></abbr> decision 
is the usual <abbr><span class="acronym">ANOVA</span></abbr>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.RSABE2L.sdsims(alpha = 0.05, theta1, theta2, theta0, CV, n, 
                     design = c("2x3x3", "2x2x4", "2x2x3"), design_dta = NULL,
                     SABE_test = "exact", regulator, nsims = 1e+05, 
                     details = FALSE, setseed = TRUE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.RSABE2L.sdsims_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower <abbr><span class="acronym">ABE</span></abbr> (Average Bioequivalence) limit to be applied
in the mixed procedure if <code>CVsWR &lt;= CVswitch</code>. Also lower limit for the point
estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio.<br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that <code>n</code> contains the number
of subjects in the sequence groups.<br />
If <code style="white-space: pre;">&#8288;n&#8288;</code> is given as single number (total sample size) and this number is not 
divisible by the number of sequences of the design an unbalanced design is 
assumed. A corresponding message is thrown (showing the numbers of subjects 
in sequence groups).<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes
per sequence is important if given as vector. <code>n[1]</code> is for sequence group
'TRT' and <code>n[2]</code> is for sequence group 'RTR'. 
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_design">design</code></td>
<td>

<p>Design of the study.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>design="2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_design_dta">design_dta</code></td>
<td>

<p>Alternatively to using the arguments <code>design</code> and <code>n</code> the design may 
be defined via a data.frame with columns <code>subject, sequence, period</code> and
<code style="white-space: pre;">&#8288;tmt&#8288;</code>. This feature is experimental in the sense that the data.frame is
not checked for complying with the assumed structure.<br />
If you use the argument <code>design_dta</code> you don’t need to specify the arguments
<code>design</code> and <code>n</code>.<br />
The default <code>design_dta=NULL</code> means that <code style="white-space: pre;">&#8288;design&#8288;</code> and <code style="white-space: pre;">&#8288;n&#8288;</code> are used
for the internal construction of the design data.frame.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_sabe_test">SABE_test</code></td>
<td>

<p>This argument specifies the test method to be used for the reference scaled
<abbr><span class="acronym">ABE</span></abbr> decision.<br />
Default is the <code>"exact"</code> &lsquo;ncTOST&rsquo; method of the two Laszlós. Other choices are <code>"ABEL"</code>, <code>"hyslop"</code> and <code>"fda"</code>. See Details.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as character <code>"EMA"</code> or as an object of
class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br /><br />
If given as object of class 'regSet' the component <code>est_method</code> can not be <code>"ISC"</code>. 
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+05.<br />
If simulations are aimed for empirical alpha <code>nsims=1e+06</code> is recommended.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_details">details</code></td>
<td>

<p>If set to <code style="white-space: pre;">&#8288;TRUE&#8288;</code> the computational time is shown as well as the components
for the BE decision.<br />
<code style="white-space: pre;">&#8288;p(BE-RSABE)&#8288;</code> is the probability of a positive outcome of the <abbr><span class="acronym">SABE</span></abbr> test.<br />
<code style="white-space: pre;">&#8288;p(BE-PE)&#8288;</code> is the probability that the point estimate is within
<code style="white-space: pre;">&#8288;theta1&#8288;</code> ... <code style="white-space: pre;">&#8288;theta2&#8288;</code>.<br />
<code style="white-space: pre;">&#8288;p(BE-ABE)&#8288;</code> is the simulated probability for the conventional <abbr><span class="acronym">ABE</span></abbr> test.
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed()</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
<tr><td><code id="power.RSABE2L.sdsims_+3A_progress">progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and <code>nsims &gt;5e5</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assumes a 
log-normal distribution on the original scale.<br /><br />
The data.frame with columns <code>subject, sequence, period</code> and <code>tmt</code> 
necessary for evalution of simulated subject data is constructed internally from 
the arguments <code>design</code> and <code>n</code> or may be given user defined via the argument 
<code>design_dta</code>. The last option is usefull if missing data have to be considered
or if designs have to be evaluated which are not in the list of argument 
<code>design</code>.<br /><br />
The estimation method for obtaining the statistics necessary to perform the
reference scaled ABE decision is the usual <abbr><span class="acronym">ANOVA</span></abbr> with effects treatment, period,
sequence and subject within sequence for the evaluation of all data and period,
sequence and subject within sequence for the evaluation of the Reference formulation
data only.<br /><br />
The SABE tests implemented are:<br />
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>"exact"</code> </td><td style="text-align: left;"> &lsquo;exact&rsquo; based method of the two Laszlós (see references, 
  called there &lsquo;ncTOST&rsquo;)</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"ABEL"</code> </td><td style="text-align: left;"> Average bioequivalence with expanding limits</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"hyslop"</code> </td><td style="text-align: left;"> BE decision via the linearized RSABE criterion and its 
  upper 95% CI</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>"fda"</code> </td><td style="text-align: left;"> Hyslop with an additional bias correction term as implemented 
  in the <abbr><span class="acronym">SAS</span></abbr> code of the</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;"> <abbr><span class="acronym">FDA</span></abbr>’s Guidance on Progesterone.
</td>
</tr>

</table>



<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details=FALSE</code>.<br /><br />
Returns a named vector if argument <code>details=TRUE</code>.<br />
<code style="white-space: pre;">&#8288;p(BE)&#8288;</code> is the power, <code style="white-space: pre;">&#8288;p(BE-RSABE)&#8288;</code> is the power of using the reference
scaled <abbr><span class="acronym">ABE</span></abbr> alone, and <code style="white-space: pre;">&#8288;p(BE-pe)&#8288;</code> is the power of the criterion
&lsquo;point estimate within acceptance range&rsquo; alone. <code style="white-space: pre;">&#8288;p(BE-ABE)&#8288;</code> is the power of
the conventional <abbr><span class="acronym">ABE</span></abbr> test given for comparative purposes.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, power calculations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The function is relatively slow. The run-time for 1 Mio. simulations 
is between ~ 1 up to 6 minutes for n=12 or n=120 and 1 Mio. sim’s
(see the call under examples) on a machine with an Intel core i7 processor.<br />
Thus be patient and go for a cup of coffee if you use this function with higher 
sample sizes and aim for estimating the type 1 error!
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Progesterone.</em> Recommended Apr 2010. Revised Feb 2011. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Progesterone_caps_19781_RC02-11.pdf">download</a>
</p>
<p>Tóthfalusi L, Endrényi L. <em>An Exact Procedure for the Evaluation of Reference-Scaled Average Bioequivalence.</em> AAPS J. 2016;18(2):476&ndash;89. <a href="https://doi.org/10.1208/s12248-016-9873-6">doi:10.1208/s12248-016-9873-6</a>.
</p>
<p>Tóthfalusi L, Endrényi L. <em>Algorithms for evaluating reference scaled average bioequivalence: power, bias, and consumer risk.</em> Stat Med. 2017;36(27):4378&ndash;4390. <a href="https://doi.org/10.1002/sim.7440">doi:10.1002/sim.7440</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.RSABE">power.RSABE</a>, <a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Not run due to timing policy of CRAN

# pure EMA settings without mixed procedure, cap on widening and PE constraint
# as in the reference from 2017
reg           &lt;- reg_const("EMA")
reg$CVswitch  &lt;- 0
reg$CVcap     &lt;- Inf
reg$pe_constr &lt;- FALSE
reg$name      &lt;- "EMA pure"
power.RSABE2L.sds(CV = 0.4, n = 12, theta0 = exp(0.05),
                  design = "2x2x4", regulator = reg, nsims = 50000)
# should give:
# [1] 0.46504 (compared to 47.1% in the 2017 reference)
</code></pre>

<hr>
<h2 id='power.scABEL'>
(Empirical) Power of BE decision via scaled (widened) BE acceptance limits
</h2><span id='topic+power.scABEL'></span>

<h3>Description</h3>

<p>These function performs the power calculation of the BE decision via 
scaled (widened) BE acceptance limits by simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.scABEL(alpha = 0.05, theta1, theta2, theta0, CV, n, 
             design = c("2x3x3", "2x2x4", "2x2x3"), regulator, 
             nsims, details = FALSE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.scABEL_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in 
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.scABEL_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that <code>n</code> contains the number
of subjects in the sequence groups.<br />
If <code>n</code> is given as single number (total sample size) and this number is not 
divisible by the number of sequences of the design an unbalanced design is 
assumed. A corresponding message is thrown showing the numbers of subjects 
in sequence groups.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes is important 
if given as vector. <code>n[1]</code> is for sequence group 'TRT' and <code>n[2]</code> is for 
sequence group 'RTR'. 
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_design">design</code></td>
<td>

<p>Design of the study.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as character from the choices <code>"EMA"</code>, <code>"HC"</code>, <code>"FDA"</code>, 
<code>"GCC"</code> or as an object of class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br />
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+05.<br />
If not given and <code>theta0</code> equals one of the expanded limits (<em>i.e.</em>, 
simulating empirical alpha), defaults to 1e+06.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> the computational time is shown as well as the components
for the BE decision.<br />
p(BE-wABEL) is the probability that the CI is within (widened) limits.<br />
p(BE-PE) is the probability that the point estimate is within theta1 ... theta2.<br />
p(BE-ABE) is the simulated probability for the conventional ABE test.
</p>
</td></tr>
<tr><td><code id="power.scABEL_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed()</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assume a 
log-normal distribution on the original scale.<br /><br />
The widened BE acceptance limits will be calculated by the formula<br />
<code style="white-space: pre;">&#8288;  [L, U] = exp(-/+ r_const * sWR)&#8288;</code><br />
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference. <code>r_const = 0.76</code> (~log(1.25)/0.29356) is used 
in case of <code>regulator="EMA"</code> or <code>regulator="HC"</code> and in case of 
<code>regulator="FDA"</code> <code>r_const = 0.89257...</code> (log(1.25)/0.25).
If the CVwR of the Reference is &lt; CVswitch=0.3 the conventional ABE limits 
apply (mixed procedure).<br /><br /> 
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if 
CVwR&gt;0.5, <em>i.e.</em>, the widened limits are held at value calculated for CVwR=0.5.
In case of <code>regulator="HC"</code> the capping is done such that the acceptance
limits are 0.6666 ... 1.5 at maximum.<br /><br />
The case of <code>regulator="GCC"</code> is treatd as special case of ABEL with 
CVswitch = CVcap = 0.3. The r_const = log(1.25)/CV2se(0.3) assures that for CV&gt;0.3
the widened BE limits of 0.7 ... 1.3333 are used.<br /><br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on widened ABEL.<br />
For more details see the document <code style="white-space: pre;">&#8288;Implementation_scaledABE_simsVx.yy.pdf&#8288;</code> in the 
<code>/doc</code> sub-directory of the package.<br /><br />
Function <code>power.scABEL()</code> implements the simulation via distributional 
characteristics of the &lsquo;key&rsquo; statistics obtained from the EMA recommended 
evaluation via ANOVA if <code>regulator="EMA"</code> or if the regulator component 
<code>est_method</code> is set to <code>"ANOVA"</code> if regulator is an object of class 'regSet'.<br />
Otherwise the simulations are based on the distributional characteristis of the 
&lsquo;key&rsquo; statistics obtained from evaluation via intra-subject contrasts (ISC), 
as recommended by the FDA.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details=FALSE</code>.<br /><br />
Returns a named vector if argument <code>details=TRUE</code>.<br />
p(BE) is the power, p(BE-ABEL) is the power of the widened ABEL criterion alone 
and p(BE-pe) is the power of the criterion &lsquo;point estimate within acceptance 
range&rsquo; alone. p(BE-ABE) is the power of the conventional ABE test given for 
comparative purposes.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, power calculations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>Cross-validation of the simulations as implemented here and via the &lsquo;classical&rsquo; 
subject data simulation have shown somewhat unsatisfactory results for the 
2x3x3 design if the variabilities for Test and Reference are different and/or sequences exteremly unbalanced.<br />
The function <code>power.scABEL()</code> therefore gives a warning if calculations 
with different CVwT and CVwR are requested for the 2x3x3 partial replicate design. For <code>"EMA"</code> subject simulations are provided in <code><a href="#topic+power.scABEL.sdsims">power.scABEL.sdsims</a></code>.
For more details see the above mentioned document <code style="white-space: pre;">&#8288;Implementation_scaledABE_simsVy.xx.pdf&#8288;</code>.
</p>


<h3>Note</h3>

<p>In case of <code>regulator="FDA"</code> the (empirical) power is only approximate since
the BE decision method is not exactly what is expected by the FDA. But the &ldquo;Two Laszlós&rdquo; state that the scABEL method should be &lsquo;operational equivalent&rsquo; to the
FDA method.<br />
To get the power for the FDA favored method via linearized scaled ABE criterion
use function <code><a href="#topic+power.RSABE">power.RSABE</a></code>.<br /><br />
In case of <code>regulator="HC"</code> (based on ISC), power is also only approximative since Health Canada recommends an evaluation via mixed model approach. This could only implemented via 
subject data simulations which are very time consuming. But ISC may be a good 
substitute.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. 
<a href="https://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open source</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a>, <a href="#topic+power.RSABE">power.RSABE</a>, <a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults:
# design="2x3x3", EMA regulatory settings
# PE constraint 0.8-1.25, cap on widening if CV&gt;0.5
# true ratio=0.90, 1E+6 simulations
power.scABEL(CV = 0.4, n = 29)
# should give:
# Unbalanced design. n(i)=10/10/9 assumed.
# [1] 0.66113
#
# with details=TRUE to view the computational time and components
power.scABEL(CV = 0.5, n = 54, theta0 = 1.15, details = TRUE)
# should give (times may differ depending on your machine):
# 1e+05sims. Time elapsed (sec): 0.07
# 
#      p(BE) p(BE-wABEL)    p(BE-pe)   p(BE-ABE) 
#    0.81727     0.82078     0.85385     0.27542
#
# exploring 'pure ABEL' with the EMA regulatory constant
# (without mixed method, without capping, without pe constraint)
rs           &lt;- reg_const("EMA")
rs$CVswitch  &lt;- 0
rs$CVcap     &lt;- Inf
rs$pe_constr &lt;- FALSE
power.scABEL(CV = 0.5, n = 54, theta0 = 1.15, regulator = rs)
# should give
# [1] 0.8519
</code></pre>

<hr>
<h2 id='power.scABEL.sds'>
(Empirical) Power of BE decision via scaled (widened) BE acceptance limits
</h2><span id='topic+power.scABEL.sdsims'></span><span id='topic+power.scABEL.sds'></span>

<h3>Description</h3>

<p>These function performs the power calculation of the BE decision via 
scaled (widened) BE acceptance limits based on <b>subject data</b> simulations.<br />
This function has an alias power.scABEL.sds().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.scABEL.sdsims(alpha = 0.05, theta1, theta2, theta0, CV, n, 
                    design = c("2x3x3", "2x2x4", "2x2x3"), design_dta=NULL,
                    regulator, nsims = 1e+05, details = FALSE, setseed = TRUE, 
                    progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.scABEL.sds_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in 
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that <code>n</code> contains the number
of subjects in the sequence groups.<br />
If <code>n</code> is given as single number (total sample size) and this number is not 
divisible by the number of sequences of the design an unbalanced design is 
assumed. A corresponding message is thrown showing the numbers of subjects 
in sequence groups.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes is important 
if given as vector. <code>n[1]</code> is for sequence group 'TRT' and <code>n[2]</code> is for 
sequence group 'RTR'. 
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design (TRR|RTR|RRT).<br />
<code>"2x2x4"</code> is the full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is the 3-period design with sequences TRT|RTR.<br />
Defaults to <code>design="2x3x3"</code>.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_design_dta">design_dta</code></td>
<td>

<p>Alternatively to using the arguments <code>design</code> and <code>n</code> the design may 
be defined via a data.frame with columns <code>subject, sequence, period</code> and
<code>tmt</code>. This feature is experimental in the sense that the data.frame is
not checked for complying with the assumed structure.<br />
If you use the argument <code>design_dta</code> you don't need to specify the arguments
<code>design</code> and <code>n</code>.<br />
The default <code>design_dta = NULL</code> means that <code>design</code> and <code>n</code> are used
for the internal construction of the design data.frame.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as <code>"EMA"</code> or as an object of
class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br /><br />
If given as object of class 'regSet' the component <code>est_method</code> must not be <code>"ISC"</code>. 
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+05.<br />
If simulations are aimed for empirical alpha <code>nsims=1e+06</code> is recommended.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> the computational time is shown as well as the components
for the BE decision.<br />
p(BE-wABEL) is the probability that the CI is within (widened) limits.<br />
p(BE-PE) is the probability that the point estimate is within theta1 ... theta2.<br />
p(BE-ABE) is the simulated probability for the conventional ABE test.
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed()</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
<tr><td><code id="power.scABEL.sds_+3A_progress">progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and nsims &gt;5E5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assume a 
log-normal distribution on the original scale.<br /><br />
The widened BE acceptance limits will be calculated by the formula<br />
<code style="white-space: pre;">&#8288;  [L, U] = exp(± r_const * sWR)&#8288;</code><br />
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference. <code>r_const = 0.76</code> (~log(1.25)/0.29356) is used 
in case of <code>regulator="EMA"</code>.
If the CVwR of the Reference is &lt; CVswitch=0.3 the conventional ABE limits 
apply (mixed procedure).<br /> 
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if 
CVwr&gt;0.5, <em>i.e.</em>, the widened limits are held at value calculated for CVwR=0.5.<br /><br />
The simulations are done by simulating subject data (all effects fixed except the
residuals) and evaluating these data via ANOVA of all data to get the point estimate
of T vs. R along with its 90% CI and an ANOVA of the data under R(eference) only
to get an estimate of s2wR.<br />
The data.frame with columns  <code>subject, sequence, period</code> and <code>tmt</code> 
necessary for evalution of simulated subject data is constructed internally from 
the arguments <code>design</code> and <code>n</code> or may be given user defined via the argument 
<code>design_dta</code>. The last option is usefull if missing data have to be considered
or if designs have to be evaluated which are not in the list of argument 
<code>design</code>.<br />
This feature is experimental in the sense that the data.frame is not checked 
for complying with the assumed structure.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power if argument <code>details=FALSE</code>.<br /><br />
Returns a named vector if argument <code>details=TRUE</code>.<br />
p(BE) is the power, p(BE-wABEL) is the power of the widened ABEL criterion alone 
and p(BE-pe) is the power of the criterion 'point estimat within acceptance 
range' alone. p(BE-ABE) is the power of the conventional ABE test given for 
comparative purposes.
</p>


<h3>Note</h3>

<p>The function is mainly intended for crosscheck of <code>power.scABEL()</code> results.<br />
But may be mandatory for cases where <code>power.scABEL()</code> results are inaccurate
(low sample sizes and/or heteroscedasticity).<br />
It is relatively slow. The run-time of this function doing 1 Mio sims is between 
~ 7-8 sec for n=12 and ~ 3-4 min for n=120 on a machine with an Intel core i7 processor.<br />
Thus be patient and go for a cup of coffee if you use this function with high 
sample sizes!
</p>


<h3>Author(s)</h3>

<p>D. Labes, B. Lang
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. <a href="http://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open source</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.scABEL">power.scABEL</a>, <a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults:
# design="2x3x3", EMA regulatory settings
# PE constraint 0.8-1.25, cap on widening if CV&gt;0.5
# true ratio=0.90, 1E+5 simulations
power.scABEL.sdsims(CV = 0.4, n = 36)
# should give:
# [1] 0.74321
</code></pre>

<hr>
<h2 id='power.TOST'>
Power of the classical TOST procedure
</h2><span id='topic+power.TOST'></span>

<h3>Description</h3>

<p>Calculates the exact or approximate power of the two-one-sided t-tests (TOST)
procedure for various study designs used in BE studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.TOST(alpha = 0.05, logscale = TRUE, theta1, theta2, theta0, CV, n, 
           design = "2x2", method="exact", robust=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.TOST_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to 0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code> or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of <code>n</code> vector has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_method">method</code></td>
<td>

<p>Method for calculation of the power.<br />  
Defaults to <code>"exact"</code> in which case the calculation is done based on formulas 
with Owen’s Q. The calculation via Owen’s Q can also be choosen with 
<code>method="owenq"</code>.<br />
Another exact method via direct integration of the bivariate non-central 
<em>t</em>-distribution may be chosen with <code>method="mvt"</code>. This may have somewhat 
lower precision compared to Owen’s Q and longer run-time.<br />
Approximate calculations can be choosen via <code>method="noncentral"</code> or 
<code>method="nct"</code> for the approximation using the non-central <em>t</em>-distribution.
With <code>method="central"</code> or <code>method="shifted"</code> the relative crude
approximation via &lsquo;shifted&rsquo; central <em>t</em>-distribution is chosen.<br />
The strings for <code>method</code> may be abbreviated.
</p>
</td></tr>
<tr><td><code id="power.TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; 
evaluation (aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exact calculations of power are based on Owen’s Q-function or by direct 
integration of the bivariate non-central <em>t</em>-distribution via function
<code><a href="mvtnorm.html#topic+pmvt">pmvt</a></code> of package <code>mvtnorm</code>.<br />
Approximate power is implemented via the non-central <em>t</em>-distribution
or the &lsquo;shifted&rsquo; central <em>t</em>-distribution.<br /><br />
The formulas cover balanced and unbalanced studies w.r.t (sequence) groups.<br /><br />
In case of parallel group design and higher order crossover designs 
(replicate crossover or crossover with more than two treatments) the calculations 
are based on the assumption of equal variances for Test and Reference products
under consideration.<br /><br />
The formulas for the paired means 'design' do not take a correlation parameter 
into account. They are solely based on the paired <em>t</em>-test (TOST of differences = zero).
</p>


<h3>Value</h3>

<p>Value of power according to the input arguments.
</p>


<h3>Note</h3>

<p>Of course it is highly recommended to use the default <code>method="exact"</code> :-).<br />
There is no reason beside testing and for comparative purposes to use an 
approximation if the exact method is available.<br /><br />
If <code>n</code> is given as scalar (total sample size) and this number is not 
divisible by the number of (sequence) groups of the design an unbalanced design 
with small imbalance is assumed. A corresponding message is thrown showing the 
assumed numbers of subjects in (sequence) groups.<br />
The function does not vectorize properly if design is a vector.<br />
The function vectorizes properly if CV or theta0 are vectors.<br />
Other vector input is not tested yet.<br /><br />
The former function <code>power2.TOST()</code> designd to handle unbalanced studies is 
defunct since <code>power.TOST()</code> handles balanced as well as unbalanced designs.
</p>


<h3>Author(s)</h3>

<p>D. Labes, direct integration of bivariate non-central <em>t</em>-distribution by B. Lang
</p>


<h3>References</h3>

<p>Phillips KF. <em>Power of the Two One-Sided Tests Procedure in Bioequivalence.</em> J Pharmacokin Biopharm. 1990;18(2):137&ndash;44. <a href="https://doi.org/10.1007/BF01063556">doi:10.1007/BF01063556</a>
</p>
<p>Diletti D, Hauschke D, Steinijans VW. <em>Sample Size Determination for Bioequivalence Assessment by Means of 
Confidence Intervals.</em> Int J Clin Pharmacol Ther Toxicol. 1991;29(1):1&ndash;8. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.TOST">sampleN.TOST</a>, <a href="#topic+known.designs">known.designs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># power for the 2x2 cross-over design with 24 subjects and CV 25%
# using all the other default values
power.TOST(CV = 0.25, n = 24)
# should give: [1] 0.7391155
# nct approximation very good for this configuration
power.TOST(CV = 0.25, n = 24, method = "nct")
# gives also: [1] 0.7391155
# shifted-central-t  approximation 
power.TOST(CV = 0.25, n = 24, method = "shifted")
# gives:      [1] 0.7328894

# power for the 2x2 cross-over study with 24 subjects, CV 25%
# and 2 drop-outs in the same sequence group (unbalanced study)
power.TOST(CV=0.25, n=c(10,12))
# should give: [1] 0.6912935
# not the same compared to the balanced setting
power.TOST(CV=0.25, n=22)
# should give: [1] 0.6953401
</code></pre>

<hr>
<h2 id='power.TOST.sds'>
Power calculation of the BE decision with models incorporating groups
</h2><span id='topic+power.TOST.sds'></span>

<h3>Description</h3>

<p>The power is obtained via subject data simulations.<br />
Three models are implemented:
</p>

<ul>
<li><p> gmodel==1 is full FDA model for testing group-by-treatment interaction
followed by gmodel==2 or gmodel==3 with data of the biggest group
depending on the test of the treatment by group interaction
</p>
</li>
<li><p> gmodel==2 is full FDA model but without group-by-treatment interaction
</p>
</li>
<li><p> gmodel==3 is model with pooled groups, i.e. without any group term
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>power.TOST.sds(alpha = 0.05, theta1, theta2, theta0, CV, n, 
               design = c("2x2", "2x2x2", "2x3x3", "2x2x4", "2x2x3"),
               design_dta = NULL, grps = 2, ngrp = NULL, gmodel = 2, p.level=0.1,
               nsims = 1e+05, details = FALSE, setseed = TRUE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.TOST.sds_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability, significance level. Conventionally mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_theta1">theta1</code></td>
<td>

<p>Lower BE limit. Defaults to 0.8 if not given explicitely.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_theta2">theta2</code></td>
<td>

<p>Upper BE limit. Defaults to 1.25 if not given explicitely.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.95 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in 
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="power.TOST.sds_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
May be given as vector. In that case it is assumed that <code>n</code> contains the number
of subjects in the sequence groups.<br />
If <code>n</code> is given as single number (total sample size) and this number is not 
divisible by the number of sequences of the design an unbalanced design is 
assumed. A corresponding message is thrown showing the numbers of subjects 
in sequence groups.<br />
Attention! In case of the <code>"2x2x3"</code> (TRT|RTR) design the order of sample sizes is important 
if given as vector. <code>n[1]</code> is for sequence group 'TRT' and <code>n[2]</code> is for 
sequence group 'RTR'. 
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x2"</code> or <code>"2x2x2"</code> is the conventional cross-over design.<br />
<code>"2x3x3"</code> is the partial replicate design (TRR|RTR|RRT).<br />
<code>"2x2x4"</code> is the full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is the 3-period design with sequences TRT|RTR.<br />
Defaults to <code>design="2x2"</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_design_dta">design_dta</code></td>
<td>

<p>Alternatively to using the arguments <code>design</code> and <code>n</code> the design may 
be defined via a data.frame with columns <code>subject, sequence, period</code> and
<code>tmt</code>. This feature is experimental in the sense that the data.frame is
not checked for complying with the assumed structure.<br />
If you use the argument <code>design_dta</code> you don't need to specify the arguments
<code>design</code> and <code>n</code>.<br />
The default <code>design_dta = NULL</code> means that <code>design</code> and <code>n</code> are used
for the internal construction of the design data.frame.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_grps">grps</code></td>
<td>

<p>Number of (logistical) groups. Defaults to 2.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_ngrp">ngrp</code></td>
<td>

<p>Vector of number of subjects in groups.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_gmodel">gmodel</code></td>
<td>

<p>Number describing the model incorporating group effects
</p>

<ul>
<li> <p><code>gmodel=1</code> is full FDA model for testing group-by-treatment interaction
followed by <code>gmodel=2</code> or <code>gmodel=3</code> with data of the biggest group
depending on the test of the treatment by group interaction
</p>
</li>
<li> <p><code>gmodel=2</code> is full FDA model but without group-by-treatment interaction
</p>
</li>
<li> <p><code>gmodel=3</code> is model with pooled groups, i.e. without any group term
</p>
</li></ul>

<p>Defaults to <code>gmodel=2</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_p.level">p.level</code></td>
<td>
<p>Significance level of the test of a group-by-treatment interaction.
Defaults to <code>p.level=0.1</code>.
</p>
</td></tr> 
<tr><td><code id="power.TOST.sds_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+05.<br />
If simulations are aimed for empirical alpha <code>nsims=1e+06</code> is recommended.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> the computational time is shown.
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
<tr><td><code id="power.TOST.sds_+3A_progress">progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and nsims &gt;5E5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power is calculated via subject data sims.<br />
The evaluation of BE is done via 1-2*alpha confidence interval using classical ANOVA
for the models with group effects.<br />
The data.frame with columns  <code>subject, sequence, period</code> and <code>tmt</code> 
necessary for evaluation of simulated subject data is constructed internally from 
the arguments <code>design</code> and <code>n</code> or may be given user defined via the argument 
<code>design_dta</code>. The last option is usefull if missing data have to be considered
or if designs have to be evaluated which are not in the list of argument 
<code>design</code>.<br />
This feature is experimental in the sense that the data.frame is not checked 
for complying with the assumed structure.<br /><br />
The p.value of the test of the group-by-treatment interaction in case of <code>gmodel=1</code> <br />
defaults to <code>p.level = 0.1</code>, the value originally used by the FDA. Later on a value of 
<code>p.level = 0.05</code> was used.
</p>
<p>If the group-by-treatment interaction is significant the subsequent BE decision 
is done with the data of the largest group. If there are more than one with the same size, one gets a warning that this feature &ndash; showing BE in all that groups &ndash; is not implemented yet.
Only the first of the largest groups is tested for BE.
</p>


<h3>Value</h3>

<p>Returns the value of the (empirical) power
</p>


<h3>Note</h3>

<p>The run time of the function may be relatively long.<br />
Take a cup of coffee and be patient.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Schütz H. <br /> 
<em>Multi-Group Studies in Bioequivalence. To pool or not to pool?</em><br />
Presentation at BioBriges 2018, Prague. <a href="https://bebac.at/lectures/Prague2018.pdf">https://bebac.at/lectures/Prague2018.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># power for gmodel=2, 2x2 crossover, grps=3 with even number of subjects
power.TOST.sds(CV=0.2, n=18, grps=3)
# gives [1] 0.78404
# without considering groups
power.TOST.sds(CV=0.2, n=18, gmodel=3)
# gives [1] 0.7887
</code></pre>

<hr>
<h2 id='power.TOST.sim'>
Power of the TOST procedure obtained via simulations
</h2><span id='topic+power.TOST.sim'></span>

<h3>Description</h3>

<p>Power is calculated by simulations of studies (PE via its normal distribution, 
MSE via its associated <em>&chi;</em><sup>2</sup> distribution) and application of the two one-sided <em>t</em>-tests. Power is obtained via ratio of studies found BE to 
the number of simulated studies. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.TOST.sim(alpha = 0.05, logscale = TRUE, theta1, theta2, theta0, CV, n, 
               design = "2x2", robust = FALSE, setseed = TRUE, nsims = 1e+05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.TOST.sim_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to 0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code> or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_n">n</code></td>
<td>

<p>Number of subjects under study.<br />
Is total number if given as scalar, else number of subjects in the (sequence) 
groups. In the latter case the length of <code>n</code> vector has to be equal to the 
number of (sequence) groups.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed(1234567)</code> 
is issued if <code>setseed=TRUE</code>, the default.<br />
Set this argument to <code>FALSE</code> to view the variation in power between 
different runs.
</p>
</td></tr>
<tr><td><code id="power.TOST.sim_+3A_nsims">nsims</code></td>
<td>

<p>Number of studies to simulate. Defaults to 100,000 = 1E5.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of power according to the input arguments.
</p>


<h3>Note</h3>

<p>This function was intended for internal check of the analytical power
calculation methods. Use of the analytical power calculation methods 
(<code>power.TOST()</code>) for real problems is recommended.<br />
For sufficient precision nsims &gt; 1E5 (default) may be necessary. 
Be patient if using nsims=1E6. May take some seconds.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.TOST">power.TOST</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the default design 2x2, BE range 0.8 ... 1.25, logscale, theta0=0.95
power.TOST.sim(alpha = 0.05, CV = 0.3, n = 12)
# should give 0.15054, with nsims=1E6 it will be 0.148533
# exact analytical is
power.TOST(alpha = 0.05, CV = 0.3, n = 12)
# should give 0.1484695

# very unusual alpha setting
power.TOST.sim(alpha = 0.9, CV = 0.3, n = 12)
# should give the same (within certain precision) as
power.TOST(alpha = 0.95, CV = 0.3, n = 12)
# or also within certain precision equal to  
power.TOST(alpha = 0.95, CV = 0.3, n = 12, method = "mvt")
# SAS Proc Power gives here the incorrect value 0.60525
</code></pre>

<hr>
<h2 id='pvalue.TOST'>
p-value(s) of the TOST procedure
</h2><span id='topic+pvalue.TOST'></span><span id='topic+pvalues.TOST'></span>

<h3>Description</h3>

<p>Calculates the <em>p</em>-value(s) of the TOST procedure via students <em>t</em>-distribution
given pe, CV and n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvalue.TOST(pe, CV, n, logscale = TRUE, theta1, theta2, design = "2x2", 
            robust = FALSE, both = FALSE)
pvalues.TOST(pe, CV, n, logscale = TRUE, theta1, theta2, design = "2x2", 
             robust = FALSE, both = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvalue.TOST_+3A_pe">pe</code></td>
<td>

<p>Observed point estimate of the T/R ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the observed difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the observed (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to the observed (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>pe</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_n">n</code></td>
<td>

<p>Total number of subjects if given as scalar.<br />
Number of subjects in (sequence) groups if given as vector.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data be used after log-transformation or on original scale? <br />
<code>TRUE</code> or <code>FALSE</code>. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>pe</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code> or as <code>-theta1</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_robust">robust</code></td>
<td>

<p>If set to <code>TRUE</code> triggers the use of degrees of freedom according to the &lsquo;robust&rsquo; 
evaluation (aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code>. Has only effect for higher-order crossover designs.<br />
Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.
</p>
</td></tr>
<tr><td><code id="pvalue.TOST_+3A_both">both</code></td>
<td>

<p>Indicates if both <em>p</em>-values (<em>t</em>-tests of pe &gt;= theta1 and pe &lt;= theta2) shall be given 
back or only the maximum.<br />
Defaults to <code>FALSE</code> for the function <code>pvalue.TOST()</code> and to 
<code>TRUE</code> for the function <code>pvalue</code><b>s</b><code>.TOST()</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the <em>p</em>-value(s).<br />
Returns a vector with named elements <code>p.left</code>, <code>p.right</code> if arguments <code>pe</code> and <code>CV</code> 
are scalars, else a matrix with columns <code>p.left</code>, <code>p.right</code>. <br />
<code>p.left</code> gives the <em>p</em>-value of testing<br />
<code style="white-space: pre;">&#8288;  HA1: theta &gt;= theta1&#8288;</code><br />
and <code>p.right</code> the <em>p</em>-value of testing<br />
<code style="white-space: pre;">&#8288;  HA2: theta &lt;= theta2&#8288;</code><br />
against their respective Nulls.
</p>


<h3>Note</h3>

<p>The formulas implemented cover balanced and unbalanced designs.<br /><br />
In case of argument <code>n</code> given as n(total) and is not divisible by the number
of (sequence) groups the total sample size is partitioned to the (sequence) 
groups to have small imbalance only. A message is given in such cases.<br /><br />
SAS procedure TTEST with the TOST option names p.left = Upper, p.right= Lower
according to the tail of the <em>t</em>-distribution to be used for obtaining the 
<em>p</em>-values.
</p>


<h3>Author(s)</h3>

<p>B. Lang, man page by D. Labes
</p>


<h3>References</h3>

<p>Schuirmann DJ. <em>A comparison of the two one-sided tests procedure and the power approach for
assessing the equivalence of average bioavailability.</em> J Pharmacokin Biopharm. 1987;15:657&ndash;80. <a href="https://doi.org/10.1007/BF01068419">doi:10.1007/BF01068419</a>
</p>
<p>Hauschke D, Steinijans V, Pigeot I. <em>Bioequivalence Studies in Drug Development.</em> Chichester: Wiley; 2007.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CI.BE">CI.BE</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Defaults: 2x2 crossover, log-transformation
# BE acceptance limits 0.8 ... 1.25, usual dfs
# interested in both p-values
pvalues.TOST(pe = 0.95, CV = 0.3, n = 12)
# gives the vector (named elements)
#     p.left    p.right
# 0.09105601 0.02250985
# i.e. 'left' hypothesis H01: theta&lt;=theta1 can't be rejected
# 'right' hypothesis H02: theta&gt;=theta2 can be rejected

# max. p-value only as 'overall' pvalue, preferred by Benjamin
pvalue.TOST(pe = 0.912, CV = 0.333, n = 24)
# should give 0.08777621, i.e., inequivalence can't be rejected
# this is operationally identical to 
CI.BE(pe = 0.912, CV = .333, n = 24)
# lower limit = 0.7766 outside 0.8 ... 1.25, i.e., inequivalence can't be rejected
</code></pre>

<hr>
<h2 id='reg_const'>
Constructor of an object with class 'regSet' containing the regulatory settings for ABEL
</h2><span id='topic+reg_const'></span>

<h3>Description</h3>

<p>This function may be used to define regulatory settings not implemented yet
in PowerTOST.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg_const(regulator, r_const, CVswitch, CVcap, pe_constr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reg_const_+3A_regulator">regulator</code></td>
<td>

<p>Name of the regulatory body as a string. Implemented settings are for <code>"EMA"</code>,
<code>"FDA"</code>, <code>"HC"</code>, and <code>"GCC"</code>.<br />
The former (inofficial) settings for <code>"ANVISA"</code> are covered by the EMA settings.<br />
In case of <code>regulator="USER"</code> the other arguments must be given.
Otherwise, they may be missing.
</p>
</td></tr>
<tr><td><code id="reg_const_+3A_r_const">r_const</code></td>
<td>

<p>Regulatory constant.
</p>
</td></tr>
<tr><td><code id="reg_const_+3A_cvswitch">CVswitch</code></td>
<td>

<p>CV to switch to the widened acceptance limits.
</p>
</td></tr>
<tr><td><code id="reg_const_+3A_cvcap">CVcap</code></td>
<td>

<p>CV for capping the widening of the acceptance limits.
</p>
</td></tr>
<tr><td><code id="reg_const_+3A_pe_constr">pe_constr</code></td>
<td>

<p>Logical. Shall pe constraint be applied? Defaults to <code style="white-space: pre;">&#8288;TRUE&#8288;</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class 'regSet', a list with components
</p>
<table>
<tr><td><code>name</code></td>
<td>
<p>Name of the settings</p>
</td></tr>
<tr><td><code>CVswitch</code></td>
<td>
<p>see arguments</p>
</td></tr>
<tr><td><code>r_const</code></td>
<td>
<p>Regulatory constant</p>
</td></tr>
<tr><td><code>CVcap</code></td>
<td>
<p>see arguments</p>
</td></tr>
<tr><td><code>pe_constr</code></td>
<td>
<p>see arguments</p>
</td></tr>
<tr><td><code>est_method</code></td>
<td>
<p><code>"ANOVA"</code> or <code>"ISC"</code></p>
</td></tr>
</table>
<p>Class 'regSet' has a S3 print method.<br /><br />
The component <code style="white-space: pre;">&#8288;est_method&#8288;</code> is automatically set to <code>"ANOVA"</code>, except for
<code>regulator="FDA"</code> or <code>regulator="HC"</code> where <code>"ISC"</code> is used.
</p>


<h3>Note</h3>

<p>The former inofficial regulatory settings for <code>regulator="ANVISA"</code> are covered by <code>regulator="EMA"</code> (BEBA Forum).<br /><br />
The settings for CVcap of Health Canada (<code>regulator="HC"</code>) were chosen in such a way
that the limits of the acceptance range are capped nearly exact to 1/1.5
up to 1.5. Literally it is given rounded to 3 significant digits.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>BEBA Forum. May 2016. <a href="http://forum.bebac.at/mix_entry.php?id=16319">online</a>
</p>
<p>Health Canada, Therapeutic Products Directorate. <em>Comparative Bioavailability Standards: Formulations Used for Systemic Effects, 2.1.1.8 Highly variable drug products</em> Ottawa, 08 June 2018. <a href="https://www.canada.ca/en/health-canada/services/drugs-health-products/drug-products/applications-submissions/guidance-documents/bioavailability-bioequivalence/comparative-bioavailability-standards-formulations-used-systemic-effects.html#a2.1.1.8">online</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># to retrieve the EMA settings
reg_const("EMA")
# to define the old ANVISA settings
reg      &lt;- reg_const("USER", r_const = 0.76, CVswitch = 0.4, CVcap = 0.5)
reg$name &lt;- "Old ANVISA"
# Use reg as argument in the scaled ABEL power / sample size functions for
</code></pre>

<hr>
<h2 id='sampleN.2TOST'>
Sample size based on power of two TOSTs
</h2><span id='topic+sampleN.2TOST'></span>

<h3>Description</h3>

<p>Estimates the necessary sample size to have at least a given power when two
parameters are tested simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.2TOST(alpha = c(0.05, 0.05), targetpower = 0.8, logscale = TRUE, 
              theta0, theta1, theta2, CV, rho, design = "2x2", setseed = TRUE,
              robust = FALSE, print = TRUE, details = FALSE, imax = 100,
              nsims = 1e+05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.2TOST_+3A_alpha">alpha</code></td>
<td>

<p>Vector; contains one-sided significance level for each of the two TOSTs.<br />
For one TOST, by convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default) or <code style="white-space: pre;">&#8288;FALSE&#8288;</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_theta0">theta0</code></td>
<td>

<p>Vector; contains &lsquo;true&rsquo; assumed T/R ratio for each of the two TOSTs.<br />
In case of <code>logscale=TRUE</code> each element must be given as ratio,<br />
otherwise as difference to 1. See examples.<br />
Defaults to <code>c(0.95, 0.95)</code> if <code>logscale=TRUE</code> or to 
<code>c(0.05, 0.05)</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_theta1">theta1</code></td>
<td>

<p>Vector; contains lower bioequivalence limit for each of the two TOSTs.<br />
In case of <code>logscale=TRUE</code> it is given as ratio, otherwise as diff. to 1.<br />
Defaults to <code>c(0.8, 0.8)</code> if <code>logscale=TRUE</code> or to <code>c(-0.2, -0.2)</code>
if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_theta2">theta2</code></td>
<td>

<p>Vector; contains upper bioequivalence limit for each of the two TOSTs.<br />
If not given <code style="white-space: pre;">&#8288;theta2&#8288;</code> will be calculated as <code>1/theta1</code> if <code>logscale=TRUE</code><br />
or as <code style="white-space: pre;">&#8288;-theta1&#8288;</code> if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_cv">CV</code></td>
<td>

<p>Vector of coefficient of variations (given as as ratio, <em>e.g.</em>, 0.2 for 20%).<br />
In case of cross-over studies this is the within-subject CV, <br />
in case of a parallel-group design the CV of the total variability.<br />
In case of <code>logscale=FALSE</code> CV is assumed to be the respective standard 
deviation.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_rho">rho</code></td>
<td>

<p>Correlation between the two PK metrics (<em>e.g.</em>, AUC and Cmax) under consideration.
This is defined as correlation between the estimator of the treatment difference of
PK metric one and the estimator of the treatment difference of PK metric two. Has to be within {&ndash;1, +1}.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_setseed">setseed</code></td>
<td>

<p>Logical; if <code style="white-space: pre;">&#8288;TRUE&#8288;</code>, the default, a seed of 1234567 is set.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code style="white-space: pre;">&#8288;FALSE&#8288;</code>. With that value the usual degrees of freedom will be used.<br />
Set to <code style="white-space: pre;">&#8288;TRUE&#8288;</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These degrees of freedom are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results.<br /> 
If <code>FALSE</code> only the result list will be returned. 
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the design characteristics and the steps during
sample size calculations will be shown.<br /> 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. <br /> 
Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.2TOST_+3A_nsims">nsims</code></td>
<td>

<p>Number of studies to simulate. Defaults to 100,000 = 1E5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is estimated via iterative evaluation of power of the two TOSTs.<br />
Start value for the sample size search is taken from a large sample approximation
(one TOST) according to Zhang, modified.<br />
The sample size is bound to 4 as minimum.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>A list with the input and results will be returned.<br />
The element name <code>"Sample size"</code> contains the total sample size.
</p>


<h3>Warning</h3>

<p>The function does not vectorize properly.<br />
If you need sample sizes with varying CVs, use f.i. for-loops or the apply-family.
</p>


<h3>Note</h3>

<p>If both <code>theta0</code> are near the acceptance limits then the starting value may not
be a good approximation resulting in a lot of iteration steps; <code>imax</code> may need
to be increased to obtain the required sample size.<br /><br />
</p>


<h3>Author(s)</h3>

<p>B. Lang, D. Labes
</p>


<h3>References</h3>

<p>Phillips KF. <em>Power for Testing Multiple Instances of the Two One-Sided Tests Procedure.</em> Int J Biostat. 2009;5(1):Article 15.
</p>
<p>Hua SY, Xu S, D’Agostino RB Sr. <em>Multiplicity adjustments in testing for bioequivalence.</em> Stat Med. 2015;34(2):215&ndash;31. <a href="https://doi.org/10.1002/sim.6247">doi:10.1002/sim.6247</a>
</p>
<p>Lang B, Fleischer F. <em>Letter to the Editor: Comments on &lsquo;Multiplicity adjustments in testing for bioequivalence&rsquo;.</em> Stat Med. 2016;35(14):2479&ndash;80. <a href="https://doi.org/10.1002/sim.6488">doi:10.1002/sim.6488</a>
</p>
<p>Zhang P. <em>A Simple Formula for Sample Size Calculation in Equivalence Studies.</em> J Biopharm Stat. 2003;13(3):529&ndash;538. <a href="https://doi.org/10.1081/BIP-120022772">doi:10.1081/BIP-120022772</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.2TOST">power.2TOST</a>, <a href="#topic+known.designs">known.designs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Sample size for 2x2x2 cross-over design, intra-subject CV = 30% and assumed
# ratios of 0.95 for both parameters, and correlation 0.9 between parameters
# (using all the other default values)
# Should give n=44 with power=0.80879
sampleN.2TOST(theta0 = rep(0.95, 2), CV = rep(0.3, 2), rho = 0.9)

# Sample size for a parallel group design,
# evaluation on the original (untransformed) scale
# BE limits 80 ... 120% = -20% ... +20% of reference,
# assumed true BE ratio 0.95% = -5% to reference mean for both parameters,
# total CV=20% for both parameters, and correlation 0.9 between parameters
# should give n=52 with power=0.80094
sampleN.2TOST(logscale=FALSE, theta0 = rep(-0.05, 2), CV = c(0.2, 0.2), 
              rho = 0.9, design = "parallel")
</code></pre>

<hr>
<h2 id='sampleN.dp'>
Sample size estimation of dose-proportionality studies evaluated via the power model
</h2><span id='topic+sampleN.dp'></span>

<h3>Description</h3>

<p>Performes a sample size estimation for dose-proportionality studies using the 
power model for cossover (Latin square), parallel group designs or incomplete
block designs via a confidence interval equivalence criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.dp(alpha = 0.05, CV, doses, targetpower = 0.8, beta0, theta1 = 0.8, 
           theta2 = 1/theta1, design = c("crossover", "parallel", "IBD"), 
           dm=NULL, CVb, print = TRUE, details = FALSE, imax = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.dp_+3A_alpha">alpha</code></td>
<td>

<p>Type 1 error. Usually set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation. Is intra-subject CV for <code>design="crossover"</code> and
CV of total variability in case of <code>design="parallel"</code>
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_doses">doses</code></td>
<td>

<p>Vector of dose values under study. At least two doses have to be given.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_beta0">beta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed slope of the power model. If missing defaults to <code>1+log(0.95)/log(rd)</code>
where <code>rd</code> is the ratio is the ratio of the highest to the lowest dose.<br /> 
Has to be within slope acceptance range according to
<code>1+log(theta1)/log(rd)</code> and <code>1+log(theta2)/log(rd)</code>. Otherwise, the 
function issues an error.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_theta1">theta1</code></td>
<td>

<p>Lower acceptance limit for the ratio of dose normalized means (Rdmn).<br />
Transformes into slope acceptance range as described under item <code>beta0</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_theta2">theta2</code></td>
<td>

<p>Upper acceptance limit for the ratio of dose normalized means (Rdmn).
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_design">design</code></td>
<td>

<p>Crossover design (default), parallel group design or incomplete block design (IBD).<br />
Crossover design means Latin square design with number of doses as dimension.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_dm">dm</code></td>
<td>

<p>'Design matrix' of the incomplete block design (IBD) if <code>design="IBD"</code>.<br />
This matrix contains the sequences in rows and periods in columns. 
The entry (<em>i</em>, <em>j</em>) of the design matrix corresponds to the dose (index) a subject 
with <em>i</em>-th sequence gets in the <em>j</em>-th period.
Can be obtained f.i. via functions of package <code>crossdes</code>. See examples.<br />
Function <code><a href="#topic+bib.CL">bib.CL</a></code> returns some IBDs described by Chow &amp; Liu.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_cvb">CVb</code></td>
<td>

<p>Coefficient of variation of the between-subject variability.<br />
Only necessary if <code>design="IBD"</code>. Will be set to 2*CV if missing.
This is only a crude rule of thumb. Better obtain an estimate of CVb from a previous crossover study.<br /><br />
Set <code>CVb=0</code> if all-effects-fixed model shall be used. This model gives
lower sample sizes than the mixed model with random subject effects 
(random intercept).  
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results.<br /> 
If set to <code>FALSE</code> only the data.frame with the results will be returned. 
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_details">details</code></td>
<td>

<p>If <code>details=TRUE</code> the steps during sample size search will be shown. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.dp_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. <br /> 
Defaults to 100. Adaption only in rare cases needed, if any.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is estimated via iterative evaluation of <code>power.dp()</code>.<br />
Start value for the sample size search is taken from a large sample approximation.<br />
The sample size is bound to number of dose or sequence groups as minimum.<br />
Balanced designs are used although this is not absolutely necessary.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>A data.frame with the input and results will be returned.<br />
The <code>Sample size</code> column contains the total sample size.
</p>


<h3>Warning </h3>

<p>This function is &lsquo;experimental&rsquo; only, since it is not thorougly tested yet. 
Especially for <code>design="IBD"</code> reliable test cases are missing.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Chow SC, Liu JP. <em>Design and Analysis of Bioavailability and Bioequivalence Studies.</em> Boca Raton: CRC Press; 3<sup>rd</sup> edition 2009.
</p>
<p>Patterson S, Jones B. <em>Bioequivalence and Statistics in Clinical Pharmacology.</em> Boca Raton: Chapman &amp; Hall/CRC: 2006. p. 239.<br />
(contains presumably a bug)
</p>
<p>Sethuraman VS, Leonov S, Squassante L, Mitchell TR, Hale MD. <em>Sample size calculation for the Power Model for dose proportionality studies.</em> Pharm Stat. 2007;6(1):35&ndash;41. <a href="https://doi.org/10.1002/pst.241">doi:10.1002/pst.241</a>
</p>
<p>Hummel J, McKendrick S, Brindley C, French R. <em>Exploratory assessment of dose proportionality: review of current approaches and proposal for a practical criterion.</em> Pharm. Stat. 2009;8(1):38&ndash;49. <a href="https://doi.org/10.1002/pst.326">doi:10.1002/pst.326</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.dp">power.dp</a></code>, <code><a href="#topic+bib.CL">bib.CL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults, i.e. crossover design, alpha=0.05
# theta1=0.8, theta2=1.25 but true slope slightly off 1
sampleN.dp(CV = 0.2, doses = c(1, 2, 8), beta0 = 1.02)
# should give n=18, power=0.854528


# incomplete block design with 5 doses, 3 periods
# from library(crossdes)
doses  &lt;- c(5, 25, 50, 100, 200)
CVb    &lt;- mse2CV(0.8)
levels &lt;- length(doses)
per    &lt;- 3
block  &lt;- levels*(levels-1)/(per-1)
# IBD based on balanced minimal repeated measurements design
# gives n=30 and 10 sequences
ibd    &lt;- crossdes::balmin.RMD(levels, block, per)
sampleN.dp(CV = 0.2, doses = doses, beta0 = 1, design = "IBD", dm = ibd, 
           CVb = CVb, targetpower=0.9)
</code></pre>

<hr>
<h2 id='sampleN.HVNTID'>
Sample size estimation for BE decision via FDA method for highly variable (HV)
narrow therapeutic index drugs (NTIDs)
</h2><span id='topic+sampleN.HVNTID'></span>

<h3>Description</h3>

<p>This function performs the sample size estimation for the BE decision via
the FDA’s method for highly variable NTIDs as described in respective guidances based on simulations.<br />
The study designs may be the full replicate design 2x2x4 with 4 periods (TRTR|RTRT) and
the 3-period replicate design 2x2x3 with sequences RTR|TRT.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.HVNTID(alpha = 0.05, targetpower = 0.8, theta0, theta1, theta2, CV,
               design = c("2x2x4", "2x2x3"), nsims = 1e+05, nstart, imax = 100,
               print = TRUE, details = TRUE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.HVNTID_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio.<br />
Defaults to 0.95 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the FDA procedure.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the FDA procedure.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x2x4"</code> is the full replicate with 2 sequences and 4 periods (TRTR|RTRT).<br />
<code>"2x2x3"</code> is the full replicate with 2 sequences and 3 periods (TRT|RTR).<br />
Defaults to <code>design="2x2x4"</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+5.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start value for the sample size if a previous run failed.<br />
May be missing.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_print">print</code></td>
<td>

<p>If <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default) the function prints its results. If <code style="white-space: pre;">&#8288;FALSE&#8288;</code> only the resulting dataframe will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code>, the default, the steps during sample size search are shown.
Moreover the details of the method settings are printed.
</p>
</td></tr>
<tr><td><code id="sampleN.HVNTID_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number
generator. To avoid differences in power values for different runs a
<code>set.seed(123456)</code> is issued if <code>setseed=TRUE</code>, the default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For deciding BE the study must pass the conventional ABE test and additionally
the test that the ratio of sWT/sWR is &lt;= 2.5.<br /><br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on these method.<br />
Details can be found in a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_sims&#8288;</code> located in
the <code>/doc</code> sub-directory of the package.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for re-starting.
</p>


<h3>Warning </h3>

<p>For some input constellations the sample size search may be very time
consuming and will eventually also fail since the start values chosen may
not really reasonable for them.<br />
In case of a failed sample size search you may restart with setting the argument
<code style="white-space: pre;">&#8288;nstart&#8288;</code>.<br />
</p>


<h3>Note</h3>

<p>The design recommended by the FDA is the full replicate design <code>"2x2x4"</code>.<br />
The sample size estimation is done only for balanced studies since the
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only valid for balanced designs.<br />
The FDA method is described for the ABE limits 0.8 ... 1.25 only. Setting theta1, theta2
to other values may not be reasonable and is not tested.<br />
The minimum sample size is 6, even if the power is higher than the intended  targetpower.<br /><br />
The method is also required by China’s Center of Drug Evaluation.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Dabigatran Etexilate Mesylate.</em> Recommended Jun 2012; Revised Sep 2015, Jul 2017. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Dabigatran%20etexilate%20mesylate_oral%20capsule_NDA%20022512_RV05-17.pdf">download</a>
</p>
<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Rivaroxaban.</em> Recommended Sep 2015. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Rivaroxaban_oral%20tablet_22406_RC09-15.pdf">download</a>
</p>
<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Edoxaban Tosylate.</em> Recommended May 2017; Revised Mar 2020. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/PSG_206316.pdf">download</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.HVNTID">power.HVNTID</a></code><br />
and <code><a href="#topic+power.NTIDFDA">power.NTIDFDA</a></code>, <code><a href="#topic+sampleN.NTIDFDA">sampleN.NTIDFDA</a></code> for NTIDs with
low variability
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all defaults but CV
sampleN.HVNTID(CV = 0.3)
# should give
# n=22 with an (empirical) power of 0.829700

# Test formulation with lower variability but same pooled CV
CVs &lt;- CVp2CV(0.3, ratio = 0.25)
sampleN.HVNTID(CV = CVs)
# should give (no distinct difference to example above)
# n=22 with an (empirical) power of 0.837520
</code></pre>

<hr>
<h2 id='sampleN.noninf'>
Sample size for the non-inferiority t-test
</h2><span id='topic+sampleN.noninf'></span>

<h3>Description</h3>

<p>Function for estimating the sample size needed to have a pre-specified power
for the one-sided non-inferiority <em>t</em>-test for normal or log-normal distributed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.noninf(alpha = 0.025, targetpower = 0.8, logscale = TRUE,
               margin,theta0, CV, design = "2x2", robust = FALSE, 
               details = FALSE, print = TRUE, imax=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.noninf_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Defaults here to 0.025.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed or on original scale? <code>TRUE</code> (default) or <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio or difference.<br />
In case of <code>logscale=TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale=FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, i.e. as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>margin</code> and <code>CV</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale=TRUE</code> or to -0.05 if <code>logscale=FALSE</code>
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_margin">margin</code></td>
<td>

<p>Non-inferiority margin.<br />
In case of <code>logscale=TRUE</code> it is given as ratio.<br />
If <code>logscale=FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code> and <code>theta0</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale=TRUE</code> or to -0.2 if <code>logscale=FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), i.e. again as a coefficient of variation; or untransformed, i.e. as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code><a href="#topic+known.designs">known.designs</a></code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_robust">robust</code></td>
<td>

<p>Defaults to FALSE. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These df are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the design characteristics and the steps during
sample size calculations will be shown.<br /> 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results.<br /> 
If <code>FALSE</code> only the data.frame with the results will be returned. 
</p>
</td></tr>
<tr><td><code id="sampleN.noninf_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. <br /> 
Defaults to 100. Adaption only in rare cases needed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is calculated via iterative evaluation of <code>power.noninf()</code>.<br />
Start value for the sample size search is taken from a large sample approximation.<br />
The sample size is bound to 4 as minimum.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).<br />
</p>
<p><strong>Notes on the underlying hypotheses</strong><br />
If the supplied margin is &lt; 0 (<code>logscale=FALSE</code>) or &lt; 1 (<code>logscale=TRUE</code>), 
then it is assumed higher response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &lt;= margin vs. H1: theta0 &gt; margin&#8288;</code>,<br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &lt;= log(margin) vs. H1: log(theta0) &gt; log(margin)&#8288;</code>,<br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
</p>
<p>If the supplied margin is &gt; 0 (<code>logscale=FALSE</code>) or &gt; 1 (<code>logscale=TRUE</code>), 
then it is assumed lower response values are better. The hypotheses are<br />
<code style="white-space: pre;">&#8288;  H0: theta0 &gt;= margin vs. H1: theta0 &lt; margin&#8288;</code><br />
where <code>theta0 = mean(test)-mean(reference)</code> if <code>logscale=FALSE</code><br />
or<br />
<code style="white-space: pre;">&#8288;  H0: log(theta0) &gt;= log(margin) vs. H1: log(theta0) &lt; log(margin)&#8288;</code><br />
where <code>theta0 = mean(test)/mean(reference)</code> if <code>logscale=TRUE</code>.<br />
This latter case may also be considered as &lsquo;non-superiority&rsquo;.
</p>


<h3>Value</h3>

<p>A data.frame with the input settings and results will be returned.<br />
Explore it with <code>str(sampleN.noninf(...)</code>
</p>


<h3>Warning </h3>

<p>The function does not vectorize properly.<br />
If you need sample sizes with varying CVs, use f.i. for-loops or the apply-family.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Julious SA. <em>Sample sizes for clinical trials with Normal data.</em> Stat Med. 2004;23(12):1921&ndash;86. <a href="https://doi.org/10.1002/sim.1783">doi:10.1002/sim.1783</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+known.designs">known.designs</a></code>, <code><a href="#topic+power.noninf">power.noninf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults: margin=0.8, theta0=0.95, alpha=0.025
# log-transformed, design="2x2"
sampleN.noninf(CV = 0.3)
# should give n=48
#
# 'non-superiority' case, log-transformed data
# with assumed 'true' ratio somewhat above 1
sampleN.noninf(CV = 0.3, targetpower = 0.9,
               margin = 1.25, theta0 = 1.05)
# should give n=62
</code></pre>

<hr>
<h2 id='sampleN.NTID'>
Sample size estimation for BE decision via the FDA's method for narrow therapeutic index drugs (NTIDs)
</h2><span id='topic+sampleN.NTID'></span><span id='topic+sampleN.NTIDFDA'></span>

<h3>Description</h3>

<p>This function performs the sample size estimation for the BE decision for
the FDA’s method for NTIDs based on simulations. The study design is the full
replicate design 2x2x4 (TRTR|RTRT) or the 3-period replicate design with sequences TRT|RTR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.NTID(alpha = 0.05, targetpower = 0.8, theta0, theta1, theta2, CV,
             design = c("2x2x4", "2x2x3"), nsims = 1e+05, nstart, imax = 100,
             print = TRUE, details = TRUE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.NTID_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio.<br />
Attention! Defaults here to 0.975 if not given explicitly. The value was chosen
closer to 1 because the potency (contents) settings for NTIDs are tightened
by the FDA.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the FDA procedure.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the FDA procedure.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT == CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.NTID_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x2x4"</code> is the full replicate with 2 sequences and 4 periods (TRTR|RTRT).<br />
<code>"2x2x3"</code> is the full replicate with 2 sequences and 3 periods (TRT|RTR).<br />
Defaults to <code>design = "2x2x4"</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the empirical power.
Defaults to 100,000 = 1e+5.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start value for the sample size if a previous run failed.<br />
May be missing.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results. If <code>FALSE</code> only the resulting dataframe will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code>, the default, the steps during sample size search are shown.
Moreover the details of the method settings are printed.
</p>
</td></tr>
<tr><td><code id="sampleN.NTID_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number
generator. To avoid differences in power values for different runs a
<code>set.seed(123456)</code> is issued if <code>setseed = TRUE</code>, the default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linearized scaled ABE criterion is calculated according to the SAS code
given in the FDA’s guidances. For deciding BE the study must pass that criterion,
the conventional ABE test, and that the upper confidence limit of
<em>&sigma;</em><sub>wT</sub>/<em>&sigma;</em><sub>wR</sub>&nbsp;&leq;&nbsp;2.5.<br /><br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on this method.<br />
Details can be found in a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_sims&#8288;</code> located in
the <code>/doc</code> sub-directory of the package.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject / sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data frame with the input settings and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for re-starting.
</p>


<h3>Warning</h3>

<p>For some input combinations the sample size search may be very time
consuming and will eventually even fail since the start values chosen may
not really reasonable for them. This applies especially for <code>theta0</code> values
close to the implied scaled limits according to
exp(&mnplus;1.053605&nbsp;&times;&nbsp;<em>s</em><sub>wR</sub>).<br />
In case of a failed sample size search you may restart with setting the argument
<code style="white-space: pre;">&#8288;nstart&#8288;</code>.<br />
In case of <code>theta0</code> values outside the implied scaled (tightened/widened) ABE limits
no sample size estimation is possible and the function throws an error
(f.i. <code>CV = 0.04, theta0 = 0.95</code>).
</p>


<h3>Note</h3>

<p>The design recommended by the FDA is the full replicate design <code>"2x2x4"</code>.<br />
The sample size estimation is done only for balanced studies since the
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only valid for balanced designs.<br />
The FDA method is described for the ABE limits 0.8 ... 1.25 only. Setting <code>theta1</code>,
<code>theta2</code> to other values may not be reasonable and is not tested.<br />
The results for the design <code>"2x2x3"</code> are to be considered as experimental since
at present not thorougly tested.<br />
The minimum sample size is 6, even if the power is higher than the intended
targetpower.<br /><br />
The method is also required by China’s Center of Drug Evaluation.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Warfarin Sodium.</em> Recommended Dec 2012. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Warfarin_Sodium_tab_09218_RC12-12.pdf">download</a>
</p>
<p>Food and Drug Administration, Center for Drug Evaluation and Research (CDER). <em>Draft Guidance for Industry. Bioequivalence Studies with Pharmacokinetic Endpoints for Drugs Submitted Under an ANDA.</em> August 2021. <a href="https://www.fda.gov/media/87219/download">download</a>
</p>
<p>Yu LX, Jiang W, Zhang X, Lionberger R, Makhlouf F, Schuirmann DJ, Muldowney L, Chen ML, Davit B, Conner D, Woodcock J. <em>Novel bioequivalence approach for narrow therapeutic index drugs.</em> Clin Pharmacol Ther. 2015;97(3):286&ndash;91. <a href="https://doi.org/10.1002/cpt.28">doi:10.1002/cpt.28</a>
</p>
<p>Jiang W, Makhlouf F, Schuirmann DJ, Zhang X, Zheng N, Conner D, Yu LX, Lionberger R. <em>A Bioequivalence Approach for Generic Narrow Therapeutic Index Drugs: Evaluation of the Reference-Scaled Approach and Variability Comparison Criterion.</em> AAPS J. 2015;17(4):891&ndash;901. <a href="https://doi.org/10.1208/s12248-015-9753-5">doi:10.1208/s12248-015-9753-5</a>
</p>
<p>Endrényi L, Tóthfalusi L. <em>Determination of Bioequivalence for Drugs with Narrow Therapeutic Index: Reduction of the Regulatory Burden.</em> J Pharm Pharm Sci. 2013;16(5):676&ndash;82. <a href="https://journals.library.ualberta.ca/jpps/index.php/JPPS/article/download/20900/15927/0">open access</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.NTID">power.NTID</a></code>
and <code><a href="#topic+power.HVNTID">power.HVNTID</a></code>, <code><a href="#topic+sampleN.HVNTID">sampleN.HVNTID</a></code> for NTIDs with
high variability
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sampleN.NTID(CV = 0.04,theta0 = 0.975)
# should give
# n=54 with an (empirical) power of 0.809590
#
# Test formulation with lower variability
sampleN.NTID(CV = c(0.04,0.06),theta0 = 0.975)
# should give
# n=20 with an (empirical) power of 0.0.814610
#
# alternative 3-period design
sampleN.NTID(CV = 0.04,theta0 = 0.975, design="2x2x3")
# should give
# n=86 with power = 0.80364
</code></pre>

<hr>
<h2 id='sampleN.RatioF'>
Sample size for equivalence of the ratio of two means with normality on original scale
</h2><span id='topic+sampleN.RatioF'></span>

<h3>Description</h3>

<p>Estimates the necessary sample size to have at least a given power based on 
Fieller’s confidence (&lsquo;fiducial&rsquo;) interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.RatioF(alpha = 0.025, targetpower = 0.8, theta1 = 0.8, theta2, 
               theta0 = 0.95, CV, CVb, design = "2x2", print = TRUE,
               details = FALSE, imax=100, setseed=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.RatioF_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. <br />
Defaults here to 0.025 because this function is intended for studies
with clinical endpoints. 
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1. Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_theta1">theta1</code></td>
<td>

<p>Lower bioequivalence limit. Typically 0.8 (default).
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_theta2">theta2</code></td>
<td>

<p>Upper bioequivalence limit. Typically 1.25.<br />
Is set to <code>1/theta1</code> if missing.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Typically set to 0.95.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation as ratio. In case of <code>design="parallel"</code> this is
the CV of the total variability, in case of <code>design="2x2"</code> the intra-subject
CV (CVw in the reference).
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_cvb">CVb</code></td>
<td>

<p>CV of the between-subject variability. Only necessary for <code>design="2x2"</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_design">design</code></td>
<td>

<p>A character string describing the study design.<br />
<code>design="parallel"</code> or <code>design="2x2"</code> allowed for a two-parallel 
group design or a classical TR|RT crossover design.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results. If <code>FALSE</code> only
a data.frame with the results will be returned. 
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the steps during sample size calculations will be shown.<br /> 
Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search.<br /> 
Defaults to 100. Adaption only in rare cases needed.
</p>
</td></tr>
<tr><td><code id="sampleN.RatioF_+3A_setseed">setseed</code></td>
<td>

<p>If set to <code>TRUE</code> the dependence of the power from the state of the random number
generator is avoided.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is based on exact power calculated using the bivariate 
non-central <em>t</em>-distribution via function <code><a href="mvtnorm.html#topic+pmvt">pmvt</a></code> of the package <code>mvtnorm</code>.<br />
Due to the calculation method used in package mvtnorm these
probabilities are dependent from the state of the random number generator
within the precision of the power.<br /><br />
The CV(within) and CVb(etween) in case of <code>design="2x2"</code> are obtained 
via an appropriate ANOVA from the error term and from the difference 
<code>(MS(subject within sequence)-MS(error))/2</code>.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>A data.frame with the input values and results will be returned.<br />
The sample size n returned is the total sample size for both designs.<br />
</p>


<h3>Note</h3>

<p>This function is intended for studies with clinical endpoints.<br /> In such studies
the 95% confidence intervals are usually used for equivalence testing.<br />
Therefore, alpha defaults here to 0.025 (see EMEA 2000).
</p>


<h3>Author(s)</h3>

<p>D. Labes</p>


<h3>References</h3>

<p>Fieller EC. <em>Some Problems in Interval Estimation.</em> J Royal Stat Soc B. 1954;16(2):175&ndash;85. <a href="https://doi.org/10.1111/j.2517-6161.1954.tb00159.x">doi:10.1111/j.2517-6161.1954.tb00159.x</a>
</p>
<p>Sasabuchi S. <em>A test of a multivariate normal mean with composite hypotheses determined by linear inequalities.</em> Biometrika. 1980;67(2):429&ndash;39. <a href="https://doi.org/10.1093/biomet/67.2.429">doi:10.1093/biomet/67.2.429</a>
</p>
<p>Hauschke D, Kieser M, Diletti E, Burke M. <em>Sample size determination for proving equivalence based on the ratio of two means for normally distributed data.</em> Stat Med. 1999;18(1):93&ndash;105.
</p>
<p>Hauschke D, Steinijans V, Pigeot I. <em>Bioequivalence Studies in Drug Development.</em> Chichester: Wiley; 2007. Chapter 10.
</p>
<p>European Agency for the Evaluation of Medicinal Products, CPMP. <em>Points to Consider on Switching between Superiority and Non-Inferiority.</em> London, 27 July 2000. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/points-consider-switching-between-superiority-and-non-inferiority_en.pdf">CPMP/EWP/482/99</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.RatioF">power.RatioF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sample size for a 2x2 cross-over study
# with CVw=0.2, CVb=0.4
# alpha=0.025 (95% CIs), target power = 80%
# 'true' ratio = 95%, BE acceptance limits 80-125%
# using all the defaults:
sampleN.RatioF(CV = 0.2, CVb = 0.4)
# gives n=28 with an achieved power of 0.807774
# see Hauschke et.al. (2007) Table 10.3a

# sample size for a 2-group parallel study
# with CV=0.4 (total variability) 
# alpha=0.025 (95% CIs), target power = 90%
# 'true' ratio = 90%, BE acceptance limits 75-133.33%
sampleN.RatioF(targetpower = 0.9, theta1 = 0.75,
               theta0 = 0.90, CV = 0.4, design = "parallel")
# gives n=236 with an achieved power of 0.900685
# see Hauschke et.al. (2007) Table 10.2

# a rather strange setting of ratio0! have a look at n.
# it would be better this is not the sample size but your account balance ;-).
sampleN.RatioF(theta0 = 0.801, CV = 0.2, CVb = 0.4)

</code></pre>

<hr>
<h2 id='sampleN.RSABE'>
Sample size estimation for BE decision via linearized scaled ABE criterion
</h2><span id='topic+sampleN.RSABE'></span>

<h3>Description</h3>

<p>This function performs the sample size estimation for the BE decision via 
linearized scaled ABE criterion based on simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.RSABE(alpha = 0.05, targetpower = 0.8, theta0, theta1, theta2, CV,
              design = c("2x3x3", "2x2x4", "2x2x3"), regulator = c("FDA", "EMA"),
              nsims = 1e+05, nstart, imax=100, print = TRUE,
              details = TRUE, setseed=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.RSABE_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>.<br />
Also Lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in 
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>design="2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory body settings for the scaled ABE criterion.<br />
Defaults to <code>design="FDA"</code>.<br />
Also the scaled ABE criterion is usually calculated with the FDA constant<br />
<code>r_const=log(1.25)/0.25</code> you can override this behavior to use the EMA setting
<code>r_const=0.76</code> to avoid the discontinuity at CV=30% and be more stringent.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the (empirical) power.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start for the sample size search if a previous run failed.<br />
After reworking the start n in version 1.1-05 rarely needed.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results. If <code>FALSE</code> only the result data.frame will be returned. 
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code>, the default, the steps during sample size search are shown.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linearized scaled ABE criterion is calculated according to the SAS code
given in the FDA progesterone guidance.<br /><br />
The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on scaled ABE.<br />
For more details see a document <code style="white-space: pre;">&#8288;Implementation_scaledABE_simsVx.yy.pdf&#8288;</code> in the <code>/doc</code> sub-directory of 
the package.<br /><br />
If a CVcap is defined for the regulator, the BE decision is based on the inclusion
of the CI in the capped widened acceptance limits in case of CVwR &gt; CVcap. This
resembles method &lsquo;Howe-EMA&rsquo; in Muñoz <em>et al.</em> and is the standard behavior now if
<code>regulator="EMA"</code> is choosen.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for restarting.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>The sample size estimation for theta0 &gt;1.2 and &lt;0.85 may be very time consuming 
and will eventually also fail since the start values chosen are not really 
reasonable in that ranges. This is especially true in the range about CV = 0.3 
and regulatory constant according to FDA.<br />
If you really need sample sizes in that range be prepared to restart the sample 
size estimation via the argument nstart.<br />
Since the dependence of power from n is very flat in the mentioned region you 
may also consider to adapt the number of simulations not to tap in the simulation 
error trap.
</p>


<h3>Note</h3>

<p>The sample size estimation is done only for balanced designs since the 
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only for balanced designs.<br />
The minimum sample size is n=6, even if the power is higher than the intended 
targetpower.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Food and Drug Administration, Office of Generic Drugs (OGD). <em>Draft Guidance on Progesterone.</em> Recommended Apr 2010. Revised Feb 2011. <a href="https://www.accessdata.fda.gov/drugsatfda_docs/psg/Progesterone_caps_19781_RC02-11.pdf">download</a>
</p>
<p>Tóthfalusi, L, Endrényi, L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. 
<a href="https://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>
<p>Tóthfalusi L, Endrényi L, García Arieta A. <em>Evaluation of Bioequivalence for Highly Variable Drugs with Scaled Average Bioequivalence.</em> Clin Pharmacokin. 2009;48(11):725&ndash;43. <a href="https://doi.org/10.2165/11318040-000000000-00000">doi:10.2165/11318040-000000000-00000</a>
</p>
<p>Muñoz J, Alcaide D, Ocaña J. <em>Consumer’s risk in the EMA and FDA regulatory approaches for bioequivalence in highly variable drugs.</em> Stat Med. 2015;35(12):1933&ndash;43. <a href="https://doi.org/10.1002/sim.6834">doi:10.1002/sim.6834</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.RSABE">power.RSABE</a></code>, <code><a href="#topic+power.scABEL">power.scABEL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults:
# design=2x3x3 (partial replicate design), theta0=0.90, 
# ABE limits, PE constraint 0.8 - 1.25
# targetpower=80%, alpha=0.05, 1E5 simulations
sampleN.RSABE(CV = 0.3)
# should result in a sample size n=45, power=0.80344
</code></pre>

<hr>
<h2 id='sampleN.RSABE2L.sdsims'>
Sample size estimation for BE Decision via Reference Scaled ABE
</h2><span id='topic+sampleN.RSABE2L.sdsims'></span><span id='topic+sampleN.RSABE2L.sds'></span>

<h3>Description</h3>

<p>These functions performs the sample size estimation of the BE decision via 
the reference scaled ABE based on <b>subject data</b> simulations.
Implemented are the methods ABEL, Hyslop and &lsquo;exact&rsquo; (see the References in 
<code><a href="#topic+power.RSABE2L.sdsims">power.RSABE2L.sdsims</a></code>).<br />
The estimation method of the key statistics needed to perform the <abbr><span class="acronym">RSABE</span></abbr> decision 
is the usual <abbr><span class="acronym">ANOVA</span></abbr>.<br />
This function has an alias sampleN.RSABE2L.sds().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.RSABE2L.sdsims(alpha = 0.05, targetpower = 0.8, theta0,
                       theta1, theta2, CV,
                       design = c("2x3x3", "2x2x4", "2x2x3"),
                       SABE_test = "exact", regulator, nsims=1e5,
                       nstart, imax = 100, print = TRUE,
                       details = TRUE, setseed = TRUE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>.<br />
Also Lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if 
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV)==1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV)==2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>design="2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_sabe_test">SABE_test</code></td>
<td>

<p>This argument specifies the test method to be used for the reference scaled
<abbr><span class="acronym">ABE</span></abbr> decision.<br />
Default is the <code>"exact"</code> &lsquo;ncTOST&rsquo; method of the two Laszlós. 
Other choices are <code>"ABEL"</code>, <code>"Hyslop"</code> and <code>"FDA"</code>. See Details.<br />
This argument may be given also in lower case.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as character <code>"EMA"</code> or as an object of
class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br />
If given as object of class 'regSet' the component <code>est_method</code> can not be <code>"ISC"</code>. 
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the (empirical) power.
The default value 100,000 = 1e+5 is usually sufficient. Consider to rise 
this value if theta0&lt;=0.85 or &gt;=1.25. But see the warning section.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start for the sample size search if a previous run failed.<br />
After reworking the start n in version 1.1-05 rarely needed.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_print">print</code></td>
<td>

<p>If <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default) the function prints its results. If <code style="white-space: pre;">&#8288;FALSE&#8288;</code> only the result data.frame will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> (default), the steps during sample size search are shown.
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number 
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code> 
is issued if <code>setseed=TRUE</code>, the default. 
</p>
</td></tr>
<tr><td><code id="sampleN.RSABE2L.sdsims_+3A_progress">progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and nsims &gt;5E5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assume a 
log-normal distribution on the original scale.<br /><br />
The widened BE acceptance limits will be calculated by the formula<br />
<code style="white-space: pre;">&#8288;  [L, U] = exp(± r_const * sWR)&#8288;</code><br />
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference. <code>r_const = 0.76</code> (~log(1.25)/0.29356) is used 
in case of <code>regulator="EMA"</code>.
If the CVwR of the Reference is &lt; CVswitch=0.3 the conventional ABE limits 
apply (mixed procedure).<br /> 
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if 
CVwr&gt;0.5, <em>i.e.</em>, the widened limits are held at value calculated for CVwR=0.5.<br /><br />
The simulations are done by simulating subject data (all effects fixed except the
residuals) and evaluating these data via ANOVA of all data to get the point estimate
of T vs. R along with its 90% CI and an ANOVA of the data under R(eference) only
to get an estimate of s2wR.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input settings and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for restarting.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>The sample size estimation for very extreme theta0 (&lt;0.83 or &gt;1.21) may be very 
time consuming and will eventually also fail since the start values chosen are 
not really reasonable in that ranges.<br />
If you really need sample sizes in that range be prepared to restart the sample 
size estimation via the argument nstart.<br />
Since the dependence of power from n is very flat in the mentioned region you may 
also consider to adapt the number of simulations not to tap in the simulation 
error trap.
</p>


<h3>Note</h3>

<p>We are doing the sample size estimation only for balanced designs since the 
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only for balanced designs.<br />
The minimum sample size is 6, even if the power is higher than the intended 
targetpower.<br /><br />
Subject simulations are relatively slow. Thus be patient and go for a cup of coffee if you use this function with high sample sizes!
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.RSABE2L.sdsims">power.RSABE2L.sdsims</a></code>, <code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a></code>, <code><a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the defaults:
# partial replicate design, targetpower=80%,
# true assumed ratio = 0.90, 1E+5 simulated studies
# ABE limits, PE constraint 0.8 - 1.25
# EMA regulatory settings
# compare results

CV     &lt;- 0.4
method &lt;- c("exact", "abel", "hyslop", "fda")
res    &lt;- data.frame(SABE_test = c("ncTOST", "ABEL",
                                   "Hyslop", "FDA"),
                     n = NA, power = NA)
for (i in 1:nrow(res)) {
  res[i, 2:3] &lt;- sampleN.RSABE2L.sdsims(CV = CV,
                                        SABE_test = method[i],
                                        details = FALSE,
                                        print = FALSE)[8:9]
}
print(res, digits = 4, row.names = FALSE)
# should result in a sample size n=48 with all methods,
# power=0.8197 (ncTOST), 0.8411 (ABEL), 0.8089 (Hyslop), 0.8113 (FDA)
</code></pre>

<hr>
<h2 id='sampleN.scABEL'>
Sample size estimation for BE decision via scaled (expanded) BE acceptance limits
</h2><span id='topic+sampleN.scABEL'></span>

<h3>Description</h3>

<p>This function performs the sample size estimation via power calculations of the
BE decision via scaled (expanded) BE acceptance limits, based on simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.scABEL(alpha = 0.05, targetpower = 0.8, theta0, theta1, theta2,
               CV, design = c("2x3x3", "2x2x4", "2x2x3"), regulator,
               nsims = 1e+05, nstart, imax = 100, print = TRUE,
               details = TRUE, setseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.scABEL_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>.<br />
Also Lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> CV of Test and Reference is assumed (homoscedasticity, <em>CV</em><sub>wT</sub>&nbsp;=&nbsp;<em>CV</em><sub>wR</sub>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming heteroscedasticity, the <em>CV</em> of the Test <strong>must</strong> be given in
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>design="2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as character from the choices <code>"EMA"</code>, <code>"HC"</code>, <code>"GCC"</code>,
<code>"FDA"</code> or as an object of class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br /><br />
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the (empirical) power.
The default value 100,000 = 1e+5 is usually sufficient. Consider to rise
this value if <code>theta0</code> &lt;=0.85 or &gt;=1.20. But see the warning section.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start for the sample size search if a previous run failed.<br />
After reworking the start n in version 1.1-05 rarely needed.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_print">print</code></td>
<td>

<p>If <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default) the function prints its results.
If <code style="white-space: pre;">&#8288;FALSE&#8288;</code> only the result data.frame will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> (default), the steps during sample size search are shown.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number
generator. To avoid differences in power for different runs a <code>set.seed(123456)</code>
is issued if <code>setseed = TRUE</code>, the default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulations are done via the distributional properties of the statistical
quantities necessary for deciding BE based on ABEL (&lsquo;Average Bioequivalence with Expanded Limits&rsquo;). For more details see a description in the <code>/doc</code> sub-directory of the package.<br /><br />
Function <code>sampleN.scABEL()</code> is based on power calculations via simulations
using the distributional characteristics of the &lsquo;key&rsquo; statistics obtained from
the EMA recommended evaluation via ANOVA if <code>regulator="EMA"</code> or if the
regulator component <code>est_method</code> is set to <code>"ANOVA"</code> if regulator is an object
of class 'regSet'.<br />
Otherwise, the simulations are based on the distributional characteristis of the
&lsquo;key&rsquo; statistics obtained from evaluation via intra-subject contrasts (ISC),
as recommended by the FDA.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects
(not subject/sequence &ndash; like in some other software packages).<br /><br />
Function <code>sampleN.scABEL2()</code> is solely based on power calculations via
simulation using the distributional characteristics of the &lsquo;key&rsquo; statistics
obtained from evaluation via intra-subject contrasts (ISC). This function is deprecated.
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input settings and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for restarting.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>The sample size estimation for extreme <code>theta0</code> (&lt;0.83 or &gt;1.21) may be very
time consuming and will eventually also fail since the start values chosen are
not really reasonable in that ranges. This is especially true in the range around
CV = 0.3 and regulatory constant according to FDA.<br />
If you really need sample sizes in that range be prepared to restart the sample
size estimation via the argument <code>nstart</code>.<br />
Since the dependence of power from n is very flat in the mentioned region you may
also consider to adapt the number of simulations not to get caught in the simulation
error trap.<br /><br />
If results of <code><a href="#topic+power.scABEL">power.scABEL</a></code> are expected to be inaccurate (partial
replicate design with unbalanced sequences and/or heteroscedasticity in the case of <em>CV</em><sub>wT</sub>&nbsp;&gt;&nbsp;<em>CV</em><sub>wR</sub>, subject data via <code><a href="#topic+sampleN.scABEL.sdsims">sampleN.scABEL.sdsims</a></code> should be simulated instead. Very time consuming (easily 100times slower)! Subject data simulations are only supported for <code>regulator="EMA"</code> and <code>regulator="GCC"</code>.
</p>


<h3>Note</h3>

<p>We are doing the sample size estimation only for balanced designs since the
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only for balanced designs.<br /><br />
In case of <code>regulator="FDA"</code> the sample size is only approximate since
the BE decision method is not exactly what is expected by the FDA. But the two Lászlós state that the scABEL method should be &lsquo;operationally&rsquo; equivalent to the
FDA method. Thus the sample size should be comparable.<br />
Consider in case of <code>regulator="FDA"</code> to use the function
<code>sampleN.RSABE()</code> instead.<br /><br />
In case of <code>regulator="HC"</code> the underlying power is only approximative
since the Health Canada recommends evaluation by a mixed model approach.
But this could only implemented via subject data simulations which are very
time consuming.<br /><br />
The minimum sample size is 6, even if the power is higher than the intended
targetpower.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84.
<a href="http://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.scABEL">power.scABEL</a></code>, <code><a href="#topic+sampleN.scABEL.sdsims">sampleN.scABEL.sdsims</a></code>, <code><a href="#topic+sampleN.RSABE">sampleN.RSABE</a></code>,
<code><a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using all the defaults:
# partial replicate design, targetpower=80%,
# true assumed ratio = 0.90, 1E+5 simulated studies
# ABE limits, PE constraint 0.8 - 1.25
# EMA regulatory settings
sampleN.scABEL(CV = 0.3)
# should result in a sample size n=54, power=0.8159

# Now with former (inofficial) ANVISA settings, CVswitch=40%
# (since 2016 ANVISA uses the same settings as EMA)
reg      &lt;- reg_const("USER", r_const = 0.76, CVswitch = 0.4, CVcap = 0.5)
reg$name &lt;- "Old ANVISA"
sampleN.scABEL(CV = 0.3, regulator = reg)
# should result in a sample size n=60, power=0.8101

# For the full replicate design, target power = 90%
# true assumed ratio = 0.9, FDA regulatory settings
# sims based on evalaution via ISC
sampleN.scABEL(CV = 0.4, targetpower = 0.9, design = "2x2x4",
               regulator = "FDA")
# should result in a sample size n=32, power=0.9125

# Fixed wider limits (0.7500 - 1.3333) for the GCC
sampleN.scABEL(CV = 0.4, targetpower = 0.9, design = "2x2x4",
               regulator = "GCC")
# should result in a sample size n=40, power=0.9039
</code></pre>

<hr>
<h2 id='sampleN.scABEL.ad'>
Sample size estimation for ABEL and iteratively adjusted alpha
</h2><span id='topic+sampleN.scABEL.ad'></span>

<h3>Description</h3>

<p>This function performs a sample size estimation for the BE decision
via Average Bioequivalenc with Expanding Limits (<abbr><span class="acronym">ABEL</span></abbr>) based
on simulations. Simultaneously alpha is iteratively adjusted in order
to maintain the consumer risk at the nominal level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.scABEL.ad(alpha = 0.05, targetpower = 0.8, theta0, theta1, theta2,
                  CV, design = c("2x3x3", "2x2x4", "2x2x3"), regulator,
                  nstart = NA, nsims = 1e+06, imax = 100, tol,
                  print = TRUE, details = FALSE, alpha.pre = 0.05,
                  setseed = TRUE, sdsims = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.scABEL.ad_+3A_alpha">alpha</code></td>
<td>

<p>Type I error (<abbr><span class="acronym">TIE</span></abbr>) probability (nominal level of the test). Per
convention commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1. Typical values are 0.80
to 0.90 (<em>i.e.</em>, 80% to 90%). Defaults to 0.80 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure
if <code>CVwR == CVswitch</code>. Also lower limit for the point estimate
constraint. Defaults to 0.80 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure
if <code>CVwR == CVswitch</code>. Also upper limit for the point estimate
constraint. Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> <em>CV</em> of Test
and Reference is assumed (homoscedasticity: <em>CV</em><sub>wT</sub>&nbsp;=&nbsp;<em>CV</em><sub>wR</sub>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>) &ndash; assuming
heteroscedasticity &ndash;<br />
the <em>CV</em> of Test <strong>must</strong> be given in the <em>first</em> element
and the one of Reference in the <em>second</em>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the <abbr><span class="acronym">BE</span></abbr> acceptance limits.
Choose from <code>"EMA"</code> (default), <code>"HC"</code>, or <code>"GCC"</code>. This argument may be given also in lower case.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_nstart">nstart</code></td>
<td>

<p>Best &ldquo;guess&rdquo; sample size. If not given (default), simulations
start with the sample size estimated for <code>alpha</code> (or <code>alpha.pre</code>,
if given), <code>theta0</code>, and <code>targetpower</code>.<br />
Can also be set to start the sample size search if a previous run
failed.<br />
According to regulatory requirements must be &gt;=12 for the <abbr><span class="acronym">EMA</span></abbr> and
&gt;=24 for <abbr><span class="acronym">ANVISA</span></abbr>.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to estimate the (empirical)
<abbr><span class="acronym">TIE</span></abbr> and in each iteration of adjusting alpha. The default value
1,000,000 = 1E+6 should not be lowered.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_tol">tol</code></td>
<td>

<p>Desired accuracy (convergence tolerance). Defaults to 1E-6.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default), the function sends its results to the console.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> (default), the steps during sample size search are
shown. Additionally information about the impact on power by
adjusting alpha and change of study costs due to the increased sample
size is given.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_alpha.pre">alpha.pre</code></td>
<td>

<p>Pre-specified alpha (optional). Must be <code>&lt;=alpha</code>. <abbr><span class="acronym">ABEL</span></abbr> will be
performed at level <code style="white-space: pre;">&#8288;alpha.pre&#8288;</code> and the <abbr><span class="acronym">TIE</span></abbr> assessed at level <code>alpha</code>.<br />
Less powerful than adjusting alpha but an alternative in the critical
region of maximum inflation of the <abbr><span class="acronym">TIE</span></abbr>. In certain scenarios
Bonferroni’s 0.025 is not sufficient to preserve the Type I Error.<br />
Not recommended if <em>CV</em><sub>wR</sub>&nbsp;&ge;&nbsp;0.45 due to poor power characteristics.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo)
random number generator. To avoid differences in power for different
runs <code>set.seed(123456)</code> is issued if <code>setseed = TRUE</code> (default).
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_sdsims">sdsims</code></td>
<td>

<p>If <code>FALSE</code> (default) power is estimated by the respective &lsquo;key&rsquo; statistics.
Recommended for speed reasons.<br />
Set to <code>TRUE</code> if results of <code><a href="#topic+power.scABEL">power.scABEL</a></code> are expected to
be inaccurate (partial replicate design with unbalanced sequences and/or heteroscedasticity
where <em>CV</em><sub>wT</sub>&nbsp;&gt;&nbsp;<em>CV</em><sub>wR</sub>) and subject data via <code><a href="#topic+power.scABEL.sdsims">power.scABEL.sdsims</a></code> should
be simulated instead. Very time consuming (easily 100times slower)! Subject data simulations are only supported for <code>regulator = "EMA"</code> and <code>regulator = "GCC"</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.ad_+3A_progress">progress</code></td>
<td>

<p>Set to <code>TRUE</code> if a progress bar should be displayed. Defaults to <code>FALSE</code>.<br />
Ignored if <code>sdsims = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulations are done via the distributional properties of the statistical
quantities necessary for assessing <abbr><span class="acronym">BE</span></abbr> based on <abbr><span class="acronym">ABEL</span></abbr>.
Simulations of the <abbr><span class="acronym">TIE</span></abbr> are performed at the upper (expanded) limit <em>U</em>
of the acceptance range. Due to the symmetry around 1 results are valid for the lower
(expanded) limit <em>L</em> as well.<br />
<em>U</em> at the <abbr><span class="acronym">EMA</span></abbr>’s and Health Canada’s <code>CVcap</code>, the <abbr><span class="acronym">GCC</span></abbr>’s for <em>any</em> <em>CV</em><sub>wR</sub>&nbsp;&gt;&nbsp;0.30:</p>
<pre>
scABEL(CV = 0.5, reg = "EMA")[["upper"]]
[1] 1.43191
scABEL(CV = 0.57382, reg = "HC")[["upper"]]
[1] 1.5
scABEL(CV = 0.31, reg = "GCC")[["upper"]]
[1] 1.333333</pre>
<p>Simulated studies are evaluated by ANOVA (Method A) as recommended in the
<abbr><span class="acronym">EMA</span></abbr>’s Q&amp;A-document and by intra-subject contrasts if <code>regulator="HC"</code>.
Health Canada requires a mixed effects model which cannot be implemented in R. However,
intra-subjects contrasts are a sufficiently close approximation.<br />
</p>
<p>If an inflation of the <abbr><span class="acronym">TIE</span></abbr> is expected (<em>i.e.</em>, <code>&gt;alpha</code>), alpha is
iteratively adjusted until at least the target power is reached and the consumer
risk is maintained (<code>&lt;=alpha</code>). For details about the algorithm see the
respective section of <code><a href="#topic+scABEL.ad">scABEL.ad</a></code>.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input and results for adjusted alpha,
type I error, sample size, and achieved power.<br />
The <code>Sample size</code> column contains the total sample size.
If no adjustment is necessary, <code>NA</code> will be returned in the
<code>alpha.adj</code> column and other results are identical to the ones
obtained by <code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a></code>.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning</h3>

<p>The sample size estimation for extreme <code>theta0</code> (&lt;0.83 or &gt;1.21) may be time
consuming and will eventually also fail since the start values chosen are
not really reasonable in that ranges.<br />
If you really need sample sizes in that range be prepared to restart the sample
size estimation with <code>nstart</code> above the last one before failure.<br />
Since the dependence of power from <code>n</code> is very flat in the mentioned region you may
also consider to adapt the number of simulations not to tap in the simulation
error trap.<br /><br />
See also the Warning section of the function <code><a href="#topic+power.scABEL">power.scABEL</a></code> concerning
the power value agreement to those obtained from simulations via subject data.<br /><br />
For the <abbr><span class="acronym">GCC</span></abbr> and <em>CV</em><sub>wR</sub>&nbsp;&le;&nbsp;0.30 simulations will be time consuming and may result in large sample sizes.

</p>


<h3>Note</h3>

<p>We are doing the sample size estimation only for balanced designs
since the break down of the total subject number in case of unbalanced
sequences is not unique. Moreover the formulas used are only for
balanced designs.
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. <a href="http://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>
<p>Wonnemann M, Frömke C, Koch A. <em>Inflation of the Type I Error: Investigations on Regulatory Recommendations for Bioequivalence of Highly Variable Drugs.</em> Pharm Res. 2015;32(1):135&ndash;43. <a href="https://doi.org/10.1007/s11095-014-1450-z">doi:10.1007/s11095-014-1450-z</a>
</p>
<p>Muñoz J, Alcaide D, Ocaña J. <em>Consumer’s risk in the EMA and FDA regulatory approaches for bioequivalence in highly variable drugs.</em> Stat Med. 2015;35(12):1933&ndash;43. <a href="https://doi.org/10.1002/sim.6834">doi:10.1002/sim.6834</a>
</p>
<p>Labes D, Schütz H. <em>Inflation of Type I Error in the Evaluation of Scaled Average Bioequivalence,
and a Method for its Control.</em> Pharm Res. 2016;33(11):2805&ndash;14. <a href="https://doi.org/10.1007/s11095-016-2006-1">doi:10.1007/s11095-016-2006-1</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scABEL.ad">scABEL.ad</a></code>, <code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a></code>, <code><a href="#topic+power.scABEL">power.scABEL</a></code>,
<code><a href="#topic+scABEL">scABEL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># --- Not run due to timing policy of CRAN for examples
# each may run some ten seconds or more
# using all the defaults:
# TRR|RTR|RRT, target power 80%, assumed ratio 0.90, 1E+6 simulated studies,
# EMA regulatory settings (ABE limits, PE constraint 0.8 - 1.25)

sampleN.scABEL.ad(CV = 0.3)
# should result in n 60, power 0.8022.
# Note: Without adjustment by sampleN.scABEL(): n 54, power 0.8159
# Easier to show the details:

sampleN.scABEL.ad(CV = 0.3, details = TRUE)
#
# TRTR|RTRT, target power 90%, pre-specified alpha 0.025

sampleN.scABEL.ad(CV = 0.3, targetpower = 0.9, design = "2x2x4", alpha.pre = 0.025)
# should result in n 60, power 0.9021; pre-specified alpha justified.
</code></pre>

<hr>
<h2 id='sampleN.scABEL.sdsims'>
Sample size estimation for BE decision via scaled (expanded) BE acceptance limits
</h2><span id='topic+sampleN.scABEL.sdsims'></span><span id='topic+sampleN.scABEL.sds'></span>

<h3>Description</h3>

<p>These functions performs the sample size estimation via power calculations of the BE decision via scaled (expanded) BE acceptance limits, based on <b>subject data</b> simulations.<br />
This function has an alias sampleN.scABEL.sds().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.scABEL.sdsims(alpha = 0.05, targetpower = 0.8, theta0, theta1,
                      theta2, CV, design = c("2x3x3", "2x2x4", "2x2x3"),
                      regulator, nsims = 1e5, nstart, imax = 100,
                      print = TRUE, details = TRUE,
                      setseed = TRUE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_alpha">alpha</code></td>
<td>

<p>Type I error probability. Per convention mostly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. <br />
Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>.<br />
Also Lower limit for the point estimate constraint.<br />
Defaults to 0.8 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper ABE limit to be applied in the mixed procedure if
<code>CVsWR &lt;= CVswitch</code>. Also upper limit for the point estimate constraint.<br />
Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> <em>CV</em> of Test
and Reference is assumed (homoscedasticity, <em>CV</em><sub>wT</sub>&nbsp;=&nbsp;<em>CV</em><sub>wR</sub>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming heteroscedasticity, the <em>CV</em> of the Test <strong>must</strong> be given in
<code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_design">design</code></td>
<td>

<p>Design of the study to be planned.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the widening of the BE acceptance limits.<br />
May be given as <code>"EMA"</code>, <code>"GCC"</code>, or as an object of class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator = "EMA"</code> if missing.<br />
This argument may be given also in lower case if given as character.<br />
If given as object of class 'regSet' the component <code>est_method</code> must not be <code>"ISC"</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to obtain the (empirical) power.
The default value 100,000 = 1e+5 is usually sufficient. Consider to rise
this value if <code>theta0</code> &lt;=0.85 or &gt;=1.20. But see the warning section.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_nstart">nstart</code></td>
<td>

<p>Set this to a start for the sample size search if a previous run failed.<br />
After reworking the start n in version 1.1-05 rarely needed.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_print">print</code></td>
<td>

<p>If <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default) the function prints its results. If <code style="white-space: pre;">&#8288;FALSE&#8288;</code> only the result data.frame will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_details">details</code></td>
<td>

<p>If set to <code>TRUE</code> (default), the steps during sample size search are shown.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo) random number generator. To avoid differences in power for different runs a <code>set.seed(123456)</code> is issued if <code>setseed = TRUE</code>, the default.
</p>
</td></tr>
<tr><td><code id="sampleN.scABEL.sdsims_+3A_progress">progress</code></td>
<td>

<p>Should a progressbar be shown? Defaults to <code>TRUE</code> if missing and <code>nsims</code> &gt;5E5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods rely on the analysis of log-transformed data, <em>i.e.</em>, assume a
log-normal distribution on the original scale.<br /><br />
The expanded BE acceptance limits will be calculated by the formula<br />
<code style="white-space: pre;">&#8288;  [L, U] = exp(± r_const * sWR)&#8288;</code><br />
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference. <code>r_const = 0.76</code> (~log(1.25)/0.29356) is used
in case of <code>regulator = "EMA"</code>.
If the CVwR is &lt; CVswitch=0.3 the conventional ABE limits apply (mixed procedure).<br />
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if
<em>CV</em><sub>wR</sub>&nbsp;&gt;&nbsp;0.50, <em>i.e.</em>, the widened limits are held at value calculated for <em>CV</em><sub>wR</sub>&nbsp;=&nbsp;0.50.<br />
In case of <code>regulator="GCC"</code> <em>fixed</em> wider limits of 0.7500 &ndash; 1.3333 for <em>CV</em><sub>wR</sub>&nbsp;&gt;&nbsp;0.30 are applied and the conventional limits otherwise.<br /><br />
The simulations are done by simulating subject data (all effects fixed except the
residuals) and evaluating these data via ANOVA of all data to get the point estimate
of T vs. R along with its 90% CI and an ANOVA of the data under R(eference) only
to get an estimate of <em>s</em>&sup2;<sub>wR</sub>.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>Returns a data.frame with the input settings and sample size results.<br />
The <code>Sample size</code> column contains the total sample size.<br />
The <code>nlast</code> column contains the last <code>n</code> value. May be useful for restarting.
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, sample size estimations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>The sample size estimation for very extreme <code>theta0</code> (&lt;0.83 or &gt;1.21) may be very
time consuming and will eventually also fail since the start values chosen are
not really reasonable in that ranges.<br />
If you really need sample sizes in that range be prepared to restart the sample
size estimation via the argument nstart.<br />
Since the dependence of power from n is very flat in the mentioned region you may
also consider to adapt the number of simulations not to get caught in the simulation
error trap.
</p>


<h3>Note</h3>

<p>We are doing the sample size estimation only for balanced designs since the
break down of the total subject number in case of unbalanced sequence groups
is not unique. Moreover the formulas used are only for balanced designs.<br />
The minimum sample size is 6, even if the power is higher than the intended
targetpower.<br /><br />
Subject simulations are easily more than 100times slower than simulations based
on the &lsquo;key&rsquo; statistics. We recommend this function only for the partial
replicate design (TRR|RTR|RRT) assuming heteroscedasticity in the case of  <em>CV</em><sub>wT</sub>&nbsp;&gt;&nbsp;<em>CV</em><sub>wR</sub>.<br />
Thus be patient and go for a cup of coffee if you use this function with high
sample sizes!
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>References</h3>

<p>Tóthfalusi L, Endrényi L. <em>Sample Sizes for Designing Bioequivalence Studies for Highly Variable Drugs.</em> J Pharm Pharmaceut Sci. 2011;15(1):73&ndash;84. <a href="http://ejournals.library.ualberta.ca/index.php/JPPS/article/download/11612/9489">open access</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.scABEL.sdsims">power.scABEL.sdsims</a></code>, <code><a href="#topic+sampleN.scABEL">sampleN.scABEL</a></code>, <code><a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># using the defaults:
# partial replicate design, targetpower=80%,
# true assumed ratio = 0.90, 1E+5 simulated studies
# ABE limits, PE constraint 0.8 - 1.25
# EMA regulatory settings
# Heteroscedasticity (CVwT 0.4, CVwR 0.3)
# compare results and run times

CV           &lt;- c(0.4, 0.3)
expl         &lt;- data.frame(method = c("subject simulations", "\'key\' statistics"),
                           n = NA, power = NA, seconds = NA)
start        &lt;- proc.time()[[3]]
expl[1, 2:3] &lt;- sampleN.scABEL.sdsims(CV = CV, print = FALSE,
                                      details = FALSE)[8:9]
expl[1, 4]   &lt;- proc.time()[[3]] - start
start        &lt;- proc.time()[[3]]
expl[2, 2:3] &lt;- sampleN.scABEL(CV = CV, print = FALSE,
                               details = FALSE)[8:9]
expl[2, 4]   &lt;- proc.time()[[3]] - start
print(expl, row.names = FALSE)
# should result in a sample size n=69, power=0.80198 for
# the subject simulations and n=66, power=0.80775 for the
# 'key' statistics
</code></pre>

<hr>
<h2 id='sampleN.TOST'>
Sample size based on power of TOST
</h2><span id='topic+sampleN.TOST'></span>

<h3>Description</h3>

<p>Estimates the necessary sample size to obtain at least a target (desired) power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleN.TOST(alpha = 0.05, targetpower = 0.8, logscale = TRUE,
             theta0, theta1, theta2, CV, design = "2x2",
             method = "exact", robust = FALSE, print = TRUE,
             details = FALSE, imax=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleN.TOST_+3A_alpha">alpha</code></td>
<td>

<p>Significance level (one-sided). Commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_targetpower">targetpower</code></td>
<td>

<p>Power to achieve at least. Must be &gt;0 and &lt;1.<br />
Typical values are 0.8 or 0.9.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_logscale">logscale</code></td>
<td>

<p>Should the data used on log-transformed (<code>TRUE</code>) or on original
scale (<code>FALSE</code>)? Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio or difference.<br />
In case of <code>logscale = TRUE</code> it must be given as ratio T/R.<br />
If <code>logscale = FALSE</code>, the difference in means. In this case, the difference may be expressed in two ways: relative to the same (underlying) reference mean, <em>i.e.</em>, as (T-R)/R = T/R - 1; or as difference in means T-R. Note that in the former case the units of <code>CV</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.95 if <code>logscale = TRUE</code> or to 0.05 if <code>logscale = FALSE</code>
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_theta1">theta1</code></td>
<td>

<p>Lower (bio-)equivalence limit.<br />
In case of <code>logscale = TRUE</code> it is given as ratio.<br />
If <code>logscale = FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
Defaults to 0.8 if <code>logscale = TRUE</code> or to -0.2 if <code>logscale = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_theta2">theta2</code></td>
<td>

<p>Upper (bio-)equivalence limit.<br />
In case of <code>logscale = TRUE</code> it is given as ratio.
If <code>logscale = FALSE</code>, the limit may be expressed in two ways:
difference of means relative to the same (underlying) reference mean or in units of the difference of means.
Note that in the former case the units of <code>CV</code>, <code>theta0</code> and <code>theta1</code> need also be given relative to the reference mean (specified as ratio).<br />
If not given, <code>theta2</code> will be calculated as <code>1/theta1</code> if <code>logscale = TRUE</code> or as <code>-theta1</code> if <code>logscale = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_cv">CV</code></td>
<td>

<p>In case of <code>logscale=TRUE</code> the (geometric) coefficient of variation given as ratio.<br />
If <code>logscale=FALSE</code> the argument refers to (residual) standard deviation of the response. In this case, standard deviation may be expressed two ways: relative to a reference mean (specified as ratio sigma/muR), <em>i.e.</em>, again as a coefficient of variation; or untransformed, <em>i.e.</em>, as standard deviation of the response. Note that in the former case the units of <code>theta0</code>, <code>theta1</code> and <code>theta2</code> need also be given relative to the reference mean (specified as ratio).<br />
</p>
<p>In case of cross-over studies this is the within-subject CV, in case of a parallel-group design the CV of the total variability.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_design">design</code></td>
<td>

<p>Character string describing the study design.<br />
See <code>known.designs()</code> for designs covered in this package.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_method">method</code></td>
<td>

<p>Method for calculation of the power.<br />
Defaults to <code>"exact"</code> in which case the calculation is done based on formulas
with Owen’s Q. The calculation via Owen’s Q can also be choosen with
<code>method = "owenq"</code>.<br />
Another exact method via direct use of the bivariate non-central <em>t</em>-distribution
may be chosen with <code style="white-space: pre;">&#8288;method = "mvt"&#8288;</code>. This may have somewhat lower precision
compared to Owen’s Q and has a much longer run-time.<br />
Approximate calculations can be choosen via <code style="white-space: pre;">&#8288;method = "noncentral"&#8288;</code> or
<code style="white-space: pre;">&#8288;method = "nct"&#8288;</code> for the approximation using the non-central <em>t</em>-distribution.
With <code style="white-space: pre;">&#8288;method = "central"&#8288;</code> or <code style="white-space: pre;">&#8288;method = "shifted"&#8288;</code> the relatively crude
approximation via the &lsquo;shifted&rsquo; central <em>t</em>-distribution is chosen.<br />
The strings for <code style="white-space: pre;">&#8288;method&#8288;</code> may be abbreviated.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_robust">robust</code></td>
<td>

<p>Defaults to <code>FALSE</code>. With that value the usual degrees of freedom will be used.<br />
Set to <code>TRUE</code> will use the degrees of freedom according to the &lsquo;robust&rsquo; evaluation
(aka Senn’s basic estimator). These df are calculated as <code>n-seq</code>.<br />
See <code>known.designs()$df2</code> for designs covered in this package.<br />
Has only effect for higher-order crossover designs.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_print">print</code></td>
<td>

<p>If <code>TRUE</code> (default) the function prints its results. If <code>FALSE</code> only the data frame with the results will be returned.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code> the design characteristics and the steps during
sample size calculations will be shown. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="sampleN.TOST_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search.<br />
Defaults to 100. Adaption only in rare cases needed.<br />
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size is estimated via iterative evaluation of power of the <abbr><span class="acronym">TOST</span></abbr> procedure.<br />
Start value for the sample size search is taken from a large sample approximation
according to Zhang, modified.<br />
The sample size is bound to 4 as minimum.<br /><br />
The estimated sample size gives always the <em>total</em> number of subjects (not subject/sequence in crossovers or subjects/group in parallel designs &ndash; like in some other software packages).
</p>


<h3>Value</h3>

<p>A data frame with the input and results will be returned.<br />
The <code>Sample size</code> column contains the total sample size.
</p>


<h3>Warning</h3>

<p>The function does not vectorize properly.<br />
If you need sample sizes with varying CVs, use f.i. <code style="white-space: pre;">&#8288;for&#8288;</code>-loops or the <code style="white-space: pre;">&#8288;apply&#8288;</code>-family.
</p>


<h3>Note</h3>

<p>Of course it is highly recommended to use the default <code style="white-space: pre;">&#8288;method = "exact"&#8288;</code>. :-)<br />
There is no reason besides testing and for comparative purposes to use an
approximation if the exact method is available at no extra costs.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Phillips KF. <em>Power of the Two One-Sided Tests Procedure in Bioequivalence.</em> J Pharmacokin Biopharm. 1990;18:137&ndash;44. <a href="https://doi.org/10.1007/BF01063556">doi:10.1007/BF01063556</a>
</p>
<p>Diletti D, Hauschke D, Steinijans VW. <em>Sample Size Determination for Bioequivalence Assessment by Means of Confidence Intervals.</em> Int J Clin Pharmacol Ther Toxicol. 1991;29(1):1&ndash;8.
</p>
<p>Diletti D, Hauschke D, Steinijans VW. <em>Sample size determination: Extended tables for the multiplicative model and bioequivalence ranges of 0.9 to 1.11 and 0.7 to 1.43.</em> Int J Clin Pharmacol Ther Toxicol. 1992;30(Suppl 1):S59&ndash;62.
</p>
<p>Zhang P. <em>A Simple Formula for Sample Size Calculation in Equivalence Studies.</em> J Biopharm Stat. 2003;13(3):529&ndash;38. <a href="https://doi.org/10.1081/BIP-120022772">doi:10.1081/BIP-120022772</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.TOST">power.TOST</a>, <a href="#topic+known.designs">known.designs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Exact calculation for a classical 2x2 cross-over (TR/RT),
# BE limits 80 ... 125%, assumed true BE ratio 0.95, intra-subject CV=30%,
# using all the default values
# should give n=40 power=0.815845
sampleN.TOST(CV = 0.3)

# Exact calculation for a parallel group design
# evaluation on the original (untransformed) scale
# BE limits 80 ... 120% = -20% ... +20% of reference,
# assumed true BE ratio 0.95% = -5% to reference mean,
# total CV=20%
# should give n=48 (total) power=0.815435
sampleN.TOST(logscale = FALSE, theta1 = -0.2, theta0 = -0.05,
             CV = 0.2, design = "parallel")

# A rather strange setting of theta0! Have a look at n.
# It would be better this is not the sample size but the running total
# of my bank account. But the first million is the hardest. ;-)
sampleN.TOST(CV = 0.2, theta0 = 0.8005)
</code></pre>

<hr>
<h2 id='scABEL'>
Scaled (widened) BE Acceptance Limits
</h2><span id='topic+scABEL'></span>

<h3>Description</h3>

<p>The (widened) scaled BE acceptance limits are calculated according to the 
regulatory settings of EMA, HC, FDA or via user defined regulatory settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scABEL(CV, regulator)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scABEL_+3A_cv">CV</code></td>
<td>

<p>Coefficient of variation (of the Reference) as ratio.
</p>
</td></tr>
<tr><td><code id="scABEL_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory body settings for the widening of the BE acceptance limits.<br />
May be given as character from the choices <code>"EMA"</code>, <code>"HC"</code> (Health Canada), <code>"GCC"</code> (Gulf Cooperation Council), <code>"FDA"</code> or as an object of
class 'regSet' (see <code><a href="#topic+reg_const">reg_const</a></code>).<br />
Defaults to <code>regulator="EMA"</code> if missing.<br />
The former <code>regulator="ANVISA"</code> is no longer allowed. The ANVISA 
recommends since 2016 the EMA’s regulatory settings.<br />
The former <code>regulator="USER"</code> is no longer accepted but can be handled now
via function <code>reg_const()</code> to define an object with class 'regSet'.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The widened BE acceptance limits are calculated by the formula<br />
<code style="white-space: pre;">&#8288;  [L, U] = exp(-/+ r_const * sWR)&#8288;</code><br />
with <code>r_const</code> the regulatory constant and <code>sWR</code> the standard deviation of the within
subjects variability of the Reference.<br />
</p>

<ul>
<li> <p><code>regulator="EMA"</code> or <code>regulator="HC"</code><br />
<code>r_const = 0.76</code> (~ log(1.25)/sqrt(log(0.30^2+1)))
</p>
</li>
<li> <p><code>regulator="GCC"</code><br />
<code>r_const = 0.97997...</code> (= log(1/0.75)/sqrt(log(0.30^2+1)))
</p>
</li>
<li> <p><code>regulator="FDA"</code><br />
<code>r_const = 0.89257...</code> (= log(1.25)/0.25)
</p>
</li></ul>

<p>If the CVwR of the Reference is &lt; CVswitch=0.3 the conventional ABE limits 
apply (mixed procedure).<br /><br /> 
In case of <code>regulator="EMA"</code> a cap is placed on the widened limits if 
CVwR&gt;0.5, <em>i.e.</em>, the widened limits are held at the value calculated for CVwR=0.5.<br />
In case of <code>regulator="HC"</code> the capping is done such that the acceptance
limits are 0.6666 ... 1.5 at maximum, <em>i.e.</em>, CVcap=0.57382. 
Literally it is given by Health Canada rounded to three significant digits as 57.4%.
</p>


<h3>Value</h3>

<p>Returns a vector of lenghth 2 if one CV is given or a matrix if CV is given as vector 
with named components <code>lower</code> and <code>upper</code> of the scaled acceptance limits.
</p>


<h3>Note</h3>

<p>The scaled acceptance limits (coined <em>&lsquo;implied limits&rsquo;</em> by Davit <em>et al.</em>) are not directly used in the BE evaluation for HVDP(s) recommended by the FDA. They are included here for comparative purposes. Moreover, there are controversies where to locate the <em>&lsquo;implied limits&rsquo;</em> and whether the so-called &lsquo;desired consumer-risk model&rsquo; should be used.
</p>


<h3>Author(s)</h3>

<p>D. Labes
</p>


<h3>References</h3>

<p>Davit BM, Chen ML, Conner DP, Haidar SH, Kim S, Lee CH, Lionberger RA, Makhlouf FT, Nwakama PE, Patel DT, Schuirmann DJ, Yu LX. <em>Implementation of a Reference-Scaled Average Bioequivalence Approach for 
Highly Variable Generic Drug Products by the US Food and Drug Administration.</em> AAPS J. 2012;14(4):915&ndash;24. <a href="https://doi.org/10.1208/s12248-012-9406-x">doi:10.1208/s12248-012-9406-x</a>
</p>
<p>Health Canada, Therapeutic Products Directorate. <em>Guidance Document. Comparative Bioavailability Standards:
Formulations Used for Systemic Effects.</em> 2018/06/08. <a href="https://www.canada.ca/content/dam/hc-sc/migration/hc-sc/dhp-mps/alt_formats/pdf/prodpharma/applic-demande/guide-ld/bio/comparative-bioavailability-standards-formulations-used-systemic-effects.pdf">ISBN: 978-0-660-25514-9</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.scABEL">power.scABEL</a>, <a href="#topic+sampleN.scABEL">sampleN.scABEL</a>, <a href="#topic+reg_const">reg_const</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>scABEL(CV = 0.3, regulator = "EMA")
# should give the conventional (unscaled) BE limits:
# lower upper
#  0.80  1.25

scABEL(CV = 0.5, regulator = "EMA")
# should give the (maximum) expanded limits:
#     lower     upper
# 0.6983678 1.4319102

# define old ANVISA settings via reg_const()
rc      &lt;- reg_const("USER", r_const = 0.76,
                     CVswitch = 0.4, CVcap = 0.5)
rc$name &lt;- "ANVISAold"
scABEL(CV = 0.4, regulator = rc)
# should give the conventional (not expanded) limits:
# lower upper
#  0.80  1.25

scABEL(CV = 0.55, regulator = "HC")
# should give the widened limits:
#     lower     upper
# 0.6765789 1.4780241

scABEL(CV = 0.55, regulator = "GCC")
# should give the widened limits:
#    lower    upper
# 0.750000 1.333333

scABEL(CV = 0.55, regulator = "FDA")
# should give the 'implied' limits:
#     lower     upper
# 0.6320032 1.5822705
</code></pre>

<hr>
<h2 id='scABEL.ad'>
Iteratively adjusted alpha for ABEL
</h2><span id='topic+scABEL.ad'></span>

<h3>Description</h3>

<p>This function iteratively adjusts alpha for the <abbr><span class="acronym">BE</span></abbr> decision
via Average Bioequivalence with Expanding Limits (<abbr><span class="acronym">ABEL</span></abbr>) based
on simulations in order to maintain the consumer risk at the nominal level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scABEL.ad(alpha = 0.05, theta0, theta1, theta2, CV,
          design = c("2x3x3", "2x2x4", "2x2x3"), regulator,
          n, alpha.pre = 0.05, imax = 100, tol, print = TRUE,
          details = FALSE, setseed = TRUE, nsims = 1e+06,
          sdsims = FALSE, progress)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scABEL.ad_+3A_alpha">alpha</code></td>
<td>

<p>Type I Error (<abbr><span class="acronym">TIE</span></abbr>) probability (nominal level of the test). Per
convention commonly set to 0.05.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_theta0">theta0</code></td>
<td>

<p>&lsquo;True&rsquo; or assumed T/R ratio. Defaults to 0.90 according to the two Lászlós if not given explicitly.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_theta1">theta1</code></td>
<td>

<p>Conventional lower <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure
if <code>CVwR == CVswitch</code>. Also lower limit for the point estimate
constraint. Defaults to 0.80 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_theta2">theta2</code></td>
<td>

<p>Conventional upper <abbr><span class="acronym">ABE</span></abbr> limit to be applied in the mixed procedure
if <code>CVwR == CVswitch</code>. Also upper limit for the point estimate
constraint. Defaults to 1.25 if not given explicitly.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_cv">CV</code></td>
<td>

<p>Intra-subject coefficient(s) of variation as ratio (not percent).
</p>

<ul>
<li><p> If given as a scalar (<code>length(CV) == 1</code>) the <em>same</em> CV of Test
and Reference is assumed (homoscedasticity, <code>CVwT==CVwR</code>).
</p>
</li>
<li><p> If given as a vector (<code>length(CV) == 2</code>), <em>i.e.</em>, assuming
heteroscedasticity, the CV of the Test <strong>must</strong> be given in <code>CV[1]</code> and the one of the Reference in the <code>CV[2]</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="scABEL.ad_+3A_design">design</code></td>
<td>

<p>Design of the study.<br />
<code>"2x3x3"</code> is the partial replicate design.<br />
<code>"2x2x4"</code> is a full replicate design with 2 sequences and 4 periods.<br />
<code>"2x2x3"</code> is a full replicate design with 2 sequences and 3 periods.<br />
Defaults to <code>"2x3x3"</code>. Details are given the section about Designs.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_regulator">regulator</code></td>
<td>

<p>Regulatory settings for the expanding of the <abbr><span class="acronym">BE</span></abbr> acceptance limits.
Choose from <code>"EMA"</code> (default), <code>"HC"</code>, <code>"GCC"</code>, or <code>"FDA"</code>. This argument
may also be given in lower case.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_n">n</code></td>
<td>

<p>Total sample size of the study or a vector of sample size / sequences.
If <code>n</code> leads to an unbalanced design (<em>i.e.</em>, is not a multiple of two
in the full replicate designs or not a multiple of three in the partial
replicate), the code tries to keep subjects / sequence as balanced as possible.<br />
In evaluating a particular <em>unbalanced</em> study <strong>always</strong> give <code>n</code>
as a vector.<br />
Only if <code>design = "2x2x3"</code> (TRT|RTR) the <em>order</em> of sample sizes
is important. <code>n[1]</code> is for sequence TRT and <code>n[2]</code> for sequence RTR.<br />
If <code>n</code> is missing, a sample size is estimated with target power 0.80 and pre-specified
alpha if defined. Otherwise, alpha is used.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_alpha.pre">alpha.pre</code></td>
<td>

<p>Pre-specified alpha (optional). Must be <code>&lt;=alpha</code>. <abbr><span class="acronym">ABEL</span></abbr> will be
performed at level <code style="white-space: pre;">&#8288;alpha.pre&#8288;</code> and the <abbr><span class="acronym">TIE</span></abbr> assessed at level <code style="white-space: pre;">&#8288;alpha&#8288;</code>.<br />
Less powerful than adjusting alpha but an alternative in the critical region
of maximum inflation of the <abbr><span class="acronym">TIE</span></abbr>. In certain scenarios Bonferroni’s
0.025 is not sufficient to preserve the Type I Error (<em>e.g.</em>, the third example).<br />
Not recommended if <code>CVwR &gt;= 0.45</code> due to poor power characteristics.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_imax">imax</code></td>
<td>

<p>Maximum number of steps in sample size search. Defaults to 100.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_tol">tol</code></td>
<td>

<p>Desired accuracy (convergence tolerance). Defaults to 1E-6.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_print">print</code></td>
<td>

<p>If <code style="white-space: pre;">&#8288;TRUE&#8288;</code> (default), the function sends its results to the console.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_details">details</code></td>
<td>

<p>If <code>TRUE</code>, the <em>relative</em> change of the consumer risk in percent is shown.
Additionally information about the impact on power (for specified <code>theta0</code>
and target power 0.80), runtime, and number of simulations (iterations)
are given. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_setseed">setseed</code></td>
<td>

<p>Simulations are dependent on the starting point of the (pseudo)
random number generator. To avoid differences in power for different
runs <code>set.seed(123456)</code> is issued if <code>setseed=TRUE</code> (default).
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_nsims">nsims</code></td>
<td>

<p>Number of simulations to be performed to estimate the (empirical)
<abbr><span class="acronym">TIE</span></abbr> error and in each iteration of adjusting alpha. The default value
1,000,000 = 1E+6 should not be lowered.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_sdsims">sdsims</code></td>
<td>

<p>If <code>FALSE</code> (default) power is estimated by the respective &lsquo;key&rsquo; statistics.
Recommended for speed reasons.<br />
Set to <code>TRUE</code> if results of <code><a href="#topic+power.scABEL">power.scABEL</a></code> are expected to
be inaccurate (partial replicate design with unbalanced sequences and/or heteroscedasticity
where CVwT &gt; CVwR) and subject data via <code><a href="#topic+power.scABEL.sdsims">power.scABEL.sdsims</a></code> should
be simulated instead. Very time consuming (easily 100times slower)! Subject data
simulations are only supported for <code>regulator = "EMA"</code> and <code>regulator = "GCC"</code>.
</p>
</td></tr>
<tr><td><code id="scABEL.ad_+3A_progress">progress</code></td>
<td>

<p>Set to <code>TRUE</code> if a progress bar should be displayed. Ignored if <code>sdsims = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulations are done via the distributional properties of the statistical
quantities necessary for assessing <abbr><span class="acronym">BE</span></abbr> based on <abbr><span class="acronym">ABEL</span></abbr>.
Simulations for the <abbr><span class="acronym">TIE</span></abbr> are performed at the upper (expanded) limit <em>U</em>
of the acceptance range. Due to the symmetry around 1 results are valid for the lower
(expanded) limit <em>L</em> as well.<br />
<em>U</em> at the <abbr><span class="acronym">EMA</span></abbr>’s and Health Canada’s <code>CVcap</code>, the <abbr><span class="acronym">GCC</span></abbr>’s for <em>any</em> CVwR &gt; 0.3:</p>
<pre>scABEL(CV = 0.5, reg = "EMA")[["upper"]]
[1] 1.43191
scABEL(CV = 0.57382, reg = "HC")[["upper"]]
[1] 1.5
scABEL(CV = 0.5, reg = "GCC")[["upper"]]
[1] 1.333333</pre>
<p>Simulated studies are evaluated by ANOVA (Method A) as recommended in the
<abbr><span class="acronym">EMA</span></abbr>’ Q&amp;A-document and by intra-subject contrasts if <code>regulator = "HC"</code>.
Health Canada requires a mixed-effects model which cannot be implemented in R.
However, intra-subjects contrasts are a sufficiently close approximation.<br />
The Type I Error in <abbr><span class="acronym">ABEL</span></abbr> depends only on <code>CVwR</code> and &ndash; to a
minor degree &ndash; the sample size. Algorithm:
</p>

<ol>
<li><p> The <abbr><span class="acronym">TIE</span></abbr> is assessed based on <code>alpha</code> (or <code>alpha.pre</code>)
and compared to the nominal level of the test <code>alpha</code>.
</p>
</li>
<li><p> If no inflation of the <abbr><span class="acronym">TIE</span></abbr> is found, the algorithm stops.
</p>
</li>
<li><p> Otherwise, alpha is iteratively adjusted (<em>i.e.</em>, <code>alpha.adj &lt;alpha</code>)
until no more relevant inflation of the <abbr><span class="acronym">TIE</span></abbr> is detected (<em>i.e.</em>,
<code>abs(TIE - alpha) &lt;= tol</code>).
</p>
</li></ol>



<h3>Value</h3>

<p>Sends results to the console if argument <code>print=TRUE</code> (default).<br />
Returns a list with the input, adjusted alpha, and Type I Error (for nominal
and adjusted alpha) if argument <code>print=FALSE</code>.<br />
If no adjustment is necessary, <code>NAs</code> will be returned for the respective
variables (<code>alpha.adj</code>, <code>TIE.adj</code>, <code>rel.change</code>, <code>pwr.adj</code>, <code>rel.loss</code>).
</p>


<h3>Designs</h3>

<p>Although some designs are more &lsquo;popular&rsquo; than others, power calculations are valid for <em>all</em> of the following designs:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>"2x2x4"</code> </td><td style="text-align: left;"> TRTR | RTRT</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRRT | RTTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TTRR | RRTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x2x3"</code> </td><td style="text-align: left;"> TRT | RTR</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> TRR | RTT</td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>"2x3x3"</code> </td><td style="text-align: left;"> TRR | RTR | RRT
  </td>
</tr>

</table>



<h3>Warning </h3>

<p>See the Warning section of the function <code><a href="#topic+power.scABEL">power.scABEL</a></code> concerning
the power value agreement to the one obtained by simulations via subject data.
</p>


<h3>Note</h3>

<p>Specifying <code>theta0</code> is not necessary.<br />
If <code>theta0</code> <em>is not</em> given, achievable power for the common target
of 0.80 (both for <code>alpha</code> and adjusted alpha) will be estimated. If
<code>theta0</code> <em>is</em> specified, its value will be used; again for target power 0.80.<br />
If you are interested in other levels of power, use <code><a href="#topic+sampleN.scABEL.ad">sampleN.scABEL.ad</a></code>.
</p>
<p>The EMA’s method is currently recommended in other jurisdictions as well (<em>e.g.</em>, by the WHO;
in ASEAN States, Australia, Brazil, Egypt, the Eurasian Economic Union, New Zealand, and the East African Community).<br />
If CVwR &gt; 30%, <em>fixed</em> wider limits of 0.7500&ndash;1.3333 are recommended by the Gulf Cooperation Council (Bahrain, Kuwait, Oman, Qatar, Saudi Arabia, United Arab Emirates).
</p>


<h3>Author(s)</h3>

<p>H. Schütz
</p>


<h3>References</h3>

<p>Wonnemann M, Frömke C, Koch A. <em>Inflation of the Type I Error: Investigations on Regulatory Recommendations for Bioequivalence of Highly Variable Drugs.</em> Pharm Res. 2015;32(1):135&ndash;43. <a href="https://doi.org/10.1007/s11095-014-1450-z">doi:10.1007/s11095-014-1450-z</a>
</p>
<p>Muñoz J, Alcaide D, Ocaña J. <em>Consumer’s risk in the EMA and FDA regulatory approaches for bioequivalence in highly variable drugs.</em> Stat Med. 2015;35(12):1933&ndash;43. <a href="https://doi.org/10.1002/sim.6834">doi:10.1002/sim.6834</a>
</p>
<p>Labes D, Schütz H. <em>Inflation of Type I Error in the Evaluation of Scaled Average Bioequivalence, and a Method for its Control.</em> Pharm Res. 2016;33(11):2805&ndash;14. <a href="https://doi.org/10.1007/s11095-016-2006-1">doi:10.1007/s11095-016-2006-1</a>
</p>
<p>Tóthfalusi L, Endrényi L. <em>Algorithms for Evaluating Reference Scaled Average Bioequivalence: Power, Bias, and Consumer Risk.</em> Stat Med. 2017;36(27):4378&ndash;90. <a href="https://doi.org/10.1002/sim.7440">doi:10.1002/sim.7440</a>
</p>
<p>Molins E, Cobo E, Ocaña J. <em>Two-Stage Designs Versus European Scaled Average Designs in Bioequivalence Studies for Highly Variable Drugs: Which to Choose?</em> Stat Med. 2017;36(30):4777&ndash;88. <a href="https://doi.org/10.1002/sim.7452">doi:10.1002/sim.7452</a>
</p>
<p>European Medicines Agency, Committee for Medicinal Products for Human Use. <em>Guideline on the Investigation of Bioequivalence.</em> London, 20 January 2010. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/guideline-investigation-bioequivalence-rev1_en.pdf">CPMP/EWP/QWP/1401/98 Rev. 1/ Corr **</a>
</p>
<p>European Medicines Agency, Committee for Medicinal Products for Human Use. <em>Questions &amp; Answers: positions on specific questions addressed to the Pharmacokinetics Working Party (PKWP).</em> London, 19 November 2015. <a href="https://www.ema.europa.eu/en/documents/scientific-guideline/questions-and-answers-positions-specific-questions-addressed-pharmacokinetics-working-party_en.pdf">EMA/618604/2008 Rev. 13</a>
</p>
<p>Health Canada, Therapeutic Products Directorate. <em>Comparative Bioavailability Standards: Formulations Used for Systemic Effects, 2.1.1.8 Highly variable drug products</em> Ottawa, 08 June 2018. <a href="https://www.canada.ca/en/health-canada/services/drugs-health-products/drug-products/applications-submissions/guidance-documents/bioavailability-bioequivalence/comparative-bioavailability-standards-formulations-used-systemic-effects.html#a2.1.1.8">online</a>
</p>
<p>Executive Board of the Health Ministers’ Council for GCC States. <em>The GCC Guidelines for Bioequivalence.</em> May 2021. <a href="https://web.archive.org/web/20220728114758/https://www.sfda.gov.sa/sites/default/files/2021-10/GCC_Guidelines_Bioequivalence.pdf">Version 3.0</a>
Saudi Food &amp; Drug Authority <em>The GCC Guidelines for Bioequivalence.</em> <a href="https://www.sfda.gov.sa/sites/default/files/2022-08/GCC_Guidelines_Bioequivalence31_0.pdf">Version 3.1</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sampleN.scABEL.ad">sampleN.scABEL.ad</a></code>, <code><a href="#topic+power.scABEL">power.scABEL</a></code>, <code><a href="#topic+power.scABEL.sdsims">power.scABEL.sdsims</a></code>, <code><a href="#topic+scABEL">scABEL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using all defaults:
# TRR|RTR|RRT, target power 80% for assumed ratio 0.90 (estimated sample size 54),
# EMA regulatory settings (ABE limits and PE constraint 0.80 - 1.25),
# 1E+6 simulated studies.
# Not run: due to timing policy of CRAN for examples

scABEL.ad(CV = 0.3)
# Should result in adjusted alpha 0.03389 (TIE 0.5000, TIE for nominal alpha 0.07189).
#
# As above but subject data simulations.

scABEL.ad(CV = 0.3, sdsims = TRUE)
# Should result in adjusted alpha 0.03336 (TIE 0.5000, TIE for nominal alpha 0.07237).
#
# TRT|RTR, heteroscedasticity, sample size 48 (unbalanced), subject data simulations.

scABEL.ad(CV = c(0.25, 0.3), design = "2x2x3", n = c(23, 25), sdsims = TRUE)
# Should result in adjusted alpha 0.02465 (TIE 0.5000, TIE for nominal alpha 0.09050).
#
# TRTR|RTRT, CV 0.35, sample size 33 (unbalanced).

scABEL.ad(CV = 0.35, design = "2x2x4", n = c(16, 17))
# Should result in adjusted alpha 0.03632 (TIE 0.5000, TIE for nominal alpha 0.06544).
</code></pre>

<hr>
<h2 id='type1error.2TOST'>
Type I error rate for two simultaneous TOST procedures
</h2><span id='topic+type1error.2TOST'></span>

<h3>Description</h3>

<p>Was designed to calculate the type I error rate of two simultaneous TOST procedures 
(where the two parameters of the two TOSTs are correlated with some correlation)
for various study designs used in BE studies.
</p>
<p>Is defunct now since it suffers from insufficient precision to obtain the 
type 1 error (TIE) via simulations.<br /> 
Due to the intersection-union principle the TIE is always upper bounded 
to alpha by theory.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
