<!DOCTYPE html><html><head><title>Help for package statmod</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {statmod}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Digamma'><p>Digamma Generalized Linear Model Family</p></a></li>
<li><a href='#elda'><p>Extreme Limiting Dilution Analysis</p></a></li>
<li><a href='#expectedDeviance'><p>Expected Value of Scaled Unit Deviance for Linear Exponential Families</p></a></li>
<li><a href='#fitNBP'><p>Negative Binomial Model for SAGE Libraries with Pearson Estimation of Dispersion</p></a></li>
<li><a href='#forward'><p>Forward Selection of Covariates for Multiple Regression</p></a></li>
<li><a href='#gauss.quad'><p>Gaussian Quadrature</p></a></li>
<li><a href='#gauss.quad.prob'><p>Gaussian Quadrature with Probability Distributions</p></a></li>
<li><a href='#glm.scoretest'><p>Score Test for Adding a Covariate to a GLM</p></a></li>
<li><a href='#glmgam.fit'><p>Fit Gamma Generalized Linear Model by Fisher Scoring with Identity Link</p></a></li>
<li><a href='#glmnb.fit'><p>Fit Negative Binomial Generalized Linear Model with Log-Link</p></a></li>
<li><a href='#growthcurve'><p>Compare Groups of Growth Curves</p></a></li>
<li><a href='#hommel.test'><p>Test Multiple Comparisons Using Hommel's Method</p></a></li>
<li><a href='#invgauss'><p>Inverse Gaussian Distribution</p></a></li>
<li><a href='#logmdigamma'><p>Log Minus Digamma Function</p></a></li>
<li><a href='#matvec'><p>Multiply a Matrix by a Vector</p></a></li>
<li><a href='#meanT'><p>Mean t-Statistic Between Two Groups of Growth Curves</p></a></li>
<li><a href='#mixedModel2'><p>Fit Mixed Linear Model with 2 Error Components</p></a></li>
<li><a href='#mscale'><p>M Scale Estimation</p></a></li>
<li><a href='#permp'><p>Exact permutation p-values</p></a></li>
<li><a href='#plot.limdil'><p>Plot or print an object of class limdil</p></a></li>
<li><a href='#power.fisher.test'><p>Power of Fisher's Exact Test for Comparing Proportions</p></a></li>
<li><a href='#qresiduals'><p>Randomized Quantile Residuals</p></a></li>
<li><a href='#remlscore'><p>REML for Heteroscedastic Regression</p></a></li>
<li><a href='#remlscoregamma'><p>Approximate REML for Gamma Regression with Structured Dispersion</p></a></li>
<li><a href='#sage.test'><p>Exact Binomial Tests For Comparing Two SAGE Libraries (Obsolete)</p></a></li>
<li><a href='#statmod-package'><p>Introduction to the StatMod Package</p></a></li>
<li><a href='#tweedie'><p>Tweedie Generalized Linear Models</p></a></li>
<li><a href='#welding'><p>Data: Tensile Strength of Welds</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-12-28</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Modeling</td>
</tr>
<tr>
<td>Author:</td>
<td>Gordon Smyth [cre, aut], Lizhong Chen [aut], Yifang Hu [ctb], Peter Dunn [ctb], Belinda Phipson [ctb], Yunshun Chen [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gordon Smyth &lt;smyth@wehi.edu.au&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, tweedie</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of algorithms and functions to aid statistical modeling. Includes limiting dilution analysis (aka ELDA), growth curve comparisons, mixed linear models, heteroscedastic regression, inverse-Gaussian probability calculations, Gauss quadrature and a secure convergence algorithm for nonlinear models. Also includes advanced generalized linear model functions including Tweedie and Digamma distributional families, secure convergence and exact distributional calculations for unit deviances.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-28 00:45:50 UTC; smyth</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-06 10:00:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='Digamma'>Digamma Generalized Linear Model Family</h2><span id='topic+Digamma'></span><span id='topic+canonic.digamma'></span><span id='topic+d2cumulant.digamma'></span><span id='topic+unitdeviance.digamma'></span><span id='topic+cumulant.digamma'></span><span id='topic+meanval.digamma'></span><span id='topic+varfun.digamma'></span>

<h3>Description</h3>

<p>Produces a Digamma generalized linear model family object. The Digamma distribution is the
distribution of the unit deviance for a gamma response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Digamma(link = "log")
unitdeviance.digamma(y, mu)
cumulant.digamma(theta)
meanval.digamma(theta)
d2cumulant.digamma(theta)
varfun.digamma(mu)
canonic.digamma(mu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Digamma_+3A_link">link</code></td>
<td>
<p>character string, number or expressing specifying the link function. See <code>quasi</code> for specification of this argument.</p>
</td></tr>
<tr><td><code id="Digamma_+3A_y">y</code></td>
<td>
<p>numeric vector of (positive) response values</p>
</td></tr>
<tr><td><code id="Digamma_+3A_mu">mu</code></td>
<td>
<p>numeric vector of (positive) fitted values</p>
</td></tr>
<tr><td><code id="Digamma_+3A_theta">theta</code></td>
<td>
<p>numeric vector of values of the canonical variable, equal to <code class="reqn">-1/\phi</code> where <code class="reqn">\phi</code> is the dispersion parameter of the gamma distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This family is useful for dispersion modelling with gamma generalized linear models.
The Digamma distribution describes the distribution of the unit deviances for a gamma family, in the same way that the gamma distribution itself describes the distribution of the unit deviances for Gaussian or inverse Gaussian families.
The Digamma distribution is so named because it is dual to the gamma distribution in the above sense, and because the <code>digamma function</code> appears in its mean function.
</p>
<p>Suppose that <code class="reqn">y</code> follows a gamma distribution with mean <code class="reqn">\mu</code> and dispersion parameter <code class="reqn">\phi</code>, so the variance of <code class="reqn">y</code> is <code class="reqn">\phi \mu^2</code>.
Write <code class="reqn">d(y,\mu)</code> for the gamma distribution unit deviance.
Then <code>meanval.digamma(-1/phi)</code> gives the mean of <code class="reqn">d(y,\mu)</code> and <code>2*d2cumulant.digamma(-1/phi)</code> gives the variance.
</p>


<h3>Value</h3>

<p><code>Digamma</code> produces a glm family object, which is a list of functions and expressions used by <code>glm</code> in its iteratively reweighted least-squares algorithm. See <code>family</code> for details.
</p>
<p>The other functions take vector arguments and produce vector values of the same length and called by <code>Digamma</code>.
<code>unitdeviance.digamma</code> gives the unit deviances of the family, equal to the squared deviance residuals.
<code>cumulant.digamma</code> is the cumulant function.  If the dispersion is unity, then successive derivatives of the cumulant function give successive cumulants of the Digamma distribution.  <code>meanvalue.digamma</code> gives the first derivative, which is the expected value.
<code>d2cumulant.digamma</code> gives the second derivative, which is the variance.
<code>canonic.digamma</code> is the inverse of <code>meanvalue.digamma</code> and gives the canonical parameter as a function of the mean parameter.
<code>varfun.digamma</code> is the variance function of the Digamma family, the variance as a function of the mean.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Smyth, G. K. (1989). Generalized linear models with varying dispersion. <em>J. R. Statist. Soc. B</em>, <b>51</b>, 47-61.
<a href="https://doi.org/10.1111/j.2517-6161.1989.tb01747.x">doi:10.1111/j.2517-6161.1989.tb01747.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quasi">quasi</a></code>, <code><a href="stats.html#topic+make.link">make.link</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Test for log-linear dispersion trend in gamma regression
y &lt;- rchisq(20,df=1)
x &lt;- 1:20
out.gam &lt;- glm(y~x,family=Gamma(link="log"))
d &lt;- residuals(out.gam)^2
out.dig &lt;- glm(d~x,family=Digamma(link="log"))
summary(out.dig,dispersion=2)
</code></pre>

<hr>
<h2 id='elda'>Extreme Limiting Dilution Analysis</h2><span id='topic+elda'></span><span id='topic+limdil'></span><span id='topic+eldaOneGroup'></span><span id='topic+limdil.class'></span><span id='topic+limdil-class'></span>

<h3>Description</h3>

<p>Fit single-hit model to a dilution series using complementary log-log binomial regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elda(response, dose, tested=rep(1,length(response)), group=rep(1,length(response)),
     observed=FALSE, confidence=0.95, test.unit.slope=FALSE)
limdil(response, dose, tested=rep(1,length(response)), group=rep(1,length(response)),
     observed=FALSE, confidence=0.95, test.unit.slope=FALSE)
eldaOneGroup(response, dose, tested, observed=FALSE, confidence=0.95,
     tol=1e-8, maxit=100, trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elda_+3A_response">response</code></td>
<td>
<p>numeric vector giving number of positive cases out of <code>tested</code> trials. Should take non-negative integer values.</p>
</td></tr>
<tr><td><code id="elda_+3A_dose">dose</code></td>
<td>
<p>numeric vector of expected number of cells in assay. Values must be positive.</p>
</td></tr>
<tr><td><code id="elda_+3A_tested">tested</code></td>
<td>
<p>numeric vector giving number of trials at each dose. Should take integer values.</p>
</td></tr>
<tr><td><code id="elda_+3A_group">group</code></td>
<td>
<p>vector or factor giving group to which the response belongs.</p>
</td></tr>
<tr><td><code id="elda_+3A_observed">observed</code></td>
<td>
<p>logical, is the actual number of cells observed?</p>
</td></tr>
<tr><td><code id="elda_+3A_confidence">confidence</code></td>
<td>
<p>numeric level for confidence interval. Should be strictly between 0 and 1.</p>
</td></tr>
<tr><td><code id="elda_+3A_test.unit.slope">test.unit.slope</code></td>
<td>
<p>logical, should the adequacy of the single-hit model be tested?</p>
</td></tr>
<tr><td><code id="elda_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance.</p>
</td></tr>
<tr><td><code id="elda_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of Newton iterations to perform.</p>
</td></tr>
<tr><td><code id="elda_+3A_trace">trace</code></td>
<td>
<p>logical, if <code>TRUE</code> then iterim results are output at each iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>elda</code> and <code>limdil</code> are alternative names for the same function.
(<code>limdil</code> was the older name before the 2009 paper by Hu and Smyth.)
<code>eldaOneGroup</code> is a lower-level function that does the computations when there is just one group, using a globally convergent Newton iteration.
It is called by the other functions.
</p>
<p>These functions implement maximum likelihood analysis of limiting dilution data using methods proposed by Hu and Smyth (2009).
The functions gracefully accommodate situations where 0% or 100% of the assays give positive results, which is why we call it &quot;extreme&quot; limiting dilution analysis.
The functions provide the ability to test for differences in stem cell frequencies between groups, and to test goodness of fit in a number of ways.
The methodology has been applied to the analysis of stem cell assays (Shackleton et al, 2006).
</p>
<p>The statistical method is explained by Hu and Smyth (2009).
A binomial generalized linear model is fitted for each group with cloglog link and offset <code>log(dose)</code>.
If <code>observed=FALSE</code>, a classic Poisson single-hit model is assumed, and the Poisson frequency of the stem cells is the <code>exp</code> of the intercept.
If <code>observed=TRUE</code>, the values of <code>dose</code> are treated as actual cell numbers rather than expected values.
This doesn't change the generalized linear model fit, but it does change how the frequencies are extracted from the estimated model coefficient (Hu and Smyth, 2009).
</p>
<p>The confidence interval is a Wald confidence interval, unless the responses are all negative or all positive, in which case Clopper-Pearson intervals are computed.
</p>
<p>If <code>group</code> takes several values, then separate confidence intervals are computed for each group.
In this case a likelihood ratio test is conducted for differences in active cell frequencies between the groups.
</p>
<p>These functions compute a number of different tests of goodness of fit.
One test is based on the coefficient for <code>log(dose)</code> in the generalized linear model.
The nominal slope is 1.
A slope greater than one suggests a multi-hit model in which two or more cells are synergistically required to produce a positive response.
A slope less than 1 suggests some sort of cell interference.
Slopes less than 1 can also be due to heterogeneity of the stem cell frequency between assays.
<code>elda</code> conducts likelihood ratio and score tests that the slope is equal to one.
</p>
<p>Another test is based on the coefficient for <code>dose</code>.
This idea is motivated by a suggestion of Gart and Weiss (1967), who suggest that heterogeneity effects are more likely to be linear in <code>dose</code> than <code>log(dose)</code>.
These functions conducts score tests that the coefficient for <code>dose</code> is non-zero.
Negative values for this test suggest heterogeneity.
</p>
<p>These functions produce objects of class <code>"limdil"</code>.
There are <code><a href="#topic+print.limdil">print</a></code> and <code><a href="#topic+plot.limdil">plot</a></code> methods for <code>"limdil"</code> objects.
</p>


<h3>Value</h3>

<p><code>elda</code> and <code>limdil</code> produce an object of class <code>"limdil"</code>.  This is a list with the following components:
</p>
<table>
<tr><td><code>CI</code></td>
<td>
<p>numeric matrix giving estimated stem cell frequency and lower and upper limits of Wald confidence interval for each group</p>
</td></tr>
<tr><td><code>test.difference</code></td>
<td>
<p>numeric vector giving chisquare likelihood ratio test statistic and p-value for testing the difference between groups</p>
</td></tr>
<tr><td><code>test.slope.wald</code></td>
<td>
<p>numeric vector giving wald test statistics and p-value for testing the slope of the offset equal to one</p>
</td></tr>
<tr><td><code>test.slope.lr</code></td>
<td>
<p>numeric vector giving chisquare likelihood ratio test statistics and p-value for testing the slope of the offset equal to one</p>
</td></tr>
<tr><td><code>test.slope.score.logdose</code></td>
<td>
<p>numeric vector giving score test statistics and p-value for testing multi-hit alternatives</p>
</td></tr>
<tr><td><code>test.slope.score.dose</code></td>
<td>
<p>numeric vector giving score test statistics and p-value for testing heterogeneity</p>
</td></tr>
<tr><td><code>response</code></td>
<td>
<p>numeric of integer counts of positive cases, out of <code>tested</code> trials</p>
</td></tr>
<tr><td><code>tested</code></td>
<td>
<p>numeric vector giving number of trials at each dose</p>
</td></tr>
<tr><td><code>dose</code></td>
<td>
<p>numeric vector of expected number of cells in assay</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>vector or factor giving group to which the response belongs</p>
</td></tr>
<tr><td><code>num.group</code></td>
<td>
<p>number of groups</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yifang Hu and Gordon Smyth</p>


<h3>References</h3>

<p>Hu, Y, and Smyth, GK (2009).
ELDA: Extreme limiting dilution analysis for comparing depleted and enriched populations in stem cell and other assays.
<em>Journal of Immunological Methods</em> 347, 70-78.
<a href="https://doi.org/10.1016/j.jim.2009.06.008">doi:10.1016/j.jim.2009.06.008</a>
<a href="http://www.statsci.org/smyth/pubs/ELDAPreprint.pdf">http://www.statsci.org/smyth/pubs/ELDAPreprint.pdf</a>
</p>
<p>Shackleton, M., Vaillant, F., Simpson, K. J., Stingl, J., Smyth, G. K., Asselin-Labat, M.-L., Wu, L., Lindeman, G. J., and Visvader, J. E. (2006).
Generation of a functional mammary gland from a single stem cell.
<em>Nature</em> 439, 84-88.
<a href="https://doi.org/10.1038/nature04372">doi:10.1038/nature04372</a>
</p>
<p>Gart, JJ, and Weiss, GH (1967).
Graphically oriented tests for host variability in dilution experiments.
<em>Biometrics</em> 23, 269-284.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.limdil">plot.limdil</a></code> and <code><a href="#topic+print.limdil">print.limdil</a></code> are methods for <code>limdil</code> class objects.
</p>
<p>A web interface to this function is available at <a href="https://bioinf.wehi.edu.au/software/elda/">https://bioinf.wehi.edu.au/software/elda/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># When there is one group
Dose &lt;- c(50,100,200,400,800)
Responses &lt;- c(2,6,9,15,21)
Tested &lt;- c(24,24,24,24,24)
out &lt;- elda(Responses,Dose,Tested,test.unit.slope=TRUE)
out
plot(out)

# When there are four groups
Dose &lt;- c(30000,20000,4000,500,30000,20000,4000,500,30000,20000,4000,500,30000,20000,4000,500)
Responses &lt;- c(2,3,2,1,6,5,6,1,2,3,4,2,6,6,6,1)
Tested &lt;- c(6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6)
Group &lt;- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4)
elda(Responses,Dose,Tested,Group,test.unit.slope=TRUE)
</code></pre>

<hr>
<h2 id='expectedDeviance'>Expected Value of Scaled Unit Deviance for Linear Exponential Families</h2><span id='topic+expectedDeviance'></span>

<h3>Description</h3>

<p>Expected value and variance of the scaled unit deviance for common generalized linear model families.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectedDeviance(mu, family="binomial", binom.size, nbinom.size, gamma.shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expectedDeviance_+3A_mu">mu</code></td>
<td>
<p>numeric vector or matrix giving mean of response variable.</p>
</td></tr>
<tr><td><code id="expectedDeviance_+3A_family">family</code></td>
<td>
<p>character string indicating the linear exponential family. Possible values are <code>"binomial"</code>,<code>"gaussian"</code>, <code>"Gamma"</code>, <code>"inverse.gaussian"</code>, <code>"poisson"</code> or <code>"negative.binomial"</code>.</p>
</td></tr>
<tr><td><code id="expectedDeviance_+3A_binom.size">binom.size</code></td>
<td>
<p>integer vector giving the number of binomial trials when <code>family = "binomial"</code>. Equivalent to the <code>"size"</code> argument of <code>pbinom</code>.</p>
</td></tr>
<tr><td><code id="expectedDeviance_+3A_nbinom.size">nbinom.size</code></td>
<td>
<p>numeric vector giving the negative binomial size parameter when <code>family = "negative.binomial"</code>, such that the variance of the response variable is <code>mu + mu^2 / nbinom.size</code>. Equivalent to the <code>"size"</code> parameter of <code>pnbinom</code>.</p>
</td></tr>
<tr><td><code id="expectedDeviance_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>numeric vector giving the gamma shape parameter when <code>family = "Gamma"</code>, such that the variance of the response variable is <code>mu^2 / gamma.shape</code>. Equivalent to the <code>"shape"</code> parameter of <code>pgamma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a generalized linear model (GLM), the scaled unit deviances can be computed using <code>d &lt;- f$dev.resids(y, mu, wt=1/phi)</code> where <code>f</code> is the GLM family object, <code>y</code> is the response variable, <code>mu</code> is the vector of means and <code>phi</code> is the vector of GLM dispersions (incorporating any prior weights).
</p>
<p>The scaled unit deviances are often treated as being chiquare distributed on 1 df, so the mean should be 1 and the variance should be 2.
This distribution result only holds however when the saddlepoint approximation is accurate for the response variable distribution (Dunn and Smyth, 2018).
In other cases, the expected value and variance of the unit deviances can be far from the nominal values.
The <code>expectedDeviance</code> function returns the exact mean and variance of the unit deviance for the usual GLM familes assuming that <code>mu</code> is the true mean and <code>phi</code> is the true dispersion.
</p>
<p>When <code>family</code> is <code>"poisson"</code>, <code>"binomial"</code> or <code>"negative.binomial"</code>, the expected values and variances are computed using Chebyshev polynomial approximations.
When <code>family = "Gamma"</code>, the function uses exact formulas derived by Smyth (1989).
</p>


<h3>Value</h3>

<p>A list with the components
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>expected values</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>
<p>variances</p>
</td></tr>
</table>
<p>both of which have the same length and dimensions as the input <code>mu</code>.
</p>


<h3>Author(s)</h3>

<p>Lizong Chen and Gordon Smyth</p>


<h3>References</h3>

<p>Dunn PK, Smyth GK (2018).
<em>Generalized linear models with examples in R</em>.
Springer, New York, NY.
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
</p>
<p>Smyth, G. K. (1989).
Generalized linear models with varying dispersion.
<em>J. R. Statist. Soc. B</em>, <b>51</b>, 47-61.
<a href="https://doi.org/10.1111/j.2517-6161.1989.tb01747.x">doi:10.1111/j.2517-6161.1989.tb01747.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+family">family</a></code>, <code><a href="#topic+meanval.digamma">meanval.digamma</a></code>, <code><a href="#topic+d2cumulant.digamma">d2cumulant.digamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Poisson example
lambda &lt;- 3
nsim &lt;- 1e4
y &lt;- rpois(nsim, lambda=lambda)
d &lt;- poisson()$dev.resids(y=y, mu=rep(lambda,nsim), wt=1)
c(mean=mean(d), variance=var(d))
unlist(expectedDeviance(mu=lambda, family="poisson"))

# binomial example
n &lt;- 10
p &lt;- 0.01
y &lt;- rbinom(nsim, prob=p, size=n)
d &lt;- binomial()$dev.resids(y=y/n, mu=rep(p,nsim), wt=n)
c(mean=mean(d), variance=var(d))
unlist(expectedDeviance(mu=p, family="binomial", binom.size=n))

# gamma example
alpha &lt;- 5
beta &lt;- 2
y &lt;- beta * rgamma(1e4, shape=alpha)
d &lt;- Gamma()$dev.resids(y=y, mu=rep(alpha*beta,n), wt=alpha)
c(mean=mean(d), variance=var(d))
unlist(expectedDeviance(mu=alpha*beta, family="Gamma", gamma.shape=alpha))

# negative binomial example
library(MASS)
mu &lt;- 10
phi &lt;- 0.2
y &lt;- rnbinom(nsim, mu=mu, size=1/phi)
f &lt;- MASS::negative.binomial(theta=1/phi)
d &lt;- f$dev.resids(y=y, mu=rep(mu,nsim), wt=1)
c(mean=mean(d), variance=var(d))
unlist(expectedDeviance(mu=mu, family="negative.binomial", nbinom.size=1/phi))

# binomial expected deviance tends to zero for p small:
p &lt;- seq(from=0.001,to=0.11,len=200)
ed &lt;- expectedDeviance(mu=p,family="binomial",binom.size=10)
plot(p,ed$mean,type="l")
</code></pre>

<hr>
<h2 id='fitNBP'>Negative Binomial Model for SAGE Libraries with Pearson Estimation of Dispersion</h2><span id='topic+fitNBP'></span>

<h3>Description</h3>

<p>Fit a multi-group negative-binomial model to SAGE data, with Pearson estimation of the common overdispersion parameter. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitNBP(y, group=NULL, lib.size=colSums(y), tol=1e-5, maxit=40, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitNBP_+3A_y">y</code></td>
<td>
<p>numeric matrix giving counts. Rows correspond to tags (genes) and columns to SAGE libraries.</p>
</td></tr>
<tr><td><code id="fitNBP_+3A_group">group</code></td>
<td>
<p>factor indicating which library belongs to each group. If <code>NULL</code> then one group is assumed.</p>
</td></tr>
<tr><td><code id="fitNBP_+3A_lib.size">lib.size</code></td>
<td>
<p>vector giving total number of tags in each library.</p>
</td></tr>
<tr><td><code id="fitNBP_+3A_tol">tol</code></td>
<td>
<p>small positive numeric tolerance to judge convergence</p>
</td></tr>
<tr><td><code id="fitNBP_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations permitted</p>
</td></tr>
<tr><td><code id="fitNBP_+3A_verbose">verbose</code></td>
<td>
<p>logical, if <code>TRUE</code> then iteration progress information is output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The overdispersion parameter is estimated equating the Pearson goodness of fit to its expectation.
The variance is assumed to be of the form
Var(y)=mu*(1+phi*mu)
where E(y)=mu and phi is the dispersion parameter.
All tags are assumed to share the same dispersion.
</p>
<p>For given dispersion, the model for each tag is a negative-binomial generalized linear model with log-link and <code>log(lib.size)</code> as offset.
The coefficient parametrization used is that corresponding to the formula <code>~0+group+offset(log(lib.size)</code>.
</p>
<p>Except for the dispersion being common rather than genewise, the model fitted by this function is equivalent to that proposed by Lu et al (2005).
The numeric algorithm used is that of alternating iterations (Smyth, 1996) using Newton's method as the outer iteration for the dispersion parameter starting at phi=0.
This iteration is monotonically convergent for the dispersion.
</p>


<h3>Value</h3>

<p>List with components
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric matrix of rates for each tag (gene) and each group</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>numeric matrix of fitted values</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>estimated dispersion parameter</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function has been made obsolete by the <a href="https://doi.org/doi:10.18129/B9.bioc.edgeR">edgeR</a> package on Bioconductor.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Lu, J, Tomfohr, JK, Kepler, TB (2005).
Identifying differential expression in multiple SAGE libraries: an overdispersed log-linear model approach.
<em>BMC Bioinformatics</em> 6,165.
</p>
<p>Smyth, G. K. (1996).
Partitioned algorithms for maximum likelihood and other nonlinear estimation.
<em>Statistics and Computing</em>, 6, 201-216.
<a href="https://doi.org/10.1007/BF00140865">doi:10.1007/BF00140865</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sage.test">sage.test</a></code>
</p>
<p>The edgeR package on Biconductor provides new and better functions to fit negative-binomial glms to SAGE or RNA-seq data.
See particularly the <code>glmFit</code> and <code>mglmOneWay</code> functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># True value for dispersion is 1/size=2/3
# Note the Pearson method tends to under-estimate the dispersion
y &lt;- matrix(rnbinom(10*4,mu=4,size=1.5),10,4)
lib.size &lt;- rep(50000,4)
group &lt;- c(1,1,2,2)
fit &lt;- fitNBP(y,group=group,lib.size=lib.size)
logratio &lt;- fit$coef %*% c(-1,1)
</code></pre>

<hr>
<h2 id='forward'>Forward Selection of Covariates for Multiple Regression</h2><span id='topic+forward'></span>

<h3>Description</h3>

<p>Fit a multi-group negative-binomial model to SAGE data, with Pearson estimation of the common overdispersion parameter. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward(y, x, xkept=NULL, intercept=TRUE, nvar=ncol(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_+3A_y">y</code></td>
<td>
<p>numeric response vector.</p>
</td></tr>
<tr><td><code id="forward_+3A_x">x</code></td>
<td>
<p>numeric matrix of covariates, candidates to be added to the regression.</p>
</td></tr>
<tr><td><code id="forward_+3A_xkept">xkept</code></td>
<td>
<p>numeric matrix of covariates to be included in the starting regression.</p>
</td></tr>
<tr><td><code id="forward_+3A_intercept">intercept</code></td>
<td>
<p>logical, should an intercept be added to <code>xkept</code>?</p>
</td></tr>
<tr><td><code id="forward_+3A_nvar">nvar</code></td>
<td>
<p>integer, number of covariates from <code>x</code> to add to the regression.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has the advantage that <code>x</code> can have many more columns than the length of <code>y</code>.
</p>


<h3>Value</h3>

<p>Integer vector of length <code>nvar</code>, giving the order in which columns of <code>x</code> are added to the regression.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+step">step</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(10)
x &lt;- matrix(rnorm(10*5),10,5)
forward(y,x)
</code></pre>

<hr>
<h2 id='gauss.quad'>Gaussian Quadrature</h2><span id='topic+gauss.quad'></span>

<h3>Description</h3>

<p>Calculate nodes and weights for Gaussian quadrature.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss.quad(n, kind = "legendre", alpha = 0, beta = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gauss.quad_+3A_n">n</code></td>
<td>
<p>number of nodes and weights</p>
</td></tr>
<tr><td><code id="gauss.quad_+3A_kind">kind</code></td>
<td>
<p>kind of Gaussian quadrature, one of <code>"legendre"</code>, <code>"chebyshev1"</code>, <code>"chebyshev2"</code>, <code>"hermite"</code>, <code>"jacobi"</code> or <code>"laguerre"</code></p>
</td></tr>
<tr><td><code id="gauss.quad_+3A_alpha">alpha</code></td>
<td>
<p>parameter for Jacobi or Laguerre quadrature, must be greater than -1</p>
</td></tr>
<tr><td><code id="gauss.quad_+3A_beta">beta</code></td>
<td>
<p>parameter for Jacobi quadrature, must be greater than -1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The integral from <code>a</code> to <code>b</code> of <code>w(x)*f(x)</code> is approximated by <code>sum(w*f(x))</code> where <code>x</code> is the vector of nodes and <code>w</code> is the vector of weights.  The approximation is exact if <code>f(x)</code> is a polynomial of order no more than <code>2n-1</code>.
The possible choices for <code>w(x)</code>, <code>a</code> and <code>b</code> are as follows:
</p>
<p>Legendre quadrature: <code>w(x)=1</code> on <code>(-1,1)</code>.
</p>
<p>Chebyshev quadrature of the 1st kind: <code>w(x)=1/sqrt(1-x^2)</code> on <code>(-1,1)</code>.
</p>
<p>Chebyshev quadrature of the 2nd kind: <code>w(x)=sqrt(1-x^2)</code> on <code>(-1,1)</code>.
</p>
<p>Hermite quadrature: <code>w(x)=exp(-x^2)</code> on <code>(-Inf,Inf)</code>.
</p>
<p>Jacobi quadrature: <code>w(x)=(1-x)^alpha*(1+x)^beta</code> on <code>(-1,1)</code>. Note that Chebyshev quadrature is a special case of this.
</p>
<p>Laguerre quadrature: <code>w(x)=x^alpha*exp(-x)</code> on <code>(0,Inf)</code>.
</p>
<p>The algorithm used to generated the nodes and weights is explained in Golub and Welsch (1969).
</p>


<h3>Value</h3>

<p>A list containing the components
</p>
<table>
<tr><td><code>nodes</code></td>
<td>
<p>vector of values at which to evaluate the function</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>vector of weights to give the function values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth, using Netlib Fortran code <a href="https://netlib.org/go/gaussq.f">https://netlib.org/go/gaussq.f</a>, and including a suggestion from Stephane Laurent</p>


<h3>References</h3>

<p>Golub, G. H., and Welsch, J. H. (1969). Calculation of Gaussian
quadrature rules. <em>Mathematics of Computation</em> <b>23</b>, 221-230.
</p>
<p>Golub, G. H. (1973). Some modified matrix eigenvalue problems.
<em>Siam Review</em> <b>15</b>, 318-334.
</p>
<p>Smyth, G. K. (1998). Numerical integration.
In: <em>Encyclopedia of Biostatistics</em>, P. Armitage and T. Colton (eds.), Wiley, London, pages 3088-3095.
<a href="http://www.statsci.org/smyth/pubs/NumericalIntegration-Preprint.pdf">http://www.statsci.org/smyth/pubs/NumericalIntegration-Preprint.pdf</a>
</p>
<p>Smyth, G. K. (1998). Polynomial approximation.
In: <em>Encyclopedia of Biostatistics</em>, P. Armitage and T. Colton (eds.), Wiley, London, pages 3425-3429.
<a href="http://www.statsci.org/smyth/pubs/PolyApprox-Preprint.pdf">http://www.statsci.org/smyth/pubs/PolyApprox-Preprint.pdf</a>
</p>
<p>Stroud, AH, and Secrest, D (1966). <em>Gaussian Quadrature Formulas</em>. Prentice-Hall, Englewood Cliffs, N.J.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gauss.quad.prob">gauss.quad.prob</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  mean of gamma distribution with alpha=6
out &lt;- gauss.quad(10,"laguerre",alpha=5)
sum(out$weights * out$nodes) / gamma(6)
</code></pre>

<hr>
<h2 id='gauss.quad.prob'>Gaussian Quadrature with Probability Distributions</h2><span id='topic+gauss.quad.prob'></span>

<h3>Description</h3>

<p>Calculate nodes and weights for Gaussian quadrature in terms of probability distributions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss.quad.prob(n, dist = "uniform", l = 0, u = 1,
                mu = 0, sigma = 1, alpha = 1, beta = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gauss.quad.prob_+3A_n">n</code></td>
<td>
<p>number of nodes and weights</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_dist">dist</code></td>
<td>
<p>distribution that Gaussian quadrature is based on, one of <code>"uniform"</code>, <code>"normal"</code>, <code>"beta"</code> or <code>"gamma"</code></p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_l">l</code></td>
<td>
<p>lower limit of uniform distribution</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_u">u</code></td>
<td>
<p>upper limit of uniform distribution</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_mu">mu</code></td>
<td>
<p>mean of normal distribution</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_sigma">sigma</code></td>
<td>
<p>standard deviation of normal distribution</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_alpha">alpha</code></td>
<td>
<p>positive shape parameter for gamma distribution or first shape parameter for beta distribution</p>
</td></tr>
<tr><td><code id="gauss.quad.prob_+3A_beta">beta</code></td>
<td>
<p>positive scale parameter for gamma distribution or second shape parameter for beta distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a rewriting and simplification of <code>gauss.quad</code> in terms of probability distributions.
The probability interpretation is explained by Smyth (1998).
For details on the underlying quadrature rules, see <code><a href="#topic+gauss.quad">gauss.quad</a></code>.
</p>
<p>The expected value of <code>f(X)</code> is approximated by <code>sum(w*f(x))</code> where <code>x</code> is the vector of nodes and <code>w</code> is the vector of weights.  The approximation is exact if <code>f(x)</code> is a polynomial of order no more than <code>2n-1</code>.
The possible choices for the distribution of <code>X</code> are as follows:
</p>
<p>Uniform on <code>(l,u)</code>.
</p>
<p>Normal with mean <code>mu</code> and standard deviation <code>sigma</code>.
</p>
<p>Beta with density <code>x^(alpha-1)*(1-x)^(beta-1)/B(alpha,beta)</code> on <code>(0,1)</code>.
</p>
<p>Gamma with density <code>x^(alpha-1)*exp(-x/beta)/beta^alpha/gamma(alpha)</code>.
</p>


<h3>Value</h3>

<p>A list containing the components
</p>
<table>
<tr><td><code>nodes</code></td>
<td>
<p>vector of values at which to evaluate the function</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>vector of weights to give the function values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth, using Netlib Fortran code <a href="https://netlib.org/go/gaussq.f">https://netlib.org/go/gaussq.f</a>, and including corrections suggested by Spencer Graves</p>


<h3>References</h3>

<p>Smyth, G. K. (1998). Polynomial approximation.
In: <em>Encyclopedia of Biostatistics</em>, P. Armitage and T. Colton (eds.), Wiley, London, pages 3425-3429.
<a href="http://www.statsci.org/smyth/pubs/PolyApprox-Preprint.pdf">http://www.statsci.org/smyth/pubs/PolyApprox-Preprint.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gauss.quad">gauss.quad</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  the 4th moment of the standard normal is 3
out &lt;- gauss.quad.prob(10,"normal")
sum(out$weights * out$nodes^4)

#  the expected value of log(X) where X is gamma is digamma(alpha)
out &lt;- gauss.quad.prob(32,"gamma",alpha=5)
sum(out$weights * log(out$nodes))
</code></pre>

<hr>
<h2 id='glm.scoretest'>Score Test for Adding a Covariate to a GLM</h2><span id='topic+glm.scoretest'></span>

<h3>Description</h3>

<p>Computes score test statistics (z-statistics) for adding covariates to a generalized linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.scoretest(fit, x2, dispersion=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.scoretest_+3A_fit">fit</code></td>
<td>
<p>generalized linear model fit object, of class <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="glm.scoretest_+3A_x2">x2</code></td>
<td>
<p>vector or matrix with each column a covariate to be added.</p>
</td></tr>
<tr><td><code id="glm.scoretest_+3A_dispersion">dispersion</code></td>
<td>
<p>the dispersion for the generalized linear model family.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rao's score test is a type of asymptotic test that is an alternative to Wald tests or likelihood ratio tests (LRTs) (Dunn and Smyth, 2018).
Wald tests are computed by dividing parameter estimates by their standard errors.
LRTs are computed from differences in the log-likihoods between the null and alternative hypotheses.
Score tests are computed from log-likelihood derivatives.
All three types of tests (Wald, score and LRT) are asymptotically equivalent under ideal circumstances, but the score and LRT tests are invariant under-reparametrization whereas Wald tests are not.
</p>
<p>One of the main differences between the tests is the need for estimation of parameters under the null and alternative hypotheses.
Wald tests require maximum likelihood estimates (MLEs) to be computed only under the alternative hypothesis, LRT tests require both the null and alternative models to be fitted, while score tests require only the null hypothesis to be fitted.
</p>
<p>When a generalized linear model (GLM) is fitted in R using the <code>glm</code> function, the <code>summary()</code> function presents Wald tests for all the coefficients in the linear model while <code>anova()</code> is able to compute likelihood ratio tests.
GLM output in R has historically not included score tests, although score tests can be a very computationally coefficient choice when one wants to test for many potential additional covariates being added to a relatively simple null model.
</p>
<p>A number of well known Pearson chisquare statistics, including goodness of fit statistics and the Pearson test for independence in a contingency table can be derived as score tests (Smyth, 2003; Dunn and Smyth, 2018).
</p>
<p>This function computes score test statistics for adding a single numerical covariate to a GLM, given the <code>glm</code> output for the null model.
It makes very efficient use of the quantities already stored in the GLM fit object.
A computational formula for the score test statistics is given in Section 7.2.6 of Dunn and Smyth (2018).
</p>
<p>The dispersion parameter is treated as for <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>.
If <code>NULL</code>, the Pearson estimator is used, except for the binomial, Poisson and negative binomial
families, for which the dispersion is one.
</p>
<p>Note that the <code>anova.glm</code> function in the stats package has offered a Rao score test option since 2011, but it requires model fits under the alternative as well as the null hypothesis, which does not take advantage of the computational advantage of score test.
The <code>glm.scoretest</code> is more efficient as it does not require a full model fit.
On the other hand, <code>anova.glm</code> can compute score tests for factors and multiple covariates, which <code>glm.scoretest</code> does not currently do.
</p>


<h3>Value</h3>

<p>numeric vector containing the z-statistics, one for each covariate.
The z-statistics can be treated as standard normal under the null hypothesis.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Dunn, PK, and Smyth, GK (2018). <em>Generalized linear models with examples in R</em>. Springer, New York, NY. 
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
</p>
<p>Lovison, G (2005). On Rao score and Pearson X^2 statistics in generalized linear models.
<em>Statistical Papers</em>, 46, 555-574.
</p>
<p>Pregibon, D (1982). Score tests in GLIM with applications.
In <em>GLIM82: Proceedings of the International Conference on Generalized Linear Models</em>,
R Gilchrist (ed.), Lecture Notes in Statistics, Volume 14, Springer, New York, pages 87-97. 
</p>
<p>Smyth, G. K. (2003). Pearson's goodness of fit statistic as a score test statistic. In: <em>Science and Statistics: A Festschrift for Terry Speed</em>, D. R. Goldstein (ed.), IMS Lecture Notes - Monograph Series, Volume 40, Institute of Mathematical Statistics, Beachwood, Ohio, pages 115-126.
<a href="http://www.statsci.org/smyth/pubs/goodness.pdf">http://www.statsci.org/smyth/pubs/goodness.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+add1">add1</a></code>, <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Pearson's chisquare test for independence
#  in a contingency table is a score test.

#  First the usual test

y &lt;- c(20,40,40,30)
chisq.test(matrix(y,2,2), correct=FALSE)

#  Now same test using glm.scoretest

a &lt;- gl(2,1,4)
b &lt;- gl(2,2,4)
fit &lt;- glm(y~a+b, family=poisson)
x2 &lt;- c(0,0,0,1)
z &lt;- glm.scoretest(fit, x2)
z^2
</code></pre>

<hr>
<h2 id='glmgam.fit'>Fit Gamma Generalized Linear Model by Fisher Scoring with Identity Link</h2><span id='topic+glmgam.fit'></span>

<h3>Description</h3>

<p>Fit a generalized linear model with secure convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmgam.fit(X, y, coef.start = NULL, tol = 1e-6, maxit = 50, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmgam.fit_+3A_x">X</code></td>
<td>
<p>design matrix, assumed to be of full column rank.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="glmgam.fit_+3A_y">y</code></td>
<td>
<p>numeric vector of responses. Negative or missing values not allowed.</p>
</td></tr>
<tr><td><code id="glmgam.fit_+3A_coef.start">coef.start</code></td>
<td>
<p>numeric vector of starting values for the regression coefficients</p>
</td></tr>
<tr><td><code id="glmgam.fit_+3A_tol">tol</code></td>
<td>
<p>small positive numeric value giving convergence tolerance</p>
</td></tr>
<tr><td><code id="glmgam.fit_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations allowed</p>
</td></tr>
<tr><td><code id="glmgam.fit_+3A_trace">trace</code></td>
<td>
<p>logical value. If <code>TRUE</code> then output diagnostic information at each iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements a modified Fisher scoring algorithm for generalized linear models, similar to the Levenberg-Marquardt algorithm for nonlinear least squares.
The Levenberg-Marquardt modification checks for a reduction in the deviance at each step, and avoids the possibility of divergence.
The result is a very secure algorithm that converges for almost all datasets.
</p>
<p><code>glmgam.fit</code> is in principle equivalent to <code>glm.fit(X,y,family=Gamma(link="identity"))</code> but with much more secure convergence.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric vector of regression coefficients</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>numeric vector of fitted values</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>residual deviance</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations used to convergence. If convergence was not achieved then <code>iter</code> is set to <code>maxit+1</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth and Yunshun Chen</p>


<h3>References</h3>

<p>Dunn, PK, and Smyth, GK (2018).
<em>Generalized linear models with examples in R</em>. Springer, New York, NY.
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
</p>


<h3>See Also</h3>

<p><code>glmgam.fit</code> is called by <code><a href="#topic+mixedModel2Fit">mixedModel2Fit</a></code>.
</p>
<p><code><a href="stats.html#topic+glm">glm</a></code> is the standard glm fitting function in the stats package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rgamma(10, shape=5)
X &lt;- cbind(1, 1:10)
fit &lt;- glmgam.fit(X, y, trace=TRUE)
</code></pre>

<hr>
<h2 id='glmnb.fit'>Fit Negative Binomial Generalized Linear Model with Log-Link</h2><span id='topic+glmnb.fit'></span>

<h3>Description</h3>

<p>Fit a generalized linear model with secure convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnb.fit(X, y, dispersion, weights = NULL, offset = 0, coef.start = NULL,
          start.method = "mean", tol = 1e-6, maxit = 50L, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnb.fit_+3A_x">X</code></td>
<td>
<p>design matrix, assumed to be of full column rank.  Missing values not allowed.</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_y">y</code></td>
<td>
<p>numeric vector of responses. Negative or missing values not allowed.</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_dispersion">dispersion</code></td>
<td>
<p>numeric vector of dispersion parameters for the negative binomial distribution. If of length 1, then the same dispersion is assumed for all observations.</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_weights">weights</code></td>
<td>
<p>numeric vector of positive weights, defaults to all one.</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_offset">offset</code></td>
<td>
<p>offset vector for linear model</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_coef.start">coef.start</code></td>
<td>
<p>numeric vector of starting values for the regression coefficients</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_start.method">start.method</code></td>
<td>
<p>method used to find starting values, possible values are <code>"mean"</code> or <code>"log(y)"</code></p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_tol">tol</code></td>
<td>
<p>small positive numeric value giving convergence tolerance</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations allowed</p>
</td></tr>
<tr><td><code id="glmnb.fit_+3A_trace">trace</code></td>
<td>
<p>logical value. If <code>TRUE</code> then output diagnostic information at each iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements a modified Fisher scoring algorithm for generalized linear models, analogous to the Levenberg-Marquardt algorithm for nonlinear least squares.
The Levenberg-Marquardt modification checks for a reduction in the deviance at each step, and avoids the possibility of divergence.
The result is a very secure algorithm that converges for almost all datasets.
</p>
<p><code>glmnb.fit</code> is in principle equivalent to <code>glm.fit(X,y,family=negative.binomial(link="log",theta=1/dispersion))</code> but with more secure convergence.
Here <code>negative.binomial</code> is a function in the MASS package.
</p>
<p>The <code>dispersion</code> parameter is the same as <code>1/theta</code> for the <code>MASS::negative.binomial</code> function or <code>1/size</code> for the <code>stats::rnbinom</code> function.
<code>dispersion=0</code> corresponds to the Poisson distribution.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric vector of regression coefficients</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>numeric vector of fitted values</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>residual deviance</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations used to convergence. If convergence was not achieved then <code>iter</code> is set to <code>maxit+1</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth and Yunshun Chen</p>


<h3>References</h3>

<p>Dunn, PK, and Smyth, GK (2018).
<em>Generalized linear models with examples in R</em>. Springer, New York, NY.
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
</p>


<h3>See Also</h3>

<p>The <code>glmFit</code> function in the edgeR package on Bioconductor is a high-performance version of <code>glmnb.fit</code> for many <code>y</code> vectors at once.
</p>
<p><code><a href="stats.html#topic+glm">glm</a></code> is the standard glm fitting function in the stats package.
<code>negative.binomial</code> in the MASS package defines a negative binomial family for use with <code>glm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnbinom(10, mu=1:10, size=5)
X &lt;- cbind(1, 1:10)
fit &lt;- glmnb.fit(X, y, dispersion=0.2, trace=TRUE)
</code></pre>

<hr>
<h2 id='growthcurve'>Compare Groups of Growth Curves</h2><span id='topic+compareGrowthCurves'></span><span id='topic+compareTwoGrowthCurves'></span><span id='topic+plotGrowthCurves'></span>

<h3>Description</h3>

<p>Do all pairwise comparisons between groups of growth curves using a permutation test. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareGrowthCurves(group, y, levels=NULL, nsim=100, fun=meanT, times=NULL,
                    verbose=TRUE, adjust="holm", n0=0.5)
compareTwoGrowthCurves(group, y, nsim=100, fun=meanT, n0=0.5)
plotGrowthCurves(group, y, levels=sort(unique(group)), times=NULL, col=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="growthcurve_+3A_group">group</code></td>
<td>
<p>vector or factor indicating group membership.  Missing values are allowed in <code>compareGrowthCurves</code> but not in <code>compareTwoGrowthCurves</code>.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_y">y</code></td>
<td>
<p>matrix of response values with rows for individuals and columns for times.  The number of rows must agree with the length of <code>group</code>. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_levels">levels</code></td>
<td>
<p>a character vector containing the identifiers of the groups to be compared.  By default all groups with two more more members will be compared.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_nsim">nsim</code></td>
<td>
<p>number of permutations to estimated p-values.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_fun">fun</code></td>
<td>
<p>a function defining the statistic used to measure the distance between two groups of growth curves.
Defaults to <code><a href="#topic+meanT">meanT</a></code>.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_times">times</code></td>
<td>
<p>a numeric vector containing the column numbers on which the groups should be compared.
By default all the columns are used.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_verbose">verbose</code></td>
<td>
<p>should progress results be printed?</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_adjust">adjust</code></td>
<td>
<p>method used to adjust for multiple testing, see <code>p.adjust</code>.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_n0">n0</code></td>
<td>
<p>offset used for numerator and denominator of p-value calculation.</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_col">col</code></td>
<td>
<p>vector of colors corresponding to distinct groups</p>
</td></tr>
<tr><td><code id="growthcurve_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code>plot()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>compareTwoGrowthCurves</code> performs a permutation test of the difference between two groups of growth curves.
<code>compareGrowthCurves</code> does all pairwise comparisons between two or more groups of growth curves.
</p>
<p>The permutation p-values are computed as p = (ngt + neq/2 + n0) / (nsim + n0) where ngt is the number of permutations with test statistics greater than observed, neq is the number of permuttation with test statistics equal to that observed, and n0 is an offset to avoid p-values of zero (Phipson &amp; Smyth 2010).
The offset n0 improves the type I error rate control and can be interpreted as allowing for the observed data as one of the permutations.
High resolution p-values can be obtained by setting <code>nsim</code> to some large value, <code>nsim=10000</code> say.
</p>


<h3>Value</h3>

<p><code>compareTwoGrowthCurves</code> returns a list with two components, <code>stat</code> and <code>p.value</code>, containing the observed statistics and the estimated p-value.  <code>compareGrowthCurves</code> returns a data frame with components
</p>
<table>
<tr><td><code>Group1</code></td>
<td>
<p>name of first group in a comparison</p>
</td></tr>
<tr><td><code>Group2</code></td>
<td>
<p>name of second group in a comparison</p>
</td></tr>
<tr><td><code>Stat</code></td>
<td>
<p>observed value of the statistic</p>
</td></tr>
<tr><td><code>P.Value</code></td>
<td>
<p>permutation p-value</p>
</td></tr>
<tr><td><code>adj.P.Value</code></td>
<td>
<p>p-value adjusted for multiple testing</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Elso, C. M., Roberts, L. J., Smyth, G. K., Thomson, R. J., Baldwin, T. M., 
Foote, S. J., and Handman, E. (2004). Leishmaniasis host response loci 
(lmr13) modify disease severity through a Th1/Th2-independent pathway.  
<em>Genes and Immunity</em> 5, 93-100.
</p>
<p>Baldwin, T., Sakthianandeswaren, A., Curtis, J., Kumar, B., Smyth, G. K., Foote, S., and Handman, E. (2007).
Wound healing response is a major contributor to the severity of cutaneous leishmaniasis in the ear model of infection.
<em>Parasite Immunology</em> 29, 501-513.
</p>
<p>Phipson B, Smyth GK (2010).
Permutation P-values should never be zero: calculating exact P-values when permutations are randomly drawn.
<em>Statistical Applications in Genetics and Molecular Biology</em>, Volume 9, Issue 1, Article 39.
<a href="https://doi.org/10.2202/1544-6115.1585">doi:10.2202/1544-6115.1585</a>,
<a href="https://doi.org/10.48550/arXiv.1603.05766">doi:10.48550/arXiv.1603.05766</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+meanT">meanT</a></code>, <code><a href="#topic+compareGrowthCurves">compareGrowthCurves</a></code>, <code><a href="#topic+compareTwoGrowthCurves">compareTwoGrowthCurves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A example with only one time
data(PlantGrowth)
compareGrowthCurves(PlantGrowth$group,as.matrix(PlantGrowth$weight))
# Can make p-values more accurate by nsim=10000
</code></pre>

<hr>
<h2 id='hommel.test'>Test Multiple Comparisons Using Hommel's Method</h2><span id='topic+hommel.test'></span>

<h3>Description</h3>

<p>Given a set of p-values and a test level, returns vector of test results for each hypothesis.</p>


<h3>Usage</h3>

<pre><code class='language-R'>hommel.test(p, alpha=0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hommel.test_+3A_p">p</code></td>
<td>
<p>numeric vector of p-values</p>
</td></tr>
<tr><td><code id="hommel.test_+3A_alpha">alpha</code></td>
<td>
<p>numeric value, desired significance level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the multiple testing procedure of Hommel (1988).
Hommel's method is also implemented as an adjusted p-value method in the function <code>p.adjust</code> but the accept/reject approach used here is faster.
</p>


<h3>Value</h3>

<p>logical vector indicating whether each hypothesis is accepted</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Hommel, G. (1988). A stagewise rejective multiple test procedure based on a modified Bonferroni test. <em>Biometrika</em>, <b>75</b>, 383-386.
</p>
<p>Shaffer, J. P. (1995). Multiple hypothesis testing. <em>Annual Review of Psychology</em> <b>46</b>, 561-576. (An excellent review of the area.)
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+p.adjust">p.adjust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- sort(runif(100))[1:10]
cbind(p,p.adjust(p,"hommel"),hommel.test(p))
</code></pre>

<hr>
<h2 id='invgauss'>Inverse Gaussian Distribution</h2><span id='topic+InverseGaussian'></span><span id='topic+dinvgauss'></span><span id='topic+pinvgauss'></span><span id='topic+qinvgauss'></span><span id='topic+rinvgauss'></span>

<h3>Description</h3>

<p>Density, cumulative probability, quantiles and random generation for the inverse Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinvgauss(x, mean=1, shape=NULL, dispersion=1, log=FALSE)
pinvgauss(q, mean=1, shape=NULL, dispersion=1, lower.tail=TRUE, log.p=FALSE)
qinvgauss(p, mean=1, shape=NULL, dispersion=1, lower.tail=TRUE, log.p=FALSE,
          maxit=200L, tol=1e-14, trace=FALSE)
rinvgauss(n, mean=1, shape=NULL, dispersion=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invgauss_+3A_x">x</code>, <code id="invgauss_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_n">n</code></td>
<td>
<p>sample size. If <code>length(n)</code> is larger than 1, then <code>length(n)</code> random values are returned.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_mean">mean</code></td>
<td>
<p>vector of (positive) means.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_shape">shape</code></td>
<td>
<p>vector of (positive) shape parameters.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_dispersion">dispersion</code></td>
<td>
<p>vector of (positive) dispersion parameters. Ignored if <code>shape</code> is not <code>NULL</code>, in which case <code>dispersion=1/shape</code>.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities are P(X&lt;q) otherwise P(X&gt;q).</p>
</td></tr>
<tr><td><code id="invgauss_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code>, the log-density is returned.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities are on the log-scale.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of Newton iterations used to find <code>q</code>.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_tol">tol</code></td>
<td>
<p>small positive numeric value giving the convergence tolerance for the quantile.</p>
</td></tr>
<tr><td><code id="invgauss_+3A_trace">trace</code></td>
<td>
<p>logical, if <code>TRUE</code> then the working estimate for <code>q</code> from each iteration will be output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse Gaussian distribution takes values on the positive real line.
It is somewhat more right skew than the gamma distribution, with variance given by <code>dispersion*mean^3</code>.
The distribution has applications in reliability and survival analysis and is one of the response distributions used in generalized linear models.
</p>
<p>Giner and Smyth (2016) show that the inverse Gaussian distribution converges to an inverse chi-squared distribution as the mean becomes large.
</p>
<p>The functions provided here implement numeric algorithms developed by Giner and Smyth (2016) that achieve close to full machine accuracy for all possible parameter values.
Giner and Smyth (2016) show that the probability calculations provided by these functions are considerably more accurate, and in most cases faster, than previous implementations of inverse Gaussian functions.
The improvement in accuracy is most noticeable for extreme probability values and for large parameter values.
</p>
<p>The shape and dispersion parameters are alternative parametrizations for the variability, with <code>dispersion=1/shape</code>.
Only one of these two arguments needs to be specified.
If both are set, then <code>shape</code> takes precedence.
</p>


<h3>Value</h3>

<p>Output values give density (<code>dinvgauss</code>), probability (<code>pinvgauss</code>), quantile (<code>qinvgauss</code>) or random sample (<code>rinvgauss</code>) for the inverse Gaussian distribution with mean <code>mean</code> and dispersion <code>dispersion</code>.
Output is a vector of length equal to the maximum length of any of the arguments <code>x</code>, <code>q</code>, <code>mean</code>, <code>shape</code> or <code>dispersion</code>.
If the first argument is the longest, then all the attributes of the input argument are preserved on output, for example, a matrix <code>x</code> will give a matrix on output.
Elements of input vectors that are missing will cause the corresponding elements of the result to be missing, as will non-positive values for <code>mean</code> or <code>dispersion</code>.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth.
</p>
<p>Very early S-Plus versions of these functions, using simpler algorithms, were published 1998 at <a href="http://www.statsci.org/s/invgauss.html">http://www.statsci.org/s/invgauss.html</a>.
Paul Bagshaw (Centre National d'Etudes des Telecommunications, France) contributed the original version of <code>qinvgauss</code> in December 1998.
Trevor Park (Department of Statistics, University of Florida) suggested improvements to a version of <code>rinvguass</code> in 2005.</p>


<h3>References</h3>

<p>Giner, G., and Smyth, G. K. (2016).
statmod: Probability calculations for the inverse Gaussian distribution.
<em>R Journal</em> 8(1), 339-351.
<a href="https://journal.r-project.org/archive/2016-1/giner-smyth.pdf">https://journal.r-project.org/archive/2016-1/giner-smyth.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>q &lt;- rinvgauss(10, mean=1, disp=0.5) # generate vector of 10 random numbers
p &lt;- pinvgauss(q, mean=1, disp=0.5) # p should be uniformly distributed

# Quantile for small right tail probability:
qinvgauss(1e-20, mean=1.5, disp=0.7, lower.tail=FALSE)

# Same quantile, but represented in terms of left tail probability on log-scale
qinvgauss(-1e-20, mean=1.5, disp=0.7, lower.tail=TRUE, log.p=TRUE)
</code></pre>

<hr>
<h2 id='logmdigamma'>Log Minus Digamma Function</h2><span id='topic+logmdigamma'></span>

<h3>Description</h3>

<p>The difference between the <code>log</code> and <code>digamma</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logmdigamma(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logmdigamma_+3A_x">x</code></td>
<td>
<p>numeric vector or array of positive values. Negative or zero values will return <code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>digamma(x)</code> is asymptotically equivalent to <code>log(x)</code>.  <code>logmdigamma(x)</code> computes <code>log(x) - digamma(x)</code> without subtractive cancellation for large <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Abramowitz, M., and Stegun, I. A. (1970). <em>Handbook of
mathematical functions.</em> Dover, New York.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+digamma">digamma</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>log(10^15) - digamma(10^15) # returns 0
logmdigamma(10^15) # returns value correct to 15 figures
</code></pre>

<hr>
<h2 id='matvec'>Multiply a Matrix by a Vector</h2><span id='topic+matvec'></span><span id='topic+vecmat'></span>

<h3>Description</h3>

<p>Multiply the rows or columns of a matrix by the elements of a vector.</p>


<h3>Usage</h3>

<pre><code class='language-R'>matvec(M, v)
vecmat(v, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matvec_+3A_m">M</code></td>
<td>
<p>numeric matrix, or object which can be coerced to a matrix.</p>
</td></tr>
<tr><td><code id="matvec_+3A_v">v</code></td>
<td>
<p>numeric vector, or object which can be coerced to a vector. Length should match the number of columns of <code>M</code> (for <code>matvec</code>) or the number of rows of <code>M</code> (for <code>vecmat</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>matvec(M,v)</code> is equivalent to <code>M %*% diag(v)</code> but is faster to execute.
Similarly <code>vecmat(v,M)</code> is equivalent to <code>diag(v) %*% M</code> but is faster to execute.
</p>


<h3>Value</h3>

<p>A matrix of the same dimensions as <code>M</code>.</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(1:12,3,4)
A
matvec(A,c(1,2,3,4))
vecmat(c(1,2,3),A)
</code></pre>

<hr>
<h2 id='meanT'>Mean t-Statistic Between Two Groups of Growth Curves</h2><span id='topic+meanT'></span>

<h3>Description</h3>

<p>The mean-t statistic of the distance between two groups of growth curves. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanT(y1, y2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanT_+3A_y1">y1</code></td>
<td>
<p>matrix of response values for the first group, with a row for each individual and a column for each time. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="meanT_+3A_y2">y2</code></td>
<td>
<p>matrix of response values for the second group.  Must have the same number of columns as <code>y1</code>. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the pooled two-sample t-statistic between the response values at each time, and returns the mean of these values weighted by the degrees of freedom.
This function is used by <code>compareGrowthCurves</code>.
</p>


<h3>Value</h3>

<p>numeric vector of length one containing the mean t-statistic.</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>See Also</h3>

<p><code><a href="#topic+compareGrowthCurves">compareGrowthCurves</a></code>, <code><a href="#topic+compareTwoGrowthCurves">compareTwoGrowthCurves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y1 &lt;- matrix(rnorm(4*3),4,3)
y2 &lt;- matrix(rnorm(4*3),4,3)
meanT(y1,y2)

data(PlantGrowth)
compareGrowthCurves(PlantGrowth$group,as.matrix(PlantGrowth$weight))
# Can make p-values more accurate by nsim=10000
</code></pre>

<hr>
<h2 id='mixedModel2'>Fit Mixed Linear Model with 2 Error Components</h2><span id='topic+mixedModel2'></span><span id='topic+mixedModel2Fit'></span><span id='topic+randomizedBlock'></span><span id='topic+randomizedBlockFit'></span>

<h3>Description</h3>

<p>Fits a mixed linear model by REML.  The linear model contains one random factor apart from the unit errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixedModel2(formula, random, weights=NULL, only.varcomp=FALSE, data=list(),
            subset=NULL, contrasts=NULL, tol=1e-6, maxit=50, trace=FALSE)
mixedModel2Fit(y, X, Z, w=NULL, only.varcomp=FALSE, tol=1e-6, maxit=50, trace=FALSE)
randomizedBlock(formula, random, weights=NULL, only.varcomp=FALSE, data=list(),
            subset=NULL, contrasts=NULL, tol=1e-6, maxit=50, trace=FALSE)
randomizedBlockFit(y, X, Z, w=NULL, only.varcomp=FALSE, tol=1e-6, maxit=50, trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<p>The arguments <code>formula</code>, <code>weights</code>, <code>data</code>, <code>subset</code> and <code>contrasts</code> have the same meaning as in <code>lm</code>.
The arguments <code>y</code>, <code>X</code> and <code>w</code> have the same meaning as in <code>lm.wfit</code>.
</p>
<table>
<tr><td><code id="mixedModel2_+3A_formula">formula</code></td>
<td>
<p>formula specifying the fixed model.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_random">random</code></td>
<td>
<p>vector or factor specifying the blocks corresponding to random effects.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_weights">weights</code></td>
<td>
<p>optional vector of prior weights.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_only.varcomp">only.varcomp</code></td>
<td>
<p>logical value, if <code>TRUE</code> computation of standard errors and fixed effect coefficients will be skipped</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code> argument of <code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_tol">tol</code></td>
<td>
<p>small positive numeric tolerance, passed to <code>glmgam.fit</code></p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations permitted, passed to <code>glmgam.fit</code></p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_trace">trace</code></td>
<td>
<p>logical value, passed to <code>glmgam.fit</code>. If <code>TRUE</code> then working estimates will be printed at each iteration.</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_y">y</code></td>
<td>
<p>numeric response vector</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_x">X</code></td>
<td>
<p>numeric design matrix for fixed model</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_z">Z</code></td>
<td>
<p>numeric design matrix for random effects</p>
</td></tr>
<tr><td><code id="mixedModel2_+3A_w">w</code></td>
<td>
<p>optional vector of prior weights</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>randomizedBlock</code> and <code>mixedModel2</code> are alternative names for the same function.
</p>
<p>This function fits the model <code class="reqn">y=Xb+Zu+e</code> where <code class="reqn">b</code> is a vector of fixed coefficients and <code class="reqn">u</code> is a vector of random effects.
Write <code class="reqn">n</code> for the length of <code class="reqn">y</code> and <code class="reqn">q</code> for the length of <code class="reqn">u</code>.
The random effect vector <code class="reqn">u</code> is assumed to be normal, mean zero, with covariance matrix <code class="reqn">\sigma^2_uI_q</code> while <code class="reqn">e</code> is normal, mean zero, with covariance matrix <code class="reqn">\sigma^2I_n</code>.
If <code class="reqn">Z</code> is an indicator matrix, then this model corresponds to a randomized block experiment.
The model is fitted using an eigenvalue decomposition that transforms the problem into a Gamma generalized linear model.
To the knowledge of the author, this is an original and unpublished approach to the problem of fitting mixed models.
</p>
<p>Note that the block variance component <code>varcomp[2]</code> is not constrained to be non-negative.
It may take negative values corresponding to negative intra-block correlations.
However the correlation <code>varcomp[2]/sum(varcomp)</code> must lie between <code>-1</code> and <code>1</code>.
</p>
<p>Missing values in the data are not allowed.
</p>
<p>This function is in principle equivalent to <code>lme(fixed=formula,random=~1|random)</code> except that the block variance component is not constrained to be non-negative.
If the block variance component is non-negative, then this function is faster and more accurate than <code>lme</code> for small to moderate size data sets but slower than <code>lme</code> when the number of observations is large.
</p>
<p>This function tends to be fast and reliable, compared to competitor functions that fit randomized block models, when then number of observations is small, say no more than 200.
However it becomes quadratically slow as the number of observations increases because of the need to compute two singular value decompositions of order nearly equal to the number of observations, although this can be limited to only one decomposition if <code>only.varcomp = TRUE</code>).
For these reasons, this function is a good choice when fitting large numbers of mixed models to small datasets but is not optimal as currently implemented for fitting mixed models to very large data sets.
</p>


<h3>Value</h3>

<p>A list with the components:
</p>
<table>
<tr><td><code>varcomp</code></td>
<td>
<p>numeric vector of length two containing the residual and block components of variance.</p>
</td></tr>
<tr><td><code>se.varcomp</code></td>
<td>
<p>standard errors for the variance components (if <code>only.varcomp=FALSE</code>).</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric vector of fixed coefficients (if <code>only.varcomp=FALSE</code>).</p>
</td></tr>
<tr><td><code>se.coefficients</code></td>
<td>
<p>standard errors for the fixed coefficients (if <code>only.varcomp=FALSE</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Venables, W., and Ripley, B. (2002). <em>Modern Applied Statistics with S-Plus</em>, Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmgam.fit">glmgam.fit</a></code>, <code><a href="nlme.html#topic+lme">lme</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+lm.fit">lm.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Compare with first data example from Venable and Ripley (2002),
#  Chapter 10, "Linear Models"
library(MASS)
data(petrol)
out &lt;- mixedModel2(Y~SG+VP+V10+EP, random=No, data=petrol)
cbind(varcomp=out$varcomp,se=out$se.varcomp)
</code></pre>

<hr>
<h2 id='mscale'>M Scale Estimation</h2><span id='topic+mscale'></span>

<h3>Description</h3>

<p>Robust estimation of a scale parameter using Hampel's redescending psi function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mscale(u, na.rm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mscale_+3A_u">u</code></td>
<td>
<p>numeric vector of residuals.</p>
</td></tr>
<tr><td><code id="mscale_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates a scale parameter or standard deviation using an M-estimator with 50% breakdown.
This means the estimator is highly robust to outliers.
If the input residuals <code>u</code> are a normal sample, then <code>mscale(u)</code> should be equal to the standard deviation.
</p>


<h3>Value</h3>

<p>numeric constant giving the estimated scale.</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Yohai, V. J. (1987). High breakdown point and high efficiency robust estimates for regression. <em>Ann. Statist.</em> 15, 642-656.
</p>
<p>Stromberg, A. J. (1993). Computation of high breakdown nonlinear regression parameters. <em>J. Amer. Statist. Assoc.</em> 88, 237-244.
</p>
<p>Smyth, G. K., and Hawkins, D. M. (2000). Robust frequency estimation using elemental sets. <em>Journal of Computational and Graphical Statistics</em> 9, 196-214. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>u &lt;- rnorm(100)
sd(u)
mscale(u)
</code></pre>

<hr>
<h2 id='permp'>Exact permutation p-values</h2><span id='topic+permp'></span>

<h3>Description</h3>

<p>Calculates exact p-values for permutation tests when permutations are randomly drawn with replacement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permp(x, nperm, n1, n2, total.nperm=NULL, method="auto", twosided=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permp_+3A_x">x</code></td>
<td>
<p>number of permutations that yielded test statistics at least as extreme as the observed data. May be a vector or an array of values.</p>
</td></tr>
<tr><td><code id="permp_+3A_nperm">nperm</code></td>
<td>
<p>total number of permutations performed.</p>
</td></tr>
<tr><td><code id="permp_+3A_n1">n1</code></td>
<td>
<p>sample size of group 1. Not required if <code>total.nperm</code> is supplied.</p>
</td></tr>
<tr><td><code id="permp_+3A_n2">n2</code></td>
<td>
<p>sample size of group 2. Not required if <code>total.nperm</code> is supplied.</p>
</td></tr>
<tr><td><code id="permp_+3A_total.nperm">total.nperm</code></td>
<td>
<p>total number of permutations allowable from the design of the experiment.</p>
</td></tr>
<tr><td><code id="permp_+3A_method">method</code></td>
<td>
<p>character string indicating computation method. Possible values are <code>"exact"</code>, <code>"approximate"</code> or <code>"auto"</code>.</p>
</td></tr>
<tr><td><code id="permp_+3A_twosided">twosided</code></td>
<td>
<p>logical, is the test two-sided and symmetric between the two groups?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used for calculating exact p-values for permutation tests where permutations are sampled with replacement, using theory and methods developed by Phipson and Smyth (2010).
The input values are the total number of permutations done (<code>nperm</code>) and the number of these that were considered at least as extreme as the observed data (<code>x</code>).
</p>
<p><code>total.nperm</code> is the total number of distinct values of the test statistic that are possible.
This is generally equal to the number of possible permutations, unless a two-sided test is conducted with equal sample sizes, in which case <code>total.nperm</code> is half the number of permutations, because the test statistic must then be symmetric in the two groups.
Usually <code>total.nperm</code> is computed automatically from <code>n1</code> and <code>n2</code>, but can also be supplied directly by the user.
</p>
<p>When <code>method="exact"</code>, the p-values are computed to full machine precision by summing a series terms.
When <code>method="approximate"</code>, an approximation is used that is faster and uses less memory.
If <code>method="auto"</code>, the exact calculation is used when <code>total.nperm</code> is less than or equal to 10,000 and the approximation is used otherwise.
</p>


<h3>Value</h3>

<p>vector or array of p-values, of same dimensions as <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Belinda Phipson and Gordon Smyth</p>


<h3>References</h3>

<p>Phipson B, Smyth GK (2010).
Permutation P-values should never be zero: calculating exact P-values when permutations are randomly drawn.
<em>Statistical Applications in Genetics and Molecular Biology</em>, Volume 9, Issue 1, Article 39.
<a href="https://doi.org/10.2202/1544-6115.1585">doi:10.2202/1544-6115.1585</a>,
<a href="https://doi.org/10.48550/arXiv.1603.05766">doi:10.48550/arXiv.1603.05766</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 0:5
# Both calls give same results
permp(x=x, nperm=99, n1=6, n2=6)
permp(x=x, nperm=99, total.nperm=462)
</code></pre>

<hr>
<h2 id='plot.limdil'>Plot or print an object of class limdil</h2><span id='topic+print.limdil'></span><span id='topic+plot.limdil'></span>

<h3>Description</h3>

<p>Plot or print the results of a limiting dilution analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'limdil'
print(x, ...)
## S3 method for class 'limdil'
plot(x, col.group=NULL, cex=1, lwd=1, legend.pos="bottomleft", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.limdil_+3A_x">x</code></td>
<td>
<p>object of class <code>limdil</code>.</p>
</td></tr>
<tr><td><code id="plot.limdil_+3A_col.group">col.group</code></td>
<td>
<p>vector of colors for the groups of the same length as <code>levels(x$group)</code>.</p>
</td></tr>
<tr><td><code id="plot.limdil_+3A_cex">cex</code></td>
<td>
<p>relative symbol size</p>
</td></tr>
<tr><td><code id="plot.limdil_+3A_lwd">lwd</code></td>
<td>
<p>relative line width</p>
</td></tr>
<tr><td><code id="plot.limdil_+3A_legend.pos">legend.pos</code></td>
<td>
<p>positioning on plot of legend when there are multiple groups</p>
</td></tr>
<tr><td><code id="plot.limdil_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code>plot</code> or <code>print</code>.
Note that <code>pch</code> and <code>lty</code> are reserved arguments for the plot method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The print method formats results similarly to a regression or anova summary in R.
</p>
<p>The plot method produces a plot of a limiting dilution experiment similar to that in Bonnefoix et al (2001). 
The basic design of the plot was made popular by Lefkovits and Waldmann (1979).
</p>
<p>The plot shows frequencies and confidence intervals for the multiple groups. 
A novel feature is that assays with 100% successes are included in the plot and are represented by down-pointing triangles. 
</p>


<h3>Author(s)</h3>

<p>Yifang Hu and Gordon Smyth</p>


<h3>References</h3>

<p>Bonnefoix, T, Bonnefoix, P, Callanan, M, Verdiel, P, and Sotto, JJ (2001).
Graphical representation of a generalized linear model-based statistical test estimating the fit of the single-hit poisson model to limiting
dilution assays.
<em>The Journal of Immunology</em> 167, 5725-5730.
</p>
<p>Lefkovits, I, and Waldmann, H (1979).
<em>Limiting dilution analysis of cells in the immune system</em>.
Cambridge University Press, Cambridge.
</p>


<h3>See Also</h3>

<p><a href="#topic+limdil">limdil</a> describes the <code>limdil</code> class.</p>

<hr>
<h2 id='power.fisher.test'>Power of Fisher's Exact Test for Comparing Proportions</h2><span id='topic+power.fisher.test'></span>

<h3>Description</h3>

<p>Calculate by simulation the power of Fisher's exact test for comparing two proportions given two margin counts. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.fisher.test(p1, p2, n1, n2, alpha=0.05, nsim=100, alternative="two.sided")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.fisher.test_+3A_p1">p1</code></td>
<td>
<p>first proportion to be compared.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_p2">p2</code></td>
<td>
<p>second proportion to be compared.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_n1">n1</code></td>
<td>
<p>first sample size.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_n2">n2</code></td>
<td>
<p>second sample size.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_alpha">alpha</code></td>
<td>
<p>significance level.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_nsim">nsim</code></td>
<td>
<p>number of data sets to simulate.</p>
</td></tr>
<tr><td><code id="power.fisher.test_+3A_alternative">alternative</code></td>
<td>
<p>indicates the alternative hypothesis and must be one of &quot;two.sided&quot;, &quot;greater&quot; or &quot;less&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates the power of Fisher's exact test for testing the null hypothesis that <code>p1</code> equals <code>p2</code> against the alternative that they are not equal.
</p>
<p>The power is estimated by simulation.
The function generates <code>nsim</code> pairs of binomial deviates and calls <code>fisher.test</code> to obtain <code>nsim</code> p-values.
The required power is tnen the proportion of the simulated p-values that are less than <code>alpha</code>.
</p>


<h3>Value</h3>

<p>Estimated power of the test.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fisher.test">fisher.test</a></code>, <code><a href="stats.html#topic+power.t.test">power.t.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>power.fisher.test(0.5,0.9,20,20) # 70% chance of detecting difference
</code></pre>

<hr>
<h2 id='qresiduals'>Randomized Quantile Residuals</h2><span id='topic+qresiduals'></span><span id='topic+qresid'></span><span id='topic+qres.binom'></span><span id='topic+qres.pois'></span><span id='topic+qres.nbinom'></span><span id='topic+qres.gamma'></span><span id='topic+qres.invgauss'></span><span id='topic+qres.tweedie'></span><span id='topic+qres.default'></span>

<h3>Description</h3>

<p>Compute randomized quantile residuals for generalized linear models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>qresiduals(glm.obj,dispersion=NULL)
qresid(glm.obj,dispersion=NULL)
qres.binom(glm.obj)
qres.pois(glm.obj)
qres.nbinom(glm.obj)
qres.gamma(glm.obj,dispersion=NULL)
qres.invgauss(glm.obj,dispersion=NULL)
qres.tweedie(glm.obj,dispersion=NULL)
qres.default(glm.obj,dispersion=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qresiduals_+3A_glm.obj">glm.obj</code></td>
<td>
<p>Object of class <code>glm</code>. The generalized linear model family is assumed to be binomial for <code>qres.binom</code>, poisson for
<code>qres.pois</code>, negative binomial for <code>qres.nbinom</code>, Gamma for
<code>qres.gamma</code>, inverse Gaussian for <code>qres.invgauss</code> or
tweedie for <code>qres.tweedie</code>.</p>
</td></tr>
<tr><td><code id="qresiduals_+3A_dispersion">dispersion</code></td>
<td>
<p>a positive real number. Specifies the value of the
dispersion parameter for a Gamma or inverse Gaussian generalized linear
model if known. If <code>NULL</code>, the dispersion will be estimated by its
Pearson estimator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Quantile residuals are based on the idea of inverting the
estimated distribution function for each observation to
obtain exactly standard normal residuals. In the case of
discrete distributions, such as the binomial and Poisson,
some randomization is introduced to produce continuous
normal residuals. Quantile residuals are the residuals of
choice for generalized linear models in large dispersion
situations when the deviance and Pearson residuals can be
grossly non-normal. Quantile residuals are the only
useful residuals for binomial or Poisson data when the
response takes on only a small number of distinct values.
</p>


<h3>Value</h3>

<p>Numeric vector of standard normal quantile residuals.</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Dunn, K. P., and Smyth, G. K. (1996). Randomized quantile residuals. <em>Journal of Computational and Graphical Statistics</em> <b>5</b>, 1-10.
<a href="http://www.statsci.org/smyth/pubs/residual.html">http://www.statsci.org/smyth/pubs/residual.html</a>
</p>
<p>Dunn, PK, and Smyth, GK (2018).
<em>Generalized linear models with examples in R</em>. Springer, New York, NY.
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Poisson example: quantile residuals show no granularity
y &lt;- rpois(20,lambda=4)
x &lt;- 1:20
fit &lt;- glm(y~x, family=poisson)
qr &lt;- qresiduals(fit)
qqnorm(qr)
abline(0,1)

#  Gamma example:
#  Quantile residuals are nearly normal while usual resids are not
y &lt;- rchisq(20, df=1)
fit &lt;- glm(y~1, family=Gamma)
qr &lt;- qresiduals(fit, dispersion=2)
qqnorm(qr)
abline(0,1)

#  Negative binomial example:
if(require("MASS")) {
fit &lt;- glm(Days~Age,family=negative.binomial(2),data=quine)
summary(qresiduals(fit))
fit &lt;- glm.nb(Days~Age,link=log,data = quine)
summary(qresiduals(fit))
}
</code></pre>

<hr>
<h2 id='remlscore'>REML for Heteroscedastic Regression</h2><span id='topic+remlscore'></span>

<h3>Description</h3>

<p>Fits a heteroscedastic regression model using residual maximum likelihood (REML).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remlscore(y, X, Z, trace=FALSE, tol=1e-5, maxit=40)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remlscore_+3A_y">y</code></td>
<td>
<p>numeric vector of responses</p>
</td></tr>
<tr><td><code id="remlscore_+3A_x">X</code></td>
<td>
<p>design matrix for predicting the mean</p>
</td></tr>
<tr><td><code id="remlscore_+3A_z">Z</code></td>
<td>
<p>design matrix for predicting the variance</p>
</td></tr>
<tr><td><code id="remlscore_+3A_trace">trace</code></td>
<td>
<p>Logical variable. If true then output diagnostic information at each iteration.</p>
</td></tr>
<tr><td><code id="remlscore_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance</p>
</td></tr>
<tr><td><code id="remlscore_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations allowed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Write <code class="reqn">\mu_i=E(y_i)</code> and <code class="reqn">\sigma^2_i=\mbox{var}(y_i)</code> for the expectation and variance of the <code class="reqn">i</code>th response.
We assume the heteroscedastic regression model
</p>
<p style="text-align: center;"><code class="reqn">\mu_i=\bold{x}_i^T\bold{\beta}</code>
</p>

<p style="text-align: center;"><code class="reqn">\log(\sigma^2_i)=\bold{z}_i^T\bold{\gamma},</code>
</p>

<p>where <code class="reqn">\bold{x}_i</code> and <code class="reqn">\bold{z}_i</code> are vectors of covariates, and <code class="reqn">\bold{\beta}</code> and <code class="reqn">\bold{\gamma}</code> are vectors of regression coefficients affecting the mean and variance respectively.
</p>
<p>Parameters are estimated by maximizing the REML likelihood using REML scoring as described in Smyth (2002).
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>vector of regression coefficients for predicting the mean</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>vector of standard errors for beta</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>vector of regression coefficients for predicting the variance</p>
</td></tr>
<tr><td><code>se.gam</code></td>
<td>
<p>vector of standard errors for gamma</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated means</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>estimated variances</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>minus twice the REML log-likelihood</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>numeric vector of leverages</p>
</td></tr>
<tr><td><code>cov.beta</code></td>
<td>
<p>estimated covariance matrix for beta</p>
</td></tr>
<tr><td><code>cov.gam</code></td>
<td>
<p>estimated covarate matrix for gamma</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Smyth, G. K. (2002).
An efficient algorithm for REML in heteroscedastic regression.
<em>Journal of Computational and Graphical Statistics</em> <b>11</b>, 836-847.
<a href="https://doi.org/10.1198/106186002871">doi:10.1198/106186002871</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(welding)
attach(welding)
y &lt;- Strength
# Reproduce results from Table 1 of Smyth (2002)
X &lt;- cbind(1,(Drying+1)/2,(Material+1)/2)
colnames(X) &lt;- c("1","B","C")
Z &lt;- cbind(1,(Material+1)/2,(Method+1)/2,(Preheating+1)/2)
colnames(Z) &lt;- c("1","C","H","I")
out &lt;- remlscore(y,X,Z)
cbind(Estimate=out$gamma,SE=out$se.gam)
</code></pre>

<hr>
<h2 id='remlscoregamma'>Approximate REML for Gamma Regression with Structured Dispersion</h2><span id='topic+remlscoregamma'></span>

<h3>Description</h3>

<p>Estimates structured dispersion effects using approximate REML with gamma responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remlscoregamma(y, X, Z, mlink="log", dlink="log", trace=FALSE, tol=1e-5, maxit=40)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remlscoregamma_+3A_y">y</code></td>
<td>
<p>numeric vector of responses.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_x">X</code></td>
<td>
<p>design matrix for predicting the mean.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_z">Z</code></td>
<td>
<p>design matrix for predicting the variance.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_mlink">mlink</code></td>
<td>
<p>character string or numeric value specifying link for mean model.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_dlink">dlink</code></td>
<td>
<p>character string or numeric value specifying link for dispersion model.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_trace">trace</code></td>
<td>
<p>logical value. If <code>TRUE</code> then diagnostic information is output at each iteration.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance.</p>
</td></tr>
<tr><td><code id="remlscoregamma_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a double generalized linear model (glm) with gamma responses.
As for ordinary gamma glms, a link-linear model is assumed for the expected values.
The double glm assumes a separate link-linear model for the dispersions as well.
The responses <code>y</code> are assumed to follow a gamma generalized linear model with link <code>mlink</code> and design matrix
<code>X</code>.
The dispersions follow a link-linear model with link <code>dlink</code> and design matrix <code>Z</code>.
</p>
<p>Write <code class="reqn">y_i</code> for the <code class="reqn">i</code>th response.
The <code class="reqn">y_i</code> are assumed to be independent and gamma distributed with <code class="reqn">E(y_i) = \mu_i</code> and var<code class="reqn">(y_i)=\phi_i\mu_i^2</code>.
The link-linear model for the means can be written as
</p>
<p style="text-align: center;"><code class="reqn">g(\mu)=X\beta</code>
</p>

<p>where <code class="reqn">g</code> is the mean-link function defined by <code>mlink</code> and <code class="reqn">\mu</code> is the vector of means.
The dispersion link-linear model can be written as
</p>
<p style="text-align: center;"><code class="reqn">h(\phi)=Z\gamma</code>
</p>

<p>where <code class="reqn">h</code> is the dispersion-link function defined by <code>dlink</code> and <code class="reqn">\phi</code> is the vector of dispersions.
</p>
<p>The parameters <code class="reqn">\gamma</code> are estimated by approximate REML likelihood using an adaption of the algorithm described by Smyth (2002).
See also Smyth and Verbyla (1999a,b) and Smyth and Verbyla (2009).
Having estimated <code class="reqn">\gamma</code> and <code class="reqn">\phi</code>, the <code class="reqn">\beta</code> are estimated as usual for a gamma glm.
</p>
<p>The estimated values for <code class="reqn">\beta</code>, <code class="reqn">\mu</code>, <code class="reqn">\gamma</code> and <code class="reqn">\phi</code> are return as <code>beta</code>, <code>mu</code>, <code>gamma</code> and <code>phi</code> respectively.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>numeric vector of regression coefficients for predicting the mean.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>numeric vector of standard errors for beta.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>numeric vector of regression coefficients for predicting the variance.</p>
</td></tr>
<tr><td><code>se.gam</code></td>
<td>
<p>numeric vector of standard errors for gamma.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>numeric vector of estimated means.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>numeric vector of estimated dispersions.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>minus twice the REML log-likelihood.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>numeric vector of leverages.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Smyth, G. K., and Verbyla, A. P. (1999a). Adjusted likelihood methods for modelling dispersion in generalized linear models. <em>Environmetrics</em> 10, 695-709. 
<a href="http://www.statsci.org/smyth/pubs/ties98tr.html">http://www.statsci.org/smyth/pubs/ties98tr.html</a>
</p>
<p>Smyth, G. K., and Verbyla, A. P. (1999b). Double generalized linear models: approximate REML and diagnostics. In <em>Statistical Modelling: Proceedings of the 14th International Workshop on Statistical Modelling</em>, Graz, Austria, July 19-23, 1999, H. Friedl, A. Berghold, G. Kauermann (eds.), Technical University, Graz, Austria, pages 66-80.
<a href="http://www.statsci.org/smyth/pubs/iwsm99-Preprint.pdf">http://www.statsci.org/smyth/pubs/iwsm99-Preprint.pdf</a>
</p>
<p>Smyth, G. K. (2002). An efficient algorithm for REML in heteroscedastic regression. <em>Journal of Computational and Graphical Statistics</em> <b>11</b>, 836-847.
</p>
<p>Smyth, GK, and Verbyla, AP (2009). Leverage adjustments for dispersion modelling in generalized nonlinear models. <em>Australian and New Zealand Journal of Statistics</em> 51, 433-448.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(welding)
attach(welding)
y &lt;- Strength
X &lt;- cbind(1,(Drying+1)/2,(Material+1)/2)
colnames(X) &lt;- c("1","B","C")
Z &lt;- cbind(1,(Material+1)/2,(Method+1)/2,(Preheating+1)/2)
colnames(Z) &lt;- c("1","C","H","I")
out &lt;- remlscoregamma(y,X,Z)
</code></pre>

<hr>
<h2 id='sage.test'>Exact Binomial Tests For Comparing Two SAGE Libraries (Obsolete)</h2><span id='topic+sage.test'></span>

<h3>Description</h3>

<p>Computes p-values for differential abundance for each tag between two digital libraries,
conditioning on the total count for each tag.
The counts in each group as a proportion of the whole are assumed to follow a binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sage.test(x, y, n1=sum(x), n2=sum(y))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sage.test_+3A_x">x</code></td>
<td>
<p>integer vector giving counts in first library.
Non-integer values are rounded to the nearest integer.</p>
</td></tr>
<tr><td><code id="sage.test_+3A_y">y</code></td>
<td>
<p>integer vector giving counts in second library.
Non-integer values are rounded to the nearest integer.</p>
</td></tr>
<tr><td><code id="sage.test_+3A_n1">n1</code></td>
<td>
<p>total number of tags in first library.
Non-integer values are rounded to the nearest integer.</p>
</td></tr>
<tr><td><code id="sage.test_+3A_n2">n2</code></td>
<td>
<p>total number of tags in second library.
Non-integer values are rounded to the nearest integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was originally written for comparing SAGE libraries (a method for counting the frequency of sequence tags in samples of RNA).
It can however be used for comparing any two digital libraries from RNA-Seq, ChIP-Seq or other technologies with respect to technical variation.
</p>
<p>An exact two-sided binomial test is computed for each tag.
This test is closely related to Fisher's exact test for 2x2 contingency tables but, unlike Fisher's test, it conditions on the total number of counts for each tag.
The null hypothesis is that the expected counts are in the same proportions as the library sizes, i.e., that the binomial probability for the first library is <code>n1/(n1+n2)</code>.
</p>
<p>The two-sided rejection region is chosen analogously to Fisher's test.
Specifically, the rejection region consists of those values with smallest probabilities
under the null hypothesis.
</p>
<p>When the counts are reasonably large, the binomial test, Fisher's test and Pearson's chisquare all give the same results.
When the counts are smaller, the binomial test is usually to be preferred in this context.
</p>
<p>This function is a later version of the earlier <code>sage.test</code> function in the sagenhaft Bioconductor package.
This function has been made obsolete by <code>binomTest</code> in the edgeR package.
</p>


<h3>Value</h3>

<p>Numeric vector of p-values.
</p>


<h3>Note</h3>

<p>This function is kept in the statmod package so as not to break code that depends on it
but it has been replaced by <code>binomTest</code> in the edgeR Bioconductor package and 
is no longer updated.
It may be removed in a later release of this package.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Binomial_test">https://en.wikipedia.org/wiki/Binomial_test</a>
</p>
<p><a href="https://en.wikipedia.org/wiki/Fisher's_exact_test">https://en.wikipedia.org/wiki/Fisher's_exact_test</a>
</p>
<p><a href="https://en.wikipedia.org/wiki/Serial_analysis_of_gene_expression">https://en.wikipedia.org/wiki/Serial_analysis_of_gene_expression</a>
</p>
<p><a href="https://en.wikipedia.org/wiki/RNA-Seq">https://en.wikipedia.org/wiki/RNA-Seq</a>
</p>


<h3>See Also</h3>

<p>The <code>binomTest</code> function in the <a href="https://doi.org/doi:10.18129/B9.bioc.edgeR">edgeR</a> package on Bioconductor is a newer and better version of this function.
</p>
<p><code><a href="stats.html#topic+binom.test">binom.test</a></code> in the stats package performs univariate binomial tests.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sage.test(c(0,5,10),c(0,30,50),n1=10000,n2=15000)
#  Univariate equivalents:
binom.test(5,5+30,p=10000/(10000+15000))$p.value
binom.test(10,10+50,p=10000/(10000+15000))$p.value
</code></pre>

<hr>
<h2 id='statmod-package'>Introduction to the StatMod Package</h2><span id='topic+statmod'></span><span id='topic+statmod-package'></span>

<h3>Description</h3>

<p>This package includes a variety of functions for numerical analysis and statistical modelling.
The functions are briefly summarized by type of application below.
</p>


<h3>Generalized Linear Models</h3>

<p>The function <code><a href="#topic+tweedie">tweedie</a></code> defines a large class of generalized linear model families with power variance functions.
It used in conjunction with the glm function, and widens the class of families that can be fitted.
</p>
<p><code><a href="#topic+qresiduals">qresiduals</a></code> implements randomized quantile residuals for generalized linear models.
</p>
<p>The functions
<code>canonic.digamma</code>,
<code>unitdeviance.digamma</code>,
<code>varfun.digamma</code>,
<code>cumulant.digamma</code>,
<code>d2cumulant.digamma</code>,
<code>meanval.digamma</code>
and <code>logmdigamma</code>
are used to fit double-generalized models, in which a link-linear model is fitted to the dispersion as well as to the mean.
Spefically they are used to fit the dispersion submodel associated with a gamma glm.
</p>


<h3>Growth Curves</h3>

<p><code><a href="#topic+compareGrowthCurves">compareGrowthCurves</a></code>,
<code>compareTwoGrowthCurves</code> and
<code>meanT</code>
are functions to test for differences between growth curves with repeated measurements on subjects.
</p>


<h3>Limiting Dilution Analysis</h3>

<p>The <code><a href="#topic+limdil">limdil</a></code> function is used in the analysis of stem cell frequencies.
It implements limiting dilution analysis using complemenary log-log binomial generalized linear model regression, with some improvements on previous programs.
</p>


<h3>Probability Distributions</h3>

<p>The functions
<code><a href="#topic+qinvgauss">qinvgauss</a></code>,
<code><a href="#topic+dinvgauss">dinvgauss</a></code>,
<code><a href="#topic+pinvgauss">pinvgauss</a></code> and
<code><a href="#topic+rinvgauss">rinvgauss</a></code>
provide probability calculations for the inverse Gaussian distribution. 
</p>
<p><code><a href="#topic+gauss.quad">gauss.quad</a></code> and
<code>gauss.quad.prob</code> compute Gaussian Quadrature with probability distributions. 
</p>


<h3>Tests</h3>

<p><code><a href="#topic+hommel.test">hommel.test</a></code> performs Hommel's multiple comparison tests.
</p>
<p><code><a href="#topic+power.fisher.test">power.fisher.test</a></code> computes the power of Fisher's Exact Test for comparing proportions.
</p>
<p><code><a href="#topic+sage.test">sage.test</a></code> is a fast approximation to Fisher's exact test for each tag for comparing two Serial Analysis of Gene Expression (SAGE) libraries.
</p>
<p><code><a href="#topic+permp">permp</a></code> computes p-values for permutation tests when the permutations are randomly drawn.
</p>


<h3>Variance Models</h3>

<p><code><a href="#topic+mixedModel2">mixedModel2</a></code>,
<code><a href="#topic+mixedModel2Fit">mixedModel2Fit</a></code> and
<code><a href="#topic+glmgam.fit">glmgam.fit</a></code> fit mixed linear models.
</p>
<p><code><a href="#topic+remlscore">remlscore</a></code> and <code><a href="#topic+remlscoregamma">remlscoregamma</a></code> fit heteroscedastic and varying dispersion models by REML.
<code><a href="#topic+welding">welding</a></code> is an example data set.
</p>


<h3>Matrix Computations</h3>

<p><code><a href="#topic+matvec">matvec</a></code> and <code><a href="#topic+vecmat">vecmat</a></code> facilitate multiplying matrices by vectors.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>

<hr>
<h2 id='tweedie'>Tweedie Generalized Linear Models</h2><span id='topic+tweedie'></span>

<h3>Description</h3>

<p>Produces a generalized linear model family object with any power variance function and any power link. Includes the Gaussian, Poisson, gamma and inverse-Gaussian families as special cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweedie(var.power = 0, link.power = 1 - var.power)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweedie_+3A_var.power">var.power</code></td>
<td>
<p>index of power variance function</p>
</td></tr>
<tr><td><code id="tweedie_+3A_link.power">link.power</code></td>
<td>
<p>index of power link function. <code>link.power=0</code> produces a log-link. Defaults to the canonical link, which is <code>1-var.power</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function provides access to a range of generalized linear model (GLM) response distributions that are not otherwise provided by R.
It is also useful for accessing distribution/link combinations that are disallowed by the R <code>glm</code> function.
The variance function for the GLM is assumed to be V(mu) = mu^var.power, where mu is the expected value of the distribution.
The link function of the GLM is assumed to be mu^link.power for non-zero values of link.power or log(mu) for var.power=0.
For example, <code>var.power=1</code> produces the identity link.
The canonical link for each Tweedie family is <code>link.power = 1 - var.power</code>.
</p>
<p>The Tweedie family of GLMs is discussed in detail by Dunn and Smyth (2018).
Each value of <code>var.power</code> corresponds to a particular type of response distribution.
The values 0, 1, 2 and 3 correspond to the normal distribution, the Poisson distribution, the gamma distribution and the inverse-Gaussian distribution respectively.
For these choices of <code>var.power</code>, the Tweedie family is exactly equivalent to the usual GLM famly except with a greater choice of link powers.
For example, <code>tweedie(var.power = 1, link.power = 0)</code> is exactly equivalent to <code>poisson(link = "log")</code>.
</p>
<p>The most interesting Tweedie families occur for <code>var.power</code> between 1 and 2.
For these GLMs, the response distribution has mass at zero (i.e., it has exact zeros) but is otherwise continuous on the positive real numbers (Smyth, 1996; Hasan et al, 2012).
These GLMs have been used to model rainfall for example.
Many days there is no rain at all (exact zero) but, if there is any rain, then the actual amount of rain is continuous and positive.
</p>
<p>Generally speaking, <code>var.power</code> should be chosen so that the theoretical response distribution matches the type of response data being modeled.
Hence <code>var.power</code> should be chosen between 1 and 2 only if the response observations are continuous and positive except for exact zeros and <code>var.power</code> should be chosen greater than or equal to 2 only if the response observations are continuous and strictly positive.
</p>
<p>There are no theoretical Tweedie GLMs with var.power between 0 and 1 (Jorgensen 1987).
The <code>tweedie</code> function will work for those values but the family should be interpreted in a quasi-likelihood sense.
</p>
<p>Theoretical Tweedie GLMs do exist for negative values of var.power, but they are of little practical application.
These distributions assume 
The <code>tweedie</code> function will work for those values but the family should be interpreted in a quasi-likelihood sense.
</p>
<p>The name Tweedie has been associated with this family by Joergensen (1987) in honour of M. C. K. Tweedie.
Joergensen (1987) gives a mathematical derivation of the Tweedie distributions proving that no distributions exist for var.power between 0 and 1.
</p>
<p>Mathematically, a Tweedie GLM assumes the following.
Let <code class="reqn">\mu_i = E(y_i)</code> be the expectation of the <code class="reqn">i</code>th response. We assume that
</p>
<p style="text-align: center;"><code class="reqn">\mu_i^q = x_i^Tb, var(y_i) = \phi \mu_i^p</code>
</p>
 
<p>where <code class="reqn">x_i</code> is a vector of covariates and b is a vector of regression cofficients, for some <code class="reqn">\phi</code>, <code class="reqn">p</code> and <code class="reqn">q</code>.
This family is specified by <code>var.power = p</code> and <code>link.power = q</code>.
A value of zero for <code class="reqn">q</code> is interpreted as <code class="reqn">\log(\mu_i) = x_i^Tb</code>. 
</p>
<p>The following table summarizes the possible Tweedie response distributions:
</p>

<table>
<tr>
 <td style="text-align: center;">
<b>var.power</b> </td><td style="text-align: left;"> <b>Response distribution</b></td>
</tr>
<tr>
 <td style="text-align: center;">
0 </td><td style="text-align: left;"> Normal</td>
</tr>
<tr>
 <td style="text-align: center;">
1 </td><td style="text-align: left;"> Poisson</td>
</tr>
<tr>
 <td style="text-align: center;">
(1, 2) </td><td style="text-align: left;"> Compound Poisson, non-negative with mass at zero</td>
</tr>
<tr>
 <td style="text-align: center;">
2 </td><td style="text-align: left;"> Gamma</td>
</tr>
<tr>
 <td style="text-align: center;">
3 </td><td style="text-align: left;"> Inverse-Gaussian</td>
</tr>
<tr>
 <td style="text-align: center;">
&gt; 2 </td><td style="text-align: left;"> Stable, with support on the positive reals
</td>
</tr>

</table>



<h3>Value</h3>

<p>A family object, which is a list of functions and expressions used by <code>glm</code> and <code>gam</code> in their iteratively reweighted least-squares algorithms.
See <code><a href="stats.html#topic+family">family</a></code> and <code><a href="stats.html#topic+glm">glm</a></code> in the R base help for details. 
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth</p>


<h3>References</h3>

<p>Dunn, P. K., and Smyth, G. K, (2018).
<em>Generalized linear models with examples in R</em>. Springer, New York, NY.
<a href="https://doi.org/10.1007/978-1-4419-0118-7">doi:10.1007/978-1-4419-0118-7</a>
(Chapter 12 gives an overall discussion of Tweedie GLMs with R code and case studies.)
</p>
<p>Hasan, M.M. and Dunn, P.K. (2012).
Understanding the effect of climatology on monthly rainfall amounts in Australia using Tweedie GLMs.
<em>International Journal of Climatology</em>, 32(7) 1006-1017.
(An example with var.power between 1 and 2)
</p>
<p>Joergensen, B. (1987). Exponential dispersion models. <em>J. R. Statist. Soc.</em> B <b>49</b>, 127-162. 
(Mathematical derivation of Tweedie response distributions)
</p>
<p>Tweedie, M. C. K. (1984). An index which distinguishes between some important exponential families.
In <em>Statistics: Applications and New Directions</em>. Proceedings of the Indian Statistical Institute Golden Jubilee International Conference.
(Eds. J. K. Ghosh and J. Roy), pp. 579-604. Calcutta: Indian Statistical Institute.
(The original mathematical paper from which the family is named)
</p>
<p>Smyth, G. K. (1996). Regression modelling of quantity data with exact zeroes.
<em>Proceedings of the Second Australia-Japan Workshop on Stochastic Models in Engineering, Technology and Management</em>.
Technology Management Centre, University of Queensland, pp. 572-580.
<a href="http://www.statsci.org/smyth/pubs/RegressionWithExactZerosPreprint.pdf">http://www.statsci.org/smyth/pubs/RegressionWithExactZerosPreprint.pdf</a>
(Derivation and examples of Tweedie GLMS with var.power between 0 and 1)
</p>
<p>Smyth, G. K., and Verbyla, A. P., (1999). Adjusted likelihood methods for modelling dispersion in generalized linear models. <em>Environmetrics</em> <b>10</b>, 695-709.
<a href="http://www.statsci.org/smyth/pubs/Ties98-Preprint.pdf">http://www.statsci.org/smyth/pubs/Ties98-Preprint.pdf</a>
(Includes examples of Tweedie GLMs with <code>var.power=2</code> and <code>var.power=4</code>)
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+family">family</a></code>, <code><a href="tweedie.html#topic+dtweedie">dtweedie</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rgamma(20,shape=5)
x &lt;- 1:20
# Fit a poisson generalized linear model with identity link
glm(y~x,family=tweedie(var.power=1,link.power=1))

# Fit an inverse-Gaussion glm with log-link
glm(y~x,family=tweedie(var.power=3,link.power=0)) 
</code></pre>

<hr>
<h2 id='welding'>Data: Tensile Strength of Welds</h2><span id='topic+welding'></span>

<h3>Description</h3>

<p>This is a highly fractionated two-level factorial design employed as a screening design
in an off-line welding experiment performed by the National Railway Corporation of Japan.
There were 16 runs and 9 experimental factors. The response variable is the observed
tensile strength of the weld, one of several quality characteristics measured. All other
variables are at plus and minus levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(welding)</code></pre>


<h3>Format</h3>

<p>A data frame containing the following variables.
All the explanatory variables are numeric with two levels, <code>-1</code> and <code>1</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <b>Variable</b> </td><td style="text-align: left;"> <b>Description</b></td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Rods </td><td style="text-align: left;"> Kind of welding rods</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Drying </td><td style="text-align: left;"> Period of drying</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Material </td><td style="text-align: left;"> Welded material</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Thickness </td><td style="text-align: left;"> Thickness</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Angle </td><td style="text-align: left;"> Angle</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Opening </td><td style="text-align: left;"> Opening</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Current </td><td style="text-align: left;"> Current</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Method </td><td style="text-align: left;"> Welding method</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Preheating </td><td style="text-align: left;"> Preheating</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Strength </td><td style="text-align: left;"> Tensile strength of the weld in kg/mm. The response variable.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Source</h3>

<p><a href="http://www.statsci.org/data/general/welding.html">http://www.statsci.org/data/general/welding.html</a>
</p>


<h3>References</h3>

<p>Smyth, G. K., Huele, F., and Verbyla, A. P. (2001). Exact and approximate REML for heteroscedastic regression. <em>Statistical Modelling</em> <b>1</b>, 161-175.
</p>
<p>Smyth, G. K. (2002). An efficient algorithm for REML in heteroscedastic regression. <em>Journal of Computational and Graphical Statistics</em> <b>11</b>, 1-12.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
