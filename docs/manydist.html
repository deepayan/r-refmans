<!DOCTYPE html><html lang="en"><head><title>Help for package manydist</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {manydist}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cdist'><p>Calculation of Pairwise Distances for Categorical Data</p></a></li>
<li><a href='#fifa_nl'><p>FIFA 21 Player Data - Dutch League</p></a></li>
<li><a href='#mdist'><p>Calculation of Pairwise Distances for Mixed-Type Data</p></a></li>
<li><a href='#ndist'><p>Calculation of Pairwise Distances for Continuous Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Unbiased Distances for Mixed-Type Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Angelos Markos &lt;amarkos@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A comprehensive framework for calculating unbiased distances in datasets 
    containing mixed-type variables (numerical and categorical). The package implements 
    a general formulation that ensures multivariate additivity and commensurability, 
    meaning that variables contribute equally to the overall distance regardless of 
    their type, scale, or distribution. Supports multiple distance measures including 
    Gower's distance, Euclidean distance, Manhattan distance, and various categorical 
    variable distances such as simple matching, Eskin, occurrence frequency, and 
    association-based distances. Provides tools for variable scaling (standard 
    deviation, range, robust range, and principal component scaling), and handles 
    both independent and association-based category dissimilarities. Implements 
    methods to correct for biases that typically arise from different variable types, 
    distributions, and number of categories. Particularly useful for cluster analysis, 
    data visualization, and other distance-based methods when working with mixed data. 
    Methods based on van de Velden et al. (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2411.00429">doi:10.48550/arXiv.2411.00429</a>&gt; 
    "Unbiased mixed variables distance".</td>
</tr>
<tr>
<td>Imports:</td>
<td>entropy, Matrix, fastDummies, data.table, philentropy,
cluster, purrr, dplyr, tidyr, forcats, tibble, magrittr, fpc,
recipes, rsample, Rfast, readr, distances</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>palmerpenguins</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-11 17:35:43 UTC; amarkos</td>
</tr>
<tr>
<td>Author:</td>
<td>Alfonso Iodice D'Enza [aut],
  Angelos Markos [aut, cre],
  Michel van de Velden [aut],
  Carlo Cavicchia [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-12 19:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cdist'>Calculation of Pairwise Distances for Categorical Data</h2><span id='topic+cdist'></span>

<h3>Description</h3>

<p>Computes a distance matrix for categorical variables with support for validation data, multiple distance metrics, and variable weighting. The function implements various distance calculation approaches as described in van de Velden et al. (2024), including commensurable distances and supervised options when response variable is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdist(x, response = NULL, validate_x = NULL, method = "tot_var_dist",
      commensurable = FALSE, weights = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cdist_+3A_x">x</code></td>
<td>
<p>A data frame or matrix of categorical variables (factors).</p>
</td></tr>
<tr><td><code id="cdist_+3A_response">response</code></td>
<td>
<p>Optional response variable for supervised distance calculations. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="cdist_+3A_validate_x">validate_x</code></td>
<td>
<p>Optional validation data frame or matrix. If provided, distances are computed between observations in <code>validate_x</code> and <code>x</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="cdist_+3A_method">method</code></td>
<td>
<p>Character string or vector specifying the distance metric(s). Options include:
</p>

<ul>
<li> <p><code>"tot_var_dist"</code>: Total variation distance (default)
</p>
</li>
<li> <p><code>"HL"</code>, <code>"HLeucl"</code>: Hennig-Liao distance
</p>
</li>
<li> <p><code>"cat_dis"</code>: Category-based dissimilarity
</p>
</li>
<li> <p><code>"mca"</code>: Multiple correspondence analysis based
</p>
</li>
<li> <p><code>"st_dev"</code>: Standard deviation based
</p>
</li>
<li> <p><code>"matching"</code>, <code>"eskin"</code>, <code>"iof"</code>, <code>"of"</code>: Various coefficients
</p>
</li>
<li> <p><code>"goodall_3"</code>, <code>"goodall_4"</code>: Goodall-based distances
</p>
</li>
<li> <p><code>"gifi_chi2"</code>: Gifi chi-square distance
</p>
</li>
<li> <p><code>"lin"</code>: Lin's similarity measure
</p>
</li>
<li> <p><code>"var_entropy"</code>, <code>"var_mutability"</code>: Variability-based measures
</p>
</li>
<li> <p><code>"supervised"</code>, <code>"supervised_full"</code>: Response-guided distances
</p>
</li>
<li> <p><code>"le_and_ho"</code>: Le and Ho distance
</p>
</li>
<li><p> Additional methods from philentropy package
</p>
</li></ul>

<p>Can be a single string or vector for different methods per variable.</p>
</td></tr>
<tr><td><code id="cdist_+3A_commensurable">commensurable</code></td>
<td>
<p>Logical. If <code>TRUE</code>, standardizes each variable's distance matrix by dividing by its mean distance. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cdist_+3A_weights">weights</code></td>
<td>
<p>Numeric vector or matrix of weights. If vector, must have length equal to number of variables. If matrix, must match the dimension of level-wise distances. Default is 1 (equal weighting).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cdist</code> function provides a comprehensive framework for categorical distance calculations:
</p>

<ul>
<li><p> Supports multiple distance calculation methods that can be specified globally or per variable
</p>
</li>
<li><p> Handles validation data through <code>validate_x</code> parameter
</p>
</li>
<li><p> Implements supervised distances when response variable is provided
</p>
</li>
<li><p> Supports commensurable distances for better comparability across variables
</p>
</li>
<li><p> Provides flexible weighting schemes at variable and level granularity
</p>
</li></ul>

<p><strong>Important notes:</strong>
</p>

<ul>
<li><p> Input variables are automatically converted to factors with dropped unused levels
</p>
</li>
<li><p> Different methods per variable is not supported for <code>"none"</code>, <code>"st_dev"</code>, <code>"HL"</code>, <code>"cat_dis"</code>, <code>"HLeucl"</code>, <code>"mca"</code>
</p>
</li>
<li><p> Weight vector length must match the number of variables when specified as a vector
</p>
</li>
<li><p> Variables should be factors; numeric variables will cause errors
</p>
</li></ul>



<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>distance_mat</code></td>
<td>
<p>Matrix of pairwise distances. If <code>validate_x</code> is provided, rows correspond to validation observations and columns to training observations.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>Matrix or list of matrices containing level-wise distances for each variable.</p>
</td></tr>
<tr><td><code>delta_names</code></td>
<td>
<p>Vector of level names used in the delta matrices.</p>
</td></tr>
</table>


<h3>References</h3>

<p>van de Velden, M., Iodice D'Enza, A., Markos, A., Cavicchia, C. (2024). (Un)biased distances for mixed-type data. <em>arXiv preprint</em>. Retrieved from <a href="https://arxiv.org/abs/2411.00429">https://arxiv.org/abs/2411.00429</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mdist">mdist</a></code> for mixed-type data distances, <code><a href="#topic+ndist">ndist</a></code> for continuous data distances
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(palmerpenguins)
library(rsample)

# Prepare data with complete cases for both categorical variables and response
complete_vars &lt;- c("species", "island", "sex", "body_mass_g")
penguins_complete &lt;- penguins[complete.cases(penguins[, complete_vars]), ]
penguins_cat &lt;- penguins_complete[, c("species", "island", "sex")]
response &lt;- penguins_complete$body_mass_g

# Create training-test split
set.seed(123)
penguins_split &lt;- initial_split(penguins_cat, prop = 0.8)
tr_penguins &lt;- training(penguins_split)
ts_penguins &lt;- testing(penguins_split)
response_tr &lt;- response[penguins_split$in_id]
response_ts &lt;- response[-penguins_split$in_id]

# Basic usage
result &lt;- cdist(tr_penguins)

# With validation data
val_result &lt;- cdist(x = tr_penguins, 
                   validate_x = ts_penguins,
                   method = "tot_var_dist")
                   
# ...and commensurability
val_result_COMM &lt;- cdist(x = tr_penguins, 
                   validate_x = ts_penguins,
                   method = "tot_var_dist",
                   commensurable = TRUE)

# Supervised distance with response variable
sup_result &lt;- cdist(x = tr_penguins, 
                   response = response_tr,
                   method = "supervised")

# Supervised with validation data
sup_val_result &lt;- cdist(x = tr_penguins,
                       validate_x = ts_penguins,
                       response = response_tr,
                       method = "supervised")

# Commensurable distances with custom weights
comm_result &lt;- cdist(tr_penguins,
                    commensurable = TRUE,
                    weights = c(2, 1, 1))

# Different methods per variable
multi_method &lt;- cdist(tr_penguins,
                     method = c("matching", "goodall_3", "tot_var_dist"))

</code></pre>

<hr>
<h2 id='fifa_nl'>FIFA 21 Player Data - Dutch League</h2><span id='topic+fifa_nl'></span>

<h3>Description</h3>

<p>The <code>fifa_nl</code> dataset contains information on players in the Dutch League from the FIFA 21 video game. This dataset includes various attributes of players, such as demographics, club details, skill ratings, and physical characteristics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("fifa_nl")</code></pre>


<h3>Format</h3>

<p>A data frame with observations on various attributes describing the players.
</p>

<dl>
<dt><code>player_positions</code></dt><dd><p>Primary playing positions of the player.</p>
</dd>
<dt><code>nationality</code></dt><dd><p>The country the player represents.</p>
</dd>
<dt><code>team_position</code></dt><dd><p>Player's assigned position within their club.</p>
</dd>
<dt><code>club_name</code></dt><dd><p>Name of the club the player is part of.</p>
</dd>
<dt><code>work_rate</code></dt><dd><p>The player's work rate, describing defensive and attacking intensity.</p>
</dd>
<dt><code>weak_foot</code></dt><dd><p>Skill rating for the player's non-dominant foot, ranging from 1 to 5.</p>
</dd>
<dt><code>skill_moves</code></dt><dd><p>Skill moves rating, indicating technical skill and ability to perform complex moves, on a scale of 1 to 5.</p>
</dd>
<dt><code>international_reputation</code></dt><dd><p>Player's reputation on an international scale, from 1=local to 3=global star.</p>
</dd>
<dt><code>body_type</code></dt><dd><p>Body type of the player ( Lean, Normal, Stocky.</p>
</dd>
<dt><code>preferred_foot</code></dt><dd><p>Dominant foot of the player, either Left or Right.</p>
</dd>
<dt><code>age</code></dt><dd><p>Age of the player in years.</p>
</dd>
<dt><code>height_cm</code></dt><dd><p>Height of the player in centimeters.</p>
</dd>
<dt><code>weight_kg</code></dt><dd><p>Weight of the player in kilograms.</p>
</dd>
<dt><code>overall</code></dt><dd><p>Overall skill rating of the player out of 100.</p>
</dd>
<dt><code>potential</code></dt><dd><p>Potential skill rating the player may achieve in the future.</p>
</dd>
<dt><code>value_eur</code></dt><dd><p>Estimated market value of the player in Euros.</p>
</dd>
<dt><code>wage_eur</code></dt><dd><p>Player's weekly wage in Euros.</p>
</dd>
<dt><code>release_clause_eur</code></dt><dd><p>Release clause value in Euros, which other clubs must pay to buy out the player's contract.</p>
</dd>
<dt><code>pace</code></dt><dd><p>Speed rating of the player out of 100.</p>
</dd>
<dt><code>shooting</code></dt><dd><p>Shooting skill rating out of 100.</p>
</dd>
<dt><code>passing</code></dt><dd><p>Passing skill rating out of 100.</p>
</dd>
<dt><code>dribbling</code></dt><dd><p>Dribbling skill rating out of 100.</p>
</dd>
<dt><code>defending</code></dt><dd><p>Defending skill rating out of 100.</p>
</dd>
<dt><code>physic</code></dt><dd><p>Physicality rating out of 100.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset provides a snapshot of player attributes and performance indicators as represented in FIFA 21 for players in the Dutch League. It can be used to analyze player characteristics, compare skills across players, and explore potential relationships among variables such as age, position, and various skill ratings.
</p>


<h3>References</h3>

<p>Stefano Leone. (2021). <em>FIFA 21 Complete Player Dataset</em>. Retrieved from <a href="https://www.kaggle.com/datasets/stefanoleone992/fifa-21-complete-player-dataset">https://www.kaggle.com/datasets/stefanoleone992/fifa-21-complete-player-dataset</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fifa_nl)
summary(fifa_nl)
</code></pre>

<hr>
<h2 id='mdist'>Calculation of Pairwise Distances for Mixed-Type Data</h2><span id='topic+mdist'></span>

<h3>Description</h3>

<p>Computes pairwise distances between observations described by numeric and/or categorical attributes, with support for validation data. The function provides options for computing independent, dependent, and practice-based distances as defined in van de Velden et al. (2024), with support for various continuous and categorical distance metrics, scaling, and commensurability adjustments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdist(x, validate_x = NULL, response = NULL, distance_cont = "manhattan", 
      distance_cat = "tot_var_dist", commensurable = FALSE, scaling = "none",
      ncomp = ncol(x), threshold = NULL, preset = "custom")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mdist_+3A_x">x</code></td>
<td>
<p>A dataframe or tibble containing continuous (coded as numeric), categorical (coded as factors), or mixed-type variables.</p>
</td></tr>
<tr><td><code id="mdist_+3A_validate_x">validate_x</code></td>
<td>
<p>Optional validation data with the same structure as <code>x</code>. If provided, distances are computed between observations in <code>validate_x</code> and <code>x</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_response">response</code></td>
<td>
<p>An optional factor for supervised distance calculation in categorical variables, applied only if <code>distance_cat = "supervised"</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_distance_cont">distance_cont</code></td>
<td>
<p>Character string specifying the distance metric for continuous variables. Options include <code>"manhattan"</code> (default) and <code>"euclidean"</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_distance_cat">distance_cat</code></td>
<td>
<p>Character string specifying the distance metric for categorical variables. Options include <code>"tot_var_dist"</code> (default), <code>"HL"</code>, <code>"HLeucl"</code>, <code>cat_dis</code>, <code>mca</code>, <code>st_dev</code>,  <code>"matching"</code>, <code>"eskin"</code>, <code>"iof"</code>, <code>"of"</code>, <code>"goodall_3"</code>, <code>"goodall_4"</code>, <code>"gifi_chi2"</code>, <code>"lin"</code>, <code>"var_entropy"</code>, <code>"var_mutability"</code>, <code>"supervised"</code>, <code>"supervised_full"</code>, <code>"le_and_ho"</code> and all the options in the package philentropy.</p>
</td></tr>
<tr><td><code id="mdist_+3A_commensurable">commensurable</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the function adjusts each variable's contribution to ensure equal average influence in the overall distance. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_scaling">scaling</code></td>
<td>
<p>Character string specifying the scaling method for continuous variables. Options include <code>"none"</code> (default), <code>"std"</code>, <code>"range"</code>, <code>"pc_scores"</code>, and <code>"robust"</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_ncomp">ncomp</code></td>
<td>
<p>Integer specifying the number of components to retain when <code>scaling = "pc_scores"</code>. Default is <code>ncol(x)</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_threshold">threshold</code></td>
<td>
<p>Numeric value specifying the percentage of variance explained by retained components when <code>scaling = "pc_scores"</code>. Overrides <code>ncomp</code> if specified. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mdist_+3A_preset">preset</code></td>
<td>
<p>Character string specifying pre-defined combinations of arguments. Options include:
</p>

<ul>
<li><p><code>"custom"</code> (default): Use specified distance metrics and parameters
</p>
</li>
<li><p><code>"gower"</code>: Gower's distance for mixed data
</p>
</li>
<li><p><code>"unbiased_dependent"</code>: Total variation distance for categorical and Manhattan for standardized continuous
</p>
</li>
<li><p><code>"euclidean_onehot"</code>: Euclidean distance on one-hot encoded categorical and standardized continuous
</p>
</li>
<li><p><code>"catdissim"</code>: Matching distance for categorical and Manhattan for standardized continuous
</p>
</li></ul>

</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of pairwise distances. If <code>validate_x</code> is provided, rows correspond to validation observations and columns to training observations.
</p>


<h3>References</h3>

<p>van de Velden, M., Iodice D'Enza, A., Markos, A., Cavicchia, C. (2024). (Un)biased distances for mixed-type data. <em>arXiv preprint</em>. Retrieved from <a href="https://arxiv.org/abs/2411.00429">https://arxiv.org/abs/2411.00429</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdist">cdist</a></code> for categorical-only distances, <code><a href="#topic+ndist">ndist</a></code> for continuous-only distances
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(palmerpenguins)
library(rsample)

# Prepare complete data
pengmix &lt;- palmerpenguins::penguins[complete.cases(palmerpenguins::penguins), ]

# Create training-test split
set.seed(123)
pengmix_split &lt;- initial_split(pengmix, prop = 0.8)
tr_pengmix &lt;- training(pengmix_split)
ts_pengmix &lt;- testing(pengmix_split)

# Example 1: Basic usage with validation data
dist_matrix &lt;- mdist(x = tr_pengmix, 
                    validate_x = ts_pengmix)

# Example 2: Gower preset with validation
dist_gower &lt;- mdist(x = tr_pengmix, 
                   validate_x = ts_pengmix,
                   preset = "gower", 
                   commensurable = TRUE)

# Example 3: Euclidean one-hot preset with validation
dist_onehot &lt;- mdist(x = tr_pengmix, 
                    validate_x = ts_pengmix,
                    preset = "euclidean_onehot")

# Example 4: Custom preset with standardization
dist_custom &lt;- mdist(x = tr_pengmix,
                    validate_x = ts_pengmix,
                    preset = "custom",
                    distance_cont = "manhattan",
                    distance_cat = "matching",
                    commensurable = TRUE,
                    scaling = "std")

# Example 5: PCA-based scaling with threshold
dist_pca &lt;- mdist(x = tr_pengmix,
                 validate_x = ts_pengmix,
                 distance_cont = "euclidean",
                 scaling = "pc_scores",
                 threshold = 0.85)

# Example 6: Categorical variables only
cat_vars &lt;- c("species", "island", "sex")
dist_cat &lt;- mdist(tr_pengmix[, cat_vars],
                 validate_x = ts_pengmix[, cat_vars],
                 distance_cat = "tot_var_dist")

# Example 7: Continuous variables only
num_vars &lt;- c("bill_length_mm", "bill_depth_mm", 
              "flipper_length_mm", "body_mass_g")
dist_cont &lt;- mdist(tr_pengmix[, num_vars],
                  validate_x = ts_pengmix[, num_vars],
                  distance_cont = "manhattan",
                  scaling = "std")

# Example 8: Supervised distance with response
response_tr &lt;- tr_pengmix$body_mass_g
dist_sup &lt;- mdist(tr_pengmix,
                 validate_x = ts_pengmix,
                 response = response_tr,
                 distance_cat = "supervised")


</code></pre>

<hr>
<h2 id='ndist'>Calculation of Pairwise Distances for Continuous Data</h2><span id='topic+ndist'></span>

<h3>Description</h3>

<p>Computes a distance matrix for continuous data with support for multiple distance metrics, scaling methods, dimensionality reduction, and validation data. The function implements various distance calculation approaches as described in van de Velden et al. (2024), including options for commensurable distances and variable weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ndist(x, validate_x = NULL, commensurable = FALSE, method = "manhattan",
      sig = NULL, scaling = "none", ncomp = ncol(x), threshold = NULL,
      weights = rep(1, ncol(x)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ndist_+3A_x">x</code></td>
<td>
<p>A data frame or matrix of continuous input variables.</p>
</td></tr>
<tr><td><code id="ndist_+3A_validate_x">validate_x</code></td>
<td>
<p>Optional data frame or matrix for validation data. If provided, distances are computed between observations in <code>validate_x</code> and <code>x</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_commensurable">commensurable</code></td>
<td>
<p>Logical. If <code>TRUE</code>, standardizes each variable's distance matrix by dividing by its mean distance, making distances comparable across variables. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_method">method</code></td>
<td>
<p>Character string specifying the distance metric. Options include <code>"manhattan"</code>, <code>"euclidean"</code>, and <code>"mahalanobis"</code>. Default is <code>"manhattan"</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_sig">sig</code></td>
<td>
<p>Covariance matrix to be used when <code>method = "mahalanobis"</code>. If <code>NULL</code>, computed from the data. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_scaling">scaling</code></td>
<td>
<p>Character string specifying the scaling method. Options:
</p>

<ul>
<li> <p><code>"none"</code>: No scaling
</p>
</li>
<li> <p><code>"std"</code>: Standardization (zero mean, unit variance)
</p>
</li>
<li> <p><code>"range"</code>: Min-max scaling to [0,1]
</p>
</li>
<li> <p><code>"pc_scores"</code>: PCA-based dimensionality reduction
</p>
</li>
<li> <p><code>"robust"</code>: Robust scaling using median and IQR
</p>
</li></ul>

<p>Default is <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of principal components to retain when <code>scaling = "pc_scores"</code>. Default is the number of columns in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_threshold">threshold</code></td>
<td>
<p>Proportion of variance to retain when <code>scaling = "pc_scores"</code>. If specified, overrides <code>ncomp</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ndist_+3A_weights">weights</code></td>
<td>
<p>Numeric vector of weights for each variable. Must have length equal to the number of variables in <code>x</code>. Default is a vector of ones.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>ndist</code> function provides a comprehensive framework for distance calculations in continuous data:
</p>

<ul>
<li><p> When <code>validate_x</code> is provided, computes distances between observations in <code>validate_x</code> and <code>x</code>.
</p>
</li>
<li><p> Supports multiple scaling methods that can be applied before distance calculation.
</p>
</li>
<li><p> PCA-based dimensionality reduction can be controlled either by number of components or variance threshold.
</p>
</li>
<li><p> For Mahalanobis distance, handles singular covariance matrices with appropriate error messages.
</p>
</li>
<li><p> Implements commensurable distances for better comparability across variables.
</p>
</li></ul>

<p><strong>Warning:</strong> The function validates:
</p>

<ul>
<li><p> Weight vector length must match the number of variables
</p>
</li>
<li><p> Covariance matrix singularity for Mahalanobis distance
</p>
</li>
<li><p> Compatibility of <code>x</code> and <code>validate_x</code> dimensions
</p>
</li></ul>



<h3>Value</h3>

<p>A distance matrix where element [i,j] represents the distance between:
</p>

<ul>
<li><p> observation i and j of <code>x</code> if <code>validate_x</code> is <code>NULL</code>
</p>
</li>
<li><p> observation i of <code>validate_x</code> and observation j of <code>x</code> if <code>validate_x</code> is provided
</p>
</li></ul>



<h3>References</h3>

<p>van de Velden, M., Iodice D'Enza, A., Markos, A., Cavicchia, C. (2024). (Un)biased distances for mixed-type data. <em>arXiv preprint</em>. Retrieved from <a href="https://arxiv.org/abs/2411.00429">https://arxiv.org/abs/2411.00429</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mdist">mdist</a></code> for mixed-type data distances, <code><a href="#topic+cdist">cdist</a></code> for categorical data distances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(palmerpenguins)
library(rsample)

penguins_cont &lt;- palmerpenguins::penguins[, c("bill_length_mm",
"bill_depth_mm", "flipper_length_mm", "body_mass_g")]
penguins_cont &lt;- penguins_cont[complete.cases(penguins_cont), ]

# Basic usage
dist_matrix &lt;- ndist(penguins_cont)

# Commensurable distances with standardization
dist_matrix &lt;- ndist(penguins_cont, 
                    commensurable = TRUE, 
                    scaling = "std")

# PCA-based dimensionality reduction
dist_matrix &lt;- ndist(penguins_cont, 
                    scaling = "pc_scores", 
                    threshold = 0.95)

# Mahalanobis distance
dist_matrix &lt;- ndist(penguins_cont, 
                    method = "mahalanobis")

# Weighted Euclidean distance
dist_matrix &lt;- ndist(penguins_cont, 
                    method = "euclidean",
                    weights = c(1, 0.5, 2, 1))
                    
# Training-test split example with validation data
set.seed(123)
# Create training-test split using rsample
penguins_split &lt;- initial_split(penguins_cont, prop = 0.8)
tr_penguins &lt;- training(penguins_split)
ts_penguins &lt;- testing(penguins_split)

# Basic usage with training data only
dist_matrix &lt;- ndist(tr_penguins)

# Computing distances between test and training sets
val_dist_matrix &lt;- ndist(x = tr_penguins, 
                        validate_x = ts_penguins,
                        method = "euclidean")

# Using validation data with standardization
val_dist_matrix_std &lt;- ndist(x = tr_penguins,
                            validate_x = ts_penguins,
                            scaling = "std",
                            method = "manhattan")

# Validation with PCA and commensurability
val_dist_matrix_pca &lt;- ndist(x = tr_penguins,
                            validate_x = ts_penguins,
                            scaling = "pc_scores",
                            ncomp = 2,
                            commensurable = TRUE)

# Validation with robust scaling and custom weights
val_dist_matrix_robust &lt;- ndist(x = tr_penguins,
                               validate_x = ts_penguins,
                               scaling = "robust",
                               weights = c(1, 0.5, 2, 1))

# Mahalanobis distance with validation data
val_dist_matrix_mahal &lt;- ndist(x = tr_penguins,
                              validate_x = ts_penguins,
                              method = "mahalanobis")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
