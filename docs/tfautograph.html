<!DOCTYPE html><html><head><title>Help for package tfautograph</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfautograph}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[[&lt;-.tensorflow.python.ops.tensor_array_ops.TensorArray'><p><code>TensorArray.write()</code></p></a></li>
<li><a href='#ag_if_vars'><p>Specify <code>tf.cond()</code> output structure when autographing <code>if</code></p></a></li>
<li><a href='#ag_loop_vars'><p>Specify loop variables</p></a></li>
<li><a href='#ag_name'><p>Specify a tensor name</p></a></li>
<li><a href='#ag_while_opts'><p>specify <code>tf.while_loop</code> options</p></a></li>
<li><a href='#autograph'><p>Autograph R code</p></a></li>
<li><a href='#tf_assert'><p>tf_assert</p></a></li>
<li><a href='#tf_case'><p>tf.case</p></a></li>
<li><a href='#tf_cond'><p>tf.cond</p></a></li>
<li><a href='#tf_map'><p><code>tf.map_fn()</code></p></a></li>
<li><a href='#tf_switch'><p>tf.switch_case</p></a></li>
<li><a href='#view_function_graph'><p>Visualizes the generated graph</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Autograph R for 'Tensorflow'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Translate R control flow expressions into 'Tensorflow' graphs.</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>TensorFlow (https://www.tensorflow.org/)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://t-kalinowski.github.io/tfautograph/">https://t-kalinowski.github.io/tfautograph/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/t-kalinowski/tfautograph/issues">https://github.com/t-kalinowski/tfautograph/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate, backports</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rlang, tensorflow, testthat (&ge; 2.1.0)</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-17 20:11:35 UTC; tomasz</td>
</tr>
<tr>
<td>Author:</td>
<td>Tomasz Kalinowski [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomasz Kalinowski &lt;kalinowskit@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-17 20:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B+5B+26lt+3B-.tensorflow.python.ops.tensor_array_ops.TensorArray'><code>TensorArray.write()</code></h2><span id='topic++5B+5B+3C-.tensorflow.python.ops.tensor_array_ops.TensorArray'></span>

<h3>Description</h3>

<p><code>TensorArray.write()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 replacement method for class 'tensorflow.python.ops.tensor_array_ops.TensorArray'
ta[[i, ..., name = NULL]] &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B+2B5B+2B26lt+2B3B-.tensorflow.python.ops.tensor_array_ops.TensorArray_+3A_ta">ta</code></td>
<td>
<p>a tensorflow <code>TensorArray</code></p>
</td></tr>
<tr><td><code id="+2B5B+2B5B+2B26lt+2B3B-.tensorflow.python.ops.tensor_array_ops.TensorArray_+3A_i">i</code></td>
<td>
<p>something castable to an int32 scalar tensor. 0-based.</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B+2B26lt+2B3B-.tensorflow.python.ops.tensor_array_ops.TensorArray_+3A_...">...</code></td>
<td>
<p>Error if anything is passed to <code>...</code></p>
</td></tr>
<tr><td><code id="+2B5B+2B5B+2B26lt+2B3B-.tensorflow.python.ops.tensor_array_ops.TensorArray_+3A_name">name</code></td>
<td>
<p>A scalar string, name of the op</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B+2B26lt+2B3B-.tensorflow.python.ops.tensor_array_ops.TensorArray_+3A_value">value</code></td>
<td>
<p>The value to write.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ta &lt;- tf$TensorArray(tf$float32, size = 5L)
for(i in 0:4)
  ta[[i]] &lt;- i
ta$stack()

# You can use this to grow objects in graph mode
accuracies_log &lt;- tf$TensorArray(tf$float32, size = 0L, dynamic_size=TRUE)
for(epoch in 0:4)
  accuracies_log[[epoch]] &lt;- runif(1)
acc &lt;- accuracies_log$stack()
acc

## End(Not run)
</code></pre>

<hr>
<h2 id='ag_if_vars'>Specify <code>tf.cond()</code> output structure when autographing <code>if</code></h2><span id='topic+ag_if_vars'></span>

<h3>Description</h3>

<p>This function can be used to specify the output structure from <code>tf.cond()</code>
when autographing an <code>if</code> statement. In most use cases, use of this function
is purely optional. If not supplied, the <code>if</code> output structure is
automatically built.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ag_if_vars(
  ...,
  modified = list(),
  return = FALSE,
  undefs = NULL,
  control_flow = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ag_if_vars_+3A_...">...</code></td>
<td>
<p>Variables modified by the <code>tf.cond()</code> node supplied as bare
symbols like <code>foo</code> or expressions using <code>$</code> e.g, <code>foo$bar</code>. Symbols do not
have to exist before the autographed <code>if</code> so long as they are created in
both branches.</p>
</td></tr>
<tr><td><code id="ag_if_vars_+3A_modified">modified</code></td>
<td>
<p>Variables names supplied as a character vector, or a list of
character vectors if specifying nested complex structures. This is an
escape hatch for the lazy evaluation semantics of <code>...</code></p>
</td></tr>
<tr><td><code id="ag_if_vars_+3A_return">return</code></td>
<td>
<p>logical, whether to include the return value the evaluated R
expression in the <code>tf.cond()</code>. if <code>FALSE</code> (the default), only the objects
assigned in scope are captured.</p>
</td></tr>
<tr><td><code id="ag_if_vars_+3A_undefs">undefs</code></td>
<td>
<p>A bare character vector or a list of character vectors.
Supplied names are exported as undefs in the parent frame. This is used to
give a more informative error message when attempting to access a variable
that can't be balanced between branches.</p>
</td></tr>
<tr><td><code id="ag_if_vars_+3A_control_flow">control_flow</code></td>
<td>
<p>An integer, the maximum number of control-flow statements
(<code>break</code> and/or <code>next</code>) that will be captured in a single branch as part of
the <code>tf.cond()</code>. Do not count statements in loops that are dispatching to
standard R control flow (e.g., don't count <code>break</code> statements in a <code>for</code>
loop that is iterating over an R vector)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the output structure is not explicitly supplied via
<code>ag_if_vars()</code>, then the output structure is automatically composed: The
true and false branches of the expression are traced into concrete
functions, then the output signature from the two branch functions are
balanced. Balancing is performed by either fetching a variable from an
outer scope or by reclassifying a symbol as an undef.
</p>
<p>When dealing with complex composites (that is, nested structures where a
modified tensor is part of a named list or dictionary), care is taken to
prevent unnecessarily capturing other unmodified tensors in the structure.
This is done by pruning unmodified tensors from the returned output
structure, and then merging them back with the original object recursively.
One limitation of the implementation is that lists must either be fully
named with unique names, or not named at all, partially named lists or
duplicated names in a list throw an error. This is due to the conversion
that happens when going between python and R: named lists get converted to
python dictionaries, which require that all keys are unique. Additionally,
pruning of unmodified objects from an autographed <code>if</code> is currently only
supported for named lists (python dictionaries). Unnamed lists or tuples
are passed as is (e.g, no pruning and merging done), which may lead to
unnecessarily bloat in the constructed graphs.
</p>


<h3>Value</h3>

<p><code>NULL</code>, invisibly
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# these examples only have an effect in graph mode
# to enter graph mode easily we'll create a few helpers
ag &lt;- autograph

# pass which symbols you expect to be modifed or created liks this:
ag_if_vars(x)
ag(if (y &gt; 0) {
  x &lt;- y * y
} else {
  x &lt;- y
})

# if the return value from the if expression is important, pass `return = TRUE`
ag_if_vars(return = TRUE)
x &lt;- ag(if(y &gt; 0) y * y else y)

# pass complex nested structures like this
x &lt;- list(a = 1, b = 2)

ag_if_vars(x$a)
ag(if(y &gt; 0) {
  x$a &lt;- y
})

# undefs are for mark branch-local variables
ag_if_vars(y, x$a, undef = "tmp_local_var")
ag(if(y &gt; 0) {
  y &lt;- y * 100
  tmp_local_var &lt;- y + 1
  x$a &lt;- tmp_local_var
})

# supplying `undef` is not necessary, it exists purely as a way to supply a
# guardrail for defensive programming and/or to improve code readability

## modified vars can be supplied in `...` or as a named arg.
## these paires of ag_if_vars() calls are equivalent
ag_if_vars(y, x$a)
ag_if_vars(modified = list("y", c("x", "a")))

ag_if_vars(x, y, z)
ag_if_vars(modified = c("x", "y", "z"))


## control flow
# count number of odds between 0:10
ag({
  x &lt;- 10
  count &lt;- 0
  while(x &gt; 0) {
    ag_if_vars(control_flow = 1)
    if(x %% 2 == 0)
      next
    count &lt;- count + 1
  }
})

## End(Not run)
</code></pre>

<hr>
<h2 id='ag_loop_vars'>Specify loop variables</h2><span id='topic+ag_loop_vars'></span>

<h3>Description</h3>

<p>This can be used to manually specify which variables are to be included
explicitly as <code>loop_vars</code> when autographing an expression into a
<code>tf.while_loop()</code> call, or the <code>loop_vars</code> equivalent when building a
<code>dataset.reduce()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ag_loop_vars(
  ...,
  list = character(),
  include = character(),
  exclude = character(),
  undef = character()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ag_loop_vars_+3A_...">...</code></td>
<td>
<p>Variables as bare symbol names</p>
</td></tr>
<tr><td><code id="ag_loop_vars_+3A_list">list</code>, <code id="ag_loop_vars_+3A_include">include</code>, <code id="ag_loop_vars_+3A_exclude">exclude</code></td>
<td>
<p>optionally, the variable names as a character
vector (use this as an escape hatch from the <code>...</code> lazy evaluation
semantics).</p>
</td></tr>
<tr><td><code id="ag_loop_vars_+3A_undef">undef</code></td>
<td>
<p>character vector of symbols</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use of this is usually not required as the loop variables are automatically
inferred. Inference is done by statically looking through the loop body and
finding the symbols that are the targets of the common assignment operators
from base R (<code style="white-space: pre;">&#8288;&lt;-&#8288;</code>, <code style="white-space: pre;">&#8288;-&gt;&#8288;</code>, <code>=</code>), from package:zeallot (<code style="white-space: pre;">&#8288;%&lt;-%&#8288;</code> and <code style="white-space: pre;">&#8288;%-&gt;%&#8288;</code>) and
package:magrittr (<code style="white-space: pre;">&#8288;%&lt;&gt;%&#8288;</code>).
</p>
<p>In certain circumstances, this approach may capture variables that are
intended to be local variables only. In those circumstances it is also
possible to specify them preceded with a <code>-</code>.
</p>
<p>Note, the specified loop vars are expected to exist before the autographed
expression, and a warning is issued otherwise (usually immediately preceding
an error thrown when attempting to actually autograph the expression)
</p>
<p>Only bare symbol names can be supplied as loop vars. In the future, support
may be expanded to allow for nested complex composites (e.g., specifying
variables that are nested within a more complex structure&ndash;passing
<code>ag_loop_vars(foo$bar$baz)</code> is currently not supported.)
</p>


<h3>Value</h3>

<p>the specified hint invisibly.
</p>


<h3>Note</h3>

<p>The semantics of this function are inspired by base::rm()
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
i &lt;- tf$constant(0L)

autograph({
  ag_loop_vars(x, i)
  while(x &gt; 0) {
    if(x %%2 == 0)
      i &lt;- i + 1L
    x &lt;- x - 1
  }
})

## sometimes, a variable is infered to be a loop_var unnecessarily. For example
x &lt;- tf$constant(1:10)

# imagine x is left over in the current scope from some previous calculations
# It's value is not important, but it exists
autograph({
  for(i in tf$constant(1:6)) {
    x &lt;- i * i
    tf$print(x)
  }
})

# this will throw an error because `x` was infered to be a `loop_var`,
# but it's shape witin the loop body is different from what it was before.
# there are two solutions to prevent `x` from being captured as a loop_var
## 1) remove `x` from the current scope like so:
rm(x)

## 2) provide a hint like so:
ag_loop_vars(-x)

## if your variable names are being dynamically generated, there is an
## escape hatch for the lazy evaluation semantics of ...
ag_loop_vars(exclude = "x")

## End(Not run)
</code></pre>

<hr>
<h2 id='ag_name'>Specify a tensor name</h2><span id='topic+ag_name'></span>

<h3>Description</h3>

<p>This can be used before any autographed expression that results in the
creation of a tensor or op graph node. This can be used before <code>for</code> (both with tensors and datasets), <code>while</code>, and <code>if</code> statements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ag_name(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ag_name_+3A_x">x</code></td>
<td>
<p>A string</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>x</code>, invisibly
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## when you're in graph mode. (e.g, tf$executing_eagerly == FALSE)

ag_name("main-training-loop")
for(elem in dataset) ...

## End(Not run)
</code></pre>

<hr>
<h2 id='ag_while_opts'>specify <code>tf.while_loop</code> options</h2><span id='topic+ag_while_opts'></span>

<h3>Description</h3>

<p>See https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/while_loop
for additional details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ag_while_opts(
  ...,
  shape_invariants = NULL,
  parallel_iterations = 10L,
  back_prop = TRUE,
  swap_memory = FALSE,
  maximum_iterations = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ag_while_opts_+3A_...">...</code></td>
<td>
<p>Ignored, used to ensure all arguments supplied are named.</p>
</td></tr>
<tr><td><code id="ag_while_opts_+3A_shape_invariants">shape_invariants</code></td>
<td>
<p>The shape invariants for the loop variables.</p>
</td></tr>
<tr><td><code id="ag_while_opts_+3A_parallel_iterations">parallel_iterations</code></td>
<td>
<p>The number of iterations allowed to run in
parallel. It must be a positive integer.</p>
</td></tr>
<tr><td><code id="ag_while_opts_+3A_back_prop">back_prop</code></td>
<td>
<p>Deprecated (optional). <code>FALSE</code> disables support for back
propagation. Prefer using <code>tf$stop_gradient</code> instead.</p>
</td></tr>
<tr><td><code id="ag_while_opts_+3A_swap_memory">swap_memory</code></td>
<td>
<p>Whether GPU-CPU memory swap is enabled for this loop.</p>
</td></tr>
<tr><td><code id="ag_while_opts_+3A_maximum_iterations">maximum_iterations</code></td>
<td>
<p>Optional maximum number of iterations of the while
loop to run. If provided, the <code>cond</code> output is AND-ed with an additional
condition ensuring the number of iterations executed is no greater than
<code>maximum_iterations</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>&lsquo;NULL&ldquo; invisibly, called for it&rsquo;s side effect.
</p>


<h3>Note</h3>

<p>Use <code><a href="#topic+ag_name">ag_name()</a></code> to supply <code>name</code> and <code><a href="#topic+ag_loop_vars">ag_loop_vars()</a></code> to supply
<code>loop_vars</code> directly.
</p>
<p>This is only applicable when autograph in graph mode, otherwise this has no
effect.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## use tf_function() to enter graph mode:
tf_function(autograph(function(n) {
  ag_name("silly-example")
  ag_while_opts(back_prop = FALSE)
  while(n &gt; 0)
    n &lt;- n - 1
}))

## End(Not run)
</code></pre>

<hr>
<h2 id='autograph'>Autograph R code</h2><span id='topic+autograph'></span>

<h3>Description</h3>

<p>Note, this documentation page is meant to serve as a technical reference, not
an introduction to <code>autograph</code>. For the latter, please visit the
documentation website: (https://t-kalinowski.github.io/tfautograph/) or see
the package vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autograph(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autograph_+3A_x">x</code></td>
<td>
<p>a function supplied as a bare symbol, or an expression</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>x</code> is a function, then the the same function with a new parent
environment, <code>package:tfautograph:ag_mask</code>, which is the autograph mask
that contains implementations of R control flow primitives that are capable
of handling tensorflow tensors. The parent of the
<code>package:tfautograph:ag_mask</code> in turn is the original environment of <code>x</code>.
</p>
<p>if <code>x</code> is an expression, then that expression is evaluated in a special
environment with the autograph mask <code>ag_mask</code> active. If the result of that
expression included local assignment or modifications of variables, (for
example, via <code style="white-space: pre;">&#8288;&lt;-&#8288;</code>), those modified variables are then exported into the
current frame. The return value of the expression is then returned.
</p>

<hr>
<h2 id='tf_assert'>tf_assert</h2><span id='topic+tf_assert'></span>

<h3>Description</h3>

<p>A thin wrapper around <code>tf$Assert()</code> that automatically constructs an
informative error message (passed on to <code>data</code> argument), which includes the
expression passed to <code>condition</code>, the values of the symbols found in the
expression, as well as the full R call stack at the time the <code>tf$Assert()</code>
node is created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_assert(
  condition,
  ...,
  expr = substitute(condition),
  summarize = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_assert_+3A_condition">condition</code></td>
<td>
<p>A boolean tensor</p>
</td></tr>
<tr><td><code id="tf_assert_+3A_...">...</code></td>
<td>
<p>Additional elements passed on to <code>data</code>. (e.g, an informative
error message as a string, additional tensor values that might be useful to
have in the error message, etc.)</p>
</td></tr>
<tr><td><code id="tf_assert_+3A_expr">expr</code></td>
<td>
<p>A language object, provided in case <code>condition</code> is already
computed prior to the call</p>
</td></tr>
<tr><td><code id="tf_assert_+3A_summarize">summarize</code></td>
<td>
<p>Print this many entries of each tensor.</p>
</td></tr>
<tr><td><code id="tf_assert_+3A_name">name</code></td>
<td>
<p>A name for this operation (optional).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- tf$constant(-1)
try(tf_assert(x &gt; 0, "oopsies! x must be greater than 0"))

## End(Not run)
</code></pre>

<hr>
<h2 id='tf_case'>tf.case</h2><span id='topic+tf_case'></span>

<h3>Description</h3>

<p>This is a minimal wrapper around <code>tf.case()</code> that allows you to supply the
<code>pred_fn_pairs</code> using the <code>~</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_case(
  ...,
  pred_fn_pairs = list(...),
  default = NULL,
  exclusive = FALSE,
  name = "case"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_case_+3A_...">...</code>, <code id="tf_case_+3A_pred_fn_pairs">pred_fn_pairs</code></td>
<td>
<p>a list <code>pred_fn_pairs</code> supplied with the <code>~</code> like
so: <code>pred ~ fn_body</code></p>
</td></tr>
<tr><td><code id="tf_case_+3A_default">default</code></td>
<td>
<p>a function, optionally specified with the <code>~</code>, (or something
coercible to a function via <code>as.function()</code>)</p>
</td></tr>
<tr><td><code id="tf_case_+3A_exclusive">exclusive</code></td>
<td>
<p>bool, whether to evaluate all <code>preds</code> and ensure only one is
true. If <code>FALSE</code> (the default), then the <code>preds</code> are evaluated in the order
supplied until the first <code>TRUE</code> value is encountered (effectively, acting
as an <code style="white-space: pre;">&#8288;if()... else if() ... else if() ...&#8288;</code> chain)</p>
</td></tr>
<tr><td><code id="tf_case_+3A_name">name</code></td>
<td>
<p>a string, passed on to <code>tf.case()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result from <code>tf$case()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fizz_buzz_one &lt;- function(x) {
  tf_case(
    x %% 15 == 0 ~ "FizzBuzz",
    x %%  5 == 0 ~ "Buzz",
    x %%  3 == 0 ~ "Fizz",
    default = ~ tf$as_string(x, precision = 0L)
  )
}

fn &lt;- tf_function(autograph(function(n) {
  for(e in tf$range(n))
    tf$print(fizz_buzz_one(e))
}))

x &lt;- tf$constant(16)
fn(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='tf_cond'>tf.cond</h2><span id='topic+tf_cond'></span>

<h3>Description</h3>

<p>This is a minimal wrapper around <code>tf$cond()</code> that allows you to supply
<code>true_fn</code> and <code>false_fn</code> as lambda functions defined using the tilde <code>~</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_cond(pred, true_fn, false_fn, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_cond_+3A_pred">pred</code></td>
<td>
<p>R logical or a tensor.</p>
</td></tr>
<tr><td><code id="tf_cond_+3A_true_fn">true_fn</code>, <code id="tf_cond_+3A_false_fn">false_fn</code></td>
<td>
<p>a <code>~</code> function, a function, or something coercible to
a function via <code>as.function</code></p>
</td></tr>
<tr><td><code id="tf_cond_+3A_name">name</code></td>
<td>
<p>a string, passed on to <code>tf.cond()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>if cond is a tensor, then the result of <code>tf.cond()</code>. Otherwise, if
<code>pred</code> is an <code>EagerTensor</code> or an R logical, then the result of either
<code>true_fn()</code> or <code>false_fn()</code>
</p>


<h3>Note</h3>

<p>in Tensorflow version 1, the <code>strict</code> keyword argument is supplied with
a value of <code>TRUE</code> (different from the default)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## square if positive
# using tf$cond directly:
raw &lt;- function(x) tf$cond(x &gt; 0, function() x * x, function() x)

# using tf_cond() wrapper
tilde &lt;- function(x) tf_cond(x &gt; 0, ~ x * x, ~ x)

## End(Not run)
</code></pre>

<hr>
<h2 id='tf_map'><code>tf.map_fn()</code></h2><span id='topic+tf_map'></span>

<h3>Description</h3>

<p>Thin wrapper around <code>tf.map_fn()</code> with the following
differences:
</p>

<ul>
<li><p> accepts <code>purrr</code> style <code>~</code> lambda syntax to define function <code>fn</code>.
</p>
</li>
<li><p> The order of <code>elems</code> and <code>fn</code> is switched to make it more pipe <code style="white-space: pre;">&#8288;%&gt;%&#8288;</code>
friendly and consistent with R mappers <code>lapply()</code> and <code>purrr::map()</code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>tf_map(
  elems,
  fn,
  dtype = NULL,
  parallel_iterations = NULL,
  back_prop = TRUE,
  swap_memory = FALSE,
  infer_shape = TRUE,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_map_+3A_elems">elems</code></td>
<td>
<p>A tensor or (possibly nested) sequence of tensors, each of which
will be unpacked along their first dimension. The nested sequence of the
resulting slices will be applied to <code>fn</code>.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_fn">fn</code></td>
<td>
<p>An R function, specified using <code>purrr</code> style ~ syntax, a character
string, a python function (or more generally, any python object with a
<code style="white-space: pre;">&#8288;__call__&#8288;</code> method) or anything coercible via <code>as.function()</code>. The function
will be be called with one argument, which will have the same (possibly
nested) structure as <code>elems</code>. Its output must return the same structure as
<code>dtype</code> if one is provided, otherwise it must return the same structure as
<code>elems</code>.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_dtype">dtype</code></td>
<td>
<p>(optional) The output type(s) of fn. If fn returns a structure
of Tensors differing from the structure of elems, then dtype is not
optional and must have the same structure as the output of fn.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_parallel_iterations">parallel_iterations</code></td>
<td>
<p>(optional) The number of iterations allowed to
run in parallel. When graph building, the default value is 10. While
executing eagerly, the default value is set to 1.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_back_prop">back_prop</code></td>
<td>
<p>(optional) True enables support for back propagation.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_swap_memory">swap_memory</code></td>
<td>
<p>(optional) True enables GPU-CPU memory swapping.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_infer_shape">infer_shape</code></td>
<td>
<p>(optional) False disables tests for consistent output
shapes.</p>
</td></tr>
<tr><td><code id="tf_map_+3A_name">name</code></td>
<td>
<p>(optional) Name prefix for the returned tensors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor or (possibly nested) sequence of tensors. Each tensor packs
the results of applying fn to tensors unpacked from elems along the first
dimension, from first to last.
</p>

<hr>
<h2 id='tf_switch'>tf.switch_case</h2><span id='topic+tf_switch'></span>

<h3>Description</h3>

<p>tf.switch_case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_switch(
  branch_index,
  ...,
  branch_fns = list(...),
  default = NULL,
  name = "switch_case"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_switch_+3A_branch_index">branch_index</code></td>
<td>
<p>an integer tensor</p>
</td></tr>
<tr><td><code id="tf_switch_+3A_...">...</code>, <code id="tf_switch_+3A_branch_fns">branch_fns</code></td>
<td>
<p>a list of function bodies specified with a <code>~</code>,
optionally supplied with a branch index on the left hand side. See examples</p>
</td></tr>
<tr><td><code id="tf_switch_+3A_default">default</code></td>
<td>
<p>A function defined with a <code>~</code>, or something coercible via
'as.function()&ldquo;</p>
</td></tr>
<tr><td><code id="tf_switch_+3A_name">name</code></td>
<td>
<p>a string, passed on to <code>tf.switch_case()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result from <code>tf.switch_case()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tf_pow &lt;- tf_function(function(x, pow) {
   tf_switch(pow,
   0 ~ 1,
   1 ~ x,
   2 ~ x * x,
   3 ~ x * x * x,
   default = ~ -1)
})

# can optionally also omit the left hand side int, in which case the order of
# the functions is used.
tf_pow &lt;- function(x, pow) {
  tf_switch(pow,
            ~ 1,
            ~ x,
            ~ x * x,
            ~ x * x * x,
            default = ~ -1)
}

# supply just some of the ints to override the default order
tf_pow &lt;- function(x, pow) {
  tf_switch(pow,
            3 ~ x * x * x,
            2 ~ x * x,
            ~ 1,
            ~ x,
            default = ~ -1)
}

# A slightly less contrived example:
tf_norm &lt;- tf_function(function(x, l) {
  tf_switch(l,
            0 ~ tf$reduce_sum(tf$cast(x != 0, tf$float32)), # L0 norm
            1 ~ tf$reduce_sum(tf$abs(x)),                   # L1 norm
            2 ~ tf$sqrt(tf$reduce_sum(tf$square(x))),       # L2 norm
            default = ~ tf$reduce_max(tf$abs(x)))         # L-infinity norm
})

## End(Not run)
</code></pre>

<hr>
<h2 id='view_function_graph'>Visualizes the generated graph</h2><span id='topic+view_function_graph'></span>

<h3>Description</h3>

<p>Visualizes the generated graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>view_function_graph(
  fn,
  args,
  ...,
  name = deparse(substitute(fn)),
  profiler = FALSE,
  concrete_fn = do.call(fn$get_concrete_fn, args),
  graph = concrete_fn$graph
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="view_function_graph_+3A_fn">fn</code></td>
<td>
<p>TensorFlow function (returned from <code>tf.function()</code>)</p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_args">args</code></td>
<td>
<p>arguments passed to <code>fun</code></p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="tensorflow.html#topic+tensorboard">tensorflow::tensorboard()</a></code></p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_name">name</code></td>
<td>
<p>string, provided to tensorboard</p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_profiler">profiler</code></td>
<td>
<p>logical, passed on to <code>tf.compat.v2.summary.trace_on()</code> (only
used in eager mode)</p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_concrete_fn">concrete_fn</code></td>
<td>
<p>a <code>ConcreteFunction</code> (only used in graph mode, ignored
with a warning if executing eagerly)</p>
</td></tr>
<tr><td><code id="view_function_graph_+3A_graph">graph</code></td>
<td>
<p>a tensorflow graph (only used in graph mode, ignored with a
warning if executing eagerly)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fn &lt;- tf_function(function(x) autograph(if(x &gt; 0) x * x else x))
view_function_graph(fn, list(tf$constant(5)))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
