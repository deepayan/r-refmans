<!DOCTYPE html><html lang="en"><head><title>Help for package mlt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mlt-package'><p>General Information on the <span class="pkg">mlt</span> Package</p></a></li>
<li><a href='#confband'>
<p>Confidence Bands</p></a></li>
<li><a href='#ctm'>
<p>Conditional Transformation Models</p></a></li>
<li><a href='#ctm-methods'>
<p>Methods for ctm Objects</p></a></li>
<li><a href='#mlt'>
<p>Most Likely Transformations</p></a></li>
<li><a href='#mlt-methods'>
<p>Methods for mlt Objects</p></a></li>
<li><a href='#mltoptim'>
<p>Control Optimisation</p></a></li>
<li><a href='#mmlt'>
<p>Multivariate Conditional Transformation Models</p></a></li>
<li><a href='#mmlt-methods'>
<p>Methods for mmlt Objects</p></a></li>
<li><a href='#plot-predict-simulate'>
<p>Plots, Predictions and Samples from mlt Objects</p></a></li>
<li><a href='#R'>
<p>Response Variables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Most Likely Transformations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-20</td>
</tr>
<tr>
<td>Description:</td>
<td>Likelihood-based estimation of conditional transformation
  models via the most likely transformation approach described in
  Hothorn et al. (2018) &lt;<a href="https://doi.org/10.1111%2Fsjos.12291">doi:10.1111/sjos.12291</a>&gt; and Hothorn (2020)
  &lt;<a href="https://doi.org/10.18637%2Fjss.v092.i01">doi:10.18637/jss.v092.i01</a>&gt;.  Shift-scale (Siegfried et al, 2023, &lt;<a href="https://doi.org/10.1080%2F00031305.2023.2203177">doi:10.1080/00031305.2023.2203177</a>&gt;)
  and multivariate (Klein et al, 2022, &lt;<a href="https://doi.org/10.1111%2Fsjos.12501">doi:10.1111/sjos.12501</a>&gt;) transformation models
  are part of this package. A package vignette is available from &lt;<a href="https://doi.org/10.32614%2FCRAN.package.mlt.docreg">doi:10.32614/CRAN.package.mlt.docreg</a>&gt; and
  more convenient user interfaces to many models from &lt;<a href="https://doi.org/10.32614%2FCRAN.package.tram">doi:10.32614/CRAN.package.tram</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>basefun (&ge; 1.2-1), variables (&ge; 1.1-0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>BB, alabama, stats, quadprog, coneproj, graphics, methods,
grDevices, sandwich, numDeriv, survival, Matrix, nloptr,
mvtnorm</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, nnet, TH.data, multcomp, qrng</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://ctm.R-forge.R-project.org">http://ctm.R-forge.R-project.org</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-20 08:08:03 UTC; hothorn</td>
</tr>
<tr>
<td>Author:</td>
<td>Torsten Hothorn <a href="https://orcid.org/0000-0001-8301-0471"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Torsten Hothorn &lt;Torsten.Hothorn@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-20 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mlt-package'>General Information on the <span class="pkg">mlt</span> Package</h2><span id='topic+mlt-package'></span>

<h3>Description</h3>

<p>The <span class="pkg">mlt</span> package implements maximum likelihood estimation in 
conditional transformation models as introduced by Hothorn et al. (2020),
Klein et al. (2022), and Siegfried et al. (2023).
</p>
<p>An introduction to the package is available in the <code>mlt</code> package
vignette from package <code>mlt.docreg</code> (Hothorn, 2020).
</p>
<p>Novice users might find the high(er) level interfaces offered by package
<span class="pkg">tram</span> more convenient.
</p>


<h3>Author(s)</h3>

<p>This package is authored by Torsten Hothorn &lt;Torsten.Hothorn@R-project.org&gt;.
</p>


<h3>References</h3>

<p>Torsten Hothorn, Lisa Moest, Peter Buehlmann (2018), Most Likely
Transformations, <em>Scandinavian Journal of Statistics</em>, <b>45</b>(1),
110&ndash;134, <a href="https://doi.org/10.1111/sjos.12291">doi:10.1111/sjos.12291</a>.
</p>
<p>Torsten Hothorn (2020), Most Likely Transformations: The mlt Package,
<em>Journal of Statistical Software</em>, <b>92</b>(1), 1&ndash;68,
<a href="https://doi.org/10.18637/jss.v092.i01">doi:10.18637/jss.v092.i01</a>
</p>
<p>Nadja Klein, Torsten Hothorn, Luisa Barbanti, Thomas Kneib (2022),
Multivariate Conditional Transformation Models. <em>Scandinavian Journal
of Statistics</em>, <b>49</b>, 116&ndash;142, <a href="https://doi.org/10.1111/sjos.12501">doi:10.1111/sjos.12501</a>.
</p>
<p>Sandra Siegfried, Lucas Kook, Torsten Hothorn (2023), 
Distribution-Free Location-Scale Regression, <em>The American Statistician</em>,
<b>77</b>(4), 345&ndash;356, <a href="https://doi.org/10.1080/00031305.2023.2203177">doi:10.1080/00031305.2023.2203177</a>.
</p>
<p>Torsten Hothorn (2024), On Nonparanormal Likelihoods. <a href="https://doi.org/10.48550/arXiv.2408.17346">doi:10.48550/arXiv.2408.17346</a>.
</p>

<hr>
<h2 id='confband'>
Confidence Bands
</h2><span id='topic+confband'></span><span id='topic+confband.mlt'></span>

<h3>Description</h3>

<p>Confidence bands for transformation, distribution, survivor or
cumulative hazard functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confband(object, newdata, level = 0.95, ...)
## S3 method for class 'mlt'
confband(object, newdata, level = 0.95, 
       type = c("trafo", "distribution", "survivor", "cumhazard"), 
       K = 20, cheat = K, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confband_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+mlt">mlt</a></code></p>
</td></tr>
<tr><td><code id="confband_+3A_newdata">newdata</code></td>
<td>
<p>a data frame of observations</p>
</td></tr>
<tr><td><code id="confband_+3A_level">level</code></td>
<td>
<p>the confidence level</p>
</td></tr>
<tr><td><code id="confband_+3A_type">type</code></td>
<td>
<p>the function to compute the confidence band for</p>
</td></tr>
<tr><td><code id="confband_+3A_k">K</code></td>
<td>
<p>number of grid points the function is evaluated at</p>
</td></tr>
<tr><td><code id="confband_+3A_cheat">cheat</code></td>
<td>
<p>number of grid points the function is evaluated at when
using the quantile obtained for <code>K</code> grid points</p>
</td></tr>
<tr><td><code id="confband_+3A_...">...</code></td>
<td>
<p>additional arguments to <code><a href="multcomp.html#topic+confint.glht">confint.glht</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is evaluated at <code>K</code> grid points and simultaneous
confidence intervals are then interpolated in order to construct the band.
</p>
<p>A smoother band can be obtained by setting <code>cheat</code> to something larger 
than <code>K</code>: The quantile is obtained for <code>K</code> grid points but
the number of evaluated grid points <code>cheat</code> can be much larger at no 
additional cost. Technically, the nominal level is not maintained in
this case but the deviation will be small for reasonably large <code>K</code>.
</p>


<h3>Value</h3>

<p>For each row in <code>newdata</code> the function and corresponding confidence
band evaluated at the <code>K</code> (or <code>cheat</code>) grid points is returned.
</p>

<hr>
<h2 id='ctm'>
Conditional Transformation Models
</h2><span id='topic+ctm'></span>

<h3>Description</h3>

<p>Specification of conditional transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctm(response, interacting = NULL, shifting = NULL, scaling = NULL, 
    scale_shift = FALSE, data = NULL, 
    todistr = c("Normal", "Logistic", "MinExtrVal", "MaxExtrVal", 
                "Exponential", "Laplace", "Cauchy"), 
    sumconstr = inherits(interacting, c("formula", "formula_basis")), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ctm_+3A_response">response</code></td>
<td>
<p>a basis function, ie, an object of class <code>basis</code></p>
</td></tr>
<tr><td><code id="ctm_+3A_interacting">interacting</code></td>
<td>
<p>a basis function, ie, an object of class <code>basis</code></p>
</td></tr>
<tr><td><code id="ctm_+3A_shifting">shifting</code></td>
<td>
<p>a basis function, ie, an object of class <code>basis</code></p>
</td></tr>
<tr><td><code id="ctm_+3A_scaling">scaling</code></td>
<td>
<p>a basis function, ie, an object of class <code>basis</code></p>
</td></tr>
<tr><td><code id="ctm_+3A_scale_shift">scale_shift</code></td>
<td>
<p>a logical choosing between two different model types
in the presence of a <code>scaling</code> term</p>
</td></tr>
<tr><td><code id="ctm_+3A_data">data</code></td>
<td>
<p>either a <code>data.frame</code> containing the model variables
or a formal description of these variables in an object of class <code>vars</code></p>
</td></tr>
<tr><td><code id="ctm_+3A_todistr">todistr</code></td>
<td>
<p>a character vector describing the distribution to be transformed</p>
</td></tr>
<tr><td><code id="ctm_+3A_sumconstr">sumconstr</code></td>
<td>
<p>a logical indicating if sum constraints shall be applied</p>
</td></tr>
<tr><td><code id="ctm_+3A_...">...</code></td>
<td>
<p>arguments to <code>as.basis</code> when <code>shifting</code> is a formula</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only specifies the model which can then be fitted using
<code><a href="#topic+mlt">mlt</a></code>. The shift term is positive by default. All arguments except
<code>response</code> can be missing (in this case an unconditional distribution
is estimated). Hothorn et al. (2018) explain the model class.
</p>
<p>Possible choices of the distributions the model transforms to (the inverse
link functions <code class="reqn">F_Z</code>) include the 
standard normal (<code>"Normal"</code>), the standard logistic
(<code>"Logistic"</code>), the standard minimum extreme value
(<code>"MinExtrVal"</code>, also known as Gompertz distribution), and the
standard maximum extreme value (<code>"MaxExtrVal"</code>, also known as Gumbel
distribution) distributions. The exponential distribution
(<code>"Exponential"</code>) can be used to fit Aalen additive hazard models.
Laplace and Cauchy distributions are also available.
</p>
<p>Shift-scale models (Siegfried et al., 2023) of the form
</p>
<p style="text-align: center;"><code class="reqn">P(Y \le y \mid X = x) = F_Z(\sqrt{\exp(s(x)^\top \gamma)} [(a(y) \otimes b(x))^\top \vartheta] + d(x)^\top \beta)</code>
</p>

<p>(<code>scale_shift = FALSE</code>) or
</p>
<p style="text-align: center;"><code class="reqn">P(Y \le y \mid X = x) = F_Z(\sqrt{\exp(s(x)^\top \gamma)} [(a(y) \otimes b(x))^\top \vartheta + d(x)^\top \beta])</code>
</p>

<p>(<code>scale_shift = TRUE</code>)
with bases <code class="reqn">a(y)</code> (<code>response</code>), <code class="reqn">b(x)</code> (<code>interacting</code>),
<code class="reqn">d(x)</code> (<code>shifting</code>), and <code class="reqn">s(x)</code> (<code>scaling</code>) can be
specified as well. 
</p>


<h3>Value</h3>

<p>An object of class <code>ctm</code>.
</p>


<h3>References</h3>

<p>Torsten Hothorn, Lisa Moest, Peter Buehlmann (2018), Most Likely
Transformations, <em>Scandinavian Journal of Statistics</em>, <b>45</b>(1),
110&ndash;134, <a href="https://doi.org/10.1111/sjos.12291">doi:10.1111/sjos.12291</a>.
</p>
<p>Sandra Siegfried, Lucas Kook, Torsten Hothorn (2023), 
Distribution-Free Location-Scale Regression, <em>The American Statistician</em>,
<b>77</b>(4), 345&ndash;356, <a href="https://doi.org/10.1080/00031305.2023.2203177">doi:10.1080/00031305.2023.2203177</a>.
</p>

<hr>
<h2 id='ctm-methods'>
Methods for ctm Objects
</h2><span id='topic+variable.names.ctm'></span><span id='topic+coef+3C-.ctm'></span><span id='topic+coef.ctm'></span>

<h3>Description</h3>

<p>Methods for objects of class ctm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctm'
variable.names(object, 
              which = c("all", "response", "interacting", 
                        "shifting", "scaling"), 
              ...)
## S3 method for class 'ctm'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ctm-methods_+3A_object">object</code></td>
<td>
<p>an unfitted conditional transformation model as returned by <code><a href="#topic+ctm">ctm</a></code></p>
</td></tr>
<tr><td><code id="ctm-methods_+3A_which">which</code></td>
<td>
<p>a character specifying which names shall be returned</p>
</td></tr>
<tr><td><code id="ctm-methods_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef</code> can be used to get and set model parameters.
</p>

<hr>
<h2 id='mlt'>
Most Likely Transformations
</h2><span id='topic+mlt'></span>

<h3>Description</h3>

<p>Likelihood-based model estimation in conditional transformation models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlt(model, data, weights = NULL, offset = NULL, fixed = NULL, theta = NULL, 
    pstart = NULL, scale = FALSE, dofit = TRUE, optim = mltoptim())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlt_+3A_model">model</code></td>
<td>
<p>a conditional transformation model as specified by <code><a href="#topic+ctm">ctm</a></code></p>
</td></tr>
<tr><td><code id="mlt_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> containing all variables specified in <code>model</code></p>
</td></tr>
<tr><td><code id="mlt_+3A_weights">weights</code></td>
<td>
<p>an optional vector of case weights</p>
</td></tr>
<tr><td><code id="mlt_+3A_offset">offset</code></td>
<td>
<p>an optional vector of offset values; offsets are not added
to an optional <code>scaling</code> term (see <code>link{ctm}</code>)</p>
</td></tr>
<tr><td><code id="mlt_+3A_fixed">fixed</code></td>
<td>
<p>a named vector of fixed regression coefficients; the names
need to correspond to column names of the design matrix</p>
</td></tr>
<tr><td><code id="mlt_+3A_theta">theta</code></td>
<td>
<p>optional starting values for the model parameters</p>
</td></tr>
<tr><td><code id="mlt_+3A_pstart">pstart</code></td>
<td>
<p>optional starting values for the distribution function
evaluated at the data</p>
</td></tr>
<tr><td><code id="mlt_+3A_scale">scale</code></td>
<td>
<p>a logical indicating if (internal) scaling shall be applied to the
model coefficients</p>
</td></tr>
<tr><td><code id="mlt_+3A_dofit">dofit</code></td>
<td>
<p>a logical indicating if the model shall be fitted to the
data (<code>TRUE</code>) or not. If <code>theta</code> is given,
a model of class <code>mlt</code> (a full &quot;fitted&quot; model)
featuring these parameters is returned. Otherwise,
an unfitted model of class <code>ctm</code> is returned</p>
</td></tr>
<tr><td><code id="mlt_+3A_optim">optim</code></td>
<td>
<p>a list of functions implementing suitable optimisers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a conditional transformation model by searching for 
the most likely transformation as described in Hothorn et al. (2018) and
Hothorn (2020).
</p>


<h3>Value</h3>

<p>An object of class <code>mlt</code> with corresponding methods.
</p>


<h3>References</h3>

<p>Torsten Hothorn, Lisa Moest, Peter Buehlmann (2018), Most Likely
Transformations, <em>Scandinavian Journal of Statistics</em>, <b>45</b>(1),
110&ndash;134, <a href="https://doi.org/10.1111/sjos.12291">doi:10.1111/sjos.12291</a>.
</p>
<p>Torsten Hothorn (2020), Most Likely Transformations: The mlt Package,
<em>Journal of Statistical Software</em>, <b>92</b>(1), 1&ndash;68,
<a href="https://doi.org/10.18637/jss.v092.i01">doi:10.18637/jss.v092.i01</a>
</p>
<p>Sandra Siegfried, Lucas Kook, Torsten Hothorn (2023), 
Distribution-Free Location-Scale Regression, <em>The American Statistician</em>,
<b>77</b>(4), 345&ndash;356, <a href="https://doi.org/10.1080/00031305.2023.2203177">doi:10.1080/00031305.2023.2203177</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  ### set-up conditional transformation model for conditional
  ### distribution of dist given speed
  dist &lt;- numeric_var("dist", support = c(2.0, 100), bounds = c(0, Inf))
  speed &lt;- numeric_var("speed", support = c(5.0, 23), bounds = c(0, Inf)) 
  ctmm &lt;- ctm(response = Bernstein_basis(dist, order = 4, ui = "increasing"),
              interacting = Bernstein_basis(speed, order = 3))

  ### fit model
  mltm &lt;- mlt(ctmm, data = cars)

  ### plot data
  plot(cars)
  ### predict quantiles and overlay data with model via a "quantile sheet"
  q &lt;- predict(mltm, newdata = data.frame(speed = 0:24), type = "quantile", 
               p = 2:8 / 10, K = 500)
  tmp &lt;- apply(q, 1, function(x) lines(0:24, x, type = "l"))

</code></pre>

<hr>
<h2 id='mlt-methods'>
Methods for mlt Objects
</h2><span id='topic+coef+3C-'></span><span id='topic+coef+3C-.mlt'></span><span id='topic+coef.mlt'></span><span id='topic+weights.mlt'></span><span id='topic+logLik.mlt'></span><span id='topic+vcov.mlt'></span><span id='topic+Hessian'></span><span id='topic+Gradient'></span><span id='topic+Hessian.mlt'></span><span id='topic+Gradient.mlt'></span><span id='topic+estfun.mlt'></span><span id='topic+residuals.mlt'></span><span id='topic+mkgrid.mlt'></span><span id='topic+bounds.mlt'></span><span id='topic+variable.names.mlt'></span><span id='topic+update.mlt_fit'></span><span id='topic+as.mlt'></span><span id='topic+as.mlt.mlt'></span>

<h3>Description</h3>

<p>Methods for objects of class mlt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlt'
coef(object, fixed = TRUE, ...)
coef(object) &lt;- value
## S3 method for class 'mlt'
weights(object, ...)
## S3 method for class 'mlt'
logLik(object, parm = coef(object, fixed = FALSE), w = NULL, newdata, ...)
## S3 method for class 'mlt'
vcov(object, parm = coef(object, fixed = FALSE), complete = FALSE, ...)
Hessian(object, ...)
## S3 method for class 'mlt'
Hessian(object, parm = coef(object, fixed = FALSE), ...)
Gradient(object, ...)
## S3 method for class 'mlt'
Gradient(object, parm = coef(object, fixed = FALSE), ...)
## S3 method for class 'mlt'
estfun(x, parm = coef(x, fixed = FALSE),
       w = NULL, newdata, ...)
## S3 method for class 'mlt'
residuals(object, parm = coef(object, fixed = FALSE), 
       w = NULL, newdata, what = c("shifting", "scaling"), ...)
## S3 method for class 'mlt'
mkgrid(object, n, ...)
## S3 method for class 'mlt'
bounds(object)
## S3 method for class 'mlt'
variable.names(object, ...)
## S3 method for class 'mlt_fit'
update(object, weights = stats::weights(object), 
       subset = NULL, offset = object$offset, theta = coef(object, fixed = FALSE), 
       fixed = NULL, ...)
## S3 method for class 'mlt'
as.mlt(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlt-methods_+3A_object">object</code>, <code id="mlt-methods_+3A_x">x</code></td>
<td>
<p>a fitted conditional transformation model as returned by <code><a href="#topic+mlt">mlt</a></code></p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_fixed">fixed</code></td>
<td>
<p>a logical indicating if only estimated coefficients (<code>fixed = FALSE</code>) 
should be returned OR (for <code>update</code>)
a named vector of fixed regression coefficients; the names
need to correspond to column names of the design matrix</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_value">value</code></td>
<td>
<p>coefficients to be assigned to the model</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_parm">parm</code></td>
<td>
<p>model parameters</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_w">w</code></td>
<td>
<p>model weights</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_what">what</code></td>
<td>
<p>type of residual: <code>shifting</code> means score with respect to
a constant intercept for the shift term and <code>scaling</code> means 
score with respect to a constant intercept in the scaling term. 
This works whether or not such terms are actually present in the model</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_weights">weights</code></td>
<td>
<p>model weights</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame of new observations. Allows
evaluation of the log-likelihood for a given
model <code>object</code> on these new observations. The
parameters <code>parm</code> and <code>w</code> are ignored in this situation.</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_n">n</code></td>
<td>
<p>number of grid points</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_subset">subset</code></td>
<td>
<p>an optional integer vector indicating the subset of
observations to be used for fitting.</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_offset">offset</code></td>
<td>
<p>an optional vector of offset values</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_theta">theta</code></td>
<td>
<p>optional starting values for the model parameters</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_complete">complete</code></td>
<td>
<p>currently ignored</p>
</td></tr>
<tr><td><code id="mlt-methods_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef</code> can be used to get and set model parameters, <code>weights</code> and 
<code>logLik</code> extract weights and evaluate the log-likelihood (also for
parameters other than the maximum likelihood estimate). <code>Hessian</code>
returns the Hessian (of the <em>negative</em> log-likelihood) and <code>vcov</code> the inverse thereof. <code>Gradient</code>
gives the negative gradient (minus sum of the score contributions) 
and <code>estfun</code> the <em>negative</em> score contribution by each observation. <code>mkgrid</code>
generates a grid of all variables (as returned by <code>variable.names</code>) in the model.
<code>update</code> allows refitting the model with alternative weights and potentially
different starting values. <code>bounds</code> gets bounds for bounded variables in the model.
</p>

<hr>
<h2 id='mltoptim'>
Control Optimisation
</h2><span id='topic+mltoptim'></span>

<h3>Description</h3>

<p>Define optimisers and their control parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mltoptim(auglag = list(maxtry = 5, kkt2.check = FALSE), 
         spg = list(maxit = 10000, quiet = TRUE, checkGrad = FALSE), 
         nloptr = list(algorithm = "NLOPT_LD_MMA", xtol_rel = 1.0e-8, maxeval = 1000L), 
         trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mltoptim_+3A_auglag">auglag</code></td>
<td>

<p>A list with control parameters for the <code><a href="alabama.html#topic+auglag">auglag</a></code> optimiser.
<code>maxtry</code> is the number of times the algorithm is started on random starting
values in case it failed with the precomputed ones.
</p>
</td></tr>
<tr><td><code id="mltoptim_+3A_spg">spg</code></td>
<td>

<p>A list with control parameters for the <code><a href="BB.html#topic+BBoptim">BBoptim</a></code> optimiser (calling
<code><a href="BB.html#topic+spg">spg</a></code> internally).
</p>
</td></tr>
<tr><td><code id="mltoptim_+3A_nloptr">nloptr</code></td>
<td>

<p>A list with control parameters for the <code><a href="nloptr.html#topic+nloptr">nloptr</a></code>
family of optimisers. 
</p>
</td></tr>
<tr><td><code id="mltoptim_+3A_trace">trace</code></td>
<td>

<p>A logical switching trace reports by the optimisers off.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function sets-up functions to be called in <code><a href="#topic+mlt">mlt</a></code> internally.
</p>


<h3>Value</h3>

<p>A list of functions with arguments <code>theta</code> (starting values), <code>f</code> (log-likelihood),
<code>g</code> (scores), <code>ui</code> and <code>ci</code> (linear inequality constraints).
Adding further such functions is a way to add more optimisers to <code><a href="#topic+mlt">mlt</a></code>.
The first one in this list converging  defines the resulting model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  ### set-up linear transformation model for conditional
  ### distribution of dist given speed
  dist &lt;- numeric_var("dist", support = c(2.0, 100), bounds = c(0, Inf))
  ctmm &lt;- ctm(response = Bernstein_basis(dist, order = 4, ui = "increasing"),
              shifting = ~ speed, data = cars)

  ### use auglag with kkt2.check = TRUE =&gt; the numerically determined
  ### hessian is returned as "optim_hessian" slot
  op &lt;- mltoptim(auglag = list(maxtry = 5, kkt2.check = TRUE))[1]
  mltm &lt;- mlt(ctmm, data = cars, scale = FALSE, optim = op)

  ### compare analytical and numerical hessian
  all.equal(c(Hessian(mltm)), c(mltm$optim_hessian), tol = 1e-4)

</code></pre>

<hr>
<h2 id='mmlt'>
Multivariate Conditional Transformation Models
</h2><span id='topic+mmlt'></span><span id='topic+coef.cmmlt'></span><span id='topic+coef.mmmlt'></span><span id='topic+predict.mmlt'></span><span id='topic+simulate.mmlt'></span>

<h3>Description</h3>

<p>Conditional transformation models for multivariate continuous, discrete,
or a mix of continuous and discrete outcomes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmlt(..., formula = ~ 1, data, conditional = FALSE, theta = NULL, fixed = NULL,
     scale = FALSE, optim = mltoptim(auglag = list(maxtry = 5)), 
     args = list(seed = 1, M = 1000), dofit = TRUE, domargins = TRUE)
## S3 method for class 'cmmlt'
coef(object, newdata, 
     type = c("all", "conditional", "Lambdapar", "Lambda", "Lambdainv", 
              "Precision", "PartialCorr", "Sigma", "Corr", 
              "Spearman", "Kendall"), fixed = TRUE, 
     ...)
## S3 method for class 'mmmlt'
coef(object, newdata, 
     type = c("all", "marginal", "Lambdapar", "Lambda", "Lambdainv", 
              "Precision", "PartialCorr", "Sigma", "Corr", 
              "Spearman", "Kendall"), fixed = TRUE,
     ...)
## S3 method for class 'mmlt'
predict(object, newdata, margins = 1:J, 
        type = c("trafo", "distribution", "survivor", "density", "hazard"), 
                 log = FALSE, args = object$args, ...)
## S3 method for class 'mmlt'
simulate(object, nsim = 1L, seed = NULL, newdata, K = 50, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mmlt_+3A_...">...</code></td>
<td>
<p>marginal transformation models, one for each response, for
<code>mmlt</code>. Additional arguments for the methods.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_formula">formula</code></td>
<td>
<p>a model formula describing a model for the dependency
structure via the lambda parameters. The default is set to <code>~ 1</code> for constant lambdas.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_data">data</code></td>
<td>
<p>a data.frame.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_conditional">conditional</code></td>
<td>
<p>logical; parameters are defined conditionally (only
possible when all models are probit models). This is the default as
described by Klein et al. (2022). If <code>FALSE</code>, parameters can be
directly interpreted marginally, this is explained in Section 2.6 by Klein
et al. (2022). Using <code>conditional = FALSE</code> with probit-only models
gives the same likelihood but different parameter estimates.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_theta">theta</code></td>
<td>
<p>an optional vector of starting values.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_fixed">fixed</code></td>
<td>
<p>an optional named numeric vector of predefined parameter values
or a logical (for <code>coef</code>) indicating to also return fixed parameters
(only when <code>type = "all"</code>).
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_scale">scale</code></td>
<td>
<p>a logical indicating if (internal) scaling shall be applied
to the model coefficients.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_optim">optim</code></td>
<td>
<p>a list of optimisers as returned by <code><a href="#topic+mltoptim">mltoptim</a></code>
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_args">args</code></td>
<td>
<p>a list of arguments for <code><a href="mvtnorm.html#topic+lpmvnorm">lpmvnorm</a></code>.</p>
</td></tr>
<tr><td><code id="mmlt_+3A_dofit">dofit</code></td>
<td>
<p>logical; parameters are fitted by default, otherwise a list
with log-likelihood and score function is returned.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_domargins">domargins</code></td>
<td>
<p>logical; all model parameters are fitted by default, 
including the parameters of marginal models.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_object">object</code></td>
<td>
<p>an object of class <code>mmlt</code>.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_newdata">newdata</code></td>
<td>
<p>an optional data.frame coefficients and predictions shall
be computed for.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_type">type</code></td>
<td>
<p>type of coefficient or prediction to be returned.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_margins">margins</code></td>
<td>
<p>indices defining marginal models to be evaluated. Can be
single integers giving the marginal distribution of the corresponding
variable, or multiple integers (currently only <code>1:j</code> implemented).
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_log">log</code></td>
<td>
<p>logical; return log-probabilities or log-densities if
<code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="mmlt_+3A_nsim">nsim</code></td>
<td>
<p>number of samples to generate.</p>
</td></tr>
<tr><td><code id="mmlt_+3A_seed">seed</code></td>
<td>
<p>optional seed for the random number generator.</p>
</td></tr>
<tr><td><code id="mmlt_+3A_k">K</code></td>
<td>
<p>number of grid points to generate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements core functionality for fitting 
multivariate conditional transformation models
as described by Klein et al (2020). 
</p>


<h3>Value</h3>

<p>An object of class <code>mmlt</code> with <code>coef</code> and <code>predict</code>
methods.
</p>


<h3>References</h3>

<p>Nadja Klein, Torsten Hothorn, Luisa Barbanti, Thomas Kneib (2022),
Multivariate Conditional Transformation Models. <em>Scandinavian Journal
of Statistics</em>, <b>49</b>, 116&ndash;142, <a href="https://doi.org/10.1111/sjos.12501">doi:10.1111/sjos.12501</a>.
</p>
<p>Torsten Hothorn (2024), On Nonparanormal Likelihoods. <a href="https://doi.org/10.48550/arXiv.2408.17346">doi:10.48550/arXiv.2408.17346</a>.
</p>

<hr>
<h2 id='mmlt-methods'>
Methods for mmlt Objects
</h2><span id='topic+coef+3C-.mmlt'></span><span id='topic+weights.mmlt'></span><span id='topic+logLik.mmlt'></span><span id='topic+vcov.mmlt'></span><span id='topic+Hessian.mmlt'></span><span id='topic+Gradient.mmlt'></span><span id='topic+estfun.mmlt'></span><span id='topic+mkgrid.mmlt'></span><span id='topic+variable.names.mmlt'></span>

<h3>Description</h3>

<p>Methods for objects of class mmlt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mmlt'
weights(object, ...)
## S3 method for class 'mmlt'
logLik(object, parm = coef(object, fixed = FALSE), w = NULL, newdata = NULL, ...)
## S3 method for class 'mmlt'
vcov(object, parm = coef(object, fixed = FALSE), complete = FALSE, ...)
## S3 method for class 'mmlt'
Hessian(object, parm = coef(object, fixed = FALSE), ...)
## S3 method for class 'mmlt'
Gradient(object, parm = coef(object, fixed = FALSE), ...)
## S3 method for class 'mmlt'
estfun(x, parm = coef(x, fixed = FALSE),
       w = NULL, newdata = NULL, ...)
## S3 method for class 'mmlt'
mkgrid(object, ...)
## S3 method for class 'mmlt'
variable.names(object, response_only = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mmlt-methods_+3A_object">object</code>, <code id="mmlt-methods_+3A_x">x</code></td>
<td>
<p>a fitted multivariate transformation model as returned by <code><a href="#topic+mmlt">mmlt</a></code></p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_fixed">fixed</code></td>
<td>
<p>a logical indicating if only estimated coefficients (<code>fixed = FALSE</code>) 
should be returned OR (for <code>update</code>)
a named vector of fixed regression coefficients; the names
need to correspond to column names of the design matrix</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_parm">parm</code></td>
<td>
<p>model parameters</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_w">w</code></td>
<td>
<p>model weights</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_weights">weights</code></td>
<td>
<p>model weights</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame of new observations. Allows
evaluation of the log-likelihood for a given
model <code>object</code> on these new observations. The
parameters <code>parm</code> and <code>w</code> are ignored in this situation.</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_response_only">response_only</code></td>
<td>
<p>only return the names of the response variables</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_complete">complete</code></td>
<td>
<p>currently ignored</p>
</td></tr>
<tr><td><code id="mmlt-methods_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef</code> can be used to get and set model parameters, <code>weights</code> and 
<code>logLik</code> extract weights and evaluate the log-likelihood (also for
parameters other than the maximum likelihood estimate). <code>Hessian</code>
returns the Hessian (of the <em>negative</em> log-likelihood) and <code>vcov</code> the inverse thereof. <code>Gradient</code>
gives the negative gradient (minus sum of the score contributions) 
and <code>estfun</code> the <em>negative</em> score contribution by each observation. <code>mkgrid</code>
generates a grid of all variables (as returned by <code>variable.names</code>) in the model.
</p>

<hr>
<h2 id='plot-predict-simulate'>
Plots, Predictions and Samples from mlt Objects
</h2><span id='topic+predict.ctm'></span><span id='topic+predict.mlt'></span><span id='topic+simulate.ctm'></span><span id='topic+simulate.mlt'></span><span id='topic+plot.ctm'></span><span id='topic+plot.mlt'></span>

<h3>Description</h3>

<p>Plot, predict and sample from objects of class mlt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ctm'
plot(x, newdata, type = c(
         "distribution", "logdistribution", 
         "survivor", "logsurvivor", 
         "density", "logdensity", 
         "hazard", "loghazard", 
         "cumhazard", "logcumhazard", 
         "odds", "logodds", 
         "quantile", "trafo"),
     q = NULL, prob = 1:(K - 1) / K, K = 50, col = rgb(.1, .1, .1, .1), lty = 1, 
     add = FALSE, ...)
## S3 method for class 'mlt'
plot(x, ...)
## S3 method for class 'ctm'
predict(object, newdata, type = c("trafo", 
         "distribution", "logdistribution", 
         "survivor", "logsurvivor", 
         "density", "logdensity", 
         "hazard", "loghazard", 
         "cumhazard", "logcumhazard", 
         "odds", "logodds", 
         "quantile"), 
         terms = c("bresponse", "binteracting", "bshifting"), 
         q = NULL, prob = NULL, K = 50, interpolate = FALSE, ...)
## S3 method for class 'mlt'
predict(object, newdata = object$data, ...)
## S3 method for class 'ctm'
simulate(object, nsim = 1, seed = NULL, newdata, K = 50, q = NULL,
         interpolate = FALSE, bysim = TRUE, ...)
## S3 method for class 'mlt'
simulate(object, nsim = 1, seed = NULL, newdata = object$data, bysim = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot-predict-simulate_+3A_object">object</code></td>
<td>
<p>a fitted conditional transformation model as returned by <code><a href="#topic+mlt">mlt</a></code>
or an unfitted conditional transformation model as returned by <code><a href="#topic+ctm">ctm</a></code></p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_x">x</code></td>
<td>
<p>a fitted conditional transformation model as returned by <code><a href="#topic+mlt">mlt</a></code></p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame of observations</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_type">type</code></td>
<td>
<p>type of prediction or plot to generate</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_q">q</code></td>
<td>
<p>quantiles at which to evaluate the model</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_prob">prob</code></td>
<td>
<p>probabilities for the evaluation of the quantile function (<code>type = "quantile"</code>)</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_terms">terms</code></td>
<td>
<p>terms to evaluate for the predictions, corresponds to the argument
<code>response</code>, <code>interacting</code> and <code>shifting</code> in <code><a href="#topic+ctm">ctm</a></code></p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_k">K</code></td>
<td>
<p>number of grid points to generate (in the absence of <code>q</code>)</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_col">col</code></td>
<td>
<p>color for the lines to plot</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_lty">lty</code></td>
<td>
<p>line type for the lines to plot</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_add">add</code></td>
<td>
<p>logical indicating if a new plot shall be generated (the default)</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_interpolate">interpolate</code></td>
<td>
<p>logical indicating if quantiles shall be interpolated
linearily. This unnecessary option is no longer implemented (starting with 1.2-1).</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_nsim">nsim</code></td>
<td>
<p>number of samples to generate</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_seed">seed</code></td>
<td>
<p>optional seed for the random number generator</p>
</td></tr>
<tr><td><code id="plot-predict-simulate_+3A_bysim">bysim</code></td>
<td>
<p>logical, if <code>TRUE</code> a list with <code>nsim</code> elements is returned,
each element is of length <code>nrow(newdata)</code> and 
contains one sample from the conditional distribution for each
row of <code>newdata</code>. If <code>FALSE</code>, a list of length <code>nrow(newdata)</code>
is returned, its ith element of length <code>nsim</code> contains <code>nsim</code> samples
from the conditional distribution given <code>newdata[i,]</code>.</p>
</td></tr> 
<tr><td><code id="plot-predict-simulate_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot</code> evaluates the transformation function over a grid of <code>q</code> values
for all observations in <code>newdata</code> and plots these functions (according to 
<code>type</code>). <code>predict</code> evaluates the transformation function over a grid
of <code>q</code> values for all observations in <code>newdata</code> and returns the
result as a matrix (where _columns_ correspond to _rows_ in
<code>newdata</code>, see examples). Lack of <code>type = "mean"</code> is a feature
and not a bug.
</p>
<p>Argument <code>type</code> defines the scale of the plots or predictions:
<code>type = "distribution"</code> means the cumulative distribution function, 
<code>type = "survivor"</code> is the survivor function (one minus distribution
function), <code>type = "density"</code> the absolute continuous or discrete
density (depending on the response), <code>type = "hazard"</code>, <code>type =
  "cumhazard"</code>, and <code>type = "odds"</code> refers to the hazard (absolute
continuous or discrete), cumulative hazard (defined as minus log-survivor
function in both the absolute continuous and discrete cases), and odds
(distribution divided by survivor) functions. The quantile function can be
evaluated for probabilities <code>prob</code> by <code>type = "quantile"</code>.
</p>
<p>Note that the <code>predict</code> method for <code>ctm</code> objects requires all
model coefficients to be specified in this unfitted model.
<code>simulate</code> draws samples from <code>object</code> by numerical inversion of the
quantile function.
</p>
<p>Note that offsets are ALWAYS IGNORED when computing predictions. If you
want the methods to pay attention to offsets, specify them as a variable
in the model with fixed regression coefficient using the <code>fixed</code>
argument in <code><a href="#topic+mlt">mlt</a></code>.
</p>
<p>More examples can be found in Hothorn (2018).
</p>


<h3>References</h3>

<p>Torsten Hothorn (2020), Most Likely Transformations: The mlt Package,
<em>Journal of Statistical Software</em>, <b>92</b>(1), 1&ndash;68,
<a href="https://doi.org/10.18637/jss.v092.i01">doi:10.18637/jss.v092.i01</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  library("survival")
  op &lt;- options(digits = 2)

  ### GBSG2 dataset
  data("GBSG2", package = "TH.data")

  ### right-censored response
  GBSG2$y &lt;- with(GBSG2, Surv(time, cens))

  ### define Bernstein(log(time)) parameterisation
  ### of transformation function. The response
  ### is bounded (log(0) doesn't work, so we use log(1))
  ### support defines the support of the Bernstein polynomial
  ### and add can be used to make the grid wider (see below)
  rvar &lt;- numeric_var("y", bounds = c(0, Inf), 
                      support = c(100, 2000))
  rb &lt;- Bernstein_basis(rvar, order = 6, ui = "increasing")
  ### dummy coding of menopausal status
  hb &lt;- as.basis(~ 0 + menostat, data = GBSG2)
  ### treatment contrast of hormonal treatment
  xb &lt;- as.basis(~ horTh, data = GBSG2, remove_intercept = TRUE)

  ### set-up and fit Cox model, stratified by menopausal status
  m &lt;- ctm(rb, interacting = hb, shifting = xb, todistr = "MinExtrVal")
  fm &lt;- mlt(m, data = GBSG2)

  ### generate grid for all three variables
  ### note that the response grid ranges between 1 (bounds[1])
  ### and 2000 (support[2])
  (d &lt;- mkgrid(m, n = 10))
  ### data.frame of menopausal status and treatment
  nd &lt;- do.call("expand.grid", d[-1])

  ### plot model on different scales, for all four combinations
  ### of menopausal status and hormonal treatment
  typ &lt;- c("distribution", "survivor", "density", "hazard", 
           "cumhazard", "odds")
  layout(matrix(1:6, nrow = 2))
  nl &lt;- sapply(typ, function(tp) 
      ### K = 500 makes densities and hazards smooth
      plot(fm, newdata = nd, type = tp, col = 1:nrow(nd), K = 500))
  legend("topleft", lty = 1, col = 1:nrow(nd), 
         legend = do.call("paste", nd), bty = "n")

  ### plot calls predict, which generates a grid with K = 50
  ### response values
  ### note that a K x nrow(newdata) matrix is returned
  ### (for reasons explained in the next example)
  predict(fm, newdata = nd, type = "survivor")

  ### newdata can take a list, and evaluates the survivor
  ### function on the grid defined by newdata 
  ### using a linear array model formulation and is 
  ### extremely efficient (wrt computing time and memory)
  ### d[1] (the response grid) varies fastest
  ### =&gt; the first dimension of predict() is always the response,
  ### not the dimension of the predictor variables (like one 
  ### might expect)
  predict(fm, newdata = d, type = "survivor")

  ### owing to this structure, the result can be quickly stored in 
  ### a data frame as follows
  cd &lt;- do.call("expand.grid", d)
  cd$surv &lt;- c(S &lt;- predict(fm, newdata = d, type = "survivor"))

  ### works for distribution functions
  all.equal(1 - S, predict(fm, newdata = d, type = "distribution"))
  ### cumulative hazard functions
  all.equal(-log(S), predict(fm, newdata = d, type = "cumhazard"))
  ### log-cumulative hazard functions (= trafo, for Cox models)
  all.equal(log(-log(S)), predict(fm, newdata = d, type = "logcumhazard"))
  all.equal(log(-log(S)), predict(fm, newdata = d, type = "trafo"))
  ### densities, hazards, or odds functions
  predict(fm, newdata = d, type = "density")
  predict(fm, newdata = d, type = "hazard")
  predict(fm, newdata = d, type = "odds")
  ### and quantiles (10 and 20%)
  predict(fm, newdata = d[-1], type = "quantile", prob = 1:2 / 10)

  ### note that some quantiles are only defined as intervals
  ### (&gt; 2000, in this case). Intervals are returned as an "response" 
  ### object, see ?R. Unfortunately, these can't be stored as array, so
  ### a data.frame is returned where the quantile varies first
  p &lt;- c(list(prob = 1:9/10), d[-1])
  np &lt;- do.call("expand.grid", p)
  (Q &lt;- predict(fm, newdata = d[-1], type = "quantile", prob = 1:9 / 10))
  np$Q &lt;- Q
  np

  ### simulating from the model works by inverting the distribution 
  ### function; some obs are right-censored at 2000
  (s &lt;- simulate(fm, newdata = nd, nsim = 3))
  ### convert to Surv
  sapply(s, as.Surv)

  ### generate 3 parametric bootstrap samples from the model
  tmp &lt;- GBSG2[, c("menostat", "horTh")]
  s &lt;- simulate(fm, newdata = tmp, nsim = 3)
  ### refit the model using the simulated response
  lapply(s, function(y) {
    tmp$y &lt;- y
    coef(mlt(m, data = tmp))
  })

  options(op)

</code></pre>

<hr>
<h2 id='R'>
Response Variables
</h2><span id='topic+R'></span><span id='topic+R.Surv'></span><span id='topic+R.factor'></span><span id='topic+R.ordered'></span><span id='topic+R.numeric'></span><span id='topic+R.integer'></span><span id='topic+R.list'></span><span id='topic+R.response'></span><span id='topic+as.Surv'></span><span id='topic+as.Surv.response'></span><span id='topic+as.double.response'></span>

<h3>Description</h3>

<p>Represent a possibly censored or truncated response variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R(object, ...)
## S3 method for class 'numeric'
R(object = NA, cleft = NA, cright = NA,
   tleft = NA, tright = NA, tol = sqrt(.Machine$double.eps), 
   as.R.ordered = FALSE, as.R.interval = FALSE, ...)
## S3 method for class 'ordered'
R(object, cleft = NA, cright = NA, ...)
## S3 method for class 'integer'
R(object, cleft = NA, cright = NA, bounds = c(min(object), Inf), ...)
## S3 method for class 'factor'
R(object, ...)
## S3 method for class 'Surv'
R(object, as.R.ordered = FALSE, as.R.interval = FALSE, ...)
as.Surv(object)
## S3 method for class 'response'
as.Surv(object)
## S3 method for class 'response'
as.double(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="R_+3A_object">object</code></td>
<td>

<p>A vector of (conceptually) exact measurements or an object of class
<code>response</code> (for <code>as.Surv</code>) or a list.</p>
</td></tr>
<tr><td><code id="R_+3A_x">x</code></td>
<td>
<p>same as <code>object</code>.</p>
</td></tr>
<tr><td><code id="R_+3A_cleft">cleft</code></td>
<td>

<p>A vector of left borders of censored measurements</p>
</td></tr>
<tr><td><code id="R_+3A_cright">cright</code></td>
<td>

<p>A vector of right borders of censored measurements</p>
</td></tr>
<tr><td><code id="R_+3A_tleft">tleft</code></td>
<td>

<p>A vector of left truncations</p>
</td></tr>
<tr><td><code id="R_+3A_tright">tright</code></td>
<td>

<p>A vector of right truncations</p>
</td></tr>
<tr><td><code id="R_+3A_tol">tol</code></td>
<td>

<p>Tolerance for checking if <code>cleft</code> &lt; <code>cright</code></p>
</td></tr>
<tr><td><code id="R_+3A_bounds">bounds</code></td>
<td>

<p>Range of possible values for integers</p>
</td></tr>
<tr><td><code id="R_+3A_as.r.ordered">as.R.ordered</code></td>
<td>
<p>logical, should numeric responses or right-censored
(and possible left-truncated survival) times be coded as ordered factor?
This leads to a parameterisation allowing to maximise the nonparametric
maximum likelihood</p>
</td></tr>
<tr><td><code id="R_+3A_as.r.interval">as.R.interval</code></td>
<td>
<p>logical, should numeric responses be coded for
the nonparametric maximum likelihood</p>
</td></tr>
<tr><td><code id="R_+3A_...">...</code></td>
<td>

<p>other arguments, ignored except for <code>tleft</code> and <code>tright</code> to
<code>R.ordered</code> and <code>R.integer</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>R</code> is basically an extention of <code><a href="survival.html#topic+Surv">Surv</a></code> for the
representation of arbitrarily censored or truncated measurements at any scale.
The <code>storage.mode</code> of <code>object</code> determines if models are fitted
by the discrete likelihood (integers or factors) or the continuous
likelihood (log-density for numeric <code>object</code>s). Interval-censoring
is given by intervals (<code>cleft</code>, <code>cright</code>], also for integers and
factors (see example below). Left- and right-truncation can be defined
by the <code>tleft</code> and <code>tright</code> arguments. Existing <code>Surv</code>
objects can be converted using <code>R(Surv(...))</code>$ and, in some cases, an
<code>as.Surv()</code> method exists for representing <code>response</code> objects as
<code>Surv</code> objects.
</p>
<p><code>R</code> applied to a list calls <code>R</code> for each of the list elements
and returns a joint object.
</p>
<p>More examples can be found in Hothorn (2018) and in 
<code>vignette("tram", package = "tram")</code>.
</p>


<h3>References</h3>

<p>Torsten Hothorn (2020), Most Likely Transformations: The mlt Package,
<em>Journal of Statistical Software</em>, <b>92</b>(1), 1&ndash;68,
<a href="https://doi.org/10.18637/jss.v092.i01">doi:10.18637/jss.v092.i01</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 library("survival")
 
 ### randomly right-censored continuous observations
 time &lt;- as.double(1:9)
 event &lt;- rep(c(FALSE, TRUE), length = length(time))

 Surv(time, event)
 R(Surv(time, event))

 ### right-censoring, left-truncation
 ltm &lt;- 1:9 / 10
 Surv(ltm, time, event)
 R(Surv(ltm, time, event))

 ### interval-censoring
 Surv(ltm, time, type = "interval2")
 R(Surv(ltm, time, type = "interval2"))

 ### interval-censoring, left/right-truncation
 lc &lt;- as.double(1:4)
 lt &lt;- c(NA, NA, 7, 8)
 rt &lt;- c(NA, 9, NA, 10)
 x &lt;- c(3, NA, NA, NA)
 rc &lt;- as.double(11:14)
 R(x, cleft = lt, cright = rt)
 as.Surv(R(x, cleft = lt, cright = rt))
 R(x, tleft = 1, cleft = lt, cright = rt)
 R(x, tleft = 1, cleft = lt, cright = rt, tright = 15)
 R(x, tleft = lc, cleft = lt, cright = rt, tright = rc)

 ### discrete observations: counts
 x &lt;- 0:9
 R(x)
 ### partially interval-censored counts
 rx &lt;- c(rep(NA, 6), rep(15L, 4))
 R(x, cright = rx)

 ### ordered factor
 x &lt;- gl(5, 2, labels = LETTERS[1:5], ordered = TRUE)
 R(x)
 ### interval-censoring (ie, observations can have multiple levels)
 lx &lt;- ordered(c("A", "A", "B", "C", "D", "E"), 
               levels = LETTERS[1:5], labels = LETTERS[1:5])
 rx &lt;- ordered(c("B", "D", "E", "D", "D", "E"), 
               levels = LETTERS[1:5], labels = LETTERS[1:5])
 R(rx, cleft = lx, cright = rx)

 ### facilitate nonparametric maximum likelihood
 (y &lt;- round(runif(10), 1))
 R(y, as.R.ordered = TRUE)

 R(Surv(time, event), as.R.ordered = TRUE)
 R(Surv(ltm, time, event), as.R.ordered = TRUE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
