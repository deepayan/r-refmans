<!DOCTYPE html><html><head><title>Help for package DWLasso</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DWLasso}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#combined'>
<p>Convert the list into a symmetric matrix</p></a></li>
<li><a href='#degreeComp'>
<p>Computing the degree of the inferred network</p></a></li>
<li><a href='#DWLasso'>
<p>Degree weighted lasso</p></a></li>
<li><a href='#MBLasso'>
<p>Inferring the network using nodewise regression method</p></a></li>
<li><a href='#weightComp'>
<p>Computing  weights from the degree of the inferred network</p></a></li>
<li><a href='#weightEstim'>
<p>Estimating weights from the degree of the inferred network</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Degree Weighted Lasso</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Nurgazy Sulaimanov, Sunil Kumar and Heinz Koeppl</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nurgazy Sulaimanov &lt;nurgazy.sulaimanov@bcs.tu-darmstadt.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Infers networks with hubs using degree weighted Lasso method.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, glmnet, hglasso</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-10-06 07:38:36 UTC; nurgazy</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-10-06 07:59:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='combined'>
Convert the list into a symmetric matrix
</h2><span id='topic+combined'></span>

<h3>Description</h3>

<p>This function converts the list of vectors into a symmetric matrix</p>


<h3>Usage</h3>

<pre><code class='language-R'>combined(dat,y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combined_+3A_dat">dat</code></td>
<td>

<p>An input matrix. The columns represent variables and the rows indicate observations.
</p>
</td></tr>
<tr><td><code id="combined_+3A_y">y</code></td>
<td>

<p>List data that includes estimates from nodewise regression. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>symMat</code></td>
<td>

<p>Symmetric matrix that represents the inferred network
</p>
</td></tr>
</table>

<hr>
<h2 id='degreeComp'>
Computing the degree of the inferred network
</h2><span id='topic+degreeComp'></span>

<h3>Description</h3>

<p>This function computes the degree of inferred network</p>


<h3>Usage</h3>

<pre><code class='language-R'>degreeComp(out.mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="degreeComp_+3A_out.mat">out.mat</code></td>
<td>

<p>Symmetric matrix that represents the inferred network
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the degree of estimated networks. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>wlasso_norm</code></td>
<td>

<p>Degree vector computed from the inferred network</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(DWLasso)
library(glmnet)
library(hglasso)


# Generate inverse covariance matrix with 3 hubs
# 20 % of the elements within a hub are zero
# 97 % of the elements that are not within hub nodes are zero
p &lt;- 60 # Number of variables
n &lt;- 40 # Number of samples

hub_number = 3  # Number of hubs

# Generate the adjacency matrix
Theta &lt;- HubNetwork(p,0.97,hub_number,0.2)$Theta

# Generate a data matrix
out &lt;- rmvnorm(n,rep(0,p),solve(Theta))

# Standardize the data
dat &lt;- scale(out)

# Infer the network using weighted nodewise regression
w.mb &lt;- rep(1,p)
adj.mat &lt;- MBLasso(dat,lambda=0.4,w.mb)

# Compute the degree of the inferred network
deg.mat &lt;- degreeComp(adj.mat)
</code></pre>

<hr>
<h2 id='DWLasso'>
Degree weighted lasso
</h2><span id='topic+DWLasso'></span><span id='topic+DWLasso'></span>

<h3>Description</h3>

<p>Infers undirected networks with hubs using weighted nodewise regression approach. The method contains two parameters that control hub and overall sparsity, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DWLasso(X, lambda1 = 0.4, lambda2 = 2, a = 1, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DWLasso_+3A_x">X</code></td>
<td>

<p>An input matrix. The columns represent variables and the rows indicate observations.
</p>
</td></tr>
<tr><td><code id="DWLasso_+3A_lambda1">lambda1</code></td>
<td>

<p>A penalty parameter that controls degree sparsity of the inferred network
</p>
</td></tr>
<tr><td><code id="DWLasso_+3A_lambda2">lambda2</code></td>
<td>

<p>A penalty parameter that controls overall sparsity of the inferred network
</p>
</td></tr>
<tr><td><code id="DWLasso_+3A_a">a</code></td>
<td>

<p>A parameter of the update equation that controls the convergence of weights
</p>
</td></tr>
<tr><td><code id="DWLasso_+3A_tol">tol</code></td>
<td>

<p>Tolerance
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implements weighted degree lasso using coordinate descent algorithm (implemented in Glmnet package) described in Sulaimanov et al.. The method is based on the weighted nodewise regression approach and infers large undirected networks with hubs in iterative manner in the setting more variables than samples (p&gt;n). Given p variables, the network is inferred by regressing each variable against the remaining (p-1) variables.
The penalty parameter, lambda1 controls the degree sparsity of the network, whereas the penalty parameter, lambda2 controls the overall sparsity.The method uses a fast Lasso solver Glmnet (Friedman et al. (2010)) with default settings.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mat</code></td>
<td>

<p>The estimated matrix corresponding to the inferred network. The diagonal elements of the matrix are zero</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p>The estimated weights used to estimate the network. These weights are computed from the degree of estimated networks</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>

<p>The value of the penalty parameter controlling degree sparsity of the inferred network.
</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>

<p>The value of the penalty parameter controlling the overall sparsity</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nurgazy Sulaimanov, Sunil Kumar, Frederic Burdet, Mark Ibberson, Marco Pagni, Heinz Koeppl.
</p>
<p>Maintainer: Nurgazy Sulaimanov, nurgazy.sulaimanov@bcs.tu-darmstadt.de
</p>


<h3>References</h3>

<p>1. Nurgazy Sulaimanov, Sunil Kumar, Frederic Burdet, Mark Ibberson, Marco Pagni, Heinz Koeppl. Inferring hub networks using weighted degree Lasso. http://arxiv.org/abs/1710.01912.
</p>
<p>2. Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization Paths for Generalized Linear Models via Coordinate Descent. Journal of Statistical Software, 33(1), 1-22. URL http://www.jstatsoft.org/v33/i01/.
</p>
<p>3. Tan, KM., London, P., Mohan, K., Lee, S-I., Fazel, M., and Witten, D. (2014). Learning graphical models with hubs. Journal of Machine Learning Research. 5.1 (2014): 3297-3331.
</p>
<p>4. Meinshausen, Nicolai, and Peter Bühlmann. &quot;High-dimensional graphs and variable selection with the lasso.&quot; The annals of statistics (2006): 1436-1462.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DWLasso)
library(glmnet)
library(hglasso)


# Generate inverse covariance matrix with 3 hubs
# 20 % of the elements within a hub are zero
# 97 % of the elements that are not within hub nodes are zero
p &lt;- 60 # Number of variables
n &lt;- 40 # Number of samples

hub_number = 3  # Number of hubs

# Generate the adjacency matrix
Theta &lt;- HubNetwork(p,0.97,hub_number,0.2)$Theta

# Generate a data matrix
out &lt;- rmvnorm(n,rep(0,p),solve(Theta))

# Standardize the data
dat &lt;- scale(out)

# Run DWLasso
out.p &lt;- DWLasso(dat, lambda1 = 0.6, lambda2 = 10)

# print out a summary of the output
summary(out.p)
</code></pre>

<hr>
<h2 id='MBLasso'>
Inferring the network using nodewise regression method
</h2><span id='topic+MBLasso'></span>

<h3>Description</h3>

<p>This function infers the network using nodewise regression method by Meinhausen and Buhlmann. </p>


<h3>Usage</h3>

<pre><code class='language-R'>  MBLasso(dat,lambda=0.4,w.mb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MBLasso_+3A_dat">dat</code></td>
<td>

<p>An input matrix. The columns represent variables and the rows indicate observations.
</p>
</td></tr>
<tr><td><code id="MBLasso_+3A_lambda">lambda</code></td>
<td>

<p>A penalty parameter of the weighted Lasso that controls the sparsity of the inferred network.
</p>
</td></tr>
<tr><td><code id="MBLasso_+3A_w.mb">w.mb</code></td>
<td>

<p>An unput weight vector which is computed from the degree of the inferred network. 
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Meinshausen, Nicolai, and Peter Bühlmann. &quot;High-dimensional graphs and variable selection with the lasso.&quot; The annals of statistics (2006): 1436-1462.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DWLasso)
library(glmnet)
library(hglasso)


# Generate inverse covariance matrix with 3 hubs
# 20 % of the elements within a hub are zero
# 97 % of the elements that are not within hub nodes are zero
p &lt;- 60 # Number of variables
n &lt;- 40 # Number of samples

hub_number = 3  # Number of hubs

# Generate the adjacency matrix
Theta &lt;- HubNetwork(p,0.97,hub_number,0.2)$Theta

# Generate a data matrix
out &lt;- rmvnorm(n,rep(0,p),solve(Theta))

# Standardize the data
dat &lt;- scale(out)

# Infer the network using weighted nodewise regression
w.mb &lt;- rep(1,p)
adj.mat &lt;- MBLasso(dat,lambda=0.4,w.mb)
</code></pre>

<hr>
<h2 id='weightComp'>
Computing  weights from the degree of the inferred network
</h2><span id='topic+weightComp'></span>

<h3>Description</h3>

<p>This function computes weights from the degree of estimated network using the weighted Lasso approach</p>


<h3>Usage</h3>

<pre><code class='language-R'>  weightComp(dat,lam=0.4,w.mb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightComp_+3A_dat">dat</code></td>
<td>

<p>An input matrix. The columns represent variables and the rows indicate observations.
</p>
</td></tr>
<tr><td><code id="weightComp_+3A_lam">lam</code></td>
<td>

<p>A penalty parameter of the weighted Lasso that controls the sparsity of the inferred network.
</p>
</td></tr>
<tr><td><code id="weightComp_+3A_w.mb">w.mb</code></td>
<td>

<p>An unput weight vector which is computed from the degree of the inferred network. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>d.mb</code></td>
<td>

<p>Weight vector computed from degree of the inferred network</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(DWLasso)
library(glmnet)
library(hglasso)


# Generate inverse covariance matrix with 3 hubs
# 20 % of the elements within a hub are zero
# 97 % of the elements that are not within hub nodes are zero
p &lt;- 60 # Number of variables
n &lt;- 40 # Number of samples

hub_number = 3  # Number of hubs

# Generate the adjacency matrix
Theta &lt;- HubNetwork(p,0.97,hub_number,0.2)$Theta

# Generate a data matrix
out &lt;- rmvnorm(n,rep(0,p),solve(Theta))

# Standardize the data
dat &lt;- scale(out)

# Compute weights from the inferred network
w.mb &lt;- rep(1,p)
w.Mat &lt;- weightComp(dat,lam=0.4,w.mb)
</code></pre>

<hr>
<h2 id='weightEstim'>
Estimating weights from the degree of the inferred network
</h2><span id='topic+weightEstim'></span>

<h3>Description</h3>

<p>This function estimates weigths from the degree of the inferred network using iterative procedure. This function is called from the main functon DWLasso.R 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightEstim(dat, lam=0.4, a=1, tol=1e-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightEstim_+3A_dat">dat</code></td>
<td>

<p>An input matrix. The columns represent variables and the rows indicate observations.
</p>
</td></tr>
<tr><td><code id="weightEstim_+3A_lam">lam</code></td>
<td>

<p>A penalty parameter that controls degree sparsity of the inferred network
</p>
</td></tr>
<tr><td><code id="weightEstim_+3A_a">a</code></td>
<td>

<p>A parameter of the update equation that controls the convergence of weights
</p>
</td></tr>
<tr><td><code id="weightEstim_+3A_tol">tol</code></td>
<td>

<p>Tolerance
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>w.dat</code></td>
<td>

<p>Estimated weight vector from the last iteration at which the algorithm converges</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nurgazy Sulaimanov, Sunil Kumar and Heinz Koeppl
</p>


<h3>References</h3>

<p>Nurgazy Sulaimanov, Sunil Kumar, Frederic Burdet, Mark Ibberson, Marco Pagni, Heinz Koeppl. Inferring hub networks using weighted degree Lasso. http://arxiv.org/abs/1710.01912.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DWLasso)
library(glmnet)
library(hglasso)


# Generate inverse covariance matrix with 3 hubs
# 20 % of the elements within a hub are zero
# 97 % of the elements that are not within hub nodes are zero
p &lt;- 60 # Number of variables
n &lt;- 40 # Number of samples

hub_number = 3  # Number of hubs

# Generate the adjacency matrix
Theta &lt;- HubNetwork(p,0.97,hub_number,0.2)$Theta

# Generate a data matrix
out &lt;- rmvnorm(n,rep(0,p),solve(Theta))

# Standardize the data
dat &lt;- scale(out)

# Estimate weights from the degrees of the inferred network
w.est &lt;- weightEstim(dat, lam=0.4, a=1, tol=1e-6)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
