<!DOCTYPE html><html><head><title>Help for package quanteda.textmodels</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {quanteda.textmodels}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#affinity'><p>Internal function to fit the likelihood scaling mixture model.</p></a></li>
<li><a href='#as.coefficients_textmodel'><p>Coerce various objects to coefficients_textmodel</p></a></li>
<li><a href='#as.matrix.csr.dfm'><p>convert a dfm into a matrix.csr from SparseM package</p></a></li>
<li><a href='#as.statistics_textmodel'><p>Coerce various objects to statistics_textmodel</p></a></li>
<li><a href='#as.summary.textmodel'><p>Assign the summary.textmodel class to a list</p></a></li>
<li><a href='#coef.textmodel_ca'><p>Extract model coefficients from a fitted textmodel_ca object</p></a></li>
<li><a href='#data_corpus_dailnoconf1991'><p>Confidence debate from 1991 Irish Parliament</p></a></li>
<li><a href='#data_corpus_EPcoaldebate'><p>Crowd-labelled sentence corpus from a 2010 EP debate on coal subsidies</p></a></li>
<li><a href='#data_corpus_irishbudget2010'><p>Irish budget speeches from 2010</p></a></li>
<li><a href='#data_corpus_moviereviews'><p>Movie reviews with polarity from Pang and Lee (2004)</p></a></li>
<li><a href='#force_conformance'><p>Internal function to match a dfm features to a target set</p></a></li>
<li><a href='#influence.predict.textmodel_affinity'><p>Compute feature influence from a predicted textmodel_affinity object</p></a></li>
<li><a href='#predict.textmodel_affinity'><p>Prediction for a fitted affinity textmodel</p></a></li>
<li><a href='#predict.textmodel_lr'><p>Prediction from a fitted textmodel_lr object</p></a></li>
<li><a href='#predict.textmodel_nb'><p>Prediction from a fitted textmodel_nb object</p></a></li>
<li><a href='#predict.textmodel_svm'><p>Prediction from a fitted textmodel_svm object</p></a></li>
<li><a href='#predict.textmodel_svmlin'><p>Prediction from a fitted textmodel_svmlin object</p></a></li>
<li><a href='#predict.textmodel_wordfish'><p>Prediction from a textmodel_wordfish method</p></a></li>
<li><a href='#predict.textmodel_wordscores'><p>Predict textmodel_wordscores</p></a></li>
<li><a href='#print.coefficients_textmodel'><p>Print methods for textmodel features estimates</p></a></li>
<li><a href='#print.statistics_textmodel'><p>Implements print methods for textmodel_statistics</p></a></li>
<li><a href='#print.summary.textmodel'><p>print method for summary.textmodel</p></a></li>
<li><a href='#print.textmodel_wordfish'><p>print method for a wordfish model</p></a></li>
<li><a href='#summary.textmodel_lr'><p>summary method for textmodel_lr objects</p></a></li>
<li><a href='#summary.textmodel_nb'><p>summary method for textmodel_nb objects</p></a></li>
<li><a href='#summary.textmodel_svm'><p>summary method for textmodel_svm objects</p></a></li>
<li><a href='#summary.textmodel_svmlin'><p>summary method for textmodel_svmlin objects</p></a></li>
<li><a href='#summary.textmodel_wordfish'><p>summary method for textmodel_wordfish</p></a></li>
<li><a href='#textmodel_affinity'><p>Class affinity maximum likelihood text scaling model</p></a></li>
<li><a href='#textmodel_affinity-internal'><p>Internal methods for textmodel_affinity</p></a></li>
<li><a href='#textmodel_ca'><p>Correspondence analysis of a document-feature matrix</p></a></li>
<li><a href='#textmodel_lr'><p>Logistic regression classifier for texts</p></a></li>
<li><a href='#textmodel_lsa'><p>Latent Semantic Analysis</p></a></li>
<li><a href='#textmodel_lsa-postestimation'><p>Post-estimations methods for textmodel_lsa</p></a></li>
<li><a href='#textmodel_nb'><p>Naive Bayes classifier for texts</p></a></li>
<li><a href='#textmodel_svm'><p>Linear SVM classifier for texts</p></a></li>
<li><a href='#textmodel_svmlin'><p>[experimental] Linear SVM classifier for texts</p></a></li>
<li><a href='#textmodel_wordfish'><p>Wordfish text model</p></a></li>
<li><a href='#textmodel_wordscores'><p>Wordscores text model</p></a></li>
<li><a href='#textmodels'><p>quanteda.textmodels: Scaling Models and Classifiers for Textual Data</p></a></li>
<li><a href='#textplot_influence'><p>Influence plot for text scaling models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Scaling Models and Classifiers for Textual Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Scaling models and classifiers for sparse matrix objects representing 
    textual data in the form of a document-feature matrix.  Includes original 
    implementations of 'Laver', 'Benoit', and Garry's (2003) &lt;<a href="https://doi.org/10.1017%2FS0003055403000698">doi:10.1017/S0003055403000698</a>&gt;,
    'Wordscores' model, the Perry and 'Benoit' (2017) &lt;<a href="https://arxiv.org/abs/1710.08963">arXiv:1710.08963</a>&gt; class affinity scaling model, 
    and the 'Slapin' and 'Proksch' (2008) &lt;<a href="https://doi.org/10.1111%2Fj.1540-5907.2008.00338.x">doi:10.1111/j.1540-5907.2008.00338.x</a>&gt; 'wordfish'
    model, as well as methods for correspondence analysis, latent semantic analysis,
    and fast Naive Bayes and linear 'SVMs' specially designed for sparse textual data.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, LiblineaR, Matrix (&ge; 1.2), quanteda (&ge; 2.0),
RSpectra, Rcpp (&ge; 0.12.12), RcppParallel, SparseM, stringi</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ca, covr, fastNaiveBayes, knitr, lsa, microbenchmark,
naivebayes, quanteda.textplots, spelling, testthat, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppParallel, RcppArmadillo (&ge; 0.7.600.1.0), quanteda</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/quanteda/quanteda.textmodels">https://github.com/quanteda/quanteda.textmodels</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'RcppExports.R' 'quanteda.textmodels-package.R'
'data-documentation.R' 'textmodel-methods.R'
'textmodel_affinity.R' 'textmodel_ca.R' 'textmodel_lsa.R'
'textmodel_lr.R' 'textmodel_nb.R' 'textmodel_svm.R'
'textmodel_svmlin.R' 'textmodel_wordfish.R'
'textmodel_wordscores.R' 'textplot_influence.R' 'utils.R'</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-22 00:55:30 UTC; kbenoit</td>
</tr>
<tr>
<td>Author:</td>
<td>Kenneth Benoit <a href="https://orcid.org/0000-0002-0797-564X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut, cph],
  Kohei Watanabe <a href="https://orcid.org/0000-0001-6519-5265"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Haiyan Wang <a href="https://orcid.org/0000-0003-4992-4311"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Patrick O. Perry <a href="https://orcid.org/0000-0001-7460-127X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Benjamin Lauderdale
    <a href="https://orcid.org/0000-0003-3090-0969"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Johannes Gruber <a href="https://orcid.org/0000-0001-9177-1772"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  William Lowe <a href="https://orcid.org/0000-0002-1549-6163"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Vikas Sindhwani [cph] (authored svmlin C++ source code),
  European Research Council [fnd] (ERC-2011-StG 283794-QUANTESS)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kenneth Benoit &lt;kbenoit@lse.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-22 09:20:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='affinity'>Internal function to fit the likelihood scaling mixture model.</h2><span id='topic+affinity'></span>

<h3>Description</h3>

<p>Ken recommends you use <code><a href="#topic+textmodel_affinity">textmodel_affinity()</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>affinity(p, x, smooth = 0.5, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="affinity_+3A_p">p</code></td>
<td>
<p>word likelihoods within classes, estimated from training data</p>
</td></tr>
<tr><td><code id="affinity_+3A_x">x</code></td>
<td>
<p>term-document matrix for document(s) to be scaled</p>
</td></tr>
<tr><td><code id="affinity_+3A_smooth">smooth</code></td>
<td>
<p>a misnamed smoothing parameter, either a scalar or a vector
equal in length to the number of documents</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing:
</p>

<ul>
<li> <p><code>coefficients</code> point estimates of theta
</p>
</li>
<li> <p><code>se</code> (likelihood) standard error of theta
</p>
</li>
<li> <p><code>cov</code> covariance matrix
</p>
</li>
<li> <p><code>smooth</code> values of the smoothing parameter
</p>
</li>
<li> <p><code>support</code> logical indicating if the feature was included
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Patrick Perry
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- matrix(c(c(5/6, 0, 1/6), c(0, 4/5, 1/5)), nrow = 3,
            dimnames = list(c("A", "B", "C"), NULL))
theta &lt;- c(.2, .8)
q &lt;- drop(p %*% theta)
x &lt;- 2 * q
(fit &lt;- affinity(p, x))
</code></pre>

<hr>
<h2 id='as.coefficients_textmodel'>Coerce various objects to coefficients_textmodel</h2><span id='topic+as.coefficients_textmodel'></span>

<h3>Description</h3>

<p>Helper functions used in <code style="white-space: pre;">&#8288;summary.textmodel_*()&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.coefficients_textmodel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.coefficients_textmodel_+3A_x">x</code></td>
<td>
<p>an object to be coerced</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object with the class tag of <code>coefficients_textmodel</code>
</p>

<hr>
<h2 id='as.matrix.csr.dfm'>convert a dfm into a matrix.csr from SparseM package</h2><span id='topic+as.matrix.csr.dfm'></span>

<h3>Description</h3>

<p>Utility to convert a dfm into a <a href="SparseM.html#topic+SparseM.ontology">matrix.csr</a> from the <span class="pkg">SparseM</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dfm'
as.matrix.csr(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.csr.dfm_+3A_x">x</code></td>
<td>
<p>input dfm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <span class="pkg">SparseM</span> object of class <a href="SparseM.html#topic+SparseM.ontology">matrix.csr</a>
</p>

<hr>
<h2 id='as.statistics_textmodel'>Coerce various objects to statistics_textmodel</h2><span id='topic+as.statistics_textmodel'></span>

<h3>Description</h3>

<p>This is a helper function used in <code style="white-space: pre;">&#8288;summary.textmodel_*&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.statistics_textmodel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.statistics_textmodel_+3A_x">x</code></td>
<td>
<p>an object to be coerced</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>statistics_textmodel</code>
</p>

<hr>
<h2 id='as.summary.textmodel'>Assign the summary.textmodel class to a list</h2><span id='topic+as.summary.textmodel'></span>

<h3>Description</h3>

<p>Assigns the class <code>summary.textmodel</code> to a list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.summary.textmodel(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.summary.textmodel_+3A_x">x</code></td>
<td>
<p>a named list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>summary.textmodel</code>
</p>

<hr>
<h2 id='coef.textmodel_ca'>Extract model coefficients from a fitted textmodel_ca object</h2><span id='topic+coef.textmodel_ca'></span><span id='topic+coefficients.textmodel_ca'></span>

<h3>Description</h3>

<p><code>coef()</code> extract model coefficients from a fitted <code>textmodel_ca</code>
object.  <code>coefficients()</code> is an alias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_ca'
coef(object, doc_dim = 1, feat_dim = 1, ...)

coefficients.textmodel_ca(object, doc_dim = 1, feat_dim = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.textmodel_ca_+3A_object">object</code></td>
<td>
<p>a fitted <a href="#topic+textmodel_ca">textmodel_ca</a> object</p>
</td></tr>
<tr><td><code id="coef.textmodel_ca_+3A_doc_dim">doc_dim</code>, <code id="coef.textmodel_ca_+3A_feat_dim">feat_dim</code></td>
<td>
<p>the document and feature dimension scores to be
extracted</p>
</td></tr>
<tr><td><code id="coef.textmodel_ca_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing numeric vectors of feature and document
coordinates.  Includes <code>NA</code> vectors of standard errors for consistency with
other models' coefficient outputs, and for the possibility of having these
computed in the future.
</p>

<ul>
<li> <p><code>coef_feature</code> column coordinates of the features
</p>
</li>
<li> <p><code>coef_feature_se</code> feature length vector of <code>NA</code> values
</p>
</li>
<li> <p><code>coef_document</code> row coordinates of the documents
</p>
</li>
<li> <p><code>coef_document_se</code> document length vector of <code>NA</code> values
</p>
</li></ul>


<hr>
<h2 id='data_corpus_dailnoconf1991'>Confidence debate from 1991 Irish Parliament</h2><span id='topic+data_corpus_dailnoconf1991'></span>

<h3>Description</h3>

<p>Texts of speeches from a no-confidence motion debated in the Irish Dáil from
16-18 October 1991 over the future of the Fianna Fail-Progressive Democrat
coalition. (See Laver and Benoit 2002 for details.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_corpus_dailnoconf1991
</code></pre>


<h3>Format</h3>

<p><code>data_corpus_dailnoconf1991</code> is a corpus with 58 texts,
including docvars for <code>name</code>, <code>party</code>, and <code>position</code>.
</p>


<h3>Source</h3>

<p><a href="https://www.oireachtas.ie/en/debates/debate/dail/1991-10-16/10/">https://www.oireachtas.ie/en/debates/debate/dail/1991-10-16/10/</a>
</p>


<h3>References</h3>

<p>Laver, M. &amp; Benoit, K.R. (2002).
<a href="https://kenbenoit.net/pdfs/Laver_Benoit_IPS_2002.pdf">Locating TDs in Policy Spaces: Wordscoring Dáil Speeches</a>. <em>Irish Political
Studies</em>, 17(1), 59&ndash;73.
</p>
<p>Laver, M., Benoit, K.R., &amp; Garry, J. (2003).
<a href="https://kenbenoit.net/pdfs/WORDSCORESAPSR.pdf">Estimating Policy Positions from Political Text using Words as Data</a>. <em>American
Political Science Review</em>, 97(2), 311&ndash;331.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("quanteda")
data_dfm_dailnoconf1991 &lt;- data_corpus_dailnoconf1991 %&gt;%
    tokens(remove_punct = TRUE) %&gt;%
    dfm()
tmod &lt;- textmodel_affinity(data_dfm_dailnoconf1991,
                           c("Govt", "Opp", "Opp", rep(NA, 55)))
(pred &lt;- predict(tmod))
dat &lt;-
    data.frame(party = as.character(docvars(data_corpus_dailnoconf1991, "party")),
               govt = coef(pred)[, "Govt"],
               position = as.character(docvars(data_corpus_dailnoconf1991, "position")))
bymedian &lt;- with(dat, reorder(paste(party, position), govt, median))
oldpar &lt;- par(no.readonly = TRUE)
par(mar = c(5, 6, 4, 2) + .1)
boxplot(govt ~ bymedian, data = dat,
        horizontal = TRUE, las = 1,
        xlab = "Degree of support for government",
        ylab = "")
abline(h = 7.5, col = "red", lty = "dashed")
text(c(0.9, 0.9), c(8.5, 6.5), c("Goverment", "Opposition"))
par(oldpar)

## End(Not run)
</code></pre>

<hr>
<h2 id='data_corpus_EPcoaldebate'>Crowd-labelled sentence corpus from a 2010 EP debate on coal subsidies</h2><span id='topic+data_corpus_EPcoaldebate'></span>

<h3>Description</h3>

<p>A multilingual text corpus of speeches from a European
Parliament debate on coal subsidies in 2010, with individual crowd codings
as the unit of observation.  The sentences are drawn from officially
translated speeches from a debate over a European Parliament debate
concerning a Commission report proposing an extension to a regulation
permitting state aid to uncompetitive coal mines.
</p>
<p>Each speech is available in six languages: English, German,
Greek, Italian, Polish and Spanish. The unit of observation is the
individual crowd coding of each natural sentence. For more information on
the coding approach see Benoit et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_corpus_EPcoaldebate
</code></pre>


<h3>Format</h3>

<p>The corpus consists of 16,806 documents (i.e. codings of a sentence) and includes the following
document-level variables: </p>

<dl>
<dt>sentence_id</dt><dd><p>character; a unique identifier for each sentence</p>
</dd>
<dt>crowd_subsidy_label</dt><dd><p>factor; whether a coder labelled the sentence
as &quot;Pro-Subsidy&quot;, &quot;Anti-Subsidy&quot; or &quot;Neutral or inapplicable&quot;</p>
</dd>
<dt>language</dt><dd><p>factor; the language (translation) of the speech</p>
</dd>
<dt>name_last</dt><dd><p>character; speaker's last name</p>
</dd>
<dt>name_first</dt><dd><p>character; speaker's first name</p>
</dd>
<dt>ep_group</dt><dd><p>factor; abbreviation of the EP party group of the speaker</p>
</dd>
<dt>country</dt><dd><p>factor; the speaker's country of origin</p>
</dd>
<dt>vote</dt><dd><p>factor; the speaker's vote on the proposal (For/Against/Abstain/NA)</p>
</dd>
<dt>coder_id</dt><dd><p>character; a unique identifier for each crowd coder</p>
</dd>
<dt>coder_trust</dt><dd><p>numeric; the &quot;trust score&quot; from the Crowdflower platform used to code the
sentences, which can theoretically range between 0 and 1. Only coders with trust scores above
0.8 are included in the corpus.</p>
</dd>
</dl>

<p>A <a href="quanteda.html#topic+corpus">corpus</a> object.
</p>


<h3>References</h3>

<p>Benoit, K., Conway, D., Lauderdale, B.E., Laver, M., &amp; Mikhaylov,
S. (2016). Crowd-sourced Text Analysis: Reproducible and Agile Production
of Political Data. <em>American Political Science Review</em>, 100,(2), 278&ndash;295.
<a href="https://doi.org/10.1017/S0003055416000058">doi:10.1017/S0003055416000058</a>
</p>

<hr>
<h2 id='data_corpus_irishbudget2010'>Irish budget speeches from 2010</h2><span id='topic+data_corpus_irishbudget2010'></span>

<h3>Description</h3>

<p>Speeches and document-level variables from the debate over the Irish budget
of 2010.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_corpus_irishbudget2010
</code></pre>


<h3>Format</h3>

<p>The corpus object for the 2010 budget speeches, with document-level
variables for year, debate, serial number, first and last name of the
speaker, and the speaker's party.
</p>


<h3>Details</h3>

<p>At the time of the debate, Fianna Fáil (FF) and the Greens formed the government
coalition, while Fine Gael (FG), Labour (LAB), and Sinn Féin (SF) were in opposition.
</p>


<h3>Source</h3>

<p>Dáil Éireann Debate,
<a href="https://www.oireachtas.ie/en/debates/debate/dail/2009-12-09/33/">Budget Statement 2010.</a>
9 December 2009. vol. 697, no. 3.
</p>


<h3>References</h3>

<p>Lowe, W. &amp; Benoit, K.R. (2013). Validating Estimates of Latent
Traits From Textual Data Using Human Judgment as a Benchmark. <em>Political
Analysis</em>, 21(3), 298&ndash;313. <a href="https://doi.org/10.1093/pan/mpt002">doi:10.1093/pan/mpt002</a>.
</p>

<hr>
<h2 id='data_corpus_moviereviews'>Movie reviews with polarity from Pang and Lee (2004)</h2><span id='topic+data_corpus_moviereviews'></span>

<h3>Description</h3>

<p>A corpus object containing 2,000 movie reviews classified by positive or negative sentiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_corpus_moviereviews
</code></pre>


<h3>Format</h3>

<p>The corpus includes the following document variables: </p>

<dl>
<dt>sentiment</dt><dd><p>factor indicating whether a review was manually classified as
positive <code>pos</code> or negative <code>neg</code>.</p>
</dd>
<dt>id1</dt><dd><p>Character counting the position in the corpus.</p>
</dd>
<dt>id2</dt><dd><p>Random number for each review.</p>
</dd>
</dl>



<h3>Details</h3>

<p>For more information, see <code>cat(meta(data_corpus_moviereviews, "readme"))</code>.
</p>


<h3>Source</h3>

<p><a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a>
</p>


<h3>References</h3>

<p>Pang, B., Lee, L.  (2004)
&quot;<a href="https://www.cs.cornell.edu/home/llee/papers/cutsent.pdf">A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</a>&quot;, Proceedings of the ACL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># check polarities
table(data_corpus_moviereviews$sentiment)

# make the data into sentences, because each line is a sentence
data_corpus_moviereviewsents &lt;-
    quanteda::corpus_segment(data_corpus_moviereviews, "\n", extract_pattern = FALSE)
print(data_corpus_moviereviewsents, max_ndoc = 3)
</code></pre>

<hr>
<h2 id='force_conformance'>Internal function to match a dfm features to a target set</h2><span id='topic+force_conformance'></span>

<h3>Description</h3>

<p>Takes a dfm and a set of features, and makes them match the features listed
in the set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>force_conformance(x, features, force = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="force_conformance_+3A_x">x</code></td>
<td>
<p>input dfm</p>
</td></tr>
<tr><td><code id="force_conformance_+3A_features">features</code></td>
<td>
<p>character; a vector of feature names</p>
</td></tr>
<tr><td><code id="force_conformance_+3A_force">force</code></td>
<td>
<p>logical; if <code>TRUE</code>, make the new dfm conform to the vector of
features, otherwise return an error message</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <a href="quanteda.html#topic+dfm">dfm</a> from the <span class="pkg">quanteda</span> package containing
only <code>features</code> as columns, in the same order as <code>features</code>.  A warning message
is printed if some feature names from <code>features</code> are not matched in <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quanteda.textmodels:::force_conformance(quanteda::data_dfm_lbgexample, c("C", "B", "Z"))
</code></pre>

<hr>
<h2 id='influence.predict.textmodel_affinity'>Compute feature influence from a predicted textmodel_affinity object</h2><span id='topic+influence.predict.textmodel_affinity'></span>

<h3>Description</h3>

<p>Computes the influence of features on scaled <code><a href="#topic+textmodel_affinity">textmodel_affinity()</a></code>
applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predict.textmodel_affinity'
influence(model, subset = !train, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="influence.predict.textmodel_affinity_+3A_model">model</code></td>
<td>
<p>a predicted <a href="#topic+predict.textmodel_affinity">textmodel_affinity()</a>
object</p>
</td></tr>
<tr><td><code id="influence.predict.textmodel_affinity_+3A_subset">subset</code></td>
<td>
<p>whether to use all data or a subset (for instance, exclude the
training set)</p>
</td></tr>
<tr><td><code id="influence.predict.textmodel_affinity_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list classed as <a href="#topic+influence.predict.textmodel_affinity">influence.predict.textmodel_affinity</a> that
contains
</p>

<ul>
<li> <p><code>norm</code> a document by feature class sparse matrix of normalised influence
measures
</p>
</li>
<li> <p><code>count</code> a vector of counts of each non-zero feature in the input matrix
</p>
</li>
<li> <p><code>rate</code> the normalised feature count for each non-zero feature in the input
matrix
</p>
</li>
<li> <p><code>mode</code> an integer vector of 1 or 2 indicating the class which the feature
is influencing, for each non-zero feature
</p>
</li>
<li> <p><code>levels</code> a character vector of the affinity class labels
</p>
</li>
<li> <p><code>subset</code> a logical vector indicating whether the document was included in
the computation of influence; <code>FALSE</code> for documents assigned a class label
in training the model
</p>
</li>
<li> <p><code>support</code> logical vector for each feature matching the same return from
<a href="#topic+predict.textmodel_affinity">predict.textmodel_affinity</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="stats.html#topic+influence.lm">influence.lm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmod &lt;- textmodel_affinity(quanteda::data_dfm_lbgexample, y = c("L", NA, NA, NA, "R", NA))
pred &lt;- predict(tmod)
influence(pred)
</code></pre>

<hr>
<h2 id='predict.textmodel_affinity'>Prediction for a fitted affinity textmodel</h2><span id='topic+predict.textmodel_affinity'></span><span id='topic+coef.predict.textmodel_affinity'></span><span id='topic+residuals.predict.textmodel_affinity'></span><span id='topic+rstandard.predict.textmodel_affinity'></span>

<h3>Description</h3>

<p>Estimate <code class="reqn">\theta_i</code> for each document, from a fitted
<a href="#topic+textmodel_affinity">textmodel_affinity</a> object.
</p>
<p>Other methods below provide standard ways to extract or compute quantities
from predicted <a href="#topic+textmodel_affinity">textmodel_affinity</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_affinity'
predict(object, newdata = NULL, level = 0.95, ...)

## S3 method for class 'predict.textmodel_affinity'
coef(object, ...)

## S3 method for class 'predict.textmodel_affinity'
residuals(object, type = c("response", "pearson"), ...)

## S3 method for class 'predict.textmodel_affinity'
rstandard(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_affinity_+3A_object">object</code></td>
<td>
<p>a fitted affinity textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_affinity_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_affinity_+3A_level">level</code></td>
<td>
<p>probability level for confidence interval width</p>
</td></tr>
<tr><td><code id="predict.textmodel_affinity_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
<tr><td><code id="predict.textmodel_affinity_+3A_type">type</code></td>
<td>
<p>see <a href="stats.html#topic+residuals.lm">residuals.lm</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict()</code> returns a list of predicted affinity textmodel
quantities, containing:
</p>

<ul>
<li> <p><code>coefficients</code> a numeric matrix of affinity estimates (coefficients) for
each class (columns) for each document (rows)
</p>
</li>
<li> <p><code>se</code> a numeric matrix of likelihood standard errors for affinity coefficients
each class (columns) for each document (rows)
</p>
</li>
<li> <p><code>cov</code> an array of covariance matrices for each affinity class, one per document
</p>
</li>
<li> <p><code>smooth</code> a numeric vector of length two for the smoothing parameters <code>smooth</code>
and <code>ref_smooth</code> from <code><a href="#topic+textmodel_affinity">textmodel_affinity()</a></code>
</p>
</li>
<li> <p><code>newdata</code> a <a href="quanteda.html#topic+dfm">dfm</a> on which prediction has been made
</p>
</li>
<li> <p><code>train</code> a logical vector indicating which documents were used in training the model
</p>
</li>
<li> <p><code>level</code> the confidence level for computing standard errors
</p>
</li>
<li> <p><code>p</code> the <code>p</code> return from <code>textmodel_affinity</code>
</p>
</li>
<li> <p><code>support</code> logical vector indicating whether a feature was included in computing
class affinities
</p>
</li></ul>

<p><code>coef()</code> returns a document <code class="reqn">\times</code> class matrix of class
affinities for each document.
</p>
<p><code>residuals()</code> returns a document-by-feature matrix of residuals.
<code>resid()</code> is an alias.
</p>
<p><code>rstandard()</code> is a shortcut to return the Pearson residuals.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+influence.predict.textmodel_affinity">influence.predict.textmodel_affinity()</a></code> for methods of
computing the influence of particular features from a predicted
<a href="#topic+textmodel_affinity">textmodel_affinity</a> model.
</p>

<hr>
<h2 id='predict.textmodel_lr'>Prediction from a fitted textmodel_lr object</h2><span id='topic+predict.textmodel_lr'></span><span id='topic+coef.textmodel_lr'></span><span id='topic+coefficients.textmodel_lr'></span>

<h3>Description</h3>

<p><code>predict.textmodel_lr()</code> implements class predictions from a fitted
logistic regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_lr'
predict(
  object,
  newdata = NULL,
  type = c("class", "probability"),
  force = TRUE,
  ...
)

## S3 method for class 'textmodel_lr'
coef(object, ...)

## S3 method for class 'textmodel_lr'
coefficients(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_lr_+3A_object">object</code></td>
<td>
<p>a fitted logistic regression textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_lr_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_lr_+3A_type">type</code></td>
<td>
<p>the type of predicted values to be returned; see Value</p>
</td></tr>
<tr><td><code id="predict.textmodel_lr_+3A_force">force</code></td>
<td>
<p>make newdata's feature set conformant to the model terms</p>
</td></tr>
<tr><td><code id="predict.textmodel_lr_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.textmodel_lr()</code> returns either a vector of class
predictions for each row of <code>newdata</code> (when <code>type = "class"</code>), or
a document-by-class matrix of class probabilities (when 'type =
&quot;probability&quot;&ldquo;).
</p>
<p><code>coef.textmodel_lr()</code> returns a (sparse) matrix of coefficients for
each feature, computed at the value of the penalty parameter fitted in the
model.  For binary outcomes, results are returned only for the class
corresponding to the second level of the factor response; for multinomial
outcomes, these are computed for each class.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textmodel_lr">textmodel_lr()</a></code>
</p>

<hr>
<h2 id='predict.textmodel_nb'>Prediction from a fitted textmodel_nb object</h2><span id='topic+predict.textmodel_nb'></span><span id='topic+coef.textmodel_nb'></span><span id='topic+coefficients.textmodel_nb'></span>

<h3>Description</h3>

<p><code>predict.textmodel_nb()</code> implements class predictions from a fitted
Naive Bayes model. using trained Naive Bayes examples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_nb'
predict(
  object,
  newdata = NULL,
  type = c("class", "probability", "logposterior"),
  force = FALSE,
  ...
)

## S3 method for class 'textmodel_nb'
coef(object, ...)

## S3 method for class 'textmodel_nb'
coefficients(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_nb_+3A_object">object</code></td>
<td>
<p>a fitted Naive Bayes textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_nb_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_nb_+3A_type">type</code></td>
<td>
<p>the type of predicted values to be returned; see Value</p>
</td></tr>
<tr><td><code id="predict.textmodel_nb_+3A_force">force</code></td>
<td>
<p>make newdata's feature set conformant to the model terms</p>
</td></tr>
<tr><td><code id="predict.textmodel_nb_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.textmodel_nb</code> returns either a vector of class
predictions for each row of <code>newdata</code> (when <code>type = "class"</code>), or
a document-by-class matrix of class probabilities (when <code>type = "probability"</code>) or log posterior likelihoods (when <code>type = "logposterior"</code>).
</p>
<p><code>coef.textmodel_nb()</code> returns a matrix of estimated
word likelihoods given the class.  (In earlier versions,
this was named <code>PwGc</code>.)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textmodel_nb">textmodel_nb()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># application to LBG (2003) example data
(tmod &lt;- textmodel_nb(quanteda::data_dfm_lbgexample, y = c("A", "A", "B", "C", "C", NA)))
predict(tmod)
predict(tmod, type = "logposterior")
</code></pre>

<hr>
<h2 id='predict.textmodel_svm'>Prediction from a fitted textmodel_svm object</h2><span id='topic+predict.textmodel_svm'></span>

<h3>Description</h3>

<p><code>predict.textmodel_svm()</code> implements class predictions from a fitted
linear SVM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_svm'
predict(
  object,
  newdata = NULL,
  type = c("class", "probability"),
  force = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_svm_+3A_object">object</code></td>
<td>
<p>a fitted linear SVM textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_svm_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_svm_+3A_type">type</code></td>
<td>
<p>the type of predicted values to be returned; see Value</p>
</td></tr>
<tr><td><code id="predict.textmodel_svm_+3A_force">force</code></td>
<td>
<p>make newdata's feature set conformant to the model terms</p>
</td></tr>
<tr><td><code id="predict.textmodel_svm_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.textmodel_svm</code> returns either a vector of class
predictions for each row of <code>newdata</code> (when <code>type = "class"</code>), or
a document-by-class matrix of class probabilities (when <code>type = "probability"</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textmodel_svm">textmodel_svm()</a></code>
</p>

<hr>
<h2 id='predict.textmodel_svmlin'>Prediction from a fitted textmodel_svmlin object</h2><span id='topic+predict.textmodel_svmlin'></span>

<h3>Description</h3>

<p><code>predict.textmodel_svmlin()</code> implements class predictions from a fitted
linear SVM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_svmlin'
predict(
  object,
  newdata = NULL,
  type = c("class", "probability"),
  force = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_svmlin_+3A_object">object</code></td>
<td>
<p>a fitted linear SVM textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_svmlin_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_svmlin_+3A_type">type</code></td>
<td>
<p>the type of predicted values to be returned; see Value</p>
</td></tr>
<tr><td><code id="predict.textmodel_svmlin_+3A_force">force</code></td>
<td>
<p>logical, if <code>TRUE</code>, make newdata's feature set conformant to the
model terms</p>
</td></tr>
<tr><td><code id="predict.textmodel_svmlin_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.textmodel_svmlin</code> returns either a vector of class
predictions for each row of <code>newdata</code> (when <code>type = "class"</code>), or
a document-by-class matrix of class probabilities (when <code>type = "probability"</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textmodel_svmlin">textmodel_svmlin()</a></code>
</p>

<hr>
<h2 id='predict.textmodel_wordfish'>Prediction from a textmodel_wordfish method</h2><span id='topic+predict.textmodel_wordfish'></span><span id='topic+coef.textmodel_wordfish'></span><span id='topic+coefficients.textmodel_wordfish'></span>

<h3>Description</h3>

<p><code>predict.textmodel_wordfish()</code> returns estimated document scores and
confidence intervals.  The method is provided for consistency with other
<code style="white-space: pre;">&#8288;textmodel_*()&#8288;</code> methods, but does not currently allow prediction on
out-of-sample data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_wordfish'
predict(
  object,
  se.fit = FALSE,
  interval = c("none", "confidence"),
  level = 0.95,
  ...
)

## S3 method for class 'textmodel_wordfish'
coef(object, margin = c("both", "documents", "features"), ...)

coefficients.textmodel_wordfish(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_wordfish_+3A_object">object</code></td>
<td>
<p>a fitted wordfish model</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordfish_+3A_se.fit">se.fit</code></td>
<td>
<p>if <code>TRUE</code>, return standard errors as well</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordfish_+3A_interval">interval</code></td>
<td>
<p>type of confidence interval calculation</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordfish_+3A_level">level</code></td>
<td>
<p>tolerance/confidence level for intervals</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordfish_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordfish_+3A_margin">margin</code></td>
<td>
<p>which margin of parameter estimates to return: both (in a
list), or just document or feature parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>coef.textmodel_wordfish()</code> returns a matrix of estimated
parameters coefficients for the specified margin.
</p>

<hr>
<h2 id='predict.textmodel_wordscores'>Predict textmodel_wordscores</h2><span id='topic+predict.textmodel_wordscores'></span>

<h3>Description</h3>

<p>Predict textmodel_wordscores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_wordscores'
predict(
  object,
  newdata = NULL,
  se.fit = FALSE,
  interval = c("none", "confidence"),
  level = 0.95,
  rescaling = c("none", "lbg", "mv"),
  force = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmodel_wordscores_+3A_object">object</code></td>
<td>
<p>a fitted Wordscores textmodel</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_newdata">newdata</code></td>
<td>
<p>dfm on which prediction should be made</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_se.fit">se.fit</code></td>
<td>
<p>if <code>TRUE</code>, return standard errors as well</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_interval">interval</code></td>
<td>
<p>type of confidence interval calculation</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_level">level</code></td>
<td>
<p>tolerance/confidence level for intervals</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_rescaling">rescaling</code></td>
<td>
<p><code>"none"</code> for &quot;raw&quot; scores; <code>"lbg"</code> for LBG (2003)
rescaling; or <code>"mv"</code> for the rescaling proposed by Martin and Vanberg
(2007).  See References.</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_force">force</code></td>
<td>
<p>make the feature set of <code>newdata</code> conform to the model
terms.  The default of <code>TRUE</code> means that a fitted model can be applied
to scale a dfm that does not contain a 1:1 match of features in the
training and prediction data.</p>
</td></tr>
<tr><td><code id="predict.textmodel_wordscores_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.textmodel_wordscores()</code> returns a named vector of predicted
document scores (&quot;text scores&quot; <code class="reqn">S_{vd}</code> in LBG 2003), or a named list if
<code>se.fit = TRUE</code> consisting of the predicted scores (<code style="white-space: pre;">&#8288;$fit&#8288;</code>) and the
associated standard errors (<code style="white-space: pre;">&#8288;$se.fit&#8288;</code>). When <code>interval = "confidence"</code>, the predicted values will be a matrix.  This behaviour matches
that of <code><a href="stats.html#topic+predict.lm">stats::predict.lm()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmod &lt;- textmodel_wordscores(quanteda::data_dfm_lbgexample, c(seq(-1.5, 1.5, .75), NA))
predict(tmod)
predict(tmod, rescaling = "mv")
predict(tmod, rescaling = "lbg")
predict(tmod, se.fit = TRUE)
predict(tmod, se.fit = TRUE, interval = "confidence")
predict(tmod, se.fit = TRUE, interval = "confidence", rescaling = "lbg")
</code></pre>

<hr>
<h2 id='print.coefficients_textmodel'>Print methods for textmodel features estimates</h2><span id='topic+print.coefficients_textmodel'></span>

<h3>Description</h3>

<p>This is a helper function used in <code>print.summary.textmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coefficients_textmodel'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.coefficients_textmodel_+3A_x">x</code></td>
<td>
<p>a coefficients_textmodel object</p>
</td></tr>
<tr><td><code id="print.coefficients_textmodel_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant digits</em>, see
<code><a href="base.html#topic+print.default">print.default()</a></code></p>
</td></tr>
<tr><td><code id="print.coefficients_textmodel_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>

<hr>
<h2 id='print.statistics_textmodel'>Implements print methods for textmodel_statistics</h2><span id='topic+print.statistics_textmodel'></span>

<h3>Description</h3>

<p>Implements print methods for textmodel_statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'statistics_textmodel'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.statistics_textmodel_+3A_x">x</code></td>
<td>
<p>a textmodel_wordscore_statistics object</p>
</td></tr>
<tr><td><code id="print.statistics_textmodel_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant digits</em>, see
<code><a href="base.html#topic+print.default">print.default()</a></code></p>
</td></tr>
<tr><td><code id="print.statistics_textmodel_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>

<hr>
<h2 id='print.summary.textmodel'>print method for summary.textmodel</h2><span id='topic+print.summary.textmodel'></span>

<h3>Description</h3>

<p>print method for summary.textmodel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.textmodel'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.textmodel_+3A_x">x</code></td>
<td>
<p>a <code>summary.textmodel</code> object</p>
</td></tr>
<tr><td><code id="print.summary.textmodel_+3A_digits">digits</code></td>
<td>
<p>minimal number of <em>significant digits</em>, see
<code><a href="base.html#topic+print.default">print.default()</a></code></p>
</td></tr>
<tr><td><code id="print.summary.textmodel_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>

<hr>
<h2 id='print.textmodel_wordfish'>print method for a wordfish model</h2><span id='topic+print.textmodel_wordfish'></span>

<h3>Description</h3>

<p>print method for a wordfish model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_wordfish'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.textmodel_wordfish_+3A_x">x</code></td>
<td>
<p>for print method, the object to be printed</p>
</td></tr>
<tr><td><code id="print.textmodel_wordfish_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>

<hr>
<h2 id='summary.textmodel_lr'>summary method for textmodel_lr objects</h2><span id='topic+summary.textmodel_lr'></span>

<h3>Description</h3>

<p>summary method for textmodel_lr objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_lr'
summary(object, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.textmodel_lr_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+textmodel_lr">textmodel_lr()</a></code></p>
</td></tr>
<tr><td><code id="summary.textmodel_lr_+3A_n">n</code></td>
<td>
<p>how many coefficients to print before truncating</p>
</td></tr>
<tr><td><code id="summary.textmodel_lr_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>summary.textmodel</code> classed list containing elements from the
call to <code>textmodel_lr()</code>, including the call, statistics for lambda, and
the estimated feature scores
</p>

<hr>
<h2 id='summary.textmodel_nb'>summary method for textmodel_nb objects</h2><span id='topic+summary.textmodel_nb'></span>

<h3>Description</h3>

<p>summary method for textmodel_nb objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_nb'
summary(object, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.textmodel_nb_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+textmodel_nb">textmodel_nb()</a></code></p>
</td></tr>
<tr><td><code id="summary.textmodel_nb_+3A_n">n</code></td>
<td>
<p>how many coefficients to print before truncating</p>
</td></tr>
<tr><td><code id="summary.textmodel_nb_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>summary.textmodel</code> classed list containing the call, the class
priors, and the estimated feature scores
</p>

<hr>
<h2 id='summary.textmodel_svm'>summary method for textmodel_svm objects</h2><span id='topic+summary.textmodel_svm'></span>

<h3>Description</h3>

<p>summary method for textmodel_svm objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_svm'
summary(object, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.textmodel_svm_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+textmodel_svm">textmodel_svm()</a></code></p>
</td></tr>
<tr><td><code id="summary.textmodel_svm_+3A_n">n</code></td>
<td>
<p>how many coefficients to print before truncating</p>
</td></tr>
<tr><td><code id="summary.textmodel_svm_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>summary.textmodel</code> classed list containing the call and the
estimated feature scores
</p>

<hr>
<h2 id='summary.textmodel_svmlin'>summary method for textmodel_svmlin objects</h2><span id='topic+summary.textmodel_svmlin'></span>

<h3>Description</h3>

<p>summary method for textmodel_svmlin objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_svmlin'
summary(object, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.textmodel_svmlin_+3A_object">object</code></td>
<td>
<p>output from <code><a href="#topic+textmodel_svmlin">textmodel_svmlin()</a></code></p>
</td></tr>
<tr><td><code id="summary.textmodel_svmlin_+3A_n">n</code></td>
<td>
<p>how many coefficients to print before truncating</p>
</td></tr>
<tr><td><code id="summary.textmodel_svmlin_+3A_...">...</code></td>
<td>
<p>additional arguments not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>summary.textmodel</code> classed list containing the call and the
estimated feature scores
</p>

<hr>
<h2 id='summary.textmodel_wordfish'>summary method for textmodel_wordfish</h2><span id='topic+summary.textmodel_wordfish'></span>

<h3>Description</h3>

<p>summary method for textmodel_wordfish
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_wordfish'
summary(object, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.textmodel_wordfish_+3A_object">object</code></td>
<td>
<p>a <a href="#topic+textmodel_wordfish">textmodel_wordfish</a> object</p>
</td></tr>
<tr><td><code id="summary.textmodel_wordfish_+3A_n">n</code></td>
<td>
<p>maximum number of features to print in summary</p>
</td></tr>
<tr><td><code id="summary.textmodel_wordfish_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>summary.textmodel</code> classed list containing the call, the
estimated document positions, and the estimated feature scores
</p>

<hr>
<h2 id='textmodel_affinity'>Class affinity maximum likelihood text scaling model</h2><span id='topic+textmodel_affinity'></span>

<h3>Description</h3>

<p><code>textmodel_affinity()</code> implements the maximum likelihood supervised text
scaling method described in Perry and Benoit (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_affinity(
  x,
  y,
  exclude = NULL,
  smooth = 0.5,
  ref_smooth = 0.5,
  verbose = quanteda_options("verbose")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_affinity_+3A_x">x</code></td>
<td>
<p>the dfm or bootstrap_dfm object on which the model
will be fit.  Does not need to contain only the training documents, since
the index of these will be matched automatically.</p>
</td></tr>
<tr><td><code id="textmodel_affinity_+3A_y">y</code></td>
<td>
<p>vector of training classes/scores associated with each document
identified in <code>data</code></p>
</td></tr>
<tr><td><code id="textmodel_affinity_+3A_exclude">exclude</code></td>
<td>
<p>a set of words to exclude from the model</p>
</td></tr>
<tr><td><code id="textmodel_affinity_+3A_smooth">smooth</code></td>
<td>
<p>a smoothing parameter for class affinities; defaults to 0.5
(Jeffreys prior). A plausible alternative would be 1.0 (Laplace prior).</p>
</td></tr>
<tr><td><code id="textmodel_affinity_+3A_ref_smooth">ref_smooth</code></td>
<td>
<p>a smoothing parameter for token distributions;
defaults to 0.5</p>
</td></tr>
<tr><td><code id="textmodel_affinity_+3A_verbose">verbose</code></td>
<td>
<p>logical; if <code>TRUE</code> print diagnostic information during
fitting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>textmodel_affinity</code> class list object, with elements:
</p>

<ul>
<li> <p><code>smooth</code> a numeric vector of length two for the smoothing parameters <code>smooth</code>
and <code>ref_smooth</code>
<code>x</code> the input model matrix <code>x</code>
<code>y</code> the vector of class training labels <code>y</code>
<code>p</code> a feature <code class="reqn">\times</code> class sparse matrix of estimated class affinities
</p>
</li>
<li> <p><code>support</code> logical vector indicating whether a feature was included in computing
class affinities
</p>
</li>
<li> <p><code>call</code> the model call
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Patrick Perry and Kenneth Benoit
</p>


<h3>References</h3>

<p>Perry, P.O. &amp; Benoit, K.R. (2017). Scaling Text with
the Class Affinity Model.
<a href="https://arxiv.org/abs/1710.08963">arXiv:1710.08963 [stat.ML]</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_affinity">predict.textmodel_affinity()</a></code> for methods of applying a
fitted <code><a href="#topic+textmodel_affinity">textmodel_affinity()</a></code> model object to predict quantities from
(other) documents.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(af &lt;- textmodel_affinity(quanteda::data_dfm_lbgexample, y = c("L", NA, NA, NA, "R", NA)))
predict(af)
predict(af, newdata = quanteda::data_dfm_lbgexample[6, ])

## Not run: 
# compute bootstrapped SEs
dfmat &lt;- quanteda::bootstrap_dfm(data_corpus_dailnoconf1991, n = 10, remove_punct = TRUE)
textmodel_affinity(dfmat, y = c("Govt", "Opp", "Opp", rep(NA, 55)))

## End(Not run)
</code></pre>

<hr>
<h2 id='textmodel_affinity-internal'>Internal methods for textmodel_affinity</h2><span id='topic+textmodel_affinity-internal'></span><span id='topic+print.influence.predict.textmodel_affinity'></span><span id='topic+summary.influence.predict.textmodel_affinity'></span><span id='topic+print.summary.influence.predict.textmodel_affinity'></span>

<h3>Description</h3>

<p>Internal print and summary methods for derivative
<a href="#topic+textmodel_affinity">textmodel_affinity</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'influence.predict.textmodel_affinity'
print(x, n = 30, ...)

## S3 method for class 'influence.predict.textmodel_affinity'
summary(object, ...)

## S3 method for class 'summary.influence.predict.textmodel_affinity'
print(x, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_affinity-internal_+3A_n">n</code></td>
<td>
<p>how many coefficients to print before truncating</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.influence.predict.textmodel_affinity()</code> returns a list
classes as <code>summary.influence.predict.textmodel_affinity</code> that includes:
</p>

<ul>
<li> <p><code>word</code> the feature name
</p>
</li>
<li> <p><code>count</code> the total counts of each feature for which influence was computed
</p>
</li>
<li> <p><code>mean</code>, <code>median</code>, <code>sd</code>, <code>max</code> mean, median, standard deviation, and maximum
values of influence for each feature, computed across classes
</p>
</li>
<li> <p><code>direction</code> an integer vector of 1 or 2 indicating the class which the feature
is influencing
</p>
</li>
<li> <p><code>rate</code> a document by feature class sparse matrix of normalised influence
measures
</p>
</li>
<li> <p><code>count</code> a vector of counts of each non-zero feature in the input matrix
</p>
</li>
<li> <p><code>rate</code> the median of <code>rate</code> from <code><a href="#topic+influence.predict.textmodel_affinity">influence.predict.textmodel_affinity()</a></code>
</p>
</li>
<li> <p><code>support</code> logical vector for each feature matching the same return from
<code><a href="#topic+predict.textmodel_affinity">predict.textmodel_affinity()</a></code>
</p>
</li></ul>

<p>the mean, the standard deviation, the direction of the influence, the rate,
and the support
</p>

<hr>
<h2 id='textmodel_ca'>Correspondence analysis of a document-feature matrix</h2><span id='topic+textmodel_ca'></span>

<h3>Description</h3>

<p><code>textmodel_ca</code> implements correspondence analysis scaling on a
dfm.  The method is a fast/sparse version of function <a href="ca.html#topic+ca">ca</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_ca(x, smooth = 0, nd = NA, sparse = FALSE, residual_floor = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_ca_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit</p>
</td></tr>
<tr><td><code id="textmodel_ca_+3A_smooth">smooth</code></td>
<td>
<p>a smoothing parameter for word counts; defaults to zero.</p>
</td></tr>
<tr><td><code id="textmodel_ca_+3A_nd">nd</code></td>
<td>
<p>Number of dimensions to be included in output; if <code>NA</code> (the
default) then the maximum possible dimensions are included.</p>
</td></tr>
<tr><td><code id="textmodel_ca_+3A_sparse">sparse</code></td>
<td>
<p>retains the sparsity if set to <code>TRUE</code>; set it to
<code>TRUE</code> if <code>x</code> (the dfm) is too big to be allocated after
converting to dense</p>
</td></tr>
<tr><td><code id="textmodel_ca_+3A_residual_floor">residual_floor</code></td>
<td>
<p>specifies the threshold for the residual matrix for
calculating the truncated svd.Larger value will reduce memory and time cost
but might reduce accuracy; only applicable when <code>sparse = TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="RSpectra.html#topic+svds">svds</a> in the <span class="pkg">RSpectra</span> package is applied to
enable the fast computation of the SVD.
</p>


<h3>Value</h3>

<p><code>textmodel_ca()</code> returns a fitted CA textmodel that is a special
class of <span class="pkg">ca</span> object.
</p>


<h3>Note</h3>

<p>You may need to set <code>sparse = TRUE</code>) and
increase the value of <code>residual_floor</code> to ignore less important
information and hence to reduce the memory cost when you have a very big
dfm.
If your attempt to fit the model fails due to the matrix being too large,
this is probably because of the memory demands of computing the <code class="reqn">V
  \times V</code> residual matrix.  To avoid this, consider increasing the value of
<code>residual_floor</code> by 0.1, until the model can be fit.
</p>


<h3>Author(s)</h3>

<p>Kenneth Benoit and Haiyan Wang
</p>


<h3>References</h3>

<p>Nenadic, O. &amp; Greenacre, M. (2007). Correspondence Analysis in R, with Two- and Three-dimensional Graphics:
The ca package. <em>Journal of Statistical Software</em>, 20(3).  <a href="https://doi.org/10.18637/jss.v020.i03">doi:10.18637/jss.v020.i03</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.textmodel_lsa">coef.textmodel_lsa()</a></code>, <a href="ca.html#topic+ca">ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("quanteda")
dfmat &lt;- dfm(tokens(data_corpus_irishbudget2010))
tmod &lt;- textmodel_ca(dfmat)
summary(tmod)
</code></pre>

<hr>
<h2 id='textmodel_lr'>Logistic regression classifier for texts</h2><span id='topic+textmodel_lr'></span>

<h3>Description</h3>

<p>Fits a fast penalized maximum likelihood estimator to predict discrete
categories from sparse <a href="quanteda.html#topic+dfm">dfm</a> objects. Using the <span class="pkg">glmnet</span>
package, the function computes the regularization path for the lasso or
elasticnet penalty at a grid of values for the regularization parameter
lambda.  This is done automatically by testing on several folds of the data
at estimation time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_lr(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_lr_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit.  Does not need to
contain only the training documents.</p>
</td></tr>
<tr><td><code id="textmodel_lr_+3A_y">y</code></td>
<td>
<p>vector of training labels associated with each document identified
in <code>train</code>.  (These will be converted to factors if not already
factors.)</p>
</td></tr>
<tr><td><code id="textmodel_lr_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textmodel_lr</code>, a list containing:
</p>

<ul>
<li> <p><code>x</code>, <code>y</code> the input model matrix and input training class labels
</p>
</li>
<li> <p><code>algorithm</code> character; the type and family of logistic regression model used in calling
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code>
</p>
</li>
<li> <p><code>type</code> the type of associated with <code>algorithm</code>
</p>
</li>
<li> <p><code>classnames</code> the levels of training classes in <code>y</code>
</p>
</li>
<li> <p><code>lrfitted</code> the fitted model object from <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code>
</p>
</li>
<li> <p><code>call</code> the model call
</p>
</li></ul>



<h3>References</h3>

<p>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010). Regularization Paths for
Generalized Linear Models via Coordinate Descent. <em>Journal of Statistical
Software</em> 33(1), 1-22.  <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code>, <code><a href="#topic+predict.textmodel_lr">predict.textmodel_lr()</a></code>,
<code><a href="#topic+coef.textmodel_lr">coef.textmodel_lr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from 13.1 of _An Introduction to Information Retrieval_
library("quanteda")
corp &lt;- corpus(c(d1 = "Chinese Beijing Chinese",
                 d2 = "Chinese Chinese Shanghai",
                 d3 = "Chinese Macao",
                 d4 = "Tokyo Japan Chinese",
                 d5 = "London England Chinese",
                 d6 = "Chinese Chinese Chinese Tokyo Japan"),
               docvars = data.frame(train = factor(c("Y", "Y", "Y", "N", "N", NA))))
dfmat &lt;- dfm(tokens(corp), tolower = FALSE)

## simulate bigger sample as classification on small samples is problematic
set.seed(1)
dfmat &lt;- dfm_sample(dfmat, 50, replace = TRUE)

## train model
(tmod1 &lt;- textmodel_lr(dfmat, docvars(dfmat, "train")))
summary(tmod1)
coef(tmod1)

## predict probability and classes
predict(tmod1, type = "prob")
predict(tmod1)
</code></pre>

<hr>
<h2 id='textmodel_lsa'>Latent Semantic Analysis</h2><span id='topic+textmodel_lsa'></span>

<h3>Description</h3>

<p>Fit the Latent Semantic Analysis scaling model to a dfm, which may be
weighted (for instance using <code><a href="quanteda.html#topic+dfm_tfidf">quanteda::dfm_tfidf()</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_lsa(x, nd = 10, margin = c("both", "documents", "features"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_lsa_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit</p>
</td></tr>
<tr><td><code id="textmodel_lsa_+3A_nd">nd</code></td>
<td>
<p>the number of dimensions to be included in output</p>
</td></tr>
<tr><td><code id="textmodel_lsa_+3A_margin">margin</code></td>
<td>
<p>margin to be smoothed by the SVD</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="RSpectra.html#topic+svds">svds</a> in the <span class="pkg">RSpectra</span> package is applied to
enable the fast computation of the SVD.
</p>


<h3>Value</h3>

<p>a <code>textmodel_lsa</code> class object, a list containing:
</p>

<ul>
<li> <p><code>sk</code> a numeric vector containing the d values from the SVD
</p>
</li>
<li> <p><code>docs</code> document coordinates from the SVD (u)
</p>
</li>
<li> <p><code>features</code> feature coordinates from the SVD (v)
</p>
</li>
<li> <p><code>matrix_low_rank</code> the multiplication of udv'
</p>
</li>
<li> <p><code>data</code> the input data as a CSparseMatrix from the <span class="pkg">Matrix</span> package
</p>
</li></ul>



<h3>Note</h3>

<p>The number of dimensions <code>nd</code> retained in LSA is an empirical
issue. While a reduction in <code class="reqn">k</code> can remove much of the noise, keeping
too few dimensions or factors may lose important information.
</p>


<h3>Author(s)</h3>

<p>Haiyan Wang and Kohei Watanabe
</p>


<h3>References</h3>

<p>Rosario, B. (2000).
<a href="http://www.cse.msu.edu/~cse960/Papers/LSI/LSI.pdf">Latent Semantic Indexing: An Overview</a>. <em>Technical report INFOSYS 240 Spring
Paper, University of California, Berkeley.</em>
</p>
<p>Deerwester, S., Dumais, S.T., Furnas, G.W., Landauer, T.K., &amp;
Harshman, R. (1990). <a href="https://www.proquest.com/docview/1301252034">Indexing by Latent Semantic Analysis</a>. <em>Journal of the American Society for
Information Science</em>, 41(6): 391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_lsa">predict.textmodel_lsa()</a></code>, <code><a href="#topic+coef.textmodel_lsa">coef.textmodel_lsa()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("quanteda")
dfmat &lt;- dfm(tokens(data_corpus_irishbudget2010))
# create an LSA space and return its truncated representation in the low-rank space
tmod &lt;- textmodel_lsa(dfmat[1:10, ])
head(tmod$docs)

# matrix in low_rank LSA space
tmod$matrix_low_rank[,1:5]

# fold queries into the space generated by dfmat[1:10,]
# and return its truncated versions of its representation in the new low-rank space
pred &lt;- predict(tmod, newdata = dfmat[11:14, ])
pred$docs_newspace

</code></pre>

<hr>
<h2 id='textmodel_lsa-postestimation'>Post-estimations methods for textmodel_lsa</h2><span id='topic+textmodel_lsa-postestimation'></span><span id='topic+predict.textmodel_lsa'></span><span id='topic+as.dfm.textmodel_lsa'></span><span id='topic+coef.textmodel_lsa'></span><span id='topic+coefficients.textmodel_lsa'></span>

<h3>Description</h3>

<p>Post-estimation methods for fitted <a href="#topic+textmodel_lsa">textmodel_lsa</a> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmodel_lsa'
predict(object, newdata = NULL, ...)

## S3 method for class 'textmodel_lsa'
as.dfm(x)

## S3 method for class 'textmodel_lsa'
coef(object, doc_dim = 1, feat_dim = 1, ...)

coefficients.textmodel_lsa(object, doc_dim = 1, feat_dim = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_lsa-postestimation_+3A_object">object</code>, <code id="textmodel_lsa-postestimation_+3A_x">x</code></td>
<td>
<p>previously fitted <a href="#topic+textmodel_lsa">textmodel_lsa</a> object</p>
</td></tr>
<tr><td><code id="textmodel_lsa-postestimation_+3A_newdata">newdata</code></td>
<td>
<p>new matrix to be transformed into the lsa space</p>
</td></tr>
<tr><td><code id="textmodel_lsa-postestimation_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
<tr><td><code id="textmodel_lsa-postestimation_+3A_doc_dim">doc_dim</code>, <code id="textmodel_lsa-postestimation_+3A_feat_dim">feat_dim</code></td>
<td>
<p>the document and feature dimension scores to be
extracted</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict()</code> returns a predicted <a href="#topic+textmodel_lsa">textmodel_lsa</a> object, projecting the patterns onto
new data.
</p>
<p><code>coef.textmodel_lsa</code> extracts model coefficients from a fitted
<a href="#topic+textmodel_ca">textmodel_ca</a> object.
</p>

<hr>
<h2 id='textmodel_nb'>Naive Bayes classifier for texts</h2><span id='topic+textmodel_nb'></span>

<h3>Description</h3>

<p>Fit a multinomial or Bernoulli Naive Bayes model, given a dfm and some
training labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_nb(
  x,
  y,
  smooth = 1,
  prior = c("uniform", "docfreq", "termfreq"),
  distribution = c("multinomial", "Bernoulli")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_nb_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit.  Does not need to
contain only the training documents.</p>
</td></tr>
<tr><td><code id="textmodel_nb_+3A_y">y</code></td>
<td>
<p>vector of training labels associated with each document identified
in <code>train</code>.  (These will be converted to factors if not already
factors.)</p>
</td></tr>
<tr><td><code id="textmodel_nb_+3A_smooth">smooth</code></td>
<td>
<p>smoothing parameter for feature counts, added to the
feature frequency totals by training class</p>
</td></tr>
<tr><td><code id="textmodel_nb_+3A_prior">prior</code></td>
<td>
<p>prior distribution on texts; one of <code>"uniform"</code>,
<code>"docfreq"</code>, or <code>"termfreq"</code>.  See Prior Distributions below.</p>
</td></tr>
<tr><td><code id="textmodel_nb_+3A_distribution">distribution</code></td>
<td>
<p>count model for text features, can be <code>multinomial</code> or
<code>Bernoulli</code>.  To fit a &quot;binary multinomial&quot; model, first convert the dfm to
a binary matrix using <code style="white-space: pre;">&#8288;[quanteda::dfm_weight](x, scheme = "boolean")&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>textmodel_nb()</code> returns a list consisting of the following (where
<code class="reqn">I</code> is the total number of documents, <code class="reqn">J</code> is the total number of
features, and <code class="reqn">k</code> is the total number of training classes):
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>original function call</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p><code class="reqn">k \times V</code>; class conditional posterior estimates</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>the <code class="reqn">N \times V</code> training dfm <code>x</code></p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the <code class="reqn">N</code>-length <code>y</code> training class vector, where NAs will
not be used will be retained in the saved <code>x</code> matrix</p>
</td></tr>
<tr><td><code>distribution</code></td>
<td>
<p>character; the distribution of <code>x</code> for the NB
model</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p>numeric; the class prior probabilities</p>
</td></tr>
<tr><td><code>smooth</code></td>
<td>
<p>numeric; the value of the smoothing parameter</p>
</td></tr>
</table>


<h3>Prior distributions</h3>

<p>Prior distributions refer to the prior probabilities assigned to the
training classes, and the choice of prior distribution affects the
calculation of the fitted probabilities.  The default is uniform priors,
which sets the unconditional probability of observing the one class to be
the same as observing any other class.
</p>
<p>&quot;Document frequency&quot; means that the class priors will be taken from the
relative proportions of the class documents used in the training set.  This
approach is so common that it is assumed in many examples, such as the
worked example from Manning, Raghavan, and Schütze (2008) below.  It is not
the default in <span class="pkg">quanteda</span>, however, since there may be nothing
informative in the relative numbers of documents used to train a classifier
other than the relative availability of the documents.  When training
classes are balanced in their number of documents (usually advisable),
however, then the empirically computed &quot;docfreq&quot; would be equivalent to
&quot;uniform&quot; priors.
</p>
<p>Setting <code>prior</code> to &quot;termfreq&quot; makes the priors equal to the proportions of
total feature counts found in the grouped documents in each training class,
so that the classes with the largest number of features are assigned the
largest priors. If the total count of features in each training class was
the same, then &quot;uniform&quot; and &quot;termfreq&quot; would be the same.
</p>


<h3>Smoothing parameter</h3>

<p>The <code>smooth</code> value is added to the feature frequencies, aggregated by
training class, to avoid zero frequencies in any class.  This has the
effect of giving more weight to infrequent term occurrences.
</p>


<h3>Author(s)</h3>

<p>Kenneth Benoit
</p>


<h3>References</h3>

<p>Manning, C.D., Raghavan, P., &amp; Schütze, H. (2008). <em>An
Introduction to Information Retrieval</em>. Cambridge: Cambridge University
Press (Chapter 13). Available at
<a href="https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf">https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf</a>.
</p>
<p>Jurafsky, D. &amp; Martin, J.H. (2018). From <em>Speech and Language Processing:
An Introduction to Natural Language Processing, Computational Linguistics,
and Speech Recognition</em>. Draft of September 23, 2018 (Chapter 6, Naive
Bayes). Available at <a href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_nb">predict.textmodel_nb()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from 13.1 of _An Introduction to Information Retrieval_
library("quanteda")
txt &lt;- c(d1 = "Chinese Beijing Chinese",
         d2 = "Chinese Chinese Shanghai",
         d3 = "Chinese Macao",
         d4 = "Tokyo Japan Chinese",
         d5 = "Chinese Chinese Chinese Tokyo Japan")
x &lt;- dfm(tokens(txt), tolower = FALSE)
y &lt;- factor(c("Y", "Y", "Y", "N", NA), ordered = TRUE)

## replicate IIR p261 prediction for test set (document 5)
(tmod1 &lt;- textmodel_nb(x, y, prior = "docfreq"))
summary(tmod1)
coef(tmod1)
predict(tmod1, type = "prob")
predict(tmod1)

# contrast with other priors
predict(textmodel_nb(x, y, prior = "uniform"))
predict(textmodel_nb(x, y, prior = "termfreq"))

## replicate IIR p264 Bernoulli Naive Bayes
tmod2 &lt;- textmodel_nb(x, y, distribution = "Bernoulli", prior = "docfreq")
predict(tmod2, newdata = x[5, ], type = "prob")
predict(tmod2, newdata = x[5, ])
</code></pre>

<hr>
<h2 id='textmodel_svm'>Linear SVM classifier for texts</h2><span id='topic+textmodel_svm'></span>

<h3>Description</h3>

<p>Fit a fast linear SVM classifier for texts, using the
<span class="pkg">LiblineaR</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_svm(
  x,
  y,
  weight = c("uniform", "docfreq", "termfreq"),
  type = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_svm_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit.  Does not need to
contain only the training documents.</p>
</td></tr>
<tr><td><code id="textmodel_svm_+3A_y">y</code></td>
<td>
<p>vector of training labels associated with each document identified
in <code>train</code>.  (These will be converted to factors if not already
factors.)</p>
</td></tr>
<tr><td><code id="textmodel_svm_+3A_weight">weight</code></td>
<td>
<p>weights for different classes for imbalanced training sets,
passed to <code>wi</code> in <code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code>. <code>"uniform"</code>
uses default; <code>"docfreq"</code> weights by the number of training examples,
and <code>"termfreq"</code> by the relative sizes of the training classes in
terms of their total lengths in tokens.</p>
</td></tr>
<tr><td><code id="textmodel_svm_+3A_type">type</code></td>
<td>
<p>argument passed to the <code>type</code> argument in
<code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code>; default is <code>1</code> for L2-regularized L2-loss support
vector classification (dual)</p>
</td></tr>
<tr><td><code id="textmodel_svm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textmodel_svm</code>, a list containing:
</p>

<ul>
<li> <p><code>x</code>, <code>y</code>, <code>weights</code>, <code>type</code>: argument values from the call parameters
</p>
</li>
<li> <p><code>algorithm</code> character label of the algorithm used in the call to
<code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code>
</p>
</li>
<li> <p><code>classnames</code> levels of <code>y</code>
</p>
</li>
<li> <p><code>bias</code> the value of <code>Bias</code> returned from <code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code>
</p>
</li>
<li> <p><code>svmlinfitted</code> the fitted model object passed from the call to
LiblineaR::LiblineaR()]
</p>
</li>
<li> <p><code>call</code> the model call
</p>
</li></ul>



<h3>References</h3>

<p>R. E. Fan, K. W. Chang, C. J. Hsieh, X. R. Wang, and C. J. Lin. (2008)
LIBLINEAR: A Library for Large Linear Classification.
<em>Journal of Machine Learning Research</em> 9: 1871-1874.
<a href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">https://www.csie.ntu.edu.tw/~cjlin/liblinear/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="LiblineaR.html#topic+LiblineaR">LiblineaR::LiblineaR()</a></code> <code><a href="#topic+predict.textmodel_svm">predict.textmodel_svm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use party leaders for govt and opposition classes
library("quanteda")
docvars(data_corpus_irishbudget2010, "govtopp") &lt;-
    c(rep(NA, 4), "Gov", "Opp", NA, "Opp", NA, NA, NA, NA, NA, NA)
dfmat &lt;- dfm(tokens(data_corpus_irishbudget2010))
tmod &lt;- textmodel_svm(dfmat, y = dfmat$govtopp)
predict(tmod)

# multiclass problem - all party leaders
tmod2 &lt;- textmodel_svm(dfmat,
    y = c(rep(NA, 3), "SF", "FF", "FG", NA, "LAB", NA, NA, "Green", rep(NA, 3)))
predict(tmod2)
</code></pre>

<hr>
<h2 id='textmodel_svmlin'>[experimental] Linear SVM classifier for texts</h2><span id='topic+textmodel_svmlin'></span>

<h3>Description</h3>

<p>Fit a fast linear SVM classifier for sparse text matrices, using svmlin C++
code written by Vikas Sindhwani and S. Sathiya Keerthi.  This method
implements the modified finite Newton L2-SVM method (L2-SVM-MFN) method
described in Sindhwani and Keerthi (2006). Currently,
<code>textmodel_svmlin()</code> only works for two-class problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_svmlin(
  x,
  y,
  intercept = TRUE,
  lambda = 1,
  cp = 1,
  cn = 1,
  scale = FALSE,
  center = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_svmlin_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit.  Does not need to contain
only the training documents.</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_y">y</code></td>
<td>
<p>vector of training labels associated with each document identified
in <code>train</code>.  (These will be converted to factors if not already factors.)</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_intercept">intercept</code></td>
<td>
<p>logical; if <code>TRUE</code>, add an intercept to the data</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_lambda">lambda</code></td>
<td>
<p>numeric; regularization parameter lambda (default 1)</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_cp">cp</code></td>
<td>
<p>numeric; Relative cost for &quot;positive&quot; examples (the second factor
level)</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_cn">cn</code></td>
<td>
<p>numeric; Relative cost for &quot;negative&quot; examples (the first factor
level)</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_scale">scale</code></td>
<td>
<p>logical; if <code>TRUE</code>, normalize the feature counts</p>
</td></tr>
<tr><td><code id="textmodel_svmlin_+3A_center">center</code></td>
<td>
<p>logical; if <code>TRUE</code>, centre the feature counts</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a fitted model object of class <code>textmodel_svmlin</code>
</p>


<h3>Warning</h3>

<p>This function is marked experimental since it's not fully working yet in a
way that translates into more standard SVM parameters that we understand. Use
with caution after reading the Sindhwani and Keerthi (2006) paper.
</p>


<h3>References</h3>

<p>Vikas Sindhwani and S. Sathiya Keerthi (2006).  <a href="https://vikas.sindhwani.org/sk_sigir06.pdf">Large Scale Semi-supervised Linear SVMs</a>. <em>Proceedings of ACM
SIGIR</em>. August 6–11, 2006, Seattle.
</p>
<p>V. Sindhwani and S. Sathiya Keerthi (2006).  Newton Methods for Fast Solution
of Semi-supervised Linear SVMs. Book Chapter in <em>Large Scale Kernel
Machines</em>, MIT Press, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_svmlin">predict.textmodel_svmlin()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use Lenihan for govt class and Bruton for opposition
library("quanteda")
docvars(data_corpus_irishbudget2010, "govtopp") &lt;- c("Govt", "Opp", rep(NA, 12))
dfmat &lt;- dfm(tokens(data_corpus_irishbudget2010))

tmod &lt;- textmodel_svmlin(dfmat, y = dfmat$govtopp)
predict(tmod)
</code></pre>

<hr>
<h2 id='textmodel_wordfish'>Wordfish text model</h2><span id='topic+textmodel_wordfish'></span>

<h3>Description</h3>

<p>Estimate Slapin and Proksch's (2008) &quot;wordfish&quot; Poisson scaling model of
one-dimensional document positions using conditional maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_wordfish(
  x,
  dir = c(1, 2),
  priors = c(Inf, Inf, 3, 1),
  tol = c(1e-06, 1e-08),
  dispersion = c("poisson", "quasipoisson"),
  dispersion_level = c("feature", "overall"),
  dispersion_floor = 0,
  sparse = FALSE,
  abs_err = FALSE,
  svd_sparse = TRUE,
  residual_floor = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_wordfish_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be fit</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_dir">dir</code></td>
<td>
<p>set global identification by specifying the indexes for a pair of
documents such that <code class="reqn">\hat{\theta}_{dir[1]} &lt; \hat{\theta}_{dir[2]}</code>.</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_priors">priors</code></td>
<td>
<p>prior precisions for the estimated parameters <code class="reqn">\alpha_i</code>,
<code class="reqn">\psi_j</code>, <code class="reqn">\beta_j</code>, and <code class="reqn">\theta_i</code>, where <code class="reqn">i</code> indexes
documents and <code class="reqn">j</code> indexes features</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_tol">tol</code></td>
<td>
<p>tolerances for convergence.  The first value is a convergence
threshold for the log-posterior of the model, the second value is the
tolerance in the difference in parameter values from the iterative
conditional maximum likelihood (from conditionally estimating
document-level, then feature-level parameters).</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_dispersion">dispersion</code></td>
<td>
<p>sets whether a quasi-Poisson quasi-likelihood should be
used based on a single dispersion parameter (<code>"poisson"</code>), or
quasi-Poisson (<code>"quasipoisson"</code>)</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_dispersion_level">dispersion_level</code></td>
<td>
<p>sets the unit level for the dispersion parameter,
options are <code>"feature"</code> for term-level variances, or <code>"overall"</code>
for a single dispersion parameter</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_dispersion_floor">dispersion_floor</code></td>
<td>
<p>constraint for the minimal underdispersion multiplier
in the quasi-Poisson model.  Used to minimize the distorting effect of
terms with rare term or document frequencies that appear to be severely
underdispersed.  Default is 0, but this only applies if <code>dispersion = "quasipoisson"</code>.</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_sparse">sparse</code></td>
<td>
<p>specifies whether the <code>"dfm"</code> is coerced to dense.  While
setting this to <code>TRUE</code> will make it possible to handle larger dfm
objects (and make execution faster), it will generate slightly different
results each time, because the sparse SVD routine has a stochastic element.</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_abs_err">abs_err</code></td>
<td>
<p>specifies how the convergence is considered</p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_svd_sparse">svd_sparse</code></td>
<td>
<p>uses svd to initialize the starting values of theta,
only applies when <code>sparse = TRUE</code></p>
</td></tr>
<tr><td><code id="textmodel_wordfish_+3A_residual_floor">residual_floor</code></td>
<td>
<p>specifies the threshold for residual matrix when
calculating the svds, only applies when <code>sparse = TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returns match those of Will Lowe's R implementation of
<code>wordfish</code> (see the austin package), except that here we have renamed
<code>words</code> to be <code>features</code>.  (This return list may change.)  We
have also followed the practice begun with Slapin and Proksch's early
implementation of the model that used a regularization parameter of
se<code class="reqn">(\sigma) = 3</code>, through the third element in <code>priors</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>textmodel_fitted_wordfish</code>.  This is a list
containing: </p>
<table>
<tr><td><code>dir</code></td>
<td>
<p>global identification of the dimension</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>estimated document positions</p>
</td></tr> <tr><td><code>alpha</code></td>
<td>
<p>estimated document
fixed effects</p>
</td></tr> <tr><td><code>beta</code></td>
<td>
<p>estimated feature marginal effects</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>estimated word fixed effects</p>
</td></tr> <tr><td><code>docs</code></td>
<td>
<p>document labels</p>
</td></tr>
<tr><td><code>features</code></td>
<td>
<p>feature labels</p>
</td></tr> <tr><td><code>sigma</code></td>
<td>
<p>regularization parameter for
betas in Poisson form</p>
</td></tr> <tr><td><code>ll</code></td>
<td>
<p>log likelihood at convergence</p>
</td></tr>
<tr><td><code>se.theta</code></td>
<td>
<p>standard errors for theta-hats</p>
</td></tr> <tr><td><code>x</code></td>
<td>
<p>dfm to which
the model was fit</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In the rare situation where a warning message of &quot;The algorithm did not
converge.&quot; shows up, removing some documents may work.
</p>


<h3>Author(s)</h3>

<p>Benjamin Lauderdale, Haiyan Wang, and Kenneth Benoit
</p>


<h3>References</h3>

<p>Slapin, J. &amp; Proksch, S.O. (2008). A Scaling Model for Estimating
Time-Series Party Positions from Texts.
<a href="https://doi.org/10.1111/j.1540-5907.2008.00338.x">doi:10.1111/j.1540-5907.2008.00338.x</a>. <em>American Journal of Political
Science</em>, 52(3), 705&ndash;772.
</p>
<p>Lowe, W. &amp; Benoit, K.R. (2013). Validating Estimates of Latent Traits from
Textual Data Using Human Judgment as a Benchmark.
<a href="https://doi.org/10.1093/pan/mpt002">doi:10.1093/pan/mpt002</a>. <em>Political Analysis</em>, 21(3), 298&ndash;313.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_wordfish">predict.textmodel_wordfish()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmod1 &lt;- textmodel_wordfish(quanteda::data_dfm_lbgexample, dir = c(1,5)))
summary(tmod1, n = 10)
coef(tmod1)
predict(tmod1)
predict(tmod1, se.fit = TRUE)
predict(tmod1, interval = "confidence")

## Not run: 
library("quanteda")
dfmat &lt;- dfm(tokens(data_corpus_irishbudget2010))
(tmod2 &lt;- textmodel_wordfish(dfmat, dir = c(6,5)))
(tmod3 &lt;- textmodel_wordfish(dfmat, dir = c(6,5),
                             dispersion = "quasipoisson", dispersion_floor = 0))
(tmod4 &lt;- textmodel_wordfish(dfmat, dir = c(6,5),
                             dispersion = "quasipoisson", dispersion_floor = .5))
plot(tmod3$phi, tmod4$phi, xlab = "Min underdispersion = 0", ylab = "Min underdispersion = .5",
     xlim = c(0, 1.0), ylim = c(0, 1.0))
plot(tmod3$phi, tmod4$phi, xlab = "Min underdispersion = 0", ylab = "Min underdispersion = .5",
     xlim = c(0, 1.0), ylim = c(0, 1.0), type = "n")
underdispersedTerms &lt;- sample(which(tmod3$phi &lt; 1.0), 5)
which(featnames(dfmat) %in% names(topfeatures(dfmat, 20)))
text(tmod3$phi, tmod4$phi, tmod3$features,
     cex = .8, xlim = c(0, 1.0), ylim = c(0, 1.0), col = "grey90")
text(tmod3$phi['underdispersedTerms'], tmod4$phi['underdispersedTerms'],
     tmod3$features['underdispersedTerms'],
     cex = .8, xlim = c(0, 1.0), ylim = c(0, 1.0), col = "black")
if (requireNamespace("austin")) {
    tmod5 &lt;- austin::wordfish(quanteda::as.wfm(dfmat), dir = c(6, 5))
    cor(tmod1$theta, tmod5$theta)
}
## End(Not run)
</code></pre>

<hr>
<h2 id='textmodel_wordscores'>Wordscores text model</h2><span id='topic+textmodel_wordscores'></span>

<h3>Description</h3>

<p><code>textmodel_wordscores</code> implements Laver, Benoit and Garry's (2003)
&quot;Wordscores&quot; method for scaling texts on a single dimension, given a set of
anchoring or <em>reference</em> texts whose values are set through reference
scores. This scale can be fitted in the linear space (as per LBG 2003) or in
the logit space (as per Beauchamp 2012).  Estimates of <em>virgin</em> or
unknown texts are obtained using the <code>predict()</code> method to score
documents from a fitted <code>textmodel_wordscores</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textmodel_wordscores(x, y, scale = c("linear", "logit"), smooth = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textmodel_wordscores_+3A_x">x</code></td>
<td>
<p>the dfm on which the model will be trained</p>
</td></tr>
<tr><td><code id="textmodel_wordscores_+3A_y">y</code></td>
<td>
<p>vector of training scores associated with each document
in <code>x</code></p>
</td></tr>
<tr><td><code id="textmodel_wordscores_+3A_scale">scale</code></td>
<td>
<p>scale on which to score the words; <code>"linear"</code> for classic
LBG linear posterior weighted word class differences, or <code>"logit"</code>
for log posterior differences</p>
</td></tr>
<tr><td><code id="textmodel_wordscores_+3A_smooth">smooth</code></td>
<td>
<p>a smoothing parameter for word counts; defaults to zero to
match the LBG (2003) method. See Value below for additional information on
the behaviour of this argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>textmodel_wordscores()</code> function and the associated
<code><a href="#topic+predict.textmodel_wordscores">predict()</a></code> method are designed
to function in the same manner as <code><a href="stats.html#topic+predict.lm">stats::predict.lm()</a></code>.
<code>coef()</code> can also be used to extract the word coefficients from the
fitted <code>textmodel_wordscores</code> object, and <code>summary()</code> will print
a nice summary of the fitted object.
</p>


<h3>Value</h3>

<p>A fitted <code>textmodel_wordscores</code> object.  This object will
contain a copy of the input data, but in its original form without any
smoothing applied. Calling <code><a href="#topic+predict.textmodel_wordscores">predict.textmodel_wordscores()</a></code> on
this object without specifying a value for <code>newdata</code>, for instance,
will predict on the unsmoothed object.  This behaviour differs from
versions of <span class="pkg">quanteda</span> &lt;= 1.2.
</p>


<h3>Author(s)</h3>

<p>Kenneth Benoit
</p>


<h3>References</h3>

<p>Laver, M., Benoit, K.R., &amp; Garry, J. (2003). <a href="https://kenbenoit.net/pdfs/WORDSCORESAPSR.pdf">Estimating Policy Positions from Political Text using Words as Data</a>. <em>American Political
Science Review</em>, 97(2), 311&ndash;331.
</p>
<p>Beauchamp, N. (2012). <a href="http://nickbeauchamp.com/work/Beauchamp_scaling_current.pdf">Using Text to Scale Legislatures with Uninformative Voting</a>. New
York University Mimeo.
</p>
<p>Martin, L.W. &amp; Vanberg, G. (2007). A Robust Transformation Procedure for
Interpreting Political Text.  <em>Political Analysis</em> 16(1), 93&ndash;100.
<a href="https://doi.org/10.1093/pan/mpm010">doi:10.1093/pan/mpm010</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmodel_wordscores">predict.textmodel_wordscores()</a></code> for methods of applying a
fitted <a href="#topic+textmodel_wordscores">textmodel_wordscores</a> model object to predict quantities from
(other) documents.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmod &lt;- textmodel_wordscores(quanteda::data_dfm_lbgexample, y = c(seq(-1.5, 1.5, .75), NA)))
summary(tmod)
coef(tmod)
predict(tmod)
predict(tmod, rescaling = "lbg")
predict(tmod, se.fit = TRUE, interval = "confidence", rescaling = "mv")
</code></pre>

<hr>
<h2 id='textmodels'>quanteda.textmodels: Scaling Models and Classifiers for Textual Data</h2><span id='topic+textmodels'></span><span id='topic+_PACKAGE'></span><span id='topic+quanteda.textmodels'></span><span id='topic+quanteda.textmodels-package'></span>

<h3>Description</h3>

<p>Scaling models and classifiers for sparse matrix objects representing textual data in the form of a document-feature matrix. Includes original implementations of 'Laver', 'Benoit', and Garry's (2003) <a href="https://doi.org/10.1017/S0003055403000698">doi:10.1017/S0003055403000698</a>, 'Wordscores' model, the Perry and 'Benoit' (2017) <a href="https://arxiv.org/abs/1710.08963">arXiv:1710.08963</a> class affinity scaling model, and the 'Slapin' and 'Proksch' (2008) <a href="https://doi.org/10.1111/j.1540-5907.2008.00338.x">doi:10.1111/j.1540-5907.2008.00338.x</a> 'wordfish' model, as well as methods for correspondence analysis, latent semantic analysis, and fast Naive Bayes and linear 'SVMs' specially designed for sparse textual data.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Kenneth Benoit <a href="mailto:kbenoit@lse.ac.uk">kbenoit@lse.ac.uk</a> (<a href="https://orcid.org/0000-0002-0797-564X">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Kohei Watanabe <a href="mailto:watanabe.kohei@gmail.com">watanabe.kohei@gmail.com</a> (<a href="https://orcid.org/0000-0001-6519-5265">ORCID</a>)
</p>
</li>
<li><p> Haiyan Wang <a href="mailto:whyinsa@yahoo.com">whyinsa@yahoo.com</a> (<a href="https://orcid.org/0000-0003-4992-4311">ORCID</a>)
</p>
</li>
<li><p> Patrick O. Perry <a href="mailto:patperry@gmail.com">patperry@gmail.com</a> (<a href="https://orcid.org/0000-0001-7460-127X">ORCID</a>)
</p>
</li>
<li><p> Benjamin Lauderdale <a href="mailto:b.e.lauderdale@lse.ac.uk">b.e.lauderdale@lse.ac.uk</a> (<a href="https://orcid.org/0000-0003-3090-0969">ORCID</a>)
</p>
</li>
<li><p> Johannes Gruber <a href="mailto:JohannesB.Gruber@gmail.com">JohannesB.Gruber@gmail.com</a> (<a href="https://orcid.org/0000-0001-9177-1772">ORCID</a>)
</p>
</li>
<li><p> William Lowe <a href="mailto:lowe@hertie-school.org">lowe@hertie-school.org</a> (<a href="https://orcid.org/0000-0002-1549-6163">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Vikas Sindhwani <a href="mailto:vikas.sindhwani@gmail.com">vikas.sindhwani@gmail.com</a> (authored svmlin C++ source code) [copyright holder]
</p>
</li>
<li><p> European Research Council (ERC-2011-StG 283794-QUANTESS) [funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/quanteda/quanteda.textmodels">https://github.com/quanteda/quanteda.textmodels</a>
</p>
</li></ul>


<hr>
<h2 id='textplot_influence'>Influence plot for text scaling models</h2><span id='topic+textplot_influence'></span>

<h3>Description</h3>

<p>Plot the results of a fitted scaling model, from (e.g.) a predicted
<a href="#topic+textmodel_affinity">textmodel_affinity</a> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textplot_influence(x, n = 30, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="textplot_influence_+3A_x">x</code></td>
<td>
<p>the object output from <code>influence()</code> run on the
fitted or predicted scaling model object to be plotted</p>
</td></tr>
<tr><td><code id="textplot_influence_+3A_n">n</code></td>
<td>
<p>the number of features whose influence will be plotted</p>
</td></tr>
<tr><td><code id="textplot_influence_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="graphics.html#topic+plot">plot()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a base R plot of feature influences of the median influence
by the log10 median rate of the feature, and invisibly returns the elements
from the call to <code><a href="graphics.html#topic+plot">plot()</a></code>.
</p>


<h3>Author(s)</h3>

<p>Patrick Perry and Kenneth Benoit
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textmodel_affinity">textmodel_affinity()</a></code>
</p>
<p><code><a href="#topic+influence.predict.textmodel_affinity">influence.predict.textmodel_affinity()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmod &lt;- textmodel_affinity(quanteda::data_dfm_lbgexample, y = c("L", NA, NA, NA, "R", NA))
pred &lt;- predict(tmod)
textplot_influence(influence(pred))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
