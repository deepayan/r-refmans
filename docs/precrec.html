<!DOCTYPE html><html><head><title>Help for package precrec</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {precrec}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.data.frame'><p>Convert a curves and points object to a data frame</p></a></li>
<li><a href='#auc'><p>Retrieve a data frame of AUC scores</p></a></li>
<li><a href='#auc_ci'><p>Calculate CIs of ROC and precision-recall AUCs</p></a></li>
<li><a href='#autoplot'><p>Plot performance evaluation measures with ggplot2</p></a></li>
<li><a href='#B1000'><p>Balanced data with 1000 positives and 1000 negatives.</p></a></li>
<li><a href='#B500'><p>Balanced data with 500 positives and 500 negatives.</p></a></li>
<li><a href='#create_sim_samples'><p>Create random samples for simulations</p></a></li>
<li><a href='#evalmod'><p>Evaluate models and calculate performance evaluation measures</p></a></li>
<li><a href='#format_nfold'><p>Create n-fold cross validation dataset from data frame</p></a></li>
<li><a href='#fortify'><p>Convert a curves and points object to a data frame for ggplot2</p></a></li>
<li><a href='#IB1000'><p>Imbalanced data with 1000 positives and 10000 negatives.</p></a></li>
<li><a href='#IB500'><p>Imbalanced data with 500 positives and 5000 negatives.</p></a></li>
<li><a href='#join_labels'><p>Join observed labels of multiple test datasets into a list</p></a></li>
<li><a href='#join_scores'><p>Join scores of multiple models into a list</p></a></li>
<li><a href='#M2N50F5'><p>5-fold cross validation sample.</p></a></li>
<li><a href='#mmdata'><p>Reformat input data for performance evaluation calculation</p></a></li>
<li><a href='#P10N10'><p>A small example dataset with several tied scores.</p></a></li>
<li><a href='#part'><p>Calculate partial AUCs</p></a></li>
<li><a href='#pauc'><p>Retrieve a data frame of pAUC scores</p></a></li>
<li><a href='#plot'><p>Plot performance evaluation measures</p></a></li>
<li><a href='#precrec'><p>precrec: A package for computing accurate ROC and Precision-Recall curves</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Calculate Accurate Precision-Recall and ROC (Receiver Operator
Characteristics) Curves</td>
</tr>
<tr>
<td>Version:</td>
<td>0.14.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-11</td>
</tr>
<tr>
<td>Description:</td>
<td>Accurate calculations and visualization of precision-recall and ROC (Receiver Operator Characteristics)
    curves. Saito and Rehmsmeier (2015) &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0118432">doi:10.1371/journal.pone.0118432</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/evalclass/precrec">https://github.com/evalclass/precrec</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/evalclass/precrec/issues">https://github.com/evalclass/precrec/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), knitr (&ge; 1.11), rmarkdown (&ge; 2.0),
vdiffr (&ge; 1.0.0), patchwork (&ge; 1.1.2)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.0), ggplot2 (&ge; 3.0.0), assertthat (&ge; 0.2),
grid, gridExtra (&ge; 2.0.0), methods, data.table (&ge; 1.10.4),
withr (&ge; 2.3.0), graphics (&ge; 4.0.0), rlang (&ge; 1.0.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-11 21:27:44 UTC; takaya</td>
</tr>
<tr>
<td>Author:</td>
<td>Takaya Saito <a href="https://orcid.org/0000-0002-0154-8452"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Marc Rehmsmeier <a href="https://orcid.org/0000-0002-5021-7721"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Takaya Saito &lt;takaya.saito@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-11 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.data.frame'>Convert a curves and points object to a data frame</h2><span id='topic+as.data.frame'></span><span id='topic+as.data.frame.sscurves'></span><span id='topic+as.data.frame.mscurves'></span><span id='topic+as.data.frame.smcurves'></span><span id='topic+as.data.frame.mmcurves'></span><span id='topic+as.data.frame.sspoints'></span><span id='topic+as.data.frame.mspoints'></span><span id='topic+as.data.frame.smpoints'></span><span id='topic+as.data.frame.mmpoints'></span><span id='topic+as.data.frame.aucroc'></span>

<h3>Description</h3>

<p>The <code>as.data.frame</code> function converts an <code>S3</code> object generated by
<code><a href="#topic+evalmod">evalmod</a></code> to a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sscurves'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'mscurves'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'smcurves'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'mmcurves'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'sspoints'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'mspoints'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'smpoints'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'mmpoints'
as.data.frame(x, row.names = NULL, optional = FALSE, raw_curves = NULL, ...)

## S3 method for class 'aucroc'
as.data.frame(x, row.names = NULL, optional = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame_+3A_x">x</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>as.data.frame</code> function takes
one of the following <code>S3</code> objects.
</p>

<ol>
<li><p> ROC and Precision-Recall curves (mode = &quot;rocprc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> Basic evaluation measures (mode = &quot;basic&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sspoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mspoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smpoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmpoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> Fast AUC (ROC) calculation with the U statistic (mode = &quot;aucroc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    aucroc </td><td style="text-align: left;"> -   </td><td style="text-align: left;"> -
  </td>
</tr>

</table>

</li></ol>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_row.names">row.names</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_optional">optional</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_raw_curves">raw_curves</code></td>
<td>
<p>A Boolean value to specify whether raw curves are
shown instead of the average curve. It is effective only
when <code>raw_curves</code> is set to <code>TRUE</code>
of the <code><a href="#topic+evalmod">evalmod</a></code> function.</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_...">...</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>as.data.frame</code> function returns a data frame.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Convert sscurves to a data frame
sscurves.df &lt;- as.data.frame(sscurves)

## Show data frame
head(sscurves.df)

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)
## Convert sspoints to a data frame
sspoints.df &lt;- as.data.frame(sspoints)

## Show data frame
head(sspoints.df)


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Convert mscurves to a data frame
mscurves.df &lt;- as.data.frame(mscurves)

## Show data frame
head(mscurves.df)

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")

## Convert mspoints to a data frame
mspoints.df &lt;- as.data.frame(mspoints)

## Show data frame
head(mspoints.df)


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Convert smcurves to a data frame
smcurves.df &lt;- as.data.frame(smcurves)

## Show data frame
head(smcurves.df)

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")

## Convert smpoints to a data frame
smpoints.df &lt;- as.data.frame(smpoints)

## Show data frame
head(smpoints.df)


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Convert mmcurves to a data frame
mmcurves.df &lt;- as.data.frame(mmcurves)

## Show data frame
head(mmcurves.df)

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")

## Convert mmpoints to a data frame
mmpoints.df &lt;- as.data.frame(mmpoints)

## Show data frame
head(mmpoints.df)


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
cvcurves &lt;- evalmod(cvdat)

## Convert mmcurves to a data frame
cvcurves.df &lt;- as.data.frame(cvcurves)

## Show data frame
head(cvcurves.df)

## Generate an mmpoints object that contains basic evaluation measures
cvpoints &lt;- evalmod(cvdat, mode = "basic")

## Convert mmpoints to a data frame
cvpoints.df &lt;- as.data.frame(cvpoints)

## Show data frame
head(cvpoints.df)


##################################################
### AUC with the U statistic
###

## mode = "aucroc"
data(P10N10)
uauc1 &lt;- evalmod(
  scores = P10N10$scores, labels = P10N10$labels,
  mode = "aucroc"
)

# as.data.frame 'aucroc'
as.data.frame(uauc1)

## mode = "aucroc"
samps &lt;- create_sim_samples(10, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)
uauc2 &lt;- evalmod(mdat, mode = "aucroc")

# as.data.frame 'aucroc'
head(as.data.frame(uauc2))

## End(Not run)

</code></pre>

<hr>
<h2 id='auc'>Retrieve a data frame of AUC scores</h2><span id='topic+auc'></span><span id='topic+auc.aucs'></span>

<h3>Description</h3>

<p>The <code>auc</code> function takes an <code>S3</code> object generated by
<code><a href="#topic+evalmod">evalmod</a></code> and retrieves a data frame with the Area Under
the Curve (AUC) scores of ROC and Precision-Recall curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc(curves)

## S3 method for class 'aucs'
auc(curves)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc_+3A_curves">curves</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>auc</code> function accepts the following S3 objects.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>auc</code> function returns a data frame with AUC scores.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures. <code><a href="#topic+pauc">pauc</a></code> for retrieving
a dataset of pAUCs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Shows AUCs
auc(sscurves)


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Shows AUCs
auc(mscurves)


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Get AUCs
sm_aucs &lt;- auc(smcurves)

## Shows AUCs
sm_aucs

## Get AUCs of Precision-Recall
sm_aucs_prc &lt;- subset(sm_aucs, curvetypes == "PRC")

## Shows AUCs
sm_aucs_prc

##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Get AUCs
mm_aucs &lt;- auc(mmcurves)

## Shows AUCs
mm_aucs

## Get AUCs of Precision-Recall
mm_aucs_prc &lt;- subset(mm_aucs, curvetypes == "PRC")

## Shows AUCs
mm_aucs_prc

</code></pre>

<hr>
<h2 id='auc_ci'>Calculate CIs of ROC and precision-recall AUCs</h2><span id='topic+auc_ci'></span><span id='topic+auc_ci.aucs'></span>

<h3>Description</h3>

<p>The <code>auc_ci</code> function takes an <code>S3</code> object generated by
<code><a href="#topic+evalmod">evalmod</a></code> and calculates CIs of AUCs when multiple data sets
are specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc_ci(curves, alpha = NULL, dtype = NULL)

## S3 method for class 'aucs'
auc_ci(curves, alpha = 0.05, dtype = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc_ci_+3A_curves">curves</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>auc_ci</code> function accepts the following S3 objects.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="auc_ci_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value of the significant level (default: 0.05)</p>
</td></tr>
<tr><td><code id="auc_ci_+3A_dtype">dtype</code></td>
<td>
<p>A string to specify the distribution used for CI calculation.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <strong>dtype</strong> </td><td style="text-align: left;"> <strong>distribution</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
  normal (default) </td><td style="text-align: left;"> Normal distribution </td>
</tr>
<tr>
 <td style="text-align: left;">
  z </td><td style="text-align: left;"> Normal distribution </td>
</tr>
<tr>
 <td style="text-align: left;">
  t </td><td style="text-align: left;"> t-distribution
</td>
</tr>

</table>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>auc_ci</code> function returns a dataframe of AUC CIs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures. <code><a href="#topic+auc">auc</a></code> for retrieving a dataset
of AUCs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat)

## Calculate CI of AUCs
sm_auc_cis &lt;- auc_ci(smcurves)

## Shows the result
sm_auc_cis

##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat)

## Calculate CI of AUCs
mm_auc_ci &lt;- auc_ci(mmcurves)

## Shows the result
mm_auc_ci

</code></pre>

<hr>
<h2 id='autoplot'>Plot performance evaluation measures with ggplot2</h2><span id='topic+autoplot'></span><span id='topic+autoplot.sscurves'></span><span id='topic+autoplot.mscurves'></span><span id='topic+autoplot.smcurves'></span><span id='topic+autoplot.mmcurves'></span><span id='topic+autoplot.sspoints'></span><span id='topic+autoplot.mspoints'></span><span id='topic+autoplot.smpoints'></span><span id='topic+autoplot.mmpoints'></span>

<h3>Description</h3>

<p>The <code>autoplot</code> function plots performance evaluation measures
by using <span class="pkg">ggplot2</span> instead of the general R plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sscurves'
autoplot(object, curvetype = c("ROC", "PRC"), ...)

## S3 method for class 'mscurves'
autoplot(object, curvetype = c("ROC", "PRC"), ...)

## S3 method for class 'smcurves'
autoplot(object, curvetype = c("ROC", "PRC"), ...)

## S3 method for class 'mmcurves'
autoplot(object, curvetype = c("ROC", "PRC"), ...)

## S3 method for class 'sspoints'
autoplot(object, curvetype = .get_metric_names("basic"), ...)

## S3 method for class 'mspoints'
autoplot(object, curvetype = .get_metric_names("basic"), ...)

## S3 method for class 'smpoints'
autoplot(object, curvetype = .get_metric_names("basic"), ...)

## S3 method for class 'mmpoints'
autoplot(object, curvetype = .get_metric_names("basic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot_+3A_object">object</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>autoplot</code> function accepts the following <code>S3</code> objects for two
different modes, &quot;rocprc&quot; and &quot;basic&quot;.
</p>

<ol>
<li><p> ROC and Precision-Recall curves (<code>mode = "rocprc"</code>)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> Basic evaluation measures (<code>mode = "basic"</code>)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sspoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mspoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smpoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmpoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li></ol>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="autoplot_+3A_curvetype">curvetype</code></td>
<td>
<p>A character vector with the following curve types.
</p>

<ol>
<li><p> ROC and Precision-Recall curves (mode = &quot;rocprc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
      <strong>curvetype</strong>
      </td><td style="text-align: left;"> <strong>description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

      ROC </td><td style="text-align: left;"> ROC curve </td>
</tr>
<tr>
 <td style="text-align: left;">
      PRC </td><td style="text-align: left;"> Precision-Recall curve
    </td>
</tr>

</table>

<p>Multiple <code>curvetype</code> can be combined, such as
<code>c("ROC", "PRC")</code>.
</p>
</li>
<li><p> Basic evaluation measures (mode = &quot;basic&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
      <strong>curvetype</strong>
      </td><td style="text-align: left;"> <strong>description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

      error </td><td style="text-align: left;"> Normalized ranks vs. error rate </td>
</tr>
<tr>
 <td style="text-align: left;">
      accuracy </td><td style="text-align: left;"> Normalized ranks vs. accuracy </td>
</tr>
<tr>
 <td style="text-align: left;">
      specificity </td><td style="text-align: left;"> Normalized ranks vs. specificity </td>
</tr>
<tr>
 <td style="text-align: left;">
      sensitivity </td><td style="text-align: left;"> Normalized ranks vs. sensitivity </td>
</tr>
<tr>
 <td style="text-align: left;">
      precision </td><td style="text-align: left;"> Normalized ranks vs. precision </td>
</tr>
<tr>
 <td style="text-align: left;">
      mcc </td><td style="text-align: left;"> Normalized ranks vs. Matthews correlation coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
      fscore </td><td style="text-align: left;"> Normalized ranks vs. F-score
   </td>
</tr>

</table>

<p>Multiple <code>curvetype</code> can be combined, such as
<code>c("precision", "sensitivity")</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="autoplot_+3A_...">...</code></td>
<td>
<p>Following additional arguments can be specified.
</p>

<dl>
<dt>type</dt><dd>
<p>A character to specify the line type as follows.
</p>

<dl>
<dt>&quot;l&quot;</dt><dd><p>lines</p>
</dd>
<dt>&quot;p&quot;</dt><dd><p>points</p>
</dd>
<dt>&quot;b&quot;</dt><dd><p>both lines and points</p>
</dd>
</dl>

</dd>
<dt>show_cb</dt><dd>
<p>A Boolean value to specify whether point-wise confidence
bounds are drawn. It is effective only when <code>calc_avg</code> of the
<code><a href="#topic+evalmod">evalmod</a></code> function is set to <code>TRUE</code> .
</p>
</dd>
<dt>raw_curves</dt><dd>
<p>A Boolean value to specify whether raw curves are
shown instead of the average curve. It is effective only
when <code>raw_curves</code> of the <code><a href="#topic+evalmod">evalmod</a></code> function is set to
<code>TRUE</code>.
</p>
</dd>
<dt>show_legend</dt><dd>
<p>A Boolean value to specify whether the legend is shown.
</p>
</dd>
<dt>ret_grob</dt><dd>
<p>A logical value to indicate whether
<code>autoplot</code> returns a <code>grob</code> object. The <code>grob</code> object
is internally generated by <code><a href="gridExtra.html#topic+arrangeGrob">arrangeGrob</a></code>.
The <code><a href="grid.html#topic+grid.draw">grid.draw</a></code> function takes a <code>grob</code> object and
shows a plot. It is effective only when a multiple-panel plot is
generated, for example, when <code>curvetype</code> is <code>c("ROC", "PRC")</code>.
</p>
</dd>
<dt>reduce_points</dt><dd>
<p>A Boolean value to decide whether the points should be reduced
when <code>mode = "rocprc"</code>. The points are reduced according to
<code>x_bins</code> of the <code><a href="#topic+evalmod">evalmod</a></code> function.
The default values is <code>TRUE</code>.
</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>autoplot</code> function returns a <code>ggplot</code> object
for a single-panel plot and a frame-grob object for a multiple-panel plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating an <code>S3</code> object.
<code><a href="#topic+fortify">fortify</a></code> for converting a curves and points object
to a data frame.  <code><a href="#topic+plot">plot</a></code> for plotting the equivalent curves
with the general R plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## Load libraries
library(ggplot2)
library(grid)

##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Plot both ROC and Precision-Recall curves
autoplot(sscurves)

## Reduced/Full supporting points
sampss &lt;- create_sim_samples(1, 50000, 50000)
evalss &lt;- evalmod(scores = sampss$scores, labels = sampss$labels)

# Reduced supporting point
system.time(autoplot(evalss))

# Full supporting points
system.time(autoplot(evalss, reduce_points = FALSE))

## Get a grob object for multiple plots
pp1 &lt;- autoplot(sscurves, ret_grob = TRUE)
plot.new()
grid.draw(pp1)

## A ROC curve
autoplot(sscurves, curvetype = "ROC")

## A Precision-Recall curve
autoplot(sscurves, curvetype = "PRC")

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)

## Normalized ranks vs. basic evaluation measures
autoplot(sspoints)

## Normalized ranks vs. precision
autoplot(sspoints, curvetype = "precision")


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## ROC and Precision-Recall curves
autoplot(mscurves)

## Reduced/Full supporting points
sampms &lt;- create_sim_samples(5, 50000, 50000)
evalms &lt;- evalmod(scores = sampms$scores, labels = sampms$labels)

# Reduced supporting point
system.time(autoplot(evalms))

# Full supporting points
system.time(autoplot(evalms, reduce_points = FALSE))

## Hide the legend
autoplot(mscurves, show_legend = FALSE)

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")

## Normalized ranks vs. basic evaluation measures
autoplot(mspoints)

## Hide the legend
autoplot(mspoints, show_legend = FALSE)


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Average ROC and Precision-Recall curves
autoplot(smcurves, raw_curves = FALSE)

## Hide confidence bounds
autoplot(smcurves, raw_curves = FALSE, show_cb = FALSE)

## Raw ROC and Precision-Recall curves
autoplot(smcurves, raw_curves = TRUE, show_cb = FALSE)

## Reduced/Full supporting points
sampsm &lt;- create_sim_samples(4, 5000, 5000)
mdatsm &lt;- mmdata(sampsm$scores, sampsm$labels, expd_first = "dsids")
evalsm &lt;- evalmod(mdatsm, raw_curves = TRUE)

# Reduced supporting point
system.time(autoplot(evalsm, raw_curves = TRUE))

# Full supporting points
system.time(autoplot(evalsm, raw_curves = TRUE, reduce_points = FALSE))

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")

## Normalized ranks vs. average basic evaluation measures
autoplot(smpoints)


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Average ROC and Precision-Recall curves
autoplot(mmcurves, raw_curves = FALSE)

## Show confidence bounds
autoplot(mmcurves, raw_curves = FALSE, show_cb = TRUE)

## Raw ROC and Precision-Recall curves
autoplot(mmcurves, raw_curves = TRUE)

## Reduced/Full supporting points
sampmm &lt;- create_sim_samples(4, 5000, 5000)
mdatmm &lt;- mmdata(sampmm$scores, sampmm$labels,
  modnames = c("m1", "m2"),
  dsids = c(1, 2), expd_first = "modnames"
)
evalmm &lt;- evalmod(mdatmm, raw_curves = TRUE)

# Reduced supporting point
system.time(autoplot(evalmm, raw_curves = TRUE))

# Full supporting points
system.time(autoplot(evalmm, raw_curves = TRUE, reduce_points = FALSE))

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")

## Normalized ranks vs. average basic evaluation measures
autoplot(mmpoints)


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
cvcurves &lt;- evalmod(cvdat)

## Average ROC and Precision-Recall curves
autoplot(cvcurves)

## Show confidence bounds
autoplot(cvcurves, show_cb = TRUE)

## Generate an mmpoints object that contains basic evaluation measures
cvpoints &lt;- evalmod(cvdat, mode = "basic")

## Normalized ranks vs. average basic evaluation measures
autoplot(cvpoints)

## End(Not run)

</code></pre>

<hr>
<h2 id='B1000'>Balanced data with 1000 positives and 1000 negatives.</h2><span id='topic+B1000'></span>

<h3>Description</h3>

<p>A list contains labels and scores of five different performance levels.
All scores were randomly generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(B1000)
</code></pre>


<h3>Format</h3>

<p>A list with 8 items.
</p>

<dl>
<dt>np</dt><dd><p>number of positives: 1000</p>
</dd>
<dt>nn</dt><dd><p>number of negatives: 1000</p>
</dd>
<dt>labels</dt><dd><p>labels of observed data</p>
</dd>
<dt>random_scores</dt><dd><p>scores of a random performance level</p>
</dd>
<dt>poor_er_scores</dt><dd><p>scores of a poor early retrieval level</p>
</dd>
<dt>good_er_scores</dt><dd><p>scores of a good early retrieval level</p>
</dd>
<dt>excel_scores</dt><dd><p>scores of an excellent level</p>
</dd>
<dt>perf_scores</dt><dd><p>scores of the perfect level</p>
</dd>
</dl>


<hr>
<h2 id='B500'>Balanced data with 500 positives and 500 negatives.</h2><span id='topic+B500'></span>

<h3>Description</h3>

<p>A list contains labels and scores of five different performance levels.
All scores were randomly generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(B500)
</code></pre>


<h3>Format</h3>

<p>A list with 8 items.
</p>

<dl>
<dt>np</dt><dd><p>number of positives: 500</p>
</dd>
<dt>nn</dt><dd><p>number of negatives: 500</p>
</dd>
<dt>labels</dt><dd><p>labels of observed data</p>
</dd>
<dt>random_scores</dt><dd><p>scores of a random performance level</p>
</dd>
<dt>poor_er_scores</dt><dd><p>scores of a poor early retrieval level</p>
</dd>
<dt>good_er_scores</dt><dd><p>scores of a good early retrieval level</p>
</dd>
<dt>excel_scores</dt><dd><p>scores of an excellent level</p>
</dd>
<dt>perf_scores</dt><dd><p>scores of the perfect level</p>
</dd>
</dl>


<hr>
<h2 id='create_sim_samples'>Create random samples for simulations</h2><span id='topic+create_sim_samples'></span>

<h3>Description</h3>

<p>The <code>create_sim_samples</code> function generates random samples
with different performance levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_sim_samples(n_repeat, np, nn, score_names = "random")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_sim_samples_+3A_n_repeat">n_repeat</code></td>
<td>
<p>The number of iterations to make samples.</p>
</td></tr>
<tr><td><code id="create_sim_samples_+3A_np">np</code></td>
<td>
<p>The number of positives in a sample.</p>
</td></tr>
<tr><td><code id="create_sim_samples_+3A_nn">nn</code></td>
<td>
<p>The number of negatives in a sample.</p>
</td></tr>
<tr><td><code id="create_sim_samples_+3A_score_names">score_names</code></td>
<td>
<p>A character vector for the names of
the following performance levels.
</p>

<dl>
<dt>&quot;random&quot;</dt><dd><p>Random</p>
</dd>
<dt>&quot;poor_er&quot;</dt><dd><p>Poor early retrieval</p>
</dd>
<dt>&quot;good_er&quot;</dt><dd><p>Good early retrieval</p>
</dd>
<dt>&quot;excel&quot;</dt><dd><p>Excellent</p>
</dd>
<dt>&quot;perf&quot;</dt><dd><p>Perfect</p>
</dd>
<dt>&quot;all&quot;</dt><dd><p>All of the above</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>create_sim_samples</code> function returns a list
with the following items.
</p>

<ul>
<li><p> scores: a list of numeric vectors
</p>
</li>
<li><p> labels: an integer vector
</p>
</li>
<li><p> modnames: a character vector of the model names
</p>
</li>
<li><p> dsids: a character vector of the dataset IDs
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+mmdata">mmdata</a></code> for formatting input data.
<code><a href="#topic+evalmod">evalmod</a></code> for calculation evaluation measures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Create a set of samples with 10 positives and 10 negatives
### for the random performance level
###
samps1 &lt;- create_sim_samples(1, 10, 10, "random")

## Show the list structure
str(samps1)


##################################################
### Create two sets of samples with 10 positives and 20 negatives
### for the random and the poor early retrieval performance levels
###
samps2 &lt;- create_sim_samples(2, 10, 20, c("random", "poor_er"))

## Show the list structure
str(samps2)


##################################################
### Create 3 sets of samples with 5 positives and 5 negatives
### for all 5 levels
###
samps3 &lt;- create_sim_samples(3, 5, 5, "all")

## Show the list structure
str(samps3)

</code></pre>

<hr>
<h2 id='evalmod'>Evaluate models and calculate performance evaluation measures</h2><span id='topic+evalmod'></span>

<h3>Description</h3>

<p>The <code>evalmod</code> function calculates ROC and Precision-Recall curves for
specified prediction scores and binary labels. It also calculate several
basic performance evaluation measures, such as accuracy, error rate, and
precision, by specifying <code>mode</code> as &quot;basic&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalmod(
  mdat,
  mode = NULL,
  scores = NULL,
  labels = NULL,
  modnames = NULL,
  dsids = NULL,
  posclass = NULL,
  na_worst = TRUE,
  ties_method = "equiv",
  calc_avg = TRUE,
  cb_alpha = 0.05,
  raw_curves = FALSE,
  x_bins = 1000,
  interpolate = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evalmod_+3A_mdat">mdat</code></td>
<td>
<p>An <code>S3</code> object created by the <code><a href="#topic+mmdata">mmdata</a></code>
function. It contains formatted scores and labels.
The <code>evalmod</code> function ignores the following arguments
when <code>mdat</code> is specified.
</p>

<ul>
<li> <p><code>scores</code>
</p>
</li>
<li> <p><code>labels</code>
</p>
</li>
<li> <p><code>modnames</code>
</p>
</li>
<li> <p><code>dsids</code>
</p>
</li>
<li> <p><code>posclass</code>
</p>
</li>
<li> <p><code>na_worst</code>
</p>
</li>
<li> <p><code>ties_method</code>
</p>
</li></ul>

<p>These arguments are internally passed to the <code><a href="#topic+mmdata">mmdata</a></code> function
when <code>mdat</code> is unspecified.
In that case, both <code>scores</code> and <code>labels</code> must be
at least specified.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_mode">mode</code></td>
<td>
<p>A string that specifies the types of evaluation measures
that the <code>evalmod</code> function calculates.
</p>

<dl>
<dt>&quot;rocprc&quot;</dt><dd><p>ROC and Precision-Recall curves</p>
</dd>
<dt>&quot;prcroc&quot;</dt><dd><p>Same as above</p>
</dd>
<dt>&quot;basic&quot;</dt><dd><p>Normalized ranks vs. accuracy, error rate, specificity,
sensitivity, precision, Matthews correlation coefficient,
and F-score. </p>
</dd>
<dt>&quot;aucroc&quot;</dt><dd><p>Fast AUC(ROC) calculation with the U statistic</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="evalmod_+3A_scores">scores</code></td>
<td>
<p>A numeric dataset of predicted scores. It can be a vector,
a matrix, an array, a data frame, or a list. The <code><a href="#topic+join_scores">join_scores</a></code>
function can be useful to make scores with multiple datasets.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_labels">labels</code></td>
<td>
<p>A numeric, character, logical, or factor dataset
of observed labels. It can be a vector, a matrix, an array,
a data frame, or a list. The <code><a href="#topic+join_labels">join_labels</a></code>
function can be useful to make labels with multiple datasets.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_modnames">modnames</code></td>
<td>
<p>A character vector for the names of the models.
The <code>evalmod</code> function automatically generates default names
as &quot;m1&quot;, &quot;m2&quot;, &quot;m3&quot;, and so on when it is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_dsids">dsids</code></td>
<td>
<p>A numeric vector for test dataset IDs.
The <code>evalmod</code> function automatically generates the default ID
as <code>1</code> when it is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_posclass">posclass</code></td>
<td>
<p>A scalar value to specify the label of positives
in <code>labels</code>. It must be the same data type as <code>labels</code>.
For example, <code>posclass = -1</code> changes the positive label
from <code>1</code> to <code>-1</code> when <code>labels</code> contains
<code>1</code> and <code>-1</code>. The positive label will be automatically
detected when <code>posclass</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_na_worst">na_worst</code></td>
<td>
<p>A Boolean value for controlling the treatment of NAs
in <code>scores</code>.
</p>

<dl>
<dt>TRUE</dt><dd><p>All NAs are treated as the worst scores</p>
</dd>
<dt>FALSE</dt><dd><p>All NAs are treated as the best scores</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="evalmod_+3A_ties_method">ties_method</code></td>
<td>
<p>A string for controlling ties in <code>scores</code>.
</p>

<dl>
<dt>&quot;equiv&quot;</dt><dd><p>Ties are equivalently ranked</p>
</dd>
<dt>&quot;first&quot;</dt><dd><p>Ties are ranked in an increasing order as appeared</p>
</dd>
<dt>&quot;random&quot;</dt><dd><p> Ties are ranked in random order</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="evalmod_+3A_calc_avg">calc_avg</code></td>
<td>
<p>A logical value to specify whether average curves should
be calculated. It is effective only when <code>dsids</code> contains multiple
dataset IDs. For instance, the function calculates the average for the
model &quot;m1&quot; when <code>modnames</code> is <code>c("m1", "m1", "m1")</code> and
<code>dsids</code> is <code>c(1, 2, 3)</code>. The calculation points are defined by
<code>x_bins</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_cb_alpha">cb_alpha</code></td>
<td>
<p>A numeric value with range [0, 1] to specify the alpha
value of the point-wise confidence bounds calculation. It is effective only
when <code>calc_avg</code> is set to <code>TRUE</code>. For example, it should be
<code>0.05</code> for the 95% confidence level. The calculation points are
defined by <code>x_bins</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_raw_curves">raw_curves</code></td>
<td>
<p>A logical value to specify whether all raw curves
should be discarded after the average curves are calculated.
It is effective only when <code>calc_avg</code> is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_x_bins">x_bins</code></td>
<td>
<p>An integer value to specify the number of minimum bins
on the x-axis. It is then used to define supporting points For instance,
the x-values of the supporting points will be <code>c(0, 0.5, 1)</code> and
<code>c(0, 0.25, 0.5, 0.75, 1)</code> when <code>x_bins = 2</code>
and <code>x_bins = 4</code>, respectively. All corresponding y-values of
the supporting points are calculated. <code>x_bins</code> is effective only
when <code>mode</code> is set to <code>rocprc</code> or <code>prcroc</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_interpolate">interpolate</code></td>
<td>
<p>A Boolean value to specify whether or not
interpolation of ROC and precision-recall curves are
performed. <code>x_bins</code> and <code>calc_avg</code> are
ignored and  when <code>x_bins</code> is set to <code>FALSE</code>.
<code>interpolate</code> is effective only when <code>mode</code> is set
to <code>rocprc</code> or <code>prcroc</code>.</p>
</td></tr>
<tr><td><code id="evalmod_+3A_...">...</code></td>
<td>
<p>These additional arguments are passed to <code><a href="#topic+mmdata">mmdata</a></code>
for data preparation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>evalmod</code> function returns an <code>S3</code> object
that contains performance evaluation measures. The number of models and
the number of datasets can be controlled by <code>modnames</code> and
<code>dsids</code>. For example, the number of models is &quot;single&quot; and the number
of test datasets is &quot;multiple&quot; when <code>modnames = c("m1", "m1", "m1")</code>
and <code>dsids = c(1, 2, 3)</code> are specified.
</p>
<p>Different <code>S3</code> objects have different default behaviors of <code>S3</code>
generics, such as <code><a href="#topic+plot">plot</a></code>, <code><a href="#topic+autoplot">autoplot</a></code>, and
<code><a href="#topic+fortify">fortify</a></code>.
</p>

<ol>
<li><p>  The <code>evalmod</code> function returns one of the following <code>S3</code>
objects when <code>mode</code> is &quot;prcroc&quot;.
The objects contain ROC and Precision-Recall curves.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> The <code>evalmod</code> function returns one of the following <code>S3</code>
objects when <code>mode</code> is &quot;basic&quot;.
They contain five different basic evaluation measures; error rate,
accuracy, specificity, sensitivity, and precision.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sspoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mspoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smpoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmpoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> The <code>evalmod</code> function returns the <code>aucroc</code> S3 object
when <code>mode</code> is &quot;aucroc&quot;, which can be used with 'print'
and 'as.data.frame'.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+plot">plot</a></code> for plotting curves with the general R plot.
<code><a href="#topic+autoplot">autoplot</a></code> and <code><a href="#topic+fortify">fortify</a></code> for plotting curves
with <span class="pkg">ggplot2</span>. <code><a href="#topic+mmdata">mmdata</a></code> for formatting input data.
<code><a href="#topic+join_scores">join_scores</a></code> and <code><a href="#topic+join_labels">join_labels</a></code> for formatting
scores and labels with multiple datasets.
<code><a href="#topic+format_nfold">format_nfold</a></code> for creating n-fold cross validation dataset
from data frame.
<code><a href="#topic+create_sim_samples">create_sim_samples</a></code> for generating random samples
for simulations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)
sscurves

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)
sspoints


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)
mscurves

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")
mspoints


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat)
smcurves

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")
smpoints


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat)
mmcurves

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")
mmpoints


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
cvcurves &lt;- evalmod(cvdat)
cvcurves

## Generate an mmpoints object that contains basic evaluation measures
cvpoints &lt;- evalmod(cvdat, mode = "basic")
cvpoints

## Specify mmdata arguments from evalmod
cvcurves2 &lt;- evalmod(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)
cvcurves2


##################################################
### AUC with the U statistic
###

## mode = "aucroc" returns 'aucroc' S3 object
data(P10N10)

# 'aucroc' S3 object
uauc1 &lt;- evalmod(
  scores = P10N10$scores, labels = P10N10$labels,
  mode = "aucroc"
)

# print 'aucroc'
uauc1

# as.data.frame 'aucroc'
as.data.frame(uauc1)

## It is 2-3 times faster than mode = "rocprc"
# A sample of 100,000
samp1 &lt;- create_sim_samples(1, 50000, 50000)

# a function to test mode = "rocprc"
func_evalmod_rocprc &lt;- function(samp) {
  curves &lt;- evalmod(scores = samp$scores, labels = samp$labels)
  aucs &lt;- auc(curves)
}

# a function to test mode = "aucroc"
func_evalmod_aucroc &lt;- function(samp) {
  uaucs &lt;- evalmod(
    scores = samp$scores, labels = samp$labels,
    mode = "aucroc"
  )
  as.data.frame(uaucs)
}

# Process time
system.time(res1 &lt;- func_evalmod_rocprc(samp1))
system.time(res2 &lt;- func_evalmod_aucroc(samp1))

# AUCs
res1
res2

</code></pre>

<hr>
<h2 id='format_nfold'>Create n-fold cross validation dataset from data frame</h2><span id='topic+format_nfold'></span>

<h3>Description</h3>

<p>The <code>format_nfold</code> function takes a data frame with scores, label,
and n-fold columns and convert it to a list for <code><a href="#topic+evalmod">evalmod</a></code>
and <code><a href="#topic+mmdata">mmdata</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_nfold(nfold_df, score_cols, lab_col, fold_col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_nfold_+3A_nfold_df">nfold_df</code></td>
<td>
<p>A data frame that contains at least one score column,
label and fold columns.</p>
</td></tr>
<tr><td><code id="format_nfold_+3A_score_cols">score_cols</code></td>
<td>
<p>A character/numeric vector that specifies score columns
of <code>nfold_df</code>.</p>
</td></tr>
<tr><td><code id="format_nfold_+3A_lab_col">lab_col</code></td>
<td>
<p>A number/string that specifies the label column
of <code>nfold_df</code>.</p>
</td></tr>
<tr><td><code id="format_nfold_+3A_fold_col">fold_col</code></td>
<td>
<p>A number/string that specifies the fold column
of <code>nfold_df</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>format_nfold</code> function returns a list that
contains multiple scores and labels.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for calculation evaluation measures.
<code><a href="#topic+mmdata">mmdata</a></code> for formatting input data.
<code><a href="#topic+join_scores">join_scores</a></code> and <code><a href="#topic+join_labels">join_labels</a></code> for formatting
scores and labels with multiple datasets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Convert dataframe with 2 models and 5-fold datasets
###

## Load test data
data(M2N50F5)
head(M2N50F5)

## Convert with format_nfold
nfold_list1 &lt;- format_nfold(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4
)

## Show the list structure
str(nfold_list1)
str(nfold_list1$scores)
str(nfold_list1$labels)


##################################################
### Speficy a single score column
###

## Convert with format_nfold
nfold_list2 &lt;- format_nfold(
  nfold_df = M2N50F5, score_cols = 1,
  lab_col = 3, fold_col = 4
)

## Show the list structure
str(nfold_list2)
str(nfold_list2$scores)
str(nfold_list2$labels)


##################################################
### Use column names
###

## Convert with format_nfold
nfold_list3 &lt;- format_nfold(
  nfold_df = M2N50F5,
  score_cols = c("score1", "score2"),
  lab_col = "label", fold_col = "fold"
)

## Show the list structure
str(nfold_list3)
str(nfold_list3$scores)
str(nfold_list3$labels)

</code></pre>

<hr>
<h2 id='fortify'>Convert a curves and points object to a data frame for ggplot2</h2><span id='topic+fortify'></span><span id='topic+fortify.sscurves'></span><span id='topic+fortify.mscurves'></span><span id='topic+fortify.smcurves'></span><span id='topic+fortify.mmcurves'></span><span id='topic+fortify.sspoints'></span><span id='topic+fortify.mspoints'></span><span id='topic+fortify.smpoints'></span><span id='topic+fortify.mmpoints'></span>

<h3>Description</h3>

<p>The <code>fortify</code> function converts an <code>S3</code> object generated by
<code><a href="#topic+evalmod">evalmod</a></code> to a data frame for <span class="pkg">ggplot2</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sscurves'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'mscurves'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'smcurves'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'mmcurves'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'sspoints'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'mspoints'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'smpoints'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)

## S3 method for class 'mmpoints'
fortify(model, data, raw_curves = NULL, reduce_points = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fortify_+3A_model">model</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>fortify</code> function takes one of the following <code>S3</code> objects.
</p>

<ol>
<li><p> ROC and Precision-Recall curves (mode = &quot;rocprc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> Basic evaluation measures (mode = &quot;basic&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sspoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mspoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smpoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmpoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li></ol>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="fortify_+3A_data">data</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
<tr><td><code id="fortify_+3A_raw_curves">raw_curves</code></td>
<td>
<p>A Boolean value to specify whether raw curves are
shown instead of the average curve. It is effective only
when <code>raw_curves</code> is set to <code>TRUE</code>
of the <code><a href="#topic+evalmod">evalmod</a></code> function.</p>
</td></tr>
<tr><td><code id="fortify_+3A_reduce_points">reduce_points</code></td>
<td>
<p>A Boolean value to decide whether the points should
be reduced. The points are reduced according to <code>x_bins</code>
of the <code><a href="#topic+evalmod">evalmod</a></code> function. The default values is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fortify_+3A_...">...</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>fortify</code> function returns a data frame for
<span class="pkg">ggplot2</span>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures.
<code><a href="#topic+autoplot">autoplot</a></code> for plotting with <span class="pkg">ggplot2</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## Load library
library(ggplot2)

##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Let ggplot internally call fortify
p_rocprc &lt;- ggplot(sscurves, aes(x = x, y = y))
p_rocprc &lt;- p_rocprc + geom_line()
p_rocprc &lt;- p_rocprc + facet_wrap(~curvetype)
p_rocprc

## Explicitly fortify sscurves
ssdf &lt;- fortify(sscurves)

## Plot a ROC curve
p_roc &lt;- ggplot(subset(ssdf, curvetype == "ROC"), aes(x = x, y = y))
p_roc &lt;- p_roc + geom_line()
p_roc

## Plot a Precision-Recall curve
p_prc &lt;- ggplot(subset(ssdf, curvetype == "PRC"), aes(x = x, y = y))
p_prc &lt;- p_prc + geom_line()
p_prc

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)
## Fortify sspoints
ssdf &lt;- fortify(sspoints)

## Plot normalized ranks vs. precision
p_prec &lt;- ggplot(subset(ssdf, curvetype == "precision"), aes(x = x, y = y))
p_prec &lt;- p_prec + geom_point()
p_prec


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 10 positives and 10 negatives
samps &lt;- create_sim_samples(1, 10, 10, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Let ggplot internally call fortify
p_rocprc &lt;- ggplot(mscurves, aes(x = x, y = y, color = modname))
p_rocprc &lt;- p_rocprc + geom_line()
p_rocprc &lt;- p_rocprc + facet_wrap(~curvetype)
p_rocprc

## Explicitly fortify mscurves
msdf &lt;- fortify(mscurves)

## Plot ROC curve
df_roc &lt;- subset(msdf, curvetype == "ROC")
p_roc &lt;- ggplot(df_roc, aes(x = x, y = y, color = modname))
p_roc &lt;- p_roc + geom_line()
p_roc

## Fortified data frame can be used for plotting a Precision-Recall curve
df_prc &lt;- subset(msdf, curvetype == "PRC")
p_prc &lt;- ggplot(df_prc, aes(x = x, y = y, color = modname))
p_prc &lt;- p_prc + geom_line()
p_prc

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")

## Fortify mspoints
msdf &lt;- fortify(mspoints)

## Plot normalized ranks vs. precision
df_prec &lt;- subset(msdf, curvetype == "precision")
p_prec &lt;- ggplot(df_prec, aes(x = x, y = y, color = modname))
p_prec &lt;- p_prec + geom_point()
p_prec


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 10 positives and 10 negatives
samps &lt;- create_sim_samples(5, 10, 10, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Let ggplot internally call fortify
p_rocprc &lt;- ggplot(smcurves, aes(x = x, y = y, group = dsid))
p_rocprc &lt;- p_rocprc + geom_smooth(stat = "identity")
p_rocprc &lt;- p_rocprc + facet_wrap(~curvetype)
p_rocprc

## Explicitly fortify smcurves
smdf &lt;- fortify(smcurves, raw_curves = FALSE)

## Plot average ROC curve
df_roc &lt;- subset(smdf, curvetype == "ROC")
p_roc &lt;- ggplot(df_roc, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_roc &lt;- p_roc + geom_smooth(stat = "identity")
p_roc

## Plot average Precision-Recall curve
df_prc &lt;- subset(smdf, curvetype == "PRC")
p_prc &lt;- ggplot(df_prc, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_prc &lt;- p_prc + geom_smooth(stat = "identity")
p_prc

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")

## Fortify smpoints
smdf &lt;- fortify(smpoints)

## Plot normalized ranks vs. precision
df_prec &lt;- subset(smdf, curvetype == "precision")
p_prec &lt;- ggplot(df_prec, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_prec &lt;- p_prec + geom_ribbon(aes(min = ymin, ymax = ymax),
  stat = "identity", alpha = 0.25,
  fill = "grey25"
)
p_prec &lt;- p_prec + geom_point(aes(x = x, y = y))
p_prec


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 10 positives and 10 negatives
samps &lt;- create_sim_samples(5, 10, 10, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Let ggplot internally call fortify
p_rocprc &lt;- ggplot(mmcurves, aes(x = x, y = y, group = dsid))
p_rocprc &lt;- p_rocprc + geom_smooth(aes(color = modname), stat = "identity")
p_rocprc &lt;- p_rocprc + facet_wrap(~curvetype)
p_rocprc

## Explicitly fortify mmcurves
mmdf &lt;- fortify(mmcurves, raw_curves = FALSE)

## Plot average ROC curve
df_roc &lt;- subset(mmdf, curvetype == "ROC")
p_roc &lt;- ggplot(df_roc, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_roc &lt;- p_roc + geom_smooth(aes(color = modname), stat = "identity")
p_roc

## Plot average Precision-Recall curve
df_prc &lt;- subset(mmdf, curvetype == "PRC")
p_prc &lt;- ggplot(df_prc, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_prc &lt;- p_prc + geom_smooth(aes(color = modname), stat = "identity")
p_prc

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")

## Fortify mmpoints
mmdf &lt;- fortify(mmpoints)

## Plot normalized ranks vs. precision
df_prec &lt;- subset(mmdf, curvetype == "precision")
p_prec &lt;- ggplot(df_prec, aes(x = x, y = y, ymin = ymin, ymax = ymax))
p_prec &lt;- p_prec + geom_ribbon(aes(min = ymin, ymax = ymax, group = modname),
  stat = "identity", alpha = 0.25,
  fill = "grey25"
)
p_prec &lt;- p_prec + geom_point(aes(x = x, y = y, color = modname))
p_prec

## End(Not run)

</code></pre>

<hr>
<h2 id='IB1000'>Imbalanced data with 1000 positives and 10000 negatives.</h2><span id='topic+IB1000'></span>

<h3>Description</h3>

<p>A list contains labels and scores of five different performance levels.
All scores were randomly generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IB1000)
</code></pre>


<h3>Format</h3>

<p>A list with 8 items.
</p>

<dl>
<dt>np</dt><dd><p>number of positives: 1000</p>
</dd>
<dt>nn</dt><dd><p>number of negatives: 10000</p>
</dd>
<dt>labels</dt><dd><p>labels of observed data</p>
</dd>
<dt>random_scores</dt><dd><p>scores of a random performance level</p>
</dd>
<dt>poor_er_scores</dt><dd><p>scores of a poor early retrieval level</p>
</dd>
<dt>good_er_scores</dt><dd><p>scores of a good early retrieval level</p>
</dd>
<dt>excel_scores</dt><dd><p>scores of an excellent level</p>
</dd>
<dt>perf_scores</dt><dd><p>scores of the perfect level</p>
</dd>
</dl>


<hr>
<h2 id='IB500'>Imbalanced data with 500 positives and 5000 negatives.</h2><span id='topic+IB500'></span>

<h3>Description</h3>

<p>A list contains labels and scores of five different performance levels.
All scores were randomly generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IB500)
</code></pre>


<h3>Format</h3>

<p>A list with 8 items.
</p>

<dl>
<dt>np</dt><dd><p>number of positives: 500</p>
</dd>
<dt>nn</dt><dd><p>number of negatives: 5000</p>
</dd>
<dt>labels</dt><dd><p>labels of observed data</p>
</dd>
<dt>random_scores</dt><dd><p>scores of a random performance level</p>
</dd>
<dt>poor_er_scores</dt><dd><p>scores of a poor early retrieval level</p>
</dd>
<dt>good_er_scores</dt><dd><p>scores of a good early retrieval level</p>
</dd>
<dt>excel_scores</dt><dd><p>scores of an excellent level</p>
</dd>
<dt>perf_scores</dt><dd><p>scores of the perfect level</p>
</dd>
</dl>


<hr>
<h2 id='join_labels'>Join observed labels of multiple test datasets into a list</h2><span id='topic+join_labels'></span>

<h3>Description</h3>

<p><code>join_labels</code> takes observed labels and converts them to a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>join_labels(..., byrow = FALSE, chklen = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="join_labels_+3A_...">...</code></td>
<td>
<p>Multiple datasets. They can be vectors, arrays, matrices,
data frames, and lists.</p>
</td></tr>
<tr><td><code id="join_labels_+3A_byrow">byrow</code></td>
<td>
<p>A Boolean value to specify whether row vectors are used
for matrix, data frame, and array.</p>
</td></tr>
<tr><td><code id="join_labels_+3A_chklen">chklen</code></td>
<td>
<p>A Boolean value to specify whether all list items must be
the same lengths.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>join_labels</code> function returns a list that
contains all combined label data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for calculation evaluation measures.
<code><a href="#topic+mmdata">mmdata</a></code> for formatting input data.
<code><a href="#topic+join_scores">join_scores</a></code> for formatting scores with multiple datasets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Add three numeric vectors
###
l1 &lt;- c(1, 0, 1, 1)
l2 &lt;- c(1, 1, 0, 0)
l3 &lt;- c(0, 1, 0, 1)
labels1 &lt;- join_labels(l1, l2, l3)

## Show the list structure
str(labels1)


##################################################
### Add a matrix and a numeric vector
###
a1 &lt;- matrix(rep(c(1, 0), 4), 4, 2)
labels2 &lt;- join_labels(a1, l3)

## Show the list structure
str(labels2)


##################################################
### Use byrow
###
a2 &lt;- matrix(rep(c(1, 0), 4), 2, 4, byrow = TRUE)
labels3 &lt;- join_labels(a2, l3, byrow = TRUE)

## Show the list structure
str(labels3)


##################################################
### Use chklen
###
l4 &lt;- c(-1, 0, -1)
l5 &lt;- c(0, -1)
labels4 &lt;- join_labels(l4, l5, chklen = FALSE)

## Show the list structure
str(labels4)

</code></pre>

<hr>
<h2 id='join_scores'>Join scores of multiple models into a list</h2><span id='topic+join_scores'></span>

<h3>Description</h3>

<p>The <code>join_scores</code> function takes predicted scores from multiple models
and converts them to a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>join_scores(..., byrow = FALSE, chklen = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="join_scores_+3A_...">...</code></td>
<td>
<p>Multiple datasets. They can be vectors, arrays, matrices,
data frames, and lists.</p>
</td></tr>
<tr><td><code id="join_scores_+3A_byrow">byrow</code></td>
<td>
<p>A Boolean value to specify whether row vectors are used
for matrix, data frame, and array.</p>
</td></tr>
<tr><td><code id="join_scores_+3A_chklen">chklen</code></td>
<td>
<p>A Boolean value to specify whether all list items must be
the same lengths.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>join_scores</code> function returns a list that
contains all combined score data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for calculation evaluation measures.
<code><a href="#topic+mmdata">mmdata</a></code> for formatting input data.
<code><a href="#topic+join_labels">join_labels</a></code> for formatting labels with multiple datasets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Add three numeric vectors
###
s1 &lt;- c(1, 2, 3, 4)
s2 &lt;- c(5, 6, 7, 8)
s3 &lt;- c(2, 4, 6, 8)
scores1 &lt;- join_scores(s1, s2, s3)

## Show the list structure
str(scores1)


##################################################
### Add a matrix and a numeric vector
###
a1 &lt;- matrix(seq(8), 4, 2)
scores2 &lt;- join_scores(a1, s3)

## Show the list structure
str(scores2)


##################################################
### Use byrow
###
a2 &lt;- matrix(seq(8), 2, 4, byrow = TRUE)
scores3 &lt;- join_scores(a2, s3, byrow = TRUE)

## Show the list structure
str(scores3)


##################################################
### Use chklen
###
s4 &lt;- c(1, 2, 3)
s5 &lt;- c(5, 6, 7, 8)
scores4 &lt;- join_scores(s4, s5, chklen = FALSE)

## Show the list structure
str(scores4)

</code></pre>

<hr>
<h2 id='M2N50F5'>5-fold cross validation sample.</h2><span id='topic+M2N50F5'></span>

<h3>Description</h3>

<p>A data frame contains labels and scores for 5-fold test sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(M2N50F5)
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 columns.
</p>

<dl>
<dt>score1</dt><dd><p>50 random scores</p>
</dd>
<dt>score2</dt><dd><p>50 random scores</p>
</dd>
<dt>label</dt><dd><p>50 labels as 'pos' or 'neg'</p>
</dd>
<dt>fold</dt><dd><p>50 fold IDs as 1:5</p>
</dd>
</dl>


<hr>
<h2 id='mmdata'>Reformat input data for performance evaluation calculation</h2><span id='topic+mmdata'></span>

<h3>Description</h3>

<p>The <code>mmdata</code> function takes predicted scores and labels
and returns an <code>mdat</code> object. The <code><a href="#topic+evalmod">evalmod</a></code> function
takes an <code>mdat</code> object as input data to calculate evaluation measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmdata(
  scores,
  labels,
  modnames = NULL,
  dsids = NULL,
  posclass = NULL,
  na_worst = TRUE,
  ties_method = "equiv",
  expd_first = NULL,
  mode = "rocprc",
  nfold_df = NULL,
  score_cols = NULL,
  lab_col = NULL,
  fold_col = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmdata_+3A_scores">scores</code></td>
<td>
<p>A numeric dataset of predicted scores. It can be a vector,
a matrix, an array, a data frame, or a list. The <code><a href="#topic+join_scores">join_scores</a></code>
function can be useful to make scores with multiple datasets.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_labels">labels</code></td>
<td>
<p>A numeric, character, logical, or factor dataset
of observed labels. It can be a vector, a matrix, an array,
a data frame, or a list. The <code><a href="#topic+join_labels">join_labels</a></code>
function can be useful to make labels with multiple datasets.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_modnames">modnames</code></td>
<td>
<p>A character vector for the names of the models.
The <code>evalmod</code> function automatically generates default names
as &quot;m1&quot;, &quot;m2&quot;, &quot;m3&quot;, and so on when it is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_dsids">dsids</code></td>
<td>
<p>A numeric vector for test dataset IDs.
The <code>evalmod</code> function automatically generates the default ID
as <code>1</code> when it is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_posclass">posclass</code></td>
<td>
<p>A scalar value to specify the label of positives
in <code>labels</code>. It must be the same data type as <code>labels</code>.
For example, <code>posclass = -1</code> changes the positive label
from <code>1</code> to <code>-1</code> when <code>labels</code> contains
<code>1</code> and <code>-1</code>. The positive label will be automatically
detected when <code>posclass</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_na_worst">na_worst</code></td>
<td>
<p>A Boolean value for controlling the treatment of NAs
in <code>scores</code>.
</p>

<dl>
<dt>TRUE</dt><dd><p>All NAs are treated as the worst scores</p>
</dd>
<dt>FALSE</dt><dd><p>All NAs are treated as the best scores</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mmdata_+3A_ties_method">ties_method</code></td>
<td>
<p>A string for controlling ties in <code>scores</code>.
</p>

<dl>
<dt>&quot;equiv&quot;</dt><dd><p>Ties are equivalently ranked</p>
</dd>
<dt>&quot;first&quot;</dt><dd><p>Ties are ranked in an increasing order as appeared</p>
</dd>
<dt>&quot;random&quot;</dt><dd><p> Ties are ranked in random order</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mmdata_+3A_expd_first">expd_first</code></td>
<td>
<p>A string to indicate which of the two variables
- model names or test dataset IDs
should be expanded first when they are automatically generated.
</p>

<dl>
<dt>&quot;modnames&quot;</dt><dd><p>Model names are expanded first. For example,
The <code>mmdata</code> function generates <code>modnames</code> as
<code>c("m1", "m2")</code> and <code>dsids</code> as <code>c(1, 1)</code>
when two vectors are passed as input,
and <code>modnames</code> and <code>dsids</code> are unspecified.</p>
</dd>
<dt>&quot;dsids&quot;</dt><dd><p>Test dataset IDs are expanded first. For example,
The <code>mmdata</code> function generates <code>modnames</code> as
<code>c("m1", "m1")</code> and <code>dsids</code> as <code>c(1, 2)</code>
when two vectors are passed as input,
and <code>modnames</code> and <code>dsids</code> are unspecified.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mmdata_+3A_mode">mode</code></td>
<td>
<p>A string that specifies the types of evaluation measures
that the <code>evalmod</code> function calculates.
</p>

<dl>
<dt>&quot;rocprc&quot;</dt><dd><p>ROC and Precision-Recall curves</p>
</dd>
<dt>&quot;prcroc&quot;</dt><dd><p>Same as above</p>
</dd>
<dt>&quot;basic&quot;</dt><dd><p>Normalized ranks vs. accuracy, error rate, specificity,
sensitivity, precision, Matthews correlation coefficient,
and F-score. </p>
</dd>
<dt>&quot;aucroc&quot;</dt><dd><p>Fast AUC(ROC) calculation with the U statistic</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mmdata_+3A_nfold_df">nfold_df</code></td>
<td>
<p>A data frame that contains at least one score column,
label and fold columns.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_score_cols">score_cols</code></td>
<td>
<p>A character/numeric vector that specifies score columns
of <code>nfold_df</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_lab_col">lab_col</code></td>
<td>
<p>A number/string that specifies the label column
of <code>nfold_df</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_fold_col">fold_col</code></td>
<td>
<p>A number/string that specifies the fold column
of <code>nfold_df</code>.</p>
</td></tr>
<tr><td><code id="mmdata_+3A_...">...</code></td>
<td>
<p>Not used by this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>mmdata</code> function returns an <code>mdat</code> object
that contains formatted labels and score ranks. The object can
be used as input data for the <code><a href="#topic+evalmod">evalmod</a></code> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for calculation evaluation measures.
<code><a href="#topic+join_scores">join_scores</a></code> and <code><a href="#topic+join_labels">join_labels</a></code> for formatting
scores and labels with multiple datasets.
<code><a href="#topic+format_nfold">format_nfold</a></code> for creating n-fold cross validation dataset
from data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate mdat object
ssmdat1 &lt;- mmdata(P10N10$scores, P10N10$labels)
ssmdat1
ssmdat2 &lt;- mmdata(1:8, sample(c(0, 1), 8, replace = TRUE))
ssmdat2


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")

## Multiple models &amp; single test dataset
msmdat1 &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)
msmdat1

## Use join_scores and join_labels
s1 &lt;- c(1, 2, 3, 4)
s2 &lt;- c(5, 6, 7, 8)
scores &lt;- join_scores(s1, s2)

l1 &lt;- c(1, 0, 1, 1)
l2 &lt;- c(1, 0, 1, 1)
labels &lt;- join_labels(l1, l2)

msmdat2 &lt;- mmdata(scores, labels, modnames = c("ms1", "ms2"))
msmdat2


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "good_er")

## Single model &amp; multiple test datasets
smmdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)
smmdat


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "all")

## Multiple models &amp; multiple test datasets
mmmdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)
mmmdat


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)
head(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat1 &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)
cvdat1

## Use column names
cvdat2 &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c("score1", "score2"),
  lab_col = "label", fold_col = "fold",
  modnames = c("m1", "m2"), dsids = 1:5
)
cvdat2

</code></pre>

<hr>
<h2 id='P10N10'>A small example dataset with several tied scores.</h2><span id='topic+P10N10'></span>

<h3>Description</h3>

<p>A list contains labels and scores for 10 positives and 10 negatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(P10N10)
</code></pre>


<h3>Format</h3>

<p>A list with 4 items.
</p>

<dl>
<dt>np</dt><dd><p>number of positives: 10</p>
</dd>
<dt>nn</dt><dd><p>number of negatives: 10</p>
</dd>
<dt>labels</dt><dd><p>20 labels of observed data</p>
</dd>
<dt>scores</dt><dd><p>20 scores with some ties</p>
</dd>
</dl>


<hr>
<h2 id='part'>Calculate partial AUCs</h2><span id='topic+part'></span><span id='topic+part.sscurves'></span><span id='topic+part.mscurves'></span><span id='topic+part.smcurves'></span><span id='topic+part.mmcurves'></span>

<h3>Description</h3>

<p>The <code>part</code> function takes an <code>S3</code> object generated by
<code><a href="#topic+evalmod">evalmod</a></code> and calculate partial AUCs and Standardized partial
AUCs of ROC and Precision-Recall curves.
Standardized pAUCs are standardized to the range between 0 and 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>part(curves, xlim = NULL, ylim = NULL, curvetype = NULL)

## S3 method for class 'sscurves'
part(curves, xlim = c(0, 1), ylim = c(0, 1), curvetype = c("ROC", "PRC"))

## S3 method for class 'mscurves'
part(curves, xlim = c(0, 1), ylim = c(0, 1), curvetype = c("ROC", "PRC"))

## S3 method for class 'smcurves'
part(curves, xlim = c(0, 1), ylim = c(0, 1), curvetype = c("ROC", "PRC"))

## S3 method for class 'mmcurves'
part(curves, xlim = c(0, 1), ylim = c(0, 1), curvetype = c("ROC", "PRC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="part_+3A_curves">curves</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>part</code> function accepts the following S3 objects.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="part_+3A_xlim">xlim</code></td>
<td>
<p>A numeric vector of length two to specify x range between
two points in [0, 1]</p>
</td></tr>
<tr><td><code id="part_+3A_ylim">ylim</code></td>
<td>
<p>A numeric vector of length two to specify y range between
two points in [0, 1]</p>
</td></tr>
<tr><td><code id="part_+3A_curvetype">curvetype</code></td>
<td>
<p>A character vector with the following curve types.
</p>

<table>
<tr>
 <td style="text-align: left;">
  <strong>curvetype</strong> </td><td style="text-align: left;"> <strong>description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
  ROC </td><td style="text-align: left;"> ROC curve </td>
</tr>
<tr>
 <td style="text-align: left;">
  PRC </td><td style="text-align: left;"> Precision-Recall curve
</td>
</tr>

</table>

<p>Multiple <code>curvetype</code> can be combined, such as
<code>c("ROC", "PRC")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>part</code> function returns the same S3 object specified as
input with calculated pAUCs and standardized pAUCs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures. <code><a href="#topic+pauc">pauc</a></code> for retrieving
a dataset of pAUCs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## Load library
library(ggplot2)

##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Calculate partial AUCs
sscurves.part &lt;- part(sscurves, xlim = c(0.25, 0.75))

## Show AUCs
sscurves.part

## Plot partial curve
plot(sscurves.part)

## Plot partial curve with ggplot
autoplot(sscurves.part)


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Calculate partial AUCs
mscurves.part &lt;- part(mscurves, xlim = c(0, 0.75), ylim = c(0.25, 0.75))

## Show AUCs
mscurves.part

## Plot partial curves
plot(mscurves.part)

## Plot partial curves with ggplot
autoplot(mscurves.part)


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat)

## Calculate partial AUCs
smcurves.part &lt;- part(smcurves, xlim = c(0.25, 0.75))

## Show AUCs
smcurves.part

## Plot partial curve
plot(smcurves.part)

## Plot partial curve with ggplot
autoplot(smcurves.part)


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Calculate partial AUCs
mmcurves.part &lt;- part(mmcurves, xlim = c(0, 0.25))

## Show AUCs
mmcurves.part

## Plot partial curves
plot(mmcurves.part)

## Plot partial curves with ggplot
autoplot(mmcurves.part)

## End(Not run)

</code></pre>

<hr>
<h2 id='pauc'>Retrieve a data frame of pAUC scores</h2><span id='topic+pauc'></span><span id='topic+pauc.aucs'></span>

<h3>Description</h3>

<p>The <code>auc</code> function takes an <code>S3</code> object generated by
<code><a href="#topic+part">part</a></code> and <code><a href="#topic+evalmod">evalmod</a></code> and retrieves a data frame
with the partial AUC scores of ROC and Precision-Recall curves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pauc(curves)

## S3 method for class 'aucs'
pauc(curves)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pauc_+3A_curves">curves</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+part">part</a></code> and
<code><a href="#topic+evalmod">evalmod</a></code>. The <code>pauc</code> function accepts the following
S3 objects.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>auc</code> function returns a data frame with pAUC scores.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating <code>S3</code> objects with
performance evaluation measures. <code><a href="#topic+part">part</a></code> for calculation of
pAUCs. <code><a href="#topic+auc">auc</a></code> for retrieving a dataset of AUCs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Calculate partial AUCs
sscurves.part &lt;- part(sscurves, xlim = c(0.25, 0.75))

## Shows pAUCs
pauc(sscurves.part)

##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Calculate partial AUCs
mscurves.part &lt;- part(mscurves, xlim = c(0, 0.75), ylim = c(0.25, 0.75))

## Shows pAUCs
pauc(mscurves.part)

##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Calculate partial AUCs
smcurves.part &lt;- part(smcurves, xlim = c(0.25, 0.75))

## Shows pAUCs
pauc(smcurves.part)

##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(4, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Calculate partial AUCs
mmcurves.part &lt;- part(mmcurves, xlim = c(0, 0.25))

## Shows pAUCs
pauc(mmcurves.part)

</code></pre>

<hr>
<h2 id='plot'>Plot performance evaluation measures</h2><span id='topic+plot'></span><span id='topic+plot.sscurves'></span><span id='topic+plot.mscurves'></span><span id='topic+plot.smcurves'></span><span id='topic+plot.mmcurves'></span><span id='topic+plot.sspoints'></span><span id='topic+plot.mspoints'></span><span id='topic+plot.smpoints'></span><span id='topic+plot.mmpoints'></span>

<h3>Description</h3>

<p>The <code>plot</code> function creates a plot of performance evaluation measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sscurves'
plot(x, y = NULL, ...)

## S3 method for class 'mscurves'
plot(x, y = NULL, ...)

## S3 method for class 'smcurves'
plot(x, y = NULL, ...)

## S3 method for class 'mmcurves'
plot(x, y = NULL, ...)

## S3 method for class 'sspoints'
plot(x, y = NULL, ...)

## S3 method for class 'mspoints'
plot(x, y = NULL, ...)

## S3 method for class 'smpoints'
plot(x, y = NULL, ...)

## S3 method for class 'mmpoints'
plot(x, y = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>An <code>S3</code> object generated by <code><a href="#topic+evalmod">evalmod</a></code>.
The <code>plot</code> function accepts the following <code>S3</code> objects.
</p>

<ol>
<li><p> ROC and Precision-Recall curves (mode = &quot;rocprc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sscurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mscurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smcurves </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmcurves </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li>
<li><p> Basic evaluation measures (mode = &quot;basic&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong><code>S3</code> object</strong>
    </td><td style="text-align: left;"> <strong># of models</strong>
    </td><td style="text-align: left;"> <strong># of test datasets</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

    sspoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    mspoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> single   </td>
</tr>
<tr>
 <td style="text-align: left;">
    smpoints </td><td style="text-align: left;"> single   </td><td style="text-align: left;"> multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
    mmpoints </td><td style="text-align: left;"> multiple </td><td style="text-align: left;"> multiple
  </td>
</tr>

</table>

</li></ol>

<p>See the <strong>Value</strong> section of <code><a href="#topic+evalmod">evalmod</a></code> for more details.</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>Equivalent with <code>curvetype</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>All the following arguments can be specified.
</p>

<dl>
<dt>curvetype</dt><dd>

<ol>
<li><p> ROC and Precision-Recall curves (mode = &quot;rocprc&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
          <strong>curvetype</strong>
          </td><td style="text-align: left;"> <strong>description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

          ROC </td><td style="text-align: left;"> ROC curve </td>
</tr>
<tr>
 <td style="text-align: left;">
          PRC </td><td style="text-align: left;"> Precision-Recall curve
        </td>
</tr>

</table>

<p>Multiple <code>curvetype</code> can be combined, such as
<code>c("ROC", "PRC")</code>.
</p>
</li>
<li><p> Basic evaluation measures (mode = &quot;basic&quot;)
</p>

<table>
<tr>
 <td style="text-align: left;">
          <strong>curvetype</strong>
          </td><td style="text-align: left;"> <strong>description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">

          error </td><td style="text-align: left;"> Normalized ranks vs. error rate </td>
</tr>
<tr>
 <td style="text-align: left;">
          accuracy </td><td style="text-align: left;"> Normalized ranks vs. accuracy </td>
</tr>
<tr>
 <td style="text-align: left;">
          specificity </td><td style="text-align: left;"> Normalized ranks vs. specificity </td>
</tr>
<tr>
 <td style="text-align: left;">
          sensitivity </td><td style="text-align: left;"> Normalized ranks vs. sensitivity </td>
</tr>
<tr>
 <td style="text-align: left;">
          precision </td><td style="text-align: left;"> Normalized ranks vs. precision </td>
</tr>
<tr>
 <td style="text-align: left;">
          mcc </td><td style="text-align: left;"> Normalized ranks vs. Matthews correlation coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
          fscore </td><td style="text-align: left;"> Normalized ranks vs. F-score
       </td>
</tr>

</table>

<p>Multiple <code>curvetype</code> can be combined, such as
<code>c("precision", "sensitivity")</code>.
</p>
</li></ol>

</dd>
<dt>type</dt><dd>
<p>A character to specify the line type as follows.
</p>

<dl>
<dt>&quot;l&quot;</dt><dd><p>lines</p>
</dd>
<dt>&quot;p&quot;</dt><dd><p>points</p>
</dd>
<dt>&quot;b&quot;</dt><dd><p>both lines and points</p>
</dd>
</dl>

</dd>
<dt>show_cb</dt><dd>
<p>A Boolean value to specify whether point-wise confidence
bounds are drawn. It is effective only when <code>calc_avg</code> of the
<code><a href="#topic+evalmod">evalmod</a></code> function is set to <code>TRUE</code>.
</p>
</dd>
<dt>raw_curves</dt><dd>
<p>A Boolean value to specify whether raw curves are
shown instead of the average curve. It is effective only
when <code>raw_curves</code> of the <code><a href="#topic+evalmod">evalmod</a></code> function is set to
<code>TRUE</code>.
</p>
</dd>
<dt>show_legend</dt><dd>
<p>A Boolean value to specify whether the legend is shown.
</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>plot</code> function shows a plot and returns NULL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evalmod">evalmod</a></code> for generating an <code>S3</code> object.
<code><a href="#topic+autoplot">autoplot</a></code> for plotting the equivalent curves
with <span class="pkg">ggplot2</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##################################################
### Single model &amp; single test dataset
###

## Load a dataset with 10 positives and 10 negatives
data(P10N10)

## Generate an sscurve object that contains ROC and Precision-Recall curves
sscurves &lt;- evalmod(scores = P10N10$scores, labels = P10N10$labels)

## Plot both ROC and Precision-Recall curves
plot(sscurves)

## Plot a ROC curve
plot(sscurves, curvetype = "ROC")

## Plot a Precision-Recall curve
plot(sscurves, curvetype = "PRC")

## Generate an sspoints object that contains basic evaluation measures
sspoints &lt;- evalmod(
  mode = "basic", scores = P10N10$scores,
  labels = P10N10$labels
)

## Plot normalized ranks vs. basic evaluation measures
plot(sspoints)

## Plot normalized ranks vs. precision
plot(sspoints, curvetype = "precision")


##################################################
### Multiple models &amp; single test dataset
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(1, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mscurves &lt;- evalmod(mdat)

## Plot both ROC and Precision-Recall curves
plot(mscurves)

## Hide the legend
plot(mscurves, show_legend = FALSE)

## Generate an mspoints object that contains basic evaluation measures
mspoints &lt;- evalmod(mdat, mode = "basic")

## Plot normalized ranks vs. basic evaluation measures
plot(mspoints)

## Hide the legend
plot(mspoints, show_legend = FALSE)


##################################################
### Single model &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "good_er")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an smcurve object that contains ROC and Precision-Recall curves
smcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Plot average ROC and Precision-Recall curves
plot(smcurves, raw_curves = FALSE)

## Hide confidence bounds
plot(smcurves, raw_curves = FALSE, show_cb = FALSE)

## Plot raw ROC and Precision-Recall curves
plot(smcurves, raw_curves = TRUE, show_cb = FALSE)

## Generate an smpoints object that contains basic evaluation measures
smpoints &lt;- evalmod(mdat, mode = "basic")

## Plot normalized ranks vs. average basic evaluation measures
plot(smpoints)


##################################################
### Multiple models &amp; multiple test datasets
###

## Create sample datasets with 100 positives and 100 negatives
samps &lt;- create_sim_samples(10, 100, 100, "all")
mdat &lt;- mmdata(samps[["scores"]], samps[["labels"]],
  modnames = samps[["modnames"]],
  dsids = samps[["dsids"]]
)

## Generate an mscurve object that contains ROC and Precision-Recall curves
mmcurves &lt;- evalmod(mdat, raw_curves = TRUE)

## Plot average ROC and Precision-Recall curves
plot(mmcurves, raw_curves = FALSE)

## Show confidence bounds
plot(mmcurves, raw_curves = FALSE, show_cb = TRUE)

## Plot raw ROC and Precision-Recall curves
plot(mmcurves, raw_curves = TRUE)

## Generate an mmpoints object that contains basic evaluation measures
mmpoints &lt;- evalmod(mdat, mode = "basic")

## Plot normalized ranks vs. average basic evaluation measures
plot(mmpoints)


##################################################
### N-fold cross validation datasets
###

## Load test data
data(M2N50F5)

## Speficy nessesary columns to create mdat
cvdat &lt;- mmdata(
  nfold_df = M2N50F5, score_cols = c(1, 2),
  lab_col = 3, fold_col = 4,
  modnames = c("m1", "m2"), dsids = 1:5
)

## Generate an mmcurve object that contains ROC and Precision-Recall curves
cvcurves &lt;- evalmod(cvdat)

## Average ROC and Precision-Recall curves
plot(cvcurves)

## Show confidence bounds
plot(cvcurves, show_cb = TRUE)

## Generate an mmpoints object that contains basic evaluation measures
cvpoints &lt;- evalmod(cvdat, mode = "basic")

## Normalized ranks vs. average basic evaluation measures
plot(cvpoints)

## End(Not run)
</code></pre>

<hr>
<h2 id='precrec'>precrec: A package for computing accurate ROC and Precision-Recall curves</h2><span id='topic+precrec'></span>

<h3>Description</h3>

<p>The precrec package contains several functions and <code>S3</code> generics to
provide a robust platform for performance evaluation of binary classifiers.
</p>


<h3>Functions</h3>

<p>The precrec package provides the following six functions.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong>Function</strong> </td><td style="text-align: left;"> <strong>Description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+evalmod">evalmod</a></code>
          </td><td style="text-align: left;"> Main function to calculate evaluation measures </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+mmdata">mmdata</a></code>
          </td><td style="text-align: left;"> Reformat input data for performance evaluation calculation </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+join_scores">join_scores</a></code>
          </td><td style="text-align: left;"> Join scores of multiple models into a list </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+join_labels">join_labels</a></code>
          </td><td style="text-align: left;"> Join observed labels of multiple test datasets into a list </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+create_sim_samples">create_sim_samples</a></code>
          </td><td style="text-align: left;"> Create random samples for simulations </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+format_nfold">format_nfold</a></code>
          </td><td style="text-align: left;"> Create n-fold cross validation dataset from data frame
  </td>
</tr>

</table>



<h3>S3 generics</h3>

<p>The precrec package provides nine different <code>S3</code> generics for the
<code>S3</code> objects generated by the <code><a href="#topic+evalmod">evalmod</a></code> function.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <strong>S3 generic</strong>
    </td><td style="text-align: left;"> <strong>Library</strong>
    </td><td style="text-align: left;"> <strong>Description</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>print</code>
    </td><td style="text-align: left;"> base
    </td><td style="text-align: left;"> Print the calculation results and the summary of the test data </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+as.data.frame">as.data.frame</a></code>
    </td><td style="text-align: left;"> base
    </td><td style="text-align: left;"> Convert a precrec object to a data frame </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+plot">plot</a></code>
    </td><td style="text-align: left;"> graphics
    </td><td style="text-align: left;"> Plot performance evaluation measures </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+autoplot">autoplot</a></code>
    </td><td style="text-align: left;"> ggplot2
    </td><td style="text-align: left;"> Plot performance evaluation measures with ggplot2  </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+fortify">fortify</a></code>
    </td><td style="text-align: left;"> ggplot2
    </td><td style="text-align: left;"> Prepare a data frame for ggplot2 </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+auc">auc</a></code>
    </td><td style="text-align: left;"> precrec
    </td><td style="text-align: left;"> Make a data frame with AUC scores </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+part">part</a></code>
    </td><td style="text-align: left;"> precrec
    </td><td style="text-align: left;"> Calculate partial curves and partial AUC scores </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+pauc">pauc</a></code>
    </td><td style="text-align: left;"> precrec
    </td><td style="text-align: left;"> Make a data frame with pAUC scores </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code><a href="#topic+auc_ci">auc_ci</a></code>
    </td><td style="text-align: left;"> precrec
    </td><td style="text-align: left;"> Calculate confidence intervals of AUC scores
  </td>
</tr>

</table>



<h3>Performance measure calculations</h3>

<p>The <code><a href="#topic+evalmod">evalmod</a></code> function calculates ROC and Precision-Recall
curves and returns an <code>S3</code> object. The generated <code>S3</code> object can
be used with several different <code>S3</code> generics, such as <code>print</code> and
<code><a href="#topic+plot">plot</a></code>. The <code><a href="#topic+evalmod">evalmod</a></code> function can also
calculate basic evaluation measures - error rate, accuracy, specificity,
sensitivity, precision, Matthews correlation coefficient, and F-Score.
</p>


<h3>Data preparation</h3>

<p>The <code><a href="#topic+mmdata">mmdata</a></code> function creates an input dataset for
the <code><a href="#topic+evalmod">evalmod</a></code> function. The generated dataset contains
formatted scores and labels.
</p>
<p><code><a href="#topic+join_scores">join_scores</a></code> and <code><a href="#topic+join_labels">join_labels</a></code> are helper
functions to combine multiple scores and labels.
</p>
<p>The <code><a href="#topic+create_sim_samples">create_sim_samples</a></code> function creates test datasets with
five different performance levels.
</p>


<h3>Data visualization</h3>

<p><code><a href="#topic+plot">plot</a></code> takes an <code>S3</code> object generated
by <code><a href="#topic+evalmod">evalmod</a></code> as input and plot corresponding curves.
</p>
<p><code><a href="#topic+autoplot">autoplot</a></code> uses <code>ggplot</code> to plot curves.
</p>


<h3>Result retrieval</h3>

<p><code><a href="#topic+as.data.frame">as.data.frame</a></code> takes an <code>S3</code> object generated
by <code><a href="#topic+evalmod">evalmod</a></code> as input and and returns a data frame
with calculated curve points.
</p>
<p><code><a href="#topic+auc">auc</a></code> and <code><a href="#topic+pauc">pauc</a></code> returns a data frame with AUC scores
and partial AUC scores, respectively. <code><a href="#topic+auc_ci">auc_ci</a></code>
returns confidence intervals of AUCs for both ROC
and precision-recall curves.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
