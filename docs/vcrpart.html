<!DOCTYPE html><html lang="en"><head><title>Help for package vcrpart</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {vcrpart}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#contr.wsum'><p>Contrast matrices</p></a></li>
<li><a href='#fvcm'><p>Bagging and Random Forests based on <code>tvcm</code></p></a></li>
<li><a href='#fvcm-methods'><p>Methods for <code>fvcm</code> objects</p></a></li>
<li><a href='#movie'><p>Movie critics</p></a></li>
<li><a href='#olmm'><p>Fitting ordinal and nominal two-stage linear mixed models</p></a></li>
<li><a href='#olmm-control'><p>Control parameters for <code>olmm</code>.</p></a></li>
<li><a href='#olmm-gefp'><p>Methods for score processes of <code>olmm</code> objects</p></a></li>
<li><a href='#olmm-methods'><p>Methods for <code>olmm</code> objects</p></a></li>
<li><a href='#olmm-predict'><p>Predict outcome probabilities and responses for</p>
<code>olmm</code> objects</a></li>
<li><a href='#olmm-summary'><p>Printing and summarizing <code>olmm</code> objects</p></a></li>
<li><a href='#otsplot'><p>Time-series plot for longitudinal ordinal data</p></a></li>
<li><a href='#PL'><p>Effect of parental leave policy</p></a></li>
<li><a href='#poverty'><p>Poverty in Switzerland</p></a></li>
<li><a href='#schizo'><p>National Institute of Mental Health shizophrenia study</p></a></li>
<li><a href='#tvcglm'><p>Coefficient-wise tree-based varying coefficient regression based</p>
on generalized linear models</a></li>
<li><a href='#tvcm'><p>Tree-based varying coefficient regression models</p></a></li>
<li><a href='#tvcm-assessment'><p>Model selection utility functions for <code>tvcm</code> objects.</p></a></li>
<li><a href='#tvcm-control'><p>Control parameters for <code>tvcm</code>.</p></a></li>
<li><a href='#tvcm-methods'><p>Methods for <code>tvcm</code> objects</p></a></li>
<li><a href='#tvcm-plot'><p><code>plot</code> method for <code>tvcm</code> objects.</p></a></li>
<li><a href='#tvcolmm'><p>Tree-based varying coefficient regression based on ordinal and</p>
nominal two-stage linear mixed models.</a></li>
<li><a href='#vcrpart-demo'><p>Synthetic data sets</p></a></li>
<li><a href='#vcrpart-formula'><p>Special terms for formulas.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tree-Based Varying Coefficient Regression for Generalized Linear
and Ordinal Mixed Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Reto Burgin <a href="https://orcid.org/0000-0002-6212-1567"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Gilbert Ritschard <a href="https://orcid.org/0000-0001-7776-0903"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Reto Burgin &lt;rbuergin@gmx.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Recursive partitioning for varying coefficient generalized linear models and ordinal linear mixed models. Special features are coefficient-wise partitioning, non-varying coefficients and partitioning of time-varying variables in longitudinal regression. A description of a part of this package was published by Burgin and Ritschard (2017) &lt;<a href="https://doi.org/10.18637%2Fjss.v080.i06">doi:10.18637/jss.v080.i06</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), parallel, partykit</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, grid, graphics, methods, nlme (&ge; 3.1-123), rpart,
formula.tools, numDeriv, ucminf, zoo, sandwich, strucchange</td>
</tr>
<tr>
<td>Suggests:</td>
<td>xtable, mlbench, Ecdat, RWeka</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-04 19:27:30 UTC; reto</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-04 20:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='contr.wsum'>Contrast matrices</h2><span id='topic+contr.wsum'></span>

<h3>Description</h3>

<p>Returns a category-weighted contrast matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contr.wsum(x, weights = rep.int(1.0, length(x)), sparse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="contr.wsum_+3A_x">x</code></td>
<td>
<p>a factor vector</p>
</td></tr>
<tr><td><code id="contr.wsum_+3A_weights">weights</code></td>
<td>
<p>a vector of weights with the same length as <code>x</code>.</p>
</td></tr>
<tr><td><code id="contr.wsum_+3A_sparse">sparse</code></td>
<td>
<p>ogical indicating if the result should be sparse (of class <code>dgCMatrix</code>), using package <span class="pkg">Matrix</span>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes a contrast matrix similar to <code><a href="stats.html#topic+contr.sum">contr.sum</a></code>. The
reference category is however weighted by the sum of weights of the
other categories.
</p>


<h3>Value</h3>

<p>A matrix with <code>nlevels(x)</code> rows and <code>nlevels(x)- 1</code>
columns.</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+contr.sum">contr.sum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- factor(rep(LETTERS[1:3], c(10, 20, 30)))
contr.wsum(x) # standard call
contr.wsum(x, sparse = TRUE) # using a sparse matrix
</code></pre>

<hr>
<h2 id='fvcm'>Bagging and Random Forests based on <code><a href="#topic+tvcm">tvcm</a></code></h2><span id='topic+fvcm'></span><span id='topic+fvcm_control'></span><span id='topic+fvcolmm'></span><span id='topic+fvcolmm_control'></span><span id='topic+fvcglm'></span><span id='topic+fvcglm_control'></span>

<h3>Description</h3>

<p>Bagging (Breiman, 1996) and Random Forest (Breiman, 2001) ensemble
algorithms for <code><a href="#topic+tvcm">tvcm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fvcm(..., control = fvcm_control())

fvcm_control(maxstep = 10, minsize = 10,
             folds = folds_control("subsampling", K = 100),
             mtry = 5, sctest = FALSE, alpha = 1.0,
             mindev = 0.0, verbose = TRUE, ...)

fvcolmm(..., family = cumulative(), control = fvcolmm_control())

fvcolmm_control(maxstep = 10, minsize = 20, 
                folds = folds_control("subsampling", K = 100),
                mtry = 5, sctest = TRUE, alpha = 1.0,  
                nimpute = 1, verbose = TRUE, ...)

fvcglm(..., family, control = fvcglm_control())

fvcglm_control(maxstep = 10, minsize = 10,
               folds = folds_control("subsampling", K = 100),
               mtry = 5, mindev = 0,
               verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fvcm_+3A_...">...</code></td>
<td>
<p>for <code><a href="#topic+fvcm">fvcm</a></code>, <code><a href="#topic+fvcolmm">fvcolmm</a></code> and
<code><a href="#topic+fvcglm">fvcglm</a></code> arguments to be passed to
<code><a href="#topic+tvcm">tvcm</a></code>. This includes at least the arguments
<code>formula</code>, <code>data</code> and <code>family</code>, see examples below. For
<code><a href="#topic+fvcm_control">fvcm_control</a></code> further control arguments to be passed
to <code><a href="#topic+tvcm_control">tvcm_control</a></code>. For
<code><a href="#topic+fvcolmm_control">fvcolmm_control</a></code> and
<code><a href="#topic+fvcglm_control">fvcglm_control</a></code> further control arguments to be passed
to <code><a href="#topic+fvcm_control">fvcm_control</a></code></p>
</td></tr></table>
<p>.       
</p>
<table role = "presentation">
<tr><td><code id="fvcm_+3A_control">control</code></td>
<td>
<p>a list of control parameters as produced by
<code><a href="#topic+fvcm_control">fvcm_control</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm_+3A_family">family</code></td>
<td>
<p>the model family, e.g., <code><a href="stats.html#topic+binomial">binomial</a></code> or 
<code><a href="#topic+cumulative">cumulative</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm_+3A_maxstep">maxstep</code></td>
<td>
<p>integer. The maximum number of steps for when growing
individual trees.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_folds">folds</code></td>
<td>
<p>a list of parameters to control the extraction of subsets, 
as created by <code><a href="#topic+folds_control">folds_control</a></code>.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_mtry">mtry</code></td>
<td>
<p>positive integer scalar. The number of combinations of
partitions, nodes and variables to be randomly sampled as candidates
in each iteration.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_sctest">sctest</code></td>
<td>
<p>logical scalar. Defines whether coefficient constancy
tests should be used for the variable and node selection in each
iteration.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_mindev">mindev</code>, <code id="fvcm_+3A_alpha">alpha</code></td>
<td>
<p>these parameters are merely specified to
disable the default stopping rules for <code><a href="#topic+tvcm">tvcm</a></code>. See
also <code><a href="#topic+tvcm_control">tvcm_control</a></code> for details.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_minsize">minsize</code>, <code id="fvcm_+3A_nimpute">nimpute</code></td>
<td>
<p>special parameter settings for
<code><a href="#topic+fvcolmm">fvcolmm</a></code>. The minimum node size is set to the
default of <code><a href="#topic+tvcolmm">tvcolmm</a></code>. The default <code>nimpute</code>
deactivates the imputation procedure in cases of unbalanced data.</p>
</td></tr>
<tr><td><code id="fvcm_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should information about the fitting process
be printed to the screen?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements the <em>Bagging</em> (Breiman, 1996) and <em>Random
Forests</em> (Breiman, 2001) ensemble algorithms for
<code><a href="#topic+tvcm">tvcm</a></code>. The method consist in growing multiple trees by
using <code><a href="#topic+tvcm">tvcm</a></code> and aggregating the fitted coefficient
functions in the scale of the predictor function. To enable bagging,
use <code>mtry = Inf</code> in <code><a href="#topic+fvcm_control">fvcm_control</a></code>.    
</p>
<p><code><a href="#topic+fvcolmm">fvcolmm</a></code> and <code><a href="#topic+fvcglm">fvcglm</a></code> are the
extensions for <code><a href="#topic+tvcolmm">tvcolmm</a></code> and
<code><a href="#topic+tvcglm">tvcglm</a></code>.
</p>
<p><code><a href="#topic+fvcm_control">fvcm_control</a></code> is a wrapper of
<code><a href="#topic+tvcm_control">tvcm_control</a></code> and the arguments indicated specify
modified defaults and parameters for randomizing split
selections. Notice that, relative to <code><a href="#topic+tvcm_control">tvcm_control</a></code>,
also the <code>cv</code> <code>prune</code> arguments are internally disabled. The
default arguments for <code>alpha</code> and <code>maxoverstep</code> essentially
disable the stopping rules of <code><a href="#topic+tvcm">tvcm</a></code>, where the
argument <code>maxstep</code> (the number of iterations i.e. the maximum
number of splits) fully controls the stopping. The parameter
<code>mtry</code> controls the randomization for selecting combinations of
partitions, nodes and variables for splitting. The default of
<code>mtry = 5</code> is arbitrary.
</p>


<h3>Value</h3>

<p>An object of class <code>fvcm</code>.</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Breiman, L. (1996). Bagging Predictors. <em>Machine Learning</em>,
<b>24</b>(2), 123&ndash;140.
</p>
<p>Breiman, L. (2001). Random Forests. <em>Machine Learning</em>,
<b>45</b>(1), 5&ndash;32.
</p>
<p>Hastie, T., R. Tibshirani and J. Friedman (2001). <em>The Elements
of Statistical Learning</em> (2 ed.). New York, USA: Springer-Verlag.
</p>
<p>Burgin, R. A. (2015). Tree-based methods for moderated regression
with application to longitudinal data. PhD thesis. University of
Geneva. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fvcm-methods">fvcm-methods</a></code>, <code><a href="#topic+tvcm">tvcm</a></code>, 
<code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+olmm">olmm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example:
##
## Bagging 'tvcm' on the artificially generated data 'vcrpart_3'. The 
## true coefficient function is a sinus curve between -pi/2 and pi/2. 
## The parameters 'maxstep = 3' and 'K = 5' are chosen to restrict the 
## computations.
## ------------------------------------------------------------------- #

## simulated data
data(vcrpart_3)

## setting parameters
control &lt;-
  fvcm_control(maxstep = 3, 
               folds = folds_control("subsampling", K = 5, 0.5, seed = 3))

## fitting the forest
model &lt;- fvcm(y ~ vc(z1, by = x1), data = vcrpart_3, 
              family = gaussian(), control = control)

## plot the first two trees
plot(model, "coef", 1:2)

## plotting the partial dependency of the coefficient for 'x1'
plot(model, "partdep")
</code></pre>

<hr>
<h2 id='fvcm-methods'>Methods for <code><a href="#topic+fvcm">fvcm</a></code> objects</h2><span id='topic+fvcm-methods'></span><span id='topic+fitted.fvcm'></span><span id='topic+print.fvcm'></span><span id='topic+oobloss.fvcm'></span><span id='topic+plot.fvcm'></span><span id='topic+predict.fvcm'></span><span id='topic+ranef.fvcm'></span>

<h3>Description</h3>

<p>Standard methods for computing on <code><a href="#topic+fvcm">fvcm</a></code>
objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fvcm'
oobloss(object, fun = NULL, ranef = FALSE, ...)

## S3 method for class 'fvcm'
plot(x, type = c("default", "coef", 
           "simple", "partdep"),
     tree = NULL, ask = NULL, ...)

## S3 method for class 'fvcm'
predict(object, newdata = NULL,
        type = c("link", "response", "prob", "class", "coef", "ranef"),
        ranef = FALSE, na.action = na.pass, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fvcm-methods_+3A_object">object</code>, <code id="fvcm-methods_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+fvcm">fvcm</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_fun">fun</code></td>
<td>
<p>the loss function. The default loss function is defined 
as the sum of the deviance residuals. For a user defined function
<code>fun</code>, see the examples of 
<code><a href="#topic+oobloss.tvcm">oobloss.tvcm</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables
with which to predict. If omitted, the training data are used.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_type">type</code></td>
<td>
<p>character string indicating the type of plot or
prediction. See <code><a href="#topic+plot.tvcm">plot.tvcm</a></code> or
<code><a href="#topic+predict.tvcm">predict.tvcm</a></code>. <code>"response"</code> and <code>"prob"</code>
are identical.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_tree">tree</code></td>
<td>
<p>integer vector. Which trees should be plotted.</p>
</td></tr>
<tr><td><code id="fvcm-methods_+3A_ask">ask</code></td>
<td>
<p>logical. Whether an input should be asked before printing
the next panel.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_ranef">ranef</code></td>
<td>
<p>logical scalar or matrix indicating whether predictions
should be based on random effects. See
<code><a href="#topic+predict.olmm">predict.olmm</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values for fixed effects in <code>newdata</code>. The default is to
predict <code>NA</code>: see <code><a href="stats.html#topic+na.pass">na.pass</a></code>.</p>
</td></tr> 
<tr><td><code id="fvcm-methods_+3A_verbose">verbose</code></td>
<td>
<p>logical scalar. If <code>TRUE</code> verbose output is
generated during the validation.</p>
</td></tr>
<tr><td><code id="fvcm-methods_+3A_...">...</code></td>
<td>
<p>further arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+oobloss.fvcm">oobloss.fvcm</a></code> estimates the out-of-bag loss based on
predictions of the model that aggregates only those trees in which the
observation didn't appear (cf. Hastie et al, 2001, sec. 15). The
prediction error is computed as the sum of prediction errors obtained
with <code>fun</code>, which are the deviance residuals by default. 
</p>
<p>The plot and the prediction methods are analogous to
<code><a href="#topic+plot.tvcm">plot.tvcm</a></code> resp. <code><a href="#topic+predict.tvcm">predict.tvcm</a></code>. Note
that the plot options <code>mean</code> and <code>conf.int</code> for
<code>type ="coef"</code> are not available (and internally set to
<code>FALSE</code>).  
</p>
<p>Further undocumented, available methods are <code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="base.html#topic+print">print</a></code> and <code><a href="#topic+ranef">ranef</a></code>. All these latter
methods have the same arguments as the corresponding default methods. 
</p>


<h3>Value</h3>

<p>The methods <code><a href="#topic+fitted.fvcm">fitted.fvcm</a></code> and
<code><a href="#topic+predict.fvcm">predict.fvcm</a></code> return an object of class <code>numeric</code>
or <code>matrix</code>, depending on the used model or the specification of
the argument <code>type</code>. See also <code><a href="#topic+fitted.tvcm">fitted.tvcm</a></code>. 
</p>
<p>The <code><a href="#topic+oobloss.fvcm">oobloss.fvcm</a></code> method returns the output of the
loss function defined by <code>fun</code>. This is a single numeric by
default. See also <code><a href="#topic+oobloss">oobloss</a></code>.
</p>
<p>The <code><a href="#topic+plot.fvcm">plot.fvcm</a></code> method returns <code>NULL</code>.
</p>
<p>The <code><a href="#topic+ranef.fvcm">ranef.fvcm</a></code> method returns an object of class
<code>matrix</code> with values for the random effects. See also
<code><a href="#topic+ranef.olmm">ranef.olmm</a></code> and <code><a href="#topic+ranef">ranef</a></code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Breiman, L. (1996). Bagging Predictors. <em>Machine Learning</em>,
<b>24</b>(2), 123&ndash;140.
</p>
<p>Breiman, L. (2001). Random Forests. <em>Machine Learning</em>,
<b>45</b>(1), 5&ndash;32.
</p>
<p>Hastie, T., R. Tibshirani and J. Friedman (2001). <em>The Elements
of Statistical Learning</em> (2 ed.). New York, USA: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fvcm">fvcm</a></code>, <code><a href="#topic+tvcm-methods">tvcm-methods</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ------------------------------------------------------------------- #
## Dummy example 1:
##
## Fitting a random forest tvcm on artificially generated ordinal
## longitudinal data. The parameters 'maxstep = 1' and 'K = 2' are     
## chosen to restrict the computations.
## ------------------------------------------------------------------- # 

## load the data

data(vcrpart_1)

## fit and analyse the model

control &lt;-
  fvcolmm_control(mtry = 2, maxstep = 1, 
                  folds = folds_control(type = "subsampling", K = 2, prob = 0.75))

model.1 &lt;-
  fvcolmm(y ~ -1 + wave + vc(z3, z4, by = treat, intercept = TRUE) + re(1|id),
          family = cumulative(), subset = 1:100,
          data = vcrpart_1, control = control)

## estimating the out of bag loss
suppressWarnings(oobloss(model.1))

## predicting responses and varying coefficients for subject '27'
subs &lt;- vcrpart_1$id == "27"

## predict coefficients
predict(model.1, newdata = vcrpart_1[subs,], type = "coef")

## marginal response prediction
predict(model.1, vcrpart_1[subs,], "response", ranef = FALSE)

## conditional response prediction
re &lt;- matrix(5, 1, 1, dimnames = list("27", "(Intercept)"))
predict(model.1, vcrpart_1[subs,], "response", ranef = re)
predict(model.1, vcrpart_1[subs,], "response", ranef = 0 * re)

## predicting in-sample random effects
head(predict(model.1, type = "ranef"))

## fitted responses (marginal and conditional prediction)
head(predict(model.1, type = "response", ranef = FALSE))
head(predict(model.1, type = "response", ranef = TRUE))


## ------------------------------------------------------------------- #
## Dummy example 2:
##
## Fitting a random forest tvcm on artificially generated normally
## distributed data. The parameters 'maxstep = 3' and 'K = 3' are
## chosen to restrict the computations and 'minsize = 5' to obtain at
## least a few splits given the small sample size.
## ------------------------------------------------------------------- #

data(vcrpart_2)

## fit and analyse the model

control &lt;- fvcm_control(mtry = 1L, minsize = 5, maxstep = 3,
                        folds_control("subsampling", K = 3, 0.75))

model.2 &lt;- fvcglm(y ~ -1  + vc(z1, z2, by = x1, intercept = TRUE) + x2,
                  data = vcrpart_2,
                  family = gaussian(), subset = 1:50,control = control)

## estimating the out of bag loss
suppressWarnings(oobloss(model.2))

## predict the coefficient for individual cases
predict(model.2, vcrpart_2[91:100, ], "coef")
</code></pre>

<hr>
<h2 id='movie'>Movie critics</h2><span id='topic+movie'></span>

<h3>Description</h3>

<p>Movie critics of the Variety magazine. The data were
previously used to fit adjacent-categories mixed models by Hartzl et
al. (2001)</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(movie)</code></pre>


<h3>Format</h3>

<p>A data frame with 372 observations on 93 movies. Three vectors contain
information on 
</p>

<dl>
<dt><code>movie</code></dt><dd><p>movie ID.</p>
</dd>
<dt><code>critic</code></dt><dd><p>ordinal response on a 3 category scale, &quot;Con&quot; &lt;
&quot;Mixed&quot; &lt; &quot;Pro&quot;.</p>
</dd> 
<dt><code>review</code></dt><dd><p>critics, &quot;Medved&quot;, &quot;Ebert&quot;, &quot;Siskel&quot; and
&quot;Medved&quot;.</p>
</dd> 
</dl>



<h3>Source</h3>

<p>The data are tabulated in Hartzel et al. (2001).</p>


<h3>References</h3>

<p>Hartzel, J., A. Agresti and B. Caffo (2001). Multinomial Logit Random
Effect Models, <em>Statistical Modelling</em> <b>1</b>(2), 81&ndash;102.
</p>

<hr>
<h2 id='olmm'>Fitting ordinal and nominal two-stage linear mixed models</h2><span id='topic+family.olmm'></span><span id='topic+cumulative'></span><span id='topic+adjacent'></span><span id='topic+baseline'></span><span id='topic+olmm'></span>

<h3>Description</h3>

<p>Fits different types of two-stage linear mixed models for longitudinal 
(or clustered) ordinal (or multinomial) responses. O	ne-stage models 
are also allowed. Random effects are assumed to be multivariate normal  
distributed with expectation 0. At the time being, cumulative link 
models with the logit, probit or cauchy link, the baseline-category 
logit and the adjacent-category logit model are
implemented. Coefficients can be category-specific
(i.e. non-proportional odds effects) or global (i.e. proportional
odds, or parallel effects). 
</p>
<p>The function solves the score function for coefficients of the
marginal likelihood by using Gauss-Hermite quadrature (e.g., Hedeker; 
1994). Random effects are predicted by their expectation (see Hartzl
et al.; 2001). Standard deviations of parameter estimates are, by
default, based on the expected Fisher-information matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cumulative(link = c("logit", "probit", "cauchy"))
adjacent(link = "logit")
baseline(link = "logit")

olmm(formula, data, family = cumulative(), 
     weights, subset, na.action = na.omit,
     offset, contrasts, control = olmm_control(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model. This should be
something like
</p>
<p><code>y ~ ce(x1) + ge(x2) +re(1 + ge(w2) | id)</code> 
</p>
<p>where <code>ce(x1)</code> specifies that the predictor <code>x1</code> has a 
category-specific i.e. non-proportional odds effect and
<code>ge(x2)</code> that the predictor <code>x2</code> has global
i.e. proportional odds fixed effect, see <code><a href="#topic+ge">ge</a></code>,
resp. <code><a href="#topic+ce">ce</a></code>. Random effects are specified within the
<code><a href="#topic+re">re</a></code> term, where the variable <code>id</code> above behind
the vertical bar <code>|</code> defines the subject i.e. cluster
factor. Notice that only one subject factor is allowed. See details.</p>
</td></tr>   
<tr><td><code id="olmm_+3A_data">data</code></td>
<td>
<p>an optional data frame with the variables
in <code>formula</code>. By default the variables are taken from the 
environment from which <code>olmm</code> is called.</p>
</td></tr>
<tr><td><code id="olmm_+3A_family">family</code></td>
<td>
<p>an <code>family.olmm</code> object produced by
<code>cumulative</code>, <code>adjacent</code> or <code>baseline</code>.</p>
</td></tr>
<tr><td><code id="olmm_+3A_weights">weights</code></td>
<td>
<p>a numeric vector of weights with length equal the
number of observations. The weights should be constant for
subjects.</p>
</td></tr> 
<tr><td><code id="olmm_+3A_offset">offset</code></td>
<td>
<p>a matrix specifying the offset separately for each
predictor equation, of which there are the number of categories of 
the response minus one.</p>
</td></tr>
<tr><td><code id="olmm_+3A_subset">subset</code>, <code id="olmm_+3A_na.action">na.action</code>, <code id="olmm_+3A_contrasts">contrasts</code></td>
<td>
<p>further model
specification arguments as in <code><a href="stats.html#topic+lm">lm</a></code>.</p>
</td></tr> 
<tr><td><code id="olmm_+3A_control">control</code></td>
<td>
<p>a list of control parameters produced by
<code><a href="#topic+olmm_control">olmm_control</a></code>.</p>
</td></tr> 
<tr><td><code id="olmm_+3A_link">link</code></td>
<td>
<p>character string. The name of the link function.</p>
</td></tr>
<tr><td><code id="olmm_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code>control</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function can be used to fit simple ordinal two-stage
mixed effect models with up to 3-4 random effects. For
models with higher dimensions on random effects, the procedure may
not convergence (cf. Tutz; 1996). Coefficients for the
adjacent-category logit model are extracted via coefficient
transformation (e.g. Agresti; 2010). 
</p>
<p>The three implemented families are defined as follows:
<code><a href="#topic+cumulative">cumulative</a></code> is defined as the link of the sum of
probabilities of lower categories, e.g., for <code>link = "logit"</code>,
the logit of the sum of probabilities of lower
categories. <code><a href="#topic+adjacent">adjacent</a></code> is defined as the logit of 
the probability of the lower of two adjacent
categories. <code><a href="#topic+baseline">baseline</a></code> is defined as the logit of the
probability of a category with reference to the highest
category. Notice that the estimated coefficients of cumulative models 
may have the opposite sign those obtained with alternative software.  
</p>
<p>For alternative fitting functions, see for example the 
functions <code>clmm</code> of <span class="pkg">ordinal</span>,
<code>nplmt</code> of package <span class="pkg">mixcat</span>,
<code>DPolmm</code> of package <span class="pkg">DPpackage</span>, 
<code>lcmm</code> of package <span class="pkg">lcmm</span>,
<code>MCMCglmm</code> of package <span class="pkg">MCMCglmm</span> or
<code>OrdinalBoost</code> of package <span class="pkg">GMMBoost</span>. 
</p>
<p>The implementation adopts functions of the packages <span class="pkg">statmod</span>
(Novomestky, 2012) and <span class="pkg">matrixcalc</span> (Smyth et al., 2014), which 
is not visible for the user. The authors are grateful for these
codes.
</p>
<p>The <code>formula</code> argument specifies the model to be
fitted. Categorical regression models distinguish between global
effects (or proportional-odds effects), which are defined with
<code><a href="#topic+ge">ge</a></code> terms, and category-specific effects, which are
defined by <code><a href="#topic+ce">ce</a></code> terms. For undefined terms, the
function will use <code><a href="#topic+ge">ge</a></code> terms. Notice that this default
does not necessarily yield interpretable outputs. For example, for the
<code><a href="#topic+baseline">baseline</a></code> model you may use only <code><a href="#topic+ce">ce</a></code>
terms, which must be specified manually manually. See the example
below. For <code><a href="#topic+cumulative">cumulative</a></code> models at present it is not
possible to specifiy <code><a href="#topic+ce">ce</a></code> for the random effects
component because the internal, unconstraint integration would
yield unusable predictor values. 
</p>


<h3>Value</h3>

<p><code><a href="#topic+olmm">olmm</a></code> returns an object of class
<code><a href="#topic+olmm">olmm</a></code>. <code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+adjacent">adjacent</a></code> and <code><a href="#topic+baseline">baseline</a></code> yield an
object of class <code>family.olmm</code>. The <code><a href="#topic+olmm">olmm</a></code> class is
a list containing the following components: 
</p>
<table role = "presentation">
<tr><td><code>env</code></td>
<td>
<p>environment in which the object was built.</p>
</td></tr>  
<tr><td><code>frame</code></td>
<td>
<p>the model frame.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call to the function that created the object 
(class <code>"call"</code>).</p>
</td></tr> 
<tr><td><code>control</code></td>
<td>
<p>a list of class <code>olmm_control</code> produced by
<code><a href="#topic+olmm_control">olmm_control</a></code>.</p>
</td></tr>  
<tr><td><code>formula</code></td>
<td>
<p>the formula of the call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>a list of <code><a href="stats.html#topic+terms">terms</a></code> of the fitted model.</p>
</td></tr> 
<tr><td><code>family</code></td>
<td>
<p>an object of class <code>family.olmm</code> that specifies
that family of the fitted model.</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>(ordered) categorical response vector.</p>
</td></tr> 
<tr><td><code>X</code></td>
<td>
<p>model matrix for the fixed effects.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>model matrix for the random effects.</p>
</td></tr>
<tr><td><code>subject</code></td>
<td>
<p>a factor vector with grouping levels.</p>
</td></tr>
<tr><td><code>subjectName</code></td>
<td>
<p>variable name of the subject vector.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>numeric observations weights vector.</p>
</td></tr>
<tr><td><code>weights_sbj</code></td>
<td>
<p>numeric weights vector of length N.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>numeric offset matrix</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>(only where relevant) a list of levels of the
factors used in fitting.</p>
</td></tr> 
<tr><td><code>contrasts</code></td>
<td>
<p>(only where relevant) a list of contrasts
used.</p>
</td></tr> 
<tr><td><code>dims</code></td>
<td>
<p>a named integer of dimensions. Some of the
dimensions are <code class="reqn">n</code> is the number of observations, <code class="reqn">p</code> is
the number of fixed effects per predictor and <code class="reqn">q</code> is the total 
number of random effects.</p>
</td></tr>
<tr><td><code>fixef</code></td>
<td>
<p>a matrix of fixed effects (one column for each
predictor).</p>
</td></tr>
<tr><td><code>ranefCholFac</code></td>
<td>
<p>a lower triangular matrix. The cholesky
decomposition of the covariance matrix of the random effects.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a numeric vector of several fitted model
parameters</p>
</td></tr>
<tr><td><code>restricted</code></td>
<td>
<p>a logical vector indicating which elements
of the <code>coefficients</code> slot are restricted to an initial value 
at the estimation.</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>a matrix of unconditional linear predictors of
the fixed effects without random effects.</p>
</td></tr>  
<tr><td><code>u</code></td>
<td>
<p>a matrix of orthogonal standardized random
effects (one row for each subject level).</p>
</td></tr> 
<tr><td><code>logLik_obs</code></td>
<td>
<p>a numeric vector of log likelihood value
(one value for each observation).</p>
</td></tr>
<tr><td><code>logLik_sbj</code></td>
<td>
<p>a numeric vector of log likelihood values
(one value for each subject level).</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>a numeric value. The log likelihood of the
model.</p>
</td></tr> 
<tr><td><code>score_obs</code></td>
<td>
<p>a matrix of observation-wise partial
derivates of the marginal log-likelihood equation.</p>
</td></tr> 
<tr><td><code>score_sbj</code></td>
<td>
<p>a matrix of subject-wise partial derivates
of the marginal log-likelihood equation.</p>
</td></tr> 
<tr><td><code>score</code></td>
<td>
<p>a numeric vector of (total) partial derivates
of the log-Likelihood function.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>the information matrix (default is the expected
information).</p>
</td></tr>
<tr><td><code>ghx</code></td>
<td>
<p>a matrix of quadrature points for the
Gauss-Hermite quadrature integration.</p>
</td></tr> 
<tr><td><code>ghw</code></td>
<td>
<p>a matrix of weights for the Gauss-Hermite
quadrature integration.</p>
</td></tr> 
<tr><td><code>ranefElMat</code></td>
<td>
<p>a transformation matrix</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>a list of arguments for calling the optimizer
function.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a list of used control arguments produced by
<code><a href="#topic+olmm_control">olmm_control</a></code>.</p>
</td></tr> 
<tr><td><code>output</code></td>
<td>
<p>the output of the optimizer (class
<code>"list"</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Agresti, A. (2010). <em>Analysis of Ordinal Categorical Data</em> (2
ed.). New Jersey, USA: John Wiley &amp; Sons.
</p>
<p>Hartzel, J., A. Agresti and B. Caffo (2001). Multinomial Logit Random
Effect Models, <em>Statistical Modelling</em> <b>1</b>(2), 81&ndash;102.
</p>
<p>Hedeker, D. and R. Gibbons (1994). A Random-Effects Ordinal
Regression Model for Multilevel Analysis, <em>Biometrics</em>
<b>20</b>(4), 933&ndash;944. 
</p>
<p>Tutz, G. and W. Hennevogl (1996). Random Effects in Ordinal Regression 
Models, <em>Computational Statistics &amp; Data Analysis</em> <b>22</b>(5),
537&ndash;557. 
</p>
<p>Tutz, G. (2012). <em>Regression for Categorical Data</em>. New York,
USA: Cambridge Series in Statistical and Probabilistic Mathematics.
</p>
<p>Novomestky, F. (2012). matrixcalc: Collection of Functions for 
Matrix Calculations. R package version 1.0-3. URL 
<a href="https://CRAN.R-project.org/package=matrixcalc">https://CRAN.R-project.org/package=matrixcalc</a>
</p>
<p>Smyth, G., Y. Hu, P. Dunn, B. Phipson and Y. Chen (2014). statmod:
Statistical Modeling. R package version 1.4.20. URL
<a href="https://CRAN.R-project.org/package=statmod">https://CRAN.R-project.org/package=statmod</a> 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm-methods">olmm-methods</a></code>, <code><a href="#topic+olmm_control">olmm_control</a></code>,
<code><a href="base.html#topic+ordered">ordered</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Example 1: Schizophrenia
##
## Estimating the cumulative mixed models of
## Agresti (2010) chapters 10.3.1
## ------------------------------------------------------------------- #

data(schizo)

model.10.3.1 &lt;-
  olmm(imps79o ~ tx + sqrt(week) + re(1|id),
       data = schizo, family = cumulative())

summary(model.10.3.1)

## ------------------------------------------------------------------- #
## Example 2: Movie critics
##
## Estimating three of several adjacent-categories
## mixed models of Hartzl et. al. (2001)
## ------------------------------------------------------------------- #

data(movie)

## model with category-specific effects for "review"
model.24.1 &lt;- olmm(critic ~ ce(review) + re(1|movie, intercept = "ce"),
                   data = movie, family = adjacent())

summary(model.24.1)
</code></pre>

<hr>
<h2 id='olmm-control'>Control parameters for <code><a href="#topic+olmm">olmm</a></code>.</h2><span id='topic+olmm-control'></span><span id='topic+olmm_control'></span>

<h3>Description</h3>

<p>Various parameters that control aspects for <code><a href="#topic+olmm">olmm</a></code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olmm_control(fit = c("nlminb", "ucminf", "optim"), 
             doFit = TRUE, numGrad = FALSE, 
             numHess = numGrad, nGHQ = 7L,
             start = NULL, restricted = NULL, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm-control_+3A_fit">fit</code></td>
<td>
<p>character string. The name of the function to be used for the 
optimization. Can be one of <code>"nlminb"</code>, <code>"ucminf"</code>, <code>"optim"</code></p>
</td></tr>
<tr><td><code id="olmm-control_+3A_dofit">doFit</code></td>
<td>
<p>logical scalar. When <code>FALSE</code> an unfitted
<code><a href="#topic+olmm">olmm</a></code> object is returned.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_numgrad">numGrad</code></td>
<td>
<p>logical scalar indicating whether the score function
should be retrieved numerically.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_numhess">numHess</code></td>
<td>
<p>logical scalar. Indicates whether the Hess matrix for
the variance-covariance matrix should be estimated numerically,
which is an approximation of the observed Fisher information. Must
be <code>TRUE</code> if <code>numGrad</code> is <code>TRUE</code>. See details.</p>
</td></tr> 
<tr><td><code id="olmm-control_+3A_nghq">nGHQ</code></td>
<td>
<p>a positive integer specifying the number of quadrature
points for the approximation of the marginal Likelihood by numerical
integration.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_start">start</code></td>
<td>
<p>a named numeric vector of initial values for the
parameters. The parameter must be named in exactly in the way as
they appear when the model is fitted.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_restricted">restricted</code></td>
<td>
<p>a character vector of names of coefficients to be
restricted to the initial values. The argument is ignored in case of
adjacent category models.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_verbose">verbose</code></td>
<td>
<p>logical scalar. If <code>TRUE</code> verbose output is
generated during the optimization of the parameter estimates.</p>
</td></tr>
<tr><td><code id="olmm-control_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>fit</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Initial values may decrease the computation time and avoid
divergence. The <code>start</code> argument accepts a vector with named
elements according to the column names of the
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code>. At the time being, initial values for
adjacent-categories models must be transformed into the
baseline-category model form.
</p>
<p>Notice that an additional argument <code>control</code>, e.g.,
<code>control = list(trace = 1)</code>, can be passed access control
parameters of the optimizers. For arguments, see
<code><a href="ucminf.html#topic+ucminf">ucminf</a></code>, <code><a href="stats.html#topic+nlminb">nlminb</a></code> or
<code><a href="stats.html#topic+optim">optim</a></code>.   
</p>


<h3>Value</h3>

<p>A list of class <code><a href="#topic+olmm_control">olmm_control</a></code> containing
the control parameters.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>olmm_control(doFit = FALSE)
</code></pre>

<hr>
<h2 id='olmm-gefp'>Methods for score processes of <code><a href="#topic+olmm">olmm</a></code> objects</h2><span id='topic+olmm-gefp'></span><span id='topic+olmm_gefp'></span><span id='topic+predecor_control'></span><span id='topic+olmm_estfun'></span>

<h3>Description</h3>

<p>Methods to extract and pre-decorrelate the (negative)
marginal maximum likelihood observation scores and compute the
standardized cumulative score processes of a fitted
<code><a href="#topic+olmm">olmm</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>olmm_estfun(x, predecor = FALSE, control = predecor_control(),
            nuisance = NULL, ...)

predecor_control(impute = TRUE, seed = NULL, 
                 symmetric = TRUE, center = FALSE,
                 reltol = 1e-6,
                 maxit = 250L, minsize = 1L,
                 include = c("observed", "all"),
                 verbose = FALSE, silent = FALSE)

olmm_gefp(object, scores = NULL, order.by = NULL, subset = NULL,
          predecor = TRUE, parm = NULL, center = TRUE, drop = TRUE,
          silent = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm-gefp_+3A_x">x</code>, <code id="olmm-gefp_+3A_object">object</code></td>
<td>
<p>a fitted <code><a href="#topic+olmm">olmm</a></code> object.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_predecor">predecor</code></td>
<td>
<p>logical scalar. Indicates whether the within-subject
correlation of the estimating equations should be removed by a linear
transformation. See details.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_control">control</code></td>
<td>
<p>a list of control parameter as produced by
<code><a href="#topic+predecor_control">predecor_control</a></code>.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_nuisance">nuisance</code></td>
<td>
<p>integer vector. Defines the coefficients which are
regarded as nuisance and therefore omitted from the transformation.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_impute">impute</code></td>
<td>
<p>logical scalar. Whether missing values should be
replaced using imputation.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_seed">seed</code></td>
<td>
<p>an integer scalar. Specifies the random number used for
the <code>set.seed</code> call before the imputation. If set to
<code>NULL</code>, <code>set.seed</code> is not processed.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_symmetric">symmetric</code></td>
<td>
<p>logical scalar. Whether the transformation matrix
should be symmetric.</p>
</td></tr> 
<tr><td><code id="olmm-gefp_+3A_minsize">minsize</code></td>
<td>
<p>integer scalar. The minimum number of observations for
which entries in the transformation should be computed. Higher
values will lead to lower accuracy but stabilize the computation.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_reltol">reltol</code></td>
<td>
<p>convergence tolerance used to compute the transformation
matrix.</p>
</td></tr> 
<tr><td><code id="olmm-gefp_+3A_maxit">maxit</code></td>
<td>
<p>the maximum number of iterations used to compute the
transformation matrix.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_silent">silent</code></td>
<td>
<p>logical scalar. Should the report of warnings be
suppressed?</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_include">include</code></td>
<td>
<p>logical scalar. Whether the transformation matrix
should be computed based on the scores corresponding to observations
(option <code>"observed"</code>) or on all scores (option <code>"all"</code>),
including the imputed values.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_verbose">verbose</code></td>
<td>
<p>logical scalar. Produces messages.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_scores">scores</code></td>
<td>
<p>a function or a matrix. Function to extract the
estimating equations from <code>object</code> or a matrix representing the
estimating equations. If <code>NULL</code> (default), the
<code><a href="#topic+olmm_estfun">olmm_estfun</a></code> function will be used with
argument <code>predecor</code> and additional arguments from <code>...</code>.</p>
</td></tr> 
<tr><td><code id="olmm-gefp_+3A_order.by">order.by</code></td>
<td>
<p>a numeric or factor vector. The explanatory variable
to be used to order the entries in the estimating equations. If set
to <code>NULL</code> (the default) the observations are assumed to be
ordered.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_subset">subset</code></td>
<td>
<p>logical vector. For extracts the subset of the
estimating equations to be used.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_parm">parm</code></td>
<td>
<p>integer, logical or a character vector. Extracts the
columns of the estimating equations.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_center">center</code></td>
<td>
<p>logical scalar. <code>TRUE</code> subtracts, if necessary, the 
column means of the estimating equations.</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_drop">drop</code></td>
<td>
<p>logical. Whether singularities should be handled
automatically (otherwise singularities yield an error).</p>
</td></tr>
<tr><td><code id="olmm-gefp_+3A_...">...</code></td>
<td>
<p>arguments passed to other
functions. <code><a href="#topic+olmm_gefp">olmm_gefp</a></code> passes these arguments to
<code>scores</code> if <code>scores</code> is a function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Complements the <code>estfun</code> method of the package <span class="pkg">sandwich</span>
and the <code>gefp</code> function of the package <span class="pkg">strucchange</span> for
<code><a href="#topic+olmm">olmm</a></code> objects. <code><a href="#topic+olmm_estfun">olmm_estfun</a></code> allows to
pre-decorrelate the intra-individual correlation of observation
scores, see the argument <code>predecor</code>. The value returned by
<code>olmm_gefp</code> may be used for testing coefficient constancy
regarding an explanatory variable <code>order.by</code> by the
<code>sctest</code> function of package <span class="pkg">strucchange</span>, see the
examples below. 
</p>
<p>If <code>predecor = TRUE</code> in <code><a href="#topic+olmm_estfun">olmm_estfun</a></code>, a linear
within-subject transformation is applied that removes (approximately) 
the intra-subject correlation from the scores. Backgrounds are
provided by Burgin and Ritschard (2014a).
</p>
<p>Given a score matrix produced by <code><a href="#topic+olmm_estfun">olmm_estfun</a></code>, the
empirical fluctuation process can be computed by
<code><a href="#topic+olmm_gefp">olmm_gefp</a></code>. See Zeileis and Hornik
(2007). <code><a href="#topic+olmm_gefp">olmm_gefp</a></code> provides with <code>subset</code> and
<code>parm</code> arguments specifically designed for nodewise tests in the
<code><a href="#topic+tvcm">tvcm</a></code> algorithm. Using <code>subset</code> extracts the
partial fluctuation process of the selected subset. Further,
<code>center = TRUE</code> makes sure that the partial fluctuation process
(starts and) ends with zero.   
</p>


<h3>Value</h3>

<p><code><a href="#topic+predecor_control">predecor_control</a></code> returns a list of control parameters
for computing the pre-decorrelation transformation
matrix. <code><a href="#topic+olmm_estfun">olmm_estfun</a></code> returns a <code><a href="base.html#topic+matrix">matrix</a></code>
with the estimating equations and <code><a href="#topic+olmm_gefp">olmm_gefp</a></code> a list of
class class <code>"gefp"</code>.  
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for
Parameter Instability, <em>Statistica Neerlandica</em>, <b>61</b>(4),
488&ndash;508. 
</p>
<p>Burgin R. and Ritschard G. (2015), Tree-Based Varying Coefficient 
Regression for Longitudinal Ordinal Responses. <em>Computational
Statistics &amp; Data Analysis</em>, <b>86</b>, 65&ndash;80.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example :
##
## Testing coefficient constancy on 'z4' of the 'vcrpart_1' data.
## ------------------------------------------------------------------- #

data(vcrpart_1)

## extract a unbalanced subset to show to the full functionality of estfun
vcrpart_1 &lt;- vcrpart_1[-seq(1, 100, 4),]
subset &lt;- vcrpart_1$wave != 1L ## obs. to keep for fluctuation tests
table(table(vcrpart_1$id))

## fit the model
model &lt;- olmm(y ~ treat + re(1|id), data = vcrpart_1)

## extract and pre-decorrelate the scores
scores &lt;- olmm_estfun(
  model, predecor = TRUE,
  control = predecor_control(verbose = TRUE))
attr(scores, "T") # transformation matrix

## compute the empirical fluctuation process
fp &lt;- olmm_gefp(model, scores, order.by = vcrpart_1$z4)

## process a fluctuation test
library(strucchange)
sctest(fp, functional = catL2BB(fp))
</code></pre>

<hr>
<h2 id='olmm-methods'>Methods for <code><a href="#topic+olmm">olmm</a></code> objects</h2><span id='topic+olmm-methods'></span><span id='topic+anova.olmm'></span><span id='topic+coefficients.olmm'></span><span id='topic+coef.olmm'></span><span id='topic+deviance.olmm'></span><span id='topic+formula.olmm'></span><span id='topic+fixef'></span><span id='topic+fixef.glm'></span><span id='topic+fixef.olmm'></span><span id='topic+getCall.olmm'></span><span id='topic+logLik.olmm'></span><span id='topic+model.frame.olmm'></span><span id='topic+model.matrix.olmm'></span><span id='topic+neglogLik2'></span><span id='topic+neglogLik2.olmm'></span><span id='topic+ranef'></span><span id='topic+ranef.olmm'></span><span id='topic+ranefCov'></span><span id='topic+ranefCov.olmm'></span><span id='topic+resid.olmm'></span><span id='topic+residuals.olmm'></span><span id='topic+simulate.olmm'></span><span id='topic+terms.olmm'></span><span id='topic+update.olmm'></span><span id='topic+VarCorr'></span><span id='topic+VarCorr.olmm'></span><span id='topic+print.VarCorr.olmm'></span><span id='topic+vcov.olmm'></span><span id='topic+weights.olmm'></span>

<h3>Description</h3>

<p>Standard methods for computing on <code><a href="#topic+olmm">olmm</a></code>
objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'olmm'
anova(object, ...)

## S3 method for class 'olmm'
coef(object, which = c("all", "fe"), ...)

## S3 method for class 'olmm'
fixef(object, which = c("all", "ce", "ge"), ...)

## S3 method for class 'olmm'
model.matrix(object, which = c("fe", "fe-ce", "fe-ge",
             "re", "re-ce", "re-ge"), ...)

## S3 method for class 'olmm'
neglogLik2(object, ...)

## S3 method for class 'olmm'
ranef(object, norm = FALSE, ...)

## S3 method for class 'olmm'
ranefCov(object, ...) 

## S3 method for class 'olmm'
simulate(object, nsim = 1, seed = NULL,
         newdata = NULL, ranef = TRUE, ...)

## S3 method for class 'olmm'
terms(x, which = c("fe-ce", "fe-ge", "re-ce", "re-ge"), ...)

## S3 method for class 'olmm'
VarCorr(x, sigma = 1., ...)

## S3 method for class 'olmm'
weights(object, level = c("observation", "subject"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm-methods_+3A_object">object</code>, <code id="olmm-methods_+3A_x">x</code></td>
<td>
<p>an <code><a href="#topic+olmm">olmm</a></code> object.</p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_which">which</code></td>
<td>
<p>optional character string. For  <code><a href="stats.html#topic+coef">coef</a></code> and
<code><a href="#topic+fixef">fixef</a></code>, it indicates whether <code>"all"</code>
coefficients, the fixed effects <code>"fe"</code>, the category-specific
fixed effects <code>"ce"</code> (i.e. non-proportional odds) or the global
fixed effects <code>"ge"</code> (i.e. proportional odds) should be
extracted. For <code>model.matrix</code> it indicates whether the model
matrix of the fixed- (<code>"fe"</code>) or the random effects (<code>"re"</code>)
should be extracted.</p>
</td></tr> 
<tr><td><code id="olmm-methods_+3A_level">level</code></td>
<td>
<p>character string. Whether the results should be on the
observation level (<code>level = "observation"</code>) or on the subject
level (<code>level = "subject"</code>).</p>
</td></tr> 
<tr><td><code id="olmm-methods_+3A_norm">norm</code></td>
<td>
<p>logical. Whether residuals should be divided by their
standard deviation.</p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_nsim">nsim</code></td>
<td>
<p>number of response vectors to simulate.  Defaults to 1.</p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_seed">seed</code></td>
<td>
<p>an object specifying if and how the random number
generator should be initialized. See <code><a href="stats.html#topic+simulate">simulate</a></code></p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_newdata">newdata</code></td>
<td>
<p>a data frame with predictor variables.</p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_ranef">ranef</code></td>
<td>
<p>either a logical or a matrix (see
<code><a href="#topic+predict.olmm">predict.olmm</a></code>). Whether the simulated responses should
be conditional on random effects. If <code>TRUE</code>, the <code>newdata</code>
data frame must contain the subject identification
variable. Further, if all subjects in <code>newdata</code> are in
<code>object</code>, the simulation will be based on the estimated random
effects as obtained with <code><a href="#topic+ranef">ranef</a></code>. If any subject in
<code>newdata</code> is not in <code>object</code> the random effects are
simulated.</p>
</td></tr>
<tr><td><code id="olmm-methods_+3A_sigma">sigma</code></td>
<td>
<p>ignored but obligatory argument from original generic.</p>
</td></tr> 
<tr><td><code id="olmm-methods_+3A_...">...</code></td>
<td>
<p>potential further arguments passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="stats.html#topic+anova">anova</a></code> implements log-likelihood ratio tests for model  
comparisons, based on the marginal likelihood. At the time being, 
at least two models must be assigned.
</p>
<p><code><a href="#topic+neglogLik2">neglogLik2</a></code> returns the marginal maximum likelihood of the
fitted model times minus 2. 
</p>
<p><code><a href="#topic+ranefCov">ranefCov</a></code> extracts the variance-covariance matrix of
the random effects. Similarly, <code><a href="#topic+VarCorr">VarCorr</a></code> extracts the
estimated variances, standard deviations and correlations of the
random effects.  
</p>
<p><code><a href="stats.html#topic+resid">resid</a></code> extracts the residuals of Li and Sheperd
(2012). By default, the marginal outcome distribution is used to
compute these residuals. The conditional residuals can be computed by
assigning <code>ranef = TRUE</code> as a supplementary argument.   
</p>
<p><code><a href="stats.html#topic+simulate">simulate</a></code> simulates ordinal responses based on the
input model. 
</p>
<p>Further, undocumented methods are <code><a href="stats.html#topic+deviance">deviance</a></code>,
<code><a href="stats.html#topic+extractAIC">extractAIC</a></code>, <code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+formula">formula</a></code>, <code><a href="stats.html#topic+getCall">getCall</a></code>,
<code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+model.frame">model.frame</a></code>,
<code><a href="stats.html#topic+nobs">nobs</a></code>, <code><a href="stats.html#topic+update">update</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>.  
</p>
<p>The <code><a href="stats.html#topic+anova">anova</a></code> implementation is based on codes of the 
<span class="pkg">lme4</span> package. The authors are grateful for these codes. 
</p>


<h3>Value</h3>

<p>The <code><a href="#topic+anova.olmm">anova.olmm</a></code> method returns an object of class
<code>anova</code>, see also <code><a href="stats.html#topic+anova">anova</a></code>.
</p>
<p>The <code><a href="#topic+coef.olmm">coef.olmm</a></code>, <code><a href="#topic+coefficients.olmm">coefficients.olmm</a></code>,
<code><a href="#topic+fixef">fixef</a></code>, <code><a href="#topic+fixef.glm">fixef.glm</a></code> and
<code><a href="#topic+fixef.olmm">fixef.olmm</a></code> methods return named <code>numeric</code>
vectors. See also <code><a href="stats.html#topic+coef">coef</a></code> and
<code><a href="stats.html#topic+coefficients">coefficients</a></code>. 
</p>
<p>The <code><a href="#topic+deviance.olmm">deviance.olmm</a></code> method returns a single numeric,
see also <code><a href="stats.html#topic+deviance">deviance</a></code>.
</p>
<p>The <code><a href="#topic+formula.olmm">formula.olmm</a></code> method extracts the model formula,
which is an object of class <code>formula</code>. See also
<code><a href="stats.html#topic+formula">formula</a></code>. 
</p>
<p>The <code><a href="#topic+getCall.olmm">getCall.olmm</a></code> method extracts the call for fitting
the model, which is an object of class <code>call</code>. See also
<code><a href="base.html#topic+call">call</a></code>. 
</p>
<p>The <code><a href="#topic+logLik.olmm">logLik.olmm</a></code> method returns an object of class
<code>logLik</code>, which is a single numeric with a few attributes. See
also <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>
<p>The <code><a href="#topic+neglogLik2">neglogLik2</a></code> and <code><a href="#topic+neglogLik2.olmm">neglogLik2.olmm</a></code>
methods return a single numeric.  
</p>
<p>The <code><a href="#topic+model.frame.olmm">model.frame.olmm</a></code> and
<code><a href="#topic+model.matrix.olmm">model.matrix.olmm</a></code> methods return the model frame and
the model matrix of the <code>olmm</code> object. See also
<code><a href="stats.html#topic+model.frame">model.frame</a></code> and <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>.
</p>
<p>The <code><a href="#topic+ranef">ranef</a></code> and <code><a href="#topic+ranef.olmm">ranef.olmm</a></code> methods
return a matrix with the estimated random effects.
</p>
<p>The <code><a href="#topic+ranefCov">ranefCov</a></code> and <code><a href="#topic+ranefCov.olmm">ranefCov.olmm</a></code>
methods return an object of class <code>matrix</code>. The
<code><a href="#topic+VarCorr">VarCorr</a></code> and <code><a href="#topic+VarCorr.olmm">VarCorr.olmm</a></code> methods
return an object of class
<code>VarCorr.olmm</code>. <code><a href="#topic+print.VarCorr.olmm">print.VarCorr.olmm</a></code> returns an
object of class <code>VarCorr.olmm</code>.
</p>
<p>The <code><a href="#topic+resid.olmm">resid.olmm</a></code> and <code><a href="#topic+residuals.olmm">residuals.olmm</a></code>
methods return a numeric vector.
</p>
<p>The <code><a href="#topic+simulate.olmm">simulate.olmm</a></code> method returns a <code>data.frame</code>
including simulated responses based on the input model.
</p>
<p>The <code><a href="#topic+terms.olmm">terms.olmm</a></code> method returns an object of class
<code>terms</code>. See also <code><a href="stats.html#topic+terms">terms</a></code>.
</p>
<p>The <code><a href="#topic+update.olmm">update.olmm</a></code> method will update and (by default)
re-fit a model. It returns an object of class <code>olmm</code>. See also
<code><a href="stats.html#topic+update">update</a></code>. 
</p>
<p>The <code><a href="#topic+vcov.olmm">vcov.olmm</a></code> method extracts a <code>matrix</code> with
the variances and covariances of the fixed effects of the model. See
also <code><a href="stats.html#topic+vcov">vcov</a></code>.
</p>
<p>The <code><a href="#topic+weights.olmm">weights.olmm</a></code> method extracts a <code>numeric</code>
vector with the model weights. See also <code><a href="stats.html#topic+weights">weights</a></code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Agresti, A. (2010). <em>Analysis of Ordinal Categorical Data</em> (2
ed.). New Jersey, USA: John Wiley &amp; Sons.
</p>
<p>Tutz, G. (2012). <em>Regression for Categorical Data</em>. New York,
USA: Cambridge Series in Statistical and Probabilistic Mathematics. 
</p>
<p>Li, C. and B. E. Sheperd (2012). A New Residual for Ordinal
Outcomes, <em>Biometrika</em>, <b>99</b>(2), 437&ndash;480.
</p>
<p>Bates, D., M. Maechler, B. M. Bolker and S. Walker (2015). Fitting
Linear Mixed-Effects Models Using lme4, <em>Journal of Statistical
Software</em>, <b>67</b>(1), 1&ndash;48.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code>, <code><a href="#topic+predict.olmm">predict.olmm</a></code>,
<code><a href="#topic+olmm_gefp">olmm_gefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## --------------------------------------------------------- #
## Example: Schizophrenia (see also example of 'olmm')
## --------------------------------------------------------- #

data(schizo)

schizo &lt;- schizo[1:181,]
schizo$id &lt;- droplevels(schizo$id)

## anova comparison
## ----------------

## fit two alternative models for the 'schizo' data
model.0 &lt;- olmm(imps79o ~ tx + sqrt(week) + re(1|id), schizo)
model.1 &lt;- olmm(imps79o ~ tx + sqrt(week)+tx*sqrt(week)+re(1|id),schizo)
anova(model.0, model.1)

## simulate responses
## ------------------

## simulate responses based on estimated random effects
simulate(model.0, newdata = schizo[1, ], ranef = TRUE, seed = 1)
simulate(model.0, newdata = schizo[1, ], seed = 1,
         ranef = ranef(model.0)[schizo[1, "id"],,drop=FALSE])
## simulate responses based on simulated random effects
newdata &lt;- schizo[1, ]
newdata$id &lt;- factor("123456789")
simulate(model.0, newdata = newdata, ranef = TRUE)

## other methods
## -------------

coef(model.1)
fixef(model.1)
head(model.matrix(model.1, "fe-ge"))
head(weights(model.1))
ranefCov(model.1)
head(resid(model.1))
terms(model.1, "fe-ge")
VarCorr(model.1)
head(weights(model.1, "subject"))
</code></pre>

<hr>
<h2 id='olmm-predict'>Predict outcome probabilities and responses for
<code><a href="#topic+olmm">olmm</a></code> objects</h2><span id='topic+olmm-predict'></span><span id='topic+fitted.olmm'></span><span id='topic+predict.olmm'></span>

<h3>Description</h3>

<p><code>fitted</code> and <code>predict</code> method for
<code><a href="#topic+olmm">olmm</a></code> objects. The function implements mainly the 
prediction methods of Skrondal and Rabe-Hesketh (2009).</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'olmm'
fitted(object, ...)

## S3 method for class 'olmm'
predict(object, newdata = NULL,
        type = c("link", "response", "prob", "class", "ranef"),
        ranef = FALSE, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm-predict_+3A_object">object</code></td>
<td>
<p>a fitted <code><a href="#topic+olmm">olmm</a></code> object.</p>
</td></tr>
<tr><td><code id="olmm-predict_+3A_newdata">newdata</code></td>
<td>
<p>data frame for which to evaluate predictions.</p>
</td></tr>
<tr><td><code id="olmm-predict_+3A_type">type</code></td>
<td>
<p>character string. <code>type = "response"</code> and 
<code>type = "prob"</code> yield response probabilities, 
<code>type = "class"</code> the response category with highest 
probability and <code>type = "link"</code> the linear predictor
matrix. <code>type = "ranef"</code> yields the predicted random effects,
see <code><a href="#topic+ranef.olmm">ranef.olmm</a></code>.</p>
</td></tr>
<tr><td><code id="olmm-predict_+3A_ranef">ranef</code></td>
<td>
<p>logical or numeric matrix. See details.</p>
</td></tr> 
<tr><td><code id="olmm-predict_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values for fixed effects in <code>newdata</code>. The default is to
predict <code>NA</code>: see <code><a href="stats.html#topic+na.pass">na.pass</a></code>.</p>
</td></tr> 
<tr><td><code id="olmm-predict_+3A_...">...</code></td>
<td>
<p>optional additional parameters. Includes <code>offset</code> and
<code>subset</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>If <code>type = "link"</code> and <code>ranef = FALSE</code>, the fixed 
effects components are computed. The random effect components are ignored.
</p>
<p>If <code>type = "link"</code> and <code>ranef = TRUE</code>, the fixed effect components 
plus the random effect components are computed. The function will look for 
whether random coefficients are available for the subjects (i.e. clusters) 
in <code>newdata</code>. If so, it extracts the corresponding random effects as
obtained by <code><a href="#topic+ranef">ranef</a></code>. For new subjects in <code>newdata</code> the 
random effects are set to zero. If <code>newdata</code> does not contain a subject
vector, the random effects are set to zero.
</p>
<p>If <code>type = "link"</code> and <code>ranef</code> is a matrix, the fixed effect 
components plus the random effect components with the random coefficients 
from the assigned matrix are computed. Notice that <code>newdata</code> should 
contain a subject vector to assign the random coefficients. This prediction 
method is, amongst others, proposed in Skrondal and Rabe-Hesketh (2009), 
Sec. 7.1. 
</p>
<p>The two options <code>type = "response"</code> and <code>type = "prob"</code> are 
identical and <code>type = "class"</code> extracts the response category 
with the highest probability. Hence, the prediction mechanism is the 
same for all three options.
</p>
<p>Given <code>newdata</code> contains a subject vector, <code>type = "response"</code> 
combined with <code>ranef = FALSE</code> yields for new subjects the 
population-averaged response probabilities (Skrondal and Rabe-Hesketh, Sec. 7.2) 
and for existing subjects the cluster-averaged prediction (Skrondal and 
Rabe-Hesketh 2009, Sec. 7.3). If no subject vector is assigned the function 
assumes that all subjects are new and therefore yields the population-averaged 
response probabilities (Skrondal and Rabe-Hesketh 2009, Sec. 7.2).
</p>
<p>The option <code>type = "response"</code> combined with <code>ranef = TRUE</code> 
works equivalent to <code>type = "link"</code> combined with <code>ranef = TRUE</code>. 
</p>
<p>If the model does not contain random effects, the argument <code>ranef</code> is 
ignored.
</p>


<h3>Value</h3>

<p>A matrix or a vector of predicted values or response probabilities. 
</p>


<h3>Note</h3>

<p>The method can not yet handle new categories in categorical predictors
and will return an error. 
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Skrondal, A., S. Rabe-Hesketh (2009). Prediction in Multilevel
Generalized Linear Models. <em>Journal of the Royal Statistical
Society A</em>, <b>172</b>(3), 659&ndash;687.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code>, <code><a href="#topic+olmm-methods">olmm-methods</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Example: Schizophrenia
## ------------------------------------------------------------------- #

data(schizo)

## omit subject 1103 and the last observations of 1104 and 1105 
subs &lt;- c(1:4, 8, 11)

dat.train &lt;- schizo[-subs, ] # training data
dat.valid &lt;- schizo[ subs, ] # test data

## fit the model
model &lt;- olmm(imps79o ~ tx + sqrt(week) + tx:sqrt(week) + re(1|id), dat.train)

## prediction on the predictor scale
## ---------------------------------

## random effects are set equal zero
predict(model, newdata = dat.valid, type = "link", ranef = FALSE)

## .. or equally with self-defined random effects
ranef &lt;- matrix(0, 3, 1)
rownames(ranef) &lt;- c("1103", "1104", "1105")
predict(model, newdata = dat.valid, type = "link", ranef = ranef)

## use random effects for the subjects 1104 and 1105. 
predict(model, newdata = dat.valid, type = "link", ranef = TRUE)

## prediction on the response scale
## --------------------------------

## use random effects for the subjects 1104 and 1105. 
predict(model, newdata = dat.valid, type = "response", ranef = FALSE)
predict(model, newdata = dat.valid, type = "prob", ranef = FALSE) # .. or, equally
predict(model, newdata = dat.valid, type = "class", ranef = FALSE)

## treat all individuals as new (subject vector is deleted)
predict(model, newdata = dat.valid[,-1], type = "response", ranef = FALSE)

## use random effects for the subjects 1104 and 1105. 
predict(model, newdata = dat.valid, type = "response", ranef = TRUE)

## use self defined random effects
ranef &lt;- matrix(0, 3, 1)
rownames(ranef) &lt;- c("1103", "1104", "1105")
predict(model, newdata = dat.valid, type = "response", ranef = ranef)

## predict random effects
## ----------------------

head(predict(model, type = "ranef"))
head(ranef(model)) # .. or, equally
</code></pre>

<hr>
<h2 id='olmm-summary'>Printing and summarizing <code><a href="#topic+olmm">olmm</a></code> objects</h2><span id='topic+olmm-summary'></span><span id='topic+summary.olmm'></span><span id='topic+print.summary.olmm'></span><span id='topic+print.olmm'></span>

<h3>Description</h3>

<p>Generates summary results of a fitted <code><a href="#topic+olmm">olmm</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'olmm'
summary(object, etalab = c("int", "char", "eta"),
        silent = FALSE, ...)

## S3 method for class 'olmm'
print(x, etalab = c("int", "char", "eta"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="olmm-summary_+3A_object">object</code>, <code id="olmm-summary_+3A_x">x</code></td>
<td>
<p>a fitted <code><a href="#topic+olmm">olmm</a></code> object.</p>
</td></tr>
<tr><td><code id="olmm-summary_+3A_etalab">etalab</code></td>
<td>
<p>character. Whether category-specific effects should be 
labeled by integers of categories (default), the labels of the 
categories or the index of the predictor.</p>
</td></tr>
<tr><td><code id="olmm-summary_+3A_silent">silent</code></td>
<td>
<p>logical: should a warning be reported if the computation 
of the covariance matrix for the estimated coefficients failed.</p>
</td></tr>
<tr><td><code id="olmm-summary_+3A_...">...</code></td>
<td>
<p>additional arguments passed to print.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>summary</code> method returns a list of class
<code>"summary.olmm"</code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code>, <code><a href="#topic+olmm-methods">olmm-methods</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example:
##
## Printing the summary of a model on artificially generated data.
## ------------------------------------------------------------------- #

data(vcrpart_1)

model &lt;- olmm(y ~ wave + z4:treat + re(1|id), vcrpart_1, subset = 1:60)

print(model, digits = 2)

summary(model, digits = 2)
</code></pre>

<hr>
<h2 id='otsplot'>Time-series plot for longitudinal ordinal data</h2><span id='topic+otsplot'></span><span id='topic+otsplot.default'></span><span id='topic+otsplot_control'></span><span id='topic+otsplot_filter'></span>

<h3>Description</h3>

<p>Plots multiple ordinal sequences in a <code class="reqn">x</code> (usually
time) versus <code class="reqn">y</code> (response variable) scatterplot. The sequences 
are displayed by jittered frequency-weighted parallel lines.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## Default S3 method:
otsplot(x, y, subject, weights, groups,
        control = otsplot_control(), filter = NULL, 
        main, xlab, ylab, xlim, ylim, ...)

otsplot_control(cex = 1, lwd = 1/4, col = NULL,
                hide.col = grey(0.8), seed = NULL,
                lorder = c("background", "foreground") ,
                lcourse = c("upwards", "downwards"),
                grid.scale = 1/5, grid.lwd = 1/2,
                grid.fill =  grey(0.95), grid.col = grey(0.6),          
                layout = NULL, margins = c(5.1, 4.1, 4.1, 3.1),
                strip.fontsize = 12, strip.fill =  grey(0.9),
                pop = TRUE, newpage = TRUE, maxit = 500L)

otsplot_filter(method = c("minfreq", "cumfreq", "linear"), level = NULL) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="otsplot_+3A_x">x</code></td>
<td>
<p>a <code>numeric</code> or <code>factor</code> vector for the <code>x</code>
axis, e.g. time.</p>
</td></tr>  
<tr><td><code id="otsplot_+3A_y">y</code></td>
<td>
<p>an <code>ordered</code> factor vector for the <code>y</code> axis.</p>
</td></tr> 
<tr><td><code id="otsplot_+3A_subject">subject</code></td>
<td>
<p>a <code>factor</code> vector that identifies the subject,
i.e., allocates elements in <code>x</code> and <code>y</code> to the subject
i.e. observation unit.</p>
</td></tr> 
<tr><td><code id="otsplot_+3A_weights">weights</code></td>
<td>
<p>a numeric vector of weights of length equal the number
of subjects.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_groups">groups</code></td>
<td>
<p>a <code>numeric</code> or <code>factor</code> vector of group
memberships of length equal the number of subjects. When specified,
one panel is generated for each distinct membership value.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_control">control</code></td>
<td>
<p>control parameters produced by <code>otsplot_control</code>,
such as line colors or the scale of translation zones.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_filter">filter</code></td>
<td>
<p>an <code><a href="#topic+otsplot_filter">otsplot_filter</a></code> object which defines line 
coloring options. See details.</p>
</td></tr> 
<tr><td><code id="otsplot_+3A_main">main</code>, <code id="otsplot_+3A_xlab">xlab</code>, <code id="otsplot_+3A_ylab">ylab</code></td>
<td>
<p>title and axis labels for the plot.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_xlim">xlim</code>, <code id="otsplot_+3A_ylim">ylim</code></td>
<td>
<p>the x limits <code>c(x1, x2)</code> resp. y limits
<code>(y1,y2)</code>.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_...">...</code></td>
<td>
<p>additional undocumented arguments.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_cex">cex</code></td>
<td>
<p>expansion factor for the squared symbols.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_lwd">lwd</code></td>
<td>
<p>expansion factor for line widths. The expansion is
relative to the size of the squared symbols.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_col">col</code></td>
<td>
<p>color palette vector for line coloring.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_hide.col">hide.col</code></td>
<td>
<p>Color for ordinal time-series filtered-out by the
<code>filter</code> specification in <code>otsplot</code>.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_seed">seed</code></td>
<td>
<p>an integer specifying which seed should be set at the
beginning.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_lorder">lorder</code></td>
<td>
<p>line ordering. Either <code>"background"</code> or
<code>"foreground"</code>.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_lcourse">lcourse</code></td>
<td>
<p>Method to connect simultaneous elements with the
preceding and following ones. Either <code>"upwards"</code> (default) or
<code>"downwards"</code>.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_grid.scale">grid.scale</code></td>
<td>
<p>expansion factor for the translation zones.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_grid.lwd">grid.lwd</code></td>
<td>
<p>expansion factor for the borders of translation
zones.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_grid.fill">grid.fill</code></td>
<td>
<p>the fill color for translation zones.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_grid.col">grid.col</code></td>
<td>
<p>the border color for translation zones.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_strip.fontsize">strip.fontsize</code></td>
<td>
<p>fontsize of titles in stripes that appear
when a <code>groups</code> vector is assigned.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_strip.fill">strip.fill</code></td>
<td>
<p>color of strips that appear when a <code>groups</code>
vector is assigned.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_layout">layout</code></td>
<td>
<p>an integer vector <code>c(nr, nc)</code> specifying the
number of rows and columns of the panel arrangement when the
<code>groups</code> argument is used.</p>
</td></tr> 
<tr><td><code id="otsplot_+3A_margins">margins</code></td>
<td>
<p>a numeric vector <code>c(bottom, left, top, right)</code>
specifying the space on the margins of the plot. See also
the argument <code>mar</code> in <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_pop">pop</code></td>
<td>
<p>logical scalar. Whether the viewport tree should be popped
before return.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_newpage">newpage</code></td>
<td>
<p>logical scalar. Whether <code>grid.newpage()</code> should be
called previous to the plot.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_maxit">maxit</code></td>
<td>
<p>maximal number of iteration for the algorithm that
computes the translation arrangement.</p>
</td></tr>
<tr><td><code id="otsplot_+3A_method">method</code></td>
<td>
<p>character string. Defines the filtering
function. Available are <code>"minfreq"</code>, <code>"cumfreq"</code> and
<code>"linear"</code>.</p>
</td></tr> 
<tr><td><code id="otsplot_+3A_level">level</code></td>
<td>
<p>numeric scalar between 0 and 1. The frequency threshold
for the filtering methods <code>"minfreq"</code> and <code>"cumfreq"</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function is a scaled down version of the <code>seqpcplot</code>
function of the <span class="pkg">TraMineR</span> package, implemented in the <span class="pkg">grid</span>
graphics environment.
</p>
<p>The <code>filter</code> argument serves to specify filters to fade out less 
interesting patterns. The filtered-out patterns are displayed in the
<code>hide.col</code> color. The <code>filter</code> argument expects an object 
produced by <code><a href="#topic+otsplot_filter">otsplot_filter</a></code>.
</p>
<p><code>otsplot_filter("minfreq", level = 0.05)</code> colors patterns with a 
support of at least 5% (within a
group). <code>otsplot_filter("cumfreq", level = 0.75)</code> 
highlight the 75% most frequent patterns (within
group). <code>otsplot_filter("linear")</code>  
linearly greys out patterns with low support.
</p>
<p>The implementation adopts a color palette which was originally
generated by the <span class="pkg">colorspace</span> package (Ihaka et al., 2013). The
authors are grateful for these codes.  
</p>


<h3>Value</h3>

<p><code><a href="#topic+otsplot">otsplot</a></code> returns an object of class
<code>otsplot</code>.
</p>
<p><code><a href="#topic+otsplot_control">otsplot_control</a></code> returns an object of class
<code>otsplot_control</code> and <code><a href="#topic+otsplot_filter">otsplot_filter</a></code> an object
of class <code>otsplot_filter</code>. Both these object types are
specifically designed as input arguments of <code><a href="#topic+otsplot">otsplot</a></code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin and Gilbert Ritschard</p>


<h3>References</h3>

<p>Burgin, R. and G. Ritschard (2014). A Decorated Parallel Coordinate 
Plot for Categorical Longitudinal Data, <em>The American
Statistician</em> <b>68</b>(2), 98&ndash;103. 
</p>
<p>Ihaka, R., P. Murrell, K. Hornik, J. C. Fisher and A. Zeileis (2013).
colorspace: Color Space Manipulation. R package version 1.2-4. URL
<a href="https://CRAN.R-project.org/package=colorspace">https://CRAN.R-project.org/package=colorspace</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example: 
##
## Plotting artificially generated ordinal longitudinal data
## ------------------------------------------------------------------- #

## load the data
data(vcrpart_1)
vcrpart_1 &lt;- vcrpart_1[1:40,]

## plot the data
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y, subject = vcrpart_1$id)

## using 'groups'
groups &lt;- rep(c("A", "B"), each = nrow(vcrpart_1) / 2L)
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y, subject = vcrpart_1$id,
        groups = groups)

## color series with supports over 30%
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y, subject = vcrpart_1$id,
        filter = otsplot_filter("minfreq", level = 0.3))

## highlight the 50% most frequent series
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y, subject = vcrpart_1$id,
        filter = otsplot_filter("cumfreq", level = 0.5))

## linearly grey out series with low support 
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y, subject = vcrpart_1$id,
        filter = otsplot_filter("linear"))

## subject-wise plot 
otsplot(x = vcrpart_1$wave, y = vcrpart_1$y,
        subject = vcrpart_1$id, groups = vcrpart_1$id)
</code></pre>

<hr>
<h2 id='PL'>Effect of parental leave policy</h2><span id='topic+PL'></span>

<h3>Description</h3>

<p>Data to analyze the effect of the 1990 Austrian parental leave
reform on fertility and postbirth labor market careers. The data originate 
from the Austrian Social Security Database (ASSD) and where prepared by 
Lalive and Zweimueller (2009). The sample includes 6'180 women giving a 
childbirth (the first birth recorded in the ASSD data) between June
and July 1990 and were eligible to benefit from the parental leave
program.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PL)</code></pre>


<h3>Format</h3>

<p>A data frame with 6'180 observations on the following variables
</p>

<dl>
<dt><code>uncb3</code></dt><dd><p>binary. Additional birth 0-36 months after child birth.</p>
</dd>
<dt><code>uncb10</code></dt><dd><p>binary. Additional birth 0-120 months after child birth.</p>
</dd>
<dt><code>uncj3</code></dt><dd><p>binary. Return-to-work 0-36 months after child birth.</p>
</dd>
<dt><code>uncj10</code></dt><dd><p>numeric. Return-to-work 0-120 months after child birth.</p>
</dd>
<dt><code>pbexp10</code></dt><dd><p>numeric. Employment (months/yr), 37-120 months
after child birth.</p>
</dd> 
<dt><code>pbinc_tot10</code></dt><dd><p>numeric. Earnings (EUR/month), 37-120
months after child birth.</p>
</dd>
<dt><code>pbexp3</code></dt><dd><p>numeric. Employment (months/yr), 0-36 months
after child birth.</p>
</dd> 
<dt><code>pbinc_tot3</code></dt><dd><p>numeric. Earnings (EUR/month), 0-36 months
after child birth.</p>
</dd> 
<dt><code>ikar3</code></dt><dd><p>numeric. Length of parental leave of the first
year after birth.</p>
</dd> 
<dt><code>ikar4</code></dt><dd><p>numeric. Length of parental leave of the second
year after birth.</p>
</dd> 
<dt><code>july</code></dt><dd><p>binary treatment variable. Indicates whether the child 
considered (the first recorded in the ASSD data) was born in June 1990
or in July 1990.</p>
</dd>
<dt><code>bd</code></dt><dd><p>child's birthday.</p>
</dd>
<dt><code>workExp</code></dt><dd><p>years in employment prior to birth.</p>
</dd>
<dt><code>unEmpl</code></dt><dd><p>years in unemployment prior to birth.</p>
</dd>
<dt><code>zeroLabEarn</code></dt><dd><p>factor. Whether women has earnings at birth.</p>
</dd>
<dt><code>laborEarnings</code></dt><dd><p>numeric. Earnings at birth.</p>
</dd>
<dt><code>employed</code></dt><dd><p>factor. Whether the woman was employed in 1989.</p>
</dd>
<dt><code>whiteCollar</code></dt><dd><p>factor. Whether woman is white collar worker.</p>
</dd>
<dt><code>wage</code></dt><dd><p>numeric. Daily 1989 earnings.</p>
</dd>
<dt><code>age</code></dt><dd><p>ordered factor. Age.</p>
</dd>
<dt><code>industry</code>, <code>industry.SL</code></dt><dd><p>factor. Industry where woman worked.</p>
</dd>	
<dt><code>region</code>, <code>region.SL</code></dt><dd><p>factor. The region where the woman lives.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are described in Lalive and Zweimueller (2009). 
</p>


<h3>Source</h3>

<p>Austrian Social Security Database (ASSD). The data set is also available 
from <a href="https://sites.google.com/site/rafaellalive/research">https://sites.google.com/site/rafaellalive/research</a></p>


<h3>References</h3>

<p>Lalive, R. and J. Zweimueller (2009). Does Parental Leave
Affect Fertility and Return-to-Work? Evidence from Two Natural
Experiments. <em>The Quarterly Journal of Economics</em> <b>124</b>(3),
1363&ndash;1402.
</p>

<hr>
<h2 id='poverty'>Poverty in Switzerland</h2><span id='topic+poverty'></span>

<h3>Description</h3>

<p>Poverty measurements of elderly people (older than the
Swiss legal retirement age) in Switzerland. The data are the
(complete) subsample of participants of the canton Valais of the
Vivre-Leben-Vivere (VLV) survey data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(poverty)</code></pre>


<h3>Format</h3>

<p>A data frame with 576 observations on the following variables
</p>

<dl>
<dt><code>Poor</code></dt><dd><p>binary response variable on whether the person
is considered as poor or not. 0 = no and 1 = yes.</p>
</dd>
<dt><code>Canton</code></dt><dd><p>the canton where the person lives. All
individuals origin from the canton Wallis.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>whether person is a male or a female.</p>
</dd>
<dt><code>AgeGroup</code></dt><dd><p>to which age group the person belongs to.</p>
</dd>
<dt><code>Edu</code></dt><dd><p>ordered 3-category measurement on the persons
education.</p>
</dd> 
<dt><code>CivStat</code></dt><dd><p>civil status.</p>
</dd>
<dt><code>NChild</code></dt><dd><p>number of children.</p>
</dd>
<dt><code>Working</code></dt><dd><p>whether the person is still working (even
though all persons are in the legal retirement age).</p>
</dd>
<dt><code>FirstJob</code></dt><dd><p>5-category classification of the person's
first job.</p>
</dd>
<dt><code>LastJob</code></dt><dd><p>5-category classification of the person's
last job.</p>
</dd>
<dt><code>Origin</code></dt><dd><p>whether the person origins from Switzerland or
a foreign country.</p>
</dd>
<dt><code>SocMob</code></dt><dd><p>whether and how the person has changed his
social status over the life span.</p>
</dd>
<dt><code>RetirTiming</code></dt><dd><p>timing of the retirement relative to the
legal retirement age.</p>
</dd>
<dt><code>ProfCar</code></dt><dd><p>4-category classification of the professional
carrier. Possible are <code>"full employment"</code>,
<code>"missing / early retirement"</code>, <code>"start and stop"</code> and
<code>"stop and restart"</code>. The classification was retrieved from a
longitudinal cluster analysis on the professional carriers in
Gabriel et. al. (2014).</p>
</dd> 
<dt><code>Pension</code></dt><dd><p>5-category classification of the pension
plan. Number refer to the Swiss pension three-pillar system.</p>
</dd>
<dt><code>TimFirstChild</code></dt><dd><p>timing of first child relative to the
average timing of the first child of the same age group.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Poverty is defined by a threshold of 2400 Swiss francs per person in
the household. Specifically, the <code>poverty</code> variable was retrieved
from a self-rated ordinal variable with nine categories on household 
income and was adjusted by the OECD equivalence scales methodology to
account for the household size.  
</p>
<p>The variables <code>Canton</code>, <code>Gender</code> and <code>AgeGroup</code>
represent the stratification variables of the survey design. 
</p>
<p>The data include a significant number of missings, in particular for
<code>Poor</code> and <code>RetirTiming</code>. The authors are grateful to
Rainer Gabriel, Michel Oris and the <em>Centre interfacultaire de
gerontologie et d'etudes des vulnerabilites</em> (CIGEV) at the
University of Geneva for providing the prepared data set.
</p>


<h3>Source</h3>

<p>VLV survey</p>


<h3>References</h3>

<p>Ludwig, C., S. Cavalli and M. Oris
&lsquo;Vivre/Leben/Vivere&rsquo;: An interdisciplinary survey addressing
progress and inequalities of ageing over the past 30 years in
Switzerland. <em>Archives of Gerontology and Geriatrics</em>.  
</p>
<p>Gabriel, R., M. Oris, M. Studer and M. Baeriswyl (2015). The
Persistance of Social Stratification? <em>Swiss Journal of
Sociology</em>, <b>41</b>(3), 465&ndash;487.
</p>

<hr>
<h2 id='schizo'>National Institute of Mental Health shizophrenia study</h2><span id='topic+schizo'></span>

<h3>Description</h3>

<p>Schizophrenia data from a randomized controlled trial with 
patients assigned to either drug or placebo group. &quot;Severity of
Illness&quot; was measured, at weeks 0, 1, ..., 6, on a four category
ordered scale. Most of the observations where made on weeks 0, 1, 3,
and 6.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(schizo)</code></pre>


<h3>Format</h3>

<p>A data frame with 1603 observations on 437 subjects. Five vectors
contain information on
</p>

<dl>
<dt><code>id</code></dt><dd><p>patient ID.</p>
</dd>
<dt><code>imps79</code></dt><dd><p>original response measurements on a numerical
scale.</p>
</dd> 
<dt><code>imps79o</code></dt><dd><p>ordinal response on a 4 category scale,
&quot;normal or borderline mentally ill&quot; &lt; &quot;mildly or moderately ill&quot;,
&quot;markedly ill&quot;, &quot;severely or among the most extremely ill&quot;.</p>
</dd>
<dt><code>tx</code></dt><dd><p>treatment indicator: 1 for drug, 0 for placebo.</p>
</dd>
<dt><code>week</code></dt><dd><p>week.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The documentation file was copied from the <span class="pkg">mixcat</span> package 
and slightly modified.</p>


<h3>Source</h3>

<p><a href="https://hedeker.people.uic.edu/ml.html">https://hedeker.people.uic.edu/ml.html</a></p>


<h3>References</h3>

<p>Hedeker, D. and R. Gibbons (2006). <em>Longitudinal Data
Analysis</em>. New Jersey, USA: John Wiley &amp; Sons.</p>

<hr>
<h2 id='tvcglm'>Coefficient-wise tree-based varying coefficient regression based
on generalized linear models</h2><span id='topic+tvcglm'></span><span id='topic+tvcglm_control'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+tvcglm">tvcglm</a></code> function implements the
tree-based varying coefficient regression algorithm for generalized
linear models introduced by Burgin and Ritschard (2017). The
algorithm approximates varying coefficients by piecewise constant
functions using recursive partitioning, i.e., it estimates the
selected coefficients individually by strata of the value space of
partitioning variables. The special feature of the provided algorithm
is that it allows building for each varying coefficient an individual
partition, which enhances the possibilities for model specification
and to select partitioning variables individually by coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tvcglm(formula, data, family, 
       weights, subset, offset, na.action = na.omit, 
       control = tvcglm_control(), ...)

tvcglm_control(minsize = 30, mindev = 2.0,
               maxnomsplit = 5, maxordsplit = 9, maxnumsplit = 9,
               cv = TRUE, folds = folds_control("kfold", 5),
               prune = cv, fast = TRUE, center = fast,
	       maxstep = 1e3, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcglm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to fit, e.g.,
</p>
<p><code>y ~ vc(z1, z2, z3) + vc(z1, z2, by = x1) + vc(z2, z3, by = x2)</code>
</p>
<p>where the <code>vc</code> terms specify the varying fixed
coefficients. The unnamed arguments within <code>vc</code> terms are
interpreted as partitioning variables (i.e., moderators). The
<code>by</code> argument specifies the associated predictor variable. If
no such predictor variable is specified (e.g., see the first term in
the above example formula), the <code>vc</code> term is interpreted as a
varying intercept, i.e., an nonparametric estimate of the direct
effect of the partitioning variables. For details, see
<code><a href="#topic+vcrpart-formula">vcrpart-formula</a></code>. Note that the global intercept may
be removed by a <code>-1</code> term, according to the desired
interpretation of the model.</p>
</td></tr> 
<tr><td><code id="tvcglm_+3A_family">family</code></td>
<td>
<p>the model family. An object of class
<code><a href="stats.html#topic+family">family</a></code>.</p>
</td></tr>   
<tr><td><code id="tvcglm_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_weights">weights</code></td>
<td>
<p>an optional numeric vector of weights to be used in the 
fitting process.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_subset">subset</code></td>
<td>
<p>an optional logical or integer vector specifying a
subset of <code>'data'</code> to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component 
to be included in the linear predictor during fitting.</p>
</td></tr> 	
<tr><td><code id="tvcglm_+3A_na.action">na.action</code></td>
<td>
<p>a function that indicates what should happen if data 
contain <code>NA</code>s. The default <code>na.action = na.omit</code> is
listwise deletion, i.e., observations with missings on any variable
are dropped. See <code><a href="stats.html#topic+na.action">na.action</a></code>.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_control">control</code></td>
<td>
<p>a list with control parameters as returned by
<code><a href="#topic+tvcglm_control">tvcglm_control</a></code>, or by <code><a href="#topic+tvcm_control">tvcm_control</a></code>
for advanced users.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_minsize">minsize</code></td>
<td>
<p>numeric (vector). The minimum sum of weights in
terminal nodes.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_mindev">mindev</code></td>
<td>
<p>numeric scalar. The minimum permitted training error 
reduction a split must exhibit to be considered of a new split.
The main role of this parameter is to save computing time by early
stopping. May be set lower for very few partitioning variables
resp. higher for many partitioning variables. </p>
</td></tr>
<tr><td><code id="tvcglm_+3A_maxnomsplit">maxnomsplit</code>, <code id="tvcglm_+3A_maxordsplit">maxordsplit</code>, <code id="tvcglm_+3A_maxnumsplit">maxnumsplit</code></td>
<td>
<p>integer scalars for split
candidate reduction. See <code><a href="#topic+tvcm_control">tvcm_control</a></code></p>
</td></tr>
<tr><td><code id="tvcglm_+3A_cv">cv</code></td>
<td>
<p>logical scalar. Whether or not the <code>cp</code> parameter
should be cross-validated. If <code>TRUE</code> <code><a href="#topic+cvloss">cvloss</a></code> is
called.</p>
</td></tr> 
<tr><td><code id="tvcglm_+3A_folds">folds</code></td>
<td>
<p>a list of parameters to create folds as produced by 
<code><a href="#topic+folds_control">folds_control</a></code>. Is used for cross-validation.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_prune">prune</code></td>
<td>
<p>logical scalar. Whether or not the initial tree should be
pruned by the estimated <code>cp</code> parameter from
cross-validation. Cannot be <code>TRUE</code> if <code>cv = FALSE</code>.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_fast">fast</code></td>
<td>
<p>logical scalar. Whether the approximative model should be
used to search for the next split. The approximative search model
uses only the observations of the node to split and incorporates the
fitted values of the current model as offsets. Therewith the
estimation is reduces to the coefficients of the added split. If
<code>FALSE</code>, the accurate search model is used.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_center">center</code></td>
<td>
<p>logical integer. Whether the predictor variables of
update models during the grid search should be centered. Note that
<code>TRUE</code> will not modify the predictors of the fitted model.</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_maxstep">maxstep</code></td>
<td>
<p>integer. The maximum number of iterations i.e. number
of splits to be processed.</p>
</td></tr>  
<tr><td><code id="tvcglm_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should information about the fitting process
be printed to the screen?</p>
</td></tr>
<tr><td><code id="tvcglm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the fitting function
<code>fit</code> or to <code><a href="#topic+tvcm_control">tvcm_control</a></code>.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p><code><a href="#topic+tvcglm">tvcglm</a></code> processes two stages. The first stage, called 
partitioning stage, builds overly fine partitions for each <code>vc</code>
term; the second stage, called pruning stage, selects the best-sized
partitions by collapsing inner nodes. For details on the pruning
stage, see <code><a href="#topic+tvcm-assessment">tvcm-assessment</a></code>. The partitioning stage
iterates the following steps: 
</p>

<ol>
<li><p> Fit the current generalized linear model
</p>
<p><code>y ~ NodeA:x1 + ... + NodeK:xK</code>
</p>
<p>with <code><a href="stats.html#topic+glm">glm</a></code>, where <code>Nodek</code> is a categorical
variable with terminal node labels for the <code class="reqn">k</code>-th varying
coefficient. 
</p>
</li>
<li><p> Search the globally best split among the candidate splits by
an exhaustive -2 likelihood training error search that cycles
through all possible splits.
</p>
</li>
<li><p> If the -2 likelihood training error reduction of the best
split is smaller than <code>mindev</code> or there is no candidate split
satisfying the minimum node size <code>minsize</code>, stop the
algorithm. 
</p>
</li>
<li><p> Else incorporate the best split and repeat the procedure.
</p>
</li></ol>

<p>The partitioning stage selects, in each iteration, the split that
maximizes the -2 likelihood training error reduction, compared to the
current model. The default stopping parameters are <code>minsize = 30</code>
(a minimum node size of 30) and <code>mindev = 2</code> (the training error
reduction of the best split must be larger than two to continue).
</p>
<p>The algorithm implements a number of split point reduction methods to
decrease the computational complexity. See the arguments
<code>maxnomsplit</code>, <code>maxordsplit</code> and <code>maxnumsplit</code>.
</p>
<p>The algorithm can be seen as an extension of CART (Breiman et. al.,
1984) and PartReg (Wang and Hastie, 2014), with the new feature that
partitioning can be processed coefficient-wise.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tvcm">tvcm</a></code>
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Breiman, L., J. H. Friedman, R. A. Olshen and C.J. Stone (1984).  
<em>Classification and Regression Trees</em>. New York, USA: Wadsworth. 
</p>
<p>Wang, J. C., Hastie, T. (2014), Boosted Varying-Coefficient
Regression Models for Product Demand Prediction, <em>Journal of
Computational and Graphical Statistics</em>, <b>23</b>(2), 361-382. 
</p>
<p>Burgin, R. and G. Ritschard (2017), Coefficient-Wise Tree-Based
Varying Coefficient Regression with vcrpart. <em>Journal of
Statistical Software</em>, <b>80</b>(6), 1&ndash;33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm_control">tvcm_control</a></code>, <code><a href="#topic+tvcm-methods">tvcm-methods</a></code>,
<code><a href="#topic+tvcm-plot">tvcm-plot</a></code>, <code><a href="#topic+tvcm-plot">tvcm-plot</a></code>,
<code><a href="#topic+tvcm-assessment">tvcm-assessment</a></code>, <code><a href="#topic+fvcglm">fvcglm</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #  
## Example: Moderated effect of education on poverty
##
## The algorithm is used to find out whether the effect of high
## education 'EduHigh' on poverty 'Poor' is moderated by the civil
## status 'CivStat'. We specify two 'vc' terms in the logistic
## regression model for 'Poor': a first that accounts for the direct
## effect of 'CivStat' and a second that accounts for the moderation of
## 'CivStat' on the relation between 'EduHigh' and 'Poor'. We use here
## the 2-stage procedure with a partitioning- and a pruning stage as
## described in Burgin and Ritschard (2017). 
## ------------------------------------------------------------------- #

data(poverty)
poverty$EduHigh &lt;- 1 * (poverty$Edu == "high")

## fit the model
model.Pov &lt;-
  tvcglm(Poor ~ -1 +  vc(CivStat) + vc(CivStat, by = EduHigh) + NChild, 
         family = binomial(), data = poverty, subset = 1:200,
         control = tvcm_control(verbose = TRUE, papply = lapply,
           folds = folds_control(K = 1, type = "subsampling", seed = 7)))

## diagnosis
plot(model.Pov, "cv")
plot(model.Pov, "coef")
summary(model.Pov)
splitpath(model.Pov, steps = 1:3)
prunepath(model.Pov, steps = 1)
</code></pre>

<hr>
<h2 id='tvcm'>Tree-based varying coefficient regression models</h2><span id='topic+tvcm'></span>

<h3>Description</h3>

<p><code><a href="#topic+tvcm">tvcm</a></code> is the general implementation for tree-based 
varying coefficient regression. It may be used to combine the two
different algorithms <code><a href="#topic+tvcolmm">tvcolmm</a></code> and
<code><a href="#topic+tvcglm">tvcglm</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tvcm(formula, data, fit, family,
     weights, subset, offset, na.action = na.omit,
     control = tvcm_control(), fitargs, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to fit, e.g.,
</p>
<p><code>y ~ vc(z1, z2) + vc(z1, z2, by = x)</code>
</p>
<p>where <code>vc</code> specifies the varying coefficients. See 
<code><a href="#topic+vcrpart-formula">vcrpart-formula</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm_+3A_fit">fit</code></td>
<td>
<p>a character string or a function that specifies the fitting
function, e.g., <code><a href="#topic+olmm">olmm</a></code> or <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>  
<tr><td><code id="tvcm_+3A_family">family</code></td>
<td>
<p>the model family, e.g., an object of class 
<code><a href="#topic+family.olmm">family.olmm</a></code> or <code><a href="stats.html#topic+family">family</a></code>.</p>
</td></tr> 
<tr><td><code id="tvcm_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="tvcm_+3A_weights">weights</code></td>
<td>
<p>an optional numeric vector of weights to be used in the 
fitting process.</p>
</td></tr>
<tr><td><code id="tvcm_+3A_subset">subset</code></td>
<td>
<p>an optional logical or integer vector specifying a
subset of <code>'data'</code> to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="tvcm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component 
to be included in the linear predictor during fitting.</p>
</td></tr> 	
<tr><td><code id="tvcm_+3A_na.action">na.action</code></td>
<td>
<p>a function that indicates what should happen if data 
contain <code>NA</code>s. The default <code>na.action = na.omit</code> is
listwise deletion, i.e., observations with missings on any variable
are dropped. See <code><a href="stats.html#topic+na.action">na.action</a></code>.</p>
</td></tr> 
<tr><td><code id="tvcm_+3A_control">control</code></td>
<td>
<p>a list with control parameters as returned by
<code><a href="#topic+tvcm_control">tvcm_control</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm_+3A_fitargs">fitargs</code></td>
<td>
<p>additional arguments passed to the fitting function
<code>fit</code>.</p>
</td></tr> 
<tr><td><code id="tvcm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the fitting function
<code>fit</code>. Note that using the <code>fitargs</code> argument is the
preferred way to for this.</p>
</td></tr>  
</table>


<h3>Details</h3>

 
<p>TVCM partitioning works as follows: In each iteration we fit the
current model and select a binary split for one of the current
terminal nodes. The selection requires 4 decisions: the <code>vc</code>
term, the node, the variable and the cutpoint in the selected
variable. The algorithm starts with <code class="reqn">M_k = 1</code> node for each of the
<code class="reqn">K</code> <code><a href="#topic+vc">vc</a></code> terms and iterates until the criteria
defined by <code>control</code> are reached, see
<code><a href="#topic+tvcm_control">tvcm_control</a></code>. For the specific criteria for the split
selection, see <code><a href="#topic+tvcolmm">tvcolmm</a></code> and <code><a href="#topic+tvcglm">tvcglm</a></code>.
</p>
<p>Alternative tree-based algorithm to <code><a href="#topic+tvcm">tvcm</a></code> are the
MOB (Zeileis et al., 2008) and the PartReg (Wang and Hastie, 2014)
algorithms. The MOB algorithm is implemented by the <code>mob</code>
function in the packages <span class="pkg">party</span> and <span class="pkg">partykit</span>. For smoothing
splines and kernel regression approaches to varying coefficients, see
the packages <span class="pkg">mgcv</span>, <span class="pkg">svcm</span>,<span class="pkg">mboost</span> or <span class="pkg">np</span>. 
</p>
<p>The <code><a href="#topic+tvcm">tvcm</a></code> function builds on the software
infrastructure of the <span class="pkg">partykit</span> package. The authors are grateful
for these codes. 
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tvcm">tvcm</a></code>. The
<code><a href="#topic+tvcm">tvcm</a></code> class itself is based on the
<code><a href="partykit.html#topic+party">party</a></code> class of the <span class="pkg">partykit</span> package. The most
important slots are:
</p>
<table role = "presentation">
<tr><td><code>node</code></td>
<td>
<p>an object of class <code><a href="partykit.html#topic+partynode">partynode</a></code>.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code>. The model frame with all
variables for partitioning.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>an optional <code><a href="base.html#topic+data.frame">data.frame</a></code> containing at
least the fitted terminal node identifiers as element
<code>(fitted)</code>. In addition, weights may be contained as element
<code>(weights)</code> and responses as <code>(response)</code>.</p>
</td></tr> 
<tr><td><code>info</code></td>
<td>
<p>additional information including <code>control</code>,
<code>model</code> and <code>data</code> (all untransformed data, without
missings).</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Zeileis, A., T. Hothorn, and K. Hornik (2008). Model-Based
Recursive Partitioning. <em>Journal of Computational and Graphical
Statistics</em>, <b>17</b>(2), 492&ndash;514.
</p>
<p>Wang, J. C. and T. Hastie (2014), Boosted Varying-Coefficient
Regression Models for Product Demand Prediction, <em>Journal of
Computational and Graphical Statistics</em>, <b>23</b>(2), 361&ndash;382.
</p>
<p>Hothorn, T. and A. Zeileis (2014). partykit: A Modular Toolkit
for Recursive Partytioning in R. In <em>Working Papers in Economics
and Statistics, Research Platform Empirical and Experimental
Economics</em>, Number 2014-10. Universitaet Innsbruck.
</p>
<p>Burgin R. and Ritschard G. (2015), Tree-Based Varying Coefficient 
Regression for Longitudinal Ordinal Responses. <em>Computational
Statistics &amp; Data Analysis</em>, <b>86</b>, 65&ndash;80.
</p>
<p>Burgin, R. A. (2015b). Tree-based methods for moderated regression
with application to longitudinal data. PhD thesis. University of
Geneva. 
</p>
<p>Burgin, R. and G. Ritschard (2017), Coefficient-Wise Tree-Based
Varying Coefficient Regression with vcrpart. <em>Journal of
Statistical Software</em>, <b>80</b>(6), 1&ndash;33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcolmm">tvcolmm</a></code>, <code><a href="#topic+tvcglm">tvcglm</a></code>,
<code><a href="#topic+tvcm_control">tvcm_control</a></code>, <code><a href="#topic+tvcm-methods">tvcm-methods</a></code>,
<code><a href="#topic+tvcm-plot">tvcm-plot</a></code>, <code><a href="#topic+tvcm-assessment">tvcm-assessment</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ------------------------------------------------------------------- #  
## Example 1: Moderated effect of education on poverty
##
## See the help of 'tvcglm'.
## ------------------------------------------------------------------- #

data(poverty)
poverty$EduHigh &lt;- 1 * (poverty$Edu == "high")

## fit the model
model.Pov &lt;-
  tvcm(Poor ~ -1 +  vc(CivStat) + vc(CivStat, by = EduHigh) + NChild, 
         family = binomial(), data = poverty, subset = 1:200,
         control = tvcm_control(verbose = TRUE, papply = "lapply",
           folds = folds_control(K = 1, type = "subsampling", seed = 7)))

## diagnosis
plot(model.Pov, "cv")
plot(model.Pov, "coef")
summary(model.Pov)
splitpath(model.Pov, steps = 1:3)
prunepath(model.Pov, steps = 1)


## ------------------------------------------------------------------- # 
## Example 2: Moderated effect effect of unemployment
##
## See the help of 'tvcolmm'.
## ------------------------------------------------------------------- #

data(unemp)

## fit the model
model.UE &lt;-
  tvcm(GHQL ~ -1 + 
          vc(AGE, FISIT, GENDER, UEREGION, by = UNEMP, intercept = TRUE) +
          re(1|PID),
       data = unemp, control = tvcm_control(sctest = TRUE),
       family = cumulative())

## diagnosis (no cross-validation was performed since 'sctest = TRUE')
plot(model.UE, "coef")
summary(model.UE)
splitpath(model.UE, steps = 1, details = TRUE)


</code></pre>

<hr>
<h2 id='tvcm-assessment'>Model selection utility functions for <code><a href="#topic+tvcm">tvcm</a></code> objects.</h2><span id='topic+tvcm-assessment'></span><span id='topic+prune'></span><span id='topic+prune.tvcm'></span><span id='topic+prunepath'></span><span id='topic+prunepath.tvcm'></span><span id='topic+cvloss'></span><span id='topic+cvloss.tvcm'></span><span id='topic+folds_control'></span><span id='topic+oobloss'></span><span id='topic+oobloss.tvcm'></span><span id='topic+plot.cvloss.tvcm'></span>

<h3>Description</h3>

<p>Pruning, cross-validation to find the optimal pruning parameter and computing 
validation set errors for <code><a href="#topic+tvcm">tvcm</a></code> objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'tvcm'
prune(tree, cp = NULL, alpha = NULL, maxstep = NULL,
      terminal = NULL, original = FALSE, ...)

## S3 method for class 'tvcm'
prunepath(tree, steps = 1L, ...)

## S3 method for class 'tvcm'
cvloss(object, folds = folds_control(), ...)

folds_control(type = c("kfold", "subsampling", "bootstrap"),
      K = ifelse(type == "kfold", 5, 100),
      prob = 0.5, weights = c("case", "freq"),
      seed = NULL)

## S3 method for class 'cvloss.tvcm'
plot(x, legend = TRUE, details = TRUE, ...)

## S3 method for class 'tvcm'
oobloss(object, newdata = NULL, weights = NULL,
        fun = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcm-assessment_+3A_object">object</code>, <code id="tvcm-assessment_+3A_tree">tree</code></td>
<td>
<p>an object of class <code><a href="#topic+tvcm">tvcm</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_cp">cp</code></td>
<td>
<p>numeric scalar. The complexity parameter to be cross-validated 
resp. the penalty with which the model should be pruned.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_alpha">alpha</code></td>
<td>
<p>numeric significance level. Represents the stopping
parameter for <code><a href="#topic+tvcm">tvcm</a></code> objects grown with
<code>sctest = TRUE</code>, see <code><a href="#topic+tvcm_control">tvcm_control</a></code>. A node is
splitted when the <code class="reqn">p</code> value for any coefficient stability test
in that node falls below <code>alpha</code>.</p>
</td></tr> 
<tr><td><code id="tvcm-assessment_+3A_maxstep">maxstep</code></td>
<td>
<p>integer. The maximum number of steps of the algorithm.</p>
</td></tr> 
<tr><td><code id="tvcm-assessment_+3A_terminal">terminal</code></td>
<td>
<p>a list of integer vectors with the ids of the nodes
the inner nodes to be set to terminal nodes. The length of the list must 
be equal the number of partitions.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_original">original</code></td>
<td>
<p>logical scalar. Whether pruning should be based on the
trees from partitioning rather than on the current trees.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_steps">steps</code></td>
<td>
<p>integer vector. The iteration steps from which
information should be extracted.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_folds">folds</code></td>
<td>
<p>a list with control arguments as produced by
<code><a href="#topic+folds_control">folds_control</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_type">type</code></td>
<td>
<p>character string. The type of sampling scheme to be used
to divide the data of the input model in a learning and a validation
set.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_k">K</code></td>
<td>
<p>integer scalar. The number of folds.</p>
</td></tr> 
<tr><td><code id="tvcm-assessment_+3A_weights">weights</code></td>
<td>
<p>for <code><a href="#topic+folds_control">folds_control</a></code>, a character that
defines whether the weights of <code>object</code> are case weights or
frequencies of cases; for <code><a href="#topic+oobloss">oobloss</a></code>, a numeric vector
of weights corresponding to the rows of <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_prob">prob</code></td>
<td>
<p>numeric between 0 and 1. The probability for the
<code>"subsampling"</code> cross-validation scheme.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_seed">seed</code></td>
<td>
<p>an numeric scalar that defines the seed.</p>
</td></tr>  
<tr><td><code id="tvcm-assessment_+3A_x">x</code></td>
<td>
<p>an object of class <code>cvloss.tvcm</code> as produced by
<code><a href="#topic+cvloss">cvloss</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_legend">legend</code></td>
<td>
<p>logical scalar. Whether a legend should be added.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_details">details</code></td>
<td>
<p>logical scalar. Whether the foldwise validation errors 
should be shown.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_newdata">newdata</code></td>
<td>
<p>a data.frame of out-of-bag data (including the response
variable). See also <code><a href="#topic+predict.tvcm">predict.tvcm</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_fun">fun</code></td>
<td>
<p>the loss function for the validation sets. By default, the
(possibly weighted) mean of the deviance residuals as defined by the
<code><a href="stats.html#topic+family">family</a></code> of the fitted <code>object</code> is applied.</p>
</td></tr>
<tr><td><code id="tvcm-assessment_+3A_...">...</code></td>
<td>
<p>other arguments to be passed.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code><a href="#topic+tvcglm">tvcglm</a></code> and <code><a href="#topic+tvcm">tvcm</a></code> processe
tree-size selection by default. The functions could be interesting for
advanced users. 
</p>
<p>The <code><a href="#topic+prune">prune</a></code> function is used to collapse inner nodes of
the tree structures by the tuning parameter <code>cp</code>. The aim of
pruning by <code>cp</code> is to collapse inner nodes to minimize the
cost-complexity criterion 
</p>
<p style="text-align: center;"><code class="reqn">error(cp) = error(tree) + cp * complexity(tree)</code>
</p>

<p>where the training error <code class="reqn">error(tree)</code> is defined by
<code>lossfun</code> and <code class="reqn">complexity(tree)</code> is defined as the total
number of coefficients times <code>dfpar</code> plus the total number of
splits times <code>dfsplit</code>. The function <code>lossfun</code> and the
parameters <code>dfpar</code> and <code>dfsplit</code> are defined  by the
<code>control</code> argument of <code><a href="#topic+tvcm">tvcm</a></code>, see also
<code><a href="#topic+tvcm_control">tvcm_control</a></code>. By default, <code class="reqn">error(tree)</code> is minus
two times the total likelihood of the model and <code class="reqn">complexity(tree)</code>
the number of splits. The minimization of <code class="reqn">error(cp)</code> is
implemented by the following iterative backward-stepwise algorithm 
</p>

<ol>
<li><p> fit all <code>subtree</code> models that collapse one inner node of the 
current <code>tree</code> model.
</p>
</li>
<li><p> compute the per-complexity increase in the training error
</p>
<p style="text-align: center;"><code class="reqn">dev = (error(subtree) - error(tree)) / 
        (complexity(tree) - complexity(subtree))</code>
</p>

<p>for all fitted <code>subtree</code> models
</p>
</li>
<li><p> if any <code>dev</code> &lt; <code>cp</code> then set as the <code>tree</code> model
the <code>subtree</code> that minimizes <code>dev</code> and repeated 1 to 3, 
otherwise stop.
</p>
</li></ol>

<p>The penalty <code>cp</code> is generally unknown and is estimated adaptively
from the data. The <code><a href="#topic+cvloss">cvloss</a></code> function implements the
cross-validation method to do this. <code><a href="#topic+cvloss">cvloss</a></code> repeats
for each fold the following steps
</p>

<ol>
<li><p> fit a new model with <code><a href="#topic+tvcm">tvcm</a></code> based on the training
data of the fold. 
</p>
</li>
<li><p> prune the new model for increasing <code>cp</code>. Compute for each 
<code>cp</code> the average validation error.
</p>
</li></ol>

<p>Doing so yields for each fold a sequence of values for <code>cp</code> and
a sequence of average validation errors. These sequences are then
combined to a finer grid and the average validation error is averaged 
correspondingly. From these two sequences we choose the <code>cp</code>
value that minimizes the validation error. Notice that the average
validation error is computed as the total prediction error of the
validation set divided  by the sum of validation set weights. See also
the argument <code>ooblossfun</code> in <code><a href="#topic+tvcm_control">tvcm_control</a></code> and
the function <code><a href="#topic+oobloss">oobloss</a></code>.
</p>
<p>The <code><a href="#topic+prunepath">prunepath</a></code> function can be used to backtrack the
pruning algorithm. By default, it shows the results from collapsing
inner nodes in the first iteration. The interesting iteration(s) can
be selected by the <code>steps</code> argument. The output shows several
information on the performances when collapsing inner nodes. The node
labels shown in the output refer to the initial tree.
</p>
<p>The function <code><a href="#topic+folds_control">folds_control</a></code> is used to specify the 
cross-validation scheme, where a random 5-fold cross-validation scheme 
is used by default. Alternatives are <code>type = "subsampling"</code> 
(random draws without replacement) and <code>type = "bootstrap"</code> (random 
draws with replacement). For 2-stage models (with random-effects) 
fitted by <code><a href="#topic+olmm">olmm</a></code>, the subsets are based on subject-wise 
i.e. first stage sampling. For models where weights represent frequencies
of observation units (e.g., data from contingency tables), the option
<code>weights = "freq"</code> should be considered. <code><a href="#topic+cvloss">cvloss</a></code> 
returns an object for which a <code>print</code> and a <code>plot</code> generic is
provided.  
</p>
<p><code><a href="#topic+oobloss">oobloss</a></code> can be used to estimate the total prediction
error for validation data (the <code>newdata</code> argument). By default,
the loss is defined as the sum of deviance residuals, see the return
value <code>dev.resids</code> of <code><a href="stats.html#topic+family">family</a></code>
resp. <code><a href="#topic+family.olmm">family.olmm</a></code>. Otherwise, the loss function can
be defined manually by the argument <code>fun</code>, see the examples
below. In general the sum of deviance residual is equal the sum of the
-2 log-likelihood errors. A special case is the gaussian family, where  
the deviance residuals are computed as <code class="reqn">\sum_{i=1}^N w_i (y_i-\mu)^2</code>, 
that is, the deviance residuals ignore the term <code class="reqn">log 2\pi\sigma^2</code>. 
Therefore, the sum of deviance residuals for the gaussian model (and 
possibly others) is not exactly the sum of -2 log-likelihood prediction 
errors (but shifted by a constant). Another special case are models with
random effects. For models based on <code><a href="#topic+olmm">olmm</a></code>, the deviance 
residuals are retrieved from marginal predictions (where random effects are
integrated out). 
</p>


<h3>Value</h3>

<p><code><a href="#topic+prune">prune</a></code> returns a <code><a href="#topic+tvcm">tvcm</a></code> object, 
<code><a href="#topic+folds_control">folds_control</a></code> returns a list of parameters for building a 
cross-validation scheme. <code><a href="#topic+cvloss">cvloss</a></code> returns an <code>cvloss.tvcm</code> 
object with at least the following components: 
</p>
<table role = "presentation">
<tr><td><code>grid</code></td>
<td>
<p>a list with values for <code>cp</code>.</p>
</td></tr> 
<tr><td><code>oobloss</code></td>
<td>
<p>a matrix recording the validated loss for each value in 
<code>grid</code> for each fold.</p>
</td></tr>
<tr><td><code>cp.hat</code></td>
<td>
<p>numeric scalar. The tuning parameter which
minimizes the cross-validated error.</p>
</td></tr>
<tr><td><code>folds</code></td>
<td>
<p>the used folds to extract the learning and the validation
sets.</p>
</td></tr>
</table>
<p><code><a href="#topic+oobloss">oobloss</a></code> returns a scalar representing the total prediction 
error for <code>newdata</code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Breiman, L., J. H. Friedman, R. A. Olshen and C.J. Stone (1984).  
<em>Classification and Regression Trees</em>. New York, USA: Wadsworth. 
</p>
<p>Hastie, T., R. Tibshirani and J. Friedman (2001). <em>The Elements
of Statistical Learning</em> (2 ed.). New York, USA: Springer-Verlag.
</p>
<p>Burgin, R. and G. Ritschard (2017), Coefficient-Wise Tree-Based
Varying Coefficient Regression with vcrpart. <em>Journal of
Statistical Software</em>, <b>80</b>(6), 1&ndash;33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm">tvcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## --------------------------------------------------------- #
## Dummy Example:
##
## Model selection for the 'vcrpart_2' data. The example is
## merely a syntax template.
## --------------------------------------------------------- #

## load the data
data(vcrpart_2)

## fit the model
control &lt;- tvcm_control(maxstep = 2L, minsize = 5L, cv = FALSE)
model &lt;- tvcglm(y ~ vc(z1, z2, by = x1) + vc(z1, by = x2),
                data = vcrpart_2, family = gaussian(),
                control = control, subset = 1:75)

## cross-validate 'dfsplit'
cv &lt;- cvloss(model, folds = folds_control(type = "kfold", K = 2, seed = 1))
cv
plot(cv)

## prune model with estimated 'cp'
model.p &lt;- prune(model, cp = cv$cp.hat)

## backtrack pruning
prunepath(model.p, steps = 1:3)

## out-of-bag error
oobloss(model, newdata = vcrpart_2[76:100,])

## use an alternative loss function
rfun &lt;- function(y, mu, wt) sum(abs(y - mu))
oobloss(model, newdata = vcrpart_2[76:100,], fun = rfun)
</code></pre>

<hr>
<h2 id='tvcm-control'>Control parameters for <code><a href="#topic+tvcm">tvcm</a></code>.</h2><span id='topic+tvcm-control'></span><span id='topic+tvcm_control'></span>

<h3>Description</h3>

<p>Various parameters that control aspects for <code><a href="#topic+tvcm">tvcm</a></code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tvcm_control(minsize = 30, mindev = ifelse(sctest, 0.0, 2.0),
             sctest = FALSE, alpha = 0.05, bonferroni = TRUE,
             trim = 0.1, estfun.args = list(), nimpute = 5, 
             maxnomsplit = 5, maxordsplit = 9, maxnumsplit = 9,
             maxstep = 1e3, maxwidth = Inf, maxdepth = Inf,
             lossfun = neglogLik2, ooblossfun = NULL, fast = TRUE,
             cp = 0.0, dfpar = 0.0, dfsplit = 1.0,
             cv = !sctest, folds = folds_control("kfold", 5),
             prune = cv, papply = mclapply, papply.args = list(),
             center = fast, seed = NULL, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcm-control_+3A_alpha">alpha</code>, <code id="tvcm-control_+3A_bonferroni">bonferroni</code>, <code id="tvcm-control_+3A_trim">trim</code>, <code id="tvcm-control_+3A_estfun.args">estfun.args</code>, <code id="tvcm-control_+3A_nimpute">nimpute</code></td>
<td>
<p>See
<code><a href="#topic+tvcolmm_control">tvcolmm_control</a></code></p>
</td></tr> 
<tr><td><code id="tvcm-control_+3A_mindev">mindev</code>, <code id="tvcm-control_+3A_cv">cv</code>, <code id="tvcm-control_+3A_folds">folds</code>, <code id="tvcm-control_+3A_prune">prune</code>, <code id="tvcm-control_+3A_center">center</code></td>
<td>
<p>See
<code><a href="#topic+tvcglm_control">tvcglm_control</a></code></p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_minsize">minsize</code></td>
<td>
<p>numeric (vector). The minimum sum of weights in
terminal nodes.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_sctest">sctest</code></td>
<td>
<p>logical scalar. Defines whether coefficient constancy
tests should be used for the variable and node selection in each
iteration.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_maxnomsplit">maxnomsplit</code></td>
<td>
<p>integer. For nominal partitioning variables with
more the <code>maxnomsplit</code> the categories are ordered an treated as
ordinal.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_maxordsplit">maxordsplit</code></td>
<td>
<p>integer. The maximum number of splits of ordered
partitioning variables to be evaluated.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_maxnumsplit">maxnumsplit</code></td>
<td>
<p>integer. The maximum number of splits of numeric
partitioning variables to be evaluated.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_maxstep">maxstep</code></td>
<td>
<p>integer. The maximum number of iterations i.e. number
of splits to be processed.</p>
</td></tr>  
<tr><td><code id="tvcm-control_+3A_maxwidth">maxwidth</code></td>
<td>
<p>integer (vector). The maximum width of the partition(s).</p>
</td></tr>  
<tr><td><code id="tvcm-control_+3A_maxdepth">maxdepth</code></td>
<td>
<p>integer (vector). The maximum depth of the partition(s).</p>
</td></tr> 
<tr><td><code id="tvcm-control_+3A_lossfun">lossfun</code></td>
<td>
<p>a function to extract the training error, typically
minus two times the negative log likelihood of the fitted model (see
<code><a href="#topic+neglogLik2">neglogLik2</a></code>). Is currently ignored if a <code>glm</code>
model is fitted and <code>fast = TRUE</code>.</p>
</td></tr>  
<tr><td><code id="tvcm-control_+3A_ooblossfun">ooblossfun</code></td>
<td>
<p>a loss function that defines how to compute the
validation error during cross-validation. The function will be
assigned to the <code>fun</code> argument of <code><a href="#topic+oobloss">oobloss</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_fast">fast</code></td>
<td>
<p>logical scalar. Whether the approximative model should be
used to search for the next split. The approximative search model
uses only the observations of the node to split and incorporates the
fitted values of the current model as offsets. Therewith the
estimation is reduces to the coefficients of the added split. If
<code>FALSE</code>, the accurate search model is used.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_cp">cp</code></td>
<td>
<p>numeric scalar. The penalty to be multiplied with the
complexity of the model during partitioning. The complexity of the
model is defined as the number of coefficients times <code>dfpar</code>
plus the number of splits times <code>dfsplit</code>. By default, <code>cp
      = 0</code> (no penalization during partitioning) and <code>dfpar = 0</code> and
<code>dfsplit = 1</code> (the complexity is measured as the total number
of splits). <code>cp</code> also presents the minimum evaluated value at
cross-validation.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_dfpar">dfpar</code></td>
<td>
<p>numeric scalar. The degree of freedom per model
coefficient. Is used to compute the complexity of the model, see
<code>cp</code>.</p>
</td></tr>  
<tr><td><code id="tvcm-control_+3A_dfsplit">dfsplit</code></td>
<td>
<p>a numeric scalar. The degree of freedom per split. Is
used to compute the complexity of the model, see <code>cp</code>.</p>
</td></tr>   
<tr><td><code id="tvcm-control_+3A_papply">papply</code></td>
<td>
<p>(parallel) apply function, defaults to
<code><a href="parallel.html#topic+mclapply">mclapply</a></code>. The function will parallelize the 
partition stage and the evaluation of the cross-validation folds as
well as the final pruning stage.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_papply.args">papply.args</code></td>
<td>
<p>a list of arguments to be passed to <code>papply</code>.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_seed">seed</code></td>
<td>
<p>an integer specifying which seed should be set at the
beginning.</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should information about the fitting process
be printed to the screen?</p>
</td></tr>
<tr><td><code id="tvcm-control_+3A_...">...</code></td>
<td>
<p>further, undocumented arguments to be passed.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>A list of class <code>tvcm_control</code> containing
the control parameters for <code><a href="#topic+tvcm">tvcm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcolmm_control">tvcolmm_control</a></code>,
<code><a href="#topic+tvcglm_control">tvcglm_control</a></code>, <code><a href="#topic+tvcm">tvcm</a></code>,
<code><a href="#topic+fvcm">fvcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>tvcm_control(minsize = 100)
</code></pre>

<hr>
<h2 id='tvcm-methods'>Methods for <code><a href="#topic+tvcm">tvcm</a></code> objects</h2><span id='topic+tvcm-methods'></span><span id='topic+coef.tvcm'></span><span id='topic+coefficients.tvcm'></span><span id='topic+depth.tvcm'></span><span id='topic+extract'></span><span id='topic+extract.tvcm'></span><span id='topic+formula.tvcm'></span><span id='topic+fitted.tvcm'></span><span id='topic+getCall.tvcm'></span><span id='topic+logLik.tvcm'></span><span id='topic+model.frame.tvcm'></span><span id='topic+neglogLik2.tvcm'></span><span id='topic+nobs.tvcm'></span><span id='topic+predict.tvcm'></span><span id='topic+print.tvcm'></span><span id='topic+ranef.tvcm'></span><span id='topic+resid.tvcm'></span><span id='topic+residuals.tvcm'></span><span id='topic+splitpath'></span><span id='topic+splitpath.tvcm'></span><span id='topic+summary.tvcm'></span><span id='topic+weights.tvcm'></span><span id='topic+width.tvcm'></span>

<h3>Description</h3>

<p>Standard methods for computing on <code><a href="#topic+tvcm">tvcm</a></code>
objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tvcm'
coef(object, ...)

## S3 method for class 'tvcm'
depth(x, root = FALSE, ...)

## S3 method for class 'tvcm'
extract(object, what = c(
              "control", "model", 
              "nodes", "sctest", "p.value",
              "devgrid", "cv", "selected",
              "coef", "sd", "var"),
        steps = NULL, ...)

## S3 method for class 'tvcm'
neglogLik2(object, ...)

## S3 method for class 'tvcm'
predict(object, newdata = NULL,
        type = c("link", "response", "prob", "class",
          "node", "coef", "ranef"),
        ranef = FALSE, na.action = na.pass, ...)

## S3 method for class 'tvcm'
splitpath(tree, steps = 1L,
         details = FALSE, ...)

## S3 method for class 'tvcm'
summary(object, ...)

## S3 method for class 'tvcm'
width(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcm-methods_+3A_object">object</code>, <code id="tvcm-methods_+3A_tree">tree</code>, <code id="tvcm-methods_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+tvcm">tvcm</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_root">root</code></td>
<td>
<p>logical scalar. Should the root count be counted in
<code>depth</code>?</p>
</td></tr> 
<tr><td><code id="tvcm-methods_+3A_steps">steps</code></td>
<td>
<p>integer vector. The iteration steps from which
information should be extracted.</p>
</td></tr> 
<tr><td><code id="tvcm-methods_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables 
with which to predict, if omitted, the fitted values are used.</p>
</td></tr> 
<tr><td><code id="tvcm-methods_+3A_type">type</code></td>
<td>
<p>character string. Denotes for <code><a href="stats.html#topic+predict">predict</a></code> the
type of predicted value. See <code><a href="stats.html#topic+predict.glm">predict.glm</a></code> or
<code><a href="#topic+predict.olmm">predict.olmm</a></code>. <code>"response"</code> and <code>"prob"</code>
are identical.</p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values for fixed effects in <code>newdata</code>. The default is to
predict <code>NA</code>: see <code><a href="stats.html#topic+na.pass">na.pass</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_ranef">ranef</code></td>
<td>
<p>logical scalar or matrix indicating whether prediction
should be based on random effects. See
<code><a href="#topic+predict.olmm">predict.olmm</a></code>. </p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_what">what</code></td>
<td>
<p>a character specifying the quantities to <code>extract</code>.</p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_details">details</code></td>
<td>
<p>logical scalar. Whether detail results like
coefficient constancy tests or loss minimizing grid search should be 
shown.</p>
</td></tr>
<tr><td><code id="tvcm-methods_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the calls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="stats.html#topic+predict">predict</a></code> function has two additional options for the
<code>type</code> argument. The option <code>"node"</code> calls the node id and
<code>"coef"</code> predicts the coefficients corresponding to an
observation. In cases of multiple <code><a href="#topic+vc">vc</a></code> terms for the same
predictor, the coefficients are summed up.
</p>
<p>The <code><a href="#topic+splitpath">splitpath</a></code> function allows to backtrack the
partitioning procedure. By default, it shows which split was chosen in
the first iteration. The interesting iteration(s) can be selected by
the <code>steps</code> argument. With <code>details = TRUE</code> it is also
possible to backtrack the coefficient constancy tests and/or the loss
reduction statistics.  
</p>
<p><code><a href="base.html#topic+summary">summary</a></code> computes summary statistics of the fitted model, 
including the estimated coefficients. The varying coefficient are printed
by means of a printed decision tree. Notice that in cases there is no split
for the varying coefficient, the average coefficient will be among the 
fixed effects.	
</p>
<p>Further undocumented, available methods are: <code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+formula">formula</a></code>, <code><a href="stats.html#topic+getCall">getCall</a></code>,
<code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+model.frame">model.frame</a></code>,
<code><a href="stats.html#topic+nobs">nobs</a></code>, <code><a href="base.html#topic+print">print</a></code>, <code><a href="#topic+ranef">ranef</a></code>,
<code><a href="stats.html#topic+resid">resid</a></code>, and <code><a href="stats.html#topic+weights">weights</a></code>. All these
methods have the same arguments as the corresponding default methods. 
</p>


<h3>Value</h3>

<p>The <code><a href="#topic+coef.tvcm">coef.tvcm</a></code> and <code><a href="#topic+coefficients.tvcm">coefficients.tvcm</a></code>
methods return a <code><a href="base.html#topic+list">list</a></code> with model
coefficients. Slot <code>vc</code> stores varying coefficients, <code>fe</code>
fixed coefficients and <code>re</code> coefficients on random effects.
</p>
<p>The <code><a href="#topic+depth.tvcm">depth.tvcm</a></code> method returns a integer vector with
the depth of the trees of every varying
coefficient. <code><a href="#topic+width.tvcm">width.tvcm</a></code> returns a integer vector with
the width of the trees.  
</p>
<p>The <code><a href="#topic+extract">extract</a></code> and <code><a href="#topic+extract.tvcm">extract.tvcm</a></code> methods
allow to extract further information of <code>tvcm</code> objects, such as
the underlying regression model. The type of the return value depends
on the input for argument <code>what</code>.
</p>
<p>The <code><a href="#topic+formula.tvcm">formula.tvcm</a></code> method extracts the model formula,
which is an object of class <code>formula</code>. See also
<code><a href="stats.html#topic+formula">formula</a></code>.
</p>
<p>The methods <code><a href="#topic+fitted.tvcm">fitted.tvcm</a></code> and
<code><a href="#topic+predict.fvcm">predict.fvcm</a></code> return an object of class <code>numeric</code>
or <code>matrix</code>, depending on the used model or the specification of
the argument <code>type</code>.
</p>
<p>The <code><a href="#topic+getCall.tvcm">getCall.tvcm</a></code> method extracts the call for fitting
the model, which is an object of class <code>call</code>. See also
<code><a href="base.html#topic+call">call</a></code>. 
</p>
<p>The <code><a href="#topic+logLik.tvcm">logLik.tvcm</a></code> method returns an object of class
<code>logLik</code>, see also <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>
<p>The <code><a href="#topic+model.frame.tvcm">model.frame.tvcm</a></code> method returns a
<code>data.frame</code>. See also <code><a href="stats.html#topic+model.frame">model.frame</a></code>.
</p>
<p>The <code><a href="#topic+neglogLik2.tvcm">neglogLik2.tvcm</a></code> method returns a single numeric,
see also <code><a href="#topic+neglogLik2">neglogLik2</a></code>.
</p>
<p>The <code><a href="#topic+nobs.tvcm">nobs.tvcm</a></code> method extracts the number of
observations used to fit the model. See also
<code><a href="#topic+nobs.tvcm">nobs.tvcm</a></code>. 
</p>
<p>The <code><a href="#topic+print.tvcm">print.tvcm</a></code> and <code><a href="#topic+summary.tvcm">summary.tvcm</a></code>
methods return <code>NULL</code>. 
</p>
<p>The <code><a href="#topic+ranef.tvcm">ranef.tvcm</a></code> method returns an object of class
<code>matrix</code> with values for the random effects. See also
<code><a href="#topic+ranef.olmm">ranef.olmm</a></code> and <code><a href="#topic+ranef">ranef</a></code>.
</p>
<p>The <code><a href="#topic+resid.tvcm">resid.tvcm</a></code> and <code><a href="#topic+residuals.tvcm">residuals.tvcm</a></code>
methods return  a <code>numeric</code> or a <code>matrix</code>, depending on the
used model or the type of residuals. See the help of the
<code><a href="stats.html#topic+resid">resid</a></code> method of the used model.
</p>
<p>The methods <code><a href="#topic+splitpath">splitpath</a></code> and
<code><a href="#topic+splitpath.tvcm">splitpath.tvcm</a></code> return an object of class
<code>splitpath.tvcm</code> that contains information on splitting when
building the tree.
</p>
<p>The <code><a href="#topic+weights.tvcm">weights.tvcm</a></code> method extracts a <code>numeric</code>
vector with the model weights. See also <code><a href="stats.html#topic+weights">weights</a></code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm">tvcm</a></code>, <code><a href="#topic+tvcm-assessment">tvcm-assessment</a></code>,
<code><a href="#topic+tvcm-plot">tvcm-plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example:
##
## Apply various methods on a 'tvcm' object fitted on the 'vcrpart_2'
## data. Cross-validation is omitted to accelerate the computations.
## ------------------------------------------------------------------- #

data(vcrpart_2)

model &lt;- tvcm(y ~ -1 + vc(z1, z2) + vc(z1, z2, by = x1) + x2,
              data = vcrpart_2, family = gaussian(), subset = 1:90,
              control = tvcm_control(cv = FALSE))

coef(model)
extract(model, "selected")
extract(model, "model")
predict(model, newdata = vcrpart_2[91:100,], type = "node")
predict(model, newdata = vcrpart_2[91:100,], type = "response")
splitpath(model, steps = 1)
summary(model, digits = 2)
</code></pre>

<hr>
<h2 id='tvcm-plot'><code>plot</code> method for <code><a href="#topic+tvcm">tvcm</a></code> objects.</h2><span id='topic+tvcm-plot'></span><span id='topic+plot.tvcm'></span><span id='topic+panel_coef'></span><span id='topic+panel_partdep'></span>

<h3>Description</h3>

<p><code>plot</code> method and panel functions for <code><a href="#topic+tvcm">tvcm</a></code> objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tvcm'
plot(x, type = c("default", "coef", 
        "simple", "partdep", "cv"),
     main, part = NULL, drop_terminal = TRUE,
     tnex, newpage = TRUE, ask = NULL,
     pop = TRUE, gp = gpar(), ...)

panel_partdep(object, parm = NULL,
              var = NULL, ask = NULL,
              prob = NULL, neval = 50, add = FALSE,
              etalab = c("int", "char", "eta"), ...)

panel_coef(object, parm = NULL, 
           id = TRUE, nobs = TRUE,
           exp = FALSE,
           plot_gp = list(),
           margins, yadj = 0.1,
           mean = FALSE, mean_gp = list(),
           conf.int = FALSE, conf.int_gp = list(),
           abbreviate = TRUE, etalab = c("int", "char", "eta"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcm-plot_+3A_x">x</code>, <code id="tvcm-plot_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+tvcm">tvcm</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_type">type</code></td>
<td>
<p>the type of the plot. Available types are
<code>"default"</code>, <code>"simple"</code>, <code>"coef"</code>,
<code>"partdep"</code> and <code>"cv"</code>.</p>
</td></tr>   
<tr><td><code id="tvcm-plot_+3A_main">main</code></td>
<td>
<p>character. A main title for the plot.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_drop_terminal">drop_terminal</code></td>
<td>
<p>a logical indicating whether all terminal nodes
should be plotted at the bottom. See also
<code><a href="partykit.html#topic+plot.party">plot.party</a></code>.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_tnex">tnex</code></td>
<td>
<p>a numeric value giving the terminal node extension in
relation to the inner nodes. By default the value is computed
adaptively to the tree size.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_newpage">newpage</code></td>
<td>
<p>a logical indicating whether <code>grid.newpage()</code>
should be called.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_pop">pop</code></td>
<td>
<p>a logical whether the viewport tree should be popped before
return.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_gp">gp</code></td>
<td>
<p>graphical parameters. See <code><a href="grid.html#topic+gpar">gpar</a></code>.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_part">part</code></td>
<td>
<p>integer or letter. The partition i.e. varying 
coefficient component to be plotted.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_parm">parm</code></td>
<td>
<p>character vector (<code><a href="#topic+panel_partdep">panel_partdep</a></code> and
<code><a href="#topic+panel_coef">panel_coef</a></code>) or list of character vectors
(<code><a href="#topic+panel_coef">panel_coef</a></code>) with names of model
coefficients corresponding to the chosen component. Indicates which 
coefficients should be visualized. If <code>parm</code> is a list, a
separate panel is allocated for each list component.</p>
</td></tr>  
<tr><td><code id="tvcm-plot_+3A_var">var</code></td>
<td>
<p>character vector. Indicates the partitioning variables
to be visualized.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_ask">ask</code></td>
<td>
<p>logical. Whether an input should be asked before printing
the next panel.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_prob">prob</code></td>
<td>
<p>a probability between 0 and 1. Gives the size of the
random subsample over which the coefficients are averaged. May be
smaller than 1 if the sample is large.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_neval">neval</code></td>
<td>
<p>the maximal number of distinct values of the variable to
be evaluated.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_add">add</code></td>
<td>
<p>logical. Whether the panel is to be added into an active
plot.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_id">id</code></td>
<td>
<p>logical. Whether the node id should be displayed.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_nobs">nobs</code></td>
<td>
<p>logical. Whether the number of observations in each node
should be displayed.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_exp">exp</code></td>
<td>
<p>logical. Whether the labels in the y-axes should be the
exponential of coefficients.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_plot_gp">plot_gp</code></td>
<td>
<p>a list of graphical parameters for the panels. Includes
components <code>xlim</code>, <code>ylim</code>, <code>pch</code>, <code>ylab</code>,
<code>type</code> (the type of symbols, e.g. <code>"b"</code>), <code>label</code>
(characters for ticks at the x axis), <code>height</code>, <code>width</code>,
<code>gp</code> (a list produced by <code><a href="grid.html#topic+gpar">gpar</a></code>). If <code>parm</code> 
is a list, <code>plot_gp</code> may be a nested list specifying the
graphical parameters for each list component of <code>parm</code>. See
examples.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_margins">margins</code></td>
<td>
<p>a numeric vector <code>c(bottom, left, top, right)</code>
specifying the space on the margins for each panel. By default
the values are computed adaptively to the tree size.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_yadj">yadj</code></td>
<td>
<p>a numeric scalar larger than zero that increases the
margin above the panel. May be useful if the edge labels are covered
by the coefficient panels.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_mean">mean</code></td>
<td>
<p>logical. Whether the average coefficients over the
population should be visualized.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_mean_gp">mean_gp</code></td>
<td>
<p>list with graphical parameters for plotting the mean
coefficients. Includes a component <code>gp = gpar(...)</code> and a
component <code>pch</code>. See examples.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_conf.int">conf.int</code></td>
<td>
<p>logical. Whether confidence intervals should be
visualized. These are indicative values only. They do not account
for the uncertainty of model selection procedure.</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_conf.int_gp">conf.int_gp</code></td>
<td>
<p>a list of graphical parameters for the confidence
intervals applied to <code><a href="grid.html#topic+arrow">arrow</a></code>. Includes <code>angle</code>,
<code>length</code>, <code>ends</code> and <code>type</code>. See examples.</p>
</td></tr>
<tr><td><code id="tvcm-plot_+3A_abbreviate">abbreviate</code></td>
<td>
<p>logical scalar. Whether labels of coefficients should
be abbreviated.</p>
</td></tr>		
<tr><td><code id="tvcm-plot_+3A_etalab">etalab</code></td>
<td>
<p>character. Whether category-specific effects should be
labeled by integers of categories (default), the labels of the
categories (<code>"char"</code>) or the index of the predictor
(<code>"eta"</code>).</p>
</td></tr> 
<tr><td><code id="tvcm-plot_+3A_...">...</code></td>
<td>
<p>additional arguments passed to
<code><a href="#topic+panel_partdep">panel_partdep</a></code> or <code><a href="#topic+panel_coef">panel_coef</a></code> or
other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot functions allow the diagnosis of fitted <code><a href="#topic+tvcm">tvcm</a></code>
objects. <code>type = "default"</code>, <code>type = "coef"</code> and
<code>type = "simple"</code> show the tree structure and coefficients in
each node. <code>type = "partdep"</code> plots partial dependency plots, see
Hastie et al. (2001), section 10.13.2. Finally, <code>type = "cv"</code>
shows, if available, the results from cross-validation. 
</p>
<p>The functions <code><a href="#topic+panel_partdep">panel_partdep</a></code> and
<code><a href="#topic+panel_coef">panel_coef</a></code> are exported to show the additional
arguments that can be passed to <code>...</code> of a
<code><a href="base.html#topic+plot">plot</a></code> call.  
</p>
<p>Notice that user-defined plots can be generated by the use of the
<code><a href="partykit.html#topic+plot.party">plot.party</a></code> function, see <span class="pkg">partykit</span>.
</p>


<h3>Value</h3>

<p>The <code><a href="#topic+plot.fvcm">plot.fvcm</a></code> method returns <code>NULL</code>.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Hastie, T., R. Tibshirani and J. Friedman (2001). <em>The Elements
of Statistical Learning</em> (2 ed.). New York, USA: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm">tvcm</a></code>, <code><a href="#topic+tvcm-methods">tvcm-methods</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- #
## Dummy example:
##
## Plotting the types "coef" and "partdep" for a 'tvcm' object fitted 
## on the artificial data 'vcrpart_2'.
## ------------------------------------------------------------------- # 

data(vcrpart_2)

## fit the model
model &lt;- tvcglm(y ~ vc(z1, z2, by = x1, intercept = TRUE) + x2,
                data = vcrpart_2, family = gaussian(),
                control = tvcm_control(maxwidth = 3, minbucket = 5L))

## plot type "coef"
plot(model, "coef")

## add various (stupid) plot parameters
plot(model, "coef",
     plot_gp = list(type = "p", pch = 2, ylim = c(-4, 4),
       label = c("par1", "par2"), gp = gpar(col = "blue")),
     conf.int_gp = list(angle = 45, length = unit(2, "mm"),
       ends = "last", type = "closed"),
     mean_gp = list(pch = 16,
       gp = gpar(fontsize = 16, cex = 2, col = "red")))

## separate plots with separate plot parameters
plot(model, "coef", parm = list("(Intercept)", "x1"), tnex = 2,
     plot_gp = list(list(gp = gpar(col = "red")),
                    list(gp = gpar(col = "blue"))),
     mean_gp = list(list(gp = gpar(col = "green")),
                    list(gp = gpar(col = "yellow"))))

## plot type "partdep"
par(mfrow = c(1, 2))
plot(model, "partdep", var = "z1", ask = FALSE)
</code></pre>

<hr>
<h2 id='tvcolmm'>Tree-based varying coefficient regression based on ordinal and
nominal two-stage linear mixed models.</h2><span id='topic+tvcolmm'></span><span id='topic+tvcolmm_control'></span>

<h3>Description</h3>

<p>The <code><a href="#topic+tvcolmm">tvcolmm</a></code> function implements the
tree-based longitudinal varying coefficient regression algorithm
proposed in Burgin and Ritschard (2015). The algorithm approximates
varying fixed coefficients in the cumulative logit mixed model by a
(multivariate) piecewise constant function using recursive
partitioning, i.e., it estimates the fixed effect component of the
model separately for strata of the value space of partitioning
variables. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tvcolmm(formula, data, family = cumulative(), 
        weights, subset, offset, na.action = na.omit, 
        control = tvcolmm_control(), ...)

tvcolmm_control(sctest = TRUE, alpha = 0.05, bonferroni = TRUE,
                minsize = 50, maxnomsplit = 5, maxordsplit = 9,
                maxnumsplit = 9, fast = TRUE,
                trim = 0.1, estfun.args = list(), nimpute = 5,
                seed = NULL, maxstep = 1e3, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tvcolmm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to fit, e.g.,
</p>
<p><code>y ~ -1 + vc(z1, ..., zL, by = x1 + ... + xP, intercept = TRUE) + re(1|id)</code>
</p>
<p>where <code>vc</code> term specifies the varying fixed coefficients. Only
one such <code>vc</code> term is allowed with
<code><a href="#topic+tvcolmm">tvcolmm</a></code> (in contrast to <code><a href="#topic+tvcglm">tvcglm</a></code>
where multiple <code>vc</code> terms can be specified). The above example 
formula removes the global intercepts and adds locally varying
intercepts, by adding a <code>-1</code> term and specfiying <code>intercept
    = TRUE</code> in the <code>vc</code> term. If varying intercepts are desired, we
recommend to always remove the global intercepts. For more details on
the formula specification, see <code><a href="#topic+olmm">olmm</a></code> and
<code><a href="#topic+vcrpart-formula">vcrpart-formula</a></code>.</p>
</td></tr>   
<tr><td><code id="tvcolmm_+3A_family">family</code></td>
<td>
<p>the model family. An object of class
<code><a href="#topic+family.olmm">family.olmm</a></code>.</p>
</td></tr>    
<tr><td><code id="tvcolmm_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_weights">weights</code></td>
<td>
<p>an optional numeric vector of weights to be used in the 
fitting process.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_subset">subset</code></td>
<td>
<p>an optional logical or integer vector specifying a
subset of <code>'data'</code> to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component 
to be included in the linear predictor during fitting.</p>
</td></tr> 	
<tr><td><code id="tvcolmm_+3A_na.action">na.action</code></td>
<td>
<p>a function that indicates what should happen if data 
contain <code>NA</code>s. The default <code>na.action = na.omit</code> is
listwise deletion, i.e., observations with missings on any variable
are dropped. See <code><a href="stats.html#topic+na.action">na.action</a></code>.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_control">control</code></td>
<td>
<p>a list with control parameters as returned by
<code><a href="#topic+tvcolmm_control">tvcolmm_control</a></code>, or by <code><a href="#topic+tvcm_control">tvcm_control</a></code>
for advanced users.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_sctest">sctest</code></td>
<td>
<p>logical scalar. Defines whether coefficient constancy
tests should be used for the variable and node selection in each
iteration.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_alpha">alpha</code></td>
<td>
<p>numeric significance threshold between 0 and 1. A node is
splitted when the smallest (possibly Bonferroni-corrected) <code class="reqn">p</code>
value for any coefficient constancy test in the current step falls
below <code>alpha</code>.</p>
</td></tr>  
<tr><td><code id="tvcolmm_+3A_bonferroni">bonferroni</code></td>
<td>
<p>logical. Indicates if and how <code class="reqn">p</code>-values of
coefficient constancy tests must be Bonferroni
corrected. See details.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_minsize">minsize</code></td>
<td>
<p>numeric scalar. The minimum sum of weights in terminal
nodes.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_maxnomsplit">maxnomsplit</code>, <code id="tvcolmm_+3A_maxordsplit">maxordsplit</code>, <code id="tvcolmm_+3A_maxnumsplit">maxnumsplit</code></td>
<td>
<p>integer scalars for split
candidate reduction. See <code><a href="#topic+tvcm_control">tvcm_control</a></code>.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_fast">fast</code></td>
<td>
<p>logical scalar. Whether the approximative model should be
used to search for the next split. See
<code><a href="#topic+tvcm_control">tvcm_control</a></code>.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_trim">trim</code></td>
<td>
<p>numeric between 0 and 1. Specifies the trimming parameter
in coefficient constancy tests for continuous partitioning
variables. See also the argument <code>from</code> of function
<code>supLM</code> in package <span class="pkg">strucchange</span>.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_estfun.args">estfun.args</code></td>
<td>
<p>list of arguments to be passed to
<code><a href="#topic+olmm_gefp">olmm_gefp</a></code>. See details.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_nimpute">nimpute</code></td>
<td>
<p>a positive integer scalar. The number of times
coefficient constancy tests should be repeated in each
iteration. See details.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_seed">seed</code></td>
<td>
<p>an integer specifying which seed should be set at the
beginning.</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_maxstep">maxstep</code></td>
<td>
<p>integer. The maximum number of iterations i.e. number
of splits to be processed.</p>
</td></tr>  
<tr><td><code id="tvcolmm_+3A_verbose">verbose</code></td>
<td>
<p>logical. Should information about the fitting process
be printed to the screen?</p>
</td></tr>
<tr><td><code id="tvcolmm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the fitting function
<code>fit</code> or to <code><a href="#topic+tvcm_control">tvcm_control</a></code>.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+tvcolmm">tvcolmm</a></code> function iterates the following steps:
</p>

<ol>
<li><p> Fit the current mixed model
</p>
<p><code>y ~ Node:x1 + ... + Node:xP + re(1 + w1 + ... |id)</code>
</p>
<p>with <code><a href="#topic+olmm">olmm</a></code>, where <code>Node</code> is a categorical
variable with terminal node labels <code>1</code>, ..., <code>M</code>. 
</p>
</li>
<li><p> Test the constancy of the fixed effects <code>Node:x1,
    ...</code>, separately for each moderator <code>z1</code>, ..., <code>zL</code>
in each node <code>1</code>, ..., <code>M</code>. This yields <code>L</code> times
<code>M</code> (possibly Bonferroni corrected) <code class="reqn">p</code>-values for
rejecting coefficient constancy.
</p>
</li>
<li><p> If the minimum <code class="reqn">p</code>-value is smaller than <code>alpha</code>,
then select the node and the variable corresponding to the minimum
<code class="reqn">p</code>-value. Search and incorporate the optimal
among the candidate splits in the selected node and variable by
exhaustive likelihood search.
</p>
</li>
<li><p> Else if minimum <code class="reqn">p</code>-value is larger than <code>alpha</code>,
stop the algorithm and return the current model.
</p>
</li></ol>

<p>The implemented coefficient constancy tests used for node and variable
selection (step 2) are based on the M-fluctuation tests of Zeileis and
Hornik (2007), using the observation scores of the fitted mixed
model. The observation scores can be extracted by
<code><a href="#topic+olmm_estfun">olmm_estfun</a></code> for models fitted with
<code><a href="#topic+olmm">olmm</a></code>. To deal with intra-individual correlations
between such observation scores, the <code><a href="#topic+olmm_estfun">olmm_estfun</a></code>
function decorrelates the observation scores. In cases of unbalanced
data, the pre-decorrelation method requires imputation. <code>nimpute</code>
gives the number of times the coefficient constancy tests are repeated
in each iteration. The final <code class="reqn">p</code>-values are then the averages of
the repetations.
</p>
<p>The algorithm combines the splitting technique of Zeileis (2008) with
the technique of Hajjem et. al (2011) and Sela and Simonoff (2012) to
incorporate regression trees into mixed models.
</p>
<p>For the exhaustive search, the algorithm implements a number of split
point reduction methods to decrease the computational complexity. See
the arguments <code>maxnomsplit</code>, <code>maxordsplit</code> and
<code>maxnumsplit</code>. By default, the algorithm also uses the
approximative search model approach proposed in Burgin and Ritschard
(2017). To disable this option to use the original algorithm, set
<code>fast = FALSE</code> in <code><a href="#topic+tvcolmm_control">tvcolmm_control</a></code>.
</p>
<p>Special attention is given to varying intercepts, i.e. the terms that
account for the direct effects of the moderators. A common
specification is 
</p>
<p><code>y ~ -1 + vc(z1, ..., zL, by = x1 + ... + xP, intercept = TRUE) + re(1 + w1 + ... |id)</code>
</p>
<p>Doing so replaces the globale intercept by local intercepts. As
mentioned, if a varying intercepts are desired, we recommend to always
remove the global intercept. 
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tvcm">tvcm</a></code>
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>References</h3>

<p>Zeileis, A., T. Hothorn, and K. Hornik (2008). Model-Based
Recursive Partitioning. <em>Journal of Computational and Graphical
Statistics</em>, <b>17</b>(2), 492&ndash;514. 
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for
Parameter Instability, <em>Statistica Neerlandica</em>, <b>61</b>(4),
488&ndash;508.
</p>
<p>Burgin R. and Ritschard G. (2015), Tree-Based Varying Coefficient 
Regression for Longitudinal Ordinal Responses. <em>Computational
Statistics &amp; Data Analysis</em>, <b>86</b>, 65&ndash;80.
</p>
<p>Burgin, R. and G. Ritschard (2017), Coefficient-Wise Tree-Based
Varying Coefficient Regression with vcrpart. <em>Journal of
Statistical Software</em>, <b>80</b>(6), 1&ndash;33.
</p>
<p>Sela R. and J. S. Simonoff (2012). RE-EM trees: A Data Mining
Approach for Longitudinal and Clustered data, <em>Machine Learning</em>
<b>86</b>(2), 169&ndash;207. 
</p>
<p>A. Hajjem, F. Bellavance and D. Larocque (2011), Mixed Effects
Regression Trees for Clustered Data, <em>Statistics &amp; Probability
Letters</em> <b>81</b>(4), 451&ndash;459.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm_control">tvcm_control</a></code>, <code><a href="#topic+tvcm-methods">tvcm-methods</a></code>,
<code><a href="#topic+tvcm-plot">tvcm-plot</a></code>, <code><a href="#topic+fvcolmm">fvcolmm</a></code>,
<code><a href="#topic+olmm">olmm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## ------------------------------------------------------------------- # 
## Example: Moderated effect effect of unemployment
##
## Here we fit a varying coefficient ordinal linear mixed on the 
## synthetic ordinal longitudinal data 'unemp'. The interest is whether 
## the effect of unemployment 'UNEMP' on happiness 'GHQL' is moderated 
## by 'AGE', 'FISIT', 'GENDER' and 'UEREGION'. 'FISIT' is the only true  
## moderator. For the the partitioning we coefficient constancy tests,
## as described in Burgin and Ritschard (2015)
## ------------------------------------------------------------------- #

data(unemp)

## fit the model
model.UE &lt;-
  tvcolmm(GHQL ~ -1 + 
          vc(AGE, FISIT, GENDER, UEREGION, by = UNEMP, intercept = TRUE) +
          re(1|PID), data = unemp)

## diagnosis
plot(model.UE, "coef")
summary(model.UE)
splitpath(model.UE, steps = 1, details = TRUE)
</code></pre>

<hr>
<h2 id='vcrpart-demo'>Synthetic data sets</h2><span id='topic+vcrpart-demo'></span><span id='topic+vcrpart_1'></span><span id='topic+vcrpart_2'></span><span id='topic+vcrpart_3'></span><span id='topic+unemp'></span>

<h3>Description</h3>

<p>Synthetic data for illustrations.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vcrpart_1)
data(vcrpart_2)
data(vcrpart_3)
data(unemp)
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>y</code></dt><dd><p>ordered factor. The response variable</p>
</dd>
<dt><code>id, PID</code></dt><dd><p>factor. The subject identification vector.</p>
</dd>
<dt><code>wave</code></dt><dd><p>numeric. The wave identification vector.</p>
</dd>
<dt><code>treat</code></dt><dd><p>a dummy variable. The treatment effect.</p>
</dd>
<dt><code>x1, x2</code></dt><dd><p>numeric predictor variables.</p>
</dd>
<dt><code>z1, z2, z3, z2</code></dt><dd><p>moderator (partitioning) variables.</p>
</dd>
<dt><code>GHQL</code></dt><dd><p>self rated general happiness.</p>
</dd>
<dt><code>YEAR</code></dt><dd><p>survey year.</p>
</dd>
<dt><code>UNEMP</code></dt><dd><p>unemployed or not.</p>
</dd>
<dt><code>AGE</code></dt><dd><p>age.</p>
</dd>
<dt><code>FISIT</code></dt><dd><p>self-reported financial situation.</p>
</dd>
<dt><code>GENDER</code></dt><dd><p>gender.</p>
</dd>
<dt><code>UEREGION</code></dt><dd><p>regional unemployment.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+olmm">olmm</a></code>, <code><a href="#topic+otsplot">otsplot</a></code>,
<code><a href="#topic+tvcm">tvcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## --------------------------------------------------------- #
## generating 'vcrpart_1'
## --------------------------------------------------------- #

## create skeletton
set.seed(1)
vcrpart_1 &lt;- data.frame(id = factor(rep(1:50, each = 4)),
                        wave = rep(1:4, 50),
                        treat = sample(0:1, 200, TRUE))

## add partitioning variables
vcrpart_1$z1 &lt;- rnorm(50)[vcrpart_1$id]
vcrpart_1$z2 &lt;- rnorm(200)
vcrpart_1$z3 &lt;- factor(sample(1:2, 50, TRUE)[vcrpart_1$id])
vcrpart_1$z4 &lt;- factor(sample(1:2, 200, TRUE))

## simulate response
eta &lt;- 2 * vcrpart_1$treat * (vcrpart_1$z4 == "1")
eta &lt;- eta + rnorm(50)[vcrpart_1$id] + rlogis(200)
vcrpart_1$y &lt;- cut(-eta, c(-Inf, -1, 1, Inf), 1:3,
                   ordered_result = TRUE)


## --------------------------------------------------------- #
## generating 'vcrpart_2'
## --------------------------------------------------------- #

set.seed(1)
vcrpart_2 &lt;- data.frame(x1 = rnorm(100),
                        x2 = rnorm(100),
                        z1 = factor(sample(1:3, 100, TRUE)),
                        z2 = factor(sample(1:3, 100, TRUE)))
vcrpart_2$y &lt;- vcrpart_2$x1 * (vcrpart_2$z1 == "2") +
  2 * vcrpart_2$x1 * (vcrpart_2$z1 == "3")
vcrpart_2$y &lt;- vcrpart_2$y + rnorm(100)

## --------------------------------------------------------- #
## generating 'vcrpart_3'
## --------------------------------------------------------- #

set.seed(1)
vcrpart_3 &lt;- data.frame(x1 = rnorm(100),
                        z1 = runif(100, -pi/2, pi/2))
vcrpart_3$y &lt;- vcrpart_3$x1 * sin(vcrpart_3$z1) + rnorm(100)

## --------------------------------------------------------- #
## generating 'unemp'
## --------------------------------------------------------- #

## create skeletton
set.seed(1)
unemp &lt;- data.frame(PID = factor(rep(1:50, each = 4)),
                    UNEMP = rep(c(0, 0, 1, 1), 50),
               	    YEAR = rep(2001:2004, 50))

## add partitioning variables
unemp$AGE &lt;- runif(50, 25, 60)[unemp$PID] + unemp$YEAR - 2000
unemp$FISIT &lt;- ordered(sample(1:5, 200, replace = TRUE))
unemp$GENDER &lt;- factor(sample(c("female", "male"), 50, replace = TRUE)[unemp$PID])
unemp$UEREGION &lt;- runif(50, 0.02, 0.1)[unemp$PID]

## simulate response
eta &lt;- 2 * unemp$UNEMP * (unemp$FISIT == "1" | unemp$FISIT == "2")
eta &lt;- eta + rnorm(50)[unemp$PID] + rlogis(200)
unemp$GHQL &lt;- cut(-eta, c(-Inf, -1, 0, 1, Inf), 1:4,
                  ordered_result = TRUE)

</code></pre>

<hr>
<h2 id='vcrpart-formula'>Special terms for formulas.</h2><span id='topic+vcrpart-formula'></span><span id='topic+fe'></span><span id='topic+vc'></span><span id='topic+re'></span><span id='topic+ce'></span><span id='topic+ge'></span>

<h3>Description</h3>

<p>Special terms for formulas assigned to <code><a href="#topic+tvcm">tvcm</a></code>,
<code><a href="#topic+fvcm">fvcm</a></code> and <code><a href="#topic+olmm">olmm</a></code>.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fe(formula, intercept = TRUE)
re(formula, intercept = TRUE)
vc(..., by, intercept = missing(by), nuisance = character())
ce(formula)
ge(formula)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vcrpart-formula_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the corresponding component
of the formula component. See examples.</p>
</td></tr>
<tr><td><code id="vcrpart-formula_+3A_intercept">intercept</code></td>
<td>
<p>logical or character vector. <code>intercept = TRUE</code>
(default) indicates that an intercept is incorporated.
<code>intercept = FALSE</code> removes the random intercept from the
formula. Note that the sometimes allowed <code>-1</code>
term is ignored. The character strings <code>"ce"</code>
(category-specific random intercepts) and <code>"ge"</code>
(category-global random intercepts) may be used in connection with
<code><a href="#topic+olmm">olmm</a></code>. Intercepts have specific interpretations for
<code>fe</code>, <code>re</code> and <code>vc</code>, see the details.</p>
</td></tr>  
<tr><td><code id="vcrpart-formula_+3A_...">...</code></td>
<td>
<p>the names of variables that moderate (i.e. modify) the
effects of the variables specified in <code>by</code>, separated by
commas. It is also possibly to assign a vector that contains the
variable names as characters. Note that operators like
<code>factor(x)</code> are not allowed.</p>
</td></tr>  
<tr><td><code id="vcrpart-formula_+3A_by">by</code></td>
<td>
<p>a formula of predictors the effects of which are moderated
by the variables in <code>...</code>. See <code><a href="#topic+tvcm">tvcm</a></code> and the
examples below. Note that the <code>by</code> variable must be numeric and
factor variables must be recoded to dummy variables by hand.</p>
</td></tr>
<tr><td><code id="vcrpart-formula_+3A_nuisance">nuisance</code></td>
<td>
<p>character vector of variables in <code>by</code> which have
to be estimated separately for each partition but the algorithm should
not focus on this variable when searching for splits.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Special formula terms to define fixed effects <code><a href="#topic+fe">fe</a></code>,
varying coefficients <code><a href="#topic+vc">vc</a></code> and random effects
<code><a href="#topic+re">re</a></code>. The use of these formula terms ensures that
the functions <code><a href="#topic+fvcm">fvcm</a></code>, <code><a href="#topic+tvcm">tvcm</a></code> and
<code><a href="#topic+olmm">olmm</a></code> fit the intended model. Some examples are given
below and on the documentation pages of the fitting functions.
</p>
<p>For all of <code><a href="#topic+fvcm">fvcm</a></code>, <code><a href="#topic+tvcm">tvcm</a></code> and
<code><a href="#topic+olmm">olmm</a></code>, variables which are not defined with one of
<code><a href="#topic+fe">fe</a></code>, <code><a href="#topic+vc">vc</a></code> and <code><a href="#topic+re">re</a></code> are
treated as fixed effects. Intercepts can be dropped from the model by
the <code>intercept</code> argument. The terms <code><a href="#topic+ce">ce</a></code>
(category-specific effects) and <code><a href="#topic+ge">ge</a></code> (global effect or
proportional odds effect) are designed for the function
<code><a href="#topic+olmm">olmm</a></code>. Notice that <code><a href="#topic+tvcm">tvcm</a></code> may changes,
for internal reasons, the order of the terms in the specified
formula. Note that you can put multiple terms within
<code><a href="#topic+fe">fe</a></code>, <code><a href="#topic+ge">ge</a></code> and <code><a href="#topic+ce">ce</a></code> terms
(e.g., <code>fe(ce(x1 + x2 + ge(x3 + x4))</code>).
</p>
<p>At present, the term <code>"."</code>, which is often use to extract all
variables of the data, is ignored. As an alternative,
<code><a href="#topic+vc">vc</a></code> interprets character vectors, assigned as unnamed
arguments, as lists of variables of moderators to be extracted from
<code>data</code>. See the examples below.
</p>
<p>Default for intercepts in <code><a href="#topic+fe">fe</a></code> terms is <code>intercept
    = TRUE</code>, or <code>intercept = "ce"</code> for models fitted with
<code><a href="#topic+olmm">olmm</a></code>. This means that an intercept is automatically
attached. Alternatives are <code>intercept = FALSE</code>, which is equal to
<code>intercept = "none"</code>, and <code>intercept = "ge"</code>, which yields a
global-effect intercept for models fitted with <code><a href="#topic+olmm">olmm</a></code>.
</p>
<p>Default for intercepts in <code><a href="#topic+vc">vc</a></code> is to introduce an
intercept if the <code>by</code> argument is ignored, otherwise no intercept
is introduced. Specifically, if input is specified for the <code>by</code>
argument, then  <code>intercept = TRUE</code>, or <code>intercept = "ce"</code>
for models fitted by <code><a href="#topic+olmm">olmm</a></code>. Alternatives are
<code>intercept = FALSE</code>, which is equal to <code>intercept = "none"</code>,
and <code>intercept = "ge"</code>, which yields a global-effect varying
intercept. 
</p>
<p>Default for intercepts in <code><a href="#topic+re">re</a></code> is <code>intercept =
  TRUE</code>, which is equal to <code>intercept = "ge"</code>. <code>intercept =
  FALSE</code> is equal to <code>intercept = "none"</code>. For category-specific
random intercepts, use <code>intercept = "ge"</code>. See
<code><a href="#topic+olmm">olmm</a></code>. 
</p>


<h3>Value</h3>

<p>a list used by <code><a href="#topic+tvcm">tvcm</a></code>, <code><a href="#topic+fvcm">fvcm</a></code> and
<code><a href="#topic+olmm">olmm</a></code> for constructing the model matrices.
</p>


<h3>Author(s)</h3>

<p>Reto Burgin</p>


<h3>See Also</h3>

<p><code><a href="#topic+tvcm">tvcm</a></code>, <code><a href="#topic+fvcm">fvcm</a></code>,
<code><a href="#topic+olmm">olmm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Formula for a model with 2 fixed effects (x1 and x2) and a random
## intercept. The 're' terms indicates that an intercept is fitted for
## each level of 'id'.

formula &lt;- y ~ fe(x1 + x2) + re(1|id)

## Formula for a model with one fixed effect and one varying coefficient
## term with 2 moderators and 2 varying coefficient predictors. 'tvcm'
## will fit one partition to model the effects of 'x2' and 'x3' as
## functions of 'z1' and 'z2'.

formula &lt;- y ~ x1 + vc(z1, z2, by = x2 + x3, intercept = TRUE)

## Similar formula as above, but the predictors 'x2' and 'x3' have
## separate 'vc' terms. 'tvcm' will fit a separate partition for each of
## 'x2' and 'x3' to model their effects as functions of 'z1' and 'z2'.

formula &lt;- y ~ x1 + vc(z1, z2, by = x2) + vc(z1, z2, by = x3)

## As an alternative to '.' you can define variables in a vector
vars &lt;- c("x1", "x2", "x3")
formula &lt;- y ~ x1 + vc(vars, by = x2) + vc(vars, by = x3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
