<!DOCTYPE html><html lang="en"><head><title>Help for package Rstg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Rstg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pystg_is_available'><p>Check whether STG Python package is available and can be loaded</p></a></li>
<li><a href='#stg'><p>STG: Feature Selection using Stochastic Gates</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>STG : Feature Selection using STochastic Gates</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>'STG' is a method for feature selection in neural network. The procedure is based on probabilistic relaxation of the l0 norm of features, or the count of the number of selected features. The framework simultaneously learns either a nonlinear regression or classification function while selecting a small subset of features. Read more: Yamada et al. (2020) <a href="https://proceedings.mlr.press/v119/yamada20a.html">https://proceedings.mlr.press/v119/yamada20a.html</a>.</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate (&ge; 1.4)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-12-12 02:33:36 UTC; yutaro</td>
</tr>
<tr>
<td>Author:</td>
<td>Yutaro Yamada [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yutaro Yamada &lt;yutaro.yamada@yale.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-12-13 11:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='pystg_is_available'>Check whether STG Python package is available and can be loaded</h2><span id='topic+pystg_is_available'></span>

<h3>Description</h3>

<p>This is used to avoid running tests on CRAN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pystg_is_available()
</code></pre>


<h3>Value</h3>

<p>No return value, called for side effects
</p>

<hr>
<h2 id='stg'>STG: Feature Selection using Stochastic Gates</h2><span id='topic+stg'></span>

<h3>Description</h3>

<p>STG is a method for feature selection in neural network estimation problems.
The new procedure is based on probabilistic relaxation of the l0 norm of
features, or the count of the number of selected features.
STG simultaneously learns either a nonlinear regression
or classification function while selecting a small subset of features,
as described in Yamada, et al, ICML 2020.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stg(
  task_type,
  input_dim,
  output_dim,
  hidden_dims,
  activation = "relu",
  sigma = 0.5,
  lam = 0.1,
  optimizer = "Adam",
  learning_rate = 0.001,
  batch_size = 100L,
  freeze_onward = NULL,
  feature_selection = TRUE,
  weight_decay = 0.001,
  random_state = 123L,
  device = "cpu"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stg_+3A_task_type">task_type</code></td>
<td>
<p>string
choose 'regression', 'classification', or 'cox'</p>
</td></tr>
<tr><td><code id="stg_+3A_input_dim">input_dim</code></td>
<td>
<p>integer
The number of features of your data (input dimension)</p>
</td></tr>
<tr><td><code id="stg_+3A_output_dim">output_dim</code></td>
<td>
<p>integer
The number of classes for 'classification'. Should be 1 for 'regression' and 'cox'</p>
</td></tr>
<tr><td><code id="stg_+3A_hidden_dims">hidden_dims</code></td>
<td>
<p>vector of integers,optional,default:c(60, 20, 3)
architecture vector of the neural network</p>
</td></tr>
<tr><td><code id="stg_+3A_activation">activation</code></td>
<td>
<p>string
the type of activation functions.</p>
</td></tr>
<tr><td><code id="stg_+3A_sigma">sigma</code></td>
<td>
<p>float
the noise level for the gaussian distribution</p>
</td></tr>
<tr><td><code id="stg_+3A_lam">lam</code></td>
<td>
<p>float
the regularization parameter</p>
</td></tr>
<tr><td><code id="stg_+3A_optimizer">optimizer</code></td>
<td>
<p>string
choose 'Adam' or 'SGD'</p>
</td></tr>
<tr><td><code id="stg_+3A_learning_rate">learning_rate</code></td>
<td>
<p>float</p>
</td></tr>
<tr><td><code id="stg_+3A_batch_size">batch_size</code></td>
<td>
<p>int</p>
</td></tr>
<tr><td><code id="stg_+3A_freeze_onward">freeze_onward</code></td>
<td>
<p>integer, default:NULL
the network parameters will be frozen after 'freeze_onward' epoch.
This is to train the gate parameters.</p>
</td></tr>
<tr><td><code id="stg_+3A_feature_selection">feature_selection</code></td>
<td>
<p>bool</p>
</td></tr>
<tr><td><code id="stg_+3A_weight_decay">weight_decay</code></td>
<td>
<p>float</p>
</td></tr>
<tr><td><code id="stg_+3A_random_state">random_state</code></td>
<td>
<p>integer</p>
</td></tr>
<tr><td><code id="stg_+3A_device">device</code></td>
<td>
<p>string
'cpu' or 'cuda' (if you have GPU)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a &quot;stg&quot; object is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (pystg_is_available()){
n_size &lt;- 1000L;
p_size &lt;- 20L;
stg.model &lt;- stg(task_type='regression', input_dim=p_size, output_dim=1L,
hidden_dims = c(500,50, 10), activation='tanh',
optimizer='SGD', learning_rate=0.1, batch_size=n_size,
feature_selection=TRUE, sigma=0.5, lam=0.1, random_state=0.1)
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
