<!DOCTYPE html><html lang="en"><head><title>Help for package mergen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mergen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#check_install'><p>Check and Install R Package</p></a></li>
<li><a href='#clean_code_blocks'><p>Clean code blocks returned by the agent</p></a></li>
<li><a href='#executeCode'><p>execute code</p></a></li>
<li><a href='#extractCode'><p>extract the code and text from the text returned by LLM agent</p></a></li>
<li><a href='#extractFilenames'><p>Extract file names from user prompt</p></a></li>
<li><a href='#extractInstallPkg'><p>extract package names and install them</p></a></li>
<li><a href='#fileHeaderPrompt'><p>Extract file headers from files in prompt</p></a></li>
<li><a href='#promptContext'><p>Predefined prompt contexts for prompt engineering</p></a></li>
<li><a href='#runCodeInResponse'><p>Executes the code in the received response from the agent</p></a></li>
<li><a href='#sampleResponse'><p>Sample more solutions when non-executable code returned by the agent</p></a></li>
<li><a href='#selfcorrect'><p>Self correct the code returned by the agent</p></a></li>
<li><a href='#sendPrompt'><p>Send a prompt to a specified language model agent and return the response.</p></a></li>
<li><a href='#setupAgent'><p>set up an online LLM API for subsequent tasks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>AI-Driven Code Generation, Explanation and Execution for Data
Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Employing artificial intelligence to convert data analysis questions into executable code, explanations, and algorithms. The self-correction feature ensures the generated code is optimized for performance and accuracy. 'mergen' features a user-friendly chat interface, enabling users to interact with the AI agent and extract valuable insights from their data effortlessly.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/BIMSBbioinfo/mergen">https://github.com/BIMSBbioinfo/mergen</a>,
<a href="https://bioinformatics.mdc-berlin.de/mergen/">https://bioinformatics.mdc-berlin.de/mergen/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/BIMSBbioinfo/mergen/issues">https://github.com/BIMSBbioinfo/mergen/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>openai, rmarkdown, BiocManager, assertthat (&ge; 0.2.1), httr,
jsonlite</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, readxl, data.table (&ge; 1.9.6), testthat (&ge; 3.0.0),
purrr (&ge; 0.3.4),</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Collate:</td>
<td>'setupAgent.R' 'parseBotResponse.R' 'sendPrompt.R'
'executeCode.R' 'selfcorrect.R' 'clean_code_blocks.R'
'extractInstallPkg.R' 'extractFilenames.R' 'fileHeaderPrompt.R'
'test-helper-test_argument_validation.R' 'promptContext.R'
'runCodeInResponse.R'</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-27 07:22:12 UTC; aakalin</td>
</tr>
<tr>
<td>Author:</td>
<td>Altuna Akalin <a href="https://orcid.org/0000-0002-0468-0117"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Jacqueline Anne Jansen [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Altuna Akalin &lt;aakalin@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-27 10:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='check_install'>Check and Install R Package</h2><span id='topic+check_install'></span>

<h3>Description</h3>

<p>This function checks if an R package is installed, and if not, attempts to install
it using either the standard CRAN repository or the Bioconductor repository.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_install(package_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check_install_+3A_package_name">package_name</code></td>
<td>
<p>A character string specifying the name of the package to be checked and installed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE if the package is already installed or can be installed. FALSE otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Check and install "dplyr" package
check_install("dplyr")


</code></pre>

<hr>
<h2 id='clean_code_blocks'>Clean code blocks returned by the agent</h2><span id='topic+clean_code_blocks'></span>

<h3>Description</h3>

<p>This function cleans up the response
returned by the agent to ensure code blocks
can run. It ensures that characters such as
'R' and 'r' are cleaned from code blocks in the agents
response, so that the code blocks are able to be extracted by
the extractCode() function and ran as expected. It also cleans
the response from any install.package calls, and recorded output,
so that when code blocks are extracted, the code can run smoothly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_code_blocks(response)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clean_code_blocks_+3A_response">response</code></td>
<td>
<p>response received from the agent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string holding the response of the agent, cleaned from any unwanted characters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
response &lt;- "To perform PCA, do the following: ```R prcomp(data)``` This funcion will perform PCA."
clean_code &lt;- clean_code_blocks(response)
}
</code></pre>

<hr>
<h2 id='executeCode'>execute code</h2><span id='topic+executeCode'></span>

<h3>Description</h3>

<p>The function executes a chunk of code either in the current working environment
or saves the output as an HTML file to be rendered as a part of a web page
</p>


<h3>Usage</h3>

<pre><code class='language-R'>executeCode(code, output = "eval", output.file = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="executeCode_+3A_code">code</code></td>
<td>
<p>code chunk as text, without any decorators or HTML-specific characters.</p>
</td></tr>
<tr><td><code id="executeCode_+3A_output">output</code></td>
<td>
<p>If the output is &quot;eval&quot;, the code is executed as is. If the output is &quot;html&quot;,
the code is not executed.</p>
</td></tr>
<tr><td><code id="executeCode_+3A_output.file">output.file</code></td>
<td>
<p>If the output is &quot;html&quot;, user can provide a file name for the html.
If not provided a temporary file will be created.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the output is &quot;eval&quot;: if running the code causes errors, errors are returned.
Otherwise NA is returned  If output is &quot;html&quot;, output file is returned.
</p>

<hr>
<h2 id='extractCode'>extract the code and text from the text returned by LLM agent</h2><span id='topic+extractCode'></span>

<h3>Description</h3>

<p>This function parses the agents answer and returns the text and code as single blocks.
The results can be used for code execution and might be useful for displaying purposes later on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractCode(text, delimiter = "```")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractCode_+3A_text">text</code></td>
<td>
<p>A character string containing the text with embedded code blocks.</p>
</td></tr>
<tr><td><code id="extractCode_+3A_delimiter">delimiter</code></td>
<td>
<p>A character string representing the delimiter used to enclose the code blocks (default: &quot;&ldquo;'&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two elements: 'code' and 'text'. 'code' contains the concatenated code blocks, and
'text' contains the remaining text with code blocks removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>text &lt;- "\n\nThe following, normalize the table and do PCA.
\n\n```\ndata &lt;- read.table(\"test.txt\", header = TRUE, sep = \"\\t\")\n```"
result &lt;- extractCode(text)
print(result$code)
print(result$text)


</code></pre>

<hr>
<h2 id='extractFilenames'>Extract file names from user prompt</h2><span id='topic+extractFilenames'></span>

<h3>Description</h3>

<p>This function extracts file names from the user prompt. Current filenames that
are supported by this function are *.txt, *.tsv, *.csv *.xls, *.xlsx,
*.bed, *.bigWig, *.bw and *.bigBed. Other filenames will not be extracted.
If no filenames are found, the function will return NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFilenames(text)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractFilenames_+3A_text">text</code></td>
<td>
<p>user prompt</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list holding file names from the user prompt.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
user_prompt &lt;- "How do I perform PCA on data in my file called test.txt?"
extractFilenames(text=user_prompt)
}
</code></pre>

<hr>
<h2 id='extractInstallPkg'>extract package names and install them</h2><span id='topic+extractInstallPkg'></span>

<h3>Description</h3>

<p>This function extracts all package names that
are needed to run the code returned by the agent
and installs them as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractInstallPkg(code)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractInstallPkg_+3A_code">code</code></td>
<td>
<p>code block returned by the agent.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>final status of the packages as a logical vector, TRUE if packages is already installed
or could be installed. FALSE if the package can't be install.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Check code for packages that need installing
code &lt;- "library(devtools)\n x&lt;-5"
extractInstallPkg(code)


</code></pre>

<hr>
<h2 id='fileHeaderPrompt'>Extract file headers from files in prompt</h2><span id='topic+fileHeaderPrompt'></span>

<h3>Description</h3>

<p>This function extracts file headers from
files. Recommended is to use this function
with the results from <code><a href="#topic+extractFilenames">extractFilenames</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fileHeaderPrompt(filenames)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fileHeaderPrompt_+3A_filenames">filenames</code></td>
<td>
<p>list containing file names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string containing the file headers of the files in &quot;filenames&quot; list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
prompt &lt;- "how do I perform PCA on data in a file called test.txt?"
filenames &lt;- extractFilenames(prompt)
fileHeaderPrompt(filenames)

## End(Not run)
</code></pre>

<hr>
<h2 id='promptContext'>Predefined prompt contexts for prompt engineering</h2><span id='topic+promptContext'></span>

<h3>Description</h3>

<p>This function holds various predefined prompt
contexts that can be used for prompt engineering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>promptContext(type = "simple")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="promptContext_+3A_type">type</code></td>
<td>
<p>specifies the type of context you wish to be returned.
Valid options are &quot;simple&quot;, &quot;actAs&quot;, &quot;CoT&quot; and &quot;rbionfoExp&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string holding the predefined context.
</p>

<hr>
<h2 id='runCodeInResponse'>Executes the code in the received response from the agent</h2><span id='topic+runCodeInResponse'></span>

<h3>Description</h3>

<p>The function extracts and executes the code in the response. If required it can
try to correct errors in the code via different strategies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runCodeInResponse(
  response,
  prompt = NULL,
  agent = NULL,
  context = NULL,
  correction = c("none", "selfcorrect", "sampleMore", "sampleThenCorrect",
    "correctThenSample"),
  attempts = 3,
  output.file = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runCodeInResponse_+3A_response">response</code></td>
<td>
<p>response to be parsed for code and executed</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_prompt">prompt</code></td>
<td>
<p>prompt for the response, if correction=&quot;none&quot; it is not needed</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_agent">agent</code></td>
<td>
<p>AI agent, if correction=&quot;none&quot; it is not needed</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_context">context</code></td>
<td>
<p>context for the prompt, if correction=&quot;none&quot; it is not needed</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_correction">correction</code></td>
<td>
<p>&quot;none&quot; no code correction is needed. &quot;selfcorrect&quot; feedback the errors to LLM and ask for fix.
&quot;sampleMore&quot; sample responses for the #prompt until an executable code is returned or number of attempts reached.
&quot;correctThenSample&quot; first try self-correct &quot;attempt&quot; number of times.
If no executable code is returned. It will sample new responses &quot;attempt&quot; number of times or until executable code</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_attempts">attempts</code></td>
<td>
<p>Numeric value denoting how many times the code should be sent back for fixing.</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_output.file">output.file</code></td>
<td>
<p>Optional output file created holding parsed code</p>
</td></tr>
<tr><td><code id="runCodeInResponse_+3A_...">...</code></td>
<td>
<p>arguments to sendPrompt()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table role = "presentation">
<tr><td><code>init.response</code></td>
<td>
<p>A character vector representing the initial prompt response.</p>
</td></tr>
<tr><td><code>init.blocks</code></td>
<td>
<p>A list of initial blocks.</p>
</td></tr>
<tr><td><code>final.blocks</code></td>
<td>
<p>A list of final blocks.</p>
</td></tr>
<tr><td><code>code.works</code></td>
<td>
<p>A boolean value indicating whether the code works.</p>
</td></tr>
<tr><td><code>exec.result</code></td>
<td>
<p>A character string representing the execution results.</p>
</td></tr>
<tr><td><code>tried.attempts</code></td>
<td>
<p>An integer representing the number of attempts.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+selfcorrect">selfcorrect</a></code>,<code><a href="#topic+sampleResponse">sampleResponse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

resp.list &lt;- runCodeInResponse(agent,prompt,context=rbionfoExp,correction="sampleMore",attempt=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='sampleResponse'>Sample more solutions when non-executable code returned by the agent</h2><span id='topic+sampleResponse'></span>

<h3>Description</h3>

<p>The function attempts to sample more solutions by the agent when
the code returned by the agent is faulty. The function simply asks for solutions
until an executable code is returned or until number of attempts is reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleResponse(
  agent,
  prompt,
  context = rbionfoExp,
  attempts = 3,
  output.file = NULL,
  responseWithError = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleResponse_+3A_agent">agent</code></td>
<td>
<p>An object containing the agent's information (e.g., type and model).</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_prompt">prompt</code></td>
<td>
<p>The prompt text to send to the language model.</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_context">context</code></td>
<td>
<p>Optional context to provide alongside the prompt (default is rbionfoExp).</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_attempts">attempts</code></td>
<td>
<p>Numeric value denoting how many times the code should be sent back for fixing.</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_output.file">output.file</code></td>
<td>
<p>Optional output file created holding parsed code</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_responsewitherror">responseWithError</code></td>
<td>
<p>a list of response and errors returned from executeCode().
First element is expected to be the response and the second element is the error list returned by executeCode().</p>
</td></tr>
<tr><td><code id="sampleResponse_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the <code><a href="#topic+sendPrompt">sendPrompt</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table role = "presentation">
<tr><td><code>init.response</code></td>
<td>
<p>A character vector representing the initial prompt response.</p>
</td></tr>
<tr><td><code>init.blocks</code></td>
<td>
<p>A list of initial blocks.</p>
</td></tr>
<tr><td><code>final.blocks</code></td>
<td>
<p>A list of final blocks.</p>
</td></tr>
<tr><td><code>code.works</code></td>
<td>
<p>A boolean value indicating whether the code works.</p>
</td></tr>
<tr><td><code>exec.result</code></td>
<td>
<p>A character string representing the execution results.</p>
</td></tr>
<tr><td><code>tried.attempts</code></td>
<td>
<p>An integer representing the number of attempts.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+promptContext">promptContext</a></code> for predefined contexts to use.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

resp.list &lt;- sampleResponse(agent,prompt,context=rbionfoExp, max_tokens = 500)

## End(Not run)
</code></pre>

<hr>
<h2 id='selfcorrect'>Self correct the code returned by the agent</h2><span id='topic+selfcorrect'></span>

<h3>Description</h3>

<p>The function attempts to correct the code returned by the agent
by re-feeding to the agent with the error message. If there are no
error messages function returns the original response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selfcorrect(
  agent,
  prompt,
  context = rbionfoExp,
  attempts = 3,
  output.file = NULL,
  responseWithError = NULL,
  history = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="selfcorrect_+3A_agent">agent</code></td>
<td>
<p>An object containing the agent's information (e.g., type and model).</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_prompt">prompt</code></td>
<td>
<p>The prompt text to send to the language model.</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_context">context</code></td>
<td>
<p>Optional context to provide alongside the prompt (default is rbionfoExp).</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_attempts">attempts</code></td>
<td>
<p>Numeric value denoting how many times the code should be sent back for fixing.</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_output.file">output.file</code></td>
<td>
<p>Optional output file created holding parsed code</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_responsewitherror">responseWithError</code></td>
<td>
<p>a list of response and errors returned from executeCode().</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_history">history</code></td>
<td>
<p>a list of previous response and prompts. Default is NULL and should be stayed as is for most use cases.
First element is expected to be the response and the second element is the error list returned by executeCode().</p>
</td></tr>
<tr><td><code id="selfcorrect_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the <code><a href="#topic+sendPrompt">sendPrompt</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table role = "presentation">
<tr><td><code>init.response</code></td>
<td>
<p>A character vector representing the initial prompt response.</p>
</td></tr>
<tr><td><code>init.blocks</code></td>
<td>
<p>A list of initial blocks.</p>
</td></tr>
<tr><td><code>final.blocks</code></td>
<td>
<p>A list of final blocks.</p>
</td></tr>
<tr><td><code>code.works</code></td>
<td>
<p>A boolean value indicating whether the code works.</p>
</td></tr>
<tr><td><code>exec.result</code></td>
<td>
<p>A character string representing the execution results.</p>
</td></tr>
<tr><td><code>tried.attempts</code></td>
<td>
<p>An integer representing the number of attempts.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+promptContext">promptContext</a></code> for predefined contexts to use.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

response &lt;- selfcorrect(agent,prompt,context=rbionfoExp, max_tokens = 500)

## End(Not run)
</code></pre>

<hr>
<h2 id='sendPrompt'>Send a prompt to a specified language model agent and return the response.</h2><span id='topic+sendPrompt'></span>

<h3>Description</h3>

<p>Send a prompt to a specified language model agent and return the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sendPrompt(
  agent,
  prompt,
  context = promptContext(type = "simple"),
  return.type = c("text", "object"),
  previous.msgs = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sendPrompt_+3A_agent">agent</code></td>
<td>
<p>An object containing the agent's information (e.g., type and model etc.).</p>
</td></tr>
<tr><td><code id="sendPrompt_+3A_prompt">prompt</code></td>
<td>
<p>The prompt text to send to the language model.</p>
</td></tr>
<tr><td><code id="sendPrompt_+3A_context">context</code></td>
<td>
<p>Optional context to provide alongside the prompt (default is promptContext(type = &quot;simple&quot;)).</p>
</td></tr>
<tr><td><code id="sendPrompt_+3A_return.type">return.type</code></td>
<td>
<p>The type of output to return, either the text response (&quot;text&quot;) or
the entire response object (&quot;object&quot;).</p>
</td></tr>
<tr><td><code id="sendPrompt_+3A_previous.msgs">previous.msgs</code></td>
<td>
<p>a list of lists for previous prompts and responses.
Useful to add context of the previous messages for the API.
this argument works with openai and generic models, but not with replicate API.
Default: NULL</p>
</td></tr>
<tr><td><code id="sendPrompt_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to the LLM API. Such as maximum tokens, (&quot;max_tokens&quot;), to be returned.
Users can also also provide other arguments in openai API-like
arguments documented on [the official documentation](https://platform.openai.com/docs/api-reference/chat/create). Other APIs are also following similar argument naming patterns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The text response or the entire response object, based on the specified return type.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+promptContext">promptContext</a></code> for predefined contexts to use.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
agent &lt;- setupAgent(name="openai",type="chat",model="gpt-4",
                    ai_api_key=Sys.getenv("OPENAI_API_KEY"))
prompt &lt;- "tell me a joke"
response &lt;- sendPrompt(agent, prompt,context="")

# increase tokens, it is important for getting longer responses
response &lt;- sendPrompt(agent,prompt,context="",return.type="text", max_tokens = 500)

# get previous messages into the context
prompt="what about 2010?"
response &lt;- sendPrompt(agent,prompt,context="",
                       return.type="text",
                       previous.msgs=list(
                                          list(
                                               "role" = "user",
                                                "content" = "Who won the world
                                                 series in 2020?"
                                                 ),
                                          list(
                                                "role" = "assistant",
                                              "content" = "The Los Angeles Dodgers"
                                              )
                                          )
                       )



## End(Not run)
</code></pre>

<hr>
<h2 id='setupAgent'>set up an online LLM API for subsequent tasks</h2><span id='topic+setupAgent'></span>

<h3>Description</h3>

<p>This function sets up an large language model API for tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setupAgent(
  name = c("openai", "replicate", "generic"),
  type = NULL,
  model = NULL,
  url = NULL,
  ai_api_key = Sys.getenv("AI_API_KEY")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setupAgent_+3A_name">name</code></td>
<td>
<p>A string for the name of the API, one of &quot;openai&quot;, &quot;replicate&quot; or &quot;generic&quot;.
Currently supported APIs are &quot;openai&quot; and &quot;replicate&quot;. If the user wishes to use
another API that has similar syntax to openai API this is also supported via the
the &quot;generic&quot; option. In this case, the user should also provide a url for the API
using the</p>
</td></tr>
<tr><td><code id="setupAgent_+3A_type">type</code></td>
<td>
<p>Specify type of model (chat or completion). This parameter only needs to be specified when using 'openai</p>
</td></tr>
<tr><td><code id="setupAgent_+3A_model">model</code></td>
<td>
<p>LLM model you wish to use.
For openAI chat model examples are:
</p>

<ul>
<li><p> 'gtp-3-5-turbo'
</p>
</li>
<li><p> 'gtp-4'</p>
</li></ul>

<p>For openAI completion models examples are:
</p>

<ul>
<li><p> 'text-curie-001'
</p>
</li>
<li><p> 'text-davinci-002'</p>
</li></ul>

<p>For replicate models examples are:</p>

<ul>
<li><p> llama-2-70b-chat ( as '02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3')
</p>
</li>
<li><p> llama-2-13b-chat ( as 'f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d')</p>
</li></ul>

<p>For a full list of openAI models see
https://platform.openai.com/docs/models/overview/. For a full list of Replicate models,
see https://replicate.com/collections/language-models.</p>
</td></tr>
<tr><td><code id="setupAgent_+3A_url">url</code></td>
<td>
<p>the url for the API in case the API &quot;generic&quot; is selected. (Default: NULL)</p>
</td></tr>
<tr><td><code id="setupAgent_+3A_ai_api_key">ai_api_key</code></td>
<td>
<p>personal API key for accessing LLM</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list holding agent information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
myAgent &lt;- setupAgent(name="openai",type="chat",model="gpt-4",ai_api_key="my_key")

myAgent &lt;- setupAgent(name="replicate",type=NULL,
                     model="02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",
                     ai_api_key="my_key")
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
