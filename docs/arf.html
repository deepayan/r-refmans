<!DOCTYPE html><html lang="en"><head><title>Help for package arf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {arf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#arf-package'><p>arf: Adversarial Random Forests</p></a></li>
<li><a href='#adversarial_rf'><p>Adversarial Random Forests</p></a></li>
<li><a href='#cforde'><p>Compute conditional circuit parameters</p></a></li>
<li><a href='#col_rename'><p>Adaptive column renaming</p></a></li>
<li><a href='#col_rename_all'><p>Rename all problematic columns with col_rename().</p></a></li>
<li><a href='#darf'><p>Shortcut likelihood function</p></a></li>
<li><a href='#earf'><p>Shortcut expectation function</p></a></li>
<li><a href='#expct'><p>Expected Value</p></a></li>
<li><a href='#forde'><p>Forests for Density Estimation</p></a></li>
<li><a href='#forge'><p>Forests for Generative Modeling</p></a></li>
<li><a href='#impute'><p>Missing value imputation with ARF</p></a></li>
<li><a href='#lik'><p>Likelihood Estimation</p></a></li>
<li><a href='#post_x'><p>Post-process data</p></a></li>
<li><a href='#prep_cond'><p>Preprocess conditions</p></a></li>
<li><a href='#prep_x'><p>Preprocess input data</p></a></li>
<li><a href='#rarf'><p>Shortcut sampling function</p></a></li>
<li><a href='#resample'><p>Safer version of sample()</p></a></li>
<li><a href='#which.max.random'><p>which.max() with random at ties</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Adversarial Random Forests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-24</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marvin N. Wright &lt;cran@wrig.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Adversarial random forests (ARFs) recursively partition data into 
    fully factorized leaves, where features are jointly independent. The 
    procedure is iterative, with alternating rounds of generation and 
    discrimination. Data becomes increasingly realistic at each round, until 
    original and synthetic samples can no longer be reliably distinguished. 
    This is useful for several unsupervised learning tasks, such as density
    estimation and data synthesis. Methods for both are implemented in this
    package. ARFs naturally handle unstructured data with mixed continuous and 
    categorical covariates. They inherit many of the benefits of random forests, 
    including speed, flexibility, and solid performance with default parameters. 
    For details, see Watson et al. (2023) <a href="https://proceedings.mlr.press/v206/watson23a.html">https://proceedings.mlr.press/v206/watson23a.html</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bips-hb/arf">https://github.com/bips-hb/arf</a>, <a href="https://bips-hb.github.io/arf/">https://bips-hb.github.io/arf/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bips-hb/arf/issues">https://github.com/bips-hb/arf/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, ranger, foreach, stringr, truncnorm</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, doParallel, doFuture, mlbench, knitr, rmarkdown,
tibble, palmerpenguins, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-24 21:28:44 UTC; wright</td>
</tr>
<tr>
<td>Author:</td>
<td>Marvin N. Wright <a href="https://orcid.org/0000-0002-8542-6291"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  David S. Watson <a href="https://orcid.org/0000-0001-9632-2159"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Kristin Blesch <a href="https://orcid.org/0000-0001-6241-3079"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Jan Kapar <a href="https://orcid.org/0009-0000-6408-2840"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-24 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='arf-package'>arf: Adversarial Random Forests</h2><span id='topic+arf'></span><span id='topic+arf-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Adversarial random forests (ARFs) recursively partition data into fully factorized leaves, where features are jointly independent. The procedure is iterative, with alternating rounds of generation and discrimination. Data becomes increasingly realistic at each round, until original and synthetic samples can no longer be reliably distinguished. This is useful for several unsupervised learning tasks, such as density estimation and data synthesis. Methods for both are implemented in this package. ARFs naturally handle unstructured data with mixed continuous and categorical covariates. They inherit many of the benefits of random forests, including speed, flexibility, and solid performance with default parameters. For details, see Watson et al. (2023) <a href="https://proceedings.mlr.press/v206/watson23a.html">https://proceedings.mlr.press/v206/watson23a.html</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Marvin N. Wright <a href="mailto:cran@wrig.de">cran@wrig.de</a> (<a href="https://orcid.org/0000-0002-8542-6291">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> David S. Watson <a href="mailto:david.s.watson11@gmail.com">david.s.watson11@gmail.com</a> (<a href="https://orcid.org/0000-0001-9632-2159">ORCID</a>)
</p>
</li>
<li><p> Kristin Blesch (<a href="https://orcid.org/0000-0001-6241-3079">ORCID</a>)
</p>
</li>
<li><p> Jan Kapar (<a href="https://orcid.org/0009-0000-6408-2840">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>,
<code><a href="#topic+expct">expct</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>
<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/bips-hb/arf">https://github.com/bips-hb/arf</a>
</p>
</li>
<li> <p><a href="https://bips-hb.github.io/arf/">https://bips-hb.github.io/arf/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/bips-hb/arf/issues">https://github.com/bips-hb/arf/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# Generate 100 synthetic samples from the iris dataset
x_synth &lt;- forge(psi, n_synth = 100)

# Condition on Species = "setosa" and Sepal.Length &gt; 6
evi &lt;- data.frame(Species = "setosa",
                  Sepal.Length = "(6, Inf)")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Estimate average log-likelihood
ll &lt;- lik(psi, iris, arf = arf, log = TRUE)
mean(ll)

# Expectation of Sepal.Length for class setosa
evi &lt;- data.frame(Species = "setosa")
expct(psi, query = "Sepal.Length", evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='adversarial_rf'>Adversarial Random Forests</h2><span id='topic+adversarial_rf'></span>

<h3>Description</h3>

<p>Implements an adversarial random forest to learn independence-inducing splits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adversarial_rf(
  x,
  num_trees = 10L,
  min_node_size = 2L,
  delta = 0,
  max_iters = 10L,
  early_stop = TRUE,
  prune = TRUE,
  verbose = TRUE,
  parallel = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adversarial_rf_+3A_x">x</code></td>
<td>
<p>Input data. Integer variables are recoded as ordered factors with
a warning. See Details.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees to grow in each forest. The default works
well for most generative modeling tasks, but should be increased for
likelihood estimation. See Details.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_min_node_size">min_node_size</code></td>
<td>
<p>Minimal number of real data samples in leaf nodes.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_delta">delta</code></td>
<td>
<p>Tolerance parameter. Algorithm converges when OOB accuracy is
&lt; 0.5 + <code>delta</code>.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_max_iters">max_iters</code></td>
<td>
<p>Maximum iterations for the adversarial loop.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_early_stop">early_stop</code></td>
<td>
<p>Terminate loop if performance fails to improve from one
round to the next?</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_prune">prune</code></td>
<td>
<p>Impose <code>min_node_size</code> by pruning?</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_verbose">verbose</code></td>
<td>
<p>Print discriminator accuracy after each round? Will also show
additional warnings.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see examples.</p>
</td></tr>
<tr><td><code id="adversarial_rf_+3A_...">...</code></td>
<td>
<p>Extra parameters to be passed to <code>ranger</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The adversarial random forest (ARF) algorithm partitions data into fully
factorized leaves where features are jointly independent. ARFs are trained
iteratively, with alternating rounds of generation and discrimination. In
the first instance, synthetic data is generated via independent bootstraps of
each feature, and a RF classifier is trained to distinguish between real and
fake samples. In subsequent rounds, synthetic data is generated separately in
each leaf, using splits from the previous forest. This creates increasingly
realistic data that satisfies local independence by construction. The
algorithm converges when a RF cannot reliably distinguish between the two
classes, i.e. when OOB accuracy falls below 0.5 + <code>delta</code>.
</p>
<p>ARFs are useful for several unsupervised learning tasks, such as density
estimation (see <code><a href="#topic+forde">forde</a></code>) and data synthesis (see
<code><a href="#topic+forge">forge</a></code>). For the former, we recommend increasing the number of
trees for improved performance (typically on the order of 100-1000 depending
on sample size).
</p>
<p>Integer variables are recoded with a warning (set <code>verbose = FALSE</code> to
silence these). Default behavior is to convert integer variables with six or
more unique values to numeric, while those with up to five unique values are
treated as ordered factors. To override this behavior, explicitly recode
integer variables to the target type prior to training.
</p>
<p>Note: convergence is not guaranteed in finite samples. The <code>max_iters</code>
argument sets an upper bound on the number of training rounds. Similar
results may be attained by increasing <code>delta</code>. Even a single round can
often give good performance, but data with strong or complex dependencies may
require more iterations. With the default <code>early_stop = TRUE</code>, the
adversarial loop terminates if performance does not improve from one round
to the next, in which case further training may be pointless.
</p>


<h3>Value</h3>

<p>A random forest object of class <code>ranger</code>.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>,
<code><a href="#topic+expct">expct</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# Generate 100 synthetic samples from the iris dataset
x_synth &lt;- forge(psi, n_synth = 100)

# Condition on Species = "setosa" and Sepal.Length &gt; 6
evi &lt;- data.frame(Species = "setosa",
                  Sepal.Length = "(6, Inf)")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Estimate average log-likelihood
ll &lt;- lik(psi, iris, arf = arf, log = TRUE)
mean(ll)

# Expectation of Sepal.Length for class setosa
evi &lt;- data.frame(Species = "setosa")
expct(psi, query = "Sepal.Length", evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)

</code></pre>

<hr>
<h2 id='cforde'>Compute conditional circuit parameters</h2><span id='topic+cforde'></span>

<h3>Description</h3>

<p>Compute conditional circuit parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cforde(
  params,
  evidence,
  row_mode = c("separate", "or"),
  nomatch = c("force", "na"),
  verbose = TRUE,
  stepsize = 0,
  parallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cforde_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="cforde_+3A_evidence">evidence</code></td>
<td>
<p>Data frame of conditioning event(s).</p>
</td></tr>
<tr><td><code id="cforde_+3A_row_mode">row_mode</code></td>
<td>
<p>Interpretation of rows in multi-row conditions.</p>
</td></tr>
<tr><td><code id="cforde_+3A_nomatch">nomatch</code></td>
<td>
<p>What to do if no leaf matches a condition in <code>evidence</code>?
Options are to force sampling from a random leaf (<code>"force"</code>) or return
<code>NA</code> (<code>"na"</code>). The default is <code>"force"</code>.</p>
</td></tr>
<tr><td><code id="cforde_+3A_verbose">verbose</code></td>
<td>
<p>Show warnings, e.g. when no leaf matches a condition?</p>
</td></tr>
<tr><td><code id="cforde_+3A_stepsize">stepsize</code></td>
<td>
<p>Stepsize defining number of condition rows handled in one for each step.</p>
</td></tr>
<tr><td><code id="cforde_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see examples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with conditions (<code>evidence_input</code>), prepared conditions (<code>evidence_prepped</code>)
and leaves that match the conditions in evidence with continuous data (<code>cnt</code>)
and categorical data (<code>cat</code>) as well as leaf info (<code>forest</code>).
</p>

<hr>
<h2 id='col_rename'>Adaptive column renaming</h2><span id='topic+col_rename'></span>

<h3>Description</h3>

<p>This function renames columns in case the input colnames includes any
colnames required by internal functions (e.g., <code>"y"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>col_rename(cn, old_name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="col_rename_+3A_cn">cn</code></td>
<td>
<p>Column names.</p>
</td></tr>
<tr><td><code id="col_rename_+3A_old_name">old_name</code></td>
<td>
<p>Name of column to be renamed.</p>
</td></tr>
</table>

<hr>
<h2 id='col_rename_all'>Rename all problematic columns with col_rename().</h2><span id='topic+col_rename_all'></span>

<h3>Description</h3>

<p>Rename all problematic columns with col_rename().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>col_rename_all(cn)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="col_rename_all_+3A_cn">cn</code></td>
<td>
<p>Old column names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>New columns names.
</p>

<hr>
<h2 id='darf'>Shortcut likelihood function</h2><span id='topic+darf'></span>

<h3>Description</h3>

<p>Calls <code>adversarial_rf</code>, <code>forde</code> and <code>lik</code>.
For repeated application, it is faster to save outputs of <code>adversarial_rf</code>
and <code>forde</code> and pass them via <code>...</code> or directly use <code>lik</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>darf(x, query = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="darf_+3A_x">x</code></td>
<td>
<p>Input data. Integer variables are recoded as ordered factors with
a warning. See Details.</p>
</td></tr>
<tr><td><code id="darf_+3A_query">query</code></td>
<td>
<p>Data frame of samples, optionally comprising just a subset of
training features. See Details of <code>lik</code>. Is set to <code>x</code> if <code>zero</code>.</p>
</td></tr>
<tr><td><code id="darf_+3A_...">...</code></td>
<td>
<p>Extra parameters to be passed to <code>adversarial_rf</code>, <code>forde</code>
and <code>lik</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of likelihoods, optionally on the log scale. A dataset of
<code>n_synth</code> synthetic samples or of <code>nrow(x)</code> synthetic
samples if <code>n_synth</code> is undefined.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Estimate log-likelihoods
ll &lt;- darf(iris)

# Partial evidence query
ll &lt;- darf(iris, query = iris[1, 1:3])

# Condition on Species = "setosa"
ll &lt;- darf(iris, query = iris[1, 1:3], evidence = data.frame(Species = "setosa"))


</code></pre>

<hr>
<h2 id='earf'>Shortcut expectation function</h2><span id='topic+earf'></span>

<h3>Description</h3>

<p>Calls <code>adversarial_rf</code>, <code>forde</code> and <code>expct</code>.
For repeated application, it is faster to save outputs of <code>adversarial_rf</code>
and <code>forde</code> and pass them via <code>...</code> or directly use <code>expct</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>earf(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="earf_+3A_x">x</code></td>
<td>
<p>Input data. Integer variables are recoded as ordered factors with
a warning. See Details.</p>
</td></tr>
<tr><td><code id="earf_+3A_...">...</code></td>
<td>
<p>Extra parameters to be passed to <code>adversarial_rf</code>, <code>forde</code>
and <code>expct</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one row data frame with values for all query variables.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+expct">expct</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># What is the expected values of each feature?
earf(iris)

#' # What is the expected values of Sepal.Length?
earf(iris, query = "Sepal.Length")

# What if we condition on Species = "setosa"?
earf(iris, query = "Sepal.Length", evidence = data.frame(Species = "setosa"))


</code></pre>

<hr>
<h2 id='expct'>Expected Value</h2><span id='topic+expct'></span>

<h3>Description</h3>

<p>Compute the expectation of some query variable(s), optionally conditioned
on some event(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expct(
  params,
  query = NULL,
  evidence = NULL,
  evidence_row_mode = c("separate", "or"),
  round = FALSE,
  nomatch = c("force", "na"),
  verbose = TRUE,
  stepsize = 0,
  parallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expct_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="expct_+3A_query">query</code></td>
<td>
<p>Optional character vector of variable names. Estimates will be
computed for each. If <code>NULL</code>, all variables other than those in
<code>evidence</code> will be estimated. If <code>evidence</code> contains <code>NA</code>s,
those values will be imputed and a full dataset is returned.</p>
</td></tr>
<tr><td><code id="expct_+3A_evidence">evidence</code></td>
<td>
<p>Optional set of conditioning events. This can take one of
three forms: (1) a partial sample, i.e. a single row of data with
some but not all columns; (2) a data frame of conditioning events,
which allows for inequalities and intervals; or (3) a posterior
distribution over leaves. See Details and Examples.</p>
</td></tr>
<tr><td><code id="expct_+3A_evidence_row_mode">evidence_row_mode</code></td>
<td>
<p>Interpretation of rows in multi-row evidence. If
<code>"separate"</code>, each row in <code>evidence</code> is a unique conditioning
event for which <code>n_synth</code> synthetic samples are generated. If
<code>"or"</code>, the rows are combined with a logical OR. See Examples.</p>
</td></tr>
<tr><td><code id="expct_+3A_round">round</code></td>
<td>
<p>Round continuous variables to their respective maximum precision
in the real data set?</p>
</td></tr>
<tr><td><code id="expct_+3A_nomatch">nomatch</code></td>
<td>
<p>What to do if no leaf matches a condition in <code>evidence</code>?
Options are to force sampling from a random leaf (<code>"force"</code>) or return
<code>NA</code> (<code>"na"</code>). The default is <code>"force"</code>.</p>
</td></tr>
<tr><td><code id="expct_+3A_verbose">verbose</code></td>
<td>
<p>Show warnings, e.g. when no leaf matches a condition?</p>
</td></tr>
<tr><td><code id="expct_+3A_stepsize">stepsize</code></td>
<td>
<p>How many rows of evidence should be handled at each step?
Defaults to <code>nrow(evidence) / num_registered_workers</code> for
<code>parallel == TRUE</code>.</p>
</td></tr>
<tr><td><code id="expct_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see Examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes expected values for any subset of features, optionally
conditioned on some event(s).
</p>
<p>There are three methods for (optionally) encoding conditioning events via the
<code>evidence</code> argument. The first is to provide a partial sample, where
some columns from the training data are missing or set to <code>NA</code>. The
second is to provide a data frame with condition events. This supports
inequalities and intervals. Alternatively, users may directly input a
pre-calculated posterior distribution over leaves, with columns <code>f_idx</code>
and <code>wt</code>. This may be preferable for complex constraints. See Examples.
</p>
<p>Please note that results for continuous features which are both included in
<code>query</code> and in <code>evidence</code> with an interval condition are currently
inconsistent.
</p>


<h3>Value</h3>

<p>A one row data frame with values for all query variables.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>,
<code><a href="#topic+forge">forge</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# What is the expected value of Sepal.Length?
expct(psi, query = "Sepal.Length")

# What if we condition on Species = "setosa"?
evi &lt;- data.frame(Species = "setosa")
expct(psi, query = "Sepal.Length", evidence = evi)

# Compute expectations for all features other than Species
expct(psi, evidence = evi)

# Condition on Species = "setosa" and Petal.Width &gt; 0.3
evi &lt;- data.frame(Species = "setosa", 
                  Petal.Width = "&gt;0.3")
expct(psi, evidence = evi)

# Condition on first two rows with some missing values
evi &lt;- iris[1:2,]
evi[1, 1] &lt;- NA_real_
evi[1, 5] &lt;- NA_character_
evi[2, 2] &lt;- NA_real_
x_synth &lt;- expct(psi, evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)

</code></pre>

<hr>
<h2 id='forde'>Forests for Density Estimation</h2><span id='topic+forde'></span>

<h3>Description</h3>

<p>Uses a pre-trained ARF model to estimate leaf and distribution parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forde(
  arf,
  x,
  oob = FALSE,
  family = "truncnorm",
  finite_bounds = c("no", "local", "global"),
  alpha = 0,
  epsilon = 0,
  parallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forde_+3A_arf">arf</code></td>
<td>
<p>Pre-trained <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>. Alternatively, any
object of class <code>ranger</code>.</p>
</td></tr>
<tr><td><code id="forde_+3A_x">x</code></td>
<td>
<p>Training data for estimating parameters.</p>
</td></tr>
<tr><td><code id="forde_+3A_oob">oob</code></td>
<td>
<p>Only use out-of-bag samples for parameter estimation? If
<code>TRUE</code>, <code>x</code> must be the same dataset used to train <code>arf</code>.
Set to <code>"inbag"</code> to only use in-bag samples. Default is <code>FALSE</code>,
i.e. use all observations.</p>
</td></tr>
<tr><td><code id="forde_+3A_family">family</code></td>
<td>
<p>Distribution to use for density estimation of continuous
features. Current options include truncated normal (the default
<code>family = "truncnorm"</code>) and uniform (<code>family = "unif"</code>). See
Details.</p>
</td></tr>
<tr><td><code id="forde_+3A_finite_bounds">finite_bounds</code></td>
<td>
<p>Impose finite bounds on all continuous variables? If
<code>"local"</code>, infinite bounds are set to empirical extrema within leaves.
If <code>"global"</code>, infinite bounds are set to global empirical extrema.
if <code>"no"</code> (the default), infinite bounds are left unchanged.</p>
</td></tr>
<tr><td><code id="forde_+3A_alpha">alpha</code></td>
<td>
<p>Optional pseudocount for Laplace smoothing of categorical
features. This avoids zero-mass points when test data fall outside the
support of training data. Effectively parameterizes a flat Dirichlet prior
on multinomial likelihoods.</p>
</td></tr>
<tr><td><code id="forde_+3A_epsilon">epsilon</code></td>
<td>
<p>Optional slack parameter on empirical bounds when
<code>finite_bounds != "no"</code>. This avoids zero-density points when test
data fall outside the support of training data. The gap between lower and
upper bounds is expanded by a factor of <code>1 + epsilon</code>.</p>
</td></tr>
<tr><td><code id="forde_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>forde</code> extracts leaf parameters from a pretrained forest and learns
distribution parameters for data within each leaf. The former includes
coverage (proportion of data falling into the leaf) and split criteria. The
latter includes proportions for categorical features and mean/variance for
continuous features. The result is a probabilistic circuit, stored as a
<code>data.table</code>, which can be used for various downstream inference tasks.
</p>
<p>Currently, <code>forde</code> only provides support for a limited number of
distributional families: truncated normal or uniform for continuous data,
and multinomial for discrete data.
</p>
<p>Though <code>forde</code> was designed to take an adversarial random forest as
input, the function's first argument can in principle be any object of class
<code>ranger</code>. This allows users to test performance with alternative
pipelines (e.g., with supervised forest input). There is also no requirement
that <code>x</code> be the data used to fit <code>arf</code>, unless <code>oob = TRUE</code>.
In fact, using another dataset here may protect against overfitting. This
connects with Wager &amp; Athey's (2018) notion of &quot;honest trees&quot;.
</p>


<h3>Value</h3>

<p>A <code>list</code> with 5 elements: (1) parameters for continuous data; (2)
parameters for discrete data; (3) leaf indices and coverage; (4) metadata on
variables; and (5) the data input class. This list is used for estimating
likelihoods with <code><a href="#topic+lik">lik</a></code> and generating data with <code><a href="#topic+forge">forge</a></code>.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>
<p>Wager, S. &amp; Athey, S. (2018). Estimation and inference of heterogeneous
treatment effects using random forests. <em>J. Am. Stat. Assoc.</em>,
<em>113</em>(523): 1228-1242.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forge">forge</a></code>,
<code><a href="#topic+expct">expct</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# Generate 100 synthetic samples from the iris dataset
x_synth &lt;- forge(psi, n_synth = 100)

# Condition on Species = "setosa" and Sepal.Length &gt; 6
evi &lt;- data.frame(Species = "setosa",
                  Sepal.Length = "(6, Inf)")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Estimate average log-likelihood
ll &lt;- lik(psi, iris, arf = arf, log = TRUE)
mean(ll)

# Expectation of Sepal.Length for class setosa
evi &lt;- data.frame(Species = "setosa")
expct(psi, query = "Sepal.Length", evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)


</code></pre>

<hr>
<h2 id='forge'>Forests for Generative Modeling</h2><span id='topic+forge'></span>

<h3>Description</h3>

<p>Uses pre-trained FORDE model to simulate synthetic data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forge(
  params,
  n_synth,
  evidence = NULL,
  evidence_row_mode = c("separate", "or"),
  round = TRUE,
  sample_NAs = FALSE,
  nomatch = c("force", "na"),
  verbose = TRUE,
  stepsize = 0,
  parallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forge_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="forge_+3A_n_synth">n_synth</code></td>
<td>
<p>Number of synthetic samples to generate.</p>
</td></tr>
<tr><td><code id="forge_+3A_evidence">evidence</code></td>
<td>
<p>Optional set of conditioning events. This can take one of
three forms: (1) a partial sample, i.e. a single row of data with some but
not all columns; (2) a data frame of conditioning events, which allows for
inequalities; or (3) a posterior distribution over leaves. See Details.</p>
</td></tr>
<tr><td><code id="forge_+3A_evidence_row_mode">evidence_row_mode</code></td>
<td>
<p>Interpretation of rows in multi-row evidence. If
<code>"separate"</code>, each row in <code>evidence</code> is a unique conditioning
event for which <code>n_synth</code> synthetic samples are generated. If
<code>"or"</code>, the rows are combined with a logical OR. See Examples.</p>
</td></tr>
<tr><td><code id="forge_+3A_round">round</code></td>
<td>
<p>Round continuous variables to their respective maximum precision
in the real data set?</p>
</td></tr>
<tr><td><code id="forge_+3A_sample_nas">sample_NAs</code></td>
<td>
<p>Sample <code>NA</code>s respecting the probability for missing
values in the original data?</p>
</td></tr>
<tr><td><code id="forge_+3A_nomatch">nomatch</code></td>
<td>
<p>What to do if no leaf matches a condition in <code>evidence</code>?
Options are to force sampling from a random leaf (<code>"force"</code>) or return
<code>NA</code> (<code>"na"</code>). The default is <code>"force"</code>.</p>
</td></tr>
<tr><td><code id="forge_+3A_verbose">verbose</code></td>
<td>
<p>Show warnings, e.g. when no leaf matches a condition?</p>
</td></tr>
<tr><td><code id="forge_+3A_stepsize">stepsize</code></td>
<td>
<p>How many rows of evidence should be handled at each step?
Defaults to <code>nrow(evidence) / num_registered_workers</code> for
<code>parallel == TRUE</code>.</p>
</td></tr>
<tr><td><code id="forge_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>forge</code> simulates a synthetic dataset of <code>n_synth</code> samples. First,
leaves are sampled in proportion to either their coverage (if
<code>evidence = NULL</code>) or their posterior probability. Then, each feature is
sampled independently within each leaf according to the probability mass or
density function learned by <code><a href="#topic+forde">forde</a></code>. This will create realistic
data so long as the adversarial RF used in the previous step satisfies the
local independence criterion. See Watson et al. (2023).
</p>
<p>There are three methods for (optionally) encoding conditioning events via the
<code>evidence</code> argument. The first is to provide a partial sample, where
some columns from the training data are missing or set to <code>NA</code>. The
second is to provide a data frame with condition events. This supports
inequalities and intervals. Alternatively, users may directly input a
pre-calculated posterior distribution over leaves, with columns <code>f_idx</code>
and <code>wt</code>. This may be preferable for complex constraints. See Examples.
</p>


<h3>Value</h3>

<p>A dataset of <code>n_synth</code> synthetic samples.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>,
<code><a href="#topic+expct">expct</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# Generate 100 synthetic samples from the iris dataset
x_synth &lt;- forge(psi, n_synth = 100)

# Condition on Species = "setosa"
evi &lt;- data.frame(Species = "setosa")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Condition on Species = "setosa" and Sepal.Length &gt; 6
evi &lt;- data.frame(Species = "setosa",
                  Sepal.Length = "(6, Inf)")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Alternative syntax for &lt;/&gt; conditions
evi &lt;- data.frame(Sepal.Length = "&gt;6")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Negation condition, i.e. all classes except "setosa"
evi &lt;- data.frame(Species = "!setosa")
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

# Condition on first two data rows with some missing values
evi &lt;- iris[1:2,]
evi[1, 1] &lt;- NA_real_
evi[1, 5] &lt;- NA_character_
evi[2, 2] &lt;- NA_real_
x_synth &lt;- forge(psi, n_synth = 1, evidence = evi)

# Or just input some distribution on leaves
# (Weights that do not sum to unity are automatically scaled)
n_leaves &lt;- nrow(psi$forest)
evi &lt;- data.frame(f_idx = psi$forest$f_idx, wt = rexp(n_leaves))
x_synth &lt;- forge(psi, n_synth = 100, evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)

</code></pre>

<hr>
<h2 id='impute'>Missing value imputation with ARF</h2><span id='topic+impute'></span>

<h3>Description</h3>

<p>Perform single or multiple imputation with ARFs. Calls <code>adversarial_rf</code>,
<code>forde</code> and <code>expct</code>/<code>forge</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute(
  x,
  m = 1,
  expectation = ifelse(m == 1, TRUE, FALSE),
  num_trees = 100L,
  min_node_size = 10L,
  round = TRUE,
  finite_bounds = "local",
  epsilon = 1e-14,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="impute_+3A_x">x</code></td>
<td>
<p>Input data.</p>
</td></tr>
<tr><td><code id="impute_+3A_m">m</code></td>
<td>
<p>Number of imputed datasets to generate. The default is single
imputation (<code>m = 1</code>).</p>
</td></tr>
<tr><td><code id="impute_+3A_expectation">expectation</code></td>
<td>
<p>Return expected value instead of multiple imputations. By
default, for single imputation (<code>m = 1</code>), the expected value is
returned.</p>
</td></tr>
<tr><td><code id="impute_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees to grow in the ARF.</p>
</td></tr>
<tr><td><code id="impute_+3A_min_node_size">min_node_size</code></td>
<td>
<p>Minimal number of real data samples in leaf nodes.</p>
</td></tr>
<tr><td><code id="impute_+3A_round">round</code></td>
<td>
<p>Round continuous variables to their respective maximum precision
in the real data set?</p>
</td></tr>
<tr><td><code id="impute_+3A_finite_bounds">finite_bounds</code></td>
<td>
<p>Impose finite bounds on all continuous variables? See
<code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_epsilon">epsilon</code></td>
<td>
<p>Slack parameter on empirical bounds; see <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_verbose">verbose</code></td>
<td>
<p>Print progress for <code>adversarial_rf</code>?</p>
</td></tr>
<tr><td><code id="impute_+3A_...">...</code></td>
<td>
<p>Extra parameters to be passed to <code>adversarial_rf</code>,
<code>forde</code> and <code>expct</code>/<code>forge</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Imputed data. A single dataset is returned for <code>m = 1</code>, a list
of datasets for <code>m &gt; 1</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>,
<code><a href="#topic+expct">expct</a></code>, <code><a href="#topic+lik">lik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some missings
iris_na &lt;- iris
for (j in 1:ncol(iris)) {
  iris_na[sample(1:nrow(iris), 5), j] &lt;- NA
}

# Single imputation
iris_imputed &lt;- arf::impute(iris_na, num_trees = 10, m = 1)

# Multiple imputation
iris_imputed &lt;- arf::impute(iris_na, num_trees = 10, m = 10)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)

</code></pre>

<hr>
<h2 id='lik'>Likelihood Estimation</h2><span id='topic+lik'></span>

<h3>Description</h3>

<p>Compute the likelihood of input data, optionally conditioned on some event(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lik(
  params,
  query,
  evidence = NULL,
  arf = NULL,
  oob = FALSE,
  log = TRUE,
  batch = NULL,
  parallel = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lik_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="lik_+3A_query">query</code></td>
<td>
<p>Data frame of samples, optionally comprising just a subset of
training features. Likelihoods will be computed for each sample. Missing
features will be marginalized out. See Details.</p>
</td></tr>
<tr><td><code id="lik_+3A_evidence">evidence</code></td>
<td>
<p>Optional set of conditioning events. This can take one of
three forms: (1) a partial sample, i.e. a single row of data with some but
not all columns; (2) a data frame of conditioning events, which allows for
inequalities; or (3) a posterior distribution over leaves. See Details.</p>
</td></tr>
<tr><td><code id="lik_+3A_arf">arf</code></td>
<td>
<p>Pre-trained <code><a href="#topic+adversarial_rf">adversarial_rf</a></code> or other object of class
<code>ranger</code>. This is not required but speeds up computation considerably
for total evidence queries. (Ignored for partial evidence queries.)</p>
</td></tr>
<tr><td><code id="lik_+3A_oob">oob</code></td>
<td>
<p>Only use out-of-bag leaves for likelihood estimation? If
<code>TRUE</code>, <code>x</code> must be the same dataset used to train <code>arf</code>.
Only applicable for total evidence queries.</p>
</td></tr>
<tr><td><code id="lik_+3A_log">log</code></td>
<td>
<p>Return likelihoods on log scale? Recommended to prevent underflow.</p>
</td></tr>
<tr><td><code id="lik_+3A_batch">batch</code></td>
<td>
<p>Batch size. The default is to compute densities for all of
queries in one round, which is always the fastest option if memory allows.
However, with large samples or many trees, it can be more memory efficient
to split the data into batches. This has no impact on results.</p>
</td></tr>
<tr><td><code id="lik_+3A_parallel">parallel</code></td>
<td>
<p>Compute in parallel? Must register backend beforehand, e.g.
via <code>doParallel</code> or <code>doFuture</code>; see examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the likelihood of input data, optionally conditioned
on some event(s). Queries may be partial, i.e. covering some but not all
features, in which case excluded variables will be marginalized out.
</p>
<p>There are three methods for (optionally) encoding conditioning events via the
<code>evidence</code> argument. The first is to provide a partial sample, where
some but not all columns from the training data are present. The second is to
provide a data frame with three columns: <code>variable</code>, <code>relation</code>,
and <code>value</code>. This supports inequalities via <code>relation</code>.
Alternatively, users may directly input a pre-calculated posterior
distribution over leaves, with columns <code>f_idx</code> and <code>wt</code>. This may
be preferable for complex constraints. See Examples.
</p>


<h3>Value</h3>

<p>A vector of likelihoods, optionally on the log scale.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>, <code><a href="#topic+expct">expct</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train ARF and estimate leaf parameters
arf &lt;- adversarial_rf(iris)
psi &lt;- forde(arf, iris)

# Estimate average log-likelihood
ll &lt;- lik(psi, iris, arf = arf, log = TRUE)
mean(ll)

# Identical but slower
ll &lt;- lik(psi, iris, log = TRUE)
mean(ll)

# Partial evidence query
lik(psi, query = iris[1, 1:3])

# Condition on Species = "setosa"
evi &lt;- data.frame(Species = "setosa")
lik(psi, query = iris[1, 1:3], evidence = evi)

# Condition on Species = "setosa" and Petal.Width &gt; 0.3
evi &lt;- data.frame(Species = "setosa", 
                  Petal.Width = "&gt;0.3")
lik(psi, query = iris[1, 1:3], evidence = evi)

## Not run: 
# Parallelization with doParallel
doParallel::registerDoParallel(cores = 4)

# ... or with doFuture
doFuture::registerDoFuture()
future::plan("multisession", workers = 4)

## End(Not run)

</code></pre>

<hr>
<h2 id='post_x'>Post-process data</h2><span id='topic+post_x'></span>

<h3>Description</h3>

<p>This function prepares output data for forge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_x(x, params, round = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="post_x_+3A_x">x</code></td>
<td>
<p>Input data.frame.</p>
</td></tr>
<tr><td><code id="post_x_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="post_x_+3A_round">round</code></td>
<td>
<p>Round continuous variables to their respective maximum precision in the real data set?</p>
</td></tr>
</table>

<hr>
<h2 id='prep_cond'>Preprocess conditions</h2><span id='topic+prep_cond'></span>

<h3>Description</h3>

<p>This function prepares conditions for computing conditional circuit paramaters via cforde
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_cond(evidence, params, row_mode)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prep_cond_+3A_evidence">evidence</code></td>
<td>
<p>Optional set of conditioning events.</p>
</td></tr>
<tr><td><code id="prep_cond_+3A_params">params</code></td>
<td>
<p>Circuit parameters learned via <code><a href="#topic+forde">forde</a></code>.</p>
</td></tr>
<tr><td><code id="prep_cond_+3A_row_mode">row_mode</code></td>
<td>
<p>Interpretation of rows in multi-row conditions.</p>
</td></tr>
</table>

<hr>
<h2 id='prep_x'>Preprocess input data</h2><span id='topic+prep_x'></span>

<h3>Description</h3>

<p>This function prepares input data for ARFs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prep_x(x, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prep_x_+3A_x">x</code></td>
<td>
<p>Input data.frame.</p>
</td></tr>
<tr><td><code id="prep_x_+3A_verbose">verbose</code></td>
<td>
<p>Show warning if recoding integers?</p>
</td></tr>
</table>

<hr>
<h2 id='rarf'>Shortcut sampling function</h2><span id='topic+rarf'></span>

<h3>Description</h3>

<p>Calls <code>adversarial_rf</code>, <code>forde</code> and <code>forge</code>.
For repeated application, it is faster to save outputs of <code>adversarial_rf</code>
and <code>forde</code> and pass them via <code>...</code> or directly use <code>forge</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rarf(x, n_synth = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rarf_+3A_x">x</code></td>
<td>
<p>Input data. Integer variables are recoded as ordered factors with
a warning. See Details.</p>
</td></tr>
<tr><td><code id="rarf_+3A_n_synth">n_synth</code></td>
<td>
<p>Number of synthetic samples to generate for unconditional
generation with no <code>evidence</code> given.
Number of synthetic samples to generate per <code>evidence</code> row if <code>evidence</code>
is provided.
If <code>NULL</code>, defaults to <code>nrow(x)</code> if no <code>evidence</code> is provided and to
<code>1</code> otherwise.</p>
</td></tr>
<tr><td><code id="rarf_+3A_...">...</code></td>
<td>
<p>Extra parameters to be passed to <code>adversarial_rf</code>, <code>forde</code>
and <code>forge</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataset of <code>n_synth</code> synthetic samples or of <code>nrow(x)</code> synthetic
samples if <code>n_synth</code> is undefined.
</p>


<h3>References</h3>

<p>Watson, D., Blesch, K., Kapar, J., &amp; Wright, M. (2023). Adversarial random
forests for density estimation and generative modeling. In <em>Proceedings
of the 26th International Conference on Artificial Intelligence and
Statistics</em>, pp. 5357-5375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+arf">arf</a></code>, <code><a href="#topic+adversarial_rf">adversarial_rf</a></code>, <code><a href="#topic+forde">forde</a></code>, <code><a href="#topic+forge">forge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate 150 (size of original iris dataset) synthetic samples from the iris dataset
x_synth &lt;- rarf(iris)

# Generate 100 synthetic samples from the iris dataset
x_synth &lt;- rarf(iris, n_synth = 100)

# Condition on Species = "setosa"
x_synth &lt;- rarf(iris, evidence = data.frame(Species = "setosa"))

</code></pre>

<hr>
<h2 id='resample'>Safer version of sample()</h2><span id='topic+resample'></span>

<h3>Description</h3>

<p>Safer version of sample()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample_+3A_x">x</code></td>
<td>
<p>A vector of one or more elements from which to choose.</p>
</td></tr>
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>Further arguments for sample().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length size with elements drawn from x.
</p>

<hr>
<h2 id='which.max.random'>which.max() with random at ties</h2><span id='topic+which.max.random'></span>

<h3>Description</h3>

<p>which.max() with random at ties
</p>


<h3>Usage</h3>

<pre><code class='language-R'>which.max.random(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="which.max.random_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Index of maximum value in x, with random tie-breaking.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
