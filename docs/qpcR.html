<!DOCTYPE html><html lang="en"><head><title>Help for package qpcR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qpcR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AICc'><p>Akaike's second-order corrected Information Criterion</p></a></li>
<li><a href='#akaike.weights'><p>Calculation of Akaike weights/relative likelihoods/delta-AICs</p></a></li>
<li><a href='#calib'><p>Calculation of qPCR efficiency using dilution curves and replicate bootstrapping</p></a></li>
<li><a href='#Cy0'><p>Cy0 alternative to threshold cycles as in Guescini et al. (2008)</p></a></li>
<li><a href='#eff'><p>The amplification efficiency curve of a fitted object</p></a></li>
<li><a href='#efficiency'><p>Calculation of qPCR efficiency and other important qPCR parameters</p></a></li>
<li><a href='#evidence'><p>Evidence ratio for model comparisons with AIC, AICc or BIC</p></a></li>
<li><a href='#expcomp'><p>Comparison of all sigmodal models within the exponential region</p></a></li>
<li><a href='#expfit'><p>Calculation of PCR efficiency by fitting an exponential model</p></a></li>
<li><a href='#fitchisq'><p>The chi-square goodness-of-fit</p></a></li>
<li><a href='#getPar'><p>Batch calculation of qPCR fit parameters/efficiencies/threshold cycles with simple output, especially tailored to high-throughput data</p></a></li>
<li><a href='#is.outlier'><p>Outlier summary for objects of class 'modlist' or 'replist'</p></a></li>
<li><a href='#KOD'><p>(K)inetic (O)utlier (D)etection using several methods</p></a></li>
<li><a href='#llratio'><p>Calculation of likelihood ratios for nested models</p></a></li>
<li><a href='#LOF.test'><p>Formal lack-Of-Fit test of a nonlinear model against a one-way ANOVA model</p></a></li>
<li><a href='#LRE'><p>Calculation of qPCR efficiency by the 'linear regression of efficiency' method</p></a></li>
<li><a href='#maxRatio'><p>The maxRatio method as in Shain et al. (2008)</p></a></li>
<li><a href='#meltcurve'><p>Melting curve analysis with (iterative) Tm identification and peak area calculation/cutoff</p></a></li>
<li><a href='#midpoint'><p>Calculation of the 'midpoint' region</p></a></li>
<li><a href='#modlist'><p>Create nonlinear models from a dataframe and coerce them into a list</p></a></li>
<li><a href='#mselect'><p>Sigmoidal model selection by different criteria</p></a></li>
<li><a href='#parKOD'><p>Parameters that can be changed to tweak the kinetic outlier methods</p></a></li>
<li><a href='#pcrbatch'><p>Batch calculation of qPCR efficiency and other qPCR parameters</p></a></li>
<li><a href='#pcrboot'><p>Bootstrapping and jackknifing qPCR data</p></a></li>
<li><a href='#pcrfit'><p>Workhorse function for qPCR model fitting</p></a></li>
<li><a href='#pcrGOF'><p>Summarize measures for the goodness-of-fit</p></a></li>
<li><a href='#pcrimport'><p>Advanced qPCR data import function</p></a></li>
<li><a href='#pcrimport2'><p>Simple qPCR data import function (i.e. from text files or clipboard)</p></a></li>
<li><a href='#pcropt1'><p>Combinatorial elimination of plateau and ground phase cycles</p></a></li>
<li><a href='#pcrsim'><p>Simulation of sigmoidal qPCR data with goodness-of-fit analysis</p></a></li>
<li><a href='#plot.pcrfit'><p>Plotting qPCR data with fitted curves</p></a></li>
<li><a href='#predict.pcrfit'><p>Value prediction from a fitted qPCR model</p></a></li>
<li><a href='#PRESS'><p>Allen's PRESS (Prediction Sum-Of-Squares) statistic, aka P-square</p></a></li>
<li><a href='#propagate'><p>Error propagation using different methods</p></a></li>
<li><a href='#qpcR_datasets'><p>The (published) datasets implemented in qpcR</p></a></li>
<li><a href='#qpcR_functions'><p>The nonlinear/mechanistic models implemented in qpcR</p></a></li>
<li><a href='#qpcR.news'><p>Display news and changes of qpcR package versions</p></a></li>
<li><a href='#ratiobatch'><p>Calculation of ratios in a batch format for multiple genes/samples</p></a></li>
<li><a href='#ratiocalc'><p>Calculation of ratios from qPCR runs with/without reference genes</p></a></li>
<li><a href='#ratioPar'><p>Calculation of ratios in a batch format from external PCR parameters</p></a></li>
<li><a href='#refmean'><p>Averaging of multiple reference genes</p></a></li>
<li><a href='#replist'><p>Amalgamation of single data models into a model containing replicates</p></a></li>
<li><a href='#resplot'><p>An (overlayed) residuals barplot</p></a></li>
<li><a href='#resVar'><p>Residual variance of a fitted model</p></a></li>
<li><a href='#RMSE'><p>Root-mean-squared-error of a fitted model</p></a></li>
<li><a href='#Rsq'><p>R-square value of a fitted model</p></a></li>
<li><a href='#Rsq.ad'><p>Adjusted R-square value of a fitted model</p></a></li>
<li><a href='#RSS'><p>Residual sum-of-squares of a fitted model</p></a></li>
<li><a href='#sliwin'><p>Calculation of qPCR efficiency by the 'window-of-linearity' method</p></a></li>
<li><a href='#takeoff'><p>Calculation of the qPCR takeoff point</p></a></li>
<li><a href='#update.pcrfit'><p>Updating and refitting a qPCR model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Title:</td>
<td>Modelling and Analysis of Real-Time PCR Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-05-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrej-Nikolai Spiess &lt;a.spiess@uke.uni-hamburg.de&gt;        </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrej-Nikolai Spiess &lt;a.spiess@uke.uni-hamburg.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Model fitting, optimal model selection and calculation of various features that are essential in the analysis of quantitative real-time polymerase chain reaction (qPCR).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.13.0), MASS, minpack.lm, rgl, robustbase, Matrix</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-06-05 07:13:24 UTC; anspiess</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-06-14 10:58:00 UTC</td>
</tr>
</table>
<hr>
<h2 id='AICc'>Akaike's second-order corrected Information Criterion</h2><span id='topic+AICc'></span>

<h3>Description</h3>

<p>Calculates the second-order corrected Akaike Information Criterion for objects of class <code>pcrfit</code>, <code>nls</code>, <code>lm</code>, <code>glm</code> or any other models from which <code><a href="stats.html#topic+coefficients">coefficients</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> can be extracted. This is a modified version of the original AIC which compensates for bias with small <code class="reqn">n</code>. As qPCR data usually has <code class="reqn">\frac{n}{k} &lt; 40</code> (see original reference), AICc was implemented to correct for this.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AICc(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AICc_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extends the AIC such that </p>
<p style="text-align: center;"><code class="reqn">AICc = AIC+\frac{2k(k + 1)}{n - k - 1}</code>
</p>
<p> with <code class="reqn">k</code> = number of parameters, and <code class="reqn">n</code> = number of observations. For large <code class="reqn">n</code>, AICc converges to AIC.
</p>


<h3>Value</h3>

<p>The second-order corrected AIC value.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Akaike Information Criterion Statistics.<br />
Sakamoto Y, Ishiguro M and Kitagawa G.<br /> 
D. Reidel Publishing Company (1986).<br />
</p>
<p>Regression and Time Series Model Selection in Small Samples.<br />
Hurvich CM &amp; Tsai CL.<br />  
<em>Biometrika</em> (1989), <b>76</b>: 297-307.<br />
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
AICc(m1)
</code></pre>

<hr>
<h2 id='akaike.weights'>Calculation of Akaike weights/relative likelihoods/delta-AICs</h2><span id='topic+akaike.weights'></span>

<h3>Description</h3>

<p>Calculates Akaike weights from a vector of AIC values. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>akaike.weights(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="akaike.weights_+3A_x">x</code></td>
<td>
<p>a vector containing the AIC values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although Akaike's Information Criterion is recognized as a major measure for selecting models, it has one major drawback: The AIC values lack intuitivity despite higher values meaning less goodness-of-fit. For this purpose, Akaike weights come to hand for calculating the weights in a regime of several models. Additional measures can be derived, such as <code class="reqn">\Delta(AIC)</code> and relative likelihoods that demonstrate the probability of one model being in favor over the other. This is done by using the following formulas:
</p>
<p>delta AICs: </p>
<p style="text-align: center;"><code class="reqn">\Delta_i(AIC) = AIC_i - min(AIC)</code>
</p>

<p>relative likelihood: </p>
<p style="text-align: center;"><code class="reqn">L \propto exp\left(-\frac{1}{2}\Delta_i(AIC)\right)</code>
</p>

<p>Akaike weights: </p>
<p style="text-align: center;"><code class="reqn">w_i(AIC) = \frac{exp\left(-\frac{1}{2}\Delta_i(AIC)\right)}{\sum_{k=1}^K exp\left(-\frac{1}{2}\Delta_k(AIC)\right)}</code>
</p>



<h3>Value</h3>

<p>A list containing the following items:
</p>
<table role = "presentation">
<tr><td><code>deltaAIC</code></td>
<td>
<p>the <code class="reqn">\Delta(AIC)</code> values.</p>
</td></tr>
<tr><td><code>rel.LL</code></td>
<td>
<p>the relative likelihoods.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the Akaike weights.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Classical literature:<br />
Akaike Information Criterion Statistics.<br />
Sakamoto Y, Ishiguro M and Kitagawa G.<br />
D. Reidel Publishing Company (1986).<br />
</p>
<p>Model selection and inference: a practical information-theoretic approach.<br />
Burnham KP &amp; Anderson DR.<br />
Springer Verlag, New York, USA (2002).<br />
</p>
<p>A good summary:<br />
AIC model selection using Akaike weights.
Wagenmakers EJ &amp; Farrell S.<br />
<em>Psychonomic Bull Review</em> (2004), <b>11</b>: 192-196.<br />
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Apply a list of different sigmoidal models to data
## and analyze GOF statistics with Akaike weights
## on 8 different sigmoidal models.
modList &lt;- list(l7, l6, l5, l4, b7, b6, b5, b4)
aics &lt;- sapply(modList, function(x) AIC(pcrfit(reps, 1, 2, x))) 
akaike.weights(aics)$weights 
</code></pre>

<hr>
<h2 id='calib'>Calculation of qPCR efficiency using dilution curves and replicate bootstrapping</h2><span id='topic+calib'></span>

<h3>Description</h3>

<p>This function calculates the PCR efficiency from a classical qPCR dilution experiment. The threshold cycles are plotted against the logarithmized concentration (or dilution) values, a linear regression line is fit and the efficiency calculated by <code class="reqn">E = 10^{\frac{-1}{slope}}</code>. A graph is displayed with the raw values plotted with the threshold cycle and the linear regression curve. The threshold cycles are calculated either by some arbitrary fluorescence value (i.e. as given by the qPCR software) or calculated from the second derivative maximum of the dilution curves. If values to be predicted are given, they are calculated from the curve and also displayed within. <code>calib2</code> uses a bootstrap approach if replicates for the dilutions are supplied. See 'Details'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calib(refcurve, predcurve = NULL, thresh = "cpD2", dil = NULL, 
       group = NULL, plot = TRUE, conf = 0.95, B = 200)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calib_+3A_refcurve">refcurve</code></td>
<td>
<p>a 'modlist' containing the curves for calibration.</p>
</td></tr>
<tr><td><code id="calib_+3A_predcurve">predcurve</code></td>
<td>
<p>an (optional) 'modlist' containing the curves for prediction.</p>
</td></tr>
<tr><td><code id="calib_+3A_thresh">thresh</code></td>
<td>
<p>the fluorescence value from which the threshold cycles are defined. Either &quot;cpD2&quot; or a numeric value.</p>
</td></tr> 
<tr><td><code id="calib_+3A_dil">dil</code></td>
<td>
<p>a vector with the concentration (or dilution) values corresponding to the calibration curves.</p>
</td></tr>
<tr><td><code id="calib_+3A_group">group</code></td>
<td>
<p>a factor defining the group membership for the replicates. See 'Examples'.</p>
</td></tr>
<tr><td><code id="calib_+3A_plot">plot</code></td>
<td>
<p>logical. Should the fitting (bootstrapping) be displayed? If <code>FALSE</code>, only values are returned.</p>
</td></tr>
<tr><td><code id="calib_+3A_conf">conf</code></td>
<td>
<p>the confidence interval. Defaults to 95%, can be omitted with <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="calib_+3A_b">B</code></td>
<td>
<p>the number of bootstraps.</p>
</td></tr>    
</table>


<h3>Details</h3>

<p><code>calib2</code> calculates confidence intervals for efficiency, AICc, adjusted <code class="reqn">R^2_{adj}</code> and the prediction curve concentrations. If single replicates per dilution are supplied by the user, confidence intervals for the prediction curves are calculated based on asymptotic normality. If multiple replicates are supplied, the regression curves are calculated by randomly sampling one of the replicates from each dilution group. The confidence intervals are then calculated from the bootstraped results.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff</code></td>
<td>
<p>the efficiency.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>the second-order corrected AIC.</p>
</td></tr>  
<tr><td><code>Rsq.ad</code></td>
<td>
<p>the adjusted <code class="reqn">R^2_{adj}</code>.</p>
</td></tr>
<tr><td><code>predconc</code></td>
<td>
<p>the (log) concentration of the predicted curves.</p>
</td></tr>    
<tr><td><code>conf.boot</code></td>
<td>
<p>a list containing the confidence intervals for the efficiency, the AICc, Rsq.ad and the predicted concentrations.</p>
</td></tr> 
</table>
<p>A plot is also supplied for <code>eff</code>iciency, <code>AICc</code>, <code>Rsq.ad</code> and predicted concentrations including confidence intervals in red.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Define calibration curves,
## dilutions (or copy numbers) 
## and curves to be predicted.
## Do background subtraction using
## average of first 8 cycles. No replicates.
CAL &lt;- modlist(reps, fluo = c(2, 6, 10, 14, 18, 22), 
               baseline = "mean", basecyc = 1:8)
COPIES &lt;- c(100000, 10000, 1000, 100, 10, 1)
PRED &lt;- modlist(reps, fluo = c(3, 7, 11), 
                baseline = "mean", basecyc = 1:8)

## Conduct normal quantification using
## the second derivative maximum of first curve.
calib(refcurve = CAL, predcurve = PRED, thresh = "cpD2", 
       dil = COPIES, plot = FALSE) 

## Using a defined treshold value.
#calib(refcurve = CAL, predcurve = PRED, thresh = 0.5, dil = COPIES) 

## Using six dilutions with four replicates/dilution.
## Not run: 
#CAL2 &lt;- modlist(reps, fluo = 2:25)
#calib(refcurve = CAL2, predcurve = PRED, thresh = "cpD2", 
#      dil = COPIES, group = gl(6,4)) 

## End(Not run) 
</code></pre>

<hr>
<h2 id='Cy0'>Cy0 alternative to threshold cycles as in Guescini et al. (2008)</h2><span id='topic+Cy0'></span>

<h3>Description</h3>

<p>An alternative to the classical crossing point/threshold cycle estimation as described in Guescini <em>et al</em> (2002). A tangent is fit to the first derivative maximum (point of inflection) of the modeled curve and the intersection with the x-axis is calculated.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cy0(object, plot = FALSE, add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Cy0_+3A_object">object</code></td>
<td>
<p>a fitted object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="Cy0_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, displays a plot of Cy0.</p>
</td></tr>
<tr><td><code id="Cy0_+3A_add">add</code></td>
<td>
<p>if <code>TRUE</code>, a plot is added to any other existing plot, i.e. as from <code><a href="#topic+plot.pcrfit">plot.pcrfit</a></code>.</p>
</td></tr>
<tr><td><code id="Cy0_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+plot.pcrfit">plot.pcrfit</a></code> or <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>	
</table>


<h3>Details</h3>

<p>The function calculates the first derivative maximum (cpD1) of the curve and the slope and fluorescence <code class="reqn">F_{cpD2}</code> at that point.
Cy0 is then calculated by <code class="reqn">Cy_0 = cpD1 - \frac{F_{cpD2}}{slope}</code>.
</p>


<h3>Value</h3>

<p>The <code class="reqn">Cy_0</code> value.  
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>A new real-time PCR method to overcome significant quantitative inaccuracy due to slight amplification inhibition.<br />
Guescini M, Sisti D, Rocchi MB, Stocchi L &amp; Stocchi V.<br />
<em>BMC Bioinformatics</em> (2008), <b>9</b>: 326.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Single curve with plot.
m1 &lt;- pcrfit(reps, 1, 2, l5)
Cy0(m1, plot = TRUE)

## Add to 'efficiency' plot.
efficiency(m1)
Cy0(m1, add = TRUE)

## Compare s.d. of replicates between
## Cy0 and cpD2 method. cpD2 wins!
ml1 &lt;- modlist(reps, model = l4)
cy0 &lt;- sapply(ml1, function(x) Cy0(x))
cpd2 &lt;- sapply(ml1, function(x) efficiency(x, plot = FALSE)$cpD2)
tapply(cy0, gl(7, 4), function(x) sd(x))
tapply(cpd2, gl(7, 4), function(x) sd(x)) 
</code></pre>

<hr>
<h2 id='eff'>The amplification efficiency curve of a fitted object</h2><span id='topic+eff'></span>

<h3>Description</h3>

<p>Calculates the efficiency curve from the fitted object by <code class="reqn">E_n = \frac{F_n}{F_{n-1}}</code>, with <code class="reqn">E</code> = efficiency, <code class="reqn">F</code> = raw fluorescence, <code class="reqn">n</code> = Cycle number. Alternatively, a cubic spline interpolation can be used on the raw data as in Shain <em>et al</em>. (2008). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eff(object, method = c("sigfit", "spline"), sequence = NULL, baseshift = NULL, 
    smooth = FALSE, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eff_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="eff_+3A_method">method</code></td>
<td>
<p>the efficiency curve is either calculated from the sigmoidal fit (default) or a cubic spline interpolation.</p>
</td></tr>
<tr><td><code id="eff_+3A_sequence">sequence</code></td>
<td>
<p>a 3-element vector (from, to, by) defining the sequence for the efficiency curve. Defaults to [min(Cycles), max(Cycles)] with 100 points per cycle.</p>
</td></tr>
<tr><td><code id="eff_+3A_baseshift">baseshift</code></td>
<td>
<p>baseline shift value in case of <code>type = "spline"</code>. See documentation to <code><a href="#topic+maxRatio">maxRatio</a></code>.</p>
</td></tr>
<tr><td><code id="eff_+3A_smooth">smooth</code></td>
<td>
<p>logical. If <code>TRUE</code> and <code>type = "spline"</code>, invokes a 5-point convolution filter (<code><a href="stats.html#topic+filter">filter</a></code>). See documentation to <code><a href="#topic+maxRatio">maxRatio</a></code>.</p>
</td></tr> 
<tr><td><code id="eff_+3A_plot">plot</code></td>
<td>
<p>should the efficiency be plotted?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information about the curve smoothing, baseline shifting and cubic spline interpolation for the method as in Shain <em>et al</em>. (2008), see 'Details' in <code><a href="#topic+maxRatio">maxRatio</a></code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff.x</code></td>
<td>
<p>the cycle points.</p>
</td></tr>
<tr><td><code>eff.y</code></td>
<td>
<p>the efficiency values at <code>eff.x</code>.</p>
</td></tr>   
<tr><td><code>effmax.x</code></td>
<td>
<p>the cycle number with the highest efficiency.</p>
</td></tr>
<tr><td><code>effmax.y</code></td>
<td>
<p>the maximum efficiency.</p>
</td></tr>   
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>A new method for robust quantitative and qualitative analysis of real-time PCR.<br />
Shain EB &amp; Clemens JM.<br />
<em>Nucleic Acids Research</em> (2008), <b>36</b>, e91.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## With default 100 points per cycle.
m1 &lt;- pcrfit(reps, 1, 7, l5)
eff(m1, plot = TRUE) 

## Not all data and only 10 points per cycle.
eff(m1, sequence = c(5, 35, 0.1), plot = TRUE) 

## When using cubic splines it is preferred 
## to use the smoothing option.
#eff(m1, method = "spline", plot = TRUE, smooth = TRUE, baseshift = 0.3)  
</code></pre>

<hr>
<h2 id='efficiency'>Calculation of qPCR efficiency and other important qPCR parameters</h2><span id='topic+efficiency'></span>

<h3>Description</h3>

<p>This function calculates the PCR efficiency of a model of class 'pcrfit', including several other important values for qPCR quantification like the first and second derivatives and the corresponding maxima thereof (i.e. threshold cycles). These values can subsequently be used for the calculation of PCR kinetics, fold induction etc. All values are included in a graphical output of the fit. Additionally, several measures of goodness-of-fit are calculated, i.e. the Akaike Information Criterion (AIC), the residual variance and the <code class="reqn">R^2</code> value.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efficiency(object, plot = TRUE, type = "cpD2", thresh = NULL, 
           shift = 0, amount = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="efficiency_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_plot">plot</code></td>
<td>
<p>logical. If TRUE, a graph is displayed. If FALSE, values are printed out.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_type">type</code></td>
<td>
<p>the method of efficiency estimation. See 'Details'.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_thresh">thresh</code></td>
<td>
<p>an (optional) numeric value for a fluorescence threshold border. Overrides <code>type</code>.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_shift">shift</code></td>
<td>
<p>a user defined shift in cycles from the values defined by <code>type</code>. See 'Examples'.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_amount">amount</code></td>
<td>
<p>the template amount or molecule number for quantitative calibration.</p>
</td></tr>
<tr><td><code id="efficiency_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+eff">eff</a></code> or <code><a href="#topic+plot.pcrfit">plot.pcrfit</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The efficiency is always (with the exception of <code>type = "maxRatio"</code>) calculated from the efficiency curve (in blue), which is calculated according to <code class="reqn">E_n = \frac{F_n}{F_{n-1}}</code> from the fitted curve, but taken from different points at the curve, as to be defined in <code>type</code>: 
</p>
<p>&quot;cpD2&quot;  taken from the maximum of the second derivative curve,<br />
&quot;cpD1&quot;  taken from the maximum of the first derivative curve,<br />
&quot;maxE&quot;  taken from the maximum of the efficiency curve,<br />
&quot;expR&quot;  taken from the exponential region by <code class="reqn">expR = cpD2-(cpD1-cpD2)</code>,<br />
&quot;CQ&quot;    taken from the 20% value of the fluorescence at &quot;cpD2&quot; as developed by Corbett Research (comparative quantification),<br />
&quot;Cy0&quot;   the intersection of a tangent on the first derivative maximum with the abscissa as calculated according to Guescini et al. or<br />
a numeric value taken from the threshold cycle output of the PCR software, i.e. 15.24  as defined in <code>type</code> or<br />
a numeric value taken from the fluorescence threshold output of the PCR software as defined in <code>thresh</code>.
</p>
<p>The initial fluorescence <code class="reqn">F_0</code> for relative or absolute quantification is either calculated by setting <code class="reqn">x = 0</code> in the sigmoidal model of <code>object</code> giving <code>init1</code> or by calculating an exponential model down (<code>init2</code>) with <code class="reqn">F_0 = \frac{F_n}{E^n}</code>, with <code class="reqn">F_n</code> = raw fluorescence, <code class="reqn">E</code> = PCR efficiency and <code class="reqn">n</code> = the cycle number defined by <code>type</code>. If a template amount is defined, a conversion factor <code class="reqn">cf = \frac{amount}{F_0}</code> is given. The different measures for goodness-of-fit give an overview for the validity of the efficiency estimation. First and second derivatives are calculated from the fitted function and the maxima of the derivatives curve and the efficiency curve are obtained. 
</p>
<p>If <code>type = "maxRatio"</code>, the maximum efficiency is calculated from the cubic spline interpolated raw fluorescence values and therefore NOT from the sigmoidal fit. This is a different paradigm and will usually result in fairly the same threshold cycles as with <code>type = "cpD2"</code>, but the efficiencies are generally lower. See documentation to <code><a href="#topic+maxRatio">maxRatio</a></code>. This method is usually not applied for calculating efficiencies that are to be used for relative quantification, but one might try...  
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff</code></td>
<td>
<p>the PCR efficiency.</p>
</td></tr>
<tr><td><code>resVar</code></td>
<td>
<p>the residual variance.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>the bias-corrected Akaike Information Criterion.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>the Akaike Information Criterion.</p>
</td></tr>
<tr><td><code>Rsq</code></td>
<td>
<p>the <code class="reqn">R^2</code> value.</p>
</td></tr>
<tr><td><code>Rsq.ad</code></td>
<td>
<p>the adjusted <code class="reqn">R_{adj}^2</code> value.</p>
</td></tr>
<tr><td><code>cpD1</code></td>
<td>
<p>the first derivative maximum (point of inflection in 'l4' or 'b4' models, 
can be used for defining the threshold cycle).</p>
</td></tr>
<tr><td><code>cpD2</code></td>
<td>
<p>the second derivative maximum (turning point of cpD1, more often used for defining 
the threshold cycle).</p>
</td></tr>
<tr><td><code>cpE</code></td>
<td>
<p>the PCR cycle with the highest efficiency.</p>
</td></tr>
<tr><td><code>cpR</code></td>
<td>
<p>the PCR cycle within the exponential region calculated as under 'Details'.</p>
</td></tr>
<tr><td><code>cpT</code></td>
<td>
<p>the PCR cycle corresponding to the fluorescence threshold as defined in <code>thresh</code>.</p>
</td></tr>
<tr><td><code>Cy0</code></td>
<td>
<p>the PCR threshold cycle 'Cy0' according to Guescini et al. See 'Details'.</p>
</td></tr> 
<tr><td><code>cpCQ</code></td>
<td>
<p>the PCR cycle corresponding to the 20% fluorescence value at 'cpD2'.</p>
</td></tr>
<tr><td><code>cpMR</code></td>
<td>
<p>the PCR cycle corresponding to the 'maxRatio', if this was selected.</p>
</td></tr>
<tr><td><code>fluo</code></td>
<td>
<p>the raw fluorescence value at the point defined by <code>type</code> or <code>thresh</code>.</p>
</td></tr>
<tr><td><code>init1</code></td>
<td>
<p>the initial template fluorescence from the sigmoidal model, calculated as under 'Details'.</p>
</td></tr>
<tr><td><code>init2</code></td>
<td>
<p>the initial template fluorescence from an exponential model, calculated as under 'Details'.</p>
</td></tr>
<tr><td><code>cf</code></td>
<td>
<p>the conversion factor between raw fluorescence and template amount, if the latter is defined.</p>
</td></tr>
</table>
<p>If <code>object</code> was of type 'modlist', the results are given as a matrix, with samples in columns.
</p>


<h3>Note</h3>

<p>In some curves that are fitted with the 'b5'/'l5' models, the 'f' (asymmetry) parameter can be extremely high due to severe asymmetric structure. The efficiency curve deduced from the coefficients of the fit can then be very extreme in the exponential region. It is strongly advised to use <code>efficiency(object, method = "spline")</code> so that <code><a href="#topic+eff">eff</a></code> calculates the curve from a cubic spline of the original data points (see 'Examples').
</p>
<p>Three parameter models ('b3' or 'l3') do not work very well in calculating the PCR efficiency. It is advisable not to take too many cycles of the plateau phase prior to fitting the model as this has a strong effect on the validity of the efficiency estimates. 
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess 
</p>


<h3>References</h3>

<p>Validation of a quantitative method for real time PCR kinetics.<br />
Liu W &amp; Saint DA.<br />  
<em>BBRC</em> (2002), <b>294</b>: 347-353.<br />
</p>
<p>A new real-time PCR method to overcome significant quantitative inaccuracy due to slight amplification inhibition.<br />
Guescini M, Sisti D, Rocchi MB, Stocchi L &amp; Stocchi V.<br />
<em>BMC Bioinformatics</em> (2008), <b>9</b>: 326.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fitting initial model.
m1 &lt;-  pcrfit(reps, 1, 2, l4)
efficiency(m1)
 
## Using one cycle 'downstream'
## of second derivative max.
efficiency(m1, type = "cpD2", shift = -1)

## Using "maxE" method, with calculation of PCR efficiency
## 2 cycles 'upstream' from the cycle of max efficiency.
efficiency(m1, type = "maxE", shift = 2)

## Using the exponential region.
efficiency(m1, type = "expR")

## Using threshold cycle (i.e. 15.32) 
## from PCR software.
efficiency(m1, type = 15.32)

## Using Cy0 method from Guescini et al. (2008)
## add Cy0 tangent. 
efficiency(m1, type = "Cy0")
Cy0(m1, add = TRUE)

## Using a defined fluorescence
## threshold value from PCR software.
efficiency(m1, thresh = 1)
 
## Using the first 30 cycles and a template amount
## (optical calibration).
m2 &lt;-  pcrfit(reps[1:30, ], 1, 2, l5)
efficiency(m2, amount = 1E3)

## Using 'maxRatio' method from Shain et al. (2008)
## baseshifting essential!
efficiency(m1, type = "maxRatio", baseshift = 0.2)

## Using the efficiency from a cubic spline fit
## of the 'eff' function.
efficiency(m1, method = "spline")

## Not run: 
## On a modlist with plotting
## of the efficiencies.
ml1 &lt;- modlist(reps, model = l5)
res &lt;- sapply(ml1, function(x) efficiency(x)$eff)
barplot(as.numeric(res))

## End(Not run)
</code></pre>

<hr>
<h2 id='evidence'>Evidence ratio for model comparisons with AIC, AICc or BIC</h2><span id='topic+evidence'></span>

<h3>Description</h3>

<p>The evidence ratio </p>
<p style="text-align: center;"><code class="reqn">\frac{1}{exp(-0.5 \cdot (IC2 - IC1))}</code>
</p>
<p> is calculated for one of the information criteria <code class="reqn">IC = AIC, AICc, BIC</code> either from two fitted models or two numerical values. Models can be compared that are not nested and where the f-test on residual-sum-of-squares is not applicable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evidence(x, y, type = c("AIC", "AICc", "BIC"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evidence_+3A_x">x</code></td>
<td>
<p>a fitted object or numerical value.</p>
</td></tr>
<tr><td><code id="evidence_+3A_y">y</code></td>
<td>
<p>a fitted object or numerical value.</p>
</td></tr>
<tr><td><code id="evidence_+3A_type">type</code></td>
<td>
<p>any of the three Information Criteria <code>AIC, AICc or BIC</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Small differences in values can mean substantial more 'likelihood' of one model over the other. For example, a model with AIC = -130 is nearly 150 times more likely than a model with AIC = -120.   
</p>


<h3>Value</h3>

<p>A value of the first model <code>x</code> being more likely than the second model <code>y</code>. If large, first model is better. If small, second model is better.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare two four-parameter and five-parameter
## log-logistic models.
m1 &lt;- pcrfit(reps, 1, 2, l4)
m2 &lt;- pcrfit(reps, 1, 2, l5)
evidence(m2, m1)

## Ratio of two AIC's.
evidence(-120, -123)
</code></pre>

<hr>
<h2 id='expcomp'>Comparison of all sigmodal models within the exponential region</h2><span id='topic+expcomp'></span>

<h3>Description</h3>

<p>The exponential region of the qPCR data is identified by the studentized outlier method, as in <code><a href="#topic+expfit">expfit</a></code>.
The root-mean-squared-error (RMSE) of all available sigmoidal models within this region is then calculated.
The result of the fits are plotted and models returned in order of ascending RMSE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expcomp(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expcomp_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="expcomp_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code>expfit</code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The following sigmoidal models are fitted:
b4, b5, b6, b7, l4, l5, l6, l7
</p>


<h3>Value</h3>

<p>A dataframe with names of the models, in ascending order of RMSE.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l4)
expcomp(m1)
</code></pre>

<hr>
<h2 id='expfit'>Calculation of PCR efficiency by fitting an exponential model</h2><span id='topic+expfit'></span>

<h3>Description</h3>

<p>An exponential model is fit to a window of defined size on the qPCR raw data. The window is identified either by the second derivative maximum 'cpD2' (default), 'studentized outlier' method as described in Tichopad <em>et al</em>. (2003), the 'midpoint' method (Peirson <em>et al</em>., 2003) or by subtracting the difference of cpD1 and cpD2 from cpD2 ('ERBCP', unpublished).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expfit(object, method = c("cpD2", "outlier", "midpoint", "ERBCP"),
       model = c("exp", "linexp"), offset = 0, pval = 0.05, n.outl = 3, 
       n.ground = 1:5, corfact = 1, fix = c("top", "bottom", "middle"), 
       nfit = 5, plot = TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expfit_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="expfit_+3A_method">method</code></td>
<td>
<p>one of the four possible methods to be used for defining the position of the fitting window.</p>
</td></tr>
<tr><td><code id="expfit_+3A_model">model</code></td>
<td>
<p>which exponential model to use. <code><a href="#topic+expGrowth">expGrowth</a></code> is default, but the linear-exponential model <code><a href="#topic+linexp">linexp</a></code> can also be chosen.</p>
</td></tr>
<tr><td><code id="expfit_+3A_offset">offset</code></td>
<td>
<p>for <code>method = "cpD2"</code>, the cycle offset from second derivative maximum.</p>
</td></tr>
<tr><td><code id="expfit_+3A_pval">pval</code></td>
<td>
<p>for <code>method = "outlier"</code>, the p-value for the outlier test.</p>
</td></tr>
<tr><td><code id="expfit_+3A_n.outl">n.outl</code></td>
<td>
<p>for <code>method = "outlier"</code>, the number of successive outlier cycles.</p>
</td></tr>
<tr><td><code id="expfit_+3A_n.ground">n.ground</code></td>
<td>
<p>for <code>method = "midpoint"</code>, the number of cycles in the noisy ground phase to calculate the standard deviation from.</p>
</td></tr>
<tr><td><code id="expfit_+3A_corfact">corfact</code></td>
<td>
<p>for <code>method = "ERBCP"</code>, the correction factor for finding the exponential region. See 'Details'.</p>
</td></tr>
<tr><td><code id="expfit_+3A_fix">fix</code></td>
<td>
<p>for methods &quot;midpoint&quot; and &quot;ERBCP&quot;, the orientation of the fitting window based on the identified point. See 'Details'.</p>
</td></tr> 
<tr><td><code id="expfit_+3A_nfit">nfit</code></td>
<td>
<p>the size of the fitting window.</p>
</td></tr>
<tr><td><code id="expfit_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, a graphical display of the curve and the fitted region is shown.</p>
</td></tr>
<tr><td><code id="expfit_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to the plotting function.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The exponential growth function <code class="reqn">f(x) = a \cdot exp(b \cdot x) + c</code> is fit to a subset of the data. Calls <code><a href="#topic+efficiency">efficiency</a></code> for calculation of the second derivative maximum, <code><a href="#topic+takeoff">takeoff</a></code> for calculation of the studentized residuals and 'outlier' cycle, and <code>midpoint</code> for calculation of the exponential phase 'midpoint'. For method 'ERBCP' (Exponential Region By Crossing Points), the exponential region is calculated by <code class="reqn">expR = cpD2 - \code{corfact} \cdot (cpD1-cpD2)</code>. The efficiency is calculated from the exponential fit with <code class="reqn">E = exp(b)</code> and the inital template fluorescence <code class="reqn">F_0 = a</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>point</code></td>
<td>
<p>the point within the exponential region as identified by one of the three methods.</p>
</td></tr>
<tr><td><code>cycles</code></td>
<td>
<p>the cycles of the identified region.</p>
</td></tr>
<tr><td><code>eff</code></td>
<td>
<p>the efficiency calculated from the exponential fit.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>the Akaike Information Criterion of the fit.</p>
</td></tr>
<tr><td><code>resVar</code></td>
<td>
<p>the residual variance of the fit.</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>the root-mean-squared-error of the fit.</p>
</td></tr>
<tr><td><code>init</code></td>
<td>
<p>the initial template fluorescence.</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>
<p>the exponential model of class 'nls'.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Standardized determination of real-time PCR efficiency from a single reaction set-up.<br />
Tichopad A, Dilger M, Schwarz G &amp; Pfaffl MW.<br />
<em>Nucleic Acids Research</em> (2003), <b>31</b>:e122.
</p>
<p>Comprehensive algorithm for quantitative real-time polymerase chain reaction.<br />
Zhao S &amp; Fernald RD.<br />
<em>J Comput Biol</em> (2005), <b>12</b>:1047-64.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Using default SDM method.
m1 &lt;- pcrfit(reps, 1, 2, l5)
expfit(m1)

## Using 'outlier' method.
expfit(m1, method = "outlier")

## Linear exponential model.
expfit(m1, model = "linexp")
</code></pre>

<hr>
<h2 id='fitchisq'>The chi-square goodness-of-fit</h2><span id='topic+fitchisq'></span>

<h3>Description</h3>

<p>Calculates <code class="reqn">\chi^2</code>, reduced <code class="reqn">\chi_{\nu}^2</code> and the <code class="reqn">\chi^2</code> fit probability for objects of class <code>pcrfit</code>, <code>lm</code>, <code>glm</code>, <code>nls</code> or any other object with a <code>call</code> component that includes <code>formula</code> and <code>data</code>.
The function checks for replicated data (i.e. multiple same predictor values). If replicates are not given, the function needs error values, otherwise <code>NA</code>'s are returned. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitchisq(object, error = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitchisq_+3A_object">object</code></td>
<td>
<p>a single model of class 'pcrfit', a 'replist' or any fitted model of the above.</p>
</td></tr>
<tr><td><code id="fitchisq_+3A_error">error</code></td>
<td>
<p>in case of a model without replicates, a single error for all response values or a vector of errors for each response value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance of a fit <code class="reqn">s^2</code> is also characterized by the statistic <code class="reqn">\chi^2</code> defined as followed:
</p>
<p style="text-align: center;"><code class="reqn">\chi^2 \equiv \sum_{i=1}^n \frac{(y_i - f(x_i))^2}{\sigma_i^2}</code>
</p>

<p>The relationship between <code class="reqn">s^2</code> and <code class="reqn">\chi^2</code> can be seen most easily by comparison with the reduced <code class="reqn">\chi^2</code>:
</p>
<p style="text-align: center;"><code class="reqn">\chi_\nu^2 = \frac{\chi^2}{\nu} = \frac{s^2}{\langle \sigma_i^2 \rangle}</code>
</p>

<p>whereas <code class="reqn">\nu</code> = degrees of freedom (N - p), and <code class="reqn">\langle \sigma_i^2 \rangle</code> is the weighted average of the individual variances. If the fitting function is a good approximation to the parent function, the value of the reduced chi-square should be approximately unity, <code class="reqn">\chi_\nu^2 = 1</code>. If the fitting function is not appropriate for describing the data, the deviations will be larger and the estimated variance will be too large, yielding a value greater than 1. A value less than 1 can be a consequence of the fact that there exists an uncertainty in the determination of <code class="reqn">s^2</code>, and the observed values of <code class="reqn">\chi_\nu^2</code> will fluctuate from experiment to experiment. To assign significance to the <code class="reqn">\chi^2</code> value, we can use the integral probability 
</p>
<p style="text-align: center;"><code class="reqn">P_\chi(\chi^2;\nu) = \int_{\chi^2}^\infty P_\chi(x^2, \nu)dx^2</code>
</p>

<p>which describes the probability that a random set of <em>n</em> data points sampled from the parent distribution would yield a value of <code class="reqn">\chi^2</code> equal to or greater than the calculated one. This is calculated by <code class="reqn">1 - pchisq(\chi^2, \nu)</code>.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table role = "presentation">
<tr><td><code>chi2</code></td>
<td>
<p>the <code class="reqn">\chi^2</code> value.</p>
</td></tr>
<tr><td><code>chi2.red</code></td>
<td>
<p>the reduced <code class="reqn">\chi_\nu^2</code>.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the fit probability as described above.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Data Reduction and Error Analysis for the Physical Sciences.<br />
Bevington PR &amp; Robinson DK.<br />
McGraw-Hill, New York (2003).<br />   
</p>
<p>Applied Regression Analysis.<br />
Draper NR &amp; Smith H.<br />
Wiley, New York, 1998.<br />    
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Using replicates by making a 'replist'.
ml1 &lt;- modlist(reps, fluo = 2:5)
rl1 &lt;- replist(ml1, group = c(1, 1, 1, 1))
fitchisq(rl1[[1]])

## Using single model with added error.
m1 &lt;- pcrfit(reps, 1, 2, l5)
fitchisq(m1, 0.1)
</code></pre>

<hr>
<h2 id='getPar'>Batch calculation of qPCR fit parameters/efficiencies/threshold cycles with simple output, especially tailored to high-throughput data</h2><span id='topic+getPar'></span>

<h3>Description</h3>

<p>This is a cut-down version of <code><a href="#topic+pcrbatch">pcrbatch</a></code>, starting with data of class 'modlist', which delivers a simple dataframe output, with either the parameters of the fit or calculated threshold cycles/efficiencies. The column names are deduced from the run names. All calculations have been error-protected through <code><a href="base.html#topic+tryCatch">tryCatch</a></code>, so whenever there is any kind of error (parameter extraction, efficiency estimation etc), <code>NA</code> is returned. This function can be used with high throughput data quite conveniently. All methods as in <code><a href="#topic+pcrbatch">pcrbatch</a></code> are available. The results are automatically copied to the clipboard.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPar(x, type = c("fit", "curve"), cp = "cpD2", eff = "sigfit", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPar_+3A_x">x</code></td>
<td>
<p>an object of class 'pcrfit' or 'modlist'.</p>
</td></tr>
<tr><td><code id="getPar_+3A_type">type</code></td>
<td>
<p><code>fit</code> will extract the fit parameters, <code>curve</code> will invoke <code><a href="#topic+efficiency">efficiency</a></code> and return threshold cycles/efficiencies.</p>
</td></tr>
<tr><td><code id="getPar_+3A_cp">cp</code></td>
<td>
<p>which method for threshold cycle estimation. Any of the methods in <code><a href="#topic+efficiency">efficiency</a></code>, i.e. &quot;cpD2&quot; (default), &quot;cpD1&quot;, &quot;maxE&quot;, &quot;expR&quot;, &quot;Cy0&quot;, &quot;CQ&quot;, &quot;maxRatio&quot;.</p>
</td></tr>
<tr><td><code id="getPar_+3A_eff">eff</code></td>
<td>
<p>which method for efficiency estimation. Either &quot;sigfit&quot; (default), &quot;sliwin&quot; or &quot;expfit&quot;.</p>
</td></tr>  
<tr><td><code id="getPar_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+sliwin">sliwin</a></code> or <code><a href="#topic+expfit">expfit</a></code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Takes about 4 sec for 100 runs on a Pentium 4 Quad-Core (3 Ghz) when using <code>type = "curve"</code>. When using <code>type = "fit"</code>, the fitted model parameters are returned. If <code>type = "curve"</code>, threshold cycles and efficiencies are calculated by <code><a href="#topic+efficiency">efficiency</a></code> based on the parameters supplied in <code>...</code> (default <code>cpD2</code>).
</p>


<h3>Value</h3>

<p>A dataframe, which is automatically copied to the clipboard.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simple example with fit parameters.
ml1 &lt;- modlist(rutledge, model = l5)
getPar(ml1, type = "fit")

## Using a mechanistic model such as
## 'mak3' and extracting D0 values
## =&gt; initial template fluorescence.
ml2 &lt;- modlist(rutledge, 1, 2:41, model = mak3)
res &lt;- getPar(ml2, type = "fit")
barplot(log10(res[1, ]), las = 2)
</code></pre>

<hr>
<h2 id='is.outlier'>Outlier summary for objects of class 'modlist' or 'replist'</h2><span id='topic+is.outlier'></span>

<h3>Description</h3>

<p>For model lists of class 'modlist' or 'replist', <code>is.outlier</code> returns a vector of logicals for each run if they are outliers (i.e. sigmoidal or kinetic) or not.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.outlier(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.outlier_+3A_object">object</code></td>
<td>
<p>an object of class 'modlist' or 'replist'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of logicals with run names.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KOD">KOD</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Analyze in respect to amplification
## efficiency outliers.
ml1 &lt;- modlist(reps, 1, 2:5)
res1 &lt;- KOD(ml1, check = "uni2")

## Which runs are outliers?
outl &lt;- is.outlier(res1)
outl
which(outl)

## Not run: 
## Test for sigmoidal outliers
## with the 'testdat' dataset.
ml2 &lt;- modlist(testdat, model = l5, check = "uni2")
is.outlier(ml2)    

## End(Not run)
</code></pre>

<hr>
<h2 id='KOD'>(K)inetic (O)utlier (D)etection using several methods</h2><span id='topic+KOD'></span>

<h3>Description</h3>

<p>Identifies and/or removes qPCR runs according to several published methods or own ideas. The univariate measures are based on efficiency or difference in first/second derivative maxima. Multivariate methods are implemented that describe the structure of the curves according to several fixpoints such as first/second derivative maximum, slope at first derivative maximum or plateau fluorescence. These measures are compared with a set of curves using the <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> distance with a robust covariance matrix and calculation of statistics by a <code class="reqn">\chi^2</code> distribution. See 'Details'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KOD(object, method = c("uni1", "uni2", "multi1", "multi2", "multi3"),
    par = parKOD(), remove = FALSE, verbose = TRUE, plot = TRUE,  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KOD_+3A_object">object</code></td>
<td>
<p>an object of class 'modlist' or 'replist'.</p>
</td></tr>
<tr><td><code id="KOD_+3A_method">method</code></td>
<td>
<p>which method to use for kinetic outlier identification. Method <code>"uni1"</code> is default. See 'Details' for all methods.</p>
</td></tr>
<tr><td><code id="KOD_+3A_par">par</code></td>
<td>
<p>parameters for the different <code>method</code>s. See <code><a href="#topic+parKOD">parKOD</a></code>.</p>
</td></tr>
<tr><td><code id="KOD_+3A_remove">remove</code></td>
<td>
<p>logical. If <code>TRUE</code>, outlier runs are removed and the object is updated. If <code>FALSE</code>, the individual qPCR runs are tagged as 'outliers' or not. See 'Details'.</p>
</td></tr>
<tr><td><code id="KOD_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, all calculation steps and results are displayed on the console.</p>
</td></tr>
<tr><td><code id="KOD_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, a multivariate plot is displayed.</p>
</td></tr>
<tr><td><code id="KOD_+3A_...">...</code></td>
<td>
<p>any other parameters to be passed to <code><a href="#topic+sliwin">sliwin</a></code>, <code><a href="#topic+efficiency">efficiency</a></code> or <code><a href="#topic+expfit">expfit</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>The following methods for the detection of kinetic outliers are implemented</b><br />
<code>uni1</code>: KOD method according to Bar et al. (2003). Outliers are defined by removing the sample efficiency from the replicate group and testing it against the remaining samples' efficiencies using a Z-test:
</p>
<p style="text-align: center;"><code class="reqn">P = 2 \cdot \left[1 - \Phi\left(\frac{e_i - \mu_{train}}{\sigma_{train}}\right)\right] &lt; 0.05</code>
</p>

<p><code>uni2</code>: This method from the package author is more or less a test on sigmoidal structure for the individual curves. It is different in that there is no comparison against other curves from a replicate set. The test is simple: The difference between first and second derivative maxima should be less than 10 cycles:
</p>
<p style="text-align: center;"><code class="reqn">\left(\frac{\partial^3 F(x;a,b,...)}{\partial x^3} = 0\right) - \left(\frac{\partial^2 F(x;a,b...)}{\partial x^2} = 0\right) &lt; 10</code>
</p>

<p>Sounds astonishingly simple, but works: Runs are defines as 'outliers' that really failed to amplify, i.e. have no sigmoidal structure or are very shallow. It is the default setting in <code><a href="#topic+modlist">modlist</a></code>.<br />
</p>
<p><code>multi1</code>: KOD method according to Tichopad et al. (2010). Assuming two vectors with first and second derivative maxima <code class="reqn">t_1</code> and <code class="reqn">t_2</code> from a 4-parameter sigmoidal fit within a window of points around the first derivative maximum, a linear model <code class="reqn">t_2 = t_1 \cdot b + a + \tau</code> is made. Both <code class="reqn">t_1</code> and the residuals from the fit <code class="reqn">\tau = t_2 - \hat{t_2}</code> are Z-transformed:
</p>
<p style="text-align: center;"><code class="reqn">t_1(norm) = \frac{t_1 - \bar{t}_1}{{\sigma_t}_1}, \; {\tau_1}_{norm} = \frac{\tau_1 - \bar{\tau}_1}{{\sigma_\tau}_1}</code>
</p>
 
<p>Both <code class="reqn">t_1</code> and <code class="reqn">\tau</code> are used for making a robust covariance matrix. The outcome is plugged into a <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> distance analysis using the 'adaptive reweighted estimator' from package 'mvoutlier' and p-values for significance of being an 'outlier' are deduced from a <code class="reqn">\chi^2</code> distribution. If more than two parameters are supplied, <code><a href="stats.html#topic+princomp">princomp</a></code> is used instead.
</p>
<p><code>multi2</code>: Second KOD method according to Tichopad et al. (2010), mentioned in the paper. Uses the same pipeline as <code>multi1</code>, but with the slope at the first derivative maximum and maximum fluorescence as parameters:
</p>
<p style="text-align: center;"><code class="reqn">\frac{\partial F(x;a,b,...)}{\partial x}, F_{max}</code>
</p>

<p><code>multi3</code>: KOD method according to Sisti et al. (2010). Similar to <code>multi2</code>, but uses maximum fluorescence, slope at first derivative maximum and y-value at first derivative maximum as fixpoints:
</p>
<p style="text-align: center;"><code class="reqn">\frac{\partial F(x;a,b,...)}{\partial x}, F\left(\frac{\partial^2 F(x;a,b,...)}{\partial x^2} = 0\right), F_{max}</code>
</p>

<p>All essential parameters for the methods can be tweaked by <code><a href="#topic+parKOD">parKOD</a></code>. See there and in 'Examples'.
</p>


<h3>Value</h3>

<p>An object of the same class as in <code>object</code> that is 'tagged' in its name (**name**) if it is an outlier and also with an item <code>$isOutlier</code> with outlier information (see <code><a href="#topic+is.outlier">is.outlier</a></code>). If <code>remove = TRUE</code>, the outlier runs are removed (and the fitting updated in case of a 'replist').  
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Kinetic Outlier Detection (KOD) in real-time PCR.<br />
Bar T, Stahlberg A, Muszta A &amp; Kubista M.<br />
<em>Nucl Acid Res</em> (2003), <b>31</b>: e105. 
</p>
<p>Quality control for quantitative PCR based on amplification compatibility test.<br />
Tichopad A, Bar T, Pecen L, Kitchen RR, Kubista M &amp;, Pfaffl MW.<br />
<em>Methods</em> (2010), <b>50</b>: 308-312.
</p>
<p>Shape based kinetic outlier detection in real-time PCR.<br />
Sisti D, Guescini M, Rocchi MBL, Tibollo P, D'Atri M &amp; Stocchi V.<br />
<em>BMC Bioinformatics</em> (2010), <b>11</b>: 186.
</p>


<h3>See Also</h3>

<p>Function <code><a href="#topic+is.outlier">is.outlier</a></code> to get an outlier summary.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## kinetic outliers:
## on a 'modlist', using efficiency from sigmoidal fit
## and alpha = 0.01. 
## F7.3 detected as outlier (shallower =&gt; low efficiency)
ml1 &lt;- modlist(reps, 1, c(2:5, 28), model = l5)
res1 &lt;- KOD(ml1, method = "uni1", par = parKOD(eff = "sliwin", alpha = 0.01))
plot(res1)

## Sigmoidal outliers:
## remove runs without sigmoidal structure.
ml2 &lt;- modlist(testdat, model = l5)
res2 &lt;- KOD(ml2, method = "uni2", remove = TRUE)
plot(res2, which = "single")

## Not run: 
## Multivariate outliers:
## a few runs are identified.
ml3 &lt;- modlist(reps, model = l5)
res3 &lt;- KOD(ml3, method = "multi1")

## On a 'replist', several outliers identified.
rl3 &lt;- replist(ml3, group = gl(7, 4))
res4 &lt;- KOD(rl3, method = "uni1")

## End(Not run)
</code></pre>

<hr>
<h2 id='llratio'>Calculation of likelihood ratios for nested models</h2><span id='topic+llratio'></span>

<h3>Description</h3>

<p>Calculates the likelihood ratio and p-value from a chi-square distribution for two nested models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llratio(objX, objY)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="llratio_+3A_objx">objX</code></td>
<td>
<p>Either a value of class <code>logLik</code> or a model for which <code><a href="stats.html#topic+logLik">logLik</a></code> can be applied.</p>
</td></tr>
<tr><td><code id="llratio_+3A_objy">objY</code></td>
<td>
<p>Either a value of class <code>logLik</code> or a model for which <code><a href="stats.html#topic+logLik">logLik</a></code> can be applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood ratio statistic is </p>
<p style="text-align: center;"><code class="reqn">LR = \frac{f(X, \hat{\phi}, \hat{\psi})}{f(X, \phi, \hat{\psi_0})}</code>
</p>

<p>The usual test statistic is </p>
<p style="text-align: center;"><code class="reqn">\Lambda = 2 \cdot (l(\hat{\phi}, \hat{\psi}) - l(\phi, \hat{\psi_0}))</code>
</p>

<p>Following the large sample theory, if <code class="reqn">H_0</code> is true, then </p>
<p style="text-align: center;"><code class="reqn">\Lambda \sim \chi_p^2</code>
</p>
  


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table role = "presentation">
<tr><td><code>ratio</code></td>
<td>
<p>the likelihood ratio statistic.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the change in parameters.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value from a <code class="reqn">\chi^2</code> distribution. See Details.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare l5 and l4 model.
m1 &lt;- pcrfit(reps, 1, 2, l5)
m2 &lt;- pcrfit(reps, 1, 2, l4)
llratio(m1, m2)
</code></pre>

<hr>
<h2 id='LOF.test'>Formal lack-Of-Fit test of a nonlinear model against a one-way ANOVA model</h2><span id='topic+LOF.test'></span>

<h3>Description</h3>

<p>Tests the nonlinear model against a more general one-way ANOVA model and from a likelihood ratio test.
P-values are derived from the F- and <code class="reqn">\chi^2</code> distribution, respectively. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOF.test(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LOF.test_+3A_object">object</code></td>
<td>
<p>an object of class 'replist', 'pcrfit' or 'nls', which was fit with replicate response values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The one-way ANOVA model is constructed from the <code>data</code> component of the nonlinear model by factorizing each of the predictor values.
Hence, the nonlinear model becomes a submodel of the one-way ANOVA model and we test both models with the null hypothesis that the ANOVA model
can be simplified to the nonlinear model (Lack-of-fit test). This is done by two approaches:
</p>
<p>1) an F-test (Bates &amp; Watts, 1988).<br />
2) a likelihood ratio test (Huet <em>et al</em>, 2004).
</p>
<p>P-values are derived from an F-distribution (1) and a <code class="reqn">\chi^2</code> distribution (2).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>pF</code></td>
<td>
<p>the p-value from the F-test against the one-way ANOVA model.</p>
</td></tr>
<tr><td><code>pLR</code></td>
<td>
<p>the p-value from the likelihood ratio test against the one-way ANOVA model.</p>
</td></tr>      
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Nonlinear Regression Analysis and its Applications.<br />
Bates DM &amp; Watts DG.<br />
John Wiley &amp; Sons (1988), New York.<br />
</p>
<p>Statistical Tools for Nonlinear Regression: A Practical Guide with S-PLUS and R Examples.<br />
Huet S, Bouvier A, Poursat MA &amp; Jolivet E.<br />
Springer Verlag (2004), New York, 2nd Ed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with a 'replist'
## no lack-of-fit.
ml1 &lt;- modlist(reps, fluo = 2:5, model = l5)
rl1 &lt;- replist(ml1, group = c(1, 1, 1, 1))
LOF.test(rl1)

## Example with a 'nls' fit
## =&gt; there is a lack-of-fit.
DNase1 &lt;- subset(DNase, Run == 1)
fm1DNase1 &lt;- nls(density ~ SSlogis(log(conc), Asym, xmid, scal), DNase1) 
LOF.test(fm1DNase1)
</code></pre>

<hr>
<h2 id='LRE'>Calculation of qPCR efficiency by the 'linear regression of efficiency' method</h2><span id='topic+LRE'></span>

<h3>Description</h3>

<p>The LRE method is based on a linear regression of raw fluorescence versus efficiency, with the final aim to obtain cycle dependent individual efficiencies <code class="reqn">E_n</code>. A linear model is then fit to a sliding window of defined size(s) and within a defined border. Regression coefficients are calculated for each window, and from the window of maximum regression, parameters such as PCR efficiency and initial template fluorescence are calculated. See 'Details' for more information. This approach is quite similar to the one in <code><a href="#topic+sliwin">sliwin</a></code>, but while <code>sliwin</code> regresses cycle number versus log(fluorescence), <code>LRE</code> regresses raw fluorescence versus efficiency. Hence, the former is based on assuming a constant efficiency for all cycles while the latter is based on a per-cycle individual efficiency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRE(object, wsize = 6, basecyc = 1:6, base = 0, border = NULL, 
    plot = TRUE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRE_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="LRE_+3A_wsize">wsize</code></td>
<td>
<p>the size(s) of the sliding window(s), default is <code>6</code>. A sequence such as <code>4:6</code> can be used to optimize the window size.</p>
</td></tr>
<tr><td><code id="LRE_+3A_basecyc">basecyc</code></td>
<td>
<p>if <code>base != 0</code>, which cycles to use for an initial baseline estimation based on the averaged fluorescence values.</p>
</td></tr>
<tr><td><code id="LRE_+3A_base">base</code></td>
<td>
<p>either <code>0</code> for no baseline optimization, or a scalar defining multiples of the standard deviation of all baseline points obtained from <code>basecyc</code>. These are iteratively subtracted from the raw data. See 'Details' and 'Examples'.</p>
</td></tr>
<tr><td><code id="LRE_+3A_border">border</code></td>
<td>
<p>either <code>NULL</code> (default) or a two-element vector which defines the border from the take-off point to points nearby the upper asymptote (saturation phase). See 'Details'.</p>
</td></tr>
<tr><td><code id="LRE_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, the result is plotted with the fluorescence/efficiency curve, sliding window, regression line and baseline.</p>
</td></tr>	
<tr><td><code id="LRE_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, more information is displayed in the console window.</p>
</td></tr>
<tr><td><code id="LRE_+3A_...">...</code></td>
<td>
<p>only used internally for passing the parameter matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To avoid fits with a high <code class="reqn">R^2</code> in the baseline region, some border in the data must be defined. In <code>LRE</code>, this is by default (<code>base = NULL</code>) the region in the curve starting at the take-off cycle (<code class="reqn">top</code>) as calculated from <code><a href="#topic+takeoff">takeoff</a></code> and ending at the transition region to the upper asymptote (saturation region). The latter is calculated from the first and second derivative maxima: <code class="reqn">asympt = cpD1 + (cpD1 - cpD2)</code>. If the border is to be set by the user, <code>border</code> values such as <code>c(-2, 4)</code> extend these values by <code class="reqn">top + border[1]</code> and <code class="reqn">asympt + border[2]</code>. The efficiency is calculated by <code class="reqn">E_n =  \frac{F_n}{F_{n-1}}</code> and regressed against the raw fluorescence values <code class="reqn">F</code>: <code class="reqn">E = F\beta + \epsilon</code>. For the baseline optimization, 100 baseline values <code class="reqn">Fb_i</code> are interpolated in the range of the data: </p>
<p style="text-align: center;"><code class="reqn">F_{min} \le Fb_i \le base \cdot \sigma(F_{basecyc[1]}...F_{basecyc[2]})</code>
</p>
<p> and subtracted from <code class="reqn">F_n</code>. For all iterations, the best regression window in terms of <code class="reqn">R^2</code> is found and its parameters returned.
Two different initial template fluorescence values <code class="reqn">F_0</code> are calculated in <code>LRE</code>:<br />
</p>
<p><code>init1</code>: Using the single maximum efficiency <code class="reqn">E_{max}</code> (the intercept of the best fit) and the fluorescence at second derivative maximum <code class="reqn">F_{cpD2}</code>, by
</p>
<p style="text-align: center;"><code class="reqn">F_0 = \frac{F_{cpD2}}{E_{max}^{cpD2}}</code>
</p>

<p><code>init2</code>: Using the cycle dependent efficiencies <code class="reqn">E_n</code> from <code class="reqn">n = 1</code> to the near-lowest integer (floor) cycle of the second derivative maximum <code class="reqn">n = \lfloor cpD2 \rfloor</code>, and the fluorescence at the floor of the second derivative maximum <code class="reqn">F_{\lfloor cpD2 \rfloor}</code>, by
</p>
<p style="text-align: center;"><code class="reqn">F_0 = \frac{F_{\lfloor cpD2 \rfloor}}{\prod E_n}</code>
</p>

<p>This approach corresponds to the paradigm described in Rutledge &amp; Stewart (2008), by using cycle-dependent and decreasing efficiencies <code class="reqn">\Delta_E</code> to calculate <code class="reqn">F_0</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff</code></td>
<td>
<p>the maximum PCR efficiency <code class="reqn">E_{max}</code> calculated from the best window.</p>
</td></tr>
<tr><td><code>rsq</code></td>
<td>
<p>the maximum <code class="reqn">R^2</code>.</p>
</td></tr>
<tr><td><code>base</code></td>
<td>
<p>the optimized baseline value.</p>
</td></tr>
<tr><td><code>window</code></td>
<td>
<p>the best window found within the <code>border</code>s.</p>
</td></tr>  
<tr><td><code>parMat</code></td>
<td>
<p>a matrix containing the parameters as above for each iteration.</p>
</td></tr>
<tr><td><code>init1</code></td>
<td>
<p>the initial template fluorescence <code class="reqn">F_0</code> assuming constant efficiency <code class="reqn">E_{max}</code> as described under 'Details'.</p>
</td></tr>
<tr><td><code>init2</code></td>
<td>
<p>the initial template fluorescence <code class="reqn">F_0</code>, assuming cycle-dependent efficiency <code class="reqn">E_n</code> as described under 'Details'.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>A kinetic-based sigmoidal model for the polymerase chain reaction and its application to high-capacity absolute quantitative real-time PCR.<br />
Rutledge RG &amp; Stewart D.<br />
<em>BMC Biotech</em> (2008), <b>8</b>: 47.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Sliding window of size 5 between take-off point 
## and 3 cycles upstream of the upper asymptote 
## turning point, one standard deviation baseline optimization.
m1 &lt;- pcrfit(reps, 1, 2, l4)
LRE(m1, wsize = 5, border = c(0, 3), base = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='maxRatio'>The maxRatio method as in Shain et al. (2008)</h2><span id='topic+maxRatio'></span>

<h3>Description</h3>

<p>The maximum ratio (MR) is determined along the cubic spline interpolated curve of <code class="reqn">\frac{F_n}{F_{n-1}}</code> and the corresponding cycle numbers FCN and its adjusted version FCNA are then calculated for MR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxRatio(x, method = c("spline", "sigfit"), baseshift = NULL, 
         smooth = TRUE, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maxRatio_+3A_x">x</code></td>
<td>
<p>an object of class 'pcrfit' (single run) or 'modlist' (multiple runs).</p>
</td></tr>
<tr><td><code id="maxRatio_+3A_method">method</code></td>
<td>
<p>the parameters are either calculated from the cubic spline interpolation (default) or a sigmoidal fit.</p>
</td></tr>
<tr><td><code id="maxRatio_+3A_baseshift">baseshift</code></td>
<td>
<p>numerical. Shift value in case of <code>type = "spline"</code>. See 'Details'.</p>
</td></tr>
<tr><td><code id="maxRatio_+3A_smooth">smooth</code></td>
<td>
<p>logical. If <code>TRUE</code> and <code>type = "spline"</code>, invokes a 5-point convolution filter (<code><a href="stats.html#topic+filter">filter</a></code>). See 'Details'.</p>
</td></tr> 
<tr><td><code id="maxRatio_+3A_plot">plot</code></td>
<td>
<p>Should diagnostic plots be displayed?</p>
</td></tr>
<tr><td><code id="maxRatio_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+eff">eff</a></code> or <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>     
</table>


<h3>Details</h3>

                   
<p>In a first step, the raw fluorescence data can be smoothed by a 5-point convolution filter. This is optional but feasible for many qPCR setups with significant noise in the baseline region, and therefore set to <code>TRUE</code> as default. If <code>baseshift</code> is a numeric value, this is added to each response value <code class="reqn">F_n = F_n + baseshift</code> (baseline shifting). Finally, a cubic spline is fit with a resolution of 0.01 cycles and the maximum ratio (efficiency) is calculated by <code class="reqn">MR = max(\frac{F_n}{F_{n-1}}-1)</code>. <code class="reqn">FCN</code> is then calculated as the cycle number at <code class="reqn">MR</code> and from this the adjusted <code class="reqn">FCNA = FCN -log_2(MR)</code>. Sometimes problems are encountered in which, due to high noise in the background region, randomly high efficiency ratios are calculated. This must be resolved by tweaking the <code>baseshift</code> value.  
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff</code></td>
<td>
<p>the maximum efficiency. Equals to <code>mr</code> + 1.</p>
</td></tr>
<tr><td><code>mr</code></td>
<td>
<p>the maximum ratio.</p>
</td></tr>
<tr><td><code>fcn</code></td>
<td>
<p>the cycle number at <code>mr</code>.</p>
</td></tr>
<tr><td><code>fcna</code></td>
<td>
<p>an adjusted <code>fcn</code>, as described in Shain et al.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>the names of the runs as taken from the original dataframe.</p>
</td></tr>  
</table>


<h3>Note</h3>

<p>This function has been approved by the original author (Eric Shain).
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>A new method for robust quantitative and qualitative analysis of real-time PCR.<br />
Shain EB &amp; Clemens JM.<br />
<em>Nucleic Acids Research</em> (2008), <b>36</b>: e91.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## On single curve using baseline shifting.
m1 &lt;- pcrfit(reps, 1, 2, l5)
maxRatio(m1, baseshift = 0.3)     

## On a 'modlist' using baseline shifting.
## Not run: 
ml1 &lt;- modlist(reps, model = l5) 
maxRatio(ml1, baseshift = 0.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='meltcurve'>Melting curve analysis with (iterative) Tm identification and peak area calculation/cutoff</h2><span id='topic+meltcurve'></span>

<h3>Description</h3>

<p>This function conducts a melting curve analysis from the melting curve data of a real-time qPCR instrument.
The data has to be preformatted in a way that for each column of temperature values there exists a corresponding fluorescence value column. See <code>edit(dyemelt)</code> for a proper format. The output is a graph displaying the raw fluorescence curve (black), the first derivative curve (red) and the identified melting peaks. The original data together with the results (<code class="reqn">-\frac{\partial F}{\partial T}</code> values, <code class="reqn">T_m</code> values) are returned as a list. An automatic optimization procedure is also implemented which iterates over <code>span.smooth</code> and <code>span.peaks</code> values and finds the optimal parameter combination that delivers minimum residual sum-of-squares of the identified <code class="reqn">T_m</code> values to known <code class="reqn">T_m</code> values. For all peaks, the areas can be calculated and only those included which have areas higher than a given cutoff (<code>cut.Area</code>). If no peak was identified meeting the cutoff values, the melting curves are flagged with a 'bad' attribute. See 'Details'. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meltcurve(data, temps = NULL, fluos = NULL, window = NULL, 
          norm = FALSE, span.smooth = 0.05, span.peaks = 51, 
          is.deriv = FALSE, Tm.opt = NULL, Tm.border = c(1, 1), 
          plot = TRUE, peaklines = TRUE, calc.Area = TRUE, 
          plot.Area = TRUE, cut.Area = 0,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meltcurve_+3A_data">data</code></td>
<td>
<p>a dataframe containing the temperature and fluorescence data.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_temps">temps</code></td>
<td>
<p>a vector of column numbers reflecting the temperature values. If <code>NULL</code>, they are assumed to be 1, 3, 5, ... .</p>
</td></tr>     
<tr><td><code id="meltcurve_+3A_fluos">fluos</code></td>
<td>
<p>a vector of column numbers reflecting the fluorescence values. If <code>NULL</code>, they are assumed to be 2, 4, 6, ... .</p>
</td></tr>  	
<tr><td><code id="meltcurve_+3A_window">window</code></td>
<td>
<p>a user-defined window for the temperature region to be analyzed. See 'Details'.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_norm">norm</code></td>
<td>
<p>logical. If <code>TRUE</code>, the fluorescence values are scaled between [0, 1].</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_span.smooth">span.smooth</code></td>
<td>
<p>the window span for curve smoothing. Can be tweaked to optimize <code class="reqn">T_m</code> identification.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_span.peaks">span.peaks</code></td>
<td>
<p>the window span for peak identification. Can be tweaked to optimize <code class="reqn">T_m</code> identification. Must be an odd number.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_is.deriv">is.deriv</code></td>
<td>
<p>logical. Use <code>TRUE</code>, if <code>data</code> is already in first derivative transformed format.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_tm.opt">Tm.opt</code></td>
<td>
<p>a possible vector of known <code class="reqn">T_m</code> values to optimize <code>span.smooth</code> and <code>span.peaks</code> against. See 'Details' and 'Examples'.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_tm.border">Tm.border</code></td>
<td>
<p>for peak area calculation, a vector containing left and right border temperature values from the <code class="reqn">T_m</code> values. Default is -1/+1 ?C.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, a plot with the raw melting curve, derivative curve and identified <code class="reqn">T_m</code> values is displayed for each sample.</p>
</td></tr>
<tr><td><code id="meltcurve_+3A_peaklines">peaklines</code></td>
<td>
<p>logical. If <code>TRUE</code>, lines that show the identified peaks are plotted.</p>
</td></tr> 
<tr><td><code id="meltcurve_+3A_calc.area">calc.Area</code></td>
<td>
<p>logical. If <code>TRUE</code>, all peak areas are calculated.</p>
</td></tr> 
<tr><td><code id="meltcurve_+3A_plot.area">plot.Area</code></td>
<td>
<p>logical. If <code>TRUE</code>, the baselined area identified for the peaks is plotted by filling the peaks in red.</p>
</td></tr> 
<tr><td><code id="meltcurve_+3A_cut.area">cut.Area</code></td>
<td>
<p>a peak area value to identify only those peaks with a higher area.</p>
</td></tr> 
<tr><td><code id="meltcurve_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The melting curve analysis is conducted with the following steps:<br />
</p>
<p>1a) Temperature and fluorescence values are selected in a region according to <code>window</code>.<br />
1b) If <code>norm = TRUE</code>, the fluorescence data is scaled into [0, 1] by <code>qpcR:::rescale</code>.<br />
Then, the function <code>qpcR:::TmFind</code> conducts the following steps:<br />
2a) A cubic spline function (<code><a href="stats.html#topic+splinefun">splinefun</a></code>) is fit to the raw fluorescence melt values.<br />
2b) The first derivative values are calculated from the spline function for each of the temperature values.<br />
2c) Friedman's supersmoother (<code><a href="stats.html#topic+supsmu">supsmu</a></code>) is applied to the first derivative values.<br />
2d) Melting peaks (<code class="reqn">T_m</code>) values are identified by <code>qpcR:::peaks</code>.<br />
2e) Raw melt data, first derivative data, best parameters, residual sum-of-squares and identified <code class="reqn">T_m</code> values are returned.<br /> 
Peak areas are then calculated by <code>qpcR:::peakArea</code>:<br />
3a) A linear regression curve is fit from the leftmost temperature value (<code class="reqn">T_m</code> - <code>Tm.border</code>[1]) to the rightmost temperature value (<code class="reqn">T_m</code> + <code>Tm.border</code>[2]) by <code><a href="stats.html#topic+lm">lm</a></code>.<br />
3b) A baseline curve is calculated from the regression coefficients by <code><a href="stats.html#topic+predict.lm">predict.lm</a></code>.<br />
3c) The baseline data is subtracted from the first derivative melt data (baselining).<br />
3d) A <code><a href="stats.html#topic+splinefun">splinefun</a></code> is fit to the baselined data.<br />
3e) The area of this spline function is <code><a href="stats.html#topic+integrate">integrate</a></code>d from the leftmost to rightmost temperature value.<br />
4) If calculated peak areas were below <code>cut.Area</code>, the corresponding <code class="reqn">T_m</code> values are removed.<br /> 
Finally,<br />
5) A matrix of xyy-plots is displayed using <code>qpcR:::xyy.plot</code>.<br />
</p>
<p><code>is.deriv</code> must be set to <code>TRUE</code> if the exported data was already transformed to <code class="reqn">-\frac{\partial F}{\partial T}</code> by the PCR system (i.e. Stratagene MX3000P).<br />
</p>
<p>If values are given to <code>Tm.opt</code> (see 'Examples'), then <code>meltcurve</code> is iterated over all combinations of <code>span.smooth = seq(0, 0.2, by = 0.01)</code> and <code>span.peaks = seq(11, 201, by = 10)</code>. For each iteration, <code class="reqn">T_m</code> values are calculated and compared to those given by measuring the residual sum-of-squares between the given values <code>Tm.opt</code> and the <code class="reqn">Tm</code> values obtained during the iteration:
</p>
<p style="text-align: center;"><code class="reqn">RSS = \sum_{i=1}^n{(Tm_i - Tm.opt_i)^2}</code>
</p>
 
<p>The returned list items containing the resulting data frame each has an attribute <code>"quality"</code> which is set to &quot;bad&quot; if none of the peaks met the <code>cut.Area</code> criterion (or &quot;good&quot; otherwise).
</p>


<h3>Value</h3>

<p>A list with as many items as melting curves, named as in <code>data</code>, each containing a data.frame with the temperature (<em>Temp</em>), fluorescence values (<em>Fluo</em>), first derivative (<em>dF.dT</em>) values, (optimized) parameters of <em>span.smooth</em>/<em>span.peaks</em>, residual sum-of-squares (if <code>Tm.opt != NULL</code>), identified melting points (<em>Tm</em>), calculated peak areas (<em>Area</em>) and peak baseline values (<em>baseline</em>).  
</p>


<h3>Note</h3>

<p>The <code>peaks</code> function is derived from a R-Help mailing list entry in Nov 2005 by Martin Maechler.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Default columns.
data(dyemelt)
res1 &lt;- meltcurve(dyemelt, window = c(75, 86))
res1

## Selected columns and normalized fluo values.
res2 &lt;- meltcurve(dyemelt, temps = c(1, 3), fluos = c(2, 4), 
                  window = c(75, 86), norm = TRUE)  

## Removing peaks based on peak area
## =&gt; two peaks have smaller areas and are not included.
res3 &lt;- meltcurve(dyemelt, temps = 1, fluos = 2, window = c(75, 86),  
                  cut.Area = 0.2) 
attr(res3[[1]], "quality")
                 
## If all peak areas do not meet the cutoff value, meltcurve is
## flagged as 'bad'.
res4 &lt;- meltcurve(dyemelt, temps = 1, fluos = 2, window = c(75, 86),  
                  cut.Area = 0.5) 
attr(res4[[1]], "quality")

## Optimizing span and peaks values.
## Not run: 
res5 &lt;- meltcurve(dyemelt[, 1:6], window = c(74, 88), 
                  Tm.opt = c(77.2, 80.1, 82.4, 84.8))

## End(Not run)
</code></pre>

<hr>
<h2 id='midpoint'>Calculation of the 'midpoint' region</h2><span id='topic+midpoint'></span>

<h3>Description</h3>

<p>Calculates the exponential region midpoint using the algorithm described in Peirson <em>et al</em>. (2003).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>midpoint(object, noise.cyc = 1:5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="midpoint_+3A_object">object</code></td>
<td>
<p>a fitted object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="midpoint_+3A_noise.cyc">noise.cyc</code></td>
<td>
<p>the cycles defining the background noise.</p>
</td></tr>      
</table>


<h3>Details</h3>

<p>The 'midpoint' region is calculated by </p>
<p style="text-align: center;"><code class="reqn">F_{noise} \cdot \sqrt{\frac{F_{max}}{F_{noise}}}</code>
</p>

<p>with <code class="reqn">F_{noise}</code> = the standard deviation of the background cycles and <code class="reqn">F_{max}</code> = the maximal fluorescence.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>f.mp</code></td>
<td>
<p>the 'midpoint' fluorescence.</p>
</td></tr>
<tr><td><code>cyc.mp</code></td>
<td>
<p>the 'midpoint' cycle, as predicted from <code>f.mp</code>.</p>
</td></tr>    
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Experimental validation of novel and conventional approaches to quantitative real-time PCR data analysis.<br />
Peirson SN, Butler JN &amp; Foster RG.<br />
<em>Nucleic Acids Research</em> (2003), <b>31</b>: e73.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
mp &lt;- midpoint(m1) 
plot(m1)
abline(h = mp$f.mp, col = 2)
abline(v = mp$mp, col = 2)  
</code></pre>

<hr>
<h2 id='modlist'>Create nonlinear models from a dataframe and coerce them into a list</h2><span id='topic+modlist'></span>

<h3>Description</h3>

<p>Essential function to create a list of nonlinear models from the columns (runs) of a qPCR dataframe. This function houses different methods for curve transformation prior to fitting, such as normalization in [0, 1], smoothing, baseline subtraction etc. Runs that failed to fit or that have been identified as kinetic outliers (by default: lack of sigmoidal structure) can be removed automatically as well as their entries in an optionally supplied label vector. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modlist(x, cyc = 1, fluo = NULL, model = l4, check = "uni2", 
        checkPAR = parKOD(), remove = c("none", "fit", "KOD"), 
        exclude = NULL, labels = NULL, norm = FALSE, 
        baseline = c("none", "mean", "median", "lin", "quad", "parm"),
        basecyc = 1:8, basefac = 1, smooth = NULL, smoothPAR = NULL, 
        factor = 1, opt = FALSE, 
        optPAR = list(sig.level = 0.05, crit = "ftest"), verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modlist_+3A_x">x</code></td>
<td>
<p>a dataframe containing the qPCR data or a single qPCR run of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="modlist_+3A_cyc">cyc</code></td>
<td>
<p>the column containing the cycle data. Defaults to first column.</p>
</td></tr>
<tr><td><code id="modlist_+3A_fluo">fluo</code></td>
<td>
<p>the column(s) (runs) to be analyzed. If <code>NULL</code>, all runs will be considered.</p>
</td></tr>
<tr><td><code id="modlist_+3A_model">model</code></td>
<td>
<p>the model to be used for all runs.</p>
</td></tr> 
<tr><td><code id="modlist_+3A_check">check</code></td>
<td>
<p>the method for kinetic outlier detection. Default is check for sigmoidal structure, see <code><a href="#topic+KOD">KOD</a></code>. To turn off, use <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_checkpar">checkPAR</code></td>
<td>
<p>parameters to be supplied to the <code>check</code> method, see <code><a href="#topic+KOD">KOD</a></code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_remove">remove</code></td>
<td>
<p>which runs to remove. Either <code>"none"</code>, those which failed to <code>"fit"</code> or from the <code>"KOD"</code> outlier method.</p>
</td></tr>
<tr><td><code id="modlist_+3A_exclude">exclude</code></td>
<td>
<p>either <code>""</code> for samples with missing column names or a regular expression defining columns (samples) to be excluded from <code>modlist</code>. See 'Details'.</p>
</td></tr> 
<tr><td><code id="modlist_+3A_labels">labels</code></td>
<td>
<p>a vector containing labels, i.e. for defining replicate groups prior to <code><a href="#topic+ratiobatch">ratiobatch</a></code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_norm">norm</code></td>
<td>
<p>logical. Should the raw data be normalized within [0, 1] before model fitting?</p>
</td></tr>
<tr><td><code id="modlist_+3A_baseline">baseline</code></td>
<td>
<p>type of baseline subtraction. See 'Details'.</p>
</td></tr>
<tr><td><code id="modlist_+3A_basecyc">basecyc</code></td>
<td>
<p>cycle range to be used for baseline subtraction, i.e. <code>1:5</code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_basefac">basefac</code></td>
<td>
<p>a factor for the baseline value, such as <code>0.95</code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_smooth">smooth</code></td>
<td>
<p>which curve smoothing method to use. See 'Details'.</p>
</td></tr>
<tr><td><code id="modlist_+3A_smoothpar">smoothPAR</code></td>
<td>
<p>parameters to be supplied to the smoothing functions, supplied as a list. See 'Details'.</p>
</td></tr>
<tr><td><code id="modlist_+3A_factor">factor</code></td>
<td>
<p>a multiplication factor for the fluorescence response values (barely useful, but who knows...).</p>
</td></tr>
<tr><td><code id="modlist_+3A_opt">opt</code></td>
<td>
<p>logical. Should model selection be applied to each model?</p>
</td></tr>
<tr><td><code id="modlist_+3A_optpar">optPAR</code></td>
<td>
<p>parameters to be supplied to <code><a href="#topic+mselect">mselect</a></code>.</p>
</td></tr>
<tr><td><code id="modlist_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, fitting and tagging results will be displayed in the console.</p>
</td></tr>
<tr><td><code id="modlist_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+pcrfit">pcrfit</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From version 1.4-0, the following baselining methods are available for the fluorescence values:<br />
<code>baseline = numeric</code>: a numeric value such as <code>baseline = 0.2</code> for subtracting from each <code class="reqn">F_i</code>.<br />
<code>"mean"</code>: subtracts the mean of all <code>basecyc</code> cycles from each <code class="reqn">F_i</code>.<br />
<code>"median"</code>: subtracts the median of all <code>basecyc</code> cycles from each <code class="reqn">F_i</code>.<br />
<code>"lin"</code>: creates a linear model of all <code>basecyc</code> cycles, predicts <code class="reqn">P_i</code> over all cycles <code class="reqn">i</code> from this model, and subtracts <code class="reqn">F_i - P_i</code>.<br />
<code>"quad"</code>: creates a quadratic model of all <code>basecyc</code> cycles, predicts <code class="reqn">P_i</code> over all cycles <code class="reqn">i</code> from this model, and subtracts <code class="reqn">F_i - P_i</code>.<br />
<code>"parm"</code>: extracts the <code class="reqn">c</code> parameter from the fitted sigmoidal model and subtracts this value from all <code class="reqn">F_i</code>.<br />
It is switched off by default, but in case of data with a high baseline (such as in TaqMan PCR), it should be turned on as otherwise this will give highly underestimated efficiencies and hence wrong <code>init2</code> values.<br />
</p>
<p>From version 1.3-8, the following smoothing methods are available for the fluorescence values:<br />
<code>"lowess"</code>: Lowess smoothing, see <code><a href="stats.html#topic+lowess">lowess</a></code>, parameter in <code>smoothPAR</code>: f.<br />
<code>"supsmu"</code>: Friedman's SuperSmoother, see <code><a href="stats.html#topic+supsmu">supsmu</a></code>, parameter in <code>smoothPAR</code>: span.<br />
<code>"spline"</code>: Smoothing spline, see <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>, parameter in <code>smoothPAR</code>: spar.<br />
<code>"savgol"</code>: Savitzky-Golay smoother, <code>qpcR:::savgol</code>, parameter in <code>smoothPAR</code>: none.<br />
<code>"kalman"</code>: Kalman smoother, see <code><a href="stats.html#topic+arima">arima</a></code>, parameter in <code>smoothPAR</code>: none.<br />
<code>"runmean"</code>: Running mean, see <code>qpcR:::runmean</code>, parameter in <code>smoothPAR</code>: wsize.<br />
<code>"whit"</code>: Whittaker smoother, see <code>qpcR:::whittaker</code>, parameter in <code>smoothPAR</code>: lambda.<br />
<code>"ema"</code>: Exponential moving average, see <code>qpcR:::EMA</code>, parameter in <code>smoothPAR</code>: alpha.<br />
The author of this package advocates the use of <code>"spline"</code>, <code>"savgol"</code> or <code>"whit"</code> because these three smoothers have the least influence on overall curve structure.<br />
</p>
<p>In case of unsuccessful model fitting and if <code>remove = "none"</code> (default), the original data is included in the output, albeit with no fitting information. This is useful since using <code>plot.pcrfit</code> on the 'modlist' shows the non-fitted runs. If <code>remove = "fit"</code>, the non-fitted runs are automatically removed and will thus not be displayed. If <code>remove = "KOD"</code>, by default all runs without sigmoidal structure are removed likewise. If a <code>labels</code> vector <code>lab</code> is supplied, the labels from the failed fits are removed and a new label vector <code>lab_mod</code> is written to the global environment. This way, an initial labeling vector for all samples can be supplied, bad runs and their labels automatically removed and these transfered to downstream analysis (i.e. to <code><a href="#topic+ratiobatch">ratiobatch</a></code>) without giving errors. <code>exclude</code> offers an option to exclude samples from the modlist by some regular expression or by using <code>""</code> for samples with empty column names. See 'Examples'. 
</p>


<h3>Value</h3>

<p>A list with each item containing the model from each column. A <code>names</code> item (which is tagged by *NAME*, if fitting failed) containing the column name is attached to each model as well as an item <code>isFitted</code> with either <code>TRUE</code> (fitting converged) or <code>FALSE</code> (a fitting error occured). This information is useful when <code><a href="#topic+ratiocalc">ratiocalc</a></code> is to be applied and unsuccessful fits should automatically removed from the given <code>group</code> definition. If kinetic outlier detection is selected, an item <code>isOutlier</code> is attached, defining the run as an outlier (<code>TRUE</code>) or not (<code>FALSE</code>). 
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcrbatch">pcrbatch</a></code> for batch analysis using different methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Calculate efficiencies and ct values 
## for each run in the 'reps' data, 
## subtract baseline using mean of 
## first 8 cycles.
ml1 &lt;- modlist(reps, model = l5, baseline = "mean")
getPar(ml1, type = "curve")

## 'Crossing points' for the first 3 runs (normalized)
##  and using best model from Akaike weights.
ml2 &lt;- modlist(reps, 1, 2:5, model = l5, norm = TRUE, 
               opt = TRUE, optPAR = list(crit = "weights"))
sapply(ml2, function(x) efficiency(x, plot = FALSE)$cpD2)

## Convert a single run to a 'modlist'.
m &lt;- pcrfit(reps, 1, 2, l5)
ml3 &lt;- modlist(m)

## Using the 'testdat' set
## include failed fits.
ml4 &lt;- modlist(testdat, 1, 2:9,  model = l5)
plot(ml4, which = "single")

## Remove failed fits and update a label vector.
GROUP &lt;- c("g1s1", "g1s2", "g1s3", "g1s4", "g1c1", "g1c2", "g1c3", "g1c4") 
ml5 &lt;- modlist(testdat, 1, 2:9,  model = l5, labels = GROUP, remove = "KOD")
plot(ml5, which = "single")

## Smoothing by EMA and alpha = 0.8.
ml6 &lt;- modlist(reps, model = l5, smooth = "ema",
               smoothPAR = list(alpha = 0.5))
plot(ml6)

## Not run: 
## Use one of the mechanistic models
## get D0 values.
ml7 &lt;- modlist(reps, model = mak3)
sapply(ml7, function(x) coef(x)[1])

## Exclude first sample in each 
## replicate group of dataset 'reps'.
ml8 &lt;- modlist(reps, exclude = ".1")
plot(ml8, which = "single")

## Using weighted fitting:
## weighted by inverse residuals.
ml9 &lt;- modlist(reps, weights = "1/abs(resid)")
plot(ml9, which = "single")

## Use linear model of the first 10
## cycles for baselining.
ml10 &lt;- modlist(reps, basecyc = 1:10, baseline = "lin")
plot(ml10)

## Use a single value for baselining.
ml11 &lt;- modlist(reps, basecyc = 1:10, baseline = 0.5)
plot(ml11)

## End(Not run)
</code></pre>

<hr>
<h2 id='mselect'>Sigmoidal model selection by different criteria</h2><span id='topic+mselect'></span>

<h3>Description</h3>

<p>Model selection by comparison of different models using<br />
</p>
<p>1) the maximum log likelihood value,<br />
2) Akaike's Information Criterion (AIC),<br />
3) bias-corrected Akaike's Information Criterion (AICc),<br />
4) the estimated residual variance,<br />
5) the p-value from a nested F-test on the residual variance,<br />
6) the p-value from the likelihood ratio,<br />
7) the Akaike weights based on AIC,<br />
8) the Akaike weights based on AICc, and<br />
9) the reduced chi-square, <code class="reqn">\chi_\nu^2</code>, if replicates exist.
</p>
<p>The best model is chosen by 5), 6), 8) or 9) and returned as a new model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mselect(object, fctList = NULL, sig.level = 0.05, verbose = TRUE, 
        crit = c("ftest", "ratio", "weights", "chisq"), do.all = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mselect_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit' or 'replist'.</p>
</td></tr>
<tr><td><code id="mselect_+3A_fctlist">fctList</code></td>
<td>
<p>a list of functions to be analyzed, i.e. for a non-nested regime. Should also contain the original model.</p>
</td></tr>
<tr><td><code id="mselect_+3A_sig.level">sig.level</code></td>
<td>
<p>the significance level for the nested F-test.</p>
</td></tr>
<tr><td><code id="mselect_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the result matrix is displayed in the console.</p>
</td></tr>
<tr><td><code id="mselect_+3A_crit">crit</code></td>
<td>
<p>the criterium for model selection. Either <code>"ftest"/"ratio"</code> for nested models or <code>"weights"/"fitprob"</code> for nested and non-nested models.</p>
</td></tr>
<tr><td><code id="mselect_+3A_do.all">do.all</code></td>
<td>
<p>if <code>TRUE</code>, all available sigmoidal models are tested and the best one is selected based on AICc weights.</p>
</td></tr>
<tr><td><code id="mselect_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+fitchisq">fitchisq</a></code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Criteria 5) and 6) cannot be used for comparison unless the models are nested. Criterion 8), Akaike weights, can be used for nested and non-nested regimes, which also accounts for the reduced <code class="reqn">\chi_\nu^2</code>. For criterion 1) the larger the better. For criteria 2), 3) and 4): the smaller the better. The best model is chosen either from the nested F-test (<code><a href="stats.html#topic+anova">anova</a></code>), likelihood ratio (<code><a href="#topic+llratio">llratio</a></code>), corrected Akaike weights (<code><a href="#topic+akaike.weights">akaike.weights</a></code>) or reduced <code class="reqn">\chi_\nu^2</code> (<code><a href="#topic+fitchisq">fitchisq</a></code>) and returned as a new model. When using <code>"ftest"/"ratio"</code> the corresponding nested functions are analyzed automatically, i.e. b3/b4/b5/b6/b7; l3/l4/l5/l6/l7. If supplying nested models, please do this with ascending number of parameters.  
</p>


<h3>Value</h3>

<p>A model of the best fit selected by one of the criteria above. The new model has an additional list item 'retMat' with a result matrix of the criterion tests.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p><code><a href="#topic+llratio">llratio</a></code>, <code><a href="#topic+akaike.weights">akaike.weights</a></code> and <code><a href="#topic+fitchisq">fitchisq</a></code>.   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Choose best model based on F-tests 
## on the corresponding nested models.
m1 &lt;- pcrfit(reps, 1, 2, l4)
m2 &lt;- mselect(m1)
summary(m2)  ## Converted to l7 model!

## Use Akaike weights on non-nested models
## compare to original model.
m2 &lt;- mselect(m1, fctList = list(l4, b5, cm3), crit = "weights")
summary(m2) ## Converted to b5 model!

## Try all sigmoidal models.
m3 &lt;- pcrfit(reps, 1, 20, l4)
mselect(m3, do.all = TRUE) ## l7 wins by far!

## On replicated data using reduced chi-square.
ml1 &lt;- modlist(reps, fluo = 2:5, model = l4)
rl1 &lt;- replist(ml1, group = c(1, 1, 1, 1))
mselect(rl1, crit = "chisq")  ## converted to l6!
</code></pre>

<hr>
<h2 id='parKOD'>Parameters that can be changed to tweak the kinetic outlier methods</h2><span id='topic+parKOD'></span>

<h3>Description</h3>

<p>A control function with different list items that change the performance of the different (kinetic) outlier functions as defined in <code><a href="#topic+KOD">KOD</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parKOD(eff = c("sliwin", "sigfit", "expfit"), train = TRUE, 
       alpha = 0.05, cp.crit = 10, cut = c(-6, 2))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parKOD_+3A_eff">eff</code></td>
<td>
<p><b>uni1</b>. The efficiency method to be used. Either <code>sliwin</code>, <code>sigfit</code> or <code>expfit</code>.</p>
</td></tr>
<tr><td><code id="parKOD_+3A_train">train</code></td>
<td>
<p><b>uni1</b>. If <code>TRUE</code>, the sample's efficiency is NOT included in the calculation of the average efficiency (default), if <code>FALSE</code> it is.</p>
</td></tr>
<tr><td><code id="parKOD_+3A_cp.crit">cp.crit</code></td>
<td>
<p><b>uni2</b>. The cycle difference between first and second derivative maxima, default is 10.</p>
</td></tr> 
<tr><td><code id="parKOD_+3A_cut">cut</code></td>
<td>
<p><b>multi1</b>. A 2-element vector defining the lower and upper border from the first derivative maximum from where to cut the complete curve.</p>
</td></tr>
<tr><td><code id="parKOD_+3A_alpha">alpha</code></td>
<td>
<p>the p-value cutoff value for all implemented statistical tests.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details on the function of the parameters within the different kinetic and sigmoidal outlier methods, see <code><a href="#topic+KOD">KOD</a></code>.
</p>


<h3>Value</h3>

<p>If called, returns a list with the parameters as items.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Multivariate outliers,
## adjusting the 'cut' parameter.
ml1 &lt;- modlist(reps, 1, 2:5, model = l5)
res1 &lt;- KOD(ml1, method = "multi1", par = parKOD(cut = c(-5, 2)))
</code></pre>

<hr>
<h2 id='pcrbatch'>Batch calculation of qPCR efficiency and other qPCR parameters</h2><span id='topic+pcrbatch'></span>

<h3>Description</h3>

<p>This function batch calculates the results obtained from <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+sliwin">sliwin</a></code>, <code><a href="#topic+expfit">expfit</a></code>, <code><a href="#topic+LRE">LRE</a></code> or the coefficients from any of the <code>makX/cm3</code> models on a dataframe containing many qPCR runs. The input can also be a list obtained from <code><a href="#topic+modlist">modlist</a></code>, which simplifies things in many cases. The output is a dataframe with the estimated parameters and model descriptions. Very easy to use on datasheets containing many qPCR runs, i.e. as can be imported from Excel. The result is automatically copied to the clipboard.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrbatch(x, cyc = 1, fluo = NULL, 
         methods = c("sigfit", "sliwin", "expfit", "LRE"),
         model = l4, check = "uni2", checkPAR = parKOD(), 
         remove = c("none", "fit", "KOD"), exclude = NULL, 
         type = "cpD2", labels = NULL, norm = FALSE, 
         baseline = c("none", "mean", "median", "lin", "quad", "parm"),
         basecyc = 1:8, basefac = 1, smooth = NULL, smoothPAR = NULL, 
         factor = 1, opt = FALSE, optPAR = list(sig.level = 0.05, crit = "ftest"), 
         group = NULL, names = c("group", "first"), plot = TRUE, 
         verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrbatch_+3A_x">x</code></td>
<td>
<p>a dataframe containing the qPCR raw data from the different runs or a list obtained from <code><a href="#topic+modlist">modlist</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_cyc">cyc</code></td>
<td>
<p>the column containing the cycle data. Defaults to first column.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_fluo">fluo</code></td>
<td>
<p>the column(s) (runs) to be analyzed. If <code>NULL</code>, all runs will be considered.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_methods">methods</code></td>
<td>
<p>a character vector defining the methods to use. See 'Details'.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_model">model</code></td>
<td>
<p>the model to be used for all runs.</p>
</td></tr> 
<tr><td><code id="pcrbatch_+3A_check">check</code></td>
<td>
<p>the method for outlier detection in <code><a href="#topic+KOD">KOD</a></code>. Default is check for sigmoidal structure.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_checkpar">checkPAR</code></td>
<td>
<p>parameters to be supplied to the <code>check</code> method.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_remove">remove</code></td>
<td>
<p>which runs to remove. Either <code>none</code>, those which failed to <code>fit</code> or from the outlier methods.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_exclude">exclude</code></td>
<td>
<p>either <code>""</code> for samples with missing column names or a regular expression defining columns (samples) to be excluded from <code>pcrbatch</code>. See 'Details' and 'Examples' in <code><a href="#topic+modlist">modlist</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_type">type</code></td>
<td>
<p>the point on the amplification curve from which the efficiency is estimated. See <code><a href="#topic+efficiency">efficiency</a></code>.</p>
</td></tr>  
<tr><td><code id="pcrbatch_+3A_labels">labels</code></td>
<td>
<p>a vector containing labels, i.e. for defining replicate groups prior to <code><a href="#topic+ratiobatch">ratiobatch</a></code>.</p>
</td></tr>  
<tr><td><code id="pcrbatch_+3A_norm">norm</code></td>
<td>
<p>logical. Should the raw data be normalized within [0, 1] before model fitting?</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_baseline">baseline</code></td>
<td>
<p>type of baseline subtraction. See 'Details' in <code><a href="#topic+modlist">modlist</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_basecyc">basecyc</code></td>
<td>
<p>cycle range to be used for baseline subtraction, i.e. <code>1:5</code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_basefac">basefac</code></td>
<td>
<p>a factor when using averaged baseline cycles, such as <code>0.95</code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_smooth">smooth</code></td>
<td>
<p>which curve smoothing method to use. See <code><a href="#topic+modlist">modlist</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_smoothpar">smoothPAR</code></td>
<td>
<p>parameters to be supplied to the smoothing functions, supplied as a list. See <code><a href="#topic+modlist">modlist</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_factor">factor</code></td>
<td>
<p>a multiplication factor for the fluorescence response values (barely useful, but who knows...).</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_opt">opt</code></td>
<td>
<p>logical. Should model selection be applied to each model?</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_optpar">optPAR</code></td>
<td>
<p>parameters to be supplied to <code><a href="#topic+mselect">mselect</a></code>.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_group">group</code></td>
<td>
<p>a vector containing the grouping for possible replicates.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_names">names</code></td>
<td>
<p>how to name the grouped fit. Either 'group_1, ...' or the first name of the replicates.</p>
</td></tr>   
<tr><td><code id="pcrbatch_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, the single runs are plotted from the internal 'modlist' for diagnostics.</p>
</td></tr>
<tr><td><code id="pcrbatch_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, fitting and tagging results will be displayed in the console.</p>
</td></tr>  
<tr><td><code id="pcrbatch_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to downstream methods.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The <code>methods</code> vector is used for defining the different methods from which <code>pcrbatch</code> will concatenate the results. The mechanistic models (<code>mak2, mak2i, mak3, mak3i, cm3</code>) are omitted by default, because fitting is time-expensive. If they should be included, just add <code>"mak3"</code> to <code>methods</code>. See 'Examples'. The qPCR raw data should be arranged with the cycle numbers in the first column with the name &quot;Cycles&quot;. All subsequent columns must be plain raw data with sensible column descriptions. If replicates are defined by <code>group</code>, the output will contain a numbering of groups (i.e. &quot;group_1&quot; for the first replicate group). The model selection process is optional, but we advocate using this for obtaining better parameter estimates. Normalization has been described to improve certain qPCR analyses, but this has still to be independently evaluated. Background subtraction is done as in <code><a href="#topic+modlist">modlist</a></code> and <code><a href="#topic+efficiency">efficiency</a></code>. In case of unsuccessful model fitting or lack of sigmoidal structure, the names are tagged by *NAME* or **NAME**, respectively (if <code>remove = "none"</code>). However, if <code>remove = "fit"</code> or <code>remove = "KOD"</code>, the  failed runs are excluded from the output. Similar to <code><a href="#topic+modlist">modlist</a></code>, if a <code>labels</code> vector <code>lab</code> is supplied, the labels from the failed fits are removed and a new label vector <code>lab_mod</code> is written to the global environment. 
</p>


<h3>Value</h3>

<p>A dataframe with the results in columns containing the calculated values, fit parameters and (tagged) model name together with the different methods used as the name prefix. A plot shows a plot matrix of all amplification curves/sigmoidal fits and failed amplifications marked with asterisks.
</p>


<h3>Note</h3>

<p>IMPORTANT: When subsequent use of <code><a href="#topic+ratiocalc">ratiocalc</a></code> is desired, use <code>pcrbatch</code> on the single run level with <code>group = NULL</code> and <code>remove = "none"</code>, so that <code><a href="#topic+ratiocalc">ratiocalc</a></code> can automatically delete the failed runs from its <code>group</code> definition. Otherwise error propagation will fail.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+modlist">modlist</a></code> for creating a list of models, which is used internally by <code>pcrbatch</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First 4 runs and return parameters of fit
## do background subtraction using mean the first 5 cycles.
pcrbatch(reps, fluo = 2:5, baseline = "mean", basecyc = 1:5)

## Not run: 
##  First 8 runs, with 4 replicates each, l5 model.
pcrbatch(reps, fluo = 2:9, model = l5, group = c(1,1,1,1,2,2,2,2))

## Using model selection (Akaike weights) 
## on the first 4 runs, runs 1 and 2 are replicates.
pcrbatch(reps, fluo = 2:5, group = c(1,1,2,3), 
         opt = TRUE, optPAR = list(crit = "weights"))

## Fitting a sigmoidal and 'mak3' mechanistic model.
pcrbatch(reps, methods = c("sigfit", "mak3"))

## Converting a 'modlist' to 'pcrbatch'.
ml5 &lt;- modlist(reps, 1, 2:5, b5)
res5 &lt;- pcrbatch(ml5)

## Using Whittaker smoothing.
pcrbatch(reps, smooth = "whit")

## End(Not run)    
</code></pre>

<hr>
<h2 id='pcrboot'>Bootstrapping and jackknifing qPCR data</h2><span id='topic+pcrboot'></span>

<h3>Description</h3>

<p>Confidence intervals for the estimated parameters and goodness-of-fit measures are calculated for a nonlinear qPCR data fit by either<br />
a) boostrapping the residuals of the fit or<br />
b) jackknifing and refitting the data.
</p>
<p>Confidence intervals can also be calculated for all parameters obtained from the <code><a href="#topic+efficiency">efficiency</a></code> analysis.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrboot(object, type = c("boot", "jack"), B = 100, njack = 1,
        plot = TRUE, do.eff = TRUE, conf = 0.95, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrboot_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_type">type</code></td>
<td>
<p>either <code>boot</code>strapping or <code>jack</code>knifing.</p>
</td></tr> 
<tr><td><code id="pcrboot_+3A_b">B</code></td>
<td>
<p>numeric. The number of iterations.</p>
</td></tr> 
<tr><td><code id="pcrboot_+3A_njack">njack</code></td>
<td>
<p>numeric. In case of <code>type = "jack"</code>, how many datapoints to exclude. Defaults to leave-one-out.</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_plot">plot</code></td>
<td>
<p>should the fitting and final results be displayed as a plot?</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_do.eff">do.eff</code></td>
<td>
<p>logical. If <code>TRUE</code>, <code><a href="#topic+efficiency">efficiency</a></code> analysis will be performed.</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_conf">conf</code></td>
<td>
<p>the confidence level.</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the iterations will be printed on the console.</p>
</td></tr>
<tr><td><code id="pcrboot_+3A_...">...</code></td>
<td>
<p>other parameters to be passed on to the plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Non-parametric bootstrapping is applied using the centered residuals.<br />
1) Obtain the residuals from the fit: </p>
<p style="text-align: center;"><code class="reqn">\hat{\varepsilon}_t = y_t - f(x_t, \hat{\theta})</code>
</p>

<p>2) Draw bootstrap pseudodata: </p>
<p style="text-align: center;"><code class="reqn">y_{t}^{\ast} = f(x_t, \hat{\theta}) + \epsilon_{t}^{\ast}</code>
</p>

<p>where <code class="reqn">\epsilon_{t}^{\ast}</code> are i.i.d. from distribution <code class="reqn">\hat{F}</code>, where the residuals from the original fit are centered at zero.<br />
3) Fit <code class="reqn">\hat\theta^\ast</code> by nonlinear least-squares.<br />
4) Repeat <em>B</em> times, yielding bootstrap replications </p>
<p style="text-align: center;"><code class="reqn">\hat\theta^{\ast 1}, \hat\theta^{\ast 2}, \ldots, \hat\theta^{\ast B}</code>
</p>

<p>One can then characterize the EDF and calculate confidence intervals for each parameter: </p>
<p style="text-align: center;"><code class="reqn">\theta \in [EDF^{-1}(\alpha/2), EDF^{-1}(1-\alpha/2)]</code>
</p>
      
<p>The jackknife alternative is to perform the bootstrap on the data-predictor vector, i.e. eliminating a certain number of datapoints.<br /> 
If the residuals are correlated or have non-constant variance the latter is recommended. This may be the case in qPCR data,
as the variance in the low fluorescence region (ground phase) is usually much higher than in the rest of the curve. 
</p>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table role = "presentation">
<tr><td><code>ITER</code></td>
<td>
<p>a list containing each of the results from the iterations.</p>
</td></tr>   
<tr><td><code>CONF</code></td>
<td>
<p>a list containing the confidence intervals for each item in <code>ITER</code>.</p>
</td></tr>
</table>
<p>Each item contains subitems for the coefficients (<code>coef</code>), root-mean-squared error (<code>rmse</code>), residual sum-of-squares (<code>rss</code>), goodness-of-fit measures (<code>gof</code>) and the efficiency analysis (<code>eff</code>). If <code>plot = TRUE</code>, all data is plotted as boxplots including confidence intervals.     
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Nonlinear regression analysis and its applications.<br />
Bates DM &amp; Watts DG.<br />
Wiley, Chichester, UK, 1988.<br />
</p>
<p>Nonlinear regression.<br />
Seber GAF &amp; Wild CJ.<br />
Wiley, New York, 1989.<br />
</p>
<p>Boostrap accuracy for non-linear regression models.<br />
Roy T.<br />
<em>J Chemometics</em> (1994), <b>8</b>: 37-44.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simple bootstrapping with
## too less iterations...
par(ask = FALSE)
m1 &lt;- pcrfit(reps, 1, 2, l4)
pcrboot(m1, B = 20)

## Jackknifing with leaving
## 5 datapoints out.
m2 &lt;- pcrfit(reps, 1, 2, l4)
pcrboot(m2, type = "jack", njack = 5, B = 20)
</code></pre>

<hr>
<h2 id='pcrfit'>Workhorse function for qPCR model fitting</h2><span id='topic+pcrfit'></span>

<h3>Description</h3>

<p>This is the workhorse function of the qpcR package that fits one of the available models to qPCR data using (weighted) nonlinear least-squares (Levenberg-Marquardt) fitting from <code><a href="minpack.lm.html#topic+nlsLM">nlsLM</a></code> of the 'minpack.lm' package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrfit(data, cyc = 1, fluo, model = l4, start = NULL, 
       offset = 0, weights = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrfit_+3A_data">data</code></td>
<td>
<p>the name of the dataframe containing the qPCR runs.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_cyc">cyc</code></td>
<td>
<p>the column containing the cycle data. Defaults to 1.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_fluo">fluo</code></td>
<td>
<p>the column(s) containing the raw fluorescence data of the run(s). If more than one column is given, the model will be built with the replicates. See 'Details' and 'Examples'.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_model">model</code></td>
<td>
<p>the model to be used for the analysis. Defaults to 'l4'.</p>
</td></tr> 
<tr><td><code id="pcrfit_+3A_start">start</code></td>
<td>
<p>a vector of starting values that can be supplied externally.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_offset">offset</code></td>
<td>
<p>an offset cycle number from the second derivative cut-off cycle for all <code>MAK</code> methods. See 'Details' and 'Example'.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_weights">weights</code></td>
<td>
<p>a vector with same length as <code>data</code> containing possible weights for the nonlinear fit, or an expression to calculate weights from. See 'Details'.</p>
</td></tr> 
<tr><td><code id="pcrfit_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, fitting and convergence results will be displayed in the console.</p>
</td></tr>
<tr><td><code id="pcrfit_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="minpack.lm.html#topic+nlsLM">nlsLM</a></code>.</p>
</td></tr>     
</table>


<h3>Details</h3>

<p>This is a newer (from qpcR 1.3-7 upwards) version of <code>pcrfit</code>. It is a much simpler implementation containing only the LM-Algorithm for fitting, but this fitting routine has proven to be so robust that other optimization routines (such as in <code><a href="stats.html#topic+optim">optim</a></code>) could safely be removed. The fitting is done with the new <code><a href="minpack.lm.html#topic+nlsLM">nlsLM</a></code> function of the 'minpack.lm' package, which gives a model of class 'nls' as output.  
</p>
<p>This function is to be used at the single run level or on replicates (by giving several columns). The latter will build a single model based on the replicate values. If many models should be built on a cohort of replicates, use <code><a href="#topic+modlist">modlist</a></code> and <code><a href="#topic+replist">replist</a></code>.
</p>
<p>The <code>offset</code> value defines the offset cycles from the second derivative maximum that is used as a cut-off criterion in the <code>MAK</code> methods. See 'Examples'.
</p>
<p>Since version 1.3-7, an expression given as a character string can be supplied to the <code>weights</code> argument.
This expression, which is transferred to <code>qpcR:::wfct</code>, defines how the vector of weights is calculated from the data. In principle, five different parameters can be used to define weights:<br />
<code>"x"</code> relates to the cycles <code class="reqn">x_i</code>,<br />
<code>"y"</code> relates to the raw fluorescence values <code class="reqn">y_i</code>,<br />
<code>"error"</code> relates to the error <code class="reqn">\sigma(y_{i, j})</code> of replicates <code class="reqn">j</code>,<br />
<code>"fitted"</code> relates to the fitted values <code class="reqn">\hat{y}_i</code> of the fit,<br />
<code>"resid"</code> relates to the residuals <code class="reqn">y_i - \hat{y}_i</code> of the fit.<br />
For <code>"fitted"</code> and <code>"resid"</code>, the model is fit unweighted by <code><a href="#topic+pcrfit">pcrfit</a></code>, the fitted/residual values extracted and these subsequently used for refitting the model with weights.
These parameters can be used solely or combined to create a weights vector for different regimes. The most commonly used are (see also 'Examples'):<br />
Inverse of response (raw fluorescence) <code class="reqn">\frac{1}{y_i}</code>: <code>"1/y"</code><br />
Square root of predictor (Cycles) <code class="reqn">\sqrt{x_i}</code>: <code>"sqrt(x)"</code><br />
Inverse square of fitted values: <code class="reqn">\frac{1}{\hat{y}^2_i}</code>: <code>"1/fitted^2"</code><br />
Inverse variance <code class="reqn">\frac{1}{\sigma^2(y_{i, j})}</code>: <code>"1/error^2"</code>
</p>


<h3>Value</h3>

<p>A model of class 'nls' and 'pcrfit' with the following items attached:<br />
</p>
<table role = "presentation">
<tr><td><code>DATA</code></td>
<td>
<p>the initial data used for fitting.</p>
</td></tr>
<tr><td><code>MODEL</code></td>
<td>
<p>the model used for fitting.</p>
</td></tr> 
<tr><td><code>call2</code></td>
<td>
<p>the call to <code>pcrfit</code>.</p>
</td></tr> 
<tr><td><code>parMat</code></td>
<td>
<p>the trace of the parameter values. Can be used to track problems.</p>
</td></tr>
<tr><td><code>opt.method</code></td>
<td>
<p>defaults to <code>"LM"</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Bioassay analysis using R.<br />
Ritz C &amp; Streibig JC.<br />
<em>J Stat Soft</em> (2005), <b>12</b>: 1-22.<br />
</p>
<p>A Method for the Solution of Certain Problems in Least Squares.<br />
K. Levenberg.<br />
<em>Quart Appl Math</em> (1944), <b>2</b>: 164-168.<br />
</p>
<p>An Algorithm for Least-Squares Estimation of Nonlinear Parameters.<br />
D. Marquardt.<br />
<em>SIAM J Appl Math</em> (1963), <b>11</b>: 431-441.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simple l4 fit of F1.1 of the 'reps' dataset.
m1 &lt;- pcrfit(reps, 1, 2, l4) 
plot(m1)

## Supply own starting values.
pcrfit(reps, 1, 2, l4, start = c(-5, -0.05, 11, 16)) 

## Make a replicate model,
## use inverse variance as weights.
m2 &lt;- pcrfit(reps, 1, 2:5, l5, weights = "1/error^2")
plot(m2)

## Fit a mechanistic 'mak2' model
## to -1 cycle from SDM.
m3 &lt;- pcrfit(reps, 1, 2, mak2, offset = -1)
plot(m3)
</code></pre>

<hr>
<h2 id='pcrGOF'>Summarize measures for the goodness-of-fit</h2><span id='topic+pcrGOF'></span>

<h3>Description</h3>

<p>Calculates all implemented measures for the goodness-of-fit and returns them as a list.
Works for objects of class <code>pcrfit</code>, <code>lm</code>, <code>glm</code>, <code>nls</code>, <code>drc</code> and many others...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrGOF(object, PRESS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrGOF_+3A_object">object</code></td>
<td>
<p>a fitted object.</p>
</td></tr>
<tr><td><code id="pcrGOF_+3A_press">PRESS</code></td>
<td>
<p>logical. If <code>TRUE</code>, the more calculation intensive <code class="reqn">P^2</code> is also returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with all implemented Information criteria (<code>AIC, AICc, BIC</code>), residual variance, root-mean-squared-error, the reduced <code class="reqn">\chi_{\nu}^2</code> from <code><a href="#topic+fitchisq">fitchisq</a></code> (if replicates) and the <code><a href="#topic+PRESS">PRESS</a></code> <code class="reqn">P^2</code> value (if <code>PRESS = TRUE</code>).  
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Single fit without replicates
## including PRESS statistic.
m1 &lt;- pcrfit(reps, 1, 2, l5)
pcrGOF(m1, PRESS = TRUE)

## Fit containing replicates:
## calculation of reduced 
## chi-square included!
m2 &lt;- pcrfit(reps, 1, 2:5, l5)
pcrGOF(m2)
</code></pre>

<hr>
<h2 id='pcrimport'>Advanced qPCR data import function</h2><span id='topic+pcrimport'></span>

<h3>Description</h3>

<p>Advanced function to easily import/preformat qPCR data from delimited text files, the clipboard or the workspace. The data files can be located in a directory which is automatically browsed for all files. In a series of steps, the data can be imported and transformed to the appropriate format of the 'qpcR' package (such as in dataset <code>reps</code>, with 'Cycles' in the first column and named runs with raw fluorescence data in remaining columns). A dataset can function as a transformation template, and the remaining files in the directory are then formatted according to the established parameters. See 'Details' and tutorial video in <a href="http://www.dr-spiess.de/qpcR/tutorials.html">http://www.dr-spiess.de/qpcR/tutorials.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrimport(file = NA, sep = NA, dec = NA, delCol = NA, delRow = NA,
          format = c(NA, "col", "row"), sampleDat = NA, refDat = NA,
          names = NA, sampleLen = NA, refLen = NA, check = TRUE,
          usePars = TRUE, dirPars = NULL, needFirst = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrimport_+3A_file">file</code></td>
<td>
<p>either a directory such as <code>"c:/temp"</code> containing the data file(s), the Windows <code>"clipboard"</code> or an object in the workspace such as <code>"reps"</code>.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_sep">sep</code></td>
<td>
<p>the field separator character, i.e. <code>"\t"</code> for tabs.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_dec">dec</code></td>
<td>
<p>the decimal seperator, i.e. <code>"."</code>.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_delcol">delCol</code></td>
<td>
<p>unneeded columns to delete after successful import, i.e. <code>2, 1:3, seq(1, 5, by = 2), etc...</code>.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_delrow">delRow</code></td>
<td>
<p>unneeded rows to delete after successful import, i.e. <code>2, 1:3, seq(1, 5, by = 2), etc...</code>.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_format">format</code></td>
<td>
<p>how the data is organized, i.e. in <code>col</code>umns or <code>row</code>s.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_sampledat">sampleDat</code></td>
<td>
<p>the columns with the raw fluorescence reporter dye data.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_refdat">refDat</code></td>
<td>
<p>optional columns with the raw fluorescence reference dye data.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_names">names</code></td>
<td>
<p>the row(s) that should be used for naming the runs.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_samplelen">sampleLen</code></td>
<td>
<p>the rows with the reporter dye cycles.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_reflen">refLen</code></td>
<td>
<p>the rows with the reference dye cycles.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_check">check</code></td>
<td>
<p>logical. If <code>TRUE</code>, a window displaying the transformed data after each step is displayed. This assists in choosing the right parameters.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_usepars">usePars</code></td>
<td>
<p>logical. If <code>TRUE</code>, then all files in the directory are batch analysed using the stored parameters. See 'Details'.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_dirpars">dirPars</code></td>
<td>
<p>an optional directory such as <code>"c:/pars"</code> where the formatting parameters can be stored. If <code>NULL</code>, the 'qpcR' directory is used.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_needfirst">needFirst</code></td>
<td>
<p>logical. If <code>TRUE</code>, then the (alphabetically) first file in the directory is used for an initial definition of transformation parameters.</p>
</td></tr>
<tr><td><code id="pcrimport_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="utils.html#topic+read.delim">read.delim</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has been designed to offer maximal flexibility in importing qPCR data from all kinds of systems. This is accomplished by asking the user for many formatting options in single steps, with the final goal of obtaining a dataset that is transformed in a way suitable for <code><a href="#topic+pcrfit">pcrfit</a></code>, as in all datasets in this package (i.e. 'reps'): it must be a dataframe with the first column containing the cycle numbers (&quot;Cycles&quot;) and all subsequent columns with sensible sample names, such as &quot;S1_1&quot;. In detail, the following steps are queried:<br />
</p>
<p>1) Location of the file. Either a directory containing the file(s), the (Windows) clipboard or a dataframe in the workspace.<br />
2) How are the fields separated, i.e. by tabs?<br />
3) What is the decimal separator?<br />
4) Which columns can be deleted? For analysis, we only need the raw fluorescence values and sample names. Everything else should be deleted.<br />
5) Which rows can be deleted? Same as above.<br />
6) Are the runs organized in rows or in columns?<br />
After these steps, the unwanted rows/columns are deleted and the data transformed into vertical format (if it was in rows).<br />
7) In which columns are the runs with reporter dye data (i.e. SybrGreen)?<br />
8) If a reference dye (i.e. ROX) was used, in which columns are the runs?<br />
9) How should the runs be named (automatically or from a row/rows containing names)? If more than one row is supplied, the names in the rows are pasted together, i.e. &quot;A4.GAPDH&quot;.<br />
10) Which are the rows containing the raw fluorescence data from cycle to cycle for the reporter dye?<br />
11) If a reference dye was used, which are the rows with the cycle to cycle data?<br />
After these steps, a 'Cycles' column is prepended to the data which should then be in the right format for downstream analysis.<br />
<b>ATTENTION:</b> Because of this step, if the imported data also initially had a column containing cycle numbers, these should be removed in steps 2) or 3)!<br />
</p>
<p>One major advantage of this function is that the formatting parameters are stored in a file and can be reused with new data, most conveniently when doing a batch analysis of several files in a directory. When <code>needFirst = TRUE</code>, the alphabetically first run in the directory is used for defining the formatting parameters, and if <code>usePars = TRUE</code> these are applied on all remaining datasets. If the initial definition of formatting parameters is not needed, then setting <code>needFirst = FALSE</code> will apply the last stored parameters on all datasets. By using different <code>dirPars</code>, one can establish different formatting options for different qPCR systems.<br />
</p>
<p>The function will query (if <code>needFirst = TRUE</code>) all parameters that are defined as <code>NA</code>. For example, using
<code>pcrimport(file = "c:/temp", sep = "\t", dec = ".", delCol = c(1, 3), ...)</code> will result in these parameters not being queried.<br />
</p>
<p>If reference dye data was supplied, the function checks if the data is of same dimensions than the reporter dye data. The output is then the normalized fuorescence data <code class="reqn">\frac{F_{rep}}{F_{ref}}</code>.<br />
</p>
<p>The 'Examples' feature internal datasets, but this function is best understood by the tutorial under <a href="http://www.dr-spiess.de/qpcR/tutorials.html">http://www.dr-spiess.de/qpcR/tutorials.html</a>.
</p>


<h3>Value</h3>

<p>A list with the transformed data as <code>data.frame</code> list items, suitable for downstream analysis.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## EXAMPLE 1:
## Internal dataset format01.txt (in 'add01' directory)
## with 384 runs.
## Tab delimited, 30 cycles, only reporter dye,
## data in rows, and some unneeded columns and rows.
## This is the example data path, but could be any path
## with data such as c:/temp.
PATH &lt;- path.package("qpcR")
PATHall &lt;- paste(PATH, "/add01/", sep = "")
res &lt;- pcrimport(PATHall)

## Answer queries with the following parameters and
## verify the effects in the 'View' windows:
## 1 =&gt; data is tab delimited
## 1 =&gt; decimal separator is "."
## c(1, 3) =&gt; remove columns 1 + 3
## 1:2 =&gt; remove rows 1 + 2
## 2 =&gt; data is in rows
## 0 =&gt; all data is from reporter dye
## 1 =&gt; sample names are in row #1
## 0 =&gt; reporter data goes until end of table
## Data is stored as dataframe list items and can
## then be analyzed:
ml &lt;- modlist(res[[1]], model = l5)
plot(ml, which = "single")

## Alternative without query:
res &lt;- pcrimport(PATHall, sep = "\t", dec = ".",
                 delCol = c(1, 3), delRow = 1:2,
                 format = "row", sampleDat = 0,
                 names = 1, sampleLen = 0,
                 check = FALSE)

## Do something useful with the data:
ml &lt;- modlist(res[[1]], model = l5)
plot(ml, which = "single")
                 
## EXAMPLE 2:
## Internal datasets format02a.txt - format02d.txt
## (in 'add02' directory) with 96 runs.
## Tab delimited, 40 cycles, reporter dye + reference dye,
## data in columns, and some unneeded columns and rows.
PATH &lt;- path.package("qpcR")
PATHall &lt;- paste(PATH, "/add02/", sep = "")
res &lt;- pcrimport(PATHall)

## Answer queries with the following parameters and
## verify the effects in the 'View' windows:
## 1 =&gt; data is tab delimited
## 1 =&gt; decimal separator is "."
## 1 =&gt; remove column 1 with cycle data
## c(1, 43, 44) =&gt; remove rows 1, 43, 44
## 1 =&gt; data is in columns
## 1:96 =&gt; data columns for reporter dye
## -2 =&gt; reference dye stacked under reporter dye
## 1 =&gt; sample names are in row #1
## 1:40 =&gt; reporter data is in rows 1-40
## -1 =&gt; reference data is stacked under samples
## Data is stored as dataframe list items and can
## then be analyzed.

## Alternative without query:
res2 &lt;- pcrimport(PATHall, sep = "\t", dec = ".",
                 delCol = 1, delRow = c(1, 43, 44),
                 format = "col", sampleDat = 1:96,
                 refDat = -2, names = 1,
                 sampleLen = 1:40, refLen = -1,
                 check = FALSE)

## Do something useful with the data:
ml2 &lt;- modlist(res2[[1]], model = l5)
plot(ml2)

## End(Not run)
</code></pre>

<hr>
<h2 id='pcrimport2'>Simple qPCR data import function (i.e. from text files or clipboard)</h2><span id='topic+pcrimport2'></span>

<h3>Description</h3>

<p>Simple wrapper function to easily import qPCR data from the clipboard (default) or tab-delimited text files.
In contrast to <code><a href="#topic+pcrimport">pcrimport</a></code>, this function has no enhanced formatting features, but is quick and
easy to use on data that has been pre-formatted, i.e. as in dataset <code><a href="#topic+reps">reps</a></code> ('Cycles' in the first column, all
remaining columns with sensible names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrimport2(file = "clipboard", sep = "\t", header = TRUE, quote = "",
          dec = ".", colClasses = "numeric", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrimport2_+3A_file">file</code></td>
<td>
<p>the name of the file which the data are to be read from (full path).</p>
</td></tr>
<tr><td><code id="pcrimport2_+3A_sep">sep</code></td>
<td>
<p>the field separator character.</p>
</td></tr>
<tr><td><code id="pcrimport2_+3A_header">header</code></td>
<td>
<p>a logical value indicating whether the file contains the names of the variables as its first line.</p>
</td></tr>
<tr><td><code id="pcrimport2_+3A_quote">quote</code></td>
<td>
<p>the set of quoting characters.</p>
</td></tr>
<tr><td><code id="pcrimport2_+3A_dec">dec</code></td>
<td>
<p>the character used in the file to denote decimal points.</p>
</td></tr>
<tr><td><code id="pcrimport2_+3A_colclasses">colClasses</code></td>
<td>
<p>character. A vector of classes to be assumed for the columns.</p>
</td></tr> 
<tr><td><code id="pcrimport2_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code><a href="utils.html#topic+read.table">read.table</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a more detailed description of the arguments see <code><a href="utils.html#topic+read.table">read.table</a></code>.
</p>


<h3>Value</h3>

<p>A data frame containing a representation of the data in the file.  
</p>


<h3>Note</h3>

<p>This function is the former <code>pcrimport</code> from packages 1.3-3 downward.
See <code><a href="#topic+pcrimport">pcrimport</a></code> for an enhanced version offering formatting in the presence of reference dyes, columns/rows deletion,
transforming from wide to long format, and automatic batch analysis.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Paste some Excel data into the clipboard.
## Not run: 
temp &lt;- pcrimport2()

## End(Not run)
## From a tab-delimited text file.
## Not run: 
temp &lt;- pcrimport2("c:\temp\foo.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='pcropt1'>Combinatorial elimination of plateau and ground phase cycles</h2><span id='topic+pcropt1'></span>

<h3>Description</h3>

<p>The estimation of PCR efficiency and calculation of initial fluorescence <code class="reqn">F_0</code> is analyzed by refitting the (optimized) model on subsets of the data, thereby using all possible combinations of datapoints. The estimated parameters are then collated in a dataframe. This is intended to be the prerequisite for finding the optimal datapoints that minimize the fit or exhibit the best correlation to a calibration curve. This approch is an extension to the method described in Rutledge <em>et al</em>. (2004). The result of any collected parameter can then be displayed by a rank-colored bubbleplot. See 'Examples'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcropt1(object, fact = 3, opt = FALSE, plot = TRUE, bubble = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcropt1_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="pcropt1_+3A_fact">fact</code></td>
<td>
<p>numeric. The multiplier for the scan border. See 'Details'.</p>
</td></tr> 
<tr><td><code id="pcropt1_+3A_opt">opt</code></td>
<td>
<p>logical. If <code>true</code>, model selection is applied for each combination of cycles. Beware: Slow!!</p>
</td></tr> 
<tr><td><code id="pcropt1_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, the iterative plotting is displayed, which makes the method a bit slower.</p>
</td></tr>
<tr><td><code id="pcropt1_+3A_bubble">bubble</code></td>
<td>
<p>either <code>NULL</code> for no bubble plot or any parameter (given as a character vector) in the result matrix to be displayed as a bubble plot. See 'Examples'.</p>
</td></tr>
<tr><td><code id="pcropt1_+3A_...">...</code></td>
<td>
<p>other parameters to be passed on to <code><a href="#topic+efficiency">efficiency</a></code>, <code><a href="#topic+mselect">mselect</a></code> or <code>qpcR:::bubbleplot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It has been shown by Rutledge (2004) that the estimation of PCR efficiency gives more realistic values when the number of plateau cycles are decreased. This paradigm is the basis for this function, but we also consider the cycles in the ground phase and all combinations between ground/plateau cycles. All datapoints between the lower border cpD1 - <code>fact</code> * (cpD1 - cpD2) and upper border cpD1 + <code>fact</code> * (cpD1 - cpD2) are cycled through.
</p>


<h3>Value</h3>

<p>A matrix with the selected border values, goodness-of-fit measures as obtained from <code><a href="#topic+pcrGOF">pcrGOF</a></code> and efficiency and <code class="reqn">F_0</code> values from <code><a href="#topic+efficiency">efficiency</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Sigmoidal curve fitting redefines quantitative real-time PCR with the prospective of developing automated high-throughput applications.<br />
Rutledge RG.<br />
<em>Nucleic Acids Research</em> (2004), <b>32</b>: e178.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Optimize fit and display bubbleplot of R-square.
m1 &lt;- pcrfit(reps, 1, 2, l4)
res1 &lt;- pcropt1(m1, plot = FALSE, bubble = "Rsq")

## End(Not run)
</code></pre>

<hr>
<h2 id='pcrsim'>Simulation of sigmoidal qPCR data with goodness-of-fit analysis</h2><span id='topic+pcrsim'></span>

<h3>Description</h3>

<p>Simulated sigmoidal qPCR curves are generated from an initial model to which some user-defined homoscedastic or heteroscedastic noise is added. One or more models can then be fit to this random data and goodness-of-fit (GOF) measures are calculated for each of the models. This is essentially a Monte-Carlo approach testing for the best model in dependence to some noise structure in sigmodal models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcrsim(object, nsim = 100, error = 0.02, 
       errfun = function(y) 1, plot = TRUE,
       fitmodel = NULL, select = FALSE, 
       statfun = function(y) mean(y, na.rm = TRUE),
       PRESS = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcrsim_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit.</p>
</td></tr> 
<tr><td><code id="pcrsim_+3A_nsim">nsim</code></td>
<td>
<p>the number of simulated curves.</p>
</td></tr>
<tr><td><code id="pcrsim_+3A_error">error</code></td>
<td>
<p>the gaussian error used for the simulation. See 'Details'.</p>
</td></tr>
<tr><td><code id="pcrsim_+3A_errfun">errfun</code></td>
<td>
<p>an optional function for the error distribution. See 'Details'.</p>
</td></tr>
<tr><td><code id="pcrsim_+3A_plot">plot</code></td>
<td>
<p>should the simulated and fitted curves be displayed?</p>
</td></tr>
<tr><td><code id="pcrsim_+3A_fitmodel">fitmodel</code></td>
<td>
<p>a model or model list to test against the initial model.</p>
</td></tr> 
<tr><td><code id="pcrsim_+3A_select">select</code></td>
<td>
<p>if <code>TRUE</code>, a matrix is returned with the best model in respect to each of the GOF measures.</p>
</td></tr>  
<tr><td><code id="pcrsim_+3A_statfun">statfun</code></td>
<td>
<p>a function to be finally applied to all collected GOF measures, default is the average.</p>
</td></tr> 
<tr><td><code id="pcrsim_+3A_press">PRESS</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, the computationally expensive <code><a href="#topic+PRESS">PRESS</a></code> statistic will be calculated.</p>
</td></tr>
<tr><td><code id="pcrsim_+3A_...">...</code></td>
<td>
<p>other parameters to be passed on to <code><a href="base.html#topic+plot">plot</a></code> or <code><a href="#topic+pcrfit">pcrfit</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The value defined under <code>error</code> is just the standard deviation added plainly to each y value from the initial model, thus generating a dataset with homoscedastic error. With aid of <code>errfun</code>, the distribution of the error along the y values can be altered and be used to generate heteroscedastic error along the curve, i.e. as a function of the magnitude.
</p>
<p>Example:<br />
<code>errfun = function(y) 1</code><br />
same variance for all y, as is.<br />
</p>
<p><code>errfun = function(y) y</code><br />
variance as a function of the y-magnitude.<br />
</p>
<p><code>errfun = function(y) 1/y</code><br />
variance as an inverse function of the y-magnitude.
</p>
<p>For the effect, see 'Examples'.
</p>


<h3>Value</h3>

<p>A list containing the following items:
</p>
<table role = "presentation">
<tr><td><code>cyc</code></td>
<td>
<p>same as in 'arguments'.</p>
</td></tr>
<tr><td><code>fluoMat</code></td>
<td>
<p>a matrix with the simulated qPCR data in columns.</p>
</td></tr>
<tr><td><code>coefList</code></td>
<td>
<p>a list with the coefficients from the fits for each model, as subitems.</p>
</td></tr>
<tr><td><code>gofList</code></td>
<td>
<p>a list with the GOF measures for each model, as subitems.</p>
</td></tr> 
<tr><td><code>statList</code></td>
<td>
<p>a list with the GOF measures summarized by <code>statfun</code> for each model, as subitems.</p>
</td></tr> 
<tr><td><code>modelMat</code></td>
<td>
<p>if <code>select = TRUE</code>, a matrix with the best model for each GOF measure and each simulation.</p>
</td></tr>   
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate initial model.
m1 &lt;- pcrfit(reps, 1, 2, l4)

## Simulate homoscedastic error
## and test l4 and l5 on data.
res1 &lt;- pcrsim(m1, error = 0.2, nsim = 20, 
               fitmodel = list(l4, l5))

## Not run: 
## Use heteroscedastic noise typical for 
## qPCR: more noise at lower fluorescence.
res2 &lt;- pcrsim(m1, error = 0.01, errfun = function(y) 1/y,
              nsim = 20, fitmodel = list(l4, l5, l6))

## Get 95% confidence interval for 
## the models GOF in question (l4, l5, l6).
res3 &lt;- pcrsim(m1, error = 0.2, nsim = 20, fitmodel = list(l4, l5, l6),
              statfun = function(y) quantile(y, c(0.025, 0.975)))
res3$statList  

## Count the selection of the 'true' model (l4)
## for each of the GOF measures,
## use PRESS statistic =&gt; SLOW!
## BIC wins!!
res4 &lt;- pcrsim(m1, error = 0.05, nsim = 10, fitmodel = list(l4, l5, l6),
               select = TRUE, PRESS = TRUE)
apply(res4$modelMat, 2, function(x) sum(x == 1))

## End(Not run) 
</code></pre>

<hr>
<h2 id='plot.pcrfit'>Plotting qPCR data with fitted curves</h2><span id='topic+plot.pcrfit'></span>

<h3>Description</h3>

<p>A plotting function for data of class 'pcrfit' (single curves) or 'modlist' (batch curves) displaying the data points and the fitted curve. Four different plot types are available, namely plotting all curves in a 2D graph, a 2D plot matrix, a 3D graph or a heatmap-like image plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcrfit'
plot(x, type = c("all", "single", "3D", "image"), 
        fitted = TRUE, add = FALSE, col = NULL, par2D = list(),
        par3D = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.pcrfit_+3A_x">x</code></td>
<td>
<p>an object of class 'pcrfit' or 'modlist'.</p>
</td></tr>     
<tr><td><code id="plot.pcrfit_+3A_type">type</code></td>
<td>
<p>plots all curves in 2D (<code>"all"</code>), a plot matrix with many curves (<code>"single"</code>), a 3D plot (<code>"3D"</code>) or a heatmap-like image plot (<code>image</code>).</p>
</td></tr> 
<tr><td><code id="plot.pcrfit_+3A_fitted">fitted</code></td>
<td>
<p>should the fitted lines be displayed?</p>
</td></tr>      
<tr><td><code id="plot.pcrfit_+3A_add">add</code></td>
<td>
<p>should the curve be added to an existing plot?</p>
</td></tr>
<tr><td><code id="plot.pcrfit_+3A_col">col</code></td>
<td>
<p>an optional color vector for the individual curves. Is recycled to the number of runs in <code>x</code>.</p>
</td></tr> 
<tr><td><code id="plot.pcrfit_+3A_par2d">par2D</code></td>
<td>
<p>a list containing graphical parameters to change the 2D-plots: <code><a href="base.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+points">points</a></code> or <code><a href="graphics.html#topic+lines">lines</a></code>.</p>
</td></tr>
<tr><td><code id="plot.pcrfit_+3A_par3d">par3D</code></td>
<td>
<p>a list containing graphical parameters to change the 3D-plot: <code><a href="rgl.html#topic+plot3d">plot3d</a></code>, <code><a href="rgl.html#topic+points3d">points3d</a></code>, <code><a href="rgl.html#topic+lines3d">lines3d</a></code>, <code><a href="rgl.html#topic+axis3d">axis3d</a></code> or <code><a href="rgl.html#topic+mtext3d">mtext3d</a></code>.</p>
</td></tr>
<tr><td><code id="plot.pcrfit_+3A_...">...</code></td>
<td>
<p>other parameters for downstream methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the 'rgl' package for 3D plots. If the 'modlist' contains runs that failed to fit, these are displayed with RED asterisked names. In addition, sigmoidal outlier runs will be displayed in BLUE with double asterisked names. This approach makes the identification of failed runs easy and works only with <code>type = "single"</code>. See 'Examples'.<br />
For high-throughput data, the user of this function is encouraged to use the <code>"image"</code> kind of plot, as one can see quite nicely the differences in the amplification profiles of several hundred runs. Of course, this plot type does not display the fitted curve. See 'Examples'.
</p>


<h3>Value</h3>

<p>A 2D, multiple 2D, 3D or heatmap-like qPCR plot. 
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Single plot.
m1 &lt;- pcrfit(reps, 1, 2, l5)
plot(m1)

## Add another plot in blue.
m2 &lt;- pcrfit(reps, 1, 12, l5)
plot(m2, add = TRUE, col = 4)

## Plot a 'modlist' batch with coloring of replicates.
ml1 &lt;- modlist(reps, 1, 2:13, model = l4)
plot(ml1, col = gl(3,4))   

## Subset of cycle range.
plot(ml1, col = rep(1:3, each = 4), 
     par2D = list(xlim = c(10, 30)))

## Plot single curves for diagnostics.
plot(ml1, type = "single", col = rep(1:3, each = 4))

## 3D plots of 'modlist's.
plot(ml1, type = "3D", col = rep(1:3, each = 4))
rgl.close()

## Not run: 
## Example for "image" type when
## using large data.
ml2 &lt;- modlist(vermeulen2)
plot(ml2, type = "image")

## Example for outlier identification:
## RED/*name* indicates failed fitting,
## BLUE/**name** indicates sigmoidal outlier
## using 'testdat' set.
ml3 &lt;- modlist(testdat, model = l5)
plot(ml3, type = "single") 

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.pcrfit'>Value prediction from a fitted qPCR model</h2><span id='topic+predict.pcrfit'></span>

<h3>Description</h3>

<p>After fitting the appropriate model, either the raw fluorescence values can be predicted from the cycle number or <em>vice versa</em>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcrfit'
predict(object, newdata, which = c("y", "x"), 
        interval = c("none", "confidence", "prediction"),
        level = 0.95, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.pcrfit_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>  
<tr><td><code id="predict.pcrfit_+3A_newdata">newdata</code></td>
<td>
<p>a dataframe containing the values to estimate from, using the same variable naming as in the fitted model.</p>
</td></tr>
<tr><td><code id="predict.pcrfit_+3A_which">which</code></td>
<td>
<p>either <code>"y"</code> (default) for prediction of the raw fluorescence or <code>"x"</code> for prediction of the cycle number.</p>
</td></tr>
<tr><td><code id="predict.pcrfit_+3A_interval">interval</code></td>
<td>
<p>if not <code>"none"</code>, confidence or prediction intervals are calculated.</p>
</td></tr>      
<tr><td><code id="predict.pcrfit_+3A_level">level</code></td>
<td>
<p>the confidence level.</p>
</td></tr>	
<tr><td><code id="predict.pcrfit_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional arguments. None are used in this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>y-values (Fluorescence) are estimated from <code>object$MODEL$expr</code>, x-values (Cycles) are estimated from <code>object$MODEL$inv</code>. Confidence intervals are calculated from the gradient of the function and the variance-covariance matrix of <code>object</code> by <code class="reqn">\nabla f(x) \cdot cov(y) \cdot \nabla f(x)</code> and are based on asymptotic normality (t-distribution).
</p>


<h3>Value</h3>

<p>A dataframe containing the estimated values and (if chosen) standard error/upper confidence limit/lower confidence limit. 
The gradient is attached to the dataframe and can be accessed with <code>attr</code>. 
</p>


<h3>Note</h3>

<p>The estimation of x (cycles) from fluorescence data if <code>which = "x"</code> is problematic in the asymptotic regions of the sigmoidal curves
(often gives NaN, due to logarithmation of negative values) and works fairly well in the ascending part.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)

## Which raw fluorescence value at cycle number = 17?
predict(m1, newdata = data.frame(Cycles = 17))

## Cycle numbers 20:25, with 95% confidence?
predict(m1, newdata = data.frame(Cycles = 20:25), interval = "confidence")

## Which cycle at Fluo = 4, with 95% prediction?
predict(m1, newdata = data.frame(Fluo = 4), which = "x", interval = "prediction")
</code></pre>

<hr>
<h2 id='PRESS'>Allen's PRESS (Prediction Sum-Of-Squares) statistic, aka P-square</h2><span id='topic+PRESS'></span>

<h3>Description</h3>

<p>Calculates the PRESS statistic, a leave-one-out refitting and prediction method, as described in Allen (1971).
Works for any regression model with a <code>call</code> slot, an <code><a href="stats.html#topic+update">update</a></code> and a <code><a href="stats.html#topic+predict">predict</a></code> function, hence all models of class <code>lm</code>, <code>glm</code>, <code>nls</code> and <code>drc</code> (and maybe more...).
The function also returns the PRESS analog to R-square, the P-square. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PRESS(object, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PRESS_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
<tr><td><code id="PRESS_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, iterations are displayed on the console.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>From a fitted model, each of the predictors <code class="reqn">x_i, i = 1 \ldots{n}</code> is removed and the model is refitted to the <code class="reqn">n-1</code> points.
The predicted value <code class="reqn">\hat{y}_{i, -i}</code> is calculated at the excluded point <code class="reqn">x_i</code> and the PRESS statistic is given by:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^n (y_i - \hat{y}_{i, -i})^2</code>
</p>

<p>The PRESS statistic is a surrogate measure of crossvalidation of small sample sizes and a measure for internal validity.
Small values indicate that the model is not overly sensitive to any single data point.
The P-square value, the PRESS equivalent to R-square, is given by </p>
<p style="text-align: center;"><code class="reqn">P^2 = \frac{\sum_{i=1}^n \hat{\varepsilon}^2_{-i}}{\sum_{i=1}^n (y_i - \bar{y})^2}</code>
</p>

<p>with <code class="reqn">\hat\varepsilon_{-i} = y_i - \hat{y}_{-i}</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>stat</code></td>
<td>
<p>The PRESS statistic.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>a vector containing the PRESS residuals for each <code class="reqn">x_i</code>.</p>
</td></tr>  
<tr><td><code>P.square</code></td>
<td>
<p>the P-square value. See 'Details'.</p>
</td></tr>  
</table>


<h3>Note</h3>

<p>There is also a <code>PRESS</code> function in library 'MPV' that works solely for <code>lm</code> models using the hat matrix.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>The relationship between variable selection and data augmentation and a method for prediction.<br />
Allen DM.<br />
<em>Technometrics</em> (1974), <b>16</b>: 25-127.
</p>
<p>The Prediction Sum of Squares as a Criterion for Selecting Predictor Variables.<br />
Allen DM.<br />
Technical Report Number 23 (1971), Department of Statistics, University of Kentucky.
</p>
<p>Classical and Modern Regression with Applications.<br />
Myers RH.<br />
Second Edition (1990), Duxbury Press (PWS-KENT Publishing Company), 299-304.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example for PCR analysis.
m1 &lt;- pcrfit(reps, 1, 2, l7)
PRESS(m1)

## Compare PRESS statistic in models
## with fewer parameters.
m2 &lt;- pcrfit(reps, 1, 2, l5)
PRESS(m2)
m3 &lt;- pcrfit(reps, 1, 2, l4)
PRESS(m3)

## Example for linear regression.
x &lt;- 1:10
y &lt;- rnorm(10, x, 0.1)
mod &lt;- lm(y ~ x)
PRESS(mod)

## Example for NLS fitting.     
DNase1 &lt;- subset(DNase, Run == 1)
fm1DNase1 &lt;- nls(density ~ SSlogis(log(conc), Asym, xmid, scal), DNase1)
res &lt;- PRESS(fm1DNase1)

## PRESS residuals plot.
barplot(res$residuals)
</code></pre>

<hr>
<h2 id='propagate'>Error propagation using different methods</h2><span id='topic+propagate'></span>

<h3>Description</h3>

<p>A general function for the calculation of error propagation by Monte Carlo simulation, permutation and first/second-order Taylor expansion including covariances. Can be used for qPCR data, but any data that should be subjected to error propagation analysis will do. The different methods can be used for any expression based on either replicate or summary data (mean &amp; standard deviation). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propagate(expr, data, type = c("raw", "stat"), second.order = TRUE,
          do.sim = FALSE, dist.sim = c("norm", "tnorm"), use.cov = FALSE, 
          nsim = 10000, do.perm = FALSE, perm.crit = NULL, ties = NULL, 
          nperm = 2000, alpha = 0.05, plot = TRUE, logx = FALSE, 
          verbose = FALSE, ...)  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="propagate_+3A_expr">expr</code></td>
<td>
<p>an expression, such as <code>expression(x/y)</code>.</p>
</td></tr>
<tr><td><code id="propagate_+3A_data">data</code></td>
<td>
<p>a dataframe or matrix containing either a) the replicates in columns or b) the means in the first row and the standard deviations in the second row. The variable names must be defined in the column headers.</p>
</td></tr>
<tr><td><code id="propagate_+3A_type">type</code></td>
<td>
<p>either <code>raw</code> if replicates are given, or <code>stat</code> if means and standard deviations are supplied.</p>
</td></tr>
<tr><td><code id="propagate_+3A_second.order">second.order</code></td>
<td>
<p>logical. If <code>TRUE</code>, error propagation will be calculated with first AND second-order Taylor expansion. See 'Details'.</p>
</td></tr>
<tr><td><code id="propagate_+3A_do.sim">do.sim</code></td>
<td>
<p>logical. Should Monte Carlo simulation be applied?</p>
</td></tr>
<tr><td><code id="propagate_+3A_dist.sim">dist.sim</code></td>
<td>
<p><code>"norm"</code> will use a multivariate normal distribution, <code>"tnorm"</code> a multivariate truncated normal distribution. See 'Details'.</p>
</td></tr>
<tr><td><code id="propagate_+3A_use.cov">use.cov</code></td>
<td>
<p>logical or variance-covariance matrix with the same column descriptions and column order as <code>data</code>. If <code>TRUE</code> together with replicates, the covariances are calculated from these and used within Monte Carlo simulation and error propagation. If <code>type = "stat"</code>, a square variance-covariance matrix can be supplied in the right dimensions (n x n, n = number of variables). If <code>FALSE</code>, Monte Carlo simulation and error propagation use only the diagonal (variances).</p>
</td></tr>
<tr><td><code id="propagate_+3A_nsim">nsim</code></td>
<td>
<p>the number of simulations to be performed, minimum is 5000.</p>
</td></tr>  
<tr><td><code id="propagate_+3A_do.perm">do.perm</code></td>
<td>
<p>logical. Should permutation error analysis be applied?</p>
</td></tr>     
<tr><td><code id="propagate_+3A_perm.crit">perm.crit</code></td>
<td>
<p>a character string of one or more criteria defining the null hypothesis for the permutation p-value. See 'Details'.</p>
</td></tr>
<tr><td><code id="propagate_+3A_ties">ties</code></td>
<td>
<p>a vector defining the columns that should be tied together for the permutations. See 'Details'.</p>
</td></tr>
<tr><td><code id="propagate_+3A_nperm">nperm</code></td>
<td>
<p>the number of permutations to be performed.</p>
</td></tr>  
<tr><td><code id="propagate_+3A_alpha">alpha</code></td>
<td>
<p>the confidence level.</p>
</td></tr>
<tr><td><code id="propagate_+3A_plot">plot</code></td>
<td>
<p>logical. Should histograms with confidence intervals (in blue) be plotted for all methods?</p>
</td></tr>
<tr><td><code id="propagate_+3A_logx">logx</code></td>
<td>
<p>logical. Should the x-axis of the graphs have logarithmic scale?</p>
</td></tr>
<tr><td><code id="propagate_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, a longer output is given including the simulated data, derivatives, covariance matrix, etc.</p>
</td></tr>
<tr><td><code id="propagate_+3A_...">...</code></td>
<td>
<p>other parameters to be supplied to <code>hist</code>, <code>boxplot</code> or <code>abline</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implemented methods are:<br /><br />
1) <b>Monte Carlo simulation:</b><br />
For each variable in <code>data</code>, simulated data with <code>nsim</code> samples is generated from a multivariate (truncated) normal distribution using mean <code class="reqn">\mu</code> and standard deviation <code class="reqn">\sigma</code> of each variable. All data is coerced into a new dataset that has the same covariance structure as the initial <code>data</code>. Each row of the simulated dataset is evaluated and summary statistics are calculated. In scenarios that are nonlinear in nature the distribution of the result values can be skewed, mainly due to the simulated values at the extreme end of the normal distribution. Setting <code>dist.sim = "tnorm"</code> will fit a multivariate normal distribution, calculate the lower/upper 2.5% quantile on each side for each input variable and use these as bounds for simulating from a multivariate truncated normal distribution. This will (in part) remove some of the skewness in the result distribution. 
</p>
<p>2) <b>Permutation approach:</b><br />
The original <code>data</code> is permutated <code>nperm</code> times by binding observations together according to <code>ties</code>. The <code>ties</code> bind observations that can be independent measurements from the same sample. In qPCR terms, this would be a real-time PCR for two different genes on the same sample. If <code>ties</code> are omitted, the observations are shuffled independently. In detail, two datasets are created for each permutation: Dataset1 samples the rows (replicates) of the data according to <code>ties</code>. Dataset2 is obtained by sampling the columns (samples), also binding columns as defined in <code>ties</code>. For both datasets, the permutations are evaluated and statistics are collected. A confidence interval is calculated from all evaluations of Dataset1. A p-value is calculated from all permutations that follow <code>perm.crit</code>, whereby <code>init</code> reflects the permutations of the initial <code>data</code> and <code>perm</code> the permutations of the randomly reallocated samples. Thus, the p-value gives a measure against the null hypothesis that the result in the initial group is just by chance. See also 'Examples'.<br />
The criterion for the permutation p-value (<code>perm.crit</code>) has to be defined by the user. For example, let's say we calculate some value 0.2 which is a ratio between two groups. We would hypothesize that by randomly reallocating the values between the groups, the mean values are not equal or smaller than in the initial data. We would thus define <code>perm.crit</code> as &quot;perm &lt; init&quot; meaning that we want to test if the mean of the initial data (<code>init</code>) is frequently smaller than by the randomly allocated data (<code>perm</code>). The default (<code>NULL</code>) is to test all three variants &quot;perm &gt; init&quot;, &quot;perm == init&quot; and &quot;perm &lt; init&quot;.
</p>
<p>3) <b>Error propagation:</b><br />
The propagated error is calculated by first and second-order Taylor expansion using matrix algebra. Often omitted, but important in models where the variables are correlated, is the second covariance term:
</p>
<p style="text-align: center;"><code class="reqn">\sigma_y^2 = \underbrace{\sum_{i=1}^N\left(\frac{\partial f}{\partial x_i} \right)^2 \sigma_i^2}_{\rm{variance}} + \underbrace{2\sum_{i=1\atop i \neq j}^N\sum_{j=1\atop j \neq i}^N\left(\frac{\partial f}{\partial x_i} \right)\left(\frac{\partial f}{\partial x_j} \right) \sigma_{ij}}_{\rm{covariance}}</code>
</p>

<p><code>propagate</code> calculates the propagated error either with or without covariances using matrix algebra for first- and second-order (since version 1.3-8) Taylor expansion.<br />
<b>First-order:</b><br />
<code class="reqn">\mathrm{E}(y) = f(\bar{x}_i)</code><br />
<code class="reqn">\mathbf{C}_y = \nabla_x\mathbf{C}_x\nabla_x^T</code><br />
<b>Second-order:</b><br />
<code class="reqn">\mathrm{E}(y) = f(\bar{x}_i) + \frac{1}{2}[tr(\mathbf{H}_{xx}\mathbf{C}_x)]</code><br />
<code class="reqn">\mathbf{C}_y = \nabla_x\mathbf{C}_x\nabla_x^T + \frac{1}{2}[tr(\mathbf{H}_{xx}\mathbf{C}_x\mathbf{H}_{xx}\mathbf{C}_x)]</code><br />
</p>
<p>with <code class="reqn">\mathrm{E}(y)</code> = expectation of <code class="reqn">y</code>, <code class="reqn">\mathbf{C}_y</code> = variance of <code class="reqn">y</code>, <code class="reqn">\nabla_x</code> = the p x n gradient matrix with all partial first derivatives, <code class="reqn">\mathbf{C}_x</code> = the p x p covariance matrix, <code class="reqn">\mathbf{H}_{xx}</code> the Hessian matrix with all partial second derivatives and <code class="reqn">tr(\cdot)</code> = the trace (sum of diagonal) of the matrix. For a detailed derivation, see 'References'.<br /> 
The second-order Taylor expansion (<code>second.order = TRUE</code>) corrects for bias in nonlinear expressions as the first-order Taylor expansion assumes linearity around <code class="reqn">\bar{x}_i</code>.<br />
Depending on the input formula, the error propagation may result in an error that is not normally distributed. The Monte Carlo simulation, starting with normal distributions of the variables, can clarify this. A high tendency from deviation of normality is encountered in formulas in which the error of the denominator is relatively high or in exponential models where the exponent has a high error. This is one of the problems that is inherent in real-time PCR analysis, as the classical ratio calculation with efficiencies (i.e. by the delta-ct method) is of an exponential type.  
</p>


<h3>Value</h3>

<p>A plot containing histograms of the Monte Carlo simulation, the permutation values and error propagation. Additionally inserted are a boxplot, median values in red and confidence intervals as blue borders. 
</p>
<p>A list with the following components (if <code>verbose = TRUE</code>):   
</p>
<table role = "presentation">
<tr><td><code>data.Sim</code></td>
<td>
<p>the Monte Carlo simulated data with evaluations in the last column.</p>
</td></tr>       
<tr><td><code>data.Perm</code></td>
<td>
<p>the data of the permutated observations and samples with corresponding evaluations and the decision according to <code>perm.crit</code>.</p>
</td></tr>      
<tr><td><code>data.Prop</code></td>
<td>
<p><code>nsim</code> values generated from a normal distribution with mean and s.d. as calculated from the propagated error.</p>
</td></tr>   
<tr><td><code>gradient</code></td>
<td>
<p>the evaluated gradient vector <code class="reqn">\nabla_x</code> of partial first derivatives.</p>
</td></tr>   
<tr><td><code>hessian</code></td>
<td>
<p>the evaluated hessian matrix <code class="reqn">\mathbf{H}_{xx}</code> of partial second derivatives.</p>
</td></tr>  
<tr><td><code>covMat</code></td>
<td>
<p>the covariance matrix <code class="reqn">\mathbf{C}_x</code> used for Monte Carlo simulation and error propagation.</p>
</td></tr>    
<tr><td><code>summary</code></td>
<td>
<p>a summary of the collected statistics, given as a dataframe. These are: mean, s.d. median, mad, lower/upper confidence interval and permutation p-values.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p><b>Error propagation (in general):</b><br />
An Introduction to error analysis.<br />
Taylor JR.<br />
University Science Books (1996), New York.<br />
</p>
<p>Evaluation of measurement data - Guide to the expression of uncertainty in measurement.<br />
JCGM 100:2008 (GUM 1995 with minor corrections).<br />
<a href="https://www.bipm.org/utils/common/documents/jcgm/JCGM_100_2008_E.pdf">https://www.bipm.org/utils/common/documents/jcgm/JCGM_100_2008_E.pdf</a>.<br />
</p>
<p><b>Higher-order Taylor expansion:</b><br />
On higher-order corrections for propagating uncertainties.<br />
Wang CM &amp; Iyer HK.<br />
<em>Metrologia</em> (2005), <b>42</b>: 406-410.<br />
</p>
<p>Accuracy of error propagation exemplified with ratios of random variables.<br />
Winzer PJ.<br />
<em>Rev Sci Instrum</em> (2000), <b>72</b>: 1447-1454.<br />
</p>
<p><b>Matrix algebra for error propagation:</b><br />
An Introduction to Error Propagation: Derivation, Meaning and Examples of Equation Cy = FxCxFx^t.<br />
<a href="www.nada.kth.se/~kai-a/papers/arrasTR-9801-R3.pdf">www.nada.kth.se/~kai-a/papers/arrasTR-9801-R3.pdf</a>.<br />
</p>
<p>Second order nonlinear uncertainty modeling in strapdown integration using MEMS IMUs.<br />
Zhang M, Hol JD, Slot L, Luinge H.<br />
2011 Proceedings of the 14th International Conference on Information Fusion (FUSION) (2011).<br />
</p>
<p><b>Error propagation (in qPCR):</b><br />
Error propagation in relative real-time reverse transcription polymerase chain reaction quantification models: The balance between accuracy and precision.<br />
Nordgard O, Kvaloy JT, Farmen RK, Heikkila R.<br />
<em>Anal Biochem</em> (2006), <b>356</b>: 182-193.<br />
</p>
<p>qBase relative quantification framework and software for management and analysis of real-time quantitative PCR data.<br />
Hellemans J, Mortier G, De Paepe A, Speleman F, Vandesompele J.<br />
<em>Genome Biol</em> (2007), <b>8</b>: R19.<br /> 
</p>
<p><b>Multivariate normal distribution:</b><br />
Stochastic Simulation.<br />
Ripley BD.<br />
Stochastic Simulation (1987). Wiley. Page 98.<br />
</p>
<p><b>Testing for normal distribution:</b><br />
Testing for  Normality.<br />
Thode Jr. HC.<br />
Marcel Dekker (2002), New York.<br />
</p>
<p>Approximating the Shapiro-Wilk W-test for non-normality.<br />
Royston P.<br /> 
<em>Stat Comp</em> (1992), <b>2</b>: 117-119.<br />
</p>


<h3>See Also</h3>

<p>Function <code><a href="#topic+ratiocalc">ratiocalc</a></code> for error analysis within qPCR ratio calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## From summary data just calculate 
## Monte-Carlo and propagated error.
EXPR &lt;- expression(x/y)
x &lt;- c(5, 0.01)
y &lt;- c(1, 0.01)
DF &lt;- cbind(x, y)
RES1 &lt;- propagate(expr = EXPR, data = DF, type = "stat", 
                 do.sim = TRUE, verbose = TRUE)

## Do Shapiro-Wilks test on Monte Carlo evaluations 
## !maximum 5000 datapoints can be used!
## =&gt; p.value on border to non-normality
shapiro.test(RES1$data.Sim[1:5000, 3])
## How about a graphical analysis:
qqnorm(RES1$data.Sim[, 3])

## Using raw data
## If data is of unequal length,
## use qpcR:::cbind.na to avoid replication!
## Do permutations (swap x and y values)
## and simulations.
EXPR &lt;- expression(x*y)
x &lt;- c(2, 2.1, 2.2, 2, 2.3, 2.1)
y &lt;- c(4, 4, 3.8, 4.1, 3.1)
DF &lt;- qpcR:::cbind.na(x, y)  
RES2 &lt;- propagate(EXPR, DF, type = "raw", do.perm = TRUE, 
                 do.sim = TRUE, verbose = TRUE)
RES2$summary

## For replicate data, using relative 
## quantification ratio from qPCR.
## How good is the estimation of the propagated error?
## Done without using covariance in the 
## calculation and simulation.
## cp's and efficiencies are tied together
## because they are two observations on the
## same sample!
## As we are using an exponential type function,
## better to logarithmize the x-axis.
EXPR &lt;- expression((E1^cp1)/(E2^cp2))
E1 &lt;- c(1.73, 1.75, 1.77)
cp1 &lt;- c(25.77,26.14,26.33)
E2 &lt;-  c(1.72,1.68,1.65)
cp2 &lt;- c(33.84,34.04,33.33)
DF &lt;- cbind(E1, cp1, E2, cp2)
RES3 &lt;- propagate(EXPR, DF, type = "raw", do.sim = TRUE,
                 do.perm = TRUE, verbose = TRUE, logx = TRUE)                 
## STRONG deviation from normality!
shapiro.test(RES3$data.Sim[1:5000, 5])
qqnorm(RES3$data.Sim[, 5])

## Same setup as above but also
## using a permutation approach
## for resampling the confidence interval.
## Cp's and efficiencies are tied together
## because they are two observations on the
## same sample! 
## Similar to what REST2008 software does.
RES4 &lt;- propagate(EXPR, DF, type = "raw", do.sim = TRUE,
                 perm.crit = NULL, do.perm = TRUE, 
                 ties = c(1, 1, 2, 2), logx = TRUE, verbose = TRUE)
RES4$summary
## p-value of 0 in perm &lt; init indicates that not a single 
## exchange of group memberships resulted in a smaller ratio!
              
## Proof that covariance of Monte-Carlo
## simulated dataset is the same as from 
## initial data.
RES4$covMat
cov(RES4$data.Sim[, 1:4])
all.equal(RES4$covMat, cov(RES4$data.Sim[, 1:4]))
</code></pre>

<hr>
<h2 id='qpcR_datasets'>The (published) datasets implemented in qpcR</h2><span id='topic+batsch1'></span><span id='topic+batsch2'></span><span id='topic+batsch3'></span><span id='topic+batsch4'></span><span id='topic+batsch5'></span><span id='topic+boggy'></span><span id='topic+competimer'></span><span id='topic+dil4reps94'></span><span id='topic+dyemelt'></span><span id='topic+guescini1'></span><span id='topic+guescini2'></span><span id='topic+htPCR'></span><span id='topic+karlen1'></span><span id='topic+karlen2'></span><span id='topic+karlen3'></span><span id='topic+lievens1'></span><span id='topic+lievens2'></span><span id='topic+lievens3'></span><span id='topic+reps'></span><span id='topic+reps2'></span><span id='topic+reps3'></span><span id='topic+reps384'></span><span id='topic+rutledge'></span><span id='topic+testdat'></span><span id='topic+vermeulen1'></span><span id='topic+vermeulen2'></span>

<h3>Description</h3>

<p>A compilation of published datasets for method evaluation/comparison.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batsch1
batsch2
batsch3
batsch4
batsch5
boggy
competimer
dil4reps94
dyemelt
guescini1
guescini2
htPCR
karlen1
karlen2
karlen3
lievens1
lievens2
lievens3
reps
reps2
reps3
reps384
rutledge
testdat
vermeulen1
vermeulen2
</code></pre>


<h3>Details</h3>

<p><b>batsch1-5:</b><br />
Setup: Five 4-fold dilutions with 3 replicates.<br />
Annotation: FX.Y (X = dilution number, Y = replicate number).<br />
Hardware: Lightcycler 1.0 (Roche).<br />
Details:<br />
batsch1: Primers for rat SLC6A14, Taqman probes.<br />
batsch2: Primers for human SLC22A13, Taqman probes.<br />
batsch3: Primers for pig EMT, Taqman probes.<br />
batsch4: Primers for chicken ETT, SybrGreen.<br /> 
batsch5: Primers for human GAPDH, SybrGreen.
</p>
<p><b>boggy</b>:<br />
Setup: Six 10-fold dilutions with 2 replicates.<br />
Annotation: FX.Y (X = dilution number, Y = replicate number).<br />
Hardware: Chromo4 (BioRad).<br />
Details:<br />
Primers for a synthetic template, consisting of a secondary structure-optimized random sequence (129 bp), Syto-13 dye.
</p>
<p><b>competimer</b><br />
Setup: 7 concentrations of inhibitor, six 4-fold dilutions, 3 replicates.<br />
Annotation: X_Y_Z (X = inhibitor concentration, Y = dilution number, Z = replicate number).<br />
X: % competimer<br />
A 0%, B 5%, C 10%, D 20%, E 30%, F 40%, G 50%.<br />
Y: dilution factor (-fold)<br />
A 64, B 16, C 4, D 1, E 0.25, F 0.0625, G NTC.<br />
Hardware: Lightcycler 480 (Roche).<br />
Details:<br />
Primers for human AluSx repeats, competitive primers, SybrGreen I dye. NTCs are included.
</p>
<p><b>dil4reps94</b><br />
Setup: Four 10-fold dilutions with 94 replicates.<br />
Annotation: FX_Y (X = copy number, Y = replicate number).<br /> 
Hardware: CFX384 (BioRad).<br />
Details:<br />
Primers for the human MYCN gene, synthetic MYCN oligo used as template, SybrGreen I dye. NTCs were removed.
</p>
<p><b>dyemelt</b>:<br />
Setup: Melting curves of a 4-plex qPCR with different fluorescence dyes.<br />
Annotation: T0 (Temperature), EvaGreen, T1 (Temperature), SybrGreen.I, T2 (Temperature), Syto13.<br />
Hardware: Lightcycler 1.0 (Roche).<br />
Details:<br />
A melting curve analysis of a 4-plex real-time PCR on genomic DNA with AZF deletion-specific primers. The dyes used were EvaGreen, SybrGreen I and Syto-13.
</p>
<p><b>guescini1-2:</b><br />
Setup: Seven 10-fold dilutions with 12 replicates (<code>guescini1</code>). Five decreasing steps of PCR mix with 12 replicates (<code>guescini2</code>).<br />
Annotation: FX.Y (X = dilution number, Y = replicate number).<br />
Hardware: Lightcycler 480 (Roche).<br />
Details:<br />
Primers for NADH dehydrogenase 1, SybrGreen I dye, data is background subtracted.
</p>
<p><b>htPCR:</b><br />
Setup: High throughput experiment containing 8858 runs from a 95 x 96 PCR grid.<br />
Annotation: PX.Y (X = plate number, Y = well number).<br />
Hardware: Biomark HD (Fluidigm).<br />
Details:<br />
Proprietary primers, EvaGreen dye, data is ROX normalized.
</p>
<p><b>karlen1-3:</b><br />
Setup: 4 (5) dilutions (1-, 10-, 50-, 100-, (1000)-fold) with 5 (4) replicates in 4 samples. <br />
Annotation: FX.Y.Z (X = sample number, Y = dilution number, Z = replicate number).<br />
Hardware: ABI Prism 7700 (Applied Biosystems).<br />
Details:<br />
Primers for Caveolin (<code>karlen1</code>), Fibronectin (<code>karlen2</code>) and L27 (<code>karlen3</code>),  SybrGreen I dye, data is background subtracted.
</p>
<p><b>lievens1-3:</b><br />
Setup: Five 5-fold dilutions with 18 replicates (<code>lievens1</code>). Five different concentrations of isopropanol (2.5%, 0.5%, 0.1%, 0.02% and 0.004% (v/v)) with 18 replicates (<code>lievens2</code>). Five different amounts of tannic acid per reaction (5 ng, 1 ng, 0.2 ng, 0.04 ng and 0.008 ng) and 18 replicates (<code>lievens3</code>).<br />
Annotation: SX.Y (X = dilution number, Y = replicate number) (<code>lievens1</code>). SX.Y (X = concentration step, Y = replicate number) (<code>lievens2 &amp; lievens3</code>).<br /> 
Hardware: ABI7300 (ABI) or Biorad IQ5 (Biorad).<br />
Details:<br />
Primers for the soybean lectin endogene Le1, SybrGreen I dye.
</p>
<p><b>reps, reps2, reps3:</b><br />
Setup: Seven 10-fold dilutions with 4 replicates (<code>reps</code>). Five 4-fold dilutions with 3 replicates, 2 different cDNAs (<code>reps2</code>). Seven 4-fold dilutions with 3 replicates (<code>reps3</code>).<br />
Annotation: FX.Y (X = dilution number, Y = replicate number) (<code>reps &amp; reps3</code>). FX.Y.Z (X = cDNA number, Y = dilution number, Z = replicate number) (<code>reps2</code>).<br /> 
Hardware: Lightcycler 1.0 (Roche) (<code>reps</code>) or MXPro3000P (Stratagene) (<code>reps2 &amp; reps3</code>).<br />
Details:<br />
Primers for the S27a housekeeping gene, SybrGreen I dye, <code>reps3</code> was ROX-normalized.
</p>
<p><b>reps384</b><br />
Setup: A data frame with 379 replicate runs of a 384 microtiter plate.<br />
Annotation: A_A_X (X = replicate number).<br /> 
Hardware: CFX384 (BioRad).<br />
Details:<br />
Primers for the human MYCN gene, synthetic MYCN oligo used as template (15000 copies), SybrGreen I dye. NTCs were removed.
</p>
<p><b>rutledge</b>:<br />
Setup: Six 10-fold dilutions with 4 replicates in 5 individual batches.<br />
Annotation: X.RY.Z (X = dilution number, Y = batch number, Z = replicate number).<br />
Hardware: Opticon 2 (MJ Research).<br />
Details:<br />
Primers for a 102 bp amplicon, SybrGreen I dye, data is background subtracted.
</p>
<p><b>testdat</b>:<br />
Setup: Six 10-fold dilutions with 4 replicates.<br />
Annotation: FX.Y (X = dilution number, Y = replicate number).<br />
Hardware: Lightcycler 1.0 (Roche).<br />
Details:<br />
Same as <code>reps</code>, but each FX.3 has noisy data which fails to fit with the <code><a href="#topic+l5">l5</a></code> model, each FX.4 passes fitting but fails in sigmoidal structure detection by <code><a href="#topic+KOD">KOD</a></code>. Used for evaluating quality checking methods.
</p>
<p><b>vermeulen1-2:</b><br />
Setup: A subset of the first 20 samples for each of 64 genes (<code>vermeulen1</code>) and the corresponding dilution data for all 64 genes with five 10-fold dilutions and 3 replicates (<code>vermeulen2</code>).<br />
Annotation: X.Y (X = gene name, Y = sample name) (<code>vermeulen1</code>), X.STD_Y.Z (X = gene name, Y = copy number, Z = replicate number) (<code>vermeulen2</code>).<br />
Hardware: Lightcycler 480 (Roche).<br />
Details:<br />
Primers for AHCY, AKR1C1, ALUsq(Eurogentec), ARHGEF7, BIRC5, CAMTA1, CAMTA2, CD44, CDCA5, CDH5, CDKN3, CLSTN1, CPSG3, DDC, DPYSL3, ECEL1, ELAVL4, EPB41L3, EPHA5, EPN2, FYN, GNB1, HIVEP2, HMBS, HPRT1, IGSF4, INPP1, MAP2K4, MAP7, MAPT, MCM2, MRPL3, MTSS1, MYCN(4), NHLH2, NM23A, NRCAM, NTRK1, ODC1, PAICS, PDE4DIP, PIK3R1, PLAGL1, PLAT, PMP22, PRAME, PRDM2, PRKACB, PRKCZ, PTN, PTPRF, PTPRH, PTPRN2, QPCT, SCG2, SDHA(1), SLC25A5, SLC6A8, SNAPC1, TNFRSF, TYMS, UBC(2), ULK2 and WSB1. SybrGreen I dye.<br />
Originally, raw data was available at <em>http://medgen.ugent.be/jvermeulen</em>, but site is down. The complete (<code>vermeulen_all</code>) and smaller (<code>vermeulen_sub</code>) datasets can be downloaded from <a href="http://www.dr-spiess.de/qpcR/datasets.html">http://www.dr-spiess.de/qpcR/datasets.html</a>.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p><b>batsch1-5:</b><br />
Simultaneous fitting of real-time PCR data with efficiency of amplification modeled as Gaussian function of target fluorescence.<br />
Batsch A, Noetel A, Fork C, Urban A, Lazic D, Lucas T, Pietsch J, Lazar A, Schoemig E &amp; Gruendemann D.<br /> 
<em>BMC Bioinformatics</em> (2008), <b>9</b>: 95.
Additional File 5 to the paper.
</p>
<p><b>boggy:</b><br />
A Mechanistic Model of PCR for Accurate Quantification of Quantitative PCR Data.<br />
Boggy GJ &amp; Woolf PJ.<br />
<em>PLOS One</em> (2010), <b>5</b>: e12355.
Additional File S1 to the paper.
</p>
<p><b>dyemelt:</b><br />
A one-step real-time multiplex PCR for screening Y-chromosomal microdeletions without downstream
amplicon size analysis.<br />
Kozina V, Cappallo-Obermann H, Gromoll J &amp; Spiess AN.<br />
<em>PLOS One</em> (2011), <b>6</b>: e23174. Figure 2 to the paper.
</p>
<p><b>guescini1-2:</b><br />
A new real-time PCR method to overcome significant quantitative inaccuracy due to slight amplification inhibition.<br />
Guescini M, Sisti D, Rocchi MB, Stocchi L &amp; Stocchi V.<br />
<em>BMC Bioinformatics</em> (2008), <b>9</b>: 326. Supplemental Data 1 to the paper.
</p>
<p><b>htPCR:</b><br />
Kindly supplied by Roman Bruno.
</p>
<p><b>karlen1-3:</b><br />
Karlen Y, McNair A, Perseguers S, Mazza C &amp; Mermod N.<br />
Statistical significance of quantitative PCR.<br /> 
<em>BMC Bioinformatics</em> (2007), <b>20</b>: 131. Supplemental Data 2 to the paper.
</p>
<p><b>lievens1-3:</b><br />
Enhanced analysis of real-time PCR data by using a variable efficiency model: FPK-PCR.<br />
Lievens A, Van Aelst S, Van den Bulcke M &amp; Goetghebeur E.<br />
<em>Nucleic Acids Res</em> (2012), <b>40</b>: e10. Supplemental Data to the paper.
</p>
<p><b>reps, reps2, reps3:</b><br />
Andrej-Nikolai Spiess &amp; Nadine Mueller, Institute for Hormone and Fertlity Research, Hamburg, Germany.
</p>
<p><b>competimer, dil4reps94, reps384:</b><br />
Evaluation of qPCR curve analysis methods for reliable biomarker discovery: Bias, resolution, precision, and implications.<br />
Ruijter JM, Pfaffl MW, Zhao S, Spiess AN, Boggy G, Blom J, Rutledge RG, Sisti D, Lievens A, De Preter K, Derveaux S, Hellemans J, Vandesompele J.<br />
<em>Methods</em> (2012), [Epub ahead of print] PubMed PMID: 22975077.
</p>
<p><b>rutledge:</b><br />
Sigmoidal curve-fitting redefines quantitative real-time PCR with the prospective of developing automated high-throughput applications.<br />
Rutledge RG.<br />
<em>Nucleic Acids Research</em> (2004), <b>32</b>: e178. Supplemental Data 1 to the paper.
</p>
<p><b>vermeulen1-2:</b><br />
Predicting outcomes for children with neuroblastoma using a multigene-expression signature: a retrospective SIOPEN/COG/GPOH study.<br />
Vermeulen J, De Preter K, Naranjo A, Vercruysse L, Van Roy N, Hellemans J,
Swerts K, Bravo S, Scaruffi P, et. al.<br /> 
<em>Lancet Oncol</em> (2009), <b>10</b>:663-671.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## 'reps' dataset.
g1 &lt;- gl(7, 4)
ml1 &lt;- modlist(reps, model = l5)
plot(ml1, col = g1)

## 'rutledge' dataset.
g2 &lt;- gl(6, 20)
ml2 &lt;- modlist(rutledge, model = l5)
plot(ml2, col = g2)

## 'lievens1' dataset.
g3 &lt;- gl(5, 18)
ml3 &lt;- modlist(lievens1, model = l5)
plot(ml3, col = g3)

## End(Not run)
</code></pre>

<hr>
<h2 id='qpcR_functions'>The nonlinear/mechanistic models implemented in qpcR</h2><span id='topic+l7'></span><span id='topic+l6'></span><span id='topic+l5'></span><span id='topic+l4'></span><span id='topic+b7'></span><span id='topic+b6'></span><span id='topic+b5'></span><span id='topic+b4'></span><span id='topic+expGrowth'></span><span id='topic+expSDM'></span><span id='topic+linexp'></span><span id='topic+mak2'></span><span id='topic+mak2i'></span><span id='topic+mak3'></span><span id='topic+mak3i'></span><span id='topic+lin2'></span><span id='topic+cm3'></span><span id='topic+spl3'></span>

<h3>Description</h3>

<p>A summary of all available models implemented in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l7
l6
l5
l4
b7
b6
b5
b4
expGrowth 
expSDM
linexp
mak2
mak2i
mak3
mak3i
lin2
cm3
spl3
</code></pre>


<h3>Details</h3>

<p>The following nonlinear sigmoidal models are implemented:<br /><br />
<b>l7:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + k1 \cdot x + k2 \cdot x^2 + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}</code>
</p>

<p><b>l6:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + k \cdot x + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}</code>
</p>

<p><b>l5:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}</code>
</p>

<p><b>l4:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + \frac{d - c}{1 + exp(b(log(x) - log(e)))}</code>
</p>

<p><b>b7:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + k1 \cdot x + k2 \cdot x^2 + \frac{d - c}{(1 + exp(b(x - e)))^f}</code>
</p>

<p><b>b6:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + k \cdot x + \frac{d - c}{(1 + exp(b(x - e)))^f}</code>
</p>

<p><b>b5:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + \frac{d - c}{(1 + exp(b(x - e)))^f}</code>
</p>

<p><b>b4:</b> </p>
<p style="text-align: center;"><code class="reqn">f(x) = c + \frac{d - c}{1 + exp(b(x - e))}</code>
</p>

<p>The following nonlinear models for subsets of the curve are implemented:<br /><br />
<b>expGrowth</b>: </p>
<p style="text-align: center;"><code class="reqn">f(x) = \left. a \cdot exp(b \cdot x) + c \; \right|_{n_1 \leq x \leq n_2}</code>
</p>
<p><br />
<b>expSDM</b>: </p>
<p style="text-align: center;"><code class="reqn">f(x) = \left. a \cdot exp(b \cdot x) + c \; \right|_{1 \leq x \leq \rm{SDM}}</code>
</p>
<p><br />
<b>linexp</b>: </p>
<p style="text-align: center;"><code class="reqn">f(x) = \left. a \cdot exp(b \cdot x) + (k \cdot x) + c \; \right|_{1 \leq x \leq \rm{SDM}}</code>
</p>
<p><br />
<b>lin2</b>: </p>
<p style="text-align: center;"><code class="reqn">f(x) = \left. \eta \cdot log\left(exp\left(a1 \cdot \frac{x - \tau}{\eta}\right) + exp\left(a2 \cdot \frac{x - \tau}{\eta}\right)\right) + c \; \right|_{1 \leq x \leq \rm{SDM}}</code>
</p>
<p><br />
</p>
<p>The following mechanistic models are implemented:<br /><br />
<b>mak2 &amp; mak2i</b>: </p>
<p style="text-align: center;"><code class="reqn">F_n = \left. F_{n-1} + k \cdot log \left(1 + \left(\frac{F_{n-1}}{k}\right)\right) + Fb \; \right|_{1 \leq x \leq \rm{SDM}}</code>
</p>

<p><b>mak3 &amp; mak3i</b>: </p>
<p style="text-align: center;"><code class="reqn">F_n = \left. F_{n-1} + k \cdot log \left(1 + \left(\frac{F_{n-1}}{k}\right)\right) + (slope \cdot n + Fb) \; \right|_{1 \leq x \leq \rm{SDM}}</code>
</p>

<p><b>cm3</b>: </p>
<p style="text-align: center;"><code class="reqn">F_n = F_{n-1} \cdot \left(1 + \left(\frac{max - F_{n-1}}{max}\right) - \left(\frac{F_{n-1}}{Kd + F_{n-1}}\right)\right) + Fb</code>
</p>

<p>Other models:<br /><br />
<b>spl3</b>:  </p>
<p style="text-align: center;"><code class="reqn">S:[a, b] \to Real, a = n_0 &lt; n_1 &lt; \ldots &lt; n_{k-1} &lt; n_k = b</code>
</p>

<p><b>mak2</b> and <b>mak3</b> are two mechanistic models developed by Gregory Boggy (see references). The mechanistic models are a completely different approach in that the response value (Fluorescence) is not a function of the predictor value (Cycles), but a function of the preceeding response value, that is, <code class="reqn">F_n = f(F_{n-1})</code>. These are also called 'recurrence relations' or 'iterative maps'. The implementation of these models in the 'qpcR&rdquo; package is the following:<br />
1) In case of <code>mak2/mak2i</code> or <code>mak3/mak3i</code>, all cycles up from the second derivative maximum (SDM) of a four-parameter log-logistic model (l4) are chopped off. This is because these two models do not fit to a complete sigmoidal curve. An <code>offset</code> criterion from the SDM can be defined in <code><a href="#topic+pcrfit">pcrfit</a></code>, see there.<br /> 
2) For <code>mak2i/mak3i</code>, a grid of sensible starting values is created for all parameters in the model. For <code>mak2/mak3</code> the recurrence function is fitted directly (which is much faster, but may give convergence problems), so proceed to 7).<br />
3) For each combination of starting parameters, the model is fit.<br />
4) The acquired parameters are collected in a parameter matrix together with the residual sum-of-squares (RSS) of the fit.<br />
5) The parameter combination is selected that delivered the lowest RSS.<br />
6) These parameters are transferred to <code><a href="#topic+pcrfit">pcrfit</a></code>, and the data is refitted.<br />
7) Parameter <code class="reqn">D_0</code> can be used directly to calculate expression ratios, hence making the use of threshold cycles and efficiencies expendable.<br />
<b>cm3</b> is a mechanistic model by Carr &amp; Moore (see references). In contrast to the <code>mak</code> models, <code>cm3</code> models the complete curve, which might prove advantageous as no decision on curve subset selection has to be done. As in the <code>mak</code> models, <code class="reqn">D_0</code> is the essential parameter to use.<br />
<b>spl3</b> is a cubic spline function that treats each point as being exact. It is just implemented for comparison purposes.<br />
<b>lin2</b> is a bilinear model developed by P. Buchwald (see references). These are essentially two linear functions connected by a transition region. 
</p>
<p>The functions are defined as a list containing the following items:<br />
<code>$expr</code>        the function as an expression for the fitting procedure.<br />
<code>$fct</code>         the function defined as <code>f(x, parm)</code>.<br />
<code>$ssfct</code>       the self-starter function.<br />
<code>$d1</code>          the first derivative function.<br />
<code>$d2</code>          the second derivative function.<br />
<code>$inv</code>         the inverse function.<br />
<code>$expr.grad</code>   the function as an expression for gradient calculation.<br />
<code>$inv.grad</code>    the inverse functions as an expression for gradient calculation.<br />
<code>$parnames</code>    the parameter names.<br />
<code>$name</code>        the function name.<br />
<code>$type</code>        the function type as a character string.<br />  
</p>


<h3>Note</h3>

<p>For models <code>l6, l7, b6, b7</code> there are no explicit solutions to the inverse function. The calculation of <code>x</code> from <code>y</code> (Cycles from Fluorescence) is done using <code><a href="stats.html#topic+uniroot">uniroot</a></code> by minimizing <code>model$fct(x, parm)</code> - y in the interval [1, 100].
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p><b>4-parameter logistic</b>:<br />
Validation of a quantitative method for real time PCR kinetics.<br />
Liu W &amp; Saint DA.<br />
<em>Biochem Biophys Res Commun</em> (2002), <b>294</b>:347-53. 
</p>
<p>Standardized determination of real-time PCR efficiency from a single reaction set-up.<br />
Tichopad A, Dilger M, Schwarz G &amp; Pfaffl MW.<br />
<em>Nucleic Acids Res</em> (2003), <b>31</b>:e122. 
</p>
<p>Sigmoidal curve-fitting redefines quantitative real-time PCR with the prospective of developing automated high-throughput applications.<br />
Rutledge RG.<br />
<em>Nucleic Acids Res</em> (2004), <b>32</b>:e178. 
</p>
<p>A kinetic-based sigmoidal model for the polymerase chain reaction and its application to high-capacity absolute quantitative real-time PCR.<br />
Rutledge RG &amp; Stewart D.<br />
<em>BMC Biotechnol</em> (2008), <b>8</b>:47.
</p>
<p>Evaluation of absolute quantitation by nonlinear regression in probe-based real-time PCR.<br />
Goll R, Olsen T, Cui G &amp; Florholmen J.<br />
<em>BMC Bioinformatics</em> (2006), <b>7</b>:107
</p>
<p>Comprehensive algorithm for quantitative real-time polymerase chain reaction.<br />
Zhao S &amp; Fernald RD.<br />
<em>J Comput Biol</em> (2005), <b>12</b>:1047-64. 
</p>
<p><b>4-parameter log-logistic; 5-parameter logistic/log-logistic</b>:<br />
qpcR: an R package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis.<br />
Ritz C &amp; Spiess AN.<br />
<em>Bioinformatics</em> (2008), <b>24</b>:1549-51. 
</p>
<p>Highly accurate sigmoidal fitting of real-time PCR data by introducing a parameter for asymmetry.<br />
Spiess AN, Feig C &amp; Ritz C.<br />
<em>BMC Bioinformatics</em> (2008), <b>29</b>:221. 
</p>
<p><b>exponential model</b>:<br />
Standardized determination of real-time PCR efficiency from a single reaction set-up.<br />
Tichopad A, Dilger M, Schwarz G &amp; Pfaffl MW.<br />
<em>Nucleic Acids Research</em> (2003), <b>31</b>:e122.
</p>
<p>Comprehensive algorithm for quantitative real-time polymerase chain reaction.<br />
Zhao S &amp; Fernald RD.<br />
<em>J Comput Biol</em> (2005), <b>12</b>:1047-64.
</p>
<p><b>mak2, mak2i, mak3, mak3i</b>:<br />
A Mechanistic Model of PCR for Accurate Quantification of Quantitative PCR Data.<br />
Boggy GJ &amp; Woolf PJ.<br />
<em>PLoS ONE</em> (2010), <b>5</b>:e12355.
</p>
<p><b>lin2</b>:<br />
A general bilinear model to describe growth or decline time profiles.<br />
Buchwald P.<br />
<em>Math Biosci</em> (2007), <b>205</b>:108-36.
</p>
<p><b>cm3</b>:<br />
Robust quantification of polymerase chain reactions using global fitting.<br />
Carr AC &amp; Moore SD.<br />
<em>PLoS One</em> (2012), <b>7</b>:e37640.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, b4)
m2 &lt;- pcrfit(reps, 1, 2, b5)
m3 &lt;- pcrfit(reps, 1, 2, l6)
m4 &lt;- pcrfit(reps, 1, 2, l7)

## Get the second derivative
## curve of m2.
d2 &lt;- b5$d2(m2$DATA[, 1], coef(m2))
plot(m2)
lines(d2, col = 2)  
</code></pre>

<hr>
<h2 id='qpcR.news'>Display news and changes of qpcR package versions</h2><span id='topic+qpcR.news'></span>

<h3>Description</h3>

<p>Displays the latest changes (new functions, bug fixes etc.) of the different package versions in a text window. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpcR.news(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qpcR.news_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code><a href="base.html#topic+file.show">file.show</a></code>. Usually needs no entry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qpcR.news()    
</code></pre>

<hr>
<h2 id='ratiobatch'>Calculation of ratios in a batch format for multiple genes/samples</h2><span id='topic+ratiobatch'></span>

<h3>Description</h3>

<p>For multiple qPCR data from type 'pcrbatch', this function calculates ratios between samples, using normalization against one or more reference gene(s), if supplied. Multiple reference genes can be averaged according to Vandesompele <em>et al</em>. (2002). The input may be single qPCR data or (more likely) data containing replicates. This is essentially a version of <code><a href="#topic+ratiocalc">ratiocalc</a></code> that can handle multiple reference genes and genes-of-interest with multiple (replicated) samples as found in large-scale qPCR runs such as 96- or 384-Well plates. A boxplot representation for all Monte-Carlo simulations, permutations and error propagations including 95% confidence intervals is calculated for each ratio calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratiobatch(data, group = NULL, plot = TRUE, 
           combs = c("same", "across", "all"), 
           type.eff = "mean.single", which.cp = "cpD2", 
           which.eff = "sli", refmean = FALSE,
           dataout = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ratiobatch_+3A_data">data</code></td>
<td>
<p>multiple qPCR data generated by <code><a href="#topic+pcrbatch">pcrbatch</a></code>.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_group">group</code></td>
<td>
<p>a character vector defining the replicates (if any) of control/treatment samples and reference genes/genes-of-interest. See 'Details'</p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code id="ratiobatch_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, plots are displayed for the diagnostics and analysis.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_combs">combs</code></td>
<td>
<p>type of combinations between different samples (i.e. r1s1:g1s2). See 'Details'.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_type.eff">type.eff</code></td>
<td>
<p>type of efficiency averaging used. Same as in <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_which.eff">which.eff</code></td>
<td>
<p>efficiency obtained from which method. Same as in <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_which.cp">which.cp</code></td>
<td>
<p>threshold cycle obtained from which method. Same as in <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>   
<tr><td><code id="ratiobatch_+3A_dataout">dataout</code></td>
<td>
<p>an optional file path where to store the result dataframe.</p>
</td></tr>   
<tr><td><code id="ratiobatch_+3A_refmean">refmean</code></td>
<td>
<p>logical. If <code>TRUE</code>, multiple reference are averaged before calculating the ratios. See 'Details'.</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the steps of analysis are shown in the console window</p>
</td></tr>
<tr><td><code id="ratiobatch_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to <code><a href="#topic+ratiocalc">ratiocalc</a></code>, the replicates of the 'pcrbatch' data columns are to be defined as a character vector with the following abbreviations:
</p>
<p>&quot;g1s1&quot;:   gene-of-interest #1 in treatment sample #1<br />
&quot;g1c1&quot;:   gene-of-interest #1 in control sample #1<br />
&quot;r1s1&quot;:   reference gene #1 in treatment sample #1<br />
&quot;r1c1&quot;:   reference gene #1 in control sample #1
</p>
<p>There is no distinction between the different technical replicates so that three different runs of gene-of-interest #1 in treatment sample #2 are defined as c(&quot;g1s2&quot;, &quot;g1s2&quot;, &quot;g1s2&quot;). 
</p>
<p>Example:<br />
1 control sample with 2 genes-of-interest (2 technical replicates), 2 treatment samples with 2 genes-of-interest (2 technical replicates):<br />
&quot;g1c1&quot;, &quot;g1c1&quot;, &quot;g2c1&quot;, &quot;g2c1&quot;, &quot;g1s1&quot;, &quot;g1s1&quot;, &quot;g1s2&quot;, &quot;g1s2&quot;, &quot;g2s1&quot;, &quot;g2s1&quot;, &quot;g2s2&quot;, &quot;g2s2&quot;
</p>
<p>The ratios are calculated for all pairwise 'rc:gc' and 'rs:gs' combinations according to:<br />
For all control samples <code class="reqn">i = 1 \ldots I</code> and treatment samples <code class="reqn">j = 1 \ldots J</code>, reference genes <code class="reqn">k = 1 \ldots K</code> and genes-of-interest <code class="reqn">l = 1 \ldots L</code>, calculate<br />
</p>
<p>Without reference genes:  </p>
<p style="text-align: center;"><code class="reqn">\frac{E(g_lc_i)^{cp(g_lc_i)}}{E(g_ls_j)^{cp(g_ls_j)}}</code>
</p>

<p>With reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{E(g_lc_i)^{cp(g_lc_i)}}{E(g_ls_j)^{cp(g_ls_j)}}/\frac{E(r_kc_i)^{cp(r_kc_i)}}{E(r_ks_j)^{cp(r_ks_j)}}</code>
</p>

<p>For the mechanistic models <code>makX/cm3</code> the following is calculated:<br />
</p>
<p>Without reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(g_ls_j)}{D_0(g_lc_i)}</code>
</p>
 
<p>With reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(g_ls_j)}{D_0(g_lc_i)}/\frac{D_0(r_ks_j)}{D_0(r_kc_i)}</code>
</p>

<p>Efficiencies can be taken from the individual curves or averaged from the replicates as described in the documentation to <code><a href="#topic+ratiocalc">ratiocalc</a></code>. It is also possible to give external efficiencies (i.e. acquired by some calibration curve) to the function. See 'Examples'. The different combinations of <code>type.eff</code>, <code>which.eff</code> and <code>which.cp</code> can yield very different results in ratio calculation. We observed a relatively stable setup which minimizes the overall variance using the combination
</p>
<p><code>type.eff = "mean.single"</code>     # averaging efficiency across replicates<br />
<code>which.eff = "sli"</code>            # taking efficiency from the sliding window method<br />
<code>which.cp = "sig"</code>             # using the second derivative maximum of a sigmoidal fit 
</p>
<p>This is also the default setup in the function. The lowest variance can be obtained for the threshold cycles if the asymmetric 5-parameter <code>l5</code> model is used in the <code><a href="#topic+pcrbatch">pcrbatch</a></code> function. 
</p>
<p>There are three different combination setups possible when calculating the pairwise ratios:<br />
<code>combs = "same"</code>: reference genes, genes-of-interest, control and treatment samples are the <code>same</code>, i.e. <code class="reqn">i = k, m = o, j = n, l = p</code>.<br />
<code>combs = "across"</code>: control and treatment samples are the same, while the genes are combinated, i.e. <code class="reqn">i \neq k, m \neq o, j = n, l = p, </code>.<br />
<code>combs = "all"</code>: reference genes, genes-of-interest, control and treatment samples are all combinated, i.e. <code class="reqn">i \neq k, m \neq o, j \neq n, l \neq p</code>.
</p>
<p>The last setting rarely makes sense and is very time-intensive. <code>combs = "same"</code> is the most common setting, but <code>combs = "across"</code> also makes sense if different genes-of-interest and reference gene combinations should be calculated for the same samples.
</p>
<p>From version 1.3-6, <code>ratiobatch</code> has the option of averaging several reference genes, as described in Vandesompele <em>et al.</em> (2002). Threshold cycles and efficiency values for any <code class="reqn">i</code> reference genes with <code class="reqn">j</code> replicates are averaged before calculating the ratios using the averaged value <code class="reqn">\mu_r</code> for all reference genes in a control/treatment sample. The overall error <code class="reqn">\sigma_r</code> is obtained by error propagation. The whole procedure is accomplished by function <code><a href="#topic+refmean">refmean</a></code>, which can be used as a stand-alone function, but is most conveniently used inside <code>ratiobatch</code> setting <code>refmean = TRUE</code>. See in 'Examples'. For details about reference gene averaging by <code><a href="#topic+refmean">refmean</a></code>, see there. If none or only one per sample is found, the data is analyzed without using reference gene averaging/error propagation.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>resList</code></td>
<td>
<p>a list with the results from the combinations as list items.</p>
</td></tr>
<tr><td><code>resDat</code></td>
<td>
<p>a dataframe with the results in colums.</p>
</td></tr>
</table>
<p>Both <code>resList</code> and <code>resDat</code> have as names the combinations used for the ratio calculation.
If <code>plot = TRUE</code>, a boxplot matrix from the Monte-Carlo simulations, permutations and error propagations is given including 95% confidence intervals as coloured horizontal lines.
</p>


<h3>Note</h3>

<p>This function can be used quite conveniently when the raw fluorescence data from the 96- or 384-well runs come from Excel with 'Cycles' in the first column and run descriptions as explained above in the remaining column descriptions (such as 'r1c6'). Examples for a proper format can be found under <a href="http://www.dr-spiess.de//qpcR//datasets.html">http://www.dr-spiess.de//qpcR//datasets.html</a>. This data may then be imported into <span class="rlang"><b>R</b></span> by <code>dat &lt;- pcrimport()</code>.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Accurate normalization of real-time quantitative RT-PCR data by geometric averaging of multiple internal control genes.<br />
Vandesompele J, De Preter K, Pattyn F, Poppe B, Van Roy N, De Paepe A, Speleman F.<br />
<em>Genome Biol</em> (2002), <b>3</b>: research0034-research0034.11.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## One reference gene, one gene of interest,
## one control and one treatment sample with 
## 4 replicates each =&gt; 1 x Ratio = 1.
DAT1 &lt;- pcrbatch(reps, fluo = c(2:9, 2:9), model = l5)
GROUP1 &lt;- c("g1c1", "g1c1", "g1c1", "g1c1",
            "g1s1", "g1s1", "g1s1", "g1s1", 
            "r1c1", "r1c1", "r1c1", "r1c1",
            "r1s1", "r1s1", "r1s1", "r1s1") 
ratiobatch(DAT1, GROUP1, refmean = FALSE)  

## One reference gene, one gene of interest,
## two control and two treatment samples with 
## 2 replicates each =&gt; 4 x Ratio = 1.
DAT2 &lt;- pcrbatch(reps, fluo = c(2:9, 2:9), model = l5)
GROUP2 &lt;- c("g1c1", "g1c1", "g1c2", "g1c2",
            "g1s1", "g1s1", "g1s2", "g1s2", 
            "r1c1", "r1c1", "r1c2", "r1c2",
            "r1s1", "r1s1", "r1s2", "r1s2") 
ratiobatch(DAT2, GROUP2, refmean = FALSE)

## Two reference genes, one gene of interest,
## one control and one treatment samples with 
## 4 replicates each =&gt; 2 x Ratio = 1.
DAT3 &lt;- pcrbatch(reps, fluo = c(2:9, 2:9, 2:9), model = l5)
GROUP3 &lt;- c("g1c1", "g1c1", "g1c1", "g1c1",
            "g1s1", "g1s1", "g1s1", "g1s1", 
            "r1c1", "r1c1", "r1c1", "r1c1",
            "r1s1", "r1s1", "r1s1", "r1s1",
            "r2c1", "r2c1", "r2c1", "r2c1",
            "r2s1", "r2s1", "r2s1", "r2s1") 
ratiobatch(DAT3, GROUP3, refmean = FALSE)

## Two reference genes, one gene of interest,
## one control and one treatment samples with 
## 4 replicates each.
## Reference genes are averaged =&gt; 1 x Ratio = 1.
DAT4 &lt;- pcrbatch(reps, fluo = c(2:9, 2:9, 2:9), model = l5)
GROUP4 &lt;- c("g1c1", "g1c1", "g1c1", "g1c1",
            "g1s1", "g1s1", "g1s1", "g1s1", 
            "r1c1", "r1c1", "r1c1", "r1c1",
            "r1s1", "r1s1", "r1s1", "r1s1",
            "r2c1", "r2c1", "r2c1", "r2c1",
            "r2s1", "r2s1", "r2s1", "r2s1") 
ratiobatch(DAT4, GROUP4, refmean = TRUE)

## Same as above, but use same efficiency E = 2.         
ratiobatch(DAT4, GROUP4, which.eff = 2) 
                   
## No reference genes, two genes-of-interest, 
## two control and two treatment samples with
## 2 replicates each, efficiency from sigmoidal model. 
DAT6 &lt;- pcrbatch(reps, fluo = 2:17, model = l5)
GROUP6 &lt;- c("g1s1", "g1s1", "g1s2", "g1s2",
            "g2s1", "g2s1", "g2s2", "g2s2",
            "g1c1", "g1c1", "g1c2", "g1c2",
            "g2c1", "g2c1", "g2c2", "g2c2")            
ratiobatch(DAT6, GROUP6, which.eff = "sig")

## Same as above, but using a mechanistic model (mak3).
## BEWARE: type.eff must be "individual"!
DAT7 &lt;- pcrbatch(reps, fluo = 2:17, model = l5,
                 methods = c("sigfit", "mak3"))
GROUP7 &lt;- c("g1s1", "g1s1", "g1s2", "g1s2",
            "g2s1", "g2s1", "g2s2", "g2s2",
            "g1c1", "g1c1", "g1c2", "g1c2",
            "g2c1", "g2c1", "g2c2", "g2c2")
ratiobatch(DAT7, GROUP7, which.eff = "mak", 
           type.eff = "individual")

## Using external efficiencies from a 
## calibration curve. Can be supplied by the
## user from external calibration (or likewise),
## but in this example acquired by function 'calib'.
ml1 &lt;- modlist(reps, fluo = 2:25, model = l5)
DIL &lt;- rep(10^(5:0), each = 4) 
EFF &lt;- calib(refcurve = ml1, dil = DIL)$eff   
DAT8 &lt;- pcrbatch(ml1)
GROUP8 &lt;- c(rep("g1s1", 4), rep("g1s2", 4),
            rep("g1s3", 4), rep("g1s4", 4), 
            rep("g1s5", 4), rep("g1c1", 4)) 
ratiobatch(DAT8, GROUP8, which.eff = EFF)

## End(Not run)
</code></pre>

<hr>
<h2 id='ratiocalc'>Calculation of ratios from qPCR runs with/without reference genes</h2><span id='topic+ratiocalc'></span>

<h3>Description</h3>

<p>For multiple qPCR data from type 'pcrbatch', this function calculates ratios between two samples (control/treatment) of a gene-of-interest, using normalization against a reference gene, if supplied. The input can be single qPCR data or (more likely) data containing replicates. Errors and confidence intervals for the obtained ratios can be calculated by Monte-Carlo simulation, a permutation approach similar to the popular REST software and by error propagation. Statistical significance for the ratios is calculated by a permutation approach of randomly reallocated vs. non-reallocated data. See 'Details'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratiocalc(data, group = NULL, 
          which.eff = c("sig", "sli", "exp", "mak", "cm3", "ext"), 
          type.eff = c("individual", "mean.single", "median.single", 
                       "mean.pair", "median.pair"),
          which.cp = c("cpD2", "cpD1", "cpE", "cpR", "cpT", "Cy0", "ext"),
          ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ratiocalc_+3A_data">data</code></td>
<td>
<p>multiple qPCR data generated by <code><a href="#topic+pcrbatch">pcrbatch</a></code>.</p>
</td></tr>
<tr><td><code id="ratiocalc_+3A_group">group</code></td>
<td>
<p>a character vector defining the replicates (if any) of control/treatment samples and reference genes/genes-of-interest. See 'Details'.</p>
</td></tr>
<tr><td><code id="ratiocalc_+3A_which.eff">which.eff</code></td>
<td>
<p>efficiency calculated by which method. Defaults to sigmoidal fit. See output of <code><a href="#topic+pcrbatch">pcrbatch</a></code>. Alternatively, a numeric value for all runs, a vector of external efficiencies with one element per run or directly transferred from <code><a href="#topic+ratioPar">ratioPar</a></code>.</p>
</td></tr>
<tr><td><code id="ratiocalc_+3A_type.eff">type.eff</code></td>
<td>
<p>type of efficiency pre-processing prior to error analysis. See 'Details'.</p>
</td></tr>
<tr><td><code id="ratiocalc_+3A_which.cp">which.cp</code></td>
<td>
<p>type of threshold cycles to be used for the analysis. See output of <code><a href="#topic+efficiency">efficiency</a></code>. Alternatively, a vector of external threshold cycles with one element per run or directly transferred from <code><a href="#topic+ratioPar">ratioPar</a></code>.</p>
</td></tr>   
<tr><td><code id="ratiocalc_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+propagate">propagate</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The replicates for the data columns are to be defined as a character vector with the following abbreviations:<br />
</p>
<p>&quot;gs&quot;:   gene-of-interest in treatment sample<br />
&quot;gc&quot;:   gene-of-interest in control sample<br />
&quot;rs&quot;:   reference gene in treatment sample<br />
&quot;rc&quot;:   reference gene in control sample<br />
</p>
<p>There is no distinction between the different runs of the same sample, so that three different runs of a gene-of-interest in a treatment sample are defined as c(&quot;gs&quot;, &quot;gs&quot;, &quot;gs&quot;). The error analysis calculates statistics from ALL replicates, so that a further sub-categorization of runs is superfluous. NOTE: If the setup consists of different sample or gene combinations, use <code><a href="#topic+ratiobatch">ratiobatch</a></code>!
</p>
<p>Examples:<br />
No replicates: NULL.<br />
2 runs with 2 replicates each, no reference gene: c(&quot;gs&quot;, &quot;gs&quot;, &quot;gs&quot;, &quot;gs&quot;, &quot;gc&quot;, &quot;gc&quot;, &quot;gc&quot;, &quot;gc&quot;).<br />
1 run with two replicates each and reference gene:  c(&quot;gs&quot;, &quot;gs&quot;, &quot;gc&quot;, &quot;gc&quot;, &quot;rs&quot;, &quot;rs&quot;, &quot;rc&quot;, &quot;rc&quot;).<br />
</p>
<p><code>type.eff</code> defines the pre-processing of the efficiencies before being transferred to <code><a href="#topic+propagate">propagate</a></code>. The qPCR community sometimes uses single efficiencies, or averaged over replicates etc., so that different settings were implemented. In detail, these are the following:<br />
</p>
<p>&quot;individual&quot;:     The individual efficiencies from each run are used.<br />
&quot;mean.single&quot;:    Efficiencies are averaged over all replicates.<br />
&quot;median.single&quot;:  Same as above but median instead of mean.<br /> 
&quot;mean.pair&quot;:      Efficiencies are averaged from all replicates of treatment sample AND control.<br />
&quot;median.pair&quot;:    Same as above but median instead of mean.<br />
</p>
<p>Efficiencies can be taken from the individual curves or averaged from the replicates as described in the documentation to <code><a href="#topic+ratiocalc">ratiocalc</a></code>. The different combinations of <code>type.eff</code>, <code>which.eff</code> and <code>which.cp</code> can yield very different results in ratio calculation. We observed a relatively stable setup which minimizes the overall variance using the combination
</p>
<p><code>type.eff = "mean.single"</code>     # averaging efficiency across replicates<br />
<code>which.eff = "sli"</code>            # taking efficiency from the sliding window method<br />
<code>which.cp = "sig"</code>             # using the second derivative maximum of a sigmoidal fit<br /> 
</p>
<p>The ratios are calculated according to the following formulas:<br />
Without reference gene: </p>
<p style="text-align: center;"><code class="reqn">\frac{E(gc)^{cp(gc)}}{E(gs)^{cp(gs)}}</code>
</p>

<p>With reference gene: </p>
<p style="text-align: center;"><code class="reqn">\frac{E(gc)^{cp(gc)}}{E(gs)^{cp(gs)}}/\frac{E(rc)^{cp(rc)}}{E(rs)^{cp(rs)}}</code>
</p>
  
<p>The permutation approach permutates threshold cycles and efficiency replicates within treatment and control samples. The treatment/control samples (and their respective efficiencies) are tied together, which is similar to the popular REST software approach (&quot;pairwise-reallocation test&quot;). Ratios are calculated for each permutation and compared to ratios obtained if samples were randomly reallocated from the treatment to the control group. Three p-values are calculated from all permutations that gave a higher/equal/lower ratio than the original data. The resulting p-values are thus an indication for the significance in any direction AGAINST the null hypothesis that ratios calculated by permutation are just by chance.
</p>
<p>If the mechanistic <code>mak2/mak2i/mak3/mak3i/cm3</code> models are used in <code><a href="#topic+pcrbatch">pcrbatch</a></code>, set <code>which.eff = "mak"</code> for ratio calculations from the <code class="reqn">D0</code> values of the model:<br />
Without reference gene: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(gs)}{D_0(gc)}</code>
</p>

<p>With reference gene: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(gs)}{D_0(gc)}/\frac{D_0(rs)}{D_0(rc)}</code>
</p>

<p>Confidence values are returned for all three methods (Monte Carlo, permutation, error propagation) as follows:<br />
Monte-Carlo:  From the evaluations of the Monte-Carlo simulated data.<br />
Permutation:  From the evaluations of the within-group permutated data.<br />
Propagation:  From the propagated error, assuming normality.
</p>


<h3>Value</h3>

<p>A list with the following components:<br />
<code>data</code>: the data that was transferred to <code><a href="#topic+propagate">propagate</a></code> for the error analysis.<br />
<code>data.Sim, data.Perm, data.Prop, derivs, covMat</code>: The complete output from <code><a href="#topic+propagate">propagate</a></code>.<br />
<code>summary</code>: a summary of the results obtained from the Monte Carlo simulation, permutation and error propagation. 
</p>


<h3>Note</h3>

<p>The error calculated from qPCR data by <code><a href="#topic+propagate">propagate</a></code> often seems quite high. This largely depends on the error of the base (i.e. efficiency) of the exponential function. The error usually decreases when setting <code>use.cov = TRUE</code> in the <code>...</code> part of the function. It can be debated anyhow, if the variables 'efficiency' and 'threshold cycles' have a covariance structure. As the efficiency is deduced at the second derivative maximum of the sigmoidal curve, variance in the second should show an effect on the first, such that the use of a var-cov matrix might be feasible. It is also commonly encountered that the propagated error is much higher when using reference genes, as the number of partial derivative functions increases.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Analysis of relative gene expression data using real-time quantitative PCR and the 2(-Delta Delta C(T)) method.<br />
Livak KJ &amp; Schmittgen TD.<br />
<em>Methods</em> (2001), <b>25</b>: 402-428.<br />
</p>
<p>Standardized determination of real-time PCR efficiency from a single reaction set-up.<br />
Tichopad A, Dilger M, Schwarz G, Pfaffl MW.<br />
<em>Nucleic Acids Res</em> (2003), <b>31</b>: e122.<br />
</p>
<p>Validation of a quantitative method for real time PCR kinetics.<br />
Liu W &amp; Saint DA.<br />
<em>Biochem Biophys Res Commun</em> (2002), <b>294</b>: 347-53.<br />
</p>
<p>Relative expression software tool (REST) for group-wise comparison and statistical analysis of relative expression results in real-time PCR.<br />
Pfaffl MW, Horgan GW, Dempfle L.<br />
<em>Nucl Acids Res</em> (2002), <b>30</b>: e36. 
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+ratioPar">ratioPar</a></code>, which is a much better and simpler way if only external threshold cycles/efficiencies should be used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Only treatment sample and control,
## no reference gene, 4 replicates each.
## Individual efficiencies for error calculation. 
DAT1 &lt;- pcrbatch(reps, fluo = 2:9, model = l4)
GROUP1 &lt;- c("gs", "gs", "gs", "gs", "gc", "gc", "gc", "gc")
RES1 &lt;- ratiocalc(DAT1, group = GROUP1, which.eff = "sli",
                 type.eff = "individual", which.cp = "cpD2")       
RES1$summary

## Not run: 
## Gets even better using averaged efficiencies 
## over all replicates.
## p-value indicates significant upregulation in 
## comparison to randomly reallocated 
## samples (similar to REST software)
RES2 &lt;- ratiocalc(DAT1, GROUP1, which.eff = "sli", 
                  type.eff = "mean.single", which.cp = "cpD2")                 
RES2$summary    

## Using reference data.
## Toy example is same data as above
## but replicated as reference such
## that the ratio should be 1.
DAT3 &lt;- pcrbatch(reps, fluo = c(2:9, 2:9), model = l4)
GROUP3 &lt;- c("gs", "gs", "gs", "gs", 
            "gc", "gc", "gc", "gc",
            "rs", "rs", "rs", "rs",
            "rc", "rc", "rc", "rc")
RES3 &lt;- ratiocalc(DAT3, GROUP3, which.eff = "sli", 
                  type.eff = "mean.single", which.cp = "cpD2")                  
RES3$summary

## Using one of the mechanistic models
## =&gt; ratios are calculated from the replicate
## D0 values, without reference genes.
DAT4 &lt;- pcrbatch(reps, fluo = 2:9, 
                 methods = c("sigfit", "sliwin", "mak3"))
GROUP4 &lt;- c("gs", "gs", "gs", "gs", "gc", "gc", "gc", "gc")
RES4 &lt;- ratiocalc(DAT4, GROUP4, which.eff = "mak")
RES4$summary

## Example without replicates 
## =&gt; no Monte-Carlo simulations
## and hence no plots.
DAT5 &lt;- pcrbatch(reps, fluo = 2:5, model = l4)
GROUP5 &lt;- c("gs", "gc", "rs", "rc")
RES5 &lt;- ratiocalc(DAT5, GROUP5, which.eff = "sli", 
                  type.eff = "individual", which.cp = "cpD2")
RES5$summary

## Using external efficiencies.
DAT6 &lt;- pcrbatch(reps, fluo = 2:9, model = l5)
GROUP6 &lt;- c("gs", "gs", "gs", "gs", "gc", "gc", "gc", "gc")
EFF6 &lt;- rep(c(1.72, 1.76), c(4, 4)) 
RES6 &lt;- ratiocalc(DAT6, GROUP6, which.eff = EFF6, 
                 type.eff = "individual", which.cp = "cpD2")       
RES6$summary

## Using external efficiencies AND
## external threshold cycles.
DAT7 &lt;- pcrbatch(reps, fluo = 2:9, model = l5)
GROUP7 &lt;- c("gs", "gs", "gs", "gs", "gc", "gc", "gc", "gc")
EFF7 &lt;- rep(c(1.72, 1.76), c(4, 4))
CP7 &lt;- c(15.44, 15.33, 14.84, 15.34, 18.89, 18.71, 18.13, 17.22)
RES7 &lt;- ratiocalc(DAT7, GROUP7, which.eff = EFF7, 
                 type.eff = "individual", which.cp = CP7)       
RES7$summary

## Compare 'ratiocalc' to REST software
## using the data from the REST 2008
## manual (http://rest.gene-quantification.info/).
## We supply the threshold cycles/efficiencies from the 
## manual as external data to 'dummy' pcrbatch data.
## BETTER: use 'ratioPar' function!
cp.rc &lt;- c(26.74, 26.85, 26.83, 26.68, 27.39, 27.03, 26.78, 27.32)
cp.rs &lt;- c(26.77, 26.47, 27.03, 26.92, 26.97, 26.97, 26.07, 26.3, 26.14, 26.81)
cp.gc &lt;- c(27.57, 27.61, 27.82, 27.12, 27.76, 27.74, 26.91, 27.49)
cp.gs &lt;- c(24.54, 24.95, 24.57, 24.63, 24.66, 24.89, 24.71, 24.9, 24.26, 24.44)
eff.rc &lt;- rep(1.97, 8)
eff.rs &lt;- rep(1.97, 10)
eff.gc &lt;- rep(2.01, 8)
eff.gs &lt;- rep(2.01, 10)
CP8 &lt;- c(cp.rc, cp.rs, cp.gc, cp.gs)
EFF8 &lt;- c(eff.rc, eff.rs, eff.gc, eff.gs) 
DAT8 &lt;- pcrbatch(rutledge, 1, 2:37, model = l4)
GROUP8 &lt;- rep(c("rc", "rs", "gc", "gs"), c(8, 10, 8, 10))
RES8 &lt;- ratiocalc(DAT8, GROUP8, which.eff = EFF8, which.cp = CP8)
RES8$summary
## =&gt; Confidence interval: 2.983/9.996
## REST 2008 manual, page 10: 2.983/9.996

## End(Not run)
</code></pre>

<hr>
<h2 id='ratioPar'>Calculation of ratios in a batch format from external PCR parameters</h2><span id='topic+ratioPar'></span>

<h3>Description</h3>

<p>Starting from external PCR parameters such as threshold cycles/efficiency values commonly obtained from other programs, this function calculates ratios between samples, using normalization against one or more reference gene(s), if supplied. By default, multiple reference genes are averaged according to Vandesompele <em>et al</em>. (2002). The input can be single qPCR data or (more likely) data containing replicates. It is similar to <code><a href="#topic+ratiobatch">ratiobatch</a></code> and can handle multiple reference genes and genes-of-interest with multiple (replicated) samples as found in large-scale qPCR runs such as 96- or 384-Well plates. The results are automatically stored as a file or copied into the clipboard. A boxplot representation for all Monte-Carlo simulations, permutations and error propagations including 95% confidence intervals is also given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratioPar(group = NULL, effVec = NULL, cpVec = NULL, 
         type.eff = "individual", plot = TRUE, 
         combs = c("same", "across", "all"), 
         refmean = FALSE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ratioPar_+3A_group">group</code></td>
<td>
<p>a character vector defining the replicates (if any) of control/treatment samples and reference genes/genes-of-interest. See 'Details'.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_effvec">effVec</code></td>
<td>
<p>a vector of efficiency values with the same length of <code>group</code>.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_cpvec">cpVec</code></td>
<td>
<p>a vector of threshold cycle values with the same length of <code>group</code>.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_type.eff">type.eff</code></td>
<td>
<p>type of efficiency averaging used. Same as in <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, plots are displayed for the diagnostics and analysis.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_combs">combs</code></td>
<td>
<p>type of combinations between different samples (i.e. r1s1:g1s2). See 'Details'.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_refmean">refmean</code></td>
<td>
<p>logical. If <code>TRUE</code>, multiple reference are averaged before calculating the ratios. See 'Details'.</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the steps of analysis are shown in the console window</p>
</td></tr>
<tr><td><code id="ratioPar_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As in <code><a href="#topic+ratiobatch">ratiobatch</a></code>, the replicates are to be defined as a character vector with the following abbreviations:
</p>
<p>&quot;g1s1&quot;:   gene-of-interest #1 in treatment sample #1<br />
&quot;g1c1&quot;:   gene-of-interest #1 in control sample #1<br />
&quot;r1s1&quot;:   reference gene #1 in treatment sample #1<br />
&quot;r1c1&quot;:   reference gene #1 in control sample #1
</p>
<p>There is no distinction between the different technical replicates so that three different runs of gene-of-interest #1 in treatment sample #2 are defined as c(&quot;g1s2&quot;, &quot;g1s2&quot;, &quot;g1s2&quot;). 
</p>
<p>Example:<br />
1 control sample with 2 genes-of-interest (2 technical replicates), 2 treatment samples with 2 genes-of-interest (2 technical replicates):<br />
&quot;g1c1&quot;, &quot;g1c1&quot;, &quot;g2c1&quot;, &quot;g2c1&quot;, &quot;g1s1&quot;, &quot;g1s1&quot;, &quot;g1s2&quot;, &quot;g1s2&quot;, &quot;g2s1&quot;, &quot;g2s1&quot;, &quot;g2s2&quot;, &quot;g2s2&quot;
</p>
<p>The ratios are calculated for all pairwise 'rc:gc' and 'rs:gs' combinations according to:<br />
For all control samples <code class="reqn">i = 1 \ldots I</code> and treatment samples <code class="reqn">j = 1 \ldots J</code>, reference genes <code class="reqn">k = 1 \ldots K</code> and genes-of-interest <code class="reqn">l = 1 \ldots L</code>, calculate<br />
</p>
<p>Without reference genes:  </p>
<p style="text-align: center;"><code class="reqn">\frac{E(g_lc_i)^{cp(g_lc_i)}}{E(g_ls_j)^{cp(g_ls_j)}}</code>
</p>

<p>With reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{E(g_lc_i)^{cp(g_lc_i)}}{E(g_ls_j)^{cp(g_ls_j)}}/\frac{E(r_kc_i)^{cp(r_kc_i)}}{E(r_ks_j)^{cp(r_ks_j)}}</code>
</p>

<p>For the mechanistic models <code>makX/cm3</code> the following is calculated:<br />
</p>
<p>Without reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(g_ls_j)}{D_0(g_lc_i)}</code>
</p>
 
<p>With reference genes: </p>
<p style="text-align: center;"><code class="reqn">\frac{D_0(g_ls_j)}{D_0(g_lc_i)}/\frac{D_0(r_ks_j)}{D_0(r_kc_i)}</code>
</p>

<p>Efficiencies can be taken from the individual samples or averaged from the replicates as described in the documentation to <code><a href="#topic+ratiocalc">ratiocalc</a></code>. Different settings in <code>type.eff</code> can yield very different results in ratio calculation. We observed a relatively stable setup which minimizes the overall variance using the <code>type.eff = "mean.single"</code>.   
</p>
<p>There are three different combination setups possible when calculating the pairwise ratios:<br />
<code>combs = "same"</code>: reference genes, genes-of-interest, control and treatment samples are the <code>same</code>, i.e. <code class="reqn">i = k, m = o, j = n, l = p</code>.<br />
<code>combs = "across"</code>: control and treatment samples are the same, while the genes are combinated, i.e. <code class="reqn">i \neq k, m \neq o, j = n, l = p, </code>.<br />
<code>combs = "all"</code>: reference genes, genes-of-interest, control and treatment samples are all combinated, i.e. <code class="reqn">i \neq k, m \neq o, j \neq n, l \neq p</code>.
</p>
<p>The last setting rarely makes sense and is very time-intensive. <code>combs = "same"</code> is the most common setting, but <code>combs = "across"</code> also makes sense if different genes-of-interest and reference gene combinations should be calculated for the same samples.
</p>
<p><code>ratioPar</code> has an option of averaging several reference genes, as described in Vandesompele <em>et al.</em> (2002). Threshold cycles and efficiency values for any <code class="reqn">i</code> reference genes with <code class="reqn">j</code> replicates are averaged before calculating the ratios using the averaged value <code class="reqn">\mu_r</code> for all reference genes in a control/treatment sample. The overall error <code class="reqn">\sigma_r</code> is obtained by error propagation. The whole procedure is accomplished by function <code><a href="#topic+refmean">refmean</a></code>, which can be used as a stand-alone function, but is most conveniently used inside <code>ratioPar</code> setting <code>refmean = TRUE</code>. For details about reference gene averaging by <code><a href="#topic+refmean">refmean</a></code>, see there.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>resList</code></td>
<td>
<p>a list with the results from the combinations as list items.</p>
</td></tr>
<tr><td><code>resDat</code></td>
<td>
<p>a dataframe with the results in colums.</p>
</td></tr>
</table>
<p>Both <code>resList</code> and <code>resDat</code> have as names the combinations used for the ratio calculation.
If <code>plot = TRUE</code>, a boxplot matrix from the Monte-Carlo simulations, permutations and error propagations is given including 95% confidence intervals as coloured horizontal lines.
</p>


<h3>Note</h3>

<p>This function can be used quite conveniently when the PCR parameters are from 96- or 384-well runs plates and exported to a tab-delimited file.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Accurate normalization of real-time quantitative RT-PCR data by geometric averaging of multiple internal control genes.<br />
Vandesompele J, De Preter K, Pattyn F, Poppe B, Van Roy N, De Paepe A, Speleman F.<br />
<em>Genome Biol</em> (2002), <b>3</b>: research0034-research0034.11.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## One control sample, two treatment samples, 
## one gene-of-interest, two reference genes, 
## two replicates each. Replicates are averaged,
## but reference genes not, so that we have 4 ratios.
GROUP1 &lt;- c("r1c1", "r1c1", "r2c1", "r2c1", "g1c1", "g1c1",
           "r1s1", "r1s1", "r1s2", "r1s2", "r2s1", "r2s1",
           "r2s2", "r2s2", "g1s1", "g1s1", "g1s2", "g1s2") 
EFF1 &lt;- c(1.96, 2.03, 1.60, 1.67, 1.91, 1.97, 1.53, 1.61, 1.87, 
          1.92, 1.52, 1.58, 1.84, 1.90, 1.49, 1.56, 1.83, 1.87)
CP1 &lt;- c(15.44, 15.33, 14.84, 15.34, 18.89, 18.71, 18.13, 17.22, 22.06, 
        21.85, 21.03, 20.92, 25.34, 25.12, 25.00, 24.62, 28.39, 28.28)
RES1 &lt;- ratioPar(group = GROUP1, effVec = EFF1, cpVec= CP1, refmean = FALSE)


## Not run: 
## Same as above, but now we average the two
## reference genes, so that we have 2 ratios.
RES2 &lt;- ratioPar(group = GROUP1, effVec = EFF1, cpVec= CP1, refmean = TRUE)

## Two control samples, one treatment sample, 
## one gene-of-interest, one reference gene, 
## no replicates. Reference gene has efficiency = 1.8,
## gene-of-interest has efficiency = 1.9.
GROUP3 &lt;- c("r1c1", "r1c2", "g1c1", "g1c2", 
            "r1s1", "g1s1") 
EFF3 &lt;- c(1.8, 1.8, 1.9, 1.9, 1.8, 1.9)
CP3 &lt;- c(17.25, 17.38, 22.52, 23.18, 21.42, 19.83)
RES3 &lt;- ratioPar(group = GROUP3, effVec = EFF3, cpVec= CP3, refmean = TRUE)
                   
## One control sample, one treatment sample, 
## three genes-of-interest, no reference gene, 
## three replicates. Using efficiency from sigmoidal model. 
GROUP4 &lt;- c("g1c1", "g1c1", "g1c1", "g2c1", "g2c1", "g2c1", "g3c1", "g3c1", "g3c1",
            "g1s1", "g1s1", "g1s1", "g2s1", "g2s1", "g2s1", "g3s1", "g3s1", "g3s1")
EFF4 &lt;- c(1.79, 1.71, 1.83, 1.98, 1.85, 1.76, 1.76, 1.91, 1.84, 1.80, 1.79, 1.91,
          1.88, 1.79, 1.78, 1.89, 1.86, 1.81)
CP4 &lt;- c(15.68, 15.84, 14.47, 14.96, 18.97, 19.04, 17.65, 16.76, 22.11, 22.03, 20.43, 
         20.36, 25.29, 25.29, 24.27, 23.99, 28.34, 28.38)
RES4 &lt;- ratioPar(group = GROUP4, effVec = EFF4, cpVec= CP4, refmean = TRUE)

## Compare to REST software using the data from the 
## REST 2008 manual (http://rest.gene-quantification.info/)
cp.rc &lt;- c(26.74, 26.85, 26.83, 26.68, 27.39, 27.03, 26.78, 27.32)
cp.rs &lt;- c(26.77, 26.47, 27.03, 26.92, 26.97, 26.97, 26.07, 26.3, 26.14, 26.81)
cp.gc &lt;- c(27.57, 27.61, 27.82, 27.12, 27.76, 27.74, 26.91, 27.49)
cp.gs &lt;- c(24.54, 24.95, 24.57, 24.63, 24.66, 24.89, 24.71, 24.9, 24.26, 24.44)
eff.rc &lt;- rep(1.97, 8)
eff.rs &lt;- rep(1.97, 10)
eff.gc &lt;- rep(2.01, 8)
eff.gs &lt;- rep(2.01, 10)
CP5 &lt;- c(cp.rc, cp.rs, cp.gc, cp.gs)
EFF5 &lt;- c(eff.rc, eff.rs, eff.gc, eff.gs) 
GROUP5 &lt;- rep(c("r1c1", "r1s1", "g1c1", "g1s1"), c(8, 10, 8, 10))
RES5 &lt;- ratioPar(group = GROUP5, effVec = EFF5, cpVec = CP5)
RES5$resDat

## End(Not run)        
</code></pre>

<hr>
<h2 id='refmean'>Averaging of multiple reference genes</h2><span id='topic+refmean'></span>

<h3>Description</h3>

<p>This function averages the expression of several reference genes before calculation of gene expression ratios by <code><a href="#topic+ratiocalc">ratiocalc</a></code> or <code><a href="#topic+ratiobatch">ratiobatch</a></code>. The method is similar to that described in Vandesompele <em>et al.</em> (2002), but uses <b>arithmetic</b> averaging of threshold cycles/efficiencies and <b>not geometric</b> averaging of relative expression values. This is equivalent, as discussed in 'Details' and as shown in 'Examples'. An essential extension of this method is, that if replicates for the reference genes are supplied, the threshold cycles and efficiencies are subjected to error propagation prior to ratio calculation. The propagated error is then included in the calculation of the gene expression ratios, as advocated in Nordgard <em>et al.</em> (2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>refmean(data, group, which.eff = c("sig", "sli", "exp", "mak", "ext"),
        type.eff = c("individual", "mean.single"), 
        which.cp = c("cpD2", "cpD1", "cpE", "cpR", "cpT", "Cy0", "ext"),
        verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="refmean_+3A_data">data</code></td>
<td>
<p>multiple qPCR data generated by <code><a href="#topic+pcrbatch">pcrbatch</a></code>.</p>
</td></tr>
<tr><td><code id="refmean_+3A_group">group</code></td>
<td>
<p>a character vector defining the replicates (if any) of control/treatment samples and reference genes/genes-of-interest. See 'Details'</p>
</td></tr>
<tr><td><code id="refmean_+3A_which.eff">which.eff</code></td>
<td>
<p>efficiency calculated by which method. Defaults to sigmoidal fit. Can also be a value such as 1.8, as shown in 'Examples'. See <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>
<tr><td><code id="refmean_+3A_type.eff">type.eff</code></td>
<td>
<p>using individual or averaged efficiencies for the replicates of a reference gene. See 'Details'.</p>
</td></tr>
<tr><td><code id="refmean_+3A_which.cp">which.cp</code></td>
<td>
<p>type of threshold cycles to be used for the analysis. Defaults to cpD2. See <code><a href="#topic+ratiocalc">ratiocalc</a></code>.</p>
</td></tr>  
<tr><td><code id="refmean_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the steps of analysis are shown in the console window.</p>
</td></tr>
<tr><td><code id="refmean_+3A_...">...</code></td>
<td>
<p>parameters to be supplied to <code><a href="#topic+propagate">propagate</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As in <code><a href="#topic+ratiobatch">ratiobatch</a></code>, the samples are to be defined as a character vector in the style of &quot;g1s1&quot;, &quot;g1c1&quot;, &quot;r1s1&quot; and &quot;r1c1&quot; etc. If <code>refmean</code> is used as a standalone function or switched on in <code><a href="#topic+ratiobatch">ratiobatch</a></code> using <code>refmean = TRUE</code>, different reference genes per control/treatment samples are averaged when supplied either as single runs or as replicates. 
</p>
<p>Examples (omitting genes-of-interest in control/treatment samples):<br />
2 reference genes, 2 replicates each:<br />
c(&quot;r1s1&quot;, &quot;r1s1, &quot;r2s1&quot;, &quot;r2s1&quot;, &quot;r1c1&quot;, &quot;r1c1, &quot;r2c1&quot;, &quot;r2c1&quot;, ...).<br />
3 reference genes, no replicates:<br />
c(&quot;r1s1&quot;, &quot;r2s1, &quot;r3s1&quot;, &quot;r1c1&quot;, &quot;r2c1, &quot;r3c1&quot;, ...)
</p>
<p>Averaging of multiple reference genes is accomplished the following way:<br />
Given <code class="reqn">i</code> reference genes with <code class="reqn">j</code> replicates in a sample, all replicates <code class="reqn">r_{ij}</code> are used for calculating mean <code class="reqn">\mu_{r_i}</code> and standard deviation <code class="reqn">\sigma_{r_i}</code> of the threshold cycles and efficiencies. The overall (grand) mean <code class="reqn">\mu_r</code> and propagated error <code class="reqn">\sigma_r</code> is calculated using <code><a href="#topic+propagate">propagate</a></code> with first-order Taylor expansion including covariance: <code class="reqn">\sigma_r = F_{r_i}C_{r_i}F_{r_i}^T</code>. Finally, a vector of length <code class="reqn">L = n(r_{ij})</code> containing equidistant numbers <code class="reqn">X = (x_1, x_2, x_3, \ldots x_L)</code> with mean <code class="reqn">\mu_r</code> and standard deviation <code class="reqn">\sigma_r</code> is generated for a new overall reference gene <code class="reqn">r_1</code>. This is done using the internal function <code>qpcR:::makeStat</code> which calculates a shifted (<code class="reqn">\mu_r</code>) and scaled (<code class="reqn">\sigma_r</code>) Z-transformation on a vector <code class="reqn">x_1 \ldots x_L</code>:
</p>
<p style="text-align: center;"><code class="reqn">Z_i = \mu_r + \frac{(x_i - \bar{X})}{\sigma_X} \cdot \sigma_r</code>
</p>

<p>The new <code class="reqn">Z_i</code> threshold cycle and efficiency values replace all values of <code class="reqn">r_{ij}</code> in <code>data</code>. When using <code><a href="#topic+ratiobatch">ratiobatch</a></code>, this modified data is then used for the ratio calculation, again using <code><a href="#topic+propagate">propagate</a></code> to calculate errors for ratios using the <code class="reqn">Z_i</code> values as mentioned above.<br />
By using logarithmic identities (<a href="http://en.wikipedia.org/wiki/Logarithmic_identities">http://en.wikipedia.org/wiki/Logarithmic_identities</a>), it can be shown that the <b>geometric</b> mean can be transformed to the <b>arithmetic</b> mean by logarithmation (assuming constant <code class="reqn">E</code>):
</p>
<p style="text-align: center;"><code class="reqn">\left( \prod_{i=1}^n E^{x_i} \right)^{\frac{1}{n}} = \frac{1}{n} \cdot \log_E \left( \prod_{i=1}^n E^{x_i} \right) = \frac{1}{n} \sum_{i=1}^n x_i</code>
</p>

<p>Hence, <b>arithmetic</b> averaging of the threshold cycles <b>BEFORE</b> ratio calculation is the same as doing <b>geometric</b> averaging on relative quantities <b>AFTER</b> ratio calculation. This is demonstrated in 'Examples' and also mentioned in the geNorm manual (<a href="http://www.gene-quantification.com/geNorm_manual.pdf">http://www.gene-quantification.com/geNorm_manual.pdf</a>) in Q8 (page 12).
</p>
<p>When setting <code>type.eff = "individual"</code> (default), all efficiencies from replicates of a reference gene in a control/treatment sample <code class="reqn">E(r_{ij})</code> are used for calculating mean <code class="reqn">\mu_{E(r_i)}</code> and standard deviation <code class="reqn">\sigma_{E(r_i)}</code>, the latter being used for calculating a propagated error for all reference gene efficiencies <code class="reqn">\sigma_{E(r)}</code>. If <code>type.eff = "mean.single"</code>, all <code class="reqn">E(r_{ij})</code> values from the replicates are set to the same value <code class="reqn">\mu_{E(r_i)}</code>, that is, there is no variation assumed between the different <code class="reqn">E(r_{ij})</code>. In this case, <code class="reqn">\sigma_{E(r_i)} = 0</code>, so that no error of the replicates is propagated to <code class="reqn">\sigma_{E(r)}</code>. This results in smaller overall errors of the output, but it can be debated if this is a realistic approach, hence both settings were implemented.
</p>
<p><code>which.eff</code> can be supplied with an efficiency value such as <code>1.8</code>, which is then used as the efficiency for all reference runs <code class="reqn">E(r_{ij})</code>.
</p>


<h3>Value</h3>

<p>The same dataset <code>data</code> which was supplied to the function, but with modified threshold cycle/efficiency values in which the values are created per sample in a way, that they have the mean of all averaged reference genes and the same standard deviation as obtained by error propagation. See 'Details' for a more thorough explanation. Furthermore, a modified label vector <code>"NAME_mod"</code> is written to the global environment (if <code>"NAME"</code> was supplied for <code>group</code>) in which the different reference gene labels are aggregated, i.e. c(&quot;r1c1&quot;, &quot;r2c1&quot;, &quot;r3c1&quot;) will become c(&quot;r1c1&quot;, &quot;r1c1&quot;, &quot;r1c1&quot;). This new label vector is also attached as an attribute to the output data and can be obtained by <code>attr(RES1, "group")</code>.
</p>


<h3>Note</h3>

<p>The function checks stringently if the same number of different reference genes are used for control and treatment samples, although the number of replicates may differ.<br />
Example:<br />
GROUP &lt;- c(&quot;r1c1&quot;, &quot;r1c1&quot;, &quot;r2c1&quot;, &quot;r2c1&quot;, &quot;r1s1&quot;, &quot;r2s1&quot;) will work (2 reference genes in control/treatment samples), but GROUP &lt;- c(&quot;r1c1&quot;, &quot;r2c1&quot;, &quot;r3c1&quot;, &quot;r1s1&quot;, &quot;r1s1&quot;, &quot;r1s2&quot;, &quot;r1s2&quot;, &quot;r2s1&quot;, &quot;r2s1&quot;) will not work (3 reference genes in controls, only 2 in treatment samples).
Also, when no or only one reference genes are detected, the original data is not averaged and returned unchanged.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Accurate normalization of real-time quantitative RT-PCR data by geometric averaging of multiple internal control genes.<br />
Vandesompele J, De Preter K, Pattyn F, Poppe B, Van Roy N, De Paepe A, Speleman F.<br />
<em>Genome Biol</em> (2002), <b>3</b>: research0034-research0034.11.<br />
</p>
<p>Error propagation in relative real-time reverse transcription polymerase chain reaction quantification models: the balance between accuracy and precision.<br />
Nordgard O, Kvaloy JT, Farmen RK, Heikkil? R.<br />
<em>Anal Biochem</em> (2006), <b>356</b>: 182-193.<br />
</p>


<h3>See Also</h3>

<p>In <code><a href="#topic+ratiobatch">ratiobatch</a></code>, reference gene averaging can be done automatically by setting <code>refmean = TRUE</code>. See there.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Replacing the reference gene values by
## averaged ones in the original data.
## =&gt; RES1 is new dataset.
## =&gt; GROUP1_mod in global environment is
## new labeling vector.
DAT1 &lt;- pcrbatch(reps, fluo = 2:19, model = l5)
GROUP1 &lt;- c("r1c1", "r1c1", "r2c1", "r2c1", "g1c1", "g1c1",
           "r1s1", "r1s1", "r1s2", "r1s2", "r2s1", "r2s1",
           "r2s2", "r2s2", "g1s1", "g1s1", "g1s2", "g1s2") 
RES1 &lt;- refmean(DAT1, GROUP1, which.eff = "sig", which.cp = "cpD2")

## Using three reference genes without replicates
## and then 'ratiobatch'.
## This can also be called in 'ratiobatch' directly
## with parameter 'refmean = TRUE'. See there.
## In this example, already averaged dataset and 
## new labeling vector are supplied to 'ratiobatch', 
## so one has to set 'refmean = FALSE'.
DAT2 &lt;- pcrbatch(reps, fluo = 2:9, model = l5)
GROUP2 &lt;- c("r1c1", "r2c1", "r3c1", "g1c1", "r1s1", "r2s1", "r3s1", "g1s1" ) 
RES2 &lt;- refmean(DAT2, GROUP2, which.eff = "sig", which.cp = "cpD2")
ratiobatch(RES2, GROUP2_mod, refmean = FALSE)

## Comparison between 'refmean' ct-value arithmetic averaging
## and 'geNorm' relative quantities geometric averaging
## using data from the geNorm manual (2008), page 6.
## We will use HK1-HK3 as in the manual (no replicates).
## First we create a 'pcrbatch' dataset and then 
## override the ct values with those of the manual and all
## efficiencies with E = 2. Sample A is considered as control sample.
DAT3 &lt;- pcrbatch(reps, fluo = 2:17, model = l5)
DAT3[8, -1] &lt;- c(32.10, 27.00, 34.90, 23.00,
                 33.30, 28.40, 36.10, 24.20,
                 31.00, 27.50, 34.00, 26.35,
                 30.50, 28.20, 33.00, 25.45)
DAT3[1, -1] &lt;- 2
GROUP3 &lt;- c("r1c1", "r2c1", "r3c1", "g1c1",
            "r1s1", "r2s1", "r3s1", "g1s1",
            "r1s2", "r2s2", "r3s2", "g1s2",
            "r1s3", "r2s3", "r3s3", "g1s3")
RES3 &lt;- refmean(DAT3, GROUP3, which.eff = "sig", which.cp = "cpD2")
ratiobatch(RES3, GROUP3_mod, which.cp = "cpD2",
           which.eff = "sig", refmean = FALSE)
## Results:
## r1c1:g1c1:r1s1:g1s1  refmean 1.0497
##                      geNorm 1.0472 (2.351/2.245)
## r1c1:g1c1:r1s2:g1s2  refmean 0.0693
##                      geNorm 0.0695 (0.156/2.245)
## r1c1:g1c1:r1s3:g1s3  refmean 0.1081
##                      geNorm 0.1074 (0.241/2.245)
## Slight differences are due to rounding.

## End(Not run)
</code></pre>

<hr>
<h2 id='replist'>Amalgamation of single data models into a model containing replicates</h2><span id='topic+replist'></span>

<h3>Description</h3>

<p>Starting from a 'modlist' containing qPCR models from single data, <code>replist</code> amalgamates the models according to the grouping structure as defined in <code>group</code>. The result is a 'replist' with models obtained from fitting the replicates by <code><a href="#topic+pcrfit">pcrfit</a></code>. A kinetic outlier detection and removal option is included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replist(object, group = NULL, check = "none",
        checkPAR = parKOD(), remove = c("none", "KOD"), 
        names = c("group", "first"), doFit = TRUE, opt = FALSE, 
        optPAR = list(sig.level = 0.05, crit = "ftest"), 
        verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="replist_+3A_object">object</code></td>
<td>
<p>an object of class 'modlist'.</p>
</td></tr>
<tr><td><code id="replist_+3A_group">group</code></td>
<td>
<p>a vector defining the replicates for each group.</p>
</td></tr>
<tr><td><code id="replist_+3A_check">check</code></td>
<td>
<p>which method to use for kinetic outlier detection. Either <code>none</code> or any of the methods in <code><a href="#topic+KOD">KOD</a></code>.</p>
</td></tr>
<tr><td><code id="replist_+3A_checkpar">checkPAR</code></td>
<td>
<p>parameters to be supplied to the <code>check</code> method, see <code><a href="#topic+KOD">KOD</a></code>.</p>
</td></tr>
<tr><td><code id="replist_+3A_remove">remove</code></td>
<td>
<p>which runs to remove. Either <code>none</code> or those that failed from the method defined in <code>check</code>.</p>
</td></tr>
<tr><td><code id="replist_+3A_names">names</code></td>
<td>
<p>how to name the grouped fit. Either 'group_1, ...' or the first name of the replicates.</p>
</td></tr>
<tr><td><code id="replist_+3A_dofit">doFit</code></td>
<td>
<p>logical. If set to <code>FALSE</code>, the replicate data is only aggregated without doing a refitting. See 'Details'.</p>
</td></tr>
<tr><td><code id="replist_+3A_opt">opt</code></td>
<td>
<p>logical. Should model selection be applied to the final model?</p>
</td></tr>
<tr><td><code id="replist_+3A_optpar">optPAR</code></td>
<td>
<p>parameters to be supplied to <code><a href="#topic+mselect">mselect</a></code>.</p>
</td></tr>
<tr><td><code id="replist_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code>, the analysis is printed to the console.</p>
</td></tr>
<tr><td><code id="replist_+3A_...">...</code></td>
<td>
<p>other parameters to be supplied to <code><a href="#topic+mselect">mselect</a></code>.</p>
</td></tr>    
</table>


<h3>Details</h3>

<p>As being defined by <code>group</code>, the 'modlist' is split into groups of runs and these amalgamated into a nonlinear model. Runs which have failed to be fitted by <code><a href="#topic+modlist">modlist</a></code> are automatically removed and <code>group</code> is updated (that is, the correpsonding entries also removed) prior to fitting the replicate model by <code><a href="#topic+pcrfit">pcrfit</a></code>. Model selection can be applied to the final replicate model by setting <code>opt = TRUE</code> and changing the parameters in <code>optPAR</code>. If <code>check</code> is set to any of the methods in <code>"KOD"</code>, kinetic outliers are identified and optionally removed, if <code>remove</code> is set to <code>"KOD"</code>.<br />
If <code>doFit = FALSE</code>, the replicate data is only aggregated and no refitting is done. This is useful when plotting replicate data by some grouping vector. See 'Examples'.
</p>


<h3>Value</h3>

<p>An object of class 'replist' containing the replicate models of class 'nls'/'pcrfit'.  
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modlist">modlist</a></code>, <code><a href="#topic+pcrfit">pcrfit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    
## Convert 'modlist' into 'replist'.
ml1 &lt;- modlist(reps, model = l4)
rl1 &lt;- replist(ml1, group = gl(7, 4))
plot(rl1)
summary(rl1[[1]])

## Optimize model based on Akaike weights.
rl2 &lt;- replist(ml1, group = gl(7, 4), opt = TRUE, 
               optPARS = list(crit = "weights"))
plot(rl2)

## Not run: 
## Remove kinetic outliers,
## use first replicate name for output.
ml3 &lt;- modlist(reps, model = l4)
rl3 &lt;- replist(ml3, group = gl(7, 4), check = "uni1", 
               remove = "KOD", names = "first")
plot(rl3, which = "single")

## Just aggregation and no refitting.
ml4 &lt;- modlist(reps, model = l4)
rl4 &lt;- replist(ml4, group = gl(7, 4), doFit = FALSE)
plot(rl4, which = "single")

## Scenario 1:
## automatic removal of runs that failed to
## fit during 'modlist' by using 'testdat' set.
ml5 &lt;- modlist(testdat, model = l5)
rl5 &lt;- replist(ml5, gl(6, 4))
plot(rl5, which = "single")

## Scenario 2:
## automatic removal of runs that failed to
## fit during 'replist':
## samples F3.1-F3.4 is set to 1.
dat1 &lt;- reps
ml6 &lt;- modlist(dat1)
ml6[[9]]$DATA[, 2] &lt;- 1
ml6[[10]]$DATA[, 2] &lt;- 1
ml6[[11]]$DATA[, 2] &lt;- 1
ml6[[12]]$DATA[, 2] &lt;- 1
rl6 &lt;- replist(ml6, gl(7, 4))
plot(rl6, which = "single")

## End(Not run)
</code></pre>

<hr>
<h2 id='resplot'>An (overlayed) residuals barplot</h2><span id='topic+resplot'></span>

<h3>Description</h3>

<p>A plotting function which displays a barplot of the (standardized) residuals. The bars are colour-coded with heat colours proportional to the residual value. As default, the residuals are displayed together with the points of the fitted PCR curve. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resplot(object, overlay = TRUE, ylim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resplot_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit.</p>
</td></tr> 
<tr><td><code id="resplot_+3A_overlay">overlay</code></td>
<td>
<p>logical. If <code>TRUE</code>, the residuals are plotted on top of the fitted curve, else alone.</p>
</td></tr>
<tr><td><code id="resplot_+3A_ylim">ylim</code></td>
<td>
<p>graphical ylim values for tweaking the scale and position of the barplot overlay.</p>
</td></tr>
<tr><td><code id="resplot_+3A_...">...</code></td>
<td>
<p>any other parameters to be passed to <code><a href="graphics.html#topic+barplot">barplot</a></code>.</p>
</td></tr> 	
</table>


<h3>Details</h3>

<p>If replicate data is present in the fitted curve, the residuals from all replicates <code class="reqn">i, j</code> are summed up from the absolute values: <code class="reqn">Y_i = \sum{|\hat{\varepsilon}_{i, j}|}</code>.
</p>


<h3>Value</h3>

<p>A plot as described above.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create l5 model and plot 
## standardized residuals.
m1 &lt;- pcrfit(reps, 1, 2, l5)
resplot(m1)

## Not run: 
## Using replicates.
m2 &lt;- pcrfit(reps, 1, 2:5, l5)
resplot(m2)

## End(Not run)
</code></pre>

<hr>
<h2 id='resVar'>Residual variance of a fitted model</h2><span id='topic+resVar'></span>

<h3>Description</h3>

<p>Calculates the residual variance for objects of class <code>nls</code>, <code>lm</code>, <code>glm</code>, <code>drc</code> or any other models from which <code><a href="stats.html#topic+coef">coef</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> can be extracted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resVar(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resVar_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">resVar = \frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{n - p}</code>
</p>

<p>where <code class="reqn">n</code> is the number of response values and <code class="reqn">p</code> the number of parameters in the model.
</p>


<h3>Value</h3>

<p>The residual variance of the fit.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
resVar(m1)
</code></pre>

<hr>
<h2 id='RMSE'>Root-mean-squared-error of a fitted model</h2><span id='topic+RMSE'></span>

<h3>Description</h3>

<p>Calculates the root-mean-squared-error (RMSE) for objects of class <code>nls</code>, <code>lm</code>, <code>glm</code>, <code>drc</code> or any other models from which <code><a href="stats.html#topic+residuals">residuals</a></code> can be extacted. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(object, which = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RMSE_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_which">which</code></td>
<td>
<p>a subset of the curve to be used for RMSE calculation. If not defined, the complete curve is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">RMSE = \sqrt{\overline{(y_i-\hat{y}_i)^2}}</code>
</p>



<h3>Value</h3>

<p>The root-mean-squared-error from the fit or a part thereof.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## For a curve subset.
m1 &lt;- pcrfit(reps, 1, 2, l5)
RMSE(m1, 10:15)
</code></pre>

<hr>
<h2 id='Rsq'>R-square value of a fitted model</h2><span id='topic+Rsq'></span>

<h3>Description</h3>

<p>Calculates the <code class="reqn">R^2</code> value for objects of class <code>nls</code>, <code>lm</code>, <code>glm</code>, <code>drc</code> or any other models from which <code><a href="stats.html#topic+fitted">fitted</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> can be extracted. Since version 1.2-9 it calculates a weighted <code class="reqn">R^2</code> if the object has an item <code>object$weights</code> containing weighting values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rsq(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rsq_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the most general definition of <code class="reqn">R^2</code>: </p>
<p style="text-align: center;"><code class="reqn">R^2 \equiv 1 - \frac{RSS}{TSS}</code>
</p>
<p> where
</p>
<p style="text-align: center;"><code class="reqn">RSS = \sum_{i=1}^{n}w_i \cdot (y_i-\hat{y}_i)^2</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">TSS = \sum_{i=1}^{n}w_i \cdot (y_i - \bar{y})^2</code>
</p>
<p> using the weighted mean </p>
<p style="text-align: center;"><code class="reqn">\bar{y} = \frac{\sum_{i=1}^{n}w_ix_i}{\sum_{i=1}^{n}w_i}</code>
</p>
 


<h3>Value</h3>

<p>The <code class="reqn">R^2</code> value of the fit.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
Rsq(m1)   
</code></pre>

<hr>
<h2 id='Rsq.ad'>Adjusted R-square value of a fitted model</h2><span id='topic+Rsq.ad'></span>

<h3>Description</h3>

<p>Calculates the adjusted <code class="reqn">R_{adj}^2</code> value for objects of class <code>nls</code>, <code>lm</code>, <code>glm</code>, <code>drc</code> or any other models from which <code><a href="stats.html#topic+fitted">fitted</a></code>, <code><a href="stats.html#topic+residuals">residuals</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> can be extracted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rsq.ad(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rsq.ad_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">R_{adj}^2 = 1 - \frac{n - 1}{n - p} \cdot (1 - R^2)</code>
</p>

<p>with <code class="reqn">n</code> = sample size, <code class="reqn">p</code> = number of parameters.
</p>


<h3>Value</h3>

<p>The adjusted <code class="reqn">R_{adj}^2</code> value of the fit.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Single model.
m1 &lt;- pcrfit(reps, 1, 2, l7)
Rsq.ad(m1)

## Compare different models with increasing
## number of parameters.
ml1 &lt;- lapply(list(l4, l5, l6), function(x) pcrfit(reps, 1, 2, x))
sapply(ml1, function(x) Rsq.ad(x)) 
</code></pre>

<hr>
<h2 id='RSS'>Residual sum-of-squares of a fitted model</h2><span id='topic+RSS'></span>

<h3>Description</h3>

<p>Calculates the residual sum-of-squares for objects of class <code>nls</code>, <code>lm</code>, <code>glm</code>, <code>drc</code> or any other models from which <code><a href="stats.html#topic+residuals">residuals</a></code> can be extacted. From version 1.3-6, this function uses weights, if <code>object</code> has an item <code>$weights</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSS(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RSS_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">RSS = \sum_{i=1}^{n}w_i \cdot (y_i-\hat{y}_i)^2</code>
</p>



<h3>Value</h3>

<p>The (weighted) residual sum-of-squares from the fit.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
RSS(m1)
</code></pre>

<hr>
<h2 id='sliwin'>Calculation of qPCR efficiency by the 'window-of-linearity' method</h2><span id='topic+sliwin'></span>

<h3>Description</h3>

<p>A linear model of Cycles versus log(Fluorescence) is fit within a sliding window of defined size(s) and within a defined border. Regression coefficients are calculated for each window, and at the point of maximum regression (log-linear range) or least variation in slope, parameters such as PCR efficiency and initial template fluorescence are calculated. From version 1.3-5, an approach &quot;not unlike&quot; to Ruijter et al. (2009) has been implemented, in which baseline values can be iteratively subtracted from the data prior to fitting the sliding window. See 'Details' for more information.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sliwin(object, wsize = 6, basecyc = 1:6, base = 0, border = NULL,
       type = c("rsq", "slope"), plot = TRUE, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sliwin_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_wsize">wsize</code></td>
<td>
<p>the size(s) of the sliding window(s), default is <code>6</code>. A sequence such as <code>4:6</code> can be used to optimize the window size.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_basecyc">basecyc</code></td>
<td>
<p>if <code>base != 0</code>, which cycles to use for an initial baseline estimation based on the averaged fluorescence values.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_base">base</code></td>
<td>
<p>either <code>0</code> for no baseline optimization, or a scalar defining multiples of the standard deviation of all baseline points obtained from <code>basecyc</code>. These are iteratively subtracted from the raw data. See 'Details' and 'Examples'.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_border">border</code></td>
<td>
<p>either <code>NULL</code> (default) or a two-element vector which defines the border from the take-off point to points nearby the upper asymptote (saturation phase). See 'Details'.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_type">type</code></td>
<td>
<p>selection of the window with best baseline + maximum <code class="reqn">R^2</code> (<code>"rsq"</code>) or best baseline + minimal variance in slope + maximum <code class="reqn">R^2</code> (<code>"slope"</code>).</p>
</td></tr>  
<tr><td><code id="sliwin_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, the result is plotted with the logarithmized curve, sliding window, regression line and baseline.</p>
</td></tr>	
<tr><td><code id="sliwin_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, more information is displayed in the console window.</p>
</td></tr>
<tr><td><code id="sliwin_+3A_...">...</code></td>
<td>
<p>only used internally for passing the parameter matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To avoid fits with a high <code class="reqn">R^2</code> in the baseline region, some border in the data must be defined. In <code>sliwin</code>, this is by default (<code>base = NULL</code>) the region in the curve starting at the take-off cycle (<code class="reqn">top</code>) as calculated from <code><a href="#topic+takeoff">takeoff</a></code> and ending at the transition region to the upper asymptote (saturation region). The latter is calculated from the first and second derivative maxima: <code class="reqn">asympt = cpD1 + (cpD1 - cpD2)</code>. If the border is to be set by the user, <code>border</code> values such as <code>c(-2, 4)</code> extend these values by <code class="reqn">top + border[1]</code> and <code class="reqn">asympt + border[2]</code>. The <code class="reqn">log_{10}</code> transformed raw fluorescence values are regressed against the cycle number <code class="reqn">log_{10}(F) = n\beta + \epsilon</code> and the efficiency is then calculated by <code class="reqn">E = 10^{slope}</code>. For the baseline optimization, 100 baseline values <code class="reqn">Fb_i</code> are interpolated in the range of the data: </p>
<p style="text-align: center;"><code class="reqn">F_{min} \le Fb_i \le base \cdot \sigma(F_{basecyc[1]}...F_{basecyc[2]})</code>
</p>
<p> and subtracted from <code class="reqn">F_n</code>. If <code>type = "rsq"</code>, the best window in terms of <code class="reqn">R^2</code> is selected from all iterations, as defined by <code>wsize</code> and <code>border</code>. If <code>type = "slope"</code>, the baseline value delivering the smallest variance in the slope of the upper/lower part of the sliding window and highest <code class="reqn">R^2</code> is selected. This approach is quite similar to the one in Ruijter et al. (2009) but has to be tweaked in order to obtain the same values as in the 'LinRegPCR' software. Especially the <code>border</code> value has significant influence on the calculation of the best window's efficiency value. 
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>eff</code></td>
<td>
<p>the optimized PCR efficiency found within the sliding window.</p>
</td></tr>
<tr><td><code>rsq</code></td>
<td>
<p>the maximum R-squared.</p>
</td></tr>
<tr><td><code>init</code></td>
<td>
<p>the initial template fluorescence F0.</p>
</td></tr>  
<tr><td><code>base</code></td>
<td>
<p>the optimized baseline value.</p>
</td></tr>
<tr><td><code>window</code></td>
<td>
<p>the best window found within the <code>border</code>s.</p>
</td></tr>  
<tr><td><code>parMat</code></td>
<td>
<p>a matrix containing the parameters as above for each iteration.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Assumption-free analysis of quantitative real-time polymerase chain reaction (PCR) data.<br />
Ramakers C, Ruijter JM, Deprez RH, Moorman AF.<br />
<em>Neurosci Lett</em> (2003), <b>339</b>: 62-65.<br />
</p>
<p>Amplification efficiency: linking baseline and bias in the analysis of quantitative PCR data.<br />
Ruijter JM, Ramakers C, Hoogaars WM, Karlen Y, Bakker O, van den Hoff MJ, Moorman AF.<br />
<em>Nucleic Acids Res</em> (2009),  <b>37</b>: e45
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Sliding window of size 5 between 
## take-off point and upper asymptote, 
## no baseline optimization.
m1 &lt;- pcrfit(reps, 1, 2, l4)
sliwin(m1, wsize = 5)

## Not run: 
## Optimizing with window sizes of 4 to 6,
## between 0/+2 from lower/upper border, 
## and baseline up to 2 standard deviations.
sliwin(m1, wsize = 4:6, border = c(0, 2), base = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='takeoff'>Calculation of the qPCR takeoff point</h2><span id='topic+takeoff'></span>

<h3>Description</h3>

<p>Calculates the first significant cycle of the exponential region (takeoff point) using externally studentized residuals as described in Tichopad <em>et al.</em> (2003).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>takeoff(object, pval = 0.05, nsig = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="takeoff_+3A_object">object</code></td>
<td>
<p>an object of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="takeoff_+3A_pval">pval</code></td>
<td>
<p>the p-value for the takeoff test.</p>
</td></tr>
<tr><td><code id="takeoff_+3A_nsig">nsig</code></td>
<td>
<p>the number of successive takeoff tests. See 'Details'.</p>
</td></tr>      
</table>


<h3>Details</h3>

<p>Takeoff points are calculated essentially as described in the reference below.
The steps are:
</p>
<p>1) Fitting a linear model to background cycles <code class="reqn">1:n</code>, starting with <code class="reqn">n = 5</code>.<br />
2) Calculation of the external studentized residuals using <code><a href="stats.html#topic+rstudent">rstudent</a></code>, which uses the hat matrix of the linear model and leave-one-out:
</p>
<p style="text-align: center;"><code class="reqn">\langle \hat{\varepsilon}_i \rangle = \frac{\hat{\varepsilon}_i}{\hat{\sigma}_{(i)} \sqrt{1-h_{ii}}}, \hat{\sigma}_{(i)} = \sqrt{\frac{1}{n - p - 1} \sum_{j = 1 \atop j \ne i }^n \hat{\varepsilon}_j^2}</code>
</p>

<p>with <code class="reqn">h_{ii}</code> being the <code class="reqn">i</code>th diagonal entry in the hat matrix <code class="reqn">H = X(X^TX)^{-1}X^T</code>.<br />
3) Test if the last studentized residual <code class="reqn">\langle \hat{\varepsilon}_n \rangle</code> is an outlier in terms of t-distribution:
</p>
<p style="text-align: center;"><code class="reqn">1 - pt(\langle \hat{\varepsilon}_n \rangle, n - p) &lt; 0.05</code>
</p>
<p> with <code class="reqn">n</code> = number of residuals and <code class="reqn">p</code> = number of parameters.<br />
4) Test if the next <code>nsig</code> - 1 cycles are also outlier cycles.<br />
5) If so, take cycle number from 3), otherwise <code class="reqn">n = n + 1</code>  and start at 1).<br />
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>top</code></td>
<td>
<p>the takeoff point.</p>
</td></tr>
<tr><td><code>f.top</code></td>
<td>
<p>the fluorescence at <code>top</code>.</p>
</td></tr>    
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Standardized determination of real-time PCR efficiency from a single reaction set-up.<br />
Tichopad A, Dilger M, Schwarz G &amp; Pfaffl MW.<br />
<em>Nucleic Acids Research</em> (2003), <b>e122</b>.<br />       
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l5)
res1 &lt;- takeoff(m1) 
plot(m1)
abline(v = res1$top, col = 2)
abline(h = res1$f.top, col = 2)  
</code></pre>

<hr>
<h2 id='update.pcrfit'>Updating and refitting a qPCR model</h2><span id='topic+update.pcrfit'></span>

<h3>Description</h3>

<p>Updates and re-fits a model of class 'pcrfit'. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcrfit'
update(object, ..., evaluate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update.pcrfit_+3A_object">object</code></td>
<td>
<p>a fitted model of class 'pcrfit'.</p>
</td></tr>
<tr><td><code id="update.pcrfit_+3A_...">...</code></td>
<td>
<p>arguments to alter in object.</p>
</td></tr>
<tr><td><code id="update.pcrfit_+3A_evaluate">evaluate</code></td>
<td>
<p>logical. If <code>TRUE</code>, model is re-fit; otherwise an unevaluated call is returned.</p>
</td></tr>   
</table>


<h3>Value</h3>

<p>An updated model of class 'pcrfit' and 'nls'.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+pcrfit">pcrfit</a></code> in this package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- pcrfit(reps, 1, 2, l4)

## Update model.
update(m1, model = l5)

## Update qPCR run.
update(m1, fluo = 20)

## Update data.
update(m1, data = guescini1)    
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
