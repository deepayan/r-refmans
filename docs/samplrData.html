<!DOCTYPE html><html lang="en"><head><title>Help for package samplrData</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {samplrData}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#samplrData-package'><p>samplrData: Datasets from the SAMPLING Project</p></a></li>
<li><a href='#castillo2024.rgmomentum.e1'><p>Data from Experiment 1 in Castillo et al. (2024)</p></a></li>
<li><a href='#castillo2024.rgmomentum.e2'><p>Data from Experiment 2 in Castillo et al. (2024)</p></a></li>
<li><a href='#spicer2022.anchoringrepulsion.e1'><p>Data from Experiment 1 in Spicer et al. (2022)</p></a></li>
<li><a href='#spicer2022.anchoringrepulsion.e2'><p>Data from Experiment 2 in Spicer et al. (2022)</p></a></li>
<li><a href='#spicer2022.anchoringrepulsion.e2a'><p>Data from Experiment 2a in Spicer et al. (2022)</p></a></li>
<li><a href='#sundh2023.meanvariance.e3'><p>Data from Experiment 3 in Sundh et al. (2023)</p></a></li>
<li><a href='#sundh2023.meanvariance.e4'><p>Data from Experiment 4 in Sundh et al. (2023)</p></a></li>
<li><a href='#zhu2020.bayesiansampler.e1'><p>Data from Experiment 1 in Zhu et al. (2020)</p></a></li>
<li><a href='#zhu2020.bayesiansampler.e2'><p>Data from Experiment 2 in Zhu et al. (2020)</p></a></li>
<li><a href='#zhu2022.coherenceaccuracy.e1'><p>Data from Experiment 1 in Zhu et al. (2022)</p></a></li>
<li><a href='#zhu2022.coherenceaccuracy.e2'><p>Data from Experiment 2 in Zhu et al. (2022)</p></a></li>
<li><a href='#zhu2022.structurenoise.animals'><p>Data from Animal Experiment in Zhu et al. (2022)</p></a></li>
<li><a href='#zhu2022.structurenoise.time'><p>Data from Time Experiment in Zhu et al. (2022)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Datasets from the SAMPLING Project</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lucas Castillo &lt;lucas.castillo-marti@warwick.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains human behaviour datasets collected by the SAMPLING project (<a href="https://sampling.warwick.ac.uk">https://sampling.warwick.ac.uk</a>).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lucas-castillo/samplrData">https://github.com/lucas-castillo/samplrData</a>,
<a href="https://lucas-castillo.github.io/samplrData/">https://lucas-castillo.github.io/samplrData/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lucas-castillo/samplrData/issues">https://github.com/lucas-castillo/samplrData/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-13 09:54:15 UTC; Lucas</td>
</tr>
<tr>
<td>Author:</td>
<td>Lucas Castillo <a href="https://orcid.org/0000-0003-0274-0777"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Yun-Xiao Li <a href="https://orcid.org/0000-0002-3509-6618"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph],
  Adam N Sanborn <a href="https://orcid.org/0000-0003-0442-4372"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cph],
  European Research Council (ERC) [fnd]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-13 18:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='samplrData-package'>samplrData: Datasets from the SAMPLING Project</h2><span id='topic+samplrData'></span><span id='topic+samplrData-package'></span>

<h3>Description</h3>

<p>Contains human behaviour datasets collected by the SAMPLING project (<a href="https://sampling.warwick.ac.uk">https://sampling.warwick.ac.uk</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Lucas Castillo <a href="mailto:lucas.castillo-marti@warwick.ac.uk">lucas.castillo-marti@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0003-0274-0777">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Yun-Xiao Li <a href="mailto:yunxiao.li@warwick.ac.uk">yunxiao.li@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0002-3509-6618">ORCID</a>) [copyright holder]
</p>
</li>
<li><p> Adam N Sanborn <a href="mailto:a.n.sanborn@warwick.ac.uk">a.n.sanborn@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0003-0442-4372">ORCID</a>) [copyright holder]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> European Research Council (ERC) [funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/lucas-castillo/samplrData">https://github.com/lucas-castillo/samplrData</a>
</p>
</li>
<li> <p><a href="https://lucas-castillo.github.io/samplrData/">https://lucas-castillo.github.io/samplrData/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/lucas-castillo/samplrData/issues">https://github.com/lucas-castillo/samplrData/issues</a>
</p>
</li></ul>


<hr>
<h2 id='castillo2024.rgmomentum.e1'>Data from Experiment 1 in Castillo et al. (2024)</h2><span id='topic+castillo2024.rgmomentum.e1'></span>

<h3>Description</h3>

<p>Participants produced a random sequence of heights of either men or women in the United Kingdom. In one sequence, they sampled heights as distributed according to a uniform distribution (Uniform condition); in the other sequence, heights were distributed following their actual distribution (which is roughly Gaussian).
These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/dw8ez/">OSF</a>.
</p>

<dl>
<dt>id</dt><dd><p>participant id</p>
</dd>
<dt>part_Gender</dt><dd><p>participant's gender (self-reported)</p>
</dd>
<dt>part_Height</dt><dd><p>participant's own height (self-reported)</p>
</dd>
<dt>part_Home</dt><dd><p>participant's home country (self-reported)</p>
</dd>
<dt>RQ_Rep</dt><dd><p>percentage of correct responses in Randomness Questionnaire, for coin toss pairs where one sequence had too many repetitions</p>
</dd>
<dt>RQ_Alt</dt><dd><p>percentage of correct responses in Randomness Questionnaire, for coin toss pairs where one sequence had too many alternations</p>
</dd>
<dt>RQ_GFM</dt><dd><p>percentage of correct responses in Randomness Questionnaire, Gambling Fallacies Measure section</p>
</dd>
<dt>minHeight</dt><dd><p>height participant reports to be the shortest adult in the UK (from target gender)</p>
</dd>
<dt>maxHeight</dt><dd><p>height participant reports to be the tallest adult in the UK (from target gender)</p>
</dd>
<dt>condition</dt><dd><p>whether the participant did the uniform condition first (UN) or not (NU)</p>
</dd>
<dt>target_gender</dt><dd><p>gender they had to generate heights from, either male (M) or female (F)</p>
</dd>
<dt>index</dt><dd><p>position of the item in the sequence, 0 indexed</p>
</dd>
<dt>block</dt><dd><p>whether the item belongs to the first sequence the participant uttered (A) or the second (B)</p>
</dd>
<dt>target_dist</dt><dd><p>whether the instructions asked for heights as distributed in the population (N) or uniformly distributed (U)</p>
</dd>
<dt>label</dt><dd><p>what the participant uttered</p>
</dd>
<dt>unit</dt><dd><p>height unit, either centimetres (cm) or feet and inches (f_in).</p>
</dd>
<dt>value</dt><dd><p>value in cms of the height uttered.</p>
</dd>
<dt>value_in_units</dt><dd><p>value of the height uttered depending on the value of <code>unit</code> (either in inches or in centimetres). Used to calculate adjacencies, distances, etc.</p>
</dd>
<dt>starts</dt><dd><p>timestamp of when the utterance starts, in seconds.</p>
</dd>
<dt>delays</dt><dd><p>temporal difference with the start of the previous item (i.e. <code>starts[index] - starts[index - 1]</code>)</p>
</dd>
<dt>R</dt><dd><p>whether the item is a repetition of the last</p>
</dd>
<dt>A</dt><dd><p>whether the item is adjacent to the last (after removing repetitions)</p>
</dd>
<dt>TP_full</dt><dd><p>whether the item is a turning point, considering all items (after removing repetitions)</p>
</dd>
<dt>D</dt><dd><p>the Euclidean distance to the previous item (after removing repetitions)</p>
</dd>
<dt>S</dt><dd><p>a measure of how likely the item is in a uniform or gaussian distribution (see text)</p>
</dd>
<dt>expected_*</dt><dd><p>the expectation for measure <code>*</code> derived from reshuffling the participant's sequence 10000 times</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>castillo2024.rgmomentum.e1
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 5836 rows and 29 columns.
</p>


<h3>Source</h3>

<p><a href="https://osf.io/dw8ez/">https://osf.io/dw8ez/</a>
</p>


<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn AN (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.
</p>

<hr>
<h2 id='castillo2024.rgmomentum.e2'>Data from Experiment 2 in Castillo et al. (2024)</h2><span id='topic+castillo2024.rgmomentum.e2'></span>

<h3>Description</h3>

<p>Participants first learned a set of syllables arranged in either a single row (one-dimensional condition) or a grid (two-dimensional condition), then produced two random sequences for the same display.
These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/dw8ez/">OSF</a>.
</p>

<dl>
<dt>id</dt><dd><p>participant id</p>
</dd>
<dt>part_Gender</dt><dd><p>participant's gender (self-reported)</p>
</dd>
<dt>part_Age</dt><dd><p>participant's age (self-reported)</p>
</dd>
<dt>index</dt><dd><p>position of the item in the sequence, 0 indexed</p>
</dd>
<dt>id</dt><dd><p>unique identifier for the participant</p>
</dd>
<dt>block</dt><dd><p>whether the item belongs to the first sequence the participant uttered (A) or the second (B)</p>
</dd>
<dt>syll</dt><dd><p>syllable uttered</p>
</dd>
<dt>starts</dt><dd><p>timestamp of when the utterance starts, in seconds.</p>
</dd>
<dt>delays</dt><dd><p>temporal difference with the start of the previous item (i.e. <code>starts[index] - starts[index - 1]</code>)</p>
</dd>
<dt>dim</dt><dd><p>whether the participant was allocated to the one-dimensional or two-dimensional condition</p>
</dd>
<dt>seed</dt><dd><p>Which of five possible configurations the participant learned</p>
</dd>
<dt>position</dt><dd><p>The position of the syllable in the array. For 1D arrays, position is left to right. For 2D arrays positions 1-2 correspond to the top 2 cells; 3-5 to the middle 3 cells; and 6-7 to the bottom three cells (always left to right)</p>
</dd>
<dt>R</dt><dd><p>whether the item is a repetition of the last</p>
</dd>
<dt>A</dt><dd><p>whether the item is adjacent to the last in the display (after removing repetitions)</p>
</dd>
<dt>TP_full</dt><dd><p>whether the item is a turning point, considering all items (after removing repetitions)</p>
</dd>
<dt>D</dt><dd><p>the Euclidean distance to the previous item (after removing repetitions)</p>
</dd>
<dt>S</dt><dd><p>a measure of how likely the item is in a uniform or gaussian distribution (see text)</p>
</dd>
<dt>expected_*</dt><dd><p>the expectation for measure <code>*</code> derived from reshuffling the participant's sequence 10000 times</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>castillo2024.rgmomentum.e2
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 28483 rows and 20 columns.
</p>


<h3>Source</h3>

<p><a href="https://osf.io/dw8ez/">https://osf.io/dw8ez/</a>
</p>


<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn AN (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.
</p>

<hr>
<h2 id='spicer2022.anchoringrepulsion.e1'>Data from Experiment 1 in Spicer et al. (2022)</h2><span id='topic+spicer2022.anchoringrepulsion.e1'></span>

<h3>Description</h3>

<p>Perceptual judgments. Participants made judgments of numerosity against comparison values or absolute estimates. Comparison values (boundaries) were either similar or dissimilar to the true answer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spicer2022.anchoringrepulsion.e1
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 9600 rows and 11 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/95ruy/">OSF</a>.
</p>

<dl>
<dt>Timestamp</dt><dd><p>Date and time of the experimental session</p>
</dd>
<dt>Pt</dt><dd><p>Participant ID</p>
</dd>
<dt>Trial</dt><dd><p>Trial ID based on order of presentation</p>
</dd>
<dt>Boundary</dt><dd><p>Comparison value for that trial</p>
</dd>
<dt>DotCount</dt><dd><p>Number of dots shown on that trial</p>
</dd>
<dt>Region</dt><dd><p>Region for that dot count, being either high or low</p>
</dd>
<dt>Decision</dt><dd><p>Decision made by the participant on whether dot count was higher or lower than the boundary for that trial</p>
</dd>
<dt>Dec_RT</dt><dd><p>Response time for the decision</p>
</dd>
<dt>Accuracy</dt><dd><p>Accuracy of the selected decision</p>
</dd>
<dt>Estimate</dt><dd><p>Direct estimate of the number of dots on that trial made by the participant. NaN is used for trials in which no estimate was requested</p>
</dd>
<dt>Est_RT</dt><dd><p>Response time for the estimate</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/95ruy/">https://osf.io/95ruy/</a>
</p>


<h3>References</h3>

<p>Spicer J, Zhu J, Chater N, Sanborn AN (2022).
&ldquo;Perceptual and Cognitive Judgments Show Both Anchoring and Repulsion.&rdquo;
<em>Psychological Science</em>, <b>33</b>(9), 1395&ndash;1407.
<a href="https://doi.org/10.1177/09567976221089599">doi:10.1177/09567976221089599</a>.
</p>

<hr>
<h2 id='spicer2022.anchoringrepulsion.e2'>Data from Experiment 2 in Spicer et al. (2022)</h2><span id='topic+spicer2022.anchoringrepulsion.e2'></span>

<h3>Description</h3>

<p>Cognitive judgments. Participants answered questions about commonly experienced values. judgments of numerosity against comparison values or absolute estimates. Comparison values (boundaries) were either similar or dissimilar to the true answer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spicer2022.anchoringrepulsion.e2
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 2960 rows and 13 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/95ruy/">OSF</a>.
</p>

<dl>
<dt>Timestamp</dt><dd><p>Date and time of the experimental session</p>
</dd>
<dt>Pt</dt><dd><p>Participant ID</p>
</dd>
<dt>Trial</dt><dd><p>Trial ID based on order of presentation</p>
</dd>
<dt>QID</dt><dd><p>ID for the target question of that trial</p>
</dd>
<dt>Question</dt><dd><p>Question text</p>
</dd>
<dt>Region</dt><dd><p>Expected region for that question, being either high or low</p>
</dd>
<dt>Answer</dt><dd><p>Unbiased answer for that question from calibration data</p>
</dd>
<dt>Boundary</dt><dd><p>Comparison value for that trial</p>
</dd>
<dt>Decision</dt><dd><p>Decision made by the participant on whether answer to the question was higher or lower than the boundary</p>
</dd>
<dt>Dec_RT</dt><dd><p>Response time for the decision</p>
</dd>
<dt>Accuracy</dt><dd><p>Accuracy of the selected decision based on calibration data</p>
</dd>
<dt>Estimate</dt><dd><p>Direct estimate of the answer to the question for that trial made by the participant</p>
</dd>
<dt>Est_RT</dt><dd><p>Response time for the estimate</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/95ruy/">https://osf.io/95ruy/</a>
</p>


<h3>References</h3>

<p>Spicer J, Zhu J, Chater N, Sanborn AN (2022).
&ldquo;Perceptual and Cognitive Judgments Show Both Anchoring and Repulsion.&rdquo;
<em>Psychological Science</em>, <b>33</b>(9), 1395&ndash;1407.
<a href="https://doi.org/10.1177/09567976221089599">doi:10.1177/09567976221089599</a>.
</p>

<hr>
<h2 id='spicer2022.anchoringrepulsion.e2a'>Data from Experiment 2a in Spicer et al. (2022)</h2><span id='topic+spicer2022.anchoringrepulsion.e2a'></span>

<h3>Description</h3>

<p>Cognitive judgments. Participants answered questions about commonly experienced values. Unlike in Experiment 2, participants viewed each question multiple times, comparing each against both a low (25.5) and high (75.5) comparison value to create 40 trial cases. As in Experiment 1, decisions were requested on all trials, but only 30% of trials were randomly selected to include a direct estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spicer2022.anchoringrepulsion.e2a
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 9920 rows and 13 columns.
</p>


<h3>Details</h3>

<p>This experiment is described in the supplementary materials.
These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/95ruy/">OSF</a>.
</p>

<dl>
<dt>Timestamp</dt><dd><p>Date and time of the experimental session</p>
</dd>
<dt>Pt</dt><dd><p>Unique ID for that participant</p>
</dd>
<dt>Trial</dt><dd><p>Trial ID based on order of presentation</p>
</dd>
<dt>QID</dt><dd><p>ID for the target question of that trial. Note that these IDs match those of the calibration data.</p>
</dd>
<dt>Question</dt><dd><p>Question text for that trial</p>
</dd>
<dt>Region</dt><dd><p>Expected region for that question, being either high or low</p>
</dd>
<dt>Answer</dt><dd><p>Unbiased answer for that question from calibration data</p>
</dd>
<dt>Boundary</dt><dd><p>Comparison value for that trial</p>
</dd>
<dt>Decision</dt><dd><p>Decision made by the participant on whether answer to the question was higher or lower than the boundary for that trial</p>
</dd>
<dt>Dec_RT</dt><dd><p>Response time for the decision</p>
</dd>
<dt>Accuracy</dt><dd><p>Accuracy of the selected decision based on calibration data</p>
</dd>
<dt>Estimate</dt><dd><p>Direct estimate of the answer to the question for that trial made by the participant. NaN is used for trials in which no estimate was requested</p>
</dd>
<dt>Est_RT</dt><dd><p>Response time for the estimate</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/95ruy/">https://osf.io/95ruy/</a>
</p>


<h3>References</h3>

<p>Spicer J, Zhu J, Chater N, Sanborn AN (2022).
&ldquo;Perceptual and Cognitive Judgments Show Both Anchoring and Repulsion.&rdquo;
<em>Psychological Science</em>, <b>33</b>(9), 1395&ndash;1407.
<a href="https://doi.org/10.1177/09567976221089599">doi:10.1177/09567976221089599</a>.
</p>

<hr>
<h2 id='sundh2023.meanvariance.e3'>Data from Experiment 3 in Sundh et al. (2023)</h2><span id='topic+sundh2023.meanvariance.e3'></span>

<h3>Description</h3>

<p>Participants made probability judgments of the format: “What is the probability that the weather is [X] on a random day in England?&quot;. Various weather events were used, and the queries included both marginal events, conditional events, conjunctions, and disjunctions. The total set of 20 unique queries formed a block within which the presentation order was randomized for each participant. The experiment consisted of three blocks, so that all participants responded to each unique query three times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sundh2023.meanvariance.e3
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 12420 rows and 10 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/9kea6/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd></dd>
<dt>block</dt><dd><p>3 blocks in total</p>
</dd>
<dt>trial</dt><dd><p>Trial Number within a block</p>
</dd>
<dt>query, querydetail</dt><dd><p>Verbal descriptions of the query</p>
</dd>
<dt>querytype</dt><dd><p>Type of query: e.g. notBgA = p(¬B|A)</p>
</dd>
<dt>Estimate</dt><dd><p>Estimated probability, in percentages</p>
</dd>
<dt>starttime, endtime</dt><dd></dd>
<dt>RT</dt><dd></dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/9kea6/">https://osf.io/9kea6/</a>
</p>


<h3>References</h3>

<p>Sundh J, Zhu J, Chater N, Sanborn A (2023).
&ldquo;A Unified Explanation of Variability and Bias in Human Probability Judgments: How Computational Noise Explains the Mean Variance Signature.&rdquo;
<em>Journal of Experimental Psychology: General</em>, <b>152</b>(10), 2842&ndash;2860.
<a href="https://doi.org/10.1037/xge0001414">doi:10.1037/xge0001414</a>.
</p>

<hr>
<h2 id='sundh2023.meanvariance.e4'>Data from Experiment 4 in Sundh et al. (2023)</h2><span id='topic+sundh2023.meanvariance.e4'></span>

<h3>Description</h3>

<p>Participants made probability judgments about future hypothetical events, of the format: “What is the probability that there will be an early UK general election AND the UK economy will recover this year?&quot;. The experiment consisted of three blocks, so that all participants responded to each unique query three times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sundh2023.meanvariance.e4
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 13320 rows and 7 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/9kea6/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd></dd>
<dt>block</dt><dd><p>3 blocks in total</p>
</dd>
<dt>query, querydetail</dt><dd><p>Verbal descriptions of the query</p>
</dd>
<dt>querytype</dt><dd><p>Type of query: e.g. not B given A = p(¬B|A)</p>
</dd>
<dt>queryset</dt><dd><p>Whether the query is about biden and 2050 climate goals or UK election and economic recovery</p>
</dd>
<dt>Estimate</dt><dd><p>Estimated probability, in percentages</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/9kea6/">https://osf.io/9kea6/</a>
</p>


<h3>References</h3>

<p>Sundh J, Zhu J, Chater N, Sanborn A (2023).
&ldquo;A Unified Explanation of Variability and Bias in Human Probability Judgments: How Computational Noise Explains the Mean Variance Signature.&rdquo;
<em>Journal of Experimental Psychology: General</em>, <b>152</b>(10), 2842&ndash;2860.
<a href="https://doi.org/10.1037/xge0001414">doi:10.1037/xge0001414</a>.
</p>

<hr>
<h2 id='zhu2020.bayesiansampler.e1'>Data from Experiment 1 in Zhu et al. (2020)</h2><span id='topic+zhu2020.bayesiansampler.e1'></span>

<h3>Description</h3>

<p>Participants made probability judgments of the format: “What is the probability that the weather is [X] on a random day in England?&quot;. Various weather events were used, and the queries included both marginal events, conditional events, conjunctions, and disjunctions. The total set of 20 unique queries formed a block within which the presentation order was randomized for each participant. The experiment consisted of three blocks, so that all participants responded to each unique query three times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2020.bayesiansampler.e1
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 7080 rows and 10 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/mgcxj/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd></dd>
<dt>block</dt><dd><p>3 blocks in total</p>
</dd>
<dt>trial</dt><dd><p>Trial Number within a block</p>
</dd>
<dt>query, querydetail</dt><dd><p>Verbal descriptions of the query</p>
</dd>
<dt>querytype</dt><dd><p>Type of query: e.g. notBgA = p(¬B|A)</p>
</dd>
<dt>Estimate</dt><dd><p>Estimated probability, in percentages</p>
</dd>
<dt>starttime, endtime</dt><dd></dd>
<dt>RT</dt><dd></dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/mgcxj/">https://osf.io/mgcxj/</a>
</p>


<h3>References</h3>

<p>Zhu J, Sanborn AN, Chater N (2020).
&ldquo;The Bayesian Sampler: Generic Bayesian Inference Causes Incoherence in Human Probability Judgments.&rdquo;
<em>Psychological Review</em>, <b>127</b>(5), 719&ndash;748.
<a href="https://doi.org/10.1037/rev0000190">doi:10.1037/rev0000190</a>.
</p>

<hr>
<h2 id='zhu2020.bayesiansampler.e2'>Data from Experiment 2 in Zhu et al. (2020)</h2><span id='topic+zhu2020.bayesiansampler.e2'></span>

<h3>Description</h3>

<p>Participants made probability judgments of the format: “What is the probability that the weather is [X] on a random day in England?&quot;. Various weather events were used, and the queries included both marginal events, conditional events, conjunctions, and disjunctions. The total set of 20 unique queries formed a block within which the presentation order was randomized for each participant. The experiment consisted of three blocks, so that all participants responded to each unique query three times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2020.bayesiansampler.e2
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 22380 rows and 10 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/mgcxj/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd></dd>
<dt>block</dt><dd><p>3 blocks in total</p>
</dd>
<dt>trial</dt><dd><p>Trial Number within a block</p>
</dd>
<dt>query, querydetail</dt><dd><p>Verbal descriptions of the query</p>
</dd>
<dt>querytype</dt><dd><p>Type of query: e.g. notBgA = p(¬B|A)</p>
</dd>
<dt>Estimate</dt><dd><p>Estimated probability, in percentages</p>
</dd>
<dt>starttime, endtime</dt><dd></dd>
<dt>RT</dt><dd></dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/mgcxj/">https://osf.io/mgcxj/</a>
</p>


<h3>References</h3>

<p>Zhu J, Sanborn AN, Chater N (2020).
&ldquo;The Bayesian Sampler: Generic Bayesian Inference Causes Incoherence in Human Probability Judgments.&rdquo;
<em>Psychological Review</em>, <b>127</b>(5), 719&ndash;748.
<a href="https://doi.org/10.1037/rev0000190">doi:10.1037/rev0000190</a>.
</p>

<hr>
<h2 id='zhu2022.coherenceaccuracy.e1'>Data from Experiment 1 in Zhu et al. (2022)</h2><span id='topic+zhu2022.coherenceaccuracy.e1'></span>

<h3>Description</h3>

<p>Participants (from Prolific) estimated the frequencies of different 3-card combinations in a 52 card deck and 3-ball combinations in a 52 ball urn (mathematically identical questions). They also answered surveys on poker playing habits and gamblers fallacy questionnaire.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2022.coherenceaccuracy.e1
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 82 rows and 23 columns.
</p>


<h3>Details</h3>

<p>See exact questions in original paper's supplementary materials (Appendix B). These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/cdvkn/">OSF</a>.
</p>

<dl>
<dt>group</dt><dd><p>Self-reported response on whether they have played poker before</p>
</dd>
<dt>q1-q9</dt><dd><p>Answers to the poker questions</p>
</dd>
<dt>mq1-mq9</dt><dd><p>Answers to the ball questions</p>
</dd>
<dt>gfs</dt><dd><p>number of correct answers in gambler's fallacy questionnaire</p>
</dd>
<dt>cs</dt><dd><p>Inferred poker playing time in the last 12 months</p>
</dd>
<dt>RT</dt><dd></dd>
<dt>taskEqual</dt><dd><p>judged similarity between the Card and Ball task (0=all equal, 1=all differ, 0.5=answers differ but urn and deck were equal)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/cdvkn/">https://osf.io/cdvkn/</a>
</p>


<h3>References</h3>

<p>Zhu J, Newall PW, Sundh J, Chater N, Sanborn AN (2022).
&ldquo;Clarifying the Relationship between Coherence and Accuracy in Probability Judgments.&rdquo;
<em>Cognition</em>, <b>223</b>, 105022.
<a href="https://doi.org/10.1016/j.cognition.2022.105022">doi:10.1016/j.cognition.2022.105022</a>.
</p>

<hr>
<h2 id='zhu2022.coherenceaccuracy.e2'>Data from Experiment 2 in Zhu et al. (2022)</h2><span id='topic+zhu2022.coherenceaccuracy.e2'></span>

<h3>Description</h3>

<p>Participants (professional players recruited from twoplustwo.com) estimated the frequencies of different 3-card combinations in a 52 card deck and 3-ball combinations in a 52 ball urn (mathematically identical questions). They also answered surveys on poker playing habits and gamblers fallacy questionnaire.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2022.coherenceaccuracy.e2
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 186 rows and 23 columns.
</p>


<h3>Details</h3>

<p>See exact questions in original paper's supplementary materials (Appendix B). These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/cdvkn/">OSF</a>.
</p>

<dl>
<dt>group</dt><dd><p>value here is always professional (in contrast to Experiment 1)</p>
</dd>
<dt>q1-q9</dt><dd><p>Answers to the poker questions</p>
</dd>
<dt>mq1-mq9</dt><dd><p>Answers to the ball questions</p>
</dd>
<dt>gfs</dt><dd><p>number of correct answers in gambler's fallacy questionnaire</p>
</dd>
<dt>cs</dt><dd><p>Inferred poker playing time in the last 12 months</p>
</dd>
<dt>RT</dt><dd></dd>
<dt>taskEqual</dt><dd><p>judged similarity between the Card and Ball task (0=all equal, 1=all differ, 0.5=answers differ but urn and deck were equal)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/cdvkn/">https://osf.io/cdvkn/</a>
</p>


<h3>References</h3>

<p>Zhu J, Newall PW, Sundh J, Chater N, Sanborn AN (2022).
&ldquo;Clarifying the Relationship between Coherence and Accuracy in Probability Judgments.&rdquo;
<em>Cognition</em>, <b>223</b>, 105022.
<a href="https://doi.org/10.1016/j.cognition.2022.105022">doi:10.1016/j.cognition.2022.105022</a>.
</p>

<hr>
<h2 id='zhu2022.structurenoise.animals'>Data from Animal Experiment in Zhu et al. (2022)</h2><span id='topic+zhu2022.structurenoise.animals'></span>

<h3>Description</h3>

<p>Participants were asked to type animal names as they came to mind and were explicitly instructed that they could resubmit previous animals, though not consecutively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2022.structurenoise.animals
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 4967 rows and 7 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/kcfgp/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd><p>Participant ID</p>
</dd>
<dt>Order</dt><dd><p>Index of the response</p>
</dd>
<dt>Responses</dt><dd><p>Transcribed response</p>
</dd>
<dt>Animal</dt><dd><p>Category the response was allocated to</p>
</dd>
<dt>StartType,EndType</dt><dd><p>Absolute time of starting and ending to type the response</p>
</dd>
<dt>IRI</dt><dd><p>Time between last response's EndType and this response's StartType</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/kcfgp/">https://osf.io/kcfgp/</a>
</p>


<h3>References</h3>

<p>Zhu J, León-Villagrá P, Chater N, Sanborn AN (2022).
&ldquo;Understanding the Structure of Cognitive Noise.&rdquo;
<em>PLoS Computational Biology</em>, <b>18</b>(8), e1010312.
<a href="https://doi.org/10.1371/journal.pcbi.1010312">doi:10.1371/journal.pcbi.1010312</a>.
</p>

<hr>
<h2 id='zhu2022.structurenoise.time'>Data from Time Experiment in Zhu et al. (2022)</h2><span id='topic+zhu2022.structurenoise.time'></span>

<h3>Description</h3>

<p>Participants first listened to a sample of the target temporal interval for 60 seconds. Participants were instructed to reproduce the target by pressing the spacebar when they believed the target interval had elapsed (i.e. perfect performance in the task would mean <code>IRI == Target</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zhu2022.structurenoise.time
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 29822 rows and 6 columns.
</p>


<h3>Details</h3>

<p>These data are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>, reproduced from materials in <a href="https://osf.io/kcfgp/">OSF</a>.
</p>

<dl>
<dt>ID</dt><dd><p>Participant ID</p>
</dd>
<dt>Order</dt><dd><p>Index of the response</p>
</dd>
<dt>StartType,EndType</dt><dd><p>Absolute time of starting and ending to type the response</p>
</dd>
<dt>IRI</dt><dd><p>Time between last response's EndType and this response's StartType</p>
</dd>
<dt>Target</dt><dd><p>Whether the participant had to reproduce a 1/3s, 1s or 3s interval</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/kcfgp/">https://osf.io/kcfgp/</a>
</p>


<h3>References</h3>

<p>Zhu J, León-Villagrá P, Chater N, Sanborn AN (2022).
&ldquo;Understanding the Structure of Cognitive Noise.&rdquo;
<em>PLoS Computational Biology</em>, <b>18</b>(8), e1010312.
<a href="https://doi.org/10.1371/journal.pcbi.1010312">doi:10.1371/journal.pcbi.1010312</a>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
