<!DOCTYPE html><html lang="en"><head><title>Help for package cia</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cia}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cia-package'><p>cia: Learn and Apply Directed Acyclic Graphs for Causal Inference</p></a></li>
<li><a href='#+5B.cia_chain'><p>Index a cia_chain object</p></a></li>
<li><a href='#+5B.cia_chains'><p>Index a cia_chains object</p></a></li>
<li><a href='#+5B.cia_post_chain'><p>Indexing with respect to iterations.</p></a></li>
<li><a href='#+5B.cia_post_chains'><p>Index a cia_post_chains object with respect to iterations.</p></a></li>
<li><a href='#+5B+5B.cia_chains'><p>Index a cia_chains object</p></a></li>
<li><a href='#+5B+5B.cia_post_chains'><p>Index a cia_post_chains object.</p></a></li>
<li><a href='#BNLearnScorer'><p>BNLearnScorer</p></a></li>
<li><a href='#CalculateAcceptanceRates'><p>Calculate acceptance rates</p></a></li>
<li><a href='#CalculateEdgeProbabilities'><p>Calculate pairwise edge probabilities</p></a></li>
<li><a href='#CalculateFeatureMean'><p>Calculate arithmetic mean for a DAG feature</p></a></li>
<li><a href='#CollectUniqueObjects'><p>Collect unique objects</p></a></li>
<li><a href='#CreateScorer'><p>Scorer constructor</p></a></li>
<li><a href='#DAGtoCPDAG'><p>Convert DAG to CPDAG</p></a></li>
<li><a href='#DAGtoPartition'><p>Convert DAG to partition</p></a></li>
<li><a href='#DefaultProposal'><p>Default proposal constructor</p></a></li>
<li><a href='#FlattenChains'><p>Flatten chains</p></a></li>
<li><a href='#GetEmptyDAG'><p>Get an empty DAG given a set of nodes.</p></a></li>
<li><a href='#GetIncrementalScoringEdges'><p>Get incremental edges</p></a></li>
<li><a href='#GetLowestPairwiseScoringEdges'><p>Preprocessing for blacklisting</p>
Get the lowest pairwise scoring edges.</a></li>
<li><a href='#GetMAP'><p>Get the maximum a posteriori state</p></a></li>
<li><a href='#MutilateGraph'><p>Mutilate graph</p></a></li>
<li><a href='#PartitionMCMC'><p>Transition objects.</p>
Partition MCMC</a></li>
<li><a href='#PartitiontoDAG'><p>Sample DAG from partition</p></a></li>
<li><a href='#PlotConcordance'><p>Concordance plot</p></a></li>
<li><a href='#PlotCumulativeMeanTrace'><p>Plot cumulative mean trace plot.</p></a></li>
<li><a href='#PlotScoreTrace'><p>Plot the score trace</p></a></li>
<li><a href='#PostProcessChains'><p>Index chains for further analysis</p></a></li>
<li><a href='#SampleChains'><p>Sample chains</p></a></li>
<li><a href='#SampleEdgeProbabilities'><p>Sample edge probabilities</p></a></li>
<li><a href='#SamplePosteriorPredictiveChains'><p>Draw from a posterior predictive distribution</p></a></li>
<li><a href='#ScoreDAG'><p>Score DAG.</p></a></li>
<li><a href='#ScoreLabelledPartition'><p>Score labelled partition</p></a></li>
<li><a href='#toBNLearn'><p>Convert to bnlearn object.</p></a></li>
<li><a href='#togRain'><p>Convert to a gRain object.</p></a></li>
<li><a href='#toMatrix'><p>Convert to adjacency matrix.</p></a></li>
<li><a href='#UniformlySampleDAG'><p>Uniformly sample DAG</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Learn and Apply Directed Acyclic Graphs for Causal Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Causal Inference Assistance (CIA) for performing causal inference within the structural causal modelling framework. Structure learning is performed using partition Markov chain Monte Carlo (Kuipers &amp; Moffa, 2017) and several additional functions have been added to help with causal inference. Kuipers and Moffa (2017) &lt;<a href="https://doi.org/10.1080%2F01621459.2015.1133426">doi:10.1080/01621459.2015.1133426</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bnlearn (&ge; 4.9), igraph, doParallel, parallel, foreach,
arrangements, graphics, dplyr, rlang, fastmatch, methods,
gRain, patchwork, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 3.0.0), gtools, gRbase,
ggplot2, qgraph, dagitty</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://spaceodyssey.github.io/cia/">https://spaceodyssey.github.io/cia/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/SpaceOdyssey/cia/issues">https://github.com/SpaceOdyssey/cia/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-11 21:41:08 UTC; mvar0005</td>
</tr>
<tr>
<td>Author:</td>
<td>Mathew Varidel <a href="https://orcid.org/0000-0002-1648-8317"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Victor An [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mathew Varidel &lt;mathew.varidel@sydney.edu.au&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-13 14:00:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='cia-package'>cia: Learn and Apply Directed Acyclic Graphs for Causal Inference</h2><span id='topic+cia'></span><span id='topic+cia-package'></span>

<h3>Description</h3>

<p>Causal Inference Assistance (CIA) for performing causal inference within the structural causal modelling framework. Structure learning is performed using partition Markov chain Monte Carlo (Kuipers &amp; Moffa, 2017) and several additional functions have been added to help with causal inference. Kuipers and Moffa (2017) <a href="https://doi.org/10.1080/01621459.2015.1133426">doi:10.1080/01621459.2015.1133426</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Mathew Varidel <a href="mailto:mathew.varidel@sydney.edu.au">mathew.varidel@sydney.edu.au</a> (<a href="https://orcid.org/0000-0002-1648-8317">ORCID</a>) [copyright holder]
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Victor An <a href="mailto:victor.an@sydney.edu.au">victor.an@sydney.edu.au</a> [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://spaceodyssey.github.io/cia/">https://spaceodyssey.github.io/cia/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/SpaceOdyssey/cia/issues">https://github.com/SpaceOdyssey/cia/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+5B.cia_chain'>Index a cia_chain object</h2><span id='topic++5B.cia_chain'></span>

<h3>Description</h3>

<p>Index a cia_chain object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_chain'
x = list()[i, ...]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B.cia_chain_+3A_x">x</code></td>
<td>
<p>A cia_chain object.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_chain_+3A_i">i</code></td>
<td>
<p>An index.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_chain_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chain.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
results[[1]][5]

</code></pre>

<hr>
<h2 id='+5B.cia_chains'>Index a cia_chains object</h2><span id='topic++5B.cia_chains'></span>

<h3>Description</h3>

<p>Index a cia_chains object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_chains'
x = list()[i, ...]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B.cia_chains_+3A_x">x</code></td>
<td>
<p>A cia_chain object.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_chains_+3A_i">i</code></td>
<td>
<p>An index to get the cia_chain iterations.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_chains_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chains object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
results[5]

</code></pre>

<hr>
<h2 id='+5B.cia_post_chain'>Indexing with respect to iterations.</h2><span id='topic++5B.cia_post_chain'></span>

<h3>Description</h3>

<p>Indexing with respect to iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_post_chain'
x = list()[i, ...]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B.cia_post_chain_+3A_x">x</code></td>
<td>
<p>A cia_post_chain object.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_post_chain_+3A_i">i</code></td>
<td>
<p>An index.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_post_chain_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>chain A cia_post_chain.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

pedge_sample &lt;- SampleEdgeProbabilities(dag_chains)
pedge_sample[5, ]

</code></pre>

<hr>
<h2 id='+5B.cia_post_chains'>Index a cia_post_chains object with respect to iterations.</h2><span id='topic++5B.cia_post_chains'></span>

<h3>Description</h3>

<p>Index a cia_post_chains object with respect to iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_post_chains'
x = list()[i, ...]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B.cia_post_chains_+3A_x">x</code></td>
<td>
<p>A cia_post_chain object.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_post_chains_+3A_i">i</code></td>
<td>
<p>An index to get the cia_post_chain iterations.</p>
</td></tr>
<tr><td><code id="+2B5B.cia_post_chains_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>chain A cia_post_chains object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

pedge_sample &lt;- SampleEdgeProbabilities(dag_chains)
pedge_sample[5, ]

</code></pre>

<hr>
<h2 id='+5B+5B.cia_chains'>Index a cia_chains object</h2><span id='topic++5B+5B.cia_chains'></span>

<h3>Description</h3>

<p>Index a cia_chains object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_chains'
x[[i, ...]]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B+2B5B.cia_chains_+3A_x">x</code></td>
<td>
<p>A cia_chains object.</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B.cia_chains_+3A_i">i</code></td>
<td>
<p>An index to get the cia_chain.</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B.cia_chains_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chains object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
results[[1]][1:3]

</code></pre>

<hr>
<h2 id='+5B+5B.cia_post_chains'>Index a cia_post_chains object.</h2><span id='topic++5B+5B.cia_post_chains'></span>

<h3>Description</h3>

<p>Index a cia_post_chains object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cia_post_chains'
x[[i, ...]]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B5B+2B5B.cia_post_chains_+3A_x">x</code></td>
<td>
<p>A cia_post_chains object.</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B.cia_post_chains_+3A_i">i</code></td>
<td>
<p>An index to get the cia_post_chain.</p>
</td></tr>
<tr><td><code id="+2B5B+2B5B.cia_post_chains_+3A_...">...</code></td>
<td>
<p>ellipsis for extra indexing parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>chain A cia_post_chains object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

pedge_sample &lt;- SampleEdgeProbabilities(dag_chains)
head(pedge_sample[[1]])

</code></pre>

<hr>
<h2 id='BNLearnScorer'>BNLearnScorer</h2><span id='topic+BNLearnScorer'></span>

<h3>Description</h3>

<p>A thin wrapper on the bnlearn::score function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BNLearnScorer(node, parents, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BNLearnScorer_+3A_node">node</code></td>
<td>
<p>Name of node to score.</p>
</td></tr>
<tr><td><code id="BNLearnScorer_+3A_parents">parents</code></td>
<td>
<p>The parents of node.</p>
</td></tr>
<tr><td><code id="BNLearnScorer_+3A_...">...</code></td>
<td>
<p>The ellipsis is used to pass other parameters to the scorer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the log score of the node given the
parents.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test
BNLearnScorer('A', c('B', 'C'), data = data)
BNLearnScorer('A', c(), data = data)
BNLearnScorer('A', vector(), data = data)
BNLearnScorer('A', NULL, data = data)
BNLearnScorer('A', c('B', 'C'), data = data, type = "bde", iss = 100)
BNLearnScorer('A', c('B', 'C'), data = data, type = "bde", iss = 1)

</code></pre>

<hr>
<h2 id='CalculateAcceptanceRates'>Calculate acceptance rates</h2><span id='topic+CalculateAcceptanceRates'></span>

<h3>Description</h3>

<p>This makes the assumption that the proposal has saved a variable &quot;proposal_used&quot;
and mcmc has saved a variable 'accept'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalculateAcceptanceRates(chains, group_by = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalculateAcceptanceRates_+3A_chains">chains</code></td>
<td>
<p>MCMC chains.</p>
</td></tr>
<tr><td><code id="CalculateAcceptanceRates_+3A_group_by">group_by</code></td>
<td>
<p>Vector of strings that are in c(&quot;chain&quot;, &quot;proposal_used&quot;).
Default is NULL which will return the acceptance rates marginalised over
chains and the proposal used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Summary of acceptance rates per grouping.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
CalculateAcceptanceRates(results)


</code></pre>

<hr>
<h2 id='CalculateEdgeProbabilities'>Calculate pairwise edge probabilities</h2><span id='topic+CalculateEdgeProbabilities'></span>

<h3>Description</h3>

<p>Calculate pairwise edge probabilities. The posterior probability of an edge
<code class="reqn">E</code> given the data <code class="reqn">D</code> is given by marginalising out
the graph structure <code class="reqn">g</code> over the graph space <code class="reqn">G</code>, such that
</p>
<p style="text-align: center;"><code class="reqn">p(E|D) = \sum_{g \in G} p(E|g)p(g|D).</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>CalculateEdgeProbabilities(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalculateEdgeProbabilities_+3A_x">x</code></td>
<td>
<p>A cia_chain(s) or collection object where states are DAGs.</p>
</td></tr>
<tr><td><code id="CalculateEdgeProbabilities_+3A_...">...</code></td>
<td>
<p>Extra parameters sent to the methods. For a dag collection you can
choose to use estimated p(g|D) in two ways which can be specified using the
'method' parameter.method='sampled' for MCMC sampled frequency (which is our
recommended method) or method='score' which uses the normalised scores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior probability for a given graph p(g|D) is estimated in two
ways which can be specified using the 'method' parameter.
</p>


<h3>Value</h3>

<p>Matrix of edge probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)
CalculateEdgeProbabilities(dag_chains)

</code></pre>

<hr>
<h2 id='CalculateFeatureMean'>Calculate arithmetic mean for a DAG feature</h2><span id='topic+CalculateFeatureMean'></span>

<h3>Description</h3>

<p>Calculate the posterior expected value for a feature (<code class="reqn">f(g)</code>, e.g.,
existence of an edge in graph <code class="reqn">g</code>) by marginalising out the graph
structure <code class="reqn">q</code> over the graph space <code class="reqn">G</code>, thus
</p>
<p style="text-align: center;"><code class="reqn">E(f|D) = \sum_{g \in G} f(g) p(g|D).</code>
</p>
<p> This can be
useful for calculating point estimates of quantities of interests, such as
the probability that an edge exists or the probability of one node being
an ancestor of another.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalculateFeatureMean(x, p_feature, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalculateFeatureMean_+3A_x">x</code></td>
<td>
<p>A chain(s) or collection object.</p>
</td></tr>
<tr><td><code id="CalculateFeatureMean_+3A_p_feature">p_feature</code></td>
<td>
<p>A function that takes an adjacency matrix or collection object
and returns a scalar corresponding to <code class="reqn">f(g)</code>. The function must be of the
form p_feature(dag).</p>
</td></tr>
<tr><td><code id="CalculateFeatureMean_+3A_...">...</code></td>
<td>
<p>Extra parameters sent to the methods. For a dag collection you can
choose to use estimated p(g|D) in two ways which can be specified using the
'method' parameter.method='sampled' for MCMC sampled frequency (which is our
recommended method) or method='score' which uses the normalised scores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value representing the posterior probability of the
feature.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

# Calculate the mean edge probability per chain.
CalculateFeatureMean(dag_chains, function(x) { return(x) })

# Calculate the mean edge probability across chains.
CalculateFeatureMean(FlattenChains(dag_chains), function(x) { return(x) })

</code></pre>

<hr>
<h2 id='CollectUniqueObjects'>Collect unique objects</h2><span id='topic+CollectUniqueObjects'></span>

<h3>Description</h3>

<p>Get the unique set of states along with their log score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollectUniqueObjects(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CollectUniqueObjects_+3A_x">x</code></td>
<td>
<p>A cia_chains or cia_chain object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This gets the unique set of states in cia_chain(s) referred to as
objects (<code class="reqn">o</code>). Then it estimates the probability for each state using two
methods. The <code>log_sampling_prob</code> is the MCMC sampled frequency estimate for
the posterior probability.
</p>
<p>An alternative method to estimate the posterior probability for each state
uses the state score. This is recorded in the <code>log_norm_state_score</code>. This
approach estimates the log of the normalisation constant assuming
<code class="reqn">\tilde{Z}_O = \Sigma_{s=1}^S p(o_s)p(D | o_s)</code> where
<code class="reqn">O = \{o_1, o_2, o_3, ..., o_S\}</code> is
the set of unique objects in the chain. This assumes that you have captured the
most probable objects, such that <code class="reqn">\tilde{Z}_O</code> is approximately equal to
the true evidence <code class="reqn">Z = \Sigma_{g \in G} p(g)p(D | g)</code> where the
sum across all possible DAGs (<code class="reqn">G</code>). This also makes the
assumption that the exponential of the score is proportional to the posterior
probability, such that
</p>
<p style="text-align: center;"><code class="reqn">p(g|D) \propto p(g)p(D | g) = \prod_i \exp(\text{score}(X_i, \text{Pa}_g(X_i) | D))</code>
</p>

<p>where <code class="reqn">\text{Pa}_g(X_i)</code> is the parents set for node <code class="reqn">X_i</code> given the
graph <code class="reqn">g</code>.
</p>
<p>After the normalisation constant has been estimated we then estimate the
log probability of each object as,
</p>
<p style="text-align: center;"><code class="reqn">\log(p(o | D)) = \log(p(o)p(D|o)) - \log(\tilde{Z}_o).</code>
</p>

<p>Preliminary analysis suggests that the sampling frequency approach is more
consistent across chains when estimating marginalised edge probabilities,
and therefore is our preferred method. However, more work needs to be done
here.
</p>


<h3>Value</h3>

<p>A list with entries:
</p>

<ul>
<li><p> state: List of unique states.
</p>
</li>
<li><p> log_evidence_state: Numeric value representing the evidence calculated
from the states.
</p>
</li>
<li><p> log_state_score: Vector with the log scores for each state.
</p>
</li>
<li><p> log_sampling_prob: Vector with the log of the probability for each
state estimated using the MCMC sampling frequency.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(100, partitioned_nodes, PartitionMCMC(), scorer)
collection &lt;- CollectUniqueObjects(results)


</code></pre>

<hr>
<h2 id='CreateScorer'>Scorer constructor</h2><span id='topic+CreateScorer'></span>

<h3>Description</h3>

<p>Scorer constructor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateScorer(
  scorer = BNLearnScorer,
  ...,
  max_parents = Inf,
  blacklist = NULL,
  whitelist = NULL,
  cache = FALSE,
  nthreads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateScorer_+3A_scorer">scorer</code></td>
<td>
<p>A scorer function that takes (node, parents) as parameters.
Default is BNLearnScorer.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_...">...</code></td>
<td>
<p>Parameters to pass to scorer.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_max_parents">max_parents</code></td>
<td>
<p>The maximum number of allowed parents. Default is
infinite.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_blacklist">blacklist</code></td>
<td>
<p>A boolean matrix of (parent, child) pairs where TRUE
represents edges that cannot be in the DAG. Default is NULL which
represents no blacklisting.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_whitelist">whitelist</code></td>
<td>
<p>A boolean matrix of (parent, child) pairs where TRUE
represents edges that must be in the DAG. Default is NULL which represents
no whitelisting.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_cache">cache</code></td>
<td>
<p>A boolean to indicate whether to build the cache. The
cache only works for problems where the scorer only varies as a function of
(node, parents). Default is FALSE.</p>
</td></tr>
<tr><td><code id="CreateScorer_+3A_nthreads">nthreads</code></td>
<td>
<p>Number of threads used to construct cache.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries:
</p>

<ul>
<li><p> scorer: Function that takes (node, parents) as parameters and returns
the score.
</p>
</li>
<li><p> parameters: List of extra parameters passed to the scorer.
</p>
</li>
<li><p> max_parents: Integer representing the maximum number of possible
possible parents that any child can have.
</p>
</li>
<li><p> blacklist: Matrix where each cell represents the (parent, child) pairs
that must not be present when equal to 1.
</p>
</li>
<li><p> whitelist: Matrix where each cell represents the (parent, child) pairs
that must be present when equal to 1.
state estimated using the MCMC sampling frequency.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>scorer &lt;- CreateScorer(data = bnlearn::asia)

</code></pre>

<hr>
<h2 id='DAGtoCPDAG'>Convert DAG to CPDAG</h2><span id='topic+DAGtoCPDAG'></span>

<h3>Description</h3>

<p>Converts a directed acyclic graph (DAG) into it's equivalence class
corresponding to a completed partially directed acyclic graph (CPDAG).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DAGtoCPDAG(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DAGtoCPDAG_+3A_x">x</code></td>
<td>
<p>A matrix, cia_chain, or cia_chains object. When it is a chain(s)
object the state must be an adjacency matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x Returns same object type converted to a CPDAG.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- UniformlySampleDAG(LETTERS[1:3])
DAGtoCPDAG(dag)

</code></pre>

<hr>
<h2 id='DAGtoPartition'>Convert DAG to partition</h2><span id='topic+DAGtoPartition'></span>

<h3>Description</h3>

<p>This converts a DAG to it's partition by iteratively constructing sets of
outpoints. This is further explained in section 4.1 of Kuipers &amp; Moffa (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DAGtoPartition(dag)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DAGtoPartition_+3A_dag">dag</code></td>
<td>
<p>A directed acyclic graph represented as an adjacency matrix,
igraph, or bnlearn object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Labelled partition for the given adjacency matrix.
</p>


<h3>References</h3>

<p>Kuipers, J., &amp; Moffa, G. (2017). Partition MCMC for inference on
acyclic digraphs. Journal of the American Statistical Association, 112(517),
282-299.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- UniformlySampleDAG(LETTERS[1:3])
partitioned_nodes &lt;- DAGtoPartition(dag)

</code></pre>

<hr>
<h2 id='DefaultProposal'>Default proposal constructor</h2><span id='topic+DefaultProposal'></span>

<h3>Description</h3>

<p>This constructs a proposal function for PartitionMCMC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DefaultProposal(p = c(0.33, 0.33, 0.165, 0.165, 0.01), verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DefaultProposal_+3A_p">p</code></td>
<td>
<p>Probability for each proposal in the order (split_join, node_move,
swap_node, swap_adjacent, stay_still).</p>
</td></tr>
<tr><td><code id="DefaultProposal_+3A_verbose">verbose</code></td>
<td>
<p>Boolean flag to record proposal used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function corresponding to the default proposal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, 
                        PartitionMCMC(
                          proposal = DefaultProposal(p = c(0.0, 1.0, 0.0, 0.0, 0.0))
                          ), 
                        scorer)

</code></pre>

<hr>
<h2 id='FlattenChains'>Flatten chains</h2><span id='topic+FlattenChains'></span>

<h3>Description</h3>

<p>Flatten a cia_chains object into a single cia_chain object. This is helpful
for when you want to calculate a feature across using all samples across
the cia_chains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FlattenChains(chains)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FlattenChains_+3A_chains">chains</code></td>
<td>
<p>A cia_chains object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chain object of flattened samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
FlattenChains(results)[1:3]

</code></pre>

<hr>
<h2 id='GetEmptyDAG'>Get an empty DAG given a set of nodes.</h2><span id='topic+GetEmptyDAG'></span>

<h3>Description</h3>

<p>Get an empty DAG given a set of nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetEmptyDAG(nodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetEmptyDAG_+3A_nodes">nodes</code></td>
<td>
<p>A vector of node names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An adjacency matrix with elements designated as (parent, child).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GetEmptyDAG(LETTERS[1:3])

</code></pre>

<hr>
<h2 id='GetIncrementalScoringEdges'>Get incremental edges</h2><span id='topic+GetIncrementalScoringEdges'></span>

<h3>Description</h3>

<p>Get edges that do not incrementally improve the score over an empty DAG
greater than a cutoff. In detail, this returns the edges where a graph
with the edge <code class="reqn">E</code> given by <code class="reqn">g_E</code> such that
Score(g_E) - Score(g_empty) &lt; cutoff. Assuming that the scorer returns the
log of the marginalised posterior, then the cutoff corresponds to the log of
the Bayes Factor. The output can be used as a blacklist.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetIncrementalScoringEdges(scorer, cutoff = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetIncrementalScoringEdges_+3A_scorer">scorer</code></td>
<td>
<p>A scorer object.</p>
</td></tr>
<tr><td><code id="GetIncrementalScoringEdges_+3A_cutoff">cutoff</code></td>
<td>
<p>A score cutoff. The score cutoff is equal to the log
of the Bayes Factor between the two models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Boolean matrix of (parent, child) pairs for blacklisting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )
  
blacklist &lt;- GetIncrementalScoringEdges(scorer, cutoff = -10.0)

blacklist_scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data,
  cache = TRUE
  )

# Randomly sample a starting DAG consistent with the blacklist. Then
# convert to a partition.
dag &lt;- UniformlySampleDAG(colnames(data)) * !blacklist
partitioned_nodes &lt;- DAGtoPartition(dag)

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), blacklist_scorer)

</code></pre>

<hr>
<h2 id='GetLowestPairwiseScoringEdges'>Preprocessing for blacklisting
Get the lowest pairwise scoring edges.</h2><span id='topic+GetLowestPairwiseScoringEdges'></span>

<h3>Description</h3>

<p>Get the lowest pairwise scoring edges represented as a blacklist matrix.
This blacklisting procedure is motivated by Koller &amp; Friedman (2003). This
is rarely used now as we found that it blacklists edges that have significant
dependencies but are not in the top <code class="reqn">n</code> edges. We prefer
the GetIncrementalScoringEdges method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetLowestPairwiseScoringEdges(scorer, n_retain)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetLowestPairwiseScoringEdges_+3A_scorer">scorer</code></td>
<td>
<p>A scorer object.</p>
</td></tr>
<tr><td><code id="GetLowestPairwiseScoringEdges_+3A_n_retain">n_retain</code></td>
<td>
<p>An integer representing the number of edges to retain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean matrix of (parent, child) pairs for blacklisting.
</p>


<h3>References</h3>


<ol>
<li><p> Koller D, Friedman N. Being Bayesian about network structure. A Bayesian
approach to structure discovery in Bayesian networks. Mach Learn.
2003;50(1):95â€“125.
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )
  
blacklist &lt;- GetLowestPairwiseScoringEdges(scorer, 3)

blacklist_scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data,
  blacklist = blacklist,
  cache = TRUE
  )

# Randomly sample a starting DAG consistent with the blacklist. Then
# convert to a partition.
dag &lt;- UniformlySampleDAG(colnames(data)) * !blacklist
partitioned_nodes &lt;- DAGtoPartition(dag)

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), blacklist_scorer)

</code></pre>

<hr>
<h2 id='GetMAP'>Get the maximum a posteriori state</h2><span id='topic+GetMAP'></span>

<h3>Description</h3>

<p>Get the maximum a posteriori state
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetMAP(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetMAP_+3A_x">x</code></td>
<td>
<p>A collection of unique objects or chains object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the adjacency matrix for the map and it's posterior
probability. It is possible for it to return multiple DAGs. The list has
elements;
</p>

<ul>
<li><p> state: List of MAP DAGs.
</p>
</li>
<li><p> log_p: Numeric vector with the log posterior probability for each state.
</p>
</li>
<li><p> log_state_score: Numeric vector representing the log score for each state.
</p>
</li>
<li><p> log_norm_state_score: Numeric vector representing the log of the
normalised score for each state.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)

# Get the MAP per chain. Can be helpful to compare chains.
GetMAP(results)

# Get MAP across all chains.
results |&gt;
  FlattenChains() |&gt;
  GetMAP()


</code></pre>

<hr>
<h2 id='MutilateGraph'>Mutilate graph</h2><span id='topic+MutilateGraph'></span>

<h3>Description</h3>

<p>Mutilate a graph in accordance with an intervention. This is typically used
to perform a do-operation on a given graph. Please note that any evidence
set within the original grain object will not be passed to the new object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MutilateGraph(grain_object, intervention)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MutilateGraph_+3A_grain_object">grain_object</code></td>
<td>
<p>A grain object.</p>
</td></tr>
<tr><td><code id="MutilateGraph_+3A_intervention">intervention</code></td>
<td>
<p>A list of nodes and their corresponding intervention
distribution represented as a vector of unconditional probabilities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A grain object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This creates a mutilated graph in accordance with turning the sprinkler 
# on in the wet grass example (i.e, do(S = 'yes')).
yn &lt;- c("yes", "no")
p.R &lt;- gRain::cptable(~R, values=c(.2, .8), levels=yn)
p.S_R &lt;- gRain::cptable(~S:R, values=c(.01, .99, .4, .6), levels=yn)
p.G_SR &lt;- gRain::cptable(~G:S:R, values=c(.99, .01, .8, .2, .9, .1, 0, 1), levels=yn)
wet.cpt &lt;- gRain::grain(gRain::compileCPT(p.R, p.S_R, p.G_SR))

mut_graph &lt;- MutilateGraph(wet.cpt, list(S = c(1.0, 0.0)))

# You can then use querygrain to perform an intervention query. For example,
# p(G | do(S = 'yes')) is given by,
gRain::querygrain(mut_graph, 'G')

# You can also perform an observational query for a node not affected
# by the intervention. For example, p(R | do(S = 'yes')) is given by,
gRain::querygrain(mut_graph, 'R')

</code></pre>

<hr>
<h2 id='PartitionMCMC'>Transition objects.
Partition MCMC</h2><span id='topic+PartitionMCMC'></span>

<h3>Description</h3>

<p>This is a constructor for a single Tempered Partition MCMC step. The function
constructs an environment with the proposal, inverse temperature, and verbose
flag. It then returns a function that takes the current_state and a scorer
object. This only allows the scores to be raised to a constant temperature
for every step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartitionMCMC(
  proposal = DefaultProposal(),
  temperature = 1,
  prerejection = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PartitionMCMC_+3A_proposal">proposal</code></td>
<td>
<p>Proposal function. Default is the DefaultProposal.</p>
</td></tr>
<tr><td><code id="PartitionMCMC_+3A_temperature">temperature</code></td>
<td>
<p>Numeric value representing the temperature to raise the
score to. Default is 1.</p>
</td></tr>
<tr><td><code id="PartitionMCMC_+3A_prerejection">prerejection</code></td>
<td>
<p>Boolean flag to reject due to the proposal disobeying the
black or white lists. Only set to FALSE if you want to understand
how often you are proposing states that disobey the black or white lists. Can
be useful for debugging or understanding the efficiency of specific proposal
distributions.</p>
</td></tr>
<tr><td><code id="PartitionMCMC_+3A_verbose">verbose</code></td>
<td>
<p>Flag to pass MCMC information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One step implementation of the tempered partition MCMC.
</p>


<h3>Value</h3>

<p>Function that takes the current state and scorer that outputs a new
state.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- UniformlySampleDAG(c('A', 'B', 'C', 'D', 'E', 'F'))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer,
  data = bnlearn::learning.test
  )

current_state &lt;- list(
  state = partitioned_nodes,
  log_score = ScoreLabelledPartition(partitioned_nodes, scorer)
  )

pmcmc &lt;- PartitionMCMC(proposal = DefaultProposal(), temperature = 1.0)
pmcmc(current_state, scorer)

</code></pre>

<hr>
<h2 id='PartitiontoDAG'>Sample DAG from partition</h2><span id='topic+PartitiontoDAG'></span>

<h3>Description</h3>

<p>Samples a DAG in accordance with it's posterior probability conditional
on it being consistent with a partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartitiontoDAG(partitions, scorer)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PartitiontoDAG_+3A_partitions">partitions</code></td>
<td>
<p>A cia_chain(s) object or data.frame representing the
partition.</p>
</td></tr>
<tr><td><code id="PartitiontoDAG_+3A_scorer">scorer</code></td>
<td>
<p>A scorer object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chain(s) object or adjacency matrix. For a cia_chain(s) object
each state will be an adjacency matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partition &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

# Used to sample from a single partition.  
PartitiontoDAG(partition, scorer)

# Used to convert a chain of partitions to DAGs.
results &lt;- SampleChains(3, partition, PartitionMCMC(), scorer)
PartitiontoDAG(results, scorer)

</code></pre>

<hr>
<h2 id='PlotConcordance'>Concordance plot</h2><span id='topic+PlotConcordance'></span>

<h3>Description</h3>

<p>Plot a concordance plot to compare point-estimates for quantities of interest
between chains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotConcordance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PlotConcordance_+3A_x">x</code></td>
<td>
<p>A list of adjacency matrices representing edge probabilities, a
chains object, or a collections object with states as DAGs.</p>
</td></tr>
<tr><td><code id="PlotConcordance_+3A_...">...</code></td>
<td>
<p>Additional parameter to send to the appropriate method. This includes
'highlight' (defauled to 0.3) which sets the cutoff difference that is used to
highlight the points, and the probability edge estimation 'method' for a
cia_collections object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object or patchwork of ggplot objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test
dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)
scorer &lt;- CreateScorer(scorer = BNLearnScorer, data = data)

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer, n_parallel_chains = 2)
dags &lt;- PartitiontoDAG(results, scorer)

p_edge &lt;- CalculateEdgeProbabilities(dags)
PlotConcordance(p_edge)

</code></pre>

<hr>
<h2 id='PlotCumulativeMeanTrace'>Plot cumulative mean trace plot.</h2><span id='topic+PlotCumulativeMeanTrace'></span>

<h3>Description</h3>

<p>Plot cumulative mean trace plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCumulativeMeanTrace(
  x,
  ncol = NULL,
  nrow = NULL,
  scales = "fixed",
  dir = "v"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PlotCumulativeMeanTrace_+3A_x">x</code></td>
<td>
<p>A posterior predictive sample object.</p>
</td></tr>
<tr><td><code id="PlotCumulativeMeanTrace_+3A_ncol">ncol</code></td>
<td>
<p>Number of columns.</p>
</td></tr>
<tr><td><code id="PlotCumulativeMeanTrace_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows.</p>
</td></tr>
<tr><td><code id="PlotCumulativeMeanTrace_+3A_scales">scales</code></td>
<td>
<p>Whether the scales should the fixed ('fixed', the default),
free ('free') or free in one dimension ('free_x', 'free_y')?</p>
</td></tr>
<tr><td><code id="PlotCumulativeMeanTrace_+3A_dir">dir</code></td>
<td>
<p>Direction to fill facets. Either 'h' for horizontal or 'v' for
vertical.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

# Sample the edge probability.
p_edge &lt;- function(dag) { return(as.vector(dag)) }
pedge_sample &lt;- SamplePosteriorPredictiveChains(dag_chains, p_edge)

PlotCumulativeMeanTrace(pedge_sample,
                        nrow = length(data), 
                        ncol = length(data))

</code></pre>

<hr>
<h2 id='PlotScoreTrace'>Plot the score trace</h2><span id='topic+PlotScoreTrace'></span>

<h3>Description</h3>

<p>Plot the score trace
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotScoreTrace(
  chains,
  attribute = "log_score",
  n_burnin = 0,
  same_plot = TRUE,
  col = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PlotScoreTrace_+3A_chains">chains</code></td>
<td>
<p>MCMC chains.</p>
</td></tr>
<tr><td><code id="PlotScoreTrace_+3A_attribute">attribute</code></td>
<td>
<p>Name of attribute to plot. Default is &quot;log_score&quot;.</p>
</td></tr>
<tr><td><code id="PlotScoreTrace_+3A_n_burnin">n_burnin</code></td>
<td>
<p>Number of steps to remove as burnin.</p>
</td></tr>
<tr><td><code id="PlotScoreTrace_+3A_same_plot">same_plot</code></td>
<td>
<p>Whether to plot on the same figure or on multiple figures.</p>
</td></tr>
<tr><td><code id="PlotScoreTrace_+3A_col">col</code></td>
<td>
<p>A string representing a color for a single chain or a vector of
strings to cycle through for multiple chains.</p>
</td></tr>
<tr><td><code id="PlotScoreTrace_+3A_...">...</code></td>
<td>
<p>Extra parameters to pass to the plot and graphics::line functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Called to produce a base R trace plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)

# Plot partition score trace.
PlotScoreTrace(results, type = 'l')

# Plot DAG score trace.
dag_chains &lt;- PartitiontoDAG(results, scorer)
PlotScoreTrace(dag_chains, type = 'l')

</code></pre>

<hr>
<h2 id='PostProcessChains'>Index chains for further analysis</h2><span id='topic+PostProcessChains'></span>

<h3>Description</h3>

<p>This allows you to remove a burnin and thin the chains after processing. This
is mostly redundant as you can now index the cia_chain(s) objects directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PostProcessChains(chains, n_burnin = 0, n_thin = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PostProcessChains_+3A_chains">chains</code></td>
<td>
<p>cia_chain(s) object.</p>
</td></tr>
<tr><td><code id="PostProcessChains_+3A_n_burnin">n_burnin</code></td>
<td>
<p>Number of steps to remove at the start as a burnin. Default
is 0.</p>
</td></tr>
<tr><td><code id="PostProcessChains_+3A_n_thin">n_thin</code></td>
<td>
<p>Number of steps between retained states. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chain(s) object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer,
  data = data
  )

results &lt;- SampleChains(100, partitioned_nodes, PartitionMCMC(), scorer)
thinned_results &lt;- PostProcessChains(results, n_thin = 2)

</code></pre>

<hr>
<h2 id='SampleChains'>Sample chains</h2><span id='topic+SampleChains'></span>

<h3>Description</h3>

<p>Sample chains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleChains(
  n_results,
  init_state,
  transition,
  scorer,
  n_thin = 1,
  n_parallel_chains = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SampleChains_+3A_n_results">n_results</code></td>
<td>
<p>Number of saved states per chain.</p>
</td></tr>
<tr><td><code id="SampleChains_+3A_init_state">init_state</code></td>
<td>
<p>An initial state that can be passed to transition. This can
be a single state or a list of states for each parallel chain.</p>
</td></tr>
<tr><td><code id="SampleChains_+3A_transition">transition</code></td>
<td>
<p>A transition function.</p>
</td></tr>
<tr><td><code id="SampleChains_+3A_scorer">scorer</code></td>
<td>
<p>A scorer object.</p>
</td></tr>
<tr><td><code id="SampleChains_+3A_n_thin">n_thin</code></td>
<td>
<p>Number of steps between saved states.</p>
</td></tr>
<tr><td><code id="SampleChains_+3A_n_parallel_chains">n_parallel_chains</code></td>
<td>
<p>Number of chains to run in parallel. Default is 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_chains object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)

</code></pre>

<hr>
<h2 id='SampleEdgeProbabilities'>Sample edge probabilities</h2><span id='topic+SampleEdgeProbabilities'></span>

<h3>Description</h3>

<p>Sample edge probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleEdgeProbabilities(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SampleEdgeProbabilities_+3A_x">x</code></td>
<td>
<p>A chain(s) or collection object where states are DAGs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>p_edge A posterior sample for the marginalised edge probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

pedge_sample &lt;- SampleEdgeProbabilities(dag_chains)

</code></pre>

<hr>
<h2 id='SamplePosteriorPredictiveChains'>Draw from a posterior predictive distribution</h2><span id='topic+SamplePosteriorPredictiveChains'></span>

<h3>Description</h3>

<p>Simulate samples from a posterior predictive distribution for a feature <code class="reqn">f(g)</code>
a graph <code class="reqn">g</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SamplePosteriorPredictiveChains(x, p_predict, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SamplePosteriorPredictiveChains_+3A_x">x</code></td>
<td>
<p>A cia_chain(s) object.</p>
</td></tr>
<tr><td><code id="SamplePosteriorPredictiveChains_+3A_p_predict">p_predict</code></td>
<td>
<p>A function that draws from the posterior predictive distribution
of interest given an adjacency matrix representing a DAG. The function must
be of the form p_predict(dag, ...) and return either a vector of numeric values.</p>
</td></tr>
<tr><td><code id="SamplePosteriorPredictiveChains_+3A_...">...</code></td>
<td>
<p>Parameters to be passed to p_predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cia_post_chain(s) object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(colnames(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer,
  data = data
  )

results &lt;- SampleChains(10, partitioned_nodes, PartitionMCMC(), scorer)
dag_chains &lt;- PartitiontoDAG(results, scorer)

# Sample the edge probability.
SamplePosteriorPredictiveChains(dag_chains, function(dag) { return(dag) })

</code></pre>

<hr>
<h2 id='ScoreDAG'>Score DAG.</h2><span id='topic+ScoreDAG'></span>

<h3>Description</h3>

<p>Score DAG.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScoreDAG(dag, scorer)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ScoreDAG_+3A_dag">dag</code></td>
<td>
<p>Adjacency matrix of (parent, child) entries with 1 denoting an
edge and 0 otherwise.</p>
</td></tr>
<tr><td><code id="ScoreDAG_+3A_scorer">scorer</code></td>
<td>
<p>Scorer object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log of DAG score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- UniformlySampleDAG(names(bnlearn::asia))
scorer &lt;- CreateScorer(data = bnlearn::asia)
ScoreDAG(dag, scorer)

</code></pre>

<hr>
<h2 id='ScoreLabelledPartition'>Score labelled partition</h2><span id='topic+ScoreLabelledPartition'></span>

<h3>Description</h3>

<p>Score labelled partition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScoreLabelledPartition(partitioned_nodes, scorer)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ScoreLabelledPartition_+3A_partitioned_nodes">partitioned_nodes</code></td>
<td>
<p>Labelled partition.</p>
</td></tr>
<tr><td><code id="ScoreLabelledPartition_+3A_scorer">scorer</code></td>
<td>
<p>Scorer object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log of the node score.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- bnlearn::learning.test

dag &lt;- UniformlySampleDAG(names(data))
partitioned_nodes &lt;- DAGtoPartition(dag)

scorer &lt;- CreateScorer(
  scorer = BNLearnScorer, 
  data = data
  )

ScoreLabelledPartition(partitioned_nodes, scorer)

</code></pre>

<hr>
<h2 id='toBNLearn'>Convert to bnlearn object.</h2><span id='topic+toBNLearn'></span>

<h3>Description</h3>

<p>Convert to bnlearn object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toBNLearn(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="toBNLearn_+3A_x">x</code></td>
<td>
<p>An object that represents a DAG.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>bn_obj A bn object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>adj &lt;- UniformlySampleDAG(c('A', 'B', 'C'))
toBNLearn(adj)

</code></pre>

<hr>
<h2 id='togRain'>Convert to a gRain object.</h2><span id='topic+togRain'></span>

<h3>Description</h3>

<p>Convert to a gRain object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>togRain(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="togRain_+3A_x">x</code></td>
<td>
<p>An adjacency matrix or igraph object.</p>
</td></tr>
<tr><td><code id="togRain_+3A_...">...</code></td>
<td>
<p>extra parameters to gRain compile.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A gRain object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- bnlearn::model2network("[A][C][F][B|A][D|A:C][E|B:F]")
gRain_obj &lt;- togRain(x = dag |&gt; toMatrix(), data = bnlearn::learning.test)

</code></pre>

<hr>
<h2 id='toMatrix'>Convert to adjacency matrix.</h2><span id='topic+toMatrix'></span>

<h3>Description</h3>

<p>Convert a DAG object from other libraries to an adjacency matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toMatrix(network)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="toMatrix_+3A_network">network</code></td>
<td>
<p>A bnlearn or igraph object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An adjacency matrix representation of network.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toMatrix(bnlearn::empty.graph(LETTERS[1:6]))
toMatrix(igraph::sample_k_regular(10, 2))

</code></pre>

<hr>
<h2 id='UniformlySampleDAG'>Uniformly sample DAG</h2><span id='topic+UniformlySampleDAG'></span>

<h3>Description</h3>

<p>Uniformly sample DAG
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UniformlySampleDAG(nodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="UniformlySampleDAG_+3A_nodes">nodes</code></td>
<td>
<p>A vector of node names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Adjacency matrix with elements designated as (parent, child).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UniformlySampleDAG(LETTERS[1:3])

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
