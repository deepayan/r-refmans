<!DOCTYPE html><html><head><title>Help for package rdomains</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rdomains}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rdomains-package'><p>rdomains: Classify Domains by their Content</p></a></li>
<li><a href='#adult_ml1_cat'><p>Probability that Domain Hosts Adult Content Based on features of Domain Name and Suffix alone.</p></a></li>
<li><a href='#alexa_cat'><p>Get Category from Alexa</p></a></li>
<li><a href='#brightcloud_cat'><p>Get Category from Brightcloud</p></a></li>
<li><a href='#dmoz_cat'><p>Get Category from DMOZ</p></a></li>
<li><a href='#get_alexa_data'><p>Get Alexa Traffic Data</p></a></li>
<li><a href='#get_dmoz_data'><p>Get DMOZ Data</p></a></li>
<li><a href='#get_shalla_data'><p>Get Shalla Data</p></a></li>
<li><a href='#glm_shalla'><p>ML Model</p></a></li>
<li><a href='#not_news'><p>Classify News and Non-News Based on keywords in the URL</p></a></li>
<li><a href='#shalla_cat'><p>Get Category from Shallalist</p></a></li>
<li><a href='#uni_cat'><p>Get Category from University Domain List</p></a></li>
<li><a href='#virustotal_cat'><p>Get Category from Virustotal</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Get the Category of Content Hosted by a Domain</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Get the category of content hosted by a domain. Use Shallalist <a href="http://shalla.de/">http://shalla.de/</a>,
    Virustotal (which provides access to lots of services) <a href="https://www.virustotal.com/">https://www.virustotal.com/</a>,
    Alexa <a href="https://aws.amazon.com/awis/">https://aws.amazon.com/awis/</a>, DMOZ <a href="https://curlie.org/">https://curlie.org/</a>, University Domain list
    <a href="https://github.com/Hipo/university-domains-list">https://github.com/Hipo/university-domains-list</a> or validated machine learning
    classifiers based on Shallalist data to learn about the kind of content hosted by a domain.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, urltools, glmnet, stats, methods, XML, httr, xml2,
curl, virustotal, aws.alexa, jsonlite, devtools, R.utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, rmarkdown, knitr (&ge; 1.11), lintr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-15 06:18:41 UTC; soodoku</td>
</tr>
<tr>
<td>Author:</td>
<td>Gaurav Sood [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gaurav Sood &lt;gsood07@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-15 12:02:41 UTC</td>
</tr>
</table>
<hr>
<h2 id='rdomains-package'>rdomains: Classify Domains by their Content</h2><span id='topic+rdomains-package'></span><span id='topic+rdomains'></span>

<h3>Description</h3>

<p>Want to know what kind of content is carried on a domain?
Get the results quickly using rdomains. The package provides access to virustotal
API, shalla, brightcloud, aws, and validated ML model based off
shallalist data to predict content of a domain.
</p>
<p>To learn how to use rdomains, see this vignette: <a href="../doc/rdomains.html">../doc/rdomains.html</a>.
</p>


<h3>Author(s)</h3>

<p>Gaurav Sood
</p>

<hr>
<h2 id='adult_ml1_cat'>Probability that Domain Hosts Adult Content Based on features of Domain Name and Suffix alone.</h2><span id='topic+adult_ml1_cat'></span>

<h3>Description</h3>

<p>Uses a validated ML model that uses keywords in the domain name
and suffix to predict probability that the domain hosts adult content. For
more information see <a href="https://github.com/themains/keyword_porn">https://github.com/themains/keyword_porn</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adult_ml1_cat(domains = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adult_ml1_cat_+3A_domains">domains</code></td>
<td>
<p>required; string; vector of domain names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with original list and content category of the domains
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
adult_ml1_cat("http://www.google.com")

## End(Not run)
</code></pre>

<hr>
<h2 id='alexa_cat'>Get Category from Alexa</h2><span id='topic+alexa_cat'></span>

<h3>Description</h3>

<p>To learn how to get the Access Key ID and Secret Access Key, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html">https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html</a>,
clicking on the username followed by security credentials. Either pass the access key and secret or
set two environmental variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>.
These environment variables persist within a R session.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alexa_cat(domain = NULL, key = NULL, secret = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alexa_cat_+3A_domain">domain</code></td>
<td>
<p>domain name</p>
</td></tr>
<tr><td><code id="alexa_cat_+3A_key">key</code></td>
<td>
<p>Alexa Access Key ID</p>
</td></tr>
<tr><td><code id="alexa_cat_+3A_secret">secret</code></td>
<td>
<p>Alexa Secret Access Key</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with 2 columns Title and AbsolutePath
</p>


<h3>References</h3>

<p><a href="https://docs.aws.amazon.com/AlexaWebInfoService/latest/">https://docs.aws.amazon.com/AlexaWebInfoService/latest/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
alexa_cat(domain = "http://www.google.com")

## End(Not run)
</code></pre>

<hr>
<h2 id='brightcloud_cat'>Get Category from Brightcloud</h2><span id='topic+brightcloud_cat'></span>

<h3>Description</h3>

<p>Returns category of content from Brighcloud
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brightcloud_cat(domain = NULL, key = NULL, secret = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brightcloud_cat_+3A_domain">domain</code></td>
<td>
<p>domain name</p>
</td></tr>
<tr><td><code id="brightcloud_cat_+3A_key">key</code></td>
<td>
<p>brightcloud API consumer key</p>
</td></tr>
<tr><td><code id="brightcloud_cat_+3A_secret">secret</code></td>
<td>
<p>brightcloud API consumer secret</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Get the API Consumer Key and Secret from <a href="http://www.brightcloud.com/">http://www.brightcloud.com/</a>.
</p>


<h3>Value</h3>

<p>named list
</p>


<h3>References</h3>

<p><a href="http://www.brightcloud.com/">http://www.brightcloud.com/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
brightcloud_cat("http://www.google.com", key = "XXXX", secret = "XXXX")

## End(Not run)

</code></pre>

<hr>
<h2 id='dmoz_cat'>Get Category from DMOZ</h2><span id='topic+dmoz_cat'></span>

<h3>Description</h3>

<p>Fetches category (or categories) of content hosted by a domain according to DMOZ. 
The function checks if path to the DMOZ file is provided by the user. 
If not, it looks for <code>dmoz_domain_cateory.csv</code> in the working directory. It also returns
results for prominent subdomains.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmoz_cat(domains = NULL, use_file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmoz_cat_+3A_domains">domains</code></td>
<td>
<p>vector of domain names</p>
</td></tr>
<tr><td><code id="dmoz_cat_+3A_use_file">use_file</code></td>
<td>
<p>path to the dmoz file, which can be downloaded using <code><a href="#topic+get_dmoz_data">get_dmoz_data</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with original list and content category of the domain
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dmoz_cat(domains = "http://www.google.com")
dmoz_cat(domains = c("http://www.google.com", "http://plus.google.com"))

## End(Not run)
</code></pre>

<hr>
<h2 id='get_alexa_data'>Get Alexa Traffic Data</h2><span id='topic+get_alexa_data'></span>

<h3>Description</h3>

<p>Get Top 1M most visited domains list from Alexa. These data can be used to weight the
classification error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_alexa_data(outdir = ".", overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_alexa_data_+3A_outdir">outdir</code></td>
<td>
<p>Optional; folder to which you want to save the file; Default is same folder</p>
</td></tr>
<tr><td><code id="get_alexa_data_+3A_overwrite">overwrite</code></td>
<td>
<p>Optional; default is FALSE. If TRUE, the file is overwritten.</p>
</td></tr>
</table>


<h3>References</h3>

<p><a href="https://aws.amazon.com/marketplace/pp/B07QK2XWNV">https://aws.amazon.com/marketplace/pp/B07QK2XWNV</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
get_alexa_data()

## End(Not run)
</code></pre>

<hr>
<h2 id='get_dmoz_data'>Get DMOZ Data</h2><span id='topic+get_dmoz_data'></span>

<h3>Description</h3>

<p>Downloads, unzips and saves archived version of the DMOZ data. For more details, check:
<a href="https://github.com/themains/rdomains/tree/master/data-raw/dmoz/">https://github.com/themains/rdomains/tree/master/data-raw/dmoz/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dmoz_data(outdir = ".", overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_dmoz_data_+3A_outdir">outdir</code></td>
<td>
<p>Optional; folder to which you want to save the file; Default is same folder</p>
</td></tr>
<tr><td><code id="get_dmoz_data_+3A_overwrite">overwrite</code></td>
<td>
<p>Optional; default is FALSE. If TRUE, the file is overwritten.</p>
</td></tr>
</table>


<h3>References</h3>

<p><a href="https://dmoztools.net">https://dmoztools.net</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
get_dmoz_data()

## End(Not run)
</code></pre>

<hr>
<h2 id='get_shalla_data'>Get Shalla Data</h2><span id='topic+get_shalla_data'></span>

<h3>Description</h3>

<p>Shalla has discontinued. We downloaded the last copy (1/14/22).
For more information see data-raw folder on github
Downloads, unzips and saves the latest version of shallalist data. By default, saves shalla data  
as <code>shalla_domain_category.csv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_shalla_data(outdir = "./", overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_shalla_data_+3A_outdir">outdir</code></td>
<td>
<p>Optional; folder to which you want to save the file; Default is same folder</p>
</td></tr>
<tr><td><code id="get_shalla_data_+3A_overwrite">overwrite</code></td>
<td>
<p>Optional; default is FALSE. If TRUE, the file is overwritten.</p>
</td></tr>
</table>


<h3>References</h3>

<p><a href="http://www.shallalist.de/">http://www.shallalist.de/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
get_shalla_data()

## End(Not run)
</code></pre>

<hr>
<h2 id='glm_shalla'>ML Model</h2><span id='topic+glm_shalla'></span>

<h3>Description</h3>

<p>ML Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm_shalla
</code></pre>


<h3>Format</h3>

<p>A list
</p>


<h3>Author(s)</h3>

<p>Gaurav Sood
</p>


<h3>Source</h3>

<p>ML model based on shallalist using keywords and domain suffixes,
</p>

<hr>
<h2 id='not_news'>Classify News and Non-News Based on keywords in the URL</h2><span id='topic+not_news'></span>

<h3>Description</h3>

<p>Based on a slightly amended version of the regular expression used to classify news, and non-news in:
&ldquo;Exposure to ideologically diverse news and opinion on Facebook&rdquo;
by Bakshy, Messing, and Adamic. Science. 2015.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>not_news(url_list = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="not_news_+3A_url_list">url_list</code></td>
<td>
<p>vector of URLs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Amendment: sport rather than sports
</p>
<p>URL containing any of the following words is classified as soft news:
&quot;sport|entertainment|arts|fashion|style|lifestyle|leisure|celeb|movie|music|gossip|food|travel|horoscope|weather|gadget&quot;
</p>
<p>URL containing any of following words is classified as hard news:
&quot;politi|usnews|world|national|state|elect|vote|govern|campaign|war|polic|econ|unemploy|racis|energy|abortion|educa|healthcare|immigration&quot;
</p>
<p>Note that it is based on patterns existing in a small set of domains. See paper for details.
</p>


<h3>Value</h3>

<p>data.frame with 3 columns: url, not_news, news
</p>


<h3>References</h3>

<p><a href="https://www.science.org/doi/10.1126/science.aaa1160">https://www.science.org/doi/10.1126/science.aaa1160</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
not_news("http://www.bbc.com/sport")
not_news(c("http://www.bbc.com/sport", "http://www.washingtontimes.com/news/politics/"))

## End(Not run)
</code></pre>

<hr>
<h2 id='shalla_cat'>Get Category from Shallalist</h2><span id='topic+shalla_cat'></span>

<h3>Description</h3>

<p>Fetches category of content hosted by a domain according to Shalla. 
The function checks if path to the shalla file is provided by the user. 
If not, it looks for <code>shalla_domain_category.csv</code> in the working directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shalla_cat(domains = NULL, use_file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shalla_cat_+3A_domains">domains</code></td>
<td>
<p>vector of domain names</p>
</td></tr>
<tr><td><code id="shalla_cat_+3A_use_file">use_file</code></td>
<td>
<p>path to the latest shallalist file downloaded using <code><a href="#topic+get_shalla_data">get_shalla_data</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with original list and content category of the domain
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shalla_cat(domains = "http://www.google.com")

## End(Not run)
</code></pre>

<hr>
<h2 id='uni_cat'>Get Category from University Domain List</h2><span id='topic+uni_cat'></span>

<h3>Description</h3>

<p>Fetches university domain json from: 
<a href="https://raw.githubusercontent.com/Hipo/university-domains-list/master/world_universities_and_domains.json">https://raw.githubusercontent.com/Hipo/university-domains-list/master/world_universities_and_domains.json</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uni_cat(domains = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uni_cat_+3A_domains">domains</code></td>
<td>
<p>vector of domain names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with original list and all the other columns from the university json
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
uni_cat(domains = "http://www.google.com")

## End(Not run)
</code></pre>

<hr>
<h2 id='virustotal_cat'>Get Category from Virustotal</h2><span id='topic+virustotal_cat'></span>

<h3>Description</h3>

<p>Returns category of content from 6 major services including: BitDefender, Dr. Web, Alexa (DMOZ), Google, 
Websense, and Trendmicro. Not all services will have categories for all the domains. When the categories are
not returned for a particular domain, we return a NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>virustotal_cat(domain = NULL, apikey = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="virustotal_cat_+3A_domain">domain</code></td>
<td>
<p>domain name</p>
</td></tr>
<tr><td><code id="virustotal_cat_+3A_apikey">apikey</code></td>
<td>
<p>virustotal API key</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Get the API Access Key from <a href="http://www.virustotal.com/">http://www.virustotal.com/</a>. Either pass the API Key to the function 
or set the environmental variable: <code>VirustotalToken</code>. Environment variables persist within 
a R session.
</p>


<h3>Value</h3>

<p>data.frame with 7 columns: domain, bitdefender, dr_web, alexa, google, websense, trendmicro
</p>


<h3>References</h3>

<p><a href="https://developers.virustotal.com/v2.0/reference">https://developers.virustotal.com/v2.0/reference</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
virustotal_cat("http://www.google.com")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
