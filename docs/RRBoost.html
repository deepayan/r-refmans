<!DOCTYPE html><html lang="en"><head><title>Help for package RRBoost</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RRBoost}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#airfoil'><p>Airfoil data</p></a></li>
<li><a href='#Boost'><p>Robust Boosting for regression</p></a></li>
<li><a href='#Boost.control'><p>Tuning and control parameters for the robust boosting algorithm</p></a></li>
<li><a href='#Boost.validation'><p>Robust Boosting for regression with initialization parameters chosen on a validation set</p></a></li>
<li><a href='#cal_imp_func'><p>Variable importance scores for the robust boosting algorithm RRBoost</p></a></li>
<li><a href='#cal_predict'><p>cal_predict</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Robust Boosting Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-17</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of robust boosting algorithms for regression in R. This includes the RRBoost method proposed in the paper "Robust Boosting for Regression Problems" (Ju X and Salibian-Barrera M. 2020) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2020.107065">doi:10.1016/j.csda.2020.107065</a>&gt;. It also implements previously proposed boosting algorithms in the simulation section of the paper: L2Boost, LADBoost, MBoost (Friedman, J. H. (2001) &lt;<a href="https://doi.org/10.1214%2Faos%2F1013203451">doi:10.1214/aos/1013203451</a>&gt;) and Robloss (Lutz et al. (2008) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2007.11.006">doi:10.1016/j.csda.2007.11.006</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, rpart, RobStatTM, methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>True</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiaomeng Ju [aut, cre],
  Matias Salibian-Barrera [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiaomeng Ju &lt;xiaomeng.ju@stat.ubc.ca&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-19 18:42:40 UTC; xmengju</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-19 19:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='airfoil'>Airfoil data</h2><span id='topic+airfoil'></span>

<h3>Description</h3>

<p>Here goes a description of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(airfoil)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"data.frame"</code>.
</p>


<h3>Details</h3>

<p>Here goes a more detailed description of the data.
There are 1503 observations and 6 variables:
<code>y</code>, <code>frequency</code>, <code>angle</code>, <code>chord_length</code>,
<code>velocity</code>, and <code>thickness</code>.
</p>


<h3>Source</h3>

<p>The UCI Archive https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise,
</p>


<h3>References</h3>

<p>Brooks, T. F., Pope, D. S., and Marcolini, M. A. (1989). Airfoil self-noise and prediction. NASA Reference Publication-1218, document id: 9890016302.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(airfoil)
</code></pre>

<hr>
<h2 id='Boost'>Robust Boosting for regression</h2><span id='topic+Boost'></span>

<h3>Description</h3>

<p>This function implements the RRBoost robust boosting algorithm for regression,
as well as other robust and non-robust boosting algorithms for regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boost(
  x_train,
  y_train,
  x_val,
  y_val,
  x_test,
  y_test,
  type = "RRBoost",
  error = c("rmse", "aad"),
  niter = 200,
  y_init = "LADTree",
  max_depth = 1,
  tree_init_provided = NULL,
  control = Boost.control()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Boost_+3A_x_train">x_train</code></td>
<td>
<p>predictor matrix for training data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="Boost_+3A_y_train">y_train</code></td>
<td>
<p>response vector for training data (vector/dataframe)</p>
</td></tr>
<tr><td><code id="Boost_+3A_x_val">x_val</code></td>
<td>
<p>predictor matrix for validation data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="Boost_+3A_y_val">y_val</code></td>
<td>
<p>response vector for validation data (vector/dataframe)</p>
</td></tr>
<tr><td><code id="Boost_+3A_x_test">x_test</code></td>
<td>
<p>predictor matrix for test data (matrix/dataframe, optional, required when <code>make_prediction</code> in control is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost_+3A_y_test">y_test</code></td>
<td>
<p>response vector for test data (vector/dataframe, optional, required when <code>make_prediction</code> in control is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost_+3A_type">type</code></td>
<td>
<p>type of the boosting method: &quot;L2Boost&quot;, &quot;LADBoost&quot;, &quot;MBoost&quot;, &quot;Robloss&quot;, &quot;SBoost&quot;, &quot;RRBoost&quot; (character string)</p>
</td></tr>
<tr><td><code id="Boost_+3A_error">error</code></td>
<td>
<p>a character string (or vector of character strings) indicating the type of error metrics to be evaluated on the test set. Valid options are: &quot;rmse&quot; (root mean squared error), &quot;aad&quot; (average absolute deviation), and &quot;trmse&quot; (trimmed root mean squared error)</p>
</td></tr>
<tr><td><code id="Boost_+3A_niter">niter</code></td>
<td>
<p>number of boosting iterations (for RRBoost: <code class="reqn">T_{1,max} + T_{2,max}</code>) (numeric)</p>
</td></tr>
<tr><td><code id="Boost_+3A_y_init">y_init</code></td>
<td>
<p>a string indicating the initial estimator to be used. Valid options are: &quot;median&quot; or &quot;LADTree&quot; (character string)</p>
</td></tr>
<tr><td><code id="Boost_+3A_max_depth">max_depth</code></td>
<td>
<p>the maximum depth of the tree learners (numeric)</p>
</td></tr>
<tr><td><code id="Boost_+3A_tree_init_provided">tree_init_provided</code></td>
<td>
<p>an optional pre-fitted initial tree (an <code>rpart</code> object)</p>
</td></tr>
<tr><td><code id="Boost_+3A_control">control</code></td>
<td>
<p>a named list of control parameters, as returned by <code><a href="#topic+Boost.control">Boost.control</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements a robust boosting algorithm for regression (RRBoost).
It  also includes the following robust and non-robust boosting algorithms
for regression: L2Boost, LADBoost, MBoost, Robloss, and SBoost. This function
uses the functions available in the <code>rpart</code> package to construct binary regression trees.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>type</code></td>
<td>
<p>which boosting algorithm was run. One of: &quot;L2Boost&quot;, &quot;LADBoost&quot;, &quot;MBoost&quot;, &quot;Robloss&quot;, &quot;SBoost&quot;, &quot;RRBoost&quot; (character string)</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the list of control parameters used</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>number of iterations for the boosting algorithm (for RRBoost <code class="reqn">T_{1,max} + T_{2,max}</code>) (numeric)</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>if <code>make_prediction = TRUE</code> in argument <code>control</code>, a vector of prediction errors evaluated on the test set at early stopping time. The length of the vector matches that of the <code>error</code> argument in the input.</p>
</td></tr>
<tr><td><code>tree_init</code></td>
<td>
<p>if <code>y_init = "LADTree"</code>, the initial tree (an object of class <code>rpart</code>)</p>
</td></tr>
<tr><td><code>tree_list</code></td>
<td>
<p>if <code>save_tree = TRUE</code> in <code>control</code>, a list of trees fitted at each boosting iteration</p>
</td></tr>
<tr><td><code>f_train_init</code></td>
<td>
<p>a vector of the initialized estimator of the training data</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>a vector of base learners' coefficients</p>
</td></tr>
<tr><td><code>early_stop_idx</code></td>
<td>
<p>early stopping iteration</p>
</td></tr>
<tr><td><code>when_init</code></td>
<td>
<p>if <code>type = "RRBoost"</code>, the early stopping time of the first stage of RRBoost</p>
</td></tr>
<tr><td><code>loss_train</code></td>
<td>
<p>a vector of training loss values (one per iteration)</p>
</td></tr>
<tr><td><code>loss_val</code></td>
<td>
<p>a vector of validation loss values (one per iteration)</p>
</td></tr>
<tr><td><code>err_val</code></td>
<td>
<p>a vector of validation aad errors (one per iteration)</p>
</td></tr>
<tr><td><code>err_train</code></td>
<td>
<p>a vector of training aad errors (one  per iteration)</p>
</td></tr>
<tr><td><code>err_test</code></td>
<td>
<p>a matrix of test errors before and at the early stopping iteration (returned if make_prediction = TRUE in control); the matrix dimension is the early stopping iteration by the number of error types (matches the <code>error</code> argument in the input); each row corresponds to the test errors at each iteration</p>
</td></tr>
<tr><td><code>f_train</code></td>
<td>
<p>a matrix of training function estimates at all iterations (returned if save_f = TRUE in control); each column corresponds to the fitted values of the predictor at each iteration</p>
</td></tr>
<tr><td><code>f_val</code></td>
<td>
<p>a matrix of validation function estimates at all iterations (returned if save_f = TRUE in control); each column corresponds to the fitted values of the predictor at each iteration</p>
</td></tr>
<tr><td><code>f_test</code></td>
<td>
<p>a matrix of test function estimatesbefore and at the early stopping iteration (returned if save_f = TRUE and make_prediction = TRUE in control); each column corresponds to the fitted values of the predictor at each iteration</p>
</td></tr>
<tr><td><code>var_select</code></td>
<td>
<p>a vector of variable selection indicators (one  per explanatory variable; 1 if the variable was selected by at least one of the base learners, and 0 otherwise)</p>
</td></tr>
<tr><td><code>var_importance</code></td>
<td>
<p> a vector of permutation variable importance scores (one per explanatory variable, and returned if cal_imp = TRUE in control)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Xiaomeng Ju, <a href="mailto:xiaomeng.ju@stat.ubc.ca">xiaomeng.ju@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Boost.validation">Boost.validation</a></code>, <code><a href="#topic+Boost.control">Boost.control</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(airfoil)
n &lt;- nrow(airfoil)
n0 &lt;- floor( 0.2 * n )
set.seed(123)
idx_test &lt;- sample(n, n0)
idx_train &lt;- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val &lt;- (1:n)[ -c(idx_test, idx_train) ]
xx &lt;- airfoil[, -6]
yy &lt;- airfoil$y
xtrain &lt;- xx[ idx_train, ]
ytrain &lt;- yy[ idx_train ]
xval &lt;- xx[ idx_val, ]
yval &lt;- yy[ idx_val ]
xtest &lt;- xx[ idx_test, ]
ytest &lt;- yy[ idx_test ]
model_RRBoost_LADTree = Boost(x_train = xtrain, y_train = ytrain,
    x_val = xval, y_val = yval, x_test = xtest, y_test = ytest,
    type = "RRBoost", error = "rmse", y_init = "LADTree",
    max_depth = 1, niter = 3, ## to keep the running time low
    control = Boost.control(max_depth_init = 2,
    min_leaf_size_init = 20, make_prediction =  TRUE,
    cal_imp = FALSE))

</code></pre>

<hr>
<h2 id='Boost.control'>Tuning and control parameters for the robust boosting algorithm</h2><span id='topic+Boost.control'></span>

<h3>Description</h3>

<p>Tuning and control parameters for the RRBoost robust boosting algorithm, including the initial fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boost.control(
  n_init = 100,
  eff_m = 0.95,
  bb = 0.5,
  trim_prop = NULL,
  trim_c = 3,
  max_depth_init = 3,
  min_leaf_size_init = 10,
  cal_imp = TRUE,
  save_f = FALSE,
  make_prediction = TRUE,
  save_tree = FALSE,
  precision = 4,
  shrinkage = 1,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Boost.control_+3A_n_init">n_init</code></td>
<td>
<p>number of iterations for the SBoost step of RRBoost (<code class="reqn">T_{1,max}</code>) (int)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_eff_m">eff_m</code></td>
<td>
<p>scalar between 0 and 1 indicating the efficiency (measured in a linear model with Gaussian errors) of Tukey's loss function used in the 2nd stage of RRBoost.</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_bb">bb</code></td>
<td>
<p>breakdown point of the M-scale estimator used in the SBoost step (numeric)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_trim_prop">trim_prop</code></td>
<td>
<p>trimming proportion if 'trmse' is used as the performance metric (numeric). 'trmse' calculates the root-mean-square error of residuals (r) of which |r| &lt; quantile(|r|, 1-trim_prop)  (e.g. trim_prop = 0.1 ignores 10% of the data and calculates RMSE of residuals whose absolute values are below 90% quantile of |r|). If  both <code>trim_prop</code> and <code>trim_c</code> are specified, <code>trim_c</code> will be used.</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_trim_c">trim_c</code></td>
<td>
<p>the trimming constant if 'trmse' is used as the performance metric (numeric, defaults to 3). 'trmse' calculates the root-mean-square error of the residuals (r) between median(r) + trim_c mad(r) and median(r) - trim_c mad(r).  If  both <code>trim_prop</code> and <code>trim_c</code> are specified, <code>trim_c</code> will be used.</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_max_depth_init">max_depth_init</code></td>
<td>
<p>the maximum depth of the initial LADTtree  (numeric, defaults to 3)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_min_leaf_size_init">min_leaf_size_init</code></td>
<td>
<p>the minimum number of observations per node of the initial LADTtree (numeric, defaults to 10)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_cal_imp">cal_imp</code></td>
<td>
<p>logical indicating whether to calculate variable importance  (defaults to <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_save_f">save_f</code></td>
<td>
<p>logical indicating whether to save the function estimates at all iterations (defaults to <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_make_prediction">make_prediction</code></td>
<td>
<p>logical indicating whether to make predictions using <code>x_test</code> (defaults to <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_save_tree">save_tree</code></td>
<td>
<p>logical indicating whether to save trees at all iterations  (defaults to <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_precision">precision</code></td>
<td>
<p>number of significant digits to keep when using validation error to calculate early stopping time (numeric, defaults to 4)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_shrinkage">shrinkage</code></td>
<td>
<p>shrinkage parameter in boosting (numeric, defaults to 1 which corresponds to no shrinkage)</p>
</td></tr>
<tr><td><code id="Boost.control_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the number of completed iterations and for RRBoost the completed combinations of LADTree hyperparameters for monitoring progress (defaults to <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Various tuning and control parameters for the RRBoost robust boosting algorithm implemented in the
function <code><a href="#topic+Boost">Boost</a></code>,  including options for the initial fit.
</p>


<h3>Value</h3>

<p>A list of all input parameters
</p>


<h3>Author(s)</h3>

<p>Xiaomeng Ju, <a href="mailto:xiaomeng.ju@stat.ubc.ca">xiaomeng.ju@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(airfoil)
n &lt;- nrow(airfoil)
n0 &lt;- floor( 0.2 * n )
set.seed(123)
idx_test &lt;- sample(n, n0)
idx_train &lt;- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val &lt;- (1:n)[ -c(idx_test, idx_train) ]
xx &lt;- airfoil[, -6]
yy &lt;- airfoil$y
xtrain &lt;- xx[ idx_train, ]
ytrain &lt;- yy[ idx_train ]
xval &lt;- xx[ idx_val, ]
yval &lt;- yy[ idx_val ]
xtest &lt;- xx[ idx_test, ]
ytest &lt;- yy[ idx_test ]
my.control &lt;- Boost.control(max_depth_init = 2,
    min_leaf_size_init = 20, make_prediction =  TRUE,
    cal_imp = FALSE)
model_RRBoost_LADTree = Boost(x_train = xtrain, y_train = ytrain,
    x_val = xval, y_val = yval, x_test = xtest, y_test = ytest,
    type = "RRBoost", error = "rmse", y_init = "LADTree",
    max_depth = 1, niter = 3, ## to keep the running time low
    control = my.control)

</code></pre>

<hr>
<h2 id='Boost.validation'>Robust Boosting for regression with initialization parameters chosen on a validation set</h2><span id='topic+Boost.validation'></span>

<h3>Description</h3>

<p>A function to fit RRBoost (see also <code><a href="#topic+Boost">Boost</a></code>) where the initialization parameters are chosen
based on the performance on the validation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boost.validation(
  x_train,
  y_train,
  x_val,
  y_val,
  x_test,
  y_test,
  type = "RRBoost",
  error = c("rmse", "aad"),
  niter = 1000,
  max_depth = 1,
  y_init = "LADTree",
  max_depth_init_set = c(1, 2, 3, 4),
  min_leaf_size_init_set = c(10, 20, 30),
  control = Boost.control()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Boost.validation_+3A_x_train">x_train</code></td>
<td>
<p>predictor matrix for training data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_y_train">y_train</code></td>
<td>
<p>response vector for training data (vector/dataframe)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_x_val">x_val</code></td>
<td>
<p>predictor matrix for validation data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_y_val">y_val</code></td>
<td>
<p>response vector for validation data (vector/dataframe)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_x_test">x_test</code></td>
<td>
<p>predictor matrix for test data (matrix/dataframe, optional, required when <code>make_prediction</code> in control is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_y_test">y_test</code></td>
<td>
<p>response vector for test data (vector/dataframe,  optional, required when <code>make_prediction</code> in control is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_type">type</code></td>
<td>
<p>type of the boosting method: &quot;L2Boost&quot;, &quot;LADBoost&quot;, &quot;MBoost&quot;, &quot;Robloss&quot;, &quot;SBoost&quot;, &quot;RRBoost&quot; (character string)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_error">error</code></td>
<td>
<p>a character string (or vector of character strings) indicating the types of error metrics to be evaluated on the test set. Valid options are: &quot;rmse&quot; (root mean squared error), &quot;aad&quot; (average absulute deviation), and &quot;trmse&quot; (trimmed root mean squared error)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_niter">niter</code></td>
<td>
<p>number of iterations (for RRBoost <code class="reqn">T_{1,max} + T_{2,max}</code>) (numeric)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_max_depth">max_depth</code></td>
<td>
<p>the maximum depth of the tree learners (numeric)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_y_init">y_init</code></td>
<td>
<p>a string indicating the initial estimator to be used. Valid options are: &quot;median&quot; or &quot;LADTree&quot; (character string)</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_max_depth_init_set">max_depth_init_set</code></td>
<td>
<p>a vector of possible values of the maximum depth of the initial LADTree that the algorithm choses from</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_min_leaf_size_init_set">min_leaf_size_init_set</code></td>
<td>
<p>a vector of possible values of the minimum observations per node of the initial LADTree that the algorithm choses from</p>
</td></tr>
<tr><td><code id="Boost.validation_+3A_control">control</code></td>
<td>
<p>a named list of control parameters, as returned by <code><a href="#topic+Boost.control">Boost.control</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function runs the RRBoost algorithm (see <code><a href="#topic+Boost">Boost</a></code>) on different combinations of the
parameters for the initial fit, and chooses the optimal set based on the performance on the validation set.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table role = "presentation">
<tr><td><code>the components of model</code></td>
<td>
<p>an object returned by Boost that is trained with selected initialization parameters</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a vector of selected initialization parameters (return (0,0) if selected initialization is the median of the training responses)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Xiaomeng Ju, <a href="mailto:xiaomeng.ju@stat.ubc.ca">xiaomeng.ju@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Boost">Boost</a></code>, <code><a href="#topic+Boost.control">Boost.control</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(airfoil)
n &lt;- nrow(airfoil)
n0 &lt;- floor( 0.2 * n )
set.seed(123)
idx_test &lt;- sample(n, n0)
idx_train &lt;- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val &lt;- (1:n)[ -c(idx_test, idx_train) ]
xx &lt;- airfoil[, -6]
yy &lt;- airfoil$y
xtrain &lt;- xx[ idx_train, ]
ytrain &lt;- yy[ idx_train ]
xval &lt;- xx[ idx_val, ]
yval &lt;- yy[ idx_val ]
xtest &lt;- xx[ idx_test, ]
ytest &lt;- yy[ idx_test ]
model_RRBoost_cv_LADTree = Boost.validation(x_train = xtrain,
      y_train = ytrain, x_val = xval, y_val = yval,
      x_test = xtest, y_test = ytest, type = "RRBoost", error = "rmse",
      y_init = "LADTree", max_depth = 1, niter = 1000,
      max_depth_init_set = 1:5,
      min_leaf_size_init_set = c(10,20,30),
      control = Boost.control(make_prediction =  TRUE,
      cal_imp = TRUE))

## End(Not run)

</code></pre>

<hr>
<h2 id='cal_imp_func'>Variable importance scores for the robust boosting algorithm RRBoost</h2><span id='topic+cal_imp_func'></span>

<h3>Description</h3>

<p>This function  calculates variable importance scores for a previously
computed <code>RRBoost</code> fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_imp_func(model, x_val, y_val, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal_imp_func_+3A_model">model</code></td>
<td>
<p>an object returned by <code><a href="#topic+Boost">Boost</a></code></p>
</td></tr>
<tr><td><code id="cal_imp_func_+3A_x_val">x_val</code></td>
<td>
<p>predictor matrix for validation data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="cal_imp_func_+3A_y_val">y_val</code></td>
<td>
<p>response vector for validation data (vector/dataframe)</p>
</td></tr>
<tr><td><code id="cal_imp_func_+3A_trace">trace</code></td>
<td>
<p>logical indicating whether to print the variable under calculation for monitoring progress (defaults to <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes permutation variable importance scores
given an object returned by <code><a href="#topic+Boost">Boost</a></code> and a validation data set.
</p>


<h3>Value</h3>

<p>a vector of permutation variable importance scores (one per explanatory variable)
</p>


<h3>Author(s)</h3>

<p>Xiaomeng Ju, <a href="mailto:xiaomeng.ju@stat.ubc.ca">xiaomeng.ju@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(airfoil)
n &lt;- nrow(airfoil)
n0 &lt;- floor( 0.2 * n )
set.seed(123)
idx_test &lt;- sample(n, n0)
idx_train &lt;- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val &lt;- (1:n)[ -c(idx_test, idx_train) ]
xx &lt;- airfoil[, -6]
yy &lt;- airfoil$y
xtrain &lt;- xx[ idx_train, ]
ytrain &lt;- yy[ idx_train ]
xval &lt;- xx[ idx_val, ]
yval &lt;- yy[ idx_val ]
xtest &lt;- xx[ idx_test, ]
ytest &lt;- yy[ idx_test ]
model = Boost(x_train = xtrain, y_train = ytrain,
     x_val = xval, y_val = yval,
     type = "RRBoost", error = "rmse",
     y_init = "LADTree", max_depth = 1, niter = 1000,
     control = Boost.control(max_depth_init = 2,
           min_leaf_size_init = 10, save_tree = TRUE,
           make_prediction =  FALSE, cal_imp = FALSE))
var_importance &lt;-  cal_imp_func(model, x_val = xval, y_val= yval)

## End(Not run)

</code></pre>

<hr>
<h2 id='cal_predict'>cal_predict</h2><span id='topic+cal_predict'></span>

<h3>Description</h3>

<p>A function to make predictions and calculate test error given an object returned by Boost and test data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_predict(model, x_test, y_test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal_predict_+3A_model">model</code></td>
<td>
<p>an object returned by Boost</p>
</td></tr>
<tr><td><code id="cal_predict_+3A_x_test">x_test</code></td>
<td>
<p>predictor matrix for test data (matrix/dataframe)</p>
</td></tr>
<tr><td><code id="cal_predict_+3A_y_test">y_test</code></td>
<td>
<p>response vector for test data (vector/dataframe)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function to make predictions and calculate test error given an object returned by Boost and test data
</p>


<h3>Value</h3>

<p>A list with with the following components:
</p>
<table role = "presentation">
<tr><td><code>f_t_test</code></td>
<td>
<p>predicted values with model at the early stopping iteration using x_test as the predictors</p>
</td></tr>
<tr><td><code>err_test</code></td>
<td>
<p>a matrix of test errors before and at the early stopping iteration (returned if make_prediction = TRUE in control); the matrix dimension is the early stopping iteration by the number of error types (matches the <code>error</code> argument in the input); each row corresponds to the test errors at each iteration</p>
</td></tr>
<tr><td><code>f_test</code></td>
<td>
<p>a matrix of test function estimates at all iterations (returned if save_f = TRUE in control)</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>a vector of test errors evaluated at the early stopping iteration</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Xiaomeng Ju, <a href="mailto:xiaomeng.ju@stat.ubc.ca">xiaomeng.ju@stat.ubc.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(airfoil)
n &lt;- nrow(airfoil)
n0 &lt;- floor( 0.2 * n )
set.seed(123)
idx_test &lt;- sample(n, n0)
idx_train &lt;- sample((1:n)[-idx_test], floor( 0.6 * n ) )
idx_val &lt;- (1:n)[ -c(idx_test, idx_train) ]
xx &lt;- airfoil[, -6]
yy &lt;- airfoil$y
xtrain &lt;- xx[ idx_train, ]
ytrain &lt;- yy[ idx_train ]
xval &lt;- xx[ idx_val, ]
yval &lt;- yy[ idx_val ]
xtest &lt;- xx[ idx_test, ]
ytest &lt;- yy[ idx_test ]
model = Boost(x_train = xtrain, y_train = ytrain,
     x_val = xval, y_val = yval,
     type = "RRBoost", error = "rmse",
     y_init = "LADTree", max_depth = 1, niter = 1000,
     control = Boost.control(max_depth_init = 2,
           min_leaf_size_init = 10, save_tree = TRUE,
           make_prediction =  FALSE, cal_imp = FALSE))
prediction &lt;- cal_predict(model, x_test = xtest, y_test = ytest)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
