<!DOCTYPE html><html><head><title>Help for package FeatureTerminatoR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FeatureTerminatoR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mutlicol_terminator'><p>Multicollinearity TerminatoR - Feature Selection to remove highly correlated values</p></a></li>
<li><a href='#rfeTerminator'><p>Recursive Feature Engineering SelectoR</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Feature Selection Engine to Remove Features with Minimal
Predictive Power</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gary Hutson &lt;hutsons-hacks@outlook.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The aim is to take in data.frame inputs and utilises methods, such as recursive feature engineering, to enable the features to be removed.
    What this does differently from the other packages, is that it gives you the choice to remove the variables manually, or it automated this process.
    Feature selection is a concept in machine learning, and statistical pipelines, whereby unimportant, or less predictive variables are eliminated from the analysis, see Boughaci (2018) &lt;<a href="https://doi.org/10.1007%2Fs40595-018-0107-y">doi:10.1007/s40595-018-0107-y</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, caret, tibble, dplyr, stats, utils, lattice, e1071,
randomForest</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, rmarkdown</td>
</tr>
<tr>
<td>LazyData:</td>
<td>FALSE</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-07-13 18:50:19 UTC; garyh</td>
</tr>
<tr>
<td>Author:</td>
<td>Gary Hutson <a href="https://orcid.org/0000-0003-3534-6143"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-07-14 09:00:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='mutlicol_terminator'>Multicollinearity TerminatoR - Feature Selection to remove highly correlated values</h2><span id='topic+mutlicol_terminator'></span>

<h3>Description</h3>

<p>This function looks at highly correlated features and allows for a correlation cutoff to be set.
Outputs from this function allow for correlations and covariance matrices to be created, alongside visuals and the
ability to remove highly correlated features from your statistic pipeline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mutlicol_terminator(df, x_cols, y_cols, alter_df = TRUE, cor_sig = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mutlicol_terminator_+3A_df">df</code></td>
<td>
<p>The data frame to pass with the x and y variables</p>
</td></tr>
<tr><td><code id="mutlicol_terminator_+3A_x_cols">x_cols</code></td>
<td>
<p>The independent variables we want to analyse for multicollinearity</p>
</td></tr>
<tr><td><code id="mutlicol_terminator_+3A_y_cols">y_cols</code></td>
<td>
<p>The dependent variables(s) in your predictive model</p>
</td></tr>
<tr><td><code id="mutlicol_terminator_+3A_alter_df">alter_df</code></td>
<td>
<p><strong>Default=TRUE</strong> - Determines whether the underlying features are removed from the data frame, with TRUE being the default.</p>
</td></tr>
<tr><td><code id="mutlicol_terminator_+3A_cor_sig">cor_sig</code></td>
<td>
<p><strong>Default=0.9</strong> - A correlation significance for the cut-off in inter-feature correlation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the outputs highlighted hereunder:
</p>
<p>det
</p>
<ul>
<li><p><strong>&quot;rfe_model_fit_results&quot;</strong> a list of the model fit results. Including the optimal features
</p>
</li>
<li><p><strong>&quot;rfe_reduced_features&quot;</strong> a data.frame object with the reduced variables and data
</p>
</li>
<li><p><strong>&quot;rfe_original_data&quot;</strong> a data.frame object with the original data passed for manual exclusion based on fit outputs
</p>
</li>
<li><p><strong>&quot;rfe_reduced_data&quot;</strong>output of setting the alter_df=TRUE will remove the features / IVs from the data.frame
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(caret)
library(FeatureTerminatoR)
library(tibble)
library(dplyr)
df &lt;- iris
mc_fit &lt;- mutlicol_terminator(df, 1:4,5, cor_sig = 0.90, alter_df = TRUE)
#View the correlation matrix
mc_fit$corr_matrix
#View the reduced data
head(mc_fit$feature_removed_df,10)
</code></pre>

<hr>
<h2 id='rfeTerminator'>Recursive Feature Engineering SelectoR</h2><span id='topic+rfeTerminator'></span>

<h3>Description</h3>

<p>This function removes the redundant features in a model and automatically selects the best combination of features to remove.
This utilises, by default, the random forest mean decrease in accuracy methods, from the caret package, reference Kuhn (2021).
This function is a wrapper for the <strong>rfe()</strong> function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfeTerminator(
  df,
  x_cols,
  y_cols,
  method = "cv",
  kfolds = 10,
  sizes = c(1:100),
  alter_df = TRUE,
  eval_funcs = rfFuncs,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rfeTerminator_+3A_df">df</code></td>
<td>
<p>data frame to fit the recursive feature engineering algorithm to</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_x_cols">x_cols</code></td>
<td>
<p>the independent variables to be used for the recursive feature engineering algorithm</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_y_cols">y_cols</code></td>
<td>
<p>the dependent variables to be used in the prediction</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_method">method</code></td>
<td>
<p><strong><em>Default = &quot;cv&quot;</em></strong>- cross validation method for resampling, other options &quot;repeatedcv&quot;</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_kfolds">kfolds</code></td>
<td>
<p><em>Default = 10</em> - the number of k folds - train / test splits to compute when resampling</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_sizes">sizes</code></td>
<td>
<p>the sizes of the search boundary for the search</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_alter_df">alter_df</code></td>
<td>
<p><em>Default = TRUE</em> - will remove the redundant features, due to having a lesser affect on the mean decrease in accuracy, or other measures.</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_eval_funcs">eval_funcs</code></td>
<td>
<p><em>Default = rfFuncs</em> (Random Forest Mean Decrease Accuracy method). Other options: rfe, lmFuncs, rfFuncs, treebagFuncs, nbFuncs, pickSizeBest, pickSizeTolerance.</p>
</td></tr>
<tr><td><code id="rfeTerminator_+3A_...">...</code></td>
<td>
<p>Function forwarding to main 'caret::rfe() function' to pass in additional parameters native to caret</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With the df_alter set to TRUE the recursive feature algorithm chosen will automatically remove the features from the returned tibble embedded in the list.
</p>


<h3>Value</h3>

<p>A list containing the outputs highlighted hereunder:
</p>

<ul>
<li><p><strong>&quot;rfe_model_fit_results&quot;</strong> a list of the model fit results. Including the optimal features
</p>
</li>
<li><p><strong>&quot;rfe_reduced_features&quot;</strong> a data.frame object with the reduced variables and data
</p>
</li>
<li><p><strong>&quot;rfe_original_data&quot;</strong> a data.frame object with the original data passed for manual exclusion based on fit outputs
</p>
</li>
<li><p><strong>&quot;rfe_reduced_data&quot;</strong>output of setting the alter_df=TRUE will remove the features / IVs from the data.frame
</p>
</li></ul>



<h3>References</h3>

<p>Kuhn (2021) Recursive Feature Elimination. <a href="https://topepo.github.io/caret/recursive-feature-elimination.html">https://topepo.github.io/caret/recursive-feature-elimination.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(caret)
library(tibble)
library(FeatureTerminatoR)
library(dplyr)
df &lt;- iris
# Passing in the indexes as slices x values located in index 1:4 and y value in location 5
rfe_fit &lt;- rfeTerminator(df, x_cols= 1:4, y_cols=5, alter_df = TRUE, eval_funcs = rfFuncs)
#Explore the optimal model results
print(rfe_fit$rfe_model_fit_results)
# Explore the optimal variables selected
print(rfe_fit$rfe_model_fit_results$optVariables)
# Explore the original data passed to the frame
print(head(rfe_fit$rfe_original_data))
# Explore the data adapted with the less important features removed
print(head(rfe_fit$rfe_reduced_data))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
