<!DOCTYPE html><html><head><title>Help for package snowfall</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {snowfall}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#snowfall-package'><p>Toplevel useability wrapper for snow to make parallel programming even</p>
more easy and comfortable.
All functions are able to run without cluster in sequential mode.
Also snowfall works as connector to the cluster management
program sfCluster, but can also run without it.</a></li>
<li><a href='#snowfall-calculation'><p>Parallel calculation functions</p></a></li>
<li><a href='#snowfall-data'><p>Internal configuration and test data</p></a></li>
<li><a href='#snowfall-init'><p>Initialisation of cluster usage</p></a></li>
<li><a href='#snowfall-tools'><p>Cluster tools</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Easier Cluster Computing (Based on 'snow')</td>
</tr>
<tr>
<td>Version:</td>
<td>1.84-6.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2013-12-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Jochen Knaus</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jochen Knaus &lt;jo@imbi.uni-freiburg.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Usability wrapper around snow for easier development of
        parallel R programs. This package offers e.g. extended error
        checks, and additional functions. All functions work in
        sequential mode, too, if no cluster is present or wished.
        Package is also designed as connector to the cluster management
        tool sfCluster, but can also used without it.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10), snow</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rmpi</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-26 11:34:08 UTC; hornik</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-26 13:55:58 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
</table>
<hr>
<h2 id='snowfall-package'>Toplevel useability wrapper for snow to make parallel programming even
more easy and comfortable.
All functions are able to run without cluster in sequential mode.
Also snowfall works as connector to the cluster management
program sfCluster, but can also run without it.</h2><span id='topic+snowfall-package'></span><span id='topic+snowfall'></span>

<h3>Description</h3>

<p><span class="pkg">snowfall</span> is designed to make setup and usage of <span class="pkg">snow</span> more
easier. It also is made ready to work together with <code>sfCluster</code>,
a ressource management and runtime observation tool for
R-cluster usage.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> snowfall</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.61</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2008-11-01</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Initialisation</h3>

<p>Initalisation via <code>sfInit</code> must be called
before the usage
of any of the <span class="pkg">snowfall</span> internal functions. <code>sfStop</code> stopps
the current cluster. Some additional functions give access to build-in
functions (like <code>sfParallel</code>, <code>sfCpus</code> etc.).
</p>


<h3>Calculations</h3>

<p>The are plenty of function to execute parallel
calculations via <span class="pkg">snowfall</span>. Most of them are wrappers to the
according <span class="pkg">snow</span> functions, but there are additional functions as
well. Most likely the parallel versions of the R-buildin applies are
interesting: <code>sfLapply</code>, <code>sfSapply</code> and <code>sfApply</code>. For
better cluster take a look at the load balanced
<code>sfClusterApplyLB</code> and the function with restore possibilities:
<code>sfClusterApplySR</code>.
</p>


<h3>Tools</h3>

<p>Various tools allow an easier access to parallel
computing: <code>sfLibrary</code> and <code>sfSource</code> for loading code on
the cluster, <code>sfExport</code>, <code>sfExportAll</code>, <code>sfRemoveAll</code>
and <code>sfRemoveAll</code> for variable sperading on the cluster. And some
more.
</p>


<h3>sfCluster</h3>

<p><span class="pkg">snowfall</span> is also the R-connector to the
cluster management program <code>sfCluster</code>. Mostly all of the
communication to this tool is done implicit and directly affecting the
initialisation via <code>sfInit</code>. Using <code>sfCluster</code> makes the
parallel programming with <span class="pkg">snowfall</span> even more practicable in real
life environments.
</p>
<p>For futher informations about the usage of <code>sfCluster</code> look at
its documentation.
</p>


<h3>Author(s)</h3>

<p>Jochen Knaus
</p>
<p>Maintainer:
Jochen Knaus &lt;jo@imbi.uni-freiburg.de&gt;,
</p>


<h3>References</h3>

<p><span class="pkg">snow</span> (Simple Network of Workstations):<br />
http://cran.r-project.org/src/contrib/Descriptions/snow.html<br /><br />
</p>
<p><code>sfCluster</code> (Unix management tool for <span class="pkg">snowfall</span> clusters):<br />
http://www.imbi.uni-freiburg.de/parallel<br />
</p>


<h3>See Also</h3>

<p>Snowfall Initialisation: <code><a href="#topic+snowfall-init">snowfall-init</a></code><br />
Snowfall Calculation: <code><a href="#topic+snowfall-calculation">snowfall-calculation</a></code><br />
Snowfall Tools: <code><a href="#topic+snowfall-tools">snowfall-tools</a></code><br />
</p>
<p>Optional links to other man pages, e.g. <code><a href="snow.html#topic+snow-cluster">snow-cluster</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Init Snowfall with settings from sfCluster
  ##sfInit()

  # Init Snowfall with explicit settings.
  sfInit( parallel=TRUE, cpus=2 )

  if( sfParallel() )
    cat( "Running in parallel mode on", sfCpus(), "nodes.\n" )
  else
    cat( "Running in sequential mode.\n" )

  # Define some global objects.
  globalVar1 &lt;- c( "a", "b", "c" )
  globalVar2 &lt;- c( "d", "e" )
  globalVar3 &lt;- c( 1:10 )
  globalNoExport &lt;- "dummy"

  # Define stupid little function.
  calculate &lt;- function( x ) {
    cat( x )
    return( 2 ^ x )
  }

  # Export all global objects except globalNoExport
  # List of exported objects is listed.
  # Work both parallel and sequential.
  sfExportAll( except=c( "globalNoExport" ) )

  # List objects on each node.
  sfClusterEvalQ( ls() )

  # Calc something with parallel sfLappy
  cat( unlist( sfLapply( globalVar3, calculate ) ) )

  # Remove all variables from object.
  sfRemoveAll( except=c( "calculate" ) )

## End(Not run)
</code></pre>

<hr>
<h2 id='snowfall-calculation'>Parallel calculation functions</h2><span id='topic+snowfall-calculation'></span><span id='topic+sfClusterMap'></span><span id='topic+sfClusterApply'></span><span id='topic+sfClusterApplyLB'></span><span id='topic+sfClusterApplySR'></span><span id='topic+sfLapply'></span><span id='topic+sfSapply'></span><span id='topic+sfApply'></span><span id='topic+sfRapply'></span><span id='topic+sfCapply'></span><span id='topic+sfMM'></span><span id='topic+sfRestore'></span>

<h3>Description</h3>

<p>Parallel calculation functions. Execution is distributed automatically
over the cluster.<br />
Most of this functions are wrappers for <span class="pkg">snow</span> functions, but all
can be used directly in sequential mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfClusterApply( x, fun, ... )
sfClusterApplyLB( x, fun, ... )
sfClusterApplySR( x, fun, ..., name="default", perUpdate=NULL, restore=sfRestore() )

sfClusterMap( fun, ..., MoreArgs = NULL, RECYCLE = TRUE )

sfLapply( x, fun, ... )
sfSapply( x, fun, ..., simplify = TRUE, USE.NAMES = TRUE )
sfApply( x, margin, fun, ... )
sfRapply( x, fun, ... )
sfCapply( x, fun, ... )

sfMM( a, b )

sfRestore()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snowfall-calculation_+3A_x">x</code></td>
<td>
<p>vary depending on function. See function details below.</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_fun">fun</code></td>
<td>
<p>function to call</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_margin">margin</code></td>
<td>
<p>vector speficying the dimension to use</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to standard function</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_simplify">simplify</code></td>
<td>
<p>logical; see <code>sapply</code></p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_use.names">USE.NAMES</code></td>
<td>
<p>logical; see <code>sapply</code></p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_a">a</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_b">b</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_recycle">RECYCLE</code></td>
<td>
<p>see snow documentation</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_moreargs">MoreArgs</code></td>
<td>
<p>see snow documentation</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_name">name</code></td>
<td>
<p>a character string indicating the name of this parallel
execution. Naming is only needed if there are more than one call to
<code>sfClusterApplySR</code> in a program.</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_perupdate">perUpdate</code></td>
<td>
<p>a numerical value indicating the progress
printing. Values range from 1 to 100 (no printing). Value means: any
X percent of progress status is printed. Default (on given value &lsquo;NULL&rsquo;) is 5).</p>
</td></tr>
<tr><td><code id="snowfall-calculation_+3A_restore">restore</code></td>
<td>
<p>logical indicating whether results from previous runs
should be restored or not. Default is coming from sfCluster. If
running without sfCluster, default is FALSE, if yes, it is set to
the value coming from the external program.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sfClusterApply</code> calls each index of a given list on a seperate
node, so length of given list must be smaller than nodes. Wrapper for
<span class="pkg">snow</span> function <code>clusterApply</code>.
</p>
<p><code>sfClusterApplyLB</code> is a load balanced version of
<code>sfClusterApply</code>. If a node finished it's list segment it
immidiately starts with the next segment. Use this function in
infrastructures with machines with different speed. Wrapper for
<span class="pkg">snow</span> function <code>clusterApplyLB</code>.
</p>
<p><code>sfClusterApplySR</code> saves intermediate results and is able to
restore them on a restart. Use this function on very long calculations
or it is (however) foreseeable that cluster will not be able to finish
it's calculations (e.g. because of a shutdown of a node machine). If
your program use more than one parallised part, argument <code>name</code>
must be given with a unique name for each loop. Intermediate data is
saved depending on R-filename, so restore of data must be explicit
given for not confusing changes on your R-file (it is recommended to
only restore on fully tested programs). If restores,
<code>sfClusterApplySR</code> continues calculation after the first non-null
value in the saved list. If your parallized function can return null
values, you probably want to change this.
</p>
<p><code>sfLapply</code>, <code>sfSapply</code> and <code>sfApply</code> are parallel
versions of <code>lapply</code>, <code>sapply</code> and <code>apply</code>. The first
two use an list or vector as argument, the latter an array.
</p>
<p><code>parMM</code> is a parallel matrix multiplication.  Wrapper for
<span class="pkg">snow</span> function <code>parMM</code>.
</p>
<p><em><code>sfRapply</code> and <code>sfCapply</code> are not implemented atm.</em>
</p>


<h3>See Also</h3>

<p>See snow documentation for details on commands:
<code><a href="snow.html#topic+snow-parallel">snow-parallel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  restoreResults &lt;- TRUE

  sfInit(parallel=FALSE)

  ## Execute in cluster or sequential.
  sfLapply(1:10, exp)

  ## Execute with intermediate result saving and restore on wish.
  sfClusterApplySR(1:100, exp, name="CALC_EXP", restore=restoreResults)
  sfClusterApplySR(1:100, sum, name="CALC_SUM", restore=restoreResults)

  sfStop()

  ##
  ## Small bootstrap example.
  ##
  sfInit(parallel=TRUE, cpus=2)

  require(mvna)
  data(sir.adm)

  sfExport("sir.adm", local=FALSE)
  sfLibrary(cmprsk)

  wrapper &lt;- function(a) {
    index &lt;- sample(1:nrow(sir.adm), replace=TRUE)
    temp &lt;- sir.adm[index, ]
    fit &lt;- crr(temp$time, temp$status, temp$pneu, failcode=1, cencode=0)
    return(fit$coef)
  }

  result &lt;- sfLapply(1:100, wrapper)

  mean( unlist( rbind( result ) ) )
  sfStop()

## End(Not run)
</code></pre>

<hr>
<h2 id='snowfall-data'>Internal configuration and test data</h2><span id='topic+config'></span><span id='topic+sfOption'></span><span id='topic+f1'></span><span id='topic+f2'></span>

<h3>Description</h3>

<p>Internal configuration and test data. Only used for internal setup and
testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>config
f1
f2
sfOption
</code></pre>


<h3>Format</h3>

<p>A matrix containing basic predefined configuration informations.</p>

<hr>
<h2 id='snowfall-init'>Initialisation of cluster usage</h2><span id='topic+snowfall-init'></span><span id='topic+sfInit'></span><span id='topic+sfStop'></span><span id='topic+sfParallel'></span><span id='topic+sfCpus'></span><span id='topic+sfNodes'></span><span id='topic+sfType'></span><span id='topic+sfIsRunning'></span><span id='topic+sfSocketHosts'></span><span id='topic+sfGetCluster'></span><span id='topic+sfSession'></span><span id='topic+sfSetMaxCPUs'></span>

<h3>Description</h3>

<p>Initialisation and organisation code to use <span class="pkg">snowfall</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfInit( parallel=NULL, cpus=NULL, type=NULL, socketHosts=NULL, restore=NULL,
        slaveOutfile=NULL, nostart=FALSE, useRscript=FALSE )
sfStop( nostop=FALSE )

sfParallel()
sfIsRunning()
sfCpus()
sfNodes()
sfGetCluster()
sfType()
sfSession()
sfSocketHosts()
sfSetMaxCPUs( number=32 )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snowfall-init_+3A_parallel">parallel</code></td>
<td>
<p>Logical determinating parallel or sequential
execution. If not set values from commandline are taken.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_cpus">cpus</code></td>
<td>
<p>Numerical amount of CPUs requested for the cluster. If
not set, values from the commandline are taken.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_nostart">nostart</code></td>
<td>
<p>Logical determinating if the basic cluster setup should
be skipped. Needed for nested use of <span class="pkg">snowfall</span> and usage in
packages.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_type">type</code></td>
<td>
<p>Type of cluster. Can be 'SOCK', 'MPI', 'PVM' or 'NWS'. Default is 'SOCK'.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_sockethosts">socketHosts</code></td>
<td>
<p>Host list for socket clusters. Only needed for
socketmode (SOCK) and
if using more than one machines (if using only your local machine
(localhost) no list is needed).</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_restore">restore</code></td>
<td>
<p>Globally set the restore behavior in the call
<code>sfClusterApplySR</code> to the given value.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_slaveoutfile">slaveOutfile</code></td>
<td>
<p>Write R slave output to this file. Default: no
output (Unix: <code>/dev/null</code>, Windows: <code>:nul</code>). If
using sfCluster this argument has no function, as slave logs are
defined using sfCluster.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_userscript">useRscript</code></td>
<td>
<p>Change startup behavior (snow&gt;0.3 needed): use shell scripts or R-script for startup (R-scripts beeing the new variant, but not working with sfCluster.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_nostop">nostop</code></td>
<td>
<p>Same as noStart for ending.</p>
</td></tr>
<tr><td><code id="snowfall-init_+3A_number">number</code></td>
<td>
<p>Amount of maximum CPUs useable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sfInit</code> initialisise the usage of the <span class="pkg">snowfall</span> functions
and - if running in parallel mode - setup the cluster and
<span class="pkg">snow</span>. If using
<code>sfCluster</code> management tool, call this without arguments. If
<code>sfInit</code> is called with arguments, these overwrite
<code>sfCluster</code> settings. If running parallel, <code>sfInit</code>
set up the
cluster by calling <code>makeCluster</code> from <span class="pkg">snow</span>. If using with
<code>sfCluster</code>, the initialisation also contains management of
lockfiles. If this function is called more than once and current
cluster is yet running, <code>sfStop</code> is called automatically.
</p>
<p>Note that you should call <code>sfInit</code> before using any other function
from <span class="pkg">snowfall</span>, with the only exception <code>sfSetMaxCPUs</code>.
If you do not call <code>sfInit</code> first, on calling any <span class="pkg">snowfall</span>
function <code>sfInit</code> is called without any parameters, which is
equal to sequential mode in <span class="pkg">snowfall</span> only mode or the settings from
sfCluster if used with sfCluster.
</p>
<p>This also means, you cannot check if <code>sfInit</code> was called from
within your own program, as any call to a function will initialize
again. Therefore the function <code>sfIsRunning</code> gives you a logical
if a cluster is running. Please note: this will not call <code>sfInit</code>
and it also returns true if a previous running cluster was stopped via
<code>sfStop</code> in the meantime.
</p>
<p>If you use <span class="pkg">snowfall</span> in a package argument <code>nostart</code> is very
handy if mainprogram uses <span class="pkg">snowfall</span> as well. If set, cluster
setup will be skipped and both parts (package and main program) use
the same cluster.
</p>
<p>If you call <code>sfInit</code> more than one time in a program without
explicit calling <code>sfStop</code>, stopping of the cluster will be
executed automatically. If your R-environment does not cover required
libraries, <code>sfInit</code> automatically switches to sequential mode
(with a warning). Required libraries for parallel usage are <span class="pkg">snow</span>
and depending on argument <code>type</code> the libraries for the
cluster mode (none for
socket clusters, <span class="pkg">Rmpi</span> for MPI clusters, <span class="pkg">rpvm</span> for
PVM clusters and <span class="pkg">nws</span> for NetWorkSpaces).
</p>
<p>If using Socket or NetWorkSpaces, <code>socketHosts</code> can be used to
specify the hosts you want to have your workers running.
Basically this is a list, where any entry can be a plain character
string with IP or hostname (depending on your DNS settings). Also
for real heterogenous clusters for any host pathes are setable. Please
look to the acccording <span class="pkg">snow</span> documentation for details.
If you are not giving an socketlist, a list with the required amount
of CPUs on your local machine (localhost) is used. This would be the
easiest way to use parallel computing on a single machine, like a
laptop.
</p>
<p>Note there is limit on CPUs used in one program (which can be
configured on package installation). The current limit are 32 CPUs. If
you need a higher amount of CPUs, call <code>sfSetMaxCPUs</code>
<em>before</em> the first call to <code>sfInit</code>. The limit is set to
prevent inadvertently request by single users affecting the cluster as
a whole.
</p>
<p>Use <code>slaveOutfile</code> to define a file where to write the log
files. The file location must be available on all nodes. Beware of
taking a location on a shared network drive! Under *nix systems, most
likely the directories <code>/tmp</code> and <code>/var/tmp</code> are not shared
between the different machines. The default is no output file.
If you are using <code>sfCluster</code> this
argument have no meaning as the slave logs are always created in a
location of <code>sfClusters</code> choice (depending on it's configuration).
</p>
<p><code>sfStop</code> stop cluster. If running in parallel mode, the LAM/MPI
cluster is shut down.
</p>
<p><code>sfParallel</code>, <code>sfCpus</code> and <code>sfSession</code> grant access to
the internal state of the currently used cluster.
All three can be configured via commandline and especially with
<code>sfCluster</code> as well, but given
arguments in <code>sfInit</code> always overwrite values on commandline.
The commandline options are <span class="option">--parallel</span> (empty option. If missing,
sequential mode is forced), <span class="option">--cpus=X</span> (for nodes, where X is a
numerical value) and <span class="option">--session=X</span> (with X a string).
</p>
<p><code>sfParallel</code> returns a
logical if program is running in parallel/cluster-mode or sequential
on a single processor.
</p>
<p><code>sfCpus</code> returns the size of the cluster in CPUs
(equals the CPUs which are useable). In sequential mode <code>sfCpus</code>
returns one. <code>sfNodes</code> is a deprecated similar to <code>sfCpus</code>.
</p>
<p><code>sfSession</code> returns a string with the
session-identification. It is mainly important if used with the
<code>sfCluster</code> tool.
</p>
<p><code>sfGetCluster</code> gets the <span class="pkg">snow</span>-cluster handler. Use for
direct calling of <span class="pkg">snow</span> functions.
</p>
<p><code>sfType</code> returns the type of the current cluster backend (if
used any). The value can be SOCK, MPI, PVM or NWS for parallel
modes or &quot;- sequential -&quot; for sequential execution.
</p>
<p><code>sfSocketHosts</code> gives the list with currently used hosts for
socket clusters. Returns empty list if not used in socket mode (means:
<code>sfType() != 'SOCK'</code>).
</p>
<p><code>sfSetMaxCPUs</code> enables to set a higher maximum CPU-count for this
program. If you need higher limits, call <code>sfSetMaxCPUs</code> before
<code>sfInit</code> with the new maximum amount.
</p>


<h3>See Also</h3>

<p>See snow documentation for details on commands:
<code>link[snow]{snow-cluster}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Run program in plain sequential mode.
  sfInit( parallel=FALSE )
  stopifnot( sfParallel() == FALSE )
  sfStop()

  # Run in parallel mode overwriting probably given values on
  # commandline.
  # Executes via Socket-cluster with 4 worker processes on
  # localhost.
  # This is probably the best way to use parallel computing
  # on a single machine, like a notebook, if you are not
  # using sfCluster.
  # Uses Socketcluster (Default) - which can also be stated
  # using type="SOCK".
  sfInit( parallel=TRUE, cpus=4 )
  stopifnot( sfCpus() == 4 )
  stopifnot( sfParallel() == TRUE )
  sfStop()

  # Run parallel mode (socket) with 4 workers on 3 specific machines.
  sfInit( parallel=TRUE, cpus=4, type="SOCK",
          socketHosts=c( "biom7", "biom7", "biom11", "biom12" ) )
  stopifnot( sfCpus() == 4 )
  stopifnot( sfParallel() == TRUE )
  sfStop()

  # Hook into MPI cluster.
  # Note: you can use any kind MPI cluster Rmpi supports.
  sfInit( parallel=TRUE, cpus=4, type="MPI" )
  sfStop()

  # Hook into PVM cluster.
  sfInit( parallel=TRUE, cpus=4, type="PVM" )
  sfStop()

  # Run in sfCluster-mode: settings are taken from commandline:
  # Runmode (sequential or parallel), amount of nodes and hosts which
  # are used.
  sfInit()

  # Session-ID from sfCluster (or XXXXXXXX as default)
  session &lt;- sfSession()

  # Calling a snow function: cluster handler needed.
  parLapply( sfGetCluster(), 1:10, exp )

  # Same using snowfall wrapper, no handler needed.
  sfLapply( 1:10, exp )

  sfStop()

## End(Not run)
</code></pre>

<hr>
<h2 id='snowfall-tools'>Cluster tools</h2><span id='topic+snowfall-tools'></span><span id='topic+sfLibrary'></span><span id='topic+sfSource'></span><span id='topic+sfExport'></span><span id='topic+sfExportAll'></span><span id='topic+sfRemove'></span><span id='topic+sfRemoveAll'></span><span id='topic+sfCat'></span><span id='topic+sfClusterSplit'></span><span id='topic+sfClusterCall'></span><span id='topic+sfClusterEval'></span><span id='topic+sfClusterEvalQ'></span><span id='topic+sfClusterSetupRNG'></span><span id='topic+sfClusterSetupRNGstream'></span><span id='topic+sfClusterSetupSPRNG'></span><span id='topic+sfTest'></span>

<h3>Description</h3>

<p>Tools for cluster usage. Allow easier handling of cluster programming.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfLibrary( package, pos=2,
           lib.loc=NULL, character.only=FALSE,
           warn.conflicts=TRUE,
           keep.source=NULL,
           verbose=getOption("verbose"), version,
           stopOnError=TRUE )
sfSource( file, encoding = getOption("encoding"), stopOnError = TRUE )
sfExport( ..., list=NULL, local=TRUE, namespace=NULL, debug=FALSE, stopOnError = TRUE )
sfExportAll( except=NULL, debug=FALSE )

sfRemove( ..., list=NULL, master=FALSE, debug=FALSE )
sfRemoveAll( except=NULL, debug=FALSE, hidden=TRUE )

sfCat( ..., sep=" ", master=TRUE )

sfClusterSplit( seq )
sfClusterCall( fun, ..., stopOnError=TRUE )
sfClusterEval( expr, stopOnError=TRUE )

sfClusterSetupRNG( type="RNGstream", ... )
sfClusterSetupRNGstream( seed=rep(12345,6), ... )
sfClusterSetupSPRNG( seed=round(2^32*runif(1)), prngkind="default", para=0, ... )

sfTest()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snowfall-tools_+3A_expr">expr</code></td>
<td>
<p>expression to evaluate</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_seq">seq</code></td>
<td>
<p>vector to split</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_fun">fun</code></td>
<td>
<p>function to call</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_list">list</code></td>
<td>
<p>character vector with names of objects to export</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_local">local</code></td>
<td>
<p>a logical indicating if variables should taken from
local scope(s) or only from global.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_namespace">namespace</code></td>
<td>
<p>a character given a namespace where to search for the
object.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_debug">debug</code></td>
<td>
<p>a logical indicating extended information is given upon
action to be done (e.g. print exported variables, print context of
local variables etc.).</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_except">except</code></td>
<td>
<p>character vector with names of objects not to
export/remove</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_hidden">hidden</code></td>
<td>
<p>also remove hidden names (starting with a dot)?</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_sep">sep</code></td>
<td>
<p>a character string separating elements in x</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_master">master</code></td>
<td>
<p>a logical indicating if executed on master as well</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to standard function</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_package">package</code></td>
<td>
<p>name of the package. Check <code>library</code> for details.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_pos">pos</code></td>
<td>
<p>position in search path to load library.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_warn.conflicts">warn.conflicts</code></td>
<td>
<p>warn on conflicts (see &quot;library&quot;).</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_keep.source">keep.source</code></td>
<td>
<p>see &quot;library&quot;. Please note: this argument has only
effect on R-2.x, starting with R-3.0 it will only be a placeholder
for backward compatibility.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_verbose">verbose</code></td>
<td>
<p>enable verbose messages.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_version">version</code></td>
<td>
<p>version of library to load (see &quot;library&quot;).</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_encoding">encoding</code></td>
<td>
<p>encoding of library to load (see &quot;library&quot;).</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_lib.loc">lib.loc</code></td>
<td>
<p>a character vector describing the location of the R
library trees to search through, or 'NULL'. Check <code>library</code> for
details.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_character.only">character.only</code></td>
<td>
<p>a logical indicating package can be assumed to
be a character string. Check <code>library</code> for details.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_file">file</code></td>
<td>
<p>filename of file to read. Check <code>source</code> for
details</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_stoponerror">stopOnError</code></td>
<td>
<p>a logical indicating if function stops on
failure or still returns. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_type">type</code></td>
<td>
<p>a character determine which random number generator should
be used for clusters. Allowed values are &quot;RNGstream&quot; for L'Ecuyer's
RNG or &quot;SPRNG&quot; for Scalable Parallel Random Number Generators.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_para">para</code></td>
<td>
<p>additional parameters for the RNGs.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_seed">seed</code></td>
<td>
<p>Seed for the RNG.</p>
</td></tr>
<tr><td><code id="snowfall-tools_+3A_prngkind">prngkind</code></td>
<td>
<p>type of RNG, see snow documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The current functions are little helpers to make cluster programming
easier.
All of these functions also work in sequential mode without any
further code changes.
</p>
<p><code>sfLibrary</code> loads an R-package on all nodes, including
master. Use this function if slaves need this library,
too. Parameters are identically to the R-build in funtion
<code><a href="base.html#topic+library">library</a></code>. If a relative path is given in <code>lib.loc</code>,
it is converted to an absolute path.\
As default <code>sfLibrary</code> stops on any error, but this can be
prevented by setting <code>stopOnError=FALSE</code>, the function is returning
<code>FALSE</code> then. On success <code>TRUE</code> is returned.
</p>
<p><code>sfSource</code> loads a sourcefile on all nodes, including master. Use
this function if the slaves need the code as well. Make sure the file
is accessible on all nodes under the same path. The loading is done
on slaves using <code>source</code> with fixes parameters:
<code>local=FALSE, chdir=FALSE, echo=FALSE</code>, so the files is loaded
global without changing of directory.\
As default <code>sfSource</code> stops on any error, but this can be
prevented by setting <code>stopOnError=FALSE</code>, the function is returning
<code>FALSE</code> then. On success <code>TRUE</code> is returned.
</p>
<p><code>sfExport</code> exports variables from the master to all
slaves. Use this function if slaves need acccess to these variables as
well. <code>sfExport</code> features two execution modes: local and global.
If using local mode (default), variables for export are searched
backwards from current environment to <code>globalenv()</code>. Use this mode
if you want to export local variables from functions or other
scopes to the slaves. In global mode only global variables from master
are exported.\
<em>Note: all exported variables are <b>global</b> on the slaves!</em>\
If you have many identical named variables in different scopes, use
argument <code>debug=TRUE</code> to view the context the exported variable
is coming from.\
Variables are given as their names or as a
character vector with their names using argument <code>list</code>.
</p>
<p><code>sfExportAll</code> exports all global variables from the master to all
slaves with exception of the
given list. Use this functions if you want to export mostly all
variables to all slaves.\Argument <code>list</code> is a character vector
with names of the variables <em>not</em> to export.
</p>
<p><code>sfRemove</code> removes a list of global (previous exported or
generated) variables from slaves and (optional) master.
Use this function if there are large further unused variables
left on slave. Basically this is only interesting if you have more than
one explicit parallel task in your program - where the danger is slaves
memory usage exceed.\
If argument <code>master</code> is given, the variables are removed from
master as well (default is FALSE).\
Give names of variables as arguments, or use argument <code>list</code>
as a character vector with the names. For deep cleaning of slave
memory use <code>sfRemoveAll</code>.
</p>
<p><code>sfRemoveAll</code> removes all global variables from the slaves. Use
this functions if you want to remove mostly all
variables on the slaves.  Argument <code>list</code> is a character vector
with names of the variables <em>not</em> to remove.
</p>
<p><code>sfCat</code> is a debugging function printing a message on all slaves
(which appear in the logfiles).
</p>
<p><code>sfClusterSplit</code> splits a vector into one consecutive piece for
each cluster and returns as a list with length equal to the number of
cluster nodes. Wrapper for <span class="pkg">snow</span> function <code>clusterSplit</code>.
</p>
<p><code>sfClusterCall</code> calls a function on each node and returns list of
results. Wrapper for <span class="pkg">snow</span> function <code>clusterCall</code>.
</p>
<p><code>sfClusterEvalQ</code> evaluates a literal expression on all
nodes. Wrapper for <span class="pkg">snow</span> function <code>clusterEvalQ</code>.
</p>
<p><code>sfTest</code> is a simple unit-test for most of the build in functions.
It runs tests and compares the results for the correct behavior. Note
there are some warnings if using, this is intended (as behavior for
some errors is tested, too). use this if you are not sure all nodes are
running your R-code correctly (but mainly it is implemented for
development).
</p>


<h3>See Also</h3>

<p>See <span class="pkg">snow</span> documentation for details on wrapper-commands:
<code><a href="snow.html#topic+snow-parallel">snow-parallel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    sfInit( parallel=FALSE )

    ## Now works both in parallel as in sequential mode without
    ## explicit cluster handler.
    sfClusterEval( cat( "yummie\n" ) );

    ## Load a library on all slaves. Stop if fails.
    sfLibrary( tools )
    sfLibrary( "tools", character.only=TRUE )  ## Alternative.

    ## Execute in cluster or sequential.
    sfLapply( 1:10, exp )

    ## Export global Var
    gVar &lt;- 99
    sfExport( "gVar" )

    ## If there are local variables with same name which shall not
    ## be exported.
    sfExport( "gVar", local=FALSE )

    ## Export local variables
    var1 &lt;- 1    ## Define global
    var2 &lt;- "a"

    f1 &lt;- function() {
      var1 &lt;- 2
      var3 &lt;- "x"

      f2 &lt;- function() {
        var1 &lt;- 3

        sfExport( "var1", "var2", "var3", local=TRUE )
        sfClusterCall( var1 )    ## 3
        sfClusterCall( var2 )    ## "a"
        sfClusterCall( var3 )    ## "x"
      }

      f2()
    }

    f1()

    ## Init random number streams (snows functions, build upon
    ## packages rlecuyer/rsprng).
    sfClusterCall( runif, 4 )

    sfClusterSetupRNG()         ## L'Ecuyer is default.
    sfClusterCall( runif, 4 )

    sfClusterSetupRNG( type="SPRNG", seed = 9876)
    sfClusterCall( runif, 4 )

    ## Run unit-test on main functions.
    sfTest()

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
