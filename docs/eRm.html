<!DOCTYPE html><html><head><title>Help for package eRm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eRm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Analysis of Deviances'><p>Analysis of Deviances for Rasch Models</p></a></li>
<li><a href='#anova.llra'><p>Analysis of Deviance for Linear Logistic Models with Relaxed Assumptions</p></a></li>
<li><a href='#build_W'>
<p>Automatized Construction of LLRA Design Matrix</p></a></li>
<li><a href='#collapse_W'>
<p>Convenient Collapsing of LLRA Design Matrix</p></a></li>
<li><a href='#eRm.data'><p>Data for Computing Extended Rasch Models</p></a></li>
<li><a href='#gofIRT'><p>Various model tests and fit indices</p></a></li>
<li><a href='#IC'><p>Information criteria</p></a></li>
<li><a href='#item_info'><p>Calculate Item Information for 'eRm' objects</p></a></li>
<li><a href='#itemfit.ppar'><p>Residuals, Personfit and Itemfit Statistics</p></a></li>
<li><a href='#LLRA'><p>Fit Linear Logistic Models with Relaxed Assumptions (LLRA)</p></a></li>
<li><a href='#llra.datprep'><p>Prepare Data Set for LLRA Analysis</p></a></li>
<li><a href='#llraDat1'><p>An Artificial LLRA Data Set</p></a></li>
<li><a href='#llraDat2'><p>An Artificial LLRA Data Set</p></a></li>
<li><a href='#llradat3'><p>An Artificial LLRA Data Set</p></a></li>
<li><a href='#LLTM'><p>Estimation of linear logistic test models</p></a></li>
<li><a href='#LPCM'><p>Estimation of linear partial credit models</p></a></li>
<li><a href='#LRSM'><p>Estimation of linear rating scale models</p></a></li>
<li><a href='#LRtest'><p>Computation of Andersen's LR-test.</p></a></li>
<li><a href='#MLoef'><p>Martin-LÃ¶f's Likelihood-Ratio-Test</p></a></li>
<li><a href='#NonparametricTests'><p>A Function to Perform Nonparametric Rasch Model Tests</p></a></li>
<li><a href='#PCM'><p>Estimation of partial credit models</p></a></li>
<li><a href='#person.parameter'><p>Estimation of Person Parameters</p></a></li>
<li><a href='#PersonMisfit'><p>Person Misfit</p></a></li>
<li><a href='#phi.range'><p>Example User Function</p></a></li>
<li><a href='#plotDIF'>
<p>Confidence intervals plot of item parameter estimates.</p></a></li>
<li><a href='#plotGR'><p>Plot Treatment or Covariate Effects for LLRA</p></a></li>
<li><a href='#plotICC'><p>ICC Plots</p></a></li>
<li><a href='#plotINFO'><p>Plot Information For <code>'eRm'</code> objects</p></a></li>
<li><a href='#plotPImap'><p>Person-Item Map</p></a></li>
<li><a href='#plotPWmap'><p>Pathway Map</p></a></li>
<li><a href='#plotTR'><p>Plot Trend Effects for LLRA</p></a></li>
<li><a href='#predict.ppar'><p>Predict methods</p></a></li>
<li><a href='#print.eRm'><p>Methods for extended Rasch models</p></a></li>
<li><a href='#RaschSampler'><p>Rasch Sampler Package</p></a></li>
<li><a href='#RM'><p>Estimation of Rasch Models</p></a></li>
<li><a href='#rsampler'><p>Sampling Binary Matrices</p></a></li>
<li><a href='#RSctr'><p>Control Object</p></a></li>
<li><a href='#rsctrl'><p>Controls for the Sampling Function</p></a></li>
<li><a href='#rsextrmat'><p>Extracting a Matrix</p></a></li>
<li><a href='#rsextrobj'><p>Extracting Encoded Sample Matrices</p></a></li>
<li><a href='#RSM'><p>Estimation of rating scale models</p></a></li>
<li><a href='#RSmpl'><p>Sample Objects</p></a></li>
<li><a href='#rstats'><p>Calculating Statistics for the Sampled Matrices</p></a></li>
<li><a href='#Separation Reliability'><p>Person Separation Reliability</p></a></li>
<li><a href='#sim.2pl'><p>Simulation of 2-PL Data</p></a></li>
<li><a href='#sim.locdep'><p>Simulation locally dependent items</p></a></li>
<li><a href='#sim.rasch'><p>Simulation of Rasch homogeneous data</p></a></li>
<li><a href='#sim.xdim'><p>Simulation of multidimensional binary data</p></a></li>
<li><a href='#stepwiseIt'><p>Stepwise item elimination</p></a></li>
<li><a href='#summary.llra'><p>Summarizing Linear Logistic Models with Relaxed Assumptions (LLRA)</p></a></li>
<li><a href='#summary.RSctr'><p>Summary Method for Control Objects</p></a></li>
<li><a href='#summary.RSmpl'><p>Summary Methods for Sample Objects</p></a></li>
<li><a href='#test_info'><p>Calculate Test Information For <code>eRm</code> objects</p></a></li>
<li><a href='#thresholds'><p>Computation of item-category treshold parameters.</p></a></li>
<li><a href='#Waldtest'><p>Item-Specific Wald Test</p></a></li>
<li><a href='#xmpl'><p>Example Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Extended Rasch Modeling</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-14</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits Rasch models (RM), linear logistic test models (LLTM), rating scale model (RSM), linear rating scale models (LRSM), partial credit models (PCM), and linear partial credit models (LPCM).  Missing values are allowed in the data matrix.  Additional features are the ML estimation of the person parameters, Andersen's LR-test, item-specific Wald test, Martin-Loef-Test, nonparametric Monte-Carlo Tests, itemfit and personfit statistics including infit and outfit measures, ICC and other plots, automated stepwise item elimination, simulation module for various binary data matrices.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, methods, MASS, splines, Matrix,
lattice, colorspace, psych</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-14 15:46:48 UTC; patrick</td>
</tr>
<tr>
<td>Author:</td>
<td>Patrick Mair [cre, aut],
  Thomas Rusch [aut],
  Reinhold Hatzinger [aut],
  Marco J. Maier [aut],
  Rudolf Debelak [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Patrick Mair &lt;mair@fas.harvard.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-15 08:36:29 UTC</td>
</tr>
</table>
<hr>
<h2 id='Analysis+20of+20Deviances'>Analysis of Deviances for Rasch Models</h2><span id='topic+anova.eRm'></span><span id='topic+print.eRm_anova'></span>

<h3>Description</h3>

<p>Performs likelihood ratio tests against the model with the largest number of parameters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eRm'
anova(object, ...)

## S3 method for class 'eRm_anova'
print(x, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Analysis+2B20of+2B20Deviances_+3A_object">object</code></td>
<td>

<p>Gives the first object to be tested against others which follow, separated by commata.
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20Deviances_+3A_x">x</code></td>
<td>

<p>An object of class <code>"eRm_anova"</code>.
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20Deviances_+3A_...">...</code></td>
<td>

<p>Further models to test with <code>anova.eRm()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>anova</code> method is quite flexible and, as long the used data are identical, every model except the <abbr><span class="acronym">LLRA</span></abbr> can be tested against each other.
Regardless of the order that models are specified, they will always be sorted by the number of parameters in decreasing order.
If <code class="reqn">\geq3</code> models are passed to the method, all models will be tested against the first model (i.e., the one with the largest amount of parameters).
</p>


<h3>Value</h3>

<p><code>anova.eRm</code> returns a list object of class <code>eRm_anova</code> containing:
</p>
<table>
<tr><td><code>calls</code></td>
<td>
<p>function calls of the different models (character).</p>
</td></tr>
<tr><td><code>statistics</code></td>
<td>
<p>the analysis of deviances table (columns are <code>LLs</code>: conditional log-likelihoods, <code>dev</code>: deviances, <code>npar</code>: number of parameters, <code>LR</code>: likelihood ratio statistics, <code>df</code>: degrees of freedom, <code>p</code>: <code class="reqn">p</code>-values).</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Although, there is a check for identical data matrices used, the models have to be nested for the likelihood ratio test to work.
You have to ensure that this is the case, otherwise results will be invalid.
</p>
<p><abbr><span class="acronym">LLRA</span></abbr>s cannot be tested with other models (<abbr><span class="acronym">RM</span></abbr>, <abbr><span class="acronym">LLTM</span></abbr>, <abbr><span class="acronym">RSM</span></abbr>, ...); for more information see <code><a href="#topic+anova.llra">anova.llra</a></code>.</p>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.llra">anova.llra</a></code>, <code><a href="stats.html#topic+anova">anova</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>### dichotomous data
dmod1 &lt;- RM(lltmdat1)
dmod2 &lt;- LLTM(lltmdat1, mpoints = 2)
anova(dmod1, dmod2)

### polytomous data
pmod1 &lt;- RSM(rsmdat)
pmod2 &lt;- PCM(rsmdat)
anova(pmod1, pmod2)

W &lt;- cbind(rep(c(1,0), each=9), rep(c(0,1), each=9))
W
pmod3 &lt;- LPCM(rsmdat, W)
anova(pmod3, pmod1, pmod2) # note that models are sorted by npar
</code></pre>

<hr>
<h2 id='anova.llra'>Analysis of Deviance for Linear Logistic Models with Relaxed Assumptions</h2><span id='topic+anova.llra'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for one or more LLRA.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'llra'
anova(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.llra_+3A_object">object</code>, <code id="anova.llra_+3A_...">...</code></td>
<td>
<p>Objects of class &quot;llra&quot;, typically the result of a
call to <code><a href="#topic+LLRA">LLRA</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An analysis of deviance table will be calculated. The models in rows are
ordered from the smallest to the largest model. Each row shows the
number of parameters (Npar) and the log-likelihood (logLik). For all but
the first model, the parameter difference (df) and the difference in
deviance or the likelihood ratio (-2LR) is given between two subsequent
models (with increasing complexity). Please note that interpreting these
values only makes sense if the models are nested. 
</p>
<p>The table also contains p-values comparing the reduction in the
deviance to the df for each row based on the asymptotic Chi^2-Distribution of the Likelihood ratio test statistic.   
</p>


<h3>Value</h3>

<p>An object of class <code>"anova"</code> inheriting from class <code>"data.frame"</code>.
</p>


<h3>Warning:</h3>

<p>The comparison between two or more models by <code>anova</code> will only be valid
if they are fitted to the same dataset and if the models are nested. The
function does not check if that is the case. 
</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>See Also</h3>

<p>The model fitting function <code><a href="#topic+LLRA">LLRA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.

#fit LLRA
ex2 &lt;- LLRA(llraDat2[,1:20],mpoints=4,groups=llraDat2[,21])

#Imposing a linear trend for items 2 and 3 using collapse_W 
collItems2 &lt;- list(c(32,37,42),c(33,38,43))
newNames2 &lt;- c("trend.I2","trend.I3")
Wnew &lt;- collapse_W(ex2$W,collItems2,newNames2)

#Estimating LLRA with the linear trend for item 2 and 3
ex2new &lt;- LLRA(llraDat2[1:20],W=Wnew,mpoints=4,groups=llraDat2[21])

#comparing models with likelihood ratio test
anova(ex2,ex2new)
## End(Not run)</code></pre>

<hr>
<h2 id='build_W'>
Automatized Construction of LLRA Design Matrix 
</h2><span id='topic+build_W'></span><span id='topic+build_catdes'></span><span id='topic+build_trdes'></span><span id='topic+build_effdes'></span><span id='topic+get_item_cats'></span>

<h3>Description</h3>

<p>Builds a design matrix for LLRA from scratch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_W(X, nitems, mpoints, grp_n, groupvec, itmgrps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build_W_+3A_x">X</code></td>
<td>
<p>Data matrix as described in Hatzinger and Rusch (2009). It
must be of long format, e.g. for each person all item answers are written in subsequent rows. The columns correspond to time
points. Missing values are not allowed. It can easily be
constructed from data in wide format with
<code>matrix(unlist(data),ncol=mpoints)</code> or from <code><a href="#topic+llra.datprep">llra.datprep</a></code>.
</p>
</td></tr> 
<tr><td><code id="build_W_+3A_nitems">nitems</code></td>
<td>
<p>The number of items.
</p>
</td></tr>
<tr><td><code id="build_W_+3A_mpoints">mpoints</code></td>
<td>
<p>The number of time points.
</p>
</td></tr>
<tr><td><code id="build_W_+3A_grp_n">grp_n</code></td>
<td>
<p>A vector of number of subjects per g+1 groups (e.g. g
treatment or covariate groups and 1 control or baseline group.
The sizes must be ordered like the corresponding groups.
</p>
</td></tr>
<tr><td><code id="build_W_+3A_groupvec">groupvec</code></td>
<td>
<p>Assignment vector, i.e. which person belongs to which
treatment/item group 
</p>
</td></tr>  
<tr><td><code id="build_W_+3A_itmgrps">itmgrps</code></td>
<td>
<p>Specifies how many groups of items there are. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is designed to be modular and calls four internal function
<code>build_effdes</code> (for treatment/covariate effects), <code>build_trdes</code> (for trend
effects), <code>build_catdes</code> (for category parameter design matrix) and
<code>get_item_cats</code> (checks how many categories each item has). Those functions are not intended to be used by the user.
</p>
<p>Labeling of effects also happens in the internal functions. 
</p>


<h3>Value</h3>

<p>An LLRA design matrix as described by Hatzinger and Rusch
(2009). This can be passed as the <code>W</code> argument to <code>LLRA</code> or
<code>LPCM</code>.
</p>
<p>The design matrix specifies every item to lie on its own
dimension. Hence at every time point &gt; 1, there are effects for
each treatment or covariate group as well as trend effects for every
item. Therefore overall there are items x (groups-1) x (time points-1)
covariate effect parameters and items x (time points-1) trend
parameters specified. For polytomous items there also are parameters
for each category with the first and second category being equated for each item. They
need not be equidistant. The number of parameters therefore increase
quite rapidly for any additional time point, item or covariate group.       
</p>


<h3>Warning </h3>

<p>A warning is printed that the first two categories
for polytomous items are equated.</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>,
<b>51</b>, pp. 87&ndash;120.
</p>


<h3>See Also</h3>

<p>This function is used for automatic generation of the design matrix in <code><a href="#topic+LLRA">LLRA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.
llraDat2a &lt;- matrix(unlist(llraDat2[1:20]),ncol=4)
groupvec &lt;-rep(1:3*5,each=20)
W &lt;- build_W(llraDat2a,nitems=5,mpoints=4,grp_n=c(10,20,40),groupvec=groupvec,itmgrps=1:5)

#There are 55 parameters
dim(W)

## Not run: 
#Estimating LLRA by specifiying W
ex2W &lt;- LLRA(llraDat2[1:20],W=W,mpoints=4,groups=llraDat2[21])
## End(Not run)
</code></pre>

<hr>
<h2 id='collapse_W'>
Convenient Collapsing of LLRA Design Matrix 
</h2><span id='topic+collapse_W'></span>

<h3>Description</h3>

<p>Collapses columns of a design matrix for LLRA to specify different
parameter restrictions in <code>LLRA</code>.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapse_W(W, listItems, newNames)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collapse_W_+3A_w">W</code></td>
<td>
<p>A design matrix (for LLRA), typically from a call to
<code><a href="#topic+build_W">build_W</a></code> or component <code>$W</code> from <code><a href="#topic+LLRA">LLRA</a></code>
or <code><a href="#topic+LPCM">LPCM</a></code>
</p>
</td></tr> 
<tr><td><code id="collapse_W_+3A_listitems">listItems</code></td>
<td>
<p>A list of numeric vectors. Each component of the list specifies
columns to be collapsed together. 
</p>
</td></tr>
<tr><td><code id="collapse_W_+3A_newnames">newNames</code></td>
<td>
<p>An (optional) character vector specifying the names of
the collapsed effects. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a convenience function to collapse a design matrix,
i.e. to specify linear trend or treatment effects and so on. Collapsing
here means that effects in columns are summed up. For this, a list of numeric
vectors with the column indices of columns to be collapsed have to be
passed to the function. For example, if you want to collapse column 3, 6
and 8 into one new effect and 1, 4 and 9 into another it needs to be
passed with <code>list(c(3,6,8),c(1,4,9))</code>.
</p>
<p>The new effects can be given names by passing a character vector to the
function with equal length as the list. 
</p>


<h3>Value</h3>

<p>An LLRA design matrix as described by Hatzinger and Rusch
(2009). This can be passed as the <code>W</code> argument to <code>LLRA</code> or
<code>LPCM</code>.
</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>,
<b>51</b>, pp. 87&ndash;120.
</p>


<h3>See Also</h3>

<p>The function to build design matrices from scratch, <code><a href="#topic+build_W">build_W</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.    
llraDat2a &lt;- matrix(unlist(llraDat2[1:20]),ncol=4)
groupvec &lt;-rep(1:3*5,each=20)
W &lt;- build_W(llraDat2a, nitems=5, mpoints=4, grp_n=c(10,20,40), groupvec=groupvec,itmgrps=1:5)

#There are 55 parameters to be estimated
dim(W)

#Imposing a linear trend for the second item ,i.e. parameters in
#columns 32, 37  and 42 need to be collapsed into a single column. 
collItems1 &lt;- list(c(32,37,42))
newNames1 &lt;- c("trend.I2")
Wstar1 &lt;- collapse_W(W,collItems1)

#53 parameters need to be estimated
dim(Wstar1)
</code></pre>

<hr>
<h2 id='eRm.data'>Data for Computing Extended Rasch Models</h2><span id='topic+eRm.data'></span><span id='topic+raschdat1'></span><span id='topic+raschdat1_RM_fitted'></span><span id='topic+raschdat1_RM_plotDIF'></span><span id='topic+raschdat1_RM_lrres2'></span><span id='topic+raschdat2'></span><span id='topic+raschdat3'></span><span id='topic+raschdat4'></span><span id='topic+lltmdat1'></span><span id='topic+lltmdat2'></span><span id='topic+pcmdat'></span><span id='topic+pcmdat2'></span><span id='topic+lpcmdat'></span><span id='topic+rsmdat'></span><span id='topic+lrsmdat'></span>

<h3>Description</h3>

<p>Artificial data sets for computing extended Rasch models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>raschdat1
raschdat2
raschdat3
raschdat4

lltmdat1
lltmdat2

rsmdat

lrsmdat

pcmdat
pcmdat2

lpcmdat

raschdat1_RM_fitted
raschdat1_RM_plotDIF
raschdat1_RM_lrres2</code></pre>


<h3>Format</h3>

<p>Numeric matrices with subjects as rows, items as columns, missing values as <code>NA</code>.</p>


<h3>Details</h3>

<p><code>raschdat1_RM_fitted</code> is the resulting object of <code>RM(raschdat1)</code> and used in examples to reduce computation time. For the generation of <code>raschdat1_RM_plotDIF</code> see the excluded example code of <code><a href="#topic+plotDIF">plotDIF</a></code>. <code>raschdat1_RM_lrres2</code> results from <code>LRtest(RM(raschdat1), split = "mean")</code></p>

<hr>
<h2 id='gofIRT'>Various model tests and fit indices</h2><span id='topic+gofIRT'></span><span id='topic+gofIRT.ppar'></span><span id='topic+summary.gof'></span><span id='topic+print.gof'></span>

<h3>Description</h3>

<p>This function computes various model tests and fit indices for objects of class <code>ppar</code>: Collapsed deviance, Casewise deviance, Rost's LR-test, Hosmer-Lemeshow test, R-Squared measures, confusion matrix, ROC analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppar'
gofIRT(object, groups.hl = 10, cutpoint = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gofIRT_+3A_object">object</code></td>
<td>
<p>Object of class <code>ppar</code> (from <code>person.parameter()</code>).</p>
</td></tr>
<tr><td><code id="gofIRT_+3A_groups.hl">groups.hl</code></td>
<td>
<p>Number of groups for Hosmer-Lemeshow test (see details).</p>
</td></tr> 
<tr><td><code id="gofIRT_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Integer between 0 and 1 for computing the 0-1 model matrix from the estimated probabilities</p>
</td></tr>
</table>


<h3>Details</h3>

<p>So far this test statistics are implemented only for dichotomous models without NA's. The Hosmer-Lemeshow test is computed by splitting the response vector into percentiles, e.g. <code>groups.hl = 10</code> corresponds to decile splitting. 
</p>


<h3>Value</h3>

<p>The function <code>gofIRT</code> returns an object of class <code>gof</code> containing:
</p>
<table>
<tr><td><code>test.table</code></td>
<td>
<p>Ouput for model tests.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>List with R-squared measures.</p>
</td></tr>
<tr><td><code>classifier</code></td>
<td>
<p>Confusion matrix, accuracy, sensitivity, specificity.</p>
</td></tr>
<tr><td><code>AUC</code></td>
<td>
<p>Area under ROC curve.</p>
</td></tr>
<tr><td><code>Gini</code></td>
<td>
<p>Gini coefficient.</p>
</td></tr>
<tr><td><code>ROC</code></td>
<td>
<p>FPR and TPR for different cutpoints.</p>
</td></tr>
<tr><td><code>opt.cut</code></td>
<td>
<p>Optimal cutpoint determined by ROC analysis.</p>
</td></tr>
<tr><td><code>predobj</code></td>
<td>
<p>Prediction output from ROC analysis (<code>ROCR</code> package)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mair, P., Reise, S. P., and Bentler, P. M. (2008). IRT goodness-of-fit using approaches from logistic regression. UCLA Statistics Preprint Series. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemfit.ppar">itemfit.ppar</a></code>,<code><a href="#topic+personfit.ppar">personfit.ppar</a></code>,<code><a href="#topic+LRtest">LRtest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Goodness-of-fit for a Rasch model
res &lt;- RM(raschdat1)
pres &lt;- person.parameter(res)
gof.res &lt;- gofIRT(pres)
gof.res
summary(gof.res)
</code></pre>

<hr>
<h2 id='IC'>Information criteria</h2><span id='topic+IC'></span><span id='topic+IC.ppar'></span>

<h3>Description</h3>

<p>Computation of information criteria such as AIC, BIC, and cAIC based on
unconditional (joint), marginal, and conditional log-likelihood</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppar'
IC(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IC_+3A_object">object</code></td>
<td>
<p>Object of class <code>ppar</code> (from <code>person.parameter()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The joint log-likelihood is established by summation of the logarithms of the estimated
solving probabilities. The marginal log-likelihood can be computed directly from the
conditional log-likelihood (see vignette for details).
</p>


<h3>Value</h3>

<p>The function <code>IC</code> returns an object of class <code>ICr</code> containing:
</p>
<table>
<tr><td><code>ICtable</code></td>
<td>
<p>Matrix containing log-likelihood values, number of parameters, AIC, BIC, and
cAIC for the joint, marginal, and conditional log-likelihood.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+LRtest.Rm">LRtest.Rm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#IC's for Rasch model
res &lt;- RM(raschdat2)             #Rasch model
pres &lt;- person.parameter(res)    #Person parameters
IC(pres)

#IC's for RSM
res &lt;- RSM(rsmdat)
pres &lt;- person.parameter(res)
IC(pres)
</code></pre>

<hr>
<h2 id='item_info'>Calculate Item Information for 'eRm' objects
</h2><span id='topic+item_info'></span><span id='topic+i_info'></span>

<h3>Description</h3>

<p>Calculates Samejima's (1969) information for all items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item_info(ermobject, theta = seq(-5, 5, 0.01))

i_info(hvec, itembeta, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item_info_+3A_ermobject">ermobject</code></td>
<td>
<p>An object of class 'eRm'.
</p>
</td></tr> 
<tr><td><code id="item_info_+3A_theta">theta</code></td>
<td>
<p>Supporting or sampling points on the latent trait.
</p>
</td></tr>
<tr><td><code id="item_info_+3A_hvec">hvec</code></td>
<td>
<p>Number of categories of a single item.
</p>
</td></tr>
<tr><td><code id="item_info_+3A_itembeta">itembeta</code></td>
<td>
<p>Cumulative item category parameters for a single item.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>item_info</code> calculates information of the
whole set of items in the 'eRm' object. The function <code>i_info</code>
does the same for a single item (and is called by <code>item_info</code>).  
</p>


<h3>Value</h3>

<p>Returns a list (<code>i_info</code>) or a list of lists (where each list element
corresponds to an item, <code>item_info</code>) and contains
</p>
<table>
<tr><td><code>c.info</code></td>
<td>
<p>Matrix of category information in columns for the
different theta values in rows.</p>
</td></tr>
<tr><td><code>i.info</code></td>
<td>
<p>Vector of item information for the
different theta values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Samejima, F. (1969) Estimation of latent ability using a response
pattern of graded scores. <em>Psychometric Monographs</em>, <b>17</b>.  
</p>


<h3>See Also</h3>

<p>The function to calculate the test information, <code><a href="#topic+test_info">test_info</a></code>
and the plot function <code><a href="#topic+plotINFO">plotINFO</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- PCM(pcmdat)
info &lt;- item_info(res)
plotINFO(res,type="item")
</code></pre>

<hr>
<h2 id='itemfit.ppar'>Residuals, Personfit and Itemfit Statistics</h2><span id='topic+itemfit.ppar'></span><span id='topic+itemfit'></span><span id='topic+personfit.ppar'></span><span id='topic+personfit'></span><span id='topic+residuals.ppar'></span><span id='topic+pmat.ppar'></span><span id='topic+pmat'></span><span id='topic+print.ifit'></span><span id='topic+print.pfit'></span><span id='topic+print.resid'></span>

<h3>Description</h3>

<p><code>pmat</code> computes the theoretical person-item matrix with solving
probabilities for each category (except 0th). <code>residuals</code> computes the squared and standardized residuals based on
the observed and the expected person-item matrix. Chi-square based itemfit and personfit
statistics can be obtained by using <code>itemfit</code> and <code>personfit</code>. Corrected item-test correlations in <code>itemfit</code> are computed using the approach from Cureton (1966). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppar'
pmat(object)
## S3 method for class 'ppar'
residuals(object,...)
## S3 method for class 'ppar'
itemfit(object)
## S3 method for class 'ppar'
personfit(object)
## S3 method for class 'ifit'
print(x, visible = TRUE, 
sort_by = c("none", "p", "outfit_MSQ", "infit_MSQ", "outfit_t", "infit_t", "discrim"), 
decreasing = FALSE, digits = 3,...)
## S3 method for class 'pfit'
print(x, visible = TRUE, ...)
## S3 method for class 'resid'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemfit.ppar_+3A_object">object</code></td>
<td>
<p>Object of class <code>ppar</code>, derived from <code>person.parameter</code>.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_x">x</code></td>
<td>
<p>Object of class <code>ifit</code>, <code>pfit</code>, or <code>resid</code>.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_visible">visible</code></td>
<td>
<p>If <code>FALSE</code>, returns the matrix of fit statistics that otherwise would be printed.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_sort_by">sort_by</code></td>
<td>
<p>Optionally the itemfit output can be sorted by one of these criteria.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_decreasing">decreasing</code></td>
<td>
<p>If <code>sort_by</code> is set, whether the output should be sorted in increasing or decreasing order.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_digits">digits</code></td>
<td>
<p>How many digits should be printed.</p>
</td></tr>
<tr><td><code id="itemfit.ppar_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>pmat</code></td>
<td>
<p>Matrix of theoretical probabilities for each category except 0th (from function <code>pmat</code>).</p>
</td></tr>
<tr><td><code>i.fit</code></td>
<td>
<p>Chi-squared itemfit statistics (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>i.df</code></td>
<td>
<p>Degrees of freedom for itemfit statistics (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>st.res</code></td>
<td>
<p>Standardized residuals (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>i.outfitMSQ</code></td>
<td>
<p>Outfit mean-square statistics (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>i.infitMSQ</code></td>
<td>
<p>Infit mean-square statistics (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>i.disc</code></td>
<td>
<p>Corrected item-test correlations (from function <code>itemfit</code>).</p>
</td></tr>
<tr><td><code>p.fit</code></td>
<td>
<p>Chi-squared personfit statistics (from function <code>personfit</code>).</p>
</td></tr>
<tr><td><code>p.df</code></td>
<td>
<p>Degrees of freedom for personfit statistics (from function <code>personfit</code>).</p>
</td></tr>
<tr><td><code>st.res</code></td>
<td>
<p>Standardized residuals (from function <code>personfit</code>).</p>
</td></tr>
<tr><td><code>p.outfitMSQ</code></td>
<td>
<p>Outfit mean-square statistics (from function <code>personfit</code>).</p>
</td></tr>
<tr><td><code>p.infitMSQ</code></td>
<td>
<p>Infit mean-square statistics (from function <code>personfit</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger, Moritz Heene</p>


<h3>References</h3>

<p>Smith Jr., E. V., and Smith, R. M. (2004). Introduction to Rasch Measurement.
JAM press.
</p>
<p>Wright, B.D., and Masters, G.N. Computation of OUTFIT and INFIT Statistics.
Rasch Measurement Transactions, 1990, 3:4 p.84-85
</p>
<p>Cureton, E. E. (1966). Corrected item-test correlations. Psychometrika, 31, 93-96
</p>


<h3>See Also</h3>

<p><code><a href="#topic+person.parameter">person.parameter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Rasch model, estimation of item and person parameters
res &lt;- RM(raschdat2)
p.res &lt;- person.parameter(res)

# Matrix with expected probabilities and corresponding residuals
pmat(p.res)
residuals(p.res)

#Itemfit
itemfit(p.res)

#Personfit
personfit(p.res)

</code></pre>

<hr>
<h2 id='LLRA'>Fit Linear Logistic Models with Relaxed Assumptions (LLRA)
</h2><span id='topic+LLRA'></span><span id='topic+print.llra'></span>

<h3>Description</h3>

<p>Automatically builds design matrix and fits LLRA.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LLRA(X, W, mpoints, groups, baseline, itmgrps = NULL, ...)

## S3 method for class 'llra'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LLRA_+3A_x">X</code></td>
<td>
<p>Data matrix as described in Hatzinger and Rusch (2009). It
must be of wide format, e.g. for each person all item answers are
written in columns for t1, t2, t3 etc. Hence each row corresponds to
all observations for a single person. See llraDat1 for an example.
Missing values are not allowed.    
</p>
</td></tr>
<tr><td><code id="LLRA_+3A_w">W</code></td>
<td>
<p>Design Matrix for LLRA to be passed to <code>LPCM</code>. If missing, it
is generated automatically.
</p>
</td></tr>
<tr><td><code id="LLRA_+3A_mpoints">mpoints</code></td>
<td>
<p>The number of time points.
</p>
</td></tr>
<tr><td><code id="LLRA_+3A_groups">groups</code></td>
<td>
<p>Vector, matrix or data frame with subject/treatment
covariates.
</p>
</td></tr>
<tr><td><code id="LLRA_+3A_baseline">baseline</code></td>
<td>
<p>An optional vector with the baseline values for the
columns in group.
</p>
</td></tr>  
<tr><td><code id="LLRA_+3A_itmgrps">itmgrps</code></td>
<td>

<p>Specifies how many groups of items there are. Currently not functional but may be useful in the future.
</p>
</td></tr>
<tr><td><code id="LLRA_+3A_x">x</code></td>
<td>
<p>For the print method, an object of class <code>"llra"</code>.
</p>
</td></tr> 
<tr><td><code id="LLRA_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to and from other methods. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>LLRA</code> is a wrapper for <code>LPCM</code> to fit
Linear Logistic Models with Relaxed Assumptions (LLRA). LLRA
are extensions of the LPCM for the measurement of change over a number
of discrete time points for a set of
items. It can incorporate categorical covariate information. If no
design matrix W is passed as an argument, it is built automatically
from scratch.
</p>
<p>Unless passed by the user, the baseline group is always the one with
the lowest (alpha-)numerical value for argument <code>groups</code>. All
other groups  are labeled decreasingly according to the
(alpha)-numerical value, e.g. with 2 treatment groups (TG1 and TG2)
and one control group (CG), CG will be the baseline than TG1 and TG2.
Hence the group effects are ordered like
<code>rev((unique(names(groupvec)))</code> for naming.    
</p>
<p>Caution is advised as LLRA will fail if all changes for a group will be into a
single direction (e.g. all subjects in the treatment group show
improvement). Currently only data matrices are supported as arguments.    
</p>


<h3>Value</h3>

<p>Returns an object of class <code>'llra'</code> (also inheriting from class <code>'eRm'</code>) containing
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See code output in nlm.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item parameters. These are the LLRA
effect parameters.</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item (easiness) parameters of the virtual
items (not useful for interpretation here).</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of virtual item parameters (not useful for interpretation here).</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix in long format. The columns correspond to the
measurement points and each persons item answers are listed
susequently in rows.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>groupvec</code></td>
<td>
<p>Assignment vector.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>itms</code></td>
<td>
<p>The number of items.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>A warning is printed that the first two categories
for polytomous items are equated to save parameters. See Hatzinger and
Rusch (2009) for a justification why this is valid also from a substantive
point of view.</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Fischer, G.H. (1995) Linear logistic models for change. In G.H. Fischer
and I. W. Molenaar (eds.), <em>Rasch models: Foundations, recent
developments and applications</em> (pp. 157&ndash;181), New York: Springer.
</p>
<p>Glueck, J. and Spiel, C. (1997) Item response models for repeated
measures designs: Application and limitations of four different
approaches. <em>Methods of Psychological  Research</em>, <b>2</b>.
</p>
<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>, <b>51</b>,
pp. 87&ndash;120.
</p>


<h3>See Also</h3>

<p>The function to build the design matrix <code><a href="#topic+build_W">build_W</a></code>, and the
S3 methods <code><a href="#topic+summary.llra">summary.llra</a></code> and <code><a href="#topic+plotTR">plotTR</a></code> and
<code><a href="#topic+plotGR">plotGR</a></code> for plotting. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Example 6 from Hatzinger &amp; Rusch (2009)
groups &lt;- c(rep("TG",30),rep("CG",30))
llra1 &lt;- LLRA(llradat3,mpoints=2,groups=groups)
llra1

## Not run: 
##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.
dats &lt;- llraDat2[1:20]
groups &lt;- llraDat2$group
tps &lt;- 4

#baseline CG
ex2 &lt;- LLRA(dats,mpoints=tps,groups=groups) 

#baseline TG1
ex2a &lt;- LLRA(dats,mpoints=tps,groups=groups,baseline="TG1") 

#summarize results
summary(ex2)
summary(ex2a)

#plotting
plotGR(ex2)
plotTR(ex2)
## End(Not run)
</code></pre>

<hr>
<h2 id='llra.datprep'>Prepare Data Set for LLRA Analysis
</h2><span id='topic+llra.datprep'></span>

<h3>Description</h3>

<p>Converts wide data matrix in long format, sorts subjects according to
groups and builds assigment vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llra.datprep(X, mpoints, groups, baseline)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="llra.datprep_+3A_x">X</code></td>
<td>
<p>Data matrix as described in Hatzinger and Rusch (2009). It
must be of wide format, e.g. for each person all item answers are
written in columns for t1, t2, t3 etc. Hence each row corresponds to
all observations for a single person.
Missing values are not allowed.  
</p>
</td></tr>
<tr><td><code id="llra.datprep_+3A_mpoints">mpoints</code></td>
<td>
<p>The number of time points.
</p>
</td></tr>
<tr><td><code id="llra.datprep_+3A_groups">groups</code></td>
<td>
<p>Vector, matrix or data frame with subject/treatment
covariates.
</p>
</td></tr>
<tr><td><code id="llra.datprep_+3A_baseline">baseline</code></td>
<td>
<p>An optional vector with the baseline values for the
columns in group.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>The function converts a data matrix from wide to long fromat as
needed for LLRA. Additionally it sorts the subjects according to the
different treatment/covariate groups. The group with the lowest
(alpha-)numerical value will be the
baseline.
</p>
<p>Treatment and covariate groups are either defined by a vector, or by a
matrix or data frame. The latter will be combined to a vector of
groups corresponding to a combination of each factor level per column
with the factor levels of the other column. The (constructed or
passed) vector will then be used to create the assignment vector.  
</p>


<h3>Value</h3>

<p>Returns a list with the components
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>Data matrix in long format with subjects sorted by groups.</p>
</td></tr>
<tr><td><code>assign.vec</code></td>
<td>
<p>The assignment vector.</p>
</td></tr>
<tr><td><code>grp_n</code></td>
<td>
<p>A vector of the number of subjects in each group.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Reinhold Hatzinger</p>


<h3>See Also</h3>

<p>The function that uses this is <code><a href="#topic+LLRA">LLRA</a></code>. The values from
<code>llra.datprep</code> can be passed to <code><a href="#topic+build_W">build_W</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # example 3 items, 3 timepoints, n=10, 2x2 treatments
    dat&lt;-sim.rasch(10,9)
    tr1&lt;-sample(c("a","b"),10,r=TRUE)
    tr2&lt;-sample(c("x","y"),10,r=TRUE)

    # one treatment
    res&lt;-llra.datprep(dat,mpoints=3,groups=tr1)
    res&lt;-llra.datprep(dat,mpoints=3,groups=tr1,baseline="b") 

    # two treatments
    res&lt;-llra.datprep(dat,mpoints=3,groups=cbind(tr1,tr2))
    res&lt;-llra.datprep(dat,mpoints=3,groups=cbind(tr1,tr2),baseline=c("b","x")) 

    # two treatments - data frame
    tr.dfr&lt;-data.frame(tr1, tr2)
    res&lt;-llra.datprep(dat,mpoints=3,groups=tr.dfr) 
</code></pre>

<hr>
<h2 id='llraDat1'>An Artificial LLRA Data Set</h2><span id='topic+llraDat1'></span>

<h3>Description</h3>

<p>Artificial data set of 5 items, 5 time points and 5 groups for LLRA.</p>


<h3>Usage</h3>

<pre><code class='language-R'>llraDat1</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations of 26 variables.
</p>

<dl>
<dt><code>t1.I1</code></dt><dd><p>Answers to item 1 at time point 1</p>
</dd>
<dt><code>t1.I2</code></dt><dd><p>Answers to item 2 at time point 1</p>
</dd>
<dt><code>t1.I3</code></dt><dd><p>Answers to item 3 at time point 1</p>
</dd>
<dt><code>t1.I4</code></dt><dd><p>Answers to item 4 at time point 1</p>
</dd>
<dt><code>t1.I5</code></dt><dd><p>Answers to item 5 at time point 1</p>
</dd>
<dt><code>t2.I1</code></dt><dd><p>Answers to item 1 at time point 2</p>
</dd>
<dt><code>t2.I2</code></dt><dd><p>Answers to item 2 at time point 2</p>
</dd>
<dt><code>t2.I3</code></dt><dd><p>Answers to item 3 at time point 2</p>
</dd>
<dt><code>t2.I4</code></dt><dd><p>Answers to item 4 at time point 2</p>
</dd>
<dt><code>t2.I5</code></dt><dd><p>Answers to item 5 at time point 2</p>
</dd>
<dt><code>t3.I1</code></dt><dd><p>Answers to item 1 at time point 3</p>
</dd>
<dt><code>t3.I2</code></dt><dd><p>Answers to item 2 at time point 3</p>
</dd>
<dt><code>t3.I3</code></dt><dd><p>Answers to item 3 at time point 3</p>
</dd>
<dt><code>t3.I4</code></dt><dd><p>Answers to item 4 at time point 3</p>
</dd>
<dt><code>t3.I5</code></dt><dd><p>Answers to item 5 at time point 3</p>
</dd>
<dt><code>t4.I1</code></dt><dd><p>Answers to item 1 at time point 4</p>
</dd>
<dt><code>t4.I2</code></dt><dd><p>Answers to item 2 at time point 4</p>
</dd>
<dt><code>t4.I3</code></dt><dd><p>Answers to item 3 at time point 4</p>
</dd>
<dt><code>t4.I4</code></dt><dd><p>Answers to item 4 at time point 4</p>
</dd>
<dt><code>t4.I5</code></dt><dd><p>Answers to item 5 at time point 4</p>
</dd>
<dt><code>t5.I1</code></dt><dd><p>Answers to item 1 at time point 5</p>
</dd>
<dt><code>t5.I2</code></dt><dd><p>Answers to item 2 at time point 5</p>
</dd>
<dt><code>t5.I3</code></dt><dd><p>Answers to item 3 at time point 5</p>
</dd>
<dt><code>t5.I4</code></dt><dd><p>Answers to item 4 at time point 5</p>
</dd>
<dt><code>t5.I5</code></dt><dd><p>Answers to item 5 at time point 5</p>
</dd>
<dt><code>groups</code></dt><dd><p>The group membership</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is a data set as described in Hatzinger and Rusch (2009). 5 items
were measured at 5 time points (in columns). Each row corresponds to one
person (P1 to P150).
There are 4 treatment groups and a control group. Treatment group G5 has
size 10 (the first ten subjects),
treatment group G4 has size 20, treatment group G3 has size 30, treatment
group G2 has size 40 and the control group CG has size 50 (the last 50
subjects). Item 1 is dichotomous, all others are polytomous. Item 2, 3, 4 and 5 have 3, 4, 5, 6 categories
respectively.   
</p>


<h3>References</h3>

<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>, <b>51</b>,
pp. 87&ndash;120.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>llraDat1
</code></pre>

<hr>
<h2 id='llraDat2'>An Artificial LLRA Data Set</h2><span id='topic+llraDat2'></span>

<h3>Description</h3>

<p>Artificial data set of 70 subjects with 5 items, 4 time points and 3 groups for LLRA.</p>


<h3>Usage</h3>

<pre><code class='language-R'>llraDat2</code></pre>


<h3>Format</h3>

<p>A data frame with 70 observations of 21 variables.
</p>

<dl>
<dt><code>t1.I1</code></dt><dd><p>Answers to item 1 at time point 1</p>
</dd>
<dt><code>t1.I2</code></dt><dd><p>Answers to item 2 at time point 1</p>
</dd>
<dt><code>t1.I3</code></dt><dd><p>Answers to item 3 at time point 1</p>
</dd>
<dt><code>t1.I4</code></dt><dd><p>Answers to item 4 at time point 1</p>
</dd>
<dt><code>t1.I5</code></dt><dd><p>Answers to item 5 at time point 1</p>
</dd>
<dt><code>t2.I1</code></dt><dd><p>Answers to item 1 at time point 2</p>
</dd>
<dt><code>t2.I2</code></dt><dd><p>Answers to item 2 at time point 2</p>
</dd>
<dt><code>t2.I3</code></dt><dd><p>Answers to item 3 at time point 2</p>
</dd>
<dt><code>t2.I4</code></dt><dd><p>Answers to item 4 at time point 2</p>
</dd>
<dt><code>t2.I5</code></dt><dd><p>Answers to item 5 at time point 2</p>
</dd>
<dt><code>t3.I1</code></dt><dd><p>Answers to item 1 at time point 3</p>
</dd>
<dt><code>t3.I2</code></dt><dd><p>Answers to item 2 at time point 3</p>
</dd>
<dt><code>t3.I3</code></dt><dd><p>Answers to item 3 at time point 3</p>
</dd>
<dt><code>t3.I4</code></dt><dd><p>Answers to item 4 at time point 3</p>
</dd>
<dt><code>t3.I5</code></dt><dd><p>Answers to item 5 at time point 3</p>
</dd>
<dt><code>t4.I1</code></dt><dd><p>Answers to item 1 at time point 4</p>
</dd>
<dt><code>t4.I2</code></dt><dd><p>Answers to item 2 at time point 4</p>
</dd>
<dt><code>t4.I3</code></dt><dd><p>Answers to item 3 at time point 4</p>
</dd>
<dt><code>t4.I4</code></dt><dd><p>Answers to item 4 at time point 4</p>
</dd>
<dt><code>t4.I5</code></dt><dd><p>Answers to item 5 at time point 4</p>
</dd>
<dt><code>group</code></dt><dd><p>The group membership</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is a data set as described in Hatzinger and Rusch (2009). 5 items
were measured at 4 time points (in columns). Each persons answers to the
items are recorded in the rows. There are 2
treatment groups and a control group. Treatment group 2 has size, 10,
treatment group 1 has size 20 and the control group has size 40. Item 1 is dichotomous, all others
are polytomous. Item 2, 3, 4 and 5 have 3, 4, 5, 6 categories
respectively.   
</p>


<h3>References</h3>

<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>, <b>51</b>,
pp. 87&ndash;120.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>llraDat2
</code></pre>

<hr>
<h2 id='llradat3'>An Artificial LLRA Data Set</h2><span id='topic+llradat3'></span>

<h3>Description</h3>

<p>Artificial data set of 3 items, 2 time points and 2 groups for LLRA. It
is example 6 from Hatzinger and Rusch (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llradat3</code></pre>


<h3>Format</h3>

<p>A data frame with 60 observations of 6 variables.
</p>

<dl>
<dt><code>V1</code></dt><dd><p>Answers to item 1 at time point 1</p>
</dd>
<dt><code>V2</code></dt><dd><p>Answers to item 2 at time point 1</p>
</dd>
<dt><code>V3</code></dt><dd><p>Answers to item 3 at time point 1</p>
</dd>
<dt><code>V4</code></dt><dd><p>Answers to item 1 at time point 2</p>
</dd>
<dt><code>V5</code></dt><dd><p>Answers to item 2 at time point 2</p>
</dd>
<dt><code>V6</code></dt><dd><p>Answers to item 3 at time point 2</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is a data set as described in Hatzinger and Rusch (2009).
</p>


<h3>References</h3>

<p>Hatzinger, R. and Rusch, T. (2009) IRT models with relaxed assumptions
in eRm: A manual-like instruction. <em>Psychology Science Quarterly</em>, <b>51</b>,
pp. 87&ndash;120.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>llradat3
</code></pre>

<hr>
<h2 id='LLTM'>Estimation of linear logistic test models</h2><span id='topic+LLTM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a linear logistic test model (LLTM)
for binary item responses by using CML estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LLTM(X, W, mpoints = 1, groupvec = 1, se = TRUE, sum0 = TRUE,
   etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LLTM_+3A_x">X</code></td>
<td>
<p>Input 0/1 data matrix or data frame; rows represent individuals (N in total),
columns represent items. Missing values have to be inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_w">W</code></td>
<td>
<p>Design matrix for the LLTM. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_mpoints">mpoints</code></td>
<td>
<p>Number of measurement points.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_groupvec">groupvec</code></td>
<td>
<p>Vector of length N which determines the group membership of each subject,
starting from 1. If <code>groupvec=1</code>, no group contrasts are imposed.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normalized to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="LLTM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Through appropriate definition of <code>W</code> the LLTM can be viewed as a more parsimonous
Rasch model, on the one hand, e.g. by imposing some cognitive base operations
to solve the items. One the other hand, linear extensions of the Rasch model
such as group comparisons and repeated measurement designs can be computed.
If more than one measurement point is examined, the item responses for the 2nd, 3rd, etc.
measurement point are added column-wise in X.
</p>
<p>If <code>W</code> is user-defined, it is nevertheless necessary to
specify <code>mpoints</code> and <code>groupvec</code>. It is important that first the time contrasts and
then the group contrasts have to be imposed.
</p>
<p>Available methods for LLTM-objects are:<br />
<code>print</code>, <code>coef</code>,
<code>model.matrix</code>, <code>vcov</code>,<code>summary</code>, <code>logLik</code>, <code>person.parameters</code>.
</p>


<h3>Value</h3>

<p>Returns on object of class <code>eRm</code> containing:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item parameters.</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>groupvec</code></td>
<td>
<p>Group membership vector.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The eRm package for
the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models
with the eRm package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRSM">LRSM</a></code>,<code><a href="#topic+LPCM">LPCM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#LLTM for 2 measurement points
#100 persons, 2*15 items, W generated automatically
res1 &lt;- LLTM(lltmdat1, mpoints = 2)
res1
summary(res1)

#Reparameterized Rasch model as LLTM (more pasimonious)
W &lt;- matrix(c(1,2,1,3,2,2,2,1,1,1),ncol=2)              #design matrix
res2 &lt;- LLTM(lltmdat2, W = W)
res2
summary(res2)
</code></pre>

<hr>
<h2 id='LPCM'>Estimation of linear partial credit models</h2><span id='topic+LPCM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a linear partial credit model (LRSM)
for polytomuous item responses by using CML estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPCM(X, W , mpoints = 1, groupvec = 1, se = TRUE, sum0 = TRUE,
   etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPCM_+3A_x">X</code></td>
<td>
<p>Input data matrix or data frame; rows represent individuals (N in total),
columns represent items. Missing values are inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="LPCM_+3A_w">W</code></td>
<td>
<p>Design matrix for the LPCM. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="LPCM_+3A_mpoints">mpoints</code></td>
<td>
<p>Number of measurement points.</p>
</td></tr>
<tr><td><code id="LPCM_+3A_groupvec">groupvec</code></td>
<td>
<p>Vector of length N which determines the group membership of each subject, starting from 1</p>
</td></tr>
<tr><td><code id="LPCM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="LPCM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normalized to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="LPCM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Through appropriate definition of <code>W</code> the LPCM can be viewed as a more parsimonous
PCM, on the one hand, e.g. by imposing some cognitive base operations
to solve the items. One the other hand, linear extensions of the Rasch model
such as group comparisons and repeated measurement designs can be computed.
If more than one measurement point is examined, the item responses for the 2nd, 3rd, etc.
measurement point are added column-wise in X.
</p>
<p>If <code>W</code> is user-defined, it is nevertheless necessary to
specify <code>mpoints</code> and <code>groupvec</code>. It is important that first the time contrasts and
then the group contrasts have to be imposed.
</p>
<p>Available methods for LPCM-objects are:<br />
<code>print</code>, <code>coef</code>,
<code>model.matrix</code>, <code>vcov</code>,<code>summary</code>, <code>logLik</code>, <code>person.parameters</code>.
</p>


<h3>Value</h3>

<p>Returns on object of class <code>'eRm'</code> containing:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item parameters.</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>groupvec</code></td>
<td>
<p>Group membership vector.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRSM">LRSM</a></code>,<code><a href="#topic+LLTM">LLTM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#LPCM for two measurement points and two subject groups
#20 subjects, 2*3 items
G &lt;- c(rep(1,10),rep(2,10))                   #group vector
res &lt;- LPCM(lpcmdat, mpoints = 2, groupvec = G)
res
summary(res)
</code></pre>

<hr>
<h2 id='LRSM'>Estimation of linear rating scale models</h2><span id='topic+LRSM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a linear rating scale model (LRSM)
for polytomuous item responses by using CML estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRSM(X, W , mpoints = 1, groupvec = 1, se = TRUE, sum0 = TRUE,
   etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRSM_+3A_x">X</code></td>
<td>
<p>Input data matrix or data frame; rows represent individuals (N in total), columns represent items. Missing values are inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="LRSM_+3A_w">W</code></td>
<td>
<p>Design matrix for the LRSM. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="LRSM_+3A_mpoints">mpoints</code></td>
<td>
<p>Number of measurement points.</p>
</td></tr>
<tr><td><code id="LRSM_+3A_groupvec">groupvec</code></td>
<td>
<p>Vector of length N which determines the group membership of each subject, starting from 1</p>
</td></tr>
<tr><td><code id="LRSM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="LRSM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normalized to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="LRSM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Through appropriate definition of <code>W</code> the LRSM can be viewed as a more parsimonous
RSM, on the one hand, e.g. by imposing some cognitive base operations
to solve the items. One the other hand, linear extensions of the Rasch model
such as group comparisons and repeated measurement designs can be computed.
If more than one measurement point is examined, the item responses for the 2nd, 3rd, etc.
measurement point are added column-wise in X.
</p>
<p>If <code>W</code> is user-defined, it is nevertheless necessary to
specify <code>mpoints</code> and <code>groupvec</code>. It is important that first the time contrasts and
then the group contrasts have to be imposed.
</p>
<p>Available methods for LRSM-objects are:
<code>print</code>, <code>coef</code>,
<code>model.matrix</code>, <code>vcov</code>,<code>summary</code>, <code>logLik</code>, <code>person.parameters</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>'eRm'</code> containing:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item parameters (item and category parameters).</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>groupvec</code></td>
<td>
<p>Group membership vector.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LLTM">LLTM</a></code>,<code><a href="#topic+LPCM">LPCM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#LRSM for two measurement points
#20 subjects, 2*3 items, W generated automatically,
#first parameter set to 0, no standard errors computed.

res &lt;- LRSM(lrsmdat, mpoints = 2, groupvec = 1, sum0 = FALSE, se = FALSE)
res
</code></pre>

<hr>
<h2 id='LRtest'>Computation of Andersen's LR-test.</h2><span id='topic+LRtest.Rm'></span><span id='topic+LRtest'></span><span id='topic+print.LR'></span><span id='topic+summary.LR'></span><span id='topic+plotGOF'></span><span id='topic+plotGOF.LR'></span>

<h3>Description</h3>

<p>This LR-test is based on subject subgroup splitting.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Rm'
LRtest(object, splitcr = "median", se = TRUE)

## S3 method for class 'LR'
plotGOF(x, beta.subset = "all", main = "Graphical Model Check", xlab, ylab,
    tlab = "item", xlim, ylim, type = "p", pos = 4, conf = NULL, ctrline = NULL, 
    smooline = NULL, asp = 1, x_axis = TRUE, y_axis = TRUE, set_par = TRUE, 
    reset_par = TRUE, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LRtest_+3A_object">object</code></td>
<td>
<p>Object of class <code>"Rm"</code>.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_splitcr">splitcr</code></td>
<td>
<p>Split criterion for subject raw score splitting.
<code>"all.r"</code> corresponds to a full raw score split, <code>"median"</code> uses the median as split criterion, <code>"mean"</code> performs a mean split.
Optionally <code>splitcr</code> can also be a vector which assigns each person to a certain subgroup (e.g., following an external criterion).
This vector can be numeric, character or a factor.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_se">se</code></td>
<td>
<p>controls computation of standard errors in the submodels (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="LRtest_+3A_x">x</code></td>
<td>
<p>Object of class <code>"LR"</code>. Also used for visualizing the fit of single items.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_beta.subset">beta.subset</code></td>
<td>
<p>If <code>"all"</code>, all items are plotted. Otherwise numeric subset vector can be specified.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_main">main</code></td>
<td>
<p>Title of the plot.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_xlab">xlab</code></td>
<td>
<p>Label on <code class="reqn">x</code>-axis, default gives name of <code>splitcr</code> and level.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_ylab">ylab</code></td>
<td>
<p>Label on <code class="reqn">y</code>-axis, default gives name of <code>splitcr</code> and level.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_tlab">tlab</code></td>
<td>
<p>Specification of item labels: <code>"item"</code> prints the item names, <code>"number"</code> gives integers corresponding to order of the beta parameters, if <code>"none"</code> no labels are printed.
<code>"identify"</code> allows for an interactive labelling.
Initially no labels are printed, after clicking close to an item point the corresponding label is added.
The identification process is terminated by clicking the second button and selecting 'Stop' from the menu, or from the 'Stop' menu on the graphics window.
For more information and basic operation see <code><a href="graphics.html#topic+identify">identify</a></code>.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_xlim">xlim</code></td>
<td>
<p>Limits on <code class="reqn">x</code>-axis.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_ylim">ylim</code></td>
<td>
<p>Limits on <code class="reqn">y</code>-axis.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_type">type</code></td>
<td>
<p>Plotting type (see <code><a href="graphics.html#topic+plot">plot</a></code>).</p>
</td></tr>
<tr><td><code id="LRtest_+3A_pos">pos</code></td>
<td>
<p>Position of the item label (see <code><a href="graphics.html#topic+text">text</a></code>).</p>
</td></tr>
<tr><td><code id="LRtest_+3A_conf">conf</code></td>
<td>
<p>for plotting confidence ellipses for the item parameters.
If <code>conf = NULL</code> (the default) no ellipses are drawn.
Otherwise, <code>conf</code> must be specified as a list with optional elements: <code>gamma</code>, is the confidence level (numeric), <code>col</code> and <code>lty</code>, color and linetype (see <code><a href="graphics.html#topic+par">par</a></code>), <code>which</code> (numeric index vector) specifying for which items ellipses are drawn (must be a subset of <code>beta.subset</code>), and <code>ia</code>, logical, if the ellipses are to be drawn interactively (cf., <code>tlab = "identify"</code> above).
For details about the default behavior, if <code>conf</code> is specified as a an empty list, see Details and Examples below.
To use <code>conf</code>, the LR object <code>x</code> has to be generated using the option <code>se = TRUE</code> in <code>LRtest()</code>.
For specification of <code>col</code> and <code>which</code> see Details and Examples below.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_ctrline">ctrline</code></td>
<td>
<p>for plotting confidence bands (control lines, cf. eg. Wright and Stone, 1999).
If <code>ctrline = NULL</code> (the default) no lines are drawn.
Otherwise, <code>ctrline</code> must be specified as a list with optional elements: <code>gamma</code>, is the confidence level (numeric), <code>col</code> and <code>lty</code>, color and linetype (see <code><a href="graphics.html#topic+par">par</a></code>).
If <code>ctrline</code> is specified as <code>ctrline = list()</code>, the default values <code>conf = list(gamma = 0.95, col = "blue", lty = "solid")</code> will be used.
See examples below.
To use <code>ctrline</code>, the LR object <code>x</code> has to be generated using the option <code>se = TRUE</code> in <code>LRtest()</code>.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_smooline">smooline</code></td>
<td>
<p>spline smoothed confidence bands; must be specified as a list with optional elements: <code>gamma</code>, is the confidence level (numeric), <code>col</code> and <code>lty</code>, color and linetype, <code>spar</code> as smoothing parameter (see <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>).</p>
</td></tr>  
<tr><td><code id="LRtest_+3A_asp">asp</code></td>
<td>
<p>sets the <code class="reqn">y/x</code> ratio of the plot (see <code><a href="graphics.html#topic+plot.window">plot.window</a></code>).</p>
</td></tr>
<tr><td><code id="LRtest_+3A_x_axis">x_axis</code></td>
<td>
<p>if <code>TRUE</code>, the <code class="reqn">x</code>-axis will be plotted.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_y_axis">y_axis</code></td>
<td>
<p>if <code>TRUE</code>, the <code class="reqn">y</code>-axis will be plotted.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_set_par">set_par</code></td>
<td>
<p>if <code>TRUE</code>, graphical parameters will be set by the function to optimize the plot's appearance. Unless <code>reset_par = FALSE</code>, these will be reset to the previous <code><a href="graphics.html#topic+par">par</a></code> settings.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_reset_par">reset_par</code></td>
<td>
<p>if <code>TRUE</code>, graphical parameters will be reset to defaults via <code><a href="graphics.html#topic+par">par</a>()</code> after plotting (only if <code>set_par = TRUE</code>). To make adjustments <em>after</em> using <code>plotGOF</code>, this reset can be switched off. Note that the changed graphical parameters will remain in place unless they are redefined (using <code><a href="graphics.html#topic+par">par</a>()</code>) or the device is closed.</p>
</td></tr>
<tr><td><code id="LRtest_+3A_...">...</code></td>
<td>
<p>additional parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the data set contains missing values and <code>mean</code> or <code>median</code> is specified as split criterion, means or medians are calculated for each missing value subgroup and consequently used for raw score splitting.
</p>
<p>When using interactive selection for both labelling of single points (<code>tlab = "identify"</code> and drawing confidence ellipses at certain points (<code>ia = TRUE</code>) then first all plotted points are labelled and afterwards all ellipses are generated.
Both identification processes can be terminated by clicking the second (right) mouse button and selecting &lsquo;Stop&rsquo; from the menu, or from the &lsquo;Stop&rsquo; menu on the graphics window.
</p>
<p>Using the specification <code>which</code> in allows for selectively drawing ellipses for certain items only, e.g., <code>which = 1:3</code> draws ellipses for items 1 to 3 (as long as they are included in <code>beta.subset</code>).
The default is drawing ellipses for all items.
The element <code>col</code> in the <code>conf</code> list can either be a single color specification such as <code>"blue"</code> or a vector with color specifications for all items.
The length must be the same as the number of ellipses to be drawn.
For color specification a palette can be set up using standard palettes (e.g., <code><a href="grDevices.html#topic+rainbow">rainbow</a></code>) or palettes from the <code>colorspace</code> or <code>RColorBrewer</code> package.
An example is given below.
</p>
<p><code>summary</code> and <code>print</code> methods are available for objects of class <code>LR</code>.
</p>


<h3>Value</h3>

<p><code>LRtest</code> returns an object of class <code>LR</code> containing:
</p>
<table>
<tr><td><code>LR</code></td>
<td>
<p>LR-value.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom of the test statistic.</p>
</td></tr>
<tr><td><code>Chisq</code></td>
<td>
<p>Chi-square value with corresponding df.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>P-value of the test.</p>
</td></tr>
<tr><td><code>likgroup</code></td>
<td>
<p>Log-likelihood values for the subgroups</p>
</td></tr>
<tr><td><code>betalist</code></td>
<td>
<p>List of beta parameters for the subgroups.</p>
</td></tr>
<tr><td><code>selist</code></td>
<td>
<p>List of standard errors of beta's.</p>
</td></tr>
<tr><td><code>etalist</code></td>
<td>
<p>List of eta parameters for the subgroups.</p>
</td></tr>
<tr><td><code>spl.gr</code></td>
<td>
<p>Names and levels for <code>splitcr</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>fitobj</code></td>
<td>
<p>List containing model objects from subgroup fit.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger, Marco J. Maier, Adrian Bruegger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations, Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>
<p>Wright, B.D., and Stone, M.H. (1999). Measurement essentials. Wide Range Inc., Wilmington. (<a href="https://www.rasch.org/measess/me-all.pdf">https://www.rasch.org/measess/me-all.pdf</a> 28Mb).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Waldtest">Waldtest</a></code>, <code><a href="#topic+MLoef">MLoef</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># the object used is the result of running ... RM(raschdat1)
res &lt;- raschdat1_RM_fitted       # see ? raschdat1_RM_fitted

# LR-test on dichotomous Rasch model with user-defined split
splitvec &lt;- sample(1:2, 100, replace = TRUE)
lrres &lt;- LRtest(res, splitcr = splitvec)
lrres
summary(lrres)

## Not run: 
# goodness-of-fit plot with interactive labelling of items w/o standard errors
plotGOF(lrres, tlab = "identify")
## End(Not run)

# LR-test with a full raw-score split
X &lt;- sim.rasch(1000, -2:2, seed = 5)
res2 &lt;- RM(X)
full_lrt &lt;- LRtest(res2, splitcr = "all.r")
full_lrt

## Not run: 
# LR-test with mean split, standard errors for beta's
lrres2 &lt;- LRtest(res, split = "mean")
## End(Not run)

# to save computation time, the results are loaded from raschdat1_RM_lrres2
lrres2 &lt;- raschdat1_RM_lrres2                    # see ?raschdat1_RM_lrres2

# goodness-of-fit plot
# additional 95 percent control line with user specified style
plotGOF(lrres2, ctrline = list(gamma = 0.95, col = "red", lty = "dashed"))

# goodness-of-fit plot for items 1, 14, 24, and 25
# additional 95 percent confidence ellipses, default style
plotGOF(lrres2, beta.subset = c(14, 25, 24, 1), conf = list())

## Not run: 
# goodness-of-fit plot for items 1, 14, 24, and 25
# for items 1 and 24 additional 95 percent confidence ellipses
# using colors for these 2 items from the colorspace package
library("colorspace")
my_colors &lt;- rainbow_hcl(2)
plotGOF(lrres2, beta.subset = c(14, 25, 24, 1),
        conf = list(which = c(1, 14), col = my_colors))
## End(Not run)

# first, save current graphical parameters in an object
old_par &lt;- par(mfrow = c(1, 2), no.readonly = TRUE)
# plots
plotGOF(lrres2, ctrline = list(gamma = 0.95, col = "red", lty = "dashed"),
  xlim = c(-3, 3), x_axis = FALSE, set_par = FALSE)
axis(1, seq(-3, 3, .5))

plotGOF(lrres2, conf = list(), xlim = c(-3, 3), x_axis = FALSE, set_par = FALSE)
axis(1, seq(-3, 3, .5))
text(-2, 2, labels = "Annotation")
# reset graphical parameters
par(old_par)
</code></pre>

<hr>
<h2 id='MLoef'>Martin-LÃ¶f's Likelihood-Ratio-Test</h2><span id='topic+MLoef'></span><span id='topic+print.MLoef'></span><span id='topic+summary.MLoef'></span>

<h3>Description</h3>

<p>This Likelihood-Ratio-Test is based on item subgroup splitting.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLoef(robj, splitcr = "median")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLoef_+3A_robj">robj</code></td>
<td>

<p>An object of class <code>'Rm'</code>.
</p>
</td></tr>
<tr><td><code id="MLoef_+3A_splitcr">splitcr</code></td>
<td>

<p>Split criterion to define the item groups.
<code>"median"</code> and <code>"mean"</code> split items in two groups based on their items' raw scores.<br />
<code>splitcr</code> can also be a vector of length <code class="reqn">k</code> (where <code class="reqn">k</code> denotes the number of items) that takes two or more distinct values to define groups used for the Martin-LÃ¶f Test.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements a generalization of the Martin-LÃ¶f test for polytomous items as proposed by Christensen, BjÃ¸rner, Kreiner &amp; Petersen (2002), but does currently not allow for missing values.
</p>
<p>If the split criterion is <code>"median"</code> or <code>"mean"</code> and one or more items' raw scores are equal the median resp. mean, <code>MLoef</code> will assign those items to the lower raw score group.
<code>summary.MLoef</code> gives detailed information about the allocation of all items.
</p>
<p><code>summary</code> and <code>print</code> methods are available for objects of class <code>'MLoef'</code>.
</p>
<p>An &lsquo;exact&rsquo; version of the Martin-LÃ¶f test for binary items is implemented in the <code><a href="#topic+NPtest">NPtest</a></code> function.
</p>


<h3>Value</h3>

<p><code>MLoef</code> returns an object of class <code>MLoef</code> containing:
</p>
<table>
<tr><td><code>LR</code></td>
<td>
<p>LR-value</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><em>p</em>-value of the test</p>
</td></tr>
<tr><td><code>fullModel</code></td>
<td>
<p>the overall Rasch model</p>
</td></tr>
<tr><td><code>subModels</code></td>
<td>
<p>a list containing the submodels</p>
</td></tr>
<tr><td><code>Lf</code></td>
<td>
<p>log-likelihood of the full model</p>
</td></tr>
<tr><td><code>Ls</code></td>
<td>
<p>list of the sub models' log-likelihoods</p>
</td></tr>
<tr><td><code>i.groups</code></td>
<td>
<p>a list of the item groups</p>
</td></tr>
<tr><td><code>splitcr</code></td>
<td>
<p>submitted split criterion</p>
</td></tr>
<tr><td><code>split.vector</code></td>
<td>
<p>binary allocation of items to groups</p>
</td></tr>
<tr><td><code>warning</code></td>
<td>
<p>items equalling median or mean for the respective split criteria</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marco J. Maier, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Christensen, K. B., BjÃ¸rner, J. B., Kreiner S. &amp; Petersen J. H. (2002). Testing unidimensionality in polytomous Rasch models. <em>Psychometrika, (67)</em>4, 563&ndash;574.
</p>
<p>Fischer, G. H., and Molenaar, I. (1995). <em>Rasch Models &ndash; Foundations, Recent Developements, and Applications.</em> Springer.
</p>
<p>Rost, J. (2004). <em>Lehrbuch Testtheorie &ndash; Testkonstruktion.</em> Bern: Huber.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRtest">LRtest</a></code>, <code><a href="#topic+Waldtest">Waldtest</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Martin-LÃ¶f-test on dichotomous Rasch model using "median" and a user-defined
# split vector. Note that group indicators can be of character and/or numeric.
splitvec &lt;- c(1, 1, 1, "x", "x", "x", 0, 0, 1, 0)

res &lt;- RM(raschdat1[,1:10])

MLoef.1 &lt;- MLoef(res, splitcr = "median")
MLoef.2 &lt;- MLoef(res, splitcr = splitvec)

MLoef.1

summary(MLoef.2)
</code></pre>

<hr>
<h2 id='NonparametricTests'>A Function to Perform Nonparametric Rasch Model Tests</h2><span id='topic+NonparametricTests'></span><span id='topic+NPtest'></span>

<h3>Description</h3>

<p>A variety of nonparametric tests as proposed by Ponocny (2001), Koller and Hatzinger (2012), and an &lsquo;exact&rsquo; version of the Martin-LÃ¶f test are implemented. The function operates on random binary matrices that have been generated using an <abbr><span class="acronym">MCMC</span></abbr> algorithm (Verhelst, 2008) from the <span class="pkg">RaschSampler</span> package (Hatzinger, Mair, and Verhelst, 2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NPtest(obj, n = NULL, method = "T1", ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NonparametricTests_+3A_obj">obj</code></td>
<td>

<p>A binary data matrix (or data frame) or an object containing the output from the <span class="pkg"><a href="#topic+RaschSampler">RaschSampler</a></span> package.
</p>
</td></tr>
<tr><td><code id="NonparametricTests_+3A_n">n</code></td>
<td>

<p>If <code>obj</code> is a matrix or a data frame, <code>n</code> is the number of sampled matrices (default is 500)
</p>
</td></tr>
<tr><td><code id="NonparametricTests_+3A_method">method</code></td>
<td>

<p>One of the test statistics. See Details below.
</p>
</td></tr>
<tr><td><code id="NonparametricTests_+3A_...">...</code></td>
<td>

<p>Further arguments according to <code>method</code>.
See Details below.
Additionally, the sampling routine can be controlled by specifying <code>burn_in</code>, <code>step</code>, and <code>seed</code> (for details see below and <code><a href="#topic+rsctrl">rsctrl</a></code>).
A summary of the sampling object may be obtained using the option <code>RSinfo = TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the <span class="pkg"><a href="#topic+RaschSampler">RaschSampler</a></span> package, which is now packaged with <span class="pkg">eRm</span> for convenience.
It can, of course, still be accessed and downloaded separately via CRAN.
</p>
<p>As an input the user has to supply either a binary data matrix or a <span class="pkg">RaschSampler</span> output object.
If the input is a data matrix, the <span class="pkg">RaschSampler</span> is called with default values (i.e., <code>rsctrl(burn_in = 256, n_eff = n, step = 32)</code>, see <code><a href="#topic+rsctrl">rsctrl</a></code>), where <code>n</code> corresponds to <code>n_eff</code> (the default number of sampled matrices is 500).
By default, the starting values for the random number generators (<code>seed</code>) are chosen randomly using system time.
Methods other than those listed below can easily be implemented using the <span class="pkg">RaschSampler</span> package directly.
</p>
<p>The currently implemented methods (following Ponocny's notation of <code class="reqn">T</code>-statistics) and their options are:
</p>

<dl>
<dt><code class="reqn">T_1</code>:</dt><dd><p><code>method = "T1"</code><br />
Checks for local dependence via increased inter-item correlations.
For all item pairs, cases are counted with equal responses on both items.
</p>
</dd>
<dt><code class="reqn">T_{1m}</code>:</dt><dd><p><code>method = "T1m"</code><br />
Checks for multidimensionality via decreased inter-item correlations.
For all item pairs, cases are counted with equal responses on both items.
</p>
</dd>
<dt><code class="reqn">T_{1l}</code>:</dt><dd><p><code>method = "T1l"</code><br />
Checks for learning.
For all item pairs, cases are counted with response pattern (1,1).
</p>
</dd>
<dt><code class="reqn">T_{md}</code>:</dt><dd><p><code>method = "Tmd", idx1, idx2</code><br />
<code>idx1</code> and <code>idx2</code> are vectors of indices specifying items which define two subscales, e.g., <code>idx1 = c(1, 5, 7)</code> and <code>idx2 = c(3, 4, 6)</code><br />
Checks for multidimensionality based on correlations of person raw scores for the subscales.
</p>
</dd>
<dt><code class="reqn">T_2</code>:</dt><dd><p><code>method = "T2", idx = NULL, stat = "var"</code><br />
<code>idx</code> is a vector of indices specifying items which define a subscale, e.g., <code>idx = c(1, 5, 7)</code><br />
<code>stat</code> defines the used statistic as a character object which can be: <code>"var"</code> (variance), <code>"mad1"</code> (mean absolute deviation), <code>"mad2"</code> (median absolute deviation), or <code>"range"</code> (range)<br />
Checks for local dependence within model deviating subscales via increased dispersion of subscale person rawscores.
</p>
</dd>
<dt><code class="reqn">T_{2m}</code>:</dt><dd><p><code>method = "T2m", idx = NULL, stat = "var"</code><br />
<code>idx</code> is a vector of indices specifying items which define a subscale, e.g., <code>idx = c(1, 5, 7)</code><br />
<code>stat</code> defines the used statistic as a character object which can be: <code>"var"</code> (variance), <code>"mad1"</code> (mean absolute deviation), <code>"mad2"</code> (median absolute deviation), <code>"range"</code> (range)<br />
Checks for multidimensionality within model deviating subscales via decreased dispersion of subscale person rawscores.
</p>
</dd>
<dt><code class="reqn">T_4</code>:</dt><dd><p><code>method = "T4", idx = NULL, group = NULL, alternative = "high"</code><br />
<code>idx</code> is a vector of indices specifying items which define a subscale, e.g., <code>idx = c(1, 5, 7)</code><br />
<code>group</code> is a logical vector defining a subject group, e.g., <code>group = ((age &gt;= 20) &amp; (age &lt; 30))</code><br />
<code>alternative</code> specifies the alternative hypothesis and can be: <code>"high"</code> or <code>"low"</code>.<br />
Checks for group anomalies (<abbr><span class="acronym">DIF</span></abbr>) via too high (low) raw scores on item(s) for specified group.
</p>
</dd>
<dt><code class="reqn">T_{10}</code>:</dt><dd><p><code>method = "T10", splitcr = "median"</code><br />
<code>splitcr</code> defines the split criterion for subject raw score splitting.
<code>"median"</code> uses the median as split criterion, <code>"mean"</code> performs a mean-split.
Optionally, <code>splitcr</code> can also be a vector which assigns each person to one of two subgroups (e.g., following an external criterion).
This vector can be numeric, character, logical, or a factor.<br />
Global test for subgroup-invariance.
Checks for different item difficulties in two subgroups (for details see Ponocny, 2001).
</p>
</dd>
<dt><code class="reqn">T_{11}</code>:</dt><dd><p><code>method = "T11"</code><br />
Global test for local dependence.
The statistic calculates the sum of absolute deviations between the observed inter-item correlations and the expected correlations.
</p>
</dd>
<dt><code class="reqn">T_{pbis}</code>:</dt><dd><p><code>method = "Tpbis", idxt, idxs</code><br />
Test for discrimination.
The statistic calculates a point-biserial correlation for a test item (specified via <code>idxt</code>) with the person row scores for a subscale of the test sum (specified via <code>idxs</code>).
If the correlation is too low, the test item shows different discrimination compared to the items of the subscale.
</p>
</dd>
<dt><em>Martin-LÃ¶f</em></dt><dd>
<p>The &lsquo;exact&rsquo; version of the <em>Martin-LÃ¶f</em> statistic is specified via <code>method = "MLoef"</code> and optionally <code>splitcr</code> (see <code><a href="#topic+MLoef">MLoef</a></code>).
</p>
</dd>

<dt><code class="reqn">Q_{3h}</code>:</dt><dd><p><code>method = "Q3h"</code><br />
Checks for local dependence by detecting an increased correlation of inter-item residuals. Low p-values correspond to a high (&quot;h&quot;) correlation between two items.
</p>
</dd>
<dt><code class="reqn">Q_{3l}</code>:</dt><dd><p><code>method = "Q3l"</code><br />
Checks for local dependence by detecting a decreased correlation of inter-item residuals. Low p-values correspond to a low (&quot;l&quot;) correlation between two items.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>Depending on the <code>method</code> argument, a list is returned which has one of the following classes:
<code>'T1obj'</code>, <code>'T1mobj'</code>, <code>'T1lobj'</code>, <code>'Tmdobj'</code>, <code>'T2obj'</code>, <code>'T2mobj'</code>, <code>'T4obj'</code>, <code>'T10obj'</code>, <code>'T11obj'</code>, <code>'Tpbisobj'</code>, <code>'Q3hobj'</code> or <code>'Q3lobj'</code>.
</p>
<p>The main output element is <code>prop</code> giving the one-sided <code class="reqn">p</code>-value, i.e., the number of statistics from the sampled matrices which are equal or exceed the statistic based on the observed data.
For <code class="reqn">T_1</code>, <code class="reqn">T_{1m}</code>, and <code class="reqn">T_{1l}</code>, <code>prop</code> is a vector.
For the Martin-LÃ¶f test, the returned object is of class <code>'MLobj'</code>.
Besides other elements, it contains a <code>prop</code> vector and <code>MLres</code>, the output object from the asymptotic Martin-LÃ¶f test on the input data.
</p>


<h3>Note</h3>

<p>The <span class="pkg">RaschSampler</span> package is no longer required to use <code>NPtest</code> since <span class="pkg">eRm</span> version 0.15-0.</p>


<h3>Author(s)</h3>

<p>Reinhold Hatzinger</p>


<h3>References</h3>


<p>Ponocny, I. (2001). Nonparametric goodness-of-fit tests for the Rasch model. <em>Psychometrika, 66</em>(3), 437&ndash;459. <a href="https://doi.org/10.1007/BF02294444">doi:10.1007/BF02294444</a>
</p>
<p>Verhelst, N. D. (2008). An efficient <abbr><span class="acronym">MCMC</span></abbr> algorithm to sample binary matrices with fixed marginals. <em>Psychometrika, 73</em>(4), 705&ndash;728. <a href="https://doi.org/10.1007/s11336-008-9062-3">doi:10.1007/s11336-008-9062-3</a>
</p>
<p>Verhelst, N., Hatzinger, R., &amp; Mair, P. (2007). The Rasch sampler. <em>Journal of Statistical Software, 20</em>(4), 1&ndash;14. <a href="https://www.jstatsoft.org/v20/i04">https://www.jstatsoft.org/v20/i04</a>
</p>
<p>Koller, I., &amp; Hatzinger, R. (2013). Nonparametric tests for the Rasch model: Explanation, development, and application of quasi-exact tests for small samples. <em>Interstat, 11</em>, 1&ndash;16. <a href="http://interstat.statjournals.net/YEAR/2013/abstracts/1311002.php">http://interstat.statjournals.net/YEAR/2013/abstracts/1311002.php</a>
</p>
<p>Koller, I., Maier, M. J., &amp; Hatzinger, R. (2015). An Empirical Power Analysis of Quasi-Exact Tests for the Rasch Model: Measurement Invariance in Small Samples. <em>Methodology, 11</em>(2), 45&ndash;54. <a href="https://doi.org/10.1027/1614-2241/a000090">doi:10.1027/1614-2241/a000090</a>
</p>
<p>Debelak, R., &amp; Koller, I. (2019). Testing the Local Independence Assumption of the Rasch Model With Q3-Based Nonparametric Model Tests. <em>Applied Psychological Measurement</em> <a href="https://doi.org/10.1177/0146621619835501">doi:10.1177/0146621619835501</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Preparation:

# data for examples below
X &lt;- as.matrix(raschdat1)

# generate 100 random matrices based on original data matrix
rmat &lt;- rsampler(X, rsctrl(burn_in = 100, n_eff = 100, seed = 123))

## the following examples can also directly be used by setting
## rmat &lt;- as.matrix(raschdat1)
## without calling rsampler() first
t1 &lt;- NPtest(rmat, n = 100, method = "T1")


### Examples ###################################################################

###--- T1 ----------------------------------------------------------------------
t1 &lt;- NPtest(rmat, method = "T1")
# choose a different alpha for selecting displayed values
print(t1, alpha = 0.01)


###--- T2 ----------------------------------------------------------------------
t21 &lt;- NPtest(rmat, method = "T2", idx = 1:5, burn_in = 100, step = 20,
              seed = 7654321, RSinfo = TRUE)
# default stat is variance
t21

t22 &lt;- NPtest(rmat, method = "T2", stat = "mad1",
              idx = c(1, 22, 5, 27, 6, 9, 11))
t22


###--- T4 ----------------------------------------------------------------------
age &lt;- sample(20:90, 100, replace = TRUE)
# group MUST be a logical vector
# (value of TRUE is used for group selection)
age &lt;- age &lt; 30
t41 &lt;- NPtest(rmat, method = "T4", idx = 1:3, group = age)
t41

sex &lt;- gl(2, 50)
# group can also be a logical expression (generating a vector)
t42 &lt;- NPtest(rmat, method = "T4", idx = c(1, 4, 5, 6), group = sex == 1)
t42


###--- T10 ---------------------------------------------------------------------
t101 &lt;- NPtest(rmat, method = "T10")       # default split criterion is "median"
t101

## Not run: 
split &lt;- runif(100)
t102 &lt;- NPtest(rmat, method = "T10", splitcr = split &gt; 0.5)
t102

t103 &lt;- NPtest(rmat, method = "T10", splitcr = sex)
t103
## End(Not run)


###--- T11 ---------------------------------------------------------------------
t11 &lt;- NPtest(rmat, method = "T11")
t11


###--- Tpbis -------------------------------------------------------------------
tpb &lt;- NPtest(X[, 1:5], method = "Tpbis", idxt = 1, idxs = 2:5)
tpb


###--- Martin-LÃ¶f --------------------------------------------------------------
## Not run: 
# takes a while ...
split &lt;- rep(1:3, each = 10)
NPtest(raschdat1, n = 100, method = "MLoef", splitcr = split)
## End(Not run)
</code></pre>

<hr>
<h2 id='PCM'>Estimation of partial credit models</h2><span id='topic+PCM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a partial credit model for polytomous
item responses by using CML estimation. </p>


<h3>Usage</h3>

<pre><code class='language-R'>PCM(X, W, se = TRUE, sum0 = TRUE, etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PCM_+3A_x">X</code></td>
<td>
<p>Input data matrix or data frame with item responses (starting from 0); rows represent individuals, columns represent items. Missing values are inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="PCM_+3A_w">W</code></td>
<td>
<p>Design matrix for the PCM. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="PCM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="PCM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normed to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="PCM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Through specification in W, the parameters of the categories with 0 responses
are set to 0 as well as the first category of the first item. Available methods
for PCM-objects are:<br />
<code>print</code>, <code>coef</code>, <code>model.matrix</code>,
<code>vcov</code>, <code>plot</code>, <code>summary</code>, <code>logLik</code>, <code>person.parameters</code>,
<code>plotICC</code>, <code>LRtest</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>Rm, eRm</code> containing.
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item difficulty parameters.</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item-category (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RM">RM</a></code>,<code><a href="#topic+RSM">RSM</a></code>,<code><a href="#topic+LRtest">LRtest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##PCM with 10 subjects, 3 items
res &lt;- PCM(pcmdat)
res
summary(res)                #eta and beta parameters with CI
thresholds(res)             #threshold parameters
</code></pre>

<hr>
<h2 id='person.parameter'>Estimation of Person Parameters</h2><span id='topic+person.parameter'></span><span id='topic+person.parameter.eRm'></span><span id='topic+summary.ppar'></span><span id='topic+print.ppar'></span><span id='topic+plot.ppar'></span><span id='topic+coef.ppar'></span><span id='topic+logLik.ppar'></span><span id='topic+print.logLik.ppar'></span><span id='topic+confint.ppar'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the person parameters with spline
interpolation for non-observed and 0/full responses. Extraction of information criteria such
as AIC, BIC, and cAIC based on unconditional log-likelihood.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eRm'
person.parameter(object)
## S3 method for class 'ppar'
summary(object, ...)
## S3 method for class 'ppar'
print(x, ...)
## S3 method for class 'ppar'
plot(x, xlab = "Person Raw Scores",
   ylab = "Person Parameters (Theta)", main = NULL, ...)
## S3 method for class 'ppar'
coef(object, extrapolated = TRUE, ...)
## S3 method for class 'ppar'
logLik(object, ...)
## S3 method for class 'ppar'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="person.parameter_+3A_object">object</code></td>
<td>
<p>Object of class <code>'eRm'</code> in <code>person.parameter</code> and object of class <code>ppar</code> in <code>IC</code>.</p>
</td></tr>
</table>
<p>Arguments for <code>print</code> and <code>plot</code> methods:
</p>
<table>
<tr><td><code id="person.parameter_+3A_x">x</code></td>
<td>
<p>Object of class <code>ppar</code>.</p>
</td></tr>
<tr><td><code id="person.parameter_+3A_xlab">xlab</code></td>
<td>
<p>Label of the x-axis.</p>
</td></tr>
<tr><td><code id="person.parameter_+3A_ylab">ylab</code></td>
<td>
<p>Label of the y-axis.</p>
</td></tr>
<tr><td><code id="person.parameter_+3A_main">main</code></td>
<td>
<p>Title of the plot.</p>
</td></tr>
<tr><td><code id="person.parameter_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>
<p>Arguments for the <code>coef</code> method:
</p>
<table>
<tr><td><code id="person.parameter_+3A_extrapolated">extrapolated</code></td>
<td>
<p>either returns extrapolated values for raw scores 0 and k or sets them <code>NA</code></p>
</td></tr>
</table>
<p>Arguments for <code>confint</code>:
</p>
<table>
<tr><td><code id="person.parameter_+3A_parm">parm</code></td>
<td>
<p>Parameter specification (ignored).</p>
</td></tr>
<tr><td><code id="person.parameter_+3A_level">level</code></td>
<td>
<p>Alpha-level.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the data set contains missing values, person parameters are estimated
for each missing value subgroup.
</p>


<h3>Value</h3>

<p>The function <code>person.parameter</code> returns an object of class <code>ppar</code> containing:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Log-likelihood of the collapsed data (for faster estimation persons with the same raw score are collapsed).</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>thetapar</code></td>
<td>
<p>Person parameter estimates.</p>
</td></tr>
<tr><td><code>se.theta</code></td>
<td>
<p>Standard errors of the person parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix.</p>
</td></tr>
<tr><td><code>theta.table</code></td>
<td>
<p>Matrix with person parameters (ordered according to original data)
including NA pattern group.</p>
</td></tr>
<tr><td><code>pers.ex</code></td>
<td>
<p>Indices with persons excluded due to 0/full raw score</p>
</td></tr>
<tr><td><code>X.ex</code></td>
<td>
<p>Data matrix with persons excluded</p>
</td></tr>
<tr><td><code>gmemb</code></td>
<td>
<p>NA group membership vector (0/full persons excluded)</p>
</td></tr>
</table>
<p>The function <code>coef</code> returns a vector of the person parameter estimates for each person (i.e., the first column
of <code>theta.table</code>).
</p>
<p>The function <code>logLik</code> returns an object of class <code>loglik.ppar</code> containing:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Log-likelihood of the collapsed data (see above).</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemfit.ppar">itemfit.ppar</a></code>,<code><a href="#topic+personfit.ppar">personfit.ppar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Person parameter estimation of a rating scale model
res &lt;- RSM(rsmdat)
pres &lt;- person.parameter(res)
pres
summary(pres)
plot(pres)

#Person parameter estimation for a Rasch model with missing values
res &lt;- RM(raschdat2, se = FALSE) #Rasch model without standard errors
pres &lt;- person.parameter(res)
pres                             #person parameters
summary(pres)
logLik(pres)                     #log-likelihood of person parameter estimation
</code></pre>

<hr>
<h2 id='PersonMisfit'>Person Misfit</h2><span id='topic+PersonMisfit'></span><span id='topic+PersonMisfit.ppar'></span>

<h3>Description</h3>

<p>This function counts the number of persons who do not fit the Rasch model. More specifically, it returns the proportion and frequency of persons - or more generally cases - who exceed a	Chi-square based Z-value of 1.96 (suggesting a statistically significant deviation from the predicted response pattern).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppar'
PersonMisfit(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PersonMisfit_+3A_object">object</code></td>
<td>
<p>Object of class <code>ppar</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the proportion and absolute number of persons who do not fit the Rasch model (Z-values &gt; 1.96).  
</p>


<h3>Value</h3>

<p><code>PersonMisfit</code> returns an object of class <code>MisfittingPersons</code> containing:
</p>
<table>
<tr><td><code>PersonMisfit</code></td>
<td>
<p>the proportion of misfitting persons,</p>
</td></tr>
<tr><td><code>count.misfit.Z</code></td>
<td>
<p>the frequency of misfitting person,</p>
</td></tr>
<tr><td><code>total.persons</code></td>
<td>
<p>the number of persons for whom a fit value was estimated.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adrian Bruegger</p>


<h3>Examples</h3>

<pre><code class='language-R'>rm1 &lt;- RM(raschdat1)
pers &lt;- person.parameter(rm1)
pmfit &lt;- PersonMisfit(pers)
pmfit
summary(pmfit)
</code></pre>

<hr>
<h2 id='phi.range'>Example User Function</h2><span id='topic+phi.range'></span>

<h3>Description</h3>

<p>Calculates the <code class="reqn">R_\phi</code> statistic, i.e., the range of the inter-column correlations (<code class="reqn">\phi</code>-coefficients) for a binary matrix.</p>


<h3>Usage</h3>

<pre><code class='language-R'>phi.range(mat)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phi.range_+3A_mat">mat</code></td>
<td>
<p>a binary matrix</p>
</td></tr></table>


<h3>Value</h3>

<p>The range of the inter-column correlations</p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(burn_in = 10, n_eff = 5, step=10, seed = 123, tfixed = FALSE)
mat &lt;- matrix(sample(c(0,1), 50, replace = TRUE), nr = 10)
rso &lt;- rsampler(mat, ctr)
rso_st &lt;- rstats(rso,phi.range)
print(unlist(rso_st))
</code></pre>

<hr>
<h2 id='plotDIF'>
Confidence intervals plot of item parameter estimates.
</h2><span id='topic+plotDIF'></span>

<h3>Description</h3>

<p>Performs an plot of item parameter conficence intervals based on <code>LRtest</code> subgroup splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDIF(object, item.subset = NULL, gamma = 0.95, main = NULL,
          xlim = NULL,  xlab = " ", ylab=" ", col = NULL,
          distance, splitnames=NULL, leg = FALSE, legpos="bottomleft", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotDIF_+3A_object">object</code></td>
<td>

<p>An object of class <code>LR</code> (if more objects should be plotted, the argument has to be defined as a <code>list</code>).
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_item.subset">item.subset</code></td>
<td>

<p>Subset of items to be plotted. Either a numeric vector indicating the items or a character vector indicating the itemnames.
If nothing is defined (default), all items are plotted.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_gamma">gamma</code></td>
<td>

<p>The level for the item parameter's confidence limits (default is gamma = 0.95).
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_main">main</code></td>
<td>

<p>Main title for the plot.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_xlim">xlim</code></td>
<td>

<p>Numeric vector of length 2, giving the x coordinates ranges of the plot (the y coordinates depend on the number of
depicted items).
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_xlab">xlab</code></td>
<td>

<p>Label for the x axis.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_ylab">ylab</code></td>
<td>

<p>Label for the y axis.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_col">col</code></td>
<td>

<p>By default the color for the drawn confidence lines is determined automatically whereas every group (split criterion)
is depicted in the same color.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_distance">distance</code></td>
<td>

<p>Distance between each item's confidence lines &ndash; if omitted, the distance shrinks with increasing numbers of split criteria. Can be overriden using values in (0, 0.5).
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_splitnames">splitnames</code></td>
<td>

<p>For labeling the splitobjects in the legend (returns a nicer output).
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_leg">leg</code></td>
<td>

<p>If <code>TRUE</code> a legend is provided by default.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_legpos">legpos</code></td>
<td>

<p>Position of the legend with possible values  <code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>,
<code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. The default value for the legend
is <code>"bottomleft"</code>.
</p>
</td></tr>
<tr><td><code id="plotDIF_+3A_...">...</code></td>
<td>

<p>Further options to be passed to <code>plot</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are items that cannot be estimated for some reasons, certainly these ones are not plotted.
For plotting several objects of class <code>LR</code>, the subgroup splitting by <code>LRtest</code> has to
be carried out for the same data set (or at least item subsets of it).
</p>
<p>Plotting a certain subset of items could be useful if the objects of class <code>LR</code> contain a huge number
of estimated items.
</p>
<p>The default level for the conficence limits is gamma = 0.95. (If the conficence limits should be
corrected it is useful to use a  correction, e.g., Bonferroni: 1 - (1 - gamma) / number of estimated items.)
</p>


<h3>Value</h3>

<p><code>plotCI</code> returns a list containing the confidence limits of each group in each <code>LRtest</code> object.
</p>


<h3>Author(s)</h3>

<p>Kathrin Gruber, Reinhold Hatzinger</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRtest">LRtest</a></code>, <code><a href="#topic+confint.threshold">confint.threshold</a></code>, <code><a href="#topic+thresholds">thresholds</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># the object used is the result of running   RM(raschdat1)
res &lt;- raschdat1_RM_fitted     # see ? raschdat1_RM_fitted

## Not run: 
# LR-test on dichotomous Rasch model with user-defined split
splitvec &lt;- rep(1:2, each = 50)
lrres &lt;- LRtest(res, splitcr = splitvec)

# LR-test with mean split
lrres2 &lt;- LRtest(res, split = "mean")

# combination of LRtest-objects in a list
RMplotCI &lt;- list(lrres, lrres2)
## End(Not run)

# the object raschdat1_RM_plotDIF is the result of the computations outlined
# above and is loaded to save computation time. see ?raschdat1_RM_plotDIF
RMplotCI &lt;- raschdat1_RM_plotDIF

# Confidence intervals plot with default assumptions
plotDIF(RMplotCI)

# Confidence intervals plot with Bonferroni correction
plotDIF(RMplotCI, gamma = (1 - (0.05/10)))

# Confidence intervals plot for an item subset
plotDIF(RMplotCI, item.subset = 1:6)

# with user defined group color and legend
plotDIF(RMplotCI, col = c("red", "blue"), leg = TRUE, legpos = "bottomright")

# with names for the splitobjects
plotDIF(RMplotCI, col = c("red", "blue"), leg = TRUE, legpos = "bottomright",
        splitnames = c(paste("User", 1:2), paste(rep("Mean", 2), 1:2)))
</code></pre>

<hr>
<h2 id='plotGR'>Plot Treatment or Covariate Effects for LLRA
</h2><span id='topic+plotGR'></span>

<h3>Description</h3>

<p>Plots treatment or covariate group effects over time.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotGR(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotGR_+3A_object">object</code></td>
<td>
<p>an object of class &quot;llra&quot;.
</p>
</td></tr>
<tr><td><code id="plotGR_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to and from other
methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is a lattice plot with each panel corresponding to an item. The
effects are plotted for each groups (including baseline) over the
different time points. The groups are given the same names as for the
parameter estimates (derived from groupvec).
</p>
<p>Please note that all effects are to be interpreted relative to the
baseline.
</p>
<p>Currently, this function only works for a full item x treatment x
timepoints LLRA. Collapsed effects will not be displayed properly. 
</p>


<h3>Warning:</h3>

<p>Objects of class <code>"llra"</code> that contain estimates from a collapsed
data matrix will not be displayed correctly.
</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>See Also</h3>

<p>The plot method for trend effects <code><a href="#topic+plotTR">plotTR</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Example 6 from Hatzinger &amp; Rusch (2009)
groups &lt;- c(rep("TG",30),rep("CG",30))
llra1 &lt;- LLRA(llradat3,mpoints=2,groups=groups)
summary(llra1)
plotGR(llra1)

## Not run:   
##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.
ex2 &lt;- LLRA(llraDat2[1:20],mpoints=4,groups=llraDat2[21])
plotGR(ex2)
## End(Not run)
</code></pre>

<hr>
<h2 id='plotICC'>ICC Plots</h2><span id='topic+plotICC'></span><span id='topic+plotICC.Rm'></span><span id='topic+plotjointICC'></span><span id='topic+plotjointICC.dRm'></span>

<h3>Description</h3>

<p>Plot functions for visualizing the item characteristic curves</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Rm'
plotICC(object, item.subset = "all", empICC = NULL, empCI = NULL,
   mplot = NULL, xlim = c(-4, 4), ylim = c(0, 1),
   xlab = "Latent Dimension", ylab = "Probability to Solve", main=NULL,
   col = NULL, lty = 1, legpos = "left", ask = TRUE, ...)
## S3 method for class 'dRm'
plotjointICC(object, item.subset = "all", legend = TRUE,
   xlim = c(-4, 4), ylim = c(0, 1), xlab = "Latent Dimension",
   ylab = "Probability to Solve", lty = 1, legpos = "topleft",
   main="ICC plot",col=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotICC_+3A_object">object</code></td>
<td>
<p>object of class <code>Rm</code> or <code>dRm</code></p>
</td></tr>
<tr><td><code id="plotICC_+3A_item.subset">item.subset</code></td>
<td>
<p>Subset of items to be plotted. Either a numeric vector indicating
the column in <code>X</code> or a character vector indiciating the column name.
If <code>"all"</code> (default), all items are plotted.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_empicc">empICC</code></td>
<td>
<p>Plotting the empirical ICCs for objects of class <code>dRm</code>.
If <code>empICC=NULL</code>
(the default) the empirical ICC is not drawn. Otherwise, <code>empICC</code> must be
specified as a list where the first element must be one of
<code>"raw"</code>, <code>"loess"</code>, <code>"tukey"</code>, <code>"kernel"</code>. The other optional elements are
<code>smooth</code> (numeric), <code>type</code> (line type for empirical ICCs,
useful values are <code>"p"</code> (default), <code>"l"</code>, and <code>"b"</code>,
see graphics parameter <code>type</code> in <code><a href="graphics.html#topic+plot.default">plot.default</a></code>),
<code>pch</code>, <code>col</code>, and <code>lty</code>, plotting &lsquo;character&rsquo;, colour and linetype
(see <code><a href="graphics.html#topic+par">par</a></code>). See details and examples below.
</p>
</td></tr>
<tr><td><code id="plotICC_+3A_empci">empCI</code></td>
<td>
<p>Plotting confidence intervals for the the empirical ICCs.
If <code>empCI=NULL</code> (the default) no confidence intervals are drawn.
Otherwise, by specifying <code>empCI</code> as a list gives &lsquo;exact&rsquo; confidence
intervals for each point of the empirical ICC.
The optional elements of this list are <code>gamma</code>, the confidence level,
<code>col</code>, colour, and <code>lty</code>, line type. If <code>empCI</code> is specified
as an empty list,
the default values <code>empCI=list(gamma=0.95,col="red",lty="dotted")</code>
will be used.
</p>
</td></tr>
<tr><td><code id="plotICC_+3A_mplot">mplot</code></td>
<td>
<p>if <code>NULL</code> the default setting is in effect. For models of class <code>dRm</code> this
is <code>mplot = TRUE</code>, i.e.,
the ICCs for up to 4 items are plotted in one figure. For <code>Rm</code>
models the default is <code>FALSE</code> (each item in one figure) but may be set to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plotICC_+3A_xlab">xlab</code></td>
<td>
<p>Label of the x-axis.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_ylab">ylab</code></td>
<td>
<p>Label of the y-axis.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_xlim">xlim</code></td>
<td>
<p>Range of person parameters.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_ylim">ylim</code></td>
<td>
<p>Range for probability to solve.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_legend">legend</code></td>
<td>
<p>If <code>TRUE</code>, legend is provided, otherwise the ICCs are labeled.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_col">col</code></td>
<td>
<p>If not specified or <code>NULL</code>, line colors are determined automatically.
Otherwise, a scalar or vector with appropriate color specifications may be supplied
(see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="plotICC_+3A_lty">lty</code></td>
<td>
<p>Line type.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_main">main</code></td>
<td>
<p>Title of the plot.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_legpos">legpos</code></td>
<td>
<p>Position of the legend with possible values  <code>"bottomright"</code>,
<code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>,
<code>"topright"</code>, <code>"right"</code> and <code>"center"</code>.
If <code>FALSE</code> no legend is displayed.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_ask">ask</code></td>
<td>
<p>If <code>TRUE</code> (the default) and the <code>R</code> session is interactive the user is asked for input,
before a new figure is drawn. <code>FALSE</code> is only useful if automated figure export is
in effect, e.g., when using <code><a href="utils.html#topic+Sweave">Sweave</a></code>.</p>
</td></tr>
<tr><td><code id="plotICC_+3A_...">...</code></td>
<td>
<p>Additional plot parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Empirical ICCs for objects of class <code>dRm</code> can be plotted using the option <code>empICC</code>, a
list where the first element specifies the type of calculation of the empirical values.
If <code>empICC=list("raw", other specifications)</code>
relative frequencies of the positive responses are calculated for each rawscore group and plotted
at the position of the corresponding person parameter. The other options use the default versions
of various smoothers: <code>"tukey"</code> (see <code><a href="stats.html#topic+smooth">smooth</a></code>), <code>"loess"</code> (see <code><a href="stats.html#topic+loess">loess</a></code>),
and <code>"kernel"</code> (see <code><a href="stats.html#topic+ksmooth">ksmooth</a></code>). For <code>"loess"</code> and <code>"kernel"</code> a further
element, <code>smooth</code>,
may be specified to control the span (default is 0.75) or the bandwith (default is 0.5),
respectively. For example, the specification could be <code>empirical = list("loess", smooth=0.9)</code>
or <code>empirical = list("kernel",smooth=2)</code>.
Higher values result in smoother estimates of the empirical ICCs.
</p>
<p>The optional confidence intervals are obtained by a procedure first given in
Clopper and Pearson (1934) based on the beta distribution (see <code><a href="stats.html#topic+binom.test">binom.test</a></code>).
</p>


<h3>Note</h3>

<p>For most of the plot options see  <code><a href="graphics.html#topic+plot">plot</a></code> and <code><a href="graphics.html#topic+par">par</a></code>.</p>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotGOF">plotGOF</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Rating scale model, ICC plot for all items
rsm.res &lt;- RSM(rsmdat)
thresholds(rsm.res)
plotICC(rsm.res)

# now items 1 to 4 in one figure without legends
plotICC(rsm.res, item.subset = 1:4, mplot = TRUE, legpos = FALSE)

# Rasch model for items 1 to 8 from raschdat1
# empirical ICCs displaying relative frequencies (default settings)
rm8.res &lt;- RM(raschdat1[,1:8])
plotICC(rm8.res, empICC=list("raw"))

# the same but using different plotting styles
plotICC(rm8.res, empICC=list("raw",type="b",col="blue",lty="dotted"))

# kernel-smoothed empirical ICCs using bandwidth = 2
plotICC(rm8.res, empICC = list("kernel",smooth=3))

# raw empirical ICCs with confidence intervals
# displaying only items 2,3,7,8
plotICC(rm8.res, item.subset=c(2,3,7,8), empICC=list("raw"), empCI=list())

# Joint ICC plot for items 2, 6, 8, and 15 for a Rasch model
res &lt;- RM(raschdat1)
plotjointICC(res, item.subset = c(2,6,8,15), legpos = "left")

## End(Not run)
</code></pre>

<hr>
<h2 id='plotINFO'>Plot Information For <code>'eRm'</code> objects
</h2><span id='topic+plotINFO'></span>

<h3>Description</h3>

<p>Calculates and plots the individual item-category information
(type='category'), item information (type='item') or test/scale information (i.e., summed item information, type='scale' or 'test') ) as defined by Samejima (1969)</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotINFO(ermobject, type = "both", theta = seq(-6, 6, length.out = 1001L), 
legpos = "topright", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotINFO_+3A_ermobject">ermobject</code></td>
<td>
<p>An object of class <code>'eRm'</code>.</p>
</td></tr>
<tr><td><code id="plotINFO_+3A_type">type</code></td>
<td>
<p>A string denoting the type of information to be
plotted. Currently supports <code>"category"</code>, <code>"item"</code>,
<code>"test"</code>, <code>"scale"</code> and <code>"both"</code> (which gives item
and scale information; default).</p>
</td></tr>
<tr><td><code id="plotINFO_+3A_theta">theta</code></td>
<td>
<p>Supporting or sampling points on the latent trait.</p>
</td></tr>
<tr><td><code id="plotINFO_+3A_legpos">legpos</code></td>
<td>
<p>Defines the positioning of the legend, as in <code><a href="#topic+plotICC">plotICC</a></code>.</p>
</td></tr>
<tr><td><code id="plotINFO_+3A_...">...</code></td>
<td>

<p>Further arguments.
<code>xlab</code> sets the label of the <code class="reqn">x</code> axis.
<code>ylabI</code> and <code>ylabT</code> control the labeling of the item or test information plot.
<code>mainI</code> and <code>mainT</code> set the titles for item/test information plots.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Samejima, F. (1969) Estimation of latent ability using a response pattern of graded scores. <em>Psychometric Monographs</em>, <b>17</b>.</p>


<h3>See Also</h3>

<p>The function to calculate the item or test information, <code><a href="#topic+item_info">item_info</a></code> and <code><a href="#topic+test_info">test_info</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- PCM(pcmdat)
plotINFO(res)
</code></pre>

<hr>
<h2 id='plotPImap'>Person-Item Map</h2><span id='topic+plotPImap'></span>

<h3>Description</h3>

<p>A person-item map displays the location of item (and threshold) parameters
as well as the distribution of person parameters.along the latent dimension.
Person-item maps are useful to compare the range and position of the item measure distribution
(lower panel) to the range and position of the person measure distribution (upper panel).
Items should ideally be located along the whole scale to meaningfully measure
the &lsquo;ability&rsquo; of all persons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPImap(object, item.subset = "all", sorted = FALSE,
   main = "Person-Item Map", latdim = "Latent Dimension",
   pplabel = "Person\nParameter\nDistribution", cex.gen = 0.7,
   xrange = NULL, warn.ord = TRUE, warn.ord.colour = "black",
   irug = TRUE, pp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPImap_+3A_object">object</code></td>
<td>
<p>Object of class <code>Rm</code> or <code>dRm</code></p>
</td></tr>
<tr><td><code id="plotPImap_+3A_item.subset">item.subset</code></td>
<td>
<p>Subset of items to be plotted. Either a numeric vector indicating
the column in <code>X</code> or a character vector indicating the column name.
If <code>"all"</code>, all items are plotted. The number of items to be plotted must be &gt; 1.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_sorted">sorted</code></td>
<td>
<p> If <code>TRUE</code>, the items are sorted in increasing order according to their location
on the latent dimension.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_main">main</code></td>
<td>
<p>Main title of the plot.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_latdim">latdim</code></td>
<td>
<p>Label of the x-axis, i.e., the latent dimension.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_pplabel">pplabel</code></td>
<td>
<p>Title for the upper panel displaying the person parameter distribution</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_cex.gen">cex.gen</code></td>
<td>
<p><code>cex</code> as a graphical parameter
specifies a numerical value giving the amount by which plotting text and symbols should be
magnified relative to the default. Here <code>cex.gen</code> applies to all text labels. The default is 0.7.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_xrange">xrange</code></td>
<td>
<p>Range for the x-axis</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_warn.ord">warn.ord</code></td>
<td>
<p>If <code>TRUE</code> (the default) asterisks are displayed in the right margin of the lower
panel to indicate nonordinal threshold locations for polytomous items.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_warn.ord.colour">warn.ord.colour</code></td>
<td>
<p>Nonordinal threshold locations for polytomous
items are coloured with this colour to make them more visible.  This
is especially useful when there are many items so that the plot is
quite dense.  The default is <code>"black"</code>, so that there is no
distinction made.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_irug">irug</code></td>
<td>
<p>If <code>TRUE</code> (the default), all thresholds are plotted below the person distribution
to indicate where the included items are most informative.</p>
</td></tr>
<tr><td><code id="plotPImap_+3A_pp">pp</code></td>
<td>
<p>If non-<code>NULL</code>, this contains the
<code>person.parameter</code> data of the data object, avoiding the
need to recalculate it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Item locations are displayed with bullets, threshold locations with circles.
</p>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger, patches from Julian Gilbey and Marco J. Maier</p>


<h3>References</h3>

<p>Bond, T.G., and Fox Ch.M. (2007) Applying the Rasch Model. Fundamental Measurement in the Human Sciences.
2nd Edition. Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- PCM(pcmdat)
plotPImap(res, sorted=TRUE)
</code></pre>

<hr>
<h2 id='plotPWmap'>Pathway Map</h2><span id='topic+plotPWmap'></span>

<h3>Description</h3>

<p>A Bond-and-Fox Pathway Map displays the location of each item or
each person against its infit t-statistic.  Pathway maps are useful
for identifying misfitting items or misfitting persons.  Items or
people should ideally have a infit t-statistic lying between about
-2 and +2, and these values are marked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPWmap(object, pmap = FALSE, imap=TRUE,
                 item.subset = "all", person.subset = "all",
                 mainitem = "Item Map", mainperson = "Person Map",
                 mainboth="Item/Person Map",
                 latdim = "Latent Dimension",
                 tlab = "Infit t statistic",
                 pp = NULL, cex.gen = 0.6, cex.pch=1,
                 person.pch = 1, item.pch = 16,
                 personCI = NULL, itemCI = NULL, horiz=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPWmap_+3A_object">object</code></td>
<td>
<p>Object of class <code>Rm</code> or <code>dRm</code></p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_pmap">pmap</code></td>
<td>
<p>Plot a person map if <code>TRUE</code>; the default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_imap">imap</code></td>
<td>
<p>Plot an item map if <code>TRUE</code> (the default); do not plot
if <code>FALSE</code>.  At least one of <code>pmap</code> and <code>imap</code> must
be <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_item.subset">item.subset</code></td>
<td>
<p>Subset of items to be plotted for an item map.
Either a numeric vector indicating the item numbers or a character
vector indicating the item names.  If <code>"all"</code>, all items are
plotted. The number of items to be plotted must be &gt; 1.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_person.subset">person.subset</code></td>
<td>
<p>Subset of persons to be plotted for a person map.
Either a numeric vector indicating the person numbers or a character
vector indicating the person names.  If <code>"all"</code>, all persons are
plotted. The number of persons to be plotted must be &gt; 1.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_mainitem">mainitem</code></td>
<td>
<p>Main title of an item plot.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_mainperson">mainperson</code></td>
<td>
<p>Main title of a person plot.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_mainboth">mainboth</code></td>
<td>
<p>Main title of a person/item joint plot.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_latdim">latdim</code></td>
<td>
<p>Label of the y-axis, i.e., the latent dimension.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_tlab">tlab</code></td>
<td>
<p>Label of the x-axis, i.e., the t-statistic dimension.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_pp">pp</code></td>
<td>
<p>If non-<code>NULL</code>, this contains the
<code>person.parameter</code> data of the data object, avoiding the
need to recalculate it.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_cex.gen">cex.gen</code></td>
<td>
<p><code>cex</code> as a graphical parameter
specifies a numerical value giving the amount by which plotting
text and symbols should be magnified relative to the
default. Here <code>cex.gen</code> applies to all text labels. The
default is 0.6.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_cex.pch">cex.pch</code></td>
<td>
<p>applies to all plotting symbols. The
default is 1.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_person.pch">person.pch</code>, <code id="plotPWmap_+3A_item.pch">item.pch</code></td>
<td>
<p>Specifies the symbol used for plotting
person data and item data respectively; the defaults are 1 and 16
respectively.  See <code><a href="graphics.html#topic+points">points</a></code> for more information
about <code>pch</code> values.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_personci">personCI</code>, <code id="plotPWmap_+3A_itemci">itemCI</code></td>
<td>
<p>Plotting confidence intervals for the the
person abilities and item difficulties.  If <code>personCI=NULL</code>
(the default) no confidence intervals are drawn for person
abilities.  Otherwise, specifying <code>personCI</code> draws
approximate confidence intervals for each person's ability.
<code>personCI</code> must be specified as a list, and the optional
elements of this list are <code>gamma</code>, the confidence level,
<code>col</code>, colour, and <code>lty</code>, line type.  If <code>personCI</code>
is specified as an empty list, or not all of the list items are
specified, the default values
<code>personCI=list(gamma=0.95,col="orange",lty="dotted")</code> will be
used.
</p>
<p>The same goes for <code>itemCI</code>, except that the default settings
are <code>itemCI=list(gamma=0.95,col="red",lty="dotted")</code>.</p>
</td></tr>
<tr><td><code id="plotPWmap_+3A_horiz">horiz</code></td>
<td>
<p>if <code>TRUE</code>, the plot is horizontal, i.e., the latent
dimension is on the x-axis. The default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This code uses vertical(horizontal) error bars rather than circles or boxes to
indicate standard errors.  It also offers the possibility of plotting
item or person data on its own; this can considerably simplify the
reading of the plots for large datasets.
</p>


<h3>Author(s)</h3>

<p>Julian Gilbey</p>


<h3>References</h3>

<p>Bond T.G., Fox C.M. (2007) <em>Applying the Rasch Model: Fundamental Measurement in the Human Sciences</em> (2nd ed.) chapter 3, Lawrence Erlbaum Associates, Inc.
</p>
<p>Linacre J.M., Wright B.D. (1994) Dichotomous Infit and Outfit Mean-Square Fit Statistics / Chi-Square Fit Statistics. <em>Rasch Measurement Transactions</em> <b>8:2</b> p. 350, <a href="https://www.rasch.org/rmt/rmt82a.htm">https://www.rasch.org/rmt/rmt82a.htm</a>
</p>
<p>Linacre J.M. (2002) What do Infit and Outfit, Mean-square and Standardized mean? <em>Rasch Measurement Transactions</em> <b>16:2</b> p. 878, <a href="https://www.rasch.org/rmt/rmt162f.htm">https://www.rasch.org/rmt/rmt162f.htm</a>
</p>
<p>Wright B.D., Masters G.N. (1990) Computation of OUTFIT and INFIT Statistics. <em>Rasch Measurement Transactions</em> <b>3:4</b> p. 84&ndash;85, <a href="https://www.rasch.org/rmt/rmt34e.htm">https://www.rasch.org/rmt/rmt34e.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- PCM(pcmdat)
pparm &lt;- person.parameter(res)
plotPWmap(res, pp = pparm)
plotPWmap(res, pp = pparm, pmap = TRUE)
</code></pre>

<hr>
<h2 id='plotTR'>Plot Trend Effects for LLRA
</h2><span id='topic+plotTR'></span>

<h3>Description</h3>

<p>Plots trend effects over time.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTR(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTR_+3A_object">object</code></td>
<td>
<p>an object of class <code>"llra"</code>
</p>
</td></tr>
<tr><td><code id="plotTR_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to and from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is a lattice plot with one panel. The effects for each items
are plotted over the different time points.
</p>
<p>Please
note that all effects are to be interpreted relative to the baseline
(i.e. t1).
</p>
<p>Currently, this function only works for a full item x treatment x
timepoints LLRA. Collapsed effects will not be displayed properly. 
</p>


<h3>Warning:</h3>

<p>Objects of class <code>"llra"</code> that contain estimates from a collapsed
data matrix will not be displayed correctly.
</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>See Also</h3>

<p>The plot method for treatment effects <code>"plotGR"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Example 6 from Hatzinger &amp; Rusch (2009)
groups &lt;- c(rep("TG",30),rep("CG",30))
llra1 &lt;- LLRA(llradat3,mpoints=2,groups=groups)
summary(llra1)
plotTR(llra1)

## Not run:  
##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.
ex2 &lt;- LLRA(llraDat2[1:20],mpoints=4,groups=llraDat2[21])
plotTR(ex2)
## End(Not run)
</code></pre>

<hr>
<h2 id='predict.ppar'>Predict methods</h2><span id='topic+predict.ppar'></span>

<h3>Description</h3>

<p>Returns data matrix based on model probabilites. So far implemented for dichotomous models only.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ppar'
predict(object, cutpoint = "randomized", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ppar_+3A_object">object</code></td>
<td>
<p>Object of class <code>ppar</code> (from <code>person.parameter()</code>).</p>
</td></tr>
<tr><td><code id="predict.ppar_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Either single integer value between 0 and 1 or <code>"randomized"</code> for randomized 0-1 assignment (see details)</p>
</td></tr>
<tr><td><code id="predict.ppar_+3A_...">...</code></td>
<td>
<p>Additional arguments ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A randomized assignment implies that for each cell an additional random number is drawn. If the model probability is larger than this value, the person gets 1 on this particular item, if smaller, 0 is assigned. Alternatively, a numeric probability cutpoint can be assigned and the 0-1 scoring is carried out according to the same rule.
</p>


<h3>Value</h3>

<p>Returns data matrix based on model probabilities
</p>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>See Also</h3>

<p><code><a href="#topic+gofIRT.ppar">gofIRT.ppar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Model-based data matrix for RSM
res &lt;- RM(raschdat2)
pres &lt;- person.parameter(res)
predict(pres)
</code></pre>

<hr>
<h2 id='print.eRm'>Methods for extended Rasch models</h2><span id='topic+print.eRm'></span><span id='topic+summary.eRm'></span><span id='topic+vcov.eRm'></span><span id='topic+model.matrix.eRm'></span><span id='topic+coef.eRm'></span><span id='topic+logLik.eRm'></span><span id='topic+confint.eRm'></span>

<h3>Description</h3>

<p>Several methods for objects of class <code>'eRm'</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eRm'
print(x, ...)
## S3 method for class 'eRm'
summary(object, ...)
## S3 method for class 'eRm'
coef(object, parm="beta", ...)
## S3 method for class 'eRm'
model.matrix(object, ...)
## S3 method for class 'eRm'
vcov(object, ...)
## S3 method for class 'eRm'
logLik(object, ...)
## S3 method for class 'eRm'
confint(object, parm = "beta", level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.eRm_+3A_x">x</code></td>
<td>
<p>Object of class <code>eRm</code>.</p>
</td></tr>
<tr><td><code id="print.eRm_+3A_object">object</code></td>
<td>
<p>Object of class <code>eRm</code>.</p>
</td></tr>
<tr><td><code id="print.eRm_+3A_parm">parm</code></td>
<td>
<p>Either <code>"eta"</code> or <code>"beta"</code>.</p>
</td></tr>
<tr><td><code id="print.eRm_+3A_level">level</code></td>
<td>
<p>Alpha-level.</p>
</td></tr>
<tr><td><code id="print.eRm_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print</code> method displays  the value of
the log-likelihood, parameter estimates (basic parameters eta) and their standard errors.
For RM, RSM, and PCM models, the etas are difficulty parameters, for the LLTM, LRSM,
LPCM the sign of the parameters depend on the design matrix and are easiness effects by default.
The <code>summary</code> method additionally gives the full set of item parameters beta as
easiness parameters for all models.
</p>
<p>Print methods are also available for the functions <code>logLik</code> and <code>confint</code>
(see below).
</p>


<h3>Value</h3>

<p>The methods below are extractor functions and return various quantities:
<code>vcov</code> returns the variance-covariance matrix of the parameter estimates,
<code>coef</code> a vector of estimates of the eta or beta basic parameters,
<code>model.matrix</code> the design matrix,
<code>logLik</code> an object with elements <code>loglik</code> and <code>df</code> containing
the log-likelihood value and df.
<code>confint</code> a matrix of confidence interval values for eta or beta.
</p>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- RM(raschdat1)
res
summary(res)
coef(res)
vcov(res)
model.matrix(res)
logLik(res)
</code></pre>

<hr>
<h2 id='RaschSampler'>Rasch Sampler Package</h2><span id='topic+RaschSampler'></span>

<h3>Description</h3>

<p>The package implements an <abbr><span class="acronym">MCMC</span></abbr> algorithm for sampling of
binary matrices with fixed margins complying to the Rasch model.
Its stationary distribution is uniform. The algorithm also allows
for square matrices with fixed diagonal.<br />
</p>
<p>Parameter estimates in the Rasch model only depend on the marginal totals of
the data matrix that is used for the estimation. From this it follows that, if the
model is valid, all binary matrices with the same marginals as the observed one
are equally likely. For any statistic of the data matrix, one can approximate
the null distribution, i.e., the distribution if the Rasch model is valid, by taking
a random sample from the collection of equally likely data matrices and constructing
the observed distribution of the statistic.
One can then simply determine the exceedence probability of the statistic in the
observed sample, and thus construct a non-parametric test of the Rasch model.
The main purpose of this package is the implementation of a methodology to build nonparametric
tests for the Rasch model. <br />
</p>
<p>In the context of social network theories, where the structure of binary asymmetric
relations is studied, for example,
person <code class="reqn">a</code> esteems person <code class="reqn">b</code>, which correponds to a 1 in cell <code class="reqn">(a, b)</code>
of the associated adjacency matrix. If one wants to study
the distribution of a statistic defined on the adjacency matrix and conditional
on the marginal totals, one has to exclude the diagonal cells from consideration, i.e.,
by keeping the diagonal cells fixed at an arbitrary value. The <code>RaschSampler</code> package
has implemented an appropriate option, thus it can be also used for sampling random adjacency
matrices with given marginal totals.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package:</td><td style="text-align: left;"> RaschSampler</td>
</tr>
<tr>
 <td style="text-align: left;">
Type:   </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version:</td><td style="text-align: left;"> 0.8-6</td>
</tr>
<tr>
 <td style="text-align: left;">
Date:   </td><td style="text-align: left;"> 2012-07-03</td>
</tr>
<tr>
 <td style="text-align: left;">
License:</td><td style="text-align: left;"> GNU GPL 2, June 1991</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The user has to supply a binary input matrix. After defining appropriate control
parameters using <code><a href="#topic+rsctrl">rsctrl</a></code> the sampling function <code><a href="#topic+rsampler">rsampler</a></code>
may be called to obtain an object of class <code><a href="#topic+RSmpl">RSmpl</a></code> which contains the
generated random matrices in encoded form. After defining an appropriate function
to operate on a binary matrix (e.g., calculate a statistic such as <code><a href="#topic+phi.range">phi.range</a></code>)
the application of this function to the sampled matrices is performed
using <code><a href="#topic+rstats">rstats</a></code>. Prior to applying the user defined function, <code><a href="#topic+rstats">rstats</a></code>
decodes the matrices packed in the <code><a href="#topic+RSmpl">RSmpl</a></code>-object.<br />
</p>
<p>The package also defines a utility function <code><a href="#topic+rsextrobj">rsextrobj</a></code> for extracting certains parts from
the <code><a href="#topic+RSmpl">RSmpl</a></code>-object resulting in an object of class <code><a href="#topic+RSmplext">RSmplext</a></code>.
Both types of objects can be saved and reloaded for later use.<br />
</p>
<p>Summary methods are available to print information on these objects, as well as
on the control object <code><a href="#topic+RSctr">RSctr</a></code> which is obtained from using
<code><a href="#topic+rsctrl">rsctrl</a></code> containing the specification for the sampling routine.
</p>


<h3>Note</h3>

<p>The current implementation allows for data matrices up to 4096 rows and 128 columns.
This can be changed by setting <code>nmax</code> and <code>kmax</code> in <code>RaschSampler.f90</code>
to values which are a power of 2. These values should also be changed in <code>rserror.R</code>.
</p>
<p>For convenience, we reuse the Fortran code of package version 0.8-1 which cicumvents the
compiler bug in Linux distributions of GCC 4.3. The following note from package version 0.8-3
is thus obsolete:
In case of compilation errors (due to a bug in Linux distributions of GCC 4.3) please use
<code>RaschSampler.f90</code> from package version 0.8-1 and change <code>nmax</code> and <code>kmax</code>
accordingly (or use GCC 4.4).</p>


<h3>Author(s)</h3>

<p>Reinhold Hatzinger, Patrick Mair, Norman D. Verhelst</p>


<h3>References</h3>

<p>Verhelst, N. D. (2008) An Efficient <abbr><span class="acronym">MCMC</span></abbr> Algorithm to Sample Binary Matrices with Fixed Marginals. Psychometrika, Volume 73, Number 4<br />
Verhelst, N. D., Hatzinger, R., and Mair, P. (2007) The Rasch Sampler, Journal of Statistical Software, Vol. 20, Issue 4, Feb 2007
</p>

<hr>
<h2 id='RM'>Estimation of Rasch Models</h2><span id='topic+RM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a Rasch model for binary item responses by using CML estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RM(X, W, se = TRUE, sum0 = TRUE, etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RM_+3A_x">X</code></td>
<td>
<p>Input 0/1 data matrix or data frame; rows represent individuals, columns represent items. Missing values are inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="RM_+3A_w">W</code></td>
<td>
<p>Design matrix for the Rasch model. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="RM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="RM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normed to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="RM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For estimating the item parameters the CML method is used.
Available methods for RM-objects are:<br />
<code>print</code>, <code>coef</code>, <code>model.matrix</code>,
<code>vcov</code>, <code>summary</code>, <code>logLik</code>, <code>person.parameter</code>, <code>LRtest</code>,
<code>Waldtest</code>, <code>plotICC</code>, <code>plotjointICC</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>dRm, Rm, eRm</code> and contains the log-likelihood value, the parameter estimates and their standard errors.
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item difficulty parameters.</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RSM">RSM</a></code>,<code><a href="#topic+PCM">PCM</a></code>, <code><a href="#topic+LRtest">LRtest</a></code>, <code><a href="#topic+Waldtest">Waldtest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Rasch model with beta.1 restricted to 0
res &lt;- RM(raschdat1, sum0 = FALSE)
res
summary(res)
res$W                                       #generated design matrix

# Rasch model with sum-0 beta restriction; no standard errors computed
res &lt;- RM(raschdat1, se = FALSE, sum0 = TRUE)
res
summary(res)
res$W                                       #generated design matrix

#Rasch model with missing values
res &lt;- RM(raschdat2)
res
summary(res)
</code></pre>

<hr>
<h2 id='rsampler'>Sampling Binary Matrices</h2><span id='topic+rsampler'></span>

<h3>Description</h3>


<p>The function implements an <abbr><span class="acronym">MCMC</span></abbr> algorithm for sampling of binary matrices with fixed margins complying to the Rasch model.
Its stationary distribution is uniform.
The algorithm also allows for square matrices with fixed diagonal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsampler(inpmat, controls = rsctrl())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsampler_+3A_inpmat">inpmat</code></td>
<td>
<p>A binary (data) matrix with <code class="reqn">n</code> rows and <code class="reqn">k</code> columns.</p>
</td></tr>
<tr><td><code id="rsampler_+3A_controls">controls</code></td>
<td>
<p>An object of class <code><a href="#topic+RSctr">RSctr</a></code>. If not specified, the default parameters as returned by function <code><a href="#topic+rsctrl">rsctrl</a></code> are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rsampler</code> is a wrapper function for a Fortran routine to generate binary random matrices based
on an input matrix.
On output the generated binary matrices are integer encoded. For further
processing of the generated matrices use the function <code><a href="#topic+rstats">rstats</a></code>.
</p>


<h3>Value</h3>

<p>A list of class <code><a href="#topic+RSmpl">RSmpl</a></code> with components
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>number of rows of the input matrix</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of columns of the input matrix</p>
</td></tr>
<tr><td><code>inpmat</code></td>
<td>
<p>the input matrix</p>
</td></tr>
<tr><td><code>tfixed</code></td>
<td>
<p><code>TRUE</code>, if diagonals of <code>inpmat</code> are fixed</p>
</td></tr>
<tr><td><code>burn_in</code></td>
<td>
<p>length of the burn in process</p>
</td></tr>
<tr><td><code>n_eff</code></td>
<td>
<p>number of generated matrices (effective matrices)</p>
</td></tr>
<tr><td><code>step</code></td>
<td>
<p>controls the number number of void matrices generated in the the burn in
process and when effective matrices are generated (see note
in <code><a href="#topic+rsctrl">rsctrl</a></code>). </p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>starting value for the random number generator</p>
</td></tr>
<tr><td><code>n_tot</code></td>
<td>
<p>number of matrices in <code>outvec</code>, <code>n_tot = n_eff + 1</code></p>
</td></tr>
<tr><td><code>outvec</code></td>
<td>
<p>vector of encoded random matrices</p>
</td></tr>
<tr><td><code>ier</code></td>
<td>
<p>error code</p>
</td></tr>
</table>


<h3>Note</h3>


<p>An element of <code>outvec</code> is a four byte (or 32 bits) integer.
The matrices to be output are stored bitwise (some bits are unused, since a integer is used for every row of a matrix).
So the number of integers per row needed equals <code class="reqn">(k+31)/32</code> (integer division), which is one to four in the present implementation since the number of columns and rows must not exceed 128 and 4096, respectively.
</p>
<p>The summary method (<code><a href="#topic+summary.RSmpl">summary.RSmpl</a></code>) prints information on the content of the output object.
</p>


<h3>Author(s)</h3>

<p>Reinhold Hatzinger, Norman Verhelst</p>


<h3>References</h3>


<p>Verhelst, N. D. (2008). An Efficient <abbr><span class="acronym">MCMC</span></abbr> Algorithm to Sample Binary Matrices with Fixed Marginals. <em>Psychometrika, 73</em> (4)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsctrl">rsctrl</a></code>, <code><a href="#topic+rstats">rstats</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(xmpl)
ctr&lt;-rsctrl(burn_in=10, n_eff=5, step=10, seed=0, tfixed=FALSE)
res&lt;-rsampler(xmpl,ctr)
summary(res)
</code></pre>

<hr>
<h2 id='RSctr'>Control Object</h2><span id='topic+RSctr'></span>

<h3>Description</h3>

<p>The object of class <code>RSctr</code> represents the control parameter
specification for the sampling function <code><a href="#topic+rsampler">rsampler</a></code>.
</p>


<h3>Value</h3>

<p>A legitimate <code><a href="#topic+RSctr">RSctr</a></code> object is a list with components
</p>
<table>
<tr><td><code>burn_in</code></td>
<td>

<p>the number of matrices to be sampled to
come close to a stationary distribution.
</p>
</td></tr>
<tr><td><code>n_eff</code></td>
<td>

<p>the number of effective matrices, i.e.,
the number of matrices
to be generated by the sampling function <code><a href="#topic+rsampler">rsampler</a></code>.
</p>
</td></tr>
<tr><td><code>step</code></td>
<td>

<p>controls the number number of void matrices generated in the the burn in
process and when effective matrices are generated (see note 
in <code><a href="#topic+rsctrl">rsctrl</a></code>). </p>
</td></tr>
<tr><td><code>seed</code></td>
<td>

<p>is the indicator for the seed of the random number generator.
If the value of seed at equals zero, a seed is generated
by the sampling function <code><a href="#topic+rsampler">rsampler</a></code>
</p>
</td></tr>
<tr><td><code>tfixed</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>. <code>tfixed = TRUE</code> has no effect
if the input matrix is not quadratic,
i.e., all matrix elements are considered free (unrestricted).
If the input matrix is quadratic, and <code>tfixed = TRUE</code>,
the main diagonal of the matrix is considered as fixed.
</p>
</td></tr>
</table>


<h3>Generation</h3>

<p>This object is returned from function
<code>rsctrl</code>.
</p>


<h3>Methods</h3>

<p>This class has a method for the generic <code>summary</code>
function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsctrl">rsctrl</a></code> </p>

<hr>
<h2 id='rsctrl'>Controls for the Sampling Function</h2><span id='topic+rsctrl'></span>

<h3>Description</h3>

<p>Various parameters that control aspects of
the random generation of binary matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsctrl(burn_in = 100, n_eff = 100, step = 16, seed = 0, tfixed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsctrl_+3A_burn_in">burn_in</code></td>
<td>

<p>the number of sampled matrices to
come close to a stationary distribution.
The default is <code>burn_in = 100</code>.
(The actual number is <code>2 * burn_in * step</code>.)
</p>
</td></tr>
<tr><td><code id="rsctrl_+3A_n_eff">n_eff</code></td>
<td>

<p>the number of effective matrices, i.e., the number of matrices to be generated by the sampling function <code><a href="#topic+rsampler">rsampler</a></code>.
<code>n_eff</code> must be positive and not larger than 8191 (<code class="reqn">2^{13}-1</code>).
The default is <code>n_eff = 100</code>.
</p>
</td></tr>
<tr><td><code id="rsctrl_+3A_step">step</code></td>
<td>
<p>controls the number number of void matrices generated in the the burn in
process and when effective matrices are generated (see note
below). The default is <code>step = 16</code>. </p>
</td></tr>
<tr><td><code id="rsctrl_+3A_seed">seed</code></td>
<td>

<p>is the indicator for the seed of the random number generator. 
Its value must be in the range 0 and 2147483646 (2**31-2).
If the value of seed equals zero, a seed is generated
by the sampling function <code><a href="#topic+rsampler">rsampler</a></code>
(dependent on the system's clock) and its value is returned
in the output. If seed is not equal to zero, its 
value is used as the seed of the random number generator.
In that case its value is unaltered at output.
The default is <code>seed = 0</code>.
</p>
</td></tr>
<tr><td><code id="rsctrl_+3A_tfixed">tfixed</code></td>
<td>
<p>logical, &ndash; specifies if in case of a quadratic input
matrix the diagonal is considered fixed (see note below).
The default is <code>tfixed = FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>RSctr</code> with components
<code>burn_in</code>, <code>n_eff</code>, <code>step</code>,
<code>seed</code>, <code>tfixed</code>.,
</p>


<h3>Note</h3>

<p>If one of the components is incorrectly specified
the error function <code>rserror</code>
is called and some informations are printed. The ouput object
will not be defined.<br /><br />
The specification of <code>step</code> controls the sampling algorithm as follows:
If , e.g., <code>burn_in = 10</code>, <code>n_eff = 5</code>, and <code>step = 2</code>,
then during the burn in period <code>step * burn_in = 2 * 10</code>
matrices are generated. After that, <code>n_eff * step = 5 * 2</code> matrices
are generated and every second matrix of these last ten is returned from
<code>link{rsampler}</code>.<br /><br />
<code>tfixed</code> has no effect if the input matrix is not quadratic,
i.e., all matrix elements are considered free (unrestricted).
If the input matrix is quadratic, and <code>tfixed = TRUE</code>,
the main diagonal of the matrix is considered as fixed.
On return from <code>link{rsampler}</code> all diagonal elements
of the generated matrices are set to zero.
This specification applies, e.g.,
to analyzing square incidence matrices
representing binary asymmetric relation
in social network theory.<br /><br />
The summary method (<code><a href="#topic+summary.RSctr">summary.RSctr</a></code>) prints
the current definitions. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(n_eff = 1, seed = 987654321)  # specify new controls
summary(ctr)

## Not run: 
# incorrect specifications will lead to an error
ctr2 &lt;- rsctrl(step = -3, n_eff = 10000)
## End(Not run)
</code></pre>

<hr>
<h2 id='rsextrmat'>Extracting a Matrix</h2><span id='topic+rsextrmat'></span>

<h3>Description</h3>

<p>Convenience function to extract a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsextrmat(RSobj, mat.no = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsextrmat_+3A_rsobj">RSobj</code></td>
<td>
<p>object as obtained from using <code>rsampler</code> or <code>rsextrobj</code></p>
</td></tr>
<tr><td><code id="rsextrmat_+3A_mat.no">mat.no</code></td>
<td>
<p>number of the matrix to extract from the sample object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One of the matrices (either the original or a sampled matrix)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code>, <code><a href="#topic+rsextrobj">rsextrobj</a></code>,<code><a href="#topic+rstats">rstats</a></code>,</p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(burn_in = 10, n_eff = 3, step=10, seed = 0, tfixed = FALSE)
mat &lt;- matrix(sample(c(0,1), 50, replace = TRUE), nr = 10)
all_m &lt;- rsampler(mat, ctr)
summary(all_m)

# extract the third sampled matrix (here the fourth)
third_m &lt;- rsextrmat(all_m, 4)
head(third_m)
</code></pre>

<hr>
<h2 id='rsextrobj'>Extracting Encoded Sample Matrices</h2><span id='topic+rsextrobj'></span>

<h3>Description</h3>

<p>Utility function to extract some of the generated matrices, still in encoded form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsextrobj(RSobj, start = 1, end = 8192)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsextrobj_+3A_rsobj">RSobj</code></td>
<td>
<p>object as obtained from using <code>rsampler</code></p>
</td></tr>
<tr><td><code id="rsextrobj_+3A_start">start</code></td>
<td>
<p>number of the matrix to start with. When specifying 1
(the default value) the original input matrix is
included in the output object.
</p>
</td></tr>
<tr><td><code id="rsextrobj_+3A_end">end</code></td>
<td>
<p>last matrix to be extracted. If <code>end</code>
is not specified, all matrices from <code>RSobj</code>
are extracted (the maximal value is 8192, see
<code>rsctrl</code>). If <code>end</code> is larger than
the number of matrices stored in <code>RSobj</code>,
<code>end</code> is set to the highest possible value
(i.e., <code>n_tot</code>).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code><a href="#topic+RSmpl">RSmpl</a></code> with components
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>number of rows of the input matrix</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of columns of the input matrix</p>
</td></tr>
<tr><td><code>inpmat</code></td>
<td>
<p>the input matrix</p>
</td></tr>
<tr><td><code>tfixed</code></td>
<td>
<p><code>TRUE</code>, if diagonals of <code>inpmat</code> are fixed</p>
</td></tr>
<tr><td><code>burn_in</code></td>
<td>
<p>length of the burn in process</p>
</td></tr>
<tr><td><code>n_eff</code></td>
<td>
<p>number of generated matrices (effective matrices)</p>
</td></tr>
<tr><td><code>step</code></td>
<td>
<p>controls the number number of void matrices generated in the burn in
process and when effective matrices are generated (see note
in <code><a href="#topic+rsctrl">rsctrl</a></code>). </p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>starting value for the random number generator</p>
</td></tr>
<tr><td><code>n_tot</code></td>
<td>
<p>number of matrices in <code>outvec</code>.</p>
</td></tr>
<tr><td><code>outvec</code></td>
<td>
<p>vector of encoded random matrices</p>
</td></tr>
<tr><td><code>ier</code></td>
<td>
<p>error code</p>
</td></tr>
</table>


<h3>Note</h3>

<p>By default, all generated matrices plus
the original matrix (in position 1) are contained in
<code>outvec</code>, thus <code>n_tot = n_eff + 1</code>. If
the original matrix is not in <code>outvec</code> then
<code>n_tot = n_eff</code>.<br />
For saving and loading objects
of class <code>RSobj</code> see the example below.
</p>
<p>For extracting a decoded (directly usable) matrix use <code><a href="#topic+rsextrmat">rsextrmat</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code>, <code><a href="#topic+rsextrmat">rsextrmat</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(burn_in = 10, n_eff = 3, step=10, seed = 0, tfixed = FALSE)
mat &lt;- matrix(sample(c(0,1), 50, replace = TRUE), nr = 10)
all_m &lt;- rsampler(mat, ctr)
summary(all_m)

some_m &lt;- rsextrobj(all_m, 1, 2)
summary(some_m)

## Not run: 
save(some_m, file = "some.RSobj.RData")
rm(some_m)
ls()

load("some.RSobj.RData")
summary(some_m)
## End(Not run)
</code></pre>

<hr>
<h2 id='RSM'>Estimation of rating scale models</h2><span id='topic+RSM'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a rating scale model for polytomous
item responses by using CML estimation. </p>


<h3>Usage</h3>

<pre><code class='language-R'>RSM(X, W, se = TRUE, sum0 = TRUE, etaStart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSM_+3A_x">X</code></td>
<td>
<p>Input data matrix or data frame with item responses (starting from 0); rows represent individuals, columns represent items. Missing values are inserted as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="RSM_+3A_w">W</code></td>
<td>
<p>Design matrix for the RSM. If omitted, the function will compute W automatically.</p>
</td></tr>
<tr><td><code id="RSM_+3A_se">se</code></td>
<td>
<p>If <code>TRUE</code>, the standard errors are computed.</p>
</td></tr>
<tr><td><code id="RSM_+3A_sum0">sum0</code></td>
<td>
<p>If <code>TRUE</code>, the parameters are normed to sum-0 by specifying
an appropriate <code>W</code>. If <code>FALSE</code>, the first parameter is restricted to 0.</p>
</td></tr>
<tr><td><code id="RSM_+3A_etastart">etaStart</code></td>
<td>
<p>A vector of starting values for the eta parameters can be specified. If missing, the 0-vector is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The design matrix approach transforms the RSM into a partial credit model
and estimates the corresponding basic parameters by using CML.
Available methods for RSM-objects are <code>print</code>, <code>coef</code>, <code>model.matrix</code>,
<code>vcov</code>, <code>summary</code>, <code>logLik</code>, <code>person.parameters</code>, <code>plotICC</code>, <code>LRtest</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>'Rm'</code>, <code>'eRm'</code> and contains the log-likelihood value,
the parameter estimates and their standard errors.
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>Conditional log-likelihood.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Number of iterations.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>Number of parameters.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>See <code>code</code> output in <code><a href="stats.html#topic+nlm">nlm</a></code>.</p>
</td></tr>
<tr><td><code>etapar</code></td>
<td>
<p>Estimated basic item difficulty parameters (item and category parameters).</p>
</td></tr>
<tr><td><code>se.eta</code></td>
<td>
<p>Standard errors of the estimated basic item parameters.</p>
</td></tr>
<tr><td><code>betapar</code></td>
<td>
<p>Estimated item-category (easiness) parameters.</p>
</td></tr>
<tr><td><code>se.beta</code></td>
<td>
<p>Standard errors of item parameters.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>Hessian matrix if <code>se = TRUE</code>.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Data matrix.</p>
</td></tr>
<tr><td><code>X01</code></td>
<td>
<p>Dichotomized data matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Mair, P., and Hatzinger, R. (2007). Extended Rasch modeling: The <span class="pkg">eRm</span> package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1-20.
</p>
<p>Mair, P., and Hatzinger, R. (2007). CML based estimation of extended Rasch models with the <span class="pkg">eRm</span> package in R. Psychology Science, 49, 26-43.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RM">RM</a></code>,<code><a href="#topic+PCM">PCM</a></code>,<code><a href="#topic+LRtest">LRtest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##RSM with 10 subjects, 3 items
res &lt;- RSM(rsmdat)
res
summary(res)                            #eta and beta parameters with CI
thresholds(res)                         #threshold parameters
</code></pre>

<hr>
<h2 id='RSmpl'>Sample Objects</h2><span id='topic+RSmpl'></span><span id='topic+RSmplext'></span>

<h3>Description</h3>

<p>The objects of class <code>RSmpl</code> and <code>RSmplext</code> contain
the original input matrix, the generated (encoded) random matrices, and
some information about the sampling process.
</p>


<h3>Value</h3>

<p>A list of class <code>RSmpl</code> or <code>RSmplext</code> with components
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>number of rows of the input matrix</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of columns of the input matrix</p>
</td></tr>
<tr><td><code>inpmat</code></td>
<td>
<p>the input matrix</p>
</td></tr>
<tr><td><code>tfixed</code></td>
<td>
<p><code>TRUE</code>, if diagonals of <code>inpmat</code> are fixed</p>
</td></tr>
<tr><td><code>burn_in</code></td>
<td>
<p>length of the burn in process</p>
</td></tr>
<tr><td><code>n_eff</code></td>
<td>
<p>number of generated matrices (effective matrices)</p>
</td></tr>
<tr><td><code>step</code></td>
<td>
<p>controls the number number of void matrices generated in the the burn in
process and when effective matrices are generated (see note 
in <code><a href="#topic+rsctrl">rsctrl</a></code>). </p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>starting value for the random number generator</p>
</td></tr>
<tr><td><code>n_tot</code></td>
<td>
<p>number of matrices in <code>outvec</code>.</p>
</td></tr>
<tr><td><code>outvec</code></td>
<td>
<p>vector of encoded random matrices</p>
</td></tr>
<tr><td><code>ier</code></td>
<td>
<p>error code (see below)</p>
</td></tr>
</table>


<h3>Generation</h3>

<p>These classes of objects are returned from
<code>rsampler</code> and <code>rsextrobj</code>.
</p>


<h3>Methods</h3>

<p>Both classes have methods for the generic <code>summary</code>
function.
</p>


<h3>Note</h3>

<p>By default, all generated matrices plus
the original matrix (in position 1) are contained in
<code>outvec</code>, thus <code>n_tot = n_eff + 1</code>. If
the original matrix is not in <code>outvec</code> then
<code>n_tot = n_eff</code>.<br /><br />
If <code>ier</code> is 0, no error was detected. Otherwise use
the error function <code>rserror(ier)</code> to obtain some informations.<br /><br />
For saving and loading objects
of class <code>RSmpl</code> or <code>RSmplext</code>
see the example in <code><a href="#topic+rsextrobj">rsextrobj</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code>, <code><a href="#topic+rsextrobj">rsextrobj</a></code> </p>

<hr>
<h2 id='rstats'>Calculating Statistics for the Sampled Matrices</h2><span id='topic+rstats'></span>

<h3>Description</h3>

<p>This function is used to calculate user defined statistics for the
(original and) sampled matrices. A user defined function has to
be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rstats(RSobj, userfunc, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rstats_+3A_rsobj">RSobj</code></td>
<td>
<p>object as obtained from using <code><a href="#topic+rsampler">rsampler</a></code>
or <code><a href="#topic+rsextrobj">rsextrobj</a></code> </p>
</td></tr>
<tr><td><code id="rstats_+3A_userfunc">userfunc</code></td>
<td>
<p>a user defined function which performs operations
on the (original and) sampled matrices. The first argument in the definition
of the user function must be an object of type matrix.</p>
</td></tr>
<tr><td><code id="rstats_+3A_...">...</code></td>
<td>
<p>further arguments, that are passed to the user function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of objects as specified in the user supplied function
</p>


<h3>Note</h3>

<p>The encoded matrices that are contained in the
input object <code>RSobj</code> are decoded and passed to the user function in turn.
If <code>RSobj</code> is not an object obtained from either <code><a href="#topic+rsampler">rsampler</a></code>
or <code><a href="#topic+rsextrobj">rsextrobj</a></code> or
no user function is specified an error message is printed.
A simple user function, <code><a href="#topic+phi.range">phi.range</a></code>, is included in
the RaschSampler package for demonstration purposes.<br />
</p>
<p><code>rstats</code> can be used to obtain the 0/1 values for any
of the sampled matrices (see second example below). Please note,
that the output from the user function is stored in a list where
the number of components corresponds to the number of matrices passed
to the user function (see third example).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code>, <code><a href="#topic+rsextrobj">rsextrobj</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(burn_in = 10, n_eff = 5, step=10, seed = 12345678, tfixed = FALSE)
mat &lt;- matrix(sample(c(0,1), 50, replace = TRUE), nr = 10)
rso &lt;- rsampler(mat, ctr)
rso_st &lt;- rstats(rso,phi.range)
unlist(rso_st)

# extract the third generated matrix
# (here, the first is the input matrix)
# and decode it into rsmat

rso2 &lt;- rsextrobj(rso,4,4)
summary(rso2)
rsmat &lt;- rstats(rso2, function(x) matrix(x, nr = rso2$n))
print(rsmat[[1]])

# extract only the first r rows of the third generated matrix

mat&lt;-function(x, nr = nr, r = 3){
  m &lt;- matrix(x, nr = nr)
  m[1:r,]
}
rsmat2 &lt;- rstats(rso2, mat, nr=rso$n, r = 3)
print(rsmat2[[1]])

# apply a user function to the decoded object
print(phi.range(rsmat[[1]]))
</code></pre>

<hr>
<h2 id='Separation+20Reliability'>Person Separation Reliability</h2><span id='topic+SepRel'></span><span id='topic+print.eRm_SepRel'></span><span id='topic+summary.eRm_SepRel'></span>

<h3>Description</h3>


<p>This function calculates the proportion of person variance that is not due to error.
The concept of person separation reliability is very similar to reliability indices such as Cronbach's <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SepRel(pobject)

## S3 method for class 'eRm_SepRel'
print(x, ...)

## S3 method for class 'eRm_SepRel'
summary(object, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Separation+2B20Reliability_+3A_pobject">pobject</code></td>
<td>
<p>Object of class <code>ppar</code> (see <code><a href="#topic+person.parameter">person.parameter</a></code>).</p>
</td></tr>
<tr><td><code id="Separation+2B20Reliability_+3A_x">x</code></td>
<td>
<p>Object of class <code>eRm_SepRel</code>.</p>
</td></tr>
<tr><td><code id="Separation+2B20Reliability_+3A_object">object</code></td>
<td>
<p>Object of class <code>eRm_SepRel</code>.</p>
</td></tr>
<tr><td><code id="Separation+2B20Reliability_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the person separation reliability <code class="reqn">\frac{\mathrm{SSD}-\mathrm{MSE}}{\mathrm{SSD}}</code> where SSD is the squared standard deviation and MSE the mean squared error. Note that persons with raw scores of 0 or k are ignored in the computation. 
</p>


<h4>Caveats</h4>


<p>Please note that the concept of <em>reliability</em> and associated problems are fundamentally different between <abbr><span class="acronym">IRT</span></abbr> and <abbr><span class="acronym">CTT</span></abbr> (Classical Test Theory).
Separation reliability is more like a workaround to make the &ldquo;change&rdquo; from <abbr><span class="acronym">CTT</span></abbr> to <abbr><span class="acronym">IRT</span></abbr> easier for users by providing something &ldquo;familiar.&rdquo;
Hence, we recommend not to put too much emphasis on this particular measure and use it with caution.
</p>



<h4>Varying results in different programs</h4>


<p>If you compare the separation reliability obtained using <span class="pkg">eRm</span> with values by other software, you will find that they are most likely not equal.
This has a couple of reasons, one of the most important is the employed estimation method.
</p>
<p><span class="pkg">eRm</span> uses a conditional maximum likelihood (<abbr><span class="acronym">CML</span></abbr>) framework and handles missing values as separate groups during the estimation of item parameters.
Person parameters are computed in a second step using unconditional or joint maximum likelihood (<abbr><span class="acronym">UML</span></abbr> or <abbr><span class="acronym">JML</span></abbr>) estimation with item parameters assumed to be known from the first step.
Other programs might do <abbr><span class="acronym">JML</span></abbr> to estimate item and person parameters at the same time, or employ marginal maximum likelihood <abbr><span class="acronym">MML</span></abbr> to estimate item parameters, assuming a certain distribution for person parameters.
In the latter case person parameters might be obtained by various methods like <abbr><span class="acronym">EAP</span></abbr>, <abbr><span class="acronym">MAP</span></abbr>, ....
Even <abbr><span class="acronym">CML</span></abbr>-based programs yield different values, for example, if they use Warm's weighted maximum likelihood estimation <abbr><span class="acronym">WLE</span></abbr> to compute person parameters in the second step.
</p>
<p>The bottom line is that, since there is not &ldquo;definite&rdquo; solution for this problem, you will end up with different values under different circumstances.
This is another reason to take results and implications with a grain of salt.
</p>



<h3>Value</h3>

<p><code>SepRel</code> returns a list object of class <code>eRm_SepRel</code> containing:
</p>
<table>
<tr><td><code>sep.rel</code></td>
<td>
<p>the person separation reliability,</p>
</td></tr>
<tr><td><code>SSD.PS</code></td>
<td>
<p>the squared standard deviation (i.e., total person variability),</p>
</td></tr>
<tr><td><code>MSE</code></td>
<td>
<p>the mean square measurement error (i.e., model error variance).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Original code by Adrian BrÃ¼gger (<a href="mailto:Adrian.Bruegger@imu.unibe.ch">Adrian.Bruegger@imu.unibe.ch</a>), adapted by Marco J. Maier</p>


<h3>References</h3>


<p>Wright, B.D., and Stone, M.H. (1999). <em>Measurement essentials.</em> Wide Range Inc., Wilmington. (<a href="https://www.rasch.org/measess/me-all.pdf">https://www.rasch.org/measess/me-all.pdf</a> 28Mb).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute Separation Reliability for a Rasch Model:
pers &lt;- person.parameter(RM(raschdat1))
res &lt;- SepRel(pers)
res
summary(res)
</code></pre>

<hr>
<h2 id='sim.2pl'>Simulation of 2-PL Data</h2><span id='topic+sim.2pl'></span>

<h3>Description</h3>

<p>This utility function returns a 0-1 matrix violating the parallel ICC assumption in the Rasch model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.2pl(persons, items, discrim = 0.25, seed = NULL, cutpoint = "randomized")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.2pl_+3A_persons">persons</code></td>
<td>
<p>Either a vector of person parameters or an integer indicating the number of persons (see details).</p>
</td></tr>
<tr><td><code id="sim.2pl_+3A_items">items</code></td>
<td>
<p>Either a vector of item parameters or an integer indicating the number of items (see details).</p>
</td></tr>
<tr><td><code id="sim.2pl_+3A_discrim">discrim</code></td>
<td>
<p>Standard deviation on the log scale.</p>
</td></tr>
<tr><td><code id="sim.2pl_+3A_seed">seed</code></td>
<td>
<p>A seed for the random number generated can be set.</p>
</td></tr>
<tr><td><code id="sim.2pl_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Either <code>"randomized"</code> for a randomized transformation of the model probability matrix into the model 0-1 matrix or an integer value between 0 and 1 (see details).</p>
</td></tr>
</table>


<h3>Details</h3>


<p>If <code>persons</code> and/or <code>items</code> (using single integers) are specified to determine the number of subjects or items, the corresponding parameter vector is drawn from N(0,1).
The <code>cutpoint</code> argument refers to the transformation of the theoretical probabilities into a 0-1 data matrix.
A randomized assingment implies that for each cell an additional random number is drawn.
If the model probability is larger than this value, the person gets 1 on this particular item, if smaller, 0 is assigned.
Alternatively, a numeric probability cutpoint can be assigned and the 0-1 scoring is carried out according to the same rule.
</p>
<p>The <code>discrim</code> argument can be specified either as a vector of length <code>items</code> defining the item discrimination parameters in the 2-PL (e.g., <code>c(1,1,0.5,1,1.5)</code>), or as a single value.
In that case, the discrimination parameters are drawn from a lognormal distribution with <code>meanlog = 0</code>, where the specified value in <code>discrim</code> refers to the standard deviation on the log-scale.
The larger the values, the stronger the degree of Rasch violation.
Reasonable values are up to 0.5.
If 0, the data are Rasch homogeneous.
</p>


<h3>References</h3>

<p>Su\'arez-Falc\'on, J. C., &amp; Glas, C. A. W. (2003). Evaluation of global testing procedures for
item fit to the Rasch model. British Journal of Mathematical and Statistical Society,
56, 127-143.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.rasch">sim.rasch</a></code>, <code><a href="#topic+sim.locdep">sim.locdep</a></code>, <code><a href="#topic+sim.xdim">sim.xdim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#simulating 2-PL data
#500 persons, 10 items, sdlog = 0.30, randomized cutpoint
X &lt;- sim.2pl(500, 10, discrim = 0.30)

#item and discrimination parameters from uniform distribution,
#cutpoint fixed
dpar &lt;- runif(50, 0, 2)
ipar &lt;- runif(50, -1.5, 1.5)
X &lt;- sim.2pl(500, ipar, dpar, cutpoint = 0.5)
</code></pre>

<hr>
<h2 id='sim.locdep'>Simulation locally dependent items</h2><span id='topic+sim.locdep'></span>

<h3>Description</h3>

<p>This utility function returns a 0-1 matrix violating the
local independence assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.locdep(persons, items, it.cor = 0.25, seed = NULL,
   cutpoint = "randomized")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.locdep_+3A_persons">persons</code></td>
<td>
<p>Either a vector of person parameters or an integer indicating the number of persons (see details).</p>
</td></tr>
<tr><td><code id="sim.locdep_+3A_items">items</code></td>
<td>
<p>Either a vector of item parameters or an integer indicating the number of items (see details).</p>
</td></tr>
<tr><td><code id="sim.locdep_+3A_it.cor">it.cor</code></td>
<td>
<p>Either a single correlation value between 0 and 1 or a positive semi-definite VC matrix.</p>
</td></tr>
<tr><td><code id="sim.locdep_+3A_seed">seed</code></td>
<td>
<p>A seed for the random number generated can be set.</p>
</td></tr>
<tr><td><code id="sim.locdep_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Either <code>"randomized"</code> for a randomized tranformation of the model probability matrix into the model 0-1 matrix or an integer value between 0 and 1 (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>persons</code> or <code>items</code> is an integer value, the corresponding parameter vector
is drawn from N(0,1). The <code>cutpoint</code> argument refers to the transformation of the theoretical
probabilities into a 0-1 data matrix. A randomized assingment implies that for each cell an
additional random number is drawn. If the model probability is larger than this value,
the person gets 1 on this particular item, if smaller, 0 is assigned. Alternatively, a numeric probability cutpoint can be assigned and the 0-1 scoring is carried out according to the same rule.
</p>
<p>The argument <code>it.cor</code> reflects the pair-wise inter-item correlation. If this should be constant
across the items, a single value between 0 (i.e. Rasch model) and 1 (strong violation) can be specified.
Alternatively, a symmetric VC-matrix of dimension number of items can be defined.
</p>


<h3>References</h3>

<p>Jannarone, R. J. (1986). Conjunctive item response theory kernels. Psychometrika, 51,
357-373.
</p>
<p>Su\'arez-Falc\'on, J. C., &amp; Glas, C. A. W. (2003). Evaluation of global testing procedures for
item fit to the Rasch model. British Journal of Mathematical and Statistical Society,
56, 127-143.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.rasch">sim.rasch</a></code>, <code><a href="#topic+sim.2pl">sim.2pl</a></code>, <code><a href="#topic+sim.xdim">sim.xdim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#simulating locally-dependent data
#500 persons, 10 items, inter-item correlation of 0.5
X &lt;- sim.locdep(500, 10, it.cor = 0.5)

#500 persons, 4 items, correlation matrix specified
sigma &lt;- matrix(c(1,0.2,0.2,0.3,0.2,1,0.4,0.1,0.2,0.4,1,0.8,0.3,0.1,0.8,1),
   ncol = 4)
X &lt;- sim.locdep(500, 4, it.cor = sigma)
</code></pre>

<hr>
<h2 id='sim.rasch'>Simulation of Rasch homogeneous data</h2><span id='topic+sim.rasch'></span>

<h3>Description</h3>

<p>This utility function returns a 0-1 matrix which fits the Rasch model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.rasch(persons, items, seed = NULL, cutpoint = "randomized")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.rasch_+3A_persons">persons</code></td>
<td>
<p>Either a vector of person parameters or an integer indicating the number of persons (see details)</p>
</td></tr>
<tr><td><code id="sim.rasch_+3A_items">items</code></td>
<td>
<p>Either a vector of item parameters or an integer indicating the number of items (see details)</p>
</td></tr>
<tr><td><code id="sim.rasch_+3A_seed">seed</code></td>
<td>
<p>A seed for the random number generated can be set.</p>
</td></tr>
<tr><td><code id="sim.rasch_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Either <code>"randomized"</code> for a randomized tranformation of the model probability matrix into the model 0-1 matrix or an integer value between 0 and 1 (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>persons</code> or <code>items</code> is an integer value, the corresponding parameter vector is drawn from N(0,1). The <code>cutpoint</code> argument refers to the transformation of the theoretical probabilities into a 0-1 data matrix. A randomized assingment implies that for each cell an additional random number is drawn. If the model probability is larger than this value, the person gets 1 on this particular item, if smaller, 0 is assigned. Alternatively, a numeric probability cutpoint can be assigned and the 0-1 scoring is carried out according to the same rule.
</p>


<h3>References</h3>

<p>Su\'arez-Falc\'on, J. C., &amp; Glas, C. A. W. (2003). Evaluation of global testing procedures for
item fit to the Rasch model. British Journal of Mathematical and Statistical Society,
56, 127-143.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.xdim">sim.xdim</a></code>, <code><a href="#topic+sim.locdep">sim.locdep</a></code>, <code><a href="#topic+sim.2pl">sim.2pl</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
#simulating Rasch homogenous data
#100 persons, 10 items, parameter drawn from N(0,1)
X &lt;- sim.rasch(100, 10)

#person parameters drawn from uniform distribution, fixed cutpoint
ppar &lt;- runif(100,-2,2)
X &lt;- sim.rasch(ppar, 10, cutpoint = 0.5)
</code></pre>

<hr>
<h2 id='sim.xdim'>Simulation of multidimensional binary data</h2><span id='topic+sim.xdim'></span>

<h3>Description</h3>

<p>This utility function simulates a 0-1 matrix violating the
unidimensionality assumption in the Rasch model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.xdim(persons, items, Sigma, weightmat, seed = NULL,
   cutpoint = "randomized")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.xdim_+3A_persons">persons</code></td>
<td>
<p>Either a matrix (each column corresponds to a dimension) of person parameters or an integer indicating the number of persons (see details).</p>
</td></tr>
<tr><td><code id="sim.xdim_+3A_items">items</code></td>
<td>
<p>Either a vector of item parameters or an integer indicating the number of items (see details).</p>
</td></tr>
<tr><td><code id="sim.xdim_+3A_sigma">Sigma</code></td>
<td>
<p>A positive-definite symmetric matrix specifying the covariance matrix of the variables.</p>
</td></tr>
<tr><td><code id="sim.xdim_+3A_weightmat">weightmat</code></td>
<td>
<p>Matrix for item-weights for each dimension (columns).</p>
</td></tr>
<tr><td><code id="sim.xdim_+3A_seed">seed</code></td>
<td>
<p>A seed for the random number generated can be set.</p>
</td></tr>
<tr><td><code id="sim.xdim_+3A_cutpoint">cutpoint</code></td>
<td>
<p>Either <code>"randomized"</code> for a randomized tranformation of the model probability matrix into the model 0-1 matrix or an integer value between 0 and 1 (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>persons</code> is specified as matrix, <code>Sigma</code> is ignored. If <code>items</code> is
an integer value, the corresponding parameter vector is drawn from N(0,1).
The <code>cutpoint</code> argument refers to the transformation of the theoretical probabilities
into a 0-1 data matrix. A randomized assingment implies that for each cell an additional random
number is drawn. If the model probability is larger than this value, the person gets 1 on
this particular item, if smaller, 0 is assigned. Alternatively, a numeric probability
cutpoint can be assigned and the 0-1 scoring is carried out according to the same rule.
</p>
<p>If <code>weightmat</code> is not specified, a random indicator matrix is generated where each item is a measurement
of only one dimension. For instance, the first row for a 3D-model could be (0,1,0) which means
that the first item measures the second dimension only. This corresponds to the between-item
multidimensional model presented by Adams et al. (1997).
</p>
<p><code>Sigma</code> reflects the VC-structure for the person parameters drawn from a multivariate
standard normal distribution. Thus, the diagonal elements are typically 1 and the lower the
covariances in the off-diagonal, the stronger the model violation.
</p>


<h3>References</h3>

<p>Adams, R. J., Wilson, M., &amp; Wang, W. C. (1997). The multidimensional random coefficients
multinomial logit model. Applied Psychological Measurement, 21, 1-23.
</p>
<p>Glas, C. A. W. (1992). A Rasch model with a multivariate distribution of ability. In M.
Wilson (Ed.), Objective Measurement: Foundations, Recent Developments, and
Applications (pp. 236-258). Norwood, NJ: Ablex.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sim.rasch">sim.rasch</a></code>, <code><a href="#topic+sim.locdep">sim.locdep</a></code>, <code><a href="#topic+sim.2pl">sim.2pl</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# 500 persons, 10 items, 3 dimensions, random weights.
Sigma &lt;- matrix(c(1, 0.01, 0.01, 0.01, 1, 0.01, 0.01, 0.01, 1), 3)
X &lt;- sim.xdim(500, 10, Sigma)

#500 persons, 10 items, 2 dimensions, weights fixed to 0.5
itemvec &lt;- runif(10, -2, 2)
Sigma &lt;- matrix(c(1, 0.05, 0.05, 1), 2)
weights &lt;- matrix(0.5, ncol = 2, nrow = 10)
X &lt;- sim.xdim(500, itemvec, Sigma, weightmat = weights)

</code></pre>

<hr>
<h2 id='stepwiseIt'>Stepwise item elimination</h2><span id='topic+stepwiseIt'></span><span id='topic+stepwiseIt.eRm'></span><span id='topic+print.step'></span>

<h3>Description</h3>

<p>This function eliminates items stepwise according to one of the following 
criteria: itemfit, Wald test, Andersen's LR-test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eRm'
stepwiseIt(object, criterion = list("itemfit"), alpha = 0.05,
           verbose = TRUE, maxstep = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepwiseIt_+3A_object">object</code></td>
<td>
<p>Object of class <code>eRm</code>.</p>
</td></tr>
<tr><td><code id="stepwiseIt_+3A_criterion">criterion</code></td>
<td>
<p>List with either <code>"itemfit"</code>, <code>"Waldtest"</code> or <code>"LRtest"</code> as first element. 
Optionally, for the Waldtest and LRtest a second element containing the split criterion can be specified (see details).</p>
</td></tr>
<tr><td><code id="stepwiseIt_+3A_alpha">alpha</code></td>
<td>
<p>Significance level.</p>
</td></tr>
<tr><td><code id="stepwiseIt_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> intermediate results are printed out. </p>
</td></tr>
<tr><td><code id="stepwiseIt_+3A_maxstep">maxstep</code></td>
<td>
<p>Maximum number of elimination steps. If <code>NA</code> the procedure stops when the itemset is Rasch homogeneous.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>criterion = list("itemfit")</code> the elimination stops when none of the p-values 
in itemfit is significant. Within each step the item with the largest chi-squared 
itemfit value is excluded.
</p>
<p>If <code>criterion = list("Waldtest")</code> the elimination stops when none of the p-values 
resulting from the Wald test is significant. Within each step the item with the largest z-value in 
Wald test is excluded. 
</p>
<p>If <code>criterion = list("LRtest")</code> the elimination stops when Andersen's LR-test is not
significant. Within each step the item with the largest z-value in Wald test is excluded. 
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>step</code> containing:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>Reduced data matrix (bad items eliminated)</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>Object of class <code>eRm</code> with the final item parameter elimination</p>
</td></tr>
<tr><td><code>it.elim</code></td>
<td>
<p>Vector contaning the names of the eliminated items</p>
</td></tr>
<tr><td><code>res.wald</code></td>
<td>
<p>Elimination results for Wald test criterion</p>
</td></tr>
<tr><td><code>res.itemfit</code></td>
<td>
<p>Elimination results for itemfit criterion</p>
</td></tr>
<tr><td><code>res.LR</code></td>
<td>
<p>Elimination results for LR-test criterion</p>
</td></tr>
<tr><td><code>nsteps</code></td>
<td>
<p>Number of elimination steps</p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+LRtest.Rm">LRtest.Rm</a></code>, <code><a href="#topic+Waldtest.Rm">Waldtest.Rm</a></code>, <code><a href="#topic+itemfit.ppar">itemfit.ppar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 2pl-data, 100 persons, 10 items
set.seed(123)
X &lt;- sim.2pl(500, 10, 0.4)
res &lt;- RM(X)

## elimination according to itemfit
stepwiseIt(res, criterion = list("itemfit"))      

## Wald test based on mean splitting
stepwiseIt(res, criterion = list("Waldtest","mean")) 

## Andersen LR-test based on random split
set.seed(123)
groupvec &lt;- sample(1:3, 500, replace = TRUE)
stepwiseIt(res, criterion = list("LRtest",groupvec))

</code></pre>

<hr>
<h2 id='summary.llra'>Summarizing Linear Logistic Models with Relaxed Assumptions (LLRA)
</h2><span id='topic+summary.llra'></span><span id='topic+print.summary.llra'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"llra"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'llra'
summary(object, level, ...)

## S3 method for class 'summary.llra'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.llra_+3A_object">object</code></td>
<td>
<p>an object of class &quot;llra&quot;, typically result of a call to
<code><a href="#topic+LLRA">LLRA</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.llra_+3A_x">x</code></td>
<td>
<p>an object of class &quot;summary.llra&quot;, usually, a result of a call
to <code>summary.llra</code>.
</p>
</td></tr>
<tr><td><code id="summary.llra_+3A_level">level</code></td>
<td>
<p>The level of confidence for the confidence
intervals. Default is 0.95.</p>
</td></tr>
<tr><td><code id="summary.llra_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects of class <code>"summary.llra"</code> contain all parameters of interest plus the confidence intervals.
</p>
<p><code>print.summary.llra</code> rounds the values to 3 digits and displays
them nicely.
</p>


<h3>Value</h3>

<p>The function <code>summary.lllra</code> computes and returns a list of
summary statistics of the fitted LLRA given in object, reusing the
components (list elements) <code>call</code>, <code>etapar</code>,
<code>iter</code>, <code>loglik</code>, <code>model</code>, <code>npar</code> and <code>se.etapar</code> from its argument, plus
</p>
<table>
<tr><td><code>ci</code></td>
<td>
<p>The upper and lower confidence interval borders.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>See Also</h3>

<p>The model fitting function <code><a href="#topic+LLRA">LLRA</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Example 6 from Hatzinger &amp; Rusch (2009)
groups &lt;- c(rep("TG",30),rep("CG",30))
llra1 &lt;- LLRA(llradat3,mpoints=2,groups=groups)
summary(llra1)

## Not run: 
##An LLRA with 2 treatment groups and 1 baseline group, 5 items and 4
##time points. Item 1 is dichotomous, all others have 3, 4, 5, 6
##categories respectively.
ex2 &lt;- LLRA(llraDat2[1:20],mpoints=4,llraDat2[21])
sumEx2 &lt;- summary(ex2, level=0.95)

#print a summary
sumEx2

#get confidence intervals
sumEx2$ci
## End(Not run)
</code></pre>

<hr>
<h2 id='summary.RSctr'>Summary Method for Control Objects</h2><span id='topic+summary.RSctr'></span>

<h3>Description</h3>

<p>Prints the current definitions for the sampling function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RSctr'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.RSctr_+3A_object">object</code></td>
<td>
<p> object of class <code>RSctr</code> as obtained from <code><a href="#topic+rsctrl">rsctrl</a></code> </p>
</td></tr>
<tr><td><code id="summary.RSctr_+3A_...">...</code></td>
<td>
<p> potential further arguments (ignored) </p>
</td></tr>
</table>


<h3>See Also</h3>

 <p><code><a href="#topic+rsctrl">rsctrl</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>   ctr &lt;- rsctrl(n_eff = 1, seed = 123123123)  # specify controls
   summary(ctr)
</code></pre>

<hr>
<h2 id='summary.RSmpl'>Summary Methods for Sample Objects</h2><span id='topic+summary.RSmpl'></span><span id='topic+summary.RSmplext'></span>

<h3>Description</h3>

<p>Prints a summary list for sample objects of class <code><a href="#topic+RSmpl">RSmpl</a></code>
and <code><a href="#topic+RSmplext">RSmplext</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RSmpl'
summary(object, ...)
## S3 method for class 'RSmplext'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.RSmpl_+3A_object">object</code></td>
<td>
<p>object as obtained from <code>rsampler</code> or <code>rsextrobj</code> </p>
</td></tr>
<tr><td><code id="summary.RSmpl_+3A_...">...</code></td>
<td>
<p> potential further arguments (ignored) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Describes the status of an sample object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rsampler">rsampler</a></code>, <code><a href="#topic+rsextrobj">rsextrobj</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>ctr &lt;- rsctrl(burn_in = 10, n_eff = 3, step=10, seed = 0, tfixed = FALSE)
mat &lt;- matrix(sample(c(0,1), 50, replace = TRUE), nr = 10)
all_m &lt;- rsampler(mat, ctr)
summary(all_m)

some_m &lt;- rsextrobj(all_m, 1, 2)
summary(some_m)
</code></pre>

<hr>
<h2 id='test_info'>Calculate Test Information For <code>eRm</code> objects
</h2><span id='topic+test_info'></span>

<h3>Description</h3>

<p>Calculates the information of a test or a scale as the sum of Samejima's (1969) information for all items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_info(ermobject, theta=seq(-5,5,0.01))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test_info_+3A_ermobject">ermobject</code></td>
<td>
<p>An object of class <code>'eRm'</code>.
</p>
</td></tr> 
<tr><td><code id="test_info_+3A_theta">theta</code></td>
<td>
<p>Supporting or sampling points on the latent trait.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>test_info</code> calculates the test or scale information of the
whole set of items in the <code>'eRm'</code> object. 
</p>


<h3>Value</h3>

<p>Returns the vector of test information for all values of theta.  
</p>


<h3>Author(s)</h3>

<p>Thomas Rusch</p>


<h3>References</h3>

<p>Samejima, F. (1969) Estimation of latent ability using a response
pattern of graded scores. <em>Psychometric Monographs</em>, <b>17</b>.  
</p>


<h3>See Also</h3>

<p>The function to calculate the item information, <code><a href="#topic+item_info">item_info</a></code>
and the plot function <code><a href="#topic+plotINFO">plotINFO</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- PCM(pcmdat)
tinfo &lt;- test_info(res)
plotINFO(res, type="test")
</code></pre>

<hr>
<h2 id='thresholds'>Computation of item-category treshold parameters.</h2><span id='topic+thresholds'></span><span id='topic+thresholds.eRm'></span><span id='topic+print.threshold'></span><span id='topic+summary.threshold'></span><span id='topic+confint.threshold'></span>

<h3>Description</h3>

<p>This function transforms the beta parameters into threshold
parameters. These can be interpreted by means of log-odds as visualized in ICC plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eRm'
thresholds(object)
## S3 method for class 'threshold'
print(x, ...)
## S3 method for class 'threshold'
summary(object, ...)
## S3 method for class 'threshold'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<p>Arguments for <code>thresholds</code>:
</p>
<table>
<tr><td><code id="thresholds_+3A_object">object</code></td>
<td>
<p>Object of class <code>eRm</code>.</p>
</td></tr>
</table>
<p>Arguments for <code>print</code>, <code>summary</code>, and <code>confint</code> methods:
</p>
<table>
<tr><td><code id="thresholds_+3A_x">x</code></td>
<td>
<p>Object of class <code>threshold</code>.</p>
</td></tr>
<tr><td><code id="thresholds_+3A_parm">parm</code></td>
<td>
<p>Parameter specification (ignored).</p>
</td></tr>
<tr><td><code id="thresholds_+3A_level">level</code></td>
<td>
<p>Alpha-level.</p>
</td></tr>
<tr><td><code id="thresholds_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to methods. They are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For dichotomous models (i.e., RM and LLTM) threshold parameters are not computed.
The <code>print</code> method returns a location parameter for each item which is the
mean of the corresponding threshold parameters. For LPCM and LRSM the thresholds are
computed for each design matrix block (i.e., measurement point/group) separately
(PCM and RSM have only 1 block).</p>


<h3>Value</h3>

<p>The function <code>thresholds</code> returns an object of class <code>threshold</code> containing:
</p>
<table>
<tr><td><code>threshpar</code></td>
<td>
<p>Vector with threshold parameters.</p>
</td></tr>
<tr><td><code>se.thresh</code></td>
<td>
<p>Vector with standard errors.</p>
</td></tr>
<tr><td><code>threshtable</code></td>
<td>
<p>Data frame with location and threshold parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Andrich, D. (1978). Application of a psychometric rating model to ordered categories which are scored with successive integers. Applied Psychological Measurement, 2, 581-594.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotICC.Rm">plotICC.Rm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Threshold parameterization for a rating scale model
res &lt;- RSM(rsmdat)
th.res &lt;- thresholds(res)
th.res
confint(th.res)
summary(th.res)

#Threshold parameters for a PCM with ICC plot
res &lt;- PCM(pcmdat)
th.res &lt;- thresholds(res)
th.res
plotICC(res)

#Threshold parameters for a LPCM:
#Block 1: t1, g1; Block 2: t1, g2; ...; Block 6: t2,g3
G &lt;- c(rep(1,7),rep(2,7),rep(3,6)) # group vector for 3 groups
res &lt;- LPCM(lpcmdat, mpoints = 2, groupvec = G)
th.res &lt;- thresholds(res)
th.res
</code></pre>

<hr>
<h2 id='Waldtest'>Item-Specific Wald Test</h2><span id='topic+Waldtest'></span><span id='topic+Waldtest.Rm'></span><span id='topic+print.wald'></span>

<h3>Description</h3>

<p>Performs a Wald test on item-level by splitting subjects into subgroups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Rm'
Waldtest(object, splitcr = "median")
## S3 method for class 'wald'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Waldtest_+3A_object">object</code></td>
<td>
<p>Object of class <code>RM</code>.</p>
</td></tr>
<tr><td><code id="Waldtest_+3A_splitcr">splitcr</code></td>
<td>
<p>Split criterion for subject raw score splitting. <code>median</code>
uses the median as split criterion, <code>mean</code> performs a mean-split.
Optionally <code>splitcr</code> can also be a dichotomous vector which assigns each person to a
certain subgroup (e.g., following an external criterion). This vector can be numeric, character or a factor. </p>
</td></tr>
<tr><td><code id="Waldtest_+3A_x">x</code></td>
<td>
<p>Object of class <code>wald</code>.</p>
</td></tr>
<tr><td><code id="Waldtest_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Items are eliminated if they not have the same number of categories in each subgroup.
To avoid this problem, for RSM and PCM it is considered to use a random or another user-defined split.
If the data set contains missing values and <code>mean</code> or <code>median</code> is specified as splitcriterion,
means or medians are calculated for each missing value subgroup and consequently used for raw score splitting.</p>


<h3>Value</h3>

<p>Returns an object of class <code>wald</code> containing:
</p>
<table>
<tr><td><code>coef.table</code></td>
<td>
<p>Data frame with test statistics, z- and p-values.</p>
</td></tr>
<tr><td><code>betapar1</code></td>
<td>
<p>Beta parameters for first subgroup</p>
</td></tr>
<tr><td><code>se.beta1</code></td>
<td>
<p>Standard errors for first subgroup</p>
</td></tr>
<tr><td><code>betapar2</code></td>
<td>
<p>Beta parameters for second subgroup</p>
</td></tr>
<tr><td><code>se.beta2</code></td>
<td>
<p>Standard errors for second subgroup</p>
</td></tr>
<tr><td><code>se.beta2</code></td>
<td>
<p>Standard errors for second subgroup</p>
</td></tr>
<tr><td><code>spl.gr</code></td>
<td>
<p>Names and levels for <code>splitcr</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Mair, Reinhold Hatzinger</p>


<h3>References</h3>

<p>Fischer, G. H., and Molenaar, I. (1995). Rasch Models - Foundations,
Recent Developements, and Applications. Springer.
</p>
<p>Fischer, G. H., and Scheiblechner, H. (1970). Algorithmen und Programme fuer das
probabilistische Testmodell von Rasch [Algorithms and programs for Rasch's
probabilistic test model]. Psychologische Beitraege, 12, 23-51.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LRtest">LRtest</a></code>, <code><a href="#topic+MLoef">MLoef</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Wald test for Rasch model with user-defined subject split
res &lt;- RM(raschdat2)
splitvec &lt;- sample(1:2,25,replace=TRUE)
Waldtest(res, splitcr = splitvec)
</code></pre>

<hr>
<h2 id='xmpl'>Example Data</h2><span id='topic+xmpl'></span><span id='topic+xmplbig'></span>

<h3>Description</h3>

<p>Ficitious data sets - matrices with binary responses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(xmpl)</code></pre>


<h3>Format</h3>

<p>The format of <code>xmpl</code> is:<br />
300 rows (referring to subjects) <br />
30 columns (referring to items) <br />
</p>
<p>The format of <code>xmplbig</code> is:<br />
4096 rows (referring to subjects) <br />
128 columns (referring to items) <br />
<code>xmplbig</code> has the maximum dimensions that the RaschSampler package
can handle currently.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(xmpl)
print(head(xmpl))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
