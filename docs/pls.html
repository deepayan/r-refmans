<!DOCTYPE html><html><head><title>Help for package pls</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pls}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#biplot.mvr'><p>Biplots of PLSR and PCR Models.</p></a></li>
<li><a href='#coef.mvr'><p>Extract Information From a Fitted PLSR or PCR Model</p></a></li>
<li><a href='#coefplot'><p>Plot Regression Coefficients of PLSR and PCR models</p></a></li>
<li><a href='#cppls.fit'><p>CPPLS (Indahl et al.)</p></a></li>
<li><a href='#crossval'><p>Cross-validation of PLSR and PCR models</p></a></li>
<li><a href='#cvsegments'><p>Generate segments for cross-validation</p></a></li>
<li><a href='#delete.intercept'><p>Delete intercept from model matrix</p></a></li>
<li><a href='#gasoline'><p>Octane numbers and NIR spectra of gasoline</p></a></li>
<li><a href='#jack.test'><p>Jackknife approximate t tests of regression coefficients</p></a></li>
<li><a href='#kernelpls.fit'><p>Kernel PLS (Dayal and MacGregor)</p></a></li>
<li><a href='#mayonnaise'><p>NIR measurements and oil types of mayonnaise</p></a></li>
<li><a href='#msc'><p>Multiplicative Scatter Correction</p></a></li>
<li><a href='#mvr'><p>Partial Least Squares and Principal Component Regression</p></a></li>
<li><a href='#mvrCv'><p>Cross-validation</p></a></li>
<li><a href='#mvrVal'><p>MSEP, RMSEP and R2 of PLSR and PCR models</p></a></li>
<li><a href='#naExcludeMvr'><p>Adjust for Missing Values</p></a></li>
<li><a href='#oliveoil'><p>Sensory and physico-chemical data of olive oils</p></a></li>
<li><a href='#oscorespls.fit'><p>Orthogonal scores PLSR</p></a></li>
<li><a href='#plot.mvr'><p>Plot Method for MVR objects</p></a></li>
<li><a href='#pls'><p>Partial Least Squares and Principal Component Regression</p></a></li>
<li><a href='#pls.options'><p>Set or return options for the pls package</p></a></li>
<li><a href='#predict.mvr'><p>Predict Method for PLSR and PCR</p></a></li>
<li><a href='#predplot'><p>Prediction Plots</p></a></li>
<li><a href='#print.mvr'><p>Summary and Print Methods for PLSR and PCR objects</p></a></li>
<li><a href='#scoreplot'><p>Plots of Scores, Loadings and Correlation Loadings</p></a></li>
<li><a href='#scores'><p>Extract Scores and Loadings from PLSR and PCR Models</p></a></li>
<li><a href='#selectNcomp'><p>Suggestions for the optimal number of components in PCR and PLSR models</p></a></li>
<li><a href='#simpls.fit'><p>Sijmen de Jong's SIMPLS</p></a></li>
<li><a href='#stdize'><p>Standardization of Data Matrices</p></a></li>
<li><a href='#svdpc.fit'><p>Principal Component Regression</p></a></li>
<li><a href='#validationplot'><p>Validation Plots</p></a></li>
<li><a href='#var.jack'><p>Jackknife Variance Estimates of Regression Coefficients</p></a></li>
<li><a href='#vcov.mvr'><p>Calculate Variance-Covariance Matrix for a Fitted Model Object</p></a></li>
<li><a href='#widekernelpls.fit'><p>Wide Kernel PLS (Rännar et al.)</p></a></li>
<li><a href='#yarn'><p>NIR spectra and density measurements of PET yarns</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Partial Least Squares and Principal Component Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>2.8-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Kristian Hovde Liland [aut, cre],
  Bjørn-Helge Mevik [aut],
  Ron Wehrens [aut],
  Paul Hiemstra [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kristian Hovde Liland &lt;kristian.liland@nmbu.no&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Description:</td>
<td>Multivariate regression methods
	Partial Least Squares Regression (PLSR), Principal Component
	Regression (PCR) and Canonical Powered Partial Least Squares (CPPLS).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, methods, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, parallel, Rmpi, testthat, RUnit</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/khliland/pls">https://github.com/khliland/pls</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/khliland/pls/issues">https://github.com/khliland/pls/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-17 21:37:16 UTC; kristian</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-17 22:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='biplot.mvr'>Biplots of PLSR and PCR Models.</h2><span id='topic+biplot.mvr'></span>

<h3>Description</h3>

<p>Biplot method for <code>mvr</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
biplot(
  x,
  comps = 1:2,
  which = c("x", "y", "scores", "loadings"),
  var.axes = FALSE,
  xlabs,
  ylabs,
  main,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplot.mvr_+3A_x">x</code></td>
<td>
<p>an <code>mvr</code> object.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_comps">comps</code></td>
<td>
<p>integer vector of length two.  The components to plot.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_which">which</code></td>
<td>
<p>character.  Which matrices to plot.  One of <code>"x"</code> (X
scores and loadings), <code>"y"</code> (Y scores and loadings), <code>"scores"</code> (X
and Y scores) and <code>"loadings"</code> (X and Y loadings).</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_var.axes">var.axes</code></td>
<td>
<p>logical.  If <code>TRUE</code>, the second set of points have
arrows representing them.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_xlabs">xlabs</code></td>
<td>
<p>either a character vector of labels for the first set of
points, or <code>FALSE</code> for no labels.  If missing, the row names of the
first matrix is used as labels.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_ylabs">ylabs</code></td>
<td>
<p>either a character vector of labels for the second set of
points, or <code>FALSE</code> for no labels.  If missing, the row names of the
second matrix is used as labels.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_main">main</code></td>
<td>
<p>character.  Title of plot.  If missing, a title is constructed
by <code>biplot.mvr</code>.</p>
</td></tr>
<tr><td><code id="biplot.mvr_+3A_...">...</code></td>
<td>
<p>Further arguments passed on to <code>biplot.default</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>biplot.mvr</code> can also be called through the <code>mvr</code> plot method by
specifying <code>plottype = "biplot"</code>.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>,
<code><a href="stats.html#topic+biplot.default">biplot.default</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oliveoil)
mod &lt;- plsr(sensory ~ chemical, data = oliveoil)
## Not run: 
## These are equivalent
biplot(mod)
plot(mod, plottype = "biplot")

## The four combinations of x and y points:
par(mfrow = c(2,2))
biplot(mod, which = "x") # Default
biplot(mod, which = "y")
biplot(mod, which = "scores")
biplot(mod, which = "loadings")

## End(Not run)

</code></pre>

<hr>
<h2 id='coef.mvr'>Extract Information From a Fitted PLSR or PCR Model</h2><span id='topic+coef.mvr'></span><span id='topic+fitted.mvr'></span><span id='topic+residuals.mvr'></span><span id='topic+model.frame.mvr'></span><span id='topic+model.matrix.mvr'></span><span id='topic+prednames'></span><span id='topic+respnames'></span><span id='topic+compnames'></span><span id='topic+explvar'></span>

<h3>Description</h3>

<p>Functions to extract information from <code>mvr</code> objects: Regression
coefficients, fitted values, residuals, the model frame, the model matrix,
names of the variables and components, and the <code class="reqn">X</code> variance explained by
the components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
coef(object, ncomp = object$ncomp, comps, intercept = FALSE, ...)

## S3 method for class 'mvr'
fitted(object, ...)

## S3 method for class 'mvr'
residuals(object, ...)

## S3 method for class 'mvr'
model.frame(formula, ...)

## S3 method for class 'mvr'
model.matrix(object, ...)

respnames(object)

prednames(object, intercept = FALSE)

compnames(object, comps, explvar = FALSE, ...)

explvar(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.mvr_+3A_object">object</code>, <code id="coef.mvr_+3A_formula">formula</code></td>
<td>
<p>an <code>mvr</code> object.  The fitted model.</p>
</td></tr>
<tr><td><code id="coef.mvr_+3A_ncomp">ncomp</code>, <code id="coef.mvr_+3A_comps">comps</code></td>
<td>
<p>vector of positive integers.  The components to include
in the coefficients or to extract the names of.  See below.</p>
</td></tr>
<tr><td><code id="coef.mvr_+3A_intercept">intercept</code></td>
<td>
<p>logical.  Whether coefficients for the intercept should be
included.  Ignored if <code>comps</code> is specified.  Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef.mvr_+3A_...">...</code></td>
<td>
<p>other arguments sent to underlying functions.  Currently only
used for <code>model.frame.mvr</code> and <code>model.matrix.mvr</code>.</p>
</td></tr>
<tr><td><code id="coef.mvr_+3A_explvar">explvar</code></td>
<td>
<p>logical.  Whether the explained <code class="reqn">X</code> variance should be
appended to the component names.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are mostly used inside other functions.  (Functions
<code>coef.mvr</code>, <code>fitted.mvr</code> and <code>residuals.mvr</code> are usually
called through their generic functions <code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="stats.html#topic+fitted">fitted</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code>, respectively.)
</p>
<p><code>coef.mvr</code> is used to extract the regression coefficients of a model,
i.e. the <code class="reqn">B</code> in <code class="reqn">y = XB</code> (for the <code class="reqn">Q</code> in <code class="reqn">y = TQ</code> where
<code class="reqn">T</code> is the scores, see <code><a href="#topic+Yloadings">Yloadings</a></code>).  An array of dimension
<code>c(nxvar, nyvar, length(ncomp))</code> or <code>c(nxvar, nyvar,
length(comps))</code> is returned.
</p>
<p>If <code>comps</code> is missing (or is <code>NULL</code>), <code>coef()[,,ncomp[i]]</code>
are the coefficients for models with <code>ncomp[i]</code> components, for <code class="reqn">i
= 1, \ldots, length(ncomp)</code>.  Also, if <code>intercept = TRUE</code>, the first
dimension is <code class="reqn">nxvar + 1</code>, with the intercept coefficients as the first
row.
</p>
<p>If <code>comps</code> is given, however, <code>coef()[,,comps[i]]</code> are the
coefficients for a model with only the component <code>comps[i]</code>, i.e. the
contribution of the component <code>comps[i]</code> on the regression
coefficients.
</p>
<p><code>fitted.mvr</code> and <code>residuals.mvr</code> return the fitted values and
residuals, respectively.  If the model was fitted with <code>na.action =
na.exclude</code> (or after setting the default <code>na.action</code> to
<code>"na.exclude"</code> with <code><a href="base.html#topic+options">options</a></code>), the fitted values (or
residuals) corresponding to excluded observations are returned as <code>NA</code>;
otherwise, they are omitted.
</p>
<p><code>model.frame.mvr</code> returns the model frame; i.e. a data frame with all
variables neccessary to generate the model matrix.  See
<code><a href="stats.html#topic+model.frame">model.frame</a></code> for details.
</p>
<p><code>model.matrix.mvr</code> returns the (possibly coded) matrix used as <code class="reqn">X</code>
in the fitting.  See <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> for details.
</p>
<p><code>prednames</code>, <code>respnames</code> and <code>compnames</code> extract the names of
the <code class="reqn">X</code> variables, responses and components, respectively.  With
<code>intercept = TRUE</code> in <code>prednames</code>, the name of the intercept
variable (i.e. <code>"(Intercept)"</code>) is returned as well.  <code>compnames</code>
can also extract component names from score and loading matrices.  If
<code>explvar = TRUE</code> in <code>compnames</code>, the explained variance for each
component (if available) is appended to the component names.  For optimal
formatting of the explained variances when not all components are to be
used, one should specify the desired components with the argument
<code>comps</code>.
</p>
<p><code>explvar</code> extracts the amount of <code class="reqn">X</code> variance (in per cent)
explained by each component in the model.  It can also handle score and
loading matrices returned by <code><a href="#topic+scores">scores</a></code> and
<code><a href="#topic+loadings">loadings</a></code>.
</p>


<h3>Value</h3>

<p><code>coef.mvr</code> returns an array of regression coefficients.
</p>
<p><code>fitted.mvr</code> returns an array with fitted values.
</p>
<p><code>residuals.mvr</code> returns an array with residuals.
</p>
<p><code>model.frame.mvr</code> returns a data frame.
</p>
<p><code>model.matrix.mvr</code> returns the <code class="reqn">X</code> matrix.
</p>
<p><code>prednames</code>, <code>respnames</code> and <code>compnames</code> return a character
vector with the corresponding names.
</p>
<p><code>explvar</code> returns a numeric vector with the explained variances, or
<code>NULL</code> if not available.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+residuals">residuals</a></code>, <code><a href="stats.html#topic+model.frame">model.frame</a></code>,
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code>, <code><a href="stats.html#topic+na.omit">na.omit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
mod &lt;- pcr(density ~ NIR, data = yarn[yarn$train,], ncomp = 5)
B &lt;- coef(mod, ncomp = 3, intercept = TRUE)
## A manual predict method:
stopifnot(drop(B[1,,] + yarn$NIR[!yarn$train,] %*% B[-1,,]) ==
          drop(predict(mod, ncomp = 3, newdata = yarn[!yarn$train,])))

## Note the difference in formatting:
mod2 &lt;- pcr(density ~ NIR, data = yarn[yarn$train,])
compnames(mod2, explvar = TRUE)[1:3]
compnames(mod2, comps = 1:3, explvar = TRUE)

</code></pre>

<hr>
<h2 id='coefplot'>Plot Regression Coefficients of PLSR and PCR models</h2><span id='topic+coefplot'></span>

<h3>Description</h3>

<p>Function to plot the regression coefficients of an <code>mvr</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefplot(
  object,
  ncomp = object$ncomp,
  comps,
  intercept = FALSE,
  separate = FALSE,
  se.whiskers = FALSE,
  nCols,
  nRows,
  labels,
  type = "l",
  lty,
  lwd = NULL,
  pch,
  cex = NULL,
  col,
  legendpos,
  xlab = "variable",
  ylab = "regression coefficient",
  main,
  pretty.xlabels = TRUE,
  xlim,
  ylim,
  ask = nRows * nCols &lt; nPlots &amp;&amp; dev.interactive(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefplot_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.  The fitted model.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_ncomp">ncomp</code>, <code id="coefplot_+3A_comps">comps</code></td>
<td>
<p>vector of positive integers.  The components to plot.
See <code><a href="#topic+coef.mvr">coef.mvr</a></code> for details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_intercept">intercept</code></td>
<td>
<p>logical.  Whether coefficients for the intercept should be
plotted.  Ignored if <code>comps</code> is specified.  Defaults to <code>FALSE</code>.
See <code><a href="#topic+coef.mvr">coef.mvr</a></code> for details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_separate">separate</code></td>
<td>
<p>logical.  If <code>TRUE</code>, coefficients for different model
sizes are blotted in separate plots.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_se.whiskers">se.whiskers</code></td>
<td>
<p>logical.  If <code>TRUE</code>, whiskers at plus/minus 1
estimated standard error are added to the plot.  This is only available if
the model was cross-validated with <code>jackknife = TRUE</code>.  Also, in the
current implementation, <code>intercept</code> must be <code>FALSE</code>, and
<code>separate</code> must be <code>TRUE</code> if <code>length(ncomp) &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_ncols">nCols</code>, <code id="coefplot_+3A_nrows">nRows</code></td>
<td>
<p>integer.  The number of coloumns and rows the plots will
be laid out in.  If not specified, <code>coefplot</code> tries to be intelligent.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_labels">labels</code></td>
<td>
<p>optional.  Alternative <code class="reqn">x</code> axis labels.  See Details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_type">type</code></td>
<td>
<p>character.  What type of plot to make.  Defaults to <code>"l"</code>
(lines).  Alternative types include <code>"p"</code> (points) and <code>"b"</code>
(both).  See <code><a href="graphics.html#topic+plot">plot</a></code> for a complete list of types.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_lty">lty</code></td>
<td>
<p>vector of line types (recycled as neccessary).  Line types can be
specified as integers or character strings (see <code><a href="graphics.html#topic+par">par</a></code> for the
details).</p>
</td></tr>
<tr><td><code id="coefplot_+3A_lwd">lwd</code></td>
<td>
<p>vector of positive numbers (recycled as neccessary), giving the
width of the lines.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_pch">pch</code></td>
<td>
<p>plot character.  A character string or a vector of single
characters or integers (recycled as neccessary).  See <code><a href="graphics.html#topic+points">points</a></code>
for all alternatives.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_cex">cex</code></td>
<td>
<p>numeric vector of character expansion sizes (recycled as
neccessary) for the plotted symbols.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_col">col</code></td>
<td>
<p>character or integer vector of colors for plotted lines and
symbols (recycled as neccessary).  See <code><a href="graphics.html#topic+par">par</a></code> for the details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_legendpos">legendpos</code></td>
<td>
<p>Legend position.  Optional.  Ignored if <code>separate</code> is
<code>TRUE</code>.  If present, a legend is drawn at the given position.  The
position can be specified symbolically (e.g., <code>legendpos =
"topright"</code>).  This requires &gt;= 2.1.0.  Alternatively, the position can be
specified explicitly (<code>legendpos = t(c(x,y))</code>) or interactively
(<code>legendpos = <a href="graphics.html#topic+locator">locator</a>()</code>).  This only works well for plots of
single-response models.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_xlab">xlab</code>, <code id="coefplot_+3A_ylab">ylab</code></td>
<td>
<p>titles for <code class="reqn">x</code> and <code class="reqn">y</code> axes.  Typically character
strings, but can be expressions (e.g., <code>expression(R^2)</code> or lists.  See
<code><a href="graphics.html#topic+title">title</a></code> for details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_main">main</code></td>
<td>
<p>optional main title for the plot.  See Details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_pretty.xlabels">pretty.xlabels</code></td>
<td>
<p>logical.  If <code>TRUE</code>, <code>coefplot</code> tries to
plot the <code class="reqn">x</code> labels more nicely.  See Details.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_xlim">xlim</code>, <code id="coefplot_+3A_ylim">ylim</code></td>
<td>
<p>optional vector of length two, with the <code class="reqn">x</code> or <code class="reqn">y</code>
limits of the plot.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_ask">ask</code></td>
<td>
<p>logical.  Whether to ask the user before each page of a plot.</p>
</td></tr>
<tr><td><code id="coefplot_+3A_...">...</code></td>
<td>
<p>Further arguments sent to the underlying plot functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coefplot</code> handles multiple responses by making one plot for each
response.  If <code>separate</code> is <code>TRUE</code>, separate plots are made for
each combination of model size and response.  The plots are laid out in a
rectangular fashion.
</p>
<p>If <code>legendpos</code> is given, a legend is drawn at the given position
(unless <code>separate</code> is <code>TRUE</code>).
</p>
<p>The argument <code>labels</code> can be a vector of labels or one of
<code>"names"</code> and <code>"numbers"</code>.  The labels are used as <code class="reqn">x</code> axis
labels.  If <code>labels</code> is <code>"names"</code> or <code>"numbers"</code>, the
variable names are used as labels, the difference being that with
<code>"numbers"</code>, the variable names are converted to numbers, if possible.
Variable names of the forms &lsquo;<span class="samp">&#8288;"number"&#8288;</span>&rsquo; or &lsquo;<span class="samp">&#8288;"number text"&#8288;</span>&rsquo; (where
the space is optional), are handled.
</p>
<p>The argument <code>main</code> can be used to specify the main title of the plot.
It is handled in a non-standard way.  If there is only on (sub) plot,
<code>main</code> will be used as the main title of the plot.  If there is
<em>more</em> than one (sub) plot, however, the presence of <code>main</code> will
produce a corresponding &lsquo;global&rsquo; title on the page.  Any graphical
parametres, e.g., <code>cex.main</code>, supplied to <code>coefplot</code> will only
affect the &lsquo;ordinary&rsquo; plot titles, not the &lsquo;global&rsquo; one.  Its
appearance can be changed by setting the parameters with <code><a href="graphics.html#topic+par">par</a></code>,
which will affect <em>both</em> titles.  (To have different settings for the
two titles, one can override the <code>par</code> settings with arguments to
<code>coefplot</code>.)
</p>
<p>The argument <code>pretty.xlabels</code> is only used when <code>labels</code> is
specified.  If <code>TRUE</code> (default), the code tries to use a
&lsquo;pretty&rsquo; selection of labels.  If <code>labels</code> is <code>"numbers"</code>,
it also uses the numerical values of the labels for horisontal spacing.  If
one has excluded parts of the spectral region, one might therefore want to
use <code>pretty.xlabels = FALSE</code>.
</p>
<p>When <code>separate</code> is <code>TRUE</code>, the arguments <code>lty</code>, <code>col</code>,
and <code>pch</code> default to their <code>par()</code> setting.  Otherwise, the
default for all of them is <code>1:nLines</code>, where <code>nLines</code> is the
number of model sizes specified, i.e., the length of <code>ncomp</code> or
<code>comps</code>.
</p>
<p>The function can also be called through the <code>mvr</code> plot method by
specifying <code>plottype = "coefficients"</code>.
</p>


<h3>Note</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code> has many options.  If you want greater control
over the appearance of the legend, omit the <code>legendpos</code> argument and
call <code>legend</code> manually.
</p>
<p>The handling of <code>labels</code> and <code>pretty.xlabels</code> is experimental.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>, <code><a href="#topic+coef.mvr">coef.mvr</a></code>,
<code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+legend">legend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
mod.nir &lt;- plsr(density ~ NIR, ncomp = 8, data = yarn)
## Not run: 
coefplot(mod.nir, ncomp = 1:6)
plot(mod.nir, plottype = "coefficients", ncomp = 1:6) # Equivalent to the previous
## Plot with legend:
coefplot(mod.nir, ncom = 1:6, legendpos = "bottomright")

## End(Not run)

data(oliveoil)
mod.sens &lt;- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil)
## Not run: coefplot(mod.sens, ncomp = 2:4, separate = TRUE)

</code></pre>

<hr>
<h2 id='cppls.fit'>CPPLS (Indahl et al.)</h2><span id='topic+cppls.fit'></span>

<h3>Description</h3>

<p>Fits a PLS model using the CPPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cppls.fit(
  X,
  Y,
  ncomp,
  Y.add = NULL,
  center = TRUE,
  stripped = FALSE,
  lower = 0.5,
  upper = 0.5,
  trunc.pow = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cppls.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_y.add">Y.add</code></td>
<td>
<p>a vector or matrix of additional responses containing relevant
information about the observations.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_lower">lower</code></td>
<td>
<p>a vector of lower limits for power optimisation. Defaults to
<code>0.5</code>.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_upper">upper</code></td>
<td>
<p>a vector of upper limits for power optimisation. Defaults to
<code>0.5</code>.</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_trunc.pow">trunc.pow</code></td>
<td>
<p>logical. If <code>TRUE</code> an experimental alternative power
algorithm is used. (Optional)</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_weights">weights</code></td>
<td>
<p>a vector of individual weights for the observations.
(Optional)</p>
</td></tr>
<tr><td><code id="cppls.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>cppls</code> or <code>mvr</code> with the argument
<code>method="cppls"</code>. Canonical Powered PLS (CPPLS) is a generalisation of
PLS incorporating discrete and continuous responses (also simultaneously),
additional responses, individual weighting of observations and power
methodology for sharpening focus on groups of variables. Depending on the
input to <code>cppls</code> it can produce the following special cases: </p>

<ul>
<li><p> PLS: uni-response continuous <code>Y</code> </p>
</li>
<li><p> PPLS: uni-response
continuous <code>Y</code>, <code>(lower || upper) != 0.5</code> </p>
</li>
<li><p> PLS-DA (using
correlation maximisation - B/W): dummy-coded descrete response <code>Y</code>
</p>
</li>
<li><p> PPLS-DA: dummy-coded descrete response <code>Y</code>, <code>(lower ||
upper) != 0.5</code> </p>
</li>
<li><p> CPLS: multi-response <code>Y</code> (continuous, discrete or
combination) </p>
</li>
<li><p> CPPLS: multi-response <code>Y</code> (continuous, discrete or
combination), <code>(lower || upper) != 0.5</code> </p>
</li></ul>
<p> The name &quot;canonical&quot; comes
from canonical correlation analysis which is used when calculating vectors
of loading weights, while &quot;powered&quot; refers to a reparameterisation of the
vectors of loading weights which can be optimised over a given interval.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td></tr>
<tr><td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td></tr>
<tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td></tr> <tr><td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>total variance in <code>X</code>.</p>
</td></tr>
<tr><td><code>gammas</code></td>
<td>
<p>gamma-values obtained in power optimisation.</p>
</td></tr>
<tr><td><code>canonical.correlations</code></td>
<td>
<p>Canonical correlation values from the
calculations of loading weights.</p>
</td></tr> <tr><td><code>A</code></td>
<td>
<p>matrix containing vectors of
weights <code>a</code> from canonical correlation (<code>cor(Za,Yb)</code>).</p>
</td></tr>
<tr><td><code>smallNorms</code></td>
<td>
<p>vector of indices of explanatory variables of length close
to or equal to 0.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code>, <code>Ymeans</code> and <code>gammas</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Kristian Hovde Liland
</p>


<h3>References</h3>

<p>Indahl, U. (2005) A twist to partial least squares regression.
<em>Journal of Chemometrics</em>, <b>19</b>, 32&ndash;44.
</p>
<p>Liland, K.H and Indahl, U.G (2009) Powered partial least squares
discriminant analysis, <em>Journal of Chemometrics</em>, <b>23</b>, 7&ndash;18.
</p>
<p>Indahl, U.G., Liland, K.H. and Næs, T. (2009) Canonical partial least
squares - a unified PLS approach to classification and regression problems.
<em>Journal of Chemometrics</em>, <b>23</b>, 495&ndash;504.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+pcr">pcr</a></code>
<code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code> <code><a href="#topic+simpls.fit">simpls.fit</a></code>
<code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mayonnaise)
# Create dummy response
mayonnaise$dummy &lt;-
    I(model.matrix(~y-1, data.frame(y = factor(mayonnaise$oil.type))))

# Predict CPLS scores for test data
may.cpls &lt;- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train)
may.test &lt;- predict(may.cpls, newdata = mayonnaise[!mayonnaise$train,], type = "score")

# Predict CPLS scores for test data (experimental used design as additional Y information)
may.cpls.yadd &lt;- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train, Y.add=design)
may.test.yadd &lt;- predict(may.cpls.yadd, newdata = mayonnaise[!mayonnaise$train,], type = "score")

# Classification by linear discriminant analysis (LDA)
library(MASS)
error &lt;- matrix(ncol = 10, nrow = 2)
dimnames(error) &lt;- list(Model = c('CPLS', 'CPLS (Y.add)'), ncomp = 1:10)
for (i in 1:10) {
    fitdata1 &lt;- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],
                           NIR.score = I(may.cpls$scores[,1:i,drop=FALSE]))
    testdata1 &lt;- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],
                            NIR.score = I(may.test[,1:i,drop=FALSE]))
    error[1,i] &lt;-
        (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata1),
                  newdata = testdata1)$class == testdata1$oil.type)) / 42
    fitdata2 &lt;- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],
                           NIR.score = I(may.cpls.yadd$scores[,1:i,drop=FALSE]))
    testdata2 &lt;- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],
                            NIR.score = I(may.test.yadd[,1:i,drop=FALSE]))
    error[2,i] &lt;-
        (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata2),
                  newdata = testdata2)$class == testdata2$oil.type)) / 42
}
round(error,2)

</code></pre>

<hr>
<h2 id='crossval'>Cross-validation of PLSR and PCR models</h2><span id='topic+crossval'></span>

<h3>Description</h3>

<p>A &ldquo;stand alone&rdquo; cross-validation function for <code>mvr</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crossval(
  object,
  segments = 10,
  segment.type = c("random", "consecutive", "interleaved"),
  length.seg,
  jackknife = FALSE,
  trace = 15,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crossval_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object; the regression to cross-validate.</p>
</td></tr>
<tr><td><code id="crossval_+3A_segments">segments</code></td>
<td>
<p>the number of segments to use, or a list with segments (see
below).</p>
</td></tr>
<tr><td><code id="crossval_+3A_segment.type">segment.type</code></td>
<td>
<p>the type of segments to use.  Ignored if <code>segments</code>
is a list.</p>
</td></tr>
<tr><td><code id="crossval_+3A_length.seg">length.seg</code></td>
<td>
<p>Positive integer.  The length of the segments to use.  If
specified, it overrides <code>segments</code> unless <code>segments</code> is a list.</p>
</td></tr>
<tr><td><code id="crossval_+3A_jackknife">jackknife</code></td>
<td>
<p>logical.  Whether jackknifing of regression coefficients
should be performed.</p>
</td></tr>
<tr><td><code id="crossval_+3A_trace">trace</code></td>
<td>
<p>if <code>TRUE</code>, tracing is turned on.  If numeric, it denotes a
time limit (in seconds).  If the estimated total time of the
cross-validation exceeds this limit, tracing is turned on.</p>
</td></tr>
<tr><td><code id="crossval_+3A_...">...</code></td>
<td>
<p>additional arguments, sent to the underlying fit function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs cross-validation on a model fit by <code>mvr</code>.  It
can handle models such as <code>plsr(y ~ msc(X), ...{})</code> or other models
where the predictor variables need to be recalculated for each segment.
When recalculation is not needed, the result of
<code>crossval(mvr(...{}))</code> is identical to <code>mvr(...{}, validation
= "CV")</code>, but slower.
</p>
<p>Note that to use <code>crossval</code>, the data <em>must</em> be specified with a
<code>data</code> argument when fitting <code>object</code>.
</p>
<p>If <code>segments</code> is a list, the arguments <code>segment.type</code> and
<code>length.seg</code> are ignored.  The elements of the list should be integer
vectors specifying the indices of the segments.  See
<code><a href="#topic+cvsegments">cvsegments</a></code> for details.
</p>
<p>Otherwise, segments of type <code>segment.type</code> are generated.  How many
segments to generate is selected by specifying the number of segments in
<code>segments</code>, or giving the segment length in <code>length.seg</code>.  If both
are specified, <code>segments</code> is ignored.
</p>
<p>If <code>jackknife</code> is <code>TRUE</code>, jackknifed regression coefficients are
returned, which can be used for for variance estimation
(<code><a href="#topic+var.jack">var.jack</a></code>) or hypothesis testing (<code><a href="#topic+jack.test">jack.test</a></code>).
</p>
<p>When tracing is turned on, the segment number is printed for each segment.
</p>
<p>By default, the cross-validation will be performed serially.  However, it
can be done in parallel using functionality in the <code><a href="lattice.html#topic+parallel">parallel</a></code>
package by setting the option <code>parallel</code> in <code><a href="#topic+pls.options">pls.options</a></code>.
See <code><a href="#topic+pls.options">pls.options</a></code> for the different ways to specify the
parallelism.  See also Examples below.
</p>


<h3>Value</h3>

<p>The supplied <code>object</code> is returned, with an additional component
<code>validation</code>, which is a list with components </p>
<table>
<tr><td><code>method</code></td>
<td>
<p>euqals
<code>"CV"</code> for cross-validation.</p>
</td></tr> <tr><td><code>pred</code></td>
<td>
<p>an array with the
cross-validated predictions.</p>
</td></tr> <tr><td><code>coefficients</code></td>
<td>
<p>(only if <code>jackknife</code>
is <code>TRUE</code>) an array with the jackknifed regression coefficients.  The
dimensions correspond to the predictors, responses, number of components,
and segments, respectively.</p>
</td></tr> <tr><td><code>PRESS0</code></td>
<td>
<p>a vector of PRESS values (one for
each response variable) for a model with zero components, i.e., only the
intercept.</p>
</td></tr> <tr><td><code>PRESS</code></td>
<td>
<p>a matrix of PRESS values for models with 1,
..., <code>ncomp</code> components.  Each row corresponds to one response
variable.</p>
</td></tr> <tr><td><code>adj</code></td>
<td>
<p>a matrix of adjustment values for calculating bias
corrected MSEP.  <code>MSEP</code> uses this.</p>
</td></tr> <tr><td><code>segments</code></td>
<td>
<p>the list of
segments used in the cross-validation.</p>
</td></tr> <tr><td><code>ncomp</code></td>
<td>
<p>the number of
components.</p>
</td></tr> <tr><td><code>gammas</code></td>
<td>
<p>if method <code>cppls</code> is used, gamma values for
the powers of each CV segment are returned.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>PRESS0</code> is always cross-validated using leave-one-out
cross-validation.  This usually makes little difference in practice, but
should be fixed for correctness.
</p>
<p>The current implementation of the jackknife stores all jackknife-replicates
of the regression coefficients, which can be very costly for large matrices.
This might change in a future version.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error of
Prediction (MSEP) Estimates for Principal Component Regression (PCR) and
Partial Least Squares Regression (PLSR).  <em>Journal of Chemometrics</em>,
<b>18</b>(9), 422&ndash;429.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+mvrCv">mvrCv</a></code> <code><a href="#topic+cvsegments">cvsegments</a></code>
<code><a href="#topic+MSEP">MSEP</a></code> <code><a href="#topic+var.jack">var.jack</a></code> <code><a href="#topic+jack.test">jack.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
yarn.pcr &lt;- pcr(density ~ msc(NIR), 6, data = yarn)
yarn.cv &lt;- crossval(yarn.pcr, segments = 10)
## Not run: plot(MSEP(yarn.cv))

## Not run: 
## Parallelised cross-validation, using transient cluster:
pls.options(parallel = 4) # use mclapply (not available on Windows)
pls.options(parallel = quote(parallel::makeCluster(4, type = "PSOCK"))) # parLapply
## A new cluster is created and stopped for each cross-validation:
yarn.cv &lt;- crossval(yarn.pcr)
yarn.loocv &lt;- crossval(yarn.pcr, length.seg = 1)

## Parallelised cross-validation, using persistent cluster:
library(parallel)
## This creates the cluster:
pls.options(parallel = makeCluster(4, type = "FORK")) # not available on Windows
pls.options(parallel = makeCluster(4, type = "PSOCK"))
## The cluster can be used several times:
yarn.cv &lt;- crossval(yarn.pcr)
yarn.loocv &lt;- crossval(yarn.pcr, length.seg = 1)
## The cluster should be stopped manually afterwards:
stopCluster(pls.options()$parallel)

## Parallelised cross-validation, using persistent MPI cluster:
## This requires the packages snow and Rmpi to be installed
library(parallel)
## This creates the cluster:
pls.options(parallel = makeCluster(4, type = "MPI"))
## The cluster can be used several times:
yarn.cv &lt;- crossval(yarn.pcr)
yarn.loocv &lt;- crossval(yarn.pcr, length.seg = 1)
## The cluster should be stopped manually afterwards:
stopCluster(pls.options()$parallel)
## It is good practice to call mpi.exit() or mpi.quit() afterwards:
mpi.exit()

## End(Not run)

</code></pre>

<hr>
<h2 id='cvsegments'>Generate segments for cross-validation</h2><span id='topic+cvsegments'></span>

<h3>Description</h3>

<p>The function generates a list of segments for cross-validation.  It can
generate random, consecutive and interleaved segments, and supports keeping
replicates in the same segment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvsegments(
  N,
  k,
  length.seg = ceiling(N/k),
  nrep = 1,
  type = c("random", "consecutive", "interleaved"),
  stratify = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvsegments_+3A_n">N</code></td>
<td>
<p>Integer.  The number of rows in the data set.</p>
</td></tr>
<tr><td><code id="cvsegments_+3A_k">k</code></td>
<td>
<p>Integer.  The number of segments to return.</p>
</td></tr>
<tr><td><code id="cvsegments_+3A_length.seg">length.seg</code></td>
<td>
<p>Integer.  The length of the segments.  If given, it
overrides <code>k</code>.</p>
</td></tr>
<tr><td><code id="cvsegments_+3A_nrep">nrep</code></td>
<td>
<p>Integer.  The number of (consecutive) rows that are replicates
of the same object.  Replicates will always be kept in the same segment.</p>
</td></tr>
<tr><td><code id="cvsegments_+3A_type">type</code></td>
<td>
<p>One of <code>"random"</code>, <code>"consecutive"</code> and
<code>"interleaved"</code>.  The type of segments to generate.  Default is
<code>"random"</code>.</p>
</td></tr>
<tr><td><code id="cvsegments_+3A_stratify">stratify</code></td>
<td>
<p>Either a <code>list</code> of indices or an integer <code>vector</code>
indicating which stratum each sample (or set of replicates) belongs to (see
Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>length.seg</code> is specified, it is used to calculate the number of
segments to generate.  Otherwise <code>k</code> must be specified.  If
<code class="reqn">k*length.seg \ne N</code>, the <code class="reqn">k*length.seg - N</code> last
segments will contain only <code class="reqn">length.seg - 1</code> indices.
</p>
<p>If <code>type</code> is <code>"random"</code>, the indices are allocated to segments in
random order.  If it is <code>"consecutive"</code>, the first segment will contain
the first <code class="reqn">length.seg</code> indices, and so on.  If <code>type</code> is
<code>"interleaved"</code>, the first segment will contain the indices <code class="reqn">1,
length.seg+1, 2*lenght.seg+1, \ldots, (k-1)*length.seg+1</code>, and so on.
</p>
<p>If <code class="reqn">nrep &gt; </code>, it is assumed that each <code>nrep</code> consecutive rows are
replicates (repeated measurements) of the same object, and care is taken
that replicates are never put in different segments.
</p>
<p>Warning: If <code>k</code> does not divide <code>N</code>, a specified <code>length.seg</code>
does not divide <code>N</code>, or <code>nrep</code> does not divide <code>length.seg</code>,
the number of segments and/or the segment length will be adjusted as needed.
Warnings are printed for some of these cases, and one should always inspect
the resulting segments to make sure they are as expected.
</p>
<p>Stratification of samples is enabled by the <code>stratify</code> argument.  This
is useful if there are sub-groups in the data set that should have a
proportional representation in the cross-validation segments or if the
response is categorical (classifiation). If <code>stratify</code> is combined with
<code>nrep</code>, <code>stratify</code> corresponds to the sets of replicates (see
example).
</p>


<h3>Value</h3>

<p>A list of vectors.  Each vector contains the indices for one
segment.  The attribute <code>"incomplete"</code> contains the number of
incomplete segments, and the attribute <code>"type"</code> contains the type of
segments.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik, Ron Wehrens and Kristian Hovde Liland
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Segments for 10-fold randomised cross-validation:
cvsegments(100, 10)

## Segments with four objects, taken consecutive:
cvsegments(60, length.seg = 4, type = "cons")

## Incomplete segments
segs &lt;- cvsegments(50, length.seg = 3)
attr(segs, "incomplete")

## Leave-one-out cross-validation:
cvsegments(100, 100)
## Leave-one-out with variable/unknown data set size n:
n &lt;- 50
cvsegments(n, length.seg = 1)

## Data set with replicates
cvsegments(100, 25, nrep = 2)
## Note that rows 1 and 2 are in the same segment, rows 3 and 4 in the
## same segment, and so on.

## Stratification
cvsegments(10, 3, type = "consecutive", stratify = c(rep(1,7), rep(2,3)))
## Note that the last three samples are spread across the segments
## according to the stratification vector.
cvsegments(20, 3, type = "consecutive", nrep = 2, stratify = c(rep(1,7), rep(2,3)))
## Note the length of stratify matching number of replicate sets, not samples.

</code></pre>

<hr>
<h2 id='delete.intercept'>Delete intercept from model matrix</h2><span id='topic+delete.intercept'></span>

<h3>Description</h3>

<p>A utility function to delete any intercept column from a model matrix, and
adjust the <code>"assign"</code> attribute correspondingly.  It is used by formula
handling functions like <code>mvr</code> and <code>model.matrix.mvr</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delete.intercept(mm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete.intercept_+3A_mm">mm</code></td>
<td>
<p>Model matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A model matrix without intercept column.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik and Ron Wehrens
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+model.matrix.mvr">model.matrix.mvr</a></code>
</p>

<hr>
<h2 id='gasoline'>Octane numbers and NIR spectra of gasoline</h2><span id='topic+gasoline'></span>

<h3>Description</h3>

<p>A data set with NIR spectra and octane numbers of 60 gasoline samples.  The
NIR spectra were measured using diffuse reflectance as log(1/R) from 900 nm
to 1700 nm in 2 nm intervals, giving 401 wavelengths.  Many thanks to John
H. Kalivas.
</p>


<h3>Format</h3>

<p>A data frame with 60 observations on the following 2 variables.
</p>
 <dl>
<dt>octane</dt><dd><p>a numeric vector.  The octane number.</p>
</dd>
<dt>NIR</dt><dd><p>a matrix with 401 columns.  The NIR spectrum.</p>
</dd> </dl>



<h3>Source</h3>

<p>Kalivas, John H. (1997) Two Data Sets of Near Infrared Spectra
<em>Chemometrics and Intelligent Laboratory Systems</em>, <b>37</b>, 255&ndash;259.
</p>

<hr>
<h2 id='jack.test'>Jackknife approximate t tests of regression coefficients</h2><span id='topic+jack.test'></span><span id='topic+print.jacktest'></span>

<h3>Description</h3>

<p>Performes approximate t tests of regression coefficients based on jackknife
variance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jack.test(object, ncomp = object$ncomp, use.mean = TRUE)

## S3 method for class 'jacktest'
print(x, P.values = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jack.test_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.  A cross-validated model fitted with
<code>jackknife = TRUE</code>.</p>
</td></tr>
<tr><td><code id="jack.test_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to use for estimating the variances</p>
</td></tr>
<tr><td><code id="jack.test_+3A_use.mean">use.mean</code></td>
<td>
<p>logical.  If <code>TRUE</code> (default), the mean coefficients
are used when estimating the (co)variances; otherwise the coefficients from
a model fitted to the entire data set.  See <code><a href="#topic+var.jack">var.jack</a></code> for
details.</p>
</td></tr>
<tr><td><code id="jack.test_+3A_x">x</code></td>
<td>
<p>an <code>jacktest</code> object, the result of <code>jack.test</code>.</p>
</td></tr>
<tr><td><code id="jack.test_+3A_p.values">P.values</code></td>
<td>
<p>logical.  Whether to print <code class="reqn">p</code> values (default).</p>
</td></tr>
<tr><td><code id="jack.test_+3A_...">...</code></td>
<td>
<p>Further arguments sent to the underlying print function
<code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>jack.test</code> uses the variance estimates from <code>var.jack</code> to perform
<code class="reqn">t</code> tests of the regression coefficients.  The resulting object has a
print method, <code>print.jacktest</code>, which uses <code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>
for the actual printing.
</p>


<h3>Value</h3>

<p><code>jack.test</code> returns an object of class <code>"jacktest"</code>, with
components </p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>The estimated regression coefficients</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>The square root of the jackknife variance estimates</p>
</td></tr>
<tr><td><code>tvalues</code></td>
<td>
<p>The <code class="reqn">t</code> statistics</p>
</td></tr> <tr><td><code>df</code></td>
<td>
<p>The &lsquo;degrees of freedom&rsquo;
used for calculating <code class="reqn">p</code> values</p>
</td></tr> <tr><td><code>pvalues</code></td>
<td>
<p>The calculated <code class="reqn">p</code>
values</p>
</td></tr>
</table>
<p><code>print.jacktest</code> returns the <code>"jacktest"</code> object (invisibly).
</p>


<h3>Warning</h3>

<p>The jackknife variance estimates are known to be biased
(see <code><a href="#topic+var.jack">var.jack</a></code>).  Also, the distribution of the regression
coefficient estimates and the jackknife variance estimates are unknown (at
least in PLSR/PCR).  Consequently, the distribution (and in particular, the
degrees of freedom) of the resulting <code class="reqn">t</code> statistics is unknown.  The
present code simply assumes a <code class="reqn">t</code> distribution with <code class="reqn">m - 1</code> degrees
of freedom, where <code class="reqn">m</code> is the number of cross-validation segments.
</p>
<p>Therefore, the resulting <code class="reqn">p</code> values should not be used uncritically, and
should perhaps be regarded as mere indicator of (non-)significance.
</p>
<p>Finally, also keep in mind that as the number of predictor variables
increase, the problem of multiple tests increases correspondingly.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Martens H. and Martens M. (2000) Modified Jack-knife Estimation
of Parameter Uncertainty in Bilinear Modelling by Partial Least Squares
Regression (PLSR).  <em>Food Quality and Preference</em>, <b>11</b>, 5&ndash;16.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+var.jack">var.jack</a></code>, <code><a href="#topic+mvrCv">mvrCv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oliveoil)
mod &lt;- pcr(sensory ~ chemical, data = oliveoil, validation = "LOO", jackknife = TRUE)
jack.test(mod, ncomp = 2)

</code></pre>

<hr>
<h2 id='kernelpls.fit'>Kernel PLS (Dayal and MacGregor)</h2><span id='topic+kernelpls.fit'></span>

<h3>Description</h3>

<p>Fits a PLSR model with the kernel algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernelpls.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernelpls.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="kernelpls.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="kernelpls.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="kernelpls.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="kernelpls.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="kernelpls.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>plsr</code> or <code>mvr</code> with the argument
<code>method="kernelpls"</code> (default).  Kernel PLS is particularly efficient
when the number of objects is (much) larger than the number of variables.
The results are equal to the NIPALS algorithm.  Several different forms of
kernel PLS have been described in literature, e.g.  by De Jong and Ter
Braak, and two algorithms by Dayal and MacGregor.  This function implements
the fastest of the latter, not calculating the crossproduct matrix of X.  In
the Dyal &amp; MacGregor paper, this is &ldquo;algorithm 1&rdquo;.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td></tr>
<tr><td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td></tr>
<tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td></tr> <tr><td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in <code>X</code>.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>de Jong, S. and ter Braak, C. J. F. (1994) Comments on the PLS
kernel algorithm.  <em>Journal of Chemometrics</em>, <b>8</b>, 169&ndash;174.
</p>
<p>Dayal, B. S. and MacGregor, J. F. (1997) Improved PLS algorithms.
<em>Journal of Chemometrics</em>, <b>11</b>, 73&ndash;85.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+cppls">cppls</a></code>
<code><a href="#topic+pcr">pcr</a></code> <code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code> <code><a href="#topic+simpls.fit">simpls.fit</a></code>
<code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code>
</p>

<hr>
<h2 id='mayonnaise'>NIR measurements and oil types of mayonnaise</h2><span id='topic+mayonnaise'></span>

<h3>Description</h3>

<p>Raw NIR measurements (351 wavelengths, 1100-2500 nm in steps of 4 nm) taken
on 54 samples of mayonnaise based on six different oil types (soybean,
sunflower, canola, olive, corn, and grapeseed). The resulting 54 samples
were measured in triplicates, resulting in 54 x 3 = 162 different spectra
(120/42 training/test).
</p>


<h3>Format</h3>

<p>A data frame with 162 observations on the following 4 variables.
</p>
 <dl>
<dt>NIR</dt><dd><p>a matrix with 351 columns</p>
</dd>
<dt>oil.type</dt><dd><p>a numeric vector</p>
</dd> <dt>design</dt><dd><p>a matrix
with 5 columns</p>
</dd> <dt>train</dt><dd><p>a logical vector</p>
</dd> </dl>



<h3>Source</h3>

<p>Indahl U, Sahni NS, Kirkhus B, Næs T.  Multivariate strategies for
classification based on NIR-spectra-with application to mayonnaise.
Chemometr. Intell. Lab. Sys. 1999; 49: 19-31.
</p>

<hr>
<h2 id='msc'>Multiplicative Scatter Correction</h2><span id='topic+msc'></span><span id='topic+predict.msc'></span><span id='topic+makepredictcall.msc'></span>

<h3>Description</h3>

<p>Performs multiplicative scatter/signal correction on a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msc(X, reference = NULL)

## S3 method for class 'msc'
predict(object, newdata, ...)

## S3 method for class 'msc'
makepredictcall(var, call)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msc_+3A_x">X</code>, <code id="msc_+3A_newdata">newdata</code></td>
<td>
<p>numeric matrices.  The data to scatter correct.</p>
</td></tr>
<tr><td><code id="msc_+3A_reference">reference</code></td>
<td>
<p>numeric vector.  Spectre to use as reference.  If
<code>NULL</code>, the column means of <code>X</code> are used.</p>
</td></tr>
<tr><td><code id="msc_+3A_object">object</code></td>
<td>
<p>an object inheriting from class <code>"msc"</code>, normally the
result of a call to <code>msc</code> with a single matrix argument.</p>
</td></tr>
<tr><td><code id="msc_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
<tr><td><code id="msc_+3A_var">var</code></td>
<td>
<p>A variable.</p>
</td></tr>
<tr><td><code id="msc_+3A_call">call</code></td>
<td>
<p>The term in the formula, as a call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>makepredictcall.msc</code> is an internal utility function; it is not meant
for interactive use.  See <code><a href="stats.html#topic+makepredictcall">makepredictcall</a></code> for details.
</p>


<h3>Value</h3>

<p>Both <code>msc</code> and <code>predict.msc</code> return a multiplicative
scatter corrected matrix, with attribute <code>"reference"</code> the vector used
as reference spectre. The matrix is given class <code>c("msc", "matrix")</code>.
For <code>predict.msc</code>, the <code>"reference"</code> attribute of <code>object</code> is
used as reference spectre.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik and Ron Wehrens
</p>


<h3>References</h3>

<p>Martens, H., Næs, T. (1989) <em>Multivariate calibration.</em>
Chichester: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+pcr">pcr</a></code>, <code><a href="#topic+plsr">plsr</a></code>,
<code><a href="#topic+stdize">stdize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
## Direct correction:
Ztrain &lt;- msc(yarn$NIR[yarn$train,])
Ztest &lt;- predict(Ztrain, yarn$NIR[!yarn$train,])

## Used in formula:
mod &lt;- plsr(density ~ msc(NIR), ncomp = 6, data = yarn[yarn$train,])
pred &lt;- predict(mod, newdata = yarn[!yarn$train,]) # Automatically scatter corrected

</code></pre>

<hr>
<h2 id='mvr'>Partial Least Squares and Principal Component Regression</h2><span id='topic+mvr'></span><span id='topic+pcr'></span><span id='topic+plsr'></span><span id='topic+cppls'></span>

<h3>Description</h3>

<p>Functions to perform partial least squares regression (PLSR), canonical
powered partial least squares (CPPLS) or principal component regression
(PCR), with a formula interface.  Cross-validation can be used.  Prediction,
model extraction, plot, print and summary methods exist.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvr(
  formula,
  ncomp,
  Y.add,
  data,
  subset,
  na.action,
  method = pls.options()$mvralg,
  scale = FALSE,
  center = TRUE,
  validation = c("none", "CV", "LOO"),
  model = TRUE,
  x = FALSE,
  y = FALSE,
  ...
)

plsr(..., method = pls.options()$plsralg)

pcr(..., method = pls.options()$pcralg)

cppls(..., Y.add, weights, method = pls.options()$cpplsalg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvr_+3A_formula">formula</code></td>
<td>
<p>a model formula.  Most of the <code><a href="stats.html#topic+lm">lm</a></code> formula
constructs are supported.  See below.</p>
</td></tr>
<tr><td><code id="mvr_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to include in the model (see below).</p>
</td></tr>
<tr><td><code id="mvr_+3A_y.add">Y.add</code></td>
<td>
<p>a vector or matrix of additional responses containing relevant
information about the observations.  Only used for <code>cppls</code>.</p>
</td></tr>
<tr><td><code id="mvr_+3A_data">data</code></td>
<td>
<p>an optional data frame with the data to fit the model from.</p>
</td></tr>
<tr><td><code id="mvr_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="mvr_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain missing values.  The default is set by the <code>na.action</code> setting
of <code><a href="base.html#topic+options">options</a></code>, and is <code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.
The &lsquo;factory-fresh&rsquo; default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another
possible value is <code>NULL</code>, no action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code>
can be useful.  See <code><a href="stats.html#topic+na.omit">na.omit</a></code> for other alternatives.</p>
</td></tr>
<tr><td><code id="mvr_+3A_method">method</code></td>
<td>
<p>the multivariate regression method to be used.  If
<code>"model.frame"</code>, the model frame is returned.</p>
</td></tr>
<tr><td><code id="mvr_+3A_scale">scale</code></td>
<td>
<p>numeric vector, or logical.  If numeric vector, <code class="reqn">X</code> is
scaled by dividing each variable with the corresponding element of
<code>scale</code>.  If <code>scale</code> is <code>TRUE</code>, <code class="reqn">X</code> is scaled by dividing
each variable by its sample standard deviation.  If cross-validation is
selected, scaling by the standard deviation is done for every segment.</p>
</td></tr>
<tr><td><code id="mvr_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="mvr_+3A_validation">validation</code></td>
<td>
<p>character.  What kind of (internal) validation to use.
See below.</p>
</td></tr>
<tr><td><code id="mvr_+3A_model">model</code></td>
<td>
<p>a logical.  If <code>TRUE</code>, the model frame is returned.</p>
</td></tr>
<tr><td><code id="mvr_+3A_x">x</code></td>
<td>
<p>a logical.  If <code>TRUE</code>, the model matrix is returned.</p>
</td></tr>
<tr><td><code id="mvr_+3A_y">y</code></td>
<td>
<p>a logical.  If <code>TRUE</code>, the response is returned.</p>
</td></tr>
<tr><td><code id="mvr_+3A_...">...</code></td>
<td>
<p>additional optional arguments, passed to the underlying fit
functions, and <code><a href="#topic+mvrCv">mvrCv</a></code>.
</p>
<p>Currently, the fit functions <code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code> and
<code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code> implement these extra arguments: </p>

<dl>
<dt>tol:</dt><dd><p>numeric.  Tolerance used for determining convergence.</p>
</dd>
<dt>maxit:</dt><dd><p>positive integer.  The maximal number of iterations used.</p>
</dd> </dl>

<p>and <code><a href="#topic+cppls.fit">cppls.fit</a></code> implements: </p>
 <dl>
<dt>lower:</dt><dd><p>a vector of
lower limits for power optimisation.</p>
</dd> <dt>upper:</dt><dd><p>a vector of upper limits
for power optimisation.</p>
</dd> <dt>trunc.pow:</dt><dd><p>logical. Whether to use an
experimental alternative power algorithm.</p>
</dd> </dl>
 <p><code><a href="#topic+mvrCv">mvrCv</a></code> implements
several arguments; the following are probably the most useful of them:
</p>
 <dl>
<dt>segments:</dt><dd><p>the number of segments to use, or a list with
segments.</p>
</dd> <dt>segment.type:</dt><dd><p>the type of segments to use.</p>
</dd>
<dt>length.seg:</dt><dd><p>Positive integer.  The length of the segments to use.</p>
</dd>
<dt>jackknife:</dt><dd><p>logical.  Whether to perform jackknifing of regression
coefficients.</p>
</dd> </dl>

<p>See the functions' documentation for details.</p>
</td></tr>
<tr><td><code id="mvr_+3A_weights">weights</code></td>
<td>
<p>a vector of individual weights for the observations.  Only
used for <code>cppls</code>.  (Optional)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions fit PLSR, CPPLS or PCR models with 1, <code class="reqn">\ldots</code>,
<code>ncomp</code> number of components.  Multi-response models are fully
supported.
</p>
<p>The type of model to fit is specified with the <code>method</code> argument. Four
PLSR algorithms are available: the kernel algorithm (<code>"kernelpls"</code>),
the wide kernel algorithm (<code>"widekernelpls"</code>), SIMPLS (<code>"simpls"</code>)
and the classical orthogonal scores algorithm (<code>"oscorespls"</code>). One
CPPLS algorithm is available (<code>"cppls"</code>) providing several extensions
to PLS. One PCR algorithm is available: using the singular value
decomposition (<code>"svdpc"</code>).  If <code>method</code> is <code>"model.frame"</code>,
the model frame is returned.  The functions <code>pcr</code>, <code>plsr</code> and
<code>cppls</code> are wrappers for <code>mvr</code>, with different values for
<code>method</code>.
</p>
<p>The <code>formula</code> argument should be a symbolic formula of the form
<code>response ~ terms</code>, where <code>response</code> is the name of the response
vector or matrix (for multi-response models) and <code>terms</code> is the name of
one or more predictor matrices, usually separated by <code>+</code>, e.g.,
<code>water ~ FTIR</code> or <code>y ~ X + Z</code>.  See <code><a href="stats.html#topic+lm">lm</a></code> for a
detailed description.  The named variables should exist in the supplied
<code>data</code> data frame or in the global environment.  Note: Do not use
<code>mvr(mydata$y ~ mydata$X, ...{})</code>, instead use <code>mvr(y ~ X, data
= mydata, ...{})</code>.  Otherwise, <code><a href="#topic+predict.mvr">predict.mvr</a></code> will not work
properly.  The chapter &lsquo;<span class="samp">&#8288;Statistical models in R&#8288;</span>&rsquo; of the manual &lsquo;<span class="samp">&#8288;An
Introduction to R&#8288;</span>&rsquo; distributed with is a good reference on formulas in .
</p>
<p>The number of components to fit is specified with the argument <code>ncomp</code>.
It this is not supplied, the maximal number of components is used (taking
account of any cross-validation).
</p>
<p>All implemented algorithms mean-center both predictor and response matrices.
This can be turned off by specifying <code>center = FALSE</code>.  See Seasholtz
and Kowalski for a discussion about centering in PLS regression.
</p>
<p>If <code>validation = "CV"</code>, cross-validation is performed.  The number and
type of cross-validation segments are specified with the arguments
<code>segments</code> and <code>segment.type</code>.  See <code><a href="#topic+mvrCv">mvrCv</a></code> for
details.  If <code>validation = "LOO"</code>, leave-one-out cross-validation is
performed.  It is an error to specify the segments when <code>validation =
"LOO"</code> is specified.
</p>
<p>By default, the cross-validation will be performed serially.  However, it
can be done in parallel using functionality in the <code><a href="lattice.html#topic+parallel">parallel</a></code>
package by setting the option <code>parallel</code> in <code><a href="#topic+pls.options">pls.options</a></code>.
See <code><a href="#topic+pls.options">pls.options</a></code> for the differnt ways to specify the
parallelism.  See also Examples below.
</p>
<p>Note that the cross-validation is optimised for speed, and some generality
has been sacrificed.  Especially, the model matrix is calculated only once
for the complete cross-validation, so models like <code>y ~ msc(X)</code> will not
be properly cross-validated.  However, scaling requested by <code>scale =
TRUE</code> is properly cross-validated.  For proper cross-validation of models
where the model matrix must be updated/regenerated for each segment, use the
separate function <code><a href="#topic+crossval">crossval</a></code>.
</p>


<h3>Value</h3>

<p>If <code>method = "model.frame"</code>, the model frame is returned.
Otherwise, an object of class <code>mvr</code> is returned.  The object contains
all components returned by the underlying fit function.  In addition, it
contains the following components: </p>
<table>
<tr><td><code>validation</code></td>
<td>
<p>if validation was
requested, the results of the cross-validation.  See <code><a href="#topic+mvrCv">mvrCv</a></code> for
details.</p>
</td></tr> <tr><td><code>fit.time</code></td>
<td>
<p>the elapsed time for the fit.  This is used by
<code><a href="#topic+crossval">crossval</a></code> to decide whether to turn on tracing.</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>if observations with missing values were removed,
<code>na.action</code> contains a vector with their indices.  The class of this
vector is used by functions like <code>fitted</code> to decide how to treat the
observations.</p>
</td></tr> <tr><td><code>ncomp</code></td>
<td>
<p>the number of components of the model.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the method used to fit the model.  See the argument
<code>method</code> for possible values.</p>
</td></tr> <tr><td><code>center</code></td>
<td>
<p>use of centering in the model</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>if scaling was requested
(with <code>scale</code>), the scaling used.</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the model terms.</p>
</td></tr> <tr><td><code>model</code></td>
<td>
<p>if <code>model = TRUE</code>, the
model frame.</p>
</td></tr> <tr><td><code>x</code></td>
<td>
<p>if <code>x = TRUE</code>, the model matrix.</p>
</td></tr> <tr><td><code>y</code></td>
<td>
<p>if
<code>y = TRUE</code>, the model response.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Martens, H., Næs, T. (1989) <em>Multivariate calibration.</em>
Chichester: Wiley.
</p>
<p>Seasholtz, M. B. and Kowalski, B. R. (1992) The effect of mean centering on
prediction in multivariate calibration.  <em>Journal of Chemometrics</em>,
<b>6</b>(2), 103&ndash;111.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code>, <code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code>,
<code><a href="#topic+simpls.fit">simpls.fit</a></code>, <code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code>,
<code><a href="#topic+cppls.fit">cppls.fit</a></code>, <code><a href="#topic+svdpc.fit">svdpc.fit</a></code>, <code><a href="#topic+mvrCv">mvrCv</a></code>,
<code><a href="#topic+crossval">crossval</a></code>, <code><a href="stats.html#topic+loadings">loadings</a></code>, <code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+loading.weights">loading.weights</a></code>, <code><a href="#topic+coef.mvr">coef.mvr</a></code>,
<code><a href="#topic+predict.mvr">predict.mvr</a></code>, <code><a href="#topic+R2">R2</a></code>, <code><a href="#topic+MSEP">MSEP</a></code>,
<code><a href="#topic+RMSEP">RMSEP</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
## Default methods:
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn, validation = "CV")
yarn.pls &lt;- plsr(density ~ NIR, 6, data = yarn, validation = "CV")
yarn.cppls &lt;- cppls(density ~ NIR, 6, data = yarn, validation = "CV")

## Alternative methods:
yarn.oscorespls &lt;- mvr(density ~ NIR, 6, data = yarn, validation = "CV",
                      method = "oscorespls")
yarn.simpls &lt;- mvr(density ~ NIR, 6, data = yarn, validation = "CV",
                  method = "simpls")

## Not run: 
## Parallelised cross-validation, using transient cluster:
pls.options(parallel = 4) # use mclapply
pls.options(parallel = quote(makeCluster(4, type = "PSOCK"))) # use parLapply
## A new cluster is created and stopped for each cross-validation:
yarn.pls &lt;- plsr(density ~ NIR, 6, data = yarn, validation = "CV")
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn, validation = "CV")

## Parallelised cross-validation, using persistent cluster:
library(parallel)
## This creates the cluster:
pls.options(parallel = makeCluster(4, type = "PSOCK"))
## The cluster can be used several times:
yarn.pls &lt;- plsr(density ~ NIR, 6, data = yarn, validation = "CV")
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn, validation = "CV")
## The cluster should be stopped manually afterwards:
stopCluster(pls.options()$parallel)

## Parallelised cross-validation, using persistent MPI cluster:
## This requires the packages snow and Rmpi to be installed
library(parallel)
## This creates the cluster:
pls.options(parallel = makeCluster(4, type = "MPI"))
## The cluster can be used several times:
yarn.pls &lt;- plsr(density ~ NIR, 6, data = yarn, validation = "CV")
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn, validation = "CV")
## The cluster should be stopped manually afterwards:
stopCluster(pls.options()$parallel)
## It is good practice to call mpi.exit() or mpi.quit() afterwards:
mpi.exit()

## End(Not run)

## Multi-response models:
data(oliveoil)
sens.pcr &lt;- pcr(sensory ~ chemical, ncomp = 4, scale = TRUE, data = oliveoil)
sens.pls &lt;- plsr(sensory ~ chemical, ncomp = 4, scale = TRUE, data = oliveoil)

## Classification
# A classification example utilizing additional response information
# (Y.add) is found in the cppls.fit manual ('See also' above).

</code></pre>

<hr>
<h2 id='mvrCv'>Cross-validation</h2><span id='topic+mvrCv'></span>

<h3>Description</h3>

<p>Performs the cross-validation calculations for <code>mvr</code>.
</p>
<p>This function is not meant to be called directly, but through the generic
functions <code>pcr</code>, <code>plsr</code>, <code>cppls</code> or <code>mvr</code> with the
argument <code>validation</code> set to <code>"CV"</code> or <code>"LOO"</code>.  All
arguments to <code>mvrCv</code> can be specified in the generic function call.
</p>
<p>If <code>segments</code> is a list, the arguments <code>segment.type</code> and
<code>length.seg</code> are ignored.  The elements of the list should be integer
vectors specifying the indices of the segments.  See
<code><a href="#topic+cvsegments">cvsegments</a></code> for details.
</p>
<p>Otherwise, segments of type <code>segment.type</code> are generated.  How many
segments to generate is selected by specifying the number of segments in
<code>segments</code>, or giving the segment length in <code>length.seg</code>.  If both
are specified, <code>segments</code> is ignored.
</p>
<p>If <code>jackknife</code> is <code>TRUE</code>, jackknifed regression coefficients are
returned, which can be used for for variance estimation
(<code><a href="#topic+var.jack">var.jack</a></code>) or hypothesis testing (<code><a href="#topic+jack.test">jack.test</a></code>).
</p>
<p><code>X</code> and <code>Y</code> do not need to be centered.
</p>
<p>Note that this function cannot be used in situations where <code class="reqn">X</code> needs to
be recalculated for each segment (except for scaling by the standard
deviation), for instance with <code>msc</code> or other preprocessing.  For such
models, use the more general (but slower) function <code><a href="#topic+crossval">crossval</a></code>.
</p>
<p>Also note that if needed, the function will silently(!) reduce <code>ncomp</code>
to the maximal number of components that can be cross-validated, which is
<code class="reqn">n - l - 1</code>, where <code class="reqn">n</code> is the number of observations and <code class="reqn">l</code> is
the length of the longest segment.  The (possibly reduced) number of
components is returned as the component <code>ncomp</code>.
</p>
<p>By default, the cross-validation will be performed serially.  However, it
can be done in parallel using functionality in the <code><a href="lattice.html#topic+parallel">parallel</a></code>
package by setting the option <code>parallel</code> in <code><a href="#topic+pls.options">pls.options</a></code>.
See <code><a href="#topic+pls.options">pls.options</a></code> for the different ways to specify the
parallelism.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrCv(
  X,
  Y,
  ncomp,
  Y.add = NULL,
  weights = NULL,
  method = pls.options()$mvralg,
  scale = FALSE,
  segments = 10,
  segment.type = c("random", "consecutive", "interleaved"),
  length.seg,
  jackknife = FALSE,
  trace = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvrCv_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_y.add">Y.add</code></td>
<td>
<p>a vector or matrix of additional responses containing relevant
information about the observations.  Only used for <code>cppls</code>.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_weights">weights</code></td>
<td>
<p>a vector of individual weights for the observations.  Only
used for <code>cppls</code>.  (Optional)</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_method">method</code></td>
<td>
<p>the multivariate regression method to be used.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_scale">scale</code></td>
<td>
<p>logical.  If <code>TRUE</code>, the learning <code class="reqn">X</code> data for each
segment is scaled by dividing each variable by its sample standard
deviation.  The prediction data is scaled by the same amount.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_segments">segments</code></td>
<td>
<p>the number of segments to use, or a list with segments (see
below).</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_segment.type">segment.type</code></td>
<td>
<p>the type of segments to use.  Ignored if <code>segments</code>
is a list.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_length.seg">length.seg</code></td>
<td>
<p>Positive integer.  The length of the segments to use.  If
specified, it overrides <code>segments</code> unless <code>segments</code> is a list.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_jackknife">jackknife</code></td>
<td>
<p>logical.  Whether jackknifing of regression coefficients
should be performed.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_trace">trace</code></td>
<td>
<p>logical; if <code>TRUE</code>, the segment number is printed for each
segment.</p>
</td></tr>
<tr><td><code id="mvrCv_+3A_...">...</code></td>
<td>
<p>additional arguments, sent to the underlying fit function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: </p>
<table>
<tr><td><code>method</code></td>
<td>
<p>equals
<code>"CV"</code> for cross-validation.</p>
</td></tr> <tr><td><code>pred</code></td>
<td>
<p>an array with the
cross-validated predictions.</p>
</td></tr> <tr><td><code>coefficients</code></td>
<td>
<p>(only if <code>jackknife</code>
is <code>TRUE</code>) an array with the jackknifed regression coefficients.  The
dimensions correspond to the predictors, responses, number of components,
and segments, respectively.</p>
</td></tr> <tr><td><code>PRESS0</code></td>
<td>
<p>a vector of PRESS values (one for
each response variable) for a model with zero components, i.e., only the
intercept.</p>
</td></tr> <tr><td><code>PRESS</code></td>
<td>
<p>a matrix of PRESS values for models with 1,
..., <code>ncomp</code> components.  Each row corresponds to one response
variable.</p>
</td></tr> <tr><td><code>adj</code></td>
<td>
<p>a matrix of adjustment values for calculating bias
corrected MSEP.  <code>MSEP</code> uses this.</p>
</td></tr> <tr><td><code>segments</code></td>
<td>
<p>the list of
segments used in the cross-validation.</p>
</td></tr> <tr><td><code>ncomp</code></td>
<td>
<p>the actual number of
components used.</p>
</td></tr> <tr><td><code>gamma</code></td>
<td>
<p>if method <code>cppls</code> is used, gamma values
for the powers of each CV segment are returned.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>PRESS0</code> is always cross-validated using leave-one-out
cross-validation.  This usually makes little difference in practice, but
should be fixed for correctness.
</p>
<p>The current implementation of the jackknife stores all jackknife-replicates
of the regression coefficients, which can be very costly for large matrices.
This might change in a future version.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error of
Prediction (MSEP) Estimates for Principal Component Regression (PCR) and
Partial Least Squares Regression (PLSR).  <em>Journal of Chemometrics</em>,
<b>18</b>(9), 422&ndash;429.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+crossval">crossval</a></code> <code><a href="#topic+cvsegments">cvsegments</a></code>
<code><a href="#topic+MSEP">MSEP</a></code> <code><a href="#topic+var.jack">var.jack</a></code> <code><a href="#topic+jack.test">jack.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn, validation = "CV", segments = 10)
## Not run: plot(MSEP(yarn.pcr))

</code></pre>

<hr>
<h2 id='mvrVal'>MSEP, RMSEP and R2 of PLSR and PCR models</h2><span id='topic+mvrVal'></span><span id='topic+mvrValstats'></span><span id='topic+MSEP'></span><span id='topic+MSEP.mvr'></span><span id='topic+RMSEP'></span><span id='topic+RMSEP.mvr'></span><span id='topic+R2'></span><span id='topic+R2.mvr'></span>

<h3>Description</h3>

<p>Functions to estimate the mean squared error of prediction (MSEP), root mean
squared error of prediction (RMSEP) and <code class="reqn">R^2</code> (A.K.A. coefficient of
multiple determination) for fitted PCR and PLSR models.  Test-set,
cross-validation and calibration-set estimates are implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrValstats(
  object,
  estimate,
  newdata,
  ncomp = 1:object$ncomp,
  comps,
  intercept = cumulative,
  se = FALSE,
  ...
)

R2(object, ...)

## S3 method for class 'mvr'
R2(
  object,
  estimate,
  newdata,
  ncomp = 1:object$ncomp,
  comps,
  intercept = cumulative,
  se = FALSE,
  ...
)

MSEP(object, ...)

## S3 method for class 'mvr'
MSEP(
  object,
  estimate,
  newdata,
  ncomp = 1:object$ncomp,
  comps,
  intercept = cumulative,
  se = FALSE,
  ...
)

RMSEP(object, ...)

## S3 method for class 'mvr'
RMSEP(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvrVal_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_estimate">estimate</code></td>
<td>
<p>a character vector.  Which estimators to use.  Should be a
subset of <code>c("all", "train", "CV", "adjCV", "test")</code>.  <code>"adjCV"</code>
is only available for (R)MSEP.  See below for how the estimators are chosen.</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_newdata">newdata</code></td>
<td>
<p>a data frame with test set data.</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_ncomp">ncomp</code>, <code id="mvrVal_+3A_comps">comps</code></td>
<td>
<p>a vector of positive integers.  The components or number
of components to use.  See below.</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_intercept">intercept</code></td>
<td>
<p>logical.  Whether estimates for a model with zero
components should be returned as well.</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_se">se</code></td>
<td>
<p>logical.  Whether estimated standard errors of the estimates
should be calculated.  Not implemented yet.</p>
</td></tr>
<tr><td><code id="mvrVal_+3A_...">...</code></td>
<td>
<p>further arguments sent to underlying functions or (for
<code>RMSEP</code>) to <code>MSEP</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RMSEP</code> simply calls <code>MSEP</code> and takes the square root of the
estimates.  It therefore accepts the same arguments as <code>MSEP</code>.
</p>
<p>Several estimators can be used.  <code>"train"</code> is the training or
calibration data estimate, also called (R)MSEC.  For <code>R2</code>, this is the
unadjusted <code class="reqn">R^2</code>.  It is overoptimistic and should not be used for
assessing models.  <code>"CV"</code> is the cross-validation estimate, and
<code>"adjCV"</code> (for <code>RMSEP</code> and <code>MSEP</code>) is the bias-corrected
cross-validation estimate.  They can only be calculated if the model has
been cross-validated.  Finally, <code>"test"</code> is the test set estimate,
using <code>newdata</code> as test set.
</p>
<p>Which estimators to use is decided as follows (see below for
<code>mvrValstats</code>).  If <code>estimate</code> is not specified, the test set
estimate is returned if <code>newdata</code> is specified, otherwise the CV and
adjusted CV (for <code>RMSEP</code> and <code>MSEP</code>) estimates if the model has
been cross-validated, otherwise the training data estimate.  If
<code>estimate</code> is <code>"all"</code>, all possible estimates are calculated.
Otherwise, the specified estimates are calculated.
</p>
<p>Several model sizes can also be specified.  If <code>comps</code> is missing (or
is <code>NULL</code>), <code>length(ncomp)</code> models are used, with <code>ncomp[1]</code>
components, ..., <code>ncomp[length(ncomp)]</code> components.  Otherwise, a
single model with the components <code>comps[1]</code>, ...,
<code>comps[length(comps)]</code> is used.  If <code>intercept</code> is <code>TRUE</code>, a
model with zero components is also used (in addition to the above).
</p>
<p>The <code class="reqn">R^2</code> values returned by <code>"R2"</code> are calculated as <code class="reqn">1 -
SSE/SST</code>, where <code class="reqn">SST</code> is the (corrected) total sum of squares of the
response, and <code class="reqn">SSE</code> is the sum of squared errors for either the fitted
values (i.e., the residual sum of squares), test set predictions or
cross-validated predictions (i.e., the <code class="reqn">PRESS</code>).  For <code>estimate =
"train"</code>, this is equivalent to the squared correlation between the fitted
values and the response.  For <code>estimate = "train"</code>, the estimate is
often called the prediction <code class="reqn">R^2</code>.
</p>
<p><code>mvrValstats</code> is a utility function that calculates the statistics
needed by <code>MSEP</code> and <code>R2</code>.  It is not intended to be used
interactively.  It accepts the same arguments as <code>MSEP</code> and <code>R2</code>.
However, the <code>estimate</code> argument must be specified explicitly: no
partial matching and no automatic choice is made.  The function simply
calculates the types of estimates it knows, and leaves the other untouched.
</p>


<h3>Value</h3>

<p><code>mvrValstats</code> returns a list with components </p>

<dl>
<dt>SSE</dt><dd><p>three-dimensional array of SSE values.  The first dimension is
the different estimators, the second is the response variables and the third
is the models.</p>
</dd> <dt>SST</dt><dd><p>matrix of SST values.  The first dimension is the
different estimators and the second is the response variables.</p>
</dd>
<dt>nobj</dt><dd><p>a numeric vector giving the number of objects used for each
estimator.</p>
</dd> <dt>comps</dt><dd><p>the components specified, with <code>0</code> prepended
if <code>intercept</code> is <code>TRUE</code>.</p>
</dd> <dt>cumulative</dt><dd><p><code>TRUE</code> if
<code>comps</code> was <code>NULL</code> or not specified.</p>
</dd> </dl>

<p>The other functions return an object of class <code>"mvrVal"</code>, with
components </p>
 <dl>
<dt>val</dt><dd><p>three-dimensional array of estimates.  The
first dimension is the different estimators, the second is the response
variables and the third is the models.</p>
</dd> <dt>type</dt><dd><p><code>"MSEP"</code>,
<code>"RMSEP"</code> or <code>"R2"</code>.</p>
</dd> <dt>comps</dt><dd><p>the components specified, with
<code>0</code> prepended if <code>intercept</code> is <code>TRUE</code>.</p>
</dd>
<dt>cumulative</dt><dd><p><code>TRUE</code> if <code>comps</code> was <code>NULL</code> or not
specified.</p>
</dd> <dt>call</dt><dd><p>the function call</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error of
Prediction (MSEP) Estimates for Principal Component Regression (PCR) and
Partial Least Squares Regression (PLSR).  <em>Journal of Chemometrics</em>,
<b>18</b>(9), 422&ndash;429.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+crossval">crossval</a></code>, <code><a href="#topic+mvrCv">mvrCv</a></code>,
<code><a href="#topic+validationplot">validationplot</a></code>, <code><a href="#topic+plot.mvrVal">plot.mvrVal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oliveoil)
mod &lt;- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil, validation = "LOO")
RMSEP(mod)
## Not run: plot(R2(mod))

</code></pre>

<hr>
<h2 id='naExcludeMvr'>Adjust for Missing Values</h2><span id='topic+naExcludeMvr'></span>

<h3>Description</h3>

<p>Use missing value information to adjust residuals and predictions.  This is
the &lsquo;mvr equivalent&rsquo; of the <code>naresid.exclude</code> and
<code>napredict.exclude</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naExcludeMvr(omit, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naExcludeMvr_+3A_omit">omit</code></td>
<td>
<p>an object produced by an <code>na.action</code> function, typically
the <code>"na.action"</code> attribute of the result of <code>na.omit</code> or
<code>na.exclude</code>.</p>
</td></tr>
<tr><td><code id="naExcludeMvr_+3A_x">x</code></td>
<td>
<p>a three-dimensional array to be adjusted based upon the missing
value information in <code>omit</code>.</p>
</td></tr>
<tr><td><code id="naExcludeMvr_+3A_...">...</code></td>
<td>
<p>further arguments.  Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a utility function used to allow <code>predict.mvr</code> and
<code>residuals.mvr</code> to compensate for the removal of <code>NA</code>s in the
fitting process.
</p>
<p>It is called only when the <code>na.action</code> is <code>na.exclude</code>, and pads
<code>x</code> with <code>NA</code>s in the correct positions to have the same number of
rows as the original data frame.
</p>


<h3>Value</h3>

<p><code>x</code>, padded with <code>NA</code>s along the first dimension
(&lsquo;rows&rsquo;).
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik and Ron Wehrens
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.mvr">predict.mvr</a></code>, <code><a href="#topic+residuals.mvr">residuals.mvr</a></code>,
<code><a href="stats.html#topic+napredict">napredict</a></code>, <code><a href="stats.html#topic+naresid">naresid</a></code>
</p>

<hr>
<h2 id='oliveoil'>Sensory and physico-chemical data of olive oils</h2><span id='topic+oliveoil'></span>

<h3>Description</h3>

<p>A data set with scores on 6 attributes from a sensory panel and measurements
of 5 physico-chemical quality parameters on 16 olive oil samples.  The first
five oils are Greek, the next five are Italian and the last six are Spanish.
</p>


<h3>Format</h3>

<p>A data frame with 16 observations on the following 2 variables.
</p>
 <dl>
<dt>sensory</dt><dd><p>a matrix with 6 columns.  Scores for
attributes &lsquo;yellow&rsquo;, &lsquo;green&rsquo;, &lsquo;brown&rsquo;, &lsquo;glossy&rsquo;,
&lsquo;transp&rsquo;, and &lsquo;syrup&rsquo;.</p>
</dd> <dt>chemical</dt><dd><p>a matrix with
5 columns.  Measurements of acidity, peroxide, K232, K270, and DK.</p>
</dd> </dl>



<h3>Source</h3>

<p>Massart, D. L., Vandeginste, B. G. M., Buydens, L. M. C., de Jong,
S., Lewi, P. J., Smeyers-Verbeke, J. (1998) <em>Handbook of Chemometrics
and Qualimetrics: Part B</em>.  Elsevier. Tables 35.1 and 35.4.
</p>

<hr>
<h2 id='oscorespls.fit'>Orthogonal scores PLSR</h2><span id='topic+oscorespls.fit'></span>

<h3>Description</h3>

<p>Fits a PLSR model with the orthogonal scores algorithm (aka the NIPALS
algorithm).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oscorespls.fit(
  X,
  Y,
  ncomp,
  center = TRUE,
  stripped = FALSE,
  tol = .Machine$double.eps^0.5,
  maxit = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oscorespls.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_tol">tol</code></td>
<td>
<p>numeric.  The tolerance used for determining convergence in
multi-response models.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_maxit">maxit</code></td>
<td>
<p>positive integer.  The maximal number of iterations used in the
internal Eigenvector calculation.</p>
</td></tr>
<tr><td><code id="oscorespls.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>plsr</code> or <code>mvr</code> with the argument
<code>method="oscorespls"</code>.  It implements the orthogonal scores algorithm,
as described in <cite>Martens and Næs (1989)</cite>.  This is one of the two
&ldquo;classical&rdquo; PLSR algorithms, the other being the orthogonal loadings
algorithm.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td></tr>
<tr><td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td></tr>
<tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td></tr> <tr><td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in <code>X</code>.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Martens, H., Næs, T. (1989) <em>Multivariate calibration.</em>
Chichester: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+pcr">pcr</a></code>
<code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code> <code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code>
<code><a href="#topic+simpls.fit">simpls.fit</a></code>
</p>

<hr>
<h2 id='plot.mvr'>Plot Method for MVR objects</h2><span id='topic+plot.mvr'></span>

<h3>Description</h3>

<p><code>plot.mvr</code> plots predictions, coefficients, scores, loadings, biplots,
correlation loadings or validation plots (RMSEP curves, etc.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
plot(
  x,
  plottype = c("prediction", "validation", "coefficients", "scores", "loadings",
    "biplot", "correlation"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mvr_+3A_x">x</code></td>
<td>
<p>an object of class <code>mvr</code>.  The fitted model to plot.</p>
</td></tr>
<tr><td><code id="plot.mvr_+3A_plottype">plottype</code></td>
<td>
<p>character.  What kind of plot to plot.</p>
</td></tr>
<tr><td><code id="plot.mvr_+3A_...">...</code></td>
<td>
<p>further arguments, sent to the underlying plot functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is simply a wrapper for the underlying plot functions used to
make the selected plots.  See <code><a href="#topic+predplot.mvr">predplot.mvr</a></code>,
<code><a href="#topic+validationplot">validationplot</a></code>, <code><a href="#topic+coefplot">coefplot</a></code>,
<code><a href="#topic+scoreplot">scoreplot</a></code>, <code><a href="#topic+loadingplot">loadingplot</a></code>, <code><a href="#topic+biplot.mvr">biplot.mvr</a></code>
or <code><a href="#topic+corrplot">corrplot</a></code> for details.  Note that all arguments except
<code>x</code> and <code>plottype</code> must be named.
</p>


<h3>Value</h3>

<p><code>plot.mvr</code> returns whatever the underlying plot function
returns.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+predplot.mvr">predplot.mvr</a></code>,
<code><a href="#topic+validationplot">validationplot</a></code>, <code><a href="#topic+coefplot">coefplot</a></code>,
<code><a href="#topic+scoreplot">scoreplot</a></code>, <code><a href="#topic+loadingplot">loadingplot</a></code>,
<code><a href="#topic+biplot.mvr">biplot.mvr</a></code>, <code><a href="#topic+corrplot">corrplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
nir.pcr &lt;- pcr(density ~ NIR, ncomp = 9, data = yarn, validation = "CV")
## Not run: 
plot(nir.pcr, ncomp = 5) # Plot of cross-validated predictions
plot(nir.pcr, "scores") # Score plot
plot(nir.pcr, "loadings", comps = 1:3) # The three first loadings
plot(nir.pcr, "coef", ncomp = 5) # Coefficients
plot(nir.pcr, "val") # RMSEP curves
plot(nir.pcr, "val", val.type = "MSEP", estimate = "CV") # CV MSEP

## End(Not run)

</code></pre>

<hr>
<h2 id='pls'>Partial Least Squares and Principal Component Regression</h2><span id='topic+pls'></span><span id='topic+pls-package'></span>

<h3>Description</h3>

<p>Multivariate regression methods Partial Least Squares Regression (PLSR), Principal Component
Regression (PCR) and Canonical Powered Partial Least Squares (CPPLS).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Kristian Hovde Liland <a href="mailto:kristian.liland@nmbu.no">kristian.liland@nmbu.no</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Bjørn-Helge Mevik <a href="mailto:b-h@mevik.net">b-h@mevik.net</a>
</p>
</li>
<li><p> Ron Wehrens
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Paul Hiemstra [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/khliland/pls">https://github.com/khliland/pls</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/khliland/pls/issues">https://github.com/khliland/pls/issues</a>
</p>
</li></ul>


<hr>
<h2 id='pls.options'>Set or return options for the pls package</h2><span id='topic+pls.options'></span>

<h3>Description</h3>

<p>A function to set options for the <span class="pkg">pls</span> package, or to return the
current options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pls.options(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pls.options_+3A_...">...</code></td>
<td>
<p>a single list, a single character vector, or any number of
named arguments (<var>name = value</var>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If called with no arguments, or with an empty list as the single argument,
<code>pls.options</code> returns the current options.
</p>
<p>If called with a character vector as the single argument, a list with the
arguments named in the vector are returned.
</p>
<p>If called with a non-empty list as the single argument, the list elements
should be named, and are treated as named arguments to the function.
</p>
<p>Otherwise, <code>pls.options</code> should be called with one or more named
arguments <var>name = value</var>.  For each argument, the option named
<var>name</var> will be given the value <var>value</var>.
</p>
<p>The recognised options are: </p>
 <dl>
<dt>mvralg</dt><dd><p>The fit method to use
in <code><a href="#topic+mvr">mvr</a></code> and <code><a href="#topic+mvrCv">mvrCv</a></code>.  The value should be one of
the allowed methods.  Defaults to <code>"kernelpls"</code>.  Can be overridden
with the argument <code>method</code> in <code>mvr</code> and <code>mvrCv</code>.</p>
</dd>
<dt>pcralg</dt><dd><p>The fit method to use in <code><a href="#topic+pcr">pcr</a></code>.  The value should
be one of the allowed methods.  Defaults to <code>"svdpc"</code>.  Can be
overridden with the argument <code>method</code> in <code>pcr</code>.</p>
</dd>
<dt>plsralg</dt><dd><p>The fit method to use in <code><a href="#topic+plsr">plsr</a></code>.  The value
should be one of the allowed methods.  Defaults to <code>"kernelpls"</code>.  Can
be overridden with the argument <code>method</code> in <code>plsr</code>.</p>
</dd>
<dt>cpplsalg</dt><dd><p>The fit method to use in <code><a href="#topic+cppls">cppls</a></code>.  The value
should be one of the allowed methods.  Defaults to <code>"cppls"</code>.  Can be
overridden with the argument <code>method</code> in <code>cppls</code>.</p>
</dd>
<dt>parallel</dt><dd><p>Specification of how the cross-validation (CV) in
<code><a href="#topic+mvr">mvr</a></code> should be performed.  If the specification is <code>NULL</code>
(default) or <code>1</code>, the CV is done serially, otherwise it is done in
parallel using functionality from the <code><a href="lattice.html#topic+parallel">parallel</a></code> package.
</p>
<p>If it is an integer greater than 1, the CV is done in parallel with the
specified number of processes, using <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.
</p>
<p>If it is a cluster object created by <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, the CV is
done in parallel on that cluster, using <code><a href="parallel.html#topic+parLapply">parLapply</a></code>.  The user
should stop the cluster herself when it is no longer needed, using
<code><a href="parallel.html#topic+stopCluster">stopCluster</a></code>.
</p>
<p>Finally, if the specification is an unevaluated call to
<code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, the call is evaluated, and the CV is done in
parallel on the resulting cluster, using <code><a href="parallel.html#topic+parLapply">parLapply</a></code>.  In this
case, the cluster will be stopped (with <code><a href="parallel.html#topic+stopCluster">stopCluster</a></code>) after the
CV.  Thus, in the final case, the cluster is created and destroyed for each
CV, just like when using <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.</p>
</dd> <dt>w.tol</dt><dd><p>The tolerance
used for removing values close to 0 in the vectors of loading weights in
<code><a href="#topic+cppls">cppls</a></code>.  Defaults to .Machine$double.eps.</p>
</dd> <dt>X.tol</dt><dd><p>The
tolerance used for removing predictor variables with L1 norms close to 0 in
<code><a href="#topic+cppls">cppls</a></code>.  Defaults to 10^-12.</p>
</dd> </dl>



<h3>Value</h3>

<p>A list with the (possibly changed) options.  If any named argument
(or list element) was provided, the list is returned invisibly.
</p>


<h3>Note</h3>

<p>The function is a slight modification of the function
<code><a href="sm.html#topic+sm.options">sm.options</a></code> from the package <span class="pkg">sm</span>.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik and Ron Wehrens
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Return current options:
pls.options()
pls.options("plsralg")
pls.options(c("plsralg", "pcralg"))

## Set options:
pls.options(plsralg = "simpls", mvralg = "simpls")
pls.options(list(plsralg = "simpls", mvralg = "simpls")) # Equivalent
pls.options()

## Restore `factory settings':
pls.options(list(mvralg = "kernelpls", plsralg = "kernelpls", cpplsalg = "cppls",
                 pcralg = "svdpc", parallel = NULL,
                 w.tol = .Machine$double.eps, X.tol = 10^-12))
pls.options()

</code></pre>

<hr>
<h2 id='predict.mvr'>Predict Method for PLSR and PCR</h2><span id='topic+predict.mvr'></span>

<h3>Description</h3>

<p>Prediction for mvr (PCR, PLSR) models.  New responses or scores are
predicted using a fitted model and a new matrix of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
predict(
  object,
  newdata,
  ncomp = 1:object$ncomp,
  comps,
  type = c("response", "scores"),
  na.action = na.pass,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.mvr_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.  The fitted model</p>
</td></tr>
<tr><td><code id="predict.mvr_+3A_newdata">newdata</code></td>
<td>
<p>a data frame.  The new data.  If missing, the training data
is used.</p>
</td></tr>
<tr><td><code id="predict.mvr_+3A_ncomp">ncomp</code>, <code id="predict.mvr_+3A_comps">comps</code></td>
<td>
<p>vector of positive integers.  The components to use in
the prediction.  See below.</p>
</td></tr>
<tr><td><code id="predict.mvr_+3A_type">type</code></td>
<td>
<p>character.  Whether to predict scores or response values</p>
</td></tr>
<tr><td><code id="predict.mvr_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>.  The default is to predict <code>NA</code>.  See
<code><a href="stats.html#topic+na.omit">na.omit</a></code> for alternatives.</p>
</td></tr>
<tr><td><code id="predict.mvr_+3A_...">...</code></td>
<td>
<p>further arguments.  Currently not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>type</code> is <code>"response"</code> (default), predicted response values
are returned.  If <code>comps</code> is missing (or is <code>NULL</code>), predictions
for <code>length(ncomp)</code> models with <code>ncomp[1]</code> components,
<code>ncomp[2]</code> components, etc., are returned.  Otherwise, predictions for
a single model with the exact components in <code>comps</code> are returned.
(Note that in both cases, the intercept is always included in the
predictions.  It can be removed by subtracting the <code>Ymeans</code> component
of the fitted model.)
</p>
<p>When <code>type</code> is <code>"scores"</code>, predicted score values are returned for
the components given in <code>comps</code>.  If <code>comps</code> is missing or
<code>NULL</code>, <code>ncomps</code> is used instead.
</p>
<p>It is also possible to supply a matrix instead of a data frame as
<code>newdata</code>, which is then assumed to be the <code class="reqn">X</code> data matrix.  Note
that the usual checks for the type of the data are then omitted.  Also note
that this is <em>only</em> possible with <code>predict</code>; it will not work in
functions like <code><a href="#topic+predplot">predplot</a></code>, <code><a href="#topic+RMSEP">RMSEP</a></code> or
<code><a href="#topic+R2">R2</a></code>, because they also need the response variable of the new
data.
</p>


<h3>Value</h3>

<p>When <code>type</code> is <code>"response"</code>, a three dimensional array of
predicted response values is returned.  The dimensions correspond to the
observations, the response variables and the model sizes, respectively.
</p>
<p>When <code>type</code> is <code>"scores"</code>, a score matrix is returned.
</p>


<h3>Note</h3>

<p>A warning message like &lsquo;<span class="samp">&#8288;'newdata' had 10 rows but variable(s)
found have 106 rows&#8288;</span>&rsquo; means that not all variables were found in the
<code>newdata</code> data frame.  This (usually) happens if the formula contains
terms like <code>yarn$NIR</code>.  Do not use such terms; use the <code>data</code>
argument instead.  See <code><a href="#topic+mvr">mvr</a></code> for details.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+summary.mvr">summary.mvr</a></code>,
<code><a href="#topic+coef.mvr">coef.mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
nir.mvr &lt;- mvr(density ~ NIR, ncomp = 5, data = yarn[yarn$train,])

## Predicted responses for models with 1, 2, 3 and 4 components
pred.resp &lt;- predict(nir.mvr, ncomp = 1:4, newdata = yarn[!yarn$train,])

## Predicted responses for a single model with components 1, 2, 3, 4
predict(nir.mvr, comps = 1:4, newdata = yarn[!yarn$train,])

## Predicted scores
predict(nir.mvr, comps = 1:3, type = "scores", newdata = yarn[!yarn$train,])

</code></pre>

<hr>
<h2 id='predplot'>Prediction Plots</h2><span id='topic+predplot'></span><span id='topic+predplot.default'></span><span id='topic+predplot.mvr'></span><span id='topic+predplotXy'></span>

<h3>Description</h3>

<p>Functions to plot predicted values against measured values for a fitted
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predplot(object, ...)

## Default S3 method:
predplot(object, ...)

## S3 method for class 'mvr'
predplot(
  object,
  ncomp = object$ncomp,
  which,
  newdata,
  nCols,
  nRows,
  xlab = "measured",
  ylab = "predicted",
  main,
  ask = nRows * nCols &lt; nPlots &amp;&amp; dev.interactive(),
  ...,
  font.main,
  cex.main
)

predplotXy(
  x,
  y,
  line = FALSE,
  labels,
  type = "p",
  main = "Prediction plot",
  xlab = "measured response",
  ylab = "predicted response",
  line.col = par("col"),
  line.lty = NULL,
  line.lwd = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predplot_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
<tr><td><code id="predplot_+3A_...">...</code></td>
<td>
<p>further arguments sent to underlying plot functions.</p>
</td></tr>
<tr><td><code id="predplot_+3A_ncomp">ncomp</code></td>
<td>
<p>integer vector.  The model sizes (numbers of components) to use
for prediction.</p>
</td></tr>
<tr><td><code id="predplot_+3A_which">which</code></td>
<td>
<p>character vector.  Which types of predictions to plot.  Should
be a subset of <code>c("train", "validation", "test")</code>.  If not specified,
<code>plot.mvr</code> selects test set predictions if <code>newdata</code> is supplied,
otherwise cross-validated predictions if the model has been cross-validated,
otherwise fitted values from the calibration data.</p>
</td></tr>
<tr><td><code id="predplot_+3A_newdata">newdata</code></td>
<td>
<p>data frame.  New data to predict.</p>
</td></tr>
<tr><td><code id="predplot_+3A_ncols">nCols</code>, <code id="predplot_+3A_nrows">nRows</code></td>
<td>
<p>integer.  The number of coloumns and rows the plots will
be laid out in.  If not specified, <code>plot.mvr</code> tries to be intelligent.</p>
</td></tr>
<tr><td><code id="predplot_+3A_xlab">xlab</code>, <code id="predplot_+3A_ylab">ylab</code></td>
<td>
<p>titles for <code class="reqn">x</code> and <code class="reqn">y</code> axes.  Typically character
strings, but can be expressions or lists.  See <code><a href="graphics.html#topic+title">title</a></code> for
details.</p>
</td></tr>
<tr><td><code id="predplot_+3A_main">main</code></td>
<td>
<p>optional main title for the plot.  See Details.</p>
</td></tr>
<tr><td><code id="predplot_+3A_ask">ask</code></td>
<td>
<p>logical.  Whether to ask the user before each page of a plot.</p>
</td></tr>
<tr><td><code id="predplot_+3A_font.main">font.main</code></td>
<td>
<p>font to use for main titles.  See <code><a href="graphics.html#topic+par">par</a></code> for
details.  Also see Details below.</p>
</td></tr>
<tr><td><code id="predplot_+3A_cex.main">cex.main</code></td>
<td>
<p>numeric.  The magnification to be used for main titles
relative to the current size.  Also see Details below.</p>
</td></tr>
<tr><td><code id="predplot_+3A_x">x</code></td>
<td>
<p>numeric vector.  The observed response values.</p>
</td></tr>
<tr><td><code id="predplot_+3A_y">y</code></td>
<td>
<p>numeric vector.  The predicted response values.</p>
</td></tr>
<tr><td><code id="predplot_+3A_line">line</code></td>
<td>
<p>logical.  Whether a target line should be drawn.</p>
</td></tr>
<tr><td><code id="predplot_+3A_labels">labels</code></td>
<td>
<p>optional.  Alternative plot labels to use.  Either a vector of
labels, or <code>"names"</code> or <code>"numbers"</code> to use the row names or row
numbers of the data as labels.</p>
</td></tr>
<tr><td><code id="predplot_+3A_type">type</code></td>
<td>
<p>character.  What type of plot to make.  Defaults to <code>"p"</code>
(points).  See <code><a href="graphics.html#topic+plot">plot</a></code> for a complete list of types.  The
argument is ignored if <code>labels</code> is specified.</p>
</td></tr>
<tr><td><code id="predplot_+3A_line.col">line.col</code>, <code id="predplot_+3A_line.lty">line.lty</code>, <code id="predplot_+3A_line.lwd">line.lwd</code></td>
<td>
<p>character or numeric.  The <code>col</code>,
<code>lty</code> and <code>lwd</code> parametres for the target line.  See
<code><a href="graphics.html#topic+par">par</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>predplot</code> is a generic function for plotting predicted versus measured
response values, with default and <code>mvr</code> methods currently implemented.
The default method is very simple, and doesn't handle multiple responses or
new data.
</p>
<p>The <code>mvr</code> method, handles multiple responses, model sizes and types of
predictions by making one plot for each combination.  It can also be called
through the plot method for <code>mvr</code>, by specifying <code>plottype =
"prediction"</code> (the default).
</p>
<p>The argument <code>main</code> can be used to specify the main title of the plot.
It is handled in a non-standard way.  If there is only on (sub) plot,
<code>main</code> will be used as the main title of the plot.  If there is
<em>more</em> than one (sub) plot, however, the presence of <code>main</code> will
produce a corresponding &lsquo;global&rsquo; title on the page.  Any graphical
parametres, e.g., <code>cex.main</code>, supplied to <code>coefplot</code> will only
affect the &lsquo;ordinary&rsquo; plot titles, not the &lsquo;global&rsquo; one.  Its
appearance can be changed by setting the parameters with <code><a href="graphics.html#topic+par">par</a></code>,
which will affect <em>both</em> titles (with the exception of <code>font.main</code>
and <code>cex.main</code>, which will only affect the &lsquo;global&rsquo; title when
there is more than one plot).  (To have different settings for the two
titles, one can override the <code>par</code> settings with arguments to
<code>predplot</code>.)
</p>
<p><code>predplotXy</code> is an internal function and is not meant for interactive
use.  It is called by the <code>predplot</code> methods, and its arguments, e.g,
<code>line</code>, can be given in the <code>predplot</code> call.
</p>


<h3>Value</h3>

<p>The functions invisibly return a matrix with the (last) plotted
data.
</p>


<h3>Note</h3>

<p>The <code>font.main</code> and <code>cex.main</code> must be (completely) named.
This is to avoid that any argument <code>cex</code> or <code>font</code> matches them.
</p>
<p>Tip: If the labels specified with <code>labels</code> are too long, they get
clipped at the border of the plot region.  This can be avoided by supplying
the graphical parameter <code>xpd = TRUE</code> in the plot call.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
mod &lt;- plsr(density ~ NIR, ncomp = 10, data = yarn[yarn$train,], validation = "CV")
## Not run: 
predplot(mod, ncomp = 1:6)
plot(mod, ncomp = 1:6) # Equivalent to the previous
## Both cross-validated and test set predictions:
predplot(mod, ncomp = 4:6, which = c("validation", "test"),
         newdata = yarn[!yarn$train,])

## End(Not run)

data(oliveoil)
mod.sens &lt;- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil)
## Not run: plot(mod.sens, ncomp = 2:4) # Several responses gives several plots

</code></pre>

<hr>
<h2 id='print.mvr'>Summary and Print Methods for PLSR and PCR objects</h2><span id='topic+print.mvr'></span><span id='topic+summary.mvr'></span><span id='topic+print.mvrVal'></span><span id='topic+as.data.frame.mvrVal'></span>

<h3>Description</h3>

<p>Summary and print methods for <code>mvr</code> and <code>mvrVal</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
print(x, ...)

## S3 method for class 'mvr'
summary(
  object,
  what = c("all", "validation", "training"),
  digits = 4,
  print.gap = 2,
  ...
)

## S3 method for class 'mvrVal'
print(x, digits = 4, print.gap = 2, ...)

## S3 method for class 'mvrVal'
as.data.frame(x, row.names = NULL, optional = FALSE, shortAlgs = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mvr_+3A_x">x</code>, <code id="print.mvr_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_...">...</code></td>
<td>
<p>Other arguments sent to underlying methods.</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_what">what</code></td>
<td>
<p>one of <code>"all"</code>, <code>"validation"</code> or <code>"training"</code></p>
</td></tr>
<tr><td><code id="print.mvr_+3A_digits">digits</code></td>
<td>
<p>integer.  Minimum number of significant digits in the output.
Default is 4.</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_print.gap">print.gap</code></td>
<td>
<p>Integer.  Gap between coloumns of the printed tables.</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_row.names">row.names</code></td>
<td>
<p>NULL or a character vector giving the row names for the data frame. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_optional">optional</code></td>
<td>
<p>Not used, only included to match signature of <code>as.data.frame</code>.</p>
</td></tr>
<tr><td><code id="print.mvr_+3A_shortalgs">shortAlgs</code></td>
<td>
<p>Logical.  Shorten algorithm names (default = TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>what</code> is <code>"training"</code>, the explained variances are given; if
it is <code>"validation"</code>, the cross-validated RMSEPs (if available) are
given; if it is <code>"all"</code>, both are given.
</p>


<h3>Value</h3>

<p><code>print.mvr</code> and <code>print.mvrVal</code> return the object
invisibly.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+pcr">pcr</a></code>, <code><a href="#topic+plsr">plsr</a></code>,
<code><a href="#topic+RMSEP">RMSEP</a></code>, <code><a href="#topic+MSEP">MSEP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
nir.mvr &lt;- mvr(density ~ NIR, ncomp = 8, validation = "LOO", data = yarn)
nir.mvr
summary(nir.mvr)
RMSEP(nir.mvr)
# Extract MVR validation statistics as data.frame:
as.data.frame(RMSEP(nir.mvr, estimate = "CV"))
as.data.frame(R2(nir.mvr))

</code></pre>

<hr>
<h2 id='scoreplot'>Plots of Scores, Loadings and Correlation Loadings</h2><span id='topic+scoreplot'></span><span id='topic+scoreplot.default'></span><span id='topic+plot.scores'></span><span id='topic+loadingplot'></span><span id='topic+loadingplot.default'></span><span id='topic+plot.loadings'></span><span id='topic+corrplot'></span>

<h3>Description</h3>

<p>Functions to make scatter plots of scores or correlation loadings, and
scatter or line plots of loadings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreplot(object, ...)

## Default S3 method:
scoreplot(
  object,
  comps = 1:2,
  labels,
  identify = FALSE,
  type = "p",
  xlab,
  ylab,
  ...
)

## S3 method for class 'scores'
plot(x, ...)

loadingplot(object, ...)

## Default S3 method:
loadingplot(
  object,
  comps = 1:2,
  scatter = FALSE,
  labels,
  identify = FALSE,
  type,
  lty,
  lwd = NULL,
  pch,
  cex = NULL,
  col,
  legendpos,
  xlab,
  ylab,
  pretty.xlabels = TRUE,
  xlim,
  ...
)

## S3 method for class 'loadings'
plot(x, ...)

corrplot(
  object,
  comps = 1:2,
  labels,
  plotx = TRUE,
  ploty = FALSE,
  radii = c(sqrt(1/2), 1),
  identify = FALSE,
  type = "p",
  xlab,
  ylab,
  col,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoreplot_+3A_object">object</code></td>
<td>
<p>an object.  The fitted model.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_...">...</code></td>
<td>
<p>further arguments sent to the underlying plot function(s).</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_comps">comps</code></td>
<td>
<p>integer vector.  The components to plot.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_labels">labels</code></td>
<td>
<p>optional.  Alternative plot labels or <code class="reqn">x</code> axis labels.
See Details.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_identify">identify</code></td>
<td>
<p>logical.  Whether to use <code>identify</code> to interactively
identify points.  See below.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_type">type</code></td>
<td>
<p>character.  What type of plot to make.  Defaults to <code>"p"</code>
(points) for scatter plots and <code>"l"</code> (lines) for line plots.  See
<code><a href="graphics.html#topic+plot">plot</a></code> for a complete list of types (not all types are
possible/meaningful for all plots).</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_xlab">xlab</code>, <code id="scoreplot_+3A_ylab">ylab</code></td>
<td>
<p>titles for <code class="reqn">x</code> and <code class="reqn">y</code> axes.  Typically character
strings, but can be expressions or lists.  See <code><a href="graphics.html#topic+title">title</a></code> for
details.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_x">x</code></td>
<td>
<p>a <code>scores</code> or <code>loadings</code> object.  The scores or loadings
to plot.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_scatter">scatter</code></td>
<td>
<p>logical.  Whether the loadings should be plotted as a scatter
instead of as lines.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_lty">lty</code></td>
<td>
<p>vector of line types (recycled as neccessary).  Line types can be
specified as integers or character strings (see <code><a href="graphics.html#topic+par">par</a></code> for the
details).</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_lwd">lwd</code></td>
<td>
<p>vector of positive numbers (recycled as neccessary), giving the
width of the lines.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_pch">pch</code></td>
<td>
<p>plot character.  A character string or a vector of single
characters or integers (recycled as neccessary).  See <code><a href="graphics.html#topic+points">points</a></code>
for all alternatives.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_cex">cex</code></td>
<td>
<p>numeric vector of character expansion sizes (recycled as
neccessary) for the plotted symbols.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_col">col</code></td>
<td>
<p>character or integer vector of colors for plotted lines and
symbols (recycled as neccessary).  See <code><a href="graphics.html#topic+par">par</a></code> for the details.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_legendpos">legendpos</code></td>
<td>
<p>Legend position.  Optional.  Ignored if <code>scatter</code> is
<code>TRUE</code>.  If present, a legend is drawn at the given position.  The
position can be specified symbolically (e.g., <code>legendpos =
"topright"</code>).  This requires &gt;= 2.1.0.  Alternatively, the position can be
specified explicitly (<code>legendpos = t(c(x,y))</code>) or interactively
(<code>legendpos = <a href="graphics.html#topic+locator">locator</a>()</code>).</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_pretty.xlabels">pretty.xlabels</code></td>
<td>
<p>logical.  If <code>TRUE</code>, <code>loadingplot</code> tries to
plot the <code class="reqn">x</code> labels more nicely.  See Details.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_xlim">xlim</code></td>
<td>
<p>optional vector of length two, with the <code class="reqn">x</code> limits of the
plot.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_plotx">plotx</code></td>
<td>
<p>locical.  Whether to plot the <code class="reqn">X</code> correlation loadings.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_ploty">ploty</code></td>
<td>
<p>locical.  Whether to plot the <code class="reqn">Y</code> correlation loadings.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="scoreplot_+3A_radii">radii</code></td>
<td>
<p>numeric vector, giving the radii of the circles drawn in
<code>corrplot</code>.  The default radii represent 50% and 100% explained
variance of the <code class="reqn">X</code> variables by the chosen components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.scores</code> is simply a wrapper calling <code>scoreplot</code>, passing all
arguments.  Similarly for <code>plot.loadings</code>.
</p>
<p><code>scoreplot</code> is generic, currently with a default method that works for
matrices and any object for which <code><a href="#topic+scores">scores</a></code> returns a matrix.
The default <code>scoreplot</code> method makes one or more scatter plots of the
scores, depending on how many components are selected.  If one or two
components are selected, and <code>identify</code> is <code>TRUE</code>, the function
<code><a href="graphics.html#topic+identify">identify</a></code> is used to interactively identify points.
</p>
<p>Also <code>loadingplot</code> is generic, with a default method that works for
matrices and any object where <code><a href="#topic+loadings">loadings</a></code> returns a matrix.  If
<code>scatter</code> is <code>TRUE</code>, the default method works exactly like the
default <code>scoreplot</code> method.  Otherwise, it makes a lineplot of the
selected loading vectors, and if <code>identify</code> is <code>TRUE</code>, uses
<code><a href="graphics.html#topic+identify">identify</a></code> to interactively identify points.  Also, if
<code>legendpos</code> is given, a legend is drawn at the position indicated.
</p>
<p><code>corrplot</code> works exactly like the default <code>scoreplot</code> method,
except that at least two components must be selected.  The
&ldquo;correlation loadings&rdquo;, i.e. the correlations between each variable
and the selected components (see References), are plotted as pairwise
scatter plots, with concentric circles of radii given by <code>radii</code>.  Each
point corresponds to a variable.  The squared distance between the point and
origin equals the fraction of the variance of the variable explained by the
components in the panel.  The default <code>radii</code> corresponds to 50% and
100% explained variance.  By default, only the correlation loadings of the
<code class="reqn">X</code> variables are plotted, but if <code>ploty</code> is <code>TRUE</code>, also the
<code class="reqn">Y</code> correlation loadings are plotted.
</p>
<p><code>scoreplot</code>, <code>loadingplot</code> and <code>corrplot</code> can also be called
through the plot method for <code>mvr</code> objects, by specifying
<code>plottype</code> as <code>"scores"</code>, <code>"loadings"</code> or
<code>"correlation"</code>, respectively.  See <code><a href="#topic+plot.mvr">plot.mvr</a></code>.
</p>
<p>The argument <code>labels</code> can be a vector of labels or one of
<code>"names"</code> and <code>"numbers"</code>.
</p>
<p>If a scatter plot is produced (i.e., <code>scoreplot</code>, <code>corrplot</code>, or
<code>loadingplot</code> with <code>scatter = TRUE</code>), the labels are used instead
of plot symbols for the points plotted.  If <code>labels</code> is <code>"names"</code>
or <code>"numbers"</code>, the row names or row numbers of the matrix (scores,
loadings or correlation loadings) are used.
</p>
<p>If a line plot is produced (i.e., <code>loadingplot</code>), the labels are used
as <code class="reqn">x</code> axis labels.  If <code>labels</code> is <code>"names"</code> or
<code>"numbers"</code>, the variable names are used as labels, the difference
being that with <code>"numbers"</code>, the variable names are converted to
numbers, if possible.  Variable names of the forms &lsquo;<span class="samp">&#8288;"number"&#8288;</span>&rsquo; or
&lsquo;<span class="samp">&#8288;"number text"&#8288;</span>&rsquo; (where the space is optional), are handled.
</p>
<p>The argument <code>pretty.xlabels</code> is only used when <code>labels</code> is
specified for a line plot.  If <code>TRUE</code> (default), the code tries to use
a &lsquo;pretty&rsquo; selection of labels.  If <code>labels</code> is
<code>"numbers"</code>, it also uses the numerical values of the labels for
horisontal spacing.  If one has excluded parts of the spectral region, one
might therefore want to use <code>pretty.xlabels = FALSE</code>.
</p>


<h3>Value</h3>

<p>The functions return whatever the underlying plot function (or
<code>identify</code>) returns.
</p>


<h3>Note</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code> has many options.  If you want greater control
over the appearance of the legend, omit the <code>legendpos</code> argument and
call <code>legend</code> manually.
</p>
<p>Graphical parametres (such as <code>pch</code> and <code>cex</code>) can also be used
with <code>scoreplot</code> and <code>corrplot</code>.  They are not listed in the
argument list simply because they are not handled specifically in the
function (unlike in <code>loadingplot</code>), but passed directly to the
underlying plot functions by <code>...{}</code>.
</p>
<p>Tip: If the labels specified with <code>labels</code> are too long, they get
clipped at the border of the plot region.  This can be avoided by supplying
the graphical parameter <code>xpd = TRUE</code> in the plot call.
</p>
<p>The handling of <code>labels</code> and <code>pretty.xlabels</code> in <code>coefplot</code>
is experimental.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Martens, H., Martens, M. (2000) Modified Jack-knife Estimation
of Parameter Uncertainty in Bilinear Modelling by Partial Least Squares
Regression (PLSR).  <em>Food Quality and Preference</em>, <b>11</b>(1&ndash;2),
5&ndash;16.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>, <code><a href="#topic+scores">scores</a></code>,
<code><a href="#topic+loadings">loadings</a></code>, <code><a href="graphics.html#topic+identify">identify</a></code>, <code><a href="graphics.html#topic+legend">legend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
mod &lt;- plsr(density ~ NIR, ncomp = 10, data = yarn)
## These three are equivalent:
## Not run: 
scoreplot(mod, comps = 1:5)
plot(scores(mod), comps = 1:5)
plot(mod, plottype = "scores", comps = 1:5)

loadingplot(mod, comps = 1:5)
loadingplot(mod, comps = 1:5, legendpos = "topright") # With legend
loadingplot(mod, comps = 1:5, scatter = TRUE) # Plot as scatterplots

corrplot(mod, comps = 1:2)
corrplot(mod, comps = 1:3)

## End(Not run)

</code></pre>

<hr>
<h2 id='scores'>Extract Scores and Loadings from PLSR and PCR Models</h2><span id='topic+scores'></span><span id='topic+loadings'></span><span id='topic+scores.default'></span><span id='topic+loadings.default'></span><span id='topic+loading.weights'></span><span id='topic+Yscores'></span><span id='topic+Yloadings'></span>

<h3>Description</h3>

<p>These functions extract score and loading matrices from fitted <code>mvr</code>
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadings(object, ...)

## Default S3 method:
loadings(object, ...)

scores(object, ...)

## Default S3 method:
scores(object, ...)

Yscores(object)

loading.weights(object)

Yloadings(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_+3A_object">object</code></td>
<td>
<p>a fitted model to extract from.</p>
</td></tr>
<tr><td><code id="scores_+3A_...">...</code></td>
<td>
<p>extra arguments, currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions extract the indicated matrix from the fitted model, and will
work with any object having a suitably named component.
</p>
<p>The default <code>scores</code> and <code>loadings</code> methods also handle
<code>prcomp</code> objects (their scores and loadings components are called
<code>x</code> and <code>rotation</code>, resp.), and add an attribute <code>"explvar"</code>
with the variance explained by each component, if this is available.  (See
<code><a href="#topic+explvar">explvar</a></code> for details.)
</p>


<h3>Value</h3>

<p>A matrix with scores or loadings.
</p>


<h3>Note</h3>

<p>There is a <code>loadings</code> function in package <span class="pkg">stats</span>.  It simply
returns any element named <code>"loadings"</code>.  See
<code><a href="stats.html#topic+loadings">loadings</a></code> for details.  The function can be accessed as
<code>stats::loadings(...)</code>.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+coef.mvr">coef.mvr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
plsmod &lt;- plsr(density ~ NIR, 6, data = yarn)
scores(plsmod)
loadings(plsmod)[,1:4]

</code></pre>

<hr>
<h2 id='selectNcomp'>Suggestions for the optimal number of components in PCR and PLSR models</h2><span id='topic+selectNcomp'></span>

<h3>Description</h3>

<p>Choosing the best number of components in PCR and PLSR models is difficult
and usually done on the basis of visual inspection of the validation plots.
In cases where large numbers of models are built this choice needs to be
automated. This function implements two proposals, one based on
randomization (permutation) testing, and an approach based on the standard
error of the cross-validation residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectNcomp(
  object,
  method = c("randomization", "onesigma"),
  nperm = 999,
  alpha = 0.01,
  ncomp = object$ncomp,
  plot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectNcomp_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.  The fitted model. It should contain a
<code>validation</code> element.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_method">method</code></td>
<td>
<p>character string, indicating the heuristic to use.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_nperm">nperm</code></td>
<td>
<p>number of permutations in the <code>"randomization"</code> approach -
not used in the <code>"onesigma"</code> approach.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_alpha">alpha</code></td>
<td>
<p>cutoff for p values in the <code>"randomization"</code> approach -
not used in the <code>"onesigma"</code> approach.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_ncomp">ncomp</code></td>
<td>
<p>maximum number of components to consider when determining the
global minimum in the cross-validation curve.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_plot">plot</code></td>
<td>
<p>whether or not to show a cross-validation plot. The plot for the
<code>"randomization"</code> approach shows models that do not differ
significantly from the global RMSEP minimum with open circles; the
<code>"onesigma"</code> approach shows the one-sigma bands around the RMSEP
values. In both cases, the selection is indicated with a blue dashed line.</p>
</td></tr>
<tr><td><code id="selectNcomp_+3A_...">...</code></td>
<td>
<p>Further plotting arguments, e.g., to add a title to the plot,
or to limit the plotting range.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In both approaches the results of cross-validation are used, so the model
should have been calculated with some form of cross-validation. First, the
absolute minimum in the CV curve is determined (considering only the first
ncomp components), leading to the reference model. The randomization test
approach (Van der Voet, 1994) checks whether the squared prediction errors
of models with fewer components are significantly larger than in the
reference model. This leads for each model considered to a <code class="reqn">p</code> value;
the smallest model not significantly worse than the reference model is
returned as the selected one.
</p>
<p>The approach <code>"onesigma"</code> simply returns the first model where the
optimal CV is within one standard error of the absolute optimum (Hastie,
Tibshirani and Friedman, 2009). Note that here we simply use the standard
deviation of the cross-validation residuals, in line with the procedure used
to calculate the error measure itself. Some other packages implementing
similar procedures (such as <code>glmnet</code>) calculate an error measure for
each validation segment separately and use the average as the final
estimate. In such cases the standard error across segments is the relevant
measure of spread. For LOO, the two procedures are identical. In other forms
of validation, small differences will occur.
</p>


<h3>Value</h3>

<p>A number indicating the suggested number of components in the model.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens, Hilko van der Voet and Gerie van der Heijden
</p>


<h3>References</h3>

<p>Van der Voet, H. (1994) Comparing the predictive accuracy of
models using a simple randomization test. Chemom. Intell. Lab. Syst. 25 (2),
313-323
</p>
<p>Hastie, T., Friedman, J. and Tibshirani, R. The Elements of Statistical
Learning: data mining, inference, and prediction, Springer (2013), 10th
printing with corrections, paragraph 7.10.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+summary.mvr">summary.mvr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
yarn.pls &lt;- plsr(density ~ NIR, data = yarn, scale = TRUE,
                 ncomp = 20, validation = "LOO")
selectNcomp(yarn.pls, "onesigma", plot = TRUE, ylim = c(0, 3))
selectNcomp(yarn.pls, "randomization", plot = TRUE)
selectNcomp(yarn.pls, "randomization", plot = TRUE,
            ncomp = 10, ylim = c(0, 3))

</code></pre>

<hr>
<h2 id='simpls.fit'>Sijmen de Jong's SIMPLS</h2><span id='topic+simpls.fit'></span>

<h3>Description</h3>

<p>Fits a PLSR model with the SIMPLS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpls.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simpls.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="simpls.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="simpls.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="simpls.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="simpls.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="simpls.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>plsr</code> or <code>mvr</code> with the argument
<code>method="simpls"</code>.  SIMPLS is much faster than the NIPALS algorithm,
especially when the number of X variables increases, but gives slightly
different results in the case of multivariate Y.  SIMPLS truly maximises the
covariance criterion.  According to de Jong, the standard PLS2 algorithms
lie closer to ordinary least-squares regression where a precise fit is
sought; SIMPLS lies closer to PCR with stable predictions.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix
of Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td></tr>
<tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td></tr> <tr><td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in <code>X</code>.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>de Jong, S. (1993) SIMPLS: an alternative approach to partial
least squares regression.  <em>Chemometrics and Intelligent Laboratory
Systems</em>, <b>18</b>, 251&ndash;263.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+pcr">pcr</a></code>
<code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code> <code><a href="#topic+widekernelpls.fit">widekernelpls.fit</a></code>
<code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code>
</p>

<hr>
<h2 id='stdize'>Standardization of Data Matrices</h2><span id='topic+stdize'></span><span id='topic+predict.stdized'></span><span id='topic+makepredictcall.stdized'></span>

<h3>Description</h3>

<p>Performs standardization (centering and scaling) of a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdize(x, center = TRUE, scale = TRUE)

## S3 method for class 'stdized'
predict(object, newdata, ...)

## S3 method for class 'stdized'
makepredictcall(var, call)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdize_+3A_x">x</code>, <code id="stdize_+3A_newdata">newdata</code></td>
<td>
<p>numeric matrices.  The data to standardize.</p>
</td></tr>
<tr><td><code id="stdize_+3A_center">center</code></td>
<td>
<p>logical value or numeric vector of length equal to the number
of coloumns of <code>x</code>.</p>
</td></tr>
<tr><td><code id="stdize_+3A_scale">scale</code></td>
<td>
<p>logical value or numeric vector of length equal to the number
of coloumns of <code>x</code>.</p>
</td></tr>
<tr><td><code id="stdize_+3A_object">object</code></td>
<td>
<p>an object inheriting from class <code>"stdized"</code>, normally the
result of a call to <code>stdize</code>.</p>
</td></tr>
<tr><td><code id="stdize_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
<tr><td><code id="stdize_+3A_var">var</code></td>
<td>
<p>A variable.</p>
</td></tr>
<tr><td><code id="stdize_+3A_call">call</code></td>
<td>
<p>The term in the formula, as a call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>makepredictcall.stdized</code> is an internal utility function; it is not
meant for interactive use.  See <code><a href="stats.html#topic+makepredictcall">makepredictcall</a></code> for details.
</p>
<p>If <code>center</code> is <code>TRUE</code>, <code>x</code> is centered by subtracting the
coloumn mean from each coloumn.  If <code>center</code> is a numeric vector, it is
used in place of the coloumn means.
</p>
<p>If <code>scale</code> is <code>TRUE</code>, <code>x</code> is scaled by dividing each coloumn
by its sample standard deviation.  If <code>scale</code> is a numeric vector, it
is used in place of the standard deviations.
</p>


<h3>Value</h3>

<p>Both <code>stdize</code> and <code>predict.stdized</code> return a scaled and/or
centered matrix, with attributes <code>"stdized:center"</code> and/or
<code>"stdized:scale"</code> the vector used for centering and/or scaling.  The
matrix is given class <code>c("stdized", "matrix")</code>.
</p>


<h3>Note</h3>

<p><code>stdize</code> is very similar to <code><a href="base.html#topic+scale">scale</a></code>.  The
difference is that when <code>scale = TRUE</code>, <code>stdize</code> divides the
coloumns by their standard deviation, while <code>scale</code> uses the
root-mean-square of the coloumns.  If <code>center</code> is <code>TRUE</code>, this is
equivalent, but in general it is not.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik and Ron Wehrens
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+pcr">pcr</a></code>, <code><a href="#topic+plsr">plsr</a></code>,
<code><a href="#topic+msc">msc</a></code>, <code><a href="base.html#topic+scale">scale</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(yarn)
## Direct standardization:
Ztrain &lt;- stdize(yarn$NIR[yarn$train,])
Ztest &lt;- predict(Ztrain, yarn$NIR[!yarn$train,])

## Used in formula:
mod &lt;- plsr(density ~ stdize(NIR), ncomp = 6, data = yarn[yarn$train,])
pred &lt;- predict(mod, newdata = yarn[!yarn$train,]) # Automatically standardized

</code></pre>

<hr>
<h2 id='svdpc.fit'>Principal Component Regression</h2><span id='topic+svdpc.fit'></span>

<h3>Description</h3>

<p>Fits a PCR model using the singular value decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svdpc.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svdpc.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="svdpc.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="svdpc.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="svdpc.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="svdpc.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="svdpc.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>pcr</code> or <code>mvr</code> with the argument <code>method="svdpc"</code>.
The singular value decomposition is used to calculate the principal
components.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the
projection matrix used to convert X to scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of
means of the X variables.</p>
</td></tr> <tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y
variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an array of fitted values.  The dimensions
of <code>fitted.values</code> are <code>c(nobj, npred, ncomp)</code> with <code>nobj</code>
the number samples and <code>npred</code> the number of Y variables.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>an array of regression residuals.  It has the same
dimensions as <code>fitted.values</code>.</p>
</td></tr> <tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of
X-variance explained by each component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in
<code>X</code>.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Martens, H., Næs, T. (1989) <em>Multivariate calibration.</em>
Chichester: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+pcr">pcr</a></code>
<code><a href="#topic+cppls">cppls</a></code>
</p>

<hr>
<h2 id='validationplot'>Validation Plots</h2><span id='topic+validationplot'></span><span id='topic+plot.mvrVal'></span>

<h3>Description</h3>

<p>Functions to plot validation statistics, such as RMSEP or <code class="reqn">R^2</code>, as a
function of the number of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validationplot(
  object,
  val.type = c("RMSEP", "MSEP", "R2"),
  estimate,
  newdata,
  ncomp,
  comps,
  intercept,
  ...
)

## S3 method for class 'mvrVal'
plot(
  x,
  nCols,
  nRows,
  type = "l",
  lty = 1:nEst,
  lwd = par("lwd"),
  pch = 1:nEst,
  cex = 1,
  col = 1:nEst,
  legendpos,
  xlab = "number of components",
  ylab = x$type,
  main,
  ask = nRows * nCols &lt; nResp &amp;&amp; dev.interactive(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validationplot_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_val.type">val.type</code></td>
<td>
<p>character.  What type of validation statistic to plot.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_estimate">estimate</code></td>
<td>
<p>character.  Which estimates of the statistic to calculate.
See <code><a href="#topic+RMSEP">RMSEP</a></code>.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_newdata">newdata</code></td>
<td>
<p>data frame.  Optional new data used to calculate statistic.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_ncomp">ncomp</code>, <code id="validationplot_+3A_comps">comps</code></td>
<td>
<p>integer vector.  The model sizes to compute the statistic
for.  See <code><a href="#topic+RMSEP">RMSEP</a></code>.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_intercept">intercept</code></td>
<td>
<p>logical.  Whether estimates for a model with zero
components should be calculated as well.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_...">...</code></td>
<td>
<p>Further arguments sent to underlying plot functions.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_x">x</code></td>
<td>
<p>an <code>mvrVal</code> object.  Usually the result of a
<code><a href="#topic+RMSEP">RMSEP</a></code>, <code><a href="#topic+MSEP">MSEP</a></code> or <code><a href="#topic+R2">R2</a></code> call.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_ncols">nCols</code>, <code id="validationplot_+3A_nrows">nRows</code></td>
<td>
<p>integers.  The number of coloumns and rows the plots will
be laid out in.  If not specified, <code>plot.mvrVal</code> tries to be
intelligent.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_type">type</code></td>
<td>
<p>character.  What type of plots to create.  Defaults to
<code>"l"</code> (lines).  Alternative types include <code>"p"</code> (points) and
<code>"b"</code> (both).  See <code><a href="graphics.html#topic+plot">plot</a></code> for a complete list of types.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_lty">lty</code></td>
<td>
<p>vector of line types (recycled as neccessary).  Line types can be
specified as integers or character strings (see <code><a href="graphics.html#topic+par">par</a></code> for the
details).</p>
</td></tr>
<tr><td><code id="validationplot_+3A_lwd">lwd</code></td>
<td>
<p>vector of positive numbers (recycled as neccessary), giving the
width of the lines.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_pch">pch</code></td>
<td>
<p>plot character.  A character string or a vector of single
characters or integers (recycled as neccessary).  See <code><a href="graphics.html#topic+points">points</a></code>
for all alternatives.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_cex">cex</code></td>
<td>
<p>numeric vector of character expansion sizes (recycled as
neccessary) for the plotted symbols.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_col">col</code></td>
<td>
<p>character or integer vector of colors for plotted lines and
symbols (recycled as neccessary).  See <code><a href="graphics.html#topic+par">par</a></code> for the details.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_legendpos">legendpos</code></td>
<td>
<p>Legend position.  Optional.  If present, a legend is drawn
at the given position.  The position can be specified symbolically (e.g.,
<code>legendpos = "topright"</code>).  This requires &gt;= 2.1.0.  Alternatively, the
position can be specified explicitly (<code>legendpos = t(c(x,y))</code>) or
interactively (<code>legendpos = <a href="graphics.html#topic+locator">locator</a>()</code>).  This only works well
for plots of single-response models.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_xlab">xlab</code>, <code id="validationplot_+3A_ylab">ylab</code></td>
<td>
<p>titles for <code class="reqn">x</code> and <code class="reqn">y</code> axes.  Typically character
strings, but can be expressions (e.g., <code>expression(R^2)</code> or lists.  See
<code><a href="graphics.html#topic+title">title</a></code> for details.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_main">main</code></td>
<td>
<p>optional main title for the plot.  See Details.</p>
</td></tr>
<tr><td><code id="validationplot_+3A_ask">ask</code></td>
<td>
<p>logical.  Whether to ask the user before each page of a plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>validationplot</code> calls the proper validation function (currently
<code><a href="#topic+MSEP">MSEP</a></code>, <code><a href="#topic+RMSEP">RMSEP</a></code> or <code><a href="#topic+R2">R2</a></code>) and plots the
results with <code>plot.mvrVal</code>.  <code>validationplot</code> can be called
through the <code>mvr</code> plot method, by specifying <code>plottype =
"validation"</code>.
</p>
<p><code>plot.mvrVal</code> creates one plot for each response variable in the model,
laid out in a rectangle.  It uses <code><a href="graphics.html#topic+matplot">matplot</a></code> for performing the
actual plotting.  If <code>legendpos</code> is given, a legend is drawn at the
given position.
</p>
<p>The argument <code>main</code> can be used to specify the main title of the plot.
It is handled in a non-standard way.  If there is only on (sub) plot,
<code>main</code> will be used as the main title of the plot.  If there is
<em>more</em> than one (sub) plot, however, the presence of <code>main</code> will
produce a corresponding &lsquo;global&rsquo; title on the page.  Any graphical
parametres, e.g., <code>cex.main</code>, supplied to <code>coefplot</code> will only
affect the &lsquo;ordinary&rsquo; plot titles, not the &lsquo;global&rsquo; one.  Its
appearance can be changed by setting the parameters with <code><a href="graphics.html#topic+par">par</a></code>,
which will affect <em>both</em> titles.  (To have different settings for the
two titles, one can override the <code>par</code> settings with arguments to the
plot function.)
</p>


<h3>Note</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code> has many options.  If you want greater control
over the appearance of the legend, omit the <code>legendpos</code> argument and
call <code>legend</code> manually.
</p>


<h3>Author(s)</h3>

<p>Ron Wehrens and Bjørn-Helge Mevik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code>, <code><a href="#topic+plot.mvr">plot.mvr</a></code>, <code><a href="#topic+RMSEP">RMSEP</a></code>,
<code><a href="#topic+MSEP">MSEP</a></code>, <code><a href="#topic+R2">R2</a></code>, <code><a href="graphics.html#topic+matplot">matplot</a></code>,
<code><a href="graphics.html#topic+legend">legend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oliveoil)
mod &lt;- plsr(sensory ~ chemical, data = oliveoil, validation = "LOO")
## Not run: 
## These three are equivalent:
validationplot(mod, estimate = "all")
plot(mod, "validation", estimate = "all")
plot(RMSEP(mod, estimate = "all"))
## Plot R2:
plot(mod, "validation", val.type = "R2")
## Plot R2, with a legend:
plot(mod, "validation", val.type = "MSEP", legendpos = "top") # R &gt;= 2.1.0

## End(Not run)

</code></pre>

<hr>
<h2 id='var.jack'>Jackknife Variance Estimates of Regression Coefficients</h2><span id='topic+var.jack'></span>

<h3>Description</h3>

<p>Calculates jackknife variance or covariance estimates of regression
coefficients.
</p>
<p>The original (Tukey) jackknife variance estimator is defined as <code class="reqn">(g-1)/g
\sum_{i=1}^g(\tilde\beta_{-i} - \bar\beta)^2</code>, where <code class="reqn">g</code> is the number
of segments, <code class="reqn">\tilde\beta_{-i}</code> is the estimated coefficient when
segment <code class="reqn">i</code> is left out (called the jackknife replicates), and
<code class="reqn">\bar\beta</code> is the mean of the <code class="reqn">\tilde\beta_{-i}</code>.  The most common
case is delete-one jackknife, with <code class="reqn">g = n</code>, the number of observations.
</p>
<p>This is the definition <code>var.jack</code> uses by default.
</p>
<p>However, Martens and Martens (2000) defined the estimator as <code class="reqn">(g-1)/g
\sum_{i=1}^g(\tilde\beta_{-i} - \hat\beta)^2</code>, where <code class="reqn">\hat\beta</code> is the
coefficient estimate using the entire data set.  I.e., they use the original
fitted coefficients instead of the mean of the jackknife replicates.  Most
(all?) other jackknife implementations for PLSR use this estimator.
<code>var.jack</code> can be made to use this definition with <code>use.mean =
FALSE</code>.  In practice, the difference should be small if the number of
observations is sufficiently large.  Note, however, that all theoretical
results about the jackknife refer to the &lsquo;proper&rsquo; definition.  (Also note
that this option might disappear in a future version.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var.jack(object, ncomp = object$ncomp, covariance = FALSE, use.mean = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var.jack_+3A_object">object</code></td>
<td>
<p>an <code>mvr</code> object.  A cross-validated model fitted with
<code>jackknife = TRUE</code>.</p>
</td></tr>
<tr><td><code id="var.jack_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to use for estimating the
(co)variances</p>
</td></tr>
<tr><td><code id="var.jack_+3A_covariance">covariance</code></td>
<td>
<p>logical.  If <code>TRUE</code>, covariances are calculated;
otherwise only variances.  The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="var.jack_+3A_use.mean">use.mean</code></td>
<td>
<p>logical.  If <code>TRUE</code> (default), the mean coefficients
are used when estimating the (co)variances; otherwise the coefficients from
a model fitted to the entire data set.  See Details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>covariance</code> is <code>FALSE</code>, an <code class="reqn">p\times q \times c</code>
array of variance estimates, where <code class="reqn">p</code> is the number of predictors,
<code class="reqn">q</code> is the number of responses, and <code class="reqn">c</code> is the number of components.
</p>
<p>If <code>covariance</code> id <code>TRUE</code>, an <code class="reqn">pq\times pq \times c</code> array of
variance-covariance estimates.
</p>


<h3>Warning</h3>

<p>Note that the Tukey jackknife variance estimator is not
unbiased for the variance of regression coefficients (Hinkley 1977).  The
bias depends on the <code class="reqn">X</code> matrix.  For ordinary least squares regression
(OLSR), the bias can be calculated, and depends on the number of
observations <code class="reqn">n</code> and the number of parameters <code class="reqn">k</code> in the mode.  For
the common case of an orthogonal design matrix with <code class="reqn">\pm 1</code> levels,
the delete-one jackknife estimate equals <code class="reqn">(n-1)/(n-k)</code> times the
classical variance estimate for the regression coefficients in OLSR.
Similar expressions hold for delete-d estimates.  Modifications have been
proposed to reduce or eliminate the bias for the OLSR case, however, they
depend on the number of parameters used in the model.  See e.g. Hinkley
(1977) or Wu (1986).
</p>
<p>Thus, the results of <code>var.jack</code> should be used with caution.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Tukey J.W. (1958) Bias and Confidence in Not-quite Large
Samples. (Abstract of Preliminary Report).  <em>Annals of Mathematical
Statistics</em>, <b>29</b>(2), 614.
</p>
<p>Martens H. and Martens M. (2000) Modified Jack-knife Estimation of Parameter
Uncertainty in Bilinear Modelling by Partial Least Squares Regression
(PLSR).  <em>Food Quality and Preference</em>, <b>11</b>, 5&ndash;16.
</p>
<p>Hinkley D.V. (1977), Jackknifing in Unbalanced Situations.
<em>Technometrics</em>, <b>19</b>(3), 285&ndash;292.
</p>
<p>Wu C.F.J. (1986) Jackknife, Bootstrap and Other Resampling Methods in
Regression Analysis.  <em>Te Annals of Statistics</em>, <b>14</b>(4),
1261&ndash;1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvrCv">mvrCv</a></code>, <code><a href="#topic+jack.test">jack.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(oliveoil)
mod &lt;- pcr(sensory ~ chemical, data = oliveoil, validation = "LOO",
           jackknife = TRUE)
var.jack(mod, ncomp = 2)

</code></pre>

<hr>
<h2 id='vcov.mvr'>Calculate Variance-Covariance Matrix for a Fitted Model Object</h2><span id='topic+vcov.mvr'></span>

<h3>Description</h3>

<p>Returns the variance-covariance matrix of the coefficients
of a Principal Component Regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvr'
vcov(object, ncomp, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.mvr_+3A_object">object</code></td>
<td>
<p>a fitted PCR object of class <code>mvr</code>.</p>
</td></tr>
<tr><td><code id="vcov.mvr_+3A_ncomp">ncomp</code></td>
<td>
<p>number of principal components to estimate <code>vcov</code> for.</p>
</td></tr>
<tr><td><code id="vcov.mvr_+3A_...">...</code></td>
<td>
<p>additional arguments (not used).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of estimated covariances between regression coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(yarn)
yarn.pcr &lt;- pcr(density ~ NIR, 6, data = yarn)
vc &lt;- vcov(yarn.pcr, 3)

# Standard error of coefficients
se &lt;- sqrt(diag(vc))
beta &lt;- coef(yarn.pcr, ncomp = 3)

# Plot regression coefficients with two standard errors shading.
plot(beta, type = 'l',
     panel.first = polygon(x = c(1:268, 268:1),
                           y = c(beta+2*se, rev(beta-2*se)),
                           col = 'lightblue',
                           border = NA))
</code></pre>

<hr>
<h2 id='widekernelpls.fit'>Wide Kernel PLS (Rännar et al.)</h2><span id='topic+widekernelpls.fit'></span>

<h3>Description</h3>

<p>Fits a PLSR model with the wide kernel algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>widekernelpls.fit(
  X,
  Y,
  ncomp,
  center = TRUE,
  stripped = FALSE,
  tol = .Machine$double.eps^0.5,
  maxit = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="widekernelpls.fit_+3A_x">X</code></td>
<td>
<p>a matrix of observations.  <code>NA</code>s and <code>Inf</code>s are not
allowed.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_y">Y</code></td>
<td>
<p>a vector or matrix of responses.  <code>NA</code>s and <code>Inf</code>s are
not allowed.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_ncomp">ncomp</code></td>
<td>
<p>the number of components to be used in the modelling.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_center">center</code></td>
<td>
<p>logical, determines if the <code class="reqn">X</code> and <code class="reqn">Y</code> matrices are
mean centered or not. Default is to perform mean centering.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_stripped">stripped</code></td>
<td>
<p>logical.  If <code>TRUE</code> the calculations are stripped as
much as possible for speed; this is meant for use with cross-validation or
simulations when only the coefficients are needed.  Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_tol">tol</code></td>
<td>
<p>numeric.  The tolerance used for determining convergence in the
algorithm.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_maxit">maxit</code></td>
<td>
<p>positive integer.  The maximal number of iterations used in the
internal Eigenvector calculation.</p>
</td></tr>
<tr><td><code id="widekernelpls.fit_+3A_...">...</code></td>
<td>
<p>other arguments.  Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function should not be called directly, but through the generic
functions <code>plsr</code> or <code>mvr</code> with the argument
<code>method="widekernelpls"</code>.  The wide kernel PLS algorithm is efficient
when the number of variables is (much) larger than the number of
observations.  For very wide <code>X</code>, for instance 12x18000, it can be
twice as fast as <code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code> and <code><a href="#topic+simpls.fit">simpls.fit</a></code>.
For other matrices, however, it can be much slower.  The results are equal
to the results of the NIPALS algorithm.
</p>


<h3>Value</h3>

<p>A list containing the following components is returned:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>an array of regression coefficients for 1, ...,
<code>ncomp</code> components.  The dimensions of <code>coefficients</code> are
<code>c(nvar, npred, ncomp)</code> with <code>nvar</code> the number of <code>X</code>
variables and <code>npred</code> the number of variables to be predicted in
<code>Y</code>.</p>
</td></tr> <tr><td><code>scores</code></td>
<td>
<p>a matrix of scores.</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>a matrix of
loadings.</p>
</td></tr> <tr><td><code>loading.weights</code></td>
<td>
<p>a matrix of loading weights.</p>
</td></tr>
<tr><td><code>Yscores</code></td>
<td>
<p>a matrix of Y-scores.</p>
</td></tr> <tr><td><code>Yloadings</code></td>
<td>
<p>a matrix of
Y-loadings.</p>
</td></tr> <tr><td><code>projection</code></td>
<td>
<p>the projection matrix used to convert X to
scores.</p>
</td></tr> <tr><td><code>Xmeans</code></td>
<td>
<p>a vector of means of the X variables.</p>
</td></tr>
<tr><td><code>Ymeans</code></td>
<td>
<p>a vector of means of the Y variables.</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>an
array of fitted values.  The dimensions of <code>fitted.values</code> are
<code>c(nobj, npred, ncomp)</code> with <code>nobj</code> the number samples and
<code>npred</code> the number of Y variables.</p>
</td></tr> <tr><td><code>residuals</code></td>
<td>
<p>an array of
regression residuals.  It has the same dimensions as <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code>Xvar</code></td>
<td>
<p>a vector with the amount of X-variance explained by each
component.</p>
</td></tr> <tr><td><code>Xtotvar</code></td>
<td>
<p>Total variance in <code>X</code>.</p>
</td></tr>
</table>
<p>If <code>stripped</code> is <code>TRUE</code>, only the components <code>coefficients</code>,
<code>Xmeans</code> and <code>Ymeans</code> are returned.
</p>


<h3>Note</h3>

<p>The current implementation has not undergone extensive testing yet,
and should perhaps be regarded as experimental.  Specifically, the internal
Eigenvector calculation does not always converge in extreme cases where the
Eigenvalue is close to zero.  However, when it does converge, it always
converges to the same results as <code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code>, up to
numerical inacurracies.
</p>
<p>The algorithm also has a bit of overhead, so when the number of observations
is moderately high, <code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code> can be faster even if the
number of predictors is much higher.  The relative speed of the algorithms
can also depend greatly on which BLAS and/or LAPACK library is linked
against.
</p>


<h3>Author(s)</h3>

<p>Bjørn-Helge Mevik
</p>


<h3>References</h3>

<p>Rännar, S., Lindgren, F., Geladi, P. and Wold, S. (1994) A PLS
Kernel Algorithm for Data Sets with Many Variables and Fewer Objects.  Part
1: Theory and Algorithm.  <em>Journal of Chemometrics</em>, <b>8</b>,
111&ndash;125.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvr">mvr</a></code> <code><a href="#topic+plsr">plsr</a></code> <code><a href="#topic+cppls">cppls</a></code>
<code><a href="#topic+pcr">pcr</a></code> <code><a href="#topic+kernelpls.fit">kernelpls.fit</a></code> <code><a href="#topic+simpls.fit">simpls.fit</a></code>
<code><a href="#topic+oscorespls.fit">oscorespls.fit</a></code>
</p>

<hr>
<h2 id='yarn'>NIR spectra and density measurements of PET yarns</h2><span id='topic+yarn'></span>

<h3>Description</h3>

<p>A training set consisting of 21 NIR spectra of PET yarns, measured at 268
wavelengths, and 21 corresponding densities.  A test set of 7 samples is
also provided.  Many thanks to Erik Swierenga.
</p>


<h3>Format</h3>

<p>A data frame with components </p>
 <dl>
<dt>NIR</dt><dd><p>Numeric matrix of
NIR measurements</p>
</dd> <dt>density</dt><dd><p>Numeric vector of densities</p>
</dd>
<dt>train</dt><dd><p>Logical vector with <code>TRUE</code> for the training samples and
<code>FALSE</code> for the test samples</p>
</dd> </dl>



<h3>Source</h3>

<p>Swierenga H., de Weijer A. P., van Wijk R. J., Buydens L. M. C.
(1999) Strategy for constructing robust multivariate calibration models
<em>Chemometrics and Intelligent Laboratoryy Systems</em>, <b>49</b>(1),
1&ndash;17.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
