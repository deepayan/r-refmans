<!DOCTYPE html><html><head><title>Help for package evreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {evreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Bel'><p>Degree of belief of interval for a Gaussian random fuzzy number</p></a></li>
<li><a href='#Belint'><p>Finds a belief interval centered on mu for a Gaussian random fuzzy number</p></a></li>
<li><a href='#combination_GRFN'><p>Combination of Gaussian random fuzzy numbers</p></a></li>
<li><a href='#ENNreg'><p>Training the ENNreg model</p></a></li>
<li><a href='#ENNreg_cv'><p>Hyperparameter tuning for the ENNreg model using cross-validation</p></a></li>
<li><a href='#ENNreg_holdout'><p>Hyperparameter tuning for the ENNreg model using the hold-out method</p></a></li>
<li><a href='#ENNreg_init'><p>Parameter initialization for the ENNreg model</p></a></li>
<li><a href='#evreg'><p>evreg: A package for evidential regression</p></a></li>
<li><a href='#intervals'><p>Computation of prediction intervals from a trained ENNreg model</p></a></li>
<li><a href='#Pl'><p>Degree of plausibility of interval for a Gaussian random fuzzy number</p></a></li>
<li><a href='#pl_contour'><p>Contour function of a Gaussian random fuzzy number</p></a></li>
<li><a href='#predict.ENNreg'><p>Prediction method for the ENNreg model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Evidential Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-09</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of the 'Evidential Neural Network for Regression' model recently introduced in Denoeux (2023) &lt;<a href="https://doi.org/10.36227%2Ftechrxiv.21791831.v1">doi:10.36227/techrxiv.21791831.v1</a>&gt;. In this model, prediction uncertainty is quantified by Gaussian random fuzzy numbers as introduced in Denoeux (2023) &lt;<a href="https://doi.org/10.1016%2Fj.fss.2022.06.004">doi:10.1016/j.fss.2022.06.004</a>&gt;. The package contains functions for training the network, tuning hyperparameters by cross-validation or the hold-out method, and making predictions. It also contains utilities for making calculations with Gaussian random fuzzy numbers (such as, e.g., computing the degrees of belief and plausibility of an interval, or combining Gaussian random fuzzy numbers).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>evclust,stats</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr,rmarkdown,nnet,MASS,ggplot2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 09:47:57 UTC; Thierry</td>
</tr>
<tr>
<td>Author:</td>
<td>Thierry Denoeux <a href="https://orcid.org/0000-0002-0660-5436"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thierry Denoeux &lt;tdenoeux@utc.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 11:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Bel'>Degree of belief of interval for a Gaussian random fuzzy number</h2><span id='topic+Bel'></span>

<h3>Description</h3>

<p><code>Bel</code> computes the degree of belief of an interval [x,y] for a given Gaussian
random fuzzy number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bel(x, y, GRFN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bel_+3A_x">x</code></td>
<td>
<p>The lower bound of the interval (may be a vector).</p>
</td></tr>
<tr><td><code id="Bel_+3A_y">y</code></td>
<td>
<p>The upper bound of the interval (may be a vector).</p>
</td></tr>
<tr><td><code id="Bel_+3A_grfn">GRFN</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The degree of belief of the interval.
</p>


<h3>References</h3>

<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Belint">Belint</a></code>, <code><a href="#topic+Pl">Pl</a></code>, <code><a href="#topic+pl_contour">pl_contour</a></code>,
<code><a href="#topic+combination_GRFN">combination_GRFN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bel&lt;-Bel(1,2,list(mu=2,sig=1,h=2))
print(bel)
</code></pre>

<hr>
<h2 id='Belint'>Finds a belief interval centered on mu for a Gaussian random fuzzy number</h2><span id='topic+Belint'></span>

<h3>Description</h3>

<p><code>Belint</code> find an interval of the form [mu-r,mu+r] with specified degree of belief
for a Gaussian random fuzzy number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Belint(level = 0.9, GRFN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Belint_+3A_level">level</code></td>
<td>
<p>The specified degree of belief (between 0 and 1).</p>
</td></tr>
<tr><td><code id="Belint_+3A_grfn">GRFN</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the lower and upper bounds of the interval.
</p>


<h3>References</h3>

<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Bel">Bel</a></code>, <code><a href="#topic+Pl">Pl</a></code>, <code><a href="#topic+pl_contour">pl_contour</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>int&lt;-Belint(0.9,list(mu=2,sig=1,h=2))
print(int)
</code></pre>

<hr>
<h2 id='combination_GRFN'>Combination of Gaussian random fuzzy numbers</h2><span id='topic+combination_GRFN'></span>

<h3>Description</h3>

<p><code>combination_GRFN</code> combines two Gaussian random fuzzy numbers using the generalized
product-intersection rule with soft or hard normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combination_GRFN(GRFN1, GRFN2, soft = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combination_GRFN_+3A_grfn1">GRFN1</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
<tr><td><code id="combination_GRFN_+3A_grfn2">GRFN2</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
<tr><td><code id="combination_GRFN_+3A_soft">soft</code></td>
<td>
<p>If TRUE (default), the combination rule with soft normalization is used.
Otherwise, hard normalization is employed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components:
</p>

<dl>
<dt>GRFN</dt><dd><p>The combined Gaussian random fuzzy number, encoded as a list with components
mu, sig and h.</p>
</dd>
<dt>conflict</dt><dd><p>The degree of conflict (equal to 0 if <code>soft==TRUE</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Bel">Bel</a></code>, <code><a href="#topic+Pl">Pl</a></code>, <code><a href="#topic+pl_contour">pl_contour</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GRFN1&lt;-list(mu=1,sig=1,h=2)
GRFN2&lt;-list(mu=2,sig=2,h=3)
GRFN12s&lt;-combination_GRFN(GRFN1,GRFN2) # soft normalization
GRFN12h&lt;-combination_GRFN(GRFN1,GRFN2,soft=FALSE) # hard normalization
print(GRFN12s)
print(GRFN12h)
</code></pre>

<hr>
<h2 id='ENNreg'>Training the ENNreg model</h2><span id='topic+ENNreg'></span>

<h3>Description</h3>

<p><code>ENNreg</code> trains the ENNreg model using batch or minibatch learning procedures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ENNreg(
  X,
  y,
  init = NULL,
  K = NULL,
  batch = TRUE,
  nstart = 100,
  c = 1,
  lambda = 0.9,
  xi = 0,
  rho = 0,
  eps = NULL,
  nu = 1e-16,
  optimProto = TRUE,
  verbose = TRUE,
  options = list(maxiter = 1000, rel.error = 1e-04, print = 10),
  opt.rmsprop = list(batch_size = 100, epsi = 0.001, rho = 0.9, delta = 1e-08, Dtmax =
    100)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ENNreg_+3A_x">X</code></td>
<td>
<p>Input matrix of size n x p, where n is the number of objects and p the number of
attributes.</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_y">y</code></td>
<td>
<p>Vector of length n containing observations of the response variable.</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_init">init</code></td>
<td>
<p>Initial model generated by <code><a href="#topic+ENNreg_init">ENNreg_init</a></code> (default=NULL).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_k">K</code></td>
<td>
<p>Number of prototypes (default=NULL; must be supplied if initial model is not supplied).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_batch">batch</code></td>
<td>
<p>If TRUE (default), batch learning is used; otherwise, online learning is
used.</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_nstart">nstart</code></td>
<td>
<p>Number of random starts of the k-means algorithm (default: 100, used only if initial
model is not supplied).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_c">c</code></td>
<td>
<p>Multiplicative coefficient applied to scale parameter gamma (defaut: 1, used only if
initial model is not supplied)</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_lambda">lambda</code></td>
<td>
<p>Parameter of the loss function (default=0.9)</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_xi">xi</code></td>
<td>
<p>Regularization coefficient penalizing precision (default=0).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_rho">rho</code></td>
<td>
<p>Regularization coefficient shrinking the solution towards a linear model (default=0).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_eps">eps</code></td>
<td>
<p>Parameter of the loss function (if NULL, set to 0.01 times the standard deviation of y).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_nu">nu</code></td>
<td>
<p>Parameter of the loss function to avoid a division par zero (default=1e-16).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_optimproto">optimProto</code></td>
<td>
<p>If TRUE (default), the initial prototypes are optimized.</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE (default) intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization procedure (see details).</p>
</td></tr>
<tr><td><code id="ENNreg_+3A_opt.rmsprop">opt.rmsprop</code></td>
<td>
<p>Parameters of the RMSprop algorithm (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>batch=TRUE</code>, function <code>harris</code> from package <code>evclust</code> is used for
optimization. Otherwise, the RMSprop minibatch learning algorithm is used. The three
parameters in list <code>options</code> are:
</p>

<dl>
<dt>maxiter</dt><dd><p>Maximum number of iterations (default: 100).</p>
</dd>
<dt>rel.error</dt><dd><p>Relative error for stopping criterion (default: 1e-4).</p>
</dd>
<dt>print</dt><dd><p>Number of iterations between two displays (default: 10).</p>
</dd>
</dl>

<p>Additional parameters for the RMSprop, used only if <code>batch=FALSE</code>, are contained in
list <code>opt.rmsprop</code>. They are:
' </p>

<dl>
<dt>batch_size</dt><dd><p>Minibatch size.</p>
</dd>
<dt>epsi</dt><dd><p>Global learning rate.</p>
</dd>
<dt>rho</dt><dd><p>Decay rate.</p>
</dd>
<dt>delta</dt><dd><p>Small constant to stabilize division by small numbers.</p>
</dd>
<dt>Dtmax</dt><dd><p>The algorithm stops when the loss has not decreased in the last Dtmax
iterations.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class &quot;ENNreg&quot;  with the following components:
</p>

<dl>
<dt>loss</dt><dd><p>Value of the loss function.</p>
</dd>
<dt>param</dt><dd><p>Parameter values.</p>
</dd>
<dt>K</dt><dd><p>Number of prototypes.</p>
</dd>
<dt>pred</dt><dd><p>Predictions on the training set (a list containing the prototype unit activations,
the output means, variances and precisions, as well as the lower and upper expectations).</p>
</dd>
</dl>



<h3>References</h3>

<p>Thierry Denoeux. An evidential neural network model for regression based on random fuzzy
numbers. In &quot;Belief functions: Theory and applications (proc. of BELIEF 2022)&quot;, pages 57-66,
Springer, 2022.
</p>
<p>Thierry Denoeux. Quantifying prediction uncertainty in regression using random fuzzy sets: the ENNreg
model. TechRxiv preprint, 2023b
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.ENNreg">predict.ENNreg</a></code>, <code><a href="#topic+ENNreg_init">ENNreg_init</a></code>, <code><a href="#topic+ENNreg_cv">ENNreg_cv</a></code>,
<code><a href="#topic+ENNreg_holdout">ENNreg_holdout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Boston dataset

library(MASS)
X&lt;-as.matrix(scale(Boston[,1:13]))
y&lt;-Boston[,14]
set.seed(220322)
n&lt;-nrow(Boston)
ntrain&lt;-round(0.7*n)
train &lt;-sample(n,ntrain)
fit &lt;- ENNreg(X[train,],y[train],K=30)
plot(y[train],fit$pred$mux,xlab="observed response",ylab="predicted response")


</code></pre>

<hr>
<h2 id='ENNreg_cv'>Hyperparameter tuning for the ENNreg model using cross-validation</h2><span id='topic+ENNreg_cv'></span>

<h3>Description</h3>

<p><code>ENNreg_cv</code> tunes parameters xi and rho of the ENNreg model using cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ENNreg_cv(
  X,
  y,
  K,
  batch = TRUE,
  folds = NULL,
  Kfold = 5,
  XI,
  RHO,
  nstart = 100,
  c = 1,
  lambda = 0.9,
  eps = NULL,
  nu = 1e-16,
  optimProto = TRUE,
  verbose = TRUE,
  options = list(maxiter = 1000, rel.error = 1e-04, print = 10),
  opt.rmsprop = list(batch_size = 100, epsi = 0.001, rho = 0.9, delta = 1e-08, Dtmax =
    100)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ENNreg_cv_+3A_x">X</code></td>
<td>
<p>Input matrix of size n x p, where n is the number of objects and p the number of
attributes.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_y">y</code></td>
<td>
<p>Vector of length n containing observations of the response variable.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_k">K</code></td>
<td>
<p>Number of prototypes.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_batch">batch</code></td>
<td>
<p>If TRUE (default), batch learning is used; otherwise, online learning is
used.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_folds">folds</code></td>
<td>
<p>Vector of length n containing the folds (integers between 1 and Kfold).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_kfold">Kfold</code></td>
<td>
<p>Number of folds (default=5, used only if <code>folds</code> is not provided).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_xi">XI</code></td>
<td>
<p>Vector of candidate values for hyperparameter <code>xi</code>.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_rho">RHO</code></td>
<td>
<p>Vector of candidate values for hyperparameter <code>rho</code>.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_nstart">nstart</code></td>
<td>
<p>Number of random starts of the k-means algorithm (default: 100).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_c">c</code></td>
<td>
<p>Multiplicative coefficient applied to scale parameter gamma (defaut: 1).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_lambda">lambda</code></td>
<td>
<p>Parameter of the loss function (default=0.9).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_eps">eps</code></td>
<td>
<p>Parameter of the loss function (if NULL, fixed to 0.01 times the standard
deviation of y).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_nu">nu</code></td>
<td>
<p>Parameter of the loss function to avoid a division par zero (default=1e-16).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_optimproto">optimProto</code></td>
<td>
<p>If TRUE (default), the initial prototypes are optimized.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE (default) intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization algorithm (see <code><a href="#topic+ENNreg">ENNreg</a></code>).</p>
</td></tr>
<tr><td><code id="ENNreg_cv_+3A_opt.rmsprop">opt.rmsprop</code></td>
<td>
<p>Parameters of the RMSprop algorithm (see <code><a href="#topic+ENNreg">ENNreg</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either the folds (a vector of the same length as y, such that <code>folds[i]</code> equals the
fold, between 1 and Kfold, containing observation i), or the number of folds must be provided.
Arguments <code>options</code> and <code>opt.rmsprop</code> are passed to function <code><a href="#topic+ENNreg">ENNreg</a></code>.
</p>


<h3>Value</h3>

<p>A list with three components:
</p>

<dl>
<dt>xi</dt><dd><p>Optimal value of xi.</p>
</dd>
<dt>rho</dt><dd><p>Optimal value of rho.</p>
</dd>
<dt>RMS</dt><dd><p>Matrix of root mean squared error values</p>
</dd></dl>
<p>.

</p>


<h3>References</h3>

<p>Thierry Denoeux. An evidential neural network model for regression based on random fuzzy
numbers. In &quot;Belief functions: Theory and applications (proc. of BELIEF 2022)&quot;, pages 57-66,
Springer, 2022.
</p>
<p>Thierry Denoeux. Quantifying prediction uncertainty in regression using random fuzzy sets: the ENNreg
model. TechRxiv preprint, 2023b
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ENNreg">ENNreg</a></code>, <code><a href="#topic+ENNreg_holdout">ENNreg_holdout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Boston dataset

library(MASS)
X&lt;-as.matrix(scale(Boston[,1:13]))
y&lt;-Boston[,14]
set.seed(220322)
n&lt;-nrow(Boston)
ntrain&lt;-round(0.7*n)
train &lt;-sample(n,ntrain)
cv&lt;-ENNreg_cv(X=X[train,],y=y[train],K=30,XI=c(0.1,1,10),RHO=c(0.1,1,10))
cv$RMS
fit &lt;- ENNreg(X[train,],y[train],K=30,xi=cv$xi,rho=cv$rho)
pred&lt;-predict(fit,newdata=X[-train,],yt=y[-train])
print(pred$RMS)

</code></pre>

<hr>
<h2 id='ENNreg_holdout'>Hyperparameter tuning for the ENNreg model using the hold-out method</h2><span id='topic+ENNreg_holdout'></span>

<h3>Description</h3>

<p><code>ENNreg_holdout tunes parameters xi and rho of the ENNreg model using the
hold-out method.</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ENNreg_holdout(
  X,
  y,
  K,
  batch = TRUE,
  val = NULL,
  nval = NULL,
  XI,
  RHO,
  nstart = 100,
  c = 1,
  lambda = 0.9,
  eps = NULL,
  nu = 1e-16,
  optimProto = TRUE,
  verbose = TRUE,
  options = list(maxiter = 1000, rel.error = 1e-04, print = 10),
  opt.rmsprop = list(batch_size = 100, epsi = 0.001, rho = 0.9, delta = 1e-08, Dtmax =
    100)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ENNreg_holdout_+3A_x">X</code></td>
<td>
<p>Input matrix of size n x p, where n is the number of objects and p the number of
attributes.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_y">y</code></td>
<td>
<p>Vector of length n containing observations of the response variable.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_k">K</code></td>
<td>
<p>Number of prototypes.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_batch">batch</code></td>
<td>
<p>If TRUE (default), batch learning is used; otherwise, online learning is
used.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_val">val</code></td>
<td>
<p>Vector of indices of the validation instances (nval integers between 1 and n).
Needed only if <code>nval</code> is not provided.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_nval">nval</code></td>
<td>
<p>Number of validation instances (needed only if <code>val</code> is not provided).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_xi">XI</code></td>
<td>
<p>Vector of candidate values for hyperparameter <code>xi</code>.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_rho">RHO</code></td>
<td>
<p>Vector of candidate values for hyperparameter <code>rho</code>.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_nstart">nstart</code></td>
<td>
<p>Number of random starts of the k-means algorithm (default: 100).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_c">c</code></td>
<td>
<p>Multiplicative coefficient applied to scale parameter gamma (defaut: 1).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_lambda">lambda</code></td>
<td>
<p>Parameter of the loss function (default=0.9).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_eps">eps</code></td>
<td>
<p>Parameter of the loss function (if NULL, fixed to 0.01 times the standard
deviation of y).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_nu">nu</code></td>
<td>
<p>Parameter of the loss function to avoid a division par zero (default=1e-16).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_optimproto">optimProto</code></td>
<td>
<p>If TRUE (default), the initial prototypes are optimized.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE (default) intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization algorithm (see <code><a href="#topic+ENNreg">ENNreg</a></code>).</p>
</td></tr>
<tr><td><code id="ENNreg_holdout_+3A_opt.rmsprop">opt.rmsprop</code></td>
<td>
<p>Parameters of the RMSprop algorithm (see <code><a href="#topic+ENNreg">ENNreg</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either the validation set (a vector of indices), or the number nval of validation
instances must be provided. Arguments <code>options</code> and <code>opt.rmsprop</code> are passed
to function <code><a href="#topic+ENNreg">ENNreg</a></code>.
</p>


<h3>Value</h3>

<p>A list with three components:
</p>

<dl>
<dt>xi</dt><dd><p>Optimal value of xi.</p>
</dd>
<dt>rho</dt><dd><p>Optimal value of rho.</p>
</dd>
<dt>RMS</dt><dd><p>Matrix of root mean squared error values</p>
</dd></dl>
<p>.

</p>


<h3>References</h3>

<p>Thierry Denoeux. An evidential neural network model for regression based on random fuzzy
numbers. In &quot;Belief functions: Theory and applications (proc. of BELIEF 2022)&quot;, pages 57-66,
Springer, 2022.
</p>
<p>Thierry Denoeux. Quantifying prediction uncertainty in regression using random fuzzy sets: the ENNreg
model. TechRxiv preprint, 2023b
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ENNreg">ENNreg</a></code>, <code><a href="#topic+ENNreg_cv">ENNreg_cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Boston dataset

library(MASS)
X&lt;-as.matrix(scale(Boston[,1:13]))
y&lt;-Boston[,14]
set.seed(220322)
n&lt;-nrow(Boston)
hold.out&lt;-ENNreg_holdout(X,y,K=30,nval=round(n/3),XI=c(0.1,1,10),RHO=c(0.1,1,10))
hold.out$RMS


</code></pre>

<hr>
<h2 id='ENNreg_init'>Parameter initialization for the ENNreg model</h2><span id='topic+ENNreg_init'></span>

<h3>Description</h3>

<p><code>ENNreg_init</code> returns initial parameter values for the ENNreg model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ENNreg_init(X, y, K, nstart = 100, c = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ENNreg_init_+3A_x">X</code></td>
<td>
<p>Input matrix of size n x p, where n is the number of objects and p the number of
attributes.</p>
</td></tr>
<tr><td><code id="ENNreg_init_+3A_y">y</code></td>
<td>
<p>Vector of length n containing observations of the response variable.</p>
</td></tr>
<tr><td><code id="ENNreg_init_+3A_k">K</code></td>
<td>
<p>Number of prototypes.</p>
</td></tr>
<tr><td><code id="ENNreg_init_+3A_nstart">nstart</code></td>
<td>
<p>Number of random starts of the k-means algorithm (default: 100)</p>
</td></tr>
<tr><td><code id="ENNreg_init_+3A_c">c</code></td>
<td>
<p>Multiplicative coefficient applied to scale parameter gamma (defaut: 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prototypes are initialized by the k-means algorithm.
</p>


<h3>Value</h3>

<p>An object of class &quot;ENNreg&quot;, which can be passed to function <code><a href="#topic+ENNreg">ENNreg</a></code>.
</p>


<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ENNreg">ENNreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Boston dataset
library(MASS)
attach(Boston)
X &lt;- as.matrix(scale(Boston[,1:13]))
y &lt;- Boston[,14]
psi &lt;- ENNreg_init(X,y,K=30)
</code></pre>

<hr>
<h2 id='evreg'>evreg: A package for evidential regression</h2><span id='topic+evreg'></span>

<h3>Description</h3>

<p>The evreg package implements ENNreg  (Denoeux 2022, 2023b), a neural network model for
regression in which prediction uncertainty is quantified by Gaussian random fuzzy numbers
(GRFNs), a newly introduced family of random fuzzy subsets of the real line that
generalizes both Gaussian random variables and Gaussian possibility distributions
(Denoeux, 2023a). The evreg package contains functions for training the ENNreg model,
tuning hyperparameters by cross-validation or the hold-out method, and making predictions.
It also contains utilities for making calculations with GRFNs (such as, e.g., computing
the degrees of belief and plausibility of an interval, or combining GRFNs). The package
consists in the following main functions:
</p>

<dl>
<dt>ENNreg</dt><dd><p>Training of the ENNreg model</p>
</dd>
<dt>ENNreg_init</dt><dd><p>Initializing a ENNreg model</p>
</dd>
<dt>ENNreg_cv</dt><dd><p>Hyperparameter tuning using cross-validation</p>
</dd>
<dt>ENNreg_holdout</dt><dd><p>Hyperparameter tuning using cross-validation using hold-out</p>
</dd>
<dt>predict.ENNreg</dt><dd><p>Prediction with a trained ENNreg model</p>
</dd>
<dt>intervals</dt><dd><p>Computation of probabilistic and belief prediction intervals</p>
</dd>
<dt>Bel</dt><dd><p>Degree of belief of a real interval</p>
</dd>
<dt>Pl</dt><dd><p>Degree of plausibility of a real interval</p>
</dd>
<dt>Belint</dt><dd><p>Computation of an interval with given degree of belief</p>
</dd>
<dt>pl_contour</dt><dd><p>Plausibility contour function of a GRFN</p>
</dd>
<dt>combination_GRFN</dt><dd><p>Combination of two GRFNs</p>
</dd>
</dl>



<h3>References</h3>

<p>Thierry Denoeux. An evidential neural network model for regression based on random fuzzy
numbers. In &quot;Belief functions: Theory and applications (proc. of BELIEF 2022)&quot;, pages 57-66,
Springer, 2022.
</p>
<p>Thierry Denoeux. Quantifying prediction uncertainty in regression using random fuzzy sets: the ENNreg
model. TechRxiv preprint, 2023b.
</p>
<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023a.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ENNreg">ENNreg</a></code>, <code><a href="#topic+ENNreg_init">ENNreg_init</a></code>,<code><a href="#topic+ENNreg_cv">ENNreg_cv</a></code>,
<code><a href="#topic+ENNreg_holdout">ENNreg_holdout</a></code>, <code><a href="#topic+predict.ENNreg">predict.ENNreg</a></code>, <code><a href="#topic+intervals">intervals</a></code>,
<code><a href="#topic+intervals">intervals</a></code>, <code><a href="#topic+Bel">Bel</a></code>, <code><a href="#topic+Pl">Pl</a></code>,<code><a href="#topic+Belint">Belint</a></code>,
<code><a href="#topic+pl_contour">pl_contour</a></code>, <code><a href="#topic+combination_GRFN">combination_GRFN</a></code>.
</p>

<hr>
<h2 id='intervals'>Computation of prediction intervals from a trained ENNreg model</h2><span id='topic+intervals'></span>

<h3>Description</h3>

<p><code>intervals</code> computes probabilistic and belief prediction intervals from a prediction object
returned by function <code><a href="#topic+predict.ENNreg">predict.ENNreg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intervals(pred, level = 0.9, yt = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intervals_+3A_pred">pred</code></td>
<td>
<p>Prediction object returned by function <code><a href="#topic+predict.ENNreg">predict.ENNreg</a></code>.</p>
</td></tr>
<tr><td><code id="intervals_+3A_level">level</code></td>
<td>
<p>Level of the prediction interval (between 0 and 1).</p>
</td></tr>
<tr><td><code id="intervals_+3A_yt">yt</code></td>
<td>
<p>Optional vector of test response values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with four elements:
</p>

<dl>
<dt>INTP</dt><dd><p>Matrix (n,2) of probabilistic prediction intervals.</p>
</dd>
<dt>INTBel</dt><dd><p>Matrix (n,2) of belief prediction intervals.</p>
</dd>
<dt>coverage.P</dt><dd><p>Estimated coverage rate of the probabilistic intervals (if yt is provided).</p>
</dd>
<dt>coverage.Bel</dt><dd><p>Estimated coverage rate of the belief intervals (if yt is provided).</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+predict.ENNreg">predict.ENNreg</a></code>, <code><a href="#topic+ENNreg">ENNreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)

X&lt;-as.matrix(scale(Boston[,1:13]))
y&lt;-Boston[,14]
set.seed(220322)
n&lt;-nrow(Boston)
ntrain&lt;-round(0.7*n)
train &lt;-sample(n,ntrain)
fit &lt;- ENNreg(X[train,],y[train],K=30)
pred&lt;-predict(fit,newdata=X[-train,],yt=y[-train])
int&lt;- intervals(pred,level=0.95,y[-train])
print(c(int$coverage.P,int$coverage.Bel))


</code></pre>

<hr>
<h2 id='Pl'>Degree of plausibility of interval for a Gaussian random fuzzy number</h2><span id='topic+Pl'></span>

<h3>Description</h3>

<p><code>Pl</code> computes the degree of plausibility of an interval [x,y] for a given Gaussian
random fuzzy number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pl(x, y, GRFN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pl_+3A_x">x</code></td>
<td>
<p>The lower bound of the interval (may be a vector).</p>
</td></tr>
<tr><td><code id="Pl_+3A_y">y</code></td>
<td>
<p>The upper bound of the interval (may be a vector).</p>
</td></tr>
<tr><td><code id="Pl_+3A_grfn">GRFN</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The degree of plausibility of the interval.
</p>


<h3>References</h3>

<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Belint">Belint</a></code>, <code><a href="#topic+Bel">Bel</a></code>, <code><a href="#topic+pl_contour">pl_contour</a></code>,
<code><a href="#topic+combination_GRFN">combination_GRFN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pl&lt;-Pl(1,2,list(mu=2,sig=1,h=2))
print(pl)
</code></pre>

<hr>
<h2 id='pl_contour'>Contour function of a Gaussian random fuzzy number</h2><span id='topic+pl_contour'></span>

<h3>Description</h3>

<p><code>pl_contour</code> computes the degree of plausibility of any number x for a given Gaussian
random fuzzy number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pl_contour(x, GRFN)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pl_contour_+3A_x">x</code></td>
<td>
<p>The input value (can be a vector).</p>
</td></tr>
<tr><td><code id="pl_contour_+3A_grfn">GRFN</code></td>
<td>
<p>A Gaussian random fuzzy number, encoded as a list with components mu, sig
and h.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pl_contour(x,GRFN) returns the same value as Pl(x,x,GRFN), but is more efficient.
</p>


<h3>Value</h3>

<p>The degree of plausibility of x.
</p>


<h3>References</h3>

<p>Thierry Denoeux. Reasoning with fuzzy and uncertain evidence using epistemic random
fuzzy sets: general framework and practical models. Fuzzy Sets and Systems, Vol. 453,
Pages 1-36, 2023.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Pl">Pl</a></code>, <code><a href="#topic+Bel">Bel</a></code>, <code><a href="#topic+Belint">Belint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pl&lt;-pl_contour(1,list(mu=2,sig=1,h=2))
print(pl)
</code></pre>

<hr>
<h2 id='predict.ENNreg'>Prediction method for the ENNreg model</h2><span id='topic+predict.ENNreg'></span>

<h3>Description</h3>

<p>Predicted values based on a trained ENNreg model (object of class &quot;ENNreg&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ENNreg'
predict(object, newdata, yt = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ENNreg_+3A_object">object</code></td>
<td>
<p>An object of type &quot;ENNreg&quot;</p>
</td></tr>
<tr><td><code id="predict.ENNreg_+3A_newdata">newdata</code></td>
<td>
<p>Input matrix of attributes for test data</p>
</td></tr>
<tr><td><code id="predict.ENNreg_+3A_yt">yt</code></td>
<td>
<p>Optional test response vector</p>
</td></tr>
<tr><td><code id="predict.ENNreg_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions for the new data, coded as a list with the following components:
</p>

<dl>
<dt>mux</dt><dd><p>Predicted means</p>
</dd>
<dt>sigx</dt><dd><p>Predicted standard deviations.</p>
</dd>
<dt>hx</dt><dd><p>Prediction precisions.</p>
</dd>
<dt>Einf</dt><dd><p>Lower expectation.</p>
</dd>
<dt>Esup</dt><dd><p>Upper expectations</p>
</dd>
<dt>NLL</dt><dd><p>Negative log likelihood (computed only if yt is provided).</p>
</dd>
<dt>RMS</dt><dd><p>Root mean squared error (computed only if yt is provided).</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+ENNreg">ENNreg</a></code>, <code><a href="#topic+ENNreg_init">ENNreg_init</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Boston dataset

library(MASS)
X&lt;-as.matrix(scale(Boston[,1:13]))
y&lt;-Boston[,14]
set.seed(220322)
n&lt;-nrow(Boston)
ntrain&lt;-round(0.7*n)
train &lt;-sample(n,ntrain)
fit &lt;- ENNreg(X[train,],y[train],K=30)
pred&lt;-predict(fit,newdata=X[-train,],yt=y[-train])
plot(y[-train],pred$mux,xlab="observed response",ylab="predicted response")


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
