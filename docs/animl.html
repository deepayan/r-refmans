<!DOCTYPE html><html><head><title>Help for package animl</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {animl}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#animl'><p>Title</p></a></li>
<li><a href='#applyPredictions'><p>Apply Classifier Predictions and Merge DataFrames</p></a></li>
<li><a href='#bestGuess'><p>Select Best Classification From Multiple Frames</p></a></li>
<li><a href='#buildFileManifest'><p>Extract exif Data and Create File Manifest</p></a></li>
<li><a href='#checkFile'><p>Check for files existence and prompt user if they want to load</p></a></li>
<li><a href='#convertCoordinates'><p>Convert bbox from Relative to Absolute Coordinates</p></a></li>
<li><a href='#cropImageGenerator'><p>Tensorflow data generator that crops images to bounding box.</p></a></li>
<li><a href='#cropImageTrainGenerator'><p>Tensorflow data generator for training that crops images to bounding box.</p></a></li>
<li><a href='#detectObject'><p>Run MD on a Single Image</p></a></li>
<li><a href='#detectObjectBatch'><p>Run MegaDetector on a batch of images</p></a></li>
<li><a href='#extractBoxes'><p>Extract bounding boxes and save as new image from a batch of images</p></a></li>
<li><a href='#extractBoxesFromFlat'><p>Extract crops from a single image represented by a processed dataframe</p></a></li>
<li><a href='#extractBoxesFromMD'><p>Extract bounding boxes for a single image and save as new images</p></a></li>
<li><a href='#getAnimals'><p>Return a dataframe of only MD animals</p></a></li>
<li><a href='#getEmpty'><p>Return MD empty, vehicle and human images in a dataframe</p></a></li>
<li><a href='#imageAugmentationColor'><p>Perform image augmentation through random color adjustments on an image/label pair.</p></a></li>
<li><a href='#imageAugmentationGeometry'><p>Perform random geometric transformations on an image.</p></a></li>
<li><a href='#ImageGenerator'><p>Tensorflow data generator that resizes images.</p></a></li>
<li><a href='#ImageGeneratorSize'><p>Tensorflow data generator that resizes images and returns original image size.</p></a></li>
<li><a href='#imageLabel'><p>Load image and return a tensor with an image and a corresponding label.</p></a></li>
<li><a href='#imageLabelCrop'><p>Load image, crop and return a tensor with an image and a corresponding label.</p></a></li>
<li><a href='#imagesFromVideos'><p>Extract frames from video for classification</p></a></li>
<li><a href='#loadData'><p>Load .csv or .Rdata file</p></a></li>
<li><a href='#loadImage'><p>Load an image and return the full size image as an image tensor.</p></a></li>
<li><a href='#loadImageResize'><p>Load and resize an image and return an image tensor.</p></a></li>
<li><a href='#loadImageResizeCrop'><p>Load, resize and crop an image and return an image tensor.</p></a></li>
<li><a href='#loadImageResizeSize'><p>Load and resize an image and return an image tensor as well as a tensor with the original image size.</p></a></li>
<li><a href='#loadMDModel'><p>Load MegaDetector model file from directory or file</p></a></li>
<li><a href='#parseMD'><p>parse MD results into a simple dataframe</p></a></li>
<li><a href='#parseMDjson'><p>converte the JSON file produced bye the</p>
Python version of MegaDetector into the format
produced by detectObjectBatch</a></li>
<li><a href='#plotBoxes'><p>Plot bounding boxes on image from md results</p></a></li>
<li><a href='#predictSpecies'><p>Classifies Crops Using Specified Models</p></a></li>
<li><a href='#processYOLO5'><p>Process YOLO5 output and convert to MD format</p></a></li>
<li><a href='#resizePad'><p>Resize an image with padding</p></a></li>
<li><a href='#saveData'><p>Save Data to Given File</p></a></li>
<li><a href='#sequenceClassification'><p>Leverage sequences to classify images</p></a></li>
<li><a href='#setupDirectory'><p>Set Working Directory and Save File Global Variables</p></a></li>
<li><a href='#symlinkMD'><p>Create SymLink Directories and Sort Classified Images Based on MD Results</p></a></li>
<li><a href='#symlinkSpecies'><p>Create SymLink Directories and Sort Classified Images</p></a></li>
<li><a href='#symUnlink'><p>Remove Symlinks</p></a></li>
<li><a href='#testMD'><p>Select a Random Image and Run Through MegaDetector</p></a></li>
<li><a href='#updateResults'><p>Title</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Collection of ML Tools for Conservation Research</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions required to classify subjects within camera trap field data. The package can handle both images and videos. The authors recommend a two-step approach using Microsoft's 'MegaDector' model and then a second model trained on the classes of interest.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, methods, pbapply, dplyr, jpeg, keras, reticulate,
tfdatasets, parallel, exifr, av, magrittr, stats, imager,</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), tensorflow (&ge; 2.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-12 20:53:44 UTC; Kyra</td>
</tr>
<tr>
<td>Author:</td>
<td>Kyra Swanson <a href="https://orcid.org/0000-0002-1496-3217"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Mathias Tobler [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kyra Swanson &lt;tswanson@sdzwa.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-13 05:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='animl'>Title</h2><span id='topic+animl'></span>

<h3>Description</h3>

<p>Title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>animl(imagedir, mdmodel, speciesmodel, classes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="animl_+3A_imagedir">imagedir</code></td>
<td>
<p>description</p>
</td></tr>
<tr><td><code id="animl_+3A_mdmodel">mdmodel</code></td>
<td>
<p>description</p>
</td></tr>
<tr><td><code id="animl_+3A_speciesmodel">speciesmodel</code></td>
<td>
<p>description</p>
</td></tr>
<tr><td><code id="animl_+3A_classes">classes</code></td>
<td>
<p>description</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
imagedir &lt;- "examples/test_data/Southwest"
 mdmodel &lt;- "/mnt/machinelearning/megaDetector/md_v5b.0.0_saved_model"
 modelfile &lt;- "/mnt/machinelearning/Models/Southwest/2022/Southwest_v2.h5"
 classes &lt;- "/mnt/machinelearning/Models/Southwest/2022/classes.txt"
 animl(imagedir,mdmodel,modelfile,classes) 
## End(Not run)
</code></pre>

<hr>
<h2 id='applyPredictions'>Apply Classifier Predictions and Merge DataFrames</h2><span id='topic+applyPredictions'></span>

<h3>Description</h3>

<p>Apply Classifier Predictions and Merge DataFrames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyPredictions(animals, pred, classfile, outfile = NULL, counts = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="applyPredictions_+3A_animals">animals</code></td>
<td>
<p>Set of animal crops/images</p>
</td></tr>
<tr><td><code id="applyPredictions_+3A_pred">pred</code></td>
<td>
<p>Classifier predictions for animal crops/images</p>
</td></tr>
<tr><td><code id="applyPredictions_+3A_classfile">classfile</code></td>
<td>
<p>.txt file containing common names for species classes</p>
</td></tr>
<tr><td><code id="applyPredictions_+3A_outfile">outfile</code></td>
<td>
<p>File to which results are saved</p>
</td></tr>
<tr><td><code id="applyPredictions_+3A_counts">counts</code></td>
<td>
<p>Returns a table of all predictions, defaults to FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fully merged dataframe with Species predictions and confidence weighted by MD conf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
alldata &lt;- applyPredictions(animals,empty,classfile,pred,counts = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='bestGuess'>Select Best Classification From Multiple Frames</h2><span id='topic+bestGuess'></span>

<h3>Description</h3>

<p>Select Best Classification From Multiple Frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestGuess(
  manifest,
  sort = "count",
  count = FALSE,
  shrink = FALSE,
  outfile = NULL,
  prompt = TRUE,
  parallel = FALSE,
  workers = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestGuess_+3A_manifest">manifest</code></td>
<td>
<p>dataframe of all frames including species classification</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_sort">sort</code></td>
<td>
<p>method for selecting best prediction, defaults to most frequent</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_count">count</code></td>
<td>
<p>if true, return column with number of MD crops for that animal (does not work for images)</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_shrink">shrink</code></td>
<td>
<p>if true, return a reduced dataframe with one row per image</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_outfile">outfile</code></td>
<td>
<p>file path to which the data frame should be saved</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_prompt">prompt</code></td>
<td>
<p>if true, prompts the user to confirm overwrite</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_parallel">parallel</code></td>
<td>
<p>Toggle for parallel processing, defaults to FALSE</p>
</td></tr>
<tr><td><code id="bestGuess_+3A_workers">workers</code></td>
<td>
<p>number of processors to use if parallel, defaults to 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe with new prediction in &quot;Species&quot; column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mdmanifest &lt;- bestGuess(manifest, sort = "conf")

## End(Not run)
</code></pre>

<hr>
<h2 id='buildFileManifest'>Extract exif Data and Create File Manifest</h2><span id='topic+buildFileManifest'></span>

<h3>Description</h3>

<p>Extract exif Data and Create File Manifest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildFileManifest(imagedir, exif = TRUE, offset = 0, outfile = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="buildFileManifest_+3A_imagedir">imagedir</code></td>
<td>
<p>file path</p>
</td></tr>
<tr><td><code id="buildFileManifest_+3A_exif">exif</code></td>
<td>
<p>returns date and time information from exif data, defaults to true</p>
</td></tr>
<tr><td><code id="buildFileManifest_+3A_offset">offset</code></td>
<td>
<p>add offset to videos, defaults to 0</p>
</td></tr>
<tr><td><code id="buildFileManifest_+3A_outfile">outfile</code></td>
<td>
<p>file path to which the data frame should be saved</p>
</td></tr>
</table>


<h3>Value</h3>

<p>files dataframe with or without file modify dates
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
files &lt;- extractFiles("C:\\Users\\usr\\Pictures\\")

## End(Not run)
</code></pre>

<hr>
<h2 id='checkFile'>Check for files existence and prompt user if they want to load</h2><span id='topic+checkFile'></span>

<h3>Description</h3>

<p>Check for files existence and prompt user if they want to load
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkFile(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkFile_+3A_file">file</code></td>
<td>
<p>the full path of the file to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a boolean indicating wether a file was found
and the user wants to load or not
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  checkFile("path/to/newfile.csv")

## End(Not run)
</code></pre>

<hr>
<h2 id='convertCoordinates'>Convert bbox from Relative to Absolute Coordinates</h2><span id='topic+convertCoordinates'></span>

<h3>Description</h3>

<p>Each row is a MD bounding box, there can be multiple bounding boxes per image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertCoordinates(results)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertCoordinates_+3A_results">results</code></td>
<td>
<p>list of bounding boxes for each image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with one entry for each bounding box
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 images&lt;-read_exif(imagedir,tags=c("filename","directory","DateTimeOriginal","FileModifyDate"),
                   recursive = TRUE)
 colnames(images)[1]&lt;-"FilePath"
 mdsession&lt;-loadMDModel(mdmodel)
 mdres&lt;-classifyImagesBatchMD(mdsession,images$FilePath,
                              resultsfile=resultsfile,checkpoint = 2500)
 mdresflat&lt;-convertresults(mdres)

## End(Not run)
</code></pre>

<hr>
<h2 id='cropImageGenerator'>Tensorflow data generator that crops images to bounding box.</h2><span id='topic+cropImageGenerator'></span>

<h3>Description</h3>

<p>Creates an image data generator that crops images based on bounding box coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cropImageGenerator(
  files,
  boxes,
  resize_height = 456,
  resize_width = 456,
  standardize = FALSE,
  batch = 32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cropImageGenerator_+3A_files">files</code></td>
<td>
<p>a vector of file names</p>
</td></tr>
<tr><td><code id="cropImageGenerator_+3A_boxes">boxes</code></td>
<td>
<p>a data frame or matrix of bounding box coordinates in the format left, top, width, height.</p>
</td></tr>
<tr><td><code id="cropImageGenerator_+3A_resize_height">resize_height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="cropImageGenerator_+3A_resize_width">resize_width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="cropImageGenerator_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image to the range 0 to 1, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageGenerator_+3A_batch">batch</code></td>
<td>
<p>the batch size for the image generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tensorflow image data generator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: #' dataset &lt;- cropImageGenerator(images, boxes, standardize = FALSE, batch = batch)
</code></pre>

<hr>
<h2 id='cropImageTrainGenerator'>Tensorflow data generator for training that crops images to bounding box.</h2><span id='topic+cropImageTrainGenerator'></span>

<h3>Description</h3>

<p>Creates an image data generator that crops images based on bounding box coordinates and returnes an image/label pair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cropImageTrainGenerator(
  files,
  boxes,
  label,
  classes,
  resize_height = 456,
  resize_width = 456,
  standardize = FALSE,
  augmentation_color = FALSE,
  augmentation_geometry = FALSE,
  shuffle = FALSE,
  cache = FALSE,
  cache_dir = NULL,
  return_iterator = FALSE,
  batch = 32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cropImageTrainGenerator_+3A_files">files</code></td>
<td>
<p>a vector of file names</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_boxes">boxes</code></td>
<td>
<p>a data frame or matrix of bounding box coordinates in the format left, top, width, height.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_label">label</code></td>
<td>
<p>a vector of labels</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_classes">classes</code></td>
<td>
<p>a vector of all classes for the active model</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_resize_height">resize_height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_resize_width">resize_width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image to the range 0 to 1, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_augmentation_color">augmentation_color</code></td>
<td>
<p>use data augmentation to change the color, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_augmentation_geometry">augmentation_geometry</code></td>
<td>
<p>use data augmentation to change the geometry of the images, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_shuffle">shuffle</code></td>
<td>
<p>return data pairas in random order, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_cache">cache</code></td>
<td>
<p>use caching to reduce reading from disk, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_cache_dir">cache_dir</code></td>
<td>
<p>directory used for caching, if none provided chaching will be done in memory.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_return_iterator">return_iterator</code></td>
<td>
<p>Should an iterator be returned? If RALSE a tfdataset will be returned.</p>
</td></tr>
<tr><td><code id="cropImageTrainGenerator_+3A_batch">batch</code></td>
<td>
<p>the batch size for the image generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tensorflow image data generator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataset &lt;- cropImageTrainGenerator(images, standardize = FALSE, batch = batch)
## End(Not run)
</code></pre>

<hr>
<h2 id='detectObject'>Run MD on a Single Image</h2><span id='topic+detectObject'></span>

<h3>Description</h3>

<p>Returns the MD bounding boxes, classes, confidence above the min_conf
threshold for a single image. #' Requires a an mdsession is already
loaded (see loadMDModel() ) and the file path of the image in question.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectObject(mdsession, imagefile, mdversion = 5, min_conf = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detectObject_+3A_mdsession">mdsession</code></td>
<td>
<p>Should be the output from loadMDmodel(model)</p>
</td></tr>
<tr><td><code id="detectObject_+3A_imagefile">imagefile</code></td>
<td>
<p>The path for the image in question</p>
</td></tr>
<tr><td><code id="detectObject_+3A_mdversion">mdversion</code></td>
<td>
<p>MegaDetector version, defaults to 5</p>
</td></tr>
<tr><td><code id="detectObject_+3A_min_conf">min_conf</code></td>
<td>
<p>Confidence threshold for returning bounding boxes, defaults to 0.1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of MD bounding boxes, classes, and confidence for the image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 images &lt;- read_exif(imagedir, 
                     tags = c("filename", "directory", "FileModifyDate"), 
                     recursive = TRUE)
 colnames(images)[1] &lt;- "FilePath"
 mdsession &lt;- loadMDModel(mdmodel)
 mdres &lt;- classifyImageMD(mdsession, images$FilePath[1])

## End(Not run)
</code></pre>

<hr>
<h2 id='detectObjectBatch'>Run MegaDetector on a batch of images</h2><span id='topic+detectObjectBatch'></span>

<h3>Description</h3>

<p>Runs MD on a list of image filepaths.
Can resume for a results file and will checkpoint the results after a set
number of images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detectObjectBatch(
  mdsession,
  images,
  mdversion = 5,
  min_conf = 0.1,
  batch = 1,
  outfile = NULL,
  checkpoint = 5000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detectObjectBatch_+3A_mdsession">mdsession</code></td>
<td>
<p>should be the output from loadMDmodel(model)</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_images">images</code></td>
<td>
<p>list of image filepaths</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_mdversion">mdversion</code></td>
<td>
<p>select MegaDetector version, defaults to 5</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_min_conf">min_conf</code></td>
<td>
<p>Confidence threshold for returning bounding boxes, defaults to 0.1</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_batch">batch</code></td>
<td>
<p>Process images in batches, defaults to 1</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_outfile">outfile</code></td>
<td>
<p>File containing previously checkpointed results</p>
</td></tr>
<tr><td><code id="detectObjectBatch_+3A_checkpoint">checkpoint</code></td>
<td>
<p>Bank results after processing a number of images, defaults to 5000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of lists of bounding boxes for each image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
images &lt;- read_exif(imagedir,
  tags = c("filename", "directory", "DateTimeOriginal", "FileModifyDate"),
  recursive = TRUE)
colnames(images)[1] &lt;- "FilePath"
mdsession &lt;- loadMDModel(mdmodel)
mdres &lt;- classifyImagesBatchMD(mdsession, images$FilePath,
  outfile = mdoutfile, checkpoint = 2500)

## End(Not run)
</code></pre>

<hr>
<h2 id='extractBoxes'>Extract bounding boxes and save as new image from a batch of images</h2><span id='topic+extractBoxes'></span>

<h3>Description</h3>

<p>Extract bounding boxes and save as new image from a batch of images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractBoxes(
  images,
  min_conf = 0,
  buffer = 0,
  save = FALSE,
  resize = NA,
  outdir = "",
  quality = 0.8,
  parallel = FALSE,
  nproc = parallel::detectCores()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractBoxes_+3A_images">images</code></td>
<td>
<p>list of MD output or flat data.frame</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_min_conf">min_conf</code></td>
<td>
<p>Confidence threshold (defaults to 0, not in use)</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_buffer">buffer</code></td>
<td>
<p>Adds a buffer to the MD bounding box, defaults to 2px</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_save">save</code></td>
<td>
<p>Toggle to save output cropped, defaults to FALSE</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_resize">resize</code></td>
<td>
<p>Size in pixels to resize cropped images, NA if images are not resized, defaults to NA</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_outdir">outdir</code></td>
<td>
<p>Directory in which output cropped images will be saved</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_quality">quality</code></td>
<td>
<p>Compression level of output cropped image, defaults to 0.8</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_parallel">parallel</code></td>
<td>
<p>Toggle to enable parallel processing, defaults to FALSE</p>
</td></tr>
<tr><td><code id="extractBoxes_+3A_nproc">nproc</code></td>
<td>
<p>Number of workers if parallel = TRUE, defaults to output of detectCores()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variable crop_rel_path in the image list or data.frame can be used to change the path where the crops will be stored.
</p>
<p>The final output path will be the outdir plus the crop_rel_path.
</p>


<h3>Value</h3>

<p>a flattened dataframe containing crop information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
images &lt;- read_exif(imagedir, tags = c("filename", "directory"), recursive = TRUE)
crops &lt;- extractAllBoxes(images,save=TRUE,out)

## End(Not run)
</code></pre>

<hr>
<h2 id='extractBoxesFromFlat'>Extract crops from a single image represented by a processed dataframe</h2><span id='topic+extractBoxesFromFlat'></span>

<h3>Description</h3>

<p>Extract crops from a single image represented by a processed dataframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractBoxesFromFlat(
  image,
  min_conf = 0,
  buffer = 0,
  save = TRUE,
  resize = NA,
  outdir = "",
  quality = 0.8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractBoxesFromFlat_+3A_image">image</code></td>
<td>
<p>dataframe containing MD output (assumes single row)</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_min_conf">min_conf</code></td>
<td>
<p>Confidence threshold (defaults to 0, not in use)</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_buffer">buffer</code></td>
<td>
<p>Adds a buffer to the MD bounding box, defaults to 2px</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_save">save</code></td>
<td>
<p>Toggle to save output cropped, defaults to FALSE</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_resize">resize</code></td>
<td>
<p>Size in pixels to resize cropped images, NA if images are not resized, defaults to NA</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_outdir">outdir</code></td>
<td>
<p>Directory in which output cropped images will be saved</p>
</td></tr>
<tr><td><code id="extractBoxesFromFlat_+3A_quality">quality</code></td>
<td>
<p>Compression level of output cropped image, defaults to 0.8</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variable crop_rel_path in the image list can be used to change the path where the crops will be stored.
</p>
<p>The final output path will be the outdir plus the crop_rel_path.
</p>


<h3>Value</h3>

<p>A dataframe containing image and crop paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
crops &lt;- extractBoxesFromFlat(mdresflat[1, ], save = TRUE, out)

## End(Not run)
</code></pre>

<hr>
<h2 id='extractBoxesFromMD'>Extract bounding boxes for a single image and save as new images</h2><span id='topic+extractBoxesFromMD'></span>

<h3>Description</h3>

<p>Requires the unflattened raw MD output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractBoxesFromMD(
  image,
  min_conf = 0,
  buffer = 0,
  return.crops = FALSE,
  save = FALSE,
  resize = NA,
  outdir = "",
  quality = 0.8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractBoxesFromMD_+3A_image">image</code></td>
<td>
<p>single image, raw MD output format (list)</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_min_conf">min_conf</code></td>
<td>
<p>Confidence threshold (defaults to 0, not in use)</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_buffer">buffer</code></td>
<td>
<p>Adds a buffer to the MD bounding box, defaults to 2px</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_return.crops">return.crops</code></td>
<td>
<p>Toggle to return list of cropped images, defaults to FALSE</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_save">save</code></td>
<td>
<p>Toggle to save output cropped, defaults to FALSE</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_resize">resize</code></td>
<td>
<p>Size in pixels to resize cropped images, NA if images are not resized, defaults to NA</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_outdir">outdir</code></td>
<td>
<p>Directory in which output cropped images will be saved</p>
</td></tr>
<tr><td><code id="extractBoxesFromMD_+3A_quality">quality</code></td>
<td>
<p>Compression level of output cropped image, defaults to 0.8</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variable crop_rel_path in the image list can be used to change the path where the crops will be stored.
</p>
<p>The final output path will be the outdir plus the crop_rel_path.
</p>


<h3>Value</h3>

<p>a flattened data.frame containing crop information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
images &lt;- read_exif(imagedir, tags = c("filename","directory"), recursive = TRUE)
crops &lt;- extractBoxesFromMD(images[1, ], return.crops = TRUE, save = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='getAnimals'>Return a dataframe of only MD animals</h2><span id='topic+getAnimals'></span>

<h3>Description</h3>

<p>Return a dataframe of only MD animals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAnimals(manifest)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAnimals_+3A_manifest">manifest</code></td>
<td>
<p>all megadetector frames</p>
</td></tr>
</table>


<h3>Value</h3>

<p>animal frames classified by MD
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
animals &lt;- getAnimals(imagesall)

## End(Not run)
</code></pre>

<hr>
<h2 id='getEmpty'>Return MD empty, vehicle and human images in a dataframe</h2><span id='topic+getEmpty'></span>

<h3>Description</h3>

<p>Return MD empty, vehicle and human images in a dataframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEmpty(manifest)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEmpty_+3A_manifest">manifest</code></td>
<td>
<p>all megadetector frames</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of empty/human/vehicle allframes with md classification
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
empty &lt;- getEmpty(imagesall)

## End(Not run)
</code></pre>

<hr>
<h2 id='imageAugmentationColor'>Perform image augmentation through random color adjustments on an image/label pair.</h2><span id='topic+imageAugmentationColor'></span>

<h3>Description</h3>

<p>Performs image augmentation on a image/label pair for training. Uses random brightness,contrast,saturation, and hue.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imageAugmentationColor(image, label, rng)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imageAugmentationColor_+3A_image">image</code></td>
<td>
<p>an image tensor.</p>
</td></tr>
<tr><td><code id="imageAugmentationColor_+3A_label">label</code></td>
<td>
<p>a label tensor.</p>
</td></tr>
<tr><td><code id="imageAugmentationColor_+3A_rng">rng</code></td>
<td>
<p>a random number generator use to generate a random seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image and label tensor.
</p>

<hr>
<h2 id='imageAugmentationGeometry'>Perform random geometric transformations on an image.</h2><span id='topic+imageAugmentationGeometry'></span>

<h3>Description</h3>

<p>Returns a keras model that performs random geometric transformations on an image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imageAugmentationGeometry()
</code></pre>


<h3>Value</h3>

<p>A keras model.
</p>

<hr>
<h2 id='ImageGenerator'>Tensorflow data generator that resizes images.</h2><span id='topic+ImageGenerator'></span>

<h3>Description</h3>

<p>Creates an image data generator that resizes images if requested.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageGenerator(
  files,
  resize_height = NULL,
  resize_width = NULL,
  standardize = FALSE,
  batch = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageGenerator_+3A_files">files</code></td>
<td>
<p>a vector of file names</p>
</td></tr>
<tr><td><code id="ImageGenerator_+3A_resize_height">resize_height</code></td>
<td>
<p>the height the cropped image will be resized to. If NULL returns original size images.</p>
</td></tr>
<tr><td><code id="ImageGenerator_+3A_resize_width">resize_width</code></td>
<td>
<p>the width the cropped image will be resized to. If NULL returns original size images..</p>
</td></tr>
<tr><td><code id="ImageGenerator_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image to the range 0 to 1, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="ImageGenerator_+3A_batch">batch</code></td>
<td>
<p>the batch size for the image generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tensorflow image data generator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataset &lt;- ImageGenerator(images, standardize = FALSE, batch = batch)

## End(Not run)
</code></pre>

<hr>
<h2 id='ImageGeneratorSize'>Tensorflow data generator that resizes images and returns original image size.</h2><span id='topic+ImageGeneratorSize'></span>

<h3>Description</h3>

<p>Creates an image data generator that resizes images if requested and also returns the original images size needed for MegaDetector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImageGeneratorSize(
  files,
  resize_height = NULL,
  resize_width = NULL,
  pad = FALSE,
  standardize = FALSE,
  batch = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImageGeneratorSize_+3A_files">files</code></td>
<td>
<p>a vector of file names</p>
</td></tr>
<tr><td><code id="ImageGeneratorSize_+3A_resize_height">resize_height</code></td>
<td>
<p>the height the cropped image will be resized to. If NULL returns original size images.</p>
</td></tr>
<tr><td><code id="ImageGeneratorSize_+3A_resize_width">resize_width</code></td>
<td>
<p>the width the cropped image will be resized to. If NULL returns original size images..</p>
</td></tr>
<tr><td><code id="ImageGeneratorSize_+3A_pad">pad</code></td>
<td>
<p>pad the image instead of stretching it, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="ImageGeneratorSize_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image to the range 0 to 1, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="ImageGeneratorSize_+3A_batch">batch</code></td>
<td>
<p>the batch size for the image generator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tensorflow image data generator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataset &lt;- ImageGenerator(images, standardize = FALSE, batch = batch)

## End(Not run)
</code></pre>

<hr>
<h2 id='imageLabel'>Load image and return a tensor with an image and a corresponding label.</h2><span id='topic+imageLabel'></span>

<h3>Description</h3>

<p>Load image and return a tensor with an image and a corresponding label. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imageLabel(data, classes, height = 299, width = 299, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imageLabel_+3A_data">data</code></td>
<td>
<p>a list with the first element being an image file path and the second element a label.</p>
</td></tr>
<tr><td><code id="imageLabel_+3A_classes">classes</code></td>
<td>
<p>list of classes</p>
</td></tr>
<tr><td><code id="imageLabel_+3A_height">height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="imageLabel_+3A_width">width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="imageLabel_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image and label tensor.
</p>

<hr>
<h2 id='imageLabelCrop'>Load image, crop and return a tensor with an image and a corresponding label.</h2><span id='topic+imageLabelCrop'></span>

<h3>Description</h3>

<p>Load image, crop and return a tensor with an image and a corresponding label. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imageLabelCrop(data, classes, height = 299, width = 299, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imageLabelCrop_+3A_data">data</code></td>
<td>
<p>a list with the first element being an image file path, the next four elements being the bounding box coordinates and the last element a label</p>
</td></tr>
<tr><td><code id="imageLabelCrop_+3A_classes">classes</code></td>
<td>
<p>list of classes</p>
</td></tr>
<tr><td><code id="imageLabelCrop_+3A_height">height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="imageLabelCrop_+3A_width">width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="imageLabelCrop_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image and label tensor.
</p>

<hr>
<h2 id='imagesFromVideos'>Extract frames from video for classification</h2><span id='topic+imagesFromVideos'></span>

<h3>Description</h3>

<p>This function can take
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imagesFromVideos(
  files,
  outdir = tempfile(),
  outfile = NULL,
  format = "jpg",
  fps = NULL,
  frames = NULL,
  parallel = FALSE,
  workers = 1,
  checkpoint = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imagesFromVideos_+3A_files">files</code></td>
<td>
<p>dataframe of videos</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_outdir">outdir</code></td>
<td>
<p>directory to save frames to</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_outfile">outfile</code></td>
<td>
<p>file to which results will be saved</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_format">format</code></td>
<td>
<p>output format for frames, defaults to jpg</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_fps">fps</code></td>
<td>
<p>frames per second, otherwise determine mathematically</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_frames">frames</code></td>
<td>
<p>number of frames to sample</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_parallel">parallel</code></td>
<td>
<p>Toggle for parallel processing, defaults to FALSE</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_workers">workers</code></td>
<td>
<p>number of processors to use if parallel, defaults to 1</p>
</td></tr>
<tr><td><code id="imagesFromVideos_+3A_checkpoint">checkpoint</code></td>
<td>
<p>if not parallel, checkpoint ever n files, defaults to 1000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe of still frames for each video
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
frames &lt;- imagesFromVideos(videos, outdir = "C:\\Users\\usr\\Videos\\", frames = 5)

## End(Not run)
</code></pre>

<hr>
<h2 id='loadData'>Load .csv or .Rdata file</h2><span id='topic+loadData'></span>

<h3>Description</h3>

<p>Load .csv or .Rdata file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadData(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadData_+3A_file">file</code></td>
<td>
<p>the full path of the file to load</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data extracted from the file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  loadData("path/to/newfile.csv")

## End(Not run)
</code></pre>

<hr>
<h2 id='loadImage'>Load an image and return the full size image as an image tensor.</h2><span id='topic+loadImage'></span>

<h3>Description</h3>

<p>Load an image and return the full size an image tensor. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImage(file, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadImage_+3A_file">file</code></td>
<td>
<p>path to a JPEG file</p>
</td></tr>
<tr><td><code id="loadImage_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image tensor.
</p>

<hr>
<h2 id='loadImageResize'>Load and resize an image and return an image tensor.</h2><span id='topic+loadImageResize'></span>

<h3>Description</h3>

<p>Load and resize an image and return an image tensor. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImageResize(
  file,
  height = 299,
  width = 299,
  pad = FALSE,
  standardize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadImageResize_+3A_file">file</code></td>
<td>
<p>path to a JPEG file</p>
</td></tr>
<tr><td><code id="loadImageResize_+3A_height">height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResize_+3A_width">width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResize_+3A_pad">pad</code></td>
<td>
<p>logical indicating whether the images should be padded or streched.</p>
</td></tr>
<tr><td><code id="loadImageResize_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image tensor.
</p>

<hr>
<h2 id='loadImageResizeCrop'>Load, resize and crop an image and return an image tensor.</h2><span id='topic+loadImageResizeCrop'></span>

<h3>Description</h3>

<p>Load a JPEG image and crop it to a bounding box. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImageResizeCrop(data, height = 299, width = 299, standardize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadImageResizeCrop_+3A_data">data</code></td>
<td>
<p>a list with the first element being a path to an image file and the next four arguments being the bounding box coordinates.</p>
</td></tr>
<tr><td><code id="loadImageResizeCrop_+3A_height">height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResizeCrop_+3A_width">width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResizeCrop_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tensorflow image data generator.
</p>

<hr>
<h2 id='loadImageResizeSize'>Load and resize an image and return an image tensor as well as a tensor with the original image size.</h2><span id='topic+loadImageResizeSize'></span>

<h3>Description</h3>

<p>Load and resize an image and return an image tensor as well as a tensor with the original image size. Internal function to be called by image generator function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImageResizeSize(
  file,
  height = 299,
  width = 299,
  pad = FALSE,
  standardize = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadImageResizeSize_+3A_file">file</code></td>
<td>
<p>path to a JPEG file</p>
</td></tr>
<tr><td><code id="loadImageResizeSize_+3A_height">height</code></td>
<td>
<p>the height the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResizeSize_+3A_width">width</code></td>
<td>
<p>the width the cropped image will be resized to.</p>
</td></tr>
<tr><td><code id="loadImageResizeSize_+3A_pad">pad</code></td>
<td>
<p>pad the image instead of stretching it, TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="loadImageResizeSize_+3A_standardize">standardize</code></td>
<td>
<p>standardize the image, TRUE or FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An image tensor.
</p>

<hr>
<h2 id='loadMDModel'>Load MegaDetector model file from directory or file</h2><span id='topic+loadMDModel'></span>

<h3>Description</h3>

<p>Load MegaDetector model file from directory or file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadMDModel(modelfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadMDModel_+3A_modelfile">modelfile</code></td>
<td>
<p>.pb file or directory obtained from megaDetector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tfsession containing the MD model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mdmodel &lt;- "megadetector_v4.1.pb"
mdsession &lt;- loadMDModel(mdmodel)

## End(Not run)
</code></pre>

<hr>
<h2 id='parseMD'>parse MD results into a simple dataframe</h2><span id='topic+parseMD'></span>

<h3>Description</h3>

<p>parse MD results into a simple dataframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parseMD(mdresults, manifest = NULL, outfile = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parseMD_+3A_mdresults">mdresults</code></td>
<td>
<p>raw MegaDetector output</p>
</td></tr>
<tr><td><code id="parseMD_+3A_manifest">manifest</code></td>
<td>
<p>dataframe containing all frames</p>
</td></tr>
<tr><td><code id="parseMD_+3A_outfile">outfile</code></td>
<td>
<p>file path to save dataframe to</p>
</td></tr>
</table>


<h3>Value</h3>

<p>original dataframe including md results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mdresults &lt;- parseMD(mdres)

## End(Not run)
</code></pre>

<hr>
<h2 id='parseMDjson'>converte the JSON file produced bye the
Python version of MegaDetector into the format
produced by detectObjectBatch</h2><span id='topic+parseMDjson'></span>

<h3>Description</h3>

<p>converte the JSON file produced bye the
Python version of MegaDetector into the format
produced by detectObjectBatch
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parseMDjson(json)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parseMDjson_+3A_json">json</code></td>
<td>
<p>json data in a list format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of MegaDetector results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mdresults &lt;- parseMDjson(json)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotBoxes'>Plot bounding boxes on image from md results</h2><span id='topic+plotBoxes'></span>

<h3>Description</h3>

<p>Plot bounding boxes on image from md results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBoxes(image, label = FALSE, minconf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBoxes_+3A_image">image</code></td>
<td>
<p>The mdres for the image</p>
</td></tr>
<tr><td><code id="plotBoxes_+3A_label">label</code></td>
<td>
<p>T/F toggle to plot MD category</p>
</td></tr>
<tr><td><code id="plotBoxes_+3A_minconf">minconf</code></td>
<td>
<p>minimum confidence to plot box</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no return value, produces bounding box in plot panel
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mdres &lt;- classifyImageMD(mdsession, images$FilePath[30000])
plotBoxes(mdres, minconf = 0.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='predictSpecies'>Classifies Crops Using Specified Models</h2><span id='topic+predictSpecies'></span>

<h3>Description</h3>

<p>Classifies Crops Using Specified Models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictSpecies(
  input,
  model,
  resize = 456,
  standardize = FALSE,
  batch = 1,
  workers = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictSpecies_+3A_input">input</code></td>
<td>
<p>either dataframe with MD crops or list of filenames</p>
</td></tr>
<tr><td><code id="predictSpecies_+3A_model">model</code></td>
<td>
<p>models with which to classify species</p>
</td></tr>
<tr><td><code id="predictSpecies_+3A_resize">resize</code></td>
<td>
<p>resize images before classification, defaults to 299x299px</p>
</td></tr>
<tr><td><code id="predictSpecies_+3A_standardize">standardize</code></td>
<td>
<p>standardize images, defaults to FALSE</p>
</td></tr>
<tr><td><code id="predictSpecies_+3A_batch">batch</code></td>
<td>
<p>number of images processed in each batch (keep small)</p>
</td></tr>
<tr><td><code id="predictSpecies_+3A_workers">workers</code></td>
<td>
<p>number of cores</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of likelihoods for each class for each image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pred &lt;- classifySpecies(imagesallanimal, paste0(modelfile, ".h5"),
                      resize = 456, standardize = FALSE, batch_size = 64, workers = 8)

## End(Not run)
</code></pre>

<hr>
<h2 id='processYOLO5'>Process YOLO5 output and convert to MD format</h2><span id='topic+processYOLO5'></span>

<h3>Description</h3>

<p>Returns a list with the standard MD output format. Used for batch processing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>processYOLO5(n, boxes, classes, scores, selection, batch)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="processYOLO5_+3A_n">n</code></td>
<td>
<p>index for the record in the batch</p>
</td></tr>
<tr><td><code id="processYOLO5_+3A_boxes">boxes</code></td>
<td>
<p>array of boxes returned by combined_non_max_suppression</p>
</td></tr>
<tr><td><code id="processYOLO5_+3A_classes">classes</code></td>
<td>
<p>vector of classes returned by combined_non_max_suppression</p>
</td></tr>
<tr><td><code id="processYOLO5_+3A_scores">scores</code></td>
<td>
<p>vector of probabilities returned by combined_non_max_suppression</p>
</td></tr>
<tr><td><code id="processYOLO5_+3A_selection">selection</code></td>
<td>
<p>vector of number of detected boxes returned by combined_non_max_suppression</p>
</td></tr>
<tr><td><code id="processYOLO5_+3A_batch">batch</code></td>
<td>
<p>batch used to detect objects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of MD bounding boxes, classes, and confidence for the image
</p>

<hr>
<h2 id='resizePad'>Resize an image with padding</h2><span id='topic+resizePad'></span>

<h3>Description</h3>

<p>Resize an image with padding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resizePad(img, size = 256)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resizePad_+3A_img">img</code></td>
<td>
<p>the image, read by jpeg library</p>
</td></tr>
<tr><td><code id="resizePad_+3A_size">size</code></td>
<td>
<p>new size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns resized jpeg image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
crop &lt;- resizePad(cropped_image_path,256)

## End(Not run)
</code></pre>

<hr>
<h2 id='saveData'>Save Data to Given File</h2><span id='topic+saveData'></span>

<h3>Description</h3>

<p>Save Data to Given File
</p>


<h3>Usage</h3>

<pre><code class='language-R'>saveData(data, outfile, prompt = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="saveData_+3A_data">data</code></td>
<td>
<p>the dataframe to be saved</p>
</td></tr>
<tr><td><code id="saveData_+3A_outfile">outfile</code></td>
<td>
<p>the full path of the saved file</p>
</td></tr>
<tr><td><code id="saveData_+3A_prompt">prompt</code></td>
<td>
<p>if true, prompts the user to confirm overwrite</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 saveData(files,"path/to/newfile.csv")

## End(Not run)
</code></pre>

<hr>
<h2 id='sequenceClassification'>Leverage sequences to classify images</h2><span id='topic+sequenceClassification'></span>

<h3>Description</h3>

<p>This function applies image classifications at a sequence level by leveraging
information from multiple images. A sequence is defined as all images at the same
camera/station where the time between consecutive images is &lt;=maxdiff. This can improve
classification accuracy, but assumes that only one species is present in each sequence.
If you regularly expect multiple species to occur in an image or sequence don't use this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequenceClassification(
  animals,
  empty = NULL,
  predictions,
  classes,
  emptyclass = "",
  stationcolumn,
  sortcolumns = NULL,
  maxdiff = 60
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequenceClassification_+3A_animals">animals</code></td>
<td>
<p>sub-selection of all images that contain MD animals</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_empty">empty</code></td>
<td>
<p>optional, data frame non-animal images (empty, human and vehicle) that will be merged back with animal imagages</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_predictions">predictions</code></td>
<td>
<p>data frame of prediction probabilities from the classifySpecies function</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_classes">classes</code></td>
<td>
<p>a vector or species corresponding to the columns of 'predictions'</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_emptyclass">emptyclass</code></td>
<td>
<p>a string indicating the class that should be considered 'Empty'</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_stationcolumn">stationcolumn</code></td>
<td>
<p>a column in the animals and empty data frame that indicates the camera or camera station</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_sortcolumns">sortcolumns</code></td>
<td>
<p>optional sort order. The default is 'stationcolumnumn' and DateTime.</p>
</td></tr>
<tr><td><code id="sequenceClassification_+3A_maxdiff">maxdiff</code></td>
<td>
<p>maximum difference between images in seconds to be included in a sequence, defaults to 60</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function retains &quot;Empty&quot; classification even if other images within the
sequence are predicted to contain animals.
Classification confidence is weighted by MD confidence.
</p>


<h3>Value</h3>

<p>data frame with predictions and confidence values for animals and empty images
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
predictions &lt;-classifyCropsSpecies(images,modelfile,resize=456)
animals &lt;- allframes[allframes$max_detection_category==1,]
empty &lt;- setEmpty(allframes)
animals &lt;- sequenceClassification(animals, empty, predictions, classes,
                                  emptyclass = "Empty",
                                  stationcolumnumn="StationID", maxdiff=60)

## End(Not run)
</code></pre>

<hr>
<h2 id='setupDirectory'>Set Working Directory and Save File Global Variables</h2><span id='topic+setupDirectory'></span>

<h3>Description</h3>

<p>Set Working Directory and Save File Global Variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setupDirectory(workingdir, pkg.env)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setupDirectory_+3A_workingdir">workingdir</code></td>
<td>
<p>local directory that contains data to process</p>
</td></tr>
<tr><td><code id="setupDirectory_+3A_pkg.env">pkg.env</code></td>
<td>
<p>environment to create global variables in</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setupDirectory(/home/kyra/animl/examples)

## End(Not run)
</code></pre>

<hr>
<h2 id='symlinkMD'>Create SymLink Directories and Sort Classified Images Based on MD Results</h2><span id='topic+symlinkMD'></span>

<h3>Description</h3>

<p>Create SymLink Directories and Sort Classified Images Based on MD Results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symlinkMD(manifest, linkdir, outfile = NULL, copy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symlinkMD_+3A_manifest">manifest</code></td>
<td>
<p>DataFrame of classified images</p>
</td></tr>
<tr><td><code id="symlinkMD_+3A_linkdir">linkdir</code></td>
<td>
<p>Destination directory for symlinks</p>
</td></tr>
<tr><td><code id="symlinkMD_+3A_outfile">outfile</code></td>
<td>
<p>Results file to save to</p>
</td></tr>
<tr><td><code id="symlinkMD_+3A_copy">copy</code></td>
<td>
<p>Toggle to determine copy or hard link, defaults to link</p>
</td></tr>
</table>


<h3>Value</h3>

<p>manifest with added link columns
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
symlinkMD(manifest, linkdir)

## End(Not run)
</code></pre>

<hr>
<h2 id='symlinkSpecies'>Create SymLink Directories and Sort Classified Images</h2><span id='topic+symlinkSpecies'></span>

<h3>Description</h3>

<p>Create SymLink Directories and Sort Classified Images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symlinkSpecies(manifest, linkdir, threshold = 0, outfile = NULL, copy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symlinkSpecies_+3A_manifest">manifest</code></td>
<td>
<p>DataFrame of classified images</p>
</td></tr>
<tr><td><code id="symlinkSpecies_+3A_linkdir">linkdir</code></td>
<td>
<p>Destination directory for symlinks</p>
</td></tr>
<tr><td><code id="symlinkSpecies_+3A_threshold">threshold</code></td>
<td>
<p>Confidence threshold for determining uncertain predictions, defaults to 0</p>
</td></tr>
<tr><td><code id="symlinkSpecies_+3A_outfile">outfile</code></td>
<td>
<p>Results file to save to</p>
</td></tr>
<tr><td><code id="symlinkSpecies_+3A_copy">copy</code></td>
<td>
<p>Toggle to determine copy or hard link, defaults to link</p>
</td></tr>
</table>


<h3>Value</h3>

<p>manifest with added link columns
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
manifest &lt;- symlinkSpecies(manifest, linkdir)

## End(Not run)
</code></pre>

<hr>
<h2 id='symUnlink'>Remove Symlinks</h2><span id='topic+symUnlink'></span>

<h3>Description</h3>

<p>Remove Symlinks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symUnlink(manifest)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symUnlink_+3A_manifest">manifest</code></td>
<td>
<p>DataFrame of classified images</p>
</td></tr>
</table>


<h3>Value</h3>

<p>manifest without link column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
symlinkMD(manifest, linkdir)

## End(Not run)
</code></pre>

<hr>
<h2 id='testMD'>Select a Random Image and Run Through MegaDetector</h2><span id='topic+testMD'></span>

<h3>Description</h3>

<p>Select a Random Image and Run Through MegaDetector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testMD(input, mdsession, mdversion = 5, minconf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="testMD_+3A_input">input</code></td>
<td>
<p>dataframe of all images</p>
</td></tr>
<tr><td><code id="testMD_+3A_mdsession">mdsession</code></td>
<td>
<p>MegaDetector mdsession</p>
</td></tr>
<tr><td><code id="testMD_+3A_mdversion">mdversion</code></td>
<td>
<p>megadetector version, defaults to 5</p>
</td></tr>
<tr><td><code id="testMD_+3A_minconf">minconf</code></td>
<td>
<p>minimum confidence with which to draw boxes, defaults to 0</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Null, plots box on image
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
testMD(input, mdsession)

## End(Not run)
</code></pre>

<hr>
<h2 id='updateResults'>Title</h2><span id='topic+updateResults'></span>

<h3>Description</h3>

<p>Title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>updateResults(resultsfile, linkdir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="updateResults_+3A_resultsfile">resultsfile</code></td>
<td>
<p>final results file with predictions, expects a &quot;UniqueName&quot; column</p>
</td></tr>
<tr><td><code id="updateResults_+3A_linkdir">linkdir</code></td>
<td>
<p>symlink directory that has been validated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe with new &quot;Species&quot; column that contains the verifed species
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
results &lt;- updateResults(resultsfile, linkdir)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
