<!DOCTYPE html><html><head><title>Help for package openair</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {openair}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#openair-package'><p>openair: Tools for the Analysis of Air Pollution Data</p></a></li>
<li><a href='#aqStats'><p>Calculate summary statistics for air pollution data by year</p></a></li>
<li><a href='#binData'><p>Bin data, calculate mean and bootstrap 95 % confidence interval in the mean</p></a></li>
<li><a href='#bootMeanDF'><p>Bootsrap confidence intervals in the mean</p></a></li>
<li><a href='#calcFno2'><p>Estimate NO2/NOX emission ratios from monitoring data</p></a></li>
<li><a href='#calcPercentile'><p>Calculate percentile values from a time series</p></a></li>
<li><a href='#calendarPlot'><p>Plot time series values in a conventional calendar format</p></a></li>
<li><a href='#conditionalEval'><p>Conditional quantile estimates with additional variables for model evaluation</p></a></li>
<li><a href='#conditionalQuantile'><p>Conditional quantile estimates for model evaluation</p></a></li>
<li><a href='#corPlot'><p>Correlation matrices with conditioning</p></a></li>
<li><a href='#cutData'><p>Function to split data in different ways for conditioning</p></a></li>
<li><a href='#drawOpenKey'><p>Scale key handling for openair</p></a></li>
<li><a href='#importADMS'><p>CERC Atmospheric Dispersion Modelling System (ADMS) data import function(s)</p>
for openair</a></li>
<li><a href='#importAURN'><p>Import data from individual UK Air Pollution Networks</p></a></li>
<li><a href='#importEurope'><p>Import air quality data from European database</p></a></li>
<li><a href='#importKCL'><p>Import data from King's College London networks</p></a></li>
<li><a href='#importMeta'><p>Import monitoring site meta data for UK and European networks</p></a></li>
<li><a href='#importTraj'><p>Import pre-calculated HYSPLIT 96-hour back trajectories</p></a></li>
<li><a href='#importUKAQ'><p>Import data from the UK Air Pollution Networks</p></a></li>
<li><a href='#linearRelation'><p>Linear relations between pollutants</p></a></li>
<li><a href='#modStats'><p>Calculate common model evaluation statistics</p></a></li>
<li><a href='#mydata'><p>Example data for openair</p></a></li>
<li><a href='#openColours'><p>Pre-defined openair colours and definition of user-defined colours</p></a></li>
<li><a href='#percentileRose'><p>Function to plot percentiles by wind direction</p></a></li>
<li><a href='#polarAnnulus'><p>Bivariate polarAnnulus plot</p></a></li>
<li><a href='#polarCluster'><p>K-means clustering of bivariate polar plots</p></a></li>
<li><a href='#polarDiff'><p>Polar plots considering changes in concentrations between two time periods</p></a></li>
<li><a href='#polarFreq'><p>Function to plot wind speed/direction frequencies and other statistics</p></a></li>
<li><a href='#polarPlot'><p>Function for plotting bivariate polar plots with smoothing.</p></a></li>
<li><a href='#pollutionRose'><p>Pollution rose variation of the traditional wind rose plot</p></a></li>
<li><a href='#quickText'><p>Automatic text formatting for openair</p></a></li>
<li><a href='#rollingMean'><p>Calculate rollingMean values</p></a></li>
<li><a href='#runRegression'><p>Rolling regression for pollutant source characterisation.</p></a></li>
<li><a href='#scatterPlot'><p>Flexible scatter plots</p></a></li>
<li><a href='#selectByDate'><p>Subset a data frame based on date</p></a></li>
<li><a href='#selectRunning'><p>Function to extract run lengths greater than a threshold</p></a></li>
<li><a href='#smoothTrend'><p>Calculate nonparametric smooth trends</p></a></li>
<li><a href='#splitByDate'><p>Divide up a data frame by time</p></a></li>
<li><a href='#summaryPlot'><p>Function to rapidly provide an overview of air quality data</p></a></li>
<li><a href='#TaylorDiagram'><p>Taylor Diagram for model evaluation with conditioning</p></a></li>
<li><a href='#TheilSen'><p>Tests for trends using Theil-Sen estimates</p></a></li>
<li><a href='#timeAverage'><p>Function to calculate time averages for data frames</p></a></li>
<li><a href='#timePlot'><p>Plot time series</p></a></li>
<li><a href='#timeProp'><p>Time series plot with categories shown as a stacked bar chart</p></a></li>
<li><a href='#timeVariation'><p>Diurnal, day of the week and monthly variation</p></a></li>
<li><a href='#trajCluster'><p>Calculate clusters for back trajectories</p></a></li>
<li><a href='#trajLevel'><p>Trajectory level plots with conditioning</p></a></li>
<li><a href='#trajPlot'><p>Trajectory line plots with conditioning</p></a></li>
<li><a href='#trendLevel'><p>Plot heat map trends</p></a></li>
<li><a href='#windRose'><p>Traditional wind rose plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for the Analysis of Air Pollution Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.18-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-11</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Carslaw &lt;david.carslaw@york.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools to analyse, interpret and understand air pollution
    data. Data are typically regular time series and air quality
    measurement, meteorological data and dispersion model output can be
    analysed. The package is described in Carslaw and Ropkins (2012,
    &lt;<a href="https://doi.org/10.1016%2Fj.envsoft.2011.09.008">doi:10.1016/j.envsoft.2011.09.008</a>&gt;) and subsequent papers.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://davidcarslaw.github.io/openair/">https://davidcarslaw.github.io/openair/</a>,
<a href="https://github.com/davidcarslaw/openair">https://github.com/davidcarslaw/openair</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/davidcarslaw/openair/issues">https://github.com/davidcarslaw/openair/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli, cluster, dplyr (&ge; 1.0), graphics, grDevices, grid,
hexbin, lattice, latticeExtra, lubridate, mapproj, MASS,
methods, mgcv, purrr (&ge; 1.0.0), Rcpp, readr, rlang, stats,
tibble, tidyr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>KernSmooth, mapdata, maps, quantreg, spelling</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-11 15:22:29 UTC; davidcarslaw</td>
</tr>
<tr>
<td>Author:</td>
<td>David Carslaw [aut, cre],
  Jack Davison [aut],
  Karl Ropkins [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-11 16:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='openair-package'>openair: Tools for the Analysis of Air Pollution Data</h2><span id='topic+openair'></span><span id='topic+openair-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Tools to analyse, interpret and understand air pollution data. Data are typically regular time series and air quality measurement, meteorological data and dispersion model output can be analysed. The package is described in Carslaw and Ropkins (2012, <a href="https://doi.org/10.1016/j.envsoft.2011.09.008">doi:10.1016/j.envsoft.2011.09.008</a>) and subsequent papers.
</p>


<h3>Details</h3>

<p>This is a UK Natural Environment Research Council (NERC) funded
knowledge exchange project that aims to make available innovative analysis
tools for air pollution data; with additional support from Defra. The tools
have generally been developed to analyse data of hourly resolution (or at
least a regular time series) both for air pollution monitoring and
dispersion modelling. The availability of meteorological data at the same
time resolution greatly enhances the capabilities of these tools.
</p>
<p><code>openair</code> contains collection of functions to analyse air pollution
data. Typically it is expected that data are hourly means, although most
functions consider other time periods. The principal aim to make available
analysis techniques that most users of air quality data and model output
would not normally have access to. The functions consist of those developed
by the authors and a growing number from other researchers.
</p>
<p>The package also provides access to a wide range of data sources including
the UK Automatic Urban and Rural Network (AURN), networks run by King's
College London (e.g. the LAQN) and the Scottish Air Quality Network (SAQN).
</p>
<p>The package has a number of requirements for input data and these are
discussed in the manual (available on the <code>openair</code> website at
<a href="https://davidcarslaw.github.io/openair/">https://davidcarslaw.github.io/openair/</a>). The key requirements are
that a date or date-time field must have the name <code style="white-space: pre;">&#8288;date' (and can be \code{Date} or \code{POSIXct} format), that wind speed is represented as &#8288;</code>ws' and that wind direction is &lsquo;wd&rsquo;.
</p>
<p>Most functions work in a very straightforward way, but offer many options
for finer control and perhaps more in-depth analysis.
</p>
<p>The <code>openair</code> package depends on several other packages written by
other people to function properly.
</p>
<p>To ensure that these other packages are available, they need to be
installed, and this requires a connection to the internet. Other packages
required come with the R base system.  If there are problems with the
automatic download of these packages, see
<a href="https://davidcarslaw.github.io/openair/">https://davidcarslaw.github.io/openair/</a> for more details.
</p>
<p>NOTE: openair assumes that data are not expressed in local time where
'Daylight Saving Time' is used. All functions check that this is the case
and issue a warning if TRUE. It is recommended that data are expressed in
UTC/GMT (or a fixed offset from) to avoid potential problems with R and
<code>openair</code> functions. The <code>openair</code> manual provides advice on
these issues (available on the website).
</p>
<p>To check to see if <code>openair</code> has been correctly installed, try some of
the examples below.
</p>


<h3>The <code>openair</code> class</h3>

<p>As well as generating the plots themselves, <code>openair</code> plotting
functions also return an object of class &ldquo;openair&rdquo;. The object includes
three main components:
</p>

<ul>
<li> <p><code>call</code>, the command used to generate the plot.
</p>
</li>
<li> <p><code>data</code>, the data frame of summarised information used to make the
plot.
</p>
</li>
<li> <p><code>plot</code>, the plot itself.
</p>
</li></ul>

<p>If retained, e.g., using <code>output &lt;- polarPlot(mydata, "nox")</code>, this
output can be used to recover the data, reproduce or rework the original
plot or undertake further analysis.
</p>
<p>An openair output can be manipulated using a number of generic operations,
including <code>print</code>, <code>plot</code> and <code>summary</code>. The examples below
show some examples of using an <code>openair</code> object.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: David Carslaw <a href="mailto:david.carslaw@york.ac.uk">david.carslaw@york.ac.uk</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Jack Davison <a href="mailto:jack.davison@ricardo.com">jack.davison@ricardo.com</a>
</p>
</li>
<li><p> Karl Ropkins <a href="mailto:K.Ropkins@its.leeds.ac.uk">K.Ropkins@its.leeds.ac.uk</a>
</p>
</li></ul>



<h3>References</h3>

<p>Most reference details are given under the specific functions.
The principal reference is below but users may also wish to cite the manual
(details for doing this are contained in the manual itself).
</p>
<p>Carslaw, D.C. and K. Ropkins, (2012) openair &mdash; an R package for air
quality data analysis.  Environmental Modelling &amp; Software. Volume 27-28,
52-61.
</p>


<h3>See Also</h3>

<p>See <a href="https://davidcarslaw.github.io/openair/">https://davidcarslaw.github.io/openair/</a> for up to date
information on the project, and the openair book
(<a href="https://bookdown.org/david_carslaw/openair/">https://bookdown.org/david_carslaw/openair/</a>) for thorough
documentation and examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# load package
library(openair)

# summarise data in a compact way
summaryPlot(mydata)

# traditional wind rose
windRose(mydata)

# polar plot
polar_nox &lt;- polarPlot(mydata, pollutant = "nox")

# see call
polar_nox$call

# get data
polar_nox$data

# could, e.g., re-plot in {ggplot2}
library(ggplot2)
ggplot(polar_nox$data, aes(u, v, fill = z)) + geom_tile() + coord_equal() +
scale_fill_gradientn(colours = openair::openColours(), na.value = NA)

## End(Not run)

</code></pre>

<hr>
<h2 id='aqStats'>Calculate summary statistics for air pollution data by year</h2><span id='topic+aqStats'></span>

<h3>Description</h3>

<p>Calculate a range of air pollution-relevant statistics by year.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aqStats(
  mydata,
  pollutant = "no2",
  type = "default",
  data.thresh = 0,
  percentile = c(95, 99),
  transpose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aqStats_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing a <code>date</code> field of hourly data.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_pollutant">pollutant</code></td>
<td>
<p>The name of a pollutant e.g. <code>pollutant = c("o3",
"pm10")</code>.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_type">type</code></td>
<td>
<p><code>type</code> allows <code><a href="#topic+timeAverage">timeAverage()</a></code> to be applied to cases where
there are groups of data that need to be split and the function applied to
each group. The most common example is data with multiple sites identified
with a column representing site name e.g. <code>type = "site"</code>. More
generally, <code>type</code> should be used where the date repeats for a
particular grouping variable.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold in %. No values are calculated
if data capture over the period of interest is less than this value.
<code>data.thresh</code> is used for example in the calculation of daily mean
values from hourly data. If there are less than <code>data.thresh</code>
percentage of measurements available in a period, <code>NA</code> is returned.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_percentile">percentile</code></td>
<td>
<p>Percentile values to calculate for each pollutant.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_transpose">transpose</code></td>
<td>
<p>The default is to return a data frame with columns
representing the statistics. If <code>transpose = TRUE</code> then the results
have columns for each pollutant-site combination.</p>
</td></tr>
<tr><td><code id="aqStats_+3A_...">...</code></td>
<td>
<p>Other arguments, currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates a range of common and air pollution-specific
statistics from a data frame. The statistics are calculated on an annual
basis and the input is assumed to be hourly data. The function can cope with
several sites and years e.g. using <code>type = "site"</code>. The user can control
the output by setting <code>transpose</code> appropriately.
</p>
<p>Note that the input data is assumed to be in mass units e.g. ug/m3 for all
species except CO (mg/m3).
</p>
<p>The following statistics are calculated:
</p>
 <ul>
<li> <p><b>data.capture</b> &mdash; percentage data capture over a full
year.
</p>
</li>
<li> <p><b>mean</b> &mdash; annual mean.
</p>
</li>
<li> <p><b>minimum</b> &mdash; minimum hourly value.
</p>
</li>
<li> <p><b>maximum</b> &mdash; maximum hourly value.
</p>
</li>
<li> <p><b>median</b> &mdash; median value.
</p>
</li>
<li> <p><b>max.daily</b> &mdash; maximum daily mean.
</p>
</li>
<li> <p><b>max.rolling.8</b> &mdash; maximum 8-hour rolling mean.
</p>
</li>
<li> <p><b>max.rolling.24</b> &mdash; maximum 24-hour rolling mean.
</p>
</li>
<li> <p><b>percentile.95</b> &mdash; 95th percentile. Note that several percentiles
can be calculated.
</p>
</li>
<li> <p><b>roll.8.O3.gt.100</b> &mdash; number of days when the daily maximum
rolling 8-hour mean ozone concentration is &gt;100 ug/m3. This is the target
value.
</p>
</li>
<li> <p><b>roll.8.O3.gt.120</b> &mdash; number of days when the daily maximum
rolling 8-hour mean ozone concentration is &gt;120 ug/m3. This is the Limit
Value not to be exceeded &gt; 10 days a year.
</p>
</li>
<li> <p><b>AOT40</b> &mdash; is the accumulated amount of ozone over the threshold
value of 40 ppb for daylight hours in the growing season (April to
September). Note that <code>latitude</code> and <code>longitude</code> can also be passed
to this calculation.
</p>
</li>
<li> <p><b>hours.gt.200</b> &mdash; number of hours NO2 is more than 200 ug/m3.
</p>
</li>
<li> <p><b>days.gt.50</b> &mdash; number of days PM10 is more than 50 ug/m3. </p>
</li></ul>

<p>For the rolling means, the user can supply the option <code>align</code>, which can
be &quot;centre&quot; (default), &quot;left&quot; or &quot;right&quot;. See <code>rollingMean</code> for more
details.
</p>
<p>There can be small discrepancies with the AURN due to the treatment of
rounding data. The <code>aqStats</code> function does not round, whereas AURN data
can be rounded at several stages during the calculations.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Statistics for 2004. NOTE! these data are in ppb/ppm so the
## example is for illustrative purposes only
aqStats(selectByDate(mydata, year = 2004), pollutant = "no2")


</code></pre>

<hr>
<h2 id='binData'>Bin data, calculate mean and bootstrap 95 % confidence interval in the mean</h2><span id='topic+binData'></span>

<h3>Description</h3>

<p>Bin a variable and calculate mean an uncertainties in mean
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binData(mydata, bin = "nox", uncer = "no2", n = 40, interval = NA, breaks = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binData_+3A_mydata">mydata</code></td>
<td>
<p>Name of the data frame to process.</p>
</td></tr>
<tr><td><code id="binData_+3A_bin">bin</code></td>
<td>
<p>The name of the column to divide into intervals</p>
</td></tr>
<tr><td><code id="binData_+3A_uncer">uncer</code></td>
<td>
<p>The name of the column for which the mean, lower and upper
uncertainties should be calculated for each interval of <code>bin</code>.</p>
</td></tr>
<tr><td><code id="binData_+3A_n">n</code></td>
<td>
<p>The number of intervals to split <code>bin</code> into.</p>
</td></tr>
<tr><td><code id="binData_+3A_interval">interval</code></td>
<td>
<p>The interval to be used for binning the data.</p>
</td></tr>
<tr><td><code id="binData_+3A_breaks">breaks</code></td>
<td>
<p>User specified breaks to use for binning.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function summarises data by intervals and calculates the mean and
bootstrap 95 % confidence intervals in the mean of a chosen variable in a
data frame. Any other numeric variables are summarised by their mean
intervals.
</p>
<p>There are three options for binning. The default is to bon <code>bin</code> into 40
intervals. Second, the user can choose an binning interval e.g.
<code>interval = 5</code>. Third, the user can supply their own breaks to use as
binning intervals.
</p>


<h3>Value</h3>

<p>Returns a summarised data frame with new columns for the mean and
upper / lower 95 percent confidence intervals in the mean.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># how does nox vary by intervals of wind speed?
results &lt;- binData(mydata, bin = "ws", uncer = "nox")

# easy to plot this using ggplot2
## Not run: 
library(ggplot2)
ggplot(results, aes(ws, mean, ymin = min, ymax = max)) +
geom_pointrange()

## End(Not run)
</code></pre>

<hr>
<h2 id='bootMeanDF'>Bootsrap confidence intervals in the mean</h2><span id='topic+bootMeanDF'></span>

<h3>Description</h3>

<p>A utility function to calculation the uncertainty intervals in the mean of a
vector. The function removes any missing data before the calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootMeanDF(x, conf.int = 0.95, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootMeanDF_+3A_x">x</code></td>
<td>
<p>A vector from which the mean and bootstrap confidence intervals in
the mean are to be calculated</p>
</td></tr>
<tr><td><code id="bootMeanDF_+3A_conf.int">conf.int</code></td>
<td>
<p>The confidence interval; default = 0.95.</p>
</td></tr>
<tr><td><code id="bootMeanDF_+3A_b">B</code></td>
<td>
<p>The number of bootstrap simulations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame with the mean, lower uncertainty, upper
uncertainty and number of values used in the calculation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- rnorm(20, mean = 10)
bootMeanDF(test)
</code></pre>

<hr>
<h2 id='calcFno2'>Estimate NO2/NOX emission ratios from monitoring data</h2><span id='topic+calcFno2'></span>

<h3>Description</h3>

<p>Given hourly NOX and NO2 from a roadside site and hourly NOX, NO2 and O3 from
a background site the function will estimate the emissions ratio of NO2/NOX
&mdash; the level of primary NO2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcFno2(input, tau = 60, user.fno2, main = "", xlab = "year", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcFno2_+3A_input">input</code></td>
<td>
<p>A data frame with the following fields. <code>nox</code> and<code>no2</code>
(roadside NOX and NO2 concentrations), <code>back_nox</code>, <code>back_no2</code> and
<code>back_o3</code> (hourly background concentrations of each pollutant). In
addition <code>temp</code> (temperature in degrees Celsius) and <code>cl</code> (cloud
cover in Oktas). Note that if <code>temp</code> and <code>cl</code> are not available,
typical means values of 11 deg. C and cloud = 3.5 will be used.</p>
</td></tr>
<tr><td><code id="calcFno2_+3A_tau">tau</code></td>
<td>
<p>Mixing time scale. It is unlikely the user will need to adjust
this. See details below.</p>
</td></tr>
<tr><td><code id="calcFno2_+3A_user.fno2">user.fno2</code></td>
<td>
<p>User-supplied f-NO2 fraction e.g. 0.1 is a NO2/NOX ratio of
10% by volume. <code>user.no2</code> will be applied to the whole time series and
is useful for testing &quot;what if&quot; questions.</p>
</td></tr>
<tr><td><code id="calcFno2_+3A_main">main</code></td>
<td>
<p>Title of plot if required.</p>
</td></tr>
<tr><td><code id="calcFno2_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label.</p>
</td></tr>
<tr><td><code id="calcFno2_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+scatterPlot">scatterPlot</a></code>
</p>

<dl>
<dt><code>mydata</code></dt><dd><p>A data frame containing at least two numeric variables to plot.</p>
</dd>
<dt><code>x</code></dt><dd><p>Name of the x-variable to plot. Note that x can be a date field or a
factor. For example, <code>x</code> can be one of the <code>openair</code> built in
types such as <code>"year"</code> or <code>"season"</code>.</p>
</dd>
<dt><code>y</code></dt><dd><p>Name of the numeric y-variable to plot.</p>
</dd>
<dt><code>z</code></dt><dd><p>Name of the numeric z-variable to plot for <code>method = "scatter"</code>
or <code>method = "level"</code>. Note that for <code>method = "scatter"</code> points
will be coloured according to a continuous colour scale, whereas for
<code>method = "level"</code> the surface is coloured.</p>
</dd>
<dt><code>method</code></dt><dd><p>Methods include &ldquo;scatter&rdquo; (conventional scatter plot),
&ldquo;hexbin&rdquo; (hexagonal binning using the <code>hexbin</code> package).
&ldquo;level&rdquo; for a binned or smooth surface plot and &ldquo;density&rdquo; (2D
kernel density estimates).</p>
</dd>
<dt><code>group</code></dt><dd><p>The grouping variable to use, if any. Setting this to a variable
in the data frame has the effect of plotting several series in the same
panel using different symbols/colours etc. If set to a variable that is a
character or factor, those categories or factor levels will be used
directly. If set to a numeric variable, it will split that variable in to
quantiles.</p>
</dd>
<dt><code>avg.time</code></dt><dd><p>This defines the time period to average to. Can be
&ldquo;sec&rdquo;, &ldquo;min&rdquo;, &ldquo;hour&rdquo;, &ldquo;day&rdquo;, &ldquo;DSTday&rdquo;,
&ldquo;week&rdquo;, &ldquo;month&rdquo;, &ldquo;quarter&rdquo; or &ldquo;year&rdquo;. For much
increased flexibility a number can precede these options followed by a
space. For example, a timeAverage of 2 months would be <code>period = "2
  month"</code>. See function <code>timeAverage</code> for further details on this. This
option se useful as one method by which the number of points plotted is
reduced i.e. by choosing a longer averaging time.</p>
</dd>
<dt><code>data.thresh</code></dt><dd><p>The data capture threshold to use (\
the data using <code>avg.time</code>. A value of zero means that all available
data will be used in a particular period regardless if of the number of
values available. Conversely, a value of 100 will mean that all data will
need to be present for the average to be calculated, else it is recorded as
<code>NA</code>. Not used if <code>avg.time = "default"</code>.</p>
</dd>
<dt><code>statistic</code></dt><dd><p>The statistic to apply when aggregating the data; default is
the mean. Can be one of &quot;mean&quot;, &quot;max&quot;, &quot;min&quot;, &quot;median&quot;, &quot;frequency&quot;, &quot;sd&quot;,
&quot;percentile&quot;. Note that &quot;sd&quot; is the standard deviation and &quot;frequency&quot; is
the number (frequency) of valid records in the period. &quot;percentile&quot; is the
percentile level (\
&quot;percentile&quot; option - see below. Not used if <code>avg.time = "default"</code>.</p>
</dd>
<dt><code>percentile</code></dt><dd><p>The percentile level in percent used when <code>statistic =
  "percentile"</code> and when aggregating the data with <code>avg.time</code>. The
default is 95. Not used if <code>avg.time = "default"</code>.</p>
</dd>
<dt><code>type</code></dt><dd><p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</dd>
<dt><code>smooth</code></dt><dd><p>A smooth line is fitted to the data if <code>TRUE</code>; optionally
with 95 percent confidence intervals shown. For <code>method = "level"</code> a
smooth surface will be fitted to binned data.</p>
</dd>
<dt><code>spline</code></dt><dd><p>A smooth spline is fitted to the data if <code>TRUE</code>. This is
particularly useful when there are fewer data points or when a connection
line between a sequence of points is required.</p>
</dd>
<dt><code>linear</code></dt><dd><p>A linear model is fitted to the data if <code>TRUE</code>; optionally
with 95 percent confidence intervals shown. The equation of the line and R2
value is also shown.</p>
</dd>
<dt><code>ci</code></dt><dd><p>Should the confidence intervals for the smooth/linear fit be shown?</p>
</dd>
<dt><code>mod.line</code></dt><dd><p>If <code>TRUE</code> three lines are added to the scatter plot to
help inform model evaluation. The 1:1 line is solid and the 1:0.5 and 1:2
lines are dashed. Together these lines help show how close a group of
points are to a 1:1 relationship and also show the points that are within a
factor of two (FAC2). <code>mod.line</code> is appropriately transformed when x
or y axes are on a log scale.</p>
</dd>
<dt><code>cols</code></dt><dd><p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</dd>
<dt><code>plot.type</code></dt><dd><p><code>lattice</code> plot type. Can be &ldquo;p&rdquo; (points &mdash;
default), &ldquo;l&rdquo; (lines) or &ldquo;b&rdquo; (lines and points).</p>
</dd>
<dt><code>key</code></dt><dd><p>Should a key be drawn? The default is <code>TRUE</code>.</p>
</dd>
<dt><code>key.title</code></dt><dd><p>The title of the key (if used).</p>
</dd>
<dt><code>key.columns</code></dt><dd><p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</dd>
<dt><code>key.position</code></dt><dd><p>Location where the scale key is to plotted.  Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</dd>
<dt><code>strip</code></dt><dd><p>Should a strip be drawn? The default is <code>TRUE</code>.</p>
</dd>
<dt><code>log.x</code></dt><dd><p>Should the x-axis appear on a log scale? The default is
<code>FALSE</code>. If <code>TRUE</code> a well-formatted log10 scale is used. This can
be useful for checking linearity once logged.</p>
</dd>
<dt><code>log.y</code></dt><dd><p>Should the y-axis appear on a log scale? The default is
<code>FALSE</code>. If <code>TRUE</code> a well-formatted log10 scale is used. This can
be useful for checking linearity once logged.</p>
</dd>
<dt><code>x.inc</code></dt><dd><p>The x-interval to be used for binning data when <code>method =
"level"</code>.</p>
</dd>
<dt><code>y.inc</code></dt><dd><p>The y-interval to be used for binning data when <code>method =
"level"</code>.</p>
</dd>
<dt><code>limits</code></dt><dd><p>For <code>method = "level"</code> the function does its best to
choose sensible limits automatically. However, there are circumstances when
the user will wish to set different ones. The limits are set in the form
<code>c(lower, upper)</code>, so <code>limits = c(0, 100)</code> would force the plot
limits to span 0-100.</p>
</dd>
<dt><code>windflow</code></dt><dd><p>This option allows a scatter plot to show the wind
speed/direction shows as an arrow. The option is a list e.g. <code>windflow
  = list(col = "grey", lwd = 2, scale = 0.1)</code>. This option requires wind
speed (<code>ws</code>) and wind direction (<code>wd</code>) to be available.
</p>
<p>The maximum length of the arrow plotted is a fraction of the plot dimension
with the longest arrow being <code>scale</code> of the plot x-y dimension. Note,
if the plot size is adjusted manually by the user it should be re-plotted
to ensure the correct wind angle. The list may contain other options to
<code>panel.arrows</code> in the <code>lattice</code> package. Other useful options
include <code>length</code>, which controls the length of the arrow head and
<code>angle</code>, which controls the angle of the arrow head.
</p>
<p>This option works best where there are not too many data to ensure
over-plotting does not become a problem.</p>
</dd>
<dt><code>y.relation</code></dt><dd><p>This determines how the y-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</dd>
<dt><code>x.relation</code></dt><dd><p>This determines how the x-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</dd>
<dt><code>ref.x</code></dt><dd><p>See <code>ref.y</code> for details.</p>
</dd>
<dt><code>ref.y</code></dt><dd><p>A list with details of the horizontal lines to be added
representing reference line(s). For example, <code>ref.y = list(h = 50, lty
  = 5)</code> will add a dashed horizontal line at 50. Several lines can be plotted
e.g. <code>ref.y = list(h = c(50, 100), lty = c(1, 5), col = c("green",
  "blue"))</code>. See <code>panel.abline</code> in the <code>lattice</code> package for more
details on adding/controlling lines.</p>
</dd>
<dt><code>k</code></dt><dd><p>Smoothing parameter supplied to <code>gam</code> for fitting a smooth
surface when <code>method = "level"</code>.</p>
</dd>
<dt><code>dist</code></dt><dd><p>When plotting smooth surfaces (<code>method = "level"</code> and
<code>smooth = TRUE</code>, <code>dist</code> controls how far from the original data
the predictions should be made. See <code>exclude.too.far</code> from the
<code>mgcv</code> package. Data are first transformed to a unit square. Values
should be between 0 and 1.</p>
</dd>
<dt><code>map</code></dt><dd><p>Should a base map be drawn? This option is under development.</p>
</dd>
<dt><code>auto.text</code></dt><dd><p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</dd>
<dt><code>plot</code></dt><dd><p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The principal purpose of this function is to estimate the level of primary
(or direct) NO2 from road vehicles. When hourly data of NOX, NO2 and O3 are
available, the total oxidant method of Clapp and Jenkin (2001) can be used.
If roadside O3 measurements are available see <code><a href="#topic+linearRelation">linearRelation()</a></code> for details
of how to estimate the primary NO2 fraction.
</p>
<p>In the absence of roadside O3 measurements, it is rather more problematic to
calculate the fraction of primary NO2. Carslaw and Beevers (2005c) developed
an approach based on <code><a href="#topic+linearRelation">linearRelation()</a></code> the analysis of roadside and
background measurements. The increment in roadside NO2 concentrations is
primarily determined by direct emissions of NO2 and the availability of One
to react with NO to form NO2. The method aims to quantify the amount of NO2
formed through these two processes by seeking the optimum level of primary
NO2 that gives the least error.
</p>
<p>Test data is provided at <a href="https://davidcarslaw.github.io/openair/">https://davidcarslaw.github.io/openair/</a>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Clapp, L.J., Jenkin, M.E., 2001. Analysis of the relationship
between ambient levels of O3, NO2 and NO as a function of NOX in the UK.
Atmospheric Environment 35 (36), 6391-6405.
</p>
<p>Carslaw, D.C. and N Carslaw (2007).  Detecting and characterising small
changes in urban nitrogen dioxide concentrations.  Atmospheric Environment.
Vol. 41, 4723-4733.
</p>
<p>Carslaw, D.C., Beevers, S.D. and M.C. Bell (2007). Risks of exceeding the
hourly EU limit value for nitrogen dioxide resulting from increased road
transport emissions of primary nitrogen dioxide. Atmospheric Environment 41
2073-2082.
</p>
<p>Carslaw, D.C. (2005a). Evidence of an increasing NO2/NOX emissions ratio
from road traffic emissions. Atmospheric Environment, 39(26) 4793-4802.
</p>
<p>Carslaw, D.C. and Beevers, S.D. (2005b). Development of an urban inventory
for road transport emissions of NO2 and comparison with estimates derived
from ambient measurements. Atmospheric Environment, (39): 2049-2059.
</p>
<p>Carslaw, D.C. and Beevers, S.D. (2005c). Estimations of road vehicle
primary NO2 exhaust emission fractions using monitoring data in London.
Atmospheric Environment, 39(1): 167-177.
</p>
<p>Carslaw, D. C. and S. D. Beevers (2004). Investigating the Potential
Importance of Primary NO2 Emissions in a Street Canyon. Atmospheric
Environment 38(22): 3585-3594.
</p>
<p>Carslaw, D. C. and S. D. Beevers (2004). New Directions: Should road
vehicle emissions legislation consider primary NO2? Atmospheric Environment
38(8): 1233-1234.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+linearRelation">linearRelation</a></code> if you have roadside ozone
measurements.
</p>

<hr>
<h2 id='calcPercentile'>Calculate percentile values from a time series</h2><span id='topic+calcPercentile'></span>

<h3>Description</h3>

<p>Calculates multiple percentile values from a time series, with flexible time
aggregation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcPercentile(
  mydata,
  pollutant = "o3",
  avg.time = "month",
  percentile = 50,
  data.thresh = 0,
  start = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcPercentile_+3A_mydata">mydata</code></td>
<td>
<p>A data frame of data with a <code>date</code> field in the format
<code>Date</code> or <code>POSIXct</code>. Must have one variable to apply calculations
to.</p>
</td></tr>
<tr><td><code id="calcPercentile_+3A_pollutant">pollutant</code></td>
<td>
<p>Name of variable to process. Mandatory.</p>
</td></tr>
<tr><td><code id="calcPercentile_+3A_avg.time">avg.time</code></td>
<td>
<p>Averaging period to use. See <code><a href="#topic+timeAverage">timeAverage()</a></code> for details.</p>
</td></tr>
<tr><td><code id="calcPercentile_+3A_percentile">percentile</code></td>
<td>
<p>A vector of percentile values. For example <code>percentile
  = 50</code> for median values, <code>percentile = c(5, 50, 95</code> for multiple
percentile values.</p>
</td></tr>
<tr><td><code id="calcPercentile_+3A_data.thresh">data.thresh</code></td>
<td>
<p>Data threshold to apply when aggregating data. See
<code><a href="#topic+timeAverage">timeAverage()</a></code> for details.</p>
</td></tr>
<tr><td><code id="calcPercentile_+3A_start">start</code></td>
<td>
<p>Start date to use - see <code><a href="#topic+timeAverage">timeAverage()</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a utility function to calculate percentiles and is used in, for
example, <code>timePlot</code>. Given a data frame with a <code>date</code> field and one
other numeric variable, percentiles are calculated.
</p>


<h3>Value</h3>

<p>Returns a data frame with new columns for each percentile level. New
columns are given names like percentile.95 e.g. when percentile = 95 is
chosen. See examples below.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p><code><a href="#topic+timePlot">timePlot</a></code>, <code><a href="#topic+timeAverage">timeAverage()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 95th percentile monthly o3 concentrations
percentiles &lt;- calcPercentile(mydata, pollutant ="o3",
avg.time = "month", percentile = 95)

head(percentiles)

# 5, 50, 95th percentile monthly o3 concentrations
## Not run: 
percentiles &lt;- calcPercentile(mydata, pollutant ="o3",
avg.time = "month", percentile = c(5, 50, 95))

head(percentiles)

## End(Not run)
</code></pre>

<hr>
<h2 id='calendarPlot'>Plot time series values in a conventional calendar format</h2><span id='topic+calendarPlot'></span>

<h3>Description</h3>

<p>This function will plot data by month laid out in a conventional calendar
format. The main purpose is to help rapidly visualise potentially complex
data in a familiar way. Users can also choose to show daily mean wind vectors
if wind speed and direction are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calendarPlot(
  mydata,
  pollutant = "nox",
  year = 2003,
  month = 1:12,
  type = "default",
  annotate = "date",
  statistic = "mean",
  cols = "heat",
  limits = c(0, 100),
  lim = NULL,
  col.lim = c("grey30", "black"),
  col.arrow = "black",
  font.lim = c(1, 2),
  cex.lim = c(0.6, 1),
  digits = 0,
  data.thresh = 0,
  labels = NA,
  breaks = NA,
  w.shift = 0,
  w.abbr.len = 1,
  remove.empty = TRUE,
  main = NULL,
  key.header = "",
  key.footer = "",
  key.position = "right",
  key = TRUE,
  auto.text = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calendarPlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>date</code> and at least one other
numeric variable. The date should be in either <code>Date</code> format or class
<code>POSIXct</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code style="white-space: pre;">&#8288;pollutant = "nox". &#8288;</code></p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_year">year</code></td>
<td>
<p>Year to plot e.g. <code>year = 2003</code>. If not supplied all data
potentially spanning several years will be plotted.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_month">month</code></td>
<td>
<p>If only certain month are required. By default the function will
plot an entire year even if months are missing. To only plot certain months
use the <code>month</code> option where month is a numeric 1:12 e.g. <code>month = c(1, 12)</code> to only plot January and December.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_type">type</code></td>
<td>
<p>Not yet implemented.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_annotate">annotate</code></td>
<td>
<p>This option controls what appears on each day of the
calendar. Can be: &quot;date&quot; &mdash; shows day of the month; &quot;wd&quot;
&mdash; shows vector-averaged wind direction, or &quot;ws&quot; &mdash; shows
vector-averaged wind direction scaled by wind speed. Finally it can be
&ldquo;value&rdquo; which shows the daily mean value.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_statistic">statistic</code></td>
<td>
<p>Statistic passed to <code><a href="#topic+timeAverage">timeAverage()</a></code>. Note that if <code>statistic = "max"</code> and <code>annotate</code> is &quot;ws&quot; or &quot;wd&quot;, the hour corresponding to the
maximum concentration of <code>polluant</code> is used to provide the associated <code>ws</code>
or <code>wd</code> and not the maximum daily <code>ws</code> or <code>wd</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. See <code><a href="#topic+openColours">openColours()</a></code> for more
details.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_limits">limits</code></td>
<td>
<p>Use this option to manually set the colour scale limits. This
is useful in the case when there is a need for two or more plots and a
consistent scale is needed on each. Set the limits to cover the maximum
range of the data for all plots of interest. For example, if one plot had
data covering 0&ndash;60 and another 0&ndash;100, then set <code>limits = c(0, 100)</code>. Note
that data will be ignored if outside the limits range.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_lim">lim</code></td>
<td>
<p>A threshold value to help differentiate values above and below
<code>lim</code>. It is used when <code>annotate = "value"</code>. See next few options for
control over the labels used.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_col.lim">col.lim</code></td>
<td>
<p>For the annotation of concentration labels on each day. The
first sets the colour of the text below <code>lim</code> and the second sets the
colour of the text above <code>lim</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_col.arrow">col.arrow</code></td>
<td>
<p>The colour of the annotated wind direction / wind speed
arrows.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_font.lim">font.lim</code></td>
<td>
<p>For the annotation of concentration labels on each day. The
first sets the font of the text below <code>lim</code> and the second sets the font of
the text above <code>lim</code>. Note that font = 1 is normal text and font = 2 is
bold text.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_cex.lim">cex.lim</code></td>
<td>
<p>For the annotation of concentration labels on each day. The
first sets the size of the text below <code>lim</code> and the second sets the size of
the text above <code>lim</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_digits">digits</code></td>
<td>
<p>The number of digits used to display concentration values when
<code>annotate = "value"</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_data.thresh">data.thresh</code></td>
<td>
<p>Data capture threshold passed to <code><a href="#topic+timeAverage">timeAverage()</a></code>. For
example, <code>data.thresh = 75</code> means that at least 75\
available in a day for the value to be calculate, else the data is removed.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_labels">labels</code></td>
<td>
<p>If a categorical scale is defined using <code>breaks</code>, then <code>labels</code>
can be used to override the default category labels, e.g., <code>labels = c("good", "bad", "very bad")</code>. Note there is one less label than break.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_breaks">breaks</code></td>
<td>
<p>If a categorical scale is required then these breaks will be
used. For example, <code>breaks = c(0, 50, 100, 1000)</code>. In this case
&ldquo;good&rdquo; corresponds to values between 0 and 50 and so on. Users
should set the maximum value of <code>breaks</code> to exceed the maximum data value
to ensure it is within the maximum final range e.g. 100&ndash;1000 in this case.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_w.shift">w.shift</code></td>
<td>
<p>Controls the order of the days of the week. By default the
plot shows Saturday first (<code>w.shift = 0</code>). To change this so that it starts
on a Monday for example, set <code>w.shift = 2</code>, and so on.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_w.abbr.len">w.abbr.len</code></td>
<td>
<p>The default (<code>1</code>) abbreviates the days of the week to a
single letter (e.g., in English, S/S/M/T/W/T/F). <code>w.abbr.len</code> defines the
number of letters to abbreviate until. For example, <code>w.abbr.len = 3</code> will
abbreviate &quot;Monday&quot; to &quot;Mon&quot;.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_remove.empty">remove.empty</code></td>
<td>
<p>Should months with no data present be removed? Default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_main">main</code></td>
<td>
<p>The plot title; default is pollutant and year.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels to the scale key. For example,
passing <code>calendarPlot(mydata, key.header = "header", key.footer = "footer")</code> adds addition text above and below the scale key. These
arguments are passed to <code><a href="#topic+drawOpenKey">drawOpenKey()</a></code> via <code><a href="#topic+quickText">quickText()</a></code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_key.footer">key.footer</code></td>
<td>
<p>see <code>key.header</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code> and <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code><a href="#topic+drawOpenKey">drawOpenKey()</a></code>. See
<code><a href="#topic+drawOpenKey">drawOpenKey()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code> titles and
axis labels will automatically try and format pollutant names and units
properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when analysing
data to extract calendar plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="calendarPlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto the <code>lattice</code> function
<code><a href="lattice.html#topic+levelplot">lattice::levelplot()</a></code>, with common axis and title labelling options (such
as <code>xlab</code>, <code>ylab</code>, <code>main</code>) being passed to via <code><a href="#topic+quickText">quickText()</a></code> to handle
routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+calendarPlot">calendarPlot()</a></code> will plot data in a conventional calendar format, i.e., by
month and day of the week. Daily statistics are calculated using
<code><a href="#topic+timeAverage">timeAverage()</a></code>, which by default will calculate the daily mean
concentration.
</p>
<p>If wind direction is available it is then possible to plot the wind direction
vector on each day. This is very useful for getting a feel for the
meteorological conditions that affect pollutant concentrations. Note that if
hourly or higher time resolution are supplied, then <code><a href="#topic+calendarPlot">calendarPlot()</a></code> will
calculate daily averages using <code><a href="#topic+timeAverage">timeAverage()</a></code>, which ensures that wind
directions are vector-averaged.
</p>
<p>If wind speed is also available, then setting the option <code>annotate = "ws"</code>
will plot the wind vectors whose length is scaled to the wind speed. Thus
information on the daily mean wind speed and direction are available.
</p>
<p>It is also possible to plot categorical scales. This is useful where, for
example, an air quality index defines concentrations as bands, e.g., &quot;good&quot;,
&quot;poor&quot;. In these cases users must supply <code>labels</code> and corresponding <code>breaks</code>.
</p>
<p>Note that is is possible to pre-calculate concentrations in some way before
passing the data to <code><a href="#topic+calendarPlot">calendarPlot()</a></code>. For example <code><a href="#topic+rollingMean">rollingMean()</a></code> could be
used to calculate rolling 8-hour mean concentrations. The data can then be
passed to <code><a href="#topic+calendarPlot">calendarPlot()</a></code> and <code>statistic = "max"</code> chosen, which will plot
maximum daily 8-hour mean concentrations.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># basic plot
calendarPlot(mydata, pollutant = "o3", year = 2003)

# show wind vectors
calendarPlot(mydata, pollutant = "o3", year = 2003, annotate = "wd")
## Not run: 
# show wind vectors scaled by wind speed and different colours
calendarPlot(mydata,
  pollutant = "o3", year = 2003, annotate = "ws",
  cols = "heat"
)

# show only specific months with selectByDate
calendarPlot(selectByDate(mydata, month = c(3, 6, 10), year = 2003),
  pollutant = "o3", year = 2003, annotate = "ws", cols = "heat"
)

# categorical scale example
calendarPlot(mydata,
  pollutant = "no2", breaks = c(0, 50, 100, 150, 1000),
  labels = c("Very low", "Low", "High", "Very High"),
  cols = c("lightblue", "green", "yellow", "red"), statistic = "max"
)

# UK daily air quality index
pm10.breaks &lt;- c(0, 17, 34, 50, 59, 67, 75, 84, 92, 100, 1000)
calendarPlot(mydata, "pm10",
  year = 1999, breaks = pm10.breaks,
  labels = c(1:10), cols = "daqi", statistic = "mean", key.header = "DAQI"
)

## End(Not run)
</code></pre>

<hr>
<h2 id='conditionalEval'>Conditional quantile estimates with additional variables for model evaluation</h2><span id='topic+conditionalEval'></span>

<h3>Description</h3>

<p>This function enhances <code><a href="#topic+conditionalQuantile">conditionalQuantile()</a></code> by also considering how other
variables vary over the same intervals. Conditional quantiles are very useful
on their own for model evaluation, but provide no direct information on how
other variables change at the same time. For example, a conditional quantile
plot of ozone concentrations may show that low concentrations of ozone tend
to be under-predicted. However, the cause of the under-prediction can be
difficult to determine. However, by considering how well the model predicts
other variables over the same intervals, more insight can be gained into the
underlying reasons why model performance is poor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditionalEval(
  mydata,
  obs = "obs",
  mod = "mod",
  var.obs = "var.obs",
  var.mod = "var.mod",
  type = "default",
  bins = 31,
  statistic = "MB",
  xlab = "predicted value",
  ylab = "statistic",
  col = brewer.pal(5, "YlOrRd"),
  col.var = "Set1",
  var.names = NULL,
  auto.text = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conditionalEval_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing the field <code>obs</code> and <code>mod</code>
representing observed and modelled values.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_obs">obs</code></td>
<td>
<p>The name of the observations in <code>mydata</code>.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_mod">mod</code></td>
<td>
<p>The name of the predictions (modelled values) in <code>mydata</code>.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_var.obs">var.obs</code></td>
<td>
<p>Other variable observations for which statistics should be
calculated. Can be more than length one e.g. <code>var.obs = c("nox.obs", "ws.obs")</code>. Note that including other variables could reduce the number of
data available to plot due to the need of having non-missing data for all
variables.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_var.mod">var.mod</code></td>
<td>
<p>Other variable predictions for which statistics should be
calculated. Can be more than length one e.g. <code>var.obs = c("nox.obs", "ws.obs")</code>.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &quot;season&quot;, &quot;year&quot;, &quot;weekday&quot; and so on. For example,
<code>type = "season"</code> will produce four plots &mdash; one for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_bins">bins</code></td>
<td>
<p>Number of bins to be used in calculating the different quantile
levels.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_statistic">statistic</code></td>
<td>
<p>Statistic(s) to be plotted. Can be &ldquo;MB&rdquo;,
&ldquo;NMB&rdquo;, &ldquo;r&rdquo;, &ldquo;COE&rdquo;, &ldquo;MGE&rdquo;, &ldquo;NMGE&rdquo;,
&ldquo;RMSE&rdquo; and &ldquo;FAC2&rdquo;, as described in <code>modStats</code>. When
these statistics are chosen, they are calculated from <code>var.mod</code> and
<code>var.mod</code>.
</p>
<p><code>statistic</code> can also be a value that can be supplied to
<code>cutData</code>. For example, <code>statistic = "season"</code> will show how
model performance varies by season across the distribution of predictions
which might highlight that at high concentrations of NOx the model tends to
underestimate concentrations and that these periods mostly occur in winter.
<code>statistic</code> can also be another variable in the data frame &mdash; see
<code>cutData</code> for more information. A special case is <code>statistic = "cluster"</code> if clusters have been calculated using <code>trajCluster</code>.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_xlab">xlab</code></td>
<td>
<p>label for the x-axis, by default &ldquo;predicted value&rdquo;.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_ylab">ylab</code></td>
<td>
<p>label for the y-axis, by default &ldquo;observed value&rdquo;.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_col">col</code></td>
<td>
<p>Colours to be used for plotting the uncertainty bands and median
line. Must be of length 5 or more.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_col.var">col.var</code></td>
<td>
<p>Colours for the additional variables to be compared. See
<code>openColours</code> for more details.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_var.names">var.names</code></td>
<td>
<p>Variable names to be shown on plot for plotting
<code>var.obs</code> and <code>var.mod</code>.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels etc. will automatically try and format pollutant
names and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="conditionalEval_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>conditionalQuantile</code>
and <code>cutData</code>. For example, <code>conditionalQuantile</code> passes the
option <code>hemisphere = "southern"</code> on to <code>cutData</code> to provide
southern (rather than default northern) hemisphere handling of <code>type = "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>conditionalEval</code> function provides information on how other
variables vary across the same intervals as shown on the conditional quantile
plot. There are two types of variable that can be considered by setting the
value of <code>statistic</code>. First, <code>statistic</code> can be another variable in
the data frame. In this case the plot will show the different proportions of
<code>statistic</code> across the range of predictions. For example <code>statistic = "season"</code> will show for each interval of <code>mod</code> the proportion of
predictions that were spring, summer, autumn or winter. This is useful
because if model performance is worse for example at high concentrations of
<code>mod</code> then knowing that these tend to occur during a particular season
etc. can be very helpful when trying to understand <em>why</em> a model fails.
See <code><a href="#topic+cutData">cutData()</a></code> for more details on the types of variable that can
be <code>statistic</code>. Another example would be <code>statistic = "ws"</code> (if
wind speed were available in the data frame), which would then split wind
speed into four quantiles and plot the proportions of each.
</p>
<p>Second, <code>conditionalEval</code> can simultaneously plot the model performance
of other observed/predicted variable <strong>pairs</strong> according to different
model evaluation statistics. These statistics derive from the
<code><a href="#topic+modStats">modStats()</a></code> function and include &ldquo;MB&rdquo;, &ldquo;NMB&rdquo;,
&ldquo;r&rdquo;, &ldquo;COE&rdquo;, &ldquo;MGE&rdquo;, &ldquo;NMGE&rdquo;, &ldquo;RMSE&rdquo; and
&ldquo;FAC2&rdquo;. More than one statistic can be supplied e.g. <code>statistic = c("NMB", "COE")</code>. Bootstrap samples are taken from the corresponding values
of other variables to be plotted and their statistics with 95\
intervals calculated. In this case, the model <em>performance</em> of other
variables is shown across the same intervals of <code>mod</code>, rather than just
the values of single variables. In this second case the model would need to
provide observed/predicted pairs of other variables.
</p>
<p>For example, a model may provide predictions of NOx and wind speed (for which
there are also observations available). The <code>conditionalEval</code> function
will show how well these other variables are predicted for the same intervals
of the main variables assessed in the conditional quantile e.g. ozone. In
this case, values are supplied to <code>var.obs</code> (observed values for other
variables) and <code>var.mod</code> (modelled values for other variables). For
example, to consider how well the model predicts NOx and wind speed
<code>var.obs = c("nox.obs", "ws.obs")</code> and <code>var.mod = c("nox.mod", "ws.mod")</code> would be supplied (assuming <code style="white-space: pre;">&#8288;nox.obs, nox.mod, ws.obs, ws.mod&#8288;</code> are present in the data frame). The analysis could show for example,
when ozone concentrations are under-predicted, the model may also be shown to
over-predict concentrations of NOx at the same time, or under-predict wind
speeds. Such information can thus help identify the underlying causes of poor
model performance. For example, an under-prediction in wind speed could
result in higher surface NOx concentrations and lower ozone concentrations.
Similarly if wind speed predictions were good and NOx was over predicted it
might suggest an over-estimate of NOx emissions. One or more additional
variables can be plotted.
</p>
<p>A special case is <code>statistic = "cluster"</code>. In this case a data frame is
provided that contains the cluster calculated by <code><a href="#topic+trajCluster">trajCluster()</a></code>
and <code><a href="#topic+importTraj">importTraj()</a></code>. Alternatively users could supply their own
pre-calculated clusters. These calculations can be very useful in showing
whether certain back trajectory clusters are associated with poor (or good)
model performance. Note that in the case of <code>statistic = "cluster"</code>
there will be fewer data points used in the analysis compared with the
ordinary statistics above because the trajectories are available for every
three hours. Also note that <code>statistic = "cluster"</code> cannot be used
together with the ordinary model evaluation statistics such as MB. The output
will be a bar chart showing the proportion of each interval of <code>mod</code> by
cluster number.
</p>
<p>Far more insight can be gained into model performance through conditioning
using <code>type</code>. For example, <code>type = "season"</code> will plot conditional
quantiles and the associated model performance statistics of other variables
by each season. <code>type</code> can also be a factor or character field e.g.
representing different models used.
</p>
<p>See Wilks (2005) for more details of conditional quantile plots.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Wilks, D. S., 2005. Statistical Methods in the Atmospheric
Sciences, Volume 91, Second Edition (International Geophysics), 2nd
Edition. Academic Press.
</p>


<h3>See Also</h3>

<p>The <code>verification</code> package for comprehensive functions for
forecast verification.
</p>
<p>Other model evaluation functions: 
<code><a href="#topic+TaylorDiagram">TaylorDiagram</a>()</code>,
<code><a href="#topic+conditionalQuantile">conditionalQuantile</a>()</code>,
<code><a href="#topic+modStats">modStats</a>()</code>
</p>

<hr>
<h2 id='conditionalQuantile'>Conditional quantile estimates for model evaluation</h2><span id='topic+conditionalQuantile'></span>

<h3>Description</h3>

<p>Function to calculate conditional quantiles with flexible conditioning. The
function is for use in model evaluation and more generally to help better
understand forecast predictions and how well they agree with observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditionalQuantile(
  mydata,
  obs = "obs",
  mod = "mod",
  type = "default",
  bins = 31,
  min.bin = c(10, 20),
  xlab = "predicted value",
  ylab = "observed value",
  col = brewer.pal(5, "YlOrRd"),
  key.columns = 2,
  key.position = "bottom",
  auto.text = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conditionalQuantile_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing the field <code>obs</code> and <code>mod</code>
representing observed and modelled values.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_obs">obs</code></td>
<td>
<p>The name of the observations in <code>mydata</code>.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_mod">mod</code></td>
<td>
<p>The name of the predictions (modelled values) in <code>mydata</code>.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_bins">bins</code></td>
<td>
<p>Number of bins to be used in calculating the different quantile
levels.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_min.bin">min.bin</code></td>
<td>
<p>The minimum number of points required for the estimates of the
25/75th and 10/90th percentiles.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_xlab">xlab</code></td>
<td>
<p>label for the x-axis, by default &ldquo;predicted value&rdquo;.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_ylab">ylab</code></td>
<td>
<p>label for the y-axis, by default &ldquo;observed value&rdquo;.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_col">col</code></td>
<td>
<p>Colours to be used for plotting the uncertainty bands and median
line. Must be of length 5 or more.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_key.position">key.position</code></td>
<td>
<p>Location of the key e.g. &ldquo;top&rdquo;, &ldquo;bottom&rdquo;,
&ldquo;right&rdquo;, &ldquo;left&rdquo;. See <code>lattice</code> <code>xyplot</code> for more
details.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels etc. will automatically try and format pollutant
names and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="conditionalQuantile_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>conditionalQuantile</code> passes the
option <code>hemisphere = "southern"</code> on to <code>cutData</code> to provide
southern (rather than default northern) hemisphere handling of <code>type = "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Conditional quantiles are a very useful way of considering model performance
against observations for continuous measurements (Wilks, 2005). The
conditional quantile plot splits the data into evenly spaced bins. For each
predicted value bin e.g. from 0 to 10~ppb the <em>corresponding</em> values of
the observations are identified and the median, 25/75th and 10/90 percentile
(quantile) calculated for that bin. The data are plotted to show how these
values vary across all bins. For a time series of observations and
predictions that agree precisely the median value of the predictions will
equal that for the observations for each bin.
</p>
<p>The conditional quantile plot differs from the quantile-quantile plot (Q-Q
plot) that is often used to compare observations and predictions. A Q-Q~plot
separately considers the distributions of observations and predictions,
whereas the conditional quantile uses the corresponding observations for a
particular interval in the predictions. Take as an example two time series,
the first a series of real observations and the second a lagged time series
of the same observations representing the predictions. These two time series
will have identical (or very nearly identical) distributions (e.g. same
median, minimum and maximum). A Q-Q plot would show a straight line showing
perfect agreement, whereas the conditional quantile will not. This is because
in any interval of the predictions the corresponding observations now have
different values.
</p>
<p>Plotting the data in this way shows how well predictions agree with
observations and can help reveal many useful characteristics of how well
model predictions agree with observations &mdash; across the full distribution of
values. A single plot can therefore convey a considerable amount of
information concerning model performance. The <code>conditionalQuantile</code>
function in openair allows conditional quantiles to be considered in a
flexible way e.g. by considering how they vary by season.
</p>
<p>The function requires a data frame consisting of a column of observations and
a column of predictions. The observations are split up into <code>bins</code>
according to values of the predictions. The median prediction line together
with the 25/75th and 10/90th quantile values are plotted together with a line
showing a &ldquo;perfect&rdquo; model. Also shown is a histogram of predicted
values (shaded grey) and a histogram of observed values (shown as a blue
line).
</p>
<p>Far more insight can be gained into model performance through conditioning
using <code>type</code>. For example, <code>type = "season"</code> will plot conditional
quantiles by each season. <code>type</code> can also be a factor or character field
e.g. representing different models used.
</p>
<p>See Wilks (2005) for more details and the examples below.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Murphy, A. H., B.G. Brown and Y. Chen. (1989) Diagnostic Verification of
Temperature Forecasts, Weather and Forecasting, Volume: 4, Issue: 4, Pages:
485-501.
</p>
<p>Wilks, D. S., 2005. Statistical Methods in the Atmospheric Sciences, Volume
91, Second Edition (International Geophysics), 2nd Edition. Academic Press.
</p>


<h3>See Also</h3>

<p>The <code>verification</code> package for comprehensive functions for
forecast verification.
</p>
<p>Other model evaluation functions: 
<code><a href="#topic+TaylorDiagram">TaylorDiagram</a>()</code>,
<code><a href="#topic+conditionalEval">conditionalEval</a>()</code>,
<code><a href="#topic+modStats">modStats</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## make some dummy prediction data based on 'nox'
mydata$mod &lt;- mydata$nox * 1.1 + mydata$nox * runif(1:nrow(mydata))

# basic conditional quantile plot
## A "perfect" model is shown by the blue line
## predictions tend to be increasingly positively biased at high nox,
## shown by departure of median line from the blue one.
## The widening uncertainty bands with increasing NOx shows that
## hourly predictions are worse for higher NOx concentrations.
## Also, the red (median) line extends beyond the data (blue line),
## which shows in this case some predictions are much higher than
## the corresponding measurements. Note that the uncertainty bands
## do not extend as far as the median line because there is insufficient
# to calculate them
conditionalQuantile(mydata, obs = "nox", mod = "mod")

## can split by season to show seasonal performance (not very
## enlightening in this case - try some real data and it will be!)

## Not run: 
conditionalQuantile(mydata, obs = "nox", mod = "mod", type = "season")

## End(Not run)
</code></pre>

<hr>
<h2 id='corPlot'>Correlation matrices with conditioning</h2><span id='topic+corPlot'></span>

<h3>Description</h3>

<p>Function to to draw and visualise correlation matrices using lattice. The
primary purpose is as a tool for exploratory data analysis. Hierarchical
clustering is used to group similar variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corPlot(
  mydata,
  pollutants = NULL,
  type = "default",
  cluster = TRUE,
  method = "pearson",
  use = "pairwise.complete.obs",
  dendrogram = FALSE,
  lower = FALSE,
  cols = "default",
  r.thresh = 0.8,
  text.col = c("black", "black"),
  auto.text = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corPlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame which should consist of some numeric columns.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_pollutants">pollutants</code></td>
<td>
<p>the names of data-series in <code>mydata</code> to be plotted by
<code>corPlot</code>. The default option <code>NULL</code> and the alternative
&ldquo;all&rdquo; use all available valid (numeric) data.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_cluster">cluster</code></td>
<td>
<p>Should the data be ordered according to cluster analysis. If
<code>TRUE</code> hierarchical clustering is applied to the correlation matrices
using <code>hclust</code> to group similar variables together. With many
variables clustering can greatly assist interpretation.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_method">method</code></td>
<td>
<p>The correlation method to use. Can be &ldquo;pearson&rdquo;,
&ldquo;spearman&rdquo; or &ldquo;kendall&rdquo;.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_use">use</code></td>
<td>
<p>How to handle missing values in the <code>cor</code> function. The default is
&quot;pairwise.complete.obs&quot;. Care should be taken with the choice of how to
handle missing data when considering pair-wise correlations.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_dendrogram">dendrogram</code></td>
<td>
<p>Should a dendrogram be plotted? When <code>TRUE</code> a
dendrogram is shown on the right of the plot. Note that this will only work
for <code>type = "default"</code>.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_lower">lower</code></td>
<td>
<p>Should only the lower triangle be plotted?</p>
</td></tr>
<tr><td><code id="corPlot_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;spectral&rdquo;,
&ldquo;hue&rdquo;, &ldquo;greyscale&rdquo; and user defined (see <code>openColours</code>
for more details).</p>
</td></tr>
<tr><td><code id="corPlot_+3A_r.thresh">r.thresh</code></td>
<td>
<p>Values of greater than <code>r.thresh</code> will be shown in bold
type. This helps to highlight high correlations.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_text.col">text.col</code></td>
<td>
<p>The colour of the text used to show the correlation values.
The first value controls the colour of negative correlations and the second
positive.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract corPlot components and plotting them in other
ways.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:levelplot</code>,
with common axis and title labelling options (such as <code>xlab</code>,
<code>ylab</code>, <code>main</code>) being passed via <code>quickText</code> to handle
routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>corPlot</code> function plots correlation matrices. The implementation
relies heavily on that shown in Sarkar (2007), with a few extensions.
</p>
<p>Correlation matrices are a very effective way of understating relationships
between many variables. The <code>corPlot</code> shows the correlation coded in
three ways: by shape (ellipses), colour and the numeric value. The ellipses
can be thought of as visual representations of scatter plot. With a perfect
positive correlation a line at 45 degrees positive slope is drawn. For zero
correlation the shape becomes a circle. See examples below.
</p>
<p>With many different variables it can be difficult to see relationships
between variables, i.e., which variables tend to behave most like one
another. For this reason hierarchical clustering is applied to the
correlation matrices to group variables that are most similar to one another
(if <code>cluster = TRUE</code>).
</p>
<p>If clustering is chosen it is also possible to add a dendrogram using the
option <code>dendrogram = TRUE</code>. Note that dendrogramscan only be plotted for
<code>type = "default"</code> i.e. when there is only a single panel. The
dendrogram can also be recovered from the plot object itself and plotted more
clearly; see examples below.
</p>
<p>It is also possible to use the <code>openair</code> type option to condition the
data in many flexible ways, although this may become difficult to visualise
with too many panels.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw &mdash; but mostly based on code contained in Sarkar (2007)
</p>


<h3>References</h3>

<p>Sarkar, D. (2007). Lattice Multivariate Data Visualization with
R. New York: Springer.
</p>
<p>Friendly, M. (2002). Corrgrams : Exploratory displays for correlation
matrices. American Statistician, 2002(4), 1-16. doi:10.1198/000313002533
</p>


<h3>See Also</h3>

<p><code>taylor.diagram</code> from the <code>plotrix</code> package from which
some of the annotation code was used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## basic corrgram plot
corPlot(mydata)
## plot by season ... and so on
corPlot(mydata, type = "season")
## recover dendrogram when cluster = TRUE and plot it
res &lt;-corPlot(mydata)
plot(res$clust)
## Not run: 
## a more interesting are hydrocarbon measurements
hc &lt;- importAURN(site = "my1", year = 2005, hc = TRUE)
## now it is possible to see the hydrocarbons that behave most
## similarly to one another
corPlot(hc)

## End(Not run)


</code></pre>

<hr>
<h2 id='cutData'>Function to split data in different ways for conditioning</h2><span id='topic+cutData'></span>

<h3>Description</h3>

<p>Utility function to split data frames up in various ways for conditioning
plots. Users would generally not be expected to call this function directly.
Widely used by many <code>openair</code> functions usually through the option
<code>type</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutData(
  x,
  type = "default",
  hemisphere = "northern",
  n.levels = 4,
  start.day = 1,
  is.axis = FALSE,
  local.tz = NULL,
  latitude = 51,
  longitude = -0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cutData_+3A_x">x</code></td>
<td>
<p>A data frame containing a field <code>date</code>.</p>
</td></tr>
<tr><td><code id="cutData_+3A_type">type</code></td>
<td>
<p>A string giving the way in which the data frame should be split.
Pre-defined values are: &ldquo;default&rdquo;, &ldquo;year&rdquo;, &ldquo;hour&rdquo;,
&ldquo;month&rdquo;, &ldquo;season&rdquo;, &ldquo;weekday&rdquo;, &ldquo;site&rdquo;,
&ldquo;weekend&rdquo;, &ldquo;monthyear&rdquo;, &ldquo;daylight&rdquo;, &ldquo;dst&rdquo;
(daylight saving time).
</p>
<p><code>type</code> can also be the name of a numeric or factor. If a numeric
column name is supplied <code>cutData</code> will split the data into four
quantiles. Factors levels will be used to split the data without any
adjustment.</p>
</td></tr>
<tr><td><code id="cutData_+3A_hemisphere">hemisphere</code></td>
<td>
<p>Can be <code>"northern"</code> or <code>"southern"</code>, used to
split data into seasons.</p>
</td></tr>
<tr><td><code id="cutData_+3A_n.levels">n.levels</code></td>
<td>
<p>Number of quantiles to split numeric data into.</p>
</td></tr>
<tr><td><code id="cutData_+3A_start.day">start.day</code></td>
<td>
<p>What day of the week should the <code>type = "weekday"</code>
start on?  The user can change the start day by supplying an integer
between 0 and 6. Sunday = 0, Monday = 1, ... For example to start the
weekday plots on a Saturday, choose <code>start.day = 6</code>.</p>
</td></tr>
<tr><td><code id="cutData_+3A_is.axis">is.axis</code></td>
<td>
<p>A logical (<code>TRUE</code>/<code>FALSE</code>), used to request
shortened cut labels for axes.</p>
</td></tr>
<tr><td><code id="cutData_+3A_local.tz">local.tz</code></td>
<td>
<p>Used for identifying whether a date has daylight savings time
(DST) applied or not. Examples include <code>local.tz = "Europe/London"</code>,
<code>local.tz = "America/New_York"</code> i.e. time zones that assume DST.
<a href="https://en.wikipedia.org/wiki/List_of_zoneinfo_time_zones">https://en.wikipedia.org/wiki/List_of_zoneinfo_time_zones</a> shows time
zones that should be valid for most systems. It is important that the
original data are in GMT (UTC) or a fixed offset from GMT. See
<code>import</code> and the openair manual for information on how to import data
and ensure no DST is applied.</p>
</td></tr>
<tr><td><code id="cutData_+3A_latitude">latitude</code></td>
<td>
<p>The decimal latitude used in <code>type = "daylight"</code>.</p>
</td></tr>
<tr><td><code id="cutData_+3A_longitude">longitude</code></td>
<td>
<p>The decimal longitude. Note that locations west of Greenwich
are negative.</p>
</td></tr>
<tr><td><code id="cutData_+3A_...">...</code></td>
<td>
<p>All additional parameters are passed on to next function(s).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section give a brief description of each of the define levels of
<code>type</code>. Note that all time dependent types require a column <code>date</code>.
</p>
<p>&quot;default&quot; does not split the data but will describe the levels as a date
range in the format &quot;day month year&quot;.
</p>
<p>&quot;year&quot; splits the data by each year.
</p>
<p>&quot;month&quot; splits the data by month of the year.
</p>
<p>&quot;hour&quot; splits the data by hour of the day.
</p>
<p>&quot;monthyear&quot; splits the data by year and month. It differs from month in that
a level is defined for each month of the data set. This is useful sometimes
to show an ordered sequence of months if the data set starts half way through
a year; rather than starting in January.
</p>
<p>&quot;weekend&quot; splits the data by weekday and weekend.
</p>
<p>&quot;weekday&quot; splits the data by day of the week - ordered to start Monday.
</p>
<p>&quot;season&quot; splits data up by season. In the northern hemisphere winter =
December, January, February; spring = March, April, May etc. These
definitions will change of <code>hemisphere = "southern"</code>.
</p>
<p>&quot;seasonyear (or &quot;yearseason&quot;) will split the data into year-season intervals,
keeping the months of a season together. For example, December 2010 is
considered as part of winter 2011 (with January and February 2011). This
makes it easier to consider contiguous seasons. In contrast, <code>type =
"season"</code> will just split the data into four seasons regardless of the year.
</p>
<p>&quot;daylight&quot; splits the data relative to estimated sunrise and sunset to give
either daylight or nighttime. The cut is made by <code>cutDaylight</code> but more
conveniently accessed via <code>cutData</code>, e.g. <code>cutData(mydata, type =
"daylight", latitude = my.latitude, longitude = my.longitude)</code>. The daylight
estimation, which is valid for dates between 1901 and 2099, is made using the
measurement location, date, time and astronomical algorithms to estimate the
relative positions of the Sun and the measurement location on the Earth's
surface, and is based on NOAA methods. Measurement location should be set
using <code>latitude</code> (+ to North; - to South) and <code>longitude</code> (+ to
East; - to West).
</p>
<p>&quot;dst&quot; will split the data by hours that are in daylight saving time (DST) and
hours that are not for appropriate time zones. The option &quot;dst&quot; also requires
that the local time zone is given e.g. <code>local.tz = "Europe/London"</code>,
<code>local.tz = "America/New_York"</code>. Each of the two periods will be in
<em>local time</em>. The main purpose of this option is to test whether there
is a shift in the diurnal profile when DST and non-DST hours are compared.
This option is particularly useful with the <code>timeVariation</code> function.
For example, close to the source of road vehicle emissions, &lsquo;rush-hour&rsquo; will
tend to occur at the same <em>local time</em> throughout the year e.g. 8 am and
5 pm. Therefore, comparing non-DST hours with DST hours will tend to show
similar diurnal patterns (at least in the timing of the peaks, if not
magnitude) when expressed in local time. By contrast a variable such as wind
speed or temperature should show a clear shift when expressed in local time.
In essence, this option when used with <code>timeVariation</code> may help
determine whether the variation in a pollutant is driven by man-made
emissions or natural processes.
</p>
<p>&quot;wd&quot; splits the data by 8 wind sectors and requires a column <code>wd</code>: &quot;NE&quot;,
&quot;E&quot;, &quot;SE&quot;, &quot;S&quot;, &quot;SW&quot;, &quot;W&quot;, &quot;NW&quot;, &quot;N&quot;.
</p>
<p>&quot;ws&quot; splits the data by 8 quantiles of wind speed and requires a column
<code>ws</code>.
</p>
<p>&quot;site&quot; splits the data by site and therefore requires a column <code>site</code>.
</p>
<p>Note that all the date-based types e.g. month/year are derived from a column
<code>date</code>. If a user already has a column with a name of one of the
date-based types it will not be used.
</p>


<h3>Value</h3>

<p>Returns a data frame with a column <code>cond</code> that is defined by
<code>type</code>.
</p>


<h3>Author(s)</h3>

<p>David Carslaw (cutData) and Karl Ropkins (cutDaylight)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## split data by day of the week
mydata &lt;- cutData(mydata, type = "weekday")


</code></pre>

<hr>
<h2 id='drawOpenKey'>Scale key handling for openair</h2><span id='topic+drawOpenKey'></span>

<h3>Description</h3>

<p>General function for producing scale keys for other openair functions.  The
function is a crude modification of the draw.colorkey function developed by
Deepayan Sarkar as part of the lattice package, and allows additional key
labelling to added, and provides some additional control of the appearance
and scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawOpenKey(key, draw = FALSE, vp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drawOpenKey_+3A_key">key</code></td>
<td>
<p>List defining the scale key structure to be produced. Most
options are identical to original <code>draw.colorkey</code> function.
</p>
<p>Original <code>draw.colorkey</code> options:
</p>
<p><code>space</code> location of the scale key (&quot;left&quot;, &quot;right&quot;, &quot;top&quot; or
&quot;bottom&quot;).  Defaults to &quot;right&quot;.
</p>
<p><code>col</code> vector of colours, used in scale key.
</p>
<p><code>at</code> numeric vector specifying where the colors change. Must be of
length 1 more than the col vector.
</p>
<p><code>labels</code> a character vector for labelling the at values, or more
commonly, a list describing characteristics of the labels. This list may
include components <code>labels</code>, <code>at</code>, <code>cex</code>, <code>col</code>,
<code>rot</code>, <code>font</code>, <code>fontface</code> and <code>fontfamily</code>.
</p>
<p><code>tick.number</code> approximate number of ticks.
</p>
<p><code>width</code> width of the key.
</p>
<p><code>height</code> height of key.
</p>
<p>Note: <code>width</code> and <code>height</code> refer to the key dimensions.
<code>height</code> is the length of the key along the plot axis it is
positioned against, and <code>width</code> is the length perpendicular to that.
</p>
<p>Additional options include:
</p>
<p><code>header</code> a character vector of extra text to be added above the key,
or a list describing some characteristics of the <code>header</code>. This list
may include components <code>header</code>, the character vector of header
labels, <code>tweaks</code>, a list of local controls, e.g. 'gap' and 'balance'
for spacing relative to scale and footer, respectively, <code>auto.text</code>,
<code>TRUE/FALSE</code> option to apply <code>quickText</code>, and <code>slot</code>, a
numeric vector setting the size of the text boxes <code>header</code> text is
placed in.
</p>
<p><code>footer</code> as in <code>header</code> but for labels below the scale key.
</p>
<p>Notes: <code>header</code> and <code>footer</code> formatting can not be set locally,
but instead are matched to those set in <code>labels</code>. <code>drawOpenKey</code>
allows for up to six additional labels (three above and three below scale
key). Any additional text is ignored.
</p>
<p><code>tweak, auto.text, slot</code> as in <code>header</code> and <code>footer</code> but
sets all options uniformly. This also overwrites anything in
<code>header</code> and/or <code>footer</code>.
</p>
<p><code>fit</code> the fit method to be applied to the header, scale key and footer
when placing the scale key left or right of the plot. Options include:
'all', 'soft' and 'scale'.  The default 'all' fits header, key and footer
into <code>height</code> range. The alternative 'scale' fits only the key
within <code>height</code>. (This means that keys keep the same proportions
relative to the main plot regardless of positioning but that header and
footer may exceed plot dimensions if <code>height</code> and/or <code>slots</code>
are too large.
</p>
<p><code>plot.style</code> a character vector of key plotting style instructions:
Options currently include: 'paddle', 'ticks' and 'border'. 'paddle'
applies the incremental paddle layout used by <code>winRose</code>. 'ticks'
places ticks between the labels scale key. 'border' places a border about
the scale key. Any combination of these may be used but if none set,
scale key defaults to <code>c("ticks", "border")</code> for most plotting
operations or <code>c("paddle")</code> for <code>windRose</code>.</p>
</td></tr>
<tr><td><code id="drawOpenKey_+3A_draw">draw</code></td>
<td>
<p>Option to return the key object or plot it directly.  The
default, FALSE, should always be used within openair calls.</p>
</td></tr>
<tr><td><code id="drawOpenKey_+3A_vp">vp</code></td>
<td>
<p>View port to be used when plotting key. The default, NULL, should
always be used within openair calls.
</p>
<p>(Note: <code>drawOpenKey</code> is a crude modification of
<code>lattice::draw.colorkey</code>, that provides labelling options for
<code>openair</code> plot scale keys. Some aspects of the function are in
development and may to subject to change. Therefore, it is recommended
that you use parent <code>openair</code> function controls, e.g.
<code>key.position</code>, <code>key.header</code>, <code>key.footer</code> options, where
possible.  <code>drawOpenKey</code> may obviously be used in other plots but it
is recommended that <code>draw.colorkey</code> itself be used wherever this
type of additional scale labelling is not required.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>drawOpenKey</code> function produces scale keys for other openair
functions.
</p>
<p>Most <code>drawOpenKey</code> options are identical to those of
<code>lattice::draw.colorkey</code>.  For example, scale key size and position
are controlled via <code>height</code>, <code>width</code> and <code>space</code>. Likewise,
the axis labelling can be set in and formatted by <code>labels</code>. See
<code><a href="lattice.html#topic+draw.colorkey">draw.colorkey</a></code> for further details.
</p>
<p>Additional scale labelling may be added above and below the scale using
<code>header</code> and <code>footer</code> options within <code>key</code>. As in other
<code>openair</code> functions, automatic text formatting can be enabled via
<code>auto.key</code>.
</p>
<p>(Note: Currently, the formatting of <code>header</code> and <code>footer</code> text
are fixed to the same style as <code>labels</code> (the scale axis) and cannot be
defined locally.)
</p>
<p>The relationship between <code>header</code>, <code>footer</code> and the scale key
itself can be controlled using <code>fit</code> options. These can be set in
<code>key$fit</code> to apply uniform control or individually in
<code>key$header$fit</code> and/or <code>key$footer$fit</code> to control locally.
</p>
<p>The appearance of the scale can be controlled using <code>plot.style</code>.
</p>


<h3>Value</h3>

<p>The function is a modification of <code>lattice::draw.colorkey</code> and
returns a scale key using a similar mechanism to that used in in the
original function as developed by Deepayan Sarkar.
</p>


<h3>Note</h3>

<p>We gratefully acknowledge the considerable help and advice of
Deepayan Sarkar.
</p>


<h3>Author(s)</h3>

<p><code>draw.colorkey</code> is part of the <code>lattice</code> package,
developed by Deepayan Sarkar.
</p>
<p>Additional modifications by Karl Ropkins.
</p>


<h3>References</h3>

<p>Deepayan Sarkar (2010). lattice: Lattice Graphics. R package
version 0.18-5.  http://r-forge.r-project.org/projects/lattice/
</p>


<h3>See Also</h3>

<p>Functions using <code>drawOpenKey</code> currently include
<code><a href="#topic+windRose">windRose</a></code>, <code><a href="#topic+pollutionRose">pollutionRose</a></code>.
</p>
<p>For details of the original function, see <code><a href="lattice.html#topic+draw.colorkey">draw.colorkey</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##########
#example 1
##########

#paddle style scale key used by windRose

windRose(mydata,)

#adding text and changing style and position via key

#note:
#some simple key control also possible directly
#For example, below does same as
#windRose(mydata, key.position="right")

windRose(mydata,
   key =list(space="right")
)

#however:
#more detailed control possible working with
#key and drawOpenKey. For example,

windRose(mydata,
   key = list(header="Title", footer="wind speed",
              plot.style = c("ticks", "border"),
              fit = "all", height = 1,
              space = "top")
)


</code></pre>

<hr>
<h2 id='importADMS'>CERC Atmospheric Dispersion Modelling System (ADMS) data import function(s)
for openair</h2><span id='topic+importADMS'></span><span id='topic+importADMSBgd'></span><span id='topic+importADMSMet'></span><span id='topic+importADMSMop'></span><span id='topic+importADMSPst'></span>

<h3>Description</h3>

<p>Function(s) to import various ADMS file types into openair. Currently handles
&quot;.met&quot;, &quot;.bgd&quot;, &quot;.mop&quot; and &quot;.pst&quot; file structures. Uses <code><a href="utils.html#topic+read.table">utils::read.csv()</a></code>
to read in data, format for R and openair and apply some file structure
testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importADMS(
  file = file.choose(),
  file.type = "unknown",
  drop.case = TRUE,
  drop.input.dates = TRUE,
  keep.units = TRUE,
  simplify.names = TRUE,
  test.file.structure = TRUE,
  drop.delim = TRUE,
  add.prefixes = TRUE,
  names = NULL,
  all = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importADMS_+3A_file">file</code></td>
<td>
<p>The ADMS file to be imported. Default, <code><a href="base.html#topic+file.choose">file.choose()</a></code> opens
browser. Use of <code><a href="utils.html#topic+read.table">utils::read.csv()</a></code> also allows this to be a readable
text-mode connection or url (although these options are currently not fully
tested).</p>
</td></tr>
<tr><td><code id="importADMS_+3A_file.type">file.type</code></td>
<td>
<p>Type of ADMS file to be imported. With default, &quot;unknown&quot;,
the import uses the file extension to identify the file type and, where
recognised, uses this to identify the file structure and import method to
be applied. Where file extension is not recognised the choice may be forced
by setting <code>file.type</code> to one of the known <code>file.type</code> options:
&quot;bgd&quot;, &quot;met&quot;, &quot;mop&quot; or &quot;pst&quot;.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_drop.case">drop.case</code></td>
<td>
<p>Option to convert all data names to lower case. Default,
<code>TRUE</code>.  Alternative, <code>FALSE</code>, returns data with name cases as
defined in file.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_drop.input.dates">drop.input.dates</code></td>
<td>
<p>Option to remove ADMS &quot;hour&quot;, &quot;day&quot;, and &quot;year&quot; data
columns after generating openair &quot;date&quot; timeseries. Default, <code>TRUE</code>.
Alternative, <code>FALSE</code>, returns both &quot;date&quot; and the associated ADMS data
columns as part of openair data frame.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_keep.units">keep.units</code></td>
<td>
<p>Option to retain ADMS data units. Default, <code>TRUE</code>,
retains units (if recoverable) as character vector in data frame comment if
defined in <code>file</code>.  Alternative, <code>FALSE</code>, discards units. (NOTE:
currently, only <code>.bgd</code> and <code>.pst</code> files assign units. So, this
option is ignored when importing <code>.met</code> or <code>.mop</code> files.)</p>
</td></tr>
<tr><td><code id="importADMS_+3A_simplify.names">simplify.names</code></td>
<td>
<p>Option to simplify data names in accordance with common
<code>openair</code> practices. Default, <code>TRUE</code>. Alternative, <code>FALSE</code>,
returns data with names as interpreted by standard R. (NOTE: Some ADMS file
data names include symbols and structures that R does not allow as part of
a name, so some renaming is automatic regardless of <code>simplify.names</code>
setting.  For example, brackets or symbols are removed from names or
replaced with &quot;.&quot;, and names in the form &quot;1/x&quot; may be returned as &quot;X1.x&quot; or
&quot;recip.x&quot;.)</p>
</td></tr>
<tr><td><code id="importADMS_+3A_test.file.structure">test.file.structure</code></td>
<td>
<p>Option to test file structure before trying to
import. Default, <code>TRUE</code>, tests for expected file structure and halts
import operation if this is not found.  Alternative, <code>FALSE</code>, attempts
import regardless of structure.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_drop.delim">drop.delim</code></td>
<td>
<p>Option to remove delim columns from the data frame. ADMS
.mop files include two columns, &quot;INPUT_DATA:&quot; and &quot;PROCESSED_DATA:&quot;, to
separate model input and output types.  Default, <code>TRUE</code>, removes
these. Alternative, <code>FALSE</code>, retains them as part of import.  (Note:
Option ignored when importing <code>.bgd</code>, <code>.met</code> or <code>.pst</code>
files.)</p>
</td></tr>
<tr><td><code id="importADMS_+3A_add.prefixes">add.prefixes</code></td>
<td>
<p>Option to add prefixes to data names. ADMS .mop files
include a number of input and process data types with shared names.
Prefixes can be automatically added to these so individual data can be
readily identified in the R/openair environment. Default, <code>TRUE</code>, adds
&quot;process.&quot; as a prefix to processed data. Other options include:
<code>FALSE</code> which uses no prefixes and leave all name rationalisation to
R, and character vectors which are treated as the required prefixes. If one
vector is sent, this is treated as processed data prefix. If two (or more)
vectors are sent, the first and second are treated as the input and
processed data prefixes, respectively. For example, the argument
(<code>add.prefixes="out"</code>) would add the &quot;out&quot; prefix to processed data
names, while the argument (<code>add.prefixes=c("in","out")</code>) would add
&quot;in&quot; and &quot;out&quot; prefixes to input and output data names, respectively.
(Note: Option ignored when importing <code>.bgd</code>, <code>.met</code> or
<code>.pst</code> files.)</p>
</td></tr>
<tr><td><code id="importADMS_+3A_names">names</code></td>
<td>
<p>Option applied by <code>simplifyNamesADMS</code> when
<code>simplify.names</code> is enabled.  All names are simplified for the default
setting, <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_all">all</code></td>
<td>
<p>For .MOP files, return all variables or not. If <code>all = TRUE</code>
a large number of processed variables are returned.</p>
</td></tr>
<tr><td><code id="importADMS_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="utils.html#topic+read.table">utils::read.csv</a></code>
</p>

<dl>
<dt><code>header</code></dt><dd><p>a logical value indicating whether the file contains the
names of the variables as its first line.  If missing, the value is
determined from the file format: <code>header</code> is set to <code>TRUE</code>
if and only if the first row contains one fewer field than the
number of columns.</p>
</dd>
<dt><code>sep</code></dt><dd><p>the field separator character.  Values on each line of the
file are separated by this character.  If <code>sep = ""</code> (the
default for <code>read.table</code>) the separator is &lsquo;white space&rsquo;,
that is one or more spaces, tabs, newlines or carriage returns.</p>
</dd>
<dt><code>quote</code></dt><dd><p>the set of quoting characters. To disable quoting
altogether, use <code>quote = ""</code>.  See <code><a href="base.html#topic+scan">scan</a></code> for the
behaviour on quotes embedded in quotes.  Quoting is only considered
for columns read as character, which is all of them unless
<code>colClasses</code> is specified.</p>
</dd>
<dt><code>dec</code></dt><dd><p>the character used in the file for decimal points.</p>
</dd>
<dt><code>fill</code></dt><dd><p>logical. If <code>TRUE</code> then in case the rows have unequal
length, blank fields are implicitly added.  See &lsquo;Details&rsquo;.</p>
</dd>
<dt><code>comment.char</code></dt><dd><p>character: a character vector of length one
containing a single character or an empty string.  Use <code>""</code> to
turn off the interpretation of comments altogether.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>importADMS</code> function were developed to help import various ADMS
file types into openair. In most cases the parent import function should work
in default configuration, e.g. <code>mydata &lt;- importADMS()</code>. The function
currently recognises four file formats: <code>.bgd</code>, <code>.met</code>, <code>.mop</code>
and <code>.pst</code>.  Where other file extensions have been set but the file
structure is known, the import call can be forced by, e.g, <code>mydata &lt;-
importADMS(file.type="bgd")</code>. Other options can be adjusted to provide fine
control of the data structuring and renaming.
</p>


<h3>Value</h3>

<p>In standard use <code><a href="#topic+importADMS">importADMS()</a></code> returns a data frame for use in
openair. By comparison to the original file, the resulting data frame is
modified as follows:
</p>
<p>Time and date information will combined in a single column &quot;date&quot;,
formatted as a conventional timeseries (<code>as.POSIX*</code>). If
<code>drop.input.dates</code> is enabled data series combined to generated the
new &quot;date&quot; data series will also be removed.
</p>
<p>If <code>simplify.names</code> is enabled common chemical names may be
simplified, and some other parameters may be reset to openair standards
(e.g. &quot;ws&quot;, &quot;wd&quot; and &quot;temp&quot;) according to operations defined in
<code>simplifyNamesADMS</code>. A summary of simplification operations can be
obtained using, e.g., the call <code>importADMS(simplify.names)</code>.
</p>
<p>If <code>drop.case</code> is enabled all upper case characters in names will be
converted to lower case.
</p>
<p>If <code>keep.units</code> is enabled data units information may also be retained
as part of the data frame comment if available.
</p>
<p>With <code>.mop</code> files, input and processed data series names may also been
modified on the basis of <code>drop.delim</code> and <code>add.prefixes</code> settings
</p>


<h3>Note</h3>

<p>Times are assumed to be in GMT. Zero wind directions reset to 360 as
part of <code>.mop</code> file import.
</p>


<h3>Author(s)</h3>

<p>Karl Ropkins, David Carslaw and Matthew Williams (CERC).
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########
#example 1
##########
#To be confirmed

#all current simplify.names operations
importADMS(simplify.names)

#to see what simplify.names does to adms data series name PHI
new.name &lt;- importADMS(simplify.names, names="PHI")
new.name
</code></pre>

<hr>
<h2 id='importAURN'>Import data from individual UK Air Pollution Networks</h2><span id='topic+importAURN'></span><span id='topic+importAQE'></span><span id='topic+importSAQN'></span><span id='topic+importWAQN'></span><span id='topic+importNI'></span><span id='topic+importLocal'></span>

<h3>Description</h3>

<p>These functions act as wrappers for <code><a href="#topic+importUKAQ">importUKAQ()</a></code> to import air pollution
data from a range of UK networks including the Automatic Urban and Rural
Network (AURN), the individual England (AQE), Scotland (SAQN), Wales (WAQN)
and Northern Ireland (NI) Networks, and many &quot;locally managed&quot; monitoring
networks across England. While <code><a href="#topic+importUKAQ">importUKAQ()</a></code> allows for data to be imported
more flexibly, including across multiple monitoring networks, these functions
are provided for convenience and back-compatibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importAURN(
  site = "my1",
  year = 2009,
  data_type = "hourly",
  pollutant = "all",
  hc = FALSE,
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)

importAQE(
  site = "yk13",
  year = 2018,
  data_type = "hourly",
  pollutant = "all",
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)

importSAQN(
  site = "gla4",
  year = 2009,
  data_type = "hourly",
  pollutant = "all",
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)

importWAQN(
  site = "card",
  year = 2018,
  data_type = "hourly",
  pollutant = "all",
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)

importNI(
  site = "bel0",
  year = 2018,
  data_type = "hourly",
  pollutant = "all",
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)

importLocal(
  site = "ad1",
  year = 2018,
  data_type = "hourly",
  pollutant = "all",
  meta = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importAURN_+3A_site">site</code></td>
<td>
<p>Site code of the site to import, e.g., <code>"my1"</code> is Marylebone
Road. Site codes can be discovered through the use of <code><a href="#topic+importMeta">importMeta()</a></code>.
Several sites can be imported at once. For example, <code>site = c("my1", "nott")</code> imports both Marylebone Road and Nottingham.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_year">year</code></td>
<td>
<p>Year(s) to import. To import a series of years use, e.g.,
<code>2000:2020</code>. To import several specific years use <code>year = c(2000, 2010, 2020)</code>.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_data_type">data_type</code></td>
<td>
<p>The type of data to be returned, defaulting to <code>"hourly"</code>
data. Alternative data types include:
</p>

<ul>
<li> <p><code>"daily"</code>: Daily average data.
</p>
</li>
<li> <p><code>"monthly"</code>: Monthly average data with data capture information for the whole network.
</p>
</li>
<li> <p><code>"annual"</code>: Annual average data with data capture information for the whole network.
</p>
</li>
<li> <p><code>"15_min"</code>: 15-minute average SO2 concentrations.
</p>
</li>
<li> <p><code>"8_hour"</code>: 8-hour rolling mean concentrations for O3 and CO.
</p>
</li>
<li> <p><code>"24_hour"</code>: 24-hour rolling mean concentrations for particulates.
</p>
</li>
<li> <p><code>"daily_max_8"</code>: Maximum daily rolling 8-hour maximum for O3 and CO.
</p>
</li>
<li> <p><code>"daqi"</code>: Daily Air Quality Index (DAQI). See
<a href="https://uk-air.defra.gov.uk/air-pollution/daqi?view=more-info">here</a> for
more details of how the index is defined. Note that this <code>data_type</code> is not
available for locally managed monitoring networks.
</p>
</li></ul>
</td></tr>
<tr><td><code id="importAURN_+3A_pollutant">pollutant</code></td>
<td>
<p>Pollutants to import. If omitted will import all pollutants
from a site. To import only NOx and NO2 for example use <code>pollutant =
  c("nox", "no2")</code>. Pollutant names can be upper or lower case.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_hc">hc</code></td>
<td>
<p>Include hydrocarbon measurements in the imported data? Defaults to
<code>FALSE</code> as most users will not be interested in using hydrocarbon data.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_meta">meta</code></td>
<td>
<p>Append the site type, latitude and longitude of each selected
<code>site</code>? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_meteo">meteo</code></td>
<td>
<p>Append modelled meteorological data, if available? Defaults to
<code>TRUE</code>, which will return wind speed (<code>ws</code>), wind direction (<code>wd</code>) and
ambient temperature (<code>air_temp</code>). The variables are calculated from using
the WRF model run by Ricardo Energy &amp; Environment and are available for
most but not all networks. Setting <code>meteo = FALSE</code> is useful if you have
other meteorological data to use in preference, for example from
the <code>worldmet</code> package.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_ratified">ratified</code></td>
<td>
<p>Append <code>qc</code> column(s) to hourly data indicating whether each
species was ratified (i.e., quality-checked)?  Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_to_narrow">to_narrow</code></td>
<td>
<p>Return the data in a &quot;narrow&quot;/&quot;long&quot;/&quot;tidy&quot; format? By
default the returned data is &quot;wide&quot; and has a column for each
pollutant/variable. When <code>to_narrow = TRUE</code> the data are returned with a
column identifying the pollutant name and a column containing the
corresponding concentration/statistic. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_verbose">verbose</code></td>
<td>
<p>Print messages to the console if hourly data cannot be
imported? Default is <code>FALSE</code>. <code>TRUE</code> is useful for debugging as the
specific <code>year</code>(s), <code>site</code>(s) and <code>source</code>(s) which cannot be imported will
be returned.</p>
</td></tr>
<tr><td><code id="importAURN_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many sites/years are being imported?
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Importing UK Air Pollution Data</h3>

<p>This family of functions has been written to make it easy to import data
from across several UK air quality networks. Ricardo have provided .RData
files (R workspaces) of all individual sites and years, as well as up to
date meta data. These files are updated on a daily basis. This approach
requires a link to the Internet to work.
</p>
<p>There are several advantages over the web portal approach where .csv files
are downloaded.
</p>

<ul>
<li><p> First, it is quick to select a range of sites, pollutants
and periods (see examples below).
</p>
</li>
<li><p> Second, storing the data as .RData
objects is very efficient as they are about four times smaller than .csv
files &mdash; which means the data downloads quickly and saves bandwidth.
</p>
</li>
<li><p> Third, the function completely avoids any need for data manipulation or
setting time formats, time zones etc. The function also has the advantage
that the proper site name is imported and used in
<a href="#topic+openair-package">openair</a> functions.
</p>
</li></ul>

<p>Users should take care if using data from both <a href="#topic+openair-package">openair</a>
<em>and</em> web portals (for example, <a href="https://uk-air.defra.gov.uk/data/">UK AIR</a>). One key difference is that the
data provided by openair is date <em>beginning</em>, whereas the web portal
provides date <em>ending</em>. Hourly concentrations may therefore appear offset
by an hour, for example.
</p>
<p>The data are imported by stacking sites on top of one another and will have
field names <code>site</code>, <code>code</code> (the site code) and <code>pollutant</code>.
</p>
<p>By default, the function returns hourly average data. However, annual,
monthly, daily and 15 minute data (for SO2) can be returned using the
option <code>data_type</code>. Annual and monthly data provide whole network
information including data capture statistics.
</p>
<p>All units are expressed in mass terms for gaseous species (ug/m3 for NO,
NO2, NOx (as NO2), SO2 and hydrocarbons; and mg/m3 for CO). PM10
concentrations are provided in gravimetric units of ug/m3 or scaled to be
comparable with these units. Over the years a variety of instruments have
been used to measure particulate matter and the technical issues of
measuring PM10 are complex. In recent years the measurements rely on FDMS
(Filter Dynamics Measurement System), which is able to measure the volatile
component of PM. In cases where the FDMS system is in use there will be a
separate volatile component recorded as 'v10' and non-volatile component
'nv10', which is already included in the absolute PM10 measurement. Prior
to the use of FDMS the measurements used TEOM (Tapered Element Oscillating.
Microbalance) and these concentrations have been multiplied by 1.3 to
provide an estimate of the total mass including the volatile fraction.
</p>
<p>Some sites report hourly and daily PM10 and / or PM2.5. When <code>data_type = "daily"</code> and there are both hourly and 'proper' daily measurements
available, these will be returned as e.g. &quot;pm2.5&quot; and &quot;gr_pm2.5&quot;; the
former corresponding to data based on original hourly measurements and the
latter corresponding to daily gravimetric measurements.
</p>
<p>The function returns modelled hourly values of wind speed (<code>ws</code>), wind
direction (<code>wd</code>) and ambient temperature (<code>air_temp</code>) if available
(generally from around 2010). These values are modelled using the WRF model
operated by Ricardo.
</p>
<p>The BAM (Beta-Attenuation Monitor) instruments that have been incorporated
into the network throughout its history have been scaled by 1.3 if they
have a heated inlet (to account for loss of volatile particles) and 0.83 if
they do not have a heated inlet. The few TEOM instruments in the network
after 2008 have been scaled using VCM (Volatile Correction Model) values to
account for the loss of volatile particles. The object of all these scaling
processes is to provide a reasonable degree of comparison between data sets
and with the reference method and to produce a consistent data record over
the operational period of the network, however there may be some
discontinuity in the time series associated with instrument changes.
</p>
<p>No corrections have been made to the PM2.5 data. The volatile component of
FDMS PM2.5 (where available) is shown in the 'v2.5' column.
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>

<hr>
<h2 id='importEurope'>Import air quality data from European database</h2><span id='topic+importEurope'></span>

<h3>Description</h3>

<p>This function is a simplified version of the <code>saqgetr</code> package (see
<a href="https://github.com/skgrange/saqgetr">https://github.com/skgrange/saqgetr</a>) for accessing European air quality
data. The function only returns valid hourly data and is meant as a fast and
convenient way of accessing the most common type of hourly air quality data.
The function works in the same way as other <code>openair</code> functions that
import air quality data that generally need a site code and year to be
supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importEurope(
  site = "debw118",
  year = 2018,
  tz = "UTC",
  meta = FALSE,
  to_narrow = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importEurope_+3A_site">site</code></td>
<td>
<p>The code of the site(s).</p>
</td></tr>
<tr><td><code id="importEurope_+3A_year">year</code></td>
<td>
<p>Year or years to import. To import a sequence of years from 1990
to 2000 use <code>year = 1990:2000</code>. To import several specific years use
<code>year = c(1990, 1995, 2000)</code> for example.</p>
</td></tr>
<tr><td><code id="importEurope_+3A_tz">tz</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="importEurope_+3A_meta">meta</code></td>
<td>
<p>Should meta data be returned? If <code>TRUE</code> the site type,
latitude and longitude are returned.</p>
</td></tr>
<tr><td><code id="importEurope_+3A_to_narrow">to_narrow</code></td>
<td>
<p>By default the returned data has a column for each
pollutant/variable. When <code>to_narrow = TRUE</code> the data are stacked into
a narrow format with a column identifying the pollutant name.</p>
</td></tr>
<tr><td><code id="importEurope_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many sites/years are being imported?
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function can however return key site meta data.
</p>
<p>The <code>saqgetr</code> package is much more comprehensive and provides data at
other time averages e.g. daily data.
</p>


<h3>Value</h3>

<p>a <a href="tibble.html#topic+tibble-package">tibble</a>
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# import data for Stuttgart Am Neckartor (S)
## Not run: 
stuttgart &lt;- importEurope("debw118", year = 2010:2019, meta = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='importKCL'>Import data from King's College London networks</h2><span id='topic+importKCL'></span>

<h3>Description</h3>

<p>Function for importing hourly mean data from King's College London networks.
Files are imported from a remote server operated by King's College London
that provides air quality data files as R data objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importKCL(
  site = "my1",
  year = 2009,
  pollutant = "all",
  met = FALSE,
  units = "mass",
  extra = FALSE,
  meta = FALSE,
  to_narrow = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importKCL_+3A_site">site</code></td>
<td>
<p>Site code of the network site to import e.g. &quot;my1&quot; is Marylebone
Road. Several sites can be imported with <code>site = c("my1", "kc1")</code> &mdash;
to import Marylebone Road and North Kensignton for example.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_year">year</code></td>
<td>
<p>Year(s) to import. To import a series of years use, e.g.,
<code>2000:2020</code>. To import several specific years use <code>year = c(2000, 2010, 2020)</code>.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_pollutant">pollutant</code></td>
<td>
<p>Pollutants to import. If omitted will import all pollutants
from a site. To import only NOx and NO2 for example use <code>pollutant =
  c("nox", "no2")</code>. Pollutant names can be upper or lower case.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_met">met</code></td>
<td>
<p>Should meteorological data be added to the import data? The
default is <code>FALSE</code>. If <code>TRUE</code> wind speed (m/s), wind direction
(degrees), solar radiation and rain amount are available. See details
below.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_units">units</code></td>
<td>
<p>By default the returned data frame expresses the units in mass
terms (ug/m3 for NOx, NO2, O3, SO2; mg/m3 for CO). Use <code>units =
  "volume"</code> to use ppb etc. PM10_raw TEOM data are multiplied by 1.3 and
PM2.5 have no correction applied. See details below concerning PM10
concentrations.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_extra">extra</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_meta">meta</code></td>
<td>
<p>Append the site type, latitude and longitude of each selected
<code>site</code>? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_to_narrow">to_narrow</code></td>
<td>
<p>Return the data in a &quot;narrow&quot;/&quot;long&quot;/&quot;tidy&quot; format? By
default the returned data is &quot;wide&quot; and has a column for each
pollutant/variable. When <code>to_narrow = TRUE</code> the data are returned with a
column identifying the pollutant name and a column containing the
corresponding concentration/statistic. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importKCL_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many sites/years are being imported?
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>importKCL</code> function has been written to make it easy to import
data from the King's College London air pollution networks. KCL have
provided .RData files (R workspaces) of all individual sites and years for
the KCL networks. These files are updated on a weekly basis. This approach
requires a link to the Internet to work.
</p>
<p>There are several advantages over the web portal approach where .csv files
are downloaded. First, it is quick to select a range of sites, pollutants
and periods (see examples below). Second, storing the data as .RData objects
is very efficient as they are about four times smaller than .csv files &mdash;
which means the data downloads quickly and saves bandwidth. Third, the
function completely avoids any need for data manipulation or setting time
formats, time zones etc. Finally, it is easy to import many years of data
beyond the current limit of about 64,000 lines. The final point makes it
possible to download several long time series in one go. The function also
has the advantage that the proper site name is imported and used in
<code>openair</code> functions.
</p>
<p>The site codes and pollutant names can be upper or lower case. The function
will issue a warning when data less than six months old is downloaded, which
may not be ratified.
</p>
<p>The data are imported by stacking sites on top of one another and will have
field names <code>date</code>, <code>site</code>, <code>code</code> (the site code) and
pollutant(s). Sometimes it is useful to have columns of site data. This can
be done using the <code>reshape</code> function &mdash; see examples below.
</p>
<p>The situation for particle measurements is not straightforward given the
variety of methods used to measure particle mass and changes in their use
over time. The <code>importKCL</code> function imports two measures of PM10 where
available. <code>PM10_raw</code> are TEOM measurements with a 1.3 factor applied
to take account of volatile losses. The <code>PM10</code> data is a current best
estimate of a gravimetric equivalent measure as described below. NOTE! many
sites have several instruments that measure PM10 or PM2.5. In the case of
FDMS measurements, these are given as separate site codes (see below). For
example &quot;MY1&quot; will be TEOM with VCM applied and &quot;MY7&quot; is the FDMS data.
</p>
<p>Where FDMS data are used the volatile and non-volatile components are
separately reported i.e. v10 = volatile PM10, v2.5 = volatile PM2.5, nv10 =
non-volatile PM10 and nv2.5 = non-volatile PM2.5. Therefore, PM10 = v10 +
nv10 and PM2.5 = v2.5 + nv2.5.
</p>
<p>For the assessment of the EU Limit Values, PM10 needs to be measured using
the reference method or one shown to be equivalent to the reference method.
Defra carried out extensive trials between 2004 and 2006 to establish which
types of particulate analysers in use in the UK were equivalent. These
trials found that measurements made using Partisol, FDMS, BAM and SM200
instruments were shown to be equivalent to the PM10 reference method.
However, correction factors need to be applied to measurements from the
SM200 and BAM instruments. Importantly, the TEOM was demonstrated as not
being equivalent to the reference method due to the loss of volatile PM,
even when the 1.3 correction factor was applied.  The Volatile Correction
Model (VCM) was developed for Defra at King's to allow measurements of PM10
from TEOM instruments to be converted to reference equivalent; it uses the
measurements of volatile PM made using nearby FDMS instruments to correct
the measurements made by the TEOM. It passed the equivalence testing using
the same methodology used in the Defra trials and is now the recommended
method for correcting TEOM measurements (Defra, 2009). VCM correction of
TEOM measurements can only be applied after 1st January 2004, when
sufficiently widespread measurements of volatile PM became available. The
1.3 correction factor is now considered redundant for measurements of PM10
made after 1st January 2004.  Further information on the VCM can be found at
<a href="http://www.volatile-correction-model.info/">http://www.volatile-correction-model.info/</a>.
</p>
<p>All PM10 statistics on the LondonAir web site, including the bulletins and
statistical tools (and in the RData objects downloaded using
<code>importKCL</code>), now report PM10 results as reference equivalent. For PM10
measurements made by BAM and SM200 analysers the applicable correction
factors have been applied. For measurements from TEOM analysers the 1.3
factor has been applied up to 1st January 2004, then the VCM method has been
used to convert to reference equivalent.
</p>
<p>The meteorological data are meant to represent 'typical' conditions in
London, but users may prefer to use their own data. The data provide a an
estimate of general meteorological conditions across Greater London. For
meteorological species (wd, ws, rain, solar) each data point is formed by
averaging measurements from a subset of LAQN monitoring sites that have been
identified as having minimal disruption from local obstacles and a long term
reliable dataset. The exact sites used varies between species, but include
between two and five sites per species. Therefore, the data should represent
'London scale' meteorology, rather than local conditions.
</p>
<p>While the function is being developed, the following site codes should help
with selection. We will also make available other meta data such as site
type and location to make it easier to select sites based on other
information. Note that these codes need to be refined because only the
common species are available for export currently i.e. NOx, NO2, O3, CO,
SO2, PM10, PM2.5.
</p>
 <ul>
<li><p> A30 | Kingston - Kingston Bypass A3 | Roadside </p>
</li>
<li><p> AD1 |
Shoreham-by-Sea | Kerbside </p>
</li>
<li><p> AR1 | Chichester - Lodsworth | Rural </p>
</li>
<li>
<p>AR2 | Wealden - Isfield | Rural </p>
</li>
<li><p> AS1 | Bath Aethalometer | Urban
Background </p>
</li>
<li><p> BA1 | Basildon - Gloucester Park | Roadside </p>
</li>
<li><p> BB1 |
Broxbourne (Roadside) | Roadside </p>
</li>
<li><p> BE0 | Belfast - Carbon | Urban
Background </p>
</li>
<li><p> BE1 | Belfast Centre AURN | Urban Background </p>
</li>
<li><p> BE3 |
Belfast Centre Aethalometer | Urban Background </p>
</li>
<li><p> BE7 | Belfast Centre
FDMS trial | Urban Background </p>
</li>
<li><p> BE8 | Belfast - Nitrate | Urban
Background </p>
</li>
<li><p> BE9 | Belfast - Partisol SO4 | Urban Background </p>
</li>
<li><p> BF1 |
Bedford Stewartby (Rural) | Industrial </p>
</li>
<li><p> BF3 | Bedford - Kempston |
Industrial </p>
</li>
<li><p> BF4 | Bedford - Prebend Street | Roadside </p>
</li>
<li><p> BF5 |
Bedford - Lurke Street | Roadside </p>
</li>
<li><p> BG1 | Barking and Dagenham - Rush
Green | Suburban </p>
</li>
<li><p> BG2 | Barking and Dagenham - Scrattons Farm |
Suburban </p>
</li>
<li><p> BG3 | Barking and Dagenham - North Street | Kerbside </p>
</li>
<li>
<p>BH0 | Brighton Preston Park AURN | Urban Background </p>
</li>
<li><p> BH1 | Brighton
Roadside | Roadside </p>
</li>
<li><p> BH2 | Brighton and Hove - Hove Town Hall |
Roadside </p>
</li>
<li><p> BH3 | Brighton and Hove - Foredown Tower | Urban Background
</p>
</li>
<li><p> BH5 | Brighton Mobile (Preston Fire Station) | Roadside </p>
</li>
<li><p> BH6 |
Brighton Mobile (Lewes Road) | Roadside </p>
</li>
<li><p> BH7 | Brighton Mobile
(Gloucester Road) | Roadside </p>
</li>
<li><p> BH8 | Brighton and Hove - Stanmer Park |
Rural </p>
</li>
<li><p> BH9 | Brighton Mobile Beaconsfield Road | Roadside </p>
</li>
<li><p> BI1 |
Birmingham Tyburn CPC | Urban Background </p>
</li>
<li><p> BL0 | Camden - Bloomsbury |
Urban Background </p>
</li>
<li><p> BL1 | Bloomsbury AURN SMPS | Urban Background </p>
</li>
<li>
<p>BM1 | Ballymena - Ballykeel | Suburban </p>
</li>
<li><p> BM2 | Ballymena - North Road |
Roadside </p>
</li>
<li><p> BN1 | Barnet - Tally Ho Corner | Kerbside </p>
</li>
<li><p> BN2 | Barnet
</p>

<ul>
<li><p> Finchley | Urban Background </p>
</li>
<li><p> BN3 | Barnet - Strawberry Vale | Urban
Background </p>
</li>
<li><p> BO1 | Ballymoney 1 | Suburban </p>
</li>
<li><p> BP0 | Westminster -
Bridge Place | Urban Background </p>
</li>
<li><p> BQ5 | Bexley - Manor Road West
Gravimetric | Industrial </p>
</li>
<li><p> BQ6 | Bexley - Manor Road East Gravimetric |
Industrial </p>
</li>
<li><p> BQ7 | Belvedere West | Urban Background </p>
</li>
<li><p> BQ8 |
Belvedere West FDMS | Urban Background </p>
</li>
<li><p> BT1 | Brent - Kingsbury |
Suburban </p>
</li>
<li><p> BT2 | Brent - Ikea Car Park | Roadside </p>
</li>
<li><p> BT3 | Brent -
Harlesden | Roadside </p>
</li>
<li><p> BT4 | Brent - Ikea | Roadside </p>
</li>
<li><p> BT5 | Brent -
Neasden Lane | Industrial </p>
</li>
<li><p> BT6 | Brent - John Keble Primary School |
Roadside </p>
</li>
<li><p> BT7 | Brent - St Marys Primary School | Urban Background
</p>
</li>
<li><p> BW1 | Brentwood - Brentwood Town Hall | Urban Background </p>
</li>
<li><p> BX0 |
Bexley - Belvedere FDMS | Suburban </p>
</li>
<li><p> BX1 | Bexley - Slade Green |
Suburban </p>
</li>
<li><p> BX2 | Bexley - Belvedere | Suburban </p>
</li>
<li><p> BX3 | Bexley -
Thamesmead | Suburban </p>
</li>
<li><p> BX4 | Bexley - Erith | Industrial </p>
</li>
<li><p> BX5 |
Bexley - Bedonwell | Suburban </p>
</li>
<li><p> BX6 | Bexley - Thames Road North FDMS |
Roadside </p>
</li>
<li><p> BX7 | Bexley - Thames Road North | Roadside </p>
</li>
<li><p> BX8 |
Bexley - Thames Road South | Roadside </p>
</li>
<li><p> BX9 | Bexley - Slade Green FDMS
| Suburban </p>
</li>
<li><p> BY1 | Bromley - Rent Office | Urban Background </p>
</li>
<li><p> BY4 |
Bromley - Tweedy Rd | Roadside </p>
</li>
<li><p> BY5 | Bromley - Biggin Hill | Suburban
</p>
</li>
<li><p> BY7 | Bromley - Harwood Avenue | Roadside </p>
</li>
<li><p> CA1 | Crawley
Background | Urban Background </p>
</li>
<li><p> CA2 | Crawley - Gatwick Airport | Urban
Background </p>
</li>
<li><p> CB1 | Chelmsford - Fire Station | Roadside </p>
</li>
<li><p> CB2 |
Chelmsford - Springfield Road | Roadside </p>
</li>
<li><p> CB3 | Chelmsford - Chignal St
James | Urban Background </p>
</li>
<li><p> CB4 | Chelmsford - Baddow Road | Roadside
</p>
</li>
<li><p> CC1 | Colchester - Lucy Lane South | Roadside </p>
</li>
<li><p> CC2 | Colchester -
Brook Street | Roadside </p>
</li>
<li><p> CC3 | Colchester - Mersea Road | Roadside
</p>
</li>
<li><p> CD1 | Camden - Swiss Cottage | Kerbside </p>
</li>
<li><p> CD3 | Camden -
Shaftesbury Avenue | Roadside </p>
</li>
<li><p> CD4 | Camden - St Martins College (NOX
</p>
</li></ul>


<ol>
<li><p> | Urban Background </p>
</li>
<li><p> CD5 | Camden - St Martins College (NOX 2) |
Urban Background </p>
</li>
<li><p> CD7 | Camden - Swiss Cottage Partisol | Kerbside
</p>
</li>
<li><p> CD9 | Camden - Euston Road | Roadside </p>
</li>
<li><p> CF1 | Cardiff Aethalometer
| Urban Background </p>
</li>
<li><p> CH1 | Cheltenham | Urban Background </p>
</li>
<li><p> CI1 |
Chichester - A27 Chichester Bypass | Roadside </p>
</li>
<li><p> CI4 | Chichester -
Orchard Street | Roadside </p>
</li>
<li><p> CK1 | Cookstown | Suburban </p>
</li>
<li><p> CP1 |
Castle Point - Canvey Island | Urban Background </p>
</li>
<li><p> CR2 | Croydon - Purley
Way | Roadside </p>
</li>
<li><p> CR3 | Croydon - Thornton Heath | Suburban </p>
</li>
<li><p> CR4 |
Croydon - George Street | Roadside </p>
</li>
<li><p> CR5 | Croydon - Norbury | Kerbside
</p>
</li>
<li><p> CR6 | Croydon - Euston Road | Suburban </p>
</li>
<li><p> CT1 | City of London -
Senator House | Urban Background </p>
</li>
<li><p> CT2 | City of London - Farringdon
Street | Kerbside </p>
</li>
<li><p> CT3 | City of London - Sir John Cass School | Urban
Background </p>
</li>
<li><p> CT4 | City of London - Beech Street | Roadside </p>
</li>
<li><p> CT6 |
City of London - Walbrook Wharf | Roadside </p>
</li>
<li><p> CT8 | City of London -
Upper Thames Street | Roadside </p>
</li>
<li><p> CY1 | Crystal Palace - Crystal Palace
Parade | Roadside </p>
</li>
<li><p> DC1 | Dacorum 1 Hemel Hempstead (Background) | Urban
Background </p>
</li>
<li><p> DC2 | Dacorum 2 Hemel Hempstead (Background) | Urban
Background </p>
</li>
<li><p> DC3 | High Street Northchurch | Roadside </p>
</li>
<li><p> DE1 | Derry
City - Brandywell | Urban Background </p>
</li>
<li><p> DE2 | Derry City - Dales Corner |
Roadside </p>
</li>
<li><p> DM1 | Dunmurry Aethalometer | Urban Background </p>
</li>
<li><p> EA0 |
Ealing - Acton Town Hall FDMS | Roadside </p>
</li>
<li><p> EA1 | Ealing - Ealing Town
Hall | Urban Background </p>
</li>
<li><p> EA2 | Ealing - Acton Town Hall | Roadside
</p>
</li>
<li><p> EA3 | Ealing 3 - A40 East Acton | Roadside </p>
</li>
<li><p> EA4 | Ealing Mobile -
Hamilton Road | Roadside </p>
</li>
<li><p> EA5 | Ealing Mobile - Southall | Roadside
</p>
</li>
<li><p> EA6 | Ealing - Hanger Lane Gyratory | Roadside </p>
</li>
<li><p> EA7 | Ealing -
Southall | Urban Background </p>
</li>
<li><p> EA8 | Ealing - Horn Lane | Industrial
</p>
</li>
<li><p> EA9 | Ealing - Court Way | Roadside </p>
</li>
<li><p> EB1 | Eastbourne -
Devonshire Park | Urban Background </p>
</li>
<li><p> EB3 | Eastbourne - Holly Place |
Urban Background </p>
</li>
<li><p> EH1 | E Herts Throcking (Rural) | Rural </p>
</li>
<li><p> EH2 |
East Herts Sawbridgeworth (Background) | Urban Background </p>
</li>
<li><p> EH3 | East
Herts Sawbridgeworth (Roadside) | Roadside </p>
</li>
<li><p> EH4 | East Herts Ware |
Roadside </p>
</li>
<li><p> EH5 | East Herts Bishops Stortford | Roadside </p>
</li>
<li><p> EI0 |
Ealing - Greenford | Urban Background </p>
</li>
<li><p> EI1 | Ealing - Western Avenue |
Roadside </p>
</li>
<li><p> EL1 | Elmbridge - Bell Farm Hersham | Urban Background </p>
</li>
<li>
<p>EL2 | Elmbridge - Esher High Street | Roadside </p>
</li>
<li><p> EL3 | Elmbridge -
Hampton Court Parade | Roadside </p>
</li>
<li><p> EL4 | Elmbridge - Walton High Street |
Kerbside </p>
</li>
<li><p> EN1 | Enfield - Bushhill Park | Suburban </p>
</li>
<li><p> EN2 | Enfield
</p>
</li></ol>


<ul>
<li><p> Church Street | Roadside </p>
</li>
<li><p> EN3 | Enfield - Salisbury School | Urban
Background </p>
</li>
<li><p> EN4 | Enfield - Derby Road | Roadside </p>
</li>
<li><p> EN5 | Enfield -
Bowes Primary School | Roadside </p>
</li>
<li><p> FB1 | Rushmoor - Medway Drive |
Roadside </p>
</li>
<li><p> GB0 | Greenwich and Bexley - Falconwood FDMS | Roadside </p>
</li>
<li>
<p>GB6 | Greenwich and Bexley - Falconwood | Roadside </p>
</li>
<li><p> GL1 | Glasgow
Centre | Suburban </p>
</li>
<li><p> GL4 | Glasgow Centre Aethalometer | Suburban </p>
</li>
<li>
<p>GN0 | Greenwich - A206 Burrage Grove | Roadside </p>
</li>
<li><p> GN2 | Greenwich -
Millennium Village | Industrial </p>
</li>
<li><p> GN3 | Greenwich - Plumstead High
Street | Roadside </p>
</li>
<li><p> GN4 | Greenwich - Fiveways Sidcup Rd A20 | Roadside
</p>
</li>
<li><p> GR4 | Greenwich - Eltham | Suburban </p>
</li>
<li><p> GR5 | Greenwich - Trafalgar
Road | Roadside </p>
</li>
<li><p> GR7 | Greenwich - Blackheath | Roadside </p>
</li>
<li><p> GR8 |
Greenwich - Woolwich Flyover | Roadside </p>
</li>
<li><p> GR9 | Greenwich - Westhorne
Avenue | Roadside </p>
</li>
<li><p> HA0 | Harwell - Carbon | Rural </p>
</li>
<li><p> HA1 | Harwell
Rural AURN | Rural </p>
</li>
<li><p> HA2 | Harwell Rural PARTISOL | Rural </p>
</li>
<li><p> HA4 |
Harwell Rural SMPS | Rural </p>
</li>
<li><p> HA9 | Harwell - Partisol SO4 | Urban
Background </p>
</li>
<li><p> HF1 | Hammersmith and Fulham - Broadway | Roadside </p>
</li>
<li>
<p>HF2 | Hammersmith and Fulham - Brook Green | Urban Background </p>
</li>
<li><p> HF3 |
Hammersmith and Fulham - Scrubs Lane | Kerbside </p>
</li>
<li><p> HG1 | Haringey -
Haringey Town Hall | Roadside </p>
</li>
<li><p> HG2 | Haringey - Priory Park | Urban
Background </p>
</li>
<li><p> HG3 | Haringey - Bounds Green | Roadside </p>
</li>
<li><p> HI0 |
Hillingdon - Sipson Road | Suburban </p>
</li>
<li><p> HI1 | Hillingdon - South Ruislip |
Roadside </p>
</li>
<li><p> HI2 | Hillingdon - Hillingdon Hospital | Roadside </p>
</li>
<li><p> HI3 |
Hillingdon - Oxford Avenue | Roadside </p>
</li>
<li><p> HK4 | Hackney - Clapton | Urban
Background </p>
</li>
<li><p> HK6 | Hackney - Old Street | Roadside </p>
</li>
<li><p> HL1 | Halifax
Aethalometer | Urban Background </p>
</li>
<li><p> HM1 | Hertsmere Borehamwood 1
(Background) | Urban Background </p>
</li>
<li><p> HM4 | Hertsmere - Borehamwood | Urban
Background </p>
</li>
<li><p> HO1 | Horsham Background | Urban Background </p>
</li>
<li><p> HO2 |
Horsham - Park Way | Roadside </p>
</li>
<li><p> HO4 | Horsham - Storrington | Roadside
</p>
</li>
<li><p> HO5 | Horsham - Cowfold | Roadside </p>
</li>
<li><p> HR1 | Harrow - Stanmore |
Urban Background </p>
</li>
<li><p> HR2 | Harrow - Pinner Road | Roadside </p>
</li>
<li><p> HS1 |
Hounslow - Brentford | Roadside </p>
</li>
<li><p> HS2 | Hounslow - Cranford | Suburban
</p>
</li>
<li><p> HS3 | Hounslow - Brentford | Roadside </p>
</li>
<li><p> HS4 | Hounslow - Chiswick
High Road | Roadside </p>
</li>
<li><p> HS5 | Hounslow - Brentford | Roadside </p>
</li>
<li><p> HS6 |
Hounslow - Heston Road | Roadside </p>
</li>
<li><p> HS7 | Hounslow - Hatton Cross |
Urban Background </p>
</li>
<li><p> HS9 | Hounslow - Feltham | Roadside </p>
</li>
<li><p> HT1 |
Hastings - Bulverhythe | Roadside </p>
</li>
<li><p> HT2 | Hastings - Fresh Fields |
Roadside </p>
</li>
<li><p> HV1 | Havering - Rainham | Roadside </p>
</li>
<li><p> HV2 | Havering -
Harold Hill | Suburban </p>
</li>
<li><p> HV3 | Havering - Romford | Roadside </p>
</li>
<li><p> HX0 |
Birmingham Tyburn Aethalometer | Urban Background </p>
</li>
<li><p> IC6 | City of London
</p>
</li>
<li><p> Walbrook Wharf Indoor | Roadside </p>
</li>
<li><p> IG4 | Greenwich - Eltham Ecology
Centre Indoor | Urban Background </p>
</li>
<li><p> IS1 | Islington - Upper Street |
Urban Background </p>
</li>
<li><p> IS2 | Islington - Holloway Road | Roadside </p>
</li>
<li><p> IS4
| Islington - Foxham Gardens | Urban Background </p>
</li>
<li><p> IS5 | Islington -
Duncan Terrace | Roadside </p>
</li>
<li><p> IS6 | Islington - Arsenal | Urban Background
</p>
</li>
<li><p> IT2 | Tower Hamlets - Mile End Road | Roadside </p>
</li>
<li><p> KB1 | South
Kirkby Aethalometer | Urban Background </p>
</li>
<li><p> KC0 | North Kensington - Carbon
| Urban Background </p>
</li>
<li><p> KC1 | Kensington and Chelsea - North Ken | Urban
Background </p>
</li>
<li><p> KC2 | Kensington and Chelsea - Cromwell Road | Roadside
</p>
</li>
<li><p> KC3 | Kensington and Chelsea - Knightsbridge | Roadside </p>
</li>
<li><p> KC4 |
Kensington and Chelsea - Kings Road | Roadside </p>
</li>
<li><p> KC5 | Kensington and
Chelsea - Earls Court Rd | Kerbside </p>
</li>
<li><p> KC7 | Kensington and Chelsea -
North Ken FDMS | Urban Background </p>
</li>
<li><p> KC9 | North Kensington - Partisol
SO4 | Urban Background </p>
</li>
<li><p> KT1 | Kingston - Chessington | Suburban </p>
</li>
<li>
<p>KT2 | Kingston - Town Centre | Roadside </p>
</li>
<li><p> LA1 | Luton Airport | Urban
Background </p>
</li>
<li><p> LB1 | Lambeth - Christchurch Road | Roadside </p>
</li>
<li><p> LB2 |
Lambeth - Vauxhall Cross | Roadside </p>
</li>
<li><p> LB3 | Lambeth - Loughborough Junct
| Urban Background </p>
</li>
<li><p> LB4 | Lambeth - Brixton Road | Kerbside </p>
</li>
<li><p> LB5 |
Lambeth - Bondway Interchange | Roadside </p>
</li>
<li><p> LB6 | Lambeth - Streatham
Green | Urban Background </p>
</li>
<li><p> LH0 | Hillingdon - Harlington | Urban
Background </p>
</li>
<li><p> LH2 | Heathrow Airport | Urban Background </p>
</li>
<li><p> LL1 |
Lullington Heath Rural AURN | Rural </p>
</li>
<li><p> LN1 | Luton - Challney Community
College | Urban Background </p>
</li>
<li><p> LS1 | Lewes - Telscombe Cliffs | Roadside
</p>
</li>
<li><p> LS2 | Lewes - Commercial Square | Roadside </p>
</li>
<li><p> LS4 | Newhaven -
Denton School | Urban Background </p>
</li>
<li><p> LW1 | Lewisham - Catford | Urban
Background </p>
</li>
<li><p> LW2 | Lewisham - New Cross | Roadside </p>
</li>
<li><p> LW3 | Lewisham
</p>
</li>
<li><p> Mercury Way | Industrial </p>
</li>
<li><p> MA1 | Manchester Piccadilly CPC | Urban
Background </p>
</li>
<li><p> MA2 | Manchester Piccadilly | Urban Background </p>
</li>
<li><p> MD1 |
Mid Beds Biggleswade (Roadside) | Roadside </p>
</li>
<li><p> MD2 | Mid Beds Silsoe
(Rural) | Rural </p>
</li>
<li><p> MD3 | Central Beds - Sandy | Roadside </p>
</li>
<li><p> MD4 |
Central Beds - Marston Vale | Rural </p>
</li>
<li><p> ME1 | Merton - Morden Civic Centre
| Roadside </p>
</li>
<li><p> MP1 | Marchwood Power - Marchwood | Industrial </p>
</li>
<li><p> MP2 |
Marchwood Power - Millbrook Rd Soton | Industrial </p>
</li>
<li><p> MR3 | Marylebone
Road Aethalometer | Kerbside </p>
</li>
<li><p> MV1 | Mole Valley - Leatherhead | Rural
</p>
</li>
<li><p> MV2 | Mole Valley - Lower Ashtead | Suburban </p>
</li>
<li><p> MV3 | Mole Valley -
Dorking | Urban Background </p>
</li>
<li><p> MW1 | Windsor and Maidenhead - Frascati Way
| Roadside </p>
</li>
<li><p> MW2 | Windsor and Maidenhead - Clarence Road | Roadside
</p>
</li>
<li><p> MW3 | Windsor and Maidenhead - Ascot | Rural </p>
</li>
<li><p> MY0 | Marylebone
Road - Carbon | Kerbside </p>
</li>
<li><p> MY1 | Westminster - Marylebone Road |
Kerbside </p>
</li>
<li><p> MY7 | Westminster - Marylebone Road FDMS | Kerbside </p>
</li>
<li><p> NA5
| Newtownabbey- Mallusk | Urban Background </p>
</li>
<li><p> NA6 | Newtownabbey- Shore
Road | Roadside </p>
</li>
<li><p> NE2 | Port Talbot TEOM and CPC | Urban Background
</p>
</li>
<li><p> NF1 | New Forest - Holbury | Industrial </p>
</li>
<li><p> NF2 | New Forest -
Fawley | Industrial </p>
</li>
<li><p> NF3 | New Forest - Ringwood | Urban Background
</p>
</li>
<li><p> NF4 | New Forest - Totton | Roadside </p>
</li>
<li><p> NF5 | New Forest -
Lyndhurst | Roadside </p>
</li>
<li><p> NH1 | North Herts Mobile - Baldock 1 | Roadside
</p>
</li>
<li><p> NH2 | North Herts Mobile - Baldock 2 | Roadside </p>
</li>
<li><p> NH3 | North
Herts Mobile - Royston | Urban Background </p>
</li>
<li><p> NH4 | North Herts -
Breechwood Green | Urban Background </p>
</li>
<li><p> NH5 | North Herts - Baldock
Roadside | Roadside </p>
</li>
<li><p> NH6 | North Herts - Hitchin Library | Roadside
</p>
</li>
<li><p> NK1 | North Kensington - CPC | Urban Background </p>
</li>
<li><p> NK3 | North
Kensington Aethalometer | Urban Background </p>
</li>
<li><p> NK6 | North Kensington -
URG | Urban Background </p>
</li>
<li><p> NM1 | Newham - Tant Avenue | Urban Background
</p>
</li>
<li><p> NM2 | Newham - Cam Road | Roadside </p>
</li>
<li><p> NM3 | Newham - Wren Close |
Urban Background </p>
</li>
<li><p> NW1 | Norwich Centre Aethalometer | Urban Background
</p>
</li>
<li><p> OX0 | Oxford Centre Roadside AURN | Urban Background </p>
</li>
<li><p> OX1 | South
Oxfordshire - Henley | Roadside </p>
</li>
<li><p> OX2 | South Oxfordshire - Wallingford
| Roadside </p>
</li>
<li><p> OX3 | South Oxfordshire - Watlington | Roadside </p>
</li>
<li><p> OX4 |
Oxford St Ebbes AURN | Urban Background </p>
</li>
<li><p> PO1 | Portsmouth Background
AURN | Urban Background </p>
</li>
<li><p> PT6 | Port Talbot Dyffryn School | Industrial
</p>
</li>
<li><p> RB1 | Redbridge - Perth Terrace | Urban Background </p>
</li>
<li><p> RB2 |
Redbridge - Ilford Broadway | Kerbside </p>
</li>
<li><p> RB3 | Redbridge - Fullwell
Cross | Kerbside </p>
</li>
<li><p> RB4 | Redbridge - Gardner Close | Roadside </p>
</li>
<li><p> RB5
| Redbridge - South Woodford | Roadside </p>
</li>
<li><p> RD0 | Reading AURN - New Town
| Urban Background </p>
</li>
<li><p> RD1 | Reading - Caversham Road | Roadside </p>
</li>
<li><p> RD2
| Reading - Kings Road | Roadside </p>
</li>
<li><p> RD3 | Reading - Oxford Road |
Roadside </p>
</li>
<li><p> RG1 | Reigate and Banstead - Horley | Suburban </p>
</li>
<li><p> RG2 |
Reigate and Banstead - Horley South | Suburban </p>
</li>
<li><p> RG3 | Reigate and
Banstead - Poles Lane | Rural </p>
</li>
<li><p> RG4 | Reigate and Banstead - Reigate
High St | Kerbside </p>
</li>
<li><p> RHA | Richmond - Lower Mortlake Road | Roadside
</p>
</li>
<li><p> RHB | Richmond - Lower Mortlake Road | Roadside </p>
</li>
<li><p> RI1 | Richmond -
Castelnau | Roadside </p>
</li>
<li><p> RI2 | Richmond - Barnes Wetlands | Suburban </p>
</li>
<li>
<p>RI5 | Richmond Mobile - St Margarets | Kerbside </p>
</li>
<li><p> RI6 | Richmond Mobile
</p>
</li>
<li><p> St Margarets | Kerbside </p>
</li>
<li><p> RI7 | Richmond Mobile - Richmond Park |
Suburban </p>
</li>
<li><p> RI8 | Richmond Mobile - Richmond Park | Suburban </p>
</li>
<li><p> RIA |
Richmond Mobile - George Street | Kerbside </p>
</li>
<li><p> RIB | Richmond Mobile -
George Street | Kerbside </p>
</li>
<li><p> RIC | Richmond Mobile - Kew Rd | Kerbside
</p>
</li>
<li><p> RID | Richmond Mobile - Kew Rd | Kerbside </p>
</li>
<li><p> RIE | Richmond Mobile
</p>
</li>
<li><p> Richmond Rd Twickenham | Roadside </p>
</li>
<li><p> RIF | Richmond Mobile - Richmond
Rd Twickenham | Roadside </p>
</li>
<li><p> RIG | Richmond Mobile - Upper Teddington Rd |
Roadside </p>
</li>
<li><p> RIH | Richmond Mobile - Upper Teddington Rd | Roadside </p>
</li>
<li>
<p>RII | Richmond Mobile - Somerset Rd Teddington | Urban Background </p>
</li>
<li><p> RIJ
| Richmond Mobile - Somerset Rd Teddington | Urban Background </p>
</li>
<li><p> RIK |
Richmond Mobile - St. Margarets Grove | Urban Background </p>
</li>
<li><p> RIL |
Richmond Mobile - St. Margarets Grove | Urban Background </p>
</li>
<li><p> RIM |
Richmond Mobile - Petersham Rd Ham | Roadside </p>
</li>
<li><p> RIN | Richmond Mobile -
Petersham Rd Ham | Roadside </p>
</li>
<li><p> RIO | Richmond Mobile - Stanley Rd
Twickenham | Roadside </p>
</li>
<li><p> RIP | Richmond Mobile - Stanley Rd Twickenham |
Roadside </p>
</li>
<li><p> RIQ | Richmond Mobile - Richmond Rd Twickenham | Roadside
</p>
</li>
<li><p> RIR | Richmond Mobile - Richmond Rd Twickenham | Roadside </p>
</li>
<li><p> RIS |
Richmond Mobile - Lincoln Ave Twickenham | Roadside </p>
</li>
<li><p> RIU | Richmond
Mobile - Mortlake Rd Kew | Roadside </p>
</li>
<li><p> RIW | Richmond - Upper Teddington
Road | Roadside </p>
</li>
<li><p> RIY | Richmond - Hampton Court Road | Kerbside </p>
</li>
<li>
<p>RO1 | Rochford - Rayleigh High Street | Roadside </p>
</li>
<li><p> RY1 | Rother - Rye
Harbour | Rural </p>
</li>
<li><p> RY2 | Rother - De La Warr Road | Roadside </p>
</li>
<li><p> SA1 |
St Albans - Fleetville | Urban Background </p>
</li>
<li><p> SB1 | South Beds - Dunstable
| Urban Background </p>
</li>
<li><p> SC1 | Sevenoaks 1 | Suburban </p>
</li>
<li><p> SD1 |
Southend-on-Sea AURN | Urban Background </p>
</li>
<li><p> SE1 | Stevenage - Lytton Way |
Roadside </p>
</li>
<li><p> SH1 | Southampton Background AURN | Urban Background </p>
</li>
<li>
<p>SH2 | Southampton - Redbridge | Roadside </p>
</li>
<li><p> SH3 | Southampton - Onslow
Road | Roadside </p>
</li>
<li><p> SH4 | Southampton - Bitterne | Urban Background </p>
</li>
<li>
<p>SK1 | Southwark - Larcom Street | Urban Background </p>
</li>
<li><p> SK2 | Southwark -
Old Kent Road | Roadside </p>
</li>
<li><p> SK5 | Southwark - A2 Old Kent Road | Roadside
</p>
</li>
<li><p> SL1 | Sunderland Aethalometer | Urban Background  </p>
</li>
<li><p> ST1 | Sutton -
Robin Hood School | Roadside </p>
</li>
<li><p> ST2 | Sutton - North Cheam | Urban
Background </p>
</li>
<li><p> ST3 | Sutton - Carshalton | Suburban </p>
</li>
<li><p> ST4 | Sutton -
Wallington | Kerbside </p>
</li>
<li><p> ST5 | Sutton - Beddington Lane | Industrial
</p>
</li>
<li><p> ST6 | Sutton - Worcester Park | Kerbside </p>
</li>
<li><p> ST7 | Sutton - Therapia
Lane | Industrial </p>
</li>
<li><p> SU1 | Sussex Mobile10 Stockbridge | Kerbside </p>
</li>
<li>
<p>SU2 | Sussex Mobile11 Jct Whitley Rd | Kerbside </p>
</li>
<li><p> SU3 | Sussex Mobile12
Cowfold | Kerbside </p>
</li>
<li><p> SU4 | Sussex Mobile 13 Newhaven | Roadside </p>
</li>
<li>
<p>SU5 | Sussex Mobile 14 Crawley | Roadside </p>
</li>
<li><p> SU6 | Sussex Mobile15
Chichester County Hall | Urban Background </p>
</li>
<li><p> SU7 | Sussex Mobile 16
Warnham | Rural </p>
</li>
<li><p> SU8 | Sussex Mobile 17 Newhaven Paradise Park |
Roadside </p>
</li>
<li><p> SX1 | Sussex Mobile 1 | Urban Background </p>
</li>
<li><p> SX2 | Sussex
Mobile 2 North Berstead | Roadside </p>
</li>
<li><p> SX3 | Sussex Mobile 3 | Roadside
</p>
</li>
<li><p> SX4 | Sussex Mobile 4 Adur | Roadside </p>
</li>
<li><p> SX5 | Sussex Mobile 5
Fresh Fields Rd Hastings | Roadside </p>
</li>
<li><p> SX6 | Sussex Mobile 6 Orchard St
Chichester | Roadside </p>
</li>
<li><p> SX7 | Sussex Mobile 7 New Road Newhaven |
Roadside </p>
</li>
<li><p> SX8 | Sussex Mobile 8 Arundel | Kerbside </p>
</li>
<li><p> SX9 | Sussex
Mobile 9 Newhaven Kerbside | Kerbside </p>
</li>
<li><p> TD0 | Richmond - National
Physical Laboratory | Suburban </p>
</li>
<li><p> TE0 | Tendring St Osyth AURN | Rural
</p>
</li>
<li><p> TE1 | Tendring - Town Hall | Roadside </p>
</li>
<li><p> TH1 | Tower Hamlets -
Poplar | Urban Background </p>
</li>
<li><p> TH2 | Tower Hamlets - Mile End Road |
Roadside </p>
</li>
<li><p> TH3 | Tower Hamlets - Bethnal Green | Urban Background </p>
</li>
<li>
<p>TH4 | Tower Hamlets - Blackwall | Roadside </p>
</li>
<li><p> TK1 | Thurrock - London
Road (Grays) | Urban Background </p>
</li>
<li><p> TK2 | Thurrock - Purfleet | Roadside
</p>
</li>
<li><p> TK3 | Thurrock - Stanford-le-Hope | Roadside </p>
</li>
<li><p> TK8 | Thurrock -
London Road (Purfleet) | Roadside </p>
</li>
<li><p> TR1 | Three Rivers - Rickmansworth |
Urban Background </p>
</li>
<li><p> UT1 | Uttlesford - Saffron Walden Fire Station |
Roadside </p>
</li>
<li><p> UT2 | Uttlesford - Takeley | Urban Background </p>
</li>
<li><p> UT3 |
Uttlesford - Broxted Farm | Rural </p>
</li>
<li><p> VS1 | Westminster - Victoria Street
| Kerbside </p>
</li>
<li><p> WA1 | Wandsworth - Garratt Lane | Roadside </p>
</li>
<li><p> WA2 |
Wandsworth - Town Hall | Urban Background </p>
</li>
<li><p> WA3 | Wandsworth -
Roehampton | Rural </p>
</li>
<li><p> WA4 | Wandsworth - High Street | Roadside </p>
</li>
<li><p> WA6
| Wandsworth - Tooting | Roadside </p>
</li>
<li><p> WA7 | Wandsworth - Putney High
Street | Kerbside </p>
</li>
<li><p> WA8 | Wandsworth - Putney High Street Facade |
Roadside </p>
</li>
<li><p> WA9 | Wandsworth - Putney | Urban Background </p>
</li>
<li><p> WE0 |
Kensington and Chelsea - Pembroke Road | Urban Background </p>
</li>
<li><p> WF1 |
Watford (Roadside) | Roadside </p>
</li>
<li><p> WF2 | Watford - Watford Town Hall |
Roadside </p>
</li>
<li><p> WH1 | Welwyn Hatfield - Council Offices | Urban Background
</p>
</li>
<li><p> WL1 | Waltham Forest - Dawlish Road | Urban Background </p>
</li>
<li><p> WL2 |
Waltham Forest - Mobile | Roadside </p>
</li>
<li><p> WL3 | Waltham Forest - Chingford |
Roadside </p>
</li>
<li><p> WL4 | Waltham Forest - Crooked Billet | Kerbside </p>
</li>
<li><p> WL5 |
Waltham Forest - Leyton | Roadside </p>
</li>
<li><p> WM0 | Westminster - Horseferry Road
| Urban Background </p>
</li>
<li><p> WM3 | Westminster - Hyde Park Partisol | Roadside
</p>
</li>
<li><p> WM4 | Westminster - Charing Cross Library | Roadside </p>
</li>
<li><p> WM5 |
Westminster - Covent Garden | Urban Background </p>
</li>
<li><p> WM6 | Westminster -
Oxford St | Kerbside </p>
</li>
<li><p> WR1 | Bradford Town Hall Aethalometer | Urban
Background </p>
</li>
<li><p> WT1 | Worthing - Grove Lodge | Kerbside </p>
</li>
<li><p> XB1 |
Bletchley | Rural </p>
</li>
<li><p> XS1 | Shukri Outdoor | Industrial </p>
</li>
<li><p> XS2 | Shukri
Indoor | Industrial </p>
</li>
<li><p> XS3 | Osiris mobile | Urban Background </p>
</li>
<li><p> YH1 |
Harrogate Roadside | Roadside </p>
</li>
<li><p> ZA1 | Ashford Rural - Pluckley | Rural
</p>
</li>
<li><p> ZA2 | Ashford Roadside | Roadside </p>
</li>
<li><p> ZA3 | Ashford Background |
Urban Background </p>
</li>
<li><p> ZA4 | Ashford M20 Background | Urban Background </p>
</li>
<li>
<p>ZC1 | Chatham Roadside - A2 | Roadside </p>
</li>
<li><p> ZD1 | Dover Roadside - Town
Hall | Roadside </p>
</li>
<li><p> ZD2 | Dover Roadside - Townwall Street | Roadside
</p>
</li>
<li><p> ZD3 | Dover Background - Langdon Cliff | Urban Background </p>
</li>
<li><p> ZD4 |
Dover Background - East Cliff | Urban Background </p>
</li>
<li><p> ZD5 | Dover Coast
Guard Met | Urban Background </p>
</li>
<li><p> ZD6 | Dover Docks | Industrial </p>
</li>
<li><p> ZF1
| Folkestone Suburban - Cheriton | Suburban </p>
</li>
<li><p> ZG1 | Gravesham Backgrnd -
Northfleet | Urban Background </p>
</li>
<li><p> ZG2 | Gravesham Roadside - A2 | Roadside
</p>
</li>
<li><p> ZG3 | Gravesham Ind Bgd - Northfleet | Urban Background </p>
</li>
<li><p> ZH1 |
Thanet Rural - Minster | Rural </p>
</li>
<li><p> ZH2 | Thanet Background - Margate |
Urban Background </p>
</li>
<li><p> ZH3 | Thanet Airport - Manston | Urban Background
</p>
</li>
<li><p> ZH4 | Thanet Roadside - Ramsgate | Roadside </p>
</li>
<li><p> ZL1 | Luton
Background | Urban Background </p>
</li>
<li><p> ZM1 | Maidstone Meteorological | Urban
Background </p>
</li>
<li><p> ZM2 | Maidstone Roadside - Fairmeadow | Kerbside </p>
</li>
<li><p> ZM3
| Maidstone Rural - Detling | Rural </p>
</li>
<li><p> ZR1 | Dartford Roadside - St
Clements | Kerbside </p>
</li>
<li><p> ZR2 | Dartford Roadside 2 - Town Centre | Roadside
</p>
</li>
<li><p> ZR3 | Dartford Roadside 3 - Bean Interchange | Roadside </p>
</li>
<li><p> ZS1 |
Stoke Rural AURN | Rural </p>
</li>
<li><p> ZT1 | Tonbridge Roadside - Town Centre |
Roadside </p>
</li>
<li><p> ZT2 | Tunbridge Wells Background - Town Hall | Urban
Background </p>
</li>
<li><p> ZT3 | Tunbridge Wells Rural - Southborough | Rural </p>
</li>
<li>
<p>ZT4 | Tunbridge Wells Roadside - St Johns | Roadside </p>
</li>
<li><p> ZT5 | Tonbridge
Roadside 2 - High St | Roadside </p>
</li>
<li><p> ZV1 | Sevenoaks - Greatness Park |
Urban Background </p>
</li>
<li><p> ZV2 | Sevenoaks - Bat and Ball | Roadside </p>
</li>
<li><p> ZW1 |
Swale Roadside - Ospringe A2 | Roadside </p>
</li>
<li><p> ZW2 | Swale Background -
Sheerness | Urban Background </p>
</li>
<li><p> ZW3 | Swale Roadside 2 - Ospringe Street
| Roadside </p>
</li>
<li><p> ZY1 | Canterbury Backgrnd - Chaucer TS | Urban Background
</p>
</li>
<li><p> ZY2 | Canterbury Roadside - St Dunstans | Roadside </p>
</li>
<li><p> ZY4 |
Canterbury St Peters Place | Roadside </p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>Returns a data frame of hourly mean values with date in POSIXct
class and time zone GMT.
</p>


<h3>Author(s)</h3>

<p>David Carslaw and Ben Barratt
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## import all pollutants from Marylebone Rd from 1990:2009
## Not run: mary &lt;- importKCL(site = "my1", year = 2000:2009)

## import nox, no2, o3 from Marylebone Road and North Kensignton for 2000
## Not run: thedata &lt;- importKCL(site = c("my1", "kc1"), year = 2000,
pollutant = c("nox", "no2", "o3"))
## End(Not run)

## import met data too...
## Not run: my1 &lt;- importKCL(site = "my1", year = 2008, met = TRUE)
</code></pre>

<hr>
<h2 id='importMeta'>Import monitoring site meta data for UK and European networks</h2><span id='topic+importMeta'></span>

<h3>Description</h3>

<p>Function to import meta data for air quality monitoring sites. By default,
the function will return the site latitude, longitude and site type, as well
as the code used in functions like <code><a href="#topic+importUKAQ">importUKAQ()</a></code>, <code><a href="#topic+importKCL">importKCL()</a></code> and
<code><a href="#topic+importEurope">importEurope()</a></code>. Additional information may optionally be returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importMeta(source = "aurn", all = FALSE, year = NA, duplicate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importMeta_+3A_source">source</code></td>
<td>
<p>One or more air quality networks for which data is available
through openair. Available networks include:
</p>

<ul>
<li> <p><code>"aurn"</code>,  The UK Automatic Urban and Rural Network.
</p>
</li>
<li> <p><code>"aqe"</code>,  The Air Quality England Network.
</p>
</li>
<li> <p><code>"saqn"</code>,  The Scottish Air Quality Network.
</p>
</li>
<li> <p><code>"waqn"</code>,  The Welsh Air Quality Network.
</p>
</li>
<li> <p><code>"ni"</code>,  The Northern Ireland Air Quality Network.
</p>
</li>
<li> <p><code>"local"</code>,  Locally managed air quality networks in England.
</p>
</li>
<li> <p><code>"kcl"</code>, King's College London networks.
</p>
</li>
<li> <p><code>"europe"</code>, European AirBase/e-reporting data.
There are two additional options provided for convenience:
</p>
</li>
<li> <p><code>"ukaq"</code> will return metadata for all networks for which data is imported by <code><a href="#topic+importUKAQ">importUKAQ()</a></code> (i.e., AURN, AQE, SAQN, WAQN, NI, and the local networks).
</p>
</li>
<li> <p><code>"all"</code> will import all available metadata (i.e., <code>"ukaq"</code> plus <code>"kcl"</code> and <code>"europe"</code>).
</p>
</li></ul>
</td></tr>
<tr><td><code id="importMeta_+3A_all">all</code></td>
<td>
<p>When <code>all = FALSE</code> only the site code, site name, latitude and
longitude and site type are imported. Setting <code>all = TRUE</code> will import all
available meta data and provide details (when available) or the individual
pollutants measured at each site.</p>
</td></tr>
<tr><td><code id="importMeta_+3A_year">year</code></td>
<td>
<p>If a single year is selected, only sites that were open at some
point in that year are returned. If <code>all = TRUE</code> only sites that
measured a particular pollutant in that year are returned. Year can also be
a sequence e.g. <code>year = 2010:2020</code> or of length 2 e.g. <code>year = c(2010, 2020)</code>, which will return only sites that were open over the
duration. Note that <code>year</code> is ignored when the <code>source</code> is either
<code>"kcl"</code> or <code>"europe"</code>.</p>
</td></tr>
<tr><td><code id="importMeta_+3A_duplicate">duplicate</code></td>
<td>
<p>Some UK air quality sites are part of multiple networks, so
could appear more than once when <code>source</code> is a vector of two or more. The
default argument, <code>FALSE</code>, drops duplicate sites. <code>TRUE</code> will return them.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function imports site meta data from several networks in the UK and
Europe:
</p>

<ul>
<li> <p><code>"aurn"</code>,  The <a href="https://uk-air.defra.gov.uk/">UK Automatic Urban and Rural Network</a>.
</p>
</li>
<li> <p><code>"aqe"</code>,  The <a href="https://www.airqualityengland.co.uk/">Air Quality England Network</a>.
</p>
</li>
<li> <p><code>"saqn"</code>,  The <a href="https://www.scottishairquality.scot/">Scottish Air Quality Network</a>.
</p>
</li>
<li> <p><code>"waqn"</code>,  The <a href="https://airquality.gov.wales/">Welsh Air Quality Network</a>.
</p>
</li>
<li> <p><code>"ni"</code>,  The <a href="https://www.airqualityni.co.uk/">Northern Ireland Air Quality Network</a>.
</p>
</li>
<li> <p><code>"local"</code>,  Locally managed air quality networks in England.
</p>
</li>
<li> <p><code>"kcl"</code>,  King's College London networks.
</p>
</li>
<li> <p><code>"europe"</code>,  Hourly European data (Air Quality e-Reporting) based on a
simplified version of the <code>{saqgetr}</code> package.
</p>
</li></ul>

<p>By default, the function will return the site latitude, longitude and site
type. If the option <code>all = TRUE</code> is used, much more detailed information is
returned. For most networks, this detailed information includes per-pollutant
summaries, opening and closing dates of sites etc.
</p>
<p>Thanks go to Trevor Davies (Ricardo), Dr Stuart Grange (EMPA) and Dr Ben
Barratt (KCL) and  for making these data available.
</p>


<h3>Value</h3>

<p>A data frame with meta data.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>the <code>networkMap()</code> function from the <code>openairmaps</code> package which can
visualise site metadata on an interactive map.
</p>
<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# basic info:
meta &lt;- importMeta(source = "aurn")

# more detailed information:
meta &lt;- importMeta(source = "aurn", all = TRUE)

# from the Scottish Air Quality Network:
meta &lt;- importMeta(source = "saqn", all = TRUE)

# from multiple networks:
meta &lt;- importMeta(source = c("aurn", "aqe", "local"))

## End(Not run)
</code></pre>

<hr>
<h2 id='importTraj'>Import pre-calculated HYSPLIT 96-hour back trajectories</h2><span id='topic+importTraj'></span>

<h3>Description</h3>

<p>Function to import pre-calculated back trajectories using the NOAA HYSPLIT
model. The trajectories have been calculated for a select range of locations
which will expand in time. They cover the last 20 years or so and can be used
together with other <code>openair</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importTraj(site = "london", year = 2009, local = NA, progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importTraj_+3A_site">site</code></td>
<td>
<p>Site code of the network site to import e.g. &quot;london&quot;. Only one
site can be imported at a time. The following sites are typically available
from 2000-2012, although some UK ozone sites go back to 1988 (code,
location, lat, lon, year):
</p>

<table>
<tr>
 <td style="text-align: left;">
abudhabi   </td><td style="text-align: left;"> Abu Dhabi                    </td><td style="text-align: right;">  24.43000 </td><td style="text-align: right;">  54.408000 </td><td style="text-align: left;"> 2012-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
ah         </td><td style="text-align: left;"> Aston Hill                   </td><td style="text-align: right;">  52.50385 </td><td style="text-align: right;">  -3.041780 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
auch       </td><td style="text-align: left;"> Auchencorth Moss             </td><td style="text-align: right;">  55.79283 </td><td style="text-align: right;">  -3.242568 </td><td style="text-align: left;"> 2006-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
berlin     </td><td style="text-align: left;"> Berlin, Germany              </td><td style="text-align: right;">  52.52000 </td><td style="text-align: right;">  13.400000 </td><td style="text-align: left;"> 2000-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
birm       </td><td style="text-align: left;"> Birmigham Centre             </td><td style="text-align: right;">  52.47972 </td><td style="text-align: right;">  -1.908078 </td><td style="text-align: left;"> 1990-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
boston     </td><td style="text-align: left;"> Boston, USA                  </td><td style="text-align: right;">  42.32900 </td><td style="text-align: right;"> -71.083000 </td><td style="text-align: left;"> 2008-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
bot        </td><td style="text-align: left;"> Bottesford                   </td><td style="text-align: right;">  52.93028 </td><td style="text-align: right;">  -0.814722 </td><td style="text-align: left;"> 1990-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
bukit      </td><td style="text-align: left;"> Bukit Kototabang, Indonesia  </td><td style="text-align: right;">  -0.19805 </td><td style="text-align: right;"> 100.318000 </td><td style="text-align: left;"> 1996-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
chittagong </td><td style="text-align: left;"> Chittagong, Bangladesh       </td><td style="text-align: right;">  22.37000 </td><td style="text-align: right;">  91.800000 </td><td style="text-align: left;"> 2010-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
dhaka      </td><td style="text-align: left;"> Dhaka, Bangladesh            </td><td style="text-align: right;">  23.70000 </td><td style="text-align: right;">  90.375000 </td><td style="text-align: left;"> 2010-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
ed         </td><td style="text-align: left;"> Edinburgh                    </td><td style="text-align: right;">  55.95197 </td><td style="text-align: right;">  -3.195775 </td><td style="text-align: left;"> 1990-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
elche      </td><td style="text-align: left;"> Elche, Spain                 </td><td style="text-align: right;">  38.27000 </td><td style="text-align: right;">  -0.690000 </td><td style="text-align: left;"> 2004-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
esk        </td><td style="text-align: left;"> Eskdalemuir                  </td><td style="text-align: right;">  55.31530 </td><td style="text-align: right;">  -3.206110 </td><td style="text-align: left;"> 1998-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
gibraltar  </td><td style="text-align: left;"> Gibraltar                    </td><td style="text-align: right;">  36.13400 </td><td style="text-align: right;">  -5.347000 </td><td style="text-align: left;"> 2005-2010</td>
</tr>
<tr>
 <td style="text-align: left;">
glaz       </td><td style="text-align: left;"> Glazebury                    </td><td style="text-align: right;">  53.46008 </td><td style="text-align: right;">  -2.472056 </td><td style="text-align: left;"> 1998-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
groningen  </td><td style="text-align: left;"> Groningen                    </td><td style="text-align: right;">  53.40000 </td><td style="text-align: right;">   6.350000 </td><td style="text-align: left;"> 2007-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
har        </td><td style="text-align: left;"> Harwell                      </td><td style="text-align: right;">  51.57108 </td><td style="text-align: right;">  -1.325283 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
hk         </td><td style="text-align: left;"> Hong Kong                    </td><td style="text-align: right;">  22.29000 </td><td style="text-align: right;"> 114.170000 </td><td style="text-align: left;"> 1998-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
hm         </td><td style="text-align: left;"> High Muffles                 </td><td style="text-align: right;">  54.33500 </td><td style="text-align: right;">  -0.808600 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
kuwait     </td><td style="text-align: left;"> Kuwait City                  </td><td style="text-align: right;">  29.36700 </td><td style="text-align: right;">  47.967000 </td><td style="text-align: left;"> 2008-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
lb         </td><td style="text-align: left;"> Ladybower                    </td><td style="text-align: right;">  53.40337 </td><td style="text-align: right;">  -1.752006 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
london     </td><td style="text-align: left;"> Central London               </td><td style="text-align: right;">  51.50000 </td><td style="text-align: right;">  -0.100000 </td><td style="text-align: left;"> 1990-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
lh         </td><td style="text-align: left;"> Lullington Heath             </td><td style="text-align: right;">  50.79370 </td><td style="text-align: right;">   0.181250 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
ln         </td><td style="text-align: left;"> Lough Navar                  </td><td style="text-align: right;">  54.43951 </td><td style="text-align: right;">  -7.900328 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
mh         </td><td style="text-align: left;"> Mace Head                    </td><td style="text-align: right;">  53.33000 </td><td style="text-align: right;">  -9.900000 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
ny-alesund </td><td style="text-align: left;"> Ny-Alesund, Norway           </td><td style="text-align: right;">  78.91763 </td><td style="text-align: right;">  11.894653 </td><td style="text-align: left;"> 2009-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
oslo       </td><td style="text-align: left;"> Oslo                         </td><td style="text-align: right;">  59.90000 </td><td style="text-align: right;">  10.750000 </td><td style="text-align: left;"> 2010-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
paris      </td><td style="text-align: left;"> Paris, France                </td><td style="text-align: right;">  48.86200 </td><td style="text-align: right;">   2.339000 </td><td style="text-align: left;"> 2000-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
roch       </td><td style="text-align: left;"> Rochester Stoke              </td><td style="text-align: right;">  51.45617 </td><td style="text-align: right;">   0.634889 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
rotterdam  </td><td style="text-align: left;"> Rotterdam                    </td><td style="text-align: right;">  51.91660 </td><td style="text-align: right;">   4.475000 </td><td style="text-align: left;"> 2010-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
saopaulo   </td><td style="text-align: left;"> Sao Paulo                    </td><td style="text-align: right;"> -23.55000 </td><td style="text-align: right;"> -46.640000 </td><td style="text-align: left;"> 2000-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
sib        </td><td style="text-align: left;"> Sibton                       </td><td style="text-align: right;">  52.29440 </td><td style="text-align: right;">   1.463970 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
sv         </td><td style="text-align: left;"> Strath Vaich                 </td><td style="text-align: right;">  57.73446 </td><td style="text-align: right;">  -4.776583 </td><td style="text-align: left;"> 1988-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
wuhan      </td><td style="text-align: left;"> Wuhan, China                 </td><td style="text-align: right;">  30.58300 </td><td style="text-align: right;"> 114.280000 </td><td style="text-align: left;"> 2008-2013</td>
</tr>
<tr>
 <td style="text-align: left;">
yw         </td><td style="text-align: left;"> Yarner Wood                  </td><td style="text-align: right;">  50.59760 </td><td style="text-align: right;">  -3.716510 </td><td style="text-align: left;"> 1988-2013
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="importTraj_+3A_year">year</code></td>
<td>
<p>Year or years to import. To import a sequence of years from
1990 to 2000 use <code>year = 1990:2000</code>. To import several specific years
use <code>year = c(1990, 1995, 2000)</code> for example.</p>
</td></tr>
<tr><td><code id="importTraj_+3A_local">local</code></td>
<td>
<p>File path to .RData trajectory files run by user and
not stored on the Ricardo web server. These files would have been
generated from the Hysplit trajectory code shown in the appendix
of the openair manual. An example would be <code>local =
'c:/users/david/TrajFiles/'</code>.</p>
</td></tr>
<tr><td><code id="importTraj_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many receptors/years are being
imported? Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function imports pre-calculated back trajectories using the HYSPLIT
trajectory model (Hybrid Single Particle Lagrangian Integrated Trajectory
Model. Back trajectories provide some very useful information for air quality
data analysis. However, while they are commonly calculated by researchers it
is generally difficult for them to be calculated on a routine basis and used
easily. In addition, the availability of back trajectories over several years
can be very useful, but again difficult to calculate.
</p>
<p>Trajectories are run at 3-hour intervals and stored in yearly files (see
below). The trajectories are started at ground-level (10m) and propagated
backwards in time.
</p>
<p>These trajectories have been calculated using the Global NOAA-NCEP/NCAR
reanalysis data archives. The global data are on a latitude-longitude grid
(2.5 degree). Note that there are many different meteorological data sets
that can be used to run HYSPLIT e.g. including ECMWF data. However, in order
to make it practicable to run and store trajectories for many years and
sites, the NOAA-NCEP/NCAR reanalysis data is most useful. In addition, these
archives are available for use widely, which is not the case for many other
data sets e.g. ECMWF. HYSPLIT calculated trajectories based on archive data
may be distributed without permission. For those wanting, for example, to
consider higher resolution meteorological data sets it may be better to run
the trajectories separately.
</p>
<p>We are extremely grateful to NOAA for making HYSPLIT available to produce
back trajectories in an open way. We ask that you cite HYSPLIT if used in
published work.
</p>
<p>Users can supply their own trajectory files to plot in openair. These files
must have the following fields: date, lat, lon and hour.inc (see details
below).
</p>
<p>The files consist of the following information:
</p>
 <dl>
<dt>date</dt><dd><p>This is the arrival point time and is repeated the
number of times equal to the length of the back trajectory &mdash; typically 96
hours (except early on in the file). The format is <code>POSIXct</code>. It is this
field that should be used to link with air quality data. See example below.</p>
</dd>
<dt>receptor</dt><dd><p>Receptor number, currently only 1.</p>
</dd> <dt>year</dt><dd><p>The year</p>
</dd>
<dt>month</dt><dd><p>Month 1-12</p>
</dd> <dt>day</dt><dd><p>Day of the month 1-31</p>
</dd> <dt>hour</dt><dd><p>Hour
of the day 0-23 GMT</p>
</dd> <dt>hour.inc</dt><dd><p>Number of hours back in time e.g. 0 to
-96.</p>
</dd> <dt>lat</dt><dd><p>Latitude in decimal format.</p>
</dd>  <dt>lon</dt><dd><p>Longitude in
decimal format.</p>
</dd>  <dt>height</dt><dd><p>Height of trajectory (m).</p>
</dd>
<dt>pressure</dt><dd><p>Pressure of trajectory (kPa).</p>
</dd>  </dl>



<h3>Value</h3>

<p>Returns a data frame with pre-calculated back trajectories.
</p>


<h3>Note</h3>

<p>The trajectories were run using the February 2011 HYSPLIT model.
The function is primarily written to investigate a single
site at a time for a single year. The trajectory files are quite
large and care should be exercised when importing several years and/or sites.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importUKAQ">importUKAQ</a>()</code>
</p>
<p>Other trajectory analysis functions: 
<code><a href="#topic+trajCluster">trajCluster</a>()</code>,
<code><a href="#topic+trajLevel">trajLevel</a>()</code>,
<code><a href="#topic+trajPlot">trajPlot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## import trajectory data for London in 2009
## Not run: mytraj &lt;- importTraj(site = "london", year = 2009)

## combine with measurements
## Not run: theData &lt;- importAURN(site = "kc1", year = 2009)
mytraj &lt;- merge(mytraj, theData, by = "date")
## End(Not run)
</code></pre>

<hr>
<h2 id='importUKAQ'>Import data from the UK Air Pollution Networks</h2><span id='topic+importUKAQ'></span>

<h3>Description</h3>

<p>Functions for importing air pollution data from a range of UK networks
including the Automatic Urban and Rural Network (AURN), the individual
England (AQE), Scotland (SAQN), Wales (WAQN) and Northern Ireland (NI)
Networks, and many &quot;locally managed&quot; monitoring networks across England.
Files are imported from a remote server operated by Ricardo that provides air
quality data files as R data objects. For an up to date list of available
sites that can be imported, see <code><a href="#topic+importMeta">importMeta()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importUKAQ(
  site = "my1",
  year = 2022,
  source = "aurn",
  data_type = "hourly",
  pollutant = "all",
  hc = FALSE,
  meta = FALSE,
  meteo = TRUE,
  ratified = FALSE,
  to_narrow = FALSE,
  verbose = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importUKAQ_+3A_site">site</code></td>
<td>
<p>Site code of the site to import, e.g., <code>"my1"</code> is Marylebone
Road. Site codes can be discovered through the use of <code><a href="#topic+importMeta">importMeta()</a></code>.
Several sites can be imported at once. For example, <code>site = c("my1", "nott")</code> imports both Marylebone Road and Nottingham. Sites from different
networks can be imported through also providing multiple <code>source</code>s. Site
codes can be upper or lower case.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_year">year</code></td>
<td>
<p>Year(s) to import. To import a series of years use, e.g.,
<code>2000:2020</code>. To import several specific years use <code>year = c(2000, 2010, 2020)</code>.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_source">source</code></td>
<td>
<p>The network to which the <code>site</code>(s) belong, defaulting to
<code>"aurn"</code>. Providing a single network will attempt to import all of the
given <code>site</code>s from the provided network. Alternatively, a vector of sources
can be provided of the same length as <code>site</code> to indicate which network each
<code>site</code> individually belongs. Available networks include:
</p>

<ul>
<li> <p><code>"aurn"</code>,  The UK Automatic Urban and Rural Network.
</p>
</li>
<li> <p><code>"aqe"</code>,  The Air Quality England Network.
</p>
</li>
<li> <p><code>"saqn"</code>,  The Scottish Air Quality Network.
</p>
</li>
<li> <p><code>"waqn"</code>,  The Welsh Air Quality Network.
</p>
</li>
<li> <p><code>"ni"</code>,  The Northern Ireland Air Quality Network.
</p>
</li>
<li> <p><code>"local"</code>,  Locally managed air quality networks in England.
</p>
</li></ul>
</td></tr>
<tr><td><code id="importUKAQ_+3A_data_type">data_type</code></td>
<td>
<p>The type of data to be returned, defaulting to <code>"hourly"</code>
data. Alternative data types include:
</p>

<ul>
<li> <p><code>"daily"</code>: Daily average data.
</p>
</li>
<li> <p><code>"monthly"</code>: Monthly average data with data capture information for the whole network.
</p>
</li>
<li> <p><code>"annual"</code>: Annual average data with data capture information for the whole network.
</p>
</li>
<li> <p><code>"15_min"</code>: 15-minute average SO2 concentrations.
</p>
</li>
<li> <p><code>"8_hour"</code>: 8-hour rolling mean concentrations for O3 and CO.
</p>
</li>
<li> <p><code>"24_hour"</code>: 24-hour rolling mean concentrations for particulates.
</p>
</li>
<li> <p><code>"daily_max_8"</code>: Maximum daily rolling 8-hour maximum for O3 and CO.
</p>
</li>
<li> <p><code>"daqi"</code>: Daily Air Quality Index (DAQI). See
<a href="https://uk-air.defra.gov.uk/air-pollution/daqi?view=more-info">here</a> for
more details of how the index is defined. Note that this <code>data_type</code> is not
available for locally managed monitoring networks.
</p>
</li></ul>
</td></tr>
<tr><td><code id="importUKAQ_+3A_pollutant">pollutant</code></td>
<td>
<p>Pollutants to import. If omitted will import all pollutants
from a site. To import only NOx and NO2 for example use <code>pollutant =
  c("nox", "no2")</code>. Pollutant names can be upper or lower case.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_hc">hc</code></td>
<td>
<p>Include hydrocarbon measurements in the imported data? Defaults to
<code>FALSE</code> as most users will not be interested in using hydrocarbon data.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_meta">meta</code></td>
<td>
<p>Append the site type, latitude and longitude of each selected
<code>site</code>? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_meteo">meteo</code></td>
<td>
<p>Append modelled meteorological data, if available? Defaults to
<code>TRUE</code>, which will return wind speed (<code>ws</code>), wind direction (<code>wd</code>) and
ambient temperature (<code>air_temp</code>). The variables are calculated from using
the WRF model run by Ricardo Energy &amp; Environment and are available for
most but not all networks. Setting <code>meteo = FALSE</code> is useful if you have
other meteorological data to use in preference, for example from
the <code>worldmet</code> package.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_ratified">ratified</code></td>
<td>
<p>Append <code>qc</code> column(s) to hourly data indicating whether each
species was ratified (i.e., quality-checked)?  Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_to_narrow">to_narrow</code></td>
<td>
<p>Return the data in a &quot;narrow&quot;/&quot;long&quot;/&quot;tidy&quot; format? By
default the returned data is &quot;wide&quot; and has a column for each
pollutant/variable. When <code>to_narrow = TRUE</code> the data are returned with a
column identifying the pollutant name and a column containing the
corresponding concentration/statistic. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_verbose">verbose</code></td>
<td>
<p>Print messages to the console if hourly data cannot be
imported? Default is <code>FALSE</code>. <code>TRUE</code> is useful for debugging as the
specific <code>year</code>(s), <code>site</code>(s) and <code>source</code>(s) which cannot be imported will
be returned.</p>
</td></tr>
<tr><td><code id="importUKAQ_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many sites/years are being imported?
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <a href="tibble.html#topic+tibble-package">tibble</a>
</p>


<h3>Importing UK Air Pollution Data</h3>

<p>This family of functions has been written to make it easy to import data
from across several UK air quality networks. Ricardo have provided .RData
files (R workspaces) of all individual sites and years, as well as up to
date meta data. These files are updated on a daily basis. This approach
requires a link to the Internet to work.
</p>
<p>There are several advantages over the web portal approach where .csv files
are downloaded.
</p>

<ul>
<li><p> First, it is quick to select a range of sites, pollutants
and periods (see examples below).
</p>
</li>
<li><p> Second, storing the data as .RData
objects is very efficient as they are about four times smaller than .csv
files &mdash; which means the data downloads quickly and saves bandwidth.
</p>
</li>
<li><p> Third, the function completely avoids any need for data manipulation or
setting time formats, time zones etc. The function also has the advantage
that the proper site name is imported and used in
<a href="#topic+openair-package">openair</a> functions.
</p>
</li></ul>

<p>Users should take care if using data from both <a href="#topic+openair-package">openair</a>
<em>and</em> web portals (for example, <a href="https://uk-air.defra.gov.uk/data/">UK AIR</a>). One key difference is that the
data provided by openair is date <em>beginning</em>, whereas the web portal
provides date <em>ending</em>. Hourly concentrations may therefore appear offset
by an hour, for example.
</p>
<p>The data are imported by stacking sites on top of one another and will have
field names <code>site</code>, <code>code</code> (the site code) and <code>pollutant</code>.
</p>
<p>By default, the function returns hourly average data. However, annual,
monthly, daily and 15 minute data (for SO2) can be returned using the
option <code>data_type</code>. Annual and monthly data provide whole network
information including data capture statistics.
</p>
<p>All units are expressed in mass terms for gaseous species (ug/m3 for NO,
NO2, NOx (as NO2), SO2 and hydrocarbons; and mg/m3 for CO). PM10
concentrations are provided in gravimetric units of ug/m3 or scaled to be
comparable with these units. Over the years a variety of instruments have
been used to measure particulate matter and the technical issues of
measuring PM10 are complex. In recent years the measurements rely on FDMS
(Filter Dynamics Measurement System), which is able to measure the volatile
component of PM. In cases where the FDMS system is in use there will be a
separate volatile component recorded as 'v10' and non-volatile component
'nv10', which is already included in the absolute PM10 measurement. Prior
to the use of FDMS the measurements used TEOM (Tapered Element Oscillating.
Microbalance) and these concentrations have been multiplied by 1.3 to
provide an estimate of the total mass including the volatile fraction.
</p>
<p>Some sites report hourly and daily PM10 and / or PM2.5. When <code>data_type = "daily"</code> and there are both hourly and 'proper' daily measurements
available, these will be returned as e.g. &quot;pm2.5&quot; and &quot;gr_pm2.5&quot;; the
former corresponding to data based on original hourly measurements and the
latter corresponding to daily gravimetric measurements.
</p>
<p>The function returns modelled hourly values of wind speed (<code>ws</code>), wind
direction (<code>wd</code>) and ambient temperature (<code>air_temp</code>) if available
(generally from around 2010). These values are modelled using the WRF model
operated by Ricardo.
</p>
<p>The BAM (Beta-Attenuation Monitor) instruments that have been incorporated
into the network throughout its history have been scaled by 1.3 if they
have a heated inlet (to account for loss of volatile particles) and 0.83 if
they do not have a heated inlet. The few TEOM instruments in the network
after 2008 have been scaled using VCM (Volatile Correction Model) values to
account for the loss of volatile particles. The object of all these scaling
processes is to provide a reasonable degree of comparison between data sets
and with the reference method and to produce a consistent data record over
the operational period of the network, however there may be some
discontinuity in the time series associated with instrument changes.
</p>
<p>No corrections have been made to the PM2.5 data. The volatile component of
FDMS PM2.5 (where available) is shown in the 'v2.5' column.
</p>


<h3>Author(s)</h3>

<p>David Carslaw, Trevor Davies, and Jack Davison
</p>


<h3>See Also</h3>

<p>Other import functions: 
<code><a href="#topic+importADMS">importADMS</a>()</code>,
<code><a href="#topic+importAURN">importAURN</a>()</code>,
<code><a href="#topic+importEurope">importEurope</a>()</code>,
<code><a href="#topic+importKCL">importKCL</a>()</code>,
<code><a href="#topic+importMeta">importMeta</a>()</code>,
<code><a href="#topic+importTraj">importTraj</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# import a single site from the AURN
importUKAQ("my1", year = 2022)

# import sites from another network
importUKAQ(c("bn1", "bn2"), year = 2022, source = "aqe")

# import sites across multiple networks
importUKAQ(c("my1", "bn1", "bn2"),
  year = 2022,
  source = c("aurn", "aqe", "aqe")
)

# get "long" format hourly data with a ratification flag
importUKAQ(
  "card",
  source = "waqn",
  year = 2022,
  to_narrow = TRUE,
  ratified = TRUE
)

# import other data types, filtering by pollutant
importUKAQ(
  data_type = "annual",
  pollutant = c("no2", "pm2.5", "pm10"),
  source = c("aurn", "aqe")
)

## End(Not run)
</code></pre>

<hr>
<h2 id='linearRelation'>Linear relations between pollutants</h2><span id='topic+linearRelation'></span>

<h3>Description</h3>

<p>This function considers linear relationships between two pollutants. The
relationships are calculated on different times bases using a linear model.
The slope and 95% confidence interval in slope relationships by time unit are
plotted in many ways. The function is particularly useful when considering
whether relationships are consistent with emissions inventories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linearRelation(
  mydata,
  x = "nox",
  y = "no2",
  period = "month",
  condition = FALSE,
  n = 20,
  rsq.thresh = 0,
  ylab = paste0("slope from ", y, " = m.", x, " + c"),
  auto.text = TRUE,
  cols = "grey30",
  date.breaks = 5,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linearRelation_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>date</code> and two
pollutants.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_x">x</code></td>
<td>
<p>First pollutant that when plotted would appear on the x-axis of a
relationship e.g. <code>x = "nox"</code>.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_y">y</code></td>
<td>
<p>Second pollutant that when plotted would appear on the y-axis of a
relationship e.g. <code>y = "pm10"</code>.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_period">period</code></td>
<td>
<p>A range of different time periods can be analysed. The default
is <code>month</code> but can be <code>year</code> and <code>week</code>. For increased
flexibility an integer can be used e.g. for 3-month values <code>period =
  "3 month"</code>. Other cases include <code>"hour"</code> will show the diurnal
relationship between <code>x</code> and <code>y</code> and &ldquo;weekday&rdquo; the day of
the week relationship between <code>x</code> and <code>y</code>. &ldquo;day.hour&rdquo; will
plot the relationship by weekday and hour of the day.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_condition">condition</code></td>
<td>
<p>For <code>period = "hour"</code>, <code>period = "day"</code> and
<code>period = "day.hour"</code>, setting <code>condition = TRUE</code> will plot the
relationships split by year. This is useful for seeing how the
relationships may be changing over time.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_n">n</code></td>
<td>
<p>The minimum number of points to be sent to the linear model.
Because there may only be a few points e.g. hours where two pollutants are
available over one week, <code>n</code> can be set to ensure that at least
<code>n</code> points are sent to the linear model. If a period has hours &lt;
<code>n</code> that period will be ignored.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_rsq.thresh">rsq.thresh</code></td>
<td>
<p>The minimum correlation coefficient (R2) allowed. If the
relationship between <code>x</code> and <code>y</code> is not very good for a
particular period, setting <code>rsq.thresh</code> can help to remove those
periods where the relationship is not strong. Any R2 values below
<code>rsq.thresh</code> will not be plotted.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_ylab">ylab</code></td>
<td>
<p>y-axis title, specified by the user.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_cols">cols</code></td>
<td>
<p>Colour for the points and uncertainty intervals.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function will
try and choose a sensible number of dates/times as well as formatting the
date/time appropriately to the range being considered.  This does not
always work as desired automatically. The user can therefore increase or
decrease the number of intervals by adjusting the value of
<code>date.breaks</code> up or down.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="linearRelation_+3A_...">...</code></td>
<td>
<p>Other graphical parameters. A useful one to remove the strip with
the date range on at the top of the plot is to set <code>strip = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relationships between pollutants can yield some very useful information
about source emissions and how they change. A scatterPlot between two
pollutants is the usual way to investigate the relationship. A linear
regression is useful to test the strength of the relationship. However,
considerably more information can be gleaned by considering different time
periods, such as how the relationship between two pollutants vary over time,
by day of the week, diurnally and so on. The <code>linearRelation</code> function
does just that - it fits a linear relationship between two pollutants over a
wide range of time periods determined by <code>period</code>.
</p>
<p><code>linearRelation</code> function is particularly useful if background
concentrations are first removed from roadside concentrations, as the
increment will relate more directly with changes in emissions. In this
respect, using <code>linearRelation</code> can provide valuable information on how
emissions may have changed over time, by hour of the day etc. Using the
function in this way will require users to do some basic manipulation with
their data first.
</p>
<p>If a data frame is supplied that contains <code>nox</code>, <code>no2</code> and
<code>o3</code>, the <code>y</code> can be chosen as <code>y = "ox"</code>. In function will
therefore consider total oxidant slope (sum of NO2 + O3), which can provide
valuable information on likely vehicle primary NO emissions. Note, however,
that most roadside sites do not have ozone measurements and
<code><a href="#topic+calcFno2">calcFno2</a></code> is the alternative.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calcFno2">calcFno2()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># monthly relationship between NOx and SO2 - note rapid fall in
# ratio at the beginning of the series
linearRelation(mydata, x = "nox", y = "so2")
# monthly relationship between NOx and SO2 - note rapid fall in
# ratio at the beginning of the series
## Not run: linearRelation(mydata, x = "nox", y = "ox")

# diurnal oxidant slope by year # clear change in magnitude
# starting 2003, but the diurnal profile has also changed: the
# morning and evening peak hours are more important, presumably
# due to change in certain vehicle types
## Not run: linearRelation(mydata, x = "nox", y = "ox", period = "hour", condition = TRUE)

# PM2.5/PM10 ratio, but only plot where monthly R2 &gt;= 0.8
## Not run: linearRelation(mydata, x = "pm10", y = "pm25", rsq.thresh = 0.8)
</code></pre>

<hr>
<h2 id='modStats'>Calculate common model evaluation statistics</h2><span id='topic+modStats'></span>

<h3>Description</h3>

<p>Function to calculate common numerical model evaluation statistics with
flexible conditioning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modStats(
  mydata,
  mod = "mod",
  obs = "obs",
  statistic = c("n", "FAC2", "MB", "MGE", "NMB", "NMGE", "RMSE", "r", "COE", "IOA"),
  type = "default",
  rank.name = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modStats_+3A_mydata">mydata</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="modStats_+3A_mod">mod</code></td>
<td>
<p>Name of a variable in <code>mydata</code> that represents modelled
values.</p>
</td></tr>
<tr><td><code id="modStats_+3A_obs">obs</code></td>
<td>
<p>Name of a variable in <code>mydata</code> that represents measured
values.</p>
</td></tr>
<tr><td><code id="modStats_+3A_statistic">statistic</code></td>
<td>
<p>The statistic to be calculated. See details below for a
description of each.</p>
</td></tr>
<tr><td><code id="modStats_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce statistics using the entire
data. <code>type</code> can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four sets of
statistics &mdash; one for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>More than one type can be considered e.g. <code>type = c("season",
  "weekday")</code> will produce statistics split by season and day of the week.</p>
</td></tr>
<tr><td><code id="modStats_+3A_rank.name">rank.name</code></td>
<td>
<p>Simple model ranking can be carried out if <code>rank.name</code>
is supplied. <code>rank.name</code> will generally refer to a column representing
a model name, which is to ranked. The ranking is based the COE performance,
as that indicator is arguably the best single model performance indicator
available.</p>
</td></tr>
<tr><td><code id="modStats_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+cutData">cutData</a></code>
</p>

<dl>
<dt><code>x</code></dt><dd><p>A data frame containing a field <code>date</code>.</p>
</dd>
<dt><code>hemisphere</code></dt><dd><p>Can be <code>"northern"</code> or <code>"southern"</code>, used to
split data into seasons.</p>
</dd>
<dt><code>n.levels</code></dt><dd><p>Number of quantiles to split numeric data into.</p>
</dd>
<dt><code>start.day</code></dt><dd><p>What day of the week should the <code>type = "weekday"</code>
start on?  The user can change the start day by supplying an integer
between 0 and 6. Sunday = 0, Monday = 1, ... For example to start the
weekday plots on a Saturday, choose <code>start.day = 6</code>.</p>
</dd>
<dt><code>is.axis</code></dt><dd><p>A logical (<code>TRUE</code>/<code>FALSE</code>), used to request
shortened cut labels for axes.</p>
</dd>
<dt><code>local.tz</code></dt><dd><p>Used for identifying whether a date has daylight savings time
(DST) applied or not. Examples include <code>local.tz = "Europe/London"</code>,
<code>local.tz = "America/New_York"</code> i.e. time zones that assume DST.
<a href="https://en.wikipedia.org/wiki/List_of_zoneinfo_time_zones">https://en.wikipedia.org/wiki/List_of_zoneinfo_time_zones</a> shows time
zones that should be valid for most systems. It is important that the
original data are in GMT (UTC) or a fixed offset from GMT. See
<code>import</code> and the openair manual for information on how to import data
and ensure no DST is applied.</p>
</dd>
<dt><code>latitude</code></dt><dd><p>The decimal latitude used in <code>type = "daylight"</code>.</p>
</dd>
<dt><code>longitude</code></dt><dd><p>The decimal longitude. Note that locations west of Greenwich
are negative.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is under development and currently provides some common model
evaluation statistics. These include (to be mathematically defined later):
</p>

<ul>
<li> <p><code class="reqn">n</code>, the number of complete pairs of data.
</p>
</li>
<li> <p><code class="reqn">FAC2</code>, fraction of predictions within a factor of two.
</p>
</li>
<li> <p><code class="reqn">MB</code>, the mean bias.
</p>
</li>
<li> <p><code class="reqn">MGE</code>, the mean gross error.
</p>
</li>
<li> <p><code class="reqn">NMB</code>, the normalised mean bias.
</p>
</li>
<li> <p><code class="reqn">NMGE</code>, the normalised mean gross error.
</p>
</li>
<li> <p><code class="reqn">RMSE</code>, the root mean squared error.
</p>
</li>
<li> <p><code class="reqn">r</code>, the Pearson correlation coefficient. Note, can also supply and
argument <code>method</code> e.g. <code>method = "spearman"</code>. Also returned is the
P value of the correlation coefficient, <code class="reqn">P</code>, which may present as <code>0</code> for
very low values.
</p>
</li>
<li> <p><code class="reqn">COE</code>, the <em>Coefficient of Efficiency</em> based on Legates and
McCabe (1999, 2012). There have been many suggestions for measuring model
performance over the years, but the COE is a simple formulation which is easy
to interpret.
</p>
<p>A perfect model has a COE = 1. As noted by Legates and McCabe although the
COE has no lower bound, a value of COE = 0.0 has a fundamental meaning. It
implies that the model is no more able to predict the observed values than
does the observed mean. Therefore, since the model can explain no more of the
variation in the observed values than can the observed mean, such a model can
have no predictive advantage.
</p>
<p>For negative values of COE, the model is less effective than the observed
mean in predicting the variation in the observations. </p>
</li>
<li> <p><code class="reqn">IOA</code>, the
Index of Agreement based on Willmott et al. (2011), which spans between -1
and +1 with values approaching +1 representing better model performance.
</p>
<p>An IOA of 0.5, for example, indicates that the sum of the error-magnitudes is
one half of the sum of the observed-deviation magnitudes.  When IOA = 0.0, it
signifies that the sum of the magnitudes of the errors and the sum of the
observed-deviation magnitudes are equivalent. When IOA = -0.5, it indicates
that the sum of the error-magnitudes is twice the sum of the perfect
model-deviation and observed-deviation magnitudes. Values of IOA near -1.0
can mean that the model-estimated deviations about O are poor estimates of
the observed deviations; but, they also can mean that there simply is little
observed variability - so some caution is needed when the IOA approaches -1.
</p>
</li></ul>

<p>All statistics are based on complete pairs of <code>mod</code> and <code>obs</code>.
</p>
<p>Conditioning is possible through setting <code>type</code>, which can be a vector
e.g. <code>type = c("weekday", "season")</code>.
</p>


<h3>Value</h3>

<p>Returns a data frame with model evaluation statistics.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Legates DR, McCabe GJ. (1999). Evaluating the use of
goodness-of-fit measures in hydrologic and hydroclimatic model validation.
Water Resources Research 35(1): 233-241.
</p>
<p>Legates DR, McCabe GJ. (2012). A refined index of model performance: a
rejoinder, International Journal of Climatology.
</p>
<p>Willmott, C.J., Robeson, S.M., Matsuura, K., 2011. A refined index of model
performance. International Journal of Climatology.
</p>


<h3>See Also</h3>

<p>Other model evaluation functions: 
<code><a href="#topic+TaylorDiagram">TaylorDiagram</a>()</code>,
<code><a href="#topic+conditionalEval">conditionalEval</a>()</code>,
<code><a href="#topic+conditionalQuantile">conditionalQuantile</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## the example below is somewhat artificial --- assuming the observed
## values are given by NOx and the predicted values by NO2.

modStats(mydata, mod = "no2", obs = "nox")

## evaluation stats by season

modStats(mydata, mod = "no2", obs = "nox", type = "season")


</code></pre>

<hr>
<h2 id='mydata'>Example data for openair</h2><span id='topic+mydata'></span>

<h3>Description</h3>

<p>The mydata dataset is provided as an example dataset as part of the openair
package. The dataset contains hourly measurements of air pollutant
concentrations, wind speed and wind direction collected at the Marylebone
(London) air quality monitoring supersite between 1st January 1998 and 23rd
June 2005. The data set is a tibble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mydata
</code></pre>


<h3>Format</h3>

<p>Data frame with 65533 observations (rows) and 10 variables:
</p>

<dl>
<dt>date</dt><dd><p>Observation date/time stamp in year-month-day hour:minute:second
format (POSIXct).</p>
</dd>
<dt>ws</dt><dd><p>Wind speed, in m/s, as numeric vector.</p>
</dd>
<dt>wd</dt><dd><p>Wind direction, in degrees from North, as a numeric vector.</p>
</dd>
<dt>nox</dt><dd><p>Oxides of nitrogen concentration, in ppb, as a numeric vector.</p>
</dd>
<dt>no2</dt><dd><p>Nitrogen dioxide concentration, in ppb, as a numeric vector.</p>
</dd>
<dt>o3</dt><dd><p>Ozone concentration, in ppb, as a numeric vector.</p>
</dd>
<dt>pm10</dt><dd><p>Particulate PM10 fraction measurement, in ug/m3 (raw TEOM), as a
numeric vector.</p>
</dd>
<dt>so2</dt><dd><p>Sulfur dioxide concentration, in ppb, as a numeric vector.</p>
</dd>
<dt>co</dt><dd><p>Carbon monoxide concentration, in ppm, as a numeric vector.</p>
</dd>
<dt>pm25</dt><dd><p>Particulate PM2.5 fraction measurement, in ug/m3, as a numeric
vector.</p>
</dd>
</dl>



<h3>Details</h3>

<p><code>mydata</code> is supplied with the <code>openair</code> package as an example
dataset for use with documented examples.
</p>


<h3>Note</h3>

<p><code>openair</code> functions generally require data frames with a field
&quot;date&quot; that can be in either <code>POSIXct</code> or <code>Date</code> format
</p>


<h3>Source</h3>

<p><code>mydata</code> was compiled from data archived in the London Air
Quality Archive.  See <a href="https://www.londonair.org.uk">https://www.londonair.org.uk</a> for site details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#basic structure
head(mydata)
</code></pre>

<hr>
<h2 id='openColours'>Pre-defined openair colours and definition of user-defined colours</h2><span id='topic+openColours'></span>

<h3>Description</h3>

<p>This in primarily an internal openair function to make it easy for users to
select particular colour schemes, or define their own range of colours of a
user-defined length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>openColours(scheme = "default", n = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="openColours_+3A_scheme">scheme</code></td>
<td>
<p>Any one of the pre-defined <code>openair</code> schemes (e.g.,
<code>"increment"</code>) or a user-defined palette (e.g., <code>c("red", "orange", "gold")</code>). See <code>?openColours</code> for a full list of available schemes.</p>
</td></tr>
<tr><td><code id="openColours_+3A_n">n</code></td>
<td>
<p>number of colours required.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of hex codes
</p>


<h3>Schemes</h3>

<p>The following schemes are made available by <code>openColours()</code>:
</p>
<p><strong>Sequential Colours:</strong>
</p>

<ul>
<li><p> &quot;default&quot;, &quot;increment&quot;, &quot;brewer1&quot;, &quot;heat&quot;, &quot;jet&quot;, &quot;turbo&quot;, &quot;hue&quot;,
&quot;greyscale&quot;.
</p>
</li>
<li><p> Simplified versions of the <code>viridis</code> colours: &quot;viridis&quot;, &quot;plasma&quot;,
&quot;magma&quot;, &quot;inferno&quot;, &quot;cividis&quot;, and &quot;turbo&quot;.
</p>
</li>
<li><p> Simplified versions of the <code>RColorBrewer</code> sequential palettes: &quot;Blues&quot;, &quot;BuGn&quot;,
&quot;BuPu&quot;, &quot;GnBu&quot;, &quot;Greens&quot;, &quot;Greys&quot;, &quot;Oranges&quot;, &quot;OrRd&quot;, &quot;PuBu&quot;, &quot;PuBuGn&quot;,
&quot;PuRd&quot;, &quot;Purples&quot;, &quot;RdPu&quot;, &quot;Reds&quot;, &quot;YlGn&quot;, &quot;YlGnBu&quot;, &quot;YlOrBr&quot;, &quot;YlOrRd&quot;.
</p>
</li></ul>

<p><strong>Diverging Palettes:</strong>
</p>

<ul>
<li><p> Simplified versions of the <code>RColorBrewer</code> diverging palettes: &quot;BrBG&quot;,
&quot;PiYG&quot;, &quot;PRGn&quot;, &quot;PuOr&quot;, &quot;RdBu&quot;, &quot;RdGy&quot;, &quot;RdYlBu&quot;, &quot;RdYlGn&quot;, &quot;Spectral&quot;.
</p>
</li></ul>

<p><strong>Qualitative Palettes:</strong>
</p>

<ul>
<li><p> Simplified versions of the <code>RColorBrewer</code> qualitative palettes:
&quot;Accent&quot;, &quot;Dark2&quot;, &quot;Paired&quot;, &quot;Pastel1&quot;, &quot;Pastel2&quot;, &quot;Set1&quot;, &quot;Set2&quot;, &quot;Set3&quot;.
</p>
</li>
<li><p> &quot;cbPalette&quot;, a colour-blind safe palette based on the work of
<a href="https://www.nature.com/articles/nmeth.1618">https://www.nature.com/articles/nmeth.1618</a>
</p>
</li></ul>

<p><strong>UK Government Palettes:</strong>
</p>

<ul>
<li><p> &quot;daqi&quot; and &quot;daqi.bands&quot;, the colours associated with the UK daily air quality index; &quot;daqi&quot; (a palette of 10 colours, corresponding to each
index value) or &quot;daqi.bands&quot; (4 colours, corresponding to each band - Low,
Moderate, High, and Very High). These colours were taken directly from
<a href="https://uk-air.defra.gov.uk/air-pollution/daqi">https://uk-air.defra.gov.uk/air-pollution/daqi</a> and may be useful in
figures like <code><a href="#topic+calendarPlot">calendarPlot()</a></code>.
</p>
</li>
<li><p> &quot;gaf.cat&quot;, &quot;gaf.focus&quot; and &quot;gaf.seq&quot;, colours recommended by the UK Government Analysis function
(<a href="https://analysisfunction.civilservice.gov.uk/policy-store/data-visualisation-colours-in-charts/">https://analysisfunction.civilservice.gov.uk/policy-store/data-visualisation-colours-in-charts/</a>).
&quot;gaf.cat&quot; will return the 'categorical' palette (max 6 colours),
&quot;gaf.focus&quot; the 'focus' palette (max 2 colours), and &quot;gaf.seq&quot; the
'sequential' palette.
</p>
</li></ul>



<h3>Details</h3>

<p>Because of the way many of the schemes have been developed they only exist
over certain number of colour gradations (typically 3&ndash;10) &mdash; see
<code>?brewer.pal</code> for actual details. If less than or more than the required
number of colours is supplied then <code>openair</code> will interpolate the colours.
</p>
<p>Each of the pre-defined schemes have merits and their use will depend on a
particular situation. For showing incrementing concentrations, e.g., high
concentrations emphasised, then &quot;default&quot;, &quot;heat&quot;, &quot;jet&quot;, &quot;turbo&quot;, and
&quot;increment&quot; are very useful. See also the description of <code>RColorBrewer</code>
schemes for the option <code>scheme</code>.
</p>
<p>To colour-code categorical-type problems, e.g., colours for different
pollutants, &quot;hue&quot; and &quot;brewer1&quot; are useful.
</p>
<p>When publishing in black and white, &quot;greyscale&quot; is often convenient.  With
most openair functions, as well as generating a greyscale colour gradient,
it also resets strip background and other coloured text and lines to
greyscale values.
</p>
<p>Failing that, the user can define their own schemes based on R colour
names. To see the full list of names, type <code><a href="grDevices.html#topic+colors">colors()</a></code> into R.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>
<p>Jack Davison
</p>


<h3>References</h3>

<p><a href="https://colorbrewer2.org/">https://colorbrewer2.org/</a>
</p>
<p><a href="https://uk-air.defra.gov.uk/air-pollution/daqi">https://uk-air.defra.gov.uk/air-pollution/daqi</a>
</p>
<p><a href="https://analysisfunction.civilservice.gov.uk/policy-store/data-visualisation-colours-in-charts/">https://analysisfunction.civilservice.gov.uk/policy-store/data-visualisation-colours-in-charts/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# to return 5 colours from the "jet" scheme:
cols &lt;- openColours("jet", 5)
cols

# to interpolate between named colours e.g. 10 colours from yellow to
#  green to red:
cols &lt;- openColours(c("yellow", "green", "red"), 10)
cols

</code></pre>

<hr>
<h2 id='percentileRose'>Function to plot percentiles by wind direction</h2><span id='topic+percentileRose'></span>

<h3>Description</h3>

<p><code>percentileRose</code> plots percentiles by wind direction with flexible
conditioning. The plot can display multiple percentile lines or filled areas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentileRose(
  mydata,
  pollutant = "nox",
  wd = "wd",
  type = "default",
  percentile = c(25, 50, 75, 90, 95),
  smooth = FALSE,
  method = "default",
  cols = "default",
  angle = 10,
  mean = TRUE,
  mean.lty = 1,
  mean.lwd = 3,
  mean.col = "grey",
  fill = TRUE,
  intervals = NULL,
  angle.scale = 45,
  auto.text = TRUE,
  key.header = NULL,
  key.footer = "percentile",
  key.position = "bottom",
  key = TRUE,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentileRose_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>wd</code> and a numeric field
to plot &mdash; <code>pollutant</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>. More than one
pollutant can be supplied e.g. <code>pollutant = c("no2", "o3")</code> provided
there is only one <code>type</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_wd">wd</code></td>
<td>
<p>Name of wind direction field.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_percentile">percentile</code></td>
<td>
<p>The percentile value(s) to plot. Must be between 0&ndash;100. If
<code>percentile = NA</code> then only a mean line will be shown.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_smooth">smooth</code></td>
<td>
<p>Should the wind direction data be smoothed using a cyclic
spline?</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_method">method</code></td>
<td>
<p>When <code>method = "default"</code> the supplied percentiles by wind
direction are calculated. When <code>method = "cpf"</code> the conditional
probability function (CPF) is plotted and a single (usually high)
percentile level is supplied. The CPF is defined as CPF = my/ny, where my
is the number of samples in the wind sector y with mixing ratios greater
than the <em>overall</em> percentile concentration, and ny is the total
number of samples in the same wind sector (see Ashbaugh et al., 1985).</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_angle">angle</code></td>
<td>
<p>Default angle of &ldquo;spokes&rdquo; is when <code>smooth = FALSE</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_mean">mean</code></td>
<td>
<p>Show the mean by wind direction as a line?</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_mean.lty">mean.lty</code></td>
<td>
<p>Line type for mean line.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_mean.lwd">mean.lwd</code></td>
<td>
<p>Line width for mean line.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_mean.col">mean.col</code></td>
<td>
<p>Line colour for mean line.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_fill">fill</code></td>
<td>
<p>Should the percentile intervals be filled (default) or should
lines be drawn (<code>fill = FALSE</code>).</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_intervals">intervals</code></td>
<td>
<p>User-supplied intervals for the scale e.g. <code>intervals =
c(0, 10, 30, 50)</code></p>
</td></tr>
<tr><td><code id="percentileRose_+3A_angle.scale">angle.scale</code></td>
<td>
<p>Sometimes the placement of the scale may interfere with an
interesting feature. The user can therefore set <code>angle.scale</code> to any
value between 0 and 360 degrees to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_key.footer">key.footer</code></td>
<td>
<p>see <code>key.footer</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="percentileRose_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>percentileRose</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common graphical arguments, such as <code>xlim</code> and
<code>ylim</code> for plotting ranges and <code>lwd</code> for line thickness when
using <code>fill = FALSE</code>, are passed on <code>xyplot</code>, although some local
modifications may be applied by openair. For example, axis and title
labelling options (such as <code>xlab</code>, <code>ylab</code> and <code>main</code>) are
passed to <code>xyplot</code> via <code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>percentileRose</code> calculates percentile levels of a pollutant and plots
them by wind direction. One or more percentile levels can be calculated and
these are displayed as either filled areas or as lines.
</p>
<p>The wind directions are rounded to the nearest 10 degrees, consistent with
surface data from the UK Met Office before a smooth is fitted. The levels by
wind direction are optionally calculated using a cyclic smooth cubic spline
using the option <code>smooth</code>. If <code>smooth = FALSE</code> then the data are
shown in 10 degree sectors.
</p>
<p>The <code>percentileRose</code> function compliments other similar functions
including <code><a href="#topic+windRose">windRose</a></code>, <code><a href="#topic+pollutionRose">pollutionRose</a></code>,
<code><a href="#topic+polarFreq">polarFreq</a></code> or <code><a href="#topic+polarPlot">polarPlot</a></code>. It is most useful for
showing the distribution of concentrations by wind direction and often can
reveal different sources e.g. those that only affect high percentile
concentrations such as a chimney stack.
</p>
<p>Similar to other functions, flexible conditioning is available through the
<code>type</code> option. It is easy for example to consider multiple percentile
values for a pollutant by season, year and so on. See examples below.
</p>
<p><code>percentileRose</code> also offers great flexibility with the scale used and
the user has fine control over both the range, interval and colour.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Ashbaugh, L.L., Malm, W.C., Sadeh, W.Z., 1985. A residence time
probability analysis of sulfur concentrations at ground canyon national
park. Atmospheric Environment 19 (8), 1263-1270.
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># basic percentile plot
percentileRose(mydata, pollutant = "o3")

# 50/95th percentiles of ozone, with different colours
percentileRose(mydata, pollutant = "o3", percentile = c(50, 95), col = "brewer1")

## Not run: 
# percentiles of ozone by year, with different colours
percentileRose(mydata, type = "year", pollutant = "o3", col = "brewer1")

# percentile concentrations by season and day/nighttime..
percentileRose(mydata, type = c("season", "daylight"), pollutant = "o3", col = "brewer1")

## End(Not run)
</code></pre>

<hr>
<h2 id='polarAnnulus'>Bivariate polarAnnulus plot</h2><span id='topic+polarAnnulus'></span>

<h3>Description</h3>

<p>Typically plots the concentration of a pollutant by wind direction and as a
function of time as an annulus. The function is good for visualising how
concentrations of pollutants vary by wind direction and a time period e.g. by
month, day of week.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarAnnulus(
  mydata,
  pollutant = "nox",
  resolution = "fine",
  local.tz = NULL,
  period = "hour",
  type = "default",
  statistic = "mean",
  percentile = NA,
  limits = NULL,
  cols = "default",
  width = "normal",
  min.bin = 1,
  exclude.missing = TRUE,
  date.pad = FALSE,
  force.positive = TRUE,
  k = c(20, 10),
  normalise = FALSE,
  key.header = statistic,
  key.footer = pollutant,
  key.position = "right",
  key = TRUE,
  auto.text = TRUE,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarAnnulus_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>date</code>, <code>wd</code> and a
pollutant.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>. There can also
be more than one pollutant specified e.g. <code>pollutant = c("nox",
  "no2")</code>. The main use of using two or more pollutants is for model
evaluation where two species would be expected to have similar
concentrations. This saves the user stacking the data and it is possible to
work with columns of data directly. A typical use would be <code>pollutant
  = c("obs", "mod")</code> to compare two columns &ldquo;obs&rdquo; (the observations)
and &ldquo;mod&rdquo; (modelled values).</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_resolution">resolution</code></td>
<td>
<p>Two plot resolutions can be set: &ldquo;normal&rdquo; and
&ldquo;fine&rdquo; (the default).</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_local.tz">local.tz</code></td>
<td>
<p>Should the results be calculated in local time that includes
a treatment of daylight savings time (DST)? The default is not to consider
DST issues, provided the data were imported without a DST offset. Emissions
activity tends to occur at local time e.g. rush hour is at 8 am every day.
When the clocks go forward in spring, the emissions are effectively
released into the atmosphere typically 1 hour earlier during the summertime
i.e. when DST applies. When plotting diurnal profiles, this has the effect
of &ldquo;smearing-out&rdquo; the concentrations. Sometimes, a useful approach
is to express time as local time. This correction tends to produce
better-defined diurnal profiles of concentration (or other variables) and
allows a better comparison to be made with emissions/activity data. If set
to <code>FALSE</code> then GMT is used. Examples of usage include <code>local.tz
  = "Europe/London"</code>, <code>local.tz = "America/New_York"</code>. See
<code>cutData</code> and <code>import</code> for more details.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_period">period</code></td>
<td>
<p>This determines the temporal period to consider. Options are
&ldquo;hour&rdquo; (the default, to plot diurnal variations), &ldquo;season&rdquo; to
plot variation throughout the year, &ldquo;weekday&rdquo; to plot day of the
week variation and &ldquo;trend&rdquo; to plot the trend by wind direction.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "site")</code> will
produce a 2x2 plot split by season and site. The use of two types is mostly
meant for situations where there are several sites. Note, when two types
are provided the first forms the columns and the second the rows.
</p>
<p>Also note that for the <code>polarAnnulus</code> function some type/period
combinations are forbidden or make little sense. For example, <code>type =
  "season"</code> and <code>period = "trend"</code> (which would result in a plot with
too many gaps in it for sensible smoothing), or <code>type = "weekday"</code> and
<code>period = "weekday"</code>.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_statistic">statistic</code></td>
<td>
<p>The statistic that should be applied to each wind
speed/direction bin. Can be &ldquo;mean&rdquo; (default), &ldquo;median&rdquo;,
&ldquo;max&rdquo; (maximum), &ldquo;frequency&rdquo;. &ldquo;stdev&rdquo; (standard
deviation), &ldquo;weighted.mean&rdquo; or &ldquo;cpf&rdquo; (Conditional Probability
Function). Because of the smoothing involved, the colour scale for some of
these statistics is only to provide an indication of overall pattern and
should not be interpreted in concentration units e.g. for <code>statistic =
  "weighted.mean"</code> where the bin mean is multiplied by the bin frequency and
divided by the total frequency. In many cases using <code>polarFreq</code> will
be better. Setting <code>statistic = "weighted.mean"</code> can be useful because
it provides an indication of the concentration * frequency of occurrence
and will highlight the wind speed/direction conditions that dominate the
overall mean.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_percentile">percentile</code></td>
<td>
<p>If <code>statistic = "percentile"</code> or <code>statistic =
  "cpf"</code> then <code>percentile</code> is used, expressed from 0 to 100. Note that
the percentile value is calculated in the wind speed, wind direction
&lsquo;bins&rsquo;. For this reason it can also be useful to set <code>min.bin</code>
to ensure there are a sufficient number of points available to estimate a
percentile. See <code>quantile</code> for more details of how percentiles are
calculated.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_limits">limits</code></td>
<td>
<p>The function does its best to choose sensible limits
automatically. However, there are circumstances when the user will wish to
set different ones. An example would be a series of plots showing each year
of data separately. The limits are set in the form <code>c(lower, upper)</code>,
so <code>limits = c(0, 100)</code> would force the plot limits to span 0-100.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_width">width</code></td>
<td>
<p>The width of the annulus; can be &ldquo;normal&rdquo; (the default),
&ldquo;thin&rdquo; or &ldquo;fat&rdquo;.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_min.bin">min.bin</code></td>
<td>
<p>The minimum number of points allowed in a wind speed/wind
direction bin.  The default is 1. A value of two requires at least 2 valid
records in each bin an so on; bins with less than 2 valid records are set
to NA. Care should be taken when using a value &gt; 1 because of the risk of
removing real data points. It is recommended to consider your data with
care. Also, the <code>polarFreq</code> function can be of use in such
circumstances.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_exclude.missing">exclude.missing</code></td>
<td>
<p>Setting this option to <code>TRUE</code> (the default)
removes points from the plot that are too far from the original data. The
smoothing routines will produce predictions at points where no data exist
i.e. they predict. By removing the points too far from the original data
produces a plot where it is clear where the original data lie. If set to
<code>FALSE</code> missing data will be interpolated.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_date.pad">date.pad</code></td>
<td>
<p>For <code>type = "trend"</code> (default), <code>date.pad = TRUE</code>
will pad-out missing data to the beginning of the first year and the end of
the last year. The purpose is to ensure that the trend plot begins and ends
at the beginning or end of year.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_force.positive">force.positive</code></td>
<td>
<p>The default is <code>TRUE</code>. Sometimes if smoothing data
with steep gradients it is possible for predicted values to be negative.
<code>force.positive = TRUE</code> ensures that predictions remain positive. This
is useful for several reasons. First, with lots of missing data more
interpolation is needed and this can result in artefacts because the
predictions are too far from the original data. Second, if it is known
beforehand that the data are all positive, then this option carries that
assumption through to the prediction. The only likely time where setting
<code>force.positive = FALSE</code> would be if background concentrations were
first subtracted resulting in data that is legitimately negative. For the
vast majority of situations it is expected that the user will not need to
alter the default option.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_k">k</code></td>
<td>
<p>The smoothing value supplied to <code>gam</code> for the temporal and wind
direction components, respectively. In some cases e.g. a trend plot with
less than 1-year of data the smoothing with the default values may become
too noisy and affected more by outliers. Choosing a lower value of <code>k</code>
(say 10) may help produce a better plot.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_normalise">normalise</code></td>
<td>
<p>If <code>TRUE</code> concentrations are normalised by dividing by
their mean value. This is done <em>after</em> fitting the smooth surface.
This option is particularly useful if one is interested in the patterns of
concentrations for several pollutants on different scales e.g. NOx and CO.
Often useful if more than one <code>pollutant</code> is chosen.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_key.footer">key.footer</code></td>
<td>
<p>see <code>key.footer</code>.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="polarAnnulus_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:levelplot</code>
and <code>cutData</code>. For example, <code>polarAnnulus</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>levelplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>polarAnnulus</code> function shares many of the properties of the
<code>polarPlot</code>. However, <code>polarAnnulus</code> is focussed on displaying
information on how concentrations of a pollutant (values of another variable)
vary with wind direction and time. Plotting as an annulus helps to reduce
compression of information towards the centre of the plot. The circular plot
is easy to interpret because wind direction is most easily understood in
polar rather than Cartesian coordinates.
</p>
<p>The inner part of the annulus represents the earliest time and the outer part
of the annulus the latest time. The time dimension can be shown in many ways
including &quot;trend&quot;, &quot;hour&quot; (hour or day), &quot;season&quot; (month of the year) and
&quot;weekday&quot; (day of the week). Taking hour as an example, the plot will show
how concentrations vary by hour of the day and wind direction. Such plots can
be very useful for understanding how different source influences affect a
location.
</p>
<p>For <code>type = "trend"</code> the amount of smoothing does not vary linearly with
the length of the time series i.e. a certain amount of smoothing per unit
interval in time. This is a deliberate choice because should one be
interested in a subset (in time) of data, more detail will be provided for
the subset compared with the full data set. This allows users to investigate
specific periods in more detail. Full flexibility is given through the
smoothing parameter <code>k</code>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># diurnal plot for PM10 at Marylebone Rd
## Not run: polarAnnulus(mydata, pollutant = "pm10",
main = "diurnal variation in pm10 at Marylebone Road")
## End(Not run)

# seasonal plot for PM10 at Marylebone Rd
## Not run: polarAnnulus(mydata, poll="pm10", period = "season")

# trend in coarse particles (PMc = PM10 - PM2.5), calculate PMc first

mydata$pmc &lt;- mydata$pm10 - mydata$pm25
## Not run: polarAnnulus(mydata, poll="pmc", period = "trend",
main = "trend in pmc at Marylebone Road")
## End(Not run)
</code></pre>

<hr>
<h2 id='polarCluster'>K-means clustering of bivariate polar plots</h2><span id='topic+polarCluster'></span>

<h3>Description</h3>

<p>Function for identifying clusters in bivariate polar plots (<code><a href="#topic+polarPlot">polarPlot()</a></code>);
identifying clusters in the original data for subsequent processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarCluster(
  mydata,
  pollutant = "nox",
  x = "ws",
  wd = "wd",
  n.clusters = 6,
  after = NA,
  cols = "Paired",
  angle.scale = 315,
  units = x,
  auto.text = TRUE,
  plot = TRUE,
  plot.data = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarCluster_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>wd</code>, another variable
to plot in polar coordinates (the default is a column &ldquo;ws&rdquo; &mdash; wind
speed) and a pollutant. Should also contain <code>date</code> if plots by time
period are required.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>. Only one
pollutant can be chosen.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_x">x</code></td>
<td>
<p>Name of variable to plot against wind direction in polar
coordinates, the default is wind speed, &ldquo;ws&rdquo;.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_wd">wd</code></td>
<td>
<p>Name of wind direction field.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_n.clusters">n.clusters</code></td>
<td>
<p>Number of clusters to use. If <code>n.clusters</code> is more
than length 1, then a <code>lattice</code> panel plot will be output showing the
clusters identified for each one of <code>n.clusters</code>.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_after">after</code></td>
<td>
<p>The function can be applied to differences between polar plot
surfaces (see <a href="#topic+polarDiff">polarDiff</a> for details). If an <code>after</code> data frame
is supplied, the clustering will be carried out on the differences between
<code>after</code> and <code>mydata</code> in the same way as <a href="#topic+polarDiff">polarDiff</a>.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_angle.scale">angle.scale</code></td>
<td>
<p>Sometimes the placement of the scale may interfere with an
interesting feature. The user can therefore set <code>angle.scale</code> to any
value between 0 and 360 degrees to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_units">units</code></td>
<td>
<p>The units shown on the polar axis scale.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_plot.data">plot.data</code></td>
<td>
<p>By default, the <code>data</code> component of <code>polarCluster()</code>
contains the original data frame appended with a new &quot;cluster&quot; column. When
<code>plot.data = TRUE</code>, the <code>data</code> component instead contains data to reproduce
the clustered polar plot itself (similar to <code>data</code> returned by
<code><a href="#topic+polarPlot">polarPlot()</a></code>). This may be useful for re-plotting the <code>polarCluster()</code>
plot in other ways.</p>
</td></tr>
<tr><td><code id="polarCluster_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+polarPlot">polarPlot</a></code>
</p>

<dl>
<dt><code>type</code></dt><dd><p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</dd>
<dt><code>statistic</code></dt><dd><p>The statistic that should be applied to each wind
speed/direction bin. Because of the smoothing involved, the colour scale
for some of these statistics is only to provide an indication of overall
pattern and should not be interpreted in concentration units e.g. for
<code>statistic = "weighted.mean"</code> where the bin mean is multiplied by the
bin frequency and divided by the total frequency. In many cases using
<code>polarFreq</code> will be better. Setting <code>statistic = "weighted.mean"</code>
can be useful because it provides an indication of the concentration *
frequency of occurrence and will highlight the wind speed/direction
conditions that dominate the overall mean.Can be:
</p>
 <ul>
<li>  <p>&ldquo;mean&rdquo; (default), &ldquo;median&rdquo;, &ldquo;max&rdquo;
(maximum), &ldquo;frequency&rdquo;. &ldquo;stdev&rdquo; (standard deviation),
&ldquo;weighted.mean&rdquo;.
</p>
</li>
<li> <p><code>statistic = "nwr"</code> Implements the Non-parametric Wind
Regression approach of Henry et al. (2009) that uses kernel smoothers. The
<code>openair</code> implementation is not identical because Gaussian kernels are
used for both wind direction and speed. The smoothing is controlled by
<code>ws_spread</code> and <code>wd_spread</code>.
</p>
</li>
<li> <p><code>statistic = "cpf"</code> the conditional probability function (CPF)
is plotted and a single (usually high) percentile level is supplied. The
CPF is defined as CPF = my/ny, where my is the number of samples in the y
bin (by default a wind direction, wind speed interval) with mixing ratios
greater than the <em>overall</em> percentile concentration, and ny is the
total number of samples in the same wind sector (see Ashbaugh et al.,
1985). Note that percentile intervals can also be considered; see
<code>percentile</code> for details.
</p>
</li>
<li><p> When <code>statistic = "r"</code> or <code>statistic = "Pearson"</code>, the
Pearson correlation coefficient is calculated for <em>two</em> pollutants.
The calculation involves a weighted Pearson correlation coefficient, which
is weighted by Gaussian kernels for wind direction an the radial variable
(by default wind speed). More weight is assigned to values close to a wind
speed-direction interval. Kernel weighting is used to ensure that all data
are used rather than relying on the potentially small number of values in a
wind speed-direction interval.
</p>
</li>
<li><p> When <code>statistic = "Spearman"</code>, the Spearman correlation
coefficient is calculated for <em>two</em> pollutants. The calculation
involves a weighted Spearman correlation coefficient, which is weighted by
Gaussian kernels for wind direction an the radial variable (by default wind
speed). More weight is assigned to values close to a wind speed-direction
interval. Kernel weighting is used to ensure that all data are used rather
than relying on the potentially small number of values in a wind
speed-direction interval.
</p>
</li>
<li> <p><code>"robust_slope"</code> is another option for pair-wise statistics and
<code>"quantile.slope"</code>, which uses quantile regression to estimate the
slope for a particular quantile level (see also <code>tau</code> for setting the
quantile level).
</p>
</li>
<li> <p><code>"york_slope"</code> is another option for pair-wise statistics which
uses the <em>York regression method</em> to estimate the slope. In this
method the uncertainties in <code>x</code> and <code>y</code> are used in the
determination of the slope. The uncertainties are provided by
<code>x_error</code> and <code>y_error</code> &mdash; see below.</p>
</li></ul>
</dd>
<dt><code>limits</code></dt><dd><p>The function does its best to choose sensible limits
automatically. However, there are circumstances when the user will wish to
set different ones. An example would be a series of plots showing each year
of data separately. The limits are set in the form <code>c(lower, upper)</code>,
so <code>limits = c(0, 100)</code> would force the plot limits to span 0-100.</p>
</dd>
<dt><code>exclude.missing</code></dt><dd><p>Setting this option to <code>TRUE</code> (the default)
removes points from the plot that are too far from the original data. The
smoothing routines will produce predictions at points where no data exist
i.e. they predict. By removing the points too far from the original data
produces a plot where it is clear where the original data lie. If set to
<code>FALSE</code> missing data will be interpolated.</p>
</dd>
<dt><code>uncertainty</code></dt><dd><p>Should the uncertainty in the calculated surface be shown?
If <code>TRUE</code> three plots are produced on the same scale showing the
predicted surface together with the estimated lower and upper uncertainties
at the 95% confidence interval. Calculating the uncertainties is useful to
understand whether features are real or not.  For example, at high wind
speeds where there are few data there is greater uncertainty over the
predicted values. The uncertainties are calculated using the GAM and
weighting is done by the frequency of measurements in each wind
speed-direction bin. Note that if uncertainties are calculated then the
type is set to &quot;default&quot;.</p>
</dd>
<dt><code>percentile</code></dt><dd><p>If <code>statistic = "percentile"</code> then <code>percentile</code>
is used, expressed from 0 to 100. Note that the percentile value is
calculated in the wind speed, wind direction &lsquo;bins&rsquo;. For this reason
it can also be useful to set <code>min.bin</code> to ensure there are a
sufficient number of points available to estimate a percentile. See
<code>quantile</code> for more details of how percentiles are calculated.
</p>
<p><code>percentile</code> is also used for the Conditional Probability Function
(CPF) plots. <code>percentile</code> can be of length two, in which case the
percentile <em>interval</em> is considered for use with CPF. For example,
<code>percentile = c(90, 100)</code> will plot the CPF for concentrations between
the 90 and 100th percentiles. Percentile intervals can be useful for
identifying specific sources. In addition, <code>percentile</code> can also be of
length 3. The third value is the &lsquo;trim&rsquo; value to be applied. When
calculating percentile intervals many can cover very low values where there
is no useful information. The trim value ensures that values greater than
or equal to the trim * mean value are considered <em>before</em> the
percentile intervals are calculated. The effect is to extract more detail
from many source signatures. See the manual for examples. Finally, if the
trim value is less than zero the percentile range is interpreted as
absolute concentration values and subsetting is carried out directly.</p>
</dd>
<dt><code>weights</code></dt><dd><p>At the edges of the plot there may only be a few data points
in each wind speed-direction interval, which could in some situations
distort the plot if the concentrations are high. <code>weights</code> applies a
weighting to reduce their influence. For example and by default if only a
single data point exists then the weighting factor is 0.25 and for two
points 0.5. To not apply any weighting and use the data as is, use
<code>weights = c(1, 1, 1)</code>.
</p>
<p>An alternative to down-weighting these points they can be removed
altogether using <code>min.bin</code>.</p>
</dd>
<dt><code>min.bin</code></dt><dd><p>The minimum number of points allowed in a wind speed/wind
direction bin.  The default is 1. A value of two requires at least 2 valid
records in each bin an so on; bins with less than 2 valid records are set
to NA. Care should be taken when using a value &gt; 1 because of the risk of
removing real data points. It is recommended to consider your data with
care. Also, the <code>polarFreq</code> function can be of use in such
circumstances.</p>
</dd>
<dt><code>mis.col</code></dt><dd><p>When <code>min.bin</code> is &gt; 1 it can be useful to show where data
are removed on the plots. This is done by shading the missing data in
<code>mis.col</code>. To not highlight missing data when <code>min.bin</code> &gt; 1
choose <code>mis.col = "transparent"</code>.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</dd>
<dt><code>upper</code></dt><dd><p>This sets the upper limit wind speed to be used. Often there are
only a relatively few data points at very high wind speeds and plotting all
of them can reduce the useful information in the plot.</p>
</dd>
<dt><code>force.positive</code></dt><dd><p>The default is <code>TRUE</code>. Sometimes if smoothing data
with steep gradients it is possible for predicted values to be negative.
<code>force.positive = TRUE</code> ensures that predictions remain positive. This
is useful for several reasons. First, with lots of missing data more
interpolation is needed and this can result in artefacts because the
predictions are too far from the original data. Second, if it is known
beforehand that the data are all positive, then this option carries that
assumption through to the prediction. The only likely time where setting
<code>force.positive = FALSE</code> would be if background concentrations were
first subtracted resulting in data that is legitimately negative. For the
vast majority of situations it is expected that the user will not need to
alter the default option.</p>
</dd>
<dt><code>k</code></dt><dd><p>This is the smoothing parameter used by the <code>gam</code> function in
package <code>mgcv</code>. Typically, value of around 100 (the default) seems to
be suitable and will resolve important features in the plot. The most
appropriate choice of <code>k</code> is problem-dependent; but extensive testing
of polar plots for many different problems suggests a value of <code>k</code> of
about 100 is suitable. Setting <code>k</code> to higher values will not tend to
affect the surface predictions by much but will add to the computation
time. Lower values of <code>k</code> will increase smoothing. Sometimes with few
data to plot <code>polarPlot</code> will fail. Under these circumstances it can
be worth lowering the value of <code>k</code>.</p>
</dd>
<dt><code>normalise</code></dt><dd><p>If <code>TRUE</code> concentrations are normalised by dividing by
their mean value. This is done <em>after</em> fitting the smooth surface.
This option is particularly useful if one is interested in the patterns of
concentrations for several pollutants on different scales e.g. NOx and CO.
Often useful if more than one <code>pollutant</code> is chosen.</p>
</dd>
<dt><code>key.header</code></dt><dd><p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</dd>
<dt><code>key.footer</code></dt><dd><p>see <code>key.footer</code>.</p>
</dd>
<dt><code>key.position</code></dt><dd><p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</dd>
<dt><code>key</code></dt><dd><p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</dd>
<dt><code>ws_spread</code></dt><dd><p>The value of sigma used for Gaussian kernel weighting of
wind speed when <code>statistic = "nwr"</code> or when correlation and regression
statistics are used such as <em>r</em>. Default is <code>0.5</code>.</p>
</dd>
<dt><code>wd_spread</code></dt><dd><p>The value of sigma used for Gaussian kernel weighting of
wind direction when <code>statistic = "nwr"</code> or when correlation and
regression statistics are used such as <em>r</em>. Default is <code>4</code>.</p>
</dd>
<dt><code>x_error</code></dt><dd><p>The <code>x</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</dd>
<dt><code>y_error</code></dt><dd><p>The <code>y</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</dd>
<dt><code>kernel</code></dt><dd><p>Type of kernel used for the weighting procedure for when
correlation or regression techniques are used. Only <code>"gaussian"</code> is
supported but this may be enhanced in the future.</p>
</dd>
<dt><code>formula.label</code></dt><dd><p>When pair-wise statistics such as regression slopes are
calculated and plotted, should a formula label be displayed?</p>
</dd>
<dt><code>tau</code></dt><dd><p>The quantile to be estimated when <code>statistic</code> is set to
<code>"quantile.slope"</code>. Default is <code>0.5</code> which is equal to the median
and will be ignored if <code>"quantile.slope"</code> is not used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Bivariate polar plots generated using the <code>polarPlot</code> function provide a
very useful graphical technique for identifying and characterising different
air pollution sources. While bivariate polar plots provide a useful graphical
indication of potential sources, their location and wind-speed or other
variable dependence, they do have several limitations. Often, a &lsquo;feature&rsquo;
will be detected in a plot but the subsequent analysis of data meeting
particular wind speed/direction criteria will be based only on the judgement
of the investigator concerning the wind speed-direction intervals of
interest. Furthermore, the identification of a feature can depend on the
choice of the colour scale used, making the process somewhat arbitrary.
</p>
<p><code>polarCluster</code> applies Partition Around Medoids (PAM) clustering
techniques to <code><a href="#topic+polarPlot">polarPlot()</a></code> surfaces to help identify potentially interesting
features for further analysis. Details of PAM can be found in the
<code>cluster</code> package (a core R package that will be pre-installed on all R
systems). PAM clustering is similar to k-means but has several advantages
e.g. is more robust to outliers. The clustering is based on the equal
contribution assumed from the u and v wind components and the associated
concentration. The data are standardized before clustering takes place.
</p>
<p>The function works best by first trying different numbers of clusters and
plotting them. This is achieved by setting <code>n.clusters</code> to be of length
more than 1. For example, if <code>n.clusters = 2:10</code> then a plot will be
output showing the 9 cluster levels 2 to 10.
</p>
<p>The clustering can also be applied to differences in polar plot surfaces (see
<code><a href="#topic+polarDiff">polarDiff()</a></code>). On this case a second data frame (<code>after</code>) should be
supplied.
</p>
<p>Note that clustering is computationally intensive and the function can take a
long time to run &mdash; particularly when the number of clusters is increased.
For this reason it can be a good idea to run a few clusters first to get a
feel for it e.g. <code>n.clusters = 2:5</code>.
</p>
<p>Once the number of clusters has been decided, the user can then run
<code>polarCluster</code> to return the original data frame together with a new
column <code>cluster</code>, which gives the cluster number as a character (see
example). Note that any rows where the value of <code>pollutant</code> is <code>NA</code>
are ignored so that the returned data frame may have fewer rows than the
original.
</p>
<p>Note that there are no automatic ways in ensuring the most appropriate number
of clusters as this is application dependent. However, there is often
a-priori information available on what different features in polar plots
correspond to. Nevertheless, the appropriateness of different clusters is
best determined by post-processing the data. The Carslaw and Beevers (2012)
paper discusses these issues in more detail.
</p>
<p>Note that unlike most other <code>openair</code> functions only a single
<code>type</code> &ldquo;default&rdquo; is allowed.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. The object includes four main
components: <code>call</code>, the command used to generate the plot;
<code>data</code>, by default the original data frame with a new field
<code>cluster</code> identifying the cluster, <code>clust_stats</code> giving the
contributions made by each cluster to number of measurements, their
percentage and the percentage by pollutant; and <code>plot</code>, the plot
itself. Note that any rows where the value of <code>pollutant</code> is <code>NA</code>
are ignored so that the returned data frame may have fewer rows than the
original.
</p>
<p>If the clustering is carried out considering differences, i.e., an
<code>after</code> data frame is supplied, the output also includes the
<code>after</code> data frame with cluster identified.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Carslaw, D.C., Beevers, S.D, Ropkins, K and M.C. Bell (2006). Detecting and
quantifying aircraft and other on-airport contributions to ambient nitrogen
oxides in the vicinity of a large international airport.  Atmospheric
Environment. 40/28 pp 5424-5434.
</p>
<p>Carslaw, D.C., &amp; Beevers, S.D. (2013). Characterising and understanding
emission sources using bivariate polar plots and k-means clustering.
Environmental Modelling &amp; Software, 40, 325-329.
doi:10.1016/j.envsoft.2012.09.005
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>
<p>Other cluster analysis functions: 
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+trajCluster">trajCluster</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## plot 2-8 clusters. Warning! This can take several minutes...
polarCluster(mydata, pollutant = "nox", n.clusters = 2:8)

# basic plot with 6 clusters
results &lt;- polarCluster(mydata, pollutant = "nox", n.clusters = 6)

## get results, could read into a new data frame to make it easier to refer to
## e.g. results &lt;- results$data...
head(results$data)

## how many points are there in each cluster?
table(results$data$cluster)

## plot clusters 3 and 4 as a timeVariation plot using SAME colours as in
## cluster plot
timeVariation(subset(results$data, cluster %in% c("3", "4")),
  pollutant = "nox",
  group = "cluster", col = openColours("Paired", 6)[c(3, 4)]
)

## End(Not run)

</code></pre>

<hr>
<h2 id='polarDiff'>Polar plots considering changes in concentrations between two time periods</h2><span id='topic+polarDiff'></span>

<h3>Description</h3>

<p>This function provides a way of showing the differences in concentrations
between two time periods as a polar plot. There are several uses of this
function, but the most common will be to see how source(s) may have changed
between two periods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarDiff(
  before,
  after,
  pollutant = "nox",
  x = "ws",
  limits = NULL,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarDiff_+3A_before">before</code></td>
<td>
<p>A data frame that represents the &quot;before&quot; case. See
<code><a href="#topic+polarPlot">polarPlot()</a></code> for details of different input requirements.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_after">after</code></td>
<td>
<p>A data frame that represents the &quot;after&quot; case. See <code><a href="#topic+polarPlot">polarPlot()</a></code>
for details of different input requirements.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>. There can also
be more than one pollutant specified e.g. <code>pollutant = c("nox",
  "no2")</code>. The main use of using two or more pollutants is for model
evaluation where two species would be expected to have similar
concentrations. This saves the user stacking the data and it is possible to
work with columns of data directly. A typical use would be <code>pollutant
  = c("obs", "mod")</code> to compare two columns &ldquo;obs&rdquo; (the observations)
and &ldquo;mod&rdquo; (modelled values). When pair-wise statistics such as
Pearson correlation and regression techniques are to be plotted,
<code>pollutant</code> takes two elements too. For example, <code>pollutant =
  c("bc", "pm25")</code> where <code>"bc"</code> is a function of <code>"pm25"</code>.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_x">x</code></td>
<td>
<p>Name of variable to plot against wind direction in polar
coordinates, the default is wind speed, &ldquo;ws&rdquo;.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_limits">limits</code></td>
<td>
<p>The function does its best to choose sensible limits
automatically. However, there are circumstances when the user will wish to
set different ones. An example would be a series of plots showing each year
of data separately. The limits are set in the form <code>c(lower, upper)</code>,
so <code>limits = c(0, 100)</code> would force the plot limits to span 0-100.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="polarDiff_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+polarPlot">polarPlot</a></code>
</p>

<dl>
<dt><code>mydata</code></dt><dd><p>A data frame minimally containing <code>wd</code>, another variable
to plot in polar coordinates (the default is a column &ldquo;ws&rdquo; &mdash; wind
speed) and a pollutant. Should also contain <code>date</code> if plots by time
period are required.</p>
</dd>
<dt><code>wd</code></dt><dd><p>Name of wind direction field.</p>
</dd>
<dt><code>type</code></dt><dd><p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</dd>
<dt><code>statistic</code></dt><dd><p>The statistic that should be applied to each wind
speed/direction bin. Because of the smoothing involved, the colour scale
for some of these statistics is only to provide an indication of overall
pattern and should not be interpreted in concentration units e.g. for
<code>statistic = "weighted.mean"</code> where the bin mean is multiplied by the
bin frequency and divided by the total frequency. In many cases using
<code>polarFreq</code> will be better. Setting <code>statistic = "weighted.mean"</code>
can be useful because it provides an indication of the concentration *
frequency of occurrence and will highlight the wind speed/direction
conditions that dominate the overall mean.Can be:
</p>
 <ul>
<li>  <p>&ldquo;mean&rdquo; (default), &ldquo;median&rdquo;, &ldquo;max&rdquo;
(maximum), &ldquo;frequency&rdquo;. &ldquo;stdev&rdquo; (standard deviation),
&ldquo;weighted.mean&rdquo;.
</p>
</li>
<li> <p><code>statistic = "nwr"</code> Implements the Non-parametric Wind
Regression approach of Henry et al. (2009) that uses kernel smoothers. The
<code>openair</code> implementation is not identical because Gaussian kernels are
used for both wind direction and speed. The smoothing is controlled by
<code>ws_spread</code> and <code>wd_spread</code>.
</p>
</li>
<li> <p><code>statistic = "cpf"</code> the conditional probability function (CPF)
is plotted and a single (usually high) percentile level is supplied. The
CPF is defined as CPF = my/ny, where my is the number of samples in the y
bin (by default a wind direction, wind speed interval) with mixing ratios
greater than the <em>overall</em> percentile concentration, and ny is the
total number of samples in the same wind sector (see Ashbaugh et al.,
1985). Note that percentile intervals can also be considered; see
<code>percentile</code> for details.
</p>
</li>
<li><p> When <code>statistic = "r"</code> or <code>statistic = "Pearson"</code>, the
Pearson correlation coefficient is calculated for <em>two</em> pollutants.
The calculation involves a weighted Pearson correlation coefficient, which
is weighted by Gaussian kernels for wind direction an the radial variable
(by default wind speed). More weight is assigned to values close to a wind
speed-direction interval. Kernel weighting is used to ensure that all data
are used rather than relying on the potentially small number of values in a
wind speed-direction interval.
</p>
</li>
<li><p> When <code>statistic = "Spearman"</code>, the Spearman correlation
coefficient is calculated for <em>two</em> pollutants. The calculation
involves a weighted Spearman correlation coefficient, which is weighted by
Gaussian kernels for wind direction an the radial variable (by default wind
speed). More weight is assigned to values close to a wind speed-direction
interval. Kernel weighting is used to ensure that all data are used rather
than relying on the potentially small number of values in a wind
speed-direction interval.
</p>
</li>
<li> <p><code>"robust_slope"</code> is another option for pair-wise statistics and
<code>"quantile.slope"</code>, which uses quantile regression to estimate the
slope for a particular quantile level (see also <code>tau</code> for setting the
quantile level).
</p>
</li>
<li> <p><code>"york_slope"</code> is another option for pair-wise statistics which
uses the <em>York regression method</em> to estimate the slope. In this
method the uncertainties in <code>x</code> and <code>y</code> are used in the
determination of the slope. The uncertainties are provided by
<code>x_error</code> and <code>y_error</code> &mdash; see below.</p>
</li></ul>
</dd>
<dt><code>exclude.missing</code></dt><dd><p>Setting this option to <code>TRUE</code> (the default)
removes points from the plot that are too far from the original data. The
smoothing routines will produce predictions at points where no data exist
i.e. they predict. By removing the points too far from the original data
produces a plot where it is clear where the original data lie. If set to
<code>FALSE</code> missing data will be interpolated.</p>
</dd>
<dt><code>uncertainty</code></dt><dd><p>Should the uncertainty in the calculated surface be shown?
If <code>TRUE</code> three plots are produced on the same scale showing the
predicted surface together with the estimated lower and upper uncertainties
at the 95% confidence interval. Calculating the uncertainties is useful to
understand whether features are real or not.  For example, at high wind
speeds where there are few data there is greater uncertainty over the
predicted values. The uncertainties are calculated using the GAM and
weighting is done by the frequency of measurements in each wind
speed-direction bin. Note that if uncertainties are calculated then the
type is set to &quot;default&quot;.</p>
</dd>
<dt><code>percentile</code></dt><dd><p>If <code>statistic = "percentile"</code> then <code>percentile</code>
is used, expressed from 0 to 100. Note that the percentile value is
calculated in the wind speed, wind direction &lsquo;bins&rsquo;. For this reason
it can also be useful to set <code>min.bin</code> to ensure there are a
sufficient number of points available to estimate a percentile. See
<code>quantile</code> for more details of how percentiles are calculated.
</p>
<p><code>percentile</code> is also used for the Conditional Probability Function
(CPF) plots. <code>percentile</code> can be of length two, in which case the
percentile <em>interval</em> is considered for use with CPF. For example,
<code>percentile = c(90, 100)</code> will plot the CPF for concentrations between
the 90 and 100th percentiles. Percentile intervals can be useful for
identifying specific sources. In addition, <code>percentile</code> can also be of
length 3. The third value is the &lsquo;trim&rsquo; value to be applied. When
calculating percentile intervals many can cover very low values where there
is no useful information. The trim value ensures that values greater than
or equal to the trim * mean value are considered <em>before</em> the
percentile intervals are calculated. The effect is to extract more detail
from many source signatures. See the manual for examples. Finally, if the
trim value is less than zero the percentile range is interpreted as
absolute concentration values and subsetting is carried out directly.</p>
</dd>
<dt><code>cols</code></dt><dd><p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</dd>
<dt><code>weights</code></dt><dd><p>At the edges of the plot there may only be a few data points
in each wind speed-direction interval, which could in some situations
distort the plot if the concentrations are high. <code>weights</code> applies a
weighting to reduce their influence. For example and by default if only a
single data point exists then the weighting factor is 0.25 and for two
points 0.5. To not apply any weighting and use the data as is, use
<code>weights = c(1, 1, 1)</code>.
</p>
<p>An alternative to down-weighting these points they can be removed
altogether using <code>min.bin</code>.</p>
</dd>
<dt><code>min.bin</code></dt><dd><p>The minimum number of points allowed in a wind speed/wind
direction bin.  The default is 1. A value of two requires at least 2 valid
records in each bin an so on; bins with less than 2 valid records are set
to NA. Care should be taken when using a value &gt; 1 because of the risk of
removing real data points. It is recommended to consider your data with
care. Also, the <code>polarFreq</code> function can be of use in such
circumstances.</p>
</dd>
<dt><code>mis.col</code></dt><dd><p>When <code>min.bin</code> is &gt; 1 it can be useful to show where data
are removed on the plots. This is done by shading the missing data in
<code>mis.col</code>. To not highlight missing data when <code>min.bin</code> &gt; 1
choose <code>mis.col = "transparent"</code>.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</dd>
<dt><code>upper</code></dt><dd><p>This sets the upper limit wind speed to be used. Often there are
only a relatively few data points at very high wind speeds and plotting all
of them can reduce the useful information in the plot.</p>
</dd>
<dt><code>angle.scale</code></dt><dd><p>Sometimes the placement of the scale may interfere with an
interesting feature. The user can therefore set <code>angle.scale</code> to any
value between 0 and 360 degrees to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</dd>
<dt><code>units</code></dt><dd><p>The units shown on the polar axis scale.</p>
</dd>
<dt><code>force.positive</code></dt><dd><p>The default is <code>TRUE</code>. Sometimes if smoothing data
with steep gradients it is possible for predicted values to be negative.
<code>force.positive = TRUE</code> ensures that predictions remain positive. This
is useful for several reasons. First, with lots of missing data more
interpolation is needed and this can result in artefacts because the
predictions are too far from the original data. Second, if it is known
beforehand that the data are all positive, then this option carries that
assumption through to the prediction. The only likely time where setting
<code>force.positive = FALSE</code> would be if background concentrations were
first subtracted resulting in data that is legitimately negative. For the
vast majority of situations it is expected that the user will not need to
alter the default option.</p>
</dd>
<dt><code>k</code></dt><dd><p>This is the smoothing parameter used by the <code>gam</code> function in
package <code>mgcv</code>. Typically, value of around 100 (the default) seems to
be suitable and will resolve important features in the plot. The most
appropriate choice of <code>k</code> is problem-dependent; but extensive testing
of polar plots for many different problems suggests a value of <code>k</code> of
about 100 is suitable. Setting <code>k</code> to higher values will not tend to
affect the surface predictions by much but will add to the computation
time. Lower values of <code>k</code> will increase smoothing. Sometimes with few
data to plot <code>polarPlot</code> will fail. Under these circumstances it can
be worth lowering the value of <code>k</code>.</p>
</dd>
<dt><code>normalise</code></dt><dd><p>If <code>TRUE</code> concentrations are normalised by dividing by
their mean value. This is done <em>after</em> fitting the smooth surface.
This option is particularly useful if one is interested in the patterns of
concentrations for several pollutants on different scales e.g. NOx and CO.
Often useful if more than one <code>pollutant</code> is chosen.</p>
</dd>
<dt><code>key.header</code></dt><dd><p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</dd>
<dt><code>key.footer</code></dt><dd><p>see <code>key.footer</code>.</p>
</dd>
<dt><code>key.position</code></dt><dd><p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</dd>
<dt><code>key</code></dt><dd><p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</dd>
<dt><code>auto.text</code></dt><dd><p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</dd>
<dt><code>ws_spread</code></dt><dd><p>The value of sigma used for Gaussian kernel weighting of
wind speed when <code>statistic = "nwr"</code> or when correlation and regression
statistics are used such as <em>r</em>. Default is <code>0.5</code>.</p>
</dd>
<dt><code>wd_spread</code></dt><dd><p>The value of sigma used for Gaussian kernel weighting of
wind direction when <code>statistic = "nwr"</code> or when correlation and
regression statistics are used such as <em>r</em>. Default is <code>4</code>.</p>
</dd>
<dt><code>x_error</code></dt><dd><p>The <code>x</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</dd>
<dt><code>y_error</code></dt><dd><p>The <code>y</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</dd>
<dt><code>kernel</code></dt><dd><p>Type of kernel used for the weighting procedure for when
correlation or regression techniques are used. Only <code>"gaussian"</code> is
supported but this may be enhanced in the future.</p>
</dd>
<dt><code>formula.label</code></dt><dd><p>When pair-wise statistics such as regression slopes are
calculated and plotted, should a formula label be displayed?</p>
</dd>
<dt><code>tau</code></dt><dd><p>The quantile to be estimated when <code>statistic</code> is set to
<code>"quantile.slope"</code>. Default is <code>0.5</code> which is equal to the median
and will be ignored if <code>"quantile.slope"</code> is not used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>While the function is primarily intended to compare two time periods at the
same location, it can be used for any two data sets that contain the same
pollutant. For example, data from two sites that are close to one another, or
two co-located instruments.
</p>
<p>The analysis works by calculating the polar plot surface for the
<code>before</code> and <code>after</code> periods and then subtracting the <code>before</code>
surface from the <code>after</code> surface.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> plot.
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

before_data &lt;- selectByDate(mydata, year = 2002)
after_data &lt;- selectByDate(mydata, year = 2003)

polarDiff(before_data, after_data, pollutant = "no2")

# with some options
polarDiff(before_data, after_data, pollutant = "no2", cols = "RdYlBu", limits = c(-20, 20))


## End(Not run)
</code></pre>

<hr>
<h2 id='polarFreq'>Function to plot wind speed/direction frequencies and other statistics</h2><span id='topic+polarFreq'></span>

<h3>Description</h3>

<p><code>polarFreq</code> primarily plots wind speed-direction frequencies in
&lsquo;bins&rsquo;. Each bin is colour-coded depending on the frequency of
measurements. Bins can also be used to show the concentration of pollutants
using a range of commonly used statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarFreq(
  mydata,
  pollutant = NULL,
  statistic = "frequency",
  ws.int = 1,
  wd.nint = 36,
  grid.line = 5,
  breaks = NULL,
  cols = "default",
  trans = TRUE,
  type = "default",
  min.bin = 1,
  ws.upper = NA,
  offset = 10,
  border.col = "transparent",
  key.header = statistic,
  key.footer = pollutant,
  key.position = "right",
  key = TRUE,
  auto.text = TRUE,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarFreq_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>ws</code>, <code>wd</code> and
<code>date</code>.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in
a data frame should be supplied e.g. <code>pollutant = "nox"</code></p>
</td></tr>
<tr><td><code id="polarFreq_+3A_statistic">statistic</code></td>
<td>
<p>The statistic that should be applied to each wind
speed/direction bin. Can be &ldquo;frequency&rdquo;, &ldquo;mean&rdquo;,
&ldquo;median&rdquo;, &ldquo;max&rdquo; (maximum), &ldquo;stdev&rdquo; (standard
deviation) or &ldquo;weighted.mean&rdquo;. The option &ldquo;frequency&rdquo; (the
default) is the simplest and plots the frequency of wind speed/direction
in different bins. The scale therefore shows the counts in each bin. The
option &ldquo;mean&rdquo; will plot the mean concentration of a pollutant (see
next point) in wind speed/direction bins, and so on.  Finally,
&ldquo;weighted.mean&rdquo; will plot the concentration of a pollutant weighted
by wind speed/direction. Each segment therefore provides the percentage
overall contribution to the total concentration. More information is given
in the examples. Note that for options other than &ldquo;frequency&rdquo;, it
is necessary to also provide the name of a pollutant. See function
<code>cutData</code> for further details.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_ws.int">ws.int</code></td>
<td>
<p>Wind speed interval assumed. In some cases e.g. a low met
mast, an interval of 0.5 may be more appropriate.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_wd.nint">wd.nint</code></td>
<td>
<p>Number of intervals of wind direction.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_grid.line">grid.line</code></td>
<td>
<p>Radial spacing of grid lines.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_breaks">breaks</code></td>
<td>
<p>The user can provide their own scale. <code>breaks</code> expects a
sequence of numbers that define the range of the scale. The sequence could
represent one with equal spacing e.g. <code>breaks = seq(0, 100, 10)</code> - a
scale from 0-10 in intervals of 10, or a more flexible sequence e.g.
<code>breaks = c(0, 1, 5, 7, 10)</code>, which may be useful for some
situations.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_trans">trans</code></td>
<td>
<p>Should a transformation be applied? Sometimes when producing
plots of this kind they can be dominated by a few high points. The default
therefore is <code>TRUE</code> and a square-root transform is applied. This
results in a non-linear scale and (usually) a better representation of the
distribution. If set to <code>FALSE</code> a linear scale is used.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_min.bin">min.bin</code></td>
<td>
<p>The minimum number of points allowed in a wind speed/wind
direction bin.  The default is 1. A value of two requires at least 2 valid
records in each bin an so on; bins with less than 2 valid records are set
to NA. Care should be taken when using a value &gt; 1 because of the risk of
removing real data points. It is recommended to consider your data with
care. Also, the <code>polarFreq</code> function can be of use in such
circumstances.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_ws.upper">ws.upper</code></td>
<td>
<p>A user-defined upper wind speed to use. This is useful for
ensuring a consistent scale between different plots. For example, to
always ensure that wind speeds are displayed between 1-10, set
<code>ws.int = 10</code>.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_offset">offset</code></td>
<td>
<p><code>offset</code> controls the size of the &lsquo;hole&rsquo; in the
middle and is expressed as a percentage of the maximum wind speed. Setting
a higher <code>offset</code> e.g. 50 is useful for <code>statistic =
  "weighted.mean"</code> when <code>ws.int</code> is greater than the maximum wind
speed. See example below.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_border.col">border.col</code></td>
<td>
<p>The colour of the boundary of each wind speed/direction
bin. The default is transparent. Another useful choice sometimes is
&quot;white&quot;.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_key.footer">key.footer</code></td>
<td>
<p>see <code>key.footer</code>.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="polarFreq_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:xyplot</code>
and <code>cutData</code>. For example, <code>polarFreq</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>polarFreq</code> is its default use provides details of wind speed and
direction frequencies. In this respect it is similar to
<code><a href="#topic+windRose">windRose</a></code>, but considers wind direction intervals of 10 degrees
and a user-specified wind speed interval. The frequency of wind
speeds/directions formed by these &lsquo;bins&rsquo; is represented on a colour
scale.
</p>
<p>The <code>polarFreq</code> function is more flexible than either
<code><a href="#topic+windRose">windRose()</a></code> or <code><a href="#topic+polarPlot">polarPlot()</a></code>. It can, for example, also
consider pollutant concentrations (see examples below). Instead of the
number of data points in each bin, the concentration can be shown. Further,
a range of statistics can be used to describe each bin - see
<code>statistic</code> above. Plotting mean concentrations is useful for source
identification and is the same as <code><a href="#topic+polarPlot">polarPlot()</a></code> but without
smoothing, which may be preferable for some data. Plotting with
<code>statistic = "weighted.mean"</code> is particularly useful for understanding
the relative importance of different source contributions. For example, high
mean concentrations may be observed for high wind speed conditions, but the
weighted mean concentration may well show that the contribution to overall
concentrations is very low.
</p>
<p><code>polarFreq</code> also offers great flexibility with the scale used and the
user has fine control over both the range, interval and colour.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># basic wind frequency plot
polarFreq(mydata)

# wind frequencies by year
## Not run: polarFreq(mydata, type = "year")


# mean SO2 by year, showing only bins with at least 2 points
## Not run: polarFreq(mydata, pollutant = "so2", type = "year", statistic = "mean", min.bin = 2)

# weighted mean SO2 by year, showing only bins with at least 2 points
## Not run: polarFreq(mydata, pollutant = "so2", type = "year", statistic = "weighted.mean",
min.bin = 2)
## End(Not run)

#windRose for just 2000 and 2003 with different colours
## Not run: polarFreq(subset(mydata, format(date, "%Y") %in% c(2000, 2003)),
type = "year", cols = "turbo")
## End(Not run)

# user defined breaks from 0-700 in intervals of 100 (note linear scale)
## Not run: polarFreq(mydata, breaks = seq(0, 700, 100))

# more complicated user-defined breaks - useful for highlighting bins
# with a certain number of data points
## Not run: polarFreq(mydata, breaks = c(0, 10, 50, 100, 250, 500, 700))

# source contribution plot and use of offset option
## Not run: polarFreq(mydata, pollutant = "pm25", statistic
="weighted.mean", offset = 50, ws.int = 25, trans = FALSE) 
## End(Not run)
</code></pre>

<hr>
<h2 id='polarPlot'>Function for plotting bivariate polar plots with smoothing.</h2><span id='topic+polarPlot'></span>

<h3>Description</h3>

<p>Function for plotting pollutant concentration in polar coordinates showing
concentration by wind speed (or another numeric variable) and direction. Mean
concentrations are calculated for wind speed-direction &lsquo;bins&rsquo; (e.g.
0-1, 1-2 m/s,...  and 0-10, 10-20 degrees etc.).  To aid interpretation,
<code>gam</code> smoothing is carried out using <code>mgcv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarPlot(
  mydata,
  pollutant = "nox",
  x = "ws",
  wd = "wd",
  type = "default",
  statistic = "mean",
  limits = NULL,
  exclude.missing = TRUE,
  uncertainty = FALSE,
  percentile = NA,
  cols = "default",
  weights = c(0.25, 0.5, 0.75),
  min.bin = 1,
  mis.col = "grey",
  upper = NA,
  angle.scale = 315,
  units = x,
  force.positive = TRUE,
  k = 100,
  normalise = FALSE,
  key.header = statistic,
  key.footer = pollutant,
  key.position = "right",
  key = TRUE,
  auto.text = TRUE,
  ws_spread = 1.5,
  wd_spread = 5,
  x_error = NA,
  y_error = NA,
  kernel = "gaussian",
  formula.label = TRUE,
  tau = 0.5,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polarPlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing <code>wd</code>, another variable
to plot in polar coordinates (the default is a column &ldquo;ws&rdquo; &mdash; wind
speed) and a pollutant. Should also contain <code>date</code> if plots by time
period are required.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>. There can also
be more than one pollutant specified e.g. <code>pollutant = c("nox",
  "no2")</code>. The main use of using two or more pollutants is for model
evaluation where two species would be expected to have similar
concentrations. This saves the user stacking the data and it is possible to
work with columns of data directly. A typical use would be <code>pollutant
  = c("obs", "mod")</code> to compare two columns &ldquo;obs&rdquo; (the observations)
and &ldquo;mod&rdquo; (modelled values). When pair-wise statistics such as
Pearson correlation and regression techniques are to be plotted,
<code>pollutant</code> takes two elements too. For example, <code>pollutant =
  c("bc", "pm25")</code> where <code>"bc"</code> is a function of <code>"pm25"</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_x">x</code></td>
<td>
<p>Name of variable to plot against wind direction in polar
coordinates, the default is wind speed, &ldquo;ws&rdquo;.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_wd">wd</code></td>
<td>
<p>Name of wind direction field.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_statistic">statistic</code></td>
<td>
<p>The statistic that should be applied to each wind
speed/direction bin. Because of the smoothing involved, the colour scale
for some of these statistics is only to provide an indication of overall
pattern and should not be interpreted in concentration units e.g. for
<code>statistic = "weighted.mean"</code> where the bin mean is multiplied by the
bin frequency and divided by the total frequency. In many cases using
<code>polarFreq</code> will be better. Setting <code>statistic = "weighted.mean"</code>
can be useful because it provides an indication of the concentration *
frequency of occurrence and will highlight the wind speed/direction
conditions that dominate the overall mean.Can be:
</p>
 <ul>
<li>  <p>&ldquo;mean&rdquo; (default), &ldquo;median&rdquo;, &ldquo;max&rdquo;
(maximum), &ldquo;frequency&rdquo;. &ldquo;stdev&rdquo; (standard deviation),
&ldquo;weighted.mean&rdquo;.
</p>
</li>
<li> <p><code>statistic = "nwr"</code> Implements the Non-parametric Wind
Regression approach of Henry et al. (2009) that uses kernel smoothers. The
<code>openair</code> implementation is not identical because Gaussian kernels are
used for both wind direction and speed. The smoothing is controlled by
<code>ws_spread</code> and <code>wd_spread</code>.
</p>
</li>
<li> <p><code>statistic = "cpf"</code> the conditional probability function (CPF)
is plotted and a single (usually high) percentile level is supplied. The
CPF is defined as CPF = my/ny, where my is the number of samples in the y
bin (by default a wind direction, wind speed interval) with mixing ratios
greater than the <em>overall</em> percentile concentration, and ny is the
total number of samples in the same wind sector (see Ashbaugh et al.,
1985). Note that percentile intervals can also be considered; see
<code>percentile</code> for details.
</p>
</li>
<li><p> When <code>statistic = "r"</code> or <code>statistic = "Pearson"</code>, the
Pearson correlation coefficient is calculated for <em>two</em> pollutants.
The calculation involves a weighted Pearson correlation coefficient, which
is weighted by Gaussian kernels for wind direction an the radial variable
(by default wind speed). More weight is assigned to values close to a wind
speed-direction interval. Kernel weighting is used to ensure that all data
are used rather than relying on the potentially small number of values in a
wind speed-direction interval.
</p>
</li>
<li><p> When <code>statistic = "Spearman"</code>, the Spearman correlation
coefficient is calculated for <em>two</em> pollutants. The calculation
involves a weighted Spearman correlation coefficient, which is weighted by
Gaussian kernels for wind direction an the radial variable (by default wind
speed). More weight is assigned to values close to a wind speed-direction
interval. Kernel weighting is used to ensure that all data are used rather
than relying on the potentially small number of values in a wind
speed-direction interval.
</p>
</li>
<li> <p><code>"robust_slope"</code> is another option for pair-wise statistics and
<code>"quantile.slope"</code>, which uses quantile regression to estimate the
slope for a particular quantile level (see also <code>tau</code> for setting the
quantile level).
</p>
</li>
<li> <p><code>"york_slope"</code> is another option for pair-wise statistics which
uses the <em>York regression method</em> to estimate the slope. In this
method the uncertainties in <code>x</code> and <code>y</code> are used in the
determination of the slope. The uncertainties are provided by
<code>x_error</code> and <code>y_error</code> &mdash; see below.</p>
</li></ul>
</td></tr>
<tr><td><code id="polarPlot_+3A_limits">limits</code></td>
<td>
<p>The function does its best to choose sensible limits
automatically. However, there are circumstances when the user will wish to
set different ones. An example would be a series of plots showing each year
of data separately. The limits are set in the form <code>c(lower, upper)</code>,
so <code>limits = c(0, 100)</code> would force the plot limits to span 0-100.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_exclude.missing">exclude.missing</code></td>
<td>
<p>Setting this option to <code>TRUE</code> (the default)
removes points from the plot that are too far from the original data. The
smoothing routines will produce predictions at points where no data exist
i.e. they predict. By removing the points too far from the original data
produces a plot where it is clear where the original data lie. If set to
<code>FALSE</code> missing data will be interpolated.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_uncertainty">uncertainty</code></td>
<td>
<p>Should the uncertainty in the calculated surface be shown?
If <code>TRUE</code> three plots are produced on the same scale showing the
predicted surface together with the estimated lower and upper uncertainties
at the 95% confidence interval. Calculating the uncertainties is useful to
understand whether features are real or not.  For example, at high wind
speeds where there are few data there is greater uncertainty over the
predicted values. The uncertainties are calculated using the GAM and
weighting is done by the frequency of measurements in each wind
speed-direction bin. Note that if uncertainties are calculated then the
type is set to &quot;default&quot;.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_percentile">percentile</code></td>
<td>
<p>If <code>statistic = "percentile"</code> then <code>percentile</code>
is used, expressed from 0 to 100. Note that the percentile value is
calculated in the wind speed, wind direction &lsquo;bins&rsquo;. For this reason
it can also be useful to set <code>min.bin</code> to ensure there are a
sufficient number of points available to estimate a percentile. See
<code>quantile</code> for more details of how percentiles are calculated.
</p>
<p><code>percentile</code> is also used for the Conditional Probability Function
(CPF) plots. <code>percentile</code> can be of length two, in which case the
percentile <em>interval</em> is considered for use with CPF. For example,
<code>percentile = c(90, 100)</code> will plot the CPF for concentrations between
the 90 and 100th percentiles. Percentile intervals can be useful for
identifying specific sources. In addition, <code>percentile</code> can also be of
length 3. The third value is the &lsquo;trim&rsquo; value to be applied. When
calculating percentile intervals many can cover very low values where there
is no useful information. The trim value ensures that values greater than
or equal to the trim * mean value are considered <em>before</em> the
percentile intervals are calculated. The effect is to extract more detail
from many source signatures. See the manual for examples. Finally, if the
trim value is less than zero the percentile range is interpreted as
absolute concentration values and subsetting is carried out directly.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code>. <code>cols</code>
can also take the values <code>"viridis"</code>, <code>"magma"</code>,
<code>"inferno"</code>, or <code>"plasma"</code> which are the viridis colour maps
ported from Python's Matplotlib library.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_weights">weights</code></td>
<td>
<p>At the edges of the plot there may only be a few data points
in each wind speed-direction interval, which could in some situations
distort the plot if the concentrations are high. <code>weights</code> applies a
weighting to reduce their influence. For example and by default if only a
single data point exists then the weighting factor is 0.25 and for two
points 0.5. To not apply any weighting and use the data as is, use
<code>weights = c(1, 1, 1)</code>.
</p>
<p>An alternative to down-weighting these points they can be removed
altogether using <code>min.bin</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_min.bin">min.bin</code></td>
<td>
<p>The minimum number of points allowed in a wind speed/wind
direction bin.  The default is 1. A value of two requires at least 2 valid
records in each bin an so on; bins with less than 2 valid records are set
to NA. Care should be taken when using a value &gt; 1 because of the risk of
removing real data points. It is recommended to consider your data with
care. Also, the <code>polarFreq</code> function can be of use in such
circumstances.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_mis.col">mis.col</code></td>
<td>
<p>When <code>min.bin</code> is &gt; 1 it can be useful to show where data
are removed on the plots. This is done by shading the missing data in
<code>mis.col</code>. To not highlight missing data when <code>min.bin</code> &gt; 1
choose <code>mis.col = "transparent"</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_upper">upper</code></td>
<td>
<p>This sets the upper limit wind speed to be used. Often there are
only a relatively few data points at very high wind speeds and plotting all
of them can reduce the useful information in the plot.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_angle.scale">angle.scale</code></td>
<td>
<p>Sometimes the placement of the scale may interfere with an
interesting feature. The user can therefore set <code>angle.scale</code> to any
value between 0 and 360 degrees to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_units">units</code></td>
<td>
<p>The units shown on the polar axis scale.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_force.positive">force.positive</code></td>
<td>
<p>The default is <code>TRUE</code>. Sometimes if smoothing data
with steep gradients it is possible for predicted values to be negative.
<code>force.positive = TRUE</code> ensures that predictions remain positive. This
is useful for several reasons. First, with lots of missing data more
interpolation is needed and this can result in artefacts because the
predictions are too far from the original data. Second, if it is known
beforehand that the data are all positive, then this option carries that
assumption through to the prediction. The only likely time where setting
<code>force.positive = FALSE</code> would be if background concentrations were
first subtracted resulting in data that is legitimately negative. For the
vast majority of situations it is expected that the user will not need to
alter the default option.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_k">k</code></td>
<td>
<p>This is the smoothing parameter used by the <code>gam</code> function in
package <code>mgcv</code>. Typically, value of around 100 (the default) seems to
be suitable and will resolve important features in the plot. The most
appropriate choice of <code>k</code> is problem-dependent; but extensive testing
of polar plots for many different problems suggests a value of <code>k</code> of
about 100 is suitable. Setting <code>k</code> to higher values will not tend to
affect the surface predictions by much but will add to the computation
time. Lower values of <code>k</code> will increase smoothing. Sometimes with few
data to plot <code>polarPlot</code> will fail. Under these circumstances it can
be worth lowering the value of <code>k</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_normalise">normalise</code></td>
<td>
<p>If <code>TRUE</code> concentrations are normalised by dividing by
their mean value. This is done <em>after</em> fitting the smooth surface.
This option is particularly useful if one is interested in the patterns of
concentrations for several pollutants on different scales e.g. NOx and CO.
Often useful if more than one <code>pollutant</code> is chosen.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels to the scale key. For example,
passing the options <code>key.header = "header", key.footer = "footer1"</code>
adds addition text above and below the scale key. These arguments are
passed to <code>drawOpenKey</code> via <code>quickText</code>, applying the
<code>auto.text</code> argument, to handle formatting.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_key.footer">key.footer</code></td>
<td>
<p>see <code>key.footer</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include <code>"top"</code>, <code>"right"</code>, <code>"bottom"</code>
and <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>drawOpenKey</code> for further details.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_ws_spread">ws_spread</code></td>
<td>
<p>The value of sigma used for Gaussian kernel weighting of
wind speed when <code>statistic = "nwr"</code> or when correlation and regression
statistics are used such as <em>r</em>. Default is <code>0.5</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_wd_spread">wd_spread</code></td>
<td>
<p>The value of sigma used for Gaussian kernel weighting of
wind direction when <code>statistic = "nwr"</code> or when correlation and
regression statistics are used such as <em>r</em>. Default is <code>4</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_x_error">x_error</code></td>
<td>
<p>The <code>x</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_y_error">y_error</code></td>
<td>
<p>The <code>y</code> error / uncertainty used when <code>statistic =
"york_slope"</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_kernel">kernel</code></td>
<td>
<p>Type of kernel used for the weighting procedure for when
correlation or regression techniques are used. Only <code>"gaussian"</code> is
supported but this may be enhanced in the future.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_formula.label">formula.label</code></td>
<td>
<p>When pair-wise statistics such as regression slopes are
calculated and plotted, should a formula label be displayed?</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_tau">tau</code></td>
<td>
<p>The quantile to be estimated when <code>statistic</code> is set to
<code>"quantile.slope"</code>. Default is <code>0.5</code> which is equal to the median
and will be ignored if <code>"quantile.slope"</code> is not used.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="polarPlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:levelplot</code>
and <code>cutData</code>. For example, <code>polarPlot</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>levelplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bivariate polar plot is a useful diagnostic tool for quickly gaining an
idea of potential sources. Wind speed is one of the most useful variables to
use to separate source types (see references). For example, ground-level
concentrations resulting from buoyant plumes from chimney stacks tend to peak
under higher wind speed conditions. Conversely, ground-level, non-buoyant
plumes such as from road traffic, tend to have highest concentrations under
low wind speed conditions. Other sources such as from aircraft engines also
show differing characteristics by wind speed.
</p>
<p>The function has been developed to allow variables other than wind speed to
be plotted with wind direction in polar coordinates. The key issue is that
the other variable plotted against wind direction should be discriminating in
some way. For example, temperature can help reveal high-level sources brought
down to ground level in unstable atmospheric conditions, or show the effect a
source emission dependent on temperature e.g. biogenic isoprene.
</p>
<p>The plots can vary considerably depending on how much smoothing is done.  The
approach adopted here is based on the very flexible and capable <code>mgcv</code>
package that uses <em>Generalized Additive Models</em>. While methods do exist
to find an optimum level of smoothness, they are not necessarily useful. The
principal aim of <code>polarPlot</code> is as a graphical analysis rather than for
quantitative purposes. In this respect the smoothing aims to strike a balance
between revealing interesting (real) features and overly noisy data. The
defaults used in <code><a href="#topic+polarPlot">polarPlot()</a></code> are based on the analysis of data from many
different sources. More advanced users may wish to modify the code and adopt
other smoothing approaches.
</p>
<p>Various statistics are possible to consider e.g. mean, maximum, median.
<code>statistic = "max"</code> is often useful for revealing sources. Pair-wise
statistics between two pollutants can also be calculated.
</p>
<p>The function can also be used to compare two pollutant species through a
range of pair-wise statistics (see help on <code>statistic</code>) and Grange et
al. (2016) (open-access publication link below).
</p>
<p>Wind direction is split up into 10 degree intervals and the other variable
(e.g. wind speed) 30 intervals. These 2D bins are then used to calculate the
statistics.
</p>
<p>These plots often show interesting features at higher wind speeds (see
references below). For these conditions there can be very few measurements
and therefore greater uncertainty in the calculation of the surface. There
are several ways in which this issue can be tackled. First, it is possible to
avoid smoothing altogether and use <code><a href="#topic+polarFreq">polarFreq()</a></code>. Second, the effect of
setting a minimum number of measurements in each wind speed-direction bin can
be examined through <code>min.bin</code>. It is possible that a single point at
high wind speed conditions can strongly affect the surface prediction.
Therefore, setting <code>min.bin = 3</code>, for example, will remove all wind
speed-direction bins with fewer than 3 measurements <em>before</em> fitting the
surface. Third, consider setting <code>uncertainty = TRUE</code>. This option will
show the predicted surface together with upper and lower 95% confidence
intervals, which take account of the frequency of measurements.
</p>
<p>Variants on <code>polarPlot</code> include <code><a href="#topic+polarAnnulus">polarAnnulus()</a></code> and <code><a href="#topic+polarFreq">polarFreq()</a></code>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. <code>data</code> contians four set
columns: <code>cond</code>, conditioning based on <code>type</code>; <code>u</code> and
<code>v</code>, the translational vectors based on <code>ws</code> and <code>wd</code>; and
the local <code>pollutant</code> estimate.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Ashbaugh, L.L., Malm, W.C., Sadeh, W.Z., 1985. A residence time probability
analysis of sulfur concentrations at ground canyon national park. Atmospheric
Environment 19 (8), 1263-1270.
</p>
<p>Carslaw, D.C., Beevers, S.D, Ropkins, K and M.C. Bell (2006). Detecting and
quantifying aircraft and other on-airport contributions to ambient nitrogen
oxides in the vicinity of a large international airport.  Atmospheric
Environment. 40/28 pp 5424-5434.
</p>
<p>Carslaw, D.C., &amp; Beevers, S.D. (2013). Characterising and understanding
emission sources using bivariate polar plots and k-means clustering.
Environmental Modelling &amp; Software, 40, 325-329.
doi:10.1016/j.envsoft.2012.09.005
</p>
<p>Henry, R.C., Chang, Y.S., Spiegelman, C.H., 2002. Locating nearby sources of
air pollution by nonparametric regression of atmospheric concentrations on
wind direction. Atmospheric Environment 36 (13), 2237-2244.
</p>
<p>Henry, R., Norris, G.A., Vedantham, R., Turner, J.R., 2009. Source region
identification using Kernel smoothing. Environ. Sci. Technol. 43 (11),
4090e4097. http:// dx.doi.org/10.1021/es8011723.
</p>
<p>Uria-Tellaetxe, I. and D.C. Carslaw (2014). Source identification using a
conditional bivariate Probability function. Environmental Modelling &amp;
Software, Vol. 59, 1-9.
</p>
<p>Westmoreland, E.J., N. Carslaw, D.C. Carslaw, A. Gillah and E. Bates (2007).
Analysis of air quality within a street canyon using statistical and
dispersion modelling techniques. Atmospheric Environment. Vol.  41(39), pp.
9195-9205.
</p>
<p>Yu, K.N., Cheung, Y.P., Cheung, T., Henry, R.C., 2004. Identifying the impact
of large urban airports on local air quality by nonparametric regression.
Atmospheric Environment 38 (27), 4501-4507.
</p>
<p>Grange, S. K., Carslaw, D. C., &amp; Lewis, A. C. 2016. Source apportionment
advances with bivariate polar plots, correlation, and regression techniques.
Atmospheric Environment. 145, 128-134.
<a href="https://www.sciencedirect.com/science/article/pii/S1352231016307166">https://www.sciencedirect.com/science/article/pii/S1352231016307166</a>
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Use openair 'mydata'

# basic plot
polarPlot(openair::mydata, pollutant = "nox")
## Not run: 

# polarPlots by year on same scale
polarPlot(mydata, pollutant = "so2", type = "year", main = "polarPlot of so2")

# set minimum number of bins to be used to see if pattern remains similar
polarPlot(mydata, pollutant = "nox", min.bin = 3)

# plot by day of the week
polarPlot(mydata, pollutant = "pm10", type = "weekday")

# show the 95% confidence intervals in the surface fitting
polarPlot(mydata, pollutant = "so2", uncertainty = TRUE)


# Pair-wise statistics
# Pearson correlation
polarPlot(mydata, pollutant = c("pm25", "pm10"), statistic = "r")

# Robust regression slope, takes a bit of time
polarPlot(mydata, pollutant = c("pm25", "pm10"), statistic = "robust.slope")

# Least squares regression works too but it is not recommended, use robust
# regression
# polarPlot(mydata, pollutant = c("pm25", "pm10"), statistic = "slope")

## End(Not run)

</code></pre>

<hr>
<h2 id='pollutionRose'>Pollution rose variation of the traditional wind rose plot</h2><span id='topic+pollutionRose'></span>

<h3>Description</h3>

<p>The traditional wind rose plot that plots wind speed and wind direction by
different intervals. The pollution rose applies the same plot structure but
substitutes other measurements, most commonly a pollutant time series, for
wind speed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pollutionRose(
  mydata,
  pollutant = "nox",
  key.footer = pollutant,
  key.position = "right",
  key = TRUE,
  breaks = 6,
  paddle = FALSE,
  seg = 0.9,
  normalise = FALSE,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pollutionRose_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing fields <code>ws</code> and <code>wd</code></p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_pollutant">pollutant</code></td>
<td>
<p>Mandatory. A pollutant name corresponding to a variable in a
data frame should be supplied e.g. <code>pollutant = "nox"</code>.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_key.footer">key.footer</code></td>
<td>
<p>Adds additional text/labels below the scale key. See
<code>key.header</code> for further information.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code><a href="#topic+drawOpenKey">drawOpenKey()</a></code>.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_breaks">breaks</code></td>
<td>
<p>Most commonly, the number of break points for pollutant
concentrations. The default, 6, attempts to breaks the supplied data at
approximately 6 sensible break points. However, <code>breaks</code> can also be
used to set specific break points. For example, the argument <code>breaks =
  c(0, 1, 10, 100)</code> breaks the data into segments &lt;1, 1-10, 10-100, &gt;100.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_paddle">paddle</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code>. If <code>TRUE</code> plots rose
using 'paddle' style spokes. If <code>FALSE</code> plots rose using 'wedge' style
spokes.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_seg">seg</code></td>
<td>
<p>When <code>paddle = TRUE</code>, <code>seg</code> determines with width of the
segments. For example, <code>seg = 0.5</code> will produce segments 0.5 *
<code>angle</code>.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_normalise">normalise</code></td>
<td>
<p>If <code>TRUE</code> each wind direction segment is normalised to
equal one. This is useful for showing how the concentrations (or other
parameters) contribute to each wind sector when the proportion of time the
wind is from that direction is low. A line showing the probability that the
wind directions is from a particular wind sector is also shown.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="pollutionRose_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+windRose">windRose</a></code>
</p>

<dl>
<dt><code>ws</code></dt><dd><p>Name of the column representing wind speed.</p>
</dd>
<dt><code>wd</code></dt><dd><p>Name of the column representing wind direction.</p>
</dd>
<dt><code>ws2,wd2</code></dt><dd><p>The user can supply a second set of wind speed and wind
direction values with which the first can be compared. See
<code><a href="#topic+pollutionRose">pollutionRose()</a></code> for more details.</p>
</dd>
<dt><code>ws.int</code></dt><dd><p>The Wind speed interval. Default is 2 m/s but for low met masts
with low mean wind speeds a value of 1 or 0.5 m/s may be better.</p>
</dd>
<dt><code>angle</code></dt><dd><p>Default angle of &ldquo;spokes&rdquo; is 30. Other potentially useful
angles are 45 and 10. Note that the width of the wind speed interval may
need adjusting using <code>width</code>.</p>
</dd>
<dt><code>type</code></dt><dd><p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</dd>
<dt><code>bias.corr</code></dt><dd><p>When <code>angle</code> does not divide exactly into 360 a bias is
introduced in the frequencies when the wind direction is already supplied
rounded to the nearest 10 degrees, as is often the case. For example, if
<code>angle = 22.5</code>, N, E, S, W will include 3 wind sectors and all other
angles will be two. A bias correction can made to correct for this problem.
A simple method according to Applequist (2012) is used to adjust the
frequencies.</p>
</dd>
<dt><code>cols</code></dt><dd><p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo;,
&ldquo;hue&rdquo; and user defined. For user defined the user can supply a list
of colour names recognised by R (type <code>colours()</code> to see the full
list). An example would be <code>cols = c("yellow", "green", "blue",
  "black")</code>.</p>
</dd>
<dt><code>grid.line</code></dt><dd><p>Grid line interval to use. If <code>NULL</code>, as in default,
this is assigned based on the available data range. However, it can also be
forced to a specific value, e.g. <code>grid.line = 10</code>. <code>grid.line</code>
can also be a list to control the interval, line type and colour. For
example <code>grid.line = list(value = 10, lty = 5, col = "purple")</code>.</p>
</dd>
<dt><code>width</code></dt><dd><p>For <code>paddle = TRUE</code>, the adjustment factor for width of
wind speed intervals. For example, <code>width = 1.5</code> will make the paddle
width 1.5 times wider.</p>
</dd>
<dt><code>auto.text</code></dt><dd><p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly, e.g., by subscripting the &lsquo;2&rsquo; in NO2.</p>
</dd>
<dt><code>offset</code></dt><dd><p>The size of the 'hole' in the middle of the plot, expressed as
a percentage of the polar axis scale, default 10.</p>
</dd>
<dt><code>max.freq</code></dt><dd><p>Controls the scaling used by setting the maximum value for
the radial limits. This is useful to ensure several plots use the same
radial limits.</p>
</dd>
<dt><code>key.header</code></dt><dd><p>Adds additional text/labels above the scale key. For
example, passing <code>windRose(mydata, key.header = "ws")</code> adds the
addition text as a scale header. Note: This argument is passed to
<code><a href="#topic+drawOpenKey">drawOpenKey()</a></code> via <code><a href="#topic+quickText">quickText()</a></code>, applying the auto.text argument, to
handle formatting.</p>
</dd>
<dt><code>dig.lab</code></dt><dd><p>The number of significant figures at which scientific number
formatting is used in break point and key labelling. Default 5.</p>
</dd>
<dt><code>include.lowest</code></dt><dd><p>Logical. If <code>FALSE</code> (the default), the first
interval will be left exclusive and right inclusive. If <code>TRUE</code>, the
first interval will be left and right inclusive. Passed to the
<code>include.lowest</code> argument of <code><a href="base.html#topic+cut">cut()</a></code>.</p>
</dd>
<dt><code>statistic</code></dt><dd><p>The <code>statistic</code> to be applied to each data bin in the
plot. Options currently include &ldquo;prop.count&rdquo;, &ldquo;prop.mean&rdquo; and
&ldquo;abs.count&rdquo;. The default &ldquo;prop.count&rdquo; sizes bins according to
the proportion of the frequency of measurements.  Similarly,
&ldquo;prop.mean&rdquo; sizes bins according to their relative contribution to
the mean. &ldquo;abs.count&rdquo; provides the absolute count of measurements in
each bin.</p>
</dd>
<dt><code>annotate</code></dt><dd><p>If <code>TRUE</code> then the percentage calm and mean values are
printed in each panel together with a description of the statistic below
the plot. If <code>" "</code> then only the statistic is below the plot. Custom
annotations may be added by setting value to <code>c("annotation 1",
  "annotation 2")</code>.</p>
</dd>
<dt><code>angle.scale</code></dt><dd><p>The scale is by default shown at a 315 degree angle.
Sometimes the placement of the scale may interfere with an interesting
feature. The user can therefore set <code>angle.scale</code> to another value
(between 0 and 360 degrees) to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</dd>
<dt><code>border</code></dt><dd><p>Border colour for shaded areas. Default is no border.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+pollutionRose">pollutionRose()</a></code> is a <code><a href="#topic+windRose">windRose()</a></code> wrapper which brings <code>pollutant</code>
forward in the argument list, and attempts to sensibly rescale break points
based on the <code>pollutant</code> data range by by-passing <code>ws.int</code>.
</p>
<p>By default, <code><a href="#topic+pollutionRose">pollutionRose()</a></code> will plot a pollution rose of <code>nox</code> using
&quot;wedge&quot; style segments and placing the scale key to the right of the plot.
</p>
<p>It is possible to compare two wind speed-direction data sets using
<code><a href="#topic+pollutionRose">pollutionRose()</a></code>. There are many reasons for doing so e.g. to see how one
site compares with another or for meteorological model evaluation. In this
case, <code>ws</code> and <code>wd</code> are considered to the the reference data sets
with which a second set of wind speed and wind directions are to be compared
(<code>ws2</code> and <code>wd2</code>). The first set of values is subtracted from the
second and the differences compared. If for example, <code>wd2</code> was biased
positive compared with <code>wd</code> then <code>pollutionRose</code> will show the bias
in polar coordinates. In its default use, wind direction bias is colour-coded
to show negative bias in one colour and positive bias in another.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. Summarised proportions can be
extracted directly using the <code>$data</code> operator, e.g.
<code>object$data</code> for <code>output &lt;- windRose(mydata)</code>. This returns a
data frame with three set columns: <code>cond</code>, conditioning based on
<code>type</code>; <code>wd</code>, the wind direction; and <code>calm</code>, the
<code>statistic</code> for the proportion of data unattributed to any specific
wind direction because it was collected under calm conditions; and then
several (one for each range binned for the plot) columns giving proportions
of measurements associated with each <code>ws</code> or <code>pollutant</code> range
plotted as a discrete panel.
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+windRose">windRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># pollutionRose of nox
pollutionRose(mydata, pollutant = "nox")

## source apportionment plot - contribution to mean
## Not run: 
pollutionRose(mydata, pollutant = "pm10", type = "year", statistic = "prop.mean")

## End(Not run)

## example of comparing 2 met sites
## first we will make some new ws/wd data with a postive bias
mydata$ws2 = mydata$ws + 2 * rnorm(nrow(mydata)) + 1
mydata$wd2 = mydata$wd + 30 * rnorm(nrow(mydata)) + 30

## need to correct negative wd
id &lt;- which(mydata$wd2 &lt; 0)
mydata$wd2[id] &lt;- mydata$wd2[id] + 360

## results show postive bias in wd and ws
pollutionRose(mydata, ws = "ws", wd = "wd", ws2 = "ws2", wd2 = "wd2")
</code></pre>

<hr>
<h2 id='quickText'>Automatic text formatting for openair</h2><span id='topic+quickText'></span>

<h3>Description</h3>

<p>Workhorse function that automatically applies routine text formatting to
common expressions and data names used in openair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quickText(text, auto.text = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quickText_+3A_text">text</code></td>
<td>
<p>A character vector.</p>
</td></tr>
<tr><td><code id="quickText_+3A_auto.text">auto.text</code></td>
<td>
<p>A logical option. The default, <code>TRUE</code>, applies
<code>quickText</code> to <code>text</code> and returns the result. The alternative,
<code>FALSE</code>, returns <code>text</code> unchanged. (A number of <code>openair</code>
functions enable/disable <code>quickText</code> using this option.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>quickText</code> is routine formatting lookup table. It screens the
supplied character vector <code>text</code> and automatically applies formatting
to any recognised character sub-series. The function is used in a number of
<code>openair</code> functions and can also be used directly by users to format
text components of their own graphs (see below).
</p>


<h3>Value</h3>

<p>The function returns an expression for graphical evaluation.
</p>


<h3>Author(s)</h3>

<p>Karl Ropkins.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

#example 1
##see axis formatting in an openair plot, e.g.:
scatterPlot(mydata, x = "no2", y = "pm10")

#example 2
##using quickText in other plots
plot(mydata$no2, mydata$pm10, xlab = quickText("my no2 label"),
     ylab = quickText("pm10 [ ug.m-3 ]"))


</code></pre>

<hr>
<h2 id='rollingMean'>Calculate rollingMean values</h2><span id='topic+rollingMean'></span>

<h3>Description</h3>

<p>Calculate rollingMean values taking account of data capture thresholds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rollingMean(
  mydata,
  pollutant = "o3",
  width = 8,
  new.name = "rolling",
  data.thresh = 75,
  align = "centre",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rollingMean_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing a <code>date</code>
field. <code>mydata</code> must contain a <code>date</code> field in
<code>Date</code> or <code>POSIXct</code> format. The input time series must
be regular e.g. hourly, daily.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_pollutant">pollutant</code></td>
<td>
<p>The name of a pollutant e.g. <code>pollutant = "o3"</code>.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_width">width</code></td>
<td>
<p>The averaging period (rolling window width) to use
e.g. <code>width = 8</code> will generate 8-hour rolling mean values
when hourly data are analysed.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_new.name">new.name</code></td>
<td>
<p>The name given to the new rollingMean variable. If
not supplied it will create a name based on the name of the
pollutant and the averaging period used.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold in %. No values are
calculated if data capture over the period of interest is less
than this value. For example, with <code>width = 8</code> and
<code>data.thresh = 75</code> at least 6 hours are required to calculate
the mean, else <code>NA</code> is returned.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_align">align</code></td>
<td>
<p>specifies how the moving window should be
aligned. <code>"right"</code> means that the previous <code>hours</code>
(including the current) are averaged. This seems to be the default
for UK air quality rolling mean statistics. <code>"left"</code> means
that the forward <code>hours</code> are averaged, and <code>"centre"</code> or
<code>"center"</code>, which is the default.</p>
</td></tr>
<tr><td><code id="rollingMean_+3A_...">...</code></td>
<td>
<p>other arguments, currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a utility function mostly designed to calculate rolling
mean statistics relevant to some pollutant limits e.g. 8 hour
rolling means for ozone and 24 hour rolling means for
PM10. However, the function has a more general use in helping to
display rolling mean values in flexible ways e.g. with the rolling
window width left, right or centre aligned.
</p>
<p>The function will try and fill in missing time gaps to get a full
time sequence but return a data frame with the same number of rows
supplied.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## rolling 8-hour mean for ozone
mydata &lt;- rollingMean(mydata, pollutant = "o3", width = 8, new.name =
"rollingo3", data.thresh = 75, align = "right")


</code></pre>

<hr>
<h2 id='runRegression'>Rolling regression for pollutant source characterisation.</h2><span id='topic+runRegression'></span>

<h3>Description</h3>

<p>This function calculates rolling regressions for input data with a set window
width. The principal use of teh function is to identify &quot;dilution lines&quot;
where the ratio between two pollutant concentrations is invariant. The
original idea is based on the work of Bentley (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runRegression(mydata, x = "nox", y = "pm10", run.len = 3, date.pad = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runRegression_+3A_mydata">mydata</code></td>
<td>
<p>A data frame with  colums for <code>date</code> and at least two
variables for use in a regression.</p>
</td></tr>
<tr><td><code id="runRegression_+3A_x">x</code></td>
<td>
<p>The column name of the <code>x</code> variable for use in a linear
regression <code>y = m.x + c</code>.</p>
</td></tr>
<tr><td><code id="runRegression_+3A_y">y</code></td>
<td>
<p>The column name of the <code>y</code> variable for use in a linear
regression <code>y = m.x + c</code>.</p>
</td></tr>
<tr><td><code id="runRegression_+3A_run.len">run.len</code></td>
<td>
<p>The window width to be used for a rolling regression. A value
of 3 for example for hourly data will consider 3 one-hour time sequences.</p>
</td></tr>
<tr><td><code id="runRegression_+3A_date.pad">date.pad</code></td>
<td>
<p>Should gaps in time series be filled before calculations are
made?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The intended use is to apply the approach to air pollution data to extract
consecutive points in time where the ratio between two pollutant
concentrations changes by very little. By filtering the output for high R2
values (typically more than 0.90 to 0.95), conditions where local source
dilution is dominant can be isolated for post processing. The function is
more fully descfibed and used in the <code>openair</code> online manual, together
with examples.
</p>


<h3>Value</h3>

<p>A tibble with <code>date</code> and calculated regression coefficients and
other information to plot dilution lines.
</p>


<h3>References</h3>

<p>For original inspiration:
</p>
<p>Bentley, S. T. (2004). Graphical techniques for constraining estimates of
aerosol emissions from motor vehicles using air monitoring network data.
Atmospheric Environment,(10), 1491–1500.
https://doi.org/10.1016/j.atmosenv.2003.11.033
</p>
<p>Example for vehicle emissions high time resolution data:
</p>
<p>Farren, N. J., Schmidt, C., Juchem, H., Pöhler, D., Wilde, S. E., Wagner, R.
L., Wilson, S., Shaw, M. D., &amp; Carslaw, D. C. (2023). Emission ratio
determination from road vehicles using a range of remote emission sensing
techniques. Science of The Total Environment, 875.
https://doi.org/10.1016/j.scitotenv.2023.162621.
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Just use part of a year of data
output &lt;- runRegression(selectByDate(mydata, year = 2004, month = 1:3),
x = "nox", y = "pm10", run.len = 3)

output
</code></pre>

<hr>
<h2 id='scatterPlot'>Flexible scatter plots</h2><span id='topic+scatterPlot'></span>

<h3>Description</h3>

<p>Scatter plots with conditioning and three main approaches: conventional
scatterPlot, hexagonal binning and kernel density estimates. The former also
has options for fitting smooth fits and linear models with uncertainties
shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scatterPlot(
  mydata,
  x = "nox",
  y = "no2",
  z = NA,
  method = "scatter",
  group = NA,
  avg.time = "default",
  data.thresh = 0,
  statistic = "mean",
  percentile = NA,
  type = "default",
  smooth = FALSE,
  spline = FALSE,
  linear = FALSE,
  ci = TRUE,
  mod.line = FALSE,
  cols = "hue",
  plot.type = "p",
  key = TRUE,
  key.title = group,
  key.columns = 1,
  key.position = "right",
  strip = TRUE,
  log.x = FALSE,
  log.y = FALSE,
  x.inc = NULL,
  y.inc = NULL,
  limits = NULL,
  windflow = NULL,
  y.relation = "same",
  x.relation = "same",
  ref.x = NULL,
  ref.y = NULL,
  k = NA,
  dist = 0.02,
  map = FALSE,
  auto.text = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scatterPlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing at least two numeric variables to plot.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_x">x</code></td>
<td>
<p>Name of the x-variable to plot. Note that x can be a date field or a
factor. For example, <code>x</code> can be one of the <code>openair</code> built in
types such as <code>"year"</code> or <code>"season"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_y">y</code></td>
<td>
<p>Name of the numeric y-variable to plot.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_z">z</code></td>
<td>
<p>Name of the numeric z-variable to plot for <code>method = "scatter"</code>
or <code>method = "level"</code>. Note that for <code>method = "scatter"</code> points
will be coloured according to a continuous colour scale, whereas for
<code>method = "level"</code> the surface is coloured.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_method">method</code></td>
<td>
<p>Methods include &ldquo;scatter&rdquo; (conventional scatter plot),
&ldquo;hexbin&rdquo; (hexagonal binning using the <code>hexbin</code> package).
&ldquo;level&rdquo; for a binned or smooth surface plot and &ldquo;density&rdquo; (2D
kernel density estimates).</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_group">group</code></td>
<td>
<p>The grouping variable to use, if any. Setting this to a variable
in the data frame has the effect of plotting several series in the same
panel using different symbols/colours etc. If set to a variable that is a
character or factor, those categories or factor levels will be used
directly. If set to a numeric variable, it will split that variable in to
quantiles.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_avg.time">avg.time</code></td>
<td>
<p>This defines the time period to average to. Can be
&ldquo;sec&rdquo;, &ldquo;min&rdquo;, &ldquo;hour&rdquo;, &ldquo;day&rdquo;, &ldquo;DSTday&rdquo;,
&ldquo;week&rdquo;, &ldquo;month&rdquo;, &ldquo;quarter&rdquo; or &ldquo;year&rdquo;. For much
increased flexibility a number can precede these options followed by a
space. For example, a timeAverage of 2 months would be <code>period = "2
  month"</code>. See function <code>timeAverage</code> for further details on this. This
option se useful as one method by which the number of points plotted is
reduced i.e. by choosing a longer averaging time.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold to use (\
the data using <code>avg.time</code>. A value of zero means that all available
data will be used in a particular period regardless if of the number of
values available. Conversely, a value of 100 will mean that all data will
need to be present for the average to be calculated, else it is recorded as
<code>NA</code>. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_statistic">statistic</code></td>
<td>
<p>The statistic to apply when aggregating the data; default is
the mean. Can be one of &quot;mean&quot;, &quot;max&quot;, &quot;min&quot;, &quot;median&quot;, &quot;frequency&quot;, &quot;sd&quot;,
&quot;percentile&quot;. Note that &quot;sd&quot; is the standard deviation and &quot;frequency&quot; is
the number (frequency) of valid records in the period. &quot;percentile&quot; is the
percentile level (\
&quot;percentile&quot; option - see below. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_percentile">percentile</code></td>
<td>
<p>The percentile level in percent used when <code>statistic =
  "percentile"</code> and when aggregating the data with <code>avg.time</code>. The
default is 95. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_smooth">smooth</code></td>
<td>
<p>A smooth line is fitted to the data if <code>TRUE</code>; optionally
with 95 percent confidence intervals shown. For <code>method = "level"</code> a
smooth surface will be fitted to binned data.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_spline">spline</code></td>
<td>
<p>A smooth spline is fitted to the data if <code>TRUE</code>. This is
particularly useful when there are fewer data points or when a connection
line between a sequence of points is required.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_linear">linear</code></td>
<td>
<p>A linear model is fitted to the data if <code>TRUE</code>; optionally
with 95 percent confidence intervals shown. The equation of the line and R2
value is also shown.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_ci">ci</code></td>
<td>
<p>Should the confidence intervals for the smooth/linear fit be shown?</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_mod.line">mod.line</code></td>
<td>
<p>If <code>TRUE</code> three lines are added to the scatter plot to
help inform model evaluation. The 1:1 line is solid and the 1:0.5 and 1:2
lines are dashed. Together these lines help show how close a group of
points are to a 1:1 relationship and also show the points that are within a
factor of two (FAC2). <code>mod.line</code> is appropriately transformed when x
or y axes are on a log scale.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_plot.type">plot.type</code></td>
<td>
<p><code>lattice</code> plot type. Can be &ldquo;p&rdquo; (points &mdash;
default), &ldquo;l&rdquo; (lines) or &ldquo;b&rdquo; (lines and points).</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_key">key</code></td>
<td>
<p>Should a key be drawn? The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_key.title">key.title</code></td>
<td>
<p>The title of the key (if used).</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted.  Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_strip">strip</code></td>
<td>
<p>Should a strip be drawn? The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_log.x">log.x</code></td>
<td>
<p>Should the x-axis appear on a log scale? The default is
<code>FALSE</code>. If <code>TRUE</code> a well-formatted log10 scale is used. This can
be useful for checking linearity once logged.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_log.y">log.y</code></td>
<td>
<p>Should the y-axis appear on a log scale? The default is
<code>FALSE</code>. If <code>TRUE</code> a well-formatted log10 scale is used. This can
be useful for checking linearity once logged.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_x.inc">x.inc</code></td>
<td>
<p>The x-interval to be used for binning data when <code>method =
"level"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_y.inc">y.inc</code></td>
<td>
<p>The y-interval to be used for binning data when <code>method =
"level"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_limits">limits</code></td>
<td>
<p>For <code>method = "level"</code> the function does its best to
choose sensible limits automatically. However, there are circumstances when
the user will wish to set different ones. The limits are set in the form
<code>c(lower, upper)</code>, so <code>limits = c(0, 100)</code> would force the plot
limits to span 0-100.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_windflow">windflow</code></td>
<td>
<p>This option allows a scatter plot to show the wind
speed/direction shows as an arrow. The option is a list e.g. <code>windflow
  = list(col = "grey", lwd = 2, scale = 0.1)</code>. This option requires wind
speed (<code>ws</code>) and wind direction (<code>wd</code>) to be available.
</p>
<p>The maximum length of the arrow plotted is a fraction of the plot dimension
with the longest arrow being <code>scale</code> of the plot x-y dimension. Note,
if the plot size is adjusted manually by the user it should be re-plotted
to ensure the correct wind angle. The list may contain other options to
<code>panel.arrows</code> in the <code>lattice</code> package. Other useful options
include <code>length</code>, which controls the length of the arrow head and
<code>angle</code>, which controls the angle of the arrow head.
</p>
<p>This option works best where there are not too many data to ensure
over-plotting does not become a problem.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_y.relation">y.relation</code></td>
<td>
<p>This determines how the y-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_x.relation">x.relation</code></td>
<td>
<p>This determines how the x-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_ref.x">ref.x</code></td>
<td>
<p>See <code>ref.y</code> for details.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_ref.y">ref.y</code></td>
<td>
<p>A list with details of the horizontal lines to be added
representing reference line(s). For example, <code>ref.y = list(h = 50, lty
  = 5)</code> will add a dashed horizontal line at 50. Several lines can be plotted
e.g. <code>ref.y = list(h = c(50, 100), lty = c(1, 5), col = c("green",
  "blue"))</code>. See <code>panel.abline</code> in the <code>lattice</code> package for more
details on adding/controlling lines.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_k">k</code></td>
<td>
<p>Smoothing parameter supplied to <code>gam</code> for fitting a smooth
surface when <code>method = "level"</code>.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_dist">dist</code></td>
<td>
<p>When plotting smooth surfaces (<code>method = "level"</code> and
<code>smooth = TRUE</code>, <code>dist</code> controls how far from the original data
the predictions should be made. See <code>exclude.too.far</code> from the
<code>mgcv</code> package. Data are first transformed to a unit square. Values
should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_map">map</code></td>
<td>
<p>Should a base map be drawn? This option is under development.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="scatterPlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto <code>cutData</code> and an
appropriate <code>lattice</code> plot function (<code>xyplot</code>, <code>levelplot</code>
or <code>hexbinplot</code> depending on <code>method</code>). For example,
<code>scatterPlot</code> passes the option <code>hemisphere = "southern"</code> on to
<code>cutData</code> to provide southern (rather than default northern)
hemisphere handling of <code>type = "season"</code>. Similarly, for the default
case <code>method = "scatter"</code> common axis and title labelling options
(such as <code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code>
via <code>quickText</code> to handle routine formatting. Other common graphical
parameters, e.g. <code>layout</code> for panel arrangement, <code>pch</code> for plot
symbol and <code>lwd</code> and <code>lty</code> for line width and type, as also
available (see examples below).
</p>
<p>For <code>method = "hexbin"</code> it can be useful to transform the scale if it
is dominated by a few very high values. This is possible by supplying two
functions: one that that applies the transformation and the other that
inverses it. For log scaling (the default) for example, <code>trans =
  function(x) log(x)</code> and <code>inv = function(x) exp(x)</code>. For a square root
transform use <code>trans = sqrt</code> and <code>inv = function(x) x^2</code>. To not
carry out any transformation the options <code>trans = NULL</code> and <code>inv
  = NULL</code> should be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+scatterPlot">scatterPlot()</a></code> is the basic function for plotting scatter plots in flexible
ways in <code>openair</code>. It is flexible enough to consider lots of
conditioning variables and takes care of fitting smooth or linear
relationships to the data.
</p>
<p>There are four main ways of plotting the relationship between two variables,
which are set using the <code>method</code> option. The default <code>"scatter"</code>
will plot a conventional scatterPlot. In cases where there are lots of data
and over-plotting becomes a problem, then <code>method = "hexbin"</code> or
<code>method = "density"</code> can be useful. The former requires the
<code>hexbin</code> package to be installed.
</p>
<p>There is also a <code>method = "level"</code> which will bin the <code>x</code> and
<code>y</code> data according to the intervals set for <code>x.inc</code> and
<code>y.inc</code> and colour the bins according to levels of a third variable,
<code>z</code>. Sometimes however, a far better understanding of the relationship
between three variables (<code>x</code>, <code>y</code> and <code>z</code>) is gained by
fitting a smooth surface through the data. See examples below.
</p>
<p>A smooth fit is shown if <code>smooth = TRUE</code> which can help show the overall
form of the data e.g. whether the relationship appears to be linear or not.
Also, a linear fit can be shown using <code>linear = TRUE</code> as an option.
</p>
<p>The user has fine control over the choice of colours and symbol type used.
</p>
<p>Another way of reducing the number of points used in the plots which can
sometimes be useful is to aggregate the data. For example, hourly data can be
aggregated to daily data. See <code><a href="#topic+timePlot">timePlot()</a></code> for examples here.
</p>
<p>By default plots are shown with a colour key at the bottom and in the case of
conditioning, strips on the top of each plot. Sometimes this may be overkill
and the user can opt to remove the key and/or the strip by setting <code>key</code>
and/or <code>strip</code> to <code>FALSE</code>. One reason to do this is to maximise the
plotting area and therefore the information shown.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p><code><a href="#topic+linearRelation">linearRelation</a></code>, <code><a href="#topic+timePlot">timePlot</a></code> and
<code><a href="#topic+timeAverage">timeAverage()</a></code> for details on selecting averaging times and other
statistics in a flexible way
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load openair data if not loaded already
dat2004 &lt;- selectByDate(mydata, year = 2004)

# basic use, single pollutant

scatterPlot(dat2004, x = "nox", y = "no2")
## Not run: 
# scatterPlot by year
scatterPlot(mydata, x = "nox", y = "no2", type = "year")

## End(Not run)

# scatterPlot by day of the week, removing key at bottom
scatterPlot(dat2004, x = "nox", y = "no2", type = "weekday", key =
FALSE)

# example of the use of continuous where colour is used to show
# different levels of a third (numeric) variable
# plot daily averages and choose a filled plot symbol (pch = 16)
# select only 2004
## Not run: 

scatterPlot(dat2004, x = "nox", y = "no2", z = "co", avg.time = "day", pch = 16)

# show linear fit, by year
scatterPlot(mydata, x = "nox", y = "no2", type = "year", smooth =
FALSE, linear = TRUE)

# do the same, but for daily means...
scatterPlot(mydata, x = "nox", y = "no2", type = "year", smooth =
FALSE, linear = TRUE, avg.time = "day")

# log scales
scatterPlot(mydata, x = "nox", y = "no2", type = "year", smooth =
FALSE, linear = TRUE, avg.time = "day", log.x = TRUE, log.y = TRUE)

# also works with the x-axis in date format (alternative to timePlot)
scatterPlot(mydata, x = "date", y = "no2", avg.time = "month",
key = FALSE)

## multiple types and grouping variable and continuous colour scale
scatterPlot(mydata, x = "nox", y = "no2", z = "o3", type = c("season", "weekend"))

# use hexagonal binning

library(hexbin)
# basic use, single pollutant
scatterPlot(mydata, x = "nox", y = "no2", method = "hexbin")

# scatterPlot by year
scatterPlot(mydata, x = "nox", y = "no2", type = "year", method =
"hexbin")


## bin data and plot it - can see how for high NO2, O3 is also high

scatterPlot(mydata, x = "nox", y = "no2", z = "o3", method = "level", dist = 0.02)


## fit surface for clearer view of relationship - clear effect of
## increased O3

scatterPlot(mydata, x = "nox", y = "no2", z = "o3", method = "level",
x.inc = 10, y.inc = 2, smooth = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='selectByDate'>Subset a data frame based on date</h2><span id='topic+selectByDate'></span>

<h3>Description</h3>

<p>Utility function to make it easier to select periods from a data frame
before sending to a function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectByDate(
  mydata,
  start = "1/1/2008",
  end = "31/12/2008",
  year = 2008,
  month = 1,
  day = "weekday",
  hour = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectByDate_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing a <code>date</code> field in hourly or high
resolution format.</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_start">start</code></td>
<td>
<p>A start date string in the form d/m/yyyy e.g. &ldquo;1/2/1999&rdquo;
or in &lsquo;R&rsquo; format i.e. &ldquo;YYYY-mm-dd&rdquo;, &ldquo;1999-02-01&rdquo;</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_end">end</code></td>
<td>
<p>See <code>start</code> for format.</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_year">year</code></td>
<td>
<p>A year or years to select e.g. <code>year = 1998:2004</code> to select
1998-2004 inclusive or <code>year = c(1998, 2004)</code> to select 1998 and
2004.</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_month">month</code></td>
<td>
<p>A month or months to select. Can either be numeric e.g.
<code>month = 1:6</code> to select months 1-6 (January to June), or by name e.g.
<code>month = c("January", "December")</code>. Names can be abbreviated to 3
letters and be in lower or upper case.</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_day">day</code></td>
<td>
<p>A day name or or days to select. <code>day</code> can be numeric (1 to
31) or character. For example <code>day = c("Monday", "Wednesday")</code> or
<code>day = 1:10</code> (to select the 1st to 10th of each month). Names can be
abbreviated to 3 letters and be in lower or upper case. Also accepts
&ldquo;weekday&rdquo; (Monday - Friday) and &ldquo;weekend&rdquo; for convenience.</p>
</td></tr>
<tr><td><code id="selectByDate_+3A_hour">hour</code></td>
<td>
<p>An hour or hours to select from 0-23 e.g. <code>hour = 0:12</code> to
select hours 0 to 12 inclusive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it much easier to select periods of interest from a data
frame based on dates in a British format. Selecting date/times in R format
can be intimidating for new users. This function can be used to select quite
complex dates simply - see examples below.
</p>
<p>Dates are assumed to be inclusive, so <code>start = "1/1/1999"</code> means that
times are selected from hour zero. Similarly, <code>end = "31/12/1999"</code> will
include all hours of the 31st December. <code>start</code> and <code>end</code> can also
be in standard R format as a string i.e. &quot;YYYY-mm-dd&quot;, so <code>start =
"1999-01-01"</code> is fine.
</p>
<p>All options are applied in turn making it possible to select quite complex
dates
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## select all of 1999
data.1999 &lt;- selectByDate(mydata, start = "1/1/1999", end = "31/12/1999")
head(data.1999)
tail(data.1999)

# or...
data.1999 &lt;- selectByDate(mydata, start = "1999-01-01", end = "1999-12-31")

# easier way
data.1999 &lt;- selectByDate(mydata, year = 1999)


# more complex use: select weekdays between the hours of 7 am to 7 pm
sub.data &lt;- selectByDate(mydata, day = "weekday", hour = 7:19)

# select weekends between the hours of 7 am to 7 pm in winter (Dec, Jan, Feb)
sub.data &lt;- selectByDate(mydata, day = "weekend", hour = 7:19, month =
c("dec", "jan", "feb"))

</code></pre>

<hr>
<h2 id='selectRunning'>Function to extract run lengths greater than a threshold</h2><span id='topic+selectRunning'></span>

<h3>Description</h3>

<p>Utility function to extract user-defined run lengths (durations) above a
threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectRunning(
  mydata,
  pollutant = "nox",
  criterion = "&gt;",
  run.len = 5,
  threshold = 500,
  result = c("yes", "no")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectRunning_+3A_mydata">mydata</code></td>
<td>
<p>A data frame with a <code>date</code> field and at least one numeric
<code>pollutant</code> field to analyse.</p>
</td></tr>
<tr><td><code id="selectRunning_+3A_pollutant">pollutant</code></td>
<td>
<p>Name of variable to process. Mandatory.</p>
</td></tr>
<tr><td><code id="selectRunning_+3A_criterion">criterion</code></td>
<td>
<p>Condition to select run lengths e.g. <code>"&gt;"</code> with select
data more than <code>threshold</code>.</p>
</td></tr>
<tr><td><code id="selectRunning_+3A_run.len">run.len</code></td>
<td>
<p>Run length for extracting contiguous values of
<code>pollutant</code> above the <code>threshold</code> value.</p>
</td></tr>
<tr><td><code id="selectRunning_+3A_threshold">threshold</code></td>
<td>
<p>The threshold value for <code>pollutant</code> above which data
should be extracted.</p>
</td></tr>
<tr><td><code id="selectRunning_+3A_result">result</code></td>
<td>
<p>A new column <code>criterion</code> is returned with string to
identity whether condition was met.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a utility function to extract runs of values above a certain
threshold. For example, for a data frame of hourly NOx values we would like
to extract all those hours where the concentration is at least 500ppb for
contiguous periods of 5 or more hours.
</p>
<p>This function is useful, for example, for selecting pollution episodes from
a data frame i.e. where concentrations remain elevated for a certain period
of time. It may also be of more general use when analysing air pollution
data. For example, <code>selectRunning</code> could be used to extract continuous
periods of rainfall &mdash; which could be important for particle
concentrations.
</p>


<h3>Value</h3>

<p>Returns a data frame that meets the chosen criteria. See examples
below.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## extract those hours where there are at least 5 consecutive NOx
## concentrations above 500ppb

mydata &lt;- selectRunning(mydata, run.len = 5, threshold = 500)

## make a polar plot of those conditions...shows that those
## conditions are dominated by low wind speeds, not
## in-canyon recirculation
## Not run: polarPlot(mydata, pollutant = "nox", type = "criterion")

</code></pre>

<hr>
<h2 id='smoothTrend'>Calculate nonparametric smooth trends</h2><span id='topic+smoothTrend'></span>

<h3>Description</h3>

<p>Use non-parametric methods to calculate time series trends
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothTrend(
  mydata,
  pollutant = "nox",
  deseason = FALSE,
  type = "default",
  statistic = "mean",
  avg.time = "month",
  percentile = NA,
  data.thresh = 0,
  simulate = FALSE,
  n = 200,
  autocor = FALSE,
  cols = "brewer1",
  shade = "grey95",
  xlab = "year",
  y.relation = "same",
  ref.x = NULL,
  ref.y = NULL,
  key.columns = length(percentile),
  name.pol = pollutant,
  ci = TRUE,
  alpha = 0.2,
  date.breaks = 7,
  auto.text = TRUE,
  k = NULL,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothTrend_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing the field <code>date</code> and at least one
other parameter for which a trend test is required; typically (but not
necessarily) a pollutant.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_pollutant">pollutant</code></td>
<td>
<p>The parameter for which a trend test is required.
Mandatory.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_deseason">deseason</code></td>
<td>
<p>Should the data be de-deasonalized first? If <code>TRUE</code> the
function <code>stl</code> is used (seasonal trend decomposition using loess).
Note that if <code>TRUE</code> missing data are first imputed using a
Kalman filter and Kalman smooth.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and
so on. For example, <code>type = "season"</code> will produce four plots &mdash; one
for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_statistic">statistic</code></td>
<td>
<p>Statistic used for calculating monthly values. Default is
&ldquo;mean&rdquo;, but can also be &ldquo;percentile&rdquo;. See <code>timeAverage</code>
for more details.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_avg.time">avg.time</code></td>
<td>
<p>Can be &ldquo;month&rdquo; (the default), &ldquo;season&rdquo; or
&ldquo;year&rdquo;. Determines the time over which data should be averaged.
Note that for &ldquo;year&rdquo;, six or more years are required. For
&ldquo;season&rdquo; the data are plit up into spring: March, April, May etc.
Note that December is considered as belonging to winter of the following
year.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_percentile">percentile</code></td>
<td>
<p>Percentile value(s) to use if <code>statistic =
  "percentile"</code> is chosen. Can be a vector of numbers e.g. <code>percentile
  = c(5, 50, 95)</code> will plot the 5th, 50th and 95th percentile values
together on the same plot.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold to use (%) when aggregating
the data using <code>avg.time</code>. A value of zero means that all available
data will be used in a particular period regardless if of the number of
values available. Conversely, a value of 100 will mean that all data will
need to be present for the average to be calculated, else it is recorded
as <code>NA</code>. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_simulate">simulate</code></td>
<td>
<p>Should simulations be carried out to determine the
Mann-Kendall tau and p-value. The default is <code>FALSE</code>. If <code>TRUE</code>,
bootstrap simulations are undertaken, which also account for
autocorrelation.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_n">n</code></td>
<td>
<p>Number of bootstrap simulations if <code>simulate = TRUE</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_autocor">autocor</code></td>
<td>
<p>Should autocorrelation be considered in the trend uncertainty
estimates? The default is <code>FALSE</code>. Generally, accounting for
autocorrelation increases the uncertainty of the trend estimate sometimes
by a large amount.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_cols">cols</code></td>
<td>
<p>Colours to use. Can be a vector of colours e.g. <code>cols =
  c("black", "green")</code> or pre-defined openair colours &mdash; see
<code>openColours</code> for more details.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_shade">shade</code></td>
<td>
<p>The colour used for marking alternate years. Use &ldquo;white&rdquo;
or &ldquo;transparent&rdquo; to remove shading.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label, by default &ldquo;year&rdquo;.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_y.relation">y.relation</code></td>
<td>
<p>This determines how the y-axis scale is plotted. &quot;same&quot;
ensures all panels use the same scale and &quot;free&quot; will use panel-specific
scales. The latter is a useful setting when plotting data with very
different values.  ref.x See <code>ref.y</code> for details. In this case the
correct date format should be used for a vertical line e.g.  <code>ref.x =
  list(v = as.POSIXct("2000-06-15"), lty = 5)</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_ref.x">ref.x</code></td>
<td>
<p>See <code>ref.y</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_ref.y">ref.y</code></td>
<td>
<p>A list with details of the horizontal lines to be added
representing reference line(s). For example, <code>ref.y = list(h = 50,
  lty = 5)</code> will add a dashed horizontal line at 50. Several lines can be
plotted e.g. <code>ref.y = list(h = c(50, 100), lty = c(1, 5), col =
  c("green", "blue"))</code>. See <code>panel.abline</code> in the <code>lattice</code>
package for more details on adding/controlling lines.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns used if a key is drawn when using the
option <code>statistic = "percentile"</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_name.pol">name.pol</code></td>
<td>
<p>Names to be given to the pollutant(s). This is useful if you
want to give a fuller description of the variables, maybe also including
subscripts etc.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_ci">ci</code></td>
<td>
<p>Should confidence intervals be plotted? The default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency of shaded confidence intervals - if
plotted. A value of 0 is fully transparent and 1 is fully opaque.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function
will try and choose a sensible number of dates/times as well as formatting
the date/time appropriately to the range being considered. This does not
always work as desired automatically. The user can therefore increase or
decrease the number of intervals by adjusting the value of
<code>date.breaks</code> up or down.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If
<code>TRUE</code> titles and axis labels will automatically try and format
pollutant names and units properly e.g.  by subscripting the &lsquo;2&rsquo; in
NO2.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_k">k</code></td>
<td>
<p>This is the smoothing parameter used by the <code>gam</code> function in
package <code>mgcv</code>. By default it is not used and the amount of smoothing
is optimised automatically. However, sometimes it is useful to set the
smoothing amount manually using <code>k</code>.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other
ways.</p>
</td></tr>
<tr><td><code id="smoothTrend_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>smoothTrend</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common graphical arguments, such as <code>xlim</code> and
<code>ylim</code> for plotting ranges and <code>pch</code> and <code>cex</code> for plot
symbol type and size, are passed on <code>xyplot</code>, although some local
modifications may be applied by openair. For example, axis and title
labelling options (such as <code>xlab</code>, <code>ylab</code> and <code>main</code>) are
passed to <code>xyplot</code> via <code>quickText</code> to handle routine formatting.
One special case here is that many graphical parameters can be vectors
when used with <code>statistic = "percentile"</code> and a vector of
<code>percentile</code> values, see examples below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>smoothTrend</code> function provides a flexible way of estimating the
trend in the concentration of a pollutant or other variable. Monthly mean
values are calculated from an hourly (or higher resolution) or daily time
series. There is the option to deseasonalise the data if there is evidence
of a seasonal cycle.
</p>
<p><code>smoothTrend</code> uses a Generalized Additive Model (GAM) from the
<code><a href="mgcv.html#topic+gam">gam</a></code> package to find the most appropriate level of smoothing.
The function is particularly suited to situations where trends are not
monotonic (see discussion with <code><a href="#topic+TheilSen">TheilSen()</a></code> for more details on
this). The <code>smoothTrend</code> function is particularly useful as an
exploratory technique e.g. to check how linear or non-linear trends are.
</p>
<p>95% confidence intervals are shown by shading. Bootstrap estimates of the
confidence intervals are also available through the <code>simulate</code> option.
Residual resampling is used.
</p>
<p>Trends can be considered in a very wide range of ways, controlled by setting
<code>type</code> - see examples below.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># trend plot for nox
smoothTrend(mydata, pollutant = "nox")

# trend plot by each of 8 wind sectors
## Not run: smoothTrend(mydata, pollutant = "o3", type = "wd", ylab = "o3 (ppb)")

# several pollutants, no plotting symbol
## Not run: smoothTrend(mydata, pollutant = c("no2", "o3", "pm10", "pm25"), pch = NA)

# percentiles
## Not run: smoothTrend(mydata, pollutant = "o3", statistic = "percentile",
percentile = 95)
## End(Not run)

# several percentiles with control over lines used
## Not run: smoothTrend(mydata, pollutant = "o3", statistic = "percentile",
percentile = c(5, 50, 95), lwd = c(1, 2, 1), lty = c(5, 1, 5))
## End(Not run)
</code></pre>

<hr>
<h2 id='splitByDate'>Divide up a data frame by time</h2><span id='topic+splitByDate'></span>

<h3>Description</h3>

<p>Utility function to prepare input data for use in openair functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitByDate(
  mydata,
  dates = "1/1/2003",
  labels = c("before", "after"),
  name = "split.by"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitByDate_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing a <code>date</code> field in hourly or high
resolution format.</p>
</td></tr>
<tr><td><code id="splitByDate_+3A_dates">dates</code></td>
<td>
<p>A date or dates to split data by.</p>
</td></tr>
<tr><td><code id="splitByDate_+3A_labels">labels</code></td>
<td>
<p>Labels for each time partition.</p>
</td></tr>
<tr><td><code id="splitByDate_+3A_name">name</code></td>
<td>
<p>The name to give the new column to identify the periods split</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function partitions a data frame up into different time segments. It
produces a new column called controlled by <code>name</code> that can be used in many
<code>openair</code> functions. Note that there must be one more label than there
are dates. See examples below and in full <code>openair</code> documentation.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## split data up into "before" and "after"
mydata &lt;- splitByDate(mydata, dates = "1/04/2000",
labels = c("before", "after"))

## split data into 3 partitions:
mydata &lt;- splitByDate(mydata, dates = c("1/1/2000", "1/3/2003"),
labels = c("before", "during", "after"))


</code></pre>

<hr>
<h2 id='summaryPlot'>Function to rapidly provide an overview of air quality data</h2><span id='topic+summaryPlot'></span>

<h3>Description</h3>

<p>This function provides a quick graphical and numerical summary of data. The
location presence/absence of data are shown, with summary statistics and
plots of variable distributions. <code><a href="#topic+summaryPlot">summaryPlot()</a></code> can also provide summaries
of a single pollutant across many sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryPlot(
  mydata,
  na.len = 24,
  clip = TRUE,
  percentile = 0.99,
  type = "histogram",
  pollutant = "nox",
  period = "years",
  avg.time = "day",
  print.datacap = TRUE,
  breaks = NULL,
  plot.type = "l",
  col.trend = "darkgoldenrod2",
  col.data = "lightblue",
  col.mis = rgb(0.65, 0.04, 0.07),
  col.hist = "forestgreen",
  cols = NULL,
  date.breaks = 7,
  auto.text = TRUE,
  plot = TRUE,
  debug = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryPlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame to be summarised. Must contain a <code>date</code> field and
at least one other parameter.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_na.len">na.len</code></td>
<td>
<p>Missing data are only shown with at least <code>na.len</code>
<em>contiguous</em> missing vales. The purpose of setting <code>na.len</code> is
for clarity: with long time series it is difficult to see where individual
missing hours are. Furthermore, setting <code>na.len = 96</code>, for example would
show where there are at least 4 days of continuous missing data.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_clip">clip</code></td>
<td>
<p>When data contain outliers, the histogram or density plot can
fail to show the distribution of the main body of data. Setting <code>clip = TRUE</code>, will remove the top 1 % of data to yield what is often a better
display of the overall distribution of the data. The amount of clipping can
be set with <code>percentile</code>.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_percentile">percentile</code></td>
<td>
<p>This is used to clip the data. For example, <code>percentile = 0.99</code> (the default) will remove the top 1 percentile of values i.e. values
greater than the 99th percentile will not be used.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_type">type</code></td>
<td>
<p><code>type</code> is used to determine whether a histogram (the default) or
a density plot is used to show the distribution of the data.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_pollutant">pollutant</code></td>
<td>
<p><code>pollutant</code> is used when there is a field <code>site</code> and there
is more than one site in the data frame.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_period">period</code></td>
<td>
<p><code>period</code> is either <code>years</code> (the default) or <code>months</code>.
Statistics are calculated depending on the <code>period</code> chosen.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_avg.time">avg.time</code></td>
<td>
<p>This defines the time period to average the time series
plots. Can be &quot;sec&quot;, &quot;min&quot;, &quot;hour&quot;, &quot;day&quot; (the default), &quot;week&quot;, &quot;month&quot;,
&quot;quarter&quot; or &quot;year&quot;. For much increased flexibility a number can precede
these options followed by a space. For example, a <code><a href="#topic+timeAverage">timeAverage()</a></code> of 2
months would be <code>avg.time = "2 month"</code>.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_print.datacap">print.datacap</code></td>
<td>
<p>Should the data capture % be shown for each period?</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_breaks">breaks</code></td>
<td>
<p>Number of histogram bins. Sometime useful but not easy to set a
single value for a range of very different variables.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_plot.type">plot.type</code></td>
<td>
<p>The <code>lattice</code> plot type, which is a line (<code>plot.type = "l"</code>)
by default. Another useful option is <code>plot.type = "h"</code>, which draws
vertical lines.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_col.trend">col.trend</code></td>
<td>
<p>Colour to be used to show the monthly trend of the data,
shown as a shaded region. Type <code>colors()</code> into R to see the full range of
colour names.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_col.data">col.data</code></td>
<td>
<p>Colour to be used to show the <em>presence</em> of data. Type
<code>colors()</code> into R to see the full range of colour names.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_col.mis">col.mis</code></td>
<td>
<p>Colour to be used to show missing data.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_col.hist">col.hist</code></td>
<td>
<p>Colour for the histogram or density plot.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_cols">cols</code></td>
<td>
<p>Predefined colour scheme, currently only enabled for
<code>"greyscale"</code>.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function will
try and choose a sensible number of dates/times as well as formatting the
date/time appropriately to the range being considered.  This does not
always work as desired automatically. The user can therefore increase or
decrease the number of intervals by adjusting the value of <code>date.breaks</code> up
or down.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code> titles and
axis labels will automatically try and format pollutant names and units
properly, e.g., by subscripting the '2' in NO2.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when analysing
data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_debug">debug</code></td>
<td>
<p>Should data types be printed to the console? <code>TRUE</code> can be
useful for debugging.</p>
</td></tr>
<tr><td><code id="summaryPlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters. Commonly used examples include the
axis and title labelling options (such as <code>xlab</code>, <code>ylab</code> and <code>main</code>), which
are all passed to the plot via <code><a href="#topic+quickText">quickText()</a></code> to handle routine formatting.
As <code><a href="#topic+summaryPlot">summaryPlot()</a></code> has two components, the axis labels may be a vector. For
example, the default case (<code>type = "histogram"</code>) sets y labels equivalent
to <code>ylab = c("", "Percent of Total")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summaryPlot">summaryPlot()</a></code> produces two panels of plots: one showing the
presence/absence of data and the other the distributions. The left panel
shows time series and codes the presence or absence of data in different
colours. By stacking the plots one on top of another it is easy to compare
different pollutants/variables. Overall statistics are given for each
variable: mean, maximum, minimum, missing hours (also expressed as a
percentage), median and the 95th percentile. For each year the data capture
rate (expressed as a percentage of hours in that year) is also given.
</p>
<p>The right panel shows either a histogram or a density plot depending on the
choice of <code>type</code>. Density plots avoid the issue of arbitrary bin sizes that
can sometimes provide a misleading view of the data distribution. Density
plots are often more appropriate, but their effectiveness will depend on the
data in question.
</p>
<p><code><a href="#topic+summaryPlot">summaryPlot()</a></code> will only show data that are numeric or integer type. This is
useful for checking that data have been imported properly. For example, if
for some reason a column representing wind speed erroneously had one or more
fields with characters in, the whole column would be either character or
factor type. The absence of a wind speed variable in the <code><a href="#topic+summaryPlot">summaryPlot()</a></code> plot
would therefore indicate a problem with the input data. In this particular
case, the user should go back to the source data and remove the characters or
remove them using R functions.
</p>
<p>If there is a field <code>site</code>, which would generally mean there is more than one
site, <code><a href="#topic+summaryPlot">summaryPlot()</a></code> will provide information on a
<em>single</em> pollutant across all sites, rather than provide details on all
pollutants at a <em>single</em> site. In this case the user should also provide a
name of a pollutant e.g. <code>pollutant = "nox"</code>. If a pollutant is not provided
the first numeric field will automatically be chosen.
</p>
<p><strong>It is strongly recommended that the <code><a href="#topic+summaryPlot">summaryPlot()</a></code> function is
applied to all new imported data sets to ensure the data are imported as
expected.</strong>
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>Examples</h3>

<pre><code class='language-R'># do not clip density plot data
## Not run: 
summaryPlot(mydata, clip = FALSE)

## End(Not run)

# exclude highest 5 % of data etc.
## Not run: 
summaryPlot(mydata, percentile = 0.95)

## End(Not run)

# show missing data where there are at least 96 contiguous missing
# values (4 days)
## Not run: 
summaryPlot(mydata, na.len = 96)

## End(Not run)

# show data in green
## Not run: 
summaryPlot(mydata, col.data = "green")

## End(Not run)

# show missing data in yellow
## Not run: 
summaryPlot(mydata, col.mis = "yellow")

## End(Not run)

# show density plot line in black
## Not run: 
summaryPlot(mydata, col.dens = "black")

## End(Not run)

</code></pre>

<hr>
<h2 id='TaylorDiagram'>Taylor Diagram for model evaluation with conditioning</h2><span id='topic+TaylorDiagram'></span>

<h3>Description</h3>

<p>Function to draw Taylor Diagrams for model evaluation. The function allows
conditioning by any categorical or numeric variables, which makes the
function very flexible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TaylorDiagram(
  mydata,
  obs = "obs",
  mod = "mod",
  group = NULL,
  type = "default",
  normalise = FALSE,
  cols = "brewer1",
  rms.col = "darkgoldenrod",
  cor.col = "black",
  arrow.lwd = 3,
  annotate = "centred\nRMS error",
  text.obs = "observed",
  key = TRUE,
  key.title = group,
  key.columns = 1,
  key.pos = "right",
  strip = TRUE,
  auto.text = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TaylorDiagram_+3A_mydata">mydata</code></td>
<td>
<p>A data frame minimally containing a column of observations and
a column of predictions.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_obs">obs</code></td>
<td>
<p>A column of observations with which the predictions (<code>mod</code>)
will be compared.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_mod">mod</code></td>
<td>
<p>A column of model predictions. Note, <code>mod</code> can be of length 2
i.e. two lots of model predictions. If two sets of predictions are are
present e.g. <code>mod = c("base", "revised")</code>, then arrows are shown on
the Taylor Diagram which show the change in model performance in going from
the first to the second. This is useful where, for example, there is
interest in comparing how one model run compares with another using
different assumptions e.g. input data or model set up. See examples below.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_group">group</code></td>
<td>
<p>The <code>group</code> column is used to differentiate between
different models and can be a factor or character. The total number of
models compared will be equal to the number of unique values of
<code>group</code>.
</p>
<p><code>group</code> can also be of length two e.g. <code>group = c("model",
  "site")</code>. In this case all model-site combinations will be shown but they
will only be differentiated by colour/symbol by the first grouping variable
(&quot;model&quot; in this case). In essence the plot removes the differentiation by
the second grouping variable. Because there will be different values of
<code>obs</code> for each group, <code>normalise = TRUE</code> should be used.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.
</p>
<p>Note that often it will make sense to use <code>type = "site"</code> when
multiple sites are available. This will ensure that each panel contains
data specific to an individual site.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_normalise">normalise</code></td>
<td>
<p>Should the data be normalised by dividing the standard
deviation of the observations? The statistics can be normalised (and
non-dimensionalised) by dividing both the RMS difference and the standard
deviation of the <code>mod</code> values by the standard deviation of the
observations (<code>obs</code>). In this case the &ldquo;observed&rdquo; point is
plotted on the x-axis at unit distance from the origin. This makes it
possible to plot statistics for different species (maybe with different
units) on the same plot. The normalisation is done by each
<code>group</code>/<code>type</code> combination.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Useful options for categorical
data are available from <code>RColorBrewer</code> colours &mdash; see the
<code>openair</code> <code>openColours</code> function for more details. Useful schemes
include &ldquo;Accent&rdquo;, &ldquo;Dark2&rdquo;, &ldquo;Paired&rdquo;, &ldquo;Pastel1&rdquo;,
&ldquo;Pastel2&rdquo;, &ldquo;Set1&rdquo;, &ldquo;Set2&rdquo;, &ldquo;Set3&rdquo; &mdash; but see
?<code>brewer.pal</code> for the maximum useful colours in each. For user defined
the user can supply a list of colour names recognised by R (type
<code>colours()</code> to see the full list). An example would be <code>cols =
  c("yellow", "green", "blue")</code>.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_rms.col">rms.col</code></td>
<td>
<p>Colour for centred-RMS lines and text.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_cor.col">cor.col</code></td>
<td>
<p>Colour for correlation coefficient lines and text.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_arrow.lwd">arrow.lwd</code></td>
<td>
<p>Width of arrow used when used for comparing two model
outputs.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_annotate">annotate</code></td>
<td>
<p>Annotation shown for RMS error.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_text.obs">text.obs</code></td>
<td>
<p>The plot annotation for observed values; default is
&quot;observed&quot;.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_key">key</code></td>
<td>
<p>Should the key be shown?</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_key.title">key.title</code></td>
<td>
<p>Title for the key.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_key.pos">key.pos</code></td>
<td>
<p>Position of the key e.g. &ldquo;top&rdquo;, &ldquo;bottom&rdquo;,
&ldquo;left&rdquo; and &ldquo;right&rdquo;. See details in <code>lattice:xyplot</code> for
more details about finer control.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_strip">strip</code></td>
<td>
<p>Should a strip be shown?</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="TaylorDiagram_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>TaylorDiagram</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common graphical parameters, such as <code>layout</code>
for panel arrangement and <code>pch</code> and <code>cex</code> for plot symbol type
and size, are passed on to <code>xyplot</code>. Most are passed unmodified,
although there are some special cases where <code>openair</code> may locally
manage this process. For example, common axis and title labelling options
(such as <code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Taylor Diagram is a very useful model evaluation tool. The diagram
provides a way of showing how three complementary model performance
statistics vary simultaneously. These statistics are the correlation
coefficient R, the standard deviation (sigma) and the (centred)
root-mean-square error. These three statistics can be plotted on one (2D)
graph because of the way they are related to one another which can be
represented through the Law of Cosines.
</p>
<p>The <code>openair</code> version of the Taylor Diagram has several enhancements
that increase its flexibility. In particular, the straightforward way of
producing conditioning plots should prove valuable under many circumstances
(using the <code>type</code> option). Many examples of Taylor Diagrams focus on
model-observation comparisons for several models using all the available
data. However, more insight can be gained into model performance by
partitioning the data in various ways e.g. by season, daylight/nighttime, day
of the week, by levels of a numeric variable e.g. wind speed or by land-use
type etc.
</p>
<p>To consider several pollutants on one plot, a column identifying the
pollutant name can be used e.g. <code>pollutant</code>. Then the Taylor Diagram can
be plotted as (assuming a data frame <code>thedata</code>):
</p>
<p><code>TaylorDiagram(thedata, obs = "obs", mod = "mod", group = "model", type
= "pollutant")</code>
</p>
<p>which will give the model performance by pollutant in each panel.
</p>
<p>Note that it is important that each panel represents data with the same mean
observed data across different groups. Therefore <code>TaylorDiagram(mydata,
group = "model", type = "season")</code> is OK, whereas <code>TaylorDiagram(mydata,
group = "season", type = "model")</code> is not because each panel (representing a
model) will have four different mean values &mdash; one for each season.
Generally, the option <code>group</code> is either missing (one model being
evaluated) or represents a column giving the model name. However, the data
can be normalised using the <code>normalise</code> option. Normalisation is carried
out on a per <code>group</code>/<code>type</code> basis making it possible to compare
data on different scales e.g. <code>TaylorDiagram(mydata, group = "season",
type = "model", normalise = TRUE)</code>. In this way it is possible to compare
different pollutants, sites etc. in the same panel.
</p>
<p>Also note that if multiple sites are present it makes sense to use <code>type
= "site"</code> to ensure that each panel represents an individual site with its
own specific standard deviation etc. If this is not the case then select a
single site from the data first e.g. <code>subset(mydata, site ==
"Harwell")</code>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. If retained, e.g., using
<code>output &lt;- TaylorDiagram(thedata, obs = "nox", mod = "mod")</code>, this
output can be used to recover the data, reproduce or rework the original
plot or undertake further analysis. For example, <code>output$data</code> will be
a data frame consisting of the group, type, correlation coefficient (R),
the standard deviation of the observations and measurements.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Taylor, K.E.: Summarizing multiple aspects of model performance in a single
diagram. J.  Geophys. Res., 106, 7183-7192, 2001 (also see PCMDI Report 55).
</p>


<h3>See Also</h3>

<p><code>taylor.diagram</code> from the <code>plotrix</code> package from which
some of the annotation code was used.
</p>
<p>Other model evaluation functions: 
<code><a href="#topic+conditionalEval">conditionalEval</a>()</code>,
<code><a href="#topic+conditionalQuantile">conditionalQuantile</a>()</code>,
<code><a href="#topic+modStats">modStats</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## in the examples below, most effort goes into making some artificial data
## the function itself can be run very simply
## Not run: 
## dummy model data for 2003
dat &lt;- selectByDate(mydata, year = 2003)
dat &lt;- data.frame(date = mydata$date, obs = mydata$nox, mod = mydata$nox)

## now make mod worse by adding bias and noise according to the month
## do this for 3 different models
dat &lt;- transform(dat, month = as.numeric(format(date, "%m")))
mod1 &lt;- transform(dat, mod = mod + 10 * month + 10 * month * rnorm(nrow(dat)),
model = "model 1")
## lag the results for mod1 to make the correlation coefficient worse
## without affecting the sd
mod1 &lt;- transform(mod1, mod = c(mod[5:length(mod)], mod[(length(mod) - 3) :
length(mod)]))

## model 2
mod2 &lt;- transform(dat, mod = mod + 7 * month + 7 * month * rnorm(nrow(dat)),
model = "model 2")
## model 3
mod3 &lt;- transform(dat, mod = mod + 3 * month + 3 * month * rnorm(nrow(dat)),
model = "model 3")

mod.dat &lt;- rbind(mod1, mod2, mod3)

## basic Taylor plot

TaylorDiagram(mod.dat, obs = "obs", mod = "mod", group = "model")

## Taylor plot by season
TaylorDiagram(mod.dat, obs = "obs", mod = "mod", group = "model", type = "season")

## now show how to evaluate model improvement (or otherwise)
mod1a &lt;- transform(dat, mod = mod + 2 * month + 2 * month * rnorm(nrow(dat)),
model = "model 1")
mod2a &lt;- transform(mod2, mod = mod * 1.3)
mod3a &lt;- transform(dat, mod = mod + 10 * month + 10 * month * rnorm(nrow(dat)),
model = "model 3")
mod.dat2 &lt;- rbind(mod1a, mod2a, mod3a)
mod.dat$mod2 &lt;- mod.dat2$mod

## now we have a data frame with 3 models, 1 set of observations
## and TWO sets of model predictions (mod and mod2)

## do for all models
TaylorDiagram(mod.dat, obs = "obs", mod = c("mod", "mod2"), group = "model")

## End(Not run)
## Not run: 
## all models, by season
TaylorDiagram(mod.dat, obs = "obs", mod = c("mod", "mod2"), group = "model",
type = "season")

## consider two groups (model/month). In this case all months are shown by model
## but are only differentiated by model.

TaylorDiagram(mod.dat, obs = "obs", mod = "mod", group = c("model", "month"))

## End(Not run)
</code></pre>

<hr>
<h2 id='TheilSen'>Tests for trends using Theil-Sen estimates</h2><span id='topic+TheilSen'></span>

<h3>Description</h3>

<p>Theil-Sen slope estimates and tests for trend.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TheilSen(
  mydata,
  pollutant = "nox",
  deseason = FALSE,
  type = "default",
  avg.time = "month",
  statistic = "mean",
  percentile = NA,
  data.thresh = 0,
  alpha = 0.05,
  dec.place = 2,
  xlab = "year",
  lab.frac = 0.99,
  lab.cex = 0.8,
  x.relation = "same",
  y.relation = "same",
  data.col = "cornflowerblue",
  trend = list(lty = c(1, 5), lwd = c(2, 1), col = c("red", "red")),
  text.col = "darkgreen",
  slope.text = NULL,
  cols = NULL,
  shade = "grey95",
  auto.text = TRUE,
  autocor = FALSE,
  slope.percent = FALSE,
  date.breaks = 7,
  date.format = NULL,
  plot = TRUE,
  silent = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TheilSen_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing the field <code>date</code> and at least one
other parameter for which a trend test is required; typically (but not
necessarily) a pollutant.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_pollutant">pollutant</code></td>
<td>
<p>The parameter for which a trend test is required.
Mandatory.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_deseason">deseason</code></td>
<td>
<p>Should the data be de-deasonalized first? If <code>TRUE</code> the
function <code>stl</code> is used (seasonal trend decomposition using loess).
Note that if <code>TRUE</code> missing data are first imputed using a
Kalman filter and Kalman smooth.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and
so on. For example, <code>type = "season"</code> will produce four plots &mdash; one
for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_avg.time">avg.time</code></td>
<td>
<p>Can be &ldquo;month&rdquo; (the default), &ldquo;season&rdquo; or
&ldquo;year&rdquo;. Determines the time over which data should be averaged.
Note that for &ldquo;year&rdquo;, six or more years are required. For
&ldquo;season&rdquo; the data are split up into spring: March, April, May etc.
Note that December is considered as belonging to winter of the following
year.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_statistic">statistic</code></td>
<td>
<p>Statistic used for calculating monthly values. Default is
&ldquo;mean&rdquo;, but can also be &ldquo;percentile&rdquo;. See <code>timeAverage</code>
for more details.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_percentile">percentile</code></td>
<td>
<p>Single percentile value to use if <code>statistic =
"percentile"</code> is chosen.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold to use (%) when aggregating
the data using <code>avg.time</code>. A value of zero means that all available
data will be used in a particular period regardless if of the number of
values available. Conversely, a value of 100 will mean that all data will
need to be present for the average to be calculated, else it is recorded
as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_alpha">alpha</code></td>
<td>
<p>For the confidence interval calculations of the slope. The
default is 0.05. To show 99\
trend, choose alpha = 0.01 etc.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_dec.place">dec.place</code></td>
<td>
<p>The number of decimal places to display the trend estimate
at. The default is 2.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label, by default <code>"year"</code>.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_lab.frac">lab.frac</code></td>
<td>
<p>Fraction along the y-axis that the trend information should
be printed at, default 0.99.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_lab.cex">lab.cex</code></td>
<td>
<p>Size of text for trend information.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_x.relation">x.relation</code></td>
<td>
<p>This determines how the x-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_y.relation">y.relation</code></td>
<td>
<p>This determines how the y-axis scale is plotted.
&ldquo;same&rdquo; ensures all panels use the same scale and &ldquo;free&rdquo; will
use panel-specific scales. The latter is a useful setting when plotting
data with very different values.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_data.col">data.col</code></td>
<td>
<p>Colour name for the data</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_trend">trend</code></td>
<td>
<p>list containing information on the line width, line type and
line colour for the main trend line and confidence intervals respectively.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_text.col">text.col</code></td>
<td>
<p>Colour name for the slope/uncertainty numeric estimates</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_slope.text">slope.text</code></td>
<td>
<p>The text shown for the slope (default is
&lsquo;units/year&rsquo;).</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_cols">cols</code></td>
<td>
<p>Predefined colour scheme, currently only enabled for
<code>"greyscale"</code>.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_shade">shade</code></td>
<td>
<p>The colour used for marking alternate years. Use &ldquo;white&rdquo;
or &ldquo;transparent&rdquo; to remove shading.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If
<code>TRUE</code> titles and axis labels will automatically try and format
pollutant names and units properly e.g.  by subscripting the &lsquo;2&rsquo; in
NO2.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_autocor">autocor</code></td>
<td>
<p>Should autocorrelation be considered in the trend uncertainty
estimates? The default is <code>FALSE</code>. Generally, accounting for
autocorrelation increases the uncertainty of the trend estimate &mdash;
sometimes by a large amount.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_slope.percent">slope.percent</code></td>
<td>
<p>Should the slope and the slope uncertainties be
expressed as a percentage change per year? The default is <code>FALSE</code> and
the slope is expressed as an average units/year change e.g. ppb.
Percentage changes can often be confusing and should be clearly defined.
Here the percentage change is expressed as 100 * (C.end/C.start - 1) /
(end.year - start.year). Where C.start is the concentration at the start
date and C.end is the concentration at the end date.
</p>
<p>For <code>avg.time = "year"</code> (end.year - start.year) will be the total
number of years - 1. For example, given a concentration in year 1 of 100
units and a percentage reduction of 5%/yr, after 5 years there will be 75
units but the actual time span will be 6 years i.e. year 1 is used as a
reference year. Things are slightly different for monthly values e.g.
<code>avg.time = "month"</code>, which will use the total number of months as a
basis of the time span and is therefore able to deal with partial years.
There can be slight differences in the %/yr trend estimate therefore,
depending on whether monthly or annual values are considered.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function
will try and choose a sensible number of dates/times as well as formatting
the date/time appropriately to the range being considered. This does not
always work as desired automatically. The user can therefore increase or
decrease the number of intervals by adjusting the value of
<code>date.breaks</code> up or down.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_date.format">date.format</code></td>
<td>
<p>This option controls the date format on the
x-axis. While <code>TheilSen</code> generally sets the date format
sensibly there can be some situations where the user wishes to
have more control. For format types see <code>strptime</code>. For
example, to format the date like &ldquo;Jan-2012&rdquo; set
<code>date.format = "%b-%Y"</code>.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract trend components and plotting them in other
ways.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_silent">silent</code></td>
<td>
<p>When <code>FALSE</code> the function will give updates on
trend-fitting progress.</p>
</td></tr>
<tr><td><code id="TheilSen_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>TheilSen</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>TheilSen</code> function provides a collection of functions to
analyse trends in air pollution data. The <code>TheilSen</code> function
is flexible in the sense that it can be applied to data in many
ways e.g. by day of the week, hour of day and wind direction. This
flexibility makes it much easier to draw inferences from data
e.g. why is there a strong downward trend in concentration from
one wind sector and not another, or why trends on one day of the
week or a certain time of day are unexpected.
</p>
<p>For data that are strongly seasonal, perhaps from a background
site, or a pollutant such as ozone, it will be important to
deseasonalise the data (using the option <code>deseason =
TRUE</code>.Similarly, for data that increase, then decrease, or show
sharp changes it may be better to use <code><a href="#topic+smoothTrend">smoothTrend</a></code>.
</p>
<p>A minimum of 6 points are required for trend estimates to be made.
</p>
<p>Note! that since version 0.5-11 openair uses Theil-Sen to derive
the p values also for the slope. This is to ensure there is
consistency between the calculated p value and other trend
parameters i.e. slope estimates and uncertainties. The p value and
all uncertainties are calculated through bootstrap simulations.
</p>
<p>Note that the symbols shown next to each trend estimate relate to
how statistically significant the trend estimate is: p $&lt;$ 0.001 =
***, p $&lt;$ 0.01 = **, p $&lt;$ 0.05 = * and p $&lt;$ 0.1 = $+$.
</p>
<p>Some of the code used in <code>TheilSen</code> is based on that from
Rand Wilcox. This mostly
relates to the Theil-Sen slope estimates and uncertainties.
Further modifications have been made to take account of correlated
data based on Kunsch (1989). The basic function has been adapted
to take account of auto-correlated data using block bootstrap
simulations if <code>autocor = TRUE</code> (Kunsch, 1989). We follow the
suggestion of Kunsch (1989) of setting the block length to n(1/3)
where n is the length of the time series.
</p>
<p>The slope estimate and confidence intervals in the slope are plotted and
numerical information presented.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. The <code>data</code> component of the
<code>TheilSen</code> output includes two subsets: <code>main.data</code>, the monthly
data <code>res2</code> the trend statistics. For <code>output &lt;- TheilSen(mydata,
  "nox")</code>, these can be extracted as <code>object$data$main.data</code> and
<code>object$data$res2</code>, respectively. Note: In the case of the intercept,
it is assumed the y-axis crosses the x-axis on 1/1/1970.
</p>


<h3>Author(s)</h3>

<p>David Carslaw with some trend code from Rand Wilcox
</p>


<h3>References</h3>

<p>Helsel, D., Hirsch, R., 2002. Statistical methods in water resources. US
Geological Survey. Note that
this is a very good resource for statistics as applied to environmental
data.
</p>
<p>Hirsch, R. M., Slack, J. R., Smith, R. A., 1982. Techniques of trend
analysis for monthly water-quality data. Water Resources Research 18 (1),
107-121.
</p>
<p>Kunsch, H. R., 1989. The jackknife and the bootstrap for general stationary
observations. Annals of Statistics 17 (3), 1217-1241.
</p>
<p>Sen, P. K., 1968. Estimates of regression coefficient based on
Kendall's tau. Journal of the American Statistical Association
63(324).
</p>
<p>Theil, H., 1950. A rank invariant method of linear and polynomial
regression analysis, i, ii, iii. Proceedings of the Koninklijke
Nederlandse Akademie Wetenschappen, Series A - Mathematical
Sciences 53, 386-392, 521-525, 1397-1412.
</p>
<p>... see also several of the Air Quality Expert Group (AQEG) reports for
the use of similar tests applied to UK/European air quality data.
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># trend plot for nox
TheilSen(mydata, pollutant = "nox")

# trend plot for ozone with p=0.01 i.e. uncertainty in slope shown at
# 99 % confidence interval

## Not run: TheilSen(mydata, pollutant = "o3", ylab = "o3 (ppb)", alpha = 0.01)

# trend plot by each of 8 wind sectors
## Not run: TheilSen(mydata, pollutant = "o3", type = "wd", ylab = "o3 (ppb)")

# and for a subset of data (from year 2000 onwards)
## Not run: TheilSen(selectByDate(mydata, year = 2000:2005), pollutant = "o3", ylab = "o3 (ppb)")
</code></pre>

<hr>
<h2 id='timeAverage'>Function to calculate time averages for data frames</h2><span id='topic+timeAverage'></span>

<h3>Description</h3>

<p>Function to flexibly aggregate or expand data frames by different time
periods, calculating vector-averaged wind direction where appropriate. The
averaged periods can also take account of data capture rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeAverage(
  mydata,
  avg.time = "day",
  data.thresh = 0,
  statistic = "mean",
  type = "default",
  percentile = NA,
  start.date = NA,
  end.date = NA,
  interval = NA,
  vector.ws = FALSE,
  fill = FALSE,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeAverage_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing a <code>date</code> field . Can be class
<code>POSIXct</code> or <code>Date</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_avg.time">avg.time</code></td>
<td>
<p>This defines the time period to average to. Can be
&ldquo;sec&rdquo;, &ldquo;min&rdquo;, &ldquo;hour&rdquo;, &ldquo;day&rdquo;, &ldquo;DSTday&rdquo;,
&ldquo;week&rdquo;, &ldquo;month&rdquo;, &ldquo;quarter&rdquo; or &ldquo;year&rdquo;. For much
increased flexibility a number can precede these options followed by a
space. For example, a timeAverage of 2 months would be <code>period = "2
  month"</code>. In addition, <code>avg.time</code> can equal &ldquo;season&rdquo;, in which
case 3-month seasonal values are calculated with spring defined as March,
April, May and so on.
</p>
<p>Note that <code>avg.time</code> can be <em>less</em> than the time interval of the
original series, in which case the series is expanded to the new time
interval. This is useful, for example, for calculating a 15-minute time
series from an hourly one where an hourly value is repeated for each new
15-minute period. Note that when expanding data in this way it is necessary
to ensure that the time interval of the original series is an exact
multiple of <code>avg.time</code> e.g. hour to 10 minutes, day to hour. Also, the
input time series must have consistent time gaps between successive
intervals so that <code>timeAverage</code> can work out how much &lsquo;padding&rsquo;
to apply. To pad-out data in this way choose <code>fill = TRUE</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold to use (%). A value of zero
means that all available data will be used in a particular period
regardless if of the number of values available. Conversely, a value of 100
will mean that all data will need to be present for the average to be
calculated, else it is recorded as <code>NA</code>. See also <code>interval</code>,
<code>start.date</code> and <code>end.date</code> to see whether it is advisable to set
these other options.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_statistic">statistic</code></td>
<td>
<p>The statistic to apply when aggregating the data; default is
the mean. Can be one of &ldquo;mean&rdquo;, &ldquo;max&rdquo;, &ldquo;min&rdquo;,
&ldquo;median&rdquo;, &ldquo;frequency&rdquo;, &ldquo;sum&rdquo;, &ldquo;sd&rdquo;,
&ldquo;percentile&rdquo;. Note that &ldquo;sd&rdquo; is the standard deviation,
&ldquo;frequency&rdquo; is the number (frequency) of valid records in the period
and &ldquo;data.cap&rdquo; is the percentage data capture. &ldquo;percentile&rdquo;
is the percentile level (%) between 0-100, which can be set using the
&ldquo;percentile&rdquo; option &mdash; see below. Not used if <code>avg.time =
  "default"</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_type">type</code></td>
<td>
<p><code>type</code> allows <code>timeAverage</code> to be applied to cases
where there are groups of data that need to be split and the function
applied to each group. The most common example is data with multiple sites
identified with a column representing site name e.g. <code>type = "site"</code>.
More generally, <code>type</code> should be used where the date repeats for a
particular grouping variable. However, if type is not supplied the data
will still be averaged but the grouping variables (character or factor)
will be dropped.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_percentile">percentile</code></td>
<td>
<p>The percentile level used when <code>statistic =
"percentile"</code>. The default is 95%.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_start.date">start.date</code></td>
<td>
<p>A string giving a start date to use. This is sometimes
useful if a time series starts between obvious intervals. For example, for
a 1-minute time series that starts &ldquo;2009-11-29 12:07:00&rdquo; that needs
to be averaged up to 15-minute means, the intervals would be
&ldquo;2009-11-29 12:07:00&rdquo;, &ldquo;2009-11-29 12:22:00&rdquo; etc. Often,
however, it is better to round down to a more obvious start point e.g.
&ldquo;2009-11-29 12:00:00&rdquo; such that the sequence is then
&ldquo;2009-11-29 12:00:00&rdquo;, &ldquo;2009-11-29 12:15:00&rdquo; ...
<code>start.date</code> is therefore used to force this type of sequence.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_end.date">end.date</code></td>
<td>
<p>A string giving an end date to use. This is sometimes useful
to make sure a time series extends to a known end point and is useful when
<code>data.thresh</code> &gt; 0 but the input time series does not extend up to the
final full interval. For example, if a time series ends sometime in October
but annual means are required with a data capture of &gt;75 % then it is
necessary to extend the time series up until the end of the year. Input in
the format yyyy-mm-dd HH:MM.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_interval">interval</code></td>
<td>
<p>The <code>timeAverage</code> function tries to determine the
interval of the original time series (e.g. hourly) by calculating the most
common interval between time steps. The interval is needed for calculations
where the <code>data.thresh</code> &gt;0. For the vast majority of regular time
series this works fine. However, for data with very poor data capture or
irregular time series the automatic detection may not work. Also, for time
series such as monthly time series where there is a variable difference in
time between months users should specify the time interval explicitly e.g.
<code>interval = "month"</code>. Users can also supply a time interval to
<em>force</em> on the time series. See <code>avg.time</code> for the format.
</p>
<p>This option can sometimes be useful with <code>start.date</code> and
<code>end.date</code> to ensure full periods are considered e.g. a full year when
<code>avg.time = "year"</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_vector.ws">vector.ws</code></td>
<td>
<p>Should vector averaging be carried out on wind speed if
available? The default is <code>FALSE</code> and scalar averages are calculated.
Vector averaging of the wind speed is carried out on the u and v wind
components. For example, consider the average of two hours where the wind
direction and speed of the first hour is 0 degrees and 2m/s and 180 degrees
and 2m/s for the second hour. The scalar average of the wind speed is
simply the arithmetic average = 2m/s and the vector average is 0m/s.
Vector-averaged wind speeds will always be lower than scalar-averaged
values.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_fill">fill</code></td>
<td>
<p>When time series are expanded i.e. when a time interval is less
than the original time series, data are &lsquo;padded out&rsquo; with <code>NA</code>.
To &lsquo;pad-out&rsquo; the additional data with the first row in each original
time interval, choose <code>fill = TRUE</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_progress">progress</code></td>
<td>
<p>Show a progress bar when many groups make up <code>type</code>? Defaults
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="timeAverage_+3A_...">...</code></td>
<td>
<p>Additional arguments for other functions calling
<code>timeAverage</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates time averages for a data frame. It also treats wind
direction correctly through vector-averaging. For example, the average of 350
degrees and 10 degrees is either 0 or 360 - not 180. The calculations
therefore average the wind components.
</p>
<p>When a data capture threshold is set through <code>data.thresh</code> it is
necessary for <code>timeAverage</code> to know what the original time interval of
the input time series is. The function will try and calculate this interval
based on the most common time gap (and will print the assumed time gap to the
screen). This works fine most of the time but there are occasions where it
may not e.g. when very few data exist in a data frame or the data are monthly
(i.e. non-regular time interval between months). In this case the user can
explicitly specify the interval through <code>interval</code> in the same format as
<code>avg.time</code> e.g. <code>interval = "month"</code>. It may also be useful to set
<code>start.date</code> and <code>end.date</code> if the time series do not span the
entire period of interest. For example, if a time series ended in October and
annual means are required, setting <code>end.date</code> to the end of the year
will ensure that the whole period is covered and that <code>data.thresh</code> is
correctly calculated. The same also goes for a time series that starts later
in the year where <code>start.date</code> should be set to the beginning of the
year.
</p>
<p><code>timeAverage</code> should be useful in many circumstances where it is
necessary to work with different time average data. For example, hourly air
pollution data and 15-minute meteorological data. To merge the two data sets
<code>timeAverage</code> can be used to make the meteorological data 1-hour means
first. Alternatively, <code>timeAverage</code> can be used to expand the hourly
data to 15 minute data - see example below.
</p>
<p>For the research community <code>timeAverage</code> should be useful for dealing
with outputs from instruments where there are a range of time periods used.
</p>
<p>It is also very useful for plotting data using <code><a href="#topic+timePlot">timePlot</a></code>. Often
the data are too dense to see patterns and setting different averaging
periods easily helps with interpretation.
</p>


<h3>Value</h3>

<p>Returns a data frame with date in class <code>POSIXct</code>.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+timePlot">timePlot</a></code> that plots time series data and uses
<code>timeAverage</code> to aggregate data where necessary.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## daily average values
daily &lt;- timeAverage(mydata, avg.time = "day")

## daily average values ensuring at least 75 % data capture
## i.e. at least 18 valid hours
## Not run: daily &lt;- timeAverage(mydata, avg.time = "day", data.thresh = 75)

## 2-weekly averages
## Not run: fortnight &lt;- timeAverage(mydata, avg.time = "2 week")

## make a 15-minute time series from an hourly one
## Not run: 
min15 &lt;-  timeAverage(mydata, avg.time = "15 min", fill = TRUE)

## End(Not run)

# average by grouping variable
## Not run: 
dat &lt;- importAURN(c("kc1", "my1"), year = 2011:2013)
timeAverage(dat, avg.time = "year", type = "site")

# can also retain site code
timeAverage(dat, avg.time = "year", type = c("site", "code"))

# or just average all the data, dropping site/code
timeAverage(dat, avg.time = "year")

## End(Not run)
</code></pre>

<hr>
<h2 id='timePlot'>Plot time series</h2><span id='topic+timePlot'></span>

<h3>Description</h3>

<p>Plot time series quickly, perhaps for multiple pollutants, grouped or in
separate panels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timePlot(
  mydata,
  pollutant = "nox",
  group = FALSE,
  stack = FALSE,
  normalise = NULL,
  avg.time = "default",
  data.thresh = 0,
  statistic = "mean",
  percentile = NA,
  date.pad = FALSE,
  type = "default",
  cols = "brewer1",
  plot.type = "l",
  key = TRUE,
  log = FALSE,
  windflow = NULL,
  smooth = FALSE,
  ci = TRUE,
  y.relation = "same",
  ref.x = NULL,
  ref.y = NULL,
  key.columns = 1,
  key.position = "bottom",
  name.pol = pollutant,
  date.breaks = 7,
  date.format = NULL,
  auto.text = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timePlot_+3A_mydata">mydata</code></td>
<td>
<p>A data frame of time series. Must include a <code>date</code> field
and at least one variable to plot.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_pollutant">pollutant</code></td>
<td>
<p>Name of variable to plot. Two or more pollutants can be
plotted, in which case a form like <code>pollutant = c("nox", "co")</code> should
be used.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_group">group</code></td>
<td>
<p>If more than one pollutant is chosen, should they all be plotted
on the same graph together? The default is <code>FALSE</code>, which means they
are plotted in separate panels with their own scaled. If <code>TRUE</code> then
they are plotted on the same plot with the same scale.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_stack">stack</code></td>
<td>
<p>If <code>TRUE</code> the time series will be stacked by year. This
option can be useful if there are several years worth of data making it
difficult to see much detail when plotted on a single plot.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_normalise">normalise</code></td>
<td>
<p>Should variables be normalised? The default is is not to
normalise the data. <code>normalise</code> can take two values, either
&ldquo;mean&rdquo; or a string representing a date in UK format e.g. &quot;1/1/1998&quot;
(in the format dd/mm/YYYY). If <code>normalise = "mean"</code> then each time
series is divided by its mean value.  If a date is chosen, then values at
that date are set to 100 and the rest of the data scaled accordingly.
Choosing a date (say at the beginning of a time series) is very useful for
showing how trends diverge over time. Setting <code>group = TRUE</code> is often
useful too to show all time series together in one panel.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_avg.time">avg.time</code></td>
<td>
<p>This defines the time period to average to. Can be
&ldquo;sec&rdquo;, &ldquo;min&rdquo;, &ldquo;hour&rdquo;, &ldquo;day&rdquo;, &ldquo;DSTday&rdquo;,
&ldquo;week&rdquo;, &ldquo;month&rdquo;, &ldquo;quarter&rdquo; or &ldquo;year&rdquo;. For much
increased flexibility a number can precede these options followed by a
space. For example, a timeAverage of 2 months would be <code>period = "2
  month"</code>. See function <code>timeAverage</code> for further details on this.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_data.thresh">data.thresh</code></td>
<td>
<p>The data capture threshold to use when aggregating the
data using <code>avg.time</code>. A value of zero means that all available data
will be used in a particular period regardless if of the number of values
available. Conversely, a value of 100 will mean that all data will need to
be present for the average to be calculated, else it is recorded as
<code>NA</code>. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_statistic">statistic</code></td>
<td>
<p>The statistic to apply when aggregating the data; default is
the mean. Can be one of &ldquo;mean&rdquo;, &ldquo;max&rdquo;, &ldquo;min&rdquo;,
&ldquo;median&rdquo;, &ldquo;frequency&rdquo;, &ldquo;sd&rdquo;, &ldquo;percentile&rdquo;. Note
that &ldquo;sd&rdquo; is the standard deviation and &ldquo;frequency&rdquo; is the
number (frequency) of valid records in the period.  &ldquo;percentile&rdquo; is
the percentile level between 0-100, which can be set using the
&ldquo;percentile&rdquo; option - see below. Not used if <code>avg.time =
  "default"</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_percentile">percentile</code></td>
<td>
<p>The percentile level in percent used when <code>statistic =
  "percentile"</code> and when aggregating the data with <code>avg.time</code>. More than
one percentile level is allowed for <code>type = "default"</code> e.g.
<code>percentile = c(50, 95)</code>. Not used if <code>avg.time = "default"</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_date.pad">date.pad</code></td>
<td>
<p>Should missing data be padded-out? This is useful where a
data frame consists of two or more &quot;chunks&quot; of data with time gaps between
them. By setting <code>date.pad = TRUE</code> the time gaps between the chunks
are shown properly, rather than with a line connecting each chunk. For
irregular data, set to <code>FALSE</code>. Note, this should not be set for
<code>type</code> other than <code>default</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Only one <code>type</code> is currently allowed in <code>timePlot</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</td></tr>
<tr><td><code id="timePlot_+3A_plot.type">plot.type</code></td>
<td>
<p>The <code>lattice</code> plot type, which is a line
(<code>plot.type = "l"</code>) by default. Another useful option is
<code>plot.type = "h"</code>, which draws vertical lines.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_key">key</code></td>
<td>
<p>Should a key be drawn? The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_log">log</code></td>
<td>
<p>Should the y-axis appear on a log scale? The default is
<code>FALSE</code>. If <code>TRUE</code> a well-formatted log10 scale is used. This can
be useful for plotting data for several different pollutants that exist on
very different scales. It is therefore useful to use <code>log = TRUE</code>
together with <code>group = TRUE</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_windflow">windflow</code></td>
<td>
<p>This option allows a scatter plot to show the wind
speed/direction as an arrow. The option is a list e.g. <code>windflow =
  list(col = "grey", lwd = 2, scale = 0.1)</code>. This option requires wind speed
(<code>ws</code>) and wind direction (<code>wd</code>) to be available.
</p>
<p>The maximum length of the arrow plotted is a fraction of the plot dimension
with the longest arrow being <code>scale</code> of the plot x-y dimension. Note,
if the plot size is adjusted manually by the user it should be re-plotted
to ensure the correct wind angle. The list may contain other options to
<code>panel.arrows</code> in the <code>lattice</code> package. Other useful options
include <code>length</code>, which controls the length of the arrow head and
<code>angle</code>, which controls the angle of the arrow head.
</p>
<p>This option works best where there are not too many data to ensure
over-plotting does not become a problem.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_smooth">smooth</code></td>
<td>
<p>Should a smooth line be applied to the data? The default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_ci">ci</code></td>
<td>
<p>If a smooth fit line is applied, then <code>ci</code> determines whether
the 95 percent confidence intervals are shown.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_y.relation">y.relation</code></td>
<td>
<p>This determines how the y-axis scale is plotted. &quot;same&quot;
ensures all panels use the same scale and &quot;free&quot; will use panel-specific
scales. The latter is a useful setting when plotting data with very
different values.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_ref.x">ref.x</code></td>
<td>
<p>See <code>ref.y</code> for details. In this case the correct date
format should be used for a vertical line e.g. <code>ref.x = list(v =
  as.POSIXct("2000-06-15"), lty = 5)</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_ref.y">ref.y</code></td>
<td>
<p>A list with details of the horizontal lines to be added
representing reference line(s). For example, <code>ref.y = list(h = 50, lty
  = 5)</code> will add a dashed horizontal line at 50. Several lines can be plotted
e.g. <code>ref.y = list(h = c(50, 100), lty = c(1, 5), col = c("green",
  "blue"))</code>. See <code>panel.abline</code> in the <code>lattice</code> package for more
details on adding/controlling lines.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Can include
&ldquo;top&rdquo;, &ldquo;bottom&rdquo;, &ldquo;right&rdquo; and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_name.pol">name.pol</code></td>
<td>
<p>This option can be used to give alternative names for the
variables plotted. Instead of taking the column headings as names, the user
can supply replacements. For example, if a column had the name &ldquo;nox&rdquo;
and the user wanted a different description, then setting <code>name.pol =
  "nox before change"</code> can be used. If more than one pollutant is plotted
then use <code>c</code> e.g. <code>name.pol = c("nox here", "o3 there")</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function will
try and choose a sensible number of dates/times as well as formatting the
date/time appropriately to the range being considered. This does not always
work as desired automatically. The user can therefore increase or decrease
the number of intervals by adjusting the value of <code>date.breaks</code> up or
down.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_date.format">date.format</code></td>
<td>
<p>This option controls the date format on the x-axis. While
<code>timePlot</code> generally sets the date format sensibly there can be some
situations where the user wishes to have more control. For format types see
<code>strptime</code>. For example, to format the date like &ldquo;Jan-2012&rdquo; set
<code>date.format = "%b-%Y"</code>.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="timePlot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed onto <code>cutData</code> and
<code>lattice:xyplot</code>. For example, <code>timePlot</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, most common plotting parameters, such as
<code>layout</code> for panel arrangement and <code>pch</code> and <code>cex</code> for plot
symbol type and size and <code>lty</code> and <code>lwd</code> for line type and width,
as passed to <code>xyplot</code>, although some maybe locally managed by
<code>openair</code> on route, e.g. axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed via <code>quickText</code> to
handle routine formatting. See examples below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>timePlot</code> is the basic time series plotting function in
<code>openair</code>. Its purpose is to make it quick and easy to plot time series
for pollutants and other variables. The other purpose is to plot potentially
many variables together in as compact a way as possible.
</p>
<p>The function is flexible enough to plot more than one variable at once. If
more than one variable is chosen plots it can either show all variables on
the same plot (with different line types) <em>on the same scale</em>, or (if
<code>group = FALSE</code>) each variable in its own panels with its own scale.
</p>
<p>The general preference is not to plot two variables on the same graph with
two different y-scales. It can be misleading to do so and difficult with more
than two variables. If there is in interest in plotting several variables
together that have very different scales, then it can be useful to normalise
the data first, which can be down be setting the <code>normalise</code> option.
</p>
<p>The user has fine control over the choice of colours, line width and line
types used. This is useful for example, to emphasise a particular variable
with a specific line type/colour/width.
</p>
<p><code>timePlot</code> works very well with <code><a href="#topic+selectByDate">selectByDate()</a></code>, which is used for
selecting particular date ranges quickly and easily. See examples below.
</p>
<p>By default plots are shown with a colour key at the bottom and in the case of
multiple pollutants or sites, strips on the left of each plot. Sometimes this
may be overkill and the user can opt to remove the key and/or the strip by
setting <code>key</code> and/or <code>strip</code> to <code>FALSE</code>. One reason to do this
is to maximise the plotting area and therefore the information shown.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# basic use, single pollutant
timePlot(mydata, pollutant = "nox")

# two pollutants in separate panels
## Not run: timePlot(mydata, pollutant = c("nox", "no2"))

# two pollutants in the same panel with the same scale
## Not run: timePlot(mydata, pollutant = c("nox", "no2"), group = TRUE)

# alternative by normalising concentrations and plotting on the same
  scale
## Not run: 
timePlot(mydata, pollutant = c("nox", "co", "pm10", "so2"), group = TRUE, avg.time =
  "year", normalise = "1/1/1998", lwd = 3, lty = 1)

## End(Not run)

# examples of selecting by date

# plot for nox in 1999
## Not run: timePlot(selectByDate(mydata, year = 1999), pollutant = "nox")

# select specific date range for two pollutants
## Not run: 
timePlot(selectByDate(mydata, start = "6/8/2003", end = "13/8/2003"),
pollutant = c("no2", "o3"))

## End(Not run)

# choose different line styles etc
## Not run: timePlot(mydata, pollutant = c("nox", "no2"), lty = 1)

# choose different line styles etc
## Not run: 
timePlot(selectByDate(mydata, year = 2004, month = 6), pollutant =
c("nox", "no2"), lwd = c(1, 2), col = "black")

## End(Not run)

# different averaging times

#daily mean O3
## Not run: timePlot(mydata, pollutant = "o3", avg.time = "day")

# daily mean O3 ensuring each day has data capture of at least 75%
## Not run: timePlot(mydata, pollutant = "o3", avg.time = "day", data.thresh = 75)

# 2-week average of O3 concentrations
## Not run: timePlot(mydata, pollutant = "o3", avg.time = "2 week")

</code></pre>

<hr>
<h2 id='timeProp'>Time series plot with categories shown as a stacked bar chart</h2><span id='topic+timeProp'></span>

<h3>Description</h3>

<p>This function shows time series plots as stacked bar charts. The different
categories in the bar chart are made up from a character or factor variable
in a data frame. The function is primarily developed to support the plotting
of cluster analysis output from <code><a href="#topic+polarCluster">polarCluster</a></code> and
<code><a href="#topic+trajCluster">trajCluster</a></code> that consider local and regional (back trajectory)
cluster analysis respectively. However, the function has more general use for
understanding time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeProp(
  mydata,
  pollutant = "nox",
  proportion = "cluster",
  avg.time = "day",
  type = "default",
  normalise = FALSE,
  cols = "Set1",
  date.breaks = 7,
  date.format = NULL,
  key.columns = 1,
  key.position = "right",
  key.title = proportion,
  auto.text = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeProp_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing the fields <code>date</code>,
<code>pollutant</code> and a splitting variable <code>proportion</code></p>
</td></tr>
<tr><td><code id="timeProp_+3A_pollutant">pollutant</code></td>
<td>
<p>Name of the pollutant to plot contained in <code>mydata</code>.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_proportion">proportion</code></td>
<td>
<p>The splitting variable that makes up the bars in the bar
chart e.g. <code>proportion = "cluster"</code> if the output from
<code>polarCluster</code> is being analysed. If <code>proportion</code> is a numeric
variable it is split into 4 quantiles (by default) by <code>cutData</code>. If
<code>proportion</code> is a factor or character variable then the categories are
used directly.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_avg.time">avg.time</code></td>
<td>
<p>This defines the time period to average to. Can be
&ldquo;sec&rdquo;, &ldquo;min&rdquo;, &ldquo;hour&rdquo;, &ldquo;day&rdquo;, &ldquo;DSTday&rdquo;,
&ldquo;week&rdquo;, &ldquo;month&rdquo;, &ldquo;quarter&rdquo; or &ldquo;year&rdquo;. For much
increased flexibility a number can precede these options followed by a
space. For example, a timeAverage of 2 months would be <code>period = "2
  month"</code>.
</p>
<p>Note that <code>avg.time</code> when used in <code>timeProp</code> should be greater
than the time gap in the original data. For example, <code>avg.time =
  "day"</code> for hourly data is OK, but <code>avg.time = "hour"</code> for daily data
is not.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &quot;season&quot;, &quot;year&quot;, &quot;weekday&quot; and so on. For example,
<code>type = "season"</code> will produce four plots &mdash; one for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p><code>type</code> must be of length one.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_normalise">normalise</code></td>
<td>
<p>If <code>normalise = TRUE</code> then each time interval is scaled
to 100. This is helpful to show the relative (percentage) contribution of
the proportions.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</td></tr>
<tr><td><code id="timeProp_+3A_date.breaks">date.breaks</code></td>
<td>
<p>Number of major x-axis intervals to use. The function will
try and choose a sensible number of dates/times as well as formatting the
date/time appropriately to the range being considered.  This does not
always work as desired automatically. The user can therefore increase or
decrease the number of intervals by adjusting the value of
<code>date.breaks</code> up or down.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_date.format">date.format</code></td>
<td>
<p>This option controls the date format on the x-axis. While
<code>timePlot</code> generally sets the date format sensibly there can be some
situations where the user wishes to have more control. For format types see
<code>strptime</code>. For example, to format the date like &ldquo;Jan-2012&rdquo; set
<code>date.format = "%b-%Y"</code>.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_key.title">key.title</code></td>
<td>
<p>The title of the key.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels etc. will automatically try and format pollutant
names and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="timeProp_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>timeProp</code> and
<code>cutData</code>. For example, <code>timeProp</code> passes the option
<code>hemisphere = "southern"</code> on to <code>cutData</code> to provide southern
(rather than default northern) hemisphere handling of <code>type =
  "season"</code>. Similarly, common axis and title labelling options (such as
<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to plot time series in this way, some sort of time aggregation is
needed, which is controlled by the option <code>avg.time</code>.
</p>
<p>The plot shows the value of <code>pollutant</code> on the y-axis (averaged
according to <code>avg.time</code>). The time intervals are made up of bars split
according to <code>proportion</code>. The bars therefore show how the total value
of <code>pollutant</code> is made up for any time interval.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>
<p>Other cluster analysis functions: 
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+trajCluster">trajCluster</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## monthly plot of SO2 showing the contribution by wind sector
timeProp(mydata, pollutant = "so2", avg.time = "month", proportion = "wd")
</code></pre>

<hr>
<h2 id='timeVariation'>Diurnal, day of the week and monthly variation</h2><span id='topic+timeVariation'></span>

<h3>Description</h3>

<p>Plots the diurnal, day of the week and monthly variation for different
variables, typically pollutant concentrations. Four separate plots are
produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timeVariation(
  mydata,
  pollutant = "nox",
  local.tz = NULL,
  normalise = FALSE,
  xlab = c("hour", "hour", "month", "weekday"),
  name.pol = pollutant,
  type = "default",
  group = NULL,
  difference = FALSE,
  statistic = "mean",
  conf.int = 0.95,
  B = 100,
  ci = TRUE,
  cols = "hue",
  ref.y = NULL,
  key = NULL,
  key.columns = 1,
  start.day = 1,
  panel.gap = 0.2,
  auto.text = TRUE,
  alpha = 0.4,
  month.last = FALSE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timeVariation_+3A_mydata">mydata</code></td>
<td>
<p>A data frame of hourly (or higher temporal resolution data).
Must include a <code>date</code> field and at least one variable to plot.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_pollutant">pollutant</code></td>
<td>
<p>Name of variable to plot. Two or more pollutants can be
plotted, in which case a form like <code>pollutant = c("nox", "co")</code> should
be used.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_local.tz">local.tz</code></td>
<td>
<p>Should the results be calculated in local time that includes
a treatment of daylight savings time (DST)? The default is not to consider
DST issues, provided the data were imported without a DST offset. Emissions
activity tends to occur at local time e.g. rush hour is at 8 am every day.
When the clocks go forward in spring, the emissions are effectively
released into the atmosphere typically 1 hour earlier during the summertime
i.e. when DST applies. When plotting diurnal profiles, this has the effect
of &ldquo;smearing-out&rdquo; the concentrations. Sometimes, a useful approach
is to express time as local time. This correction tends to produce
better-defined diurnal profiles of concentration (or other variables) and
allows a better comparison to be made with emissions/activity data. If set
to <code>FALSE</code> then GMT is used. Examples of usage include <code>local.tz
  = "Europe/London"</code>, <code>local.tz = "America/New_York"</code>. See
<code>cutData</code> and <code>import</code> for more details.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_normalise">normalise</code></td>
<td>
<p>Should variables be normalised? The default is <code>FALSE</code>.
If <code>TRUE</code> then the variable(s) are divided by their mean values. This
helps to compare the shape of the diurnal trends for variables on very
different scales.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label; one for each sub-plot.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_name.pol">name.pol</code></td>
<td>
<p>Names to be given to the pollutant(s). This is useful if you
want to give a fuller description of the variables, maybe also including
subscripts etc.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Only one <code>type</code> is allowed in<code>timeVariation</code>.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_group">group</code></td>
<td>
<p>This sets the grouping variable to be used. For example, if a
data frame had a column <code>site</code> setting <code>group = "site"</code> will plot
all sites together in each panel. See examples below.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_difference">difference</code></td>
<td>
<p>If two pollutants are chosen then setting <code>difference
  = TRUE</code> will also plot the difference in means between the two variables as
<code>pollutant[2] - pollutant[1]</code>. Bootstrap 95\
the difference in means are also calculated. A horizontal dashed line is
shown at y = 0. The difference can also be calculated if there is a column
that identifies two groups e.g. having used <code>splitByDate</code>. In this
case it is possible to call <code>timeVariation</code> with the option
<code>group = "split.by"</code> and <code>difference = TRUE</code>.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_statistic">statistic</code></td>
<td>
<p>Can be &ldquo;mean&rdquo; (default) or &ldquo;median&rdquo;. If the
statistic is &lsquo;mean&rsquo; then the mean line and the 95\
interval in the mean are plotted by default. If the statistic is
&lsquo;median&rsquo; then the median line is plotted together with the 5/95 and
25/75th quantiles are plotted. Users can control the confidence intervals
with <code>conf.int</code>.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_conf.int">conf.int</code></td>
<td>
<p>The confidence intervals to be plotted. If <code>statistic =
  "mean"</code> then the confidence intervals in the mean are plotted. If
<code>statistic = "median"</code> then the <code>conf.int</code> and <code>1 -
  conf.int</code> <em>quantiles</em> are plotted. <code>conf.int</code> can be of length 2,
which is most useful for showing quantiles. For example <code>conf.int =
  c(0.75, 0.99)</code> will yield a plot showing the median, 25/75 and 5/95th
quantiles.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates to use. Can be useful to reduce this
value when there are a large number of observations available to increase
the speed of the calculations without affecting the 95\
interval calculations by much.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_ci">ci</code></td>
<td>
<p>Should confidence intervals be shown? The default is <code>TRUE</code>.
Setting this to <code>FALSE</code> can be useful if multiple pollutants are
chosen where over-lapping confidence intervals can over complicate plots.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</td></tr>
<tr><td><code id="timeVariation_+3A_ref.y">ref.y</code></td>
<td>
<p>A list with details of the horizontal lines to be added
representing reference line(s). For example, <code>ref.y = list(h = 50, lty
  = 5)</code> will add a dashed horizontal line at 50. Several lines can be plotted
e.g. <code>ref.y = list(h = c(50, 100), lty = c(1, 5), col = c("green",
  "blue"))</code>. See <code>panel.abline</code> in the <code>lattice</code> package for more
details on adding/controlling lines.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_key">key</code></td>
<td>
<p>By default <code>timeVariation</code> produces four plots on one page.
While it is useful to see these plots together, it is sometimes necessary
just to use one for a report. If <code>key</code> is <code>TRUE</code>, a key is added
to all plots allowing the extraction of a single plot <em>with</em> key. See
below for an example.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_key.columns">key.columns</code></td>
<td>
<p>Number of columns to be used in the key. With many
pollutants a single column can make to key too wide. The user can thus
choose to use several columns by setting <code>columns</code> to be less than the
number of pollutants.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_start.day">start.day</code></td>
<td>
<p>What day of the week should the plots start on? The user can
change the start day by supplying an integer between 0 and 6. Sunday = 0,
Monday = 1, ... For example to start the weekday plots on a Saturday,
choose <code>start.day = 6</code>.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_panel.gap">panel.gap</code></td>
<td>
<p>The gap between panels in the hour-day plot.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly e.g.  by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency used for plotting confidence intervals. 0
is fully transparent and 1 is opaque. The default is 0.4</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_month.last">month.last</code></td>
<td>
<p>Should the order of the plots be changed so the plot
showing monthly means be the last plot for a logical hierarchy of averaging
periods?</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="timeVariation_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:xyplot</code> and
<code>cutData</code>. For example, in the case of <code>cutData</code> the option
<code>hemisphere = "southern"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variation of pollutant concentrations by hour of the day and day of the
week etc. can reveal many interesting features that relate to source types
and meteorology. For traffic sources, there are often important differences
in the way vehicles vary by vehicles type e.g. less heavy vehicles at
weekends.
</p>
<p>The <code>timeVariation</code> function makes it easy to see how concentrations
(and many other variable types) vary by hour of the day and day of the week.
</p>
<p>The plots also show the 95\
confidence intervals in the mean are calculated through bootstrap
simulations, which will provide more robust estimates of the confidence
intervals (particularly when there are relatively few data).
</p>
<p>The function can handle multiple pollutants and uses the flexible <code>type</code>
option to provide separate panels for each 'type' &mdash; see <code>cutData</code> for
more details. <code>timeVariation</code> can also accept a <code>group</code> option
which is useful if data are stacked. This will work in a similar way to
having multiple pollutants in separate columns.
</p>
<p>The user can supply their own <code>ylim</code> e.g. <code>ylim = c(0, 200)</code> that
will be used for all plots. <code>ylim</code> can also be a list of length four to
control the y-limits on each individual plot e.g. <code>ylim =
list(c(-100,500), c(200, 300), c(-400,400), c(50,70))</code>. These pairs
correspond to the hour, weekday, month and day-hour plots respectively.
</p>
<p>The option <code>difference</code> will calculate the difference in means of two
pollutants together with bootstrap estimates of the 95\
in the difference in the mean. This works in two ways: either two pollutants
are supplied in separate columns e.g. <code>pollutant = c("no2", "o3")</code>, or
there are two unique values of <code>group</code>. The difference is calculated as
the second pollutant minus the first and is labelled as such. Considering
differences in this way can provide many useful insights and is particularly
useful for model evaluation when information is needed about where a model
differs from observations by many different time scales. The manual contains
various examples of using <code>difference = TRUE</code>.
</p>
<p>Note also that the <code>timeVariation</code> function works well on a subset of
data and in conjunction with other plots. For example, a
<code><a href="#topic+polarPlot">polarPlot</a></code> may highlight an interesting feature for a particular
wind speed/direction range. By filtering for those conditions
<code>timeVariation</code> can help determine whether the temporal variation of
that feature differs from other features &mdash; and help with source
identification.
</p>
<p>In addition, <code>timeVariation</code> will work well with other variables if
available. Examples include meteorological and traffic flow data.
</p>
<p>Depending on the choice of statistic, a subheading is added. Users can
control the text in the subheading through the use of <code>sub</code> e.g.
<code>sub = ""</code> will remove any subheading.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. The four components of
timeVariation are: <code>day.hour</code>, <code>hour</code>, <code>day</code> and
<code>month</code>. Associated data.frames can be extracted directly using the
<code>subset</code> option, e.g. as in <code>plot(object, subset = "day.hour")</code>,
<code>summary(output, subset = "hour")</code>, etc., for <code>output &lt;-
  timeVariation(mydata, "nox")</code>
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+trendLevel">trendLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# basic use
timeVariation(mydata, pollutant = "nox")

# for a subset of conditions
## Not run: 
timeVariation(subset(mydata, ws &gt; 3 &amp; wd &gt; 100 &amp; wd &lt; 270),
pollutant = "pm10", ylab = "pm10 (ug/m3)")

## End(Not run)

# multiple pollutants with concentrations normalised
## Not run: timeVariation(mydata, pollutant = c("nox", "co"), normalise = TRUE)

# show BST/GMT variation (see ?cutData for more details)
# the NOx plot shows the profiles are very similar when expressed in
# local time, showing that the profile is dominated by a local source
# that varies by local time and not by GMT i.e. road vehicle emissions

## Not run: timeVariation(mydata, pollutant = "nox", type = "dst", local.tz = "Europe/London")

## In this case it is better to group the results for clarity:
## Not run: timeVariation(mydata, pollutant = "nox", group = "dst", local.tz = "Europe/London")

# By contrast, a variable such as wind speed shows a clear shift when
#  expressed in local time. These two plots can help show whether the
#  variation is dominated by man-made influences or natural processes

## Not run: timeVariation(mydata, pollutant = "ws", group = "dst", local.tz = "Europe/London")

## It is also possible to plot several variables and set type. For
## example, consider the NOx and NO2 split by levels of O3:

## Not run: timeVariation(mydata, pollutant = c("nox", "no2"), type = "o3", normalise = TRUE)

## difference in concentrations
## Not run: timeVariation(mydata, poll= c("pm25", "pm10"), difference = TRUE)

# It is also useful to consider how concentrations vary by
# considering two different periods e.g. in intervention
# analysis. In the following plot NO2 has clearly increased but much
# less so at weekends - perhaps suggesting vehicles other than cars
# are important because flows of cars are approximately invariant by
# day of the week

## Not run: 
mydata &lt;- splitByDate(mydata, dates= "1/1/2003", labels = c("before Jan. 2003", "After Jan. 2003"))
timeVariation(mydata, pollutant = "no2", group = "split.by", difference = TRUE)

## End(Not run)

## sub plots can be extracted from the openair object
## Not run: 
myplot &lt;- timeVariation(mydata, pollutant = "no2")
plot(myplot, subset = "day.hour") # top weekday and plot

## End(Not run)

## individual plots
## plot(myplot, subset="day.hour") for the weekday and hours subplot (top)
## plot(myplot, subset="hour") for the diurnal plot
## plot(myplot, subset="day") for the weekday plot
## plot(myplot, subset="month") for the monthly plot

## numerical results (mean, lower/upper uncertainties)
## myplot$data$day.hour # the weekday and hour data set
## summary(myplot, subset = "hour") #summary of hour data set
## head(myplot, subset = "day") #head/top of day data set
## tail(myplot, subset = "month") #tail/top of month data set

## plot quantiles and median
## Not run: 
timeVariation(mydata, stati="median", poll="pm10", col = "firebrick")

## with different intervals
timeVariation(mydata, stati="median", poll="pm10", conf.int = c(0.75, 0.99),
col = "firebrick")

## End(Not run)

</code></pre>

<hr>
<h2 id='trajCluster'>Calculate clusters for back trajectories</h2><span id='topic+trajCluster'></span>

<h3>Description</h3>

<p>This function carries out cluster analysis of HYSPLIT back trajectories. The
function is specifically designed to work with the trajectories imported
using the <code>openair</code> <code>importTraj</code> function, which provides
pre-calculated back trajectories at specific receptor locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trajCluster(
  traj,
  method = "Euclid",
  n.cluster = 5,
  type = "default",
  cols = "Set1",
  split.after = FALSE,
  map.fill = TRUE,
  map.cols = "grey40",
  map.alpha = 0.4,
  projection = "lambert",
  parameters = c(51, 51),
  orientation = c(90, 0, 0),
  by.type = FALSE,
  origin = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trajCluster_+3A_traj">traj</code></td>
<td>
<p>An openair trajectory data frame resulting from the use of
<code>importTraj</code>.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_method">method</code></td>
<td>
<p>Method used to calculate the distance matrix for the back
trajectories. There are two methods available: &ldquo;Euclid&rdquo; and
&ldquo;Angle&rdquo;.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_n.cluster">n.cluster</code></td>
<td>
<p>Number of clusters to calculate.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season. Note that the cluster calculations are separately made of each
level of &quot;type&quot;.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo; and
<code>RColorBrewer</code> colours &mdash; see the <code>openair</code> <code>openColours</code>
function for more details. For user defined the user can supply a list of
colour names recognised by R (type <code>colours()</code> to see the full list).
An example would be <code>cols = c("yellow", "green", "blue")</code></p>
</td></tr>
<tr><td><code id="trajCluster_+3A_split.after">split.after</code></td>
<td>
<p>For <code>type</code> other than &ldquo;default&rdquo; e.g.
&ldquo;season&rdquo;, the trajectories can either be calculated for each level
of <code>type</code> independently or extracted after the cluster calculations
have been applied to the whole data set.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_map.fill">map.fill</code></td>
<td>
<p>Should the base map be a filled polygon? Default is to fill
countries.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_map.cols">map.cols</code></td>
<td>
<p>If <code>map.fill = TRUE</code> <code>map.cols</code> controls the fill
colour. Examples include <code>map.fill = "grey40"</code> and <code>map.fill =
  openColours("default", 10)</code>. The latter colours the countries and can help
differentiate them.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_map.alpha">map.alpha</code></td>
<td>
<p>The transparency level of the filled map which takes values
from 0 (full transparency) to 1 (full opacity). Setting it below 1 can help
view trajectories, trajectory surfaces etc. <em>and</em> a filled base map.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_projection">projection</code></td>
<td>
<p>The map projection to be used. Different map projections
are possible through the <code>mapproj</code> package. See <code>?mapproject</code> for
extensive details and information on setting other parameters and
orientation (see below).</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_parameters">parameters</code></td>
<td>
<p>From the <code>mapproj</code> package. Optional numeric vector of
parameters for use with the projection argument. This argument is optional
only in the sense that certain projections do not require additional
parameters. If a projection does not require additional parameters then set
to null i.e. <code>parameters = NULL</code>.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_orientation">orientation</code></td>
<td>
<p>From the <code>mapproj</code> package. An optional vector
c(latitude, longitude, rotation) which describes where the &quot;North Pole&quot;
should be when computing the projection. Normally this is c(90, 0), which
is appropriate for cylindrical and conic projections. For a planar
projection, you should set it to the desired point of tangency. The third
value is a clockwise rotation (in degrees), which defaults to the midrange
of the longitude coordinates in the map.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_by.type">by.type</code></td>
<td>
<p>The percentage of the total number of trajectories is given
for all data by default. Setting <code>by.type = TRUE</code> will make each panel
add up to 100.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_origin">origin</code></td>
<td>
<p>If true a filled circle dot is shown to mark the receptor
point.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="trajCluster_+3A_...">...</code></td>
<td>
<p>Other graphical parameters passed onto <code>lattice:levelplot</code>
and <code>cutData</code>. Similarly, common axis and title labelling options
(such as <code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to
<code>levelplot</code> via <code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two main methods are available to cluster the back trajectories using two
different calculations of the distance matrix. The default is to use the
standard Euclidian distance between each pair of trajectories. Also available
is an angle-based distance matrix based on Sirois and Bottenheim (1995). The
latter method is useful when the interest is the direction of the
trajectories in clustering.
</p>
<p>The distance matrix calculations are made in C++ for speed. For data sets of
up to 1 year both methods should be relatively fast, although the
<code>method = "Angle"</code> does tend to take much longer to calculate. Further
details of these methods are given in the openair manual.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. The <code>data</code> component contains
both <code>traj</code> (the original data appended with its cluster) and <code>results</code>
(the average trajectory path per cluster, shown in the <code>trajCluster()</code>
plot.)
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Sirois, A. and Bottenheim, J.W., 1995. Use of backward trajectories to
interpret the 5-year record of PAN and O3 ambient air concentrations at
Kejimkujik National Park, Nova Scotia. Journal of Geophysical Research, 100:
2867-2881.
</p>


<h3>See Also</h3>

<p>Other trajectory analysis functions: 
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+trajLevel">trajLevel</a>()</code>,
<code><a href="#topic+trajPlot">trajPlot</a>()</code>
</p>
<p>Other cluster analysis functions: 
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## import trajectories
traj &lt;- importTraj(site = "london", year = 2009)
## calculate clusters
clust &lt;- trajCluster(traj, n.cluster = 5)
head(clust$data) ## note new variable 'cluster'
## use different distance matrix calculation, and calculate by season
traj &lt;- trajCluster(traj, method = "Angle", type = "season", n.cluster = 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='trajLevel'>Trajectory level plots with conditioning</h2><span id='topic+trajLevel'></span>

<h3>Description</h3>

<p>This function plots gridded back trajectories. This function requires that
data are imported using the <code><a href="#topic+importTraj">importTraj()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trajLevel(
  mydata,
  lon = "lon",
  lat = "lat",
  pollutant = "height",
  type = "default",
  smooth = FALSE,
  statistic = "frequency",
  percentile = 90,
  map = TRUE,
  lon.inc = 1,
  lat.inc = 1,
  min.bin = 1,
  .combine = NA,
  sigma = 1.5,
  map.fill = TRUE,
  map.res = "default",
  map.cols = "grey40",
  map.alpha = 0.3,
  projection = "lambert",
  parameters = c(51, 51),
  orientation = c(90, 0, 0),
  grid.col = "deepskyblue",
  origin = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trajLevel_+3A_mydata">mydata</code></td>
<td>
<p>Data frame, the result of importing a trajectory file using
<code>importTraj</code>.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_lon">lon</code></td>
<td>
<p>Column containing the longitude, as a decimal.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_lat">lat</code></td>
<td>
<p>Column containing the latitude, as a decimal.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_pollutant">pollutant</code></td>
<td>
<p>Pollutant to be plotted. By default the trajectory height is
used.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split, i.e., conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &quot;season&quot;, &quot;year&quot;, &quot;weekday&quot; and so on. For example,
<code>type = "season"</code> will produce four plots &mdash; one for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p><code>type</code> can be up length two e.g. <code>type = c("season", "weekday")</code>
will produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_smooth">smooth</code></td>
<td>
<p>Should the trajectory surface be smoothed?</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_statistic">statistic</code></td>
<td>
<p>Statistic to use for <code><a href="#topic+trajLevel">trajLevel()</a></code>. By default, the function
will plot the trajectory frequencies (<code>statistic = "frequency"</code>). As an
alternative way of viewing trajectory frequencies, the argument <code>method = "hexbin"</code> can be used. In this case hexagonal binning of the trajectory
<em>points</em> (i.e., a point every three hours along each back trajectory).
The plot then shows the trajectory frequencies uses hexagonal binning.
</p>
<p>There are also various ways of plotting concentrations.
</p>
<p>It is possible to set <code>statistic = "difference"</code>. In this case trajectories
where the associated concentration is greater than <code>percentile</code> are
compared with the the full set of trajectories to understand the
differences in frequencies of the origin of air masses. The comparison is
made by comparing the percentage change in gridded frequencies. For
example, such a plot could show that the top 10\
tend to originate from air-mass origins to the east.
</p>
<p>If <code>statistic = "pscf"</code> then a Potential Source Contribution Function map
is produced. This statistic method interacts with <code>percentile</code>.
</p>
<p>If <code>statistic = "cwt"</code> then concentration weighted trajectories are
plotted.
</p>
<p>If <code>statistic = "sqtba"</code> then Simplified Quantitative Transport Bias
Analysis is undertaken. This statistic method interacts with <code>.combine</code> and
<code>sigma</code>.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_percentile">percentile</code></td>
<td>
<p>The percentile concentration of <code>pollutant</code> against which
the all trajectories are compared.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_map">map</code></td>
<td>
<p>Should a base map be drawn? If <code>TRUE</code> the world base map from
the <code>maps</code> package is used.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_lon.inc">lon.inc</code>, <code id="trajLevel_+3A_lat.inc">lat.inc</code></td>
<td>
<p>The longitude and latitude intervals to be used for
binning data.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_min.bin">min.bin</code></td>
<td>
<p>The minimum number of unique points in a grid cell. Counts
below <code>min.bin</code> are set as missing.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_.combine">.combine</code></td>
<td>
<p>When statistic is &quot;SQTBA&quot; it is possible to combine lots of
receptor locations to derive a single map. <code>.combine</code> identifies the column
that differentiates different sites (commonly a column named <code>"site"</code>).
Note that individual site maps are normalised first by dividing by their
mean value.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_sigma">sigma</code></td>
<td>
<p>For the SQTBA approach <code>sigma</code> determines the amount of back
trajectory spread based on the Gaussian plume equation. Values in the
literature suggest 5.4 km after one hour. However, testing suggests lower
values reveal source regions more effectively while not introducing too
much noise.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_map.fill">map.fill</code></td>
<td>
<p>Should the base map be a filled polygon? Default is to fill
countries.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_map.res">map.res</code></td>
<td>
<p>The resolution of the base map. By default the function uses
the &lsquo;world&rsquo; map from the <code>maps</code> package. If <code>map.res =
  "hires"</code> then the (much) more detailed base map &lsquo;worldHires&rsquo; from
the <code>mapdata</code> package is used. Use <code>library(mapdata)</code>. Also
available is a map showing the US states. In this case <code>map.res =
  "state"</code> should be used.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_map.cols">map.cols</code></td>
<td>
<p>If <code>map.fill = TRUE</code> <code>map.cols</code> controls the fill
colour. Examples include <code>map.fill = "grey40"</code> and <code>map.fill =
  openColours("default", 10)</code>. The latter colours the countries and can help
differentiate them.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_map.alpha">map.alpha</code></td>
<td>
<p>The transparency level of the filled map which takes values
from 0 (full transparency) to 1 (full opacity). Setting it below 1 can help
view trajectories, trajectory surfaces etc. <em>and</em> a filled base map.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_projection">projection</code></td>
<td>
<p>The map projection to be used. Different map projections
are possible through the <code>mapproj</code> package. See <code>?mapproject</code> for
extensive details and information on setting other parameters and
orientation (see below).</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_parameters">parameters</code></td>
<td>
<p>From the <code>mapproj</code> package. Optional numeric vector of
parameters for use with the projection argument. This argument is optional
only in the sense that certain projections do not require additional
parameters. If a projection does not require additional parameters then set
to null i.e. <code>parameters = NULL</code>.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_orientation">orientation</code></td>
<td>
<p>From the <code>mapproj</code> package. An optional vector
c(latitude, longitude, rotation) which describes where the &quot;North Pole&quot;
should be when computing the projection. Normally this is c(90, 0), which
is appropriate for cylindrical and conic projections. For a planar
projection, you should set it to the desired point of tangency. The third
value is a clockwise rotation (in degrees), which defaults to the midrange
of the longitude coordinates in the map.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_grid.col">grid.col</code></td>
<td>
<p>The colour of the map grid to be used. To remove the grid set
<code>grid.col = "transparent"</code>.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_origin">origin</code></td>
<td>
<p>If true a filled circle dot is shown to mark the receptor
point.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when analysing
data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="trajLevel_+3A_...">...</code></td>
<td>
<p>other arguments are passed to <code><a href="#topic+cutData">cutData()</a></code> and <code><a href="#topic+scatterPlot">scatterPlot()</a></code>.
This provides access to arguments used in both these functions and
functions that they in turn pass arguments on to. For example,
<code><a href="#topic+trajLevel">trajLevel()</a></code> passes the argument <code>cex</code> on to <code><a href="#topic+scatterPlot">scatterPlot()</a></code> which in
turn passes it on to <code><a href="lattice.html#topic+xyplot">lattice::xyplot()</a></code> where it is applied to set the
plot symbol size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An alternative way of showing the trajectories compared with plotting
trajectory lines is to bin the points into latitude/longitude intervals. For
these purposes <code><a href="#topic+trajLevel">trajLevel()</a></code> should be used. There are several trajectory
statistics that can be plotted as gridded surfaces. First, <code>statistic</code> can be
set to &quot;frequency&quot; to show the number of back trajectory points in a grid
square. Grid squares are by default at 1 degree intervals, controlled by
<code>lat.inc</code> and <code>lon.inc</code>. Such plots are useful for showing the frequency of
air mass locations. Note that it is also possible to set <code>method = "hexbin"</code>
for plotting frequencies (not concentrations), which will produce a plot by
hexagonal binning.
</p>
<p>If <code>statistic = "difference"</code> the trajectories associated with a
concentration greater than <code>percentile</code> are compared with the the full set of
trajectories to understand the differences in frequencies of the origin of
air masses of the highest concentration trajectories compared with the
trajectories on average. The comparison is made by comparing the percentage
change in gridded frequencies. For example, such a plot could show that the
top 10\
the east.
</p>
<p>If <code>statistic = "pscf"</code> then the Potential Source Contribution Function is
plotted. The PSCF calculates the probability that a source is located at
latitude <code class="reqn">i</code> and longitude <code class="reqn">j</code> (Pekney et al., 2006).The basis of
PSCF is that if a source is located at (i,j), an air parcel back trajectory
passing through that location indicates that material from the source can be
collected and transported along the trajectory to the receptor site. PSCF
solves </p>
<p style="text-align: center;"><code class="reqn">PSCF = m_{ij}/n_{ij}</code>
</p>
<p> where <code class="reqn">n_{ij}</code> is the number of times
that the trajectories passed through the cell (i,j) and <code class="reqn">m_{ij}</code> is the
number of times that a source concentration was high when the trajectories
passed through the cell (i,j). The criterion for determining <code class="reqn">m_{ij}</code> is
controlled by <code>percentile</code>, which by default is 90. Note also that cells with
few data have a weighting factor applied to reduce their effect.
</p>
<p>A limitation of the PSCF method is that grid cells can have the same PSCF
value when sample concentrations are either only slightly higher or much
higher than the criterion. As a result, it can be difficult to distinguish
moderate sources from strong ones. Seibert et al. (1994) computed
concentration fields to identify source areas of pollutants. The
Concentration Weighted Trajectory (CWT) approach considers the concentration
of a species together with its residence time in a grid cell. The CWT
approach has been shown to yield similar results to the PSCF approach. The
openair manual has more details and examples of these approaches.
</p>
<p>A further useful refinement is to smooth the resulting surface, which is
possible by setting <code>smooth = TRUE</code>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object
</p>


<h3>Note</h3>

<p>This function is under active development and is likely to change
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>References</h3>

<p>Pekney, N. J., Davidson, C. I., Zhou, L., &amp; Hopke, P. K. (2006). Application
of PSCF and CPF to PMF-Modeled Sources of PM 2.5 in Pittsburgh. Aerosol
Science and Technology, 40(10), 952-961.
</p>
<p>Seibert, P., Kromp-Kolb, H., Baltensperger, U., Jost, D., 1994. Trajectory
analysis of high-alpine air pollution data. NATO Challenges of Modern Society
18, 595-595.
</p>
<p>Xie, Y., &amp; Berkowitz, C. M. (2007). The use of conditional probability
functions and potential source contribution functions to identify source
regions and advection pathways of hydrocarbon emissions in Houston, Texas.
Atmospheric Environment, 41(28), 5831-5847.
</p>


<h3>See Also</h3>

<p>Other trajectory analysis functions: 
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+trajCluster">trajCluster</a>()</code>,
<code><a href="#topic+trajPlot">trajPlot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# show a simple case with no pollutant i.e. just the trajectories
# let's check to see where the trajectories were coming from when
# Heathrow Airport was closed due to the Icelandic volcanic eruption
# 15--21 April 2010.
# import trajectories for London and plot
## Not run: 
lond &lt;- importTraj("london", 2010)

## End(Not run)
# more examples to follow linking with concentration measurements...

# import some measurements from KC1 - London
## Not run: 
kc1 &lt;- importAURN("kc1", year = 2010)
# now merge with trajectory data by 'date'
lond &lt;- merge(lond, kc1, by = "date")

# trajectory plot, no smoothing - and limit lat/lon area of interest
# use PSCF
trajLevel(subset(lond, lat &gt; 40 &amp; lat &lt; 70 &amp; lon &gt; -20 &amp; lon &lt; 20),
  pollutant = "pm10", statistic = "pscf"
)

# can smooth surface, suing CWT approach:
trajLevel(subset(lond, lat &gt; 40 &amp; lat &lt; 70 &amp; lon &gt; -20 &amp; lon &lt; 20),
  pollutant = "pm2.5", statistic = "cwt", smooth = TRUE
)

# plot by season:
trajLevel(subset(lond, lat &gt; 40 &amp; lat &lt; 70 &amp; lon &gt; -20 &amp; lon &lt; 20),
  pollutant = "pm2.5",
  statistic = "pscf", type = "season"
)

## End(Not run)
</code></pre>

<hr>
<h2 id='trajPlot'>Trajectory line plots with conditioning</h2><span id='topic+trajPlot'></span>

<h3>Description</h3>

<p>This function plots back trajectories. This function requires that data are
imported using the <code>importTraj</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trajPlot(
  mydata,
  lon = "lon",
  lat = "lat",
  pollutant = "height",
  type = "default",
  map = TRUE,
  group = NA,
  map.fill = TRUE,
  map.res = "default",
  map.cols = "grey40",
  map.alpha = 0.4,
  projection = "lambert",
  parameters = c(51, 51),
  orientation = c(90, 0, 0),
  grid.col = "deepskyblue",
  npoints = 12,
  origin = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trajPlot_+3A_mydata">mydata</code></td>
<td>
<p>Data frame, the result of importing a trajectory file using
<code>importTraj</code>.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_lon">lon</code></td>
<td>
<p>Column containing the longitude, as a decimal.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_lat">lat</code></td>
<td>
<p>Column containing the latitude, as a decimal.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_pollutant">pollutant</code></td>
<td>
<p>Pollutant to be plotted. By default the trajectory height is
used.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split, i.e., conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &quot;season&quot;, &quot;year&quot;, &quot;weekday&quot; and so on. For example,
<code>type = "season"</code> will produce four plots &mdash; one for each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p><code>type</code> can be up length two e.g. <code>type = c("season", "weekday")</code>
will produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_map">map</code></td>
<td>
<p>Should a base map be drawn? If <code>TRUE</code> the world base map from
the <code>maps</code> package is used.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_group">group</code></td>
<td>
<p>It is sometimes useful to group and colour trajectories
according to a grouping variable. See example below.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_map.fill">map.fill</code></td>
<td>
<p>Should the base map be a filled polygon? Default is to fill
countries.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_map.res">map.res</code></td>
<td>
<p>The resolution of the base map. By default the function uses
the &lsquo;world&rsquo; map from the <code>maps</code> package. If <code>map.res =
  "hires"</code> then the (much) more detailed base map &lsquo;worldHires&rsquo; from
the <code>mapdata</code> package is used. Use <code>library(mapdata)</code>. Also
available is a map showing the US states. In this case <code>map.res =
  "state"</code> should be used.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_map.cols">map.cols</code></td>
<td>
<p>If <code>map.fill = TRUE</code> <code>map.cols</code> controls the fill
colour. Examples include <code>map.fill = "grey40"</code> and <code>map.fill =
  openColours("default", 10)</code>. The latter colours the countries and can help
differentiate them.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_map.alpha">map.alpha</code></td>
<td>
<p>The transparency level of the filled map which takes values
from 0 (full transparency) to 1 (full opacity). Setting it below 1 can help
view trajectories, trajectory surfaces etc. <em>and</em> a filled base map.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_projection">projection</code></td>
<td>
<p>The map projection to be used. Different map projections
are possible through the <code>mapproj</code> package. See <code>?mapproject</code> for
extensive details and information on setting other parameters and
orientation (see below).</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_parameters">parameters</code></td>
<td>
<p>From the <code>mapproj</code> package. Optional numeric vector of
parameters for use with the projection argument. This argument is optional
only in the sense that certain projections do not require additional
parameters. If a projection does not require additional parameters then set
to null i.e. <code>parameters = NULL</code>.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_orientation">orientation</code></td>
<td>
<p>From the <code>mapproj</code> package. An optional vector
c(latitude, longitude, rotation) which describes where the &quot;North Pole&quot;
should be when computing the projection. Normally this is c(90, 0), which
is appropriate for cylindrical and conic projections. For a planar
projection, you should set it to the desired point of tangency. The third
value is a clockwise rotation (in degrees), which defaults to the midrange
of the longitude coordinates in the map.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_grid.col">grid.col</code></td>
<td>
<p>The colour of the map grid to be used. To remove the grid set
<code>grid.col = "transparent"</code>.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_npoints">npoints</code></td>
<td>
<p>A dot is placed every <code>npoints</code> along each full
trajectory. For hourly back trajectories points are plotted every
<code>npoint</code> hours. This helps to understand where the air masses were at
particular times and get a feel for the speed of the air (points closer
together correspond to slower moving air masses). If <code>npoints = NA</code>
then no points are added.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_origin">origin</code></td>
<td>
<p>If true a filled circle dot is shown to mark the receptor
point.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when analysing
data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="trajPlot_+3A_...">...</code></td>
<td>
<p>other arguments are passed to <code>cutData</code> and
<code>scatterPlot</code>. This provides access to arguments used in both these
functions and functions that they in turn pass arguments on to. For
example, <code>plotTraj</code> passes the argument <code>cex</code> on to
<code>scatterPlot</code> which in turn passes it on to the <code>lattice</code>
function <code>xyplot</code> where it is applied to set the plot symbol size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several types of trajectory plot are available. <code>trajPlot</code> by default
will plot each lat/lon location showing the origin of each trajectory, if no
<code>pollutant</code> is supplied.
</p>
<p>If a pollutant is given, by merging the trajectory data with concentration
data (see example below), the trajectories are colour-coded by the
concentration of <code>pollutant</code>. With a long time series there can be lots
of overplotting making it difficult to gauge the overall concentration
pattern. In these cases setting <code>alpha</code> to a low value e.g. 0.1 can
help.
</p>
<p>The user can also show points instead of lines by <code>plot.type = "p"</code>.
</p>
<p>Note that <code>trajPlot</code> will plot only the full length trajectories. This
should be remembered when selecting only part of a year to plot.
</p>


<h3>Author(s)</h3>

<p>David Carslaw
</p>


<h3>See Also</h3>

<p>Other trajectory analysis functions: 
<code><a href="#topic+importTraj">importTraj</a>()</code>,
<code><a href="#topic+trajCluster">trajCluster</a>()</code>,
<code><a href="#topic+trajLevel">trajLevel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# show a simple case with no pollutant i.e. just the trajectories
# let's check to see where the trajectories were coming from when
# Heathrow Airport was closed due to the Icelandic volcanic eruption
# 15--21 April 2010.
# import trajectories for London and plot
## Not run: 
lond &lt;- importTraj("london", 2010)
# well, HYSPLIT seems to think there certainly were conditions where trajectories
# orginated from Iceland...
trajPlot(selectByDate(lond, start = "15/4/2010", end = "21/4/2010"))
## End(Not run)

# plot by day, need a column that makes a date
## Not run: 
lond$day &lt;- as.Date(lond$date)
trajPlot(selectByDate(lond, start = "15/4/2010", end = "21/4/2010"),
type = "day")

## End(Not run)

# or show each day grouped by colour, with some other options set
## Not run: 
 trajPlot(selectByDate(lond, start = "15/4/2010", end = "21/4/2010"),
group = "day", col = "turbo", lwd = 2, key.pos = "right", key.col = 1)

## End(Not run)
# more examples to follow linking with concentration measurements...

</code></pre>

<hr>
<h2 id='trendLevel'>Plot heat map trends</h2><span id='topic+trendLevel'></span>

<h3>Description</h3>

<p>The trendLevel function provides a way of rapidly showing a large amount of
data in a condensed form. In one plot, the variation in the concentration of
one pollutant can to shown as a function of three other categorical
properties. The default version of the plot uses y = hour of day, x = month
of year and type = year to provide information on trends, seasonal effects
and diurnal variations. However, x, y and type and summarising statistics can
all be modified to provide a range of other similar plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trendLevel(
  mydata,
  pollutant = "nox",
  x = "month",
  y = "hour",
  type = "year",
  rotate.axis = c(90, 0),
  n.levels = c(10, 10, 4),
  limits = c(0, 100),
  cols = "default",
  auto.text = TRUE,
  key.header = "use.stat.name",
  key.footer = pollutant,
  key.position = "right",
  key = TRUE,
  labels = NA,
  breaks = NA,
  statistic = c("mean", "max", "frequency"),
  stat.args = NULL,
  stat.safe.mode = TRUE,
  drop.unused.types = TRUE,
  col.na = "white",
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trendLevel_+3A_mydata">mydata</code></td>
<td>
<p>The openair data frame to use to generate the <code>trendLevel</code>
plot.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_pollutant">pollutant</code></td>
<td>
<p>The name of the data series in <code>mydata</code> to sample to
produce the <code>trendLevel</code> plot.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_x">x</code></td>
<td>
<p>The name of the data series to use as the <code>trendLevel</code> x-axis.
This is used with the <code>y</code> and <code>type</code> options to bin the data
before applying <code>statistic</code> (see below). Other data series in
<code>mydata</code> can also be used. (Note: <code>trendLevel</code> does not allow
duplication in <code>x</code>, <code>y</code> and <code>type</code> options within a call.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_y">y</code></td>
<td>
<p>The names of the data series to use as the <code>trendLevel</code> y-axis
and for additional conditioning, respectively. As <code>x</code> above.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_type">type</code></td>
<td>
<p>See <code>y</code>.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_rotate.axis">rotate.axis</code></td>
<td>
<p>The rotation to be applied to <code>trendLevel</code> <code>x</code>
and <code>y</code> axes. The default, <code>c(90, 0)</code>, rotates the x axis by 90
degrees but does not rotate the y axis. (Note: If only one value is
supplied, this is applied to both axes; if more than two values are
supplied, only the first two are used.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_n.levels">n.levels</code></td>
<td>
<p>The number of levels to split <code>x</code>, <code>y</code> and
<code>type</code> data into if numeric. The default, <code>c(10, 10, 4)</code>, cuts
numeric <code>x</code> and <code>y</code> data into ten levels and numeric <code>type</code>
data into four levels. (Notes: This option is ignored for date conditioning
and factors.  If less than three values are supplied, three values are
determined by recursion; if more than three values are supplied, only the
first three are used.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_limits">limits</code></td>
<td>
<p>The colour scale range to use when generating the
<code>trendLevel</code> plot.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_cols">cols</code></td>
<td>
<p>The colour set to use to colour the <code>trendLevel</code> surface.
<code>cols</code> is passed to <code>openColours</code> for evaluation. See
<code>?openColours</code> for more details.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_auto.text">auto.text</code></td>
<td>
<p>Automatic routine text formatting. <code>auto.text = TRUE</code>
passes common <code>lattice</code> labelling terms (e.g. <code>xlab</code> for the
x-axis, <code>ylab</code> for the y-axis and <code>main</code> for the title) to the
plot via <code>quickText</code> to provide common text formatting.  The
alternative <code>auto.text = FALSE</code> turns this option off and passes any
supplied labels to the plot without modification.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_key.header">key.header</code>, <code id="trendLevel_+3A_key.footer">key.footer</code></td>
<td>
<p>Adds additional text labels above and/or below
the scale key, respectively. For example, passing the options
<code>key.header = "", key.footer = c("mean","nox")</code> adds the addition text
as a scale footer. If enabled (<code>auto.text = TRUE</code>), these arguments
are passed to the scale key (<code>drawOpenKey</code>) via <code>quickText</code> to
handle formatting. The term <code>"get.stat.name"</code>, used as the default
<code>key.header</code> setting, is reserved and automatically adds statistic
function names or defaults to <code>"level"</code> when unnamed functions are
requested via <code>statistic</code>.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key should be plotted.  Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code>drawOpenKey</code>. See
<code>?drawOpenKey</code> for further details.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_labels">labels</code></td>
<td>
<p>If a categorical colour scale is required then these labels
will be used. Note there is one less label than break. For example,
<code>labels = c("good", "bad", "very bad")</code>. <code>breaks</code> must also be
supplied if labels are given.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_breaks">breaks</code></td>
<td>
<p>If a categorical colour scale is required then these breaks
will be used. For example, <code>breaks = c(0, 50, 100, 1000)</code>. In this
case &ldquo;good&rdquo; corresponds to values between 0 and 50 and so on. Users
should set the maximum value of <code>breaks</code> to exceed the maximum data
value to ensure it is within the maximum final range e.g. 100&ndash;1000 in this
case. <code>labels</code> must also be supplied.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_statistic">statistic</code></td>
<td>
<p>The statistic method to be use to summarise locally binned
<code>pollutant</code> measurements with. Three options are currently encoded:
&ldquo;mean&rdquo; (default), &ldquo;max&rdquo; and &ldquo;frequency&rdquo;. (Note:
Functions can also be sent directly via <code>statistic</code>.  However, this
option is still in development and should be used with caution. See Details
below.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_stat.args">stat.args</code></td>
<td>
<p>Additional options to be used with <code>statistic</code> if this
is a function. The extra options should be supplied as a list of named
parameters. (see Details below.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_stat.safe.mode">stat.safe.mode</code></td>
<td>
<p>An addition protection applied when using functions
directly with <code>statistic</code> that most users can ignore. This option
returns <code>NA</code> instead of running <code>statistic</code> on binned subsamples
that are empty. Many common functions terminate with an error message when
applied to an empty dataset. So, this option provides a mechanism to work
with such functions. For a very few cases, e.g. for a function that counted
missing entries, it might need to be set to <code>FALSE</code> (see Details
below.)</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_drop.unused.types">drop.unused.types</code></td>
<td>
<p>Hide unused/empty <code>type</code> conditioning cases.
Some conditioning options may generate empty cases for some data sets, e.g.
a hour of the day when no measurements were taken. Empty <code>x</code> and
<code>y</code> cases generate 'holes' in individual plots. However, empty
<code>type</code> cases would produce blank panels if plotted. Therefore, the
default, <code>TRUE</code>, excludes these empty panels from the plot. The
alternative <code>FALSE</code> plots all <code>type</code> panels.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_col.na">col.na</code></td>
<td>
<p>Colour to be used to show missing data.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="trendLevel_+3A_...">...</code></td>
<td>
<p>Addition options are passed on to <code>cutData</code> for <code>type</code>
handling and <code>levelplot</code> in <code>lattice</code> for finer control of the
plot itself.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>trendLevel</code> allows the use of third party summarising functions via the
<code>statistic</code> option. Any additional function arguments not included
within a function called using <code>statistic</code> should be supplied as a list
of named parameters and sent using <code>stat.args</code>. For example, the encoded
option <code>statistic = "mean"</code> is equivalent to <code>statistic = mean,
stat.args = list(na.rm = TRUE)</code> or the R command <code>mean(x, na.rm= TRUE)</code>.
Many R functions and user's own code could be applied in a similar fashion,
subject to the following restrictions: the first argument sent to the
function must be the data series to be analysed; the name &lsquo;x&rsquo; cannot be used
for any of the extra options supplied in <code>stat.args</code>; and the function
should return the required answer as a numeric or <code>NA</code>. Note: If the
supplied function returns more than one answer, currently only the first of
these is retained and used by <code>trendLevel</code>. All other returned
information will be ignored without warning. If the function terminates with
an error when it is sent an empty data series, the option
<code>stat.safe.mode</code> should not be set to <code>FALSE</code> or <code>trendLevel</code>
may fail. Note: The <code>stat.safe.mode = TRUE</code> option returns an NA without
warning for empty data series.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object.
</p>


<h3>Author(s)</h3>

<p>Karl Ropkins and David Carslaw
</p>


<h3>See Also</h3>

<p>Other time series and trend functions: 
<code><a href="#topic+TheilSen">TheilSen</a>()</code>,
<code><a href="#topic+calendarPlot">calendarPlot</a>()</code>,
<code><a href="#topic+runRegression">runRegression</a>()</code>,
<code><a href="#topic+smoothTrend">smoothTrend</a>()</code>,
<code><a href="#topic+timePlot">timePlot</a>()</code>,
<code><a href="#topic+timeProp">timeProp</a>()</code>,
<code><a href="#topic+timeVariation">timeVariation</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#basic use
#default statistic = "mean"
trendLevel(mydata, pollutant = "nox")

#applying same as 'own' statistic
my.mean &lt;- function(x) mean(x, na.rm = TRUE)
trendLevel(mydata, pollutant = "nox", statistic = my.mean)

#alternative for 'third party' statistic
#trendLevel(mydata, pollutant = "nox", statistic = mean,
#           stat.args = list(na.rm = TRUE))

## Not run: 
# example with categorical scale
trendLevel(mydata, pollutant = "no2",
border = "white", statistic = "max",
breaks = c(0, 50, 100, 500),
labels = c("low", "medium", "high"),
cols = c("forestgreen", "yellow", "red"))

## End(Not run)
</code></pre>

<hr>
<h2 id='windRose'>Traditional wind rose plot</h2><span id='topic+windRose'></span>

<h3>Description</h3>

<p>The traditional wind rose plot that plots wind speed and wind direction by
different intervals. The pollution rose applies the same plot structure but
substitutes other measurements, most commonly a pollutant time series, for
wind speed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>windRose(
  mydata,
  ws = "ws",
  wd = "wd",
  ws2 = NA,
  wd2 = NA,
  ws.int = 2,
  angle = 30,
  type = "default",
  bias.corr = TRUE,
  cols = "default",
  grid.line = NULL,
  width = 1,
  seg = NULL,
  auto.text = TRUE,
  breaks = 4,
  offset = 10,
  normalise = FALSE,
  max.freq = NULL,
  paddle = TRUE,
  key.header = NULL,
  key.footer = "(m/s)",
  key.position = "bottom",
  key = TRUE,
  dig.lab = 5,
  include.lowest = FALSE,
  statistic = "prop.count",
  pollutant = NULL,
  annotate = TRUE,
  angle.scale = 315,
  border = NA,
  alpha = 1,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="windRose_+3A_mydata">mydata</code></td>
<td>
<p>A data frame containing fields <code>ws</code> and <code>wd</code></p>
</td></tr>
<tr><td><code id="windRose_+3A_ws">ws</code></td>
<td>
<p>Name of the column representing wind speed.</p>
</td></tr>
<tr><td><code id="windRose_+3A_wd">wd</code></td>
<td>
<p>Name of the column representing wind direction.</p>
</td></tr>
<tr><td><code id="windRose_+3A_ws2">ws2</code>, <code id="windRose_+3A_wd2">wd2</code></td>
<td>
<p>The user can supply a second set of wind speed and wind
direction values with which the first can be compared. See
<code><a href="#topic+pollutionRose">pollutionRose()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="windRose_+3A_ws.int">ws.int</code></td>
<td>
<p>The Wind speed interval. Default is 2 m/s but for low met masts
with low mean wind speeds a value of 1 or 0.5 m/s may be better.</p>
</td></tr>
<tr><td><code id="windRose_+3A_angle">angle</code></td>
<td>
<p>Default angle of &ldquo;spokes&rdquo; is 30. Other potentially useful
angles are 45 and 10. Note that the width of the wind speed interval may
need adjusting using <code>width</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_type">type</code></td>
<td>
<p><code>type</code> determines how the data are split i.e. conditioned,
and then plotted. The default is will produce a single plot using the
entire data. Type can be one of the built-in types as detailed in
<code>cutData</code> e.g. &ldquo;season&rdquo;, &ldquo;year&rdquo;, &ldquo;weekday&rdquo; and so
on. For example, <code>type = "season"</code> will produce four plots &mdash; one for
each season.
</p>
<p>It is also possible to choose <code>type</code> as another variable in the data
frame. If that variable is numeric, then the data will be split into four
quantiles (if possible) and labelled accordingly. If type is an existing
character or factor variable, then those categories/levels will be used
directly. This offers great flexibility for understanding the variation of
different variables and how they depend on one another.
</p>
<p>Type can be up length two e.g. <code>type = c("season", "weekday")</code> will
produce a 2x2 plot split by season and day of the week. Note, when two
types are provided the first forms the columns and the second the rows.</p>
</td></tr>
<tr><td><code id="windRose_+3A_bias.corr">bias.corr</code></td>
<td>
<p>When <code>angle</code> does not divide exactly into 360 a bias is
introduced in the frequencies when the wind direction is already supplied
rounded to the nearest 10 degrees, as is often the case. For example, if
<code>angle = 22.5</code>, N, E, S, W will include 3 wind sectors and all other
angles will be two. A bias correction can made to correct for this problem.
A simple method according to Applequist (2012) is used to adjust the
frequencies.</p>
</td></tr>
<tr><td><code id="windRose_+3A_cols">cols</code></td>
<td>
<p>Colours to be used for plotting. Options include
&ldquo;default&rdquo;, &ldquo;increment&rdquo;, &ldquo;heat&rdquo;, &ldquo;jet&rdquo;,
&ldquo;hue&rdquo; and user defined. For user defined the user can supply a list
of colour names recognised by R (type <code>colours()</code> to see the full
list). An example would be <code>cols = c("yellow", "green", "blue",
  "black")</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_grid.line">grid.line</code></td>
<td>
<p>Grid line interval to use. If <code>NULL</code>, as in default,
this is assigned based on the available data range. However, it can also be
forced to a specific value, e.g. <code>grid.line = 10</code>. <code>grid.line</code>
can also be a list to control the interval, line type and colour. For
example <code>grid.line = list(value = 10, lty = 5, col = "purple")</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_width">width</code></td>
<td>
<p>For <code>paddle = TRUE</code>, the adjustment factor for width of
wind speed intervals. For example, <code>width = 1.5</code> will make the paddle
width 1.5 times wider.</p>
</td></tr>
<tr><td><code id="windRose_+3A_seg">seg</code></td>
<td>
<p>When <code>paddle = TRUE</code>, <code>seg</code> determines with width of the
segments. For example, <code>seg = 0.5</code> will produce segments 0.5 *
<code>angle</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_auto.text">auto.text</code></td>
<td>
<p>Either <code>TRUE</code> (default) or <code>FALSE</code>. If <code>TRUE</code>
titles and axis labels will automatically try and format pollutant names
and units properly, e.g., by subscripting the &lsquo;2&rsquo; in NO2.</p>
</td></tr>
<tr><td><code id="windRose_+3A_breaks">breaks</code></td>
<td>
<p>Most commonly, the number of break points for wind speed. With
the <code>ws.int</code> default of 2 m/s, the <code>breaks</code> default, 4, generates
the break points 2, 4, 6, 8 m/s. However, <code>breaks</code> can also be used to
set specific break points. For example, the argument <code>breaks = c(0, 1,
  10, 100)</code> breaks the data into segments &lt;1, 1-10, 10-100, &gt;100.</p>
</td></tr>
<tr><td><code id="windRose_+3A_offset">offset</code></td>
<td>
<p>The size of the 'hole' in the middle of the plot, expressed as
a percentage of the polar axis scale, default 10.</p>
</td></tr>
<tr><td><code id="windRose_+3A_normalise">normalise</code></td>
<td>
<p>If <code>TRUE</code> each wind direction segment is normalised to
equal one. This is useful for showing how the concentrations (or other
parameters) contribute to each wind sector when the proportion of time the
wind is from that direction is low. A line showing the probability that the
wind directions is from a particular wind sector is also shown.</p>
</td></tr>
<tr><td><code id="windRose_+3A_max.freq">max.freq</code></td>
<td>
<p>Controls the scaling used by setting the maximum value for
the radial limits. This is useful to ensure several plots use the same
radial limits.</p>
</td></tr>
<tr><td><code id="windRose_+3A_paddle">paddle</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code>. If <code>TRUE</code> plots rose
using 'paddle' style spokes. If <code>FALSE</code> plots rose using 'wedge' style
spokes.</p>
</td></tr>
<tr><td><code id="windRose_+3A_key.header">key.header</code></td>
<td>
<p>Adds additional text/labels above the scale key. For
example, passing <code>windRose(mydata, key.header = "ws")</code> adds the
addition text as a scale header. Note: This argument is passed to
<code><a href="#topic+drawOpenKey">drawOpenKey()</a></code> via <code><a href="#topic+quickText">quickText()</a></code>, applying the auto.text argument, to
handle formatting.</p>
</td></tr>
<tr><td><code id="windRose_+3A_key.footer">key.footer</code></td>
<td>
<p>Adds additional text/labels below the scale key. See
<code>key.header</code> for further information.</p>
</td></tr>
<tr><td><code id="windRose_+3A_key.position">key.position</code></td>
<td>
<p>Location where the scale key is to plotted. Allowed
arguments currently include &ldquo;top&rdquo;, &ldquo;right&rdquo;, &ldquo;bottom&rdquo;
and &ldquo;left&rdquo;.</p>
</td></tr>
<tr><td><code id="windRose_+3A_key">key</code></td>
<td>
<p>Fine control of the scale key via <code><a href="#topic+drawOpenKey">drawOpenKey()</a></code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_dig.lab">dig.lab</code></td>
<td>
<p>The number of significant figures at which scientific number
formatting is used in break point and key labelling. Default 5.</p>
</td></tr>
<tr><td><code id="windRose_+3A_include.lowest">include.lowest</code></td>
<td>
<p>Logical. If <code>FALSE</code> (the default), the first
interval will be left exclusive and right inclusive. If <code>TRUE</code>, the
first interval will be left and right inclusive. Passed to the
<code>include.lowest</code> argument of <code><a href="base.html#topic+cut">cut()</a></code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_statistic">statistic</code></td>
<td>
<p>The <code>statistic</code> to be applied to each data bin in the
plot. Options currently include &ldquo;prop.count&rdquo;, &ldquo;prop.mean&rdquo; and
&ldquo;abs.count&rdquo;. The default &ldquo;prop.count&rdquo; sizes bins according to
the proportion of the frequency of measurements.  Similarly,
&ldquo;prop.mean&rdquo; sizes bins according to their relative contribution to
the mean. &ldquo;abs.count&rdquo; provides the absolute count of measurements in
each bin.</p>
</td></tr>
<tr><td><code id="windRose_+3A_pollutant">pollutant</code></td>
<td>
<p>Alternative data series to be sampled instead of wind speed.
The <code><a href="#topic+windRose">windRose()</a></code> default NULL is equivalent to <code>pollutant = "ws"</code>. Use
in <code><a href="#topic+pollutionRose">pollutionRose()</a></code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_annotate">annotate</code></td>
<td>
<p>If <code>TRUE</code> then the percentage calm and mean values are
printed in each panel together with a description of the statistic below
the plot. If <code>" "</code> then only the statistic is below the plot. Custom
annotations may be added by setting value to <code>c("annotation 1",
  "annotation 2")</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_angle.scale">angle.scale</code></td>
<td>
<p>The scale is by default shown at a 315 degree angle.
Sometimes the placement of the scale may interfere with an interesting
feature. The user can therefore set <code>angle.scale</code> to another value
(between 0 and 360 degrees) to mitigate such problems. For example
<code>angle.scale = 45</code> will draw the scale heading in a NE direction.</p>
</td></tr>
<tr><td><code id="windRose_+3A_border">border</code></td>
<td>
<p>Border colour for shaded areas. Default is no border.</p>
</td></tr>
<tr><td><code id="windRose_+3A_alpha">alpha</code></td>
<td>
<p>The alpha transparency to use for the plotting surface (a value
between 0 and 1 with zero being fully transparent and 1 fully opaque).
Setting a value below 1 can be useful when plotting surfaces on a map using
the package <code>openairmaps</code>.</p>
</td></tr>
<tr><td><code id="windRose_+3A_plot">plot</code></td>
<td>
<p>Should a plot be produced? <code>FALSE</code> can be useful when
analysing data to extract plot components and plotting them in other ways.</p>
</td></tr>
<tr><td><code id="windRose_+3A_...">...</code></td>
<td>
<p>Other parameters that are passed on to <code>drawOpenKey</code>,
<code>lattice:xyplot</code> and <code>cutData</code>. Axis and title labelling options
(<code>xlab</code>, <code>ylab</code>, <code>main</code>) are passed to <code>xyplot</code> via
<code>quickText</code> to handle routine formatting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>windRose</code> data are summarised by direction, typically by 45 or 30
(or 10) degrees and by different wind speed categories. Typically, wind
speeds are represented by different width &quot;paddles&quot;. The plots show the
proportion (here represented as a percentage) of time that the wind is from a
certain angle and wind speed range.
</p>
<p>By default <code>windRose</code> will plot a windRose in using &quot;paddle&quot; style
segments and placing the scale key below the plot.
</p>
<p>The argument <code>pollutant</code> uses the same plotting structure but
substitutes another data series, defined by <code>pollutant</code>, for wind speed.
It is recommended to use <code><a href="#topic+pollutionRose">pollutionRose()</a></code> for plotting pollutant
concentrations.
</p>
<p>The option <code>statistic = "prop.mean"</code> provides a measure of the relative
contribution of each bin to the panel mean, and is intended for use with
<code>pollutionRose</code>.
</p>


<h3>Value</h3>

<p>an <a href="#topic+openair-package">openair</a> object. Summarised proportions can be
extracted directly using the <code>$data</code> operator, e.g. <code>object$data</code>
for <code>output &lt;- windRose(mydata)</code>. This returns a data frame with three
set columns: <code>cond</code>, conditioning based on <code>type</code>; <code>wd</code>, the
wind direction; and <code>calm</code>, the <code>statistic</code> for the proportion of
data unattributed to any specific wind direction because it was collected
under calm conditions; and then several (one for each range binned for the
plot) columns giving proportions of measurements associated with each
<code>ws</code> or <code>pollutant</code> range plotted as a discrete panel.
</p>


<h3>Note</h3>

<p><code>windRose</code> and <code>pollutionRose</code> both use <code><a href="#topic+drawOpenKey">drawOpenKey()</a></code> to
produce scale keys.
</p>


<h3>Author(s)</h3>

<p>David Carslaw (with some additional contributions by Karl Ropkins)
</p>


<h3>References</h3>

<p>Applequist, S, 2012: Wind Rose Bias Correction. J. Appl. Meteor. Climatol.,
51, 1305-1309.
</p>
<p>Droppo,  J.G. and B.A. Napier (2008) Wind Direction Bias in Generating Wind
Roses and Conducting Sector-Based Air Dispersion Modeling, Journal of the Air
&amp; Waste Management Association, 58:7, 913-918.
</p>


<h3>See Also</h3>

<p>Other polar directional analysis functions: 
<code><a href="#topic+percentileRose">percentileRose</a>()</code>,
<code><a href="#topic+polarAnnulus">polarAnnulus</a>()</code>,
<code><a href="#topic+polarCluster">polarCluster</a>()</code>,
<code><a href="#topic+polarDiff">polarDiff</a>()</code>,
<code><a href="#topic+polarFreq">polarFreq</a>()</code>,
<code><a href="#topic+polarPlot">polarPlot</a>()</code>,
<code><a href="#topic+pollutionRose">pollutionRose</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># basic plot
windRose(mydata)

# one windRose for each year
windRose(mydata,type = "year")

# windRose in 10 degree intervals with gridlines and width adjusted
## Not run: 
windRose(mydata, angle = 10, width = 0.2, grid.line = 1)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
