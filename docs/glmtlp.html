<!DOCTYPE html><html lang="en"><head><title>Help for package glmtlp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {glmtlp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#glmtlp'><p>glmtlp: A package for fitting a GLM with l0, l1, and tlp regularization.</p></a></li>
<li><a href='#bin_data'><p>A simulated binomial data set.</p></a></li>
<li><a href='#cv.glmtlp'><p>Cross-validation for glmtlp</p></a></li>
<li><a href='#gau_data'><p>A simulated gaussian data set.</p></a></li>
<li><a href='#gen.binomial.data'><p>Simulate a binomial data set</p></a></li>
<li><a href='#gen.gaussian.data'><p>Simulate a gaussian data set</p></a></li>
<li><a href='#plot.cv.glmtlp'><p>Plot Method for a &quot;cv.glmtlp&quot; Object</p></a></li>
<li><a href='#plot.glmtlp'><p>Plot Method for a &quot;glmtlp&quot; Object</p></a></li>
<li><a href='#predict.cv.glmtlp'><p>Predict Method for a &quot;cv.glmtlp&quot; Object.</p></a></li>
<li><a href='#predict.glmtlp'><p>Predict Method for a &quot;glmtlp&quot; Object</p></a></li>
<li><a href='#setup_lambda'><p>Generate lambda sequence.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Linear Models with Truncated Lasso Penalty</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-01</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://yuyangyy.com/glmtlp/">https://yuyangyy.com/glmtlp/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, doParallel, ggplot2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>Extremely efficient procedures for fitting regularization path with l0, l1, and truncated lasso penalty for linear regression and logistic regression models. This version is a completely new version compared with our previous version, which was mainly based on R. New core algorithms are developed and are now written in C++ and highly optimized. </td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Author:</td>
<td>Chunlin Li <a href="https://orcid.org/0000-0003-2989-8785"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph],
  Yu Yang <a href="https://orcid.org/0000-0001-7355-6702"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Chong Wu <a href="https://orcid.org/0000-0002-8400-1785"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph],
  Xiaotong Shen [ths, cph],
  Wei Pan [ths, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yu Yang &lt;yuyang.stat@gmail.com&gt;</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-02 14:56:35 UTC; yuyang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-02 20:20:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='glmtlp'>glmtlp: A package for fitting a GLM with l0, l1, and tlp regularization.</h2><span id='topic+glmtlp-package'></span><span id='topic+glmtlp'></span>

<h3>Description</h3>

<p>The package provides 3 penalties: l0, l1, and tlp and 3 distribution families: 
gaussian, binomial, and poisson.
</p>
<p>Fit generalized linear models via penalized maximum likelihood. The
regularization path is computed for the l0, lasso, or truncated lasso
penalty at a grid of values for the regularization parameter <code>lambda</code>
or <code>kappa</code>. Fits linear and logistic regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmtlp(
  X,
  y,
  family = c("gaussian", "binomial"),
  penalty = c("l0", "l1", "tlp"),
  nlambda = ifelse(penalty == "l0", 50, 100),
  lambda.min.ratio = ifelse(nobs &lt; nvars, 0.05, 0.001),
  lambda = NULL,
  kappa = NULL,
  tau = 0.3 * sqrt(log(nvars)/nobs),
  delta = 2,
  tol = 1e-04,
  weights = NULL,
  penalty.factor = rep(1, nvars),
  standardize = FALSE,
  dc.maxit = 20,
  cd.maxit = 10000,
  nr.maxit = 20,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glmtlp_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> x <code>nvars</code>;
each row is  an observation vector.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_y">y</code></td>
<td>
<p>Response variable, of length <code>nobs</code>. For <code>family="gaussian"</code>,
it should be quantitative; for <code>family="binomial"</code>, it should be either
a factor with two levels or a binary vector.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_family">family</code></td>
<td>
<p>A character string representing one of the built-in families.
See Details section below.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_penalty">penalty</code></td>
<td>
<p>A character string representing one of the built-in penalties.
<code>"l0"</code> represents the <code class="reqn">L_0</code> penalty, <code>"l1"</code> represents the
lasso-type penalty (<code class="reqn">L_1</code> penalty), and <code>"tlp"</code> represents the
truncated lasso penalty.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values. Default is 100.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>The smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>, the smallest value for which all coefficients are zero.
The default depends on the sample size <code>nobs</code> relative to the number
of variables <code>nvars</code>. If <code>nobs &gt; nvars</code>, the default is
<code>0.0001</code>, and if <code>nobs &lt; nvars</code>, the default is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_lambda">lambda</code></td>
<td>
<p>A user-supplied <code>lambda</code> sequence. Typically, users should let
the program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying a value of
<code>lambda</code> will override this. WARNING: please use this option with care.
<code>glmtlp</code> relies on warms starts for speed, and it's often faster to
fit a whole path than a single fit. Therefore, provide a decreasing sequence
of <code>lambda</code> values if you want to use this option. Also, when
<code>penalty = 'l0'</code>, it is not recommended for the users to supply
this parameter.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_kappa">kappa</code></td>
<td>
<p>A user-supplied <code>kappa</code> sequence. Typically, users should
let the program compute its own <code>kappa</code> sequence based on <code>nvars</code>
and <code>nobs</code>. This sequence is used when <code>penalty = 'l0'</code>.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_tau">tau</code></td>
<td>
<p>A tuning parameter used in the TLP-penalized regression models.
Default is  <code>0.3 * sqrt(log(nvars)/nobs)</code>.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_delta">delta</code></td>
<td>
<p>A tuning parameter used in the coordinate majorization descent
algorithm. See Yang, Y., &amp; Zou, H. (2014) in the reference for more detail.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_tol">tol</code></td>
<td>
<p>Tolerance level for all iterative optimization algorithms.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_weights">weights</code></td>
<td>
<p>Observation weights. Default is 1 for each observation.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors applied to each
coefficient, which allows for differential shrinkage. Default is 1
for all variables.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_standardize">standardize</code></td>
<td>
<p>Logical. Whether or not standardize the input matrix
<code>X</code>; default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_dc.maxit">dc.maxit</code></td>
<td>
<p>Maximum number of iterations for the DC (Difference of
Convex Functions) programming; default is 20.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_cd.maxit">cd.maxit</code></td>
<td>
<p>Maximum number of iterations for the coordinate descent
algorithm; default is 10^4.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_nr.maxit">nr.maxit</code></td>
<td>
<p>Maximum number of iterations for the Newton-Raphson method;
default is 500.</p>
</td></tr>
<tr><td><code id="glmtlp_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by <code>lambda</code> (when <code>penalty = c('l1', 'tlp')</code>)
or <code>kappa</code> (when <code>penalty = 'l0'</code>) is fit by the coordinate
descent algorithm.
</p>
<p>The objective function for the <code>"gaussian"</code> family is:
</p>
<p style="text-align: center;"><code class="reqn">1/2 RSS/nobs + \lambda*penalty,</code>
</p>
<p> and for the other models it is:
</p>
<p style="text-align: center;"><code class="reqn">-loglik/nobs + \lambda*penalty.</code>
</p>

<p>Also note that, for <code>"gaussian"</code>, <code>glmtlp</code> standardizes y to
have unit variance (using 1/(n-1) formula).
</p>
<p>## Details on <code>family</code> option
</p>
<p><code>glmtlp</code> currently only supports built-in families, which are specified by a
character string. For all families, the returned object is a regularization
path for fitting the generalized linear regression models, by maximizing the
corresponding penalized log-likelihood. <code>glmtlp(..., family="binomial")</code>
fits a traditional logistic regression model for the log-odds.
</p>
<p>## Details on <code>penalty</code> option
</p>
<p>The built-in penalties are specified by a character string. For <code>l0</code>
penalty, <code>kappa</code> sequence is used for generating the regularization
path, while for <code>l1</code> and <code>tlp</code> penalty, <code>lambda</code> sequence
is used for generating the regularization path.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"glmtlp"</code>.
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>a <code>nvars x length(kappa)</code> matrix of
coefficients when <code>penalty = 'l0'</code>; or a <code>nvars x length(lambda)</code>
matrix of coefficients when <code>penalty = c('l1', 'tlp')</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call that produces this object.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the distribution family used in the model fitting.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the intercept vector, of <code>length(kappa)</code> when
<code>penalty = 'l0'</code> or <code>length(lambda)</code> when
<code>penalty = c('l1', 'tlp')</code>.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the actual sequence of <code>lambda</code> values used. Note that
the length may be smaller than the provided <code>nlambda</code> due to removal
of saturated values.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>the penalty type in the model fitting.</p>
</td></tr>
<tr><td><code>penalty.factor</code></td>
<td>
<p>the penalty factor for each coefficient used in the model fitting.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>the tuning parameter used in the model fitting, available when
<code>penalty = 'tlp'</code>.</p>
</td></tr>
</table>


<h3>glmtlp functions</h3>

<p>'glmtlp()', 'cv.glmtlp()'
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Yu Yang <a href="mailto:yuyang.stat@gmail.com">yuyang.stat@gmail.com</a> (<a href="https://orcid.org/0000-0001-7355-6702">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Chunlin Li <a href="mailto:chunlin@iastate.edu">chunlin@iastate.edu</a> (<a href="https://orcid.org/0000-0003-2989-8785">ORCID</a>) [copyright holder]
</p>
</li>
<li><p> Chong Wu (<a href="https://orcid.org/0000-0002-8400-1785">ORCID</a>) [copyright holder]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Xiaotong Shen [thesis advisor, copyright holder]
</p>
</li>
<li><p> Wei Pan [thesis advisor, copyright holder]
</p>
</li></ul>

<p>Chunlin Li, Yu Yang, Chong Wu
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012).
<em>Likelihood-based selection and sharp parameter estimation.
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013).
<em>On constrained and regularized high-dimensional regression.
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021).
<em>Inference for a Large Directed Graphical Model with Interventions.
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014).
<em>A coordinate majorization descent algorithm for l1 penalized learning.
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://yuyangyy.com/glmtlp/">https://yuyangyy.com/glmtlp/</a>
</p>
</li></ul>

<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,
and the <code>cv.glmtlp</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian
X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
fit1 &lt;- glmtlp(X, y, family = "gaussian", penalty = "l0")
fit2 &lt;- glmtlp(X, y, family = "gaussian", penalty = "l1")
fit3 &lt;- glmtlp(X, y, family = "gaussian", penalty = "tlp")

# Binomial

X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- sample(c(0, 1), 100, replace = TRUE)
fit &lt;- glmtlp(X, y, family = "binomial", penalty = "l1")
</code></pre>

<hr>
<h2 id='bin_data'>A simulated binomial data set.</h2><span id='topic+bin_data'></span>

<h3>Description</h3>

<p>A data set simulated for illustrating logistic regression models. Generated by 
<code>gen.binomial.data(n = 200, p = 20, seed = 2021)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bin_data)
</code></pre>


<h3>Format</h3>

<p>A list with three elements: design matrix <code>X</code>, response <code>y</code>, 
and the true coefficient vector <code>beta</code>.
</p>

<dl>
<dt>X</dt><dd><p>design matrix</p>
</dd>
<dt>y</dt><dd><p>response</p>
</dd>
<dt>beta</dt><dd><p>the true coefficient vector</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("bin_data")
cv.fit &lt;- cv.glmtlp(bin_data$X, bin_data$y, family = "binomial", penalty = "l1")
plot(cv.fit)

</code></pre>

<hr>
<h2 id='cv.glmtlp'>Cross-validation for glmtlp</h2><span id='topic+cv.glmtlp'></span>

<h3>Description</h3>

<p>Performs k-fold cross-validation for l0, l1, or TLP-penalized regression models 
over a grid of values for the regularization parameter <code>lambda</code> 
(if <code>penalty="l0"</code>) or <code>kappa</code> (if <code>penalty="l0"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glmtlp(X, y, ..., seed = NULL, nfolds = 10, obs.fold = NULL, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.glmtlp_+3A_x">X</code></td>
<td>
<p>input matrix, of dimension <code>nobs</code> x <code>nvars</code>, as in 
<code>glmtlp</code>.</p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_y">y</code></td>
<td>
<p>response, of length nobs, as in <code>glmtlp</code>.</p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>glmtlp</code>.</p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_seed">seed</code></td>
<td>
<p>the seed for reproduction purposes</p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds; default is 10. The smallest value allowable 
is <code>nfolds=3</code></p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_obs.fold">obs.fold</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfolds</code>
identifying what fold each observation is in. If supplied, <code>nfolds</code> can
be missing.</p>
</td></tr>
<tr><td><code id="cv.glmtlp_+3A_ncores">ncores</code></td>
<td>
<p>number of cores utilized; default is 1. If greater than 1, 
then <code>doParallel::foreach</code> will be used to fit each fold; if equal to 
1, then for loop will be used to fit each fold. Users don't have to register 
parallel clusters outside.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code>glmtlp</code> <code>nfolds</code>+1 times; the first call to get the
<code>lambda</code> or <code>kappa</code> sequence, and then the rest to compute 
the fit with each of the folds omitted. The cross-validation error is based 
on deviance (check here for more details). The error is accumulated over the 
folds, and the average error and standard deviation is computed. 
</p>
<p>When <code>family = "binomial"</code>, the fold assignment (if not provided by 
the user) is generated in a stratified manner, where the ratio of 0/1 outcomes 
are the same for each fold.
</p>


<h3>Value</h3>

<p>an object of class <code>"cv.glmtlp"</code> is returned, which is a list
with the ingredients of the cross-validation fit. 
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>the function call</p>
</td></tr>
<tr><td><code>cv.mean</code></td>
<td>
<p>The mean cross-validated error - a vector of length
<code>length(kappa)</code> if <code>penalty = "l0"</code> and <code>length{lambda}</code> 
otherwise.</p>
</td></tr> 
<tr><td><code>cv.se</code></td>
<td>
<p>estimate of standard error of <code>cv.mean</code>.</p>
</td></tr> 
<tr><td><code>fit</code></td>
<td>
<p>a fitted glmtlp object for the full data.</p>
</td></tr> 
<tr><td><code>idx.min</code></td>
<td>
<p>the index of the <code>lambda</code> or <code>kappa</code> sequence that 
corresponding to the smallest cv mean error.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>the values of <code>kappa</code> used in the fits, available when 
<code>penalty = 'l0'</code>.</p>
</td></tr>
<tr><td><code>kappa.min</code></td>
<td>
<p>the value of <code>kappa</code> that gives the minimum 
<code>cv.mean</code>, available when <code>penalty = 'l0'</code>. </p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the values of <code>lambda</code> used in the fits.</p>
</td></tr> 
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that gives minimum <code>cv.mean</code>,  
available when penalty is 'l1' or 'tlp'.</p>
</td></tr> 
<tr><td><code>null.dev</code></td>
<td>
<p>null deviance of the model.</p>
</td></tr>
<tr><td><code>obs.fold</code></td>
<td>
<p>the fold id for each observation used in the CV.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chunlin Li, Yu Yang, Chong Wu
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012). 
<em>Likelihood-based selection and sharp parameter estimation. 
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013). 
<em>On constrained and regularized high-dimensional regression. 
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021). 
<em>Inference for a Large Directed Graphical Model with Interventions. 
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014). 
<em>A coordinate majorization descent algorithm for l1 penalized learning. 
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>See Also</h3>

<p><code>glmtlp</code> and <code>plot</code>, <code>predict</code>, and <code>coef</code>
methods for <code>"cv.glmtlp"</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian
X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
cv.fit &lt;- cv.glmtlp(X, y, family = "gaussian", penalty = "l1", seed=2021)

# Binomial
X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- sample(c(0,1), 100, replace = TRUE)
cv.fit &lt;- cv.glmtlp(X, y, family = "binomial", penalty = "l1", seed=2021)

</code></pre>

<hr>
<h2 id='gau_data'>A simulated gaussian data set.</h2><span id='topic+gau_data'></span>

<h3>Description</h3>

<p>A data set simulated for illustrating linear regression models. Generated by 
<code>gen.gaussian.data(n = 200, p = 20, seed = 2021)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gau_data)
</code></pre>


<h3>Format</h3>

<p>A list with five elements: design matrix <code>X</code>, response <code>y</code>, 
correlation structure of the covariates <code>Sigma</code>, true beta <code>beta</code>, 
and the noise level <code>sigma</code>.
</p>

<dl>
<dt>X</dt><dd><p>design matrix</p>
</dd>
<dt>y</dt><dd><p>response</p>
</dd>
<dt>beta</dt><dd><p>true beta values</p>
</dd>
<dt>sigma</dt><dd><p>the noise level</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("gau_data")
cv.fit &lt;- cv.glmtlp(gau_data$X, gau_data$y, family = "gaussian", penalty = "tlp")
plot(cv.fit)

</code></pre>

<hr>
<h2 id='gen.binomial.data'>Simulate a binomial data set</h2><span id='topic+gen.binomial.data'></span>

<h3>Description</h3>

<p>Simulate a data set with binary response following the logistic regression
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.binomial.data(n, p, rho = 0, kappa = 5, beta.type = 1, seed = 2021)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen.binomial.data_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="gen.binomial.data_+3A_p">p</code></td>
<td>
<p>Number of covariates.</p>
</td></tr>
<tr><td><code id="gen.binomial.data_+3A_rho">rho</code></td>
<td>
<p>The parameter defining the AR(1) correlation matrix.</p>
</td></tr>
<tr><td><code id="gen.binomial.data_+3A_kappa">kappa</code></td>
<td>
<p>The number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="gen.binomial.data_+3A_beta.type">beta.type</code></td>
<td>
<p>Numeric indicator for choosing the beta type. For 
<code>beta.type = 1</code>, the true coefficient vector has <code>kappa</code> components being 1, 
roughly equally distributed between 1 to <code>p</code>. For <code>beta.type = 2</code>, 
the first <code>kappa</code> values are 1, and the rest are 0. For <code>beta.type = 3</code>, 
the first <code>kappa</code> values are equally-spaced values from 10 to 0.5, and 
the rest are 0. For <code>beta.type = 4</code>, the first <code>kappa</code> values are 
the first <code>kappa</code> values in c(-10, -6, -2, 2, 6, 10), and the rest are 
0. For <code>beta.type = 5</code>, the first <code>kappa</code> values are 1, and the 
rest decay exponentially to 0 with base 0.5.</p>
</td></tr>
<tr><td><code id="gen.binomial.data_+3A_seed">seed</code></td>
<td>
<p>The seed for reproducibility. Default is 2021.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the simulated data.
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the covariate matrix, of dimension <code>n</code> x <code>p</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response, of length <code>n</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the true coefficients, of length <code>p</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>bin_data &lt;- gen.binomial.data(n = 200, p = 20, seed = 2021)
head(bin_data$X)
head(bin_data$y)
head(bin_data$beta)

</code></pre>

<hr>
<h2 id='gen.gaussian.data'>Simulate a gaussian data set</h2><span id='topic+gen.gaussian.data'></span>

<h3>Description</h3>

<p>Simulate a data set with gaussian response following the linear regression
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.gaussian.data(
  n,
  p,
  rho = 0,
  kappa = 5,
  beta.type = 1,
  snr = 1,
  seed = 2021
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen.gaussian.data_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_p">p</code></td>
<td>
<p>Number of covariates.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_rho">rho</code></td>
<td>
<p>The parameter defining the AR(1) correlation matrix.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_kappa">kappa</code></td>
<td>
<p>The number of nonzero coefficients.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_beta.type">beta.type</code></td>
<td>
<p>Numeric indicator for choosing the beta type. For 
<code>beta.type = 1</code>, the true coefficient vector has <code>kappa</code> components being 1, 
roughly equally distributed between 1 to <code>p</code>. For <code>beta.type = 2</code>, 
the first <code>kappa</code> values are 1, and the rest are 0. For <code>beta.type = 3</code>, 
the first <code>kappa</code> values are equally-spaced values from 10 to 0.5, and 
the rest are 0. For <code>beta.type = 4</code>, the first <code>kappa</code> values are 
the first <code>kappa</code> values in c(-10, -6, -2, 2, 6, 10), and the rest are 
0. For <code>beta.type = 5</code>, the first <code>kappa</code> values are 1, and the 
rest decay exponentially to 0 with base 0.5.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_snr">snr</code></td>
<td>
<p>Signal-to-noise ratio. Default is 1.</p>
</td></tr>
<tr><td><code id="gen.gaussian.data_+3A_seed">seed</code></td>
<td>
<p>The seed for reproducibility. Default is 2021.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the simulated data.
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>the covariate matrix, of dimension <code>n</code> x <code>p</code>.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response, of length <code>n</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the true coefficients, of length <code>p</code>.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the standard error of the noise.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>gau_data &lt;- gen.gaussian.data(n = 200, p = 20, seed = 2021)
head(gau_data$X)
head(gau_data$y)
head(gau_data$beta)
gau_data$sigma

</code></pre>

<hr>
<h2 id='plot.cv.glmtlp'>Plot Method for a &quot;cv.glmtlp&quot; Object</h2><span id='topic+plot.cv.glmtlp'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve, and the upper and lower standard deviation
curves, as a function of the <code>lambda</code> or <code>kappa</code> values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmtlp'
plot(x, vertical.line = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cv.glmtlp_+3A_x">x</code></td>
<td>
<p>Fitted <code>cv.glmtlp</code> object</p>
</td></tr>
<tr><td><code id="plot.cv.glmtlp_+3A_vertical.line">vertical.line</code></td>
<td>
<p>Logical. Whether or not include a vertical line 
indicating the position of the index which gives the smallest CV error.</p>
</td></tr>
<tr><td><code id="plot.cv.glmtlp_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated plot is a <code>ggplot</code> object, and therefore, the users are able 
to customize the plots following the <code>ggplot2</code> syntax.
</p>


<h3>Author(s)</h3>

<p>Chunlin Li, Yu Yang, Chong Wu 
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012). 
<em>Likelihood-based selection and sharp parameter estimation. 
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013). 
<em>On constrained and regularized high-dimensional regression. 
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021). 
<em>Inference for a Large Directed Graphical Model with Interventions. 
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014). 
<em>A coordinate majorization descent algorithm for l1 penalized learning. 
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
cv.fit &lt;- cv.glmtlp(X, y, family = "gaussian", penalty = "tlp")
plot(cv.fit)
plot(cv.fit, vertical.line = FALSE)
cv.fit2 &lt;- cv.glmtlp(X, y, family = "gaussian", penalty = "l0")
plot(cv.fit2)
plot(cv.fit2, vertical.line = FALSE)

data("gau_data")
cv.fit &lt;- cv.glmtlp(gau_data$X, gau_data$y, family = "gaussian", penalty = "tlp")
plot(cv.fit)

data("bin_data")
cv.fit &lt;- cv.glmtlp(bin_data$X, bin_data$y, family = "binomial", penalty = "l1")
plot(cv.fit)

</code></pre>

<hr>
<h2 id='plot.glmtlp'>Plot Method for a &quot;glmtlp&quot; Object</h2><span id='topic+plot.glmtlp'></span>

<h3>Description</h3>

<p>Generates a solution path plot for a fitted <code>"glmtlp"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmtlp'
plot(
  x,
  xvar = c("lambda", "kappa", "deviance", "l1_norm", "log_lambda"),
  xlab = iname,
  ylab = "Coefficients",
  title = "Solution Path",
  label = FALSE,
  label.size = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.glmtlp_+3A_x">x</code></td>
<td>
<p>Fitted <code>glmtlp</code> object.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_xvar">xvar</code></td>
<td>
<p>The x-axis variable to plot against, including <code>"lambda"</code>, 
<code>"kappa"</code>, <code>"deviance"</code>, <code>"l1_norm"</code>, and <code>"log_lambda"</code>.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_xlab">xlab</code></td>
<td>
<p>The x-axis label of the plot, default is <code>"Lambda"</code>, 
<code>"Kappa"</code>, <code>"Fraction of Explained Deviance"</code>, <code>"L1 Norm"</code>, 
and <code>"Log Lambda"</code>.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_ylab">ylab</code></td>
<td>
<p>The y-axis label of the plot, default is &quot;Coefficients&quot;.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_title">title</code></td>
<td>
<p>The main title of the plot, default is &quot;Solution Path&quot;.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_label">label</code></td>
<td>
<p>Logical, whether or not attach the labels for the non-zero 
coefficients, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_label.size">label.size</code></td>
<td>
<p>The text size of the labels, default is 3.</p>
</td></tr>
<tr><td><code id="plot.glmtlp_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generated plot is a <code>ggplot</code> object, and therefore, the users are able 
to customize the plots following the <code>ggplot2</code> syntax.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object.
</p>


<h3>Author(s)</h3>

<p>Chunlin Li, Yu Yang, Chong Wu 
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012). 
<em>Likelihood-based selection and sharp parameter estimation. 
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013). 
<em>On constrained and regularized high-dimensional regression. 
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021). 
<em>Inference for a Large Directed Graphical Model with Interventions. 
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014). 
<em>A coordinate majorization descent algorithm for l1 penalized learning. 
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>See Also</h3>

<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,
and the <code>cv.glmtlp</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- glmtlp(X, y, family = "gaussian", penalty = "l1")
plot(fit, xvar = "lambda")
plot(fit, xvar = "log_lambda")
plot(fit, xvar = "l1_norm")
plot(fit, xvar = "log_lambda", label = TRUE)
fit2 &lt;- glmtlp(X, y, family = "gaussian", penalty = "l0")
plot(fit2, xvar = "kappa", label = TRUE)

</code></pre>

<hr>
<h2 id='predict.cv.glmtlp'>Predict Method for a &quot;cv.glmtlp&quot; Object.</h2><span id='topic+predict.cv.glmtlp'></span><span id='topic+coef.cv.glmtlp'></span>

<h3>Description</h3>

<p>Makes predictions for a cross-validated glmtlp model, using
the stored <code>"glmtlp"</code> object, and the optimal value chosen for
<code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glmtlp'
predict(
  object,
  X,
  type = c("link", "response", "class", "coefficients", "numnzs", "varnzs"),
  lambda = NULL,
  kappa = NULL,
  which = object$idx.min,
  ...
)

## S3 method for class 'cv.glmtlp'
coef(object, lambda = NULL, kappa = NULL, which = object$idx.min, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.glmtlp_+3A_object">object</code></td>
<td>
<p>Fitted <code>"cv.glmtlp"</code> object.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_x">X</code></td>
<td>
<p>X Matrix of new values for <code>X</code> at which predictions are to be
made. Must be a matrix.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_type">type</code></td>
<td>
<p>Type of prediction to be made. For <code>"gaussian"</code> models, type 
<code>"link"</code> and <code>"response"</code> are equivalent and both give the fitted 
values. For <code>"binomial"</code> models, type <code>"link"</code> gives the linear 
predictors and type <code>"response"</code> gives the fitted probabilities. 
Type <code>"coefficients"</code> computes the coefficients at the provided values 
of <code>lambda</code> or <code>kappa</code>. Note that for <code>"binomial"</code> 
models, results are returned only for the class corresponding to the second 
level of the factor response. Type <code>"class"</code> applies only to 
<code>"binomial"</code> models, and gives the class label corresponding to the 
maximum probability. Type <code>"numnz"</code> gives the total number of non-zero 
coefficients for each value of <code>lambda</code> or <code>kappa</code>. Type 
<code>"varnz"</code> gives a list of indices of the nonzero coefficients for 
each value of <code>lambda</code> or <code>kappa</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_lambda">lambda</code></td>
<td>
<p>Value of the penalty parameter <code>lambda</code> at which predictions
are to be made Default is NULL.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_kappa">kappa</code></td>
<td>
<p>Value of the penalty parameter <code>kappa</code> at which predictions 
are to be made. Default is NULL.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_which">which</code></td>
<td>
<p>Index of the penalty parameter <code>lambda</code> or <code>kappa</code> 
sequence at which predictions are to be made. Default is the <code>idx.min</code> 
stored in the <code>cv.glmtp</code> object.</p>
</td></tr>
<tr><td><code id="predict.cv.glmtlp_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on <code>type</code>.
</p>


<h3>Author(s)</h3>

<p>Chunlin Li, Yu Yang, Chong Wu 
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012). 
<em>Likelihood-based selection and sharp parameter estimation. 
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013). 
<em>On constrained and regularized high-dimensional regression. 
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021). 
<em>Inference for a Large Directed Graphical Model with Interventions. 
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014). 
<em>A coordinate majorization descent algorithm for l1 penalized learning. 
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>See Also</h3>

<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,
and the <code>cv.glmtlp</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
cv.fit &lt;- cv.glmtlp(X, y, family = "gaussian", penalty = "l1")
predict(cv.fit, X = X[1:5, ])
coef(cv.fit)
predict(cv.fit, X = X[1:5, ], lambda = 0.1)

</code></pre>

<hr>
<h2 id='predict.glmtlp'>Predict Method for a &quot;glmtlp&quot; Object</h2><span id='topic+predict.glmtlp'></span><span id='topic+coef.glmtlp'></span>

<h3>Description</h3>

<p>Predicts fitted values, logits, coefficients and more from a fitted 
<code>glmtlp</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmtlp'
predict(
  object,
  X,
  type = c("link", "response", "class", "coefficients", "numnz", "varnz"),
  lambda = NULL,
  kappa = NULL,
  which = 1:(ifelse(object$penalty == "l0", length(object$kappa), length(object$lambda))),
  ...
)

## S3 method for class 'glmtlp'
coef(
  object,
  lambda = NULL,
  kappa = NULL,
  which = 1:(ifelse(object$penalty == "l0", length(object$kappa), length(object$lambda))),
  drop = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.glmtlp_+3A_object">object</code></td>
<td>
<p>Fitted <code>glmtlp</code> model object.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_x">X</code></td>
<td>
<p>Matrix of new values for <code>X</code> at which predictions are to be
made. Must be a matrix. This argument will not used for 
<code>type=c("coefficients","numnz", "varnz")</code>.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_type">type</code></td>
<td>
<p>Type of prediction to be made. For <code>"gaussian"</code> models, type 
<code>"link"</code> and <code>"response"</code> are equivalent and both give the fitted 
values. For <code>"binomial"</code> models, type <code>"link"</code> gives the linear 
predictors and type <code>"response"</code> gives the fitted probabilities. 
Type <code>"coefficients"</code> computes the coefficients at the provided values 
of <code>lambda</code> or <code>kappa</code>. Note that for <code>"binomial"</code> 
models, results are returned only for the class corresponding to the second 
level of the factor response. Type <code>"class"</code> applies only to 
<code>"binomial"</code> models, and gives the class label corresponding to the 
maximum probability. Type <code>"numnz"</code> gives the total number of non-zero 
coefficients for each value of <code>lambda</code> or <code>kappa</code>. Type 
<code>"varnz"</code> gives a list of indices of the nonzero coefficients for 
each value of <code>lambda</code> or <code>kappa</code>.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_lambda">lambda</code></td>
<td>
<p>Value of the penalty parameter <code>lambda</code> at which predictions
are to be made Default is NULL.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_kappa">kappa</code></td>
<td>
<p>Value of the penalty parameter <code>kappa</code> at which predictions 
are to be made. Default is NULL.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_which">which</code></td>
<td>
<p>Index of the penalty parameter <code>lambda</code> or <code>kappa</code> 
sequence at which predictions are to be made. Default are the indices for the 
entire penalty parameter sequence.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="predict.glmtlp_+3A_drop">drop</code></td>
<td>
<p>Whether or not keep the dimension that is of length 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef(...)</code> is equivalent to <code>predict(type="coefficients",...)</code>
</p>


<h3>Value</h3>

<p>The object returned depends on <code>type</code>.
</p>


<h3>Author(s)</h3>

<p>Chunlin Li, Yu Yang, Chong Wu 
<br /> Maintainer: Yu Yang <a href="mailto:yang6367@umn.edu">yang6367@umn.edu</a>
</p>


<h3>References</h3>

<p>Shen, X., Pan, W., &amp; Zhu, Y. (2012). 
<em>Likelihood-based selection and sharp parameter estimation. 
Journal of the American Statistical Association, 107(497), 223-232.</em>
<br /> Shen, X., Pan, W., Zhu, Y., &amp; Zhou, H. (2013). 
<em>On constrained and regularized high-dimensional regression. 
Annals of the Institute of Statistical Mathematics, 65(5), 807-832.</em>
<br /> Li, C., Shen, X., &amp; Pan, W. (2021). 
<em>Inference for a Large Directed Graphical Model with Interventions. 
arXiv preprint arXiv:2110.03805.</em>
<br /> Yang, Y., &amp; Zou, H. (2014). 
<em>A coordinate majorization descent algorithm for l1 penalized learning. 
Journal of Statistical Computation and Simulation, 84(1), 84-95.</em>
<br /> Two R package Github: <em>ncvreg</em> and <em>glmnet</em>.
</p>


<h3>See Also</h3>

<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,
and the <code>cv.glmtlp</code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gaussian
X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- glmtlp(X, y, family = "gaussian", penalty = "l1")
predict(fit, X = X[1:5, ])
coef(fit)
predict(fit, X = X[1:5, ], lambda = 0.1)

# Binomial
X &lt;- matrix(rnorm(100 * 20), 100, 20)
y &lt;- sample(c(0,1), 100, replace = TRUE)
fit &lt;- glmtlp(X, y, family = "binomial", penalty = "l1")
coef(fit)
predict(fit, X = X[1:5, ], type = "response")
predict(fit, X = X[1:5, ], type = "response", lambda = 0.01)
predict(fit, X = X[1:5, ], type = "class", lambda = 0.01)
predict(fit, X = X[1:5, ], type = "numnz", lambda = 0.01)

</code></pre>

<hr>
<h2 id='setup_lambda'>Generate lambda sequence.</h2><span id='topic+setup_lambda'></span>

<h3>Description</h3>

<p>Generate lambda sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup_lambda(X, y, weights, lambda.min.ratio, nlambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setup_lambda_+3A_x">X</code></td>
<td>
<p>Input matrix, of dimension <code>nobs</code> x <code>nvars</code>; 
each row is  an observation vector.</p>
</td></tr>
<tr><td><code id="setup_lambda_+3A_y">y</code></td>
<td>
<p>Response variable, of length <code>nobs</code>. For <code>family="gaussian"</code>, 
it should be quantitative; for <code>family="binomial"</code>, it should be either 
a factor with two levels or a binary vector.</p>
</td></tr>
<tr><td><code id="setup_lambda_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
<tr><td><code id="setup_lambda_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>The smallest value for <code>lambda</code>, as a fraction of 
<code>lambda.max</code>, the smallest value for which all coefficients are zero. 
The default depends on the sample size <code>nobs</code> relative to the number 
of variables <code>nvars</code>.</p>
</td></tr>
<tr><td><code id="setup_lambda_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
