<!DOCTYPE html><html><head><title>Help for package lidR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lidR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lidR-package'><p>lidR: airborne LiDAR for forestry applications</p></a></li>
<li><a href='#add_attribute'><p>Add attributes into a LAS object</p></a></li>
<li><a href='#aggregate'><p>Metric derivation at different levels of regularization</p></a></li>
<li><a href='#as'><p>Transform to a list</p></a></li>
<li><a href='#asprs'><p>ASPRS LAS Classification</p></a></li>
<li><a href='#catalog_apply'><p>LAScatalog processing engine</p></a></li>
<li><a href='#catalog_boundaries'><p>Computes the polygon that encloses the points</p></a></li>
<li><a href='#catalog_intersect'><p>Subset a LAScatalog</p></a></li>
<li><a href='#catalog_retile'><p>Retile a LAScatalog</p></a></li>
<li><a href='#classify'><p>Classify points</p></a></li>
<li><a href='#clip'><p>Clip points in regions of interest</p></a></li>
<li><a href='#decimate_points'><p>Decimate a LAS object</p></a></li>
<li><a href='#deprecated'><p>Deprecated functions in lidR</p></a></li>
<li><a href='#dsm_pitfree'><p>Digital Surface Model Algorithm</p></a></li>
<li><a href='#dsm_point2raster'><p>Digital Surface Model Algorithm</p></a></li>
<li><a href='#dsm_tin'><p>Digital Surface Model Algorithm</p></a></li>
<li><a href='#dtm_idw'><p>Spatial Interpolation Algorithm</p></a></li>
<li><a href='#dtm_kriging'><p>Spatial Interpolation Algorithm</p></a></li>
<li><a href='#dtm_tin'><p>Spatial Interpolation Algorithm</p></a></li>
<li><a href='#engine'><p>Functions for the LAScatalog processing engine not meant to be called directly by users</p></a></li>
<li><a href='#engine_options'><p>Get or set LAScatalog processing engine options</p></a></li>
<li><a href='#Extract'><p>Extract or Replace Parts of a LAS* Object</p></a></li>
<li><a href='#filters'><p>Filter points of interest</p></a></li>
<li><a href='#gnd_csf'><p>Ground Segmentation Algorithm</p></a></li>
<li><a href='#gnd_mcc'><p>Ground Segmentation Algorithm</p></a></li>
<li><a href='#gnd_pmf'><p>Ground Segmentation Algorithm</p></a></li>
<li><a href='#interpret_waveform'><p>Convert full waveform data into a regular point cloud</p></a></li>
<li><a href='#is'><p>A set of boolean tests on objects</p></a></li>
<li><a href='#itd_lmf'><p>Individual Tree Detection Algorithm</p></a></li>
<li><a href='#itd_manual'><p>Individual Tree Detection Algorithm</p></a></li>
<li><a href='#its_dalponte2016'><p>Individual Tree Segmentation Algorithm</p></a></li>
<li><a href='#its_li2012'><p>Individual Tree Segmentation Algorithm</p></a></li>
<li><a href='#its_silva2016'><p>Individual Tree Segmentation Algorithm</p></a></li>
<li><a href='#its_watershed'><p>Individual Tree Segmentation Algorithm</p></a></li>
<li><a href='#las_check'><p>Inspect a LAS object</p></a></li>
<li><a href='#las_compression'><p>Compression of the point cloud</p></a></li>
<li><a href='#las_utilities'><p>LAS utilities</p></a></li>
<li><a href='#LAS-class'><p>An S4 class to represent a .las or .laz file</p></a></li>
<li><a href='#LAScatalog-class'><p>An S4 class to represent a collection of .las or .laz files</p></a></li>
<li><a href='#LASheader'><p>Create a <code>LASheader</code> object</p></a></li>
<li><a href='#LASheader-class'><p>An S4 class to represent the header of .las or .laz files</p></a></li>
<li><a href='#lidR-LAScatalog-drivers'><p>LAScatalog drivers</p></a></li>
<li><a href='#lidR-parallelism'><p>Parallel computation in lidR</p></a></li>
<li><a href='#lidR-spatial-index'><p>Spatial index</p></a></li>
<li><a href='#locate_trees'><p>Individual tree detection</p></a></li>
<li><a href='#merge_spatial'><p>Merge a point cloud with a source of spatial data</p></a></li>
<li><a href='#noise_ivf'><p>Noise Segmentation Algorithm</p></a></li>
<li><a href='#noise_sor'><p>Noise Segmentation Algorithm</p></a></li>
<li><a href='#normalize'><p>Normalize point cloud</p></a></li>
<li><a href='#nstdmetrics'><p>Predefined non standard metrics</p></a></li>
<li><a href='#old_spatial_packages'><p>Older R Spatial Packages</p></a></li>
<li><a href='#pitfill_stonge2008'><p>Pits and spikes filling</p></a></li>
<li><a href='#plot'><p>Plot a LAS* object</p></a></li>
<li><a href='#plot_3d'><p>Add a spatial object to a point cloud scene</p></a></li>
<li><a href='#plot.lasmetrics3d'><p>Plot voxelized LiDAR data</p></a></li>
<li><a href='#plugins'><p>Plugin system</p></a></li>
<li><a href='#point_metrics'><p>Point-based metrics</p></a></li>
<li><a href='#print.LAS'><p>Tools inherited from base R for LAS* objects</p></a></li>
<li><a href='#range_correction'><p>Intensity normalization algorithm</p></a></li>
<li><a href='#rasterize'><p>Rasterize a point cloud</p></a></li>
<li><a href='#readLAS'><p>Read .las or .laz files</p></a></li>
<li><a href='#readLAScatalog'><p>Create an object of class LAScatalog</p></a></li>
<li><a href='#readLASheader'><p>Read a .las or .laz file header</p></a></li>
<li><a href='#retrieve_pulses'><p>Retrieve individual pulses, flightlines or scanlines</p></a></li>
<li><a href='#sample_homogenize'><p>Point Cloud Decimation Algorithm</p></a></li>
<li><a href='#sample_maxima'><p>Point Cloud Decimation Algorithm</p></a></li>
<li><a href='#sample_per_voxel'><p>Point Cloud Decimation Algorithm</p></a></li>
<li><a href='#sample_random'><p>Point Cloud Decimation Algorithm</p></a></li>
<li><a href='#segment'><p>Segment a point cloud</p></a></li>
<li><a href='#set_lidr_threads'><p>Set or get number of threads that lidR should use</p></a></li>
<li><a href='#shape_detection'><p>Algorithms for shape detection of the local point neighbourhood</p></a></li>
<li><a href='#smooth_height'><p>Smooth a point cloud</p></a></li>
<li><a href='#snag_wing2015'><p>Snags Segmentation Algorithm</p></a></li>
<li><a href='#st_area'><p>Surface covered by a LAS* object</p></a></li>
<li><a href='#st_bbox'><p>Bounding box of a LAS* object</p></a></li>
<li><a href='#st_coordinates'><p>Coordinates of a LAS* object in a matrix form</p></a></li>
<li><a href='#st_crs'><p>Get or set the projection of a LAS* object</p></a></li>
<li><a href='#st_hull'><p>Concave and convex hulls for LAS objects</p></a></li>
<li><a href='#st_transform'><p>Transform or convert coordinates of LAS objects</p></a></li>
<li><a href='#stdmetrics'><p>Predefined standard metrics functions</p></a></li>
<li><a href='#track_sensor'><p>Reconstruct the trajectory of the LiDAR sensor using multiple returns</p></a></li>
<li><a href='#track_sensor_gatziolis2019'><p>Sensor tracking algorithm</p></a></li>
<li><a href='#track_sensor_roussel2020'><p>Sensor tracking algorithm</p></a></li>
<li><a href='#voxelize_points'><p>Voxelize a point cloud</p></a></li>
<li><a href='#writeLAS'><p>Write a .las or .laz file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Airborne LiDAR Data Manipulation and Visualization for Forestry
Applications</td>
</tr>
<tr>
<td>Version:</td>
<td>4.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Airborne LiDAR (Light Detection and Ranging) interface for data
    manipulation and visualization. Read/write 'las' and 'laz' files, computation
    of metrics in area based approach, point filtering, artificial point reduction,
    classification from geographic data, normalization, individual tree segmentation
    and other manipulations.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/r-lidar/lidR">https://github.com/r-lidar/lidR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-lidar/lidR/issues">https://github.com/r-lidar/lidR/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>classInt, data.table (&ge; 1.12.0), glue, grDevices, lazyeval,
Rcpp (&ge; 1.0.3), rgl, rlas (&ge; 1.5.0), sf, stats, stars, terra
(&ge; 1.5-17), tools, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>EBImage, future, geometry, gstat, raster, RCSF, RMCC, rjson,
mapview, mapedit, progress, sp, testthat (&ge; 2.1.0), knitr,
rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.72.0),Rcpp,RcppArmadillo</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-05 16:16:36 UTC; jr</td>
</tr>
<tr>
<td>Author:</td>
<td>Jean-Romain Roussel [aut, cre, cph],
  David Auty [aut, ctb] (Reviews the documentation),
  Florian De Boissieu [ctb] (Fixed bugs and improved catalog features),
  Andrew Sánchez Meador [ctb] (Implemented wing2015() for
    segment_snags()),
  Bourdon Jean-François [ctb] (Contributed to Roussel2020() for
    track_sensor()),
  Gatziolis Demetrios [ctb] (Implemented Gatziolis2019() for
    track_sensor()),
  Leon Steinmeier [ctb] (Contributed to parallelization management),
  Stanislaw Adaszewski [cph] (Author of the C++ concaveman code),
  Benoît St-Onge [cph] (Author of the 'chm_prep' function)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jean-Romain Roussel &lt;jean-romain.roussel.1@ulaval.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-05 17:00:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='lidR-package'>lidR: airborne LiDAR for forestry applications</h2><span id='topic+lidR'></span><span id='topic+lidR-package'></span>

<h3>Description</h3>

<p>lidR provides a set of tools to manipulate airborne LiDAR data in forestry contexts. The package
works with .las or .laz files. The toolbox includes algorithms for DSM, CHM, DTM, ABA,
normalisation, tree detection, tree segmentation, tree delineation, colourization, validation and
other tools, as well as a processing engine to process broad LiDAR coverage split into many files.
</p>


<h3>Details</h3>

<p>To learn more about lidR, start with the vignettes: browseVignettes(package = &quot;lidR&quot;). Users can also
find unofficial supplementary documentation in the <a href="https://r-lidar.github.io/lidRbook/">lidR book</a>.
To ask &quot;how to&quot; questions please ask on <a href="https://gis.stackexchange.com/">gis.stackexchange.com</a>
with the tag <code>lidr</code>.
</p>


<h3>Package options</h3>


<dl>
<dt><code>lidR.progress</code></dt><dd><p>Several functions have a progress bar for long operations (but not all).
Should lengthy operations show a progress bar? Default: TRUE</p>
</dd>
<dt><code>lidR.progress.delay</code></dt><dd><p>The progress bar appears only for long operations. After how many seconds
of computation does the progress bar appear? Default: 2</p>
</dd>
<dt><code>lidR.raster.default</code></dt><dd><p>The functions that return a raster are raster agnostic meaning
that they work either with rasters from packages 'raster', 'stars' or 'terra'. By default they return
rasters from 'stars'. Can be one of &quot;raster&quot;, &quot;stars&quot; or &quot;terra&quot;. Default: &quot;terra&quot;</p>
</dd>
<dt><code>lidR.check.nested.parallelism</code></dt><dd><p>The catalog processing engine (<a href="#topic+catalog_apply">catalog_apply</a>)
checks the parallel strategy chosen by the user and verify if C++ parallelization with
OpenMP should be disabled to avoid nested parallel loops. Default: TRUE. If FALSE
the catalog processing engine will not check for nested parallelism
and will respect the settings of <a href="#topic+set_lidr_threads">set_lidr_threads</a>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jean-Romain Roussel <a href="mailto:jean-romain.roussel.1@ulaval.ca">jean-romain.roussel.1@ulaval.ca</a> [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> David Auty (Reviews the documentation) [contributor]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Florian De Boissieu (Fixed bugs and improved catalog features) [contributor]
</p>
</li>
<li><p> Andrew Sánchez Meador (Implemented wing2015() for segment_snags()) [contributor]
</p>
</li>
<li><p> Bourdon Jean-François (Contributed to Roussel2020() for track_sensor()) [contributor]
</p>
</li>
<li><p> Gatziolis Demetrios (Implemented Gatziolis2019() for track_sensor()) [contributor]
</p>
</li>
<li><p> Leon Steinmeier (Contributed to parallelization management) [contributor]
</p>
</li>
<li><p> Stanislaw Adaszewski (Author of the C++ concaveman code) [copyright holder]
</p>
</li>
<li><p> Benoît St-Onge (Author of the 'chm_prep' function) [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/r-lidar/lidR">https://github.com/r-lidar/lidR</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/r-lidar/lidR/issues">https://github.com/r-lidar/lidR/issues</a>
</p>
</li></ul>


<hr>
<h2 id='add_attribute'>Add attributes into a LAS object</h2><span id='topic+add_attribute'></span><span id='topic+add_lasattribute'></span><span id='topic+add_lasattribute_manual'></span><span id='topic+add_lasrgb'></span><span id='topic+add_lasnir'></span><span id='topic+remove_lasattribute'></span>

<h3>Description</h3>

<p>A <a href="#topic+LAS-class">LAS</a> object represents a las file in R. According to the
<a href="https://www.asprs.org/a/society/committees/standards/LAS_1_4_r13.pdf">LAS specifications</a>
a las file contains a core of defined attributes, such as XYZ coordinates, intensity, return number,
and so on, for each point. It is possible to add supplementary attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_attribute(las, x, name)

add_lasattribute(las, x, name, desc)

add_lasattribute_manual(
  las,
  x,
  name,
  desc,
  type,
  offset = NULL,
  scale = NULL,
  NA_value = NULL
)

add_lasrgb(las, R, G, B)

add_lasnir(las, NIR)

remove_lasattribute(las, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_attribute_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a></p>
</td></tr>
<tr><td><code id="add_attribute_+3A_x">x</code></td>
<td>
<p>a vector that needs to be added in the LAS object. For <code>add_lasattribute*</code> it can
be missing (see details).</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_name">name</code></td>
<td>
<p>character. The name of the extra bytes attribute to add in the file.</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_desc">desc</code></td>
<td>
<p>character. A short description of the extra bytes attribute to add in the file (32 characters).</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_type">type</code></td>
<td>
<p>character. The data type of the extra bytes attribute. Can be &quot;uchar&quot;, &quot;char&quot;, &quot;ushort&quot;,
&quot;short&quot;, &quot;uint&quot;, &quot;int&quot;, &quot;uint64&quot;, &quot;int64&quot;, &quot;float&quot;, &quot;double&quot;.</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_scale">scale</code>, <code id="add_attribute_+3A_offset">offset</code></td>
<td>
<p>numeric. The scale and offset of the data. NULL if not relevant.</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_na_value">NA_value</code></td>
<td>
<p>numeric or integer. NA is not a valid value in a las file. At time of writing it will
be replaced by this value that will be considered as NA. NULL if not relevant.</p>
</td></tr>
<tr><td><code id="add_attribute_+3A_r">R</code>, <code id="add_attribute_+3A_g">G</code>, <code id="add_attribute_+3A_b">B</code>, <code id="add_attribute_+3A_nir">NIR</code></td>
<td>
<p>integer. RGB and NIR values. Values are automatically scaled to 16 bits if they are
coded on 8 bits (0 to 255).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users cannot assign names that are the same as the names of the core attributes. These functions are
dedicated to adding data that are not part of the LAS specification. For example, <code>add_lasattribute(las, x, "R")</code>
will fail because <code>R</code> is a name reserved for the red channel of a .las file that contains RGB
attributes. Use <code>add_lasrgb</code> instead.
</p>

<dl>
<dt><code>add_attribute</code></dt><dd><p>Simply adds a new column in the data but does not update the header. Thus the LAS
object is not strictly valid. These data will be temporarily usable at the R level but will not
be written in a las file with <a href="#topic+writeLAS">writeLAS</a>.</p>
</dd>
<dt> <code>add_lasattribute</code></dt><dd><p>Does the same as <code>add_attribute</code> but automatically updates the header of
the LAS object. Thus, the LAS object is valid and the new data is considered as &quot;extra bytes&quot;. This new
data will be written in a las file with <a href="#topic+writeLAS">writeLAS</a>.</p>
</dd>
<dt><code>add_lasattribute_manual</code></dt><dd><p>Allows the user to manually write all the extra bytes metadata.
This function is reserved for experienced users with a good knowledge of the LAS specifications.
The function does not perform tests to check the validity of the information.
When using <code>add_lasattribute</code> and <code>add_lasattribute_manual</code>, <code>x</code> can only be of type numeric,
(<code>integer</code> or <code>double</code>). It cannot be of type <code>character</code> or <code>logical</code> as these are
not supported by the LAS specifications. The types that are supported in lidR are types 0 to 10
(Table 24 on page 25 of the specification). Types greater than 10 are not supported.</p>
</dd>
<dt><code>add_lasrgb</code></dt><dd><p>Adds 3 columns named RGB and updates the point format of the LAS object
for a format that supports RGB attributes. If the RGB values are ranging from 0 to 255 they are
automatically scaled on 16 bits.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <a href="#topic+LAS-class">LAS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las &lt;- readLAS(LASfile, select = "xyz")

print(las)
print(header(las))

x &lt;- 1:30

las &lt;- add_attribute(las, x, "mydata")
print(las)        # The las object has a new attribute called "mydata"
print(header(las)) # But the header has not been updated. This new data will not be written

las &lt;- add_lasattribute(las, x, "mydata2", "A new data")
print(las)        # The las object has a new attribute called "mydata2"
print(header(las)) # The header has been updated. This new data will be written

# Optionally if the data is already in the LAS object you can update the header skipping the
# parameter x
las &lt;- add_attribute(las, x, "newattr")
las &lt;- add_lasattribute(las, name = "newattr", desc = "Amplitude")
print(header(las))

# Remove an extra bytes attribute
las &lt;- remove_lasattribute(las, "mydata2")
print(las)
print(header(las))

las &lt;- remove_lasattribute(las, "mydata")
print(las)
print(header(las))
</code></pre>

<hr>
<h2 id='aggregate'>Metric derivation at different levels of regularization</h2><span id='topic+aggregate'></span><span id='topic+cloud_metrics'></span><span id='topic+crown_metrics'></span><span id='topic+hexagon_metrics'></span><span id='topic+pixel_metrics'></span><span id='topic+plot_metrics'></span><span id='topic+polygon_metrics'></span><span id='topic+template_metrics'></span><span id='topic+voxel_metrics'></span>

<h3>Description</h3>

<p><code>template_metrics()</code> computes a series of user-defined descriptive statistics for a LiDAR dataset
within each element of a template. Depending on the template it can be for each pixel of a raster
(area-based approach), or each polygon, or each segmented tree, or on the whole point cloud. Other
functions are convenient and simplified wrappers around <code>template_metrics()</code> and are expected to be
the actual functions used. See Details and Examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cloud_metrics(las, func, ...)

crown_metrics(
  las,
  func,
  geom = "point",
  concaveman = c(3, 0),
  attribute = "treeID",
  ...
)

hexagon_metrics(las, func, area = 400, ...)

pixel_metrics(las, func, res = 20, start = c(0, 0), ...)

plot_metrics(las, func, geometry, ..., radius)

polygon_metrics(las, func, geometry, ...)

template_metrics(las, func, template, filter = NULL, by_echo = "all", ...)

voxel_metrics(las, func, res = 1, ..., all_voxels = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_func">func</code></td>
<td>
<p>formula or expression. An expression to be applied to each element of the template (see
section &quot;Parameter func&quot;).</p>
</td></tr>
<tr><td><code id="aggregate_+3A_...">...</code></td>
<td>
<p>propagated to <code>template_metrics</code> i.e. <code>filter</code> and <code>by_echo</code>. <code>pixel_metrics()</code> also
supports <code>pkg = "terra|raster|stars"</code> to get an output in <code>SpatRaster</code>, <code style="white-space: pre;">&#8288;Raster*&#8288;</code>
or <code>stars</code> format. Default is <code>getOption("lidR.raster.default")</code>.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_geom">geom</code></td>
<td>
<p>character. Geometry type of the output. Can be 'point', 'convex', 'concave' or 'bbox'.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_concaveman">concaveman</code></td>
<td>
<p>numeric. Only if <code>type = "concave"</code>. Vector with the two parameters of the
function <a href="#topic+concaveman">concaveman</a>.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_attribute">attribute</code></td>
<td>
<p>character. The column name of the attribute containing tree IDs. Default is
<code>"treeID"</code></p>
</td></tr>
<tr><td><code id="aggregate_+3A_area">area</code></td>
<td>
<p>numeric. Area of the hexagons</p>
</td></tr>
<tr><td><code id="aggregate_+3A_res">res</code></td>
<td>
<p>numeric. The resolution of the output. Can optionally be a <code>RasterLayer</code> or a <code>stars</code> or
a <code>SpatRaster</code>. In that case the raster is used as the template.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_start">start</code></td>
<td>
<p>vector of x and y coordinates for the reference raster. Default is (0,0) meaning that the
grid aligns on (0,0). Not consiered if <code>res</code> is a raster</p>
</td></tr>
<tr><td><code id="aggregate_+3A_geometry">geometry</code></td>
<td>
<p>A spatial vector object. <code>sp</code> and <code>sf</code>' objects are supported. <code>plot_metrics()</code>
supports point and polygons but <code>polygon_metrics()</code> supports only polygons.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_radius">radius</code></td>
<td>
<p>numeric. If the geometry is spatial points a radius must be defined. Support one
radius or a vector of radii for variable plot sizes.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_template">template</code></td>
<td>
<p>can be of many types and corresponds to the different levels of regularization.
<code>RasterLayer/stars/SpatRaster</code>, <code>sf/sfc</code> (polygons), <code>numeric</code>, <code>bbox</code>, <code>NULL</code>. The metrics are
computed for each element of the template. See examples.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_filter">filter</code></td>
<td>
<p>formula of logical predicates. Enables the function to run only on points of interest
in an optimized way. See examples.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_by_echo">by_echo</code></td>
<td>
<p>characters. The metrics are computed multiple times for different echo types. Can
be one or more of &quot;all&quot;, &quot;first&quot;, &quot;intermediate&quot;, &quot;lastofmany&quot;, &quot;single&quot;, and &quot;multiple&quot;. See examples.
Default is &quot;all&quot; meaning that it computes metrics with all points provided.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_all_voxels">all_voxels</code></td>
<td>
<p>boolean. By default the function returns only voxels that
contain 1 or more points. Empty voxels do not exist as the metrics are undefined.
If <code>all_voxels = TRUE</code> all the voxels are returned and metrics are NA for
voxels with 0 points.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>pixel_metrics</code></dt><dd><p>Area-based approach. Computes metrics in a square tessellation. The output is a
raster.</p>
</dd>
<dt><code>hexagon_metrics</code></dt><dd><p>Computes metrics in an hexagon tessellation. The output is a <code>sf/sfc_POLYGON</code></p>
</dd>
<dt><code>plot_metrics</code></dt><dd><p>Computes metrics for each plot of a ground inventory by 1. clipping the plot
inventories with <a href="#topic+clip_roi">clip_roi</a>, 2. computing the user's metrics for each plot with  <a href="#topic+cloud_metrics">cloud_metrics</a>, and
3. combining spatial data and metrics into one data.frame ready for statistical modelling with
<code>cbind</code>. The output is of the class of the input.</p>
</dd>
<dt><code>cloud_metrics</code></dt><dd><p>Computes a series of user-defined descriptive statistics for an entire point cloud.
The output is a <code>list</code></p>
</dd>
<dt><code>crown_metrics</code></dt><dd><p>Once the trees are segmented, i.e. attributes exist in the
point cloud that reference each tree, computes a set of user-defined descriptive statistics for
each individual tree. The output can be spatial points or spatial polygons (<code>sf/sfc_POINT</code> or <code>sf/sfc_POLYGON</code>)</p>
</dd>
<dt><code>voxel_metrics</code></dt><dd><p>Is a 3D version of <code>pixel_metrics</code>. It creates a 3D matrix of voxels with a given
resolution. It creates a voxel from the cloud of points if there is at least one point. The output is
a <code>data.frame</code></p>
</dd>
<dt><code>point_metrics</code></dt><dd><p>Is a bit more complex and is documented in <a href="#topic+point_metrics">point_metrics</a></p>
</dd>
</dl>



<h3>Value</h3>

<p>Depends on the function, the template and the number of metrics. Can be a <code>RasterLayer</code>,
a <code>RasterBrick</code>, a <code>stars</code>, a <code>SpatRaster</code> a <code>sf/sfc</code>, a <code>list</code>, a <code>SpatialPolygonDataFrame</code>, or
a <code>data.table</code>. Functions are supposed to return an object that is best suited for storing the level
of regularization needed.
</p>


<h3>Parameter <code>func</code></h3>

<p>The function to be applied to each cell is a classical function (see examples) that
returns a labelled list of metrics. For example, the following function <code>f</code> is correctly formed.
</p>
<pre>
f = function(x) {list(mean = mean(x), max = max(x))}
</pre>
<p>And could be applied either on the <code>Z</code> coordinates or on the intensities. These two
statements are valid:
</p>
<pre>
pixel_metrics(las, f(Z), res = 20)
voxel_metrics(las, f(Intensity), res = 2)
</pre>
<p>The following existing functions allow the user to
compute some predefined metrics: <a href="#topic+stdmetrics">stdmetrics</a>
<a href="#topic+entropy">entropy</a>, <a href="#topic+VCI">VCI</a>, <a href="#topic+LAD">LAD</a>. But usually users must write their own
functions to create metrics. <code>template_metrics</code> will dispatch the point cloud in the user's
function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-keep_random_fraction 0.5")
col &lt;- sf::sf.colors(15)
fun1 &lt;- ~list(maxz = max(Z))
fun2 &lt;- ~list(q85 = quantile(Z, probs = 0.85))

set_lidr_threads(1) ; data.table::setDTthreads(1) # for cran only

# ================
# CLOUD METRICS
# ================

cloud_metrics(las, .stdmetrics_z)

# ================
# PIXEL METRICS
# ================

m &lt;- pixel_metrics(las, fun1, 20)
#plot(m, col = col)

# ================
# PLOT METRICS
# ================

shpfile &lt;- system.file("extdata", "efi_plot.shp", package="lidR")
inventory &lt;- sf::st_read(shpfile, quiet = TRUE)
inventory # contains an ID and a Value Of Interest (VOI) per plot

m &lt;- plot_metrics(las, fun2, inventory, radius = 11.28)
#plot(header(las))
#plot(m["q85"], pch = 19, cex = 3, add = TRUE)


# Works with polygons as well
inventory &lt;- sf::st_buffer(inventory, 11.28)
#plot(header(las))
#plot(sf::st_geometry(inventory), add = TRUE)
m &lt;- plot_metrics(las, .stdmetrics_z, inventory)
#plot(m["zq85"], pch = 19, cex = 3, add = TRUE)


# ================
# VOXEL METRICS
# ================

m &lt;- voxel_metrics(las, length(Z), 8)
m &lt;- voxel_metrics(las, mean(Intensity), 8)
#plot(m, color = "V1", colorPalette = heat.colors(50), trim = 60)
#plot(m, color = "V1", colorPalette = heat.colors(50), trim = 60, voxel = TRUE)

# ================
# CROWN METRICS
# ================

# Already tree-segmented point cloud
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
trees &lt;- readLAS(LASfile, filter = "-drop_z_below 0")

metrics &lt;- crown_metrics(trees, .stdtreemetrics)
#plot(metrics["Z"], pch = 19)

metrics &lt;- crown_metrics(trees, .stdtreemetrics, geom = "convex")
#plot(metrics["Z"])

metrics &lt;- crown_metrics(trees, .stdtreemetrics, geom = "bbox")
#plot(metrics["Z"])


metrics &lt;- crown_metrics(trees, .stdtreemetrics, geom = "concave")
#plot(metrics["Z"])

# ================
# ARGUMENT FILTER
# ================

# Compute using only some points: basic
first = filter_poi(las, ReturnNumber == 1)
metrics = pixel_metrics(first, mean(Z), 20)

# Compute using only some points: optimized
# faster and uses less memory. No intermediate object
metrics = pixel_metrics(las, mean(Z), 20, filter = ~ReturnNumber == 1)

# Compute using only some points: best
# ~50% faster and uses ~10x less memory
las = readLAS(LASfile, filter = "-keep_first")
metrics = pixel_metrics(las, mean(Z), 20)

# ================
# ARGUMENT BY_ECHO
# ================

func = ~list(avgI = mean(Intensity))
echo = c("all", "first","multiple")

# func defines one metric but 3 are computed respectively for: (1) all echo types,
# (2) for first returns only and (3) for multiple returns only
metrics &lt;- pixel_metrics(las, func, 20, by_echo = echo)
#plot(metrics, col = heat.colors(25))

cloud_metrics(las, func, by_echo = echo)

## Not run: 
# ================
# TEMPLATE METRICS
# ================

# a raster as template
template &lt;- raster::raster(extent(las), nrow = 15, ncol = 15)
raster::crs(template) &lt;- crs(las)
m &lt;- template_metrics(las, fun1, template)
#plot(m, col = col)

# a sfc_POLYGON as template
sfc &lt;- sf::st_as_sfc(st_bbox(las))
template &lt;- sf::st_make_grid(sfc, cellsize = 20, square = FALSE)
m &lt;- template_metrics(las, fun1, template)
#plot(m)

# a bbox as template
template &lt;- st_bbox(las) + c(50,30,-50,-70)
plot(sf::st_as_sfc(st_bbox(las)), col = "gray")
plot(sf::st_as_sfc(template), col = "darkgreen", add = TRUE)
m &lt;- template_metrics(las, fun2, template)
print(m)

# ================
# CUSTOM METRICS
# ================

# Define a function that computes custom metrics
# in an R&amp;D perspective.
myMetrics = function(z, i) {
  metrics = list(
     zwimean = sum(z*i)/sum(i), # Mean elevation weighted by intensities
     zimean  = mean(z*i),       # Mean products of z by intensity
     zsqmean = sqrt(mean(z^2))) # Quadratic mean

   return(metrics)
}

# example with a stars template
template &lt;- stars::st_as_stars(st_bbox(las), dx = 10, dy = 10)
m &lt;- template_metrics(las, myMetrics(Z, Intensity), template)
#plot(m, col = col)

## End(Not run)
</code></pre>

<hr>
<h2 id='as'>Transform to a list</h2><span id='topic+as'></span><span id='topic+as.list.LASheader'></span>

<h3>Description</h3>

<p>Functions to construct, coerce and check for both kinds of R lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LASheader'
as.list(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_+3A_x">x</code></td>
<td>
<p>A LASheader object</p>
</td></tr>
<tr><td><code id="as_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>

<hr>
<h2 id='asprs'>ASPRS LAS Classification</h2><span id='topic+asprs'></span><span id='topic+LASNONCLASSIFIED'></span><span id='topic+LASUNCLASSIFIED'></span><span id='topic+LASGROUND'></span><span id='topic+LASLOWVEGETATION'></span><span id='topic+LASMEDIUMVEGETATION'></span><span id='topic+LASHIGHVEGETATION'></span><span id='topic+LASBUILDING'></span><span id='topic+LASLOWPOINT'></span><span id='topic+LASKEYPOINT'></span><span id='topic+LASWATER'></span><span id='topic+LASRAIL'></span><span id='topic+LASROADSURFACE'></span><span id='topic+LASWIREGUARD'></span><span id='topic+LASWIRECONDUCTOR'></span><span id='topic+LASTRANSMISSIONTOWER'></span><span id='topic+LASBRIGDE'></span><span id='topic+LASNOISE'></span>

<h3>Description</h3>

<p>A set of global variables corresponding to the point classification defined by the ASPRS for the
LAS format. Instead of remembering the classification table of the specification it is possible
to use one of these global variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LASNONCLASSIFIED

LASUNCLASSIFIED

LASGROUND

LASLOWVEGETATION

LASMEDIUMVEGETATION

LASHIGHVEGETATION

LASBUILDING

LASLOWPOINT

LASKEYPOINT

LASWATER

LASRAIL

LASROADSURFACE

LASWIREGUARD

LASWIRECONDUCTOR

LASTRANSMISSIONTOWER

LASBRIGDE

LASNOISE
</code></pre>


<h3>Format</h3>

<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>
<p>An object of class <code>integer</code> of length 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las = readLAS(LASfile)
las2 = filter_poi(las, Classification %in% c(LASGROUND, LASWATER))

print(LASGROUND)
</code></pre>

<hr>
<h2 id='catalog_apply'>LAScatalog processing engine</h2><span id='topic+catalog_apply'></span><span id='topic+catalog_sapply'></span><span id='topic+catalog_map'></span>

<h3>Description</h3>

<p>This function gives users access to the <a href="#topic+LAScatalog-class">LAScatalog</a> processing engine.
It allows the application of a user-defined routine over a collection of LAS/LAZ files. The
LAScatalog processing engine is explained in the <a href="#topic+LAScatalog-class">LAScatalog class</a><br /><br />
<code>catalog_apply()</code> is the core of the lidR package. It drives every single function that can process a
<code>LAScatalog</code>. It is flexible and powerful but also complex. <code>catalog_map()</code> is a simplified version
of <code>catalog_apply()</code> that suits for 90% of use cases.<br /><br />
<code>catalog_sapply()</code> is a previous attempt to provide simplified version of <code>catalog_apply()</code>. Use
<code>catalog_map()</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalog_apply(ctg, FUN, ..., .options = NULL)

catalog_sapply(ctg, FUN, ..., .options = NULL)

catalog_map(ctg, FUN, ..., .options = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catalog_apply_+3A_ctg">ctg</code></td>
<td>
<p>A <a href="#topic+LAScatalog-class">LAScatalog</a> object.</p>
</td></tr>
<tr><td><code id="catalog_apply_+3A_fun">FUN</code></td>
<td>
<p>A user-defined function that respects a given template (see section function template)</p>
</td></tr>
<tr><td><code id="catalog_apply_+3A_...">...</code></td>
<td>
<p>Optional arguments to FUN.</p>
</td></tr>
<tr><td><code id="catalog_apply_+3A_.options">.options</code></td>
<td>
<p>See dedicated section and examples.</p>
</td></tr>
</table>


<h3>Edge artifacts</h3>

<p>It is important to take precautions to avoid 'edge artifacts' when processing wall-to-wall
tiles. If the points from neighbouring tiles are not included during certain processes,
this could create 'edge artifacts' at the tile boundaries. For example, empty or incomplete
pixels in a rasterization process, or dummy elevations in a ground interpolation. The LAScatalog
processing engine provides internal tools to load buffered data 'on-the-fly'. <code>catalog_map()</code> takes
care of removing automatically the results computed in the buffered area to avoid unexpected output
with duplicated entries or conflict between values computed twice. It does that in predefined way
that may not suit all cases. <code>catalog_apply()</code> does not remove the buffer and leave users free
to handle this in a custom way. This is why <code>catalog_apply()</code> is more complex but gives more freedom
to build new applications.
</p>


<h3>Buffered data</h3>

<p>The LAS objects loaded in theses functions have a special attribute called 'buffer' that indicates,
for each point, if it comes from a buffered area or not. Points from non-buffered areas have a
'buffer' value of 0, while points from buffered areas have a 'buffer' value of 1, 2, 3 or 4, where
1 is the bottom buffer and 2, 3 and 4 are the left, top and right buffers, respectively. This allows
for filtering of buffer points if required.
</p>


<h3>Function template</h3>

<p>The parameter <code>FUN</code> of <code>catalog_apply</code> expects a function with a first argument that will be
supplied automatically by the <code>LAScatalog</code> processing engine. This first argument is a <code>LAScluster</code>.
A <code>LAScluster</code> is an internal undocumented class but the user needs to know only three things about
this class:
</p>

<ul>
<li><p> It represents a chunk of the file collection
</p>
</li>
<li><p> The function <a href="#topic+readLAS">readLAS</a> can be used with a <code>LAScluster</code>
</p>
</li>
<li><p> The function <a href="raster.html#topic+extent">extent</a> or <a href="sp.html#topic+bbox">bbox</a> or <a href="sf.html#topic+st_bbox">st_bbox</a>
can be used with a <code>LAScluster</code> and they return the bounding box of the chunk without the buffer.
It must be used to clip the output and remove the buffered region (see examples).
</p>
</li></ul>

<p>A user-defined function must be templated like this:
</p>
<div class="sourceCode"><pre>myfun &lt;- function(chunk, ...) {
   # Load the chunk + buffer
   las &lt;- readLAS(chunk)
   if (is.empty(las)) return(NULL)

   # do something
   output &lt;- do_something(las, ...)

   # remove the buffer of the output
   bbox &lt;- bbox(chunk)
   output &lt;- remove_buffer(output, bbox)
   return(output)
}
</pre></div>
<p>The line <code>if (is.empty(las)) return(NULL)</code> is important because some clusters (chunks) may contain
0 points (we can't know this before reading the file). In this case an empty point cloud with 0 points
is returned by <code>readLAS()</code> and this may fail in subsequent code. Thus, exiting early from the user-defined
function by returning <code>NULL</code> indicates to the internal engine that the chunk was empty.
</p>
<p><code>catalog_map</code> is much simpler (but less versatile). It automatically takes care of reading the chunk
and checks if the point cloud is empty. It also automatically crop the buffer. The way it crops the
buffer suits for most cases but for some special cases it may be advised to handle this in a more
specific way i.e. using <code>catalog_apply()</code>. For <code>catalog_map()</code> the first argument is a <code>LAS</code> and the
template is:
</p>
<div class="sourceCode"><pre>myfun &lt;- function(las, ...) {
   # do something
   output &lt;- do_something(las, ...)
   return(output)
}
</pre></div>


<h3>.options</h3>

<p>Users may have noticed that some lidR functions throw an error when the processing options are
inappropriate. For example, some functions need a buffer and thus <code>buffer = 0</code> is forbidden.
Users can add the same constraints to protect against inappropriate options. The <code>.options</code>
argument is a <code>list</code> that allows users to tune the behaviour of the processing engine.
</p>

<ul>
<li> <p><code>drop_null = FALSE</code>: not intended to be used by regular users. The engine does not remove
NULL outputs
</p>
</li>
<li> <p><code>need_buffer = TRUE</code>: the function complains if the buffer is 0.
</p>
</li>
<li> <p><code>need_output_file = TRUE</code> the function complains if no output file template is provided.
</p>
</li>
<li> <p><code>raster_alignment = ...</code> the function checks the alignment of the chunks. This option is
important if the output is a raster. See below for more details.
</p>
</li>
<li> <p><code>automerge = TRUE</code> by default the engine returns a <code>list</code> with one item per chunk. If
<code>automerge = TRUE</code>, it tries to merge the outputs into a single object: a <code style="white-space: pre;">&#8288;Raster*&#8288;</code>, a
<code style="white-space: pre;">&#8288;Spatial*&#8288;</code>, a <code style="white-space: pre;">&#8288;LAS*&#8288;</code>, an <code>sf</code>, a <code> stars</code> similarly to other functions of the package. This is a
fail-safe option so in the worst case, if the merging fails, the <code>list</code> is returned. This is
activated by <code>catalog_map</code> making it simpler.
</p>
</li>
<li> <p><code>autoread = TRUE</code>. Introduced in v3.0.0 this option enables to get rid of the first steps of the
function i.e <code>readLAS()</code> and <code style="white-space: pre;">&#8288;if (is.empty())&#8288;</code>. In this case the function must take two
objects as input, first a <code>LAS</code> object and second a <code>bbox</code> from <code>sf</code>. This is
activated by <code>catalog_map</code> making it simpler.
</p>
</li>
<li> <p><code>autocrop = TRUE</code>. Introduced in v4.0.0 this option enables to get rid of the buffer crop steps
of the function i.e <code>something &lt;- remove_buffer(something, bbox)</code>. In this case the function must
take one <code>LAS</code> object as input. This is activated by <code>catalog_map</code> making it simpler.
</p>
</li></ul>

<p>When the function <code>FUN</code> returns a raster it is important to ensure that the chunks are aligned
with the raster to avoid edge artifacts. Indeed, if the edge of a chunk does not correspond to the edge
of the pixels, the output will not be strictly continuous and will have edge artifacts (that might
not be visible). Users can check this with the options <code>raster_alignment</code>, that can take the
resolution of the raster as input, as well as the starting point if needed. The following are accepted:
</p>
<div class="sourceCode"><pre># check if chunks are aligned with a raster of resolution 20
raster_alignment = 20
raster_alignment = list(res = 20)

# check if chunks are aligned with a raster of resolution 20
# that starts at (0,10)
raster_alignment = list(res = 20, start = c(0,10))
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'># More examples might be avaible in the official lidR vignettes or
# on the github book &lt;https://jean-romain.github.io/lidRbook/&gt;

## =========================================================================
## Example 1: detect all the tree tops over an entire catalog
## (this is basically a reproduction of the existing function 'locate_trees')
## =========================================================================

# 1. Build the user-defined function that analyzes each chunk of the catalog.
# The function's first argument is a LAScluster object. The other arguments can be freely
# chosen by the users.
my_tree_detection_method &lt;- function(chunk, ws)
{
  # The chunk argument is a LAScluster object. The users do not need to know how it works.
  # readLAS will load the region of interest (chunk) with a buffer around it, taking advantage of
  # point cloud indexation if possible. The filter and select options are propagated automatically
  las &lt;- readLAS(chunk)
  if (is.empty(las)) return(NULL)

  # Find the tree tops using a user-developed method
  # (here simply a LMF for the example).
  ttops &lt;- locate_trees(las, lmf(ws))

  # ttops is an sf object that contains the tree tops in our region of interest
  # plus the trees tops in the buffered area. We need to remove the buffer otherwise we will get
  # some trees more than once.
  bbox  &lt;- st_bbox(chunk)
  ttops &lt;- sf::st_crop(ttops, bbox)
  return(ttops)
}

# 2. Build a collection of file
# (here, a single file LAScatalog for the purposes of this simple example).
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
ctg &lt;- readLAScatalog(LASfile)
plot(ctg)

# 3. Set some processing options.
# For this small single file example, the chunk size is 100 m + 10 m of buffer
opt_chunk_buffer(ctg) &lt;- 10
opt_chunk_size(ctg)   &lt;- 100            # Small because this is a dummy example.
opt_chunk_alignment(ctg) &lt;- c(-50, -35) # Align such as it creates 2 chunks only.
opt_select(ctg)       &lt;- "xyz"          # Read only the coordinates.
opt_filter(ctg)       &lt;- "-keep_first"  # Read only first returns.

# 4. Apply a user-defined function to take advantage of the internal engine
opt    &lt;- list(need_buffer = TRUE,   # catalog_apply will throw an error if buffer = 0
               automerge   = TRUE)   # catalog_apply will merge the outputs into a single object
output &lt;- catalog_apply(ctg, my_tree_detection_method, ws = 5, .options = opt)

plot(output)


## =========================================================================
## Example 1: simplified. There is nothing that requires special data
## manipulation in the previous example. Everything can be handled automatically
##=========================================================================

# 1. Build the user-defined function that analyzes a point cloud.
my_tree_detection_method &lt;- function(las, ws)
{
  # Find the tree tops using a user-developed method
  # (here simply a LMF for the example).
  ttops &lt;- locate_trees(las, lmf(ws))
  return(ttops)
}

# 2. Build a project
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
ctg &lt;- readLAScatalog(LASfile)
plot(ctg)

# 3. Set some processing options.
# For this dummy example, the chunk size is 100 m and the buffer is 10 m
opt_chunk_buffer(ctg) &lt;- 10
opt_chunk_size(ctg)   &lt;- 100            # small because this is a dummy example.
opt_chunk_alignment(ctg) &lt;- c(-50, -35) # Align such as it creates 2 chunks only.
opt_select(ctg)       &lt;- "xyz"          # Read only the coordinates.
opt_filter(ctg)       &lt;- "-keep_first"  # Read only first returns.

# 4. Apply a user-defined function to take advantage of the internal engine
opt    &lt;- list(need_buffer = TRUE)   # catalog_apply will throw an error if buffer = 0
output &lt;- catalog_map(ctg, my_tree_detection_method, ws = 5, .options = opt)

## ===================================================
## Example 2: compute a rumple index on surface points
## ===================================================

rumple_index_surface = function(las, res)
{
  las    &lt;- filter_surfacepoints(las, 1)
  rumple &lt;- pixel_metrics(las, ~rumple_index(X,Y,Z), res)
  return(rumple)
}

LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
ctg &lt;- readLAScatalog(LASfile)

opt_chunk_buffer(ctg) &lt;- 1
opt_chunk_size(ctg)   &lt;- 140     # small because this is a dummy example.
opt_select(ctg)       &lt;- "xyz"   # read only the coordinates.

opt    &lt;- list(raster_alignment = 20) # catalog_apply will adjust the chunks if required
output &lt;- catalog_map(ctg, rumple_index_surface, res = 20, .options = opt)

plot(output, col = height.colors(25))

</code></pre>

<hr>
<h2 id='catalog_boundaries'>Computes the polygon that encloses the points</h2><span id='topic+catalog_boundaries'></span>

<h3>Description</h3>

<p>Computes the polygon that encloses the points. It reads all the files one by one and computes a
concave hull using the <a href="#topic+st_concave_hull">st_concave_hull</a> function. When all the hulls are computed it updates the
LAScatalog to set the true polygons instead of the bounding boxes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalog_boundaries(ctg, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catalog_boundaries_+3A_ctg">ctg</code></td>
<td>
<p>A LAScatalog</p>
</td></tr>
<tr><td><code id="catalog_boundaries_+3A_...">...</code></td>
<td>
<p>propagated to <a href="#topic+st_concave_hull">st_concave_hull</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A LAScatalog with true boundaries
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The options 'select', 'output files', 'chunk size', 'chunk buffer', 'chunk alignment' are not
supported and not respected in  'catalog_boundaries*' because the function must always process by
file, without buffer and knows which attributes to load.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
ctg &lt;- readLAScatalog(LASfile, filter = "-drop_z_below 0.5")
ctg2 &lt;- catalog_boundaries(ctg, concavity = 1, length_threshold = 15)
plot(ctg)
plot(ctg2, add = TRUE)
</code></pre>

<hr>
<h2 id='catalog_intersect'>Subset a LAScatalog</h2><span id='topic+catalog_intersect'></span><span id='topic+catalog_subset'></span><span id='topic+catalog_select'></span>

<h3>Description</h3>

<p>Subset a LAScatalog interactively using the mouse. Subset a LAScatalog with a spatial object to
keep only the tiles of interest. It can be used to select tiles of interest that encompass spatial
objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalog_intersect(
  ctg,
  y,
  ...,
  subset = c("subset", "flag_unprocessed", "flag_processed")
)

catalog_select(
  ctg,
  mapview = TRUE,
  subset = c("subset", "flag_unprocessed", "flag_processed")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catalog_intersect_+3A_ctg">ctg</code></td>
<td>
<p>A <a href="#topic+LAScatalog-class">LAScatalog</a></p>
</td></tr>
<tr><td><code id="catalog_intersect_+3A_y">y</code></td>
<td>
<p>'bbox', 'sf', 'sfc', 'Extent', 'Raster*', 'Spatial*' objects</p>
</td></tr>
<tr><td><code id="catalog_intersect_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="catalog_intersect_+3A_subset">subset</code></td>
<td>
<p>character. By default it subsets the collection It is also possible to flag
the files to maintain the collection as a whole but process only a subset of its content.
<code>flag_unprocessed</code> flags the files that will not be processed.
<code>flag_processed</code> flags the files that will be processed.</p>
</td></tr>
<tr><td><code id="catalog_intersect_+3A_mapview">mapview</code></td>
<td>
<p>logical. If <code>FALSE</code>, use R base plot instead of mapview (no pan, no zoom, see
also <a href="#topic+plot">plot</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A LAScatalog object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ctg = readLAScatalog("&lt;Path to a folder containing a set of .las files&gt;")
new_ctg = catalog_select(ctg)

## End(Not run)
</code></pre>

<hr>
<h2 id='catalog_retile'>Retile a LAScatalog</h2><span id='topic+catalog_retile'></span>

<h3>Description</h3>

<p>Splits or merges files to reshape the original files collection (.las or .laz) into smaller or larger
files. It also enables the addition or removal of a buffer around the tiles. Internally, the
function reads and writes the chunks defined by the internal processing options of a
<a href="#topic+LAScatalog-class">LAScatalog</a>. Thus, the function is flexible and enables the user to retile
the dataset, retile while adding or removing a buffer (negative buffers are allowed), or optionally
to compress the data by retiling without changing the pattern but by changing
the format (las/laz). <strong>This function is does not load the point cloud into R memory</strong> It streams
from input file(s) to output file(s) and can be applied to large point-cloud with low memory
computer.<br /><br />
Note that this function is not actually very useful because <code>lidR</code> manages everything
(clipping, processing, buffering, ...) internally using the proper options. Thus, retiling may be
useful for working in other software, for example, but not in <code>lidR</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catalog_retile(ctg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catalog_retile_+3A_ctg">ctg</code></td>
<td>
<p>A <a href="#topic+LAScatalog-class">LAScatalog</a> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new <code>LAScatalog</code> object
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected because it always preserves the file
format and all the attributes. <code>select = "*"</code> is imposed internally.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
ctg = readLAScatalog(LASfile)
plot(ctg)

# Create a new set of 200 x 200 m.las files with first returns only
opt_chunk_buffer(ctg) &lt;- 0
opt_chunk_size(ctg) &lt;- 200
opt_filter(ctg) &lt;- "-keep_first"
opt_chunk_alignment(ctg) &lt;- c(275, 90)
opt_output_files(ctg) &lt;- paste0(tempdir(), "/retile_{XLEFT}_{YBOTTOM}")

# preview the chunk pattern
plot(ctg, chunk = TRUE)

newctg = catalog_retile(ctg)

plot(newctg)

# Create a new set of 200 x 200 m.las files
# but extended with a 50 m buffer in the folder

opt_chunk_buffer(ctg) &lt;- 25
opt_chunk_size(ctg) &lt;- 200
opt_filter(ctg) &lt;- ""
opt_chunk_alignment(ctg) &lt;- c(275, 90)
opt_output_files(ctg) &lt;- paste0(tempdir(), "/{XLEFT}_{YBOTTOM}_buffered")
newctg = catalog_retile(ctg)

plot(newctg)


## Not run: 
# Create a new set of compressed .laz file equivalent to the original, keeping only
# first returns above 2 m

opt_chunk_buffer(ctg) &lt;- 0
opt_chunk_size(ctg) &lt;- 0
opt_laz_compression(ctg) &lt;- TRUE
opt_filter(ctg) &lt;- "-keep_first -drop_z_below 2"
opt_output_files(ctg) &lt;- paste0(tempdir(), "/{ORIGINALFILENAME}_first_2m")
newctg = catalog_retile(ctg)

## End(Not run)
</code></pre>

<hr>
<h2 id='classify'>Classify points</h2><span id='topic+classify'></span><span id='topic+classify_ground'></span><span id='topic+classify_noise'></span><span id='topic+classify_poi'></span>

<h3>Description</h3>

<p>Classify points that meet some criterion and/or that belong in a region of interest. The
functions updates the attribute <code>Classification</code> of the LAS object according to
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">las specifications</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classify_ground(las, algorithm, last_returns = TRUE)

classify_noise(las, algorithm)

classify_poi(
  las,
  class,
  poi = NULL,
  roi = NULL,
  inverse_roi = FALSE,
  by_reference = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classify_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="classify_+3A_algorithm">algorithm</code></td>
<td>
<p>An algorithm for classification. lidR has has: <a href="#topic+sor">sor</a>, <a href="#topic+ivf">ivf</a> for noise
classification, and <a href="#topic+pmf">pmf</a>, <a href="#topic+csf">csf</a>, <a href="#topic+mcc">mcc</a> for ground classification (see respective
documentation).</p>
</td></tr>
<tr><td><code id="classify_+3A_last_returns">last_returns</code></td>
<td>
<p>logical. The algorithm will use only the last returns (including the first returns
in cases of a single return) to run the algorithm. If FALSE all the returns are used. If the attributes
<code>'ReturnNumber'</code> or <code>'NumberOfReturns'</code> are absent, <code>'last_returns'</code> is turned
to <code>FALSE</code> automatically.</p>
</td></tr>
<tr><td><code id="classify_+3A_class">class</code></td>
<td>
<p>The ASPRS class to attribute to the points that meet the criterion.</p>
</td></tr>
<tr><td><code id="classify_+3A_poi">poi</code></td>
<td>
<p>a formula of logical predicates. The points that are <code>TRUE</code> will be classified <code>class</code>.</p>
</td></tr>
<tr><td><code id="classify_+3A_roi">roi</code></td>
<td>
<p>A <code style="white-space: pre;">&#8288;SpatialPolygons*&#8288;</code>, from <code>sp</code> or a <code>sf/sfc_POLYGON</code> from <code>sf</code>.
The points that are in the region of interest delimited by the polygon(s) are classified
<code>class</code>.</p>
</td></tr>
<tr><td><code id="classify_+3A_inverse_roi">inverse_roi</code></td>
<td>
<p>bool. Inverses the <code>roi</code>. The points that are outside the polygon(s)
are classified <code>class</code>.</p>
</td></tr>
<tr><td><code id="classify_+3A_by_reference">by_reference</code></td>
<td>
<p>bool. Updates the classification in place (LAS only).</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>classify_noise</dt><dd><p>Classify points as 'noise' (outliers) with several possible algorithms.
lidR has: <a href="#topic+sor">sor</a>, <a href="#topic+ivf">ivf</a>. The points classified as 'noise' are assigned a value of 18.</p>
</dd>
<dt>classify_ground</dt><dd><p>Classify points as 'ground' with several possible algorithms.
lidR has <a href="#topic+pmf">pmf</a>, <a href="#topic+csf">csf</a> and <a href="#topic+mcc">mcc</a>. The points classified as 'ground' are assigned a
value of 2 </p>
</dd>
<dt>classify_poi</dt><dd><p>Classify points that meet some logical criterion and/or that belong in a
region of interest with class of choice.</p>
</dd>
</dl>



<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected because it always preserves the file format
and all the attributes. <code>select = "*"</code> is imposed internally.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ===============
# Classify ground
# ===============

LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzrn", filter = "-inside 273450 5274350 273550 5274450")

# (Parameters chosen mainly for speed)
mycsf &lt;- csf(TRUE, 1, 1, time_step = 1)
las &lt;- classify_ground(las, mycsf)
#plot(las, color = "Classification")

# ===============
# Classify noise
# ===============

LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-inside 273450 5274350 273550 5274450")

# Add 20 artificial outliers
set.seed(314)
id = round(runif(20, 0, npoints(las)))
set.seed(42)
err = runif(20, -50, 50)
las$Z[id] = las$Z[id] + err

# Using IVF
las &lt;- classify_noise(las, ivf(5,2))
#plot(las, color = "Classification")

# Remove outliers using filter_poi()
las_denoise &lt;- filter_poi(las, Classification != LASNOISE)

# ===============
# Classify POI
# ===============

LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
shp &lt;- system.file("extdata", "lake_polygons_UTM17.shp", package = "lidR")

las  &lt;- readLAS(LASfile, filter = "-keep_random_fraction 0.1")
lake &lt;- sf::st_read(shp, quiet = TRUE)

# Classifies the points that are NOT in the lake and that are NOT ground points as class 5
poi &lt;- ~Classification != LASGROUND
las &lt;- classify_poi(las, LASHIGHVEGETATION, poi = poi, roi = lake, inverse = TRUE)

# Classifies the points that are in the lake as class 9
las &lt;- classify_poi(las, LASWATER, roi = lake, inverse = FALSE)

#plot(las, color = "Classification")
</code></pre>

<hr>
<h2 id='clip'>Clip points in regions of interest</h2><span id='topic+clip'></span><span id='topic+clip_roi'></span><span id='topic+clip_rectangle'></span><span id='topic+clip_polygon'></span><span id='topic+clip_circle'></span><span id='topic+clip_transect'></span>

<h3>Description</h3>

<p>Clip points within a given region of interest (ROI) from a point cloud (LAS object) or a collection
of files (LAScatalog object).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clip_roi(las, geometry, ...)

clip_rectangle(las, xleft, ybottom, xright, ytop, ...)

clip_polygon(las, xpoly, ypoly, ...)

clip_circle(las, xcenter, ycenter, radius, ...)

clip_transect(las, p1, p2, width, xz = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clip_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="clip_+3A_geometry">geometry</code></td>
<td>
<p>a geometric object. spatial points, spatial polygons in sp or sf/sfc format, Extent,
bbox, 2x2 matrix</p>
</td></tr>
<tr><td><code id="clip_+3A_...">...</code></td>
<td>
<p>in <code>clip_roi</code>: optional supplementary options (see supported geometries). Unused in
other functions</p>
</td></tr>
<tr><td><code id="clip_+3A_xleft">xleft</code>, <code id="clip_+3A_ybottom">ybottom</code>, <code id="clip_+3A_xright">xright</code>, <code id="clip_+3A_ytop">ytop</code></td>
<td>
<p>numeric. coordinates of one or several rectangles.</p>
</td></tr>
<tr><td><code id="clip_+3A_xpoly">xpoly</code>, <code id="clip_+3A_ypoly">ypoly</code></td>
<td>
<p>numeric. x coordinates of a polygon.</p>
</td></tr>
<tr><td><code id="clip_+3A_xcenter">xcenter</code>, <code id="clip_+3A_ycenter">ycenter</code></td>
<td>
<p>numeric. x coordinates of on or several disc centres.</p>
</td></tr>
<tr><td><code id="clip_+3A_radius">radius</code></td>
<td>
<p>numeric. disc radius or radii.</p>
</td></tr>
<tr><td><code id="clip_+3A_p1">p1</code>, <code id="clip_+3A_p2">p2</code></td>
<td>
<p>numeric vectors of length 2 that gives the coordinates of two points that define a
transect</p>
</td></tr>
<tr><td><code id="clip_+3A_width">width</code></td>
<td>
<p>numeric. width of the transect.</p>
</td></tr>
<tr><td><code id="clip_+3A_xz">xz</code></td>
<td>
<p>bool. If <code>TRUE</code> the point cloud is reoriented to fit on XZ coordinates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the input is a LAS object: an object of class LAS, or a <code>list</code> of LAS objects if the
query implies several regions of interest.<br /><br />
If the input is a LAScatalog object: an object of class LAS, or a <code>list</code> of LAS
objects if the query implies several regions of interest, or a LAScatalog if the
queries are immediately written into files without loading anything in R.
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option <code style="white-space: pre;">&#8288;chunk size&#8288;</code>, <code>buffer</code>, <code style="white-space: pre;">&#8288;chunk alignment&#8288;</code> and <code>select</code> are not supported by <code style="white-space: pre;">&#8288;clip_*&#8288;</code>
because they are meaningless in this context.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")

# Load the file and clip the region of interest
las = readLAS(LASfile, select = "xyz", filter = "-keep_first")
subset1 = clip_rectangle(las, 684850, 5017850, 684900, 5017900)

# Do not load the file(s), extract only the region of interest
# from a bigger dataset
ctg = readLAScatalog(LASfile, progress = FALSE, filter = "-keep_first")
subset2 = clip_rectangle(ctg, 684850, 5017850, 684900, 5017900)

# Extract all the polygons from a shapefile
f &lt;- system.file("extdata", "lake_polygons_UTM17.shp", package = "lidR")
lakes &lt;- sf::st_read(f, quiet = TRUE)
subset3 &lt;- clip_roi(las, lakes)

# Extract the polygons for a catalog, write them in files named
# after the lake names, do not load anything in R
opt_output_files(ctg) &lt;- paste0(tempfile(), "_{LAKENAME_1}")
new_ctg = clip_roi(ctg, lakes)
plot(new_ctg)

# Extract a transect
p1 &lt;- c(684800, y = 5017800)
p2 &lt;- c(684900, y = 5017900)
tr1 &lt;- clip_transect(las, p1, p2, width = 4)

## Not run: 
plot(subset1)
plot(subset2)
plot(subset3)

plot(tr1, axis = TRUE, clear_artifacts = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='decimate_points'>Decimate a LAS object</h2><span id='topic+decimate_points'></span>

<h3>Description</h3>

<p>Reduce the number of points using several possible algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decimate_points(las, algorithm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decimate_points_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="decimate_points_+3A_algorithm">algorithm</code></td>
<td>
<p>function. An algorithm of point decimation. <code>lidR</code> have: <a href="#topic+random">random</a>,
<a href="#topic+homogenize">homogenize</a>, <a href="#topic+highest">highest</a>, <a href="#topic+lowest">lowest</a> and <a href="#topic+random_per_voxel">random_per_voxel</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the input is a <code>LAS</code> object, returns a <code>LAS</code> object. If the input is a
<code>LAScatalog</code>, returns a <code>LAScatalog</code>.
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option 'select' is not supported and not respected because it always preserves the file format
and all the attributes. 'select = &quot;*&quot;' is imposed internally.<br />
The options 'chunk buffer' is not supported and not respected because it is not needed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyz")

# Select points randomly to reach an overall density of 1
thinned1 &lt;- decimate_points(las, random(1))
#plot(rasterize_density(las))
#plot(rasterize_density(thinned1))

# Select points randomly to reach an homogeneous density of 1
thinned2 &lt;- decimate_points(las, homogenize(1,5))
#plot(rasterize_density(thinned2))

# Select the highest point within each pixel of an overlayed grid
thinned3 = decimate_points(las, highest(5))
#plot(thinned3)
</code></pre>

<hr>
<h2 id='deprecated'>Deprecated functions in lidR</h2><span id='topic+deprecated'></span><span id='topic+lascheck'></span><span id='topic+lasclip'></span><span id='topic+lasclipRectangle'></span><span id='topic+lasclipPolygon'></span><span id='topic+lasclipCircle'></span><span id='topic+lasdetectshape'></span><span id='topic+lasfilter'></span><span id='topic+lasfilterfirst'></span><span id='topic+lasfilterfirstlast'></span><span id='topic+lasfilterfirstofmany'></span><span id='topic+lasfilterground'></span><span id='topic+lasfilterlast'></span><span id='topic+lasfilternth'></span><span id='topic+lasfiltersingle'></span><span id='topic+lasfilterdecimate'></span><span id='topic+lasfilterduplicates'></span><span id='topic+lasfiltersurfacepoints'></span><span id='topic+lasground'></span><span id='topic+laspulse'></span><span id='topic+lasflightline'></span><span id='topic+lasscanline'></span><span id='topic+lasmergespatial'></span><span id='topic+lasnormalize'></span><span id='topic+lasunnormalize'></span><span id='topic+lasrangecorrection'></span><span id='topic+lasrescale'></span><span id='topic+lasreoffset'></span><span id='topic+lassmooth'></span><span id='topic+lasunsmooth'></span><span id='topic+lassnags'></span><span id='topic+lastrees'></span><span id='topic+lasadddata'></span><span id='topic+lasaddextrabytes'></span><span id='topic+lasaddextrabytes_manual'></span><span id='topic+lasremoveextrabytes'></span><span id='topic+lasvoxelize'></span><span id='topic+sensor_tracking'></span><span id='topic+tree_detection'></span><span id='topic+tree_hulls'></span><span id='topic+hexbin_metrics'></span><span id='topic+filter_surfacepoints'></span><span id='topic+filter_surfacepoints.LAS'></span><span id='topic+filter_surfacepoints.LAScatalog'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of lidR but are deprecated. They
will progressively print a message, throw a warning and eventually be removed. The links below point
to the documentation of the new names. In version 4 they now throw an error. In version 4.1 they
ill be removed definitively.<br /><br />
<a href="#topic+add_attribute">lasadd</a> <a href="#topic+las_check">lascheck</a> <a href="#topic+clip">lasclip</a>
<a href="#topic+segment_shapes">lasdetectshape</a> <a href="#topic+filter_poi">lasfilter</a>
<a href="#topic+filter_surfacepoints">lasfiltersurfacepoints</a> <a href="#topic+retrieve_flightlines">lasflightline</a>
<a href="#topic+classify_ground">lasground</a> <a href="#topic+merge_spatial">lasmergespatial</a>
<a href="#topic+normalize_height">lasnormalize</a> <a href="#topic+retrieve_pulses">laspulse</a>
<a href="#topic+normalize_intensity">lasrangecorrection</a> <a href="#topic+retrieve_flightlines">lasflightline</a>
<a href="#topic+las_reoffset">lasreoffset</a> <a href="#topic+las_rescale">lasrescale</a>
<a href="#topic+retrieve_scanlines">lasscanlines</a> <a href="#topic+smooth_height">lassmooth</a>
<a href="#topic+segment_snags">lassnags</a>
<a href="#topic+segment_trees">lastrees</a> <a href="#topic+voxelize_points">lasvoxelize</a>
<a href="#topic+track_sensor">sensor_tracking</a> <a href="#topic+locate_trees">tree_detection</a>
<a href="#topic+crown_metrics">tree_hull</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lascheck(las)

lasclip(las, geometry, ...)

lasclipRectangle(las, xleft, ybottom, xright, ytop, ...)

lasclipPolygon(las, xpoly, ypoly, ...)

lasclipCircle(las, xcenter, ycenter, radius, ...)

lasdetectshape(las, algorithm, attribute = "Shape", filter = NULL)

lasfilter(las, ...)

lasfilterfirst(las)

lasfilterfirstlast(las)

lasfilterfirstofmany(las)

lasfilterground(las)

lasfilterlast(las)

lasfilternth(las, n)

lasfiltersingle(las)

lasfilterdecimate(las, algorithm)

lasfilterduplicates(las)

lasfiltersurfacepoints(las, res)

lasground(las, algorithm, last_returns = TRUE)

laspulse(las)

lasflightline(las, dt = 30)

lasscanline(las)

lasmergespatial(las, source, attribute = NULL)

lasnormalize(
  las,
  algorithm,
  na.rm = FALSE,
  use_class = c(2L, 9L),
  ...,
  add_lasattribute = FALSE
)

lasunnormalize(las)

lasrangecorrection(
  las,
  sensor,
  Rs,
  f = 2.3,
  gpstime = "gpstime",
  elevation = "Z"
)

lasrescale(las, xscale, yscale, zscale)

lasreoffset(las, xoffset, yoffset, zoffset)

lassmooth(
  las,
  size,
  method = c("average", "gaussian"),
  shape = c("circle", "square"),
  sigma = size/6
)

lasunsmooth(las)

lassnags(las, algorithm, attribute = "snagCls")

lastrees(las, algorithm, attribute = "treeID", uniqueness = "incremental")

lasadddata(las, x, name)

lasaddextrabytes(las, x, name, desc)

lasaddextrabytes_manual(
  las,
  x,
  name,
  desc,
  type,
  offset = NULL,
  scale = NULL,
  NA_value = NULL
)

lasremoveextrabytes(las, name)

lasvoxelize(las, res)

sensor_tracking(
  las,
  interval = 0.5,
  pmin = 50,
  extra_check = TRUE,
  thin_pulse_with_time = 0.001
)

tree_detection(las, algorithm)

tree_hulls(
  las,
  type = c("convex", "concave", "bbox"),
  concavity = 3,
  length_threshold = 0,
  func = NULL,
  attribute = "treeID"
)

hexbin_metrics(...)

filter_surfacepoints(las, res)

## S3 method for class 'LAS'
filter_surfacepoints(las, res)

## S3 method for class 'LAScatalog'
filter_surfacepoints(las, res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deprecated_+3A_las">las</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_geometry">geometry</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_...">...</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_xleft">xleft</code>, <code id="deprecated_+3A_ybottom">ybottom</code>, <code id="deprecated_+3A_xright">xright</code>, <code id="deprecated_+3A_ytop">ytop</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_xpoly">xpoly</code>, <code id="deprecated_+3A_ypoly">ypoly</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_xcenter">xcenter</code>, <code id="deprecated_+3A_ycenter">ycenter</code>, <code id="deprecated_+3A_radius">radius</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_algorithm">algorithm</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_attribute">attribute</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_filter">filter</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_n">n</code>, <code id="deprecated_+3A_res">res</code>, <code id="deprecated_+3A_dt">dt</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_last_returns">last_returns</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_source">source</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_na.rm">na.rm</code>, <code id="deprecated_+3A_use_class">use_class</code>, <code id="deprecated_+3A_add_lasattribute">add_lasattribute</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_sensor">sensor</code>, <code id="deprecated_+3A_rs">Rs</code>, <code id="deprecated_+3A_f">f</code>, <code id="deprecated_+3A_gpstime">gpstime</code>, <code id="deprecated_+3A_elevation">elevation</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_xscale">xscale</code>, <code id="deprecated_+3A_yscale">yscale</code>, <code id="deprecated_+3A_zscale">zscale</code>, <code id="deprecated_+3A_xoffset">xoffset</code>, <code id="deprecated_+3A_yoffset">yoffset</code>, <code id="deprecated_+3A_zoffset">zoffset</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_size">size</code>, <code id="deprecated_+3A_method">method</code>, <code id="deprecated_+3A_shape">shape</code>, <code id="deprecated_+3A_sigma">sigma</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_uniqueness">uniqueness</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_x">x</code>, <code id="deprecated_+3A_name">name</code>, <code id="deprecated_+3A_desc">desc</code>, <code id="deprecated_+3A_type">type</code>, <code id="deprecated_+3A_offset">offset</code>, <code id="deprecated_+3A_scale">scale</code>, <code id="deprecated_+3A_na_value">NA_value</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_interval">interval</code>, <code id="deprecated_+3A_pmin">pmin</code>, <code id="deprecated_+3A_extra_check">extra_check</code>, <code id="deprecated_+3A_thin_pulse_with_time">thin_pulse_with_time</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
<tr><td><code id="deprecated_+3A_concavity">concavity</code>, <code id="deprecated_+3A_length_threshold">length_threshold</code>, <code id="deprecated_+3A_func">func</code></td>
<td>
<p>See the new functions that replace the old ones</p>
</td></tr>
</table>

<hr>
<h2 id='dsm_pitfree'>Digital Surface Model Algorithm</h2><span id='topic+dsm_pitfree'></span><span id='topic+pitfree'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_canopy">rasterize_canopy</a>. It implements the pit-free algorithm
developed by Khosravipour et al. (2014), which is based on the computation of a set of classical
triangulations at different heights (see references). The <code>subcircle</code> tweak replaces each
point with 8 points around the original one. This allows for virtual 'emulation' of the fact that
a lidar point is not a point as such, but more realistically a disc. This tweak densifies the point
cloud and the resulting canopy model is smoother and contains fewer 'pits' and empty pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitfree(
  thresholds = c(0, 2, 5, 10, 15),
  max_edge = c(0, 1),
  subcircle = 0,
  highest = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm_pitfree_+3A_thresholds">thresholds</code></td>
<td>
<p>numeric. Set of height thresholds according to the Khosravipour et al. (2014) algorithm
description (see references)</p>
</td></tr>
<tr><td><code id="dsm_pitfree_+3A_max_edge">max_edge</code></td>
<td>
<p>numeric. Maximum edge length of a triangle in the Delaunay triangulation.
If a triangle has an edge length greater than this value it will be removed. The first number is the value
for the classical triangulation (threshold = 0, see also <a href="#topic+dsmtin">dsmtin</a>), the second number
is the value for the pit-free algorithm (for thresholds &gt; 0). If <code>max_edge = 0</code> no trimming
is done (see examples).</p>
</td></tr>
<tr><td><code id="dsm_pitfree_+3A_subcircle">subcircle</code></td>
<td>
<p>numeric. radius of the circles. To obtain fewer empty pixels the algorithm
can replace each return with a circle composed of 8 points (see details).</p>
</td></tr>
<tr><td><code id="dsm_pitfree_+3A_highest">highest</code></td>
<td>
<p>bool. By default it keeps only the highest point per pixel before to triangulate to
decrease computation time. If highest = FALSE all first returns are used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Khosravipour, A., Skidmore, A. K., Isenburg, M., Wang, T., &amp; Hussin, Y. A. (2014).
Generating pit-free canopy height models from airborne lidar. Photogrammetric Engineering &amp;
Remote Sensing, 80(9), 863-872.
</p>


<h3>See Also</h3>

<p>Other digital surface model algorithms: 
<code><a href="#topic+dsm_point2raster">dsm_point2raster</a></code>,
<code><a href="#topic+dsm_tin">dsm_tin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
poi = "-drop_z_below 0 -inside 481280 3812940 481330 3812990"
las &lt;- readLAS(LASfile, filter = poi)
col &lt;- height.colors(50)

# Basic triangulation and rasterization of first returns
chm &lt;- rasterize_canopy(las, res = 0.5, dsmtin())
plot(chm, col = col)

# Khosravipour et al. pitfree algorithm
chm &lt;- rasterize_canopy(las, res = 0.5, pitfree(c(0,2,5,10,15), c(0, 1.5)))
plot(chm, col = col)

## Not run: 
# Potentially complex concave subset of point cloud
x = c(481340, 481340, 481280, 481300, 481280, 481340)
y = c(3812940, 3813000, 3813000, 3812960, 3812940, 3812940)
las2 = clip_polygon(las,x,y)
plot(las2)

# Because the TIN interpolation is done within the convex hull of the point cloud
# dummy pixels are interpolated that are correct according to the interpolation
# method used, but meaningless in our CHM
chm &lt;- rasterize_canopy(las2, res = 0.5, pitfree(max_edge = c(0, 1.5)))
plot(chm, col = col)

chm = rasterize_canopy(las2, res = 0.5, pitfree(max_edge = c(3, 1.5)))
plot(chm, col = col)

## End(Not run)
</code></pre>

<hr>
<h2 id='dsm_point2raster'>Digital Surface Model Algorithm</h2><span id='topic+dsm_point2raster'></span><span id='topic+p2r'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_canopy">rasterize_canopy</a>. It implements an algorithm for digital
surface model computation based on a points-to-raster method: for each pixel of the output raster
the function attributes the height of the highest point found. The <code>subcircle</code> tweak replaces
each point with 8 points around the original one. This allows for virtual 'emulation' of the fact
that a lidar point is not a point as such, but more realistically a disc. This tweak densifies the
point cloud and the resulting canopy model is smoother and contains fewer 'pits' and empty pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p2r(subcircle = 0, na.fill = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm_point2raster_+3A_subcircle">subcircle</code></td>
<td>
<p>numeric. Radius of the circles. To obtain fewer empty pixels the algorithm
can replace each return with a circle composed of 8 points (see details).</p>
</td></tr>
<tr><td><code id="dsm_point2raster_+3A_na.fill">na.fill</code></td>
<td>
<p>function. A function that implements an algorithm to compute spatial interpolation
to fill the empty pixel often left by points-to-raster methods. <code>lidR</code> has <a href="#topic+knnidw">knnidw</a>,
<a href="#topic+tin">tin</a>, and <a href="#topic+kriging">kriging</a> (see also <a href="#topic+rasterize_terrain">rasterize_terrain</a> for more details).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other digital surface model algorithms: 
<code><a href="#topic+dsm_pitfree">dsm_pitfree</a></code>,
<code><a href="#topic+dsm_tin">dsm_tin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile)
col &lt;- height.colors(50)

# Points-to-raster algorithm with a resolution of 1 meter
chm &lt;- rasterize_canopy(las, res = 1, p2r())
plot(chm, col = col)

# Points-to-raster algorithm with a resolution of 0.5 meters replacing each
# point by a 20 cm radius circle of 8 points
chm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.2))
plot(chm, col = col)

## Not run: 
chm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.2, na.fill = tin()))
plot(chm, col = col)

## End(Not run)
</code></pre>

<hr>
<h2 id='dsm_tin'>Digital Surface Model Algorithm</h2><span id='topic+dsm_tin'></span><span id='topic+dsmtin'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_canopy">rasterize_canopy</a>. It implements an algorithm for digital
surface model computation using a Delaunay triangulation of first returns with a linear interpolation
within each triangle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsmtin(max_edge = 0, highest = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsm_tin_+3A_max_edge">max_edge</code></td>
<td>
<p>numeric. Maximum edge length of a triangle in the Delaunay triangulation.
If a triangle has an edge length greater than this value it will be removed to trim dummy interpolation
on non-convex areas. If <code>max_edge = 0</code> no trimming is done (see examples).</p>
</td></tr>
<tr><td><code id="dsm_tin_+3A_highest">highest</code></td>
<td>
<p>bool. By default it keeps only the highest point per pixel before to triangulate to
decrease computation time. If highest = FALSE all first returns are used.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other digital surface model algorithms: 
<code><a href="#topic+dsm_pitfree">dsm_pitfree</a></code>,
<code><a href="#topic+dsm_point2raster">dsm_point2raster</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile)
col &lt;- height.colors(50)

# Basic triangulation and rasterization of first returns
chm &lt;- rasterize_canopy(las, res = 1, dsmtin())
plot(chm, col = col)

## Not run: 
# Potentially complex concave subset of point cloud
x = c(481340, 481340, 481280, 481300, 481280, 481340)
y = c(3812940, 3813000, 3813000, 3812960, 3812940, 3812940)
las2 = clip_polygon(las,x,y)
plot(las2)

# Because the TIN interpolation is done within the convex hull of the point cloud
# dummy pixels are interpolated that are correct according to the interpolation method
# used, but meaningless in our CHM
chm &lt;- rasterize_canopy(las2, res = 0.5, dsmtin())
plot(chm, col = col)

# Use 'max_edge' to trim dummy triangles
chm = rasterize_canopy(las2, res = 0.5, dsmtin(max_edge = 3))
plot(chm, col = col)

## End(Not run)
</code></pre>

<hr>
<h2 id='dtm_idw'>Spatial Interpolation Algorithm</h2><span id='topic+dtm_idw'></span><span id='topic+knnidw'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_terrain">rasterize_terrain</a> or <a href="#topic+normalize_height">normalize_height</a>. It implements an algorithm
for spatial interpolation. Interpolation is done using a k-nearest neighbour (KNN) approach with
an inverse-distance weighting (IDW).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knnidw(k = 10, p = 2, rmax = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtm_idw_+3A_k">k</code></td>
<td>
<p>integer. Number of k-nearest neighbours. Default 10.</p>
</td></tr>
<tr><td><code id="dtm_idw_+3A_p">p</code></td>
<td>
<p>numeric. Power for inverse-distance weighting. Default 2.</p>
</td></tr>
<tr><td><code id="dtm_idw_+3A_rmax">rmax</code></td>
<td>
<p>numeric. Maximum radius where to search for knn. Default 50.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other dtm algorithms: 
<code><a href="#topic+dtm_kriging">dtm_kriging</a></code>,
<code><a href="#topic+dtm_tin">dtm_tin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)

#plot(las)

dtm = rasterize_terrain(las, algorithm = knnidw(k = 6L, p = 2))

#plot(dtm)
#plot_dtm3d(dtm)
</code></pre>

<hr>
<h2 id='dtm_kriging'>Spatial Interpolation Algorithm</h2><span id='topic+dtm_kriging'></span><span id='topic+kriging'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_terrain">rasterize_terrain</a> or <a href="#topic+normalize_height">normalize_height</a>. It
implements an algorithm for spatial interpolation. Spatial interpolation is based on universal
kriging using the <a href="gstat.html#topic+krige">krige</a> function from <code>gstat</code>. This method combines the
KNN approach with the kriging approach. For each point of interest it kriges the terrain using
the k-nearest neighbour ground points. This method is more difficult to manipulate but it is also
the most advanced method for interpolating spatial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging(model = gstat::vgm(0.59, "Sph", 874), k = 10L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtm_kriging_+3A_model">model</code></td>
<td>
<p>A variogram model computed with <a href="gstat.html#topic+vgm">vgm</a>. If NULL it performs an ordinary
or weighted least squares prediction.</p>
</td></tr>
<tr><td><code id="dtm_kriging_+3A_k">k</code></td>
<td>
<p>numeric. Number of k-nearest neighbours. Default 10.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other dtm algorithms: 
<code><a href="#topic+dtm_idw">dtm_idw</a></code>,
<code><a href="#topic+dtm_tin">dtm_tin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)

plot(las)

dtm = rasterize_terrain(las, algorithm = kriging())

plot(dtm)
plot_dtm3d(dtm)

## End(Not run)
</code></pre>

<hr>
<h2 id='dtm_tin'>Spatial Interpolation Algorithm</h2><span id='topic+dtm_tin'></span><span id='topic+tin'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+rasterize_terrain">rasterize_terrain</a> or <a href="#topic+normalize_height">normalize_height</a>. It
implements an algorithm for spatial interpolation. Spatial interpolation is based on a Delaunay
triangulation, which performs a linear interpolation within each triangle. There are usually a
few points outside the convex hull, determined by the ground points at the very edge of the dataset,
that cannot be interpolated with a triangulation. Extrapolation can be performed with another algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tin(..., extrapolate = knnidw(3, 1, 50))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dtm_tin_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
<tr><td><code id="dtm_tin_+3A_extrapolate">extrapolate</code></td>
<td>
<p>There are usually a few points outside the convex hull, determined by the ground
points at the very edge of the dataset, that cannot be interpolated with a triangulation.
Extrapolation is done using <a href="#topic+knnidw">knnidw</a> by default.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other dtm algorithms: 
<code><a href="#topic+dtm_idw">dtm_idw</a></code>,
<code><a href="#topic+dtm_kriging">dtm_kriging</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile, filter = "-inside 273450 5274350 273550 5274450")

#plot(las)

dtm = rasterize_terrain(las, algorithm = tin())

#plot(dtm)
#plot_dtm3d(dtm)
</code></pre>

<hr>
<h2 id='engine'>Functions for the LAScatalog processing engine not meant to be called directly by users</h2><span id='topic+engine'></span><span id='topic+engine_apply'></span><span id='topic+engine_chunks'></span><span id='topic+engine_crop'></span><span id='topic+engine_merge'></span><span id='topic+engine_write'></span>

<h3>Description</h3>

<p>Functions for the LAScatalog processing engine not meant to be called directly by users.
They are exported for debugging and to simplify export of internal functions when processing in
parallel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>engine_apply(
  .CHUNKS,
  .FUN,
  .PROCESSOPT,
  .OUTPUTOPT,
  .GLOBALS = NULL,
  .AUTOREAD = FALSE,
  .AUTOCROP = FALSE,
  ...
)

engine_chunks(ctg, realignment = FALSE, plot = opt_progress(ctg))

engine_crop(x, bbox)

engine_merge(ctg, any_list, ...)

engine_write(x, path, drivers)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="engine_+3A_.chunks">.CHUNKS</code></td>
<td>
<p>list. list of LAScluster</p>
</td></tr>
<tr><td><code id="engine_+3A_.fun">.FUN</code></td>
<td>
<p>function. function that respects a template (see <a href="#topic+catalog_apply">catalog_apply</a>)</p>
</td></tr>
<tr><td><code id="engine_+3A_.processopt">.PROCESSOPT</code></td>
<td>
<p>list. Processing option</p>
</td></tr>
<tr><td><code id="engine_+3A_.outputopt">.OUTPUTOPT</code></td>
<td>
<p>list. Output option</p>
</td></tr>
<tr><td><code id="engine_+3A_.globals">.GLOBALS</code></td>
<td>
<p>list. Force export of some object in workers</p>
</td></tr>
<tr><td><code id="engine_+3A_.autoread">.AUTOREAD</code></td>
<td>
<p>bool. Enable autoread</p>
</td></tr>
<tr><td><code id="engine_+3A_.autocrop">.AUTOCROP</code></td>
<td>
<p>bool. Enable autocrop</p>
</td></tr>
<tr><td><code id="engine_+3A_...">...</code></td>
<td>
<p>parameters of .FUN</p>
</td></tr>
<tr><td><code id="engine_+3A_ctg">ctg</code></td>
<td>
<p>LAScatalog</p>
</td></tr>
<tr><td><code id="engine_+3A_realignment">realignment</code></td>
<td>
<p><code>FALSE</code> or <code>list(res = x, start = c(y,z))</code>. Sometimes the chunk must
be aligned with a raster, for example to ensure the continuity of the output. If the chunk size is
800 and the expected product is a raster with a resolution of 35, 800 and 35 are not compatible
and will create 2 different partial pixels on the edges. The realignment option forces the
chunk to fit the grid alignment.</p>
</td></tr>
<tr><td><code id="engine_+3A_plot">plot</code></td>
<td>
<p>logical. Displays the chunk pattern.</p>
</td></tr>
<tr><td><code id="engine_+3A_x">x</code></td>
<td>
<p>LAS, Raster, stars, SpatRaster,sf, sfc, Spatial</p>
</td></tr>
<tr><td><code id="engine_+3A_bbox">bbox</code></td>
<td>
<p>bbox</p>
</td></tr>
<tr><td><code id="engine_+3A_any_list">any_list</code></td>
<td>
<p>list of LAS, Raster, stars, SpatRaster, sf, sfc, Spatial, data.frame</p>
</td></tr>
<tr><td><code id="engine_+3A_path">path</code></td>
<td>
<p>strings</p>
</td></tr>
<tr><td><code id="engine_+3A_drivers">drivers</code></td>
<td>
<p>list. Drivers of a LAScatalog</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other LAScatalog processing engine: 
<code><a href="#topic+engine_options">engine_options</a></code>
</p>
<p>Other LAScatalog processing engine: 
<code><a href="#topic+engine_options">engine_options</a></code>
</p>

<hr>
<h2 id='engine_options'>Get or set LAScatalog processing engine options</h2><span id='topic+engine_options'></span><span id='topic+opt_chunk_buffer'></span><span id='topic+opt_chunk_buffer+3C-'></span><span id='topic+opt_chunk_size'></span><span id='topic+opt_chunk_size+3C-'></span><span id='topic+opt_chunk_alignment'></span><span id='topic+opt_chunk_alignment+3C-'></span><span id='topic+opt_restart+3C-'></span><span id='topic+opt_progress'></span><span id='topic+opt_progress+3C-'></span><span id='topic+opt_stop_early'></span><span id='topic+opt_stop_early+3C-'></span><span id='topic+opt_wall_to_wall'></span><span id='topic+opt_wall_to_wall+3C-'></span><span id='topic+opt_independent_files'></span><span id='topic+opt_independent_files+3C-'></span><span id='topic+opt_output_files'></span><span id='topic+opt_output_files+3C-'></span><span id='topic+opt_laz_compression'></span><span id='topic+opt_laz_compression+3C-'></span><span id='topic+opt_merge'></span><span id='topic+opt_merge+3C-'></span><span id='topic+opt_select'></span><span id='topic+opt_select+3C-'></span><span id='topic+opt_filter'></span><span id='topic+opt_filter+3C-'></span>

<h3>Description</h3>

<p>The names of the options and their roles are documented in <a href="#topic+LAScatalog-class">LAScatalog</a>.
The options are used by all the functions that support a <code>LAScatalog</code> as input. Most options are
easy to understand and to link to the documentation of <a href="#topic+LAScatalog-class">LAScatalog</a> but some
need more details. See section 'Details'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opt_chunk_buffer(ctg)

opt_chunk_buffer(ctg) &lt;- value

opt_chunk_size(ctg)

opt_chunk_size(ctg) &lt;- value

opt_chunk_alignment(ctg)

opt_chunk_alignment(ctg) &lt;- value

opt_restart(ctg) &lt;- value

opt_progress(ctg)

opt_progress(ctg) &lt;- value

opt_stop_early(ctg)

opt_stop_early(ctg) &lt;- value

opt_wall_to_wall(ctg)

opt_wall_to_wall(ctg) &lt;- value

opt_independent_files(ctg)

opt_independent_files(ctg) &lt;- value

opt_output_files(ctg)

opt_output_files(ctg) &lt;- value

opt_laz_compression(ctg)

opt_laz_compression(ctg) &lt;- value

opt_merge(ctg)

opt_merge(ctg) &lt;- value

opt_select(ctg)

opt_select(ctg) &lt;- value

opt_filter(ctg)

opt_filter(ctg) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="engine_options_+3A_ctg">ctg</code></td>
<td>
<p>An object of class <a href="#topic+LAScatalog-class">LAScatalog</a></p>
</td></tr>
<tr><td><code id="engine_options_+3A_value">value</code></td>
<td>
<p>An appropriate value depending on the expected input.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>opt_restart()</strong> automatically sets the chunk option named &quot;drop&quot; in such a way that
the engine will restart at a given chunk and skip all previous chunks. Useful for restarting after a crash.
</p>
</li>
<li> <p><strong>opt_independent_file()</strong> automatically sets the chunk size, chunk buffer and wall-to-wall options
to process files that are not spatially related to each other, such as plot inventories.
</p>
</li>
<li> <p><strong>opt_laz_compression()</strong> automatically modifies the drivers to write LAZ files instead of LAS files.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other LAScatalog processing engine: 
<code><a href="#topic+engine">engine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
ctg = readLAScatalog(LASfile)

plot(ctg, chunk_pattern = TRUE)

opt_chunk_size(ctg) &lt;- 150
plot(ctg, chunk_pattern = TRUE)

opt_chunk_buffer(ctg) &lt;- 10
plot(ctg, chunk_pattern = TRUE)

opt_chunk_alignment(ctg) &lt;- c(270,250)
plot(ctg, chunk_pattern = TRUE)

summary(ctg)

opt_output_files(ctg) &lt;- "/path/to/folder/templated_filename_{XBOTTOM}_{ID}"
summary(ctg)
</code></pre>

<hr>
<h2 id='Extract'>Extract or Replace Parts of a LAS* Object</h2><span id='topic+Extract'></span><span id='topic++24+2CLAS-method'></span><span id='topic++5B+5B+2CLAS+2CANY+2Cmissing-method'></span><span id='topic++24+3C-+2CLAS-method'></span><span id='topic++5B+5B+3C-+2CLAS+2CANY+2Cmissing-method'></span><span id='topic++5B+2CLAS+2Cnumeric+2CANY-method'></span><span id='topic++5B+2CLAS+2Clogical+2CANY-method'></span><span id='topic++5B+2CLAS+2Csf+2CANY-method'></span><span id='topic++5B+2CLAS+2Csfc+2CANY-method'></span><span id='topic++24+2CLAScatalog-method'></span><span id='topic++5B+5B+2CLAScatalog+2CANY+2Cmissing-method'></span><span id='topic++5B+2CLAScatalog+2CANY+2CANY-method'></span><span id='topic++5B+2CLAScatalog+2Clogical+2CANY-method'></span><span id='topic++5B+2CLAScatalog+2Csf+2CANY-method'></span><span id='topic++5B+2CLAScatalog+2Csfc+2CANY-method'></span><span id='topic++5B+5B+3C-+2CLAScatalog+2CANY+2CANY-method'></span><span id='topic++24+3C-+2CLAScatalog-method'></span><span id='topic++24+2CLASheader-method'></span><span id='topic++24+3C-+2CLASheader-method'></span><span id='topic++5B+5B+2CLASheader+2CANY+2Cmissing-method'></span><span id='topic++5B+5B+3C-+2CLASheader+2Ccharacter+2Cmissing-method'></span>

<h3>Description</h3>

<p>Operators acting on <code>LAS*</code> objects. However, some have modified behaviors to prevent some
irrelevant modifications. Indeed, a <code>LAS*</code> object cannot contain anything, as the content
is restricted by the LAS specifications. If a user attempts to use one of these functions
inappropriately an informative error will be thrown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'LAS'
x$name

## S4 method for signature 'LAS,ANY,missing'
x[[i, j, ...]]

## S4 replacement method for signature 'LAS'
x$name &lt;- value

## S4 replacement method for signature 'LAS,ANY,missing'
x[[i, j]] &lt;- value

## S4 method for signature 'LAS,numeric,ANY'
x[i]

## S4 method for signature 'LAS,logical,ANY'
x[i]

## S4 method for signature 'LAS,sf,ANY'
x[i]

## S4 method for signature 'LAS,sfc,ANY'
x[i]

## S4 method for signature 'LAScatalog'
x$name

## S4 method for signature 'LAScatalog,ANY,missing'
x[[i, j, ...]]

## S4 method for signature 'LAScatalog,ANY,ANY'
x[i, j, ..., drop = FALSE]

## S4 method for signature 'LAScatalog,logical,ANY'
x[i]

## S4 method for signature 'LAScatalog,sf,ANY'
x[i]

## S4 method for signature 'LAScatalog,sfc,ANY'
x[i]

## S4 replacement method for signature 'LAScatalog,ANY,ANY'
x[[i, j]] &lt;- value

## S4 replacement method for signature 'LAScatalog'
x$name &lt;- value

## S4 method for signature 'LASheader'
x$name

## S4 replacement method for signature 'LASheader'
x$name &lt;- value

## S4 method for signature 'LASheader,ANY,missing'
x[[i, j, ...]]

## S4 replacement method for signature 'LASheader,character,missing'
x[[i]] &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Extract_+3A_x">x</code></td>
<td>
<p>A <code>LAS*</code> object</p>
</td></tr>
<tr><td><code id="Extract_+3A_name">name</code></td>
<td>
<p>A literal character string or a name (possibly backtick quoted).</p>
</td></tr>
<tr><td><code id="Extract_+3A_i">i</code></td>
<td>
<p>string, name of elements to extract or replace.</p>
</td></tr>
<tr><td><code id="Extract_+3A_j">j</code></td>
<td>
<p>Unused.</p>
</td></tr>
<tr><td><code id="Extract_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
<tr><td><code id="Extract_+3A_value">value</code></td>
<td>
<p>typically an array-like R object of a similar class as x.</p>
</td></tr>
<tr><td><code id="Extract_+3A_drop">drop</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las = readLAS(LASfile)

las$Intensity
las[["Z"]]
las[["Number of points by return"]]

## Not run: 
las$Z = 2L
las[["Z"]] = 1:10
las$NewCol = 0
las[["NewCol"]] = 0

## End(Not run)
</code></pre>

<hr>
<h2 id='filters'>Filter points of interest</h2><span id='topic+filters'></span><span id='topic+filter_poi'></span><span id='topic+filter_first'></span><span id='topic+filter_firstlast'></span><span id='topic+filter_firstofmany'></span><span id='topic+filter_ground'></span><span id='topic+filter_last'></span><span id='topic+filter_nth'></span><span id='topic+filter_single'></span><span id='topic+filter_duplicates'></span><span id='topic+filter_duplicates.LAS'></span><span id='topic+filter_duplicates.LAScatalog'></span>

<h3>Description</h3>

<p>Filter points of interest (POI) from a LAS object where conditions are true.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_poi(las, ...)

filter_first(las)

filter_firstlast(las)

filter_firstofmany(las)

filter_ground(las)

filter_last(las)

filter_nth(las, n)

filter_single(las)

filter_duplicates(las)

## S3 method for class 'LAS'
filter_duplicates(las)

## S3 method for class 'LAScatalog'
filter_duplicates(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filters_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a></p>
</td></tr>
<tr><td><code id="filters_+3A_...">...</code></td>
<td>
<p>Logical predicates. Multiple conditions are combined with '&amp;' or ','</p>
</td></tr>
<tr><td><code id="filters_+3A_n">n</code></td>
<td>
<p>integer  ReturnNumber == n</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p><code>filter_poi</code> Select points of interest based on custom logical criteria.
</p>
</li>
<li><p><code>filter_first</code> Select only the first returns.
</p>
</li>
<li><p><code>filter_firstlast</code> Select only the first and last returns.
</p>
</li>
<li><p><code>filter_ground</code> Select only the returns classified as ground according to LAS specification.
</p>
</li>
<li><p><code>filter_last</code> Select only the last returns i.e. the last returns and the single returns.
</p>
</li>
<li><p><code>filter_nth</code> Select the returns from their position in the return sequence.
</p>
</li>
<li><p><code>filter_firstofmany</code> Select only the first returns from pulses which returned multiple points.
</p>
</li>
<li><p><code>filter_single</code> Select only the returns that return only one point.
</p>
</li>
<li><p><code>filter_duplicates</code> <strong>Removes</strong> the duplicated points (duplicated by XYZ)
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <a href="#topic+LAS-class">LAS</a>
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected because it always preserves the file format
and all the attributes. <code>select = "*"</code> is imposed internally.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
lidar = readLAS(LASfile)

# Select the first returns classified as ground
firstground = filter_poi(lidar, Classification == 2L &amp; ReturnNumber == 1L)

# Multiple arguments are equivalent to &amp;
firstground = filter_poi(lidar, Classification == 2L, ReturnNumber == 1L)

# Multiple criteria
first_or_ground = filter_poi(lidar, Classification == 2L | ReturnNumber == 1L)
</code></pre>

<hr>
<h2 id='gnd_csf'>Ground Segmentation Algorithm</h2><span id='topic+gnd_csf'></span><span id='topic+csf'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+classify_ground">classify_ground</a>. It implements an algorithm for segmentation
of ground points base on a Cloth Simulation Filter. This method is a strict implementation of
the CSF algorithm made by Zhang et al. (2016) (see references) that relies on the authors' original
source code written and exposed to R via the the <code>RCSF</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csf(
  sloop_smooth = FALSE,
  class_threshold = 0.5,
  cloth_resolution = 0.5,
  rigidness = 1L,
  iterations = 500L,
  time_step = 0.65
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gnd_csf_+3A_sloop_smooth">sloop_smooth</code></td>
<td>
<p>logical. When steep slopes exist, set this parameter to TRUE to reduce
errors during post-processing.</p>
</td></tr>
<tr><td><code id="gnd_csf_+3A_class_threshold">class_threshold</code></td>
<td>
<p>scalar. The distance to the simulated cloth to classify a point cloud into ground
and non-ground. The default is 0.5.</p>
</td></tr>
<tr><td><code id="gnd_csf_+3A_cloth_resolution">cloth_resolution</code></td>
<td>
<p>scalar. The distance between particles in the cloth. This is usually set to the
average distance of the points in the point cloud. The default value is 0.5.</p>
</td></tr>
<tr><td><code id="gnd_csf_+3A_rigidness">rigidness</code></td>
<td>
<p>integer. The rigidness of the cloth. 1 stands for very soft (to fit rugged
terrain), 2 stands for medium, and 3 stands for hard cloth (for flat terrain). The default is 1.</p>
</td></tr>
<tr><td><code id="gnd_csf_+3A_iterations">iterations</code></td>
<td>
<p>integer. Maximum iterations for simulating cloth. The default value is 500. Usually,
there is no need to change this value.</p>
</td></tr>
<tr><td><code id="gnd_csf_+3A_time_step">time_step</code></td>
<td>
<p>scalar. Time step when simulating the cloth under gravity. The default value
is 0.65. Usually, there is no need to change this value. It is suitable for most cases.</p>
</td></tr>
</table>


<h3>References</h3>

<p>W. Zhang, J. Qi*, P. Wan, H. Wang, D. Xie, X. Wang, and G. Yan, “An Easy-to-Use Airborne LiDAR Data
Filtering Method Based on Cloth Simulation,” Remote Sens., vol. 8, no. 6, p. 501, 2016.
(http://www.mdpi.com/2072-4292/8/6/501/htm)
</p>


<h3>See Also</h3>

<p>Other ground segmentation algorithms: 
<code><a href="#topic+gnd_mcc">gnd_mcc</a></code>,
<code><a href="#topic+gnd_pmf">gnd_pmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzrn")

mycsf &lt;- csf(TRUE, 1, 1, time_step = 1)
las &lt;- classify_ground(las, mycsf)
#plot(las, color = "Classification")
</code></pre>

<hr>
<h2 id='gnd_mcc'>Ground Segmentation Algorithm</h2><span id='topic+gnd_mcc'></span><span id='topic+mcc'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+classify_ground">classify_ground</a>. It implements an
algorithm for segmentation of ground points base on a Multiscale Curvature
Classification. This method is a strict implementation of the MCC algorithm
made by Evans and Hudak. (2007) (see references) that relies on the authors'
original source code written and exposed to R via the the <code>RMCC</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcc(s = 1.5, t = 0.3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gnd_mcc_+3A_s">s</code></td>
<td>
<p>numeric. Scale parameter. The optimal scale parameter is a function of
1) the scale of the objects (e.g., trees) on the ground, and 2) the sampling
interval (post spacing) of the lidar data.</p>
</td></tr>
<tr><td><code id="gnd_mcc_+3A_t">t</code></td>
<td>
<p>numeric. Curvature threshold</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two parameters that the user must define, the scale (s) parameter and
the curvature threshold (t). The optimal scale parameter is a function of
1) the scale of the objects (e.g., trees) on the ground, and 2) the sampling
interval (post spacing) of the lidar data. Current lidar sensors are capable
of collecting high density data (e.g., 8 pulses/m2) that translate to a spatial
sampling frequency (post spacing) of 0.35 m/pulse (1/sqrt(8 pulses/m2) = 0.35 m/pulse),
which is small relative to the size of mature trees and will oversample larger
trees (i.e., nominally multiple returns/tree). Sparser lidar data (e.g., 0.25 pulses/m2)
translate to a post spacing of 2.0 m/pulse (1/sqrt(0.25 pulses/m2) = 2.0 m/pulse),
which would undersample trees and fail to sample some smaller trees (i.e.,
nominally &lt;1 return/tree).<br /><br />
Therefore, a bit of trial and error is warranted to determine the best scale
and curvature parameters to use. Select a las tile containing a good variety
of canopy and terrain conditions, as it's likely the parameters that work best
there will be applicable to the rest of your project area tiles. As a starting
point: if the scale (post spacing) of the lidar survey is 1.5 m, then try 1.5.
Try varying it up or down by 0.5 m increments to see if it produces a more desirable
digital terrain model (DTM) interpolated from the classified ground returns in
the output file. Use units that match the units of the lidar data. For example,
if your lidar data were delivered in units of feet with a post spacing of 3 ft,
set the scale parameter to 3, then try varying it up or down by 1 ft increments
and compare the resulting interpolated DTMs. If the trees are large, then
it's likely that a scale parameter of 1 m (3 ft) will produce a cleaner DTM
than a scale parameter of 0.3 m (1 ft), even if the pulse density is 0.3 m
(1 ft). As for the curvature threshold, a good starting value to try might be
0.3 (if data are in meters; 1 if data are in feet), and then try varying this
up or down by 0.1 m increments (if data are in meters; 0.3 if data are in feet).
</p>


<h3>References</h3>

<p>Evans, Jeffrey S.; Hudak, Andrew T. 2007. A multiscale curvature
algorithm for classifying discrete return LiDAR in forested environments.
IEEE Transactions on Geoscience and Remote Sensing. 45(4): 1029-1038.
</p>


<h3>See Also</h3>

<p>Other ground segmentation algorithms: 
<code><a href="#topic+gnd_csf">gnd_csf</a></code>,
<code><a href="#topic+gnd_pmf">gnd_pmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzrn", filter = "-inside 273450 5274350 273550 5274450")

las &lt;- classify_ground(las, mcc(1.5,0.3))
#plot(las, color = "Classification")
</code></pre>

<hr>
<h2 id='gnd_pmf'>Ground Segmentation Algorithm</h2><span id='topic+gnd_pmf'></span><span id='topic+pmf'></span><span id='topic+util_makeZhangParam'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+classify_ground">classify_ground</a>. It implements an algorithm for segmentation
of ground points based on a progressive morphological filter. This method is an implementation of
the Zhang et al. (2003) algorithm (see reference). Note that this is not a strict implementation
of Zhang et al. This algorithm works at the point cloud level without any rasterization process.
The morphological operator is applied on the point cloud, not on a raster. Also, Zhang et al.
proposed some formulas (eq. 4, 5 and 7) to compute the sequence of windows sizes and thresholds.
Here, these parameters are free and specified by the user. The function <a href="#topic+util_makeZhangParam">util_makeZhangParam</a>
enables computation of the parameters according to the original paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmf(ws, th)

util_makeZhangParam(
  b = 2,
  dh0 = 0.5,
  dhmax = 3,
  s = 1,
  max_ws = 20,
  exp = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gnd_pmf_+3A_ws">ws</code></td>
<td>
<p>numeric. Sequence of windows sizes to be used in filtering ground returns.
The values must be positive and in the same units as the point cloud (usually meters, occasionally
feet).</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_th">th</code></td>
<td>
<p>numeric. Sequence of threshold heights above the parameterized ground surface to be
considered a ground return. The values must be positive and in the same units as the point cloud.</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_b">b</code></td>
<td>
<p>numeric. This is the parameter <code class="reqn">b</code> in Zhang et al. (2003) (eq. 4 and 5).</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_dh0">dh0</code></td>
<td>
<p>numeric. This is <code class="reqn">dh_0</code> in Zhang et al. (2003) (eq. 7).</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_dhmax">dhmax</code></td>
<td>
<p>numeric. This is <code class="reqn">dh_{max}</code> in Zhang et al. (2003) (eq. 7).</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_s">s</code></td>
<td>
<p>numeric. This is <code class="reqn">s</code> in Zhang et al. (2003) (eq. 7).</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_max_ws">max_ws</code></td>
<td>
<p>numeric. Maximum window size to be used in filtering ground returns. This limits
the number of windows created.</p>
</td></tr>
<tr><td><code id="gnd_pmf_+3A_exp">exp</code></td>
<td>
<p>logical. The window size can be increased linearly or exponentially (eq. 4 or 5).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The progressive morphological filter allows for any sequence of parameters. The 'util_makeZhangParam'
function enables computation of the sequences using equations (4),
(5) and (7) from Zhang et al. (see reference and details).
</p>
<p>In the original paper the windows size sequence is given by eq. 4 or 5:<br /><br />
<code class="reqn">w_k = 2kb + 1</code> <br /><br />
or<br /><br />
<code class="reqn">w_k = 2b^k + 1</code><br /><br />
In the original paper the threshold sequence is given by eq. 7:<br /><br />
<code class="reqn">th_k = s*(w_k - w_{k-1})*c + th_0</code><br /><br />
Because the function <a href="#topic+classify_ground">classify_ground</a> applies the morphological operation at the point
cloud level the parameter <code class="reqn">c</code> is set to 1 and cannot be modified.
</p>


<h3>References</h3>

<p>Zhang, K., Chen, S. C., Whitman, D., Shyu, M. L., Yan, J., &amp; Zhang, C. (2003). A progressive
morphological filter for removing nonground measurements from airborne LIDAR data. IEEE
Transactions on Geoscience and Remote Sensing, 41(4 PART I), 872–882. http:#doi.org/10.1109/TGRS.2003.810682.
</p>


<h3>See Also</h3>

<p>Other ground segmentation algorithms: 
<code><a href="#topic+gnd_csf">gnd_csf</a></code>,
<code><a href="#topic+gnd_mcc">gnd_mcc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzrn", filter = "-inside 273450 5274350 273550 5274450")

ws &lt;- seq(3,12, 3)
th &lt;- seq(0.1, 1.5, length.out = length(ws))

las &lt;- classify_ground(las, pmf(ws, th))
#plot(las, color = "Classification")
</code></pre>

<hr>
<h2 id='interpret_waveform'>Convert full waveform data into a regular point cloud</h2><span id='topic+interpret_waveform'></span>

<h3>Description</h3>

<p>Full waveform can be difficult to manipulate and visualize in R. This function converts
a LAS object with full waveform data into a regular point cloud. Each waveform record
becomes a point with XYZ coordinates and an amplitude (units: volts) and an ID that records
each original pulse. Notice that this has the effect of drastically inflating the size of the
object in memory, which is likely already very large
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpret_waveform(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interpret_waveform_+3A_las">las</code></td>
<td>
<p>An object of class LAS with full waveform data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class LAS 1.2 format 0 with one point per records
</p>


<h3>Full waveform</h3>

<p>With most recent versions of the <code>rlas</code> package, full waveform (FWF) can be read and <code>lidR</code>
provides some compatible functions. However, the support of FWF is still a work-in-progress
in the <code>rlas</code> package. How it is read, interpreted and represented in R may change. Consequently,
tools provided by <code>lidR</code> may also change until the support of FWF becomes mature and
stable in <code>rlas</code>. See also <a href="rlas.html#topic+read.las">rlas::read.las</a>.<br /><br />
Remember that FWF represents an insanely huge amount of data. It terms of memory it is like
having between 10 to 100 times more points. Consequently, loading FWF data in R should be
restricted to relatively small point clouds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "fwf.laz", package="rlas")
fwf &lt;- readLAS(LASfile)
las &lt;- interpret_waveform(fwf)
x &lt;- plot(fwf, size = 3, pal = "red")
plot(las, color = "Amplitude", bg = "white", add = x, size = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='is'>A set of boolean tests on objects</h2><span id='topic+is'></span><span id='topic+is.empty'></span><span id='topic+is.overlapping'></span><span id='topic+is.indexed'></span><span id='topic+is.algorithm'></span><span id='topic+is.parallelised'></span>

<h3>Description</h3>

<p><code>is.empty</code> tests if a <code>LAS</code> object is a point cloud with 0 points.<br />
<code>is.overlapping</code> tests if a <code>LAScatalog</code> has overlapping tiles.<br />
<code>is.indexed</code> tests if the points of a <code>LAScatalog</code> are indexed with <code>.lax</code> files.<br />
<code>is.algorithm</code> tests if an object is an algorithm of the lidR package.<br />
<code>is.parallelised</code> tests if an algorithm of the lidR package is natively parallelised with OpenMP.
Returns TRUE if the algorithm is at least partially parallelised i.e. if some portion of the code is
computed in parallel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.empty(las)

is.overlapping(catalog)

is.indexed(catalog)

is.algorithm(x)

is.parallelised(algorithm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_+3A_las">las</code></td>
<td>
<p>A <code>LAS</code> object.</p>
</td></tr>
<tr><td><code id="is_+3A_catalog">catalog</code></td>
<td>
<p>A <code>LAScatalog</code> object.</p>
</td></tr>
<tr><td><code id="is_+3A_x">x</code></td>
<td>
<p>Any R object.</p>
</td></tr>
<tr><td><code id="is_+3A_algorithm">algorithm</code></td>
<td>
<p>An <code>algorithm</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE or FALSE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las = readLAS(LASfile)
is.empty(las)

las = new("LAS")
is.empty(las)

f &lt;- lmf(2)
is.parallelised(f)

g &lt;- pitfree()
is.parallelised(g)

ctg &lt;- readLAScatalog(LASfile)
is.indexed(ctg)
</code></pre>

<hr>
<h2 id='itd_lmf'>Individual Tree Detection Algorithm</h2><span id='topic+itd_lmf'></span><span id='topic+lmf'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+locate_trees">locate_trees</a>. It implements an algorithm for tree
detection based on a local maximum filter. The windows size can be fixed or variable and its
shape can be square or circular. The internal algorithm works either with a raster or a point cloud.
It is deeply inspired by Popescu &amp; Wynne (2004) (see references).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmf(ws, hmin = 2, shape = c("circular", "square"), ws_args = "Z")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itd_lmf_+3A_ws">ws</code></td>
<td>
<p>numeric or function. Length or diameter of the moving window used to detect the local
maxima in the units of the input data (usually meters). If it is numeric a fixed window size is used.
If it is a function, the function determines the size of the window at any given location on the canopy.
By default function takes the height of a given pixel or point as its only argument and return the
desired size of the search window when centered on that pixel/point. This can be controled with
the 'ws_args' parameter</p>
</td></tr>
<tr><td><code id="itd_lmf_+3A_hmin">hmin</code></td>
<td>
<p>numeric. Minimum height of a tree. Threshold below which a pixel or a point
cannot be a local maxima. Default is 2.</p>
</td></tr>
<tr><td><code id="itd_lmf_+3A_shape">shape</code></td>
<td>
<p>character. Shape of the moving window used to find the local maxima. Can be &quot;square&quot;
or &quot;circular&quot;.</p>
</td></tr>
<tr><td><code id="itd_lmf_+3A_ws_args">ws_args</code></td>
<td>
<p>list. Named list of argument for the function 'ws' if 'ws' is a function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Popescu, Sorin &amp; Wynne, Randolph. (2004). Seeing the Trees in the Forest: Using Lidar and
Multispectral Data Fusion with Local Filtering and Variable Window Size for Estimating Tree Height.
Photogrammetric Engineering and Remote Sensing. 70. 589-604. 10.14358/PERS.70.5.589.
</p>


<h3>See Also</h3>

<p>Other individual tree detection algorithms: 
<code><a href="#topic+itd_manual">itd_manual</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzi", filter = "-inside 481250 3812980 481300 3813050")

# =================
# point-cloud-based
# =================

# 5x5 m fixed window size
ttops &lt;- locate_trees(las, lmf(5))

#plot(las) |&gt; add_treetops3d(ttops)

# variable windows size
f &lt;- function(x) { x * 0.07 + 3}
ttops &lt;- locate_trees(las, lmf(f))

#plot(las) |&gt; add_treetops3d(ttops)

# Very custom variable windows size
f &lt;- function(x, y, z) { x * 0.07 + y * 0.01 + z}
ws_args &lt;- list(x = "Z", y = "Intensity", z = 3)
ttops &lt;- locate_trees(las, lmf(f, ws_args = ws_args))

# ============
# raster-based
# ============

chm &lt;- rasterize_canopy(las, res = 1, p2r(0.15), pkg = "terra")
ttops &lt;- locate_trees(chm, lmf(5))

plot(chm, col = height.colors(30))
plot(sf::st_geometry(ttops), add = TRUE, col = "black", cex = 0.5, pch = 3)

# variable window size
f &lt;- function(x) { x * 0.07 + 3 }
ttops &lt;- locate_trees(chm, lmf(f))

plot(chm, col = height.colors(30))
plot(sf::st_geometry(ttops), add = TRUE, col = "black", cex = 0.5, pch = 3)
</code></pre>

<hr>
<h2 id='itd_manual'>Individual Tree Detection Algorithm</h2><span id='topic+itd_manual'></span><span id='topic+manual'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+locate_trees">locate_trees</a>. It implements an algorithm for manual
tree detection. Users can pinpoint the tree top positions manually and interactively using the mouse.
This is only suitable for small-sized plots. First the point cloud is displayed, then the user is
invited to select a rectangular region of interest in the scene using the mouse button.
Within the selected region the highest point will be flagged as 'tree top' in the scene. Once all the trees
are labelled the user can exit the tool by selecting an empty region. Points can also be unflagged.
The goal of this tool is mainly for minor correction of automatically-detected tree outputs. <br />
<strong>This algorithm does not preserve tree IDs from <code>detected</code> and renumber all trees. It also looses
all attributes</strong>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manual(detected = NULL, radius = 0.5, color = "red", button = "middle", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itd_manual_+3A_detected">detected</code></td>
<td>
<p><code>SpatialPoints* or </code>sf/sfc_POINT' with  2 or 3D points of already found tree tops
that need manual correction. Can be NULL</p>
</td></tr>
<tr><td><code id="itd_manual_+3A_radius">radius</code></td>
<td>
<p>numeric. Radius of the spheres displayed on the point cloud (aesthetic purposes only).</p>
</td></tr>
<tr><td><code id="itd_manual_+3A_color">color</code></td>
<td>
<p>character. Colour of the spheres displayed on the point cloud (aesthetic purposes only).</p>
</td></tr>
<tr><td><code id="itd_manual_+3A_button">button</code></td>
<td>
<p>Which button to use for selection. One of &quot;left&quot;, &quot;middle&quot;, &quot;right&quot;. lidR using left
for rotation and right for dragging using one of left or right will disable either rotation or dragging</p>
</td></tr>
<tr><td><code id="itd_manual_+3A_...">...</code></td>
<td>
<p>supplementary parameters to be passed to <a href="#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other individual tree detection algorithms: 
<code><a href="#topic+itd_lmf">itd_lmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las = readLAS(LASfile)

# Full manual tree detection
ttops = locate_trees(las, manual())

# Automatic detection with manual correction
ttops = locate_trees(las, lmf(5))
ttops = locate_trees(las, manual(ttops))

## End(Not run)
</code></pre>

<hr>
<h2 id='its_dalponte2016'>Individual Tree Segmentation Algorithm</h2><span id='topic+its_dalponte2016'></span><span id='topic+dalponte2016'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+segment_trees">segment_trees</a>. It implements an algorithm for tree
segmentation based on Dalponte and Coomes (2016) algorithm (see reference).
This is a seeds + growing region algorithm. This algorithm exists in the package <code>itcSegment</code>.
This version has been written from the paper in C++. Consequently it is hundreds to millions times
faster than the original version. Note that this algorithm strictly performs a segmentation, while the
original method as implemented in <code>itcSegment</code> and described in the manuscript also performs
pre- and post-processing tasks. Here these tasks are expected to be done by the user in separate functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dalponte2016(
  chm,
  treetops,
  th_tree = 2,
  th_seed = 0.45,
  th_cr = 0.55,
  max_cr = 10,
  ID = "treeID"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="its_dalponte2016_+3A_chm">chm</code></td>
<td>
<p>'RasterLayer', 'SpatRaster' or 'stars'. Canopy height model. Can be computed with <a href="#topic+rasterize_canopy">rasterize_canopy</a> or read from
an external file.</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_treetops">treetops</code></td>
<td>
<p>'SpatialPoints*' or 'sf/sfc_POINT' with 2D or 3D coordinates. Can be computed with
<a href="#topic+locate_trees">locate_trees</a> or read from an external file</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_th_tree">th_tree</code></td>
<td>
<p>numeric. Threshold below which a pixel cannot be a tree. Default is 2.</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_th_seed">th_seed</code></td>
<td>
<p>numeric. Growing threshold 1. See reference in Dalponte et al. 2016. A pixel
is added to a region if its height is greater than the tree height multiplied by this value.
It should be between 0 and 1. Default is 0.45.</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_th_cr">th_cr</code></td>
<td>
<p>numeric. Growing threshold 2. See reference in Dalponte et al. 2016. A pixel
is added to a region if its height is greater than the current mean height of the region
multiplied by this value. It should be between 0 and 1. Default is 0.55.</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_max_cr">max_cr</code></td>
<td>
<p>numeric. Maximum value of the crown diameter of a detected tree (in pixels).
Default is 10.</p>
</td></tr>
<tr><td><code id="its_dalponte2016_+3A_id">ID</code></td>
<td>
<p>character. If <code>treetops</code> contains an attribute with the ID for
each tree, the name of this attribute. This way, original IDs will be preserved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because this algorithm works on a CHM only there is no actual need for a point cloud. Sometimes the
user does not even have the point cloud that generated the CHM. <code>lidR</code> is a point cloud-oriented
library, which is why this algorithm must be used in <a href="#topic+segment_trees">segment_trees</a> to merge the result with the point
cloud. However the user can use this as a stand-alone function like this:
</p>
<pre>
 chm &lt;- raster("chm.tif")
 ttops &lt;- locate_trees(chm, lmf(3))
 crowns &lt;- dalponte2016(chm, ttops)()
</pre>


<h3>References</h3>

<p>Dalponte, M. and Coomes, D. A. (2016), Tree-centric mapping of forest carbon density from
airborne laser scanning and hyperspectral data. Methods Ecol Evol, 7: 1236–1245. doi:10.1111/2041-210X.12575.
</p>


<h3>See Also</h3>

<p>Other individual tree segmentation algorithms: 
<code><a href="#topic+its_li2012">its_li2012</a></code>,
<code><a href="#topic+its_silva2016">its_silva2016</a></code>,
<code><a href="#topic+its_watershed">its_watershed</a></code>
</p>
<p>Other raster based tree segmentation algorithms: 
<code><a href="#topic+its_silva2016">its_silva2016</a></code>,
<code><a href="#topic+its_watershed">its_watershed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
poi &lt;- "-drop_z_below 0 -inside 481280 3812940 481320 3812980"
las &lt;- readLAS(LASfile, select = "xyz", filter = poi)
col &lt;- pastel.colors(200)

chm &lt;- rasterize_canopy(las, 0.5, p2r(0.3))
ker &lt;- matrix(1,3,3)
chm &lt;- terra::focal(chm, w = ker, fun = mean, na.rm = TRUE)

ttops &lt;- locate_trees(chm, lmf(4, 2))
las   &lt;- segment_trees(las, dalponte2016(chm, ttops))
#plot(las, color = "treeID", colorPalette = col)
</code></pre>

<hr>
<h2 id='its_li2012'>Individual Tree Segmentation Algorithm</h2><span id='topic+its_li2012'></span><span id='topic+li2012'></span>

<h3>Description</h3>

<p>This functions is made to be used in <a href="#topic+segment_trees">segment_trees</a>. It implements an algorithm for tree
segmentation based on Li et al. (2012) (see reference). This method is a growing region
method working at the point cloud level. It is an implementation by lidR authors, from the original
paper, as close as possible from the original description. However we added a parameter <code>hmin</code>
to prevent over-segmentation for objects that are too low. This algorithm is known to be slow because
it has an algorithmic complexity worst that O(n^2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>li2012(dt1 = 1.5, dt2 = 2, R = 2, Zu = 15, hmin = 2, speed_up = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="its_li2012_+3A_dt1">dt1</code></td>
<td>
<p>numeric. Threshold number 1. See reference page 79 in Li et al. (2012). Default is 1.5.</p>
</td></tr>
<tr><td><code id="its_li2012_+3A_dt2">dt2</code></td>
<td>
<p>numeric. Threshold number 2. See reference page 79 in Li et al. (2012). Default is 2.</p>
</td></tr>
<tr><td><code id="its_li2012_+3A_r">R</code></td>
<td>
<p>numeric. Search radius. See page 79 in Li et al. (2012). Default is 2. If <code>R = 0</code>
all the points are automatically considered as local maxima and the search step is skipped (much
faster).</p>
</td></tr>
<tr><td><code id="its_li2012_+3A_zu">Zu</code></td>
<td>
<p>numeric. If point elevation is greater than Zu, <code>dt2</code> is used, otherwise <code>dt1</code> is
used. See page 79 in Li et al. (2012). Default is 15.</p>
</td></tr>
<tr><td><code id="its_li2012_+3A_hmin">hmin</code></td>
<td>
<p>numeric. Minimum height of a detected tree. Default is 2.</p>
</td></tr>
<tr><td><code id="its_li2012_+3A_speed_up">speed_up</code></td>
<td>
<p>numeric. Maximum radius of a crown. Any value greater than a crown is
good because this parameter does not affect the result. However, it greatly affects the
computation speed by restricting the number of comparisons to perform.
The lower the value, the faster the method. Default is 10.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Li, W., Guo, Q., Jakubowski, M. K., &amp; Kelly, M. (2012). A new method for segmenting individual
trees from the lidar point cloud. Photogrammetric Engineering &amp; Remote Sensing, 78(1), 75-84.
</p>


<h3>See Also</h3>

<p>Other individual tree segmentation algorithms: 
<code><a href="#topic+its_dalponte2016">its_dalponte2016</a></code>,
<code><a href="#topic+its_silva2016">its_silva2016</a></code>,
<code><a href="#topic+its_watershed">its_watershed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
poi &lt;- "-drop_z_below 0 -inside 481280 3812940 481320 3812980"
las &lt;- readLAS(LASfile, select = "xyz", filter = poi)
col &lt;- pastel.colors(200)

las &lt;- segment_trees(las, li2012(dt1 = 1.4))
#plot(las, color = "treeID", colorPalette = col)
</code></pre>

<hr>
<h2 id='its_silva2016'>Individual Tree Segmentation Algorithm</h2><span id='topic+its_silva2016'></span><span id='topic+silva2016'></span>

<h3>Description</h3>

<p>This functions is made to be used in <a href="#topic+segment_trees">segment_trees</a>. It implements an algorithm for tree
segmentation based on Silva et al. (2016) (see reference). This is a simple method
based on seed + voronoi tesselation (equivalent to nearest neighbour). This algorithm is implemented
in the package <code>rLiDAR</code>. This version is not the version from <code>rLiDAR</code>. It is
code written from the original article by the lidR authors and is considerably (between 250
and 1000 times) faster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silva2016(chm, treetops, max_cr_factor = 0.6, exclusion = 0.3, ID = "treeID")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="its_silva2016_+3A_chm">chm</code></td>
<td>
<p>'RasterLayer', 'SpatRaster' or 'stars'. Canopy height model. Can be computed with <a href="#topic+rasterize_canopy">rasterize_canopy</a> or read from
an external file.</p>
</td></tr>
<tr><td><code id="its_silva2016_+3A_treetops">treetops</code></td>
<td>
<p>'SpatialPoints*' or 'sf/sfc_POINT' with 2D or 3D coordinates. Can be computed with
<a href="#topic+locate_trees">locate_trees</a> or read from an external file</p>
</td></tr>
<tr><td><code id="its_silva2016_+3A_max_cr_factor">max_cr_factor</code></td>
<td>
<p>numeric. Maximum value of a crown diameter given as a proportion of the
tree height. Default is 0.6, meaning 60% of the tree height.</p>
</td></tr>
<tr><td><code id="its_silva2016_+3A_exclusion">exclusion</code></td>
<td>
<p>numeric. For each tree, pixels with an elevation lower than <code>exclusion</code>
multiplied by the tree height will be removed. Thus, this number belongs between 0 and 1.</p>
</td></tr>
<tr><td><code id="its_silva2016_+3A_id">ID</code></td>
<td>
<p>character. If <code>treetops</code> contains an attribute with the ID for
each tree, the name of this attribute. This way, original IDs will be preserved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because this algorithm works on a CHM only there is no actual need for a point cloud. Sometimes the
user does not even have the point cloud that generated the CHM. <code>lidR</code> is a point cloud-oriented
library, which is why this algorithm must be used in <a href="#topic+segment_trees">segment_trees</a> to merge the result into the point
cloud. However, the user can use this as a stand-alone function like this:
</p>
<pre>
 chm &lt;- raster("chm.tif")
 ttops &lt;- locate_trees(chm, lmf(3))
 crowns &lt;- silva2016(chm, ttops)()
</pre>


<h3>References</h3>

<p>Silva, C. A., Hudak, A. T., Vierling, L. A., Loudermilk, E. L., O’Brien, J. J., Hiers,
J. K., Khosravipour, A. (2016). Imputation of Individual Longleaf Pine (Pinus palustris Mill.)
Tree Attributes from Field and LiDAR Data. Canadian Journal of Remote Sensing, 42(5), 554–573.
https://doi.org/10.1080/07038992.2016.1196582.
</p>


<h3>See Also</h3>

<p>Other individual tree segmentation algorithms: 
<code><a href="#topic+its_dalponte2016">its_dalponte2016</a></code>,
<code><a href="#topic+its_li2012">its_li2012</a></code>,
<code><a href="#topic+its_watershed">its_watershed</a></code>
</p>
<p>Other raster based tree segmentation algorithms: 
<code><a href="#topic+its_dalponte2016">its_dalponte2016</a></code>,
<code><a href="#topic+its_watershed">its_watershed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
poi &lt;- "-drop_z_below 0 -inside 481280 3812940 481320 3812980"
las &lt;- readLAS(LASfile, select = "xyz", filter = poi)
col &lt;- pastel.colors(200)

chm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.3))
ker &lt;- matrix(1,3,3)
chm &lt;- terra::focal(chm, w = ker, fun = mean, na.rm = TRUE)

ttops &lt;- locate_trees(chm, lmf(4, 2))
las   &lt;- segment_trees(las, silva2016(chm, ttops))
#plot(las, color = "treeID", colorPalette = col)
</code></pre>

<hr>
<h2 id='its_watershed'>Individual Tree Segmentation Algorithm</h2><span id='topic+its_watershed'></span><span id='topic+watershed'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+segment_trees">segment_trees</a>. It implements an algorithm for tree
segmentation based on a watershed. It is based on the bioconductor package <code>EBIimage</code>. You
need to install this package to run this method (see its <a href="https://github.com/aoles/EBImage">github page</a>).
Internally, the function EBImage::watershed is called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>watershed(chm, th_tree = 2, tol = 1, ext = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="its_watershed_+3A_chm">chm</code></td>
<td>
<p>'RasterLayer', 'SpatRaster' or 'stars'. Canopy height model. Can be computed with <a href="#topic+rasterize_canopy">rasterize_canopy</a> or read from
an external file.</p>
</td></tr>
<tr><td><code id="its_watershed_+3A_th_tree">th_tree</code></td>
<td>
<p>numeric. Threshold below which a pixel cannot be a tree. Default is 2.</p>
</td></tr>
<tr><td><code id="its_watershed_+3A_tol">tol</code></td>
<td>
<p>numeric. Tolerance see ?EBImage::watershed.</p>
</td></tr>
<tr><td><code id="its_watershed_+3A_ext">ext</code></td>
<td>
<p>numeric. see ?EBImage::watershed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because this algorithm works on a CHM only there is no actual need for a point cloud. Sometimes the
user does not even have the point cloud that generated the CHM. <code>lidR</code> is a point cloud-oriented
library, which is why this algorithm must be used in <a href="#topic+segment_trees">segment_trees</a> to merge the result into the point
cloud. However, the user can use this as a stand-alone function like this:
</p>
<pre>
 chm &lt;- raster("chm.tif")
 crowns &lt;- watershed(chm)()
</pre>


<h3>See Also</h3>

<p>Other individual tree segmentation algorithms: 
<code><a href="#topic+its_dalponte2016">its_dalponte2016</a></code>,
<code><a href="#topic+its_li2012">its_li2012</a></code>,
<code><a href="#topic+its_silva2016">its_silva2016</a></code>
</p>
<p>Other raster based tree segmentation algorithms: 
<code><a href="#topic+its_dalponte2016">its_dalponte2016</a></code>,
<code><a href="#topic+its_silva2016">its_silva2016</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
poi &lt;- "-drop_z_below 0 -inside 481280 3812940 481320 3812980"
las &lt;- readLAS(LASfile, select = "xyz", filter = poi)
col &lt;- pastel.colors(250)

# Using raster because focal does not exist in stars
chm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.3), pkg = "raster")
ker &lt;- matrix(1,3,3)
chm &lt;- raster::focal(chm, w = ker, fun = mean, na.rm = TRUE)
las &lt;- segment_trees(las, watershed(chm))

plot(las, color = "treeID", colorPalette = col)

## End(Not run)
</code></pre>

<hr>
<h2 id='las_check'>Inspect a LAS object</h2><span id='topic+las_check'></span>

<h3>Description</h3>

<p>Performs a deep inspection of a LAS or LAScatalog object and prints a report.<br /><br />
For a LAS object it checks:
</p>

<ul>
<li><p> if the point cloud is valid according to las specification
</p>
</li>
<li><p> if the header is valid according to las specification
</p>
</li>
<li><p> if the point cloud is in accordance with the header
</p>
</li>
<li><p> if the point cloud has duplicated points and degenerated ground points
</p>
</li>
<li><p> if gpstime and pulses are consistent
</p>
</li>
<li><p> it the coordinate reference sytem is correctly recorded
</p>
</li>
<li><p> if some pre-processing, such as normalization or ground filtering, is already done.
</p>
</li>
<li><p> and much more
</p>
</li></ul>

<p>For a LAScatalog object it checks:
</p>

<ul>
<li><p> if the headers are consistent across files
</p>
</li>
<li><p> if the files are overlapping
</p>
</li>
<li><p> if some pre-processing, such as normalization, is already done.
</p>
</li></ul>

<p>For the pre-processing tests the function only makes an estimation and may not be correct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>las_check(las, print = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="las_check_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="las_check_+3A_print">print</code></td>
<td>
<p>logical. By default, prints a report and returns a <code>list</code> invisibly. If
<code>print = FALSE</code> the functions returns a <code>list</code> visibly and do not print the report.</p>
</td></tr>
<tr><td><code id="las_check_+3A_...">...</code></td>
<td>
<p>Use <code>deep = TRUE</code> on a LAScatalog only. Instead of a shallow inspection it reads
all the files and performs a deep inspection.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three elements named <code>message</code>, <code>warnings</code> and <code>errors</code>. This list is returned
invisibly if <code>print = TRUE</code>. If <code>deep = TRUE</code> a nested list is returned with one element
per file.
</p>


<h3>See Also</h3>

<p>Other las utilities: 
<code><a href="#topic+las_utilities">las_utilities</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile)
las_check(las)
</code></pre>

<hr>
<h2 id='las_compression'>Compression of the point cloud</h2><span id='topic+las_compression'></span><span id='topic+las_is_compressed'></span><span id='topic+las_size'></span>

<h3>Description</h3>

<p>Package rlas 1.6.0 supports compact representation of non populated attributes. For example <code>UserData</code>
is usually populated with zeros (not populated). Yet it takes 32 bits per point to store each 0.
With rlas 1.6.0 it can now use 644 bits no matter the number of points loaded if it is not
populated or populated with a unique value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>las_is_compressed(las)

las_size(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="las_compression_+3A_las">las</code></td>
<td>
<p>A LAS object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>las_is_compressed</code> test each attributes and returns a named vector with TRUE if the attribute is
compressed FALSE otherwise.<br /><br />
<code>las_size</code> returns the true size of a LAS object by considering the compression. <code>object.size</code> from
base R does not account for ALTREP and consequently cannot measure properly the size of a LAS object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile)
las_is_compressed(las)

format(object.size(las), units = "MB")
format(las_size(las), units = "MB")

</code></pre>

<hr>
<h2 id='las_utilities'>LAS utilities</h2><span id='topic+las_utilities'></span><span id='topic+las_rescale'></span><span id='topic+las_reoffset'></span><span id='topic+las_quantize'></span><span id='topic+las_update'></span><span id='topic+quantize'></span><span id='topic+is.quantized'></span><span id='topic+count_not_quantized'></span><span id='topic+storable_coordinate_range'></span><span id='topic+header'></span><span id='topic+payload'></span><span id='topic+phb'></span><span id='topic+vlr'></span><span id='topic+evlr'></span>

<h3>Description</h3>

<p>Tools to manipulate LAS objects maintaining compliance with
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">ASPRS specification</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>las_rescale(las, xscale, yscale, zscale)

las_reoffset(las, xoffset, yoffset, zoffset)

las_quantize(las, by_reference = TRUE)

las_update(las)

quantize(x, scale, offset, by_reference = TRUE, ...)

is.quantized(x, scale, offset, ...)

count_not_quantized(x, scale, offset)

storable_coordinate_range(scale, offset)

header(las)

payload(las)

phb(las)

vlr(las)

evlr(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="las_utilities_+3A_las">las</code></td>
<td>
<p>An object of class LAS</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_xscale">xscale</code>, <code id="las_utilities_+3A_yscale">yscale</code>, <code id="las_utilities_+3A_zscale">zscale</code></td>
<td>
<p>scalar. Can be missing if not relevant.</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_xoffset">xoffset</code>, <code id="las_utilities_+3A_yoffset">yoffset</code>, <code id="las_utilities_+3A_zoffset">zoffset</code></td>
<td>
<p>scalar. Can be missing if not relevant.</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_by_reference">by_reference</code></td>
<td>
<p>bool. Update the data in place without allocating new memory.</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_x">x</code></td>
<td>
<p>numeric. Coordinates vector</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_scale">scale</code>, <code id="las_utilities_+3A_offset">offset</code></td>
<td>
<p>scalar. scale and offset</p>
</td></tr>
<tr><td><code id="las_utilities_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the specification of the LAS format the coordinates are expected to be given
with a certain precision e.g. 0.01 for a millimeter precision (or millifeet), meaning
that a file records e.g. 123.46 not 123.45678. Also, coordinates are stored as
integers. This is made possible with a scale and offset factor. For example,
123.46 with an offset of 100 and a scale factor of 0.01 is actually stored as
(123.46 - 100)/0.01 = 2346. Storing 123.45678 with a scale factor of 0.01 and an offset
of 100 is invalid because it does not convert to an integer: (123.45678-100)/0.01
= 2345.678. Having an invalid LAS object may be critical in some lidR applications.
When writing into a LAS file, users will loose the extra precision without
warning and some algorithms in lidR use the integer conversion to make integer-based
computation and thus speed-up some algorithms and use less memory. Creation of an
invalid LAS object may cause problems and incorrect outputs.
</p>


<h3>See Also</h3>

<p>Other las utilities: 
<code><a href="#topic+las_check">las_check</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las = readLAS(LASfile)

# Manual modification of the coordinates (e.g. rotation, re-alignment, ...)
las@data$X &lt;- las@data$X + 2/3
las@data$Y &lt;- las@data$Y - 5/3

# The point cloud is no longer valid
las_check(las)

# It is important to fix that
las_quantize(las)

# Now the file is almost valid
las_check(las)

# Update the object to set up-to-date header data
las &lt;- las_update(las)
las_check(las)

# In practice the above code is not useful for regular users because the operators
# $&lt;- already perform such operations on-the-fly. Thus the following
# syntax must be preferred and returns valid objects. Previous tools
# were only intended to be used in very specific cases.
las$X &lt;- las$X + 2/3
las$Y &lt;- las$Y - 5/3

# Rescale and reoffset recompute the coordinates with
# new scales and offsets according to LAS specification
las &lt;- las_rescale(las, xscale = 0.01, yscale = 0.01)
las &lt;- las_reoffset(las, xoffset = 300000, yoffset = 5248000)
</code></pre>

<hr>
<h2 id='LAS-class'>An S4 class to represent a .las or .laz file</h2><span id='topic+LAS-class'></span><span id='topic+LAS'></span>

<h3>Description</h3>

<p>Class LAS is the representation of a las/laz file according to the
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">LAS file format specifications</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LAS(data, header = list(), crs = sf::NA_crs_, check = TRUE, index = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LAS-class_+3A_data">data</code></td>
<td>
<p>a <a href="data.table.html#topic+data.table">data.table</a> containing the data of a las or laz file.</p>
</td></tr>
<tr><td><code id="LAS-class_+3A_header">header</code></td>
<td>
<p>a <code>list</code> or a <a href="#topic+LASheader-class">LASheader</a> containing the header of
a las or laz file.</p>
</td></tr>
<tr><td><code id="LAS-class_+3A_crs">crs</code></td>
<td>
<p>crs object of class <a href="sf.html#topic+st_crs">crs</a> from sf</p>
</td></tr>
<tr><td><code id="LAS-class_+3A_check">check</code></td>
<td>
<p>logical. Conformity tests while building the object.</p>
</td></tr>
<tr><td><code id="LAS-class_+3A_index">index</code></td>
<td>
<p>list with two elements <code>list(sensor = 0L, index = 0L)</code>.
See <a href="#topic+lidR-spatial-index">spatial indexing</a></p>
</td></tr>
<tr><td><code id="LAS-class_+3A_...">...</code></td>
<td>
<p>internal use</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>LAS</code> object contains a <code>data.table</code> with the data read from a <code>las/laz</code> file and
a <a href="#topic+LASheader-class">LASheader</a> (see the ASPRS documentation for the
<a href="https://www.asprs.org/a/society/committees/standards/LAS_1_4_r13.pdf">LAS file format</a>
for more information). Because las files are standardized the table of attributes read from the las/laz file
is also standardized. Columns are named:
</p>

<ul>
<li><p><code>X</code>, <code>Y</code>, <code>Z</code> (numeric)
</p>
</li>
<li><p><code>gpstime</code> (numeric)
</p>
</li>
<li><p><code>Intensity</code> (integer)
</p>
</li>
<li><p><code>ReturnNumber</code>, <code>NumberOfReturns</code> (integer)
</p>
</li>
<li><p><code>ScanDirectionFlag</code> (integer)
</p>
</li>
<li><p><code>EdgeOfFlightline</code> (integer)
</p>
</li>
<li><p><code>Classification</code> (integer)
</p>
</li>
<li><p><code>Synthetic_flag</code>,<code>Keypoint_flag</code>, <code>Withheld_flag</code>  (logical)
</p>
</li>
<li><p><code>ScanAngleRank</code>/<code>ScanAngle</code>  (integer/numeric)
</p>
</li>
<li><p><code>UserData</code> (integer)
</p>
</li>
<li><p><code>PointSourceID</code> (integer)
</p>
</li>
<li><p><code>R</code>,<code>G</code>,<code>B</code>, <code>NIR</code> (integer)
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>LAS</code>
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>LAS()</code>: creates objects of class LAS. The original data is updated by reference to
quantize the coordinates according to the scale factor of the header if no header is provided.
In this case the scale factor is set to 0.001
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>crs</code></dt><dd><p>Object of class <a href="sf.html#topic+st_crs">crs</a> from sf.</p>
</dd>
<dt><code>data</code></dt><dd><p>Object of class <a href="data.table.html#topic+data.table">data.table</a>. Point cloud data according to the
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">LAS file format</a></p>
</dd>
<dt><code>header</code></dt><dd><p>Object of class <a href="#topic+LASheader-class">LASheader</a>. LAS file header according to the
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">LAS file format</a></p>
</dd>
<dt><code>index</code></dt><dd><p>list. See <a href="#topic+lidR-spatial-index">spatial indexing</a>.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+readLAS">readLAS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read a las/laz file
LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las &lt;- readLAS(LASfile)
las

# Creation of a LAS object out of external data
data &lt;- data.frame(X = runif(100, 0, 100),
                   Y = runif(100, 0, 100),
                   Z = runif(100, 0, 20))

# 'data' has many decimal digits
data

# Create a default header and quantize *by reference*
# the coordinates to fit with offset and scale factors
cloud &lt;- LAS(data)

# 'data' has been updated and coordinates were quantized
data
cloud

# Be careful when providing a header the function assumes that
# it corresponds to the data and won't quantize the coordinates
data &lt;- data.frame(X = runif(100, 0, 100),
                   Y = runif(100, 0, 100),
                   Z = runif(100, 0, 20))
header &lt;- header(las)

# This works but triggers warnings and creates an invalid LAS object
cloud &lt;- LAS(data, header)

las_check(cloud)
</code></pre>

<hr>
<h2 id='LAScatalog-class'>An S4 class to represent a collection of .las or .laz files</h2><span id='topic+LAScatalog-class'></span>

<h3>Description</h3>

<p>A <code>LAScatalog</code> object is a representation of a collection of las/laz files. A <code>LAScatalog</code> is
a way to manage and batch process a lidar coverage. It allows the user to process a large area, or to
selectively clip data from a large area without loading all the data into computer memory.
A <code>LAScatalog</code> can be built with the function <a href="#topic+readLAScatalog">readLAScatalog</a>.
</p>


<h3>Details</h3>

<p>A <code>LAScatalog</code> contains an <code>sf</code> object to store the geometry and metadata. It is extended with slots
that contain processing options. In <code>lidR</code>, each function that supports a <code>LAScatalog</code> as
input will respect these processing options. Internally, processing a catalog is almost always the
same and relies on a few steps:<br />
</p>

<ol>
<li><p> Define chunks. A chunk is an arbitrarily-defined region of interest (ROI) of the
collection. Altogether, the chunks are a wall-to-wall set of ROIs that encompass the whole dataset.
</p>
</li>
<li><p> Loop over each chunk (in parallel or not).
</p>
</li>
<li><p> For each chunk, load the points inside the ROI into R, run some R functions,
return the expected output.
</p>
</li>
<li><p> Merge the outputs of the different chunks once they are all processed to build a continuous
(wall-to-wall) output.
</p>
</li></ol>

<p>So basically, a <code>LAScatalog</code> is an object that allows for batch processing but with the specificity
that <code>lidR</code> does not loop through LAS or LAZ files, but loops seamlessly through chunks that do not
necessarily match with the file pattern. This way <code>lidR</code> can sequentially process tiny ROIs even if
each file may be individually too big to fit in memory. This is also why point cloud indexation
with <code>lax</code> files may significantly speed-up the processing.<br /><br />
It is important to note that catalogs with files that overlap each other are not natively supported
by <code>lidR</code>. When encountering such datasets the user should always filter any overlaps if
possible. This is possible if the overlapping points are flagged, for example in the
'withheld' attribute. Otherwise <code>lidR</code> will not be able to process the dataset correctly.
</p>


<h3>Slots</h3>


<dl>
<dt><code>data</code></dt><dd><p>sf. An <code>sf</code> <code>data.frame</code> with the bounding box of each file as well as all the information
read from the header of each LAS/LAZ file.</p>
</dd>
<dt><code>processing_options</code></dt><dd><p>list. A list that contains some settings describing how the collection will be
processed (see dedicated section).</p>
</dd>
<dt><code>chunk_options</code></dt><dd><p>list. A list that contains some settings describing how the collection will be
sub-divided into chunks to be processed (see dedicated section).</p>
</dd>
<dt><code>output_options</code></dt><dd><p>list. A list that contains some settings describing how the collection will return
the outputs (see dedicated section).</p>
</dd>
<dt><code>input_options</code></dt><dd><p>list. A list of parameters to pass to <a href="#topic+readLAS">readLAS</a> (see dedicated section).</p>
</dd>
<dt><code>index</code></dt><dd><p>list. See <a href="#topic+lidR-spatial-index">spatial indexing</a>.</p>
</dd>
</dl>


<h3>Processing options</h3>

<p>The slot <code style="white-space: pre;">&#8288;@processing_options&#8288;</code> contains a <code>list</code> of options that determine how chunks
(the sub-areas that are sequentially processed) are processed.
</p>

<ul>
<li> <p><strong>progress</strong>: boolean. Display a progress bar and a chart of progress. Default is TRUE.
Progress estimation can be enhanced by installing the package <code>progress</code>. See <a href="#topic+opt_progress">opt_progress</a>.
</p>
</li>
<li> <p><strong>stop_early</strong>: boolean. Stop the processing if an error occurs in a chunk. If <code>FALSE</code>
the process can run until the end, removing chunks that failed. Default is TRUE and the user should
have no reason to change this. See <a href="#topic+opt_stop_early">opt_stop_early</a>.
</p>
</li>
<li> <p><strong>wall.to.wall</strong> logical. The catalog processing engine always guarantees to return a
continuous output without edge effects, assuming that the catalog is a wall-to-wall catalog. To do
so, some options are checked internally to guard against bad settings, such as <code>buffer = 0</code> for an
algorithm that requires a buffer. In rare cases it might be useful to disable these controls. If
<code>wall.to.wall = FALSE</code> controls are disabled and wall-to-wall outputs cannot be guaranteed.
See <a href="#topic+opt_wall_to_wall">opt_wall_to_wall</a>
</p>
</li></ul>



<h3>Chunk options</h3>

<p>The slot <code style="white-space: pre;">&#8288;@chunk_options&#8288;</code> contains a <code>list</code> of options that determine how chunks
(the sub-areas that are sequentially processed) are made.
</p>

<ul>
<li> <p><strong>chunk_size</strong>: numeric. The size of the chunks that will be sequentially processed.
A small size allows small amounts of data to be loaded at once, saving computer memory.
With big chunks the computation is usually faster but uses much more memory. If <code>chunk_size = 0</code> the
chunk pattern is build using the file pattern. The chunks are expecting to be wall-to-wall coverage,
which means that <code>chunk_size = 0</code> has meaning only if the files are not overlapping. Default is 0 i.e.
by default the processing engine respects the existing tiling pattern. See <a href="#topic+opt_chunk_size">opt_chunk_size</a>.
</p>
</li>
<li> <p><strong>buffer</strong>: numeric. Each chunk can be read with an extra buffer around it to ensure there are
no edge effects between two independent chunks and that the output is continuous. This is mandatory for
some algorithms. Default is 30. See <a href="#topic+opt_chunk_buffer">opt_chunk_buffer</a>.
</p>
</li>
<li> <p><strong>alignment</strong>: numeric. A vector of size 2 (x and y coordinates, respectively) to align the
chunk pattern. By default the alignment is made along (0,0), meaning that the edge of the first chunk
will belong on x = 0 and y = 0 and all the the other chunks will be multiples of the chunk size.
Not relevant if <code>chunk_size = 0</code>. See <a href="#topic+opt_chunk_alignment">opt_chunk_alignment</a>.
</p>
</li>
<li> <p><strong>drop</strong>: integers. A vector of integers that specify the IDs of the chunks that should not be
created. This is designed to enable users to restart a computation that failed without reprocessing
everything. See <a href="#topic+opt_restart+3C-">opt_restart&lt;-</a>. Technically, this option may be used for partial processing of
a collection, but it generally should not be. Partial processing is already a feature of the engine. See
<a href="https://cran.r-project.org/package=lidR/vignettes/lidR-LAScatalog-engine.html#partial-processing">this vignette</a>
</p>
</li></ul>



<h3>Output options</h3>

<p>The slot <code style="white-space: pre;">&#8288;@output_options&#8288;</code> contains a <code>list</code> of options that determine how chunks
(the sub-areas that are sequentially processed) are written. By &quot;written&quot; we mean written to files
or written in R memory.
</p>

<ul>
<li> <p><strong>output_files</strong>: string. If <code>output_files = ""</code> outputs are returned in R. Otherwise, if
<code>output_files</code> is a string the outputs will be written to files.
This is useful if the output is too big to be returned in R. A path to a filename template
without a file extension (the engine guesses it for you) is expected. When several files are going to be
written a single string is provided with a template that is automatically filled. For example,
the following file names are possible:
</p>
<pre>
"/home/user/als/normalized/file_{ID}_segmented"
"C:/user/document/als/zone52_{XLEFT}_{YBOTTOM}_confidential"
"C:/user/document/als/{ORIGINALFILNAME}_normalized"
</pre>
<p>This option will generate as many filenames as needed with custom names for each file. The allowed
templates are <code>{XLEFT}, {XRIGHT}, {YBOTTOM}, {YTOP}, {ID}, {XCENTER},
{YCENTER}, {ORIGNALFILENAME}</code>. See <a href="#topic+opt_output_files">opt_output_files</a>.
</p>
</li>
<li> <p><strong>drivers</strong>: list. This contains all the drivers required to seamlessly write <code style="white-space: pre;">&#8288;Raster*&#8288;</code>,
<code>SpatRaster</code>, <code>stars</code>, <code style="white-space: pre;">&#8288;Spatial*&#8288;</code>, <code>sf</code>, and <code>LAS</code> objects. It is recommended that only advanced
users change this option. A dedicated page describes the drivers in <a href="#topic+lidR-LAScatalog-drivers">lidR-LAScatalog-drivers</a>.
</p>
</li>
<li> <p><strong>merge</strong>: boolean. Multiple objects are merged into a single object at the end of the processing.
See <a href="#topic+opt_merge">opt_merge</a>.
</p>
</li></ul>



<h3>Input options</h3>

<p>The slot <code style="white-space: pre;">&#8288;@input_options&#8288;</code> contains a <code>list</code> of options that are passed to the function
<a href="#topic+readLAS">readLAS</a>. Indeed, the <code>readLAS</code> function is not called directly by the user but by the
internal processing engine. Users can propagate these options through the <code>LAScatalog</code> settings.
</p>

<ul>
<li> <p><strong>select</strong>: string. The option <code>select</code>. Usually this option is not respected because
each function knows which data must be loaded or not. This is documented in each function. See
<a href="#topic+opt_select">opt_select</a>.
</p>
</li>
<li> <p><strong>filter</strong>: string. The option <code>filter</code>. See <a href="#topic+opt_filter">opt_filter</a>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Build a catalog
ctg &lt;- readLAScatalog("filder/to/las/files/", filter =  "-keep_first")


# Summary gives a summary of how the catalog will be processed
summary(ctg)

# We can seamlessly use lidR functions
hmean &lt;- pixel_metrics(ctg, ~~mean(Z), 20)
ttops &lt;- tree_detection(ctg, lmf(5))

# For low memory config it is probably advisable not to load entire files
# and process chunks instead
opt_chunk_size(ctg) &lt;- 500

# Sometimes the output is likely to be very large
# e.g. large coverage and small resolution
dtm &lt;- rasterize_terrain(ctg, 1, tin())

# In that case it is advisable to write the output(s) to files
opt_output_files(ctg) &lt;- "path/to/folder/DTM_chunk_{XLEFT}_{YBOTTOM}"

# Raster will be written to disk. The list of written files is returned
# or, in this specific case, a virtual raster mosaic.
dtm &lt;- rasterize_terrain(ctg, 1, tin())

# When chunks are files the original names of the las files can be preserved
opt_chunk_size(ctg) &lt;- 0
opt_output_files(ctg) &lt;- "path/to/folder/DTM_{ORIGINALFILENAME}"
dtm &lt;- rasterize_terrain(ctg, 1, tin())

# For some functions, files MUST be written to disk. Indeed, it is certain that R cannot
# handle the entire output.
opt_chunk_size(ctg) &lt;- 0
opt_output_files(ctg) &lt;- "path/to/folder/{ORIGINALFILENAME}_norm"
opt_laz_compression(ctg) &lt;- TRUE
new_ctg &lt;- normalize_height(ctg, tin())

# The user has access to the catalog engine through the functions catalog_apply
# and catalog_map
output &lt;- catalog_apply(ctg, FUN, ...)

## End(Not run)
</code></pre>

<hr>
<h2 id='LASheader'>Create a <code>LASheader</code> object</h2><span id='topic+LASheader'></span>

<h3>Description</h3>

<p>Creates a  <code>LASheader</code> object either from a raw <code>list</code> containing all the
elements named according to the <code>rlas</code> package or creates a header from a <code>data.frame</code>
or <code>data.table</code> containing a point cloud. In the latter case it will generate a header
according to the data using <a href="rlas.html#topic+header_create">rlas::header_create()</a>. It will
guess the LAS file format, the point data format, and initialize the scale factors and offsets,
but these may not suit a user's needs. Users are advised to
manually modify the results to fit their specific needs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LASheader(data = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LASheader_+3A_data">data</code></td>
<td>
<p>a list containing the data from the header of a LAS file. Can also be
a <code>data.frame</code> or <code>data.table</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>LASheader</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = data.frame(X = c(339002.889, 339002.983, 339002.918),
                  Y = c(5248000.515, 5248000.478, 5248000.318),
                  Z = c(975.589, 974.778, 974.471),
                  gpstime = c(269347.28141, 269347.28142, 269347.28143),
                  Intensity = c(82L, 54L, 27L),
                  ReturnNumber = c(1L, 1L, 2L),
                  NumberOfReturns = c(1L, 1L, 2L),
                  ScanDirectionFlag = c(1L, 1L, 1L),
                  EdgeOfFlightline = c(1L, 0L, 0L),
                  Classification = c(1L, 1L, 1L),
                  ScanAngleRank = c(-21L, -21L, -21L),
                  UserData = c(32L, 32L, 32L),
                  PointSourceID = c(17L, 17L, 17L))

header = LASheader(data)
header

# Record an EPSG code
epsg(header) &lt;- 32618
header

las &lt;- LAS(data, header)
las

# The function inferred a LAS 1.2 format 1 which is correct
# Upgrade to LAS 1.4 for the example
header@VLR &lt;- list() # Erase VLR previously written
header@PHB[["Global Encoding"]][["WKT"]] &lt;- TRUE
header@PHB[["Version Minor"]] &lt;- 4L
header@PHB[["Header Size"]] &lt;- 375L
header@PHB[["Offset to point data"]] &lt;- 375L
wkt(header) &lt;- sf::st_crs("EPSG:32618")$wkt
header
las1.4 &lt;- LAS(data, header)
las1.4
</code></pre>

<hr>
<h2 id='LASheader-class'>An S4 class to represent the header of .las or .laz files</h2><span id='topic+LASheader-class'></span>

<h3>Description</h3>

<p>An S4 class to represent the header of .las or .laz files according to the
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">LAS file format specifications</a>.
A <code>LASheader</code> object contains a <code>list</code> in the slot <code style="white-space: pre;">&#8288;@PHB&#8288;</code> with
the data read from the Public Header Block, a <code>list</code> in the slot <code style="white-space: pre;">&#8288;@VLR&#8288;</code> with
the data read from the Variable Length Records and a <code>list</code> in the slot <code>EVLR</code> with the data read
from the Extended Variable Lenght Records.
</p>


<h3>Slots</h3>


<dl>
<dt><code>PHB</code></dt><dd><p>list. Represents the Public Header Block</p>
</dd>
<dt><code>VLR</code></dt><dd><p>list. Represents the Variable Length Records</p>
</dd>
<dt><code>EVLR</code></dt><dd><p>list. Represents the Extended Variable Length Records</p>
</dd>
</dl>

<hr>
<h2 id='lidR-LAScatalog-drivers'>LAScatalog drivers</h2><span id='topic+lidR-LAScatalog-drivers'></span>

<h3>Description</h3>

<p>This document explains how objects are written on disk when processing a LAScatalog. As mentioned
in <a href="#topic+LAScatalog-class">LAScatalog-class</a>, users can set a templated filename to store the outputs on disk instead
of in R memory. By defaut <code>LAS</code> objects are stored in .las files with <a href="#topic+writeLAS">writeLAS</a>,
raster objects are stored in .tif files using native write function for <code>raster</code>, <code>stars</code> or <code>terra</code>,
<code style="white-space: pre;">&#8288;Spatial*&#8288;</code> objects are stored in .shp files with after coercion to <code>sf</code> with <a href="sf.html#topic+st_write">st_write</a>,
<code>sf</code> object are stored to <code>.gpkg</code> files with <a href="sf.html#topic+st_write">st_write</a>.<code>data.frame</code> objects are
stored in .csv files with <a href="data.table.html#topic+fwrite">fwrite</a>, and other objects are not supported.
However, users can modify all these default settings and even add new drivers.
This manual page explain how. One may also refer to some unofficial documentation
<a href="https://github.com/r-lidar/lidR/wiki/Modify-the-LAScatalog-drivers">here</a> or
<a href="https://gis.stackexchange.com/questions/325367/how-to-configure-lidr-catalog-to-save-raster-files">here</a>.
</p>


<h3>Generic form of a driver</h3>

<p>A driver is stored in the  slot <code style="white-space: pre;">&#8288;@output_options&#8288;</code> of a <code>LAScatalog</code>. It is a list that contains:
</p>

<dl>
<dt>write</dt><dd><p>A function that receives an object and a path, and writes the object into a file using
the path. The function can also have extra options.</p>
</dd>
<dt>extension</dt><dd><p>A string that gives the file extension.</p>
</dd>
<dt>object</dt><dd><p>A string that gives the name of the argument used to pass the object to write in the
function used to write the object.</p>
</dd>
<dt>path</dt><dd><p>A string that gives the name of the argument used to pass the path of the file to write
in the function used to write the object.</p>
</dd>
<dt>param</dt><dd><p>A labelled list of extra parameters for the function used to write the object</p>
</dd>
</dl>

<p>For example, the driver to write a  <code style="white-space: pre;">&#8288;Raster*&#8288;</code> is
</p>
<pre>
list(
 write = raster::writeRaster,
 extension = ".tif",
 object = "x",
 path = "filename",
 param = list(format = "GTiff"))
</pre>
<p>And the driver to write a <code>LAS</code> is
</p>
<pre>
list(
 write = lidR::writeLAS,
 extension = ".las",
 object = "las",
 path = "file",
 param = list())
</pre>


<h3>Modify a driver (1/2)</h3>

<p>Users can modify the drivers to write different file types than the default. For example, to write in
shapefile instead of a GeoPackage, one must change the <code>sf</code> driver:
</p>
<pre>
ctg@output_options$drivers$sf$extension &lt;- ".shp"
</pre>
<p>To write a <code style="white-space: pre;">&#8288;Raster*&#8288;</code> in .grd files instead of .tif files one must change the <code>Raster</code> driver:
</p>
<pre>
ctg@output_options$drivers$Raster$extension &lt;- ".grd"
ctg@output_options$drivers$Raster$param$format &lt;- "raster"
</pre>
<p>To write in .laz files instead of .las files one must change the <code>LAS</code> driver:
</p>
<pre>
ctg@output_options$drivers$LAS$extension &lt;- ".laz"
</pre>


<h3>Add a new driver</h3>

<p>The drivers allow <code>LAS</code>, <code>Spatial</code>,<code style="white-space: pre;">&#8288;sf,&#8288;</code> <code>Raster</code>, <code>stars</code>, <code>SpatRaster</code> and <code>data.frame</code> objects
to be written. When using the engine (<a href="#topic+catalog_apply">catalog_apply</a>) to build new tools, users may need to
be able to write other objects such as a <code>list</code>. To do that users need to add a <code>list</code> element
into <code style="white-space: pre;">&#8288;@output_options&#8288;</code>:
</p>
<pre>
ctg@output_options$drivers$list = list(
 write = base::saveRDS,
 object = "object",
 path = "file",
 extension = ".rds",
 param = list(compress = TRUE))
</pre>
<p>The <code>LAScatalog</code> now has a new driver capable of writing a <code>list</code>.
</p>


<h3>Modify a driver (2/2)</h3>

<p>It is also possible to completely overwrite an existing driver. By default <code>sf</code> objects are written
into GeoPackage with <a href="sf.html#topic+st_write">st_write</a>. <code>st_write</code> can also wite in GeoJSON and even in
SQLlite database objects. But it cannot add data into an existing SQLlite database. Let's create
our own driver for a <code>sf</code>. First we need a function able to write and append a <code>sf</code> into a <code>SQLlite</code>
database from the object and the path.
</p>
<pre>
dbWrite_sf = function(x, path, name)
{
 x &lt;- sf::st_drop_geometry(x)
 con &lt;- RSQLite::dbConnect(RSQLite::SQLite(), path)
 RSQLite::dbWriteTable(con, name, x, append = TRUE)
 RSQLite::dbDisconnect(con)
}</pre>
<p>Then we create the driver. User-defined drivers supersede default drivers:
</p>
<pre>
ctg@output_options$drivers$sf = list(
 write = dbWrite_sf,
 extension = ".sqlite",
 object = "x",
 path = "path",
 param = list(name = "layername"))
</pre>
<p>Then to be sure that we do not write several .sqlite files, we don't use templated filename.
</p>
<pre>
opt_output_files(ctg) &lt;- paste0(tempdir(), "/mysqlitefile")</pre>
<p>And all the <code>sf</code> will be appended in a single database. To preserve the geometry one can
</p>

<hr>
<h2 id='lidR-parallelism'>Parallel computation in lidR</h2><span id='topic+lidR-parallelism'></span>

<h3>Description</h3>

<p>This document explains how to process point clouds taking advantage of parallel processing in the
lidR package. The lidR package has two levels of parallelism, which is why it is difficult to
understand how it works. This page aims to provide users with a clear overview of how to take advantage
of multicore processing even if they are not comfortable with the parallelism concept.
</p>


<h3>Algorithm-based parallelism</h3>

<p>When processing a point cloud we are applying an algorithm on data. This algorithm may or may not be
natively parallel. In lidR some algorithms are fully computed in parallel, but some are not because they are
not parallelizable, while some are only partially parallelized. It means that some portions of the code
are computed in parallel and some are not. When an algorithm is natively parallel in lidR it is always
a C++ based parallelization with OpenMP. The advantage is that the computation is faster without any
consequence for memory usage because the memory is shared between the processors. In short,
algorithm-based parallelism provides a significant gain without any cost for your R session and
your system (but obviously there is a greater workload for the processors). By default lidR uses
half of your cores but you can control this with <a href="#topic+set_lidr_threads">set_lidr_threads</a>. For example, the <a href="#topic+lmf">lmf</a>
algorithm is natively parallel. The following code is computed in parallel:
</p>
<pre>
las  &lt;- readLAS("file.las")
tops &lt;- locate_trees(las, lmf(2))
</pre>
<p>However, as stated above, not all algorithms are parallelized or even parallelizable. For example,
<a href="#topic+li2012">li2012</a> is not parallelized. The following code is computed in serial:
</p>
<pre>
las &lt;- readLAS("file.las")
dtm &lt;- segment_trees(las, li2012())
</pre>
<p>To know which algorithms are parallelized users can refer to the documentation or use the
function <a href="#topic+is.parallelised">is.parallelised</a>.
</p>
<pre>
is.parallelised(lmf(2))   #&gt; TRUE
is.parallelised(li2012()) #&gt; FALSE
</pre>


<h3>Chunk-based parallelism</h3>

<p>When processing a <code>LAScatalog</code>, the internal engine splits the dataset into chunks and each chunk is
read and processed sequentially in a loop. This loop can be parallelized with the
<code>future</code> package. By default the chunks are processed sequentially, but they can be processed
in parallel by registering an evaluation strategy. For example, the following code is evaluated
sequentially:
</p>
<pre>
ctg &lt;- readLAScatalog("folder/")
out &lt;- pixel_metrics(ctg, ~mean(Z))
</pre>
<p>But this one is evaluated in parallel with two cores:
</p>
<pre>
library(future)
plan(multisession, workers = 2L)
ctg &lt;- readLAScatalog("folder/")
out &lt;- pixel_metrics(ctg, ~mean(Z))
</pre>
<p>With chunk-based parallelism any algorithm can be parallelized by processing several subsets of
a dataset.  However, there is a strong cost associated with this type of parallelism. When processing several
chunks at a time, the computer needs to load the corresponding point clouds. Assuming the user processes
one square kilometer chunks in parallel with 4 cores, then 4 chunks are loaded in the computer
memory. This may be too much and the speed-up is not guaranteed since there is some overhead involved in
reading several files at a time. Once this point is understood, chunk-based parallelism is very
powerful since all the algorithms can be parallelized whether or not they are natively parallel.
It also allows to parallelize the computation on several machines on the network or to work on a HPC.
</p>


<h3>Nested parallelism - part 1</h3>

<p>Previous sections stated that some algorithms are natively parallel, such as <a href="#topic+lmf">lmf</a>, and some are
not, such as <a href="#topic+li2012">li2012</a>. Anyway, users can split the dataset into chunks to process them simultaneously
with the LAScatalog processing engine. Let's assume that the user's computer has four cores,
what happens in this case:
</p>
<pre>
library(future)
plan(multisession, workers = 4L)
set_lidr_threads(4L)
ctg &lt;- readLAScatalog("folder/")
out &lt;- locate_trees(ctg, lmf(2))
</pre>
<p>Here the catalog will be split into chunks that will be processed in parallel. And each computation
itself implies a parallelized task. This is a nested parallelism task and it is dangerous! Hopefully
the lidR package handles such cases and chooses by default to give precedence to chunk-based
parallelism. In this case chunks will be processed in parallel and the points will be processed
serially by disabling OpenMP.
</p>


<h3>Nested parallelism - part 2</h3>

<p>We explained rules of precedence. But actually the user can tune the engine more accurately. Let's
define the following function:
</p>
<pre>
myfun = function(las, ws, ...)
{
  las  &lt;- normalize_height(las, tin())
  tops &lt;- locate_tree(las, lmf(ws))
  return(tops)
}

out &lt;- catalog_map(ctg, myfun, ws = 5)
</pre>
<p>This function used two algorithms, one is partially parallelized (<code>tin</code>) and one is fully
parallelized <code>lmf</code>. The user can manually use both OpenMP and future. By default the engine
will give precedence to chunk-based parallelism because it works in all cases but the user can
impose something else. In the following 2 workers are attributed to future and 2 workers are
attributed to OpenMP.
</p>
<pre>
plan(multisession, workers = 2L)
set_lidr_threads(2L)
catalog_map(ctg, myfun, ws = 5)
</pre>
<p>The rule is simple. If the number of workers needed is greater than the number of
available workers then OpenMP is disabled. Let suppose we have a 4 cores:
</p>
<pre>
# 2 chunks 2 threads: OK
plan(multisession, workers = 2L)
set_lidr_threads(2L)

# 4 chunks 1 threads: OK
plan(multisession, workers = 4L)
set_lidr_threads(1L)

# 1 chunks 4 threads: OK
plan(sequential)
set_lidr_threads(4L)

# 3 chunks 2 threads: NOT OK
# Needs 6 workers, OpenMP threads are set to 1 i.e. sequential processing
plan(multisession, workers = 3L)
set_lidr_threads(2L)
</pre>


<h3>Complex computing architectures</h3>

<p>For more complex processing architectures such as multiple computers controlled remotely
or HPC a finer tuning might be necessary. Using
</p>
<pre>
options(lidR.check.nested.parallelism = FALSE)
</pre>
<p>lidR will no longer check for nested parallelism and will never automatically disable OpenMP.
</p>

<hr>
<h2 id='lidR-spatial-index'>Spatial index</h2><span id='topic+lidR-spatial-index'></span><span id='topic+sensor'></span><span id='topic+sensor+3C-'></span><span id='topic+index'></span><span id='topic+index+3C-'></span>

<h3>Description</h3>

<p>This document explains how to process point-clouds taking advantage of different spatial
indexes available in the lidR package. lidR can use several types of spatial indexes to
apply algorithms (that need a spatial indexing) as fast as possible. The choice of the spatial
index depends on the type of point-cloud that is processed and the algorithm that is performed.
lidR can use a grid partition, a voxel partition, a quadtree or an octree. See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensor(las, h = FALSE)

sensor(las) &lt;- value

index(las, h = FALSE)

index(las) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lidR-spatial-index_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="lidR-spatial-index_+3A_h">h</code></td>
<td>
<p>boolean. Human readable. Everything is stored as integers that are understood
internally. Use <code>h = TRUE</code> for user readable output.</p>
</td></tr>
<tr><td><code id="lidR-spatial-index_+3A_value">value</code></td>
<td>
<p>integer or character. A code for referring to a sensor type or a spatial
index type. Use one of <code>"unknown"</code>, <code>"als"</code>, <code>"tls"</code>, <code>"uav"</code>, <code>"dap"</code>, <code>"multispectral"</code>
for sensor type and one of <code>"auto"</code>, <code>"gridpartition"</code>, <code>"voxelpartition"</code>, <code>"quadtree"</code>, <code>"octree"</code>
for spatial index type.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>From lidR (&gt;= 3.1.0), a <a href="#topic+LAS-class">LAS</a> object records the sensor used to sample
the point-cloud (ALS, TLS, UAV, DAP) as well as the spatial index that must be used
for processing the point cloud. This can be set manually by the user but the simplest is
to use one of the <a href="#topic+readLAS">read*LAS()</a> functions. By default a point-cloud is associated
to a sensor and the best spatial index is chosen on-the-fly depending on the algorithm
applied. It is possible to force the use of a specific spatial index.
</p>
<p>Information relative to the spatial indexing is stored in slot <code style="white-space: pre;">&#8288;@index&#8288;</code> that contains
a <code>list</code> with two elements:
</p>

<ul>
<li> <p><code>sensor</code>: an integer that records the sensor type
</p>
</li>
<li> <p><code>index</code>: an integer that records the spatial index to be used
</p>
</li></ul>

<p>By default the spatial index code is 0 (&quot;automatic&quot;) meaning that each function is free
to choose a different spatial index depending on the recorded sensor. If the code is not
0 then each function will be forced to used the spatial index that is imposed. This,
obviously, applies only to functions that use spatial indexing.
</p>
<p><a href="#topic+LAScatalog-class">LAScatalog</a> objects also record such information that is automatically
propagated to the LAS objects when processing.
</p>
<p>Note: before version 3.1.0, point-clouds were all considered as ALS because lidR was originally
designed for ALS. Consequently, for legacy and backwards-compatibility reasons, <code>readLAS()</code>
and <code>readALSLAS()</code> are actually equivalent. <code>readLAS()</code> tags the point cloud with &quot;unknown&quot;
sensor while <code>readALSLAS()</code> tags it with 'ALS'. Both behave the same and this is
especially true compared with versions &lt; 3.1. As a consequence, using <code>readLAS()</code> provides
the same performance (no degradation) than in previous versions, while using one of the <code>read*LAS()</code>
functions may improve the performance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las &lt;- readLAS(LASfile)

# By default the sensor and spatial index codes are 0
sensor(las)
index(las)

# Codes are used internally and not intended to be known by users
# Use h option for human readable output
sensor(las, h = TRUE)
index(las, h = TRUE)

# Modification of the sensor enables users to select a better spatial index
# when processing the point-cloud.
sensor(las) &lt;- "tls"
sensor(las, h = TRUE)
index(las, h = TRUE)

# Modification of the spatial index forces users to choose one of the available
# spatial indexes.
index(las) &lt;- "quadtree"
sensor(las, h = TRUE)
index(las, h = TRUE)

# The simplest way to take advantage of appropriate spatial indexing is
# to use one of the read*LAS() functions.
las &lt;- readTLSLAS(LASfile)
sensor(las, h = TRUE)
index(las, h = TRUE)

# But for some specific point-clouds / algorithms it might be advisable to force
# the use of a specific spatial index to perform the computation faster
index(las) &lt;- "voxelpartition"
index(las, h = TRUE)

# With a LAScatalog, spatial indexing information is propagated to the
# different chunks
ctg = readTLSLAScatalog(LASfile)
index(ctg) &lt;- "voxelpartition"
sensor(ctg, h = TRUE)
index(ctg, h = TRUE)

# ==================
# PERFORMANCE TESTS
# ==================

## Not run: 
# Performance tests on TLS
# ------------------------

# The package does not include TLS data
# so we can generate something that looks TLS-ish
# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
X &lt;- runif(50, -25, 25)
Y &lt;- runif(50, -25, 25)
X &lt;- as.numeric(sapply(X, function(x) rnorm(2000, x, 2)))
Y &lt;- as.numeric(sapply(Y, function(x) rnorm(2000, x, 2)))
Z &lt;- abs(rnorm(length(Y), 10, 5))
veg &lt;- data.frame(X,Y,Z)
X &lt;- runif(5000, -30, 30)
Y &lt;- runif(5000, -30, 30)
Z &lt;- runif(5000, 0, 1)
ground &lt;- data.frame(X,Y,Z)
X &lt;- runif(30, -30, 30)
Y &lt;- runif(30, -30, 30)
Z &lt;- runif(30, 0, 30)
noise &lt;- data.frame(X,Y,Z)
las &lt;- LAS(rbind(ground, veg, noise))
# &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;

plot(las)

# If read with readALSLAS()
sensor(las) &lt;- "als"
system.time(classify_noise(las, sor(20, 8)))
#&gt; 1.5 sec

# If read with readTLSLAS()
sensor(las) &lt;- "tls"
system.time(classify_noise(las, sor(20, 8)))
#&gt; 0.6 sec

# Performance tests on ALS
# ------------------------

# The package does not include large ALS data
# so we can generate something that looks ALS-ish
# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
X &lt;- runif(4e5, 0, 1000)
Y &lt;- runif(4e5, 0, 1000)
Z &lt;- 40*sin(0.01*X) + 50*cos(0.005*Y) + abs(rnorm(length(Y), 10, 5))
veg &lt;- data.frame(X,Y,Z)
X &lt;- runif(100, 0, 1000)
Y &lt;- runif(100, 0, 1000)
Z &lt;- 40*sin(0.01*X) + 50*cos(0.005*Y) + abs(rnorm(length(Y), 10, 5)) + runif(100, 30, 70)
noise &lt;- data.frame(X,Y,Z)
las &lt;- LAS(rbind(veg, noise))
# &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;

plot(las)

# If read with readALSLAS()
sensor(las) &lt;- "als"
system.time(classify_noise(las, sor(15, 8)))
#&gt; 3 sec

# If read with readTLSLAS()
sensor(las) &lt;- "tls"
system.time(classify_noise(las, sor(15, 8)))
#&gt; 4.3 sec

## End(Not run)
</code></pre>

<hr>
<h2 id='locate_trees'>Individual tree detection</h2><span id='topic+locate_trees'></span>

<h3>Description</h3>

<p>Individual tree detection function that find the position of the trees using several possible
algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>locate_trees(las, algorithm, uniqueness = "incremental")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="locate_trees_+3A_las">las</code></td>
<td>
<p>An object of class <code>LAS</code> or <code>LAScatalog</code>. Can also be a  raster from <code>raster</code>, <code>stars</code> or <code>terra</code>
representing a canopy height model, in which case it is processed like a regularly-spaced point cloud.</p>
</td></tr>
<tr><td><code id="locate_trees_+3A_algorithm">algorithm</code></td>
<td>
<p>An algorithm for individual tree detection. lidR has: <a href="#topic+lmf">lmf</a> and <a href="#topic+manual">manual</a>.
More experimental algorithms may be found in the package <a href="https://github.com/Jean-Romain/lidRplugins">lidRplugins</a>.</p>
</td></tr>
<tr><td><code id="locate_trees_+3A_uniqueness">uniqueness</code></td>
<td>
<p>character. A method to compute a unique ID. Can be 'incremental', 'gpstime' or
'bitmerge'. See section 'Uniqueness'. This feature must be considered as 'experimental'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>locate_trees</code> returns an sf object with POINT Z geometries. The table of attributes
contains a column <code>treeID</code> with an individual ID for each tree. The height of the trees (<code>Z</code>) are
also repeated in the table of attribute to be analysed as an attribute and not as a coordinate.
</p>


<h3>Uniqueness</h3>

<p>By default the tree IDs are numbered from 1 to n, n being the number of trees found. The problem
with such incremental numbering is that, while it ensures a unique ID is assigned for each tree in
a given point-cloud, it also guarantees duplication of tree IDs in different tiles or chunks when
processing a <code>LAScatalog</code>. This is because each chunk/file is processed independently of the others
and potentially in parallel on different computers. Thus, the index always restarts at 1 on each
chunk/file. Worse, in a tree segmentation process, a tree that is located exactly between
2 chunks/files will have two different IDs for its two halves.
</p>
<p>This is why we introduced some uniqueness strategies that are all imperfect and that should be seen
as experimental. Please report any troubleshooting. Using a uniqueness-safe strategy ensures that
trees from different files will not share the same IDs. It also ensures that two halves of a tree
on the edge of a processing chunk will be assigned the same ID.
</p>

<dl>
<dt>incremental</dt><dd><p>Number from 0 to n. This method <strong>does not</strong> ensure uniqueness of the IDs. This
is the legacy method.</p>
</dd>
<dt>gpstime</dt><dd><p>This method uses the gpstime of the highest point of a tree (apex) to create a
unique ID. This ID is not an integer but a 64-bit decimal number, which is suboptimal but at
least it is expected to be unique <strong>if the gpstime attribute is consistent across files</strong>.
If inconsistencies with gpstime are reported (for example gpstime records the week time and was
reset to 0 in a coverage that takes more than a week to complete), there is a (low) probability of
getting ID attribution errors.</p>
</dd>
<dt>bitmerge</dt><dd><p>This method uses the XY coordinates of the highest point (apex) of a tree to
create a single 64-bit number with a bitwise operation. First, XY coordinates are converted to
32-bit integers using the scales and offsets of the point cloud. For example, if the apex is at
(10.32, 25.64) with a scale factor of 0.01 and an offset of 0, the 32-bit integer coordinates are
X = 1032 and Y = 2564. Their binary representations are, respectively, (here displayed as 16 bits)
0000010000001000 and 0000101000000100. X is shifted by 32 bits and becomes a 64-bit integer. Y is kept
as-is and the binary representations are unionized into a 64-bit integer like (here displayed as 32 bit)
00000100000010000000101000000100 that is guaranteed to be unique. However R
does not support 64-bit integers. The previous steps are done at C++ level and the 64-bit binary
representation is reinterpreted into a 64-bit decimal number to be returned in R. The IDs thus generated
are somewhat weird. For example, the tree ID 00000100000010000000101000000100 which is 67635716 if
interpreted as an integer becomes 3.34164837074751323479078607289E-316 if interpreted as a decimal
number. This is far from optimal but at least it is guaranteed to be unique  <strong>if all files have
the same offsets and scale factors</strong>.</p>
</dd>
</dl>

<p>All the proposed options are suboptimal because they either do not guarantee uniqueness in all cases
(inconsistencies in the collection of files), or they imply that IDs are based on non-integers or
meaningless numbers. But at least it works and deals with some of the limitations of R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyz", filter = "-inside 481250 3812980 481300 3813030")

ttops &lt;- locate_trees(las, lmf(ws = 5))

#plot(las) |&gt; add_treetops3d(ttops)
</code></pre>

<hr>
<h2 id='merge_spatial'>Merge a point cloud with a source of spatial data</h2><span id='topic+merge_spatial'></span>

<h3>Description</h3>

<p>Merge a point cloud with a source of spatial data. It adds an attribute along each point based on
a value found in the spatial data. Sources of spatial data can be a <code style="white-space: pre;">&#8288;SpatialPolygons*&#8288;</code>, an <code>sf</code>/<code>sfc</code>,
a <code style="white-space: pre;">&#8288;Raster*&#8288;</code>, a <code>stars</code>, or a <code>SpatRaster</code>.<br />
</p>

<ul>
<li><p><code style="white-space: pre;">&#8288;SpatialPolygons*&#8288;</code>, <code>sf</code> and <code>sfc</code>: it checks if the points belongs within each polygon. If
the parameter <code>attribute</code> is the name of an attribute in the table of attributes it assigns
to the points the values of that attribute. Otherwise it classifies the points as boolean.
TRUE if the points are in a polygon, FALSE otherwise.
</p>
</li>
<li><p><code>RasterLayer</code>, single band <code>stars</code> or single layer <code>SpatRaster</code>: it attributes to each point
the value found in each pixel of the raster.
</p>
</li>
<li><p><code>RasterStack</code>, <code>RasterBrick</code>, multibands <code>stars</code> or multilayer <code>SpatRaster</code> must have 3
layers for RGB colors. It colorizes the point cloud with RGB values.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>merge_spatial(las, source, attribute = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_spatial_+3A_las">las</code></td>
<td>
<p>An object of class <code>LAS</code></p>
</td></tr>
<tr><td><code id="merge_spatial_+3A_source">source</code></td>
<td>
<p>An object of class <code style="white-space: pre;">&#8288;SpatialPolygons*&#8288;</code> or <code>sf</code> or <code>sfc</code> or <code>RasterLayer</code> or
<code>RasterStack</code> or <code>RasterBrick</code> or <code>stars</code>.</p>
</td></tr>
<tr><td><code id="merge_spatial_+3A_attribute">attribute</code></td>
<td>
<p>character. The name of an attribute in the table of attributes or
the name of a new column in the LAS object. Not relevant for RGB colorization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>LAS</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
shp     &lt;- system.file("extdata", "lake_polygons_UTM17.shp", package = "lidR")

las   &lt;- readLAS(LASfile, filter = "-keep_random_fraction 0.1")
lakes &lt;- sf::st_read(shp, quiet = TRUE)

# The attribute "inlake" does not exist in the shapefile.
# Points are classified as TRUE if in a polygon
las    &lt;- merge_spatial(las, lakes, "inlakes")     # New attribute 'inlakes' is added.
names(las)

forest &lt;- filter_poi(las, inlakes == FALSE)
#plot(forest)

# The attribute "LAKENAME_1" exists in the shapefile.
# Points are classified with the values of the polygons
las &lt;- merge_spatial(las, lakes, "LAKENAME_1")     # New column 'LAKENAME_1' is added.
names(las)
</code></pre>

<hr>
<h2 id='noise_ivf'>Noise Segmentation Algorithm</h2><span id='topic+noise_ivf'></span><span id='topic+ivf'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+classify_noise">classify_noise</a>. It implements an
algorithm for outliers (noise) segmentation based on isolated voxels filter (IVF).
It is similar to <a href="https://rapidlasso.de/lasnoise/">lasnoise from lastools</a>.
The algorithm finds points that have only a few other points in their surrounding
3 x 3 x 3 = 27 voxels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ivf(res = 5, n = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noise_ivf_+3A_res">res</code></td>
<td>
<p>numeric. Resolution of the voxels</p>
</td></tr>
<tr><td><code id="noise_ivf_+3A_n">n</code></td>
<td>
<p>integer. The maximal number of 'other points' in the 27 voxels</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other noise segmentation algorithms: 
<code><a href="#topic+noise_sor">noise_sor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-inside 273450 5274350 273550 5274450")

# Add some artificial outliers
set.seed(314)
id = round(runif(20, 0, npoints(las)))
set.seed(42)
err = runif(20, -50, 50)
las$Z[id] = las$Z[id] + err

las &lt;- classify_noise(las, ivf(5,2))
</code></pre>

<hr>
<h2 id='noise_sor'>Noise Segmentation Algorithm</h2><span id='topic+noise_sor'></span><span id='topic+sor'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+classify_noise">classify_noise</a>. It implements an
algorithm for outliers (noise) segmentation based on Statistical Outliers
Removal (SOR) methods first described in the PCL library
and also implemented in CloudCompare (see references).
For each point, it computes the mean distance to all its k-nearest neighbours.
The points that are farther than the average distance plus a number of times
(multiplier) the standard deviation are considered noise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sor(k = 10, m = 3, quantile = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noise_sor_+3A_k">k</code></td>
<td>
<p>numeric. The number of neighbours</p>
</td></tr>
<tr><td><code id="noise_sor_+3A_m">m</code></td>
<td>
<p>numeric. Multiplier. The maximum distance will be: <code style="white-space: pre;">&#8288;avg distance + m * std deviation&#8288;</code>.
If <code>quantile = TRUE</code>, <code>m</code> becomes the quantile threshold.</p>
</td></tr>
<tr><td><code id="noise_sor_+3A_quantile">quantile</code></td>
<td>
<p>boolean. Modification of the original SOR to use a quantile
threshold instead of a standard deviation multiplier. In this case the maximum
distance will be: <code>quantile(distances, probs = m)</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>https://pointclouds.org/documentation/tutorials/statistical_outlier.html <br />
https://www.cloudcompare.org/doc/wiki/index.php?title=SOR_filter
</p>


<h3>See Also</h3>

<p>Other noise segmentation algorithms: 
<code><a href="#topic+noise_ivf">noise_ivf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-inside 273450 5274350 273550 5274450")

# Add some artificial outliers because the original
# dataset is 'clean'
set.seed(314)
id = round(runif(20, 0, npoints(las)))
set.seed(42)
err = runif(20, -50, 50)
las$Z[id] = las$Z[id] + err

las &lt;- classify_noise(las, sor(15,7))
</code></pre>

<hr>
<h2 id='normalize'>Normalize point cloud</h2><span id='topic+normalize'></span><span id='topic+normalize_height'></span><span id='topic+unnormalize_height'></span><span id='topic+-+2CLAS+2CANY-method'></span><span id='topic+normalize_intensity'></span>

<h3>Description</h3>

<p>Normalize elevation or intensity values using multiple methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize_height(las, algorithm, use_class = c(2L, 9L), dtm = NULL, ...)

unnormalize_height(las)

## S4 method for signature 'LAS,ANY'
e1 - e2

normalize_intensity(las, algorithm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="normalize_+3A_algorithm">algorithm</code></td>
<td>
<p>(1) An algorithm for spatial interpolation. <code>lidR</code> has <a href="#topic+tin">tin</a>,
<a href="#topic+kriging">kriging</a>, <a href="#topic+knnidw">knnidw</a> or a raster representing a digital terrain
model. (2) An algorithm for intensity normalization. <code>lidR</code> currently has <a href="#topic+range_correction">range_correction</a>.</p>
</td></tr>
<tr><td><code id="normalize_+3A_use_class">use_class</code></td>
<td>
<p>integer vector. By default the terrain is computed by using ground points
(class 2) and water points (class 9). Relevant only for a normalization without a raster DTM.</p>
</td></tr>
<tr><td><code id="normalize_+3A_dtm">dtm</code></td>
<td>
<p>raster. If <code>dtm</code> is provided, then the DTM is used in place of ground points. This is
different than providing a DTM in <code>algorithm</code>. If <code>algorithm = dtm</code> the dtm is subtracted naively.
If <code>algorithm = tin()</code> and <code>dtm = raster</code> the ground points are not used and the DTM is
interpolated as if it were made of regularly-spaced ground points.</p>
</td></tr>
<tr><td><code id="normalize_+3A_...">...</code></td>
<td>
<p><code>normalized_height()</code> supports <code>add_lasattribute= TRUE</code> to add the elevation above
see level as an extra byte attribute and <code> Wdegenerated = FALSE</code> to silence the warning about
degenerated ground points.</p>
</td></tr>
<tr><td><code id="normalize_+3A_e1">e1</code></td>
<td>
<p>a LAS object</p>
</td></tr>
<tr><td><code id="normalize_+3A_e2">e2</code></td>
<td>
<p>A raster representing a digital terrain model in format from <code>raster</code>, <code>stars</code> or <code>terra</code>..</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>normalize_height</dt><dd><p>Subtract digital terrain model (DTM) from a LiDAR point cloud to create a
dataset normalized with the ground at 0. The DTM can be a raster, but it can also be computed
on-the-fly. In this case the algorithm does not use rasterized data and each point is interpolated.
There is no inaccuracy due to the discretization of the terrain and the resolution of the terrain
is virtually infinite. A new attribute 'Zref' records the former elevation values, which enables
the use of <a href="#topic+unnormalize_height">unnormalize_height</a> to restore original point elevations.</p>
</dd>
<dt>normalize_intensity</dt><dd><p>Normalize intensity values using multiple methods. The attribute 'Intensity'
records the normalized intensity. An extra attribute named 'RawIntensity' records the original
intensities.</p>
</dd>
</dl>



<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected because it always preserves the file format
and all the attributes. <code>select = "*"</code> is imposed internally.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile)

# ====================
# Normalize elevation
# ====================

# First option: use a raster as DTM
# --------------------------------------

dtm &lt;- rasterize_terrain(las, 1, knnidw(k = 6L, p = 2))
nlas &lt;- normalize_height(las, dtm)

# restore original elevations
las &lt;- unnormalize_height(nlas)

# operator - can be used. This is equivalent to the previous
nlas &lt;- las - dtm

# restore original elevations
las &lt;- unnormalize_height(las)

# Second option: interpolate each point (no discretization)
# ---------------------------------------------------------

nlas &lt;- normalize_height(las, tin())

# operator - can be used. This is equivalent to the previous
las &lt;- unnormalize_height(nlas)
nlas &lt;- las - tin()

## Not run: 
# All the following syntaxes are correct
las &lt;- normalize_height(las, knnidw())
las &lt;- normalize_height(las, knnidw(k = 8, p = 2))
las &lt;- las - knnidw()
las &lt;- las - knnidw(k = 8)
las &lt;- normalize_height(las, kriging())
las &lt;- las - kriging(k = 8)

## End(Not run)

# ====================
# Normalize intensity
# ====================

# pmin = 15 because it is an extremely small file
# strongly decimated to reduce its size. There are
# actually few multiple returns
sensor &lt;- track_sensor(las, Roussel2020(pmin = 15))

# Here the effect is virtually null because the size of
# the sample is too small to notice any effect of range
las &lt;- normalize_intensity(las, range_correction(sensor, Rs = 2000))
</code></pre>

<hr>
<h2 id='nstdmetrics'>Predefined non standard metrics</h2><span id='topic+nstdmetrics'></span><span id='topic+rumple_index'></span><span id='topic+gap_fraction_profile'></span><span id='topic+LAD'></span><span id='topic+entropy'></span><span id='topic+VCI'></span>

<h3>Description</h3>

<p>Functions and metrics from the literature. See details and references
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rumple_index(x, y = NULL, z = NULL, ...)

gap_fraction_profile(z, dz = 1, z0 = 2)

LAD(z, dz = 1, k = 0.5, z0 = 2)

entropy(z, by = 1, zmax = NULL)

VCI(z, zmax, by = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nstdmetrics_+3A_x">x</code></td>
<td>
<p>A <code>RasterLayer</code>, a <code>stars</code> a <code>SpatRaster</code> or a vector of x coordinates.</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_y">y</code></td>
<td>
<p>numeric. If <code>x</code> is a vector of coordinates: the associated y coordinates.</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_z">z</code></td>
<td>
<p>vector of positive z coordinates</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_z0">z0</code></td>
<td>
<p>numeric. The bottom limit of the profile</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_k">k</code></td>
<td>
<p>numeric. is the extinction coefficient</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_by">by</code>, <code id="nstdmetrics_+3A_dz">dz</code></td>
<td>
<p>numeric. The thickness of the layers used (height bin)</p>
</td></tr>
<tr><td><code id="nstdmetrics_+3A_zmax">zmax</code></td>
<td>
<p>numeric. Maximum elevation for an entropy normalized to zmax.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>rumple_index</dt><dd><p>Computes the roughness of a surface as the ratio between its area and its
projected area on the ground. If the input is a gridded object (raster) the function computes the
surfaces using Jenness's algorithm (see references). If the input is a point cloud the function
uses a Delaunay triangulation of the points and computes the area of each triangle.</p>
</dd>
<dt>gap_fraction_profile</dt><dd><p>Computes the gap fraction profile using the method of Bouvier et al.
(see reference). The function assesses the number of laser points that actually reached the layer
z+dz and those that passed through the layer [z, z+dz]. By definition the layer 0
will always return 0 because no returns pass through the ground. Therefore, the layer 0 is removed
from the returned results.</p>
</dd>
<dt>LAD</dt><dd><p>Computes a leaf area density profile based on the method of Bouvier et al. (see reference)
The function assesses the number of laser points that actually reached the layer z+dz and those that
passed through the layer [z, z+dz] (see <a href="#topic+gap_fraction_profile">gap_fraction_profile</a>).
Then it computes the log of this quantity and divides it by the extinction coefficient k as
described in Bouvier et al. By definition the layer 0 will always return infinity because no returns
pass through the ground. Therefore, the layer 0 is removed from the returned results.</p>
</dd>
<dt>entropy</dt><dd><p>A normalized Shannon vertical complexity index. The Shannon diversity index is a
measure for quantifying diversity and is based on the number and frequency of species present. This index,
developed by Shannon and Weaver for use in information theory, was successfully transferred
to the description of species diversity in biological systems (Shannon 1948). Here it is applied
to quantify the diversity and the evenness of an elevational distribution of las points. It
makes bins between 0 and the maximum elevation. If there are negative values the function
returns NA.</p>
</dd>
<dt>VCI</dt><dd><p>Vertical Complexity Index. A fixed normalization of the entropy function from van Ewijk
et al. (2011) (see references)</p>
</dd>
</dl>



<h3>Value</h3>

<p>numeric. The computed Rumple index.
</p>
<p>A data.frame containing the bin elevations (z) and the gap fraction for each bin (gf)
</p>
<p>A number between 0 and 1
</p>
<p>A number between 0 and 1
</p>


<h3>References</h3>

<p>Jenness, J. S. (2004). Calculating landscape surface area from digital elevation
models. Wildlife Society Bulletin, 32(3), 829–839.
</p>
<p>Bouvier, M., Durrieu, S., Fournier, R. a, &amp; Renaud, J. (2015).  Generalizing predictive
models of forest inventory attributes using an area-based approach with airborne las data. Remote
Sensing of Environment, 156, 322-334. http://doi.org/10.1016/j.rse.2014.10.004
</p>
<p>Pretzsch, H. (2008). Description and Analysis of Stand Structures. Springer Berlin Heidelberg. http://doi.org/10.1007/978-3-540-88307-4 (pages 279-280)
Shannon, Claude E. (1948), &quot;A mathematical theory of communication,&quot; Bell System Tech. Journal 27, 379-423, 623-656.
</p>
<p>van Ewijk, K. Y., Treitz, P. M., &amp; Scott, N. A. (2011). Characterizing Forest Succession in Central Ontario using LAS-derived Indices. Photogrammetric Engineering and Remote Sensing, 77(3), 261-269. Retrieved from &lt;Go to ISI&gt;://WOS:000288052100009
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(20, 0, 100)
y &lt;- runif(20, 0, 100)

# Perfectly flat surface, rumple_index = 1
z &lt;- rep(10, 20)
rumple_index(x, y, z)

# Rough surface, rumple_index &gt; 1
z &lt;- runif(20, 0, 10)
rumple_index(x, y, z)

# Rougher surface, rumple_index increases
z &lt;- runif(20, 0, 50)
rumple_index(x, y, z)

# Measure of roughness is scale-dependent
rumple_index(x, y, z)
rumple_index(x/10, y/10, z)
z &lt;- c(rnorm(1e4, 25, 6), rgamma(1e3, 1, 8)*6, rgamma(5e2, 5,5)*10)
z &lt;- z[z&lt;45 &amp; z&gt;0]

hist(z, n=50)

gapFraction = gap_fraction_profile(z)

plot(gapFraction, type="l", xlab="Elevation", ylab="Gap fraction")
z &lt;- c(rnorm(1e4, 25, 6), rgamma(1e3, 1, 8)*6, rgamma(5e2, 5,5)*10)
z &lt;- z[z&lt;45 &amp; z&gt;0]

lad &lt;- LAD(z)

plot(lad, type="l", xlab="Elevation", ylab="Leaf area density")
z &lt;- runif(10000, 0, 10)

# expected to be close to 1. The highest diversity is given for a uniform distribution
entropy(z, by = 1)

 z &lt;- runif(10000, 9, 10)

# Must be 0. The lowest diversity is given for a unique possibility
entropy(z, by = 1)

z &lt;- abs(rnorm(10000, 10, 1))

# expected to be between 0 and 1.
entropy(z, by = 1)
z &lt;- runif(10000, 0, 10)

VCI(z, by = 1, zmax = 20)

z &lt;- abs(rnorm(10000, 10, 1))

# expected to be closer to 0.
VCI(z, by = 1, zmax = 20)
</code></pre>

<hr>
<h2 id='old_spatial_packages'>Older R Spatial Packages</h2><span id='topic+old_spatial_packages'></span><span id='topic+as.spatial'></span><span id='topic+as.spatial.LAS'></span><span id='topic+as.spatial.LAScatalog'></span><span id='topic+tree_metrics'></span><span id='topic+grid_canopy'></span><span id='topic+grid_density'></span><span id='topic+grid_terrain'></span><span id='topic+grid_metrics'></span><span id='topic+find_trees'></span><span id='topic+delineate_crowns'></span>

<h3>Description</h3>

<p>lidR 4.0.0 no longer uses the <code>sp</code> and <code>raster</code> packages. New functions are based on <code>sf</code>, <code>terra</code> and <code>stars</code>.
However, to maintain backward compatibility the old functions from v&lt;4.0.0 were preserved.<br /><br />
<code>rgdal</code> and <code>rgeos</code> will be retired on Jan 1st 2024. The <code>raster</code> and <code>sp</code> packages are based on
<code>rgdal</code> and <code>rgeos</code>. <code>lidR</code> was based on <code>raster</code> and <code>sp</code> because it was created before the <code>sf</code>, <code>terra</code>
and <code>stars</code> packages. This means that sooner or later users and packages that are still based on
old R spatial packages will run into trouble. According to Edzer Pebesma, Roger Bivand: <br /><br />
<em>R users who have been around a bit longer, in particular before packages like <code>sf</code> and <code>stars</code> were
developed, may be more familiar with older packages like <code>maptools</code>, <code>sp</code>, <code>rgeos</code>, and <code>rgdal</code>. A fair
question is whether they should migrate existing code and/or existing R packages depending on these
packages. The answer is: yes (see reference).</em><br /><br />
The following functions are not formally deprecated but users should definitely move their workflow to modern
spatial packages. lidR will maintain the old functions as long as it does not generate issues
on CRAN. So, it might be until Jan 1st 2024 or later, who knows...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.spatial(x)

## S3 method for class 'LAS'
as.spatial(x)

## S3 method for class 'LAScatalog'
as.spatial(x)

tree_metrics(las, func = ~list(Z = max(Z)), attribute = "treeID", ...)

grid_canopy(las, res, algorithm)

grid_density(las, res = 4)

grid_terrain(
  las,
  res = 1,
  algorithm,
  ...,
  keep_lowest = FALSE,
  full_raster = FALSE,
  use_class = c(2L, 9L),
  Wdegenerated = TRUE,
  is_concave = FALSE
)

grid_metrics(
  las,
  func,
  res = 20,
  start = c(0, 0),
  filter = NULL,
  by_echo = "all"
)

find_trees(las, algorithm, uniqueness = "incremental")

delineate_crowns(
  las,
  type = c("convex", "concave", "bbox"),
  concavity = 3,
  length_threshold = 0,
  func = NULL,
  attribute = "treeID"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="old_spatial_packages_+3A_x">x</code>, <code id="old_spatial_packages_+3A_las">las</code></td>
<td>
<p>an object of class LAS*</p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_func">func</code></td>
<td>
<p>see <a href="#topic+template_metrics">template_metrics</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_attribute">attribute</code>, <code id="old_spatial_packages_+3A_type">type</code></td>
<td>
<p>see <a href="#topic+crown_metrics">crown_metrics</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_res">res</code>, <code id="old_spatial_packages_+3A_start">start</code></td>
<td>
<p>see <a href="#topic+pixel_metrics">pixel_metrics</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_algorithm">algorithm</code></td>
<td>
<p>see <a href="#topic+rasterize_canopy">rasterize_canopy</a>, <a href="#topic+rasterize_terrain">rasterize_terrain</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_full_raster">full_raster</code>, <code id="old_spatial_packages_+3A_use_class">use_class</code>, <code id="old_spatial_packages_+3A_wdegenerated">Wdegenerated</code>, <code id="old_spatial_packages_+3A_is_concave">is_concave</code>, <code id="old_spatial_packages_+3A_keep_lowest">keep_lowest</code></td>
<td>
<p>see <a href="#topic+rasterize_density">rasterize_density</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_filter">filter</code>, <code id="old_spatial_packages_+3A_by_echo">by_echo</code></td>
<td>
<p>see <a href="#topic+template_metrics">template_metrics</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_uniqueness">uniqueness</code></td>
<td>
<p>see <a href="#topic+crown_metrics">crown_metrics</a></p>
</td></tr>
<tr><td><code id="old_spatial_packages_+3A_concavity">concavity</code>, <code id="old_spatial_packages_+3A_length_threshold">length_threshold</code></td>
<td>
<p>see <a href="#topic+concaveman">concaveman</a></p>
</td></tr>
</table>


<h3>References</h3>

<p>Edzer Pebesma, Roger Bivand Spatial Data Science with applications in R
https://keen-swartz-3146c4.netlify.app/older.html
</p>

<hr>
<h2 id='pitfill_stonge2008'>Pits and spikes filling</h2><span id='topic+pitfill_stonge2008'></span>

<h3>Description</h3>

<p>Pits and spikes filling for raster. Typically used for post-processing CHM. This algorithm
is from St-Onge 2008 (see reference).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pitfill_stonge2008(
  x,
  lap_size = 3L,
  thr_lap = 0.1,
  thr_spk = -0.1,
  med_size = 3L,
  dil_radius = 0L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pitfill_stonge2008_+3A_x">x</code></td>
<td>
<p>raster. SpatRaster, RasterLayer, stars.</p>
</td></tr>
<tr><td><code id="pitfill_stonge2008_+3A_lap_size">lap_size</code></td>
<td>
<p>integer. Size of the Laplacian filter kernel (integer value, in pixels).</p>
</td></tr>
<tr><td><code id="pitfill_stonge2008_+3A_thr_lap">thr_lap</code></td>
<td>
<p>numeric. Threshold Laplacian value for detecting a cavity (all values above this
value will be considered a cavity). A positive value.</p>
</td></tr>
<tr><td><code id="pitfill_stonge2008_+3A_thr_spk">thr_spk</code></td>
<td>
<p>numeric. Threshold Laplacian value for detecting a spike (all values below this
value will be considered a spike). A negative value.</p>
</td></tr>
<tr><td><code id="pitfill_stonge2008_+3A_med_size">med_size</code></td>
<td>
<p>integer. Size of the median filter kernel (integer value, in pixels).</p>
</td></tr>
<tr><td><code id="pitfill_stonge2008_+3A_dil_radius">dil_radius</code></td>
<td>
<p>integer. Dilation radius (integer value, in pixels).</p>
</td></tr>
</table>


<h3>References</h3>

<p>St-Onge, B., 2008. Methods for improving the quality of a true orthomosaic of Vexcel UltraCam
images created using alidar digital surface model, Proceedings of the Silvilaser 2008, Edinburgh,
555-562. https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=81365288221f3ac34b51a82e2cfed8d58defb10e
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile)
chm &lt;- rasterize_canopy(las, 0.5, dsmtin())
sto &lt;- pitfill_stonge2008(chm)

#terra::plot(c(chm, sto), col = lidR::height.colors(25))
</code></pre>

<hr>
<h2 id='plot'>Plot a LAS* object</h2><span id='topic+plot'></span><span id='topic+plot+2CLAS+2Cmissing-method'></span><span id='topic+plot+2CLAScatalog+2Cmissing-method'></span><span id='topic+plot+2CLASheader+2Cmissing-method'></span><span id='topic+height.colors'></span><span id='topic+forest.colors'></span><span id='topic+random.colors'></span><span id='topic+pastel.colors'></span>

<h3>Description</h3>

<p>Plot displays a 3D interactive windows based on rgl for <a href="#topic+LAS">LAS</a> objects<br /><br />
Plot displays an interactive view for <a href="#topic+LAScatalog-class">LAScatalog</a> objects with pan and
zoom capabilities based on <a href="mapview.html#topic+mapview-package">mapview</a>. If the coordinate reference
system (CRS) of the <code>LAScatalog</code> is non empty, the plot can be displayed on top of base maps
(satellite data, elevation, street, and so on).<br /><br />
Plot displays a <a href="#topic+LASheader-class">LASheader</a> object exactly like it displays a LAScatalog
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(x, y, ...)

## S4 method for signature 'LAS,missing'
plot(
  x,
  y,
  ...,
  color = "Z",
  pal = "auto",
  bg = "black",
  breaks = "pretty",
  nbreaks = "auto",
  backend = "rgl",
  clear_artifacts = TRUE,
  axis = FALSE,
  legend = FALSE,
  add = FALSE,
  voxel = FALSE,
  NAcol = "lightgray",
  mapview = FALSE
)

## S4 method for signature 'LAScatalog,missing'
plot(x, y, mapview = FALSE, chunk_pattern = FALSE, overlaps = FALSE, ...)

## S4 method for signature 'LASheader,missing'
plot(x, y, mapview = FALSE, ...)

height.colors(n)

forest.colors(n)

random.colors(n)

pastel.colors(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>A <code>LAS*</code> object</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>Unused (inherited from R base)</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>Will be passed to <a href="rgl.html#topic+3dobjects">points3d</a> (LAS) or <a href="graphics.html#topic+plot.default">plot</a>
if <code>mapview = FALSE</code> or to <a href="mapview.html#topic+mapView">mapview</a> if <code>mapview = TRUE</code> (LAScatalog).</p>
</td></tr>
<tr><td><code id="plot_+3A_color">color</code></td>
<td>
<p>characters. The attribute used to color the point cloud. Default is Z coordinates. RGB
is an allowed string even if it refers to three attributes simultaneously.</p>
</td></tr>
<tr><td><code id="plot_+3A_pal">pal</code></td>
<td>
<p>palette function, similar to heat.colors, or palette values. Default is <code>"auto"</code>
providing an automatic coloring depending on the attribute <code>color</code></p>
</td></tr>
<tr><td><code id="plot_+3A_bg">bg</code></td>
<td>
<p>The color for the background. Default is black.</p>
</td></tr>
<tr><td><code id="plot_+3A_breaks">breaks</code></td>
<td>
<p>either a numeric vector with the actual breaks, or a name of a method accepted
by the style argument of <a href="classInt.html#topic+classIntervals">classIntervals</a></p>
</td></tr>
<tr><td><code id="plot_+3A_nbreaks">nbreaks</code></td>
<td>
<p>Number of colors breaks.</p>
</td></tr>
<tr><td><code id="plot_+3A_backend">backend</code></td>
<td>
<p>character. Can be <code>"rgl"</code> or <code>"lidRviewer"</code>. If <code>"rgl"</code> is chosen
the display relies on the <code>rgl</code> package. If <code>"lidRviewer"</code> is chosen it relies on the
<code>lidRviewer</code> package, which is much more efficient and can handle million of points
using less memory. <code>lidRviewer</code> is not available on CRAN yet and should
be installed from github (see. <a href="https://github.com/Jean-Romain/lidRviewer">https://github.com/Jean-Romain/lidRviewer</a>).</p>
</td></tr>
<tr><td><code id="plot_+3A_clear_artifacts">clear_artifacts</code></td>
<td>
<p>logical. It is a known and documented issue that the 3D visualisation with
<code>rgl</code> displays artifacts. The points look aligned and/or regularly spaced in some view angles.
This is because <code>rgl</code> computes with single precision <code>float</code>. To fix that the point
cloud is shifted to (0,0) to reduce the number of digits needed to represent its coordinates.
The drawback is that the point cloud is not plotted at its actual coordinates.</p>
</td></tr>
<tr><td><code id="plot_+3A_axis">axis</code></td>
<td>
<p>logical. Display axis on XYZ coordinates.</p>
</td></tr>
<tr><td><code id="plot_+3A_legend">legend</code></td>
<td>
<p>logical. Display a gradient colour legend.</p>
</td></tr>
<tr><td><code id="plot_+3A_add">add</code></td>
<td>
<p>If <code>FALSE</code> normal behaviour otherwise must be the output of a prior plot function
to enable the alignment of a second point cloud.</p>
</td></tr>
<tr><td><code id="plot_+3A_voxel">voxel</code></td>
<td>
<p>boolean or numeric. Displays voxels instead of points. Useful to render the output
of <a href="#topic+voxelize_points">voxelize_points</a>, for example. However it is computationally demanding to render and can
easily take 15 seconds for 10000 voxels. It should be reserved for small scenes. If boolean the voxel
resolution is guessed automatically. Otherwise users can provide the size of the voxels. To reduce the rendering time,
an internal optimization removes voxels that are not visible when surrounded by other voxels.</p>
</td></tr>
<tr><td><code id="plot_+3A_nacol">NAcol</code></td>
<td>
<p>a color for NA values.</p>
</td></tr>
<tr><td><code id="plot_+3A_mapview">mapview</code></td>
<td>
<p>logical. If <code>FALSE</code> the catalog is displayed in a regular plot from R base.
Since v4.0.4 'mapview = TRUE' is also possible with LAS objects.</p>
</td></tr>
<tr><td><code id="plot_+3A_chunk_pattern">chunk_pattern</code></td>
<td>
<p>logical. Display the current chunk pattern used to process the catalog.</p>
</td></tr>
<tr><td><code id="plot_+3A_overlaps">overlaps</code></td>
<td>
<p>logical. Highlight the overlaps between files.</p>
</td></tr>
<tr><td><code id="plot_+3A_n">n</code></td>
<td>
<p>The number of colors (&gt; 1) to be in the palette</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile)

plot(las)
plot(las, color = "Intensity")
plot(las, color = "ScanAngleRank", pal = rainbow)

# If outliers break the color range, use the breaks parameter
las$Intensity[150] &lt;- 1000L
plot(las, color = "Intensity")
plot(las, color = "Intensity", breaks = "quantile", nbreaks = 50)

plot(las, color = "Classification")

# This dataset is already tree segmented
plot(las, color = "treeID")
plot(las, color = "treeID", pal = random.colors)


# single file LAScatalog using data provided in lidR
ctg = readLAScatalog(LASfile)
plot(ctg)
plot(ctg, map = T, map.types = "Esri.WorldImagery")

## End(Not run)

</code></pre>

<hr>
<h2 id='plot_3d'>Add a spatial object to a point cloud scene</h2><span id='topic+plot_3d'></span><span id='topic+plot_dtm3d'></span><span id='topic+add_dtm3d'></span><span id='topic+add_treetops3d'></span><span id='topic+add_flightlines3d'></span>

<h3>Description</h3>

<p>Add a raster ('raster', 'stars' 'terra') object that represents a digital terrain model or a
'SpatialPointsDataFrame' or 'sf' that represents tree tops to a point cloud scene. To add elements
to a scene with a point cloud plotted with the function plot from lidR, the functions 'add_*'
take as first argument the output of the plot function (see examples), because the plot function
does not plot the actual coordinates of the point cloud, but offset values. See function
<a href="#topic+plot">plot</a> and its argument 'clear_artifacts' for more details. It works only
with 'rgl' i.e. 'backend = &quot;rgl&quot;' which is the default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_dtm3d(dtm, bg = "black", clear_artifacts = TRUE, ...)

add_dtm3d(x, dtm, ...)

add_treetops3d(x, ttops, z = "Z", ...)

add_flightlines3d(x, flightlines, z = "Z", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_3d_+3A_dtm">dtm</code></td>
<td>
<p>An object of the class 'RasterLayer' or 'stars' or 'SpatRaster'</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_bg">bg</code></td>
<td>
<p>The color for the background. Default is black.</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_clear_artifacts">clear_artifacts</code></td>
<td>
<p>logical. It is a known and documented issue that 3D visualisation with
<code>rgl</code> displays artifacts. The points and lines are inaccurately positioned in the space and thus
the rendering may look false or weird. This is because 'rgl' computes with single precision 'float'.
To fix this, the objects are shifted to (0,0) to reduce the number of digits needed to represent
their coordinates. The drawback is that the objects are not plotted at their actual coordinates.</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_...">...</code></td>
<td>
<p>Supplementary parameters for <a href="rgl.html#topic+surface3d">surface3d</a> or
<a href="rgl.html#topic+spheres">spheres3d</a>.</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_x">x</code></td>
<td>
<p>The output of the function plot used with a LAS object.</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_ttops">ttops</code></td>
<td>
<p>A 'SpatialPointsDataFrame' or 'sf/sfc' that contains tree tops coordinates.</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_z">z</code></td>
<td>
<p>character. The name of the attribute that contains the height of the tree tops or of the
flightlines. Only for XY geometries Ignored if the input have XYZ geometries</p>
</td></tr>
<tr><td><code id="plot_3d_+3A_flightlines">flightlines</code></td>
<td>
<p>A 'SpatialPointsDataFrame' or 'sf' that contains flightlines coordinates.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile)

dtm &lt;- rasterize_terrain(las, algorithm = tin())
ttops &lt;- locate_trees(las, lmf(ws = 5))

plot_dtm3d(dtm)

x &lt;- plot(las)
add_dtm3d(x, dtm)
add_treetops3d(x, ttops)

plot(las) |&gt; add_dtm3d(dtm) |&gt; add_treetops3d(ttops)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.lasmetrics3d'>Plot voxelized LiDAR data</h2><span id='topic+plot.lasmetrics3d'></span>

<h3>Description</h3>

<p>This function implements a 3D plot method for 'lasmetrics3d' objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lasmetrics3d'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lasmetrics3d_+3A_x">x</code></td>
<td>
<p>An object of the class <code>lasmetrics3d</code></p>
</td></tr>
<tr><td><code id="plot.lasmetrics3d_+3A_y">y</code></td>
<td>
<p>Unused (inherited from R base)</p>
</td></tr>
<tr><td><code id="plot.lasmetrics3d_+3A_...">...</code></td>
<td>
<p>Supplementary parameters for <a href="#topic+plot">plot</a>. The function internally uses the
same plot function than LAS objects.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
lidar = readLAS(LASfile)

voxels = voxel_metrics(lidar, list(Imean = mean(Intensity)), res = 5)
plot(voxels, color = "Imean", colorPalette = heat.colors(50), trim=60)

## End(Not run)
</code></pre>

<hr>
<h2 id='plugins'>Plugin system</h2><span id='topic+plugins'></span><span id='topic+plugin_dsm'></span><span id='topic+plugin_dtm'></span><span id='topic+plugin_gnd'></span><span id='topic+plugin_decimate'></span><span id='topic+plugin_shape'></span><span id='topic+plugin_snag'></span><span id='topic+plugin_track'></span><span id='topic+plugin_nintensity'></span><span id='topic+plugin_outliers'></span><span id='topic+plugin_itd'></span><span id='topic+plugin_its'></span>

<h3>Description</h3>

<p>Tools to build plugin functions for lidR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plugin_dsm(f, omp = FALSE)

plugin_dtm(f, omp = FALSE)

plugin_gnd(f, omp = FALSE)

plugin_decimate(f, omp = FALSE)

plugin_shape(f, omp = FALSE)

plugin_snag(f, omp = FALSE)

plugin_track(f, omp = FALSE)

plugin_nintensity(f, omp = FALSE)

plugin_outliers(f, omp = FALSE)

plugin_itd(f, omp = FALSE, raster_based = FALSE)

plugin_its(f, omp = FALSE, raster_based = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plugins_+3A_f">f</code></td>
<td>
<p>a function</p>
</td></tr>
<tr><td><code id="plugins_+3A_omp">omp</code></td>
<td>
<p>logical is the function natively parallized with OpenMP</p>
</td></tr>
<tr><td><code id="plugins_+3A_raster_based">raster_based</code></td>
<td>
<p>logical. For ITS and ITD algorithms, is the method raster-based or
or point-cloud-based?</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mba &lt;- function(n = 1, m = 1, h = 8, extend = TRUE) {
  f &lt;- function(las, where) {
    res &lt;- MBA::mba.points(las@data, where, n, m , h, extend)
    return(res$xyz.est[,3])
  }

  f &lt;- plugin_dtm(f)
  return(f)
}

LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)

dtm = rasterize_terrain(las, algorithm = mba())

## End(Not run)
</code></pre>

<hr>
<h2 id='point_metrics'>Point-based metrics</h2><span id='topic+point_metrics'></span><span id='topic+point_eigenvalues'></span>

<h3>Description</h3>

<p>Computes a series of user-defined descriptive statistics for a LiDAR dataset for each point based
on its k-nearest neighbours or its sphere neighbourhood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>point_metrics(las, func, k, r, xyz = FALSE, filter = NULL, ...)

point_eigenvalues(
  las,
  k,
  r,
  xyz = FALSE,
  metrics = FALSE,
  coeffs = FALSE,
  filter = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="point_metrics_+3A_las">las</code></td>
<td>
<p>An object of class LAS</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_func">func</code></td>
<td>
<p>formula. An expression to be applied to each point neighbourhood (see also
<a href="#topic+template_metrics">template_metrics</a>).</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_k">k</code>, <code id="point_metrics_+3A_r">r</code></td>
<td>
<p>integer and numeric respectively for k-nearest neighbours and radius of the neighborhood
sphere. If k is given and r is missing, computes with the knn, if r is given and k is missing
computes with a sphere neighborhood, if k and r are given computes with the knn and a limit on the
search distance.</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_xyz">xyz</code></td>
<td>
<p>logical. Coordinates of each point are returned in addition to each metric. Otherwise an
ID referring to each point.</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_filter">filter</code></td>
<td>
<p>formula of logical predicates. Enables the function to run only on points of interest
in an optimized way. See examples.</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_metrics">metrics</code></td>
<td>
<p>logical. Compute metrics or not</p>
</td></tr>
<tr><td><code id="point_metrics_+3A_coeffs">coeffs</code></td>
<td>
<p>logical. Principal component coefficients are returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the neighbourhood is knn the user-defined function is fed with the current
processed point and its k-1 neighbours. The current point being considered as
the 1-neighbour with a distance 0 to the reference point. The points are ordered
by distance to the central point. When the neighbourhood is a sphere the processed
point is also included in the query but points are coming in a random order. <code>point_eigenmetrics</code>
computes the eigenvalues of the covariance matrix and computes associated metrics following
Lucas et al, 2019 (see references). It is equivalent to <code>point_metrics(las, .stdshapemetrics)</code>
but much faster because it is optimized and parallelized internally.
</p>


<h3>Performances</h3>

<p>It is important to bear in mind that this function is very fast for the feature it provides i.e.
mapping a user-defined function at the point level using optimized memory management. However, it
is still computationally demanding.<br /><br />
To help users to get an idea of how computationally demanding this function is, let's compare it to
<a href="#topic+pixel_metrics">pixel_metrics</a>. Assuming we want to apply <code>mean(Z)</code> on a 1 km² tile with 1 point/m²
with a resolution of 20 m (400 m² cells), then the function <code>mean</code> is called roughly 2500
times (once  per cell). On the contrary, with <code>point_metrics</code>, <code>mean</code> is called 1000000
times (once per point). So the function is expected to be more than 400 times slower in this specific
case (but it does not provide the same feature).<br /><br />
This is why the user-defined function is expected to be well-optimized, otherwise it might drastically
slow down this already heavy computation. See examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")

# Read only 0.5 points/m^2 for the purposes of this example
las = readLAS(LASfile, filter = "-thin_with_grid 2")

# Computes the eigenvalues of the covariance matrix of the neighbouring
# points and applies a test on these values. This function simulates the
# 'shp_plane()' algorithm from 'segment_shape()'
plane_metrics1 = function(x,y,z, th1 = 25, th2 = 6) {
  xyz &lt;- cbind(x,y,z)
  cov_m &lt;- cov(xyz)
  eigen_m &lt;- eigen(cov_m)$value
  is_planar &lt;- eigen_m[2] &gt; (th1*eigen_m[3]) &amp;&amp; (th2*eigen_m[2]) &gt; eigen_m[1]
  return(list(planar = is_planar))
}

# Apply a user-defined function
M &lt;- point_metrics(las, ~plane_metrics1(X,Y,Z), k = 25)
#&gt; Computed in 6.3 seconds

# We can verify that it returns the same as 'shp_plane'
las &lt;- segment_shapes(las, shp_plane(k = 25), "planar")
#&gt; Computed in 0.1 seconds

all.equal(M$planar, las$planar)

# At this stage we can be clever and find that the bottleneck is
# the eigenvalue computation. Let's write a C++ version of it with
# Rcpp and RcppArmadillo
Rcpp::sourceCpp(code = "
#include &lt;RcppArmadillo.h&gt;
// [[Rcpp::depends(RcppArmadillo)]]

// [[Rcpp::export]]
SEXP eigen_values(arma::mat A) {
arma::mat coeff;
arma::mat score;
arma::vec latent;
arma::princomp(coeff, score, latent, A);
return(Rcpp::wrap(latent));
}")

plane_metrics2 = function(x,y,z, th1 = 25, th2 = 6) {
  xyz &lt;- cbind(x,y,z)
  eigen_m &lt;- eigen_values(xyz)
  is_planar &lt;- eigen_m[2] &gt; (th1*eigen_m[3]) &amp;&amp; (th2*eigen_m[2]) &gt; eigen_m[1]
  return(list(planar = is_planar))
}

M &lt;- point_metrics(las, ~plane_metrics2(X,Y,Z), k = 25)
#&gt; Computed in 0.5 seconds

all.equal(M$planar, las$planar)
# Here we can see that the optimized version is way better but is still 5-times slower
# because of the overhead of calling R functions and switching back and forth from R to C++.

M &lt;- point_eigenvalues(las, k = 25)
is_planar = M$eigen_medium &gt; (25*M$eigen_smallest) &amp; (6*M$eigen_medium) &gt; M$eigen_largest

# Use the filter argument to process only first returns
M1 &lt;- point_metrics(las, ~plane_metrics2(X,Y,Z), k = 25, filter = ~ReturnNumber == 1)
dim(M1) # 13894 instead of 17182 previously.

## End(Not run)
</code></pre>

<hr>
<h2 id='print.LAS'>Tools inherited from base R for LAS* objects</h2><span id='topic+print.LAS'></span><span id='topic+print.LAScatalog'></span><span id='topic+print.lidRAlgorithm'></span><span id='topic+print.raster_template'></span><span id='topic+summary.LAS'></span><span id='topic+summary.LAScatalog'></span><span id='topic+tools'></span><span id='topic+dim.LAS'></span><span id='topic+dim.LAScatalog'></span><span id='topic+ncol.LAS'></span><span id='topic+nrow.LAScatalog'></span><span id='topic+names.LAS'></span><span id='topic+names.LASheader'></span><span id='topic+rbind.LAS'></span><span id='topic+npoints'></span><span id='topic+density'></span><span id='topic+density+2CLAS-method'></span><span id='topic+density+2CLASheader-method'></span><span id='topic+density+2CLAScatalog-method'></span>

<h3>Description</h3>

<p>Tools inherited from base R for LAS* objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
print(x, ...)

## S3 method for class 'LAScatalog'
print(x, ...)

## S3 method for class 'lidRAlgorithm'
print(x, ...)

## S3 method for class 'raster_template'
print(x, ...)

## S3 method for class 'LAS'
summary(object, ...)

## S3 method for class 'LAScatalog'
summary(object, ...)

## S3 method for class 'LAS'
dim(x)

## S3 method for class 'LAScatalog'
dim(x)

ncol.LAS(x)

nrow.LAScatalog(x)

## S3 method for class 'LAS'
names(x)

## S3 method for class 'LASheader'
names(x)

## S3 method for class 'LAS'
rbind(...)

npoints(x, ...)

density(x, ...)

## S4 method for signature 'LAS'
density(x, ...)

## S4 method for signature 'LASheader'
density(x, ...)

## S4 method for signature 'LAScatalog'
density(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LAS_+3A_x">x</code></td>
<td>
<p>a LAS* object</p>
</td></tr>
<tr><td><code id="print.LAS_+3A_...">...</code></td>
<td>
<p>LAS* objects if it is the sole argurment (e.g. in rbind())</p>
</td></tr>
<tr><td><code id="print.LAS_+3A_object">object</code></td>
<td>
<p>A <code>LAS*</code> object or other lidR related objects.</p>
</td></tr>
</table>

<hr>
<h2 id='range_correction'>Intensity normalization algorithm</h2><span id='topic+range_correction'></span><span id='topic+get_range'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+normalize_intensity">normalize_intensity</a>. It corrects intensity with a
range correction according to the formula (see references):
</p>
<p style="text-align: center;"><code class="reqn">I_{norm} = I_{obs} \left(\frac{R}{Rs}\right)^f</code>
</p>

<p>To achieve the range correction the position of the sensor must be known at different discrete times.
Using the 'gpstime' of each point, the position of the sensor is interpolated from the reference
and a range correction is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>range_correction(sensor, Rs, f = 2.3, gpstime = "gpstime", elevation = "Z")

get_range(las, sensor, gpstime = "gpstime", elevation = "Z")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="range_correction_+3A_sensor">sensor</code></td>
<td>
<p>'SpatialPointsDataDrame' or 'sf' object containing the coordinates of
the sensor at different timepoints t. The time and elevation are stored as attributes
(default names are 'gpstime' and 'Z'). Z can also come from the geometry if the input records XYZ
coordinates. It can be computed with <a href="#topic+track_sensor">track_sensor</a>.</p>
</td></tr>
<tr><td><code id="range_correction_+3A_rs">Rs</code></td>
<td>
<p>numeric. Range of reference.</p>
</td></tr>
<tr><td><code id="range_correction_+3A_f">f</code></td>
<td>
<p>numeric. Exponent. Usually between 2 and 3 in vegetation contexts.</p>
</td></tr>
<tr><td><code id="range_correction_+3A_gpstime">gpstime</code>, <code id="range_correction_+3A_elevation">elevation</code></td>
<td>
<p>character. The name of the attributes that store the gpstime of the
position and the elevation of the sensor respectively. If the input contains 3 coordinates points,
'elevation' is not considered.</p>
</td></tr>
<tr><td><code id="range_correction_+3A_las">las</code></td>
<td>
<p>an object of class LAS. <code>get_range()</code> is a regular function documented here for
convenience.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gatziolis, D. (2011). Dynamic Range-based Intensity Normalization for Airborne, Discrete Return
Lidar Data of Forest Canopies. Photogrammetric Engineering &amp; Remote Sensing, 77(3), 251–259.
https://doi.org/10.14358/pers.77.3.251
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A valid file properly populated
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las &lt;- readLAS(LASfile)

# pmin = 15 because it is an extremely tiny file
# strongly decimated to reduce its size. There are
# actually few multiple returns
sensor &lt;- track_sensor(las, Roussel2020(pmin = 15))

# Here the effect is virtually null because the size of
# the sample is too small to notice any effect of range
las &lt;- normalize_intensity(las, range_correction(sensor, Rs = 2000))

# This might be useful for some applications
R = get_range(las, sensor)
</code></pre>

<hr>
<h2 id='rasterize'>Rasterize a point cloud</h2><span id='topic+rasterize'></span><span id='topic+rasterize_canopy'></span><span id='topic+rasterize_density'></span><span id='topic+rasterize_terrain'></span>

<h3>Description</h3>

<p>Rasterize a point cloud in different ways to compute a DTM, a CHM or a density map. Most
raster products can be computed with <a href="#topic+pixel_metrics">pixel_metrics</a> but some are more complex and require
dedicated and optimized functions. See Details and Examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rasterize_canopy(las, res = 1, algorithm = p2r(), ...)

rasterize_density(las, res = 4, ...)

rasterize_terrain(
  las,
  res = 1,
  algorithm = tin(),
  use_class = c(2L, 9L),
  shape = "convex",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rasterize_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="rasterize_+3A_res">res</code></td>
<td>
<p>numeric. The size of a grid cell in point cloud coordinates units. Can also be
<code>RasterLayer</code> or a <code>stars</code> or a <code>SpatRaster</code> used as layout.</p>
</td></tr>
<tr><td><code id="rasterize_+3A_algorithm">algorithm</code></td>
<td>
<p>function. A function that implements an algorithm to compute a digital surface model
or a digital terrain model. <code>lidR</code> implements <a href="#topic+p2r">p2r</a>, <a href="#topic+dsmtin">dsmtin</a>, <a href="#topic+pitfree">pitfree</a>
for digital surface models, and <a href="#topic+knnidw">knnidw</a>, <a href="#topic+tin">tin</a>, and <a href="#topic+kriging">kriging</a> for digital terrain
models (see respective documentation and examples).</p>
</td></tr>
<tr><td><code id="rasterize_+3A_...">...</code></td>
<td>
<p>Use <code>pkg = "terra|raster|stars"</code> to get an output in <code>SpatRaster</code>, <code>RasterLayer</code>
or <code>stars</code> format. Default is <code>getOption("lidR.raster.default")</code>.</p>
</td></tr>
<tr><td><code id="rasterize_+3A_use_class">use_class</code></td>
<td>
<p>integer vector. By default the terrain is computed by using ground points
(class 2) and water points (class 9).</p>
</td></tr>
<tr><td><code id="rasterize_+3A_shape">shape</code></td>
<td>
<p>By default the interpolation is made only within the <code>"convex"</code> hull of
the point cloud to get a DTM with the shape of the point cloud. This prevents meaningless
interpolations where there is no data. It can also be <code>"concave"</code> or <code>"bbox"</code>. It can also be an <code>sfc</code>
to define a polygon in which to perform the interpolation.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>rasterize_terrain</code></dt><dd><p>Interpolates the ground points and creates a rasterized
digital terrain model. The algorithm uses the points classified as &quot;ground&quot; and &quot;water&quot;
(Classification = 2 and 9, respectively, according to
<a href="https://www.asprs.org/wp-content/uploads/2019/07/LAS_1_4_r15.pdf">LAS file format specifications</a>)
to compute the interpolation. How well the edges of the dataset are interpolated depends on the
interpolation method used. A buffer around the region of interest is always recommended to avoid
edge effects.</p>
</dd>
<dt><code>rasterize_canopy</code></dt><dd><p>Creates a digital surface model (DSM) using several
possible algorithms. If the user provides a normalized point cloud, the output is indeed a canopy
height model (CHM).</p>
</dd>
<dt><code>rasterize_density</code></dt><dd><p>Creates a map of the point density. If a &quot;pulseID&quot;
attribute is found, also returns a map of the pulse density.</p>
</dd>
</dl>



<h3>Value</h3>

<p><code>RasterLayer</code> or a <code>stars</code> or a <code>SpatRaster</code> depending on the settings.
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected in <code style="white-space: pre;">&#8288;rasterize_*&#8288;</code> because it is internally
known what is best to select.<br />
The option <code>chunk_buffer</code> is not supported and not respected in <code>rasterize_canopy</code> and
<code>rasterize_density</code> because it is not necessary.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# =====================
# Digital Terrain Model
# =====================

LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile, filter = "-inside 273450 5274350 273550 5274450")
#plot(las)

dtm1 = rasterize_terrain(las, algorithm = knnidw(k = 6L, p = 2))
dtm2 = rasterize_terrain(las, algorithm = tin())

## Not run: 
dtm3 = rasterize_terrain(las, algorithm = kriging(k = 10L))

plot(dtm1, col = gray(0:25/25))
plot(dtm2, col = gray(0:25/25))
plot(dtm3, col = gray(0:25/25))
plot_dtm3d(dtm1)
plot_dtm3d(dtm2)
plot_dtm3d(dtm3)

## End(Not run)

# =====================
# Digital Surface Model
# =====================

LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-inside 481280 3812940 481330 3812990")
col &lt;- height.colors(15)

# Points-to-raster algorithm with a resolution of 1 meter
chm &lt;- rasterize_canopy(las, res = 1, p2r())
plot(chm, col = col)

# Points-to-raster algorithm with a resolution of 0.5 meters replacing each
# point by a 20-cm radius circle of 8 points
chm &lt;- rasterize_canopy(las, res = 0.5, p2r(0.2))
plot(chm, col = col)

# Basic triangulation and rasterization of first returns
chm &lt;- rasterize_canopy(las, res = 0.5, dsmtin())
plot(chm, col = col)

# Khosravipour et al. pitfree algorithm
chm &lt;- rasterize_canopy(las, res = 0.5, pitfree(c(0,2,5,10,15), c(0, 1.5)))
plot(chm, col = col)

# ====================
# Digital Density Map
# ====================

LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile,  filter = "-inside 684800 5017800 684900 5017900")

d &lt;- rasterize_density(las, 5)
plot(d)

las &lt;- retrieve_pulses(las)
d &lt;- rasterize_density(las)
plot(d)
</code></pre>

<hr>
<h2 id='readLAS'>Read .las or .laz files</h2><span id='topic+readLAS'></span><span id='topic+readALSLAS'></span><span id='topic+readTLSLAS'></span><span id='topic+readUAVLAS'></span><span id='topic+readDAPLAS'></span><span id='topic+readMSLAS'></span>

<h3>Description</h3>

<p>Reads .las or .laz files into an object of class <a href="#topic+LAS-class">LAS</a>. If several files are read at
once the returned LAS object is considered as one LAS file. The optional parameters enable the user
to save a substantial amount of memory by choosing to load only the attributes or points of interest.
LAS formats 1.0 to 1.4 are supported. Point Data Record Format 0 to 10 are supported.<br /><br />
<code>readLAS</code> is the original function and always works. Using one of the <code>read*LAS</code> functions
adds information to the returned object to register a point-cloud type. Registering the correct point
type <strong>may</strong> improve the performance of some functions by enabling users to select an appropriate spatial index.
See <a href="#topic+lidR-spatial-index">spatial indexing</a>. Notice that by legacy and for backwards-compatibility reasons,
<code>readLAS()</code> and <code>readALSLAS()</code> are equivalent because lidR was originally designed for ALS and thus the
original function <code>readLAS()</code> was (supposedly) used for ALS. Reading a TLS dataset with <code>readLAS()</code> instead
of <code>readTLSLAS()</code> is perfectly valid and performs similarly to versions <code style="white-space: pre;">&#8288;&lt;= 3.0.0&#8288;</code>, with neither
performance degradation nor improvements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readLAS(files, select = "*", filter = "")

readALSLAS(files, select = "*", filter = "")

readTLSLAS(files, select = "*", filter = "")

readUAVLAS(files, select = "*", filter = "")

readDAPLAS(files, select = "*", filter = "")

readMSLAS(files1, files2, files3, select = "*", filter = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readLAS_+3A_files">files</code></td>
<td>
<p>characters. Path(s) to one or several a file(s). Can also be a
<a href="#topic+LAScatalog-class">LAScatalog</a> object.</p>
</td></tr>
<tr><td><code id="readLAS_+3A_select">select</code></td>
<td>
<p>character. Read only attributes of interest to save memory (see details).</p>
</td></tr>
<tr><td><code id="readLAS_+3A_filter">filter</code></td>
<td>
<p>character. Read only points of interest to save memory (see details).</p>
</td></tr>
<tr><td><code id="readLAS_+3A_files1">files1</code>, <code id="readLAS_+3A_files2">files2</code>, <code id="readLAS_+3A_files3">files3</code></td>
<td>
<p>characters. Path(s) to one or several a file(s). Each argument being
one channel (see section 'Multispectral data'). 'files2' and 'files3' can be missing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Select:</strong> the 'select' argument specifies the data that will actually be loaded. For example,
'xyzia' means that the x, y, and z coordinates, the intensity and the scan angle will be loaded.
The supported entries are t - gpstime, a - scan angle, i - intensity, n - number of returns,
r - return number, c - classification, s - synthetic flag, k - keypoint flag, w - withheld flag,
o - overlap flag (format 6+), u - user data, p - point source ID, e - edge of flight line flag,
d - direction of scan flag, R - red channel of RGB color, G - green channel of RGB color,
B - blue channel of RGB color, N - near-infrared channel, C - scanner channel (format 6+),
W - Full waveform.
Also numbers from 1 to 9 for the extra bytes data numbers 1 to 9. 0 enables all extra bytes to be
loaded and '*' is the wildcard that enables everything to be loaded from the LAS file. <br />
Note that x, y, z are implicit and always loaded. 'xyzia' is equivalent to 'ia'.<br /><br />
<strong>Filter:</strong> the 'filter' argument allows filtering of the point cloud while reading files.
This is much more efficient than <a href="#topic+filter_poi">filter_poi</a> in many ways. If the desired filters are known
before reading the file, the internal filters should always be preferred. The available filters are
those from <code>LASlib</code> and can be found by running the following command: <code>readLAS(filter = "-help")</code>.
(see also <a href="rlas.html#topic+read.las">rlas::read.las</a>). From <code>rlas</code> v1.3.6 the transformation commands
can also be passed via the argument filter.
</p>


<h3>Value</h3>

<p>A LAS object
</p>


<h3>Full waveform</h3>

<p>With most recent versions of the <code>rlas</code> package, full waveform (FWF) can be read and <code>lidR</code>
provides some compatible functions. However, the support of FWF is still a work-in-progress
in the <code>rlas</code> package. How it is read, interpreted and represented in R may change. Consequently,
tools provided by <code>lidR</code> may also change until the support of FWF becomes mature and
stable in <code>rlas</code>. See also <a href="rlas.html#topic+read.las">rlas::read.las</a>.<br /><br />
Remember that FWF represents an insanely huge amount of data. It terms of memory it is like
having between 10 to 100 times more points. Consequently, loading FWF data in R should be
restricted to relatively small point clouds.
</p>


<h3>Multispectral data</h3>

<p>Multispectral laser data are often stored in 3 different files. If this is the case
<code>readMSLAS</code> reads the .las or .laz files of each channel and merges them into
an object of class <a href="#topic+LAS-class">LAS</a> and takes care of attributing an ID to each
channel. If the multisprectral point cloud is already stored in a single file
leave <code>file2</code> and <code>file3</code> missing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile)
las = readLAS(LASfile, select = "xyz")
las = readLAS(LASfile, select = "xyzi", filter = "-keep_first")
las = readLAS(LASfile, select = "xyziar", filter = "-keep_first -drop_z_below 0")

# Negation of attributes is also possible (all except intensity and angle)
las = readLAS(LASfile, select = "* -i -a")
</code></pre>

<hr>
<h2 id='readLAScatalog'>Create an object of class LAScatalog</h2><span id='topic+readLAScatalog'></span><span id='topic+readALSLAScatalog'></span><span id='topic+readTLSLAScatalog'></span><span id='topic+readUAVLAScatalog'></span><span id='topic+readDAPLAScatalog'></span><span id='topic+catalog'></span>

<h3>Description</h3>

<p>Create an object of class <a href="#topic+LAScatalog-class">LAScatalog</a> from a folder
or a collection of filenames. A LAScatalog is a representation of a collection
of las/laz files. A computer cannot load all the data at once. A <code>LAScatalog</code>
is a simple way to manage all the files sequentially. Most functions from
<code>lidR</code> can be used seamlessly with a LAScatalog using the internal
<code>LAScatalog</code> processing engine. To take advantage of the <code>LAScatalog</code>
processing engine the user must first adjust some processing options using the
<a href="#topic+engine_options">appropriate functions</a>. Careful reading of the
<a href="#topic+LAScatalog-class">LAScatalog class documentation</a> is required to use the
<code>LAScatalog</code> class correctly.<br /><br />
<code>readLAScatalog</code> is the original function and always works. Using one of the <code>read*LAScatalog</code> functions
adds information to the returned object to register a point-cloud type. Registering the correct point
type <strong>may</strong> improve the performance of some functions by enabling users to select an appropriate spatial index.
See <a href="#topic+lidR-spatial-index">spatial indexing</a>. Notice that by legacy and for backwards-compatibility
reasons <code>readLAScatalog()</code> and <code>readALSLAScatalog()</code> are equivalent because lidR was originally designed
for ALS and thus the original function <code>readLAScatalog()</code> was (supposedly) used for ALS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readLAScatalog(
  folder,
  progress = TRUE,
  select = "*",
  filter = "",
  chunk_size = 0,
  chunk_buffer = 30,
  ...
)

readALSLAScatalog(folder, ...)

readTLSLAScatalog(folder, ...)

readUAVLAScatalog(folder, ...)

readDAPLAScatalog(folder, ...)

catalog(folder, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readLAScatalog_+3A_folder">folder</code></td>
<td>
<p>string. The path of a folder containing a set of las/laz files.
Can also be a vector of file paths.</p>
</td></tr>
<tr><td><code id="readLAScatalog_+3A_progress">progress</code>, <code id="readLAScatalog_+3A_select">select</code>, <code id="readLAScatalog_+3A_filter">filter</code>, <code id="readLAScatalog_+3A_chunk_size">chunk_size</code>, <code id="readLAScatalog_+3A_chunk_buffer">chunk_buffer</code></td>
<td>
<p>Easily accessible processing
options tuning. See <a href="#topic+LAScatalog-class">LAScatalog-class</a> and <a href="#topic+engine_options">engine_options</a>.</p>
</td></tr>
<tr><td><code id="readLAScatalog_+3A_...">...</code></td>
<td>
<p>Extra parameters to <a href="base.html#topic+list.files">list.files</a>. Typically
<code>recursive = TRUE</code>. Propagates also to <code>readLAScatalog</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>LAScatalog</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A single file LAScatalog using data provided with the package
LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
ctg = readLAScatalog(LASfile)
plot(ctg)

## Not run: 
ctg &lt;- readLAScatalog("&lt;/path/to/folder/of/las/&gt;")

# Internal engine will sequentially process chunks of size 500 x 500 m
opt_chunk_size(ctg) &lt;- 500

# Internal engine will align the 500 x 500 m chunks on x = 250 and y = 300
opt_alignment(ctg) &lt;- c(250, 300)

# Internal engine will not display a progress estimation
opt_progress(ctg) &lt;- FALSE

# Internal engine will not return results into R.
# Instead it will write results in files.
# Files will be named e.g.
# filename_256000_1.ext
# filename_257000_2.ext
# filename_258000_3.ext
# ...
opt_output_files(ctg) &lt;- "/path/filename_{XBOTTOM}_{ID}"

# More details in the documentation
help("LAScatalog-class", "lidR")
help("engine_options", "lidR")

## End(Not run)
</code></pre>

<hr>
<h2 id='readLASheader'>Read a .las or .laz file header</h2><span id='topic+readLASheader'></span>

<h3>Description</h3>

<p>Reads a .las or .laz file header into an object of class <a href="#topic+LASheader-class">LASheader</a>.
This function strictly reads the header while the function <a href="#topic+readLAS">readLAS</a> can alter the header to
fit the actual data loaded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readLASheader(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readLASheader_+3A_file">file</code></td>
<td>
<p>characters. Path to one file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A LASheader object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
header = readLASheader(LASfile)

print(header)
plot(header)

## Not run: 
plot(header, mapview = TRUE)
## End(Not run)
</code></pre>

<hr>
<h2 id='retrieve_pulses'>Retrieve individual pulses, flightlines or scanlines</h2><span id='topic+retrieve_pulses'></span><span id='topic+retrieve_flightlines'></span><span id='topic+retrieve_scanlines'></span>

<h3>Description</h3>

<p>Retrieve each individual pulse, individual flightline or individual scanline and assigns a number
to each point. The LAS object must be properly populated according to LAS specifications otherwise
users could find unexpected outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>retrieve_pulses(las)

retrieve_flightlines(las, dt = 30)

retrieve_scanlines(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="retrieve_pulses_+3A_las">las</code></td>
<td>
<p>A LAS object</p>
</td></tr>
<tr><td><code id="retrieve_pulses_+3A_dt">dt</code></td>
<td>
<p>numeric. The threshold time-lag used to retrieve flightlines</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>retrieve_pulses</code></dt><dd><p>Retrieves each individual pulse. It uses GPS time. An attribute
<code>pulseID</code> is added in the <code>LAS</code> object</p>
</dd>
<dt><code>retrieve_scanlines</code></dt><dd><p>Retrieves each individual scanline. When data are sampled according to a
saw-tooth pattern (oscillating mirror), a scanline is one line, or row of data. The function relies
on the GPS field time to order the data. Then, the <code>ScanDirectionFlag</code> attribute is used to
retrieve each scanline. An attribute <code>scanlineID</code> is added in the <code>LAS</code> object</p>
</dd>
<dt><code>retrieve_flightlines</code></dt><dd><p>Retrieves each individual flightline. It uses GPS time. In a
continuous dataset, once points are ordered by GPS time, the time between two consecutive points
does not exceed a few milliseconds. If the time between two consecutive points is too long it means
that the second point is from a different flightline. The default threshold is 30 seconds.
An attribute <code>flightlineID</code> is added in the <code>LAS</code> object.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>LAS</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile)

las &lt;- retrieve_pulses(las)
las

las &lt;- retrieve_flightlines(las)
#plot(las, color = "flightlineID")
</code></pre>

<hr>
<h2 id='sample_homogenize'>Point Cloud Decimation Algorithm</h2><span id='topic+sample_homogenize'></span><span id='topic+homogenize'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+decimate_points">decimate_points</a>. It implements an algorithm that
creates a grid with a given resolution and filters the point cloud by randomly selecting some
points in each cell. It is designed to produce point clouds that have uniform densities throughout
the coverage area. For each cell, the proportion of points or pulses that will be retained is computed
using the actual local density and the desired density. If the desired density is greater than the actual
density it returns an unchanged set of points (it cannot increase the density). The cell size must be
large enough to compute a coherent local density. For example, in a 2 points/m^2 point cloud, 25 square
meters would be feasible; however 1 square meter cells would not be feasible because density does
not have meaning at this scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homogenize(density, res = 5, use_pulse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_homogenize_+3A_density">density</code></td>
<td>
<p>numeric. The desired output density.</p>
</td></tr>
<tr><td><code id="sample_homogenize_+3A_res">res</code></td>
<td>
<p>numeric. The resolution of the grid used to filter the point cloud</p>
</td></tr>
<tr><td><code id="sample_homogenize_+3A_use_pulse">use_pulse</code></td>
<td>
<p>logical. Decimate by removing random pulses instead of random points (requires running
<a href="#topic+retrieve_pulses">retrieve_pulses</a> first)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other point cloud decimation algorithms: 
<code><a href="#topic+sample_maxima">sample_maxima</a></code>,
<code><a href="#topic+sample_per_voxel">sample_per_voxel</a></code>,
<code><a href="#topic+sample_random">sample_random</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile, select = "xyz")

# Select points randomly to reach an homogeneous density of 1
thinned &lt;- decimate_points(las, homogenize(1,5))
plot(grid_density(thinned, 10))
</code></pre>

<hr>
<h2 id='sample_maxima'>Point Cloud Decimation Algorithm</h2><span id='topic+sample_maxima'></span><span id='topic+highest'></span><span id='topic+lowest'></span>

<h3>Description</h3>

<p>These functions are made to be used in <a href="#topic+decimate_points">decimate_points</a>. They implement algorithms that
create a grid with a given resolution and filters the point cloud by selecting the highest/lowest
point within each cell.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>highest(res = 1)

lowest(res = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_maxima_+3A_res">res</code></td>
<td>
<p>numeric. The resolution of the grid used to filter the point cloud</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other point cloud decimation algorithms: 
<code><a href="#topic+sample_homogenize">sample_homogenize</a></code>,
<code><a href="#topic+sample_per_voxel">sample_per_voxel</a></code>,
<code><a href="#topic+sample_random">sample_random</a></code>
</p>
<p>Other point cloud decimation algorithms: 
<code><a href="#topic+sample_homogenize">sample_homogenize</a></code>,
<code><a href="#topic+sample_per_voxel">sample_per_voxel</a></code>,
<code><a href="#topic+sample_random">sample_random</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile, select = "xyz")

# Select the highest point within each cell of an overlayed grid
thinned = decimate_points(las, highest(4))
#plot(thinned)

# Select the lowest point within each cell of an overlayed grid
thinned = decimate_points(las, lowest(4))
#plot(thinned)
</code></pre>

<hr>
<h2 id='sample_per_voxel'>Point Cloud Decimation Algorithm</h2><span id='topic+sample_per_voxel'></span><span id='topic+random_per_voxel'></span>

<h3>Description</h3>

<p>This functions is made to be used in <a href="#topic+decimate_points">decimate_points</a>. It implements an algorithm that
creates a 3D grid with a given resolution and filters the point cloud by randomly selecting
n points within each voxel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_per_voxel(res = 1, n = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_per_voxel_+3A_res">res</code></td>
<td>
<p>numeric. The resolution of the voxel grid used to filter the point cloud</p>
</td></tr>
<tr><td><code id="sample_per_voxel_+3A_n">n</code></td>
<td>
<p>integer. The number of points to select</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other point cloud decimation algorithms: 
<code><a href="#topic+sample_homogenize">sample_homogenize</a></code>,
<code><a href="#topic+sample_maxima">sample_maxima</a></code>,
<code><a href="#topic+sample_random">sample_random</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyz")
thinned &lt;- decimate_points(las, random_per_voxel(8, 1))
#plot(thinned)
</code></pre>

<hr>
<h2 id='sample_random'>Point Cloud Decimation Algorithm</h2><span id='topic+sample_random'></span><span id='topic+random'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+decimate_points">decimate_points</a>. It implements an algorithm that
randomly removes points or pulses to reach the desired density over the whole area (see
<code><a href="#topic+area">area</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random(density, use_pulse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_random_+3A_density">density</code></td>
<td>
<p>numeric. The desired output density.</p>
</td></tr>
<tr><td><code id="sample_random_+3A_use_pulse">use_pulse</code></td>
<td>
<p>logical. Decimate by removing random pulses instead of random points (requires running
<a href="#topic+retrieve_pulses">retrieve_pulses</a> first)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other point cloud decimation algorithms: 
<code><a href="#topic+sample_homogenize">sample_homogenize</a></code>,
<code><a href="#topic+sample_maxima">sample_maxima</a></code>,
<code><a href="#topic+sample_per_voxel">sample_per_voxel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile, select = "xyz")

# Reach a pulse density of 1 on the overall dataset
thinned1 = decimate_points(las, random(1))
plot(grid_density(las))
plot(grid_density(thinned1))
</code></pre>

<hr>
<h2 id='segment'>Segment a point cloud</h2><span id='topic+segment'></span><span id='topic+segment_shapes'></span><span id='topic+segment_snags'></span><span id='topic+segment_trees'></span>

<h3>Description</h3>

<p>Segment a point cloud using different methods. <code style="white-space: pre;">&#8288;segment_*&#8288;</code> functions add a new attribute to the
point cloud to label each point. They segment either individual trees, snags, or
geometrical features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segment_shapes(las, algorithm, attribute = "Shape", filter = NULL)

segment_snags(las, algorithm, attribute = "snagCls")

segment_trees(las, algorithm, attribute = "treeID", uniqueness = "incremental")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segment_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="segment_+3A_algorithm">algorithm</code></td>
<td>
<p>function. An algorithm for segmentation. For individual tree segmentation, lidR
has <a href="#topic+dalponte2016">dalponte2016</a>, <a href="#topic+watershed">watershed</a>, <a href="#topic+li2012">li2012</a>, and <a href="#topic+silva2016">silva2016</a>. More experimental
algorithms may be found in the package <a href="https://github.com/Jean-Romain/lidRplugins">lidRplugins</a>.
For snag segmentation, <code>lidR</code> has <a href="#topic+wing2015">wing2015</a>. For geometry segmentation, lidR has
<a href="#topic+shp_plane">shp_plane</a>, <a href="#topic+shp_hplane">shp_hplane</a>, and <a href="#topic+shp_line">shp_line</a>.</p>
</td></tr>
<tr><td><code id="segment_+3A_attribute">attribute</code></td>
<td>
<p>character. The returned LAS object as a new attribute (in a new column).
This parameter controls the name of the new attribute.</p>
</td></tr>
<tr><td><code id="segment_+3A_filter">filter</code></td>
<td>
<p>formula of logical predicates. Enables the function to run only on points of interest
in an optimized way. See the examples.</p>
</td></tr>
<tr><td><code id="segment_+3A_uniqueness">uniqueness</code></td>
<td>
<p>character. A method to compute a unique ID. Can be 'incremental', 'gpstime' or
'bitmerge'. See section 'Uniqueness'. This feature must be considered as 'experimental'.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>segment_trees</code></dt><dd><p>Individual tree segmentation with several possible algorithms. The returned
point cloud has a new extra byte attribute named after the parameter <code>attribute</code> independently
of the algorithm used.</p>
</dd>
<dt><code>segment_shapes</code></dt><dd><p>Computes, for each point, the eigenvalues of the covariance matrix of the
neighbouring points. The eigenvalues are later used either to segment linear/planar points or to
compute derived metrics. The points that meet a given criterion based on the eigenvalue are labelled
as approximately coplanar/colinear or any other shape supported.</p>
</dd>
<dt><code>segment_snags</code></dt><dd><p>Snag segmentation using several possible algorithms. The function attributes
a number identifying a snag class (<code>snagCls</code> attribute) to each point of the point cloud.
The classification/segmentation is done at the point cloud level and currently only one algorithm is
implemented, which uses LiDAR intensity thresholds and specified neighbourhoods to differentiate
bole and branch from foliage points.</p>
</dd>
</dl>



<h3>Non-supported LAScatalog options</h3>

<p>The option <code>select</code> is not supported and not respected because it always preserves the file format
and all the attributes. <code>select = "*"</code> is imposed internally.
</p>


<h3>Uniqueness</h3>

<p>By default the tree IDs are numbered from 1 to n, n being the number of trees found. The problem
with such incremental numbering is that, while it ensures a unique ID is assigned for each tree in
a given point-cloud, it also guarantees duplication of tree IDs in different tiles or chunks when
processing a <code>LAScatalog</code>. This is because each chunk/file is processed independently of the others
and potentially in parallel on different computers. Thus, the index always restarts at 1 on each
chunk/file. Worse, in a tree segmentation process, a tree that is located exactly between
2 chunks/files will have two different IDs for its two halves.
</p>
<p>This is why we introduced some uniqueness strategies that are all imperfect and that should be seen
as experimental. Please report any troubleshooting. Using a uniqueness-safe strategy ensures that
trees from different files will not share the same IDs. It also ensures that two halves of a tree
on the edge of a processing chunk will be assigned the same ID.
</p>

<dl>
<dt>incremental</dt><dd><p>Number from 0 to n. This method <strong>does not</strong> ensure uniqueness of the IDs. This
is the legacy method.</p>
</dd>
<dt>gpstime</dt><dd><p>This method uses the gpstime of the highest point of a tree (apex) to create a
unique ID. This ID is not an integer but a 64-bit decimal number, which is suboptimal but at
least it is expected to be unique <strong>if the gpstime attribute is consistent across files</strong>.
If inconsistencies with gpstime are reported (for example gpstime records the week time and was
reset to 0 in a coverage that takes more than a week to complete), there is a (low) probability of
getting ID attribution errors.</p>
</dd>
<dt>bitmerge</dt><dd><p>This method uses the XY coordinates of the highest point (apex) of a tree to
create a single 64-bit number with a bitwise operation. First, XY coordinates are converted to
32-bit integers using the scales and offsets of the point cloud. For example, if the apex is at
(10.32, 25.64) with a scale factor of 0.01 and an offset of 0, the 32-bit integer coordinates are
X = 1032 and Y = 2564. Their binary representations are, respectively, (here displayed as 16 bits)
0000010000001000 and 0000101000000100. X is shifted by 32 bits and becomes a 64-bit integer. Y is kept
as-is and the binary representations are unionized into a 64-bit integer like (here displayed as 32 bit)
00000100000010000000101000000100 that is guaranteed to be unique. However R
does not support 64-bit integers. The previous steps are done at C++ level and the 64-bit binary
representation is reinterpreted into a 64-bit decimal number to be returned in R. The IDs thus generated
are somewhat weird. For example, the tree ID 00000100000010000000101000000100 which is 67635716 if
interpreted as an integer becomes 3.34164837074751323479078607289E-316 if interpreted as a decimal
number. This is far from optimal but at least it is guaranteed to be unique  <strong>if all files have
the same offsets and scale factors</strong>.</p>
</dd>
</dl>

<p>All the proposed options are suboptimal because they either do not guarantee uniqueness in all cases
(inconsistencies in the collection of files), or they imply that IDs are based on non-integers or
meaningless numbers. But at least it works and deals with some of the limitations of R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ==============
# Segment trees
# ==============

LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyz", filter = "-drop_z_below 0")

# Using Li et al. (2012)
las &lt;- segment_trees(las, li2012(R = 3, speed_up = 5))
#plot(las, color = "treeID")

# ==============
# Segment shapes
# ==============

LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, filter = "-keep_random_fraction 0.5")

# Use the eigenvalues to estimate if points are part of a local plan
las &lt;- segment_shapes(las, shp_plane(k = 15), "Coplanar")
#plot(las, color = "Coplanar")

## Not run: 
# Drop ground point at runtime
las &lt;- segment_shapes(las, shp_plane(k = 15), "Coplanar", filter = ~Classification != 2L)
#plot(las, color = "Coplanar")

# ==============
# Segment snags
# ==============

LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyzi", filter="-keep_first") # Wing also included -keep_single

# For the Wing2015 method, supply a matrix of snag BranchBolePtRatio conditional
# assessment thresholds (see Wing et al. 2015, Table 2, pg. 172)
bbpr_thresholds &lt;- matrix(c(0.80, 0.80, 0.70,
                            0.85, 0.85, 0.60,
                            0.80, 0.80, 0.60,
                            0.90, 0.90, 0.55),
                            nrow =3, ncol = 4)

# Run snag classification and assign classes to each point
las &lt;- segment_snags(las, wing2015(neigh_radii = c(1.5, 1, 2), BBPRthrsh_mat = bbpr_thresholds))

# Plot it all, tree and snag points...
plot(las, color="snagCls", colorPalette = rainbow(5))

# Filter and plot snag points only
snags &lt;- filter_poi(las, snagCls &gt; 0)
plot(snags, color="snagCls", colorPalette = rainbow(5)[-1])

# Wing et al's (2015) methods ended with performing tree segmentation on the
# classified and filtered point cloud using the watershed method

## End(Not run)
</code></pre>

<hr>
<h2 id='set_lidr_threads'>Set or get number of threads that lidR should use</h2><span id='topic+set_lidr_threads'></span><span id='topic+get_lidr_threads'></span>

<h3>Description</h3>

<p>Set and get number of threads to be used in lidR functions that are parallelized with OpenMP.
0 means to utilize all CPU available. <code>get_lidr_threads()</code> returns the number
of threads that will be used. This affects <code>lidR</code> package but also the <code>data.table</code> package
by internally calling <a href="data.table.html#topic+openmp-utils">setDTthreads</a> because several functions  of
lidR rely on <code>data.table</code> but it does not change R itself or other packages using OpenMP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_lidr_threads(threads)

get_lidr_threads()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_lidr_threads_+3A_threads">threads</code></td>
<td>
<p>Positive scalar. Default 0 means use all CPU available. Values &gt; 1 mean
using n cores, values in ]0, 1[ mean using a fraction of the cores e.g. 0.5 = half.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+lidR-parallelism">lidR-parallelism</a>
</p>

<hr>
<h2 id='shape_detection'>Algorithms for shape detection of the local point neighbourhood</h2><span id='topic+shape_detection'></span><span id='topic+shp_plane'></span><span id='topic+shp_hplane'></span><span id='topic+shp_line'></span><span id='topic+shp_hline'></span><span id='topic+shp_vline'></span>

<h3>Description</h3>

<p>These functions are made to be used in <a href="#topic+segment_shapes">segment_shapes</a>. They implement algorithms for local
neighbourhood shape estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shp_plane(th1 = 25, th2 = 6, k = 8)

shp_hplane(th1 = 25, th2 = 6, th3 = 0.98, k = 8)

shp_line(th1 = 10, k = 8)

shp_hline(th1 = 10, th2 = 0.02, k = 8)

shp_vline(th1 = 10, th2 = 0.98, k = 8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shape_detection_+3A_th1">th1</code>, <code id="shape_detection_+3A_th2">th2</code>, <code id="shape_detection_+3A_th3">th3</code></td>
<td>
<p>numeric. Threshold values (see details)</p>
</td></tr>
<tr><td><code id="shape_detection_+3A_k">k</code></td>
<td>
<p>integer. Number of neighbours used to estimate the neighborhood.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the following, <code class="reqn">a_1, a_2, a_3</code> denote the eigenvalues of the covariance matrix
of the neighbouring points in ascending order. <code class="reqn">|Z_1|, |Z_2|, |Z_3|</code> denote
the norm of the Z component of first, second and third axis of the decomposition.
<code class="reqn">th_1, th_2, th_3</code>  denote a set of threshold values. Points are labelled
<code>TRUE</code> if they meet the following criteria. <code>FALSE</code> otherwise.<br />
</p>

<dl>
<dt>shp_plane</dt><dd><p>Detection of plans based on criteria defined by Limberger &amp; Oliveira (2015) (see
references). A point is labelled TRUE if the neighborhood is approximately planar, that is:
</p>
<p style="text-align: center;"><code class="reqn">a_2 &gt; (th_1 \times a_1) \&amp; (th_2 \times a_2) &gt; a_3</code>
</p>
</dd>
<dt>shp_hplane</dt><dd><p>The same as 'plane' but with an extra test on the orientation of the Z vector
of the principal components to test the horizontality of the surface.
</p>
<p style="text-align: center;"><code class="reqn">a_2 &gt; (th_1 \times a_1) \&amp; (th_2 \times a_2) &gt; a_3 \&amp; |Z_3| &gt; th_3</code>
</p>

<p>In theory  <code class="reqn">|Z_3|</code> should be exactly equal to 1. In practice 0.98 or 0.99 should be fine</p>
</dd>
<dt>shp_line</dt><dd><p>Detection of lines inspired by the Limberger &amp; Oliveira (2015) criterion. A point is
labelled TRUE if the neighbourhood is approximately linear, that is:
</p>
<p style="text-align: center;"><code class="reqn">th_1 \times a_2 &lt; a_3 \&amp; th_1 \times a_1 &lt; a_3</code>
</p>
</dd>
<dt>shp_hline</dt><dd><p>Detection of horizontal lines inspired by the Limberger &amp; Oliveira (2015) criterion.
A point is labelled TRUE if the neighbourhood is approximately linear and horizontal, that is:
</p>
<p style="text-align: center;"><code class="reqn">th_1 \times a_2 &lt; a_3 \&amp; th_1 \times a_1 &lt; a_3 \&amp; |Z_1| &lt; th_2</code>
</p>

<p>In theory <code class="reqn">|Z_1|</code> should be exactly equal to 0. In practice 0.02 or 0.01 should be fine</p>
</dd>
<dt>shp_vline</dt><dd><p>Detection of vertical lines inspired by the Limberger &amp; Oliveira (2015) criterion.
A point is labelled TRUE if the neighbourhood is approximately linear and vertical, that is:
</p>
<p style="text-align: center;"><code class="reqn">th_1 \times a_2 &lt; a_3 \&amp; th_1 \times a_1 &lt; a_3 \&amp; |Z_1| &gt; th_2</code>
</p>

<p>In theory <code class="reqn">|Z_1|</code> should be exactly equal to 1. In practice 0.98 or 0.99 should be fine</p>
</dd>
</dl>



<h3>References</h3>

<p>Limberger, F. A., &amp; Oliveira, M. M. (2015). Real-time detection of planar regions in unorganized
point clouds. Pattern Recognition, 48(6), 2043–2053. https://doi.org/10.1016/j.patcog.2014.12.020<br /><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generating some data
n = 400
xplane = runif(n,0,6)
yplane = runif(n,0,6)
zplane = xplane + 0.8 * yplane + runif(n, 0, 0.1)
plane = data.frame(X = xplane, Y = yplane, Z = zplane)

xhplane = runif(n,5,15)
yhplane = runif(n,0,10)
zhplane = 5 + runif(n, 0, 0.)
hplane = data.frame(X = xhplane, Y = yhplane, Z = zhplane)

tline = 1:n
xline = 0.05*tline
yline = 0.01*tline
zline = 0.02*tline + runif(n, 0, 0.1)
line = data.frame(X = xline, Y = yline, Z = zline)

thline = 1:n
xhline = 0.05*thline + runif(n, 0, 0.05)
yhline = 10 - 0.01*thline + runif(n, 0, 0.05)
zhline = 3 + runif(n, 0, 0.05)
hline = data.frame(X = xhline, Y = yhline, Z = zhline)

tvline = 1:n
xvline = 5 + runif(n, 0, 0.05)
yvline = 5 + runif(n, 0, 0.05)
zvline = 0.02*tline
vline = data.frame(X = xvline, Y = yvline, Z = zvline)

las &lt;- rbind(plane, line, hplane, hline, vline)
las &lt;- LAS(las)

las &lt;- segment_shapes(las, shp_plane(k = 20), "plane")
las &lt;- segment_shapes(las, shp_hplane(k = 20), "hplane")
las &lt;- segment_shapes(las, shp_line(k = 20), "line")
las &lt;- segment_shapes(las, shp_hline(k = 20), "hline")
las &lt;- segment_shapes(las, shp_vline(k = 20), "vline")

#plot(las)
#plot(las, color = "plane")
#plot(las, color = "hplane")
#plot(las, color = "line")
#plot(las, color = "hline")
#plot(las, color = "vline")
</code></pre>

<hr>
<h2 id='smooth_height'>Smooth a point cloud</h2><span id='topic+smooth_height'></span><span id='topic+unsmooth_height'></span>

<h3>Description</h3>

<p>Point cloud-based smoothing algorithm. Two methods are available: average within a window and
Gaussian smooth within a window. The attribute <code>Z</code> of the returned LAS object is the smoothed Z.
A new attribute <code>Zraw</code> is added to store the original values and can be used to restore the
point cloud with <code>unsmooth_height</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth_height(
  las,
  size,
  method = c("average", "gaussian"),
  shape = c("circle", "square"),
  sigma = size/6
)

unsmooth_height(las)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth_height_+3A_las">las</code></td>
<td>
<p>An object of class <code>LAS</code></p>
</td></tr>
<tr><td><code id="smooth_height_+3A_size">size</code></td>
<td>
<p>numeric. The size of the windows used to smooth.</p>
</td></tr>
<tr><td><code id="smooth_height_+3A_method">method</code></td>
<td>
<p>character. Smoothing method. Can be 'average' or 'gaussian'.</p>
</td></tr>
<tr><td><code id="smooth_height_+3A_shape">shape</code></td>
<td>
<p>character. The shape of the windows. Can be circle or square.</p>
</td></tr>
<tr><td><code id="smooth_height_+3A_sigma">sigma</code></td>
<td>
<p>numeric. The standard deviation of the gaussian if the method is gaussian.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method does not use raster-based methods to smooth the point cloud. This is a true point cloud
smoothing. It is not really useful by itself but may be interesting in combination with filters,
for example to develop new algorithms.
</p>


<h3>Value</h3>

<p>An object of the class <code>LAS</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "xyz")

las &lt;- decimate_points(las, highest(1))
#plot(las)

las &lt;- smooth_height(las, 5, "gaussian", "circle", sigma = 2)
#plot(las)

las &lt;- unsmooth_height(las)
#plot(las)
</code></pre>

<hr>
<h2 id='snag_wing2015'>Snags Segmentation Algorithm</h2><span id='topic+snag_wing2015'></span><span id='topic+wing2015'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+segment_snags">segment_snags</a>. It implements an algorithms for snags segmentation
based on Wing et al (2015) (see references). This is an automated filtering algorithm that utilizes
three dimensional neighborhood lidar point-based intensity and density statistics to remove lidar
points associated with live trees and retain lidar points associated with snags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wing2015(
  neigh_radii = c(1.5, 1, 2),
  low_int_thrsh = 50,
  uppr_int_thrsh = 170,
  pt_den_req = 3,
  BBPRthrsh_mat = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snag_wing2015_+3A_neigh_radii">neigh_radii</code></td>
<td>
<p>numeric. A vector of three radii used in quantifying local-area centered
neighborhoods. See Wing et al. (2015) reference page 171 and Figure 4. Defaults are 1.5,
1, and 2 for the sphere, small cylinder and large cylinder neighborhoods, respectively.</p>
</td></tr>
<tr><td><code id="snag_wing2015_+3A_low_int_thrsh">low_int_thrsh</code></td>
<td>
<p>numeric. The lower intensity threshold filtering value. See Wing
et al. (2015) page 171. Default is 50.</p>
</td></tr>
<tr><td><code id="snag_wing2015_+3A_uppr_int_thrsh">uppr_int_thrsh</code></td>
<td>
<p>numeric. The upper intensity threshold filtering value. See Wing
et al. (2015) page 171. Default is 170.</p>
</td></tr>
<tr><td><code id="snag_wing2015_+3A_pt_den_req">pt_den_req</code></td>
<td>
<p>numeric. Point density requirement based on plot-level point density
defined classes. See Wing et al. (2015) page 172. Default is 3.</p>
</td></tr>
<tr><td><code id="snag_wing2015_+3A_bbprthrsh_mat">BBPRthrsh_mat</code></td>
<td>
<p>matrix. A 3x4 matrix providing the four average BBPR (branch and bole
point ratio) values for each of the three neighborhoods (sphere, small cylinder and large
cylinder) to be used for conditional assessments and classification into the following four snag
classes: 1) general snag 2) small snag 3) live crown edge snag 4) high canopy
cover snag. See Wing et al. (2015) page 172 and Table 2. This matrix must be provided by
the user.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this algorithm strictly performs a classification based on user input while
the original publication's methods also included a segmentation step and some pre-
(filtering for first and single returns only) and post-process (filtering for only the
snag classified points prior to segmentation) tasks which are now expected to be performed
by the user. Also, this implementation may have some differences compared with the original
method due to potential mis-interpretation of the Wing et al. manuscript, specifically
Table 2 where they present four groups of conditional assessments with their required
neighborhood point density and average BBPR values (BBPR = branch and bole point ratio;
PDR = point density requirement).<br /><br />
This algorithm attributes each point in the point cloud (<code>snagCls</code> column) into the
following five snag classes:
</p>

<ul>
<li><p> 0: live tree - not a snag<br />
</p>
</li>
<li><p> 1: general snag - the broadest range of snag point situations<br />
</p>
</li>
<li><p> 2: small snag - isolated snags with lower point densities<br />
</p>
</li>
<li><p> 3: live crown edge snag - snags located directly adjacent or intermixing with live trees crowns <br />
</p>
</li>
<li><p> 4: high canopy cover snag - snags protruding above the live canopy in dense conditions (e.g.,
canopy cover &gt;= 55%).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Implementation by Andrew Sánchez Meador &amp; Jean-Romain Roussel
</p>


<h3>References</h3>

<p>Wing, Brian M.; Ritchie, Martin W.; Boston, Kevin; Cohen, Warren B.; Olsen, Michael J. 2015.
Individual snag detection using neighborhood attribute filtered airborne lidar data. Remote
Sensing of Environment. 163: 165-179 https://doi.org/10.1016/j.rse.2015.03.013
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "MixedConifer.laz", package="lidR")
# Wing also included -keep_single
poi ="-keep_first -inside 481260 3812920 481310 3812960"
las &lt;- readLAS(LASfile, select = "xyzi", filter = poi)

# For the Wing2015 method, supply a matrix of snag BranchBolePtRatio conditional
# assessment thresholds (see Wing et al. 2015, Table 2, pg. 172)
bbpr_thresholds &lt;- matrix(c(0.80, 0.80, 0.70,
                          0.85, 0.85, 0.60,
                          0.80, 0.80, 0.60,
                          0.90, 0.90, 0.55),
                          nrow =3, ncol = 4)

# Run snag classification and assign classes to each point
las &lt;- segment_snags(las, wing2015(neigh_radii = c(1.5, 1, 2), BBPRthrsh_mat = bbpr_thresholds))

# Plot it all, tree and snag points...
#plot(las, color="snagCls", colorPalette = rainbow(5))

# Filter and plot snag points only
snags &lt;- filter_poi(las, snagCls &gt; 0)
#plot(snags, color="snagCls", colorPalette = rainbow(5)[-1])

# Wing et al's (2015) methods ended with performing tree segmentation on the
# classified and filtered point cloud using the watershed method

</code></pre>

<hr>
<h2 id='st_area'>Surface covered by a LAS* object</h2><span id='topic+st_area'></span><span id='topic+st_area.LAS'></span><span id='topic+st_area.LASheader'></span><span id='topic+st_area.LAScatalog'></span><span id='topic+area'></span><span id='topic+area+2CLAS-method'></span><span id='topic+area+2CLASheader-method'></span><span id='topic+area+2CLAScatalog-method'></span>

<h3>Description</h3>

<p>Surface covered by a <code style="white-space: pre;">&#8288;LAS*&#8288;</code> object. The surface covered by a point cloud is mathematically 0.
To compute non zero values the function uses different strategies. The area is computed based on
the number of occupied cells, or on the area of the convex hull of the points depending on the density
and the size of the point cloud. The result is necessarily an approximation that depends on the method
used.<br /> For a <code>LAScatalog</code> it is computed as the sum of the bounding boxes of the files. For
overlapping tiles the value may be larger than the total area covered because some regions are
sampled twice. For a <code>LASheader</code> it is computed with the bounding box. As a consequence, for the same file
<code>st_area</code> applied on a LASheader or on a LAS can return slightly different values. <code>st_area()</code>
extends <code>sf:st_area()</code>, <code>area()</code> extends <code>raster:area()</code>. <code>area()</code> is provided for backward
compatibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
st_area(x, ...)

## S3 method for class 'LASheader'
st_area(x, ...)

## S3 method for class 'LAScatalog'
st_area(x, ...)

area(x, ...)

## S4 method for signature 'LAS'
area(x, ...)

## S4 method for signature 'LASheader'
area(x, ...)

## S4 method for signature 'LAScatalog'
area(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_area_+3A_x">x</code></td>
<td>
<p>An object of class <code>LAS*</code>.</p>
</td></tr>
<tr><td><code id="st_area_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric. A number in the same units as the coordinate reference system.
</p>

<hr>
<h2 id='st_bbox'>Bounding box of a LAS* object</h2><span id='topic+st_bbox'></span><span id='topic+st_bbox.LAS'></span><span id='topic+st_bbox.LASheader'></span><span id='topic+st_bbox.LAScatalog'></span><span id='topic+st_bbox.LAScluster'></span><span id='topic+ext+2CLAS-method'></span><span id='topic+ext+2CLASheader-method'></span><span id='topic+ext+2CLAScatalog-method'></span><span id='topic+ext+2CLAScluster-method'></span>

<h3>Description</h3>

<p>Bounding box of a <code style="white-space: pre;">&#8288;LAS*&#8288;</code> object. <code>st_bbox()</code> extends <code>sf</code>, and <code>ext()</code> extends <code>terra</code>. The values returned are similar to their
parent functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
st_bbox(obj, ...)

## S3 method for class 'LASheader'
st_bbox(obj, ...)

## S3 method for class 'LAScatalog'
st_bbox(obj, ...)

## S3 method for class 'LAScluster'
st_bbox(obj, ...)

## S4 method for signature 'LAS'
ext(x, ...)

## S4 method for signature 'LASheader'
ext(x, ...)

## S4 method for signature 'LAScatalog'
ext(x, ...)

## S4 method for signature 'LAScluster'
ext(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_bbox_+3A_obj">obj</code>, <code id="st_bbox_+3A_x">x</code></td>
<td>
<p>An object of class <code>LAS*</code>.</p>
</td></tr>
<tr><td><code id="st_bbox_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>bbox</code> from sf, or a <code>SpatExtent</code> from <code>terra</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- system.file("extdata", "example.las", package="rlas")
las &lt;- readLAS(f)

st_bbox(las)
ext(las)
</code></pre>

<hr>
<h2 id='st_coordinates'>Coordinates of a LAS* object in a matrix form</h2><span id='topic+st_coordinates'></span><span id='topic+st_coordinates.LAS'></span><span id='topic+st_coordinates.LAScatalog'></span>

<h3>Description</h3>

<p>Retrieve coordinates of a <code style="white-space: pre;">&#8288;LAS*&#8288;</code> object in matrix form. It creates a copy of the coordinates
because of the coercion from <code>data.frame</code> to <code>matrix</code>. This function inherits <code>sf::st_coordinates</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
st_coordinates(x, z = TRUE, ...)

## S3 method for class 'LAScatalog'
st_coordinates(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_coordinates_+3A_x">x</code></td>
<td>
<p>A LAS* object</p>
</td></tr>
<tr><td><code id="st_coordinates_+3A_z">z</code></td>
<td>
<p>bool. Return XY or XYZ matrix</p>
</td></tr>
<tr><td><code id="st_coordinates_+3A_...">...</code></td>
<td>
<p>unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las &lt;- readLAS(LASfile)
sf::st_coordinates(las)
</code></pre>

<hr>
<h2 id='st_crs'>Get or set the projection of a LAS* object</h2><span id='topic+st_crs'></span><span id='topic+st_crs.LAS'></span><span id='topic+st_crs.LAScatalog'></span><span id='topic+st_crs.LASheader'></span><span id='topic+st_crs.LAScluster'></span><span id='topic+st_crs+3C-'></span><span id='topic+st_crs+3C-.LAS'></span><span id='topic+st_crs+3C-.LASheader'></span><span id='topic+st_crs+3C-.LAScatalog'></span><span id='topic+projection'></span><span id='topic+projection+3C-'></span><span id='topic+crs'></span><span id='topic+crs+3C-'></span><span id='topic+crs+2CLASheader-method'></span><span id='topic+crs+2CLAS-method'></span><span id='topic+crs+3C-+2CLAS-method'></span><span id='topic+crs+2CLAScatalog-method'></span><span id='topic+crs+2CLAScluster-method'></span><span id='topic+crs+3C-+2CLAScatalog-method'></span><span id='topic+crs+3C-+2CLASheader-method'></span><span id='topic+epsg'></span><span id='topic+epsg+3C-'></span><span id='topic+epsg+2CLASheader-method'></span><span id='topic+epsg+3C-+2CLASheader-method'></span><span id='topic+epsg+2CLAS-method'></span><span id='topic+epsg+3C-+2CLAS-method'></span><span id='topic+wkt'></span><span id='topic+wkt+3C-'></span><span id='topic+wkt+2CLASheader-method'></span><span id='topic+wkt+3C-+2CLASheader-method'></span><span id='topic+wkt+2CLAS-method'></span><span id='topic+wkt+3C-+2CLAS-method'></span>

<h3>Description</h3>

<p>Get or set the projection of a <code style="white-space: pre;">&#8288;LAS*&#8288;</code> object.  <code>st_crs()</code> extends <code>sf:st_crs()</code>, <code>projection()</code> and
<code>crs()</code> extend <code>raster:projection()</code> and <code>raster:crs()</code>. <code>projection()</code> and <code>crs()</code> are provided
for backward compatibility. For <code>epsg()</code> and <code>wkt()</code>, see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
st_crs(x, ...)

## S3 method for class 'LAScatalog'
st_crs(x, ...)

## S3 method for class 'LASheader'
st_crs(x, ...)

## S3 method for class 'LAScluster'
st_crs(x, ...)

## S3 replacement method for class 'LAS'
st_crs(x) &lt;- value

## S3 replacement method for class 'LASheader'
st_crs(x) &lt;- value

## S3 replacement method for class 'LAScatalog'
st_crs(x) &lt;- value

projection(x, asText = TRUE)

projection(x) &lt;- value

crs(x, asText = FALSE)

crs(x, ...) &lt;- value

## S4 method for signature 'LASheader'
crs(x, asText = FALSE)

## S4 method for signature 'LAS'
crs(x, asText = FALSE)

## S4 replacement method for signature 'LAS'
crs(x, ...) &lt;- value

## S4 method for signature 'LAScatalog'
crs(x, asText = FALSE)

## S4 method for signature 'LAScluster'
crs(x, asText = FALSE)

## S4 replacement method for signature 'LAScatalog'
crs(x, ...) &lt;- value

## S4 replacement method for signature 'LASheader'
crs(x, ...) &lt;- value

epsg(object, ...)

epsg(object) &lt;- value

## S4 method for signature 'LASheader'
epsg(object, ...)

## S4 replacement method for signature 'LASheader'
epsg(object) &lt;- value

## S4 method for signature 'LAS'
epsg(object)

## S4 replacement method for signature 'LAS'
epsg(object) &lt;- value

wkt(obj)

wkt(obj) &lt;- value

## S4 method for signature 'LASheader'
wkt(obj)

## S4 replacement method for signature 'LASheader'
wkt(obj) &lt;- value

## S4 method for signature 'LAS'
wkt(obj)

## S4 replacement method for signature 'LAS'
wkt(obj) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_crs_+3A_x">x</code>, <code id="st_crs_+3A_object">object</code>, <code id="st_crs_+3A_obj">obj</code></td>
<td>
<p>An object of class LAS*</p>
</td></tr>
<tr><td><code id="st_crs_+3A_...">...</code></td>
<td>
<p>Unused.</p>
</td></tr>
<tr><td><code id="st_crs_+3A_value">value</code></td>
<td>
<p>A <code>CRS</code> or a <code>crs</code> or a <code>proj4string</code> string or WKT string or an EPSG code.</p>
</td></tr>
<tr><td><code id="st_crs_+3A_astext">asText</code></td>
<td>
<p>logical. If TRUE, the projection is returned as text. Otherwise a CRS object is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two ways to store the CRS of a point cloud in a LAS file:
</p>

<ul>
<li><p> Store an EPSG code (for LAS 1.0 to 1.3)
</p>
</li>
<li><p> Store a WTK string (for LAS 1.4)
</p>
</li></ul>

<p>On the other hand, R spatial packages use a <code>crs</code> object to store the CRS. This is why the CRS is duplicated
in a LAS object. The information belongs within the header in a format that can be written in a
LAS file and in the slot <code>crs</code>, and also in a format that can be understood by other R packages.
</p>

<ul>
<li> <p><code>st_crs</code> return the CRS in <code>sf</code> format.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;st_crs&lt;-&#8288;</code>: assigns a CRS from a <code>CRS</code> (<code>sp</code>), a <code>crs</code> (<code>sf</code>), a WKT
string, a proj4string or an epsg code. It updates the header of the LAS
object either with the EPSG code for LAS formats &lt; 1.4 or with a WKT string
</p>
</li>
<li> <p><code>epsg</code>: reads the epsg code from the header.
</p>
</li>
<li> <p><code>wkt</code>: reads the WKT string from the header.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>st_crs()</code> returns a <code>sf::crs</code>. <code>projection()</code> and <code>crs()</code> return a <code>sp::CRS</code> and should
no longer be used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile)

# Get the EPSG code stored in the header (returns 0 if not recorded)
epsg(las)

# Get the WKT string stored in the header (LAS &gt;= 1.4)
wkt(las)

# Overwrite the CRS (but does not reproject)
st_crs(las) &lt;- 26918
las

</code></pre>

<hr>
<h2 id='st_hull'>Concave and convex hulls for LAS objects</h2><span id='topic+st_hull'></span><span id='topic+st_concave_hull'></span><span id='topic+st_convex_hull.LAS'></span><span id='topic+concaveman'></span>

<h3>Description</h3>

<p>Concave and convex hulls for LAS objects. <code>st_convex_hull</code> extends <code>sf::st_convex_hull</code> for LAS
objects. Both functions return a <code>sfc_POLYGON</code>. <code>concaveman</code> is very a fast 2D concave hull algorithm
for a set of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>st_concave_hull(x, method = "concaveman", ...)

## S3 method for class 'LAS'
st_convex_hull(x)

concaveman(x, y = NULL, concavity = 2, length_threshold = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_hull_+3A_x">x</code>, <code id="st_hull_+3A_y">y</code></td>
<td>
<p>An object of class LAS or XY coordinates of points in case of <code>concaveman</code>. This can be
specified as two vectors x and y, a 2-column matrix x, a list with two components, etc.</p>
</td></tr>
<tr><td><code id="st_hull_+3A_method">method</code></td>
<td>
<p>string. currently supports &quot;concaveman&quot;.</p>
</td></tr>
<tr><td><code id="st_hull_+3A_...">...</code></td>
<td>
<p>Propagate to the method.</p>
</td></tr>
<tr><td><code id="st_hull_+3A_concavity">concavity</code></td>
<td>
<p>numeric a relative measure of concavity. 1 results in a relatively detailed shape,
Infinity results in a convex hull. You can use values lower than 1, but they can produce pretty crazy
shapes.</p>
</td></tr>
<tr><td><code id="st_hull_+3A_length_threshold">length_threshold</code></td>
<td>
<p>numeric. When a segment length is below this threshold, it stops being
considered for further detailed processing. Higher values result in simpler shapes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concaveman algorithm is based on ideas from Park and Oh (2012). A first implementation in
JavaScript was proposed by Vladimir Agafonkin in <a href="https://github.com/mapbox/concaveman">mapbox</a>.
This implementation dramatically improved performance over the one stated in the paper
using a spatial index. The algorithm was then ported to R by Joël Gombin in the R package
<a href="https://github.com/joelgombin/concaveman">concaveman</a> that runs the JavaScript
implementation proposed by Vladimir Agafonkin. Later, a C++ version of Vladimir Agafonkin's
JavaScript implementation was proposed by Stanislaw Adaszewski in
<a href="https://github.com/sadaszewski/concaveman-cpp">concaveman-cpp</a>. This concaveman
function uses Stanislaw Adaszewski's C++ code making the concaveman algorithm an
order of magnitude (up to 50 times) faster than the Javascript version.
</p>


<h3>Value</h3>

<p>A <code>sfc_POLYGON</code> from <code>sf</code> or a <code>data.frame</code> in the case of <code>concaveman</code>
</p>


<h3>References</h3>

<p>Park, J.-S &amp; Oh, S.-J. (2013). A New Concave Hull Algorithm and Concaveness Measure
for n-dimensional Datasets. Journal of Information Science and Engineering. 29. 379-392.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(35)
y &lt;- runif(35)
hull &lt;- concaveman(x,y)
plot(x,y, asp = 1)
lines(hull, lwd = 3, col = "red")

LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile, filter = "-drop_z_below 1")
hull = st_concave_hull(las, length_threshold = 10)
plot(hull)
</code></pre>

<hr>
<h2 id='st_transform'>Transform or convert coordinates of LAS objects</h2><span id='topic+st_transform'></span><span id='topic+st_transform.LAS'></span>

<h3>Description</h3>

<p>Transform or convert coordinates of LAS objects  <code>st_transform()</code> extends <code>sf::st_transform()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LAS'
st_transform(x, crs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="st_transform_+3A_x">x</code></td>
<td>
<p>An object of class LAS</p>
</td></tr>
<tr><td><code id="st_transform_+3A_crs">crs</code></td>
<td>
<p>crs object from sf or CRS object from sp</p>
</td></tr>
<tr><td><code id="st_transform_+3A_...">...</code></td>
<td>
<p>additional arguments <code>scale</code> and <code>xoffset</code>, <code>yoffset</code>, <code>zoffset</code>
for the output LAS objects. It is not  mandatory but recommended to consider providing such
information. Otherwise it will be guessed automatically which might not be the best choice.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A LAS object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "example.laz", package="rlas")
las = readLAS(LASfile)
st_crs(las)$Name
st_bbox(las)
tlas &lt;- sf::st_transform(las, sf::st_crs(26918))
st_crs(tlas)$Name
st_bbox(tlas)
</code></pre>

<hr>
<h2 id='stdmetrics'>Predefined standard metrics functions</h2><span id='topic+stdmetrics'></span><span id='topic+stdmetrics_z'></span><span id='topic+stdmetrics_i'></span><span id='topic+stdmetrics_rn'></span><span id='topic+stdmetrics_pulse'></span><span id='topic+stdmetrics_ctrl'></span><span id='topic+stdtreemetrics'></span><span id='topic+stdshapemetrics'></span><span id='topic+.stdmetrics'></span><span id='topic+.stdmetrics_z'></span><span id='topic+.stdmetrics_i'></span><span id='topic+.stdmetrics_rn'></span><span id='topic+.stdmetrics_pulse'></span><span id='topic+.stdmetrics_ctrl'></span><span id='topic+.stdtreemetrics'></span><span id='topic+.stdshapemetrics'></span>

<h3>Description</h3>

<p>Predefined metrics functions intended to me used in <code style="white-space: pre;">&#8288;*_metrics&#8288;</code> function such as
<a href="#topic+pixel_metrics">pixel_metrics</a>, <a href="#topic+cloud_metrics">cloud_metrics</a>, <a href="#topic+crown_metrics">crown_metrics</a>, <a href="#topic+voxel_metrics">voxel_metrics</a> and
so on. Each function comes with a convenient shortcuts for lazy coding. The <code>lidR</code> package aims
to provide an easy way to compute user-defined metrics rather than to provide them. However, for
efficiency and to save time, sets of standard metrics have been predefined (see details). Every
function can be computed by every <code style="white-space: pre;">&#8288;*_metrics&#8288;</code> functions however <code style="white-space: pre;">&#8288;stdmetrics*&#8288;</code> are
more pixel-based metrics, <code>stdtreemetrics</code> are more tree-based metrics and <code>stdshapemetrics</code> are
more point-based metrics. For example the metric <code>zmean</code> computed by <code>stdmetrics_z</code> makes sense
when computed at the pixel level but brings no information at the voxel level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdmetrics(x, y, z, i, rn, class, dz = 1, th = 2, zmin = 0)

stdmetrics_z(z, dz = 1, th = 2, zmin = 0)

stdmetrics_i(i, z = NULL, class = NULL, rn = NULL)

stdmetrics_rn(rn, class = NULL)

stdmetrics_pulse(pulseID, rn)

stdmetrics_ctrl(x, y, z)

stdtreemetrics(x, y, z)

stdshapemetrics(x, y, z)

.stdmetrics

.stdmetrics_z

.stdmetrics_i

.stdmetrics_rn

.stdmetrics_pulse

.stdmetrics_ctrl

.stdtreemetrics

.stdshapemetrics
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdmetrics_+3A_x">x</code>, <code id="stdmetrics_+3A_y">y</code>, <code id="stdmetrics_+3A_z">z</code>, <code id="stdmetrics_+3A_i">i</code></td>
<td>
<p>Coordinates of the points, Intensity</p>
</td></tr>
<tr><td><code id="stdmetrics_+3A_rn">rn</code>, <code id="stdmetrics_+3A_class">class</code></td>
<td>
<p>ReturnNumber, Classification</p>
</td></tr>
<tr><td><code id="stdmetrics_+3A_dz">dz</code></td>
<td>
<p>numeric. Layer thickness  metric <a href="#topic+entropy">entropy</a></p>
</td></tr>
<tr><td><code id="stdmetrics_+3A_th">th</code></td>
<td>
<p>numeric. Threshold for metrics pzabovex. Can be a vector to compute with several thresholds.</p>
</td></tr>
<tr><td><code id="stdmetrics_+3A_zmin">zmin</code></td>
<td>
<p>numeric. Lower bound of the integral for zpcumx metrics.
See <a href="https://github.com/r-lidar/lidR/wiki/stdmetrics">wiki page</a> and Wood et al.
(2008) reference.</p>
</td></tr>
<tr><td><code id="stdmetrics_+3A_pulseid">pulseID</code></td>
<td>
<p>The number referencing each pulse</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>
<p>An object of class <code>formula</code> of length 2.
</p>


<h3>Details</h3>

<p>The function names, their parameters and the output names of the metrics rely on a nomenclature
chosen for brevity:
</p>

<ul>
<li><p><code>z</code>: refers to the elevation
</p>
</li>
<li><p><code>i</code>: refers to the intensity
</p>
</li>
<li><p><code>rn</code>: refers to the return number
</p>
</li>
<li><p><code>q</code>: refers to quantile
</p>
</li>
<li><p><code>a</code>: refers to the ScanAngleRank or ScanAngle
</p>
</li>
<li><p><code>n</code>: refers to a number (a count)
</p>
</li>
<li><p><code>p</code>: refers to a percentage
</p>
</li></ul>

<p>For example the metric named <code>zq60</code> refers to the elevation, quantile, 60 i.e. the 60th percentile
of elevations. The metric <code>pground</code> refers to a percentage. It is the percentage of points
classified as ground. The function <code>stdmetric_i</code> refers to metrics of intensity. A description of
each existing metric can be found on the <a href="https://github.com/r-lidar/lidR/wiki/stdmetrics">lidR wiki page</a>.<br /><br />
Some functions have optional parameters. If these parameters are not provided the function
computes only a subset of existing metrics. For example, <code>stdmetrics_i</code> requires the intensity
values, but if the elevation values are also provided it can compute additional metrics such as
cumulative intensity at a given percentile of height.<br /><br />
Each function has a convenient associated variable. It is the name of the function, with a
dot before the name. This enables the function to be used without writing parameters. The cost
of such a feature is inflexibility. It corresponds to a predefined behaviour (see examples)<br />
</p>

<dl>
<dt><code>stdmetrics</code></dt><dd><p>is a combination of <code>stdmetrics_ctrl</code> + <code>stdmetrics_z</code> +
<code>stdmetrics_i</code> +  <code>stdmetrics_rn</code></p>
</dd>
<dt><code>stdtreemetrics</code></dt><dd><p>is a special function that works with <a href="#topic+crown_metrics">crown_metrics</a>. Actually,
it won't fail with other functions but the output makes more sense if computed at the
individual tree level.</p>
</dd>
<dt><code>stdshapemetrics</code></dt><dd><p>is a set of eigenvalue based feature described in Lucas et al, 2019
(see references).</p>
</dd>
</dl>



<h3>References</h3>

<p>M. Woods, K. Lim, and P. Treitz. Predicting forest stand variables from LiDAR data in
the Great Lakes – St. Lawrence forest of Ontario. The Forestry Chronicle. 84(6): 827-839.
https://doi.org/10.5558/tfc84827-6
</p>
<p>Lucas, C., Bouten, W., Koma, Z., Kissling, W. D., &amp; Seijmonsbergen, A. C. (2019). Identification
of Linear Vegetation Elements in a Rural Landscape Using LiDAR Point Clouds. Remote Sensing, 11(3), 292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las &lt;- readLAS(LASfile, select = "*", filter = "-keep_random_fraction 0.5")

# All the predefined metrics
m1 &lt;- pixel_metrics(las, ~stdmetrics(X,Y,Z,Intensity,ReturnNumber,Classification,dz=1), res = 40)

# Convenient shortcut
m2 &lt;- pixel_metrics(las, .stdmetrics, res = 40)

# Basic metrics from intensities
m3 &lt;- pixel_metrics(las, ~stdmetrics_i(Intensity), res = 40)

# All the metrics from intensities
m4 &lt;- pixel_metrics(las, ~stdmetrics_i(Intensity, Z, Classification, ReturnNumber), res = 40)

# Convenient shortcut for the previous example
m5 &lt;- pixel_metrics(las, .stdmetrics_i, res = 40)

# Combine some predefined function with your own new metrics
# Here convenient shortcuts are no longer usable.
myMetrics = function(z, i, rn)
{
  first  &lt;- rn == 1L
  zfirst &lt;- z[first]
  nfirst &lt;- length(zfirst)
  above2 &lt;- sum(z &gt; 2)

  x &lt;- above2/nfirst*100

  # User's metrics
  metrics &lt;- list(
     above2aboven1st = x,       # Num of returns above 2 divided by num of 1st returns
     zimean  = mean(z*i),       # Mean products of z by intensity
     zsqmean = sqrt(mean(z^2))  # Quadratic mean of z
   )

  # Combined with standard metrics
  return( c(metrics, stdmetrics_z(z)) )
}

m10 &lt;- pixel_metrics(las, ~myMetrics(Z, Intensity, ReturnNumber), res = 40)

# Users can write their own convenient shorcuts like this:
.myMetrics = ~myMetrics(Z, Intensity, ReturnNumber)
m11 &lt;- pixel_metrics(las, .myMetrics, res = 40)

</code></pre>

<hr>
<h2 id='track_sensor'>Reconstruct the trajectory of the LiDAR sensor using multiple returns</h2><span id='topic+track_sensor'></span>

<h3>Description</h3>

<p>Use multiple returns to estimate the positioning of the sensor by computing the intersection in
space of the line passing through the first and last returns. To work, this function requires a
dataset where the 'gpstime', 'ReturnNumber', 'NumberOfReturns' and 'PointSourceID' attributes are
properly populated, otherwise the output may be incorrect or weird. For LAScatalog processing
it is recommended to use large chunks and large buffers (e.g. a swath width). The point cloud must
not be normalized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>track_sensor(
  las,
  algorithm,
  extra_check = TRUE,
  thin_pulse_with_time = 0.001,
  multi_pulse = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="track_sensor_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="track_sensor_+3A_algorithm">algorithm</code></td>
<td>
<p>function. An algorithm to compute sensor tracking. <code>lidR</code> implements
<a href="#topic+Roussel2020">Roussel2020</a> and  <a href="#topic+Gatziolis2019">Gatziolis2019</a> (see respective documentation and examples).</p>
</td></tr>
<tr><td><code id="track_sensor_+3A_extra_check">extra_check</code></td>
<td>
<p>boolean. Datasets are rarely perfectly populated, leading to unexpected errors.
Time-consuming checks of data integrity are performed. These checks can be skipped as they account
for an significant proportion of the computation time. See also section 'Tests of data integrity'.</p>
</td></tr>
<tr><td><code id="track_sensor_+3A_thin_pulse_with_time">thin_pulse_with_time</code></td>
<td>
<p>numeric. In practice, it is not useful to compute the position using all
multiple returns. It is more computationally demanding but not necessarily more accurate. This keeps
only one pulse every x seconds. Set to 0 to use all multiple returns. Use 0 if the file has already
been read with <code>filter = "-thin_pulses_with_time 0.001"</code>.</p>
</td></tr>
<tr><td><code id="track_sensor_+3A_multi_pulse">multi_pulse</code></td>
<td>
<p>logical. TRUE only for systems with multiple pulses. Pulse ID must be recorded
in the UserData attribute.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An sf object with POINT Z geometries. Information about the time interval and the score of
the positioning (according to the method used) are also in the table of attributes.
</p>


<h3>Non-supported LAScatalog options</h3>

<p>The option 'select' is not supported and not respected  because it is internally known what is the
best to select<br />
The option 'output_files' is not supported and not respected because the output must be post-processed
as a whole
</p>


<h3>Test of data integrity</h3>

<p>In theory, sensor tracking is a simple problem to solve as long as each pulse is properly
identified from a well-populated dataset. In practice, many problems may arise from datasets that are populated
incorrectly. Here is a list of problems that may happen. Those with a * denote problems already encountered and
internally checked to remove weird points:
</p>

<ul>
<li><p> 'gpstime' does not record the time at which pulses were emitted and thus pulses are not identifiable
</p>
</li>
<li><p> *A pulse (two or more points that share the same gpstime) is made of points from different
flightlines (different PointSourceID). This is impossible and denotes an improperly populated PointSourceID
attribute.
</p>
</li>
<li><p> 'ReturnNumber' and 'NumberOfReturns' are wrongly populated with either some ReturnNumber &gt; NumberOfReturn
or several first returns by pulses
</p>
</li></ul>

<p>For a given time interval, when weird points are not filtered, the position is not computed for this
interval.
</p>


<h3>Author(s)</h3>

<p>Jean-Francois Bourdon &amp; Jean-Romain Roussel
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A valid file properly populated
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)
#plot(las)

# pmin = 15 because it is an extremely small file
# strongly decimated to reduce its size. There are
# actually few multiple returns
flightlines &lt;- track_sensor(las, Roussel2020(pmin = 15))

plot(las@header)
plot(sf::st_geometry(flightlines), add = TRUE)

#plot(las) |&gt; add_flightlines3d(flightlines, radius = 10)

## Not run: 
# With a LAScatalog "-drop_single" and "-thin_pulses_with_time"
# are used by default
ctg = readLAScatalog("folder/")
flightlines &lt;- track_sensor(ctg,  Roussel2020(pmin = 15))
plot(flightlines)

## End(Not run)
</code></pre>

<hr>
<h2 id='track_sensor_gatziolis2019'>Sensor tracking algorithm</h2><span id='topic+track_sensor_gatziolis2019'></span><span id='topic+Gatziolis2019'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+track_sensor">track_sensor</a>. It implements an algorithm from Gatziolis
and McGaughey 2019 (see reference) for sensor tracking using multiple returns to estimate the positioning
of the sensor by computing the intersection in space of the lines passing through the first and
last returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gatziolis2019(SEGLENFactor = 1.0059, AngleFactor = 0.8824, deltaT = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="track_sensor_gatziolis2019_+3A_seglenfactor">SEGLENFactor</code></td>
<td>
<p>scalar. Weighting factor for the distance b/w 1st and last pulse returns</p>
</td></tr>
<tr><td><code id="track_sensor_gatziolis2019_+3A_anglefactor">AngleFactor</code></td>
<td>
<p>scalar. Weighting factor for view angle of mother pulse of a return</p>
</td></tr>
<tr><td><code id="track_sensor_gatziolis2019_+3A_deltat">deltaT</code></td>
<td>
<p>scalar. TimeBlock duration (in seconds)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the original paper, two steps are described: (1) closest point approach (CPA) and (2) cubic
spline fitting. Technically, the cubic spline fitting step is a post-processing step and is not
included in this algorithm.<br /><br />
The source code of the algorithm is a slight modification of the original source code provided
with the paper to fit with the lidR package.
</p>


<h3>Author(s)</h3>

<p>Demetrios Gaziolis and Jean-Romain Roussel
</p>


<h3>References</h3>

<p>Gatziolis, D., &amp; McGaughey, R. J. (2019). Reconstructing Aircraft Trajectories from
Multi-Return Airborne Laser-Scanning Data. Remote Sensing, 11(19), 2258.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A valid file properly populated
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)
flightlines &lt;- track_sensor(las, Gatziolis2019())

plot(las@header)
plot(flightlines, add = TRUE)
</code></pre>

<hr>
<h2 id='track_sensor_roussel2020'>Sensor tracking algorithm</h2><span id='topic+track_sensor_roussel2020'></span><span id='topic+Roussel2020'></span>

<h3>Description</h3>

<p>This function is made to be used in <a href="#topic+track_sensor">track_sensor</a>. It implements an algorithm from Roussel et
al. 2020 (see reference) for sensor tracking using multiple returns to estimate the positioning of
the sensor by computing the intersection in space of the lines passing through the first and last
returns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Roussel2020(interval = 0.5, pmin = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="track_sensor_roussel2020_+3A_interval">interval</code></td>
<td>
<p>numeric. Interval used to bin the gps times and group the pulses to compute
a position at a given timepoint t.</p>
</td></tr>
<tr><td><code id="track_sensor_roussel2020_+3A_pmin">pmin</code></td>
<td>
<p>integer. Minimum number of pulses needed to estimate a sensor position.
For a given interval, the sensor position is not computed if the number of pulses is lower than
<code>pmin</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When multiple returns from a single pulse are detected, the sensor computes their positions as being
in the center of the footprint and thus all aligned. Because of that behavior, a line
drawn between and beyond those returns must cross the sensor. Thus, several consecutive pulses
emitted in a tight interval (e.g. 0.5 seconds) can be used to approximate an intersection
point in the sky that corresponds to the sensor position given that the sensor carrier hasn't
moved much during this interval. A weighted least squares method gives an approximation of the
intersection by minimizing the squared sum of the distances between the intersection point and all
the lines.
</p>


<h3>References</h3>

<p>Roussel Jean-Romain, Bourdon Jean-Francois, Achim Alexis, (2020) Range-based intensity
normalization of ALS data over forested areas using a sensor tracking method from multiple returns
(preprint) Retrieved from eartharxiv.org/k32qw https://doi.org/10.31223/osf.io/k32qw
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A valid file properly populated
LASfile &lt;- system.file("extdata", "Topography.laz", package="lidR")
las = readLAS(LASfile)

# pmin = 15 because it is an extremely tiny file
# strongly decimated to reduce its size. There are
# actually few multiple returns
flightlines &lt;- track_sensor(las, Roussel2020(pmin = 15))

plot(las@header)
plot(flightlines, add = TRUE)
</code></pre>

<hr>
<h2 id='voxelize_points'>Voxelize a point cloud</h2><span id='topic+voxelize_points'></span>

<h3>Description</h3>

<p>Reduce the number of points by voxelizing the point cloud. If the Intensity is part of the attributes
it is preserved and aggregated as <code>mean(Intensity)</code>. Other attributes cannot be aggregated and
are lost.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>voxelize_points(las, res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="voxelize_points_+3A_las">las</code></td>
<td>
<p>An object of class <a href="#topic+LAS-class">LAS</a> or <a href="#topic+LAScatalog-class">LAScatalog</a>.</p>
</td></tr>
<tr><td><code id="voxelize_points_+3A_res">res</code></td>
<td>
<p>numeric. The resolution of the voxels. <code>res = 1</code> for a 1x1x1 cubic voxels. Optionally
<code>res = c(1,2)</code> for non-cubic voxels (1x1x2 cuboid voxel).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If the input is a <code>LAS</code> object, returns a <code>LAS</code> object. If the input is a
<code>LAScatalog</code>, returns a <code>LAScatalog</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile, select = "xyz")

las2 = voxelize_points(las, 5)
#plot(las2, voxel = TRUE)
</code></pre>

<hr>
<h2 id='writeLAS'>Write a .las or .laz file</h2><span id='topic+writeLAS'></span>

<h3>Description</h3>

<p>Write a <a href="#topic+LAS-class">LAS</a> object into a binary .las or .laz file (compression
specified in filename)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>writeLAS(las, file, index = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="writeLAS_+3A_las">las</code></td>
<td>
<p>an object of class LAS.</p>
</td></tr>
<tr><td><code id="writeLAS_+3A_file">file</code></td>
<td>
<p>character. A character string naming an output file.</p>
</td></tr>
<tr><td><code id="writeLAS_+3A_index">index</code></td>
<td>
<p>boolean. Also write a lax file to index the points in the files</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing. This function is used for its side-effect of writing a file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LASfile &lt;- system.file("extdata", "Megaplot.laz", package="lidR")
las = readLAS(LASfile)
subset = clip_rectangle(las, 684850, 5017850, 684900, 5017900)
writeLAS(subset, tempfile(fileext = ".laz"))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
