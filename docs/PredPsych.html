<!DOCTYPE html><html><head><title>Help for package PredPsych</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PredPsych}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#PredPsych'><p>PredPsych.</p></a></li>
<li><a href='#classifyFun'><p>Generic Classification Analyses</p></a></li>
<li><a href='#ClassPerm'><p>Permutation Analysis for classification</p></a></li>
<li><a href='#DimensionRed'><p>Generic Dimensionallity Reduction Function</p></a></li>
<li><a href='#DTModel'><p>Generic Decision Tree Function</p></a></li>
<li><a href='#fscore'><p>f-score</p></a></li>
<li><a href='#KinData'><p>Kinematics Dataset</p>
A dataset containing part of the motion capture dataset freely available
in the publication (Ansuini et al., 2015).The dataset was obtained by
recording 15 naive participants performing reach-to-grasp movements towards
two differently sized objects:  a small object (i.e., hazelnut) and a
large object (i.e., grapefruit). The variables are as follows:</a></li>
<li><a href='#LinearDA'><p>Cross-validated Linear Discriminant Analysis</p></a></li>
<li><a href='#ModelCluster'><p>Model based Clustering</p></a></li>
<li><a href='#overallConfusionMetrics'><p>Confusion Matrix metrics for Cross-validation</p></a></li>
<li><a href='#predictNewData'><p>Predict Class membership for New Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Predictive Approaches in Psychology</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-07-23</td>
</tr>
<tr>
<td>Author:</td>
<td>Atesh Koul</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Atesh Koul &lt;atesh.koul@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Recent years have seen an increased interest in novel methods
    for analyzing quantitative data from experimental psychology. Currently, however, they lack an
    established and accessible software framework. Many existing implementations provide no guidelines,
    consisting of small code snippets, or sets of packages. In addition, the use of existing packages
    often requires advanced programming experience. 'PredPsych' is a user-friendly toolbox based on
    machine learning predictive algorithms. It comprises of multiple functionalities for multivariate
    analyses of quantitative behavioral data based on machine learning models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>plyr, ggplot2, caret, rpart, e1071, mclust, MASS, party,
randomForest, statmod</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-07-23 08:03:32 UTC; AKoul</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-07-23 08:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='PredPsych'>PredPsych.</h2><span id='topic+PredPsych'></span><span id='topic+PredPsych-package'></span>

<h3>Description</h3>

<p>PredPsych.
</p>


<h3>Details</h3>

<p>&quot;PredPsych&quot; is a user-friendly, R toolbox based on machine learning predictive algorithms.
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Koul, A., Becchio, C., &amp; Cavallo, A. (2017, March 21). 
PredPsych: A toolbox for predictive machine learning based approach in experimental 
psychology research. Retrieved from osf.io/preprints/psyarxiv/pvjac
</p>

<hr>
<h2 id='classifyFun'>Generic Classification Analyses</h2><span id='topic+classifyFun'></span>

<h3>Description</h3>

<p>function for performing generic classification Analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classifyFun(Data, classCol, selectedCols, cvType, ntrainTestFolds,
  nTrainFolds, modelTrainFolds, nTuneFolds, tuneFolds, foldSep, cvFraction,
  ranges = NULL, tune = FALSE, cost = 1, gamma = 0.5,
  classifierName = "svm", genclassifier, silent = FALSE,
  extendedResults = FALSE, SetSeed = TRUE, NewData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classifyFun_+3A_data">Data</code></td>
<td>
<p>(dataframe) dataframe of the data</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_classcol">classCol</code></td>
<td>
<p>(numeric or string) column number that contains the variable to be predicted</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_selectedcols">selectedCols</code></td>
<td>
<p>(optional) (numeric or string) all the columns of data that would be used either as predictor or as feature</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_cvtype">cvType</code></td>
<td>
<p>(optional) (string) which type of cross-validation scheme to follow; One of the following values:
</p>

<ul>
<li><p> folds       =  (default) k-fold cross-validation 
</p>
</li>
<li><p> LOSO        =  Leave-one-subject-out cross-validation
</p>
</li>
<li><p> holdout     =  holdout Crossvalidation. Only a portion of data (cvFraction) is used for training.
</p>
</li>
<li><p> LOTO        =  Leave-one-trial out cross-validation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classifyFun_+3A_ntraintestfolds">ntrainTestFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for training and testing dataset</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_ntrainfolds">nTrainFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds in which to further divide Training dataset</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_modeltrainfolds">modelTrainFolds</code></td>
<td>
<p>=  (optional) (parameter for only k-fold cross-validation) specific folds from the first train/test split
(ntrainTestFolds) to use for training</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_ntunefolds">nTuneFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for Tuning</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_tunefolds">tuneFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) specific folds from the above nTuneFolds to use for tuning</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_foldsep">foldSep</code></td>
<td>
<p>(numeric)  (parameter for only Leave-One_subject Out) mandatory column number for Leave-one-subject out cross-validation.</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_cvfraction">cvFraction</code></td>
<td>
<p>(optional) (numeric) Fraction of data to keep for training data</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_ranges">ranges</code></td>
<td>
<p>(optional) (list)  ranges for tuning support vector machine</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_tune">tune</code></td>
<td>
<p>(optional) (logical) whether tuning of svm parameters should be performed or not</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_cost">cost</code></td>
<td>
<p>(optional) (numeric) regularization parameter of svm</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_gamma">gamma</code></td>
<td>
<p>(optional) (numeric)  rbf kernel parameter</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_classifiername">classifierName</code></td>
<td>
<p>(optional) (string) name of the classifier to be used</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_genclassifier">genclassifier</code></td>
<td>
<p>(optional) (function or string) a classifier function or a name (e.g. Classifier.svm)</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_extendedresults">extendedResults</code></td>
<td>
<p>(optional) (logical) Return extended results with model and other metrics</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_setseed">SetSeed</code></td>
<td>
<p>(optional) (logical) Whether to setseed or not. use SetSeed to seed the random number generator to get consistent results; 
set false only for permutation tests</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_newdata">NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td></tr>
<tr><td><code id="classifyFun_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements Classification Analysis. 
Classification Analysis is a supervised machine learning approach that attempts to identify 
holistic patters in the data and assign to it classes (classification). Given a set of features, 
a classification analysis automatically learns intrinsic patterns in the data to be able to predict 
respective classes. If the data features are informative about the classes, a high classification score
would be achieved.
</p>


<h3>Value</h3>

<p>Depending upon <code>extendedResults</code>. <code>extendedResults</code>  = FALSE outputs Test accuracy <code>accTest</code> of discrimination; <code>extendedResults</code> = TRUE 
outputs Test accuracy <code>accTest</code> of discrimination, <code>accTestRun</code> discrimination for each run in case of cvType as LOSO,LOTO or Folds <code>ConfMatrix</code> Confusion matrices and <code>classificationResults</code> list of the cross-validation results including the model 
and  <code>ConfusionMatrixResults</code> Overall cross-validated confusion matrix results
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Duda, R. O., Hart, P. E., &amp; Stork, D. G. (2000). Pattern Classification. Wiley-Interscience (Vol. 24).
</p>
<p>Vapnik, V. (1995). The Nature of statistical Learning Theory. Springer-Verlag New York.
</p>
<p>Hsu, C. C., Chang, C. C., &amp; Lin, C. C. (2003). A practical guide to support vector classification, 1(1), 1-16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># classification analysis with SVM
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType="holdout")

# Output:

# Performing Classification Analysis
#
# Performing holdout Cross-validation
# genclassifier was not specified, 
#   Using default value of Classifier.svm (genclassifier = Classifier.svm)"
# 
# cvFraction was not specified, 
#  Using default value of 0.8 (cvFraction = 0.8)
# 
# Proportion of Test/Train Data was :  0.2470588 
# [1] "Test holdout Accuracy is  0.65"
# holdout classification Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.65
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = Accuracy from the Testing dataset

# Alternate uses:
# perform a k-folds cross-validated classification analysis:
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType = "folds")

# use extendedResults as well as tuning
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
cvType = "folds",extendedResults = TRUE,tune=TRUE)



</code></pre>

<hr>
<h2 id='ClassPerm'>Permutation Analysis for classification</h2><span id='topic+ClassPerm'></span>

<h3>Description</h3>

<p>simple function to create permutation testing of a classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClassPerm(Data, classCol, selectedCols, classifierFun, nSims = 1000,
  plot = TRUE, silent = FALSE, progress_bar = progress_time(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClassPerm_+3A_data">Data</code></td>
<td>
<p>(dataframe) dataframe of the data</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_classcol">classCol</code></td>
<td>
<p>(numeric or string) column number that contains the variable to be predicted</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_selectedcols">selectedCols</code></td>
<td>
<p>(optional) (numeric or string) all the columns of data that would be used either as predictor or as feature</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_classifierfun">classifierFun</code></td>
<td>
<p>(optional) (function) classifier function</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_nsims">nSims</code></td>
<td>
<p>(optional) (numeric) number of simulations</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_plot">plot</code></td>
<td>
<p>(optional) (logical) whether to plot null accuracy distribution</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_progress_bar">progress_bar</code></td>
<td>
<p>(optional) the type of progress bar to be utilized</p>
</td></tr>
<tr><td><code id="ClassPerm_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements Permutation tests for classification.
Permutation tests are a set of non-parametric methods for hypothesis testing without assuming 
a particular distribution (Good, 2005). In case of classification analysis, this requires 
shuffling the labels of the dataset (i.e. randomly shuffling classes/conditions between observations)
and calculating accuracies obtained.
</p>


<h3>Value</h3>

<p>Returns <code>actualAcc</code> of the classification analysis,
<code>p-value</code> from permutation testing, <code>nullAcc</code> distribution of the permutation <code>figure</code> containing null distribution
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Phipson, B., &amp; Smyth, G. K. (2010). Permutation P-values Should Never Be Zero: Calculating Exact P-values When Permutations Are Randomly Drawn. 
Statistical Applications in Genetics and Molecular Biology, 9(1), 1544-6115.
</p>
<p>Ojala, M. &amp; Garriga, G. C. Permutation Tests for Studying Classifier Performance. J. Mach. Learn. Res. 11, 1833-1863 (2010).
</p>
<p>Good, P. (2005). Permutation, Parametric and Bootstrap Tests of Hypotheses. New York: Springer-Verlag.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># perform a permutation testing for 10% of the kinematics movement data#' 
# not run
# PermutationResult &lt;- ClassPerm(Data = KinData, classCol = 1,
# selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112), nSims = 1000,cvType = "holdout")
# Output:
# Performing Permutation Analysis for Classification
#
# Performing Cross-validation
#
# Performing holdout Cross-validation 
# genclassifier was not specified, 
#  Using default value of Classifier.svm (genclassifier = Classifier.svm)
#
# cvFraction was not specified, 
#  Using default value of 0.8 (cvFraction = 0.8)
#
# Proportion of Test/Train Data was :  0.2470588 
# [1] "Test holdout Accuracy is  0.65"
# holdout classification Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.65
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = Accuracy from the Testing dataset
# 
# Performing permutation testing...
# Performing 1000 simulations 
# |=======================================================
# ==================================================================|100%
#                      Completed after 2 m 
# The p-value of the permutation testing is 0.001
# p-value generated using the approximate method for p-value calculation. 
# See Phipson, B. &amp; Gordon K., S. (2010) for details


# Using LinearDA instead as function
# not run
# PermutationResult &lt;- ClassPerm(Data = KinData, classCol = 1,
# selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112), nSims = 1000,classifierFun = LinearDA)


# Any minimalistic function can be used 
# The ClassPerm function sends the dataframe Data, classCol, 
# selectedCols as arguments
# not run
# myMinimalFun &lt;- function(...){
# ***Calculate Error function as you want***
# return(accTest)
# } 
# Use the function for permutation testing e.g.
# Results &lt;- ClassPerm(Data = KinData, classCol=1,
# selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112), 
# nSims = 1000,classifierFun = myMinimalFun)



</code></pre>

<hr>
<h2 id='DimensionRed'>Generic Dimensionallity Reduction Function</h2><span id='topic+DimensionRed'></span>

<h3>Description</h3>

<p>A simple function to perform dimensionality reduction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DimensionRed(Data, method = "MDS", selectedCols, outcome = NA,
  plot = FALSE, silent = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DimensionRed_+3A_data">Data</code></td>
<td>
<p>(dataframe)  a data frame with variable/feature columns</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_method">method</code></td>
<td>
<p>(optional) (character) Dimensionality reduction method to be used</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_selectedcols">selectedCols</code></td>
<td>
<p>(optional)(numeric) which columns should be treated as data(features/columns) (defaults to all columns)</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_outcome">outcome</code></td>
<td>
<p>(optional)(vector) optional vector for visualising plots</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_plot">plot</code></td>
<td>
<p>(optional)(logical) To plot or not to plot</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="DimensionRed_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dimensionality Reduction is the process of reducing the dimensions of the dataset. 
Multivariate data, even though are useful in getting an overall understanding of the underlying phenomena,
do not permit easy interpretability. Moreover, variables in such data often are correlated with each other
.For these reasons, it might be imperative to reduce the dimensions of the data. 
Various models have been developed for such dimensionality reduction. Of these, MDS and PCA has been 
demonstrated in the current implementation.
</p>


<h3>Value</h3>

<p>Data frame with <code>Results</code>
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Bishop, C. M. (2006). Pattern Recognition and Machine Learning. (M. Jordan, J. Kleinberg, &amp; B. Scholkopf, Eds.) 
(1st ed.). Springer-Verlag New York.
</p>
<p>Cox, T. F., &amp; Cox, M. A. A. (2000). Multidimensional scaling (Second ed.). Chapman &amp; Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># reducing dimension of Grip aperture from 10 to 2
GripAperture &lt;- DimensionRed(KinData,selectedCols = 12:21,
outcome = KinData[,"Object.Size"],plot = TRUE)

</code></pre>

<hr>
<h2 id='DTModel'>Generic Decision Tree Function</h2><span id='topic+DTModel'></span>

<h3>Description</h3>

<p>A simple function to create Decision Trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DTModel(Data, classCol, selectedCols, tree, cvType, nTrainFolds,
  ntrainTestFolds, modelTrainFolds, foldSep, cvFraction,
  extendedResults = FALSE, SetSeed = TRUE, silent = FALSE,
  NewData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DTModel_+3A_data">Data</code></td>
<td>
<p>(dataframe) a data frame with regressors and response</p>
</td></tr>
<tr><td><code id="DTModel_+3A_classcol">classCol</code></td>
<td>
<p>(numeric or string) which column should be used as response col</p>
</td></tr>
<tr><td><code id="DTModel_+3A_selectedcols">selectedCols</code></td>
<td>
<p>(optional) (numeric or string) which columns should be treated as data(features + response) (defaults to all columns)</p>
</td></tr>
<tr><td><code id="DTModel_+3A_tree">tree</code></td>
<td>
<p>which decision tree model to implement; One of the following values:
</p>

<ul>
<li><p> CART        =   Classification And Regression Tree; 
</p>
</li>
<li><p> CARTNACV    =   Crossvalidated CART Tree removing missing values;
</p>
</li>
<li><p> CARTCV      =   Crossvalidated CART Tree With missing values;
</p>
</li>
<li><p> CF          =   Conditional inference framework Tree;
</p>
</li>
<li><p> RF          =   Random Forest Tree;    
</p>
</li></ul>
</td></tr>
<tr><td><code id="DTModel_+3A_cvtype">cvType</code></td>
<td>
<p>(optional) (string) which type of cross-validation scheme to follow - only in case of CARTCV or CARTNACV;
One of the following values:
</p>

<ul>
<li><p> folds       =   (default) k-fold cross-validation 
</p>
</li>
<li><p> LOSO        =   Leave-one-subject-out cross-validation
</p>
</li>
<li><p> holdout     =   holdout Crossvalidation. Only a portion of data (cvFraction) is used for training.
</p>
</li>
<li><p> LOTO        =   Leave-one-trial out cross-validation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="DTModel_+3A_ntrainfolds">nTrainFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds in which to further divide Training dataset</p>
</td></tr>
<tr><td><code id="DTModel_+3A_ntraintestfolds">ntrainTestFolds</code></td>
<td>
<p>(optional) (parameter for only k-fold cross-validation) No. of folds for training and testing dataset</p>
</td></tr>
<tr><td><code id="DTModel_+3A_modeltrainfolds">modelTrainFolds</code></td>
<td>
<p>=   (optional) (parameter for only k-fold cross-validation) specific folds from the first train/test split
(ntrainTestFolds) to use for training</p>
</td></tr>
<tr><td><code id="DTModel_+3A_foldsep">foldSep</code></td>
<td>
<p>(numeric)  (parameter for only Leave-One_subject Out) mandatory column number for Leave-one-subject out cross-validation.</p>
</td></tr>
<tr><td><code id="DTModel_+3A_cvfraction">cvFraction</code></td>
<td>
<p>(optional) (numeric) Fraction of data to keep for training data</p>
</td></tr>
<tr><td><code id="DTModel_+3A_extendedresults">extendedResults</code></td>
<td>
<p>(optional) (logical) Return extended results with model and other metrics</p>
</td></tr>
<tr><td><code id="DTModel_+3A_setseed">SetSeed</code></td>
<td>
<p>(optional) (logical) Whether to setseed or not. use SetSeed to seed the random number generator to get consistent results;</p>
</td></tr>
<tr><td><code id="DTModel_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="DTModel_+3A_newdata">NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td></tr>
<tr><td><code id="DTModel_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements the Decision Tree models (DT models).
DT models fall under the general &quot;Tree based methods&quot;
involving generation of a recursive binary tree (Hastie et al., 2009).
In terms of input, DT  models can handle both continuous and categorical variables
as well as missing data. From the input data, DT  models build a set of logical &quot;if ..then&quot; rules
that permit accurate prediction of the input cases.
</p>
<p>The function &quot;rpart&quot; handles the missing data by creating surrogate variables 
instead of removing them entirely (Therneau, &amp; Atkinson, 1997). 
This could be useful in case the data contains multiple missing values. 
</p>
<p>Unlike regression methods like GLMs,  Decision Trees are more flexible and can model nonlinear interactions.
</p>


<h3>Value</h3>

<p>model result for the input tree <code>Results</code>  or Test accuracy <code>accTest</code> based on <code>tree</code>. If <code>extendedResults</code> = TRUE 
outputs Test accuracy <code>accTest</code> of discrimination,<code>ConfMatrix</code> Confusion matrices and <code>fit</code> the model 
and  <code>ConfusionMatrixResults</code> Overall cross-validated confusion matrix results
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The Elements of Statistical Learning. 
Springer Series in Statistics (2nd ed., Vol. 1). New York, NY: Springer New York.
</p>
<p>Terry Therneau, Beth Atkinson and Brian Ripley (2015). rpart: Recursive Partitioning and Regression Trees. 
R package version 4.1-10.  https://CRAN.R-project.org/package=rpart
</p>
<p>Therneau, T. M., &amp; Atkinson, E. J. (1997). An introduction to recursive partitioning using the RPART routines (Vol. 61, p. 452).
Mayo Foundation: Technical report.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate a cart model for 10% of the data with cross-validation
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112), tree='CARTCV',cvType = "holdout")
# Output:
# Performing Decision Tree Analysis 
#
# [1] "Generating crossvalidated Tree With Missing Values"
#
# Performing holdout Cross-validation
# 
# cvFraction was not specified,
#  Using default value of 0.8 (cvFraction = 0.8)" 
# Proportion of Test/Train Data was :  0.2470588 
# 
# [1] "Test holdout Accuracy is  0.62"
# holdout CART Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.62
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = Accuracy from the Testing dataset

#' # --CART MOdel --

# Alternate uses:  
# k-fold cross-validation with removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTNACV',cvType="folds")

# holdout cross-validation without removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTCV',cvType = "holdout")

# k-fold cross-validation without removing missing values
model &lt;- DTModel(Data = KinData,classCol=1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
tree='CARTCV',cvType="folds")

</code></pre>

<hr>
<h2 id='fscore'>f-score</h2><span id='topic+fscore'></span>

<h3>Description</h3>

<p>A simple function to generate F-scores (Fisher scores) for ranking features
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fscore(Data, classCol, featureCol, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fscore_+3A_data">Data</code></td>
<td>
<p>(dataframe) Data dataframe</p>
</td></tr>
<tr><td><code id="fscore_+3A_classcol">classCol</code></td>
<td>
<p>(numeric) column with different classes</p>
</td></tr>
<tr><td><code id="fscore_+3A_featurecol">featureCol</code></td>
<td>
<p>(numeric) all the columns that contain features</p>
</td></tr>
<tr><td><code id="fscore_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements F-score for feature selection.
F-score provides a measure of how well a single feature at a time can discriminate between different 
classes. The higher the F-score, the better the discriminatory power of that feature
</p>
<p>The F-score is calculated for two classes
</p>


<h3>Value</h3>

<p>named numeric <code>f-scores</code>
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Duda, R. O., Hart, P. E., &amp; Stork, D. G. (2000). Pattern Classification. Wiley-Interscience (Vol. 24).
</p>
<p>Chen, Y., &amp; Lin, C.-J. (2006). Combining SVMs with Various Feature Selection Strategies.
In I. Guyon, M. Nikravesh, S. Gunn, &amp; L. A. Zadeh (Eds.), 
Feature Extraction: Foundations and Applications (Vol. 324, pp. 315-324). 
Berlin, Heidelberg: Springer Berlin Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># calculate f-scores for 10% of movement
fscore(KinData,classCol = 1,featureCol = c(2,12,22,32,42,52,62,72,82,92,102,112))
# Output:
# Performing Feature selection f-score analysis 
# --f-scores--

</code></pre>

<hr>
<h2 id='KinData'>Kinematics Dataset
A dataset containing part of the motion capture dataset freely available 
in the publication (Ansuini et al., 2015).The dataset was obtained by 
recording 15 naive participants performing reach-to-grasp movements towards 
two differently sized objects:  a small object (i.e., hazelnut) and a 
large object (i.e., grapefruit). The variables are as follows:</h2><span id='topic+KinData'></span>

<h3>Description</h3>


<ul>
<li><p> Object Size :                              Size of the to-be-grasped object
(1 = small, 2 = large)
</p>
</li>
<li><p> Wrist_Velocity_01 .. Wrist_Height_10:      module of the velocity of the wrist marker
(mm/sec) from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> Grip_Aperture_01 .. Grip_Aperture_10       Distance between the marker placed 
on thumb tip and that placed on the tip of the index finger (mm) from 10% (_01) 
to 100% (_10) of the movement
</p>
</li>
<li><p> Wrist_Height_01 .. Wrist_Height_10         z-component of the wrist marker (mm)
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> x_index_01 .. x_index_10 :                 x-coordinates for the index with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> y_index_01 .. y_index_10 :                 y-coordinates for the index with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> z_index_01 .. z_index_10 :                 z-coordinates for the index with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> x_thumb_01 .. x_thumb_10 :                 x-coordinates for the thumb with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> y_thumb_01 .. y_thumb_10 :                 y-coordinates for the thumb with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> z_thumb_01 .. z_thumb_10 :                 z-coordinates for the thumb with respect to F-local (mm) 
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> x_finger_plane_01 .. x_finger_plane_10     x-components of the thumb-index plane
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> y_finger_plane_01 .. y_finger_plane_10     y-components of the thumb-index plane
from 10% (_01) to 100% (_10) of the movement
</p>
</li>
<li><p> z_finger_plane_01 .. z_finger_plane_10     z-components of the thumb-index plane
from 10% (_01) to 100% (_10) of the movement
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(KinData)
</code></pre>


<h3>Format</h3>

<p>A data frame with 848 rows and 121 variables</p>

<hr>
<h2 id='LinearDA'>Cross-validated Linear Discriminant Analysis</h2><span id='topic+LinearDA'></span>

<h3>Description</h3>

<p>A simple function to perform cross-validated Linear Discriminant Analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinearDA(Data, classCol, selectedCols, cvType, nTrainFolds,
  ntrainTestFolds, modelTrainFolds, foldSep, CV = FALSE, cvFraction,
  extendedResults = FALSE, SetSeed = TRUE, silent = FALSE,
  NewData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LinearDA_+3A_data">Data</code></td>
<td>
<p>(dataframe) Data dataframe</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_classcol">classCol</code></td>
<td>
<p>(numeric or string)  column number that contains the variable to be predicted</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_selectedcols">selectedCols</code></td>
<td>
<p>(optional) (numeric or string) all the columns of data that would be used either as predictor or as feature</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_cvtype">cvType</code></td>
<td>
<p>(optional) (string) which type of cross-validation scheme to follow; One of the following values:
</p>

<ul>
<li><p> folds        =   (default) k-fold cross-validation 
</p>
</li>
<li><p> LOSO         =   Leave-one-subject-out cross-validation
</p>
</li>
<li><p> holdout      =   holdout Crossvalidation. Only a portion of data (cvFraction) is used for training.
</p>
</li>
<li><p> LOTO         =   Leave-one-trial out cross-validation.      
</p>
</li></ul>
</td></tr>
<tr><td><code id="LinearDA_+3A_ntrainfolds">nTrainFolds</code></td>
<td>
<p>=    (optional) (parameter for only k-fold cross-validation) No. of folds in which to further divide Training dataset</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_ntraintestfolds">ntrainTestFolds</code></td>
<td>
<p>=    (optional) (parameter for only k-fold cross-validation) No. of folds for training and testing dataset</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_modeltrainfolds">modelTrainFolds</code></td>
<td>
<p>=    (optional) (parameter for only k-fold cross-validation) specific folds from the first train/test split
(ntrainTestFolds) to use for training</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_foldsep">foldSep</code></td>
<td>
<p>(numeric)  (parameter for only Leave-One_subject Out) mandatory column number for Leave-one-subject out cross-validation.</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_cv">CV</code></td>
<td>
<p>(optional) (logical) perform Cross validation of training dataset? 
If TRUE, posterior probabilites are present with the model</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_cvfraction">cvFraction</code></td>
<td>
<p>(optional) (numeric) Fraction of data to keep for training data</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_extendedresults">extendedResults</code></td>
<td>
<p>(optional) (logical) Return extended results with model  and other metrics</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_setseed">SetSeed</code></td>
<td>
<p>(optional) (logical) Whether to setseed or not. use SetSeed to seed the random number generator to get consistent results; 
set false only for permutation tests</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_newdata">NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td></tr>
<tr><td><code id="LinearDA_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements Linear Disciminant Analysis, a simple algorithm for classification based analyses
.LDA builds a model composed of a number of discriminant functions based on linear combinations of 
data features that provide the best discrimination between two or more conditions/classes. 
The aim of the statistical analysis in LDA is thus to combine the data features scores in a way that 
a single new composite variable, the discriminant function, is produced (for details see Fisher, 1936;
Rao, 1948)).
</p>


<h3>Value</h3>

<p>Depending upon <code>extendedResults</code>. <code>extendedResults</code>  = FALSE outputs Test accuracy <code>accTest</code> of discrimination; <code>extendedResults</code> = TRUE 
outputs Test accuracy <code>accTest</code> of discrimination, <code>ConfusionMatrixResults</code> Overall cross-validated confusion matrix results,<code>ConfMatrix</code> Confusion matrices
and <code>fitLDA</code> the fit cross-validated LDA model. If <code>CV</code> = TRUE , 
Posterior probabilities are generated and stored in the model.
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Fisher, R. A. (1936). The Use of Multiple Measurements in Taxonomic Problems. Annals of Eugenics, 7(2), 179-188.
</p>
<p>Rao, C. (1948). The Utilization of Multiple Measurements in Problems of Biological Classification. 
In Journal of the Royal Statistical Society. Series B (Methodological) (Vol. 10, pp. 159-203).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple model with holdout data partition of 80% and no extended results 
LDAModel &lt;- LinearDA(Data = KinData, classCol = 1, 
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType="holdout")
# Output:
#
# Performing Linear Discriminant Analysis
#
#
# Performing holdout Cross-validation
# 
# cvFraction was not specified,
#  Using default value of 0.8 (80%) fraction for training (cvFraction = 0.8)
# 
# Proportion of Test/Train Data was :  0.2470588 
# Predicted
# Actual  1  2
# 1 51 32
# 2 40 45
# [1] "Test holdout Accuracy is 0.57"
# holdout LDA Analysis: 
# cvFraction : 0.8 
# Test Accuracy 0.57
# *Legend:
# cvFraction = Fraction of data to keep for training data 
# Test Accuracy = mean accuracy from the Testing dataset

# alt uses:
# holdout cross-validation with 80% training data
LDAModel &lt;- LinearDA(Data = KinData, classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
CV=FALSE,cvFraction = 0.8,extendedResults = TRUE,cvType="holdout")

# For a 10 fold cross-validation without outputting messages 
LDAModel &lt;-  LinearDA(Data = KinData, classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),
extendedResults = FALSE,cvType = "folds",nTrainFolds=10,silent = TRUE)

</code></pre>

<hr>
<h2 id='ModelCluster'>Model based Clustering</h2><span id='topic+ModelCluster'></span>

<h3>Description</h3>

<p>A simple function to perform Model based cluster Analysis
:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ModelCluster(Data, NewData = NULL, G, silent = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ModelCluster_+3A_data">Data</code></td>
<td>
<p>(dataframe) Data dataframe</p>
</td></tr>
<tr><td><code id="ModelCluster_+3A_newdata">NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame for which the class membership is requested</p>
</td></tr>
<tr><td><code id="ModelCluster_+3A_g">G</code></td>
<td>
<p>(optional) (numeric) No. of components to verify</p>
</td></tr>
<tr><td><code id="ModelCluster_+3A_silent">silent</code></td>
<td>
<p>(optional) (logical) whether to print messages or not</p>
</td></tr>
<tr><td><code id="ModelCluster_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements Model based clustering in predictive framework. Model based clustering approaches provide a
structured way of choosing number of clusters (C. Fraley &amp; Raftery, 1998). 
Data are considered to be generated from a set of Gaussian distributions (components or clusters) 
i.e. as a mixture of these components (mixture models). Instead of using heuristics, model based 
clustering approximates Bayes factor (utilizing Bayesian information Criterion) to determine the model 
with the highest evidence (as provided by the data).
</p>


<h3>Value</h3>

<p><code>class membership</code> of the clustered <code>NewData</code>
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Han, J., Kamber, M., &amp; Pei, J. (2012). Cluster Analysis. In Data Mining (pp. 443-495). Elsevier.
</p>
<p>Fraley, C., &amp; Raftery, a E. (1998). How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis.
The Computer Journal, 41(8), 578-588.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># clustering kinematics data at 10% of movement
# not run
# cluster_time &lt;- ModelCluster(KinData[,c(2,12,22,32,42,52,62,72,82,92,102,112)],G=1:12)
# Output:
# Performing Cluster analysis 
# --cluster Results --
</code></pre>

<hr>
<h2 id='overallConfusionMetrics'>Confusion Matrix metrics for Cross-validation</h2><span id='topic+overallConfusionMetrics'></span>

<h3>Description</h3>

<p>A simple function to generate confusion matrix metrics for cross-validated Analyses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overallConfusionMetrics(confusionMat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overallConfusionMetrics_+3A_confusionmat">confusionMat</code></td>
<td>
<p>(confusion matrix or a list of it) Input confusion Matrix generated by function confusionMatrix from caret library</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function to output confusion matrices and related metrics of sensitivity, specificity, precision, recall and other metrics for cross-validated analyses.
There are multiple documented ways of calculating confusion matrix metrics for cross-validation
(see Forman and Scholz 2012 for details on F1 score). The current procedure generates a final bigger 
confusion matrix and calculates the measures of sensitivity, specificity etc. on this matrix (instead of
averaging sensitivities, specificities in each fold).
</p>
<p>The intuition from (Kelleher, Namee and D'Arcy 2015) is:
</p>
<p>&quot;When we have a small dataset (introducing the possibility of a lucky split) measuring
aggregate performance using a set of models gives a better estimate of post-deployment performance than
measuring performance using a single model.&quot;
</p>
<p>In addition, (Forman and Scholz 2010) using simulation studies show that F1 values calculated this way are 
less biased.
</p>


<h3>Value</h3>

<p>A list with metrics as generated by confusionMatrix function in caret library.
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>


<h3>References</h3>

<p>Kelleher, J. D., Namee, B. Mac &amp; D'Arcy, A. Fundamentals of Machine Learning for Predictive Data Analytics. (The MIT Press, 2015).
Section 8.4.1.2
Elkan, C. Evaluating Classifiers. (2012).https://pdfs.semanticscholar.org/2bdc/61752a02783aa0e69e92fe6f9b449916a095.pdf
pp. 4
</p>
<p>Forman, G. &amp; Scholz, M. Apples-to-apples in cross-validation studies. ACM SIGKDD Explor. Newsl. 12, 49 (2010).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Result from a confusion matrix 
confusionMat &lt;- list(table = matrix(c(110,29,80,531),ncol = 2,
dimnames = list(Prediction = c(1,2),Reference = c(1,2))))
overallConfusionMetrics(confusionMat)

# Output:
#
# Confusion Matrix and Statistics
#           Reference
# Predicted   1   2
#          1 110  80
#          2  29 531
# Accuracy : 0.8547          
# 95% CI : (0.8274, 0.8791)
# No Information Rate : 0.8147          
# P-Value [Acc &gt; NIR] : 0.002214        
# 
# Kappa : 0.5785          
# Mcnemar's Test P-Value : 1.675e-06       
# 
# Sensitivity : 0.7914          
# Specificity : 0.8691          
# Pos Pred Value : 0.5789          
# Neg Pred Value : 0.9482          
# Prevalence : 0.1853          
# Detection Rate : 0.1467          
# Detection Prevalence : 0.2533          
# Balanced Accuracy : 0.8302          
# 
# 'Positive' Class : 1         

# Alternative (realistic) examples
Results &lt;- classifyFun(Data = KinData,classCol = 1,
selectedCols = c(1,2,12,22,32,42,52,62,72,82,92,102,112),cvType = "folds",
extendedResults = TRUE)

overallConfusionMetrics(Results$ConfMatrix)



</code></pre>

<hr>
<h2 id='predictNewData'>Predict Class membership for New Data</h2><span id='topic+predictNewData'></span>

<h3>Description</h3>

<p>A simple function to predict class membership for new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictNewData(model, NewData, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictNewData_+3A_model">model</code></td>
<td>
<p>(model)     Classifier model obtained from a classification analysis</p>
</td></tr>
<tr><td><code id="predictNewData_+3A_newdata">NewData</code></td>
<td>
<p>(optional) (dataframe) New Data frame features for which the class membership is requested</p>
</td></tr>
<tr><td><code id="predictNewData_+3A_...">...</code></td>
<td>
<p>(optional) additional arguments for the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function to generate predictions on a new dataset based on a previously estimated classifier model.
This could be generated from LinearDA, classifyFun or DTMOdel functions.
</p>


<h3>Value</h3>

<p>Predictions for each case in the NewData.
</p>


<h3>Author(s)</h3>

<p>Atesh Koul, C'MON unit, Istituto Italiano di Tecnologia
</p>
<p><a href="mailto:atesh.koul@gmail.com">atesh.koul@gmail.com</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
