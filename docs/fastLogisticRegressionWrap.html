<!DOCTYPE html><html lang="en"><head><title>Help for package fastLogisticRegressionWrap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fastLogisticRegressionWrap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#asymmetric_cost_explorer'><p>Asymmetric Cost Explorer</p></a></li>
<li><a href='#confusion_results'><p>Binary Confusion Table and Errors</p></a></li>
<li><a href='#eigen_compute_single_entry_of_diagonal_matrix'><p>Compute Single Value of the Diagonal of a Symmetric Matrix's Inverse</p></a></li>
<li><a href='#eigen_det'><p>A fast det(X) function</p></a></li>
<li><a href='#eigen_inv'><p>A fast solve(X) function</p></a></li>
<li><a href='#eigen_Xt_times_diag_w_times_X'><p>A fast Xt [times] diag(w) [times] X function</p></a></li>
<li><a href='#fast_logistic_regression'><p>FastLR Wrapper</p></a></li>
<li><a href='#fast_logistic_regression_stepwise_forward'><p>Rapid Forward Stepwise Logistic Regression</p></a></li>
<li><a href='#fastLogisticRegressionWrap'><p>A Wrapper for FastLR</p></a></li>
<li><a href='#general_confusion_results'><p>General Confusion Table and Errors</p></a></li>
<li><a href='#predict.fast_logistic_regression'><p>FastLR Wrapper Predictions</p></a></li>
<li><a href='#predict.fast_logistic_regression_stepwise'><p>FastLR Wrapper Predictions</p></a></li>
<li><a href='#print.fast_logistic_regression'><p>FastLR Wrapper Print</p></a></li>
<li><a href='#print.fast_logistic_regression_stepwise'><p>FastLR Wrapper Print</p></a></li>
<li><a href='#summary.fast_logistic_regression'><p>FastLR Wrapper Summary</p></a></li>
<li><a href='#summary.fast_logistic_regression_stepwise'><p>FastLR Wrapper Summary</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Logistic Regression Wrapper</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-07</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Provides very fast logistic regression with coefficient inferences plus other useful methods such as a forward stepwise model generator (see the benchmarks by visiting the github page at the URL below). The inputs are flexible enough to accomodate GPU computations. The coefficient estimation employs the fastLR() method in the 'RcppNumerical' package by Yixuan Qiu et al. This package allows their work to be more useful to a wider community that consumes inference.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RcppNumerical, Rcpp, checkmate, stats, MASS, methods</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kapelner/fastLogisticRegressionWrap">https://github.com/kapelner/fastLogisticRegressionWrap</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kapelner/fastLogisticRegressionWrap/issues">https://github.com/kapelner/fastLogisticRegressionWrap/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-06 13:08:24 UTC; kapel</td>
</tr>
<tr>
<td>Author:</td>
<td>Adam Kapelner <a href="https://orcid.org/0000-0001-5985-6792"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Beau Walker <a href="https://orcid.org/0000-0001-7872-4007"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [rev,
    dtc],
  Gabriel Mayer [fnd, dtc]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adam Kapelner &lt;kapelner@qc.cuny.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-08 15:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='asymmetric_cost_explorer'>Asymmetric Cost Explorer</h2><span id='topic+asymmetric_cost_explorer'></span>

<h3>Description</h3>

<p>Given a set of desired proportions of predicted outcomes, what is the error rate for each of those models?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asymmetric_cost_explorer(
  phat,
  ybin,
  steps = seq(from = 0.001, to = 0.999, by = 0.001),
  outcome_of_analysis = 0,
  proportions_desired = seq(from = 0.1, to = 0.9, by = 0.1),
  proportion_tolerance = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asymmetric_cost_explorer_+3A_phat">phat</code></td>
<td>
<p>The vector of probability estimates to be thresholded to make a binary decision</p>
</td></tr>
<tr><td><code id="asymmetric_cost_explorer_+3A_ybin">ybin</code></td>
<td>
<p>The true binary responses</p>
</td></tr>
<tr><td><code id="asymmetric_cost_explorer_+3A_steps">steps</code></td>
<td>
<p>All possibile thresholds which must be a vector of numbers in (0, 1). Default is <code>seq(from = 0.001, to = 0.999, by = 0.001)</code>.</p>
</td></tr>
<tr><td><code id="asymmetric_cost_explorer_+3A_outcome_of_analysis">outcome_of_analysis</code></td>
<td>
<p>Which class do you care about performance? Either 0 or 1 for the negative class or positive class. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="asymmetric_cost_explorer_+3A_proportions_desired">proportions_desired</code></td>
<td>
<p>Which proportions of <code>outcome_of_analysis</code> class do you wish to understand performance for?</p>
</td></tr>
<tr><td><code id="asymmetric_cost_explorer_+3A_proportion_tolerance">proportion_tolerance</code></td>
<td>
<p>If the model cannot match the proportion_desired within this amount, it does not return that model's performance. Default is <code>0.01</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with column 1: <code>proportions_desired</code>, column 2: actual proportions (as close as possible), column 3: error rate, column 4: probability threshold.
</p>


<h3>Author(s)</h3>

<p>Adam Kapelner
</p>

<hr>
<h2 id='confusion_results'>Binary Confusion Table and Errors</h2><span id='topic+confusion_results'></span>

<h3>Description</h3>

<p>Provides a binary confusion table and error metrics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion_results(yhat, ybin, skip_argument_checks = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confusion_results_+3A_yhat">yhat</code></td>
<td>
<p>The binary predictions</p>
</td></tr>
<tr><td><code id="confusion_results_+3A_ybin">ybin</code></td>
<td>
<p>The true binary responses</p>
</td></tr>
<tr><td><code id="confusion_results_+3A_skip_argument_checks">skip_argument_checks</code></td>
<td>
<p>If <code>TRUE</code> it does not check this function's arguments for appropriateness. It is not recommended unless you truly need speed and thus the default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of raw results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
ybin = as.numeric(Pima.te$type == "Yes")
flr = fast_logistic_regression(
  Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = ybin
)
phat = predict(flr, model.matrix(~ . - type, Pima.te))
confusion_results(phat &gt; 0.5, ybin)
</code></pre>

<hr>
<h2 id='eigen_compute_single_entry_of_diagonal_matrix'>Compute Single Value of the Diagonal of a Symmetric Matrix's Inverse</h2><span id='topic+eigen_compute_single_entry_of_diagonal_matrix'></span>

<h3>Description</h3>

<p>Via the eigen package's conjugate gradient descent algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigen_compute_single_entry_of_diagonal_matrix(M, j, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eigen_compute_single_entry_of_diagonal_matrix_+3A_m">M</code></td>
<td>
<p>The symmetric matrix which to invert (and then extract one element of its diagonal)</p>
</td></tr>
<tr><td><code id="eigen_compute_single_entry_of_diagonal_matrix_+3A_j">j</code></td>
<td>
<p>The diagonal entry of <code>M</code>'s inverse</p>
</td></tr>
<tr><td><code id="eigen_compute_single_entry_of_diagonal_matrix_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of m^-1_j,j
</p>


<h3>Author(s)</h3>

<p>Adam Kapelner
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	n = 500
	X = matrix(rnorm(n^2), nrow = n, ncol = n)
	M = t(X) %*% X
	j = 137
	eigen_compute_single_entry_of_diagonal_matrix(M, j)
	solve(M)[j, j] #to ensure it's the same value
</code></pre>

<hr>
<h2 id='eigen_det'>A fast det(X) function</h2><span id='topic+eigen_det'></span>

<h3>Description</h3>

<p>Via the eigen package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigen_det(X, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eigen_det_+3A_x">X</code></td>
<td>
<p>A numeric matrix of size p x p</p>
</td></tr>
<tr><td><code id="eigen_det_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use. Unless p is large, keep to the default of 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The determinant as a scalar numeric value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  p = 30
  eigen_det(matrix(rnorm(p^2), nrow = p))
</code></pre>

<hr>
<h2 id='eigen_inv'>A fast solve(X) function</h2><span id='topic+eigen_inv'></span>

<h3>Description</h3>

<p>Via the eigen package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigen_inv(X, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eigen_inv_+3A_x">X</code></td>
<td>
<p>A numeric matrix of size p x p</p>
</td></tr>
<tr><td><code id="eigen_inv_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use. Unless p is large, keep to the default of 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The resulting matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  p = 10
  eigen_inv(matrix(rnorm(p^2), nrow = p))
</code></pre>

<hr>
<h2 id='eigen_Xt_times_diag_w_times_X'>A fast Xt [times] diag(w) [times] X function</h2><span id='topic+eigen_Xt_times_diag_w_times_X'></span>

<h3>Description</h3>

<p>Via the eigen package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigen_Xt_times_diag_w_times_X(X, w, num_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eigen_Xt_times_diag_w_times_X_+3A_x">X</code></td>
<td>
<p>A numeric matrix of size n x p</p>
</td></tr>
<tr><td><code id="eigen_Xt_times_diag_w_times_X_+3A_w">w</code></td>
<td>
<p>A numeric vector of length p</p>
</td></tr>
<tr><td><code id="eigen_Xt_times_diag_w_times_X_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use. Unless p is large, keep to the default of 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The resulting matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n = 100
  p = 10
  X = matrix(rnorm(n * p), nrow = n, ncol = p)
  w = rnorm(p)
  eigen_Xt_times_diag_w_times_X(t(X), w)
</code></pre>

<hr>
<h2 id='fast_logistic_regression'>FastLR Wrapper</h2><span id='topic+fast_logistic_regression'></span>

<h3>Description</h3>

<p>Returns most of what you get from glm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_logistic_regression(
  Xmm,
  ybin,
  drop_collinear_variables = FALSE,
  lm_fit_tol = 1e-07,
  do_inference_on_var = "none",
  Xt_times_diag_w_times_X_fun = NULL,
  sqrt_diag_matrix_inverse_fun = NULL,
  num_cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fast_logistic_regression_+3A_xmm">Xmm</code></td>
<td>
<p>The model.matrix for X (you need to create this yourself before)</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_ybin">ybin</code></td>
<td>
<p>The binary response vector</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_drop_collinear_variables">drop_collinear_variables</code></td>
<td>
<p>Should we drop perfectly collinear variables? Default is <code>FALSE</code> to inform the user of the problem.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_lm_fit_tol">lm_fit_tol</code></td>
<td>
<p>When <code>drop_collinear_variables = TRUE</code>, this is the tolerance to detect collinearity among predictors.
We use the default value from <code>base::lm.fit</code>'s which is 1e-7. If you fit the logistic regression and
still get p-values near 1 indicating high collinearity, we recommend making this value smaller.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_do_inference_on_var">do_inference_on_var</code></td>
<td>
<p>Which variables should we compute approximate standard errors of the coefficients and approximate p-values for the test of
no linear log-odds probability effect? Default is <code>"none"</code> for inference on none (for speed). If not default, then <code>"all"</code>
to indicate inference should be computed for all variables. The final option is to pass one index to indicate the column
number of <code>Xmm</code> where inference is desired. We have a special routine to compute inference for one variable only. It consists of a conjugate
gradient descent which is another approximation atop the coefficient-fitting approximation in RcppNumerical. Note: if you are just comparing
nested models using anova, there is no need to compute inference for coefficients (keep the default of <code>FALSE</code> for speed).</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_xt_times_diag_w_times_x_fun">Xt_times_diag_w_times_X_fun</code></td>
<td>
<p>A custom function whose arguments are <code>X</code> (an n x m matrix), <code>w</code> (a vector of length m) and this function's <code>num_cores</code> 
argument in that order. The function must return an m x m R matrix class object which is the result of the computing X^T 
function is not parallelized, the <code>num_cores</code> argument is ignored. Default is <code>NULL</code> which uses the function 
<code><a href="#topic+eigen_Xt_times_diag_w_times_X">eigen_Xt_times_diag_w_times_X</a></code> which is implemented with the Eigen C++ package and hence very fast. The only way we know of to beat the default is to use a method that employs
GPUs. See README on github for more information.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_sqrt_diag_matrix_inverse_fun">sqrt_diag_matrix_inverse_fun</code></td>
<td>
<p>A custom function that returns a numeric vector which is square root of the diagonal of the inverse of the inputted matrix. Its arguments are <code>X</code> 
(an n x n matrix) and this function's <code>num_cores</code> argument in that order. If your custom function is not parallelized, the <code>num_cores</code> argument is ignored. 
The object returned must further have a defined function <code>diag</code> which returns the diagonal of the matrix as a vector. Default is <code>NULL</code> which uses the function 
<code><a href="#topic+eigen_inv">eigen_inv</a></code> which is implemented with the Eigen C++ package and hence very fast. The only way we know of to beat the default is to use a method that employs
GPUs. See README on github for more information.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_num_cores">num_cores</code></td>
<td>
<p>Number of cores to use to speed up matrix multiplication and matrix inversion (used only during inference computation). Default is 1.
Unless the number of variables, i.e. <code>ncol(Xmm)</code>, is large, there does not seem to be a performance gain in using multiple cores.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>fastLR</code>. See documentation there.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of raw results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression(
	 Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = as.numeric(Pima.te$type == "Yes")
)
</code></pre>

<hr>
<h2 id='fast_logistic_regression_stepwise_forward'>Rapid Forward Stepwise Logistic Regression</h2><span id='topic+fast_logistic_regression_stepwise_forward'></span>

<h3>Description</h3>

<p>Roughly duplicates the following <code>glm</code>-style code:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_logistic_regression_stepwise_forward(
  Xmm,
  ybin,
  mode = "aic",
  pval_threshold = 0.05,
  use_intercept = TRUE,
  verbose = TRUE,
  drop_collinear_variables = FALSE,
  lm_fit_tol = 1e-07,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_xmm">Xmm</code></td>
<td>
<p>The model.matrix for X (you need to create this yourself before).</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_ybin">ybin</code></td>
<td>
<p>The binary response vector.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_mode">mode</code></td>
<td>
<p>&quot;aic&quot; (default, fast) or &quot;pval&quot; (slow, but possibly yields a better model).</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_pval_threshold">pval_threshold</code></td>
<td>
<p>The significance threshold to include a new variable. Default is <code>0.05</code>.
If <code>mode == "aic"</code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_use_intercept">use_intercept</code></td>
<td>
<p>Should we automatically begin with an intercept? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_verbose">verbose</code></td>
<td>
<p>Print out messages during the loop? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_drop_collinear_variables">drop_collinear_variables</code></td>
<td>
<p>Parameter used in <code>fast_logistic_regression</code>. Default is <code>FALSE</code>. See documentation there.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_lm_fit_tol">lm_fit_tol</code></td>
<td>
<p>Parameter used in <code>fast_logistic_regression</code>. Default is <code>1e-7</code>. See documentation there.</p>
</td></tr>
<tr><td><code id="fast_logistic_regression_stepwise_forward_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>fastLR</code>. See documentation there.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nullmod = glm(ybin ~ 0,     data.frame(Xmm), family = binomial)</code>
<code>fullmod = glm(ybin ~ 0 + ., data.frame(Xmm), family = binomial)</code>
<code>forwards = step(nullmod, scope = list(lower = formula(nullmod), upper = formula(fullmod)), direction = "forward", trace = 0)</code>
</p>


<h3>Value</h3>

<p>A list of raw results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression_stepwise_forward(
  Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = as.numeric(Pima.te$type == "Yes")
)
</code></pre>

<hr>
<h2 id='fastLogisticRegressionWrap'>A Wrapper for FastLR</h2><span id='topic+fastLogisticRegressionWrap'></span>

<h3>Description</h3>

<p>A tool to find many types of a priori experimental designs
</p>


<h3>Author(s)</h3>

<p>Adam Kapelner <a href="mailto:kapelner@qc.cuny.edu">kapelner@qc.cuny.edu</a>
</p>


<h3>References</h3>

<p>Kapelner, A
</p>

<hr>
<h2 id='general_confusion_results'>General Confusion Table and Errors</h2><span id='topic+general_confusion_results'></span>

<h3>Description</h3>

<p>Provides a confusion table and error metrics for general factor vectors.
There is no need for the same levels in the two vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>general_confusion_results(yhat, yfac, proportions_scaled_by_column = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="general_confusion_results_+3A_yhat">yhat</code></td>
<td>
<p>The factor predictions</p>
</td></tr>
<tr><td><code id="general_confusion_results_+3A_yfac">yfac</code></td>
<td>
<p>The true factor responses</p>
</td></tr>
<tr><td><code id="general_confusion_results_+3A_proportions_scaled_by_column">proportions_scaled_by_column</code></td>
<td>
<p>When returning the proportion table, scale by column? Default is <code>FALSE</code> to keep the probabilities 
unconditional to provide the same values as the function <code>confusion_results</code>. Set to <code>TRUE</code>
to understand error probabilities by prediction bucket.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of raw results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
ybin = as.numeric(Pima.te$type == "Yes")
flr = fast_logistic_regression(
  Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = ybin
)
phat = predict(flr, model.matrix(~ . - type, Pima.te))
yhat = array(NA, length(ybin))
yhat[phat &lt;= 1/3] = "no"
yhat[phat &gt;= 2/3] = "yes"
yhat[is.na(yhat)] = "maybe"
general_confusion_results(factor(yhat, levels = c("no", "yes", "maybe")), factor(ybin)) 
#you want the "no" to align with 0, the "yes" to align with 1 and the "maybe" to be 
#last to align with nothing
</code></pre>

<hr>
<h2 id='predict.fast_logistic_regression'>FastLR Wrapper Predictions</h2><span id='topic+predict.fast_logistic_regression'></span>

<h3>Description</h3>

<p>Predicts returning p-hats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression'
predict(object, newdata, type = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fast_logistic_regression_+3A_object">object</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression</code> or <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_+3A_newdata">newdata</code></td>
<td>
<p>A matrix of observations where you wish to predict the binary response.</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_+3A_type">type</code></td>
<td>
<p>The type of prediction required. The default is <code>"response"</code> which is on the response scale (i.e. probability estimates) and the alternative is <code>"link"</code> which is the linear scale (i.e. log-odds).</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length <code>nrow(newdata)</code> of estimates of P(Y = 1) for each unit in <code>newdata</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression(
  Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = as.numeric(Pima.te$type == "Yes")
)
phat = predict(flr, model.matrix(~ . - type, Pima.te))
</code></pre>

<hr>
<h2 id='predict.fast_logistic_regression_stepwise'>FastLR Wrapper Predictions</h2><span id='topic+predict.fast_logistic_regression_stepwise'></span>

<h3>Description</h3>

<p>Predicts returning p-hats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression_stepwise'
predict(object, newdata, type = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fast_logistic_regression_stepwise_+3A_object">object</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression</code> or <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_stepwise_+3A_newdata">newdata</code></td>
<td>
<p>A matrix of observations where you wish to predict the binary response.</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_stepwise_+3A_type">type</code></td>
<td>
<p>The type of prediction required. The default is <code>"response"</code> which is on the response scale (i.e. probability estimates) and the alternative is <code>"link"</code> which is the linear scale (i.e. log-odds).</p>
</td></tr>
<tr><td><code id="predict.fast_logistic_regression_stepwise_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length <code>nrow(newdata)</code> of estimates of P(Y = 1) for each unit in <code>newdata</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression_stepwise_forward(
  Xmm = model.matrix(~ . - type, Pima.te), 
  ybin = as.numeric(Pima.te$type == "Yes")
)
phat = predict(flr, model.matrix(~ . - type, Pima.te))
</code></pre>

<hr>
<h2 id='print.fast_logistic_regression'>FastLR Wrapper Print</h2><span id='topic+print.fast_logistic_regression'></span>

<h3>Description</h3>

<p>Returns the summary table a la glm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.fast_logistic_regression_+3A_x">x</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression</code> or <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="print.fast_logistic_regression_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to print</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary as a data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression(
	Xmm = model.matrix(~ . - type, Pima.te), 
 ybin = as.numeric(Pima.te$type == "Yes"))
print(flr)
</code></pre>

<hr>
<h2 id='print.fast_logistic_regression_stepwise'>FastLR Wrapper Print</h2><span id='topic+print.fast_logistic_regression_stepwise'></span>

<h3>Description</h3>

<p>Returns the summary table a la glm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression_stepwise'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.fast_logistic_regression_stepwise_+3A_x">x</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression</code> or <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="print.fast_logistic_regression_stepwise_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to print</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary as a data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression_stepwise_forward(
	Xmm = model.matrix(~ . - type, Pima.te), 
 ybin = as.numeric(Pima.te$type == "Yes"))
print(flr)
</code></pre>

<hr>
<h2 id='summary.fast_logistic_regression'>FastLR Wrapper Summary</h2><span id='topic+summary.fast_logistic_regression'></span>

<h3>Description</h3>

<p>Returns the summary table a la glm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression'
summary(object, alpha_order = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fast_logistic_regression_+3A_object">object</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression</code> or <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="summary.fast_logistic_regression_+3A_alpha_order">alpha_order</code></td>
<td>
<p>Should the coefficients be ordered in alphabetical order? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.fast_logistic_regression_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>summary</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary as a data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression(
	Xmm = model.matrix(~ . - type, Pima.te), 
 ybin = as.numeric(Pima.te$type == "Yes"))
summary(flr)
</code></pre>

<hr>
<h2 id='summary.fast_logistic_regression_stepwise'>FastLR Wrapper Summary</h2><span id='topic+summary.fast_logistic_regression_stepwise'></span>

<h3>Description</h3>

<p>Returns the summary table a la glm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fast_logistic_regression_stepwise'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fast_logistic_regression_stepwise_+3A_object">object</code></td>
<td>
<p>The object built using the <code>fast_logistic_regression_stepwise</code> wrapper functions</p>
</td></tr>
<tr><td><code id="summary.fast_logistic_regression_stepwise_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>summary</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The summary as a data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); data(Pima.te)
flr = fast_logistic_regression_stepwise_forward(
	Xmm = model.matrix(~ . - type, Pima.te), 
 ybin = as.numeric(Pima.te$type == "Yes"))
summary(flr)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
