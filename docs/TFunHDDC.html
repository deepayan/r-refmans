<!DOCTYPE html><html><head><title>Help for package TFunHDDC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TFunHDDC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#contaminatedTriangles'>
<p>contaminatedTriangles</p></a></li>
<li><a href='#fitNOxBenchmark'>
<p>fitNOxBenchmark</p></a></li>
<li><a href='#genModelFD'>
<p>genModelFD</p></a></li>
<li><a href='#genTriangles'>
<p>genTriangles</p></a></li>
<li><a href='#plotNOx'>
<p>plotNOx</p></a></li>
<li><a href='#plotTriangles'>
<p>plotTriangles</p></a></li>
<li><a href='#predict.tfunHDDC'>
<p>predict.tfunHDDC: Predicting Function for t-funHDDC Objects</p></a></li>
<li><a href='#tfunHDDC'>
<p>tfunHDDC: Function for Model-Based Clustering of Functional Data with Outliers Using the t-Distribution.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Clustering of Functional Data via Mixtures of t-Distributions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-06-01</td>
</tr>
<tr>
<td>Depends:</td>
<td>fda.usc, R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>tclust, stringr, MASS, fda</td>
</tr>
<tr>
<td>Description:</td>
<td>Extension of 'funHDDC' Schmutz et al. (2018) 
    &lt;<a href="https://doi.org/10.1007%2Fs00180-020-00958-4">doi:10.1007/s00180-020-00958-4</a>&gt; for cases including
    outliers by fitting t-distributions for robust groups. 'TFunHDDC' can cluster
    univariate or multivariate data produced by the 'fda' package for data using
    a b-splines or Fourier basis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-01 17:02:57 UTC; iain</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Author:</td>
<td>Cristina Anton [aut, cre],
  Iain Smith [aut],
  Malcolm Nielsen [aut],
  Jeffrey Andrews [ctb],
  Jaymeson Wickins [ctb],
  Nicholas Boers [ctb],
  Paul McNicholas [ctb],
  Amandine Schmutz [ctb],
  Julien Jacques [ctb],
  Charles Bouveyron [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Cristina Anton &lt;popescuc@macewan.ca&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-04 12:20:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='contaminatedTriangles'>
contaminatedTriangles
</h2><span id='topic+contaminatedTriangles'></span>

<h3>Description</h3>

<p>Simulated triangle data produced as an example of mild contaminated data with
behavioural outliers.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fd</code></td>
<td>
<p>A functional data object representing the fitted triangle data.</p>
</td></tr>
<tr><td><code>groupd</code></td>
<td>
<p>Group classifications for each curve as a ordinary behavioral group (1,2,3, or 4) or outlier (4 as outliers to group 1 and 6 as outliers for group 3).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>References</h3>

<p>- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).
</p>

<hr>
<h2 id='fitNOxBenchmark'>
fitNOxBenchmark
</h2><span id='topic+fitNOxBenchmark'></span>

<h3>Description</h3>

<p>Extract NOx data from fda.usc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitNOxBenchmark(nbasis=15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitNOxBenchmark_+3A_nbasis">nbasis</code></td>
<td>

<p>The number of basis functions to fit to the simulated data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Open NOx data from the poblenou data set of fda.usc. Fit the data to a given number of basis functions and
adjust classes for festive days into just weekdays and weekends.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fd</code></td>
<td>
<p>A functional data object representing the fitted NOx data.</p>
</td></tr>
<tr><td><code>groupd</code></td>
<td>
<p>Group classifications for each curve as a curve representing a weekday or weekend/festive day.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>References</h3>

<p>- Febrero-Bande M, Galeano P, Gonz~alez-Manteiga W (2008) Outlier detection
in functional data by depth measures, with application to identify abnormal
nox levels. Environmetrics 19:331-345. &lt;//doi.org/10.1002/env.878&gt;.
</p>
<p>- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotNOx">plotNOx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Univariate Contaminated Data
data1&lt;-fitNOxBenchmark(15)
plotNOx(data1)
</code></pre>

<hr>
<h2 id='genModelFD'>
genModelFD
</h2><span id='topic+genModelFD'></span>

<h3>Description</h3>

<p>Generate functional data with coefficients distributed according to a finite mixture of contamined normal distributions such that for the <code class="reqn">\textit{k}</code>th cluster we have the
multivariate contaminated normal distribution with density 
</p>
<p style="text-align: center;"><code class="reqn">
f(\gamma_i;\theta_k)=\alpha_k\phi(\gamma_i;\mu_k,\Sigma_k)+(1-\alpha_k)\phi(\gamma_i;\mu_k,\eta_k\Sigma_k)</code>
</p>

<p>where <code class="reqn">\alpha_k\in (0.5,1)</code> represents the proportion of uncontaminated data, <code class="reqn">\eta_k&gt;1</code> is the inflation coefficient due to outliers, and <code class="reqn">\phi(\gamma_i;\mu_k,\Sigma_k)</code> is the density for the multivariate normal distribution <code class="reqn">N(\mu_k,\Sigma_k)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genModelFD(ncurves=1000, nsplines=35, alpha=c(0.9,0.9,0.9),
           eta=c(10, 5, 15))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genModelFD_+3A_ncurves">ncurves</code></td>
<td>

<p>The number of curves total for the simulation.
</p>
</td></tr>
<tr><td><code id="genModelFD_+3A_nsplines">nsplines</code></td>
<td>

<p>The number of splines to fit to the simulated data.
</p>
</td></tr>
<tr><td><code id="genModelFD_+3A_alpha">alpha</code></td>
<td>

<p>The proportion of uncontaminated data in each group.
</p>
</td></tr>
<tr><td><code id="genModelFD_+3A_eta">eta</code></td>
<td>

<p>The inflation coefficient that measures the increase in variability due to the outliers. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data are generate from the model <code class="reqn">FCLM[a_k, b_k,{\bf{Q}}_k,d_k,\alpha_k,\eta_k]</code>. 
The number of clusters is fixed to <code class="reqn">K=3</code> and the mixing proportions are equal <code class="reqn">\pi_1=\pi_2=\pi_3=1/3</code>. We consider the following values of the parameters
</p>
<p>Group 1:<code class="reqn">d=5</code>, <code class="reqn">a=150</code>, <code class="reqn">b=5</code>, <code class="reqn">\mu=(1,0,50,100,0,\ldots,0)</code>
</p>
<p>Group 2: <code class="reqn">d=20</code>, <code class="reqn">a=15</code>, <code class="reqn">b=8</code>, <code class="reqn">\mu=(0,0,80,0,40,2,0,\ldots,0)</code>
</p>
<p>Group 3: <code class="reqn">d=10</code>, <code class="reqn">a=30</code>, <code class="reqn">b=10</code>, <code class="reqn">\mu=(0,\ldots,0,20,0,80,0,0,100)</code>,
</p>
<p>where <code class="reqn">d</code> is the intrinsic dimension of the subgroups, <code class="reqn">\mu</code> is the mean vector of size 70, <code class="reqn">a</code> is the values of the <code class="reqn">d</code>-first diagonal elements of <code class="reqn">\mathbf{D}</code>, and <code class="reqn">b</code> the value of the last <code class="reqn">70-d</code>- elements. Curves as smoothed using 35 Fourier basis functions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fd</code></td>
<td>
<p>A functional data object representing the simulated data.</p>
</td></tr>
<tr><td><code>groupd</code></td>
<td>
<p>Group classifications for each curve.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>References</h3>

<p>- Amovin-Assagba M, Gannaz I, Jacques J (2022) Outlier detection in multivariate
functional data through a contaminated mixture model. Comput Stat
Data Anal 174.
- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Univariate Contaminated Data
data &lt;- genModelFD(ncurves=300, nsplines=35, alpha=c(0.9,0.9,0.9),
                  eta=c(10, 7, 17))
plot(data$fd, col = data$groupd)
clm &lt;- data$groupd
</code></pre>

<hr>
<h2 id='genTriangles'>
genTriangles
</h2><span id='topic+genTriangles'></span>

<h3>Description</h3>

<p>Generate contaminated triangle data. Groups 1, 2, 3, and 4 are separable over the two dimensions of functional data. Groups 5 and 6 contain the contaminated curves of groups 1 and 3 respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genTriangles()
</code></pre>


<h3>Details</h3>

<p>Group 1:
</p>
<p><code class="reqn">X_1(t) = U + (0.6 - U)H_1(t) + \epsilon_1(t)</code>
</p>
<p><code class="reqn"> X_2(t) = U + (0.5 - U)H_1(t) + \epsilon_1(t)</code>
</p>
<p>Contaminated <code class="reqn">X_1(t) = \sin(t) + (0.6 - U)H_1(t) + \epsilon_2(t)</code>
</p>
<p>Contaminated
<code class="reqn">  X_2(t) = \sin(t) + (0.5 - U)H_1(t) + \epsilon_2(t)</code>
</p>
<p>Group 2:
</p>
<p><code class="reqn">X_1(t) = U + (0.6 - U)H_2(t) + \epsilon_1(t)</code>
</p>
<p><code class="reqn">X_2(t) = U + (0.5 - U)H_2(t) + \epsilon_1(t)</code>
</p>
<p>Group 3:
</p>
<p><code class="reqn">X_1(t) = U + (0.5 - U)H_1(t) + \epsilon_1(t)</code>
</p>
<p><code class="reqn"> X_2(t) = U + (0.6 - U)H_2(t) + \epsilon_1(t)</code>
</p>
<p>Contaminated <code class="reqn">X_1(t) = \sin(t) + (0.5 - U)H_1(t) + \epsilon_3(t)</code>
</p>
<p>Contaminated <code class="reqn">X_2(t) = \sin(t) + (0.6 - U)H_2(t) + \epsilon_3(t)</code>
</p>
<p>Group 4:
</p>
<p><code class="reqn">X_1(t) = U + (0.5 - U)H_2(t) + \epsilon_1(t)</code>
</p>
<p><code class="reqn">X_2(t) = U + (0.6 - U)H_1(t) + \epsilon_1(t).</code>
Here <code class="reqn">t\in [1,21]</code>, <code class="reqn">H_1(t) = (6-\vert t-7\vert)_+</code>, and <code class="reqn">H_2(t) = (6-\vert t-15\vert)_+</code>,  with <code class="reqn">(\cdot)_+</code> representing the positive part. <code class="reqn">U \sim \mathcal{U}(0, 0.1)</code>, and <code class="reqn">\epsilon_1(t)\sim N(0, 0.5)</code>, <code class="reqn">\epsilon_2(t)\sim N(0, 2)</code>, <code class="reqn">\epsilon_3(t) \sim Cauchy(0, 4)</code> are mutually independent white noises and independent of <code class="reqn">U</code>. We simulate 100 curves for each group, groups 1 and 3 consisting of 80 ordinary curves and 20 contaminated curves. Curves are smoothed using a 25 cubic B-spline basis.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fd</code></td>
<td>
<p>List of functional data objects representing the two dimensions of triangle data.</p>
</td></tr>
<tr><td><code>groupd</code></td>
<td>
<p>Group classification for each curve</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>References</h3>

<p>- C.Bouveyron and J.Jacques (2011), Model-based Clustering of Time Series in Group-specific Functional Subspaces, Advances in Data Analysis and Classification, vol. 5 (4), pp. 281-300,  &lt;doi:10.1007/s11634-011-0095-6&gt;
</p>
<p>- Schmutz A, Jacques J, Bouveyron C, et al (2020) Clustering multivariate functional data in group-specific functional subspaces. Comput Stat
35:1101-1131
</p>
<p>- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotTriangles">plotTriangles</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multivariate Contaminated Triangles
conTrig &lt;- genTriangles()
cls = conTrig$groupd
plotTriangles(conTrig)
</code></pre>

<hr>
<h2 id='plotNOx'>
plotNOx
</h2><span id='topic+plotNOx'></span>

<h3>Description</h3>

<p>Plot data returned by <code><a href="#topic+fitNOxBenchmark">fitNOxBenchmark</a></code> as  lines coloured according to the assigned clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotNOx(fdn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotNOx_+3A_fdn">fdn</code></td>
<td>

<p>List with an element <code class="reqn">fd</code> given the functional data, and an element <code class="reqn">groupd</code> given the classes; usually returned from the function <a href="#topic+fitNOxBenchmark">fitNOxBenchmark</a>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, used for side effects.</p>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitNOxBenchmark">fitNOxBenchmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Univariate Contaminated Data
data1&lt;-fitNOxBenchmark(15)
plotNOx(data1)
</code></pre>

<hr>
<h2 id='plotTriangles'>
plotTriangles
</h2><span id='topic+plotTriangles'></span>

<h3>Description</h3>

<p>Plot data returned by <code><a href="#topic+genTriangles">genTriangles</a></code> as  lines coloured according to the assigned clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTriangles(fdt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTriangles_+3A_fdt">fdt</code></td>
<td>

<p>List with an element <code class="reqn">fd</code> given the functional data, and an element <code class="reqn">groupd</code> given the classes, as returned from the function <code><a href="#topic+genTriangles">genTriangles</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, used for side effects.</p>


<h3>Author(s)</h3>

<p>Cristina Anton and Iain Smith
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genTriangles">genTriangles</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>conTrig &lt;- genTriangles()
plotTriangles(conTrig)
</code></pre>

<hr>
<h2 id='predict.tfunHDDC'>
predict.tfunHDDC: Predicting Function for t-funHDDC Objects
</h2><span id='topic+predict.tfunHDDC'></span>

<h3>Description</h3>

<p>Provides the matrix of classification probabilities and the classification vector for inputted observations assuming the model provided by the <code><a href="#topic+tfunHDDC">tfunHDDC</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tfunHDDC'
predict(object, data=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.tfunHDDC_+3A_object">object</code></td>
<td>

<p>An object of class <code><a href="#topic+tfunHDDC">tfunHDDC</a></code>
</p>
</td></tr>
<tr><td><code id="predict.tfunHDDC_+3A_data">data</code></td>
<td>

<p>Data frame (univariate funtional data) or a list (multivariate functional data) of new observations on the same variables used in the fitting of the <code><a href="#topic+tfunHDDC">tfunHDDC</a></code> object.  If <code>NULL</code>, then the observations used in the fitting of the <code><a href="#topic+tfunHDDC">tfunHDDC</a></code> object are inputted.
</p>
</td></tr>
<tr><td><code id="predict.tfunHDDC_+3A_...">...</code></td>
<td>

<p>Arguments to be passed to other functions.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>t</code></td>
<td>
<p>Matrix of classification probabilities</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>Vector of maximum a posteriori classifications</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton, Iain Smith
</p>


<h3>References</h3>

<p>-Andrews JL, McNicholas PD (2012) Model-based clustering, classication,
and discriminant analysis via mixtures of multivariate t-distributions:
The teigen family. Stat Comput 22:10211029. &lt;doi.org/10.1007/
s11222-011-9272-x&gt;
</p>
<p>-Andrews JL, Wickins JR, Boers NM, et al (2018) An R package for modelbased
clustering and classication via the multivariate t distribution. Journal
of Statistical Software 83(7):1-32
</p>
<p>- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).

</p>


<h3>See Also</h3>

<p><code><a href="#topic+tfunHDDC">tfunHDDC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1027)
#simulataed univariate data

data = genModelFD(ncurves=300, nsplines=35, alpha=c(0.9,0.9,0.9),
                  eta=c(10, 7, 17))

plot(data$fd, col = data$groupd)

clm = data$groupd

model1=c("AkjBkQkDk", "AkjBQkDk", "AkBkQkDk", "ABkQkDk", "AkBQkDk", "ABQkDk")

####################classification example with predictions

training=c(1:50,101:150, 201:250)

test=c(51:100,151:200, 251:300)

known1=clm[training]

t4&lt;-tfunHDDC(data$fd[training],K=3,threshold=0.2,init="kmeans",nb.rep=1,
             dfconstr="no", dfupdate="numeric", model=model1[1],known=known1, 
             itermax = 10)

if (!is.null(t4$class)) {
	table(clm[training], t4$class)

	p1&lt;-predict.tfunHDDC(t4,data$fd[test] )

	if (!is.null(p1$class)) table(clm[test], p1$class)
}

###########################NOX data

data1=fitNOxBenchmark(15)

plotNOx(data1)

###example for prediction

training=c(1:50)

test=c(51:115)

known1=data1$groupd[training]

t1&lt;-tfunHDDC(data1$fd[training],K=2,threshold=0.6,init="kmeans",nb.rep=10,
             dfconstr="no", model=c("AkjBkQkDk", "AkjBQkDk", "AkBkQkDk", 
             "ABkQkDk", "AkBQkDk", "ABQkDk"),known=known1) 

if (!is.null(t1$class)) {
	table(data1$groupd[training], t1$class)

	p1&lt;-predict.tfunHDDC(t1,data1$fd[test] )

	if (!is.null(p1$class)) table(data1$groupd[test], p1$class)
}

</code></pre>

<hr>
<h2 id='tfunHDDC'>
tfunHDDC: Function for Model-Based Clustering of Functional Data with Outliers Using the t-Distribution.
</h2><span id='topic+tfunHDDC'></span>

<h3>Description</h3>

<p>tfunHDDC is an adaptation of funHDDC (Schmutz et al., 2018) that uses t-distributions for robust clustering in the presence of outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tfunHDDC(data, K=1:10, model="AkjBkQkDk", known=NULL,dfstart=50, dfupdate="approx",
           dfconstr="no", threshold=0.1, itermax=200, eps=1e-6, init='random',
           criterion="bic", d_select="Cattell", init.vector=NULL,
           show=TRUE, mini.nb=c(5, 10), min.individuals=2, mc.cores=1, nb.rep=2,
           keepAllRes=TRUE, kmeans.control = list(), d_max=100, d_range=2,
           verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tfunHDDC_+3A_data">data</code></td>
<td>

<p>In the univariate case: a functional data object produced by the fda package. In the multivariate case: a list of functional data objects.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_k">K</code></td>
<td>

<p>The number of clusters or list of clusters to try, for example K=2:10.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_dfstart">dfstart</code></td>
<td>

<p>The df (degrees of freedom) to which we initialize the t-distribution.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_dfupdate">dfupdate</code></td>
<td>

<p>Either &quot;numeric&quot;, or &quot;approx&quot;. The default is &quot;approx&quot; indicating a closed form approximation be used. Alternatively, &quot;numeric&quot; can be specified which makes use of <code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_dfconstr">dfconstr</code></td>
<td>

<p>&quot;yes&quot; when df (degrees of freedom) for the t-distribution should be the same between all clusters; &quot;no&quot; when df may be different between clusters.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_model">model</code></td>
<td>

<p>The chosen model among 'AkjBkQkDk', 'AkjBQkDk', 'AkBkQkDk', 'ABkQkDk', 'AkBQkDk', 'ABQkDk'. 'AkjBkQkDk' is the default. We can test multiple models at the same time with the command c(). For example c(&quot;AkjBkQkDk&quot;,&quot;AkjBQkDk&quot;).
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_threshold">threshold</code></td>
<td>

<p>The threshold of the Cattell' scree-test used for selecting the group-specific intrinsic dimensions.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_known">known</code></td>
<td>

<p>A vector of known classifications that can be numeric or <code>NA</code>. It is optional for clustering. For classification, curves with unknown classification should be given the value <code>NA</code> within <code>known</code> (see the examples below). Must be the same length as the number of curves in the data set. 
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_itermax">itermax</code></td>
<td>

<p>The maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_eps">eps</code></td>
<td>

<p>The threshold of the convergence criterion.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_init">init</code></td>
<td>

<p>A character string. It is the way to initialize the EM algorithm. There are five ways of initialization: “kmeans” (default), “param”, “random”, “mini-em”, “vector”, or &quot;tkmeans&quot;. See details for more information. It can also be directly initialized with a vector containing the prior classes of the observations.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_criterion">criterion</code></td>
<td>

<p>The criterion used for model selection: bic (default) or icl. 
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_d_select">d_select</code></td>
<td>

<p>“Cattell” (default), “BIC”, or &quot;grid&quot;. This parameter selects which method to use to select the intrinsic dimensions of subgroups. &quot;grid&quot; will select d based on thecriterion value after running each combination of d1, d2, ..., dK for the groups. d used for each group is based on the values for d_range. &quot;grid&quot; will only work for a single value of K (not a list). See details for more information.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_init.vector">init.vector</code></td>
<td>

<p>A vector of integers or factors. It is a user-given initialization. It should be of the same length as of the data. Only used when init=&quot;vector&quot;.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_show">show</code></td>
<td>

<p>Use show = FALSE to settle off the informations that may be printed.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_mini.nb">mini.nb</code></td>
<td>

<p>A vector of integers of length two. This parameter is used in the “mini-em” initialization. The first integer sets how many times the algorithm is repeated; the second sets the maximum number of iterations the algorithm will do each time. For example, if init=“mini-em” and mini.nb=c(5,10), the algorithm wil be launched 5 times, doing each time 10 iterations; finally the algorithm will begin with the initialization that maximizes the log-likelihood.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_min.individuals">min.individuals</code></td>
<td>

<p>This parameter is used to control for the minimum population of a class. If the population of a class becomes stricly inferior to 'min.individuals' then the algorithm stops and gives the message: 'pop&lt;min.indiv.'. Here the meaning of &quot;population of a class&quot; is the sum of its posterior probabilities. The value of 'min.individuals' cannot be lower than 2.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_mc.cores">mc.cores</code></td>
<td>

<p>Positive integer, default is 1. If mc.cores&gt;1, then parallel computing is used, using mc.cores cores. Warning for Windows users only: the parallel computing can sometimes be slower than using one single core (due to how parLapply works).
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_nb.rep">nb.rep</code></td>
<td>

<p>A positive integer (default is 1 for kmeans initialization and 20 for random initialization). Each estimation (i.e. combination of (model, K, threshold)) is repeated nb.rep times and only the estimation with the highest log-likelihood is kept.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_keepallres">keepAllRes</code></td>
<td>

<p>Logical. Should the results of all runs be kept? If so, an argument all_results is created in the results. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_kmeans.control">kmeans.control</code></td>
<td>

<p>A list. The elements of this list should match the parameters of the <code><a href="stats.html#topic+kmeans">kmeans</a></code> initialization (see kmeans help for details). The parameters are “iter.max”, “nstart” and “algorithm”. &quot;alpha&quot; is an added parameter for the <code><a href="tclust.html#topic+tkmeans">tkmeans</a></code> initialization (see tkmeans help for details)
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_d_max">d_max</code></td>
<td>

<p>A positive integer. The maximum number of dimensions to be computed. Default is 100. It means that the instrinsic dimension of any cluster cannot be larger than d_max. It quickens a lot the algorithm for datasets with a large number of variables (e.g. thousands).
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_d_range">d_range</code></td>
<td>

<p>Vector of values to use for the intrinsic dimension for each group when d_select=&quot;grid&quot;.
</p>
</td></tr>
<tr><td><code id="tfunHDDC_+3A_verbose">verbose</code></td>
<td>

<p>Whether to print progress and approximate timing information as tfunHDDC executes. TRUE (default when running in serial) or FALSE (default when running parallel).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If we choose init=&quot;random&quot;, the algorithm is run 20 times with the same model options and the solution which maximises the log-likelihood is printed. This explains why sometimes with this initialization it runs a bit slower than with 'kmeans' initialization.
</p>
<p>If the warning message: &quot;In tfunHDDC(...) : All models diverged&quot; is printed, it means that the algorithm found less classes that the chosen number (parameter K). Because the EM algorithm is used, it could be because of a bad initialization of the EM algorithm. So we have to restart the algorithm multiple times in order to check if with a new initialization of the EM algorithm the model converges, or if there is no solution with the chosen number K.
</p>
<p>The different initializations are:
</p>
<p>“mini-em”:
it is an initialization strategy for which the classes are randomly initialized and the EM algorithm is run for several iterations.  This action is repetead a few times (the default is 5 iterations and 10 times). At the end, the initialization chosen is the one which maximise the log-likelihood (see mini.nb for more information about its parameters).
</p>
<p>“random”:
the classes are randomly given using a multinomial distribution
</p>
<p>“kmeans”:
the classes are initialized using the kmeans function (with algorithm=&quot;Hartigan-Wong&quot;; nstart=4; iter.max=50); note that the user can use his own arguments for kmeans using the dot-dot-dot argument
</p>
<p>“tkmeans”:
the classes are initialized using the tkmeans function (with same default initialization as kmeans); note that the user can use his own arguments for tkmeans using the dot-dot-dot argument
</p>
<p>A prior class &quot;vector&quot;:
It can also be directly initialized with a vector containing the prior classes of the observations. To do so use init=&quot;vector&quot; and provide the vector in the argument init.vector.
</p>
<p>Note that the BIC criterion used in this function is to be maximized and is defined as 2*LL-k*log(n) where LL is the log-likelihood, k is the number of parameters and n is the number of observations.
</p>
<p>There are three methods for selecting the intrinsic dimension using d_select:
</p>
<p>&quot;Cattell&quot;:
Runs a Cattell's scree test to approximate the intrinsic dimension that yields the greatest improvement in clustering.
</p>
<p>&quot;BIC&quot;:
At each iteration we tests each value for each group's intrinsic dimension and sets the intrinsic dimension that yields the best BIC.
</p>
<p>&quot;grid&quot;:
Runs every combination of hyperparameters (eg. K=2, threshold = 0.05, model = ...) for every combination of intrinsic dimensions that can be set with the given d_range (with K = 2 and d_range = c(2, 10) it would set (2,2), (2, 10), (10, 2), and (10, 10)). Due to the sharp increase in test cases it is recommended that this mode is run in parallel if possible. Doing an intial short run to approximate the timing with verbose = TRUE is suggested as well.
</p>


<h3>Value</h3>

<table>
<tr><td><code>d</code></td>
<td>
<p>The number of dimensions for each cluster.</p>
</td></tr>
<tr><td><code>a</code></td>
<td>
<p>Values of parameter a for each cluster.</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>Values of parameter b for each cluster.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The mean of each cluster in the original space.</p>
</td></tr>
<tr><td><code>prop</code></td>
<td>
<p>The proportion of individuals in each cluster.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The maximum of log-likelihood.</p>
</td></tr>
<tr><td><code>loglik_all</code></td>
<td>
<p>The log-likelihood at each iteration.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>The posterior probability for each individual to belong to each cluster.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>The clustering partition.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>The BIC value.</p>
</td></tr>
<tr><td><code>ICL</code></td>
<td>
<p>The ICL value.</p>
</td></tr>
<tr><td><code>complexity</code></td>
<td>
<p>the number of parameters that are estimated.</p>
</td></tr>
<tr><td><code>all_results</code></td>
<td>
<p>if multiple number of clusters or models are considered, results for each model are stored here</p>
</td></tr>
<tr><td><code>nux</code></td>
<td>
<p>Values for the degrees of freedom of the t-distributions for each group.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Cristina Anton, Iain Smith, and Malcolm Nielsen
</p>


<h3>References</h3>

<p>- Andrews JL and McNicholas PD. &ldquo;Model-based clustering, classification, and discriminant analysis with the multivariate <em>t</em>-distribution: The <em>t</em>EIGEN family&rdquo; <em>Statistics and Computing</em> 22(5), 1021&ndash;1029.
</p>
<p>- Andrews JL, McNicholas PD, and Subedi S (2011) &ldquo;Model-based classification via mixtures of multivariate t-distributions&rdquo; <em>Computational Statistics and Data Analysis</em> 55, 520&ndash;529.
</p>
<p>- C.Bouveyron and J.Jacques, Model-based Clustering of Time Series in Group-specific Functional Subspaces, Advances in Data Analysis and Classification, vol. 5 (4), pp. 281-300, 2011 &lt;doi:10.1007/s11634-011-0095-6&gt;
</p>
<p>- Schmutz A, Jacques J, Bouveyron C, et al (2020) Clustering multivariate functional data in group-specific functional subspaces. Comput Stat 35:1101-1131
</p>
<p>- Cristina Anton, Iain Smith Model-based clustering of functional data via mixtures of <code class="reqn">t</code> distributions. Advances in Data Analysis and Classification (to appear).
</p>


<h3>See Also</h3>

<p><code><a href="teigen.html#topic+teigen">teigen</a></code>, <code><a href="stats.html#topic+kmeans">kmeans</a></code>, <code><a href="tclust.html#topic+tkmeans">tkmeans</a></code>,<code><a href="#topic+predict.tfunHDDC">predict.tfunHDDC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1027)
#simulataed univariate data

data = genModelFD(ncurves=300, nsplines=35, alpha=c(0.9,0.9,0.9),
                  eta=c(10, 7, 17))

plot(data$fd, col = data$groupd)

clm = data$groupd

model1=c("AkjBkQkDk", "AkjBQkDk", "AkBkQkDk", "ABkQkDk", "AkBQkDk", "ABQkDk")

t1&lt;-tfunHDDC(data$fd,K=3,threshold=0.2,init="kmeans",nb.rep=1,dfconstr="no", 
             dfupdate="numeric", model=model1[1], itermax=10)

if (!is.null(t1$class)) table(clm, t1$class)

###############example when some classifications are known

known1=rep(NA,1,300)

known1[1]=clm[1]

known1[103]=clm[103]

known1[250]=clm[250]

t2&lt;-tfunHDDC(data$fd,K=3,threshold=0.2,init="kmeans",nb.rep=1,dfconstr="no", 
             dfupdate="numeric", model=model1[1],known=known1, itermax=10)
if (!is.null(t2$class)) table(clm, t2$class)

####### example when some classifications are known 

known1=rep(NA,1,300)

known1[1:100]=rep(3,1,50)

t3&lt;-tfunHDDC(data$fd,K=3,threshold=0.2,init="kmeans",nb.rep=1,dfconstr="no", 
             dfupdate="numeric", model=model1[1],known=known1, itermax=10)

if (!is.null(t3$class)) table(clm, t3$class)

############################multivariate simulated data
set.seed(1027)

conTrig &lt;- genTriangles()

cls = conTrig$groupd # groups 5 and 6 (contaminated) into 1 and 3 respectively

res_s = tfunHDDC(conTrig$fd, K=4, dfconstr="no", dfupdate="numeric", 
                 model="ABKQKDK", init="kmeans", threshold=0.2, nb.rep=1, 
                 itermax=10)

if (!is.null(res_s$class)) table(cls, res_s$class)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
