<!DOCTYPE html><html lang="en"><head><title>Help for package mvabund</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mvabund}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mvabund-package'><p>Statistical methods for analysing multivariate abundance data</p></a></li>
<li><a href='#anova.manyany'><p>Analysis of Deviance for Many Univariate Models Fitted to Multivariate Abundance Data</p></a></li>
<li><a href='#anova.manyglm'><p>Analysis of Deviance for Multivariate Generalized Linear Model</p>
Fits for Abundance Data</a></li>
<li><a href='#anova.manylm'><p>ANOVA for Linear Model Fits for Multivariate Abundance Data</p></a></li>
<li><a href='#anova.traitglm'><p>Testing for a environment-by-trait (fourth corner) interaction by analysis of deviance</p></a></li>
<li><a href='#antTraits'><p>Ant data, with species traits</p></a></li>
<li><a href='#best.r.sq'>
<p>Use R^2 to find the variables that best explain a multivariate response.</p></a></li>
<li><a href='#boxplot.mvabund'><p>Boxplots for multivariate abundance Data</p></a></li>
<li><a href='#coefplot.manyglm'><p>Plots the coefficients of the covariates of a manyglm object with confidence intervals.</p></a></li>
<li><a href='#cv.glm1path'>
<p>Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the best model by corss-validation.</p></a></li>
<li><a href='#deviance.manylm'><p>Model Deviance</p></a></li>
<li><a href='#extend.x.formula'><p>Extend a Formula to all of it's Terms</p></a></li>
<li><a href='#formulaUnimva'><p>Create a List of Univariate Formulas</p></a></li>
<li><a href='#glm1'>
<p>Fits a Generalised Linear Models with a LASSO (or L1) penalty, given a value of the penalty parameter.</p></a></li>
<li><a href='#glm1path'>
<p>Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the model that minimises BIC.</p></a></li>
<li><a href='#logLik.manylm'><p>Calculate the Log Likelihood</p></a></li>
<li><a href='#manyany'><p>Fitting Many Univariate Models to Multivariate Abundance Data</p></a></li>
<li><a href='#manyglm'><p>Fitting Generalized Linear Models for Multivariate Abundance Data</p></a></li>
<li><a href='#manylm'><p>Fitting Linear Models for Multivariate Abundance Data</p></a></li>
<li><a href='#manylm.fit'><p>workhose functions for fitting multivariate linear models</p></a></li>
<li><a href='#meanvar.plot'>
<p>Construct Mean-Variance plots for Multivariate Abundance Data</p></a></li>
<li><a href='#mvabund'><p>Multivariate Abundance Data Objects</p></a></li>
<li><a href='#mvabund-internal'><p>Internal mvabund Objects</p></a></li>
<li><a href='#mvformula'><p> Model Formulae for Multivariate Abundance Data</p></a></li>
<li><a href='#plot.manyany'><p>Plot Diagnostics for a manyany or glm1path Object</p></a></li>
<li><a href='#plot.manylm'><p>Plot Diagnostics for a manylm or a manyglm Object</p></a></li>
<li><a href='#plot.mvabund'><p>Plot Multivariate Abundance Data and Formulae</p></a></li>
<li><a href='#plotMvaFactor'><p>Draw a Mvabund Object split into groups.</p></a></li>
<li><a href='#predict.manyglm'><p>Predict Method for MANYGLM Fits</p></a></li>
<li><a href='#predict.manylm'><p>Model Predictions for Multivariate Linear Models</p></a></li>
<li><a href='#predict.traitglm'>
<p>Predictions from fourth corner model fits</p></a></li>
<li><a href='#residuals.manyglm'><p>Residuals for MANYGLM, MANYANY, GLM1PATH Fits</p></a></li>
<li><a href='#ridgeParamEst'>
<p>Estimation of the ridge parameter</p></a></li>
<li><a href='#shiftpoints'><p>Calculate a shift for plotting overlapping points</p></a></li>
<li><a href='#solberg'><p>Solberg Data</p></a></li>
<li><a href='#spider'><p>Spider data</p></a></li>
<li><a href='#summary.manyglm'><p>Summarizing Multivariate Generalized Linear Model Fits for Abundance Data</p></a></li>
<li><a href='#summary.manylm'><p>Summarizing Linear Model Fits for Multivariate Abundance Data</p></a></li>
<li><a href='#Tasmania'><p>Tasmania Dataset</p></a></li>
<li><a href='#tikus'><p>Tikus Island Dataset</p></a></li>
<li><a href='#traitglm'>
<p>Fits a fourth corner model for abundance as a function of environmental variables and species traits.</p></a></li>
<li><a href='#unabund'><p> Remove the mvabund Class Attribute</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Statistical Methods for Analysing Multivariate Abundance Data</td>
</tr>
<tr>
<td>Version:</td>
<td>4.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-02-10</td>
</tr>
<tr>
<td>Description:</td>
<td>A set of tools for displaying, modeling and analysing
        multivariate abundance data in community ecology. See
        'mvabund-package.Rd' for details of overall package organization.
        The package is implemented with the Gnu Scientific Library
        (<a href="http://www.gnu.org/software/gsl/">http://www.gnu.org/software/gsl/</a>) and 'Rcpp'
        (<a href="http://dirk.eddelbuettel.com/code/rcpp.html">http://dirk.eddelbuettel.com/code/rcpp.html</a>) 'R' / 'C++' classes.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, MASS, methods, stats, tweedie, statmod, parallel</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppGSL</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> [expanded from: LGPL (&ge; 2.1)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-11 08:03:38 UTC; z3103495</td>
</tr>
<tr>
<td>Author:</td>
<td>Yi Wang [aut],
  Ulrike Naumann [aut],
  Dirk Eddelbuettel [aut],
  John Wilshire [aut],
  David Warton [aut, cre],
  Julian Byrnes [ctb],
  Ralph dos Santos Silva [ctb, cph],
  Jenni Niku [ctb],
  Ian Renner [ctb],
  Stephen Wright [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Warton &lt;David.Warton@unsw.edu.au&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-16 13:40:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='mvabund-package'>Statistical methods for analysing multivariate abundance data </h2><span id='topic+mvabund-package'></span>

<h3>Description</h3>

<p>This package provides tools for a model-based approach to the analysis of multivariate abundance data in ecology (Warton 2011), where 'abundance' should be interpreted loosely - as well as counts you could have presence/absence, ordinal or biomass (via <code><a href="#topic+manyany">manyany</a></code>), etc.
</p>
<p>There are graphical methods for exploring the properties of data and the community-environment association, flexible regression methods for estimating and making robust inferences about the community-environment association, 'fourth corner models' to explain environmental response as a function of traits, and diagnostic plots to check the appropriateness of a fitted model (Wang et. al 2012).
</p>
<p>There is an emphasis on design-based inferences about these models, e.g. bootstrapping rows of residuals via <code>anova</code> calls, or cross-validation across rows, to make multivariate inferences that are robust to failure of assumptions about correlation. Another emphasis is on presenting diagnostic tools to check assumptions, especially via residual plotting.
</p>


<h3>Details</h3>

<p>The key functions available in this package are the following.
</p>
<p><b>For graphical display of the data:</b>
</p>

<dl>
<dt><code><a href="#topic+plot.mvabund">plot.mvabund</a></code></dt><dd><p> draw a range of plots for Multivariate Abundance Data </p>
</dd>
<dt><code><a href="#topic+boxplot.mvabund">boxplot.mvabund</a></code></dt><dd><p> draw a range of plots of Model Formulae for Multivariate Abundance Data </p>
</dd>
<dt><code><a href="#topic+meanvar.plot">meanvar.plot</a></code></dt><dd><p> draw mean-variance plots for Multivariate Abundance Data </p>
</dd>
</dl>

<p><b>For estimating and displaying Linear Models:</b>
</p>

<dl>
<dt><code><a href="#topic+manylm">manylm</a></code></dt><dd><p>Fitting Linear Models for Multivariate Abundance Data</p>
</dd>
<dt><code><a href="#topic+summary.manylm">summary.manylm</a></code></dt><dd><p>summarizie Multivariate Linear Model Fits for Abundance Data</p>
</dd>
<dt><code><a href="#topic+anova.manylm">anova.manylm</a></code></dt><dd><p>obtain ANOVA for Multivariate Linear Model Fits for Abundance Data</p>
</dd>
<dt><code><a href="#topic+plot.manylm">plot.manylm</a></code></dt><dd><p>plot diagnostics for a <code>manylm</code> Object</p>
</dd>
</dl>

<p><b>For estimating and displaying Generalized Linear Models:</b>
</p>

<dl>
<dt><code><a href="#topic+manyglm">manyglm</a></code></dt><dd><p>fit Generalized Linear Models for Multivariate Abundance Data</p>
</dd>
<dt><code><a href="#topic+summary.manyglm">summary.manyglm</a></code></dt><dd><p>summarize Multivariate Generalized Linear Model Fits for Abundance Data</p>
</dd>
<dt><code><a href="#topic+anova.manyglm">anova.manyglm</a></code></dt><dd><p>obtain Analysis of Deviance for Multivariate Generalized Linear Model Fits for Abundance Data</p>
</dd>
<dt><code><a href="#topic+plot.manyglm">plot.manyglm</a></code></dt><dd><p>plot diagnostics for a <code>manyglm</code> Object</p>
</dd>
</dl>

<p>Other generic functions like <code>residuals</code>, <code>predict</code>, <code>AIC</code> can be applied to <code><a href="#topic+manyglm">manyglm</a></code> objects.
</p>
<p><b>For estimating and displaying 'fourth corner models'</b> with species traits as well as environmental predictors:
</p>

<dl>
<dt><code><a href="#topic+traitglm">traitglm</a></code></dt><dd><p>predict abundance using a GLM as a function of traits as well as environmental variables</p>
</dd>
<dt><code><a href="#topic+anova.traitglm">anova.traitglm</a></code></dt><dd><p>obtain Analysis of Deviance for a fourth corner model of abundance</p>
</dd>
</dl>

<p>Other generic functions like <code>plot</code>, <code>residuals</code>, <code>predict</code>, <code>AIC</code> can be applied to <code><a href="#topic+traitglm">traitglm</a></code> objects. Note <code><a href="#topic+traitglm">traitglm</a></code> can work slowly, as it fits a single big model to vectorised data (then wants to resample it when you call <code>anova.traitglm</code>). 
</p>
<p><b>For fitting more flexible models:</b>
</p>

<dl>
<dt><code><a href="#topic+manyany">manyany</a></code></dt><dd><p>simultaneously fit univariate models to each response variable from 'any' input function</p>
</dd>
<dt><code><a href="#topic+anova.manyany">anova.manyany</a></code></dt><dd><p>simultaneously test for a community-level effect, comparing two or more <code>manyany</code> objects</p>
</dd>
<dt><code><a href="#topic+glm1path">glm1path</a></code></dt><dd><p>fit a path of Generalised Linear Models with L1 ('LASSO') penalties</p>
</dd>
<dt><code><a href="#topic+cv.glm1path">cv.glm1path</a></code></dt><dd><p>choose the value of the L1 penalty in a <code>glm1path</code> fit by cross-validation</p>
</dd>
</dl>

<p>Other generic functions like <code>residuals</code>, <code>predict</code>, <code>AIC</code> can be applied to <code><a href="#topic+manyany">manyany</a></code> and <code><a href="#topic+glm1path">glm1path</a></code> objects. These functions also can be on the slow side, especially if all rare species are included.
</p>
<p><b>For providing a data structure:</b>
</p>

<dl>
<dt><code><a href="#topic+mvabund">mvabund</a></code></dt><dd><p>create a mvabund object</p>
</dd>
<dt><code><a href="#topic+mvformula">mvformula</a></code></dt><dd><p>create Model Formulae for Multivariate Abundance Data</p>
</dd>
</dl>

<p><b>Example datasets:</b>
</p>

<dl>
<dt><code><a href="#topic+Tasmania">Tasmania</a></code></dt><dd><p> meiobenthic community data from Tasmania. Used to demonstrate test for interaction. </p>
</dd>
<dt><code><a href="#topic+solberg">solberg</a></code></dt><dd><p> solberg species counts with a 3-level treatment factor. </p>
</dd>
<dt><code><a href="#topic+spider">spider</a></code></dt><dd><p> hunting spiders counts from different sites.</p>
</dd>
<dt><code><a href="#topic+tikus">tikus</a></code></dt><dd><p> solberg nematode counts from Tikus island.</p>
</dd>
<dt><code><a href="#topic+antTraits">antTraits</a></code></dt><dd><p> ant counts from Eucalypt forests, with trait measurements.</p>
</dd>
</dl>

<p>For more details, see the documentation for any of the individual functions listed above.
</p>


<h3>Author(s)</h3>

<p>David Warton <a href="mailto:David.Warton@unsw.edu.au">David.Warton@unsw.edu.au</a>, Yi Wang and Ulrike Naumann.</p>


<h3>References</h3>

<p>Brown AM, Warton DI, Andrew NR, Binns M, Cassis G and Gibb H (2014) The fourth corner solution - using species traits to better understand how species traits interact with their environment, <em>Methods in Ecology and Evolution</em> 5, 344-352.
</p>
<p>Warton D.I. (2008a). Raw data graphing: an informative but under-utilized tool for the analysis of multivariate abundances. <em>Austral Ecology</em> 33, 290-300.
</p>
<p>Warton D.I. (2008b). Penalized normal likelihood and ridge regularization of correlation and covariance matrices. <em>Journal of the American Statistical Association</em> 103, 340-349.
</p>
<p>Warton D.I. (2011). Regularized sandwich estimators for analysis of high dimensional data using generalized estimating equations. <em>Biometrics</em>, 67, 116-123.
</p>
<p>Warton DI, Shipley B &amp; Hastie T (2015) CATS regression - a model-based approach to studying trait-based community assembly, <em>Methods in Ecology and Evolution</em> 6, 389-398.
</p>
<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3, 89-101.
</p>
<p>Wang Y., Neuman U., Wright S. and Warton D. I. (2012). mvabund: an R package
for model-based analysis of multivariate abundance data. <em>Methods in Ecology and Evolution</em>, 3, 471-473. 
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+plot.mvabund">plot.mvabund</a></code>, <code><a href="#topic+meanvar.plot">meanvar.plot</a></code>,
<code><a href="#topic+manyany">manyany</a></code>, <code><a href="#topic+manylm">manylm</a></code>, <code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="#topic+traitglm">traitglm</a></code>, <code><a href="#topic+summary.manylm">summary.manylm</a></code>, <code><a href="#topic+anova.manyany">anova.manyany</a></code>, <code><a href="#topic+anova.manylm">anova.manylm</a></code>, <code><a href="#topic+anova.traitglm">anova.traitglm</a></code>, <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, <code><a href="#topic+plot.manylm">plot.manylm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

## Load the spider dataset:
data(spider)

## Create the mvabund object spiddat:
spiddat &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

## Draw a plot of the spider data:
plot(spiddat, col="gray1", n.vars=8, transformation="sqrt", 
xlab=c("Hunting Spider"), ylab="Spider Species", scale.lab="s",
t.lab="t", shift=TRUE, fg= "lightblue", col.main="red", main="Spiders") 


## A mean-variance plot, data organised by year, 
## for 1981 and 1983 only, as in Figure 7a of Warton (2008a):
data(tikus)
tikusdat &lt;- mvabund(tikus$abund)
year &lt;- tikus$x[,1]
is81or83 &lt;- year==81 | year==83
meanvar.plot(tikusdat~year,legend=TRUE, subset=is81or83, col=c(1,10)) 	

## Create a formula for multivariate abundance data:
foo &lt;- mvformula( spiddat~X )

## Create a List of Univariate Formulas:
fooUni &lt;- formulaUnimva(spiddat~X)
fooUniInt &lt;- formulaUnimva(spiddat~X, intercept=TRUE)

## Find the three variables that best explain the response:
best.r.sq( foo, n.xvars= 3)

## Fit a multivariate linear model:
foo &lt;- mvformula( spiddat~X )
lm.spider &lt;- manylm(foo)

## Plot Diagnostics for a multivariate linear model:
plot(lm.spider,which=1:2,col.main="red",cex=3,overlay=FALSE)

## Obtain a summary of test statistics using residual resampling:
summary(lm.spider, nBoot=500)

## Calculate a ANOVA Table:
anova(lm.spider, nBoot=500)

</code></pre>

<hr>
<h2 id='anova.manyany'>Analysis of Deviance for Many Univariate Models Fitted to Multivariate Abundance Data</h2><span id='topic+anova.manyany'></span><span id='topic+print.anova.manyany'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for many univariate model fits. Slowly!</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyany'
anova(object, ..., nBoot=99, p.uni="none", block=object1$block, nCores=1,
       bootID=NULL, replace=TRUE) 

## S3 method for class 'anova.manyany'
print(x, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova.manyany_+3A_object">object</code></td>
<td>
<p>of class <code>manyany</code> under the null hypothesis, typically the result of a call to <code><a href="#topic+manyany">manyany</a></code>.</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_...">...</code></td>
<td>
<p>other generic <code>anova</code> methods. NEEDS TO INCLUDE A SECOND <code>manyany</code> object for the alternative hypothesis to be tested.</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_nboot">nBoot</code></td>
<td>
<p>the number of Bootstrap iterations, default is <code>nBoot=99</code>.</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_p.uni">p.uni</code></td>
<td>
<p>whether to calculate univariate test statistics and their P-values.<br />
&quot;none&quot; = No univariate P-values (default) <br />
&quot;unadjusted&quot; = A test statistic and (ordinary unadjusted) P-value are reported
for each response variable. If the <code>manyany</code> object is compositional (<code>composition=TRUE</code>), this option is unavailable as yet.
</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_block">block</code></td>
<td>
<p>a factor specifying the sampling level to be resampled. Default is resampling rows (if
composition=TRUE in the manyany command, this means resampling rows of data as originally sent to manyany).</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_ncores">nCores</code></td>
<td>
<p>Number of cores to use for computations (for parallel computing).</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_bootid">bootID</code></td>
<td>
<p>A user-entered matrix of indices for which observations to use in which resample. Bootstrap
resamples in rows, observations in columns. When specified, overwrites <code>nBoot</code> and <code>block</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_replace">replace</code></td>
<td>
<p>whether to sample with or without replacement, as in the <code><a href="base.html#topic+sample">sample</a></code> function.
<code>= FALSE</code> for PIT-permutation, <code> = TRUE</code> for PIT-trap.</p>
</td></tr>
<tr><td><code id="anova.manyany_+3A_x">x</code></td>
<td>
<p><code>anova.manyany</code> object to be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>anova.manyany</code> function returns a table summarising the statistical significance
of a fitted manyany model under the alternative hypothesis (<code>object2</code>) as compared
to a fit under the null hypothesis (<code>object</code>). Typically the alternative model
is nested in the null although it doesn't need to be (but consider seriously if what
you are doing makes sense if they are not nested).
</p>
<p>This function is quite computationally intensive, and a little fussy - it is an early
version we hope to improve on. Feedback welcome!
</p>
<p>This function behaves a lot like <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, the most conspicuous differences
being in flexibility and computation time. Since this function is based on <code>manyany</code>,
it offers much greater flexibility in terms of types of models that can be fitted (most
fixed effects model with <code>predict</code> and <code>family</code> arguments could be accommodated).
For information on the different types of data that can be modelled using manyany, see
<code><a href="#topic+manyany">manyany</a></code>.
</p>
<p>However this flexibility comes at considerable cost in terms of computation time, and the
default <code>nBoot</code> has been set to 99 to reflect this (although rerunning at 999 is
recommended). Other more cosmetic differences from <code><a href="#topic+anova.manyglm">anova.manyglm</a></code> are that
two and only two models can be supplied as input here; adjusted univariate P-values
are not yet implemented; and the range of test statistics and resampling algorithms is
more limited. All test statistics constructed here are sum-of-likelihood ratio statistics
as in Warton et al (2012), and the resampling method used here is the PIT-trap (short
for 'probability integral transform residual bootstrap', Warton et al 2017).
</p>
<p>To check model assumptions, use <code><a href="#topic+plot.manyany">plot.manyany</a></code>.
</p>
<p>The <code>block</code> argument allows for block resampling, such that valid inferences can
be made across independent blocks of correlated sets of observations.
For example, if data have multiple rows of records for each site, e.g. multi-species
data with entries for different species on different rows, you can use your site ID
variable as the block argument to resample sites, for valid cross-site inferences despite
within-site species correlation. Well, valid assuming sites are independent. You could
do similarly for a repeated measures design to make inferences robust to temporal autocorrelation.
Note that <code>block</code> needs to be balanced, e.g. equal number of species entries for
each site (i.e. include rows for zero abundances too). 
</p>
<p>The <code>anova.manyany</code> function is designed specifically for high-dimensional data
(that, is when the number of variables p is not small compared to the number of observations
N). In such instances a correlation matrix is computationally intensive to estimate
and is numerically unstable, so by default the test statistic is calculated assuming
independence of variables. Note however that the resampling scheme used ensures that
the P-values are approximately correct even when the independence assumption is not
satisfied. 
</p>
<p>Rather than stopping after testing for multivariate effects, it is often of interest
to find out which response variables express significant effects. Univariate statistics
are required to answer this question, and these are reported if requested. Setting <code>p.uni="unadjusted"</code>
returns resampling-based univariate P-values for all effects as well as the multivariate
P-values, if <code>composition=FALSE</code>. There are currently no univariate P-value options
when <code>composition=TRUE</code> (it's not entirely clear how such P-values should be obtained)
and if univariate P's are of interest why not rerun the model with <code>composition=FALSE</code>.
</p>
<p>A current limitation of the function is that <code>composition</code> needs to be set to
the same value in each manyany object being compared - it is not currently possible
to compare models with and without a compositional term in them.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>stat</code></td>
<td>
<p>the observed value of the test statistic.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the P-value as estimated from <code>nBoot</code> resamples.</p>
</td></tr>
<tr><td><code>stat.i</code></td>
<td>
<p>the values of the test statistic in each of the <code>nBoot</code> resamples.</p>
</td></tr>
<tr><td><code>p.i</code></td>
<td>
<p>the P-value in each of the <code>nBoot</code> resamples.</p>
</td></tr>
<tr><td><code>p.uni</code></td>
<td>
<p>the <code>p.uni</code> argument supplied.</p>
</td></tr>
</table>
<p>If <code>p.uni="unadjusted"</code> the output list also contains<br />
</p>
<table role = "presentation">
<tr><td><code>uni.test</code></td>
<td>
<p>a table showing the test statistics of the univariate tests.</p>
</td></tr>
<tr><td><code>uni.p</code></td>
<td>
<p>a table showing the p-values of the univariate tests.</p>
</td></tr>
<tr><td><code>statj.i</code></td>
<td>
<p>a matrix of values of the univariate test statistics in each of the <code>nBoot</code> resamples.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The comparison between two or more models by <code>anova.manyglm</code> will only be valid if they are fitted to the same dataset. This may be a problem if there are missing values and R's default of <code>na.action = na.omit</code> is used. 
</p>


<h3>Author(s)</h3>

<p>David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>
<p>Warton D. I., Thibaut L., Wang Y. A.  (2017). The PIT-trap - A &quot;model-free&quot; bootstrap procedure for inference about regression models with discrete, multivariate responses. <em>PLoS One</em>, 12(7), e0181790.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyany">manyany</a></code>, <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Try fitting Tikus Islands data with Tweedie models with power parameter 1.5,
## to test for compositional effect:
data(tikus)
coral &lt;- as.matrix(tikus$abund[1:20,])
sumSpp = apply(coral&gt;0,2,sum)

coral &lt;- coral[,sumSpp&gt;6] ## cutting to just species with seven(!) or more presences to cut
## computation time.  Maybe rerun with less (e.g. 4 or more presences) if curious and patient.
coralX &lt;- tikus$x[1:20,]

require(tweedie)
require(statmod)

ftTimeRep &lt;- manyany(coral ~ time+rep, "glm", data=coralX, 
  family=tweedie(var.power=1.5, link.power=0), var.power=1.5, composition=TRUE)

ftRep &lt;- manyany(coral ~ rep, "glm", data=coralX, 
  family=tweedie(var.power=1.5, link.power=0), var.power=1.5, composition=TRUE)
anova(ftRep,ftTimeRep,nBoot=9) #this takes a few seconds to run even for just 9 resamples
## This should be rerun for nBoot=999, which could a few minutes...

## Not run: library(ordinal)
## First construct an ordinal dataset:
## Not run: spidOrd = spider$abund
## Not run: spidOrd[spider$abund&gt;1 &amp; spider$abund&lt;=10]=2
## Not run: spidOrd[spider$abund&gt;10]=3
## Now fit a model using the clm function:
## Not run: manyOrd=manyany(spidOrd~bare.sand+fallen.leaves,"clm",data=spider$x)
## Test to see if fallen.leaves needs to be there:
## Not run: manyOrd0=manyany(spidOrd~bare.sand,"clm",data=spider$x)
## Not run: anova(manyOrd0,manyOrd,nBoot=19)

</code></pre>

<hr>
<h2 id='anova.manyglm'>Analysis of Deviance for Multivariate Generalized Linear Model
Fits for Abundance Data</h2><span id='topic+anova.manyglm'></span><span id='topic+print.anova.manyglm'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for one or more multivariate
generalized linear model fits.</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
## S3 method for class 'manyglm'
anova(object, ..., resamp="pit.trap", test="LR", p.uni="none",
    nBoot=999, cor.type=object$cor.type,
    pairwise.comp = NULL,
    block=NULL, show.time="total",
    show.warning=FALSE, rep.seed=FALSE, bootID=NULL, keep.boot=FALSE) 
## S3 method for class 'anova.manyglm'
print(x, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova.manyglm_+3A_object">object</code></td>
<td>
<p>objects of class <code>manyglm</code>, typically the result of a call to <code><a href="#topic+manyglm">manyglm</a></code>.
</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_...">...</code></td>
<td>
<p>for the <code>anova.manyglm</code> method, these are optional further objects of class <code>manyglm</code>, which are usually a result of a call to <code><a href="#topic+manyglm">manyglm</a></code>
for the <code>print.anova.manyglm</code> method these are optional further arguments passed to or from other methods. See <code><a href="stats.html#topic+print.summary.glm">print.summary.glm</a></code> for more details.</p>
</td></tr>        
<tr><td><code id="anova.manyglm_+3A_resamp">resamp</code></td>
<td>
<p>the method of resampling used. Can be one of &quot;case&quot;, &quot;perm.resid&quot;, &quot;montecarlo&quot; or &quot;pit.trap&quot; (default). See Details.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_test">test</code></td>
<td>
<p>the test to be used. If <code>cor.type="I"</code>, this can be one of &quot;wald&quot; for a Wald-Test or &quot;score&quot; for a Score-Test or &quot;LR&quot; for a Likelihood-Ratio-Test, otherwise only &quot;wald&quot; and &quot;score&quot; is allowed. The default value is &quot;LR&quot;.
</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_p.uni">p.uni</code></td>
<td>
<p>whether to calculate univariate test statistics and their P-values, and if so, what type. This can be one of the following options. <br />
&quot;none&quot; = No univariate P-values (default) <br />
&quot;unadjusted&quot; = A test statistic and (ordinary unadjusted) P-value are reported
for each response variable. <br />
&quot;adjusted&quot; = Univariate P-values are adjusted for multiple testing, using a
step-down resampling procedure.
</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_nboot">nBoot</code></td>
<td>
<p>the number of Bootstrap iterations, default is <code>nBoot=999</code>.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_cor.type">cor.type</code></td>
<td>
<p>structure imposed on the estimated correlation matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;. See Details.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_pairwise.comp">pairwise.comp</code></td>
<td>

<p>A character or factor vector specifying the levels for which a pairwise comparison will be carried out, adjusting for multiple comparisons via a free stepdown resampling procedure.
Alternatively, a onesided formula specifying an interaction between factor levels.
</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_block">block</code></td>
<td>
<p>a factor specifying the sampling level to be resampled. Default is resampling rows.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_show.time">show.time</code></td>
<td>
<p>Whether to display timing information for the resampling procedure: &quot;none&quot; shows none, &quot;all&quot; shows all timing information and &quot;total&quot; shows only the overall time taken for the tests. </p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_show.warning">show.warning</code></td>
<td>
<p>logical. Whether to display warning messages in the operation procedure.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_rep.seed">rep.seed</code></td>
<td>
<p>logical. Whether to fix random seed in resampling data. Useful for simulation or diagnostic purposes.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_bootid">bootID</code></td>
<td>
<p>an integer matrix where each row specifies bootstrap id's in each resampling run. When <code>bootID</code> is supplied, <code>nBoot</code> is set to the number of rows in <code>bootID</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_keep.boot">keep.boot</code></td>
<td>
<p>logical. Whether to return the bootstrapped test statistics.</p>
</td></tr>
<tr><td><code id="anova.manyglm_+3A_x">x</code></td>
<td>
<p>an object of class &quot;anova.manyglm&quot;, usually, a result of a call to
<code><a href="#topic+anova.manyglm">anova.manyglm</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>anova.manyglm</code> function returns a table summarising the statistical significance of a fitted manyglm model (Warton 2011), or of the differences between several nested models. If one model is specified, sequential test statistics (and P values) are returned for that fit. If more than one object is specified, the table contains test statistics (and P values) comparing their fits, provided that the models are fitted to the same dataset.
</p>
<p>The test statistics are determined by the argument <code>test</code>, and the 
P-values are calculated by resampling rows of the data using a method 
determined by the argument <code>resamp</code>. <code>resamp</code>. Two of the three 
available resampling methods (residual permutation and parametric bootstrap) 
are described in more detail in Davison and Hinkley (1997, chapter 6), 
whereas the default (the &ldquo;PIT-trap&rdquo;, Warton et al 2017) 
bootstraps probability integral transform residuals, which we have found 
to give the most reliable Type I error rates. All methods involve resampling 
under the resampling under the null hypothesis. These methods ensure 
approximately valid inference even when the mean-variance relationship or the 
correlation between variables has been misspecified.  Standardized Pearson 
residuals (see <code><a href="#topic+manyglm">manyglm</a></code> are currently used in residual 
permutation, and where necessary, resampled response values are truncated so 
that they fall in the required range (e.g. counts cannot be negative). 
However, this can introduce bias, especially for <code>family=binomial</code>, so 
we advise extreme caution using <code>perm.resid</code> for presence/absence data. 
If <code>resamp="none"</code>, p-values cannot be calculated, however the test 
statistics are returned. 
</p>
<p>If you do not have a specific hypothesis of primary interest that you want to test, and are instead interested in which model terms are statistically significant, then the <code>summary.manyglm</code> function is more appropriate. Whereas <code>summary.manyglm</code> tests the significance of each explanatory variable, <code>anova.manyglm</code>, given one <code>manyglm</code> object tests each  term of the formula, e.g. if the formula is 'y~a+b' then a and b, that can be vectors or matrices, are tested for significance.
</p>
<p>For information on the different types of data that can be modelled using manyglm, see <code><a href="#topic+manyglm">manyglm</a></code>. To check model assumptions, use <code><a href="#topic+plot.manyglm">plot.manyglm</a></code>.
</p>
<p>Multivariate test statistics are constructed using one of three methods: a log-likelihood ratio statistic <code>test="LR"</code>, for example as in Warton et. al. (2012) or a Wald statistic <code>test="wald"</code> or a Score statistic <code>test="score"</code>. &quot;LR&quot; has good properties, but is only available when <code>cor.type="I"</code>. 
</p>
<p>The default Wald test statistic makes use of a generalised estimating equations (GEE) approach, estimating the covariance matrix of parameter estimates using a sandwich-type estimator that assumes the mean-variance relationship in the data is correctly specified and that there is an unknown but constant correlation across all observations. Such assumptions allow the test statistic to account for correlation between variables but to do so in a more efficient way than traditional GEE sandwich estimators (Warton 2011). The common correlation matrix is estimated from standardized Pearson residuals, and the method specified by <code>cor.type</code> is used to adjust for high dimensionality. 
</p>
<p>The Wald statistic has problems for count data and presence-absence 
data when there are estimated means at zero (which usually means very large parameter estimates, check for this using <code>coef</code>). In such instances Wald statistics should not be used, Score or LR should do the job. 
</p>
<p>The <code>anova.manyglm</code> function is designed specifically for high-dimensional data (that, is when the number of variables p is not small compared to the number of observations N). In such instances a correlation matrix is computationally intensive to estimate and is numerically unstable, so by default the test statistic is calculated assuming independence of variables (<code>cor.type="I"</code>). Note however that the resampling scheme used ensures that the P-values are approximately correct even when the independence assumption is not satisfied. However if it is computationally feasible for your dataset, it is recommended that you use <code>cor.type="shrink"</code> to account for correlation between variables, or <code>cor.type="R"</code> when p is small. The <code>cor.type="R"</code> option uses the unstructured correlation matrix (only possible when N&gt;p), such that the standard  classical multivariate test statistics are obtained. Note however that such statistics are typically numerically unstable and have low power when p is not small compared to N. 
</p>
<p>The <code>cor.type="shrink"</code> option applies ridge regularisation (Warton 2008), shrinking the sample correlation matrix towards the identity, which improves its stability when p is not small compared to N. This provides a compromise between <code>"R"</code> and <code>"I"</code>, allowing us to account for correlation between variables, while using a numerically stable test statistic that has good properties. 
</p>
<p>The shrinkage parameter is an attribute of a <code><a href="#topic+manyglm">manyglm</a></code> object. For a Wald test, the sample correlation matrix of the alternative model is used to calculate the test statistics. So <code>shrink.param</code> of the alternative model is used. For a score test, the sample correlation matrix of the null model is used to calculate the test statistics. So <code>shrink.param</code> of the null model is used instead. If <code>cor.type=="shrink"</code> and <code>shrink.param</code> is NULL, then the shrinkage parameter will be estimated by cross-validation using the multivariate normal likelihood function (see <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code> and (Warton 2008)) for the corresponding model in the anova test.
</p>
<p>Rather than stopping after testing for multivariate effects, it is often of interest to find out which response variables express significant effects. Univariate statistics are required to answer this question, and these are reported if requested. Setting <code>p.uni="unadjusted"</code> returns resampling-based univariate P-values for all effects as well as the multivariate P-values, whereas <code>p.uni="adjusted"</code> returns adjusted P-values (that have been adjusted for multiple testing), calculated using a step-down resampling algorithm as in Westfall &amp; Young (1993, Algorithm 2.8). This method provides strong control of family-wise error rates, and makes use of resampling (using the method controlled by <code>resamp</code>) to ensure inferences take into account correlation between variables. This functionality is not currently available for models of relative abundance via <code>composition=TRUE</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>family</code></td>
<td>
<p>the <code>family</code> component from <code>object</code>.</p>
</td></tr>
<tr><td><code>p.uni</code></td>
<td>
<p>the <code>p.uni</code> argument supplied.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the <code>test</code> argument supplied.</p>
</td></tr>
<tr><td><code>cor.type</code></td>
<td>
<p>the <code>cor.type</code> argument supplied.</p>
</td></tr>
<tr><td><code>resamp</code></td>
<td>
<p>the <code>resamp</code> argument supplied.</p>
</td></tr>
<tr><td><code>nBoot</code></td>
<td>
<p>the <code>nBoot</code> argument supplied.</p>
</td></tr>
<tr><td><code>shrink.parameter</code></td>
<td>
<p>a list of shrink parameters from all <code>manyglm</code> objects in the anova test.</p>
</td></tr>
<tr><td><code>n.bootsdone</code></td>
<td>
<p>the number of bootstrapping iterations that were done, i.e. had no error.</p>
</td></tr>
<tr><td><code>table</code></td>
<td>
<p>the table with Residual Degrees of Freedom, Degrees of Freedom, the Test Statistics and the P values.</p>
</td></tr>
<tr><td><code>block</code></td>
<td>
<p>any <code>block</code> argument specified as an inpout argument.</p>
</td></tr>
<tr><td><code>pairwise.comp</code></td>
<td>
<p>The <code>pairwise.comp</code> argument supplied.</p>
</td></tr>
</table>
<p>If <code>p.uni="adjusted"</code> or <code>"unadjusted"</code> the output list also contains<br />
</p>
<table role = "presentation">
<tr><td><code>uni.test</code></td>
<td>
<p>a table showing the test statistics of the univariate tests.</p>
</td></tr>
<tr><td><code>uni.p</code></td>
<td>
<p>a table showing the p-values of the univariate tests.</p>
</td></tr>
</table>
<p>If <code>keep.boot=TRUE</code> the output list also contains <br />
</p>
<table role = "presentation">
<tr><td><code>bootStat</code></td>
<td>
<p>A matrix of boot strapped test statistics, the first column is the multivariate test statistic, the rest of the columns are the univariate statistic.</p>
</td></tr>
</table>
<p>If <code>!is.null(parwise.comp)</code> the output list also contains <br />
</p>
<table role = "presentation">
<tr><td><code>pairwise.comp.table</code></td>
<td>
<p>A data.frame containing the comparisons, the observed test statistcs and the holm free stepdown adjusted p-values.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The comparison between two or more models by <code>anova.manyglm</code> will only be valid if they are fitted to the same dataset. This may be a problem if there are missing values and R's default of <code>na.action = na.omit</code> is used. 
</p>


<h3>Author(s)</h3>

<p>Yi Wang, Ulrike Naumann, John Wilshire and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Davison, A. C. and Hinkley, D. V. (1997) <em>Bootstrap Methods and their Application.</em> Cambridge University Press, Cambridge.
</p>
<p>Warton D.I. (2011). Regularized sandwich estimators for analysis of high dimensional data using generalized estimating equations. <em>Biometrics</em>, 67(1), 116-123.
</p>
<p>Warton D.I. (2008). Penalized normal likelihood and ridge regularization of correlation and covariance matrices. <em>Journal of the American Statistical Association</em> 103, 340-349.
</p>
<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>
<p>Warton D. I., Thibaut L., Wang Y. A.  (2017). The PIT-trap - A &quot;model-free&quot; bootstrap procedure for inference about regression models with discrete, multivariate responses. <em>PLoS One</em>, 12(7), e0181790.
</p>
<p>Westfall, P. H. and Young, S. S. (1993) <em>Resampling-based multiple 
testing.</em> John Wiley &amp; Sons, New York.
</p>
<p>Wu, C. F. J. (1986) Jackknife, Bootstrap and Other Resampling Methods in
Regression Analysis. <em>The Annals of Statistics</em> 14:4, 1261-1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="#topic+summary.manyglm">summary.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load the Tasmania data set
data(Tasmania)

## Visualise the effect of treatment on copepod abundance
tasm.cop &lt;- mvabund(Tasmania$copepods)
treatment &lt;- Tasmania$treatment
block &lt;- Tasmania$block
#plot(tasm.cop ~ treatment, col=as.numeric(block))

## Fitting predictive models using a negative binomial model for counts:
tasm.cop.nb &lt;- manyglm(tasm.cop ~ block*treatment, family="negative.binomial")

## Testing hypotheses about the treatment effect and treatment-by-block interactions, 
## using a Wald statistic and 199 resamples (better to ramp up to 999 for a paper):
anova(tasm.cop.nb, nBoot=199, test="wald")

## Performing the Pairwise comparison:
## Not run: 
data(solberg)
manyglm(abund ~ x, data=solberg) -&gt; msolglm
## pairwise comparison on solberg$x
anova(msolglm, pairwise.comp = solberg$x, nBoot = 199)
# Could also run: anova(msolglm, pairwise.comp = ~treatment, nBoot = 199)

## End(Not run)
</code></pre>

<hr>
<h2 id='anova.manylm'>ANOVA for Linear Model Fits for Multivariate Abundance Data</h2><span id='topic+anova.manylm'></span><span id='topic+print.anova.manylm'></span>

<h3>Description</h3>

<p><code>anova</code> method for class &quot;manylm&quot; - computes an analysis of variance 
table for one or more linear model fits to high-dimensional data, such as 
multivariate abundance data in ecology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
anova(object, ..., resamp="perm.resid", test="F", p.uni="none",
        nBoot=999, cor.type=object$cor.type,
        block=NULL, shrink.param=object$shrink.param, 
	studentize=TRUE, calc.rss = FALSE, tol=1.0e-10, rep.seed=FALSE, bootID=NULL )
## S3 method for class 'anova.manylm'
print(
    x, digits = max(getOption("digits") - 3, 3),
    signif.stars = getOption("show.signif.stars"),
    dig.tst = max(1, min(5, digits - 1)),
    eps.Pvalue = .Machine$double.eps, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova.manylm_+3A_object">object</code></td>
<td>

<p>object of class <code>manylm</code>, usually, a result of a call to <code><a href="#topic+manylm">manylm</a></code>.
</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_...">...</code></td>
<td>

<p>for the <code>anova.manylm</code> method, these are optional further objects of class <code>manylm</code>, which are usually a result of a call to <code><a href="#topic+manylm">manylm</a></code>.
for the <code>print.anova.manylm</code> method these are optional further arguments
passed to or from other methods.
</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_nboot">nBoot</code></td>
<td>
<p>the number of iterations in resampling. Default is 999 for P-values as fractions out of 1000.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_resamp">resamp</code></td>
<td>
<p>the method of resampling used. Can be one of &quot;perm.resid&quot; (default), &quot;residual&quot;, &quot;score&quot;, &quot;case&quot;. See Details.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_test">test</code></td>
<td>
<p>the test to be used. Possible values are: <code>"LR"</code> = likelihood ratio statistic, <code>"F"</code> = Lawley-Hotelling trace statistic or <code>NULL</code> for no test.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_cor.type">cor.type</code></td>
<td>
<p>structure imposed on the estimated correlation matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;. See Details.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_block">block</code></td>
<td>
<p>A factor specifying the sampling level to be resampled. Default is resampling rows.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_shrink.param">shrink.param</code></td>
<td>
<p>shrinkage parameter to be used if <code>cor.type="shrink"</code>. If not supplied, but needed, it will be estimated by estimated from the data by Cross Validation using the normal likelihood as in Warton (2008).</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_p.uni">p.uni</code></td>
<td>
<p>whether to calculate univariate test statistics and their P-values, and if so, what type. <br />
&quot;none&quot; = no univariate P-values (default) <br />
&quot;unadjusted&quot; = A test statistic and (ordinary unadjusted) P-value is reported
for each response variable. <br />
&quot;adjusted&quot; = Univariate P-values are adjusted for multiple testing, using a step-down resampling procedure.
</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_studentize">studentize</code></td>
<td>
<p>logical. Whether studentized residuals should be used to simulate the data in the resampling steps. This option is not used in case resampling.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_calc.rss">calc.rss</code></td>
<td>
<p>logical. Whether the Residual Sum of Squares should be calculated.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_tol">tol</code></td>
<td>
<p>the sensitivity in calculations near 0.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_rep.seed">rep.seed</code></td>
<td>
<p>logical. Whether to fix random seed in resampling data. Useful for simulation or diagnostic purposes.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_bootid">bootID</code></td>
<td>
<p>an integer matrix where each row specifies bootstrap id's in each resampling run. When <code>bootID</code> is supplied, <code>nBoot</code> is set to the number of rows in <code>bootID</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"anova.manylm"</code>, usually, a result of a call to <code>anova.manylm</code>.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If <code>TRUE</code>, &lsquo;significance stars&rsquo; are
printed for each coefficient.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_dig.tst">dig.tst</code></td>
<td>
<p>the number of digits to round the estimates of the model parameters.</p>
</td></tr>
<tr><td><code id="anova.manylm_+3A_eps.pvalue">eps.Pvalue</code></td>
<td>
<p>a numerical tolerance for the formatting of p values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>anova.manylm</code> function returns a table summarising the statistical significance of a fitted manylm model, or of the differences between several nested models fitted to the same dataset. If one model is specified, sequential test statistics (and P values) are returned for that fit. If more than one object is specified, the table contains test statistics (and P values) comparing their fits.
</p>
<p>The test statistics are determined by the argument <code>test</code>, and the P-values are calculated by resampling rows of the data using a method determined by the argument <code>resamp</code>. The four possible resampling methods are residual-permutation (Anderson and Robinson (2001)), score resampling (Wu (1986)), case and residual resampling (Davison and Hinkley (1997, chapter 6)), and involve resampling under the null hypothesis (except for case resampling). These methods ensure approximately valid inference even when the correlation between variables has been misspecified, and for case and score resampling, even when the equal variance assumption of linear models is invalid. By default, studentised residuals (r_i/sqrt(1-h_ii)) are used in residual and score resampling, although raw residuals could be used via the argument <code>studentize=FALSE</code>. 
If <code>resamp="none"</code>, p-values cannot be calculated, however the test statistics are returned.
</p>
<p>If you do not have a specific hypothesis of primary interest that you want to test, and are instead interested in which model terms are statistically significant, then the <code>summary.manylm</code> function is more appropriate.
</p>
<p>More than one object should only be specified when the models are nested. In this case the ANOVA table has a column for the residual degrees of freedom and a column for change in degrees of freedom. It is conventional to list the models from smallest to largest, but this is up to the user.
</p>
<p>To check model assumptions, use <code>plot.manylm</code>.
</p>
<p>The <code>anova.manylm</code> function is designed specifically for high-dimensional data (that, is when the number of variables p is not small compared to the number of observations N). In such instances a correlation matrix is computationally intensive to estimate and is numerically unstable, so by default the test statistic is calculated assuming independence of variables (<code>cor.type="I"</code>). Note however that the resampling scheme used ensures that the P-values are approximately correct even when the independence assumption is not satisfied. However if it is computationally feasible for your dataset, it is recommended that you use <code>cor.type="shrink"</code> to account for correlation between variables, or <code>cor.type="R"</code> when p is small. The <code>cor.type="R"</code> option uses the unstructured correlation matrix (only possible when N&gt;p), such that the standard classical multivariate test statistics are obtained. Note however that such statistics are typically numerically unstable and have low power when p is not small compared to N. The <code>cor.type="shrink"</code> option applies ridge regularisation (Warton 2008), shrinking the sample correlation matrix towards the identity, which improves its stability when p is not small compared to N. This provides a compromise between <code>"R"</code> and <code>"I"</code>, allowing us to account for 
correlation between variables, while using a numerically stable test statistic that has good properties. The shrinkage parameter by default is estimated by cross-validation using the multivariate normal likelihood function, although it can be specified via <code>shrink.param</code> as any value between 0 and 1 (0=&quot;I&quot; and 1=&quot;R&quot;, values closer towards 0 indicate more shrinkage towards &quot;I&quot;). The validation groups are chosen by random assignment and so you may observe some slight variation in the estimated shrinkage parameter in repeat analyses. 
See <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code> for more details.
</p>
<p>Rather than stopping after testing for multivariate effects, it is often of interest to find out which response variables express significant effects. Univariate statistics are required to answer this question, and these are reported if requested. Setting <code>p.uni="unadjusted"</code> returns the resampling-based univariate ANOVA P-values as well as the multivariate P-values, whereas  <code>p.uni="adjusted"</code> returns adjusted ANOVA P-values (that have been adjusted for 
multiple testing), calculated using a step-down resampling algorithm as in Westfall &amp; Young (1993, Algorithm 2.8). This method provides strong control of family-wise error rates, and makes use of resampling (using the method controlled by <code>resampling</code>) to ensure inferences take into account correlation between variables.
</p>


<h3>Value</h3>

<p>An object of class <code>"anova.manylm"</code>. A list containing at least:  <br />
</p>
<table role = "presentation">
<tr><td><code>p.uni</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>cor.type</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>resample</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>nBoot</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>calc.rss</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>table</code></td>
<td>
<p>the data frame containing the anova table.</p>
</td></tr>
<tr><td><code>shrink.param</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>n.bootsdone</code></td>
<td>
<p>the number of bootstrapping iterations that were done,
i.e. had no error.</p>
</td></tr>
<tr><td><code>n.iter.sing</code></td>
<td>
<p>the number of bootstrap iterations where the resampled
design matrix was singular and could only be used partly.</p>
</td></tr>
<tr><td><code>one</code></td>
<td>

<p>logical. whether the anova table was calculated for one <code>manylm</code> object
or for several <code>manylm</code> objects.
</p>
</td></tr>
</table>
<p>If <code>p.uni="adjusted"</code> or <code>p.uni="unadjusted"</code> the output list also
contains: <br />
</p>
<table role = "presentation">
<tr><td><code>uni.test</code></td>
<td>
<p>a table showing the test statistics of the univariate tests</p>
</td></tr>
<tr><td><code>uni.p</code></td>
<td>
<p>a table showing the p-values of the univariate tests</p>
</td></tr>
</table>
<p>The print method for <code>anova.manylm</code> objects prints the output in a
&lsquo;pretty&rsquo; form.
</p>


<h3>Author(s)</h3>

<p>Yi Wang, Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Anderson, M.J. and J. Robinson (2001).
Permutation tests for linear models.
<em>Australian and New Zealand Journal of Statistics</em> 43, 75-88.
</p>
<p>Davison, A. C. and Hinkley, D. V. (1997)
<em>Bootstrap Methods and their Application.</em>
Cambridge University Press, Cambridge.
</p>
<p>Warton D.I. (2008). Penalized normal likelihood and ridge regularization of 
correlation and covariance matrices. <em>Journal of the American 
Statistical Association</em> 103, 340-349.
</p>
<p>Warton D.I. and Hudson H.M. (2004). A MANOVA statistic is just as powerful as
distance-based statistics, for multivariate abundances. 
<em>Ecology</em> 85(3), 858-874.
</p>
<p>Westfall, P. H. and Young, S. S. (1993) 
<em>Resampling-based multiple testing.</em> John Wiley &amp; Sons, New York.
</p>
<p>Wu, C. F. J. (1986) Jackknife, Bootstrap and Other Resampling Methods in
Regression Analysis.
<em>The Annals of Statistics</em> 14:4, 1261-1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>, <code><a href="#topic+summary.manylm">summary.manylm</a></code>, <code><a href="#topic+plot.manylm">plot.manylm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load the spider dataset:
data(spider)
spiddat &lt;- log(spider$abund+1)
spiddat &lt;- mvabund(spiddat)
spidx &lt;- as.matrix(spider$x)

## Fit several multivariate linear models:
fit &lt;- manylm( spiddat ~ spidx ) # model with all explanatory variables

## Use the default residual resampling to test the significance of this model:
## return summary of the manylm model
anova(fit)

## intercept model
fit0 &lt;- manylm(spiddat ~ 1)
## include soil and leaf variables
fit1 &lt;- update(fit0, . ~ . + spidx[, c(1, 3)])
## include moss variables
fit2 &lt;- update(fit1, . ~ . + spidx[, 4]) 

## Use (residual) resampling to test the significance of these models, 
## accounting for correlation between variables by shrinking 
## the correlation matrix to improve its stability:
anova(fit, fit0, fit1, fit2, cor.type="shrink")

## Use the sum of F statistics to estimate multivariate significance from 
## 4999 resamples, and also reporting univariate statistics with 
## adjusted P-values:
anova(fit, fit0, fit1, fit2, nBoot=4999, test="F", p.uni="adjust")

</code></pre>

<hr>
<h2 id='anova.traitglm'>Testing for a environment-by-trait (fourth corner) interaction by analysis of deviance</h2><span id='topic+anova.traitglm'></span>

<h3>Description</h3>

<p>Returns an analysis of deviance from a fourth corner model, as computed using <code><a href="#topic+traitglm">traitglm</a></code>, typically to test for an environment-by-trait interaction. Slowly! This function works via <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, which uses row-resampling for inference, and it only applies to <code><a href="#topic+traitglm">traitglm</a></code> objects that have been fitted using the (default) <code><a href="#topic+manyglm">manyglm</a></code> function.</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
## S3 method for class 'traitglm'
anova(object, ..., nBoot=99, resamp="pit.trap", test="LR",
                             block = NULL, show.time="all", bootID=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova.traitglm_+3A_object">object</code></td>
<td>

<p>A fitted object of class <code>traitglm</code> and class <code>manyglm</code>. 
</p>
</td></tr>
<tr><td><code id="anova.traitglm_+3A_...">...</code></td>
<td>

<p>Additional <code>traitglm</code> objects, fitted using the <code>formula</code> argument.
</p>
</td></tr>
<tr><td><code id="anova.traitglm_+3A_nboot">nBoot</code></td>
<td>

<p>The number of bootstrap iterations. Default is 99 (NOTE: you should increase this for later runs!)
</p>
</td></tr>
<tr><td><code id="anova.traitglm_+3A_resamp">resamp</code>, <code id="anova.traitglm_+3A_test">test</code>, <code id="anova.traitglm_+3A_bootid">bootID</code></td>
<td>

<p>Arguments as in <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, to control resampling method (<code>resamp</code>), test statistic (<code>test</code>) and whether or not a matrix of bootstrap resamples is manually entered (<code>bootID</code>).
</p>
</td></tr>
<tr><td><code id="anova.traitglm_+3A_block">block</code></td>
<td>

<p>A factor specifying the sampling level to be resampled. Default is resampling sites (which still involves passing a blocking variable to <code>anova.manyglm</code>, to keep all rows of the original abundance data together in resamples).
</p>
</td></tr>
<tr><td><code id="anova.traitglm_+3A_show.time">show.time</code></td>
<td>
<p>Whether to display timing information for the resampling procedure: this is advisable, as resampling fourth corner models many times can take a while. The default value <code>"all"</code> shows all timing information, <code>"total"</code> shows only the overall time taken for the tests, and <code>"none"</code> shows none. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two possible uses of this function, depending whether one <code>traitglm</code> object is specified or multiple objects.
</p>
<p>If one <code>traitglm</code> object is specified, the <code>anova.traitglm</code> function returns a table summarising the statistical significance of the fourth corner terms in a model, that is, the interaction between environment and traits in predicting abundance across taxa and sites. All environment-by-trait interaction terms from the model are simultaneously tested.
</p>
<p>If two or more nested <code>traitglm</code> objects are specified, and each has been fitted using a <code>formula</code> argument to the same set of datasets, then sequential test statistics (and P values) are returned for each additional model fit.
</p>
<p>All <code><a href="#topic+traitglm">traitglm</a></code> models must be fitted using the <code><a href="#topic+manyglm">manyglm</a></code> function, which is its default behaviour, in order to access the <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, which does most of the work. See <code><a href="#topic+anova.manyglm">anova.manyglm</a></code> for details on how resampling is done, and options for arguments controlling the test statistic (via <code>test</code>) and the resampling method (via <code>resamp</code>). Because <code><a href="#topic+traitglm">traitglm</a></code> models are fitted by first vectorising the data into a univariate model, arguments such as <code>p.uni</code> and <code>cor.type</code> are redundant.
</p>
<p><code><a href="#topic+traitglm">traitglm</a></code> fits a single model to abundances across all sites and taxa at the same time, meaning the vector of abundances is typically pretty long, and the design matrix explaining how abundance varies across taxa and sites is typically pretty large. So resampling can take yonks. Hence the default number of resamples has been set at <code>nBoot=99</code>, but please consider increasing this once you have a sense for how long it will take to run (scales roughly linearly with <code>nBoot</code>).
</p>


<h3>Value</h3>

<p>A list of values as returned by <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, of which the most relevant element is <code>table</code> (the analysis of deviance table).
</p>


<h3>Warning</h3>

<p>The comparison between two or more models by <code>anova.traitglm</code> will only be valid if they are fitted to the same dataset. This may be a problem if there are missing values and R's default of <code>na.action = na.omit</code> is used. 
</p>


<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;
</p>


<h3>References</h3>

<p>Warton DI, Shipley B &amp; Hastie T (2015) CATS regression - a model-based approach to studying trait-based community assembly, Methods in Ecology and Evolution 6, 389-398.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.manyglm">anova.manyglm</a></code>,<code><a href="#topic+traitglm">traitglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(antTraits)

# we'll fit a small fourth corner model, to a subset of the antTraits data.
# first select only species present in at least 25% of plots:
abSum = apply(antTraits$abund&gt;0,2,mean)
ab = antTraits$abund[,abSum&gt;0.25]
tr = antTraits$traits[abSum&gt;0.25,]

# now fit the fourth corner model, only as a function of a couple of traits and env variables:
ft=traitglm(ab,antTraits$env[,1:3],data.frame(tr$Weber,tr$Femur))
anova(ft,nBoot=39)
# Note you should refit with more bootstrap samples (e.g. 999), should take &lt;2 minutes to run

# for an example using anova.traitglm for multiple fits, uncomment the following lines:
# ft2=traitglm(antTraits$abund,antTraits$env[,3:4],antTraits$traits[,c(1,3)],
#   formula=~1,composition=TRUE) #no fourth corner terms
# ft3=traitglm(antTraits$abund,antTraits$env[,3:4],antTraits$traits[,c(1,3)],
#   formula=~Shrub.cover:Femur.length+Shrub.cover:Pilosity,composition=TRUE) #shrub interactions
# ft4=traitglm(antTraits$abund,antTraits$env[,3:4],antTraits$traits[,c(1,3)],
#   formula=~Shrub.cover:Femur.length+Shrub.cover:Pilosity+Volume.lying.CWD:Femur.length+
#   Volume.lying.CWD:Pilosity, composition=TRUE) #all interactions only
# anova(ft2,ft3,ft4) # Shrub interactions not significant but CWD interactions are.
</code></pre>

<hr>
<h2 id='antTraits'>Ant data, with species traits</h2><span id='topic+antTraits'></span>

<h3>Description</h3>

<p>Abundances of 41 epigaeic ant species across 30 sites in south-eastern Australia, with species trait and environmental data 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(antTraits)
</code></pre>


<h3>Format</h3>

<p>A list containing three elements:
</p>

<dl>
<dt>abund</dt><dd><p>A data frame with observations at 30 different locations
of abundances of 41 epigaeic ant species.
</p>
</dd>
<dt>env</dt><dd><p>A data frame containing 7 environmental variables from transects at each of the 30 sites:
</p>

<dl>
<dt>Bare.ground</dt><dd><p>Percent cover of bare ground, as estimated from ten 1x1 metre quadrats</p>
</dd>
<dt>Canopy.cover</dt><dd><p>Percent canopy cover, as estimated from two 20x20m transects</p>
</dd>
<dt>Shrub.cover</dt><dd><p>Percent canopy cover, as estimated from two 20x20m transects</p>
</dd>
<dt>Volume.lying.CWD</dt><dd><p>Estimated volume of Coarse Woody Debris in two 20x20m transects, including all debris &gt;5cm diameter.</p>
</dd>
<dt>Feral.mammal.dung</dt><dd><p>Proportion of quadrats including mammal dung, out of ten 1x1m quadrats.</p>
</dd>
</dl>

</dd>
<dt>traits</dt><dd><p>A data frame containing 5 species traits measured for each of the 41 species. Weber's length was log-transformed, Femur length was log-transformed then regressed against log(Weber's length), to remove the effect of size.
</p>

<dl>
<dt>Femur.length</dt><dd><p>Residuals from regression of log(Femur length) against log(Weber's length)</p>
</dd>
<dt>No.spines</dt><dd><p>Number of spines on propodeum and petioles, as an integer value</p>
</dd>
<dt>Pilosity</dt><dd><p>A factor with four levels of pilosity, 0 = No or very few hairs; 1 = a sparse but regular covering of hairs; 2 = a consistent, moderate covering of hair; 3 = very dense hair covering</p>
</dd>
<dt>Polymorphism</dt><dd><p>0 = Monomorphic, 1 = polymorphic, 2 = dimorphic</p>
</dd>
<dt>Webers.length</dt><dd><p>log transformed. Body length, measured as the distance from the anterodorsal margin of the pronotum to the posteroventral margin of the propodeum</p>
</dd>
</dl>

</dd>
</dl>



<h3>References</h3>

<p>Gibb H, Stoklosa J, Warton, DI, Brown, AM, Andrew, NR and Cunningham, SA (2015) Does morphology predict trophic position and habitat use of ant species and assemblages? Oecologia 177, 519-531.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(antTraits)
ft = traitglm(antTraits$abund,antTraits$env,antTraits$traits) #to do a fourth corner analysis
</code></pre>

<hr>
<h2 id='best.r.sq'>
Use R^2 to find the variables that best explain a multivariate response.
</h2><span id='topic+best.r.sq'></span>

<h3>Description</h3>

<p>Finds the subset of explanatory variables in a formula that best explain the variation in a multivariate response, as measured by a chosen definition of R^2. Modifications are included for high dimensional data, such as multivariate abundance data in ecology. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>best.r.sq(formula, data = parent.frame(), subset, var.subset,
  n.xvars= min(3, length(xn)), R2="h", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="best.r.sq_+3A_formula">formula</code></td>
<td>
<p>a mvformula, a multivariate formula.</p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_data">data</code></td>
<td>
<p>optional, the data.frame (or list) from which the variables in
formula should be taken.</p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_var.subset">var.subset</code></td>
<td>
<p>an optional vector specifying the subset of the responses
to be used.</p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_n.xvars">n.xvars</code></td>
<td>
<p>the number of independent variables with the highest average
R^2 that should be found.
</p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_r2">R2</code></td>
<td>

<p>the type of R^2 (correlation coefficient) that should be shown, possible values are: <br />
&quot;h&quot; = Hooper's R^2 = tr(SST^(-1)SSR))/p   <br />
&quot;v&quot; = vector R^2 = det(SSR)/det(SST)<br />
&quot;n&quot; = none
Note that for a univariate response, all of these are equivalent to the ordinary 
product-moment correlation coefficient. </p>
</td></tr>
<tr><td><code id="best.r.sq_+3A_...">...</code></td>
<td>
<p>further arguments that are passed on to lm.</p>
</td></tr> </table>


<h3>Details</h3>

 
<p><code>best.r.sq</code> finds the <code>n.xvars</code> influence variables obtained by a 
forward selection in a multivariate linear model given by <code>formula</code>. <br /> 
Only the response variables given by <code>var.subset</code> are considered. However, 
if <code>var.subset</code> is <code>NULL</code> all response variables are considered.<br /> 
Interactions are excluded from the search mechanism, however the indices that are 
returned correspond to the indices in the model. This function is intended as an 
exploratory tool which can be used for example in plotting, and is not intended 
as a tool for formal model selection. 
choose 'all possible subsets' 
the moment) </p>


<h3>Value</h3>

<p>This function returns a list consisting of:
</p>

<dl>
<dt>xs</dt><dd><p>a vector of indices of independent variables with the greatest
explanatory power, as previously.</p>
</dd>
<dt>r2Step</dt><dd><p>a vector of total R^2 from sequential model fits including each of
the model terms identified in <code>xs</code>.</p>
</dd>
<dt>r2Matrix</dt><dd><p>a matrix containing the total R^2 for each term in the model at
each addition step (steps in columns and model terms in rows).</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

best.r.sq( spiddat~X )
</code></pre>

<hr>
<h2 id='boxplot.mvabund'>Boxplots for multivariate abundance Data</h2><span id='topic+boxplot.mvabund'></span><span id='topic+boxplot.mvformula'></span>

<h3>Description</h3>

<p>Draw Boxplots of <code>mvabund</code> or <code>mvformula</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvabund'
boxplot(x, y, range=1.5, names=NULL, at=NULL, 
                 n.vars=min(12,NCOL(x)), overall.main="Boxplot", 
                 var.subset=NA, transformation="log", ...)

## S3 method for class 'mvformula'
boxplot(
    x, n.vars=12, overall.main="", var.subset=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boxplot.mvabund_+3A_x">x</code></td>
<td>

<p>for the <code>mvabund</code> method <code>x</code> specifies the data from
which the boxplots are to be produced. 
This can be either a numeric vector, or a single list containing such vectors. 
Additional unnamed arguments specify further data as separate vectors 
(each corresponding to a component boxplot). 
NAs are allowed in the data. <br />
For the default method, unnamed arguments are additional data vectors 
(unless <code>x</code> is a list when they are ignored), and named arguments are
arguments and graphical parameters to be passed to in addition to the ones given
by argument pars (and override those in pars). <br />
For the <code>mvformula</code> method, a formula, such as <code>y ~ grp</code>, where
y is a numeric mvabund object of data values to be split into groups according
to the grouping variable grp (a factor). 
</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_y">y</code></td>
<td>
<p>for the <code>mvabund</code> method <code>y</code> can be an additional <code>mvabund</code> object, if <code>x</code> isn't a list.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_range">range</code></td>
<td>
<p>this determines how far the plot whiskers extend out from the box. If range is positive, the whiskers extend to the most extreme data point which is no more than range times the interquartile range from the box. A value of zero causes the whiskers to extend to the data extremes.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_names">names</code></td>
<td>
<p>only available for the <code>mvabund</code> method: group labels which will be printed under each boxplot.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_at">at</code></td>
<td>
<p>only available for the <code>mvabund</code> method: numeric vector giving the locations where the boxplots should be drawn; defaults to <code>1:n</code> where <code>n</code> is the number of boxes.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_n.vars">n.vars</code></td>
<td>
<p>the number of variables to include in the plot.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_overall.main">overall.main</code></td>
<td>
<p>a character to display as title for every window.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_var.subset">var.subset</code></td>
<td>
<p>a numeric vector of indices indicating which variables of the mvabund.object should be included on the plot.</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_transformation">transformation</code></td>
<td>
<p> an optional transformation, (ONLY) for the <code>mvabund</code> method. Note, that for the <code>mvabund</code> method <code>transformation</code> must be used 
instead of <code>log</code>.<br />
Available values are:<br />
&quot;no&quot; = untransformed, &quot;sqrt&quot;=square root transformed,
&quot;log&quot; (default)=log(Y/min+1) transformed, &quot;sqrt4&quot; =4th root transformed.
</p>
</td></tr>
<tr><td><code id="boxplot.mvabund_+3A_...">...</code></td>
<td>

<p>for the <code>mvformula</code> method, named arguments to be passed to the <code>plot.mvformula</code> method. Some arguments that are available for the <code>mvabund</code> method, are not available in <code>plot.mvformula</code> and can therefore not available in the <code>mvformula</code> method.
</p>
<p>For the <code>mvabund</code> method, unamed arguments are additional data of vectors or matrices or <code>mvabund</code> objects, (unless <code>x</code> is a list when they are ignored),and named arguments are arguments and graphical parameters to be passed in addition to the ones given by argument <code>pars</code> (and override those in <code>pars</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The function <code>boxplot.mvabund</code> allows simultaneous construction of many
variables on a single figure. Thus a good comparative overview about the
distribution of abundances for several species can be obtained. <br />
There are several ways in which this function can be used. 
If one <code>mvabund</code> object, either named <code>x</code> or <code>y</code> 
or not names, is passed, it will be drawn on one plot and abundances can be
compared over several variables.<br />
If two <code>mvabund</code> objects, named <code>x</code> and <code>y</code> are 
passed for plotting, they will be shown on
one plot, showing for each species the abundances of both objects directly
one below the other. <br />
If more than two <code>mvabund</code> objects are passed, each of them will be
plotted separately. <br />
Additionally, it is possible to specify <code>x</code> as a list of <code>mvabund</code> objects.
Each of them will be plotted separately and any further <code>mvabund</code> data will 
be ignored, regardless if it is specified as <code>y</code> or unnamed.
</p>
<p>The function <code>boxplot.mvformula</code> can be used to draw boxplots of a <code>mvabund</code>
object in dependence of explanatory variables. The explanatory variables can be both 
numerical values as well as factor variables. If the formula contains both of them,
there will be separate plots for the terms with numerical values and the terms
with factor variables, displayed on separate windows.
</p>
<p>The arguments <code>plot</code>, <code>varwidth</code> and <code>add</code>, which are availabe in the default method of <code>boxplot</code>, are not available for the <code>mvabund</code> and <code>mvformula</code> methods. The argument <code>horizontal</code> is not available for the <code>mvabund</code> method. <br />
A number of other arguments like <code>at</code> and <code>names</code> are only available for the 
<code>mvabund</code> method.
</p>


<h3>Value</h3>

<p>In contrast to the default method (boxplot.default) nothing will be returned.
These functions are only used for drawing the plots.
</p>


<h3>Warning</h3>

<p>The argument <code>log</code>, that is available in most plotting functions can not be used 
for plotting <code>mvabund</code> or <code>mvformula</code> objects. Instead use <code>transformation</code> for the <code>mvabund</code> method and for the <code>mvformula</code> method
include transformations in the formula.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Yi Wang, Stephen Wright and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton, D. I. ( )
<em>Raw data graphing: an informative but under-utilised tool
for the analysis of multivariate abundances</em>, , .
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mvabund">plot.mvabund</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

#### Basic Use ####
data(spider)
spiddat &lt;- spider$abund
X &lt;- spider$x

## Create the mvabund object:
spiddat &lt;- mvabund(spiddat)

## Draw a boxplot for a mvabund object:
boxplot(spiddat)

## the same plot could be done by
plot(spiddat,type="bx")


#### Advanced Use ####
data(solberg)
solbdat &lt;- mvabund(solberg$abund)
treatment&lt;- solberg$x

# create pch type and colour vectors
treat.pch &lt;- treat.col &lt;- unclass(treatment)

# Boxplot for data
plot.mvabund(x=solbdat,y=treatment,type="bx",
             main="BoxPlot of The 12 Highest Abundant Species", 
             xlab="Abundance [sqrt scale]",ylab="",
             transformation="sqrt",t.lab="o",shift=TRUE)

</code></pre>

<hr>
<h2 id='coefplot.manyglm'>Plots the coefficients of the covariates of a manyglm object with confidence intervals.</h2><span id='topic+coefplot.manyglm'></span><span id='topic+coefplot'></span>

<h3>Description</h3>

<p>A way to plot the coefficients of the covariates of a manyglm object. Modifies code from Niku, Hui and Taskinen's coefplot.gllvm.
If you have a large number of terms in your model, consider using which.Xcoef to choose just a few to plot. Default behaviour will try to plot everything, which would be a pretty big figure!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyglm'
coefplot(object, y.label = TRUE, which.Xcoef = NULL,
  which.Ys = NULL, incl.intercept = FALSE, cex.ylab = 0.5, mfrow = NULL,
  mar = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coefplot.manyglm_+3A_object">object</code></td>
<td>
<p>A manyglm object</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_y.label">y.label</code></td>
<td>
<p>Whether all the Y variables should be labelled</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_which.xcoef">which.Xcoef</code></td>
<td>
<p>Which X covariates should be included in the plot. Defaults to all except intercept.</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_which.ys">which.Ys</code></td>
<td>
<p>Which Y variables should be included in the plot. Defaults to all.</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_incl.intercept">incl.intercept</code></td>
<td>
<p>Whether the intercept coefficient should be included.</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_cex.ylab">cex.ylab</code></td>
<td>
<p>A plotting parameter. The default is 0.5.</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_mfrow">mfrow</code></td>
<td>
<p>Plotting parameter</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_mar">mar</code></td>
<td>
<p>Plotting parameter</p>
</td></tr>
<tr><td><code id="coefplot.manyglm_+3A_...">...</code></td>
<td>
<p>Other plotting parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="#topic+summary.manyglm">summary.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load the hunting spider data set
data(spider)
spiddat &lt;- mvabund(spider$abund)
#To fit a log-linear model assuming counts are negative binomial:
glm.spid &lt;- manyglm(spiddat~., data=spider$x, family="negative.binomial")
# A coefplot of soil.dry and bare.sand parameters:
coefplot.manyglm(glm.spid, which.Xcoef=2:3) # note which.Xcoef=1 is the intercept
</code></pre>

<hr>
<h2 id='cv.glm1path'>
Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the best model by corss-validation.
</h2><span id='topic+cv.glm1path'></span>

<h3>Description</h3>

<p>Fits a sequence (path) of generalised linear models with LASSO penalties, using an iteratively reweighted local linearisation approach. The whole path of models is returned, as well as the one that minimises predictive log-likelihood on random test observations. Can handle negative binomial family, even with overdispersion parameter unknown, as well as other GLM families. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glm1path(object, block = NULL, best="min", plot=TRUE, prop.test=0.2, n.split = 10,
    seed=NULL, show.progress=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.glm1path_+3A_object">object</code></td>
<td>

<p>Output from a <code><a href="#topic+glm1path">glm1path</a></code> fit.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_block">block</code></td>
<td>

<p>A factor specifying a blocking variable, where training/test splits randomly assign blocks of observations to different groups rather than breaking up observations within blocks. Default (<code>NULL</code>) will randomly split rows into test and training groups.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_best">best</code></td>
<td>

<p>How should the best-fitting model be determined? <code>"1se"</code> uses the one standard error rule, <code>"min"</code> (or any other value) will return the model with best predictive performance. WARNING: David needs to check se calculatios...
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_plot">plot</code></td>
<td>

<p>Logical value indicating whether to plot the predictive log-likelihood as a function of model complexity.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_prop.test">prop.test</code></td>
<td>

<p>The proportion of observations (or blocks) to assign as test observations. Default value of 0.2 gives a 80:20 training:test split.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_n.split">n.split</code></td>
<td>

<p>The number of random training/test splits to use. Default is 10 but the more the merrier (and the slower).
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_seed">seed</code></td>
<td>

<p>A vector of seeds to use for the random test/training splits. This is useful if you want to be able to exactly replicate analyses, without Monte Carlo variation in the splits. Default will not used fixed seeds.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_show.progress">show.progress</code></td>
<td>
<p>Logical argument, if TRUE, console will report when a run for a seed has been completed. This option has been included because this function can take yonks to run on large datasets.
</p>
</td></tr>
<tr><td><code id="cv.glm1path_+3A_...">...</code></td>
<td>
<p>Further arguments passed through to <code><a href="#topic+glm1path">glm1path</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a series of LASSO-penalised generalised linear models, with different values for the LASSO penalty, as for <code><a href="#topic+glm1path">glm1path</a></code>. The main difference is that the best fitting model is selected by cross-validation, using <code>n.test</code> different random training/test splits to estimate predictive performance on new (test) data. Mean predictive log-likelihood (per test observation) is used as the criterion for choosing the best model, which has connections with the Kullback-Leibler distance. The <code>best</code> argument controls whether to select the model that maximises predictive log-likelihood, or the smallest model within 1se of the maximum (the '1 standard error rule').
</p>
<p>All other details of this function are as for <code><a href="#topic+glm1path">glm1path</a></code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>Vector of model coefficients for the best-fitting model (as judged by predictive log-likelihood)</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The value of the LASOS penalty parameter, lambda, for the best-fitting model (as judged by predictive log-likelihood)</p>
</td></tr>
<tr><td><code>glm1.best</code></td>
<td>
<p>The glm1 fit for the best-fitting model (as judged by predictive log-likelihood). For what this contains see <code><a href="#topic+glm1">glm1</a></code>.</p>
</td></tr>
<tr><td><code>all.coefficients</code></td>
<td>
<p>A matrix where each column represents the model coefficients for a fit along the path specified by <code>lambdas</code>.</p>
</td></tr>
<tr><td><code>lambdas</code></td>
<td>
<p>A vector specifying the path of values for the LASSO penalty, arranged from largest (strongest penalty, smallest fitted model) to smallest (giving the largest fitted model).</p>
</td></tr>
<tr><td><code>logL</code></td>
<td>
<p>A vector of log-likelihood values for each model along the path.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>A vector giving the number of non-zero parameter estimates (a crude measure of degrees of freedom) for each model along the path.</p>
</td></tr>
<tr><td><code>bics</code></td>
<td>
<p>A vector of BIC values for each model along the path. Calculated using a penalty on model complexity as specified by input argument <code>k</code>.</p>
</td></tr>
<tr><td><code>counter</code></td>
<td>
<p>A vector counting how many iterations until convergence, for each model along the path.</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>A vector of logical values specifying whether or not Karush-Kuhn-Tucker conditions are satisfied at the solution.</p>
</td></tr>
<tr><td><code>phis</code></td>
<td>
<p>For negative binomial regression - a vector of overdispersion parameters, for each model along the path.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The vector of values for the response variable specified as an input argument.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The design matrix of p explanatory variables specified as an input argument.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>The vector to be multiplied by each lambda to make the penalty for each fitted model.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The family argument specified as input.</p>
</td></tr>
<tr><td><code>ll.cv</code></td>
<td>
<p>The mean predictive log-likelihood, averaged over all observations and then over all training/test splits.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Estimated standard error of the mean predictive log-likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;
</p>


<h3>References</h3>

<p>Osborne, M.R., Presnell, B. and Turlach, B.A. (2000) On the LASSO and its dual. Journal of Computational and Graphical Statistics, 9, 319-337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm1path">glm1path</a></code>, \code<a href="#topic+glm1">glm1</a>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+family">family</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
Alopacce &lt;- spider$abund[,1]
X &lt;- model.matrix(~.,data=spider$x) # to get design matrix with intercept term

# fit a LASSO-penalised negative binomial regression:
ft = glm1path(Alopacce,X,lam.min=0.1)
coef(ft)

# now estimate the best-fitting model by cross-validation:
cvft = cv.glm1path(ft)
coef(cvft)

</code></pre>

<hr>
<h2 id='deviance.manylm'>Model Deviance</h2><span id='topic+deviance.manylm'></span>

<h3>Description</h3>

<p>Returns the deviance of a fitted multivariate model object
for abundance data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
deviance(object, na.action="na.omit", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deviance.manylm_+3A_object">object</code></td>
<td>
<p>the manylm object.</p>
</td></tr>
<tr><td><code id="deviance.manylm_+3A_na.action">na.action</code></td>
<td>

<p>how to deal with <code>NA</code> values. Can be one of 
&quot;na.omit&quot;, &quot;na.exclude&quot;, &quot;na.fail&quot;, <code>NULL</code>
</p>
</td></tr>
<tr><td><code id="deviance.manylm_+3A_...">...</code></td>
<td>
<p>additional optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the deviance extracted from the object <code>object</code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)

## Calculate the deviance:
deviance(manylm(spiddat~., data=spider$x))
</code></pre>

<hr>
<h2 id='extend.x.formula'>Extend a Formula to all of it's Terms</h2><span id='topic+extend.x.formula'></span>

<h3>Description</h3>

<p>extend a compact formula to all of it's terms as they are interpreted</p>


<h3>Usage</h3>

<pre><code class='language-R'>extend.x.formula(formula, extend.term=TRUE, return.interaction=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extend.x.formula_+3A_formula">formula</code></td>
<td>
<p>a model formula.</p>
</td></tr>
<tr><td><code id="extend.x.formula_+3A_extend.term">extend.term</code></td>
<td>
<p>logical. If <code>TRUE</code> terms that refer to multiple variables
are split into it's multiple terms.</p>
</td></tr>
<tr><td><code id="extend.x.formula_+3A_return.interaction">return.interaction</code></td>
<td>
<p>logical. Whether a list containing the new formula and 
a vector containing logical values with information about interactions should be returned
or only the new formula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>return.interaction</code> is <code>TRUE</code> a list containing the components:
</p>
<table role = "presentation">
<tr><td><code>formula</code></td>
<td>
<p>the new formula.</p>
</td></tr>
<tr><td><code>is.interaction</code></td>
<td>
<p>logical, vector giving information 
whether the corresponding formula term is an interaction or not.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvformula">mvformula</a></code>, <code><a href="#topic+formulaUnimva">formulaUnimva</a></code>, <code><a href="#topic+plot.mvformula">plot.mvformula</a></code>,
<code><a href="#topic+best.r.sq">best.r.sq</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- spider$x

foo &lt;- mvformula(spiddat~ X[,1]*X[,2]+log(X[,3]))
extend.x.formula(foo)
</code></pre>

<hr>
<h2 id='formulaUnimva'>Create a List of Univariate Formulas</h2><span id='topic+formulaUnimva'></span>

<h3>Description</h3>

<p>Create a list of m univariate formulas given a formula with multivariate
response of dimension m.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formulaUnimva(formula, var.subset, split.x=FALSE, intercept=0,
  allow.noresp=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="formulaUnimva_+3A_formula">formula</code></td>
<td>
<p>a formula or a mvformula, the elements are not allowed
to be data.frames.</p>
</td></tr>
<tr><td><code id="formulaUnimva_+3A_var.subset">var.subset</code></td>
<td>
<p>optional vector of the variable numbers to use.</p>
</td></tr>
<tr><td><code id="formulaUnimva_+3A_split.x">split.x</code></td>
<td>

<p>logical, whether explanatory terms that are matrices should be split and
each added as a single term. this is useful for plotting formulas.
</p>
</td></tr>
<tr><td><code id="formulaUnimva_+3A_intercept">intercept</code></td>
<td>

<p>numeric, either <code>1</code> if an Intercept should be included in the formula 
or <code>0</code> if there shouldn't be an Intercept in the formula.
</p>
</td></tr>
<tr><td><code id="formulaUnimva_+3A_allow.noresp">allow.noresp</code></td>
<td>

<p>logical, whether an empty response is allowed (a list with one element
would be returned) or not (would result in an error.)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing m formulas with the univariate responses chosen by var.subset.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvformula">mvformula</a></code>, <code><a href="#topic+mvabund">mvabund</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- spider$x

formulaUnimva(spiddat~X)
</code></pre>

<hr>
<h2 id='glm1'>
Fits a Generalised Linear Models with a LASSO (or L1) penalty, given a value of the penalty parameter.
</h2><span id='topic+glm1'></span>

<h3>Description</h3>

<p>Fits a generalised linear model with a LASSO penalty, using an iteratively reweighted local linearisation approach, given a value of the penalty parameter (lamb). Can handle negative binomial family, even with overdispersion parameter unknown, as well as other GLM families. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm1(y, X, lambda, family = "negative.binomial", weights = rep(1, length(y)),
     b.init = NA, phi.init = NA, phi.method = "ML", tol = c(1e-08, .Machine$double.eps),
     n.iter = 100, phi.iter = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm1_+3A_y">y</code></td>
<td>

<p>A vector of values for the response variable.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_x">X</code></td>
<td>

<p>A design matrix of p explanatory variables.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_family">family</code></td>
<td>

<p>The family of the response variable, see <code><a href="stats.html#topic+family">family</a></code>. Negative binomial with unknown overdispersion can be specified as &quot;negative.binomial&quot;, and is the default.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_lambda">lambda</code></td>
<td>

<p>The penalty parameter applied to slope parameters. Different penalties can be specified for different parameters by specifying lamb as a vector, whose length is the number of columns of X. If scalar, this penalty is applied uniformly across all parameters except for the first (assuming that it is an intercept) 
</p>
</td></tr>
<tr><td><code id="glm1_+3A_weights">weights</code></td>
<td>

<p>Observation weights. These might be useful if you want to fit a Poisson point process model...
</p>
</td></tr>
<tr><td><code id="glm1_+3A_b.init">b.init</code></td>
<td>

<p>Initial slope estimate. Must be a vector of the same length as the number of columns in X.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_phi.init">phi.init</code></td>
<td>

<p>Initial estimate of the negative binomial overdispersion parameter. Must be scalar.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_phi.method">phi.method</code></td>
<td>

<p>Method of estimating overdispersion.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_tol">tol</code></td>
<td>

<p>A vector of two values, specifying convergence tolerance, and the value to truncate fitted values at.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_n.iter">n.iter</code></td>
<td>

<p>Number of iterations to attempt before bailing.
</p>
</td></tr>
<tr><td><code id="glm1_+3A_phi.iter">phi.iter</code></td>
<td>

<p>Number of iterations estimating the negative binomial overdispersion parameter (if applicable) before returning to slope estimation. Default is one step, i.e. iterating between one-step estimates of beta and phi.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a generalised linear model with a LASSO penalty, sometimes referred to as an L1 penalty or L1 norm, hence the name glm1. The model is fit using a local linearisation approach as in Osborne et al (2000), nested inside iteratively reweighted (penalised) least squares. Look it's not the fastest thing going around, try <code>glmnet</code> if you want something faster (and possibly rougher as an approximation). The main advantage of the <code>glm1</code> function is that it has been written to accept any glm family argument (although not yet tested beyond discrete data!), and also the negative binomial distribution, which is especially useful for modelling overdispersed counts.
</p>
<p>For negative binomial with unknown overdispersion use <code>"negative.binomial"</code>, or if overdispersion is to be specified, use <code>negative.binomial(theta)</code> as in the <code>MASS</code> package. Note that the output refers to phi=1/theta, i.e. the overdispersion is parameterised such that the variance is mu+phi*mu^2. Hence values of phi close to zero suggest little overdispersion, values over one suggest a lot.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>Vector of parameter estimates</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>Vector of predicted values (on scale of the original response)</p>
</td></tr>
<tr><td><code>logLs</code></td>
<td>
<p>Vector of log-likelihoods at each iteration of the model.  The last entry is the log-likelihood for the final fit.</p>
</td></tr>
<tr><td><code>phis</code></td>
<td>
<p>Estimated overdispersion parameter at each iteration, for a negative binomial fit.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>Final estimate of the overdispersion parameter, for a negative binomial fit.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>Vector of score equation values for each parameter in the model.</p>
</td></tr>
<tr><td><code>counter</code></td>
<td>
<p>Number of iterations until convergence. Set to Inf for a model that didn't converge.</p>
</td></tr>
<tr><td><code>check</code></td>
<td>
<p>Logical for whether the Kuhn-KArush-Tucker conditions are saitsfied.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;, Ian W. Renner and Luke Wilson.
</p>


<h3>References</h3>

<p>Osborne, M.R., Presnell, B. and Turlach, B.A. (2000) On the LASSO and its dual. Journal of Computational and Graphical Statistics, 9, 319-337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm1path">glm1path</a></code>, <code><a href="#topic+glm1">glm1</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+family">family</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
Alopacce &lt;- spider$abund[,1]
X &lt;- model.matrix(~.,data=spider$x) # to get design matrix with intercept term
#fit a LASSO-penalised negative binomial GLM, with penalty parameter 10:
ft = glm1(Alopacce,X,lambda=10)

plot(ft$logLs) # a plot of the log-likelihood, each iteration to convergence
coef(ft) # coefficients in the final model

</code></pre>

<hr>
<h2 id='glm1path'>
Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the model that minimises BIC.
</h2><span id='topic+glm1path'></span>

<h3>Description</h3>

<p>Fits a sequence (path) of generalised linear models with LASSO penalties, using an iteratively reweighted local linearisation approach. The whole path of models is returned, as well as the one that minimises BIC. Can handle negative binomial family, even with overdispersion parameter unknown, as well as other GLM families. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm1path(y, X, family = "negative.binomial", lambdas = NULL,
  penalty = c(0, rep(1, dim(X)[2]-1)), df.max = sum(y &gt; 0), n.lambda = 25, lam.max = NULL,
  lam.min = NULL, k = log(length(y)), b.init = NA, phi.init = NA, phi.iter = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm1path_+3A_y">y</code></td>
<td>

<p>A vector of values for the response variable.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_x">X</code></td>
<td>

<p>A design matrix of p explanatory variables.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_family">family</code></td>
<td>

<p>The family of the response variable, see <code><a href="stats.html#topic+family">family</a></code>. Negative binomial with unknown overdispersion can be specified as &quot;negative.binomial&quot;, and is the default.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_lambdas">lambdas</code></td>
<td>

<p>An optional vector of LASSO penalty parameters, specifying the path along which models will be fitted. This penalty is applied to parameters as specified in <code>penalty</code>. By default, a geometric sequence of values will be constructed with <code>n.lambda</code> values, starting from the intercept model and reducing lambda to 1.e-6 of its original value. Any vector that is provided will be sorted in decreasing order, so that the smallest model (biggest penalty) is fitted first.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_penalty">penalty</code></td>
<td>

<p>A vector to be multiplied by each lambda to make the penalty for each fitted model. The main purpose here is to allow penalties to be applied to some parameters but not others, but it could also be used to change the size of the penalty for some terms as compared to others (e.g. to fit an adaptive LASSO). Must have the same length as the dimension of the model, <code>dim(X)[2]</code>.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_df.max">df.max</code></td>
<td>

<p>The maximum number of terms that is permitted in the fitted model. Once this threshhold is reached no further fits are attempted. The default break-point is the number of non-zero values in the response vector.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_n.lambda">n.lambda</code></td>
<td>

<p>The number of models to fit along the path (if not previously specified via <code>lambdas</code>).
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_lam.max">lam.max</code></td>
<td>

<p>The maximum value of the LASSO penalty to use along the path of fitted values (if not previously specified via <code>lambdas</code>).
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_lam.min">lam.min</code></td>
<td>

<p>The minimum value of the LASSO penalty to use along the path of fitted values (if not previously specified via <code>lambdas</code>).
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_k">k</code></td>
<td>

<p>In BIC calculation, this is the value of the penalty per parameter in the fitted model. The default value, <code>log(length(y))</code>, gives BIC (known to be consistent, for adaptive LASSO), changing it to <code>2</code> would give AIC (which is not so great in terms of properties).
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_b.init">b.init</code></td>
<td>

<p>An initial value for beta for the first model along the fitted path. Default is to fit an intercept model.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_phi.init">phi.init</code></td>
<td>

<p>For negative binomial models: An initial value for the overdispersion parameter for the first model along the fitted path. Default is zero (Poisson fit).
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_phi.iter">phi.iter</code></td>
<td>

<p>Number of iterations estimating the negative binomial overdispersion parameter (if applicable) before returning to slope estimation. Default is one step, i.e. iterating between one-step estimates of beta and phi.
</p>
</td></tr>
<tr><td><code id="glm1path_+3A_...">...</code></td>
<td>

<p>Arguments passed to <code><a href="#topic+glm1">glm1</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a series of LASSO-penalised generalised linear models, with different values for the LASSO penalty. Largely inspired by the glmnet package. This results in  a path of fitted models, from small ones (with big LASSO penalties) to larger ones (with smaller penalties). Each individual model is fitted using the  <code><a href="#topic+glm1">glm1</a></code> function, which uses a local linearisation approach as in Osborne et al (2000), nested inside iteratively reweighted (penalised) least squares, and using results from the previous fit as initial estimates. Look it's not the fastest thing going around, try glmnet if you want something faster (and possibly rougher as an approximation). The main advantage of the <code>glm1path</code> function is that it has been written to accept any glm family argument (although not yet tested beyond discrete data!), and also the negative binomial distribution, which is especially useful for modelling overdispersed counts.
</p>
<p>For negative binomial with unknown overdispersion use <code>"negative.binomial"</code>, or if overdispersion is to be specified, use <code>negative.binomial(theta)</code> as in the <code>MASS</code> package. Note that the output refers to phi=1/theta, i.e. the overdispersion is parameterised in output such that the variance is mu+phi*mu^2. Hence values of phi close to zero suggest little overdispersion, values over one suggest a lot.
</p>
<p>You can use the <code>residuals</code> and <code>plot</code> functions on <code>glm1path</code> objects in order to compute Dunn-Smyth residuals and a plots of these residuals against linear predictors, as for <code><a href="#topic+manyglm">manyglm</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>glm1path</code> with the following components:
</p>

<dl>
<dt>coefficients</dt><dd><p>Vector of model coefficients for the best-fitting model (as judged by BIC)</p>
</dd>
<dt>lambda</dt><dd><p>The value of the LASOS penalty parameter, lambda, for the best-fitting model (as judged by BIC)</p>
</dd>
<dt>glm1.best</dt><dd><p>The glm1 fit for the best-fitting model (as judged by BIC). For what this contains see <code><a href="#topic+glm1">glm1</a></code>.</p>
</dd>
<dt>all.coefficients</dt><dd><p>A matrix where each column represents the model coefficients for a fit along the path specified by <code>lambdas</code>.</p>
</dd>
<dt>lambdas</dt><dd><p>A vector specifying the path of values for the LASSO penalty, arranged from largest (strongest penalty, smallest fitted model) to smallest (giving the largest fitted model).</p>
</dd>
<dt>logL</dt><dd><p>A vector of log-likelihood values for each model along the path.</p>
</dd>
<dt>df</dt><dd><p>A vector giving the number of non-zero parameter estimates (a crude measure of degrees of freedom) for each model along the path.</p>
</dd>
<dt>bics</dt><dd><p>A vector of BIC values for each model along the path. Calculated using a penalty on model complexity as specified by input argument <code>k</code>.</p>
</dd>
<dt>counter</dt><dd><p>A vector counting how many iterations until convergence, for each model along the path.</p>
</dd>
<dt>check</dt><dd><p>A vector of logical values specifying whether or not Karush-Kuhn-Tucker conditions are satisfied at the solution.</p>
</dd>
<dt>phis</dt><dd><p>For negative binomial regression - a vector of overdispersion parameters, for each model along the path.</p>
</dd>
<dt>y</dt><dd><p>The vector of values for the response variable specified as an input argument.</p>
</dd>
<dt>X</dt><dd><p>The design matrix of p explanatory variables specified as an input argument.</p>
</dd>
<dt>penalty</dt><dd><p>The vector to be multiplied by each lambda to make the penalty for each fitted model.</p>
</dd>
<dt>family</dt><dd><p>The family argument specified as input.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;
</p>


<h3>References</h3>

<p>Osborne, M.R., Presnell, B. and Turlach, B.A. (2000) On the LASSO and its dual. Journal of Computational and Graphical Statistics, 9, 319-337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm1">glm1</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+family">family</a></code>, <code><a href="#topic+residuals.manyglm">residuals.manyglm</a></code>, <code><a href="#topic+plot.manyany">plot.manyany</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
Alopacce &lt;- spider$abund[,1]
X &lt;- model.matrix(~.,data=spider$x) # to get design matrix with intercept term

# fit a LASSO-penalised negative binomial regression:
ft = glm1path(Alopacce,X)
# have a look at the BICS for all models:
plot(ft$bics~ft$lambdas, log="x")

#the action seems to be at lambda above 0.1, re-do with a minimum lambda at 0.1 and more lambdas:
ft2 = glm1path(Alopacce,X,lam.min=0.1,n.lambda=100)
plot(ft2$bics~ft2$lambdas, log="x")

# return the slope estimates for the best-fitting model:
coef(ft2)

# look at a residual plot:
plot(ft2)

</code></pre>

<hr>
<h2 id='logLik.manylm'>Calculate the Log Likelihood</h2><span id='topic+logLik.manylm'></span>

<h3>Description</h3>

<p>Calculate the log likelihood of a multivariate linear model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
logLik(object, REML = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.manylm_+3A_object">object</code></td>
<td>
<p>a <code>manylm</code> object from which a log-likelihood value
should be extracted.</p>
</td></tr>
<tr><td><code id="logLik.manylm_+3A_...">...</code></td>
<td>
<p>some methods for this function require additional arguments.</p>
</td></tr>
<tr><td><code id="logLik.manylm_+3A_reml">REML</code></td>
<td>
<p>an optional logical value.  If <code>TRUE</code> the restricted
log-likelihood is returned, else, if <code>FALSE</code>, the
log-likelihood is returned.  Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is assumed that the scale has been estimated
(by maximum likelihood or REML), and all the constants in the
log-likelihood are included.
</p>


<h3>Value</h3>

<p>Returns an object, say <code>r</code>, of class <code>logLik</code> which is a
number with attributes, <code>attr(r, "df")</code> (<b>d</b>egrees of
<b>f</b>reedom) giving the number of (estimated) parameters in the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
lm.spider &lt;- manylm(spiddat~., data=spider$x)
logLik(lm.spider)
</code></pre>

<hr>
<h2 id='manyany'>Fitting Many Univariate Models to Multivariate Abundance Data</h2><span id='topic+manyany'></span><span id='topic+print.manyany'></span>

<h3>Description</h3>

<p><code>manyany</code> is used to fit many univariate models (GLMs, GAMs, otherwise) to high-dimensional data, such as multivariate abundance data in ecology. This is the base model-fitting function - see <code>plot.manyany</code> for assumption checking, and <code>anova.manyany</code> for significance testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manyany(formula, fn, family="negative.binomial", data, composition = FALSE, 
block = NULL, get.what="details", var.power=NA, na.action = "na.exclude", ...)
## S3 method for class 'manyany'
print(x, digits = max(3L, getOption("digits") - 3L), ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="manyany_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted.  The details of model specification are given
under Details.</p>
</td></tr>
<tr><td><code id="manyany_+3A_fn">fn</code></td>
<td>
<p>a character string giving the name of the function for the univariate
model to be applied. e.g. &quot;glm&quot;.</p>
</td></tr>
<tr><td><code id="manyany_+3A_family">family</code></td>
<td>
<p>a description of the error distribution function to be used 
in the model, either as a character string, a <code><a href="stats.html#topic+family">family</a></code> object, or
a list of such objects, one for each response variable in the dataset. Such a
list enables the fitting of models with different distributions for different
responses. See Details for the families currently supported.</p>
</td></tr>
<tr><td><code id="manyany_+3A_data">data</code></td>
<td>
<p>an optional data frame containing predictor variables (a matrix is also acceptable).</p>
</td></tr>
<tr><td><code id="manyany_+3A_composition">composition</code></td>
<td>
<p>logical. FALSE (default) fits a separate model to each species.
TRUE fits a single model to all variables, including site as a row effect, such
that all other terms model relative abundance (compositional effects).  </p>
</td></tr>
<tr><td><code id="manyany_+3A_block">block</code></td>
<td>
<p>a factor specifying the sampling level to be resampled. Default is
resampling rows (if composition=TRUE in the manyany command, this means resampling
rows of data as originally sent to manyany).</p>
</td></tr>
<tr><td><code id="manyany_+3A_get.what">get.what</code></td>
<td>
<p>what to return from each model fit: &quot;details&quot; (default) includes
predicted values and residuals in output, &quot;models&quot; also returns the fitted objects
for each model, &quot;none&quot; returns just the log-likelihood (mostly for internal use).</p>
</td></tr>
<tr><td><code id="manyany_+3A_var.power">var.power</code></td>
<td>
<p>the power parameter, if using the tweedie distribution.</p>
</td></tr>
<tr><td><code id="manyany_+3A_na.action">na.action</code></td>
<td>
<p>Default set to <code>exclude</code> (for details see
<code><a href="stats.html#topic+na.exclude">na.exclude</a></code>) to avoid errors when NA's in predictors.</p>
</td></tr>
<tr><td><code id="manyany_+3A_...">...</code></td>
<td>
<p>further arguments passed to the fitting function.</p>
</td></tr>
<tr><td><code id="manyany_+3A_x">x</code></td>
<td>
<p>an object of class &quot;manyany&quot;, usually, a result of a call to
<code><a href="#topic+manyany">manyany</a></code>.</p>
</td></tr>
<tr><td><code id="manyany_+3A_digits">digits</code></td>
<td>
<p>how many digits to include in the printed anova table.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>manyany</code> can be used to fit the model type specified in <code>fn</code> to many variables
simultaneously, a generalisation of <code><a href="#topic+manyglm">manyglm</a></code> to handle other model types.
It should be able to handle any fixed effects modelling function that has 
<code>predict</code> and <code>logLik</code> functions, and that accepts a <code>family</code> argument, 
provided that the family is on our list (currently 'gaussian', 'poisson', 'binomial', 
'negative.binomial' and 'tweedie', although models for ordinal data are also accepted 
if using the <code>clm</code> function from the <code>ordinal</code> package). Models for <code>manyany</code>
are specified symbolically, see for example the details section of <code><a href="stats.html#topic+lm">lm</a></code>
and <code><a href="stats.html#topic+formula">formula</a></code>.
</p>
<p>Unlike <code>manyglm</code>, this function accepts <code>family</code> functions as arguments
instead of just character strings, giving greater flexibility. For example, you could
use <code>family=binomial(link="probit")</code> to fit a model using the probit link, rather 
than being restricted to the default logit link or <code>cloglog</code> links available in <code>manyglm</code>.
</p>
<p>A <code>data</code> argument is required, and it must be a dataframe.
</p>
<p>Setting <code>composition=TRUE</code> enables compositional analyses, where predictors are
used to model relative abundance rather than mean abundance. This is achieved by
vectorising the response matrix and fitting a single model across all variables, with
a row effect to account for differences in relative abundance across rows.
The default <code>composition=FALSE</code> just fits a separate model for each variable.
</p>


<h3>Value</h3>

<p><code>manyany</code> returns an object inheriting from <code>"manyany"</code>.
</p>
<p>The function <code>anova</code> (i.e. <code><a href="#topic+anova.manyany">anova.manyany</a></code>) will produce a significance test comparing two <code>manyany</code> objects.
Currently there is no <code>summary</code> resampling function for objects of this class.
</p>
<p>The generic accessor functions <code>fitted.values</code>, <code>residuals</code>, <code>logLik</code>, <code>AIC</code>, <code>plot</code>
can be used to extract various useful features of the value returned by <code>manyany</code>.
</p>
<p>An object of class <code>"manyany"</code> is a list containing at least the
following components:
</p>
<table role = "presentation">
<tr><td><code>logL</code></td>
<td>
<p>a vector of log-likelihood terms for each response variable in the fitted model.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of fitted mean values, obtained by transforming the linear predictors by the inverse of the link function.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of probability integral transform (PIT) residuals.
If the fitted model is a good fit, these will be approximately standard uniformly distributed.</p>
</td></tr>
<tr><td><code>linear.predictor</code></td>
<td>
<p>the linear fit on link scale. But for ordinal models fitted using <code>clm</code>, these values are for the first category only.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>a vector of <code><a href="stats.html#topic+family">family</a></code> arguments, one for each response variable.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the <code>model.frame</code> from the model for the last response variable.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>a list of <code>terms</code> from the model for the last response variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.manyglm">anova.manyany</a></code>, <code><a href="#topic+residuals.manyany">residuals.manyany</a></code>, <code><a href="#topic+plot.manyany">plot.manyany</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)

spider = list(abund=spider$abund, x = as.matrix(spider$x))

## To fit a log-linear model assuming counts are negative binomial, via manyglm:
spidNB &lt;- manyany(abund~x,"manyglm",data=spider,family="negative.binomial")

logLik(spidNB) # a number of generic functions are applible to manyany objects

## To fit a glm with complementary log-log link to presence/absence data:
PAdat = pmin(as.matrix(spider$abund),1) #constructing presence/absence dataset
spidPA &lt;- manyany(PAdat~x,"glm",data=spider,family=binomial("cloglog"))
plot(spidPA)
# There are some wild values in there for the Pardmont variable (residuals &gt;5 or &lt;-8).
#The Pardmont model didn't converge, coefficients are a bit crazy:
coef(spidPA) 

# could try again using the glm2 package to fit the models, this fixes things up:
## Not run: library(glm2)
## Not run: spidPA2&lt;-manyany(PAdat~x,"glm",data=spider,family=binomial("cloglog"),method="glm.fit2")
## Not run: plot(spidPA2) #looks much better.

## To simultaneously fit models to ordinal data using the ordinal package:
## Not run: library(ordinal)
## First construct an ordinal dataset:
## Not run: spidOrd = spider$abund
## Not run: spidOrd[spider$abund&gt;1 &amp; spider$abund&lt;=10]=2
## Not run: spidOrd[spider$abund&gt;10]=3
## Now fit a model using the clm function:
## Not run: manyOrd=manyany(spidOrd~bare.sand+fallen.leaves,"clm",data=data.frame(spider$x))
## Not run: plot(manyOrd)
</code></pre>

<hr>
<h2 id='manyglm'>Fitting Generalized Linear Models for Multivariate Abundance Data</h2><span id='topic+manyglm'></span>

<h3>Description</h3>

<p><code>manyglm</code> is used to fit generalized linear models to high-dimensional data, such as multivariate abundance data in ecology. This is the base model-fitting function - see <code>plot.manyglm</code> for assumption checking, and <code>anova.manyglm</code> or <code>summary.manyglm</code> for significance testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manyglm(formula, family="negative.binomial", composition=FALSE, data=NULL, subset=NULL,
    na.action=options("na.action"), K=1, theta.method = "PHI", model = FALSE,
    x = TRUE, y = TRUE, qr = TRUE, cor.type= "I", shrink.param=NULL,
    tol=sqrt(.Machine$double.eps), maxiter=25, maxiter2=10,
    show.coef=FALSE, show.fitted=FALSE, show.residuals=FALSE,
    show.warning=FALSE, offset, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="manyglm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted.  The details of model specification are given
under Details.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_family">family</code></td>
<td>
<p>a description of the distribution function to be used in the
in the model. The default is negative binomial regression (using a log
link, with unknown overdispersion parameter), the following family
functions are also accepted: binomial(), binomial(link=&quot;cloglog&quot;),
poisson(), Gamma(link=&quot;log&quot;), which can also be specified using character strings as
'binomial', 'cloglog' and 'poisson', 'gamma' respectively. In future we hope
to include other family functions as described in <code><a href="stats.html#topic+family">family</a></code>.
</p>
</td></tr>
<tr><td><code id="manyglm_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model. If not found in <code>data</code>, the variables
are taken from <code>environment(formula)</code>, typically the environment
from which <code>glm</code> is called.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_composition">composition</code></td>
<td>
<p><code>FALSE</code> (default) will model abundance, <code>TRUE</code> will model relative abundance, by adding a row effect to the model, and partition effects of environmental variables into main effects (alpha, total abundance/richness) and interactions with response (beta, relative abundance/turnover). See <code>details</code>.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &lsquo;factory-fresh&rsquo;
default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another possible value is
<code>NULL</code>, no action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> can be useful.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_k">K</code></td>
<td>
<p>number of trials in binomial regression. By default, K=1 for presence-absence data using logistic regression.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_theta.method">theta.method</code></td>
<td>
<p>the method used for the estimation of the overdisperson
parameter theta, such that the mean-variance relationship is V=m+m^2/theta for
the negative binomial family. Here offers three options <br />
&quot;PHI&quot; = Maximum likelihood estimation with respect to phi (default)<br />
&quot;ML&quot; = Maximum likelihood estimation with respect to theta, as in Lawless(1987), the default for the gamma family. <br />
&quot;Chi2&quot; = Moment estimation using chi-square dampening on the log scale, as
in Hilbe(2008).
&quot;MM&quot; = Moment estimation for gamma family.




</p>
</td></tr>
<tr><td><code id="manyglm_+3A_model">model</code>, <code id="manyglm_+3A_x">x</code>, <code id="manyglm_+3A_y">y</code>, <code id="manyglm_+3A_qr">qr</code></td>
<td>
<p>logicals. If <code>TRUE</code> the corresponding
components of the fit (the model frame, the model matrix, the model
matrix, the response, the QR decomposition of the model matrix) are
returned.
</p>
</td></tr>
<tr><td><code id="manyglm_+3A_cor.type">cor.type</code></td>
<td>
<p>the structure imposed on the estimated correlation
matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;.
See Details. This parameter is merely stored in <code>manyglm</code>, and
will be used as the default value for <code>cor.type</code> in subsequent
functions for inference.
</p>
</td></tr>
<tr><td><code id="manyglm_+3A_shrink.param">shrink.param</code></td>
<td>

<p>shrinkage parameter to be used if <code>cor.type="shrink"</code>. If a numerical
value is not supplied, it will be estimated from the data by cross
validation-penalised normal likelihood as in Warton (2008). The parameter
value is stored as an attribute of the <code>manyglm</code> object, and will be
used in subsequent functions for inference.
</p>
</td></tr>
<tr><td><code id="manyglm_+3A_tol">tol</code></td>
<td>
<p>the tolerance used in estimation.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum allowed iterations in the weighted least square estimation of beta. The default value is 25.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_maxiter2">maxiter2</code></td>
<td>
<p>maximum allowed iterations in the internal ML estimations of negative binomial regression. The default value is 10.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_show.coef">show.coef</code>, <code id="manyglm_+3A_show.fitted">show.fitted</code>, <code id="manyglm_+3A_show.residuals">show.residuals</code>, <code id="manyglm_+3A_show.warning">show.warning</code></td>
<td>
<p>logical. Whether to show model coefficients, fitted values, standardized pearson residuals, or operation warnings.</p>
</td></tr>
<tr><td><code id="manyglm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an _a priori_ known component to be included in the linear predictor during fitting. This should be 'NULL' or a numeric vector of length equal to NROW (i.e. number of observations) or a matrix of NROW times p (i.e. number of species).</p>
</td></tr>
<tr><td><code id="manyglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>manyglm</code> is used to calculate the parameter estimates of generalised linear models fitted to each of many variables simultaneously as in Warton et. al. (2012) and Wang et.al.(2012). Models for <code>manyglm</code> are specified symbolically. For details on how to specify a formula see the details section of <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+formula">formula</a></code>.
</p>
<p>Generalised linear models are designed for non-normal data for which a distribution can be specified that offers a reasonable model for data, as specified using the argument <code>family</code>. The <code>manyglm</code> function currently handles count and binary data, and accepts either a character argument or a family argument for common choices of family. For binary (presence/absence) data, <code>family=binomial()</code> can be used for logistic regression (logit link, &quot;logistic regression&quot;), or the complementary log-log link can be used <code>family=binomial("cloglog")</code>, arguably a better  choice for presence-absence data. Poisson regression <code>family=poisson()</code> can be used for counts that are not &quot;overdispersed&quot; (that is, if the variance is not larger than the mean), although for multivariate abundance data it has been shown that the negative binomial distribution (<code>family="negative.binomial"</code>) is usually a better choice (Warton 2005). In both cases, a log-link is used. If another link function or family is desired, this can be specified using the <code><a href="#topic+manyany">manyany</a></code> function, which accepts regular <code><a href="stats.html#topic+family">family</a></code> arguments.
</p>
<p><code>composition=TRUE</code> allows relative abundance to be modelled rather than absolute abundance, which is useful for partitioning effects of environmental variables on alpha vs beta diversity, and is needed if there is variation in sampling intensity due to variables that haven't been measured. Data are manipulated into &quot;long format&quot;, with column factor called <code>cols</code> and row variable called <code>rows</code>, then a model is fitted using main effects for predictors as in the provided formula, plus <code>rows</code>, <code>cols</code> and the interaction of predictors with <code>cols</code>. Inclusion of <code>rows</code> in the model accounts for variation in sampling intensity across rows, main effects for environmental variables capture their effects on total abundance/richness (alpha diversity), and their interaction with <code>cols</code> captures changes in relative abundance/turnover (beta diversity). Unfortunately, data are not efficiently stored in long format, so models are slower to fit using <code>composition=TRUE</code>.
</p>
<p>In negative binomial regression, the overdispersion parameter (<code>theta</code>) is estimated separately for each variable from the data, as controlled by <code>theta.method</code> for negative binomial distributions. We iterate between updates of <code>theta</code> and generalised linear model updates for regression parameters, as many as <code>maxiter2</code> times.
</p>
<p><code>cor.type</code> is the structure imposed on the estimated correlation
matrix under the fitted model. Possible values are: <br />
<code>"I"</code>(default) = independence is assumed (correlation matrix is the identity) <br />
<code>"shrink"</code> = sample correlation matrix is shrunk towards I to improve its stability. <br />
<code>"R"</code> = unstructured correlation matrix is used.  (Only available when N&gt;p.)
</p>
<p>If <code>cor.type=="shrink"</code>, a numerical value will be assigned to <code>shrink.param</code> either through the argument or by internal estimation. The working horse function for the internal estimation is <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code>, which is based on cross-validation (Warton 2008). The validation groups are chosen by random assignment, so some slight variation in the estimated values may be observed in repeat analyses. See <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code> for more details. The shrinkage parameter can be any value between 0 and 1 (0=&quot;I&quot; and 1=&quot;R&quot;, values closer towards 0 indicate more shrinkage towards &quot;I&quot;).
</p>


<h3>Value</h3>

<p><code>manyglm</code> returns an object inheriting from <code>"manyglm"</code>,
<code>"manylm"</code> and &quot;mglm&quot;.
</p>
<p>The function <code>summary</code> (i.e. <code><a href="#topic+anova.manyglm">summary.manyglm</a></code>) can be used to obtain or print a summary of the results and the function
<code>anova</code> (i.e. <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>) to produce an
analysis of variance table, although note that these functions use resampling so they can take a while to fit.
</p>
<p>The generic accessor functions <code><a href="stats.html#topic+coefficients">coefficients</a></code>,
<code>fitted.values</code> and <code>residuals</code> can be used to
extract various useful features of the value returned by <code>manyglm</code>.
</p>
<p>An object of class <code>"manyglm"</code> is a list containing at least the
following components:
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>a named matrix of coefficients.</p>
</td></tr>
<tr><td><code>var.coefficients</code></td>
<td>
<p>the estimated variances of each coefficient.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of fitted mean values, obtained by transforming the linear predictors by the inverse of the link function.</p>
</td></tr>
<tr><td><code>linear.predictor</code></td>
<td>
<p>the linear fit on the scale of the linear predictor.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of <em>working</em> residuals, that is the Pearson residuals standardized by the leverage adjustment h obtained from the diagonal elements of the hat matrix H. </p>
</td></tr>
<tr><td><code>PIT.residuals</code></td>
<td>
<p>probability integral transform (PIT) residuals - for a model that fits well these should be approximately standard uniform values evenly scattered between 0 and 1. Their calculation involves some randomisation, so different fits will return slightly different values for PIT residuals.</p>
</td></tr>
<tr><td><code>sqrt.1_Hii</code></td>
<td>
<p>the matrix of scale terms used to standardize the Pearson reidusals.</p>
</td></tr>
<tr><td><code>var.estimator</code></td>
<td>
<p>the estimated variance of each observation, computed using the corresponding family function.</p>
</td></tr>
<tr><td><code>sqrt.weight</code></td>
<td>
<p>the matrix of square root of <em>working</em> weights,  estimated for the corresponding family function.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>the estimated nuisance parameters accounting for overdispersion</p>
</td></tr>
<tr><td><code>two.loglike</code></td>
<td>
<p>two times the log likelihood.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>up to a constant, minus twice the maximized log-likelihood.  Where sensible, the constant is chosen so that a saturated model has deviance zero.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations of IWLS used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a data frame storing the input data.</p>
</td></tr>
<tr><td><code>stderr.coefficients</code></td>
<td>
<p>the estimated standard error of each coefficient.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>the inverse of theta</p>
</td></tr>
<tr><td><code>tol</code></td>
<td>
<p>the tolerance used in estimations.</p>
</td></tr>
<tr><td><code>maxiter</code>, <code>maxiter2</code>, <code>family</code>, <code>theta.method</code>, <code>cor.type</code>, <code>formula</code></td>
<td>
<p>arguments supplied in the <code>manyglm</code> call.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>a vector returning Akaike's <em>An Information Criterion</em> for each response variable - minus twice the
maximized log-likelihood plus twice the number of coefficients.</p>
</td></tr>
<tr><td><code>AICsum</code></td>
<td>
<p>the sum of the AIC's over all variables.</p>
</td></tr>
<tr><td><code>shrink.param</code></td>
<td>
<p>the shrink parameter to be used in subsequent inference.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code><a href="stats.html#topic+terms">terms</a></code> object used.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>the numeric rank of the fitted linear model.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>(where relevant) a record of the levels of the factors used in fitting.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>if the argument <code>x</code> is <code>TRUE</code>, this is the design matrix used.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>if the argument <code>y</code> is <code>TRUE</code>, this is the response variables used.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if the argument <code>model</code> is <code>TRUE</code>, this is the <code>model.frame</code>.</p>
</td></tr>
<tr><td><code>qr</code></td>
<td>
<p>if the argument <code>qr</code> is <code>TRUE</code>, this is the QR decomposition of the design matrix.</p>
</td></tr>
<tr><td><code>show.coef</code>, <code>show.fitted</code>, <code>show.residuals</code></td>
<td>
<p>arguments supplied in the <code>manyglm</code> call concerning what it presented in output.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>the <code>offset</code> data used (where applicable).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yi Wang, Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Lawless, J. F. (1987)
<em>Negative binomial and mixed Poisson regression</em>,
Canadian Journal of Statistics 15, 209-225.
</p>
<p>Hilbe, J. M. (2008)
<em>Negative Binomial Regression</em>,
Cambridge University Press, Cambridge.
</p>
<p>Warton D.I. (2005)
<em>Many zeros does not mean zero inflation: comparing the
goodness of-fit of parametric models to multivariate abundance data</em>,
Environmetrics 16(3), 275-289.
</p>
<p>Warton D.I. (2008). Penalized normal likelihood and ridge regularization
of correlation and covariance matrices. <em>Journal of the American
Statistical Association</em> 103, 340-349.
</p>
<p>Warton D.I. (2011). Regularized sandwich estimators for analysis of high dimensional data using generalized estimating equations. <em>Biometrics</em>, 67(1), 116-123.
</p>
<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>
<p>Wang Y., Neuman U., Wright S. and Warton D. I. (2012). mvabund: an R package for model-based analysis of multivariate abundance data. <em>Methods in Ecology and Evolution</em>. online 21 Feb 2012.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.manyglm">anova.manyglm</a></code>, <code><a href="#topic+summary.manyglm">summary.manyglm</a></code>, <code><a href="#topic+residuals.manyglm">residuals.manyglm</a></code>, <code><a href="#topic+plot.manyglm">plot.manyglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

#To fit a log-linear model assuming counts are poisson:
glm.spid &lt;- manyglm(spiddat~X, family="poisson")
glm.spid

summary(glm.spid, resamp="residual")

#To fit a binomial regression model to presence/absence data:
pres.abs &lt;- spiddat
pres.abs[pres.abs&gt;0] = 1
Xdf &lt;- data.frame(spider$x) #turn into a data frame to refer to variables in formula
glm.spid.bin &lt;- manyglm(pres.abs~soil.dry+bare.sand+moss, data=Xdf, family="binomial")
glm.spid.bin
drop1(glm.spid.bin) #AICs for one-term deletions, suggests dropping bare.sand

glm2.spid.bin &lt;- manyglm(pres.abs~soil.dry+moss, data=Xdf, family="binomial")
drop1(glm2.spid.bin) #backward elimination suggests settling on this model.

</code></pre>

<hr>
<h2 id='manylm'>Fitting Linear Models for Multivariate Abundance Data</h2><span id='topic+manylm'></span>

<h3>Description</h3>

<p><code>manylm</code> is used to fit multivariate linear models
to high-dimensional data, such as multivariate abundance data in ecology.
</p>
<p>This is the base model-fitting function - see <code>plot.manylm</code> for 
assumption checking, and <code>anova.manylm</code> or <code>summary.manylm</code> 
for significance testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manylm(
   formula, data=NULL,  subset=NULL, weights=NULL, 
   na.action=options("na.action"),  method="qr", model=FALSE, 
   x=TRUE, y=TRUE, qr=TRUE, singular.ok=TRUE, contrasts=NULL, 
   offset, test="LR" , cor.type= "I", shrink.param=NULL, 
   tol=1.0e-5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="manylm_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"formula"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted. The details of model specification are given
under Details.
</p>
</td></tr>
<tr><td><code id="manylm_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code>as.data.frame</code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>manylm</code> is called.</p>
</td></tr>
<tr><td><code id="manylm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="manylm_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process.  Should be <code>NULL</code> or a numeric vector.
If non-null, weighted least squares is used with weights
<code>weights</code> (that is, minimizing <code>sum(weights*e^2)</code>); otherwise
ordinary least squares is used.</p>
</td></tr>
<tr><td><code id="manylm_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code>options</code>, and is
<code>na.fail</code> if that is unset.  The &lsquo;factory-fresh&rsquo;
default is <code>na.omit</code>.  Another possible value is
<code>NULL</code>, no action.  Value <code>na.exclude</code> can be useful.</p>
</td></tr>
<tr><td><code id="manylm_+3A_method">method</code></td>
<td>
<p>the method to be used; for fitting, currently only
<code>method = "qr"</code> is supported; <code>method = "model.frame"</code> returns
the model frame (the same as with <code>model = TRUE</code>, see below).</p>
</td></tr>
<tr><td><code id="manylm_+3A_model">model</code>, <code id="manylm_+3A_x">x</code>, <code id="manylm_+3A_y">y</code>, <code id="manylm_+3A_qr">qr</code></td>
<td>
<p>logicals.  If <code>TRUE</code> the corresponding
components of the fit (the model frame, the model matrix, the
response, the QR decomposition) are returned. </p>
</td></tr>
<tr><td><code id="manylm_+3A_singular.ok">singular.ok</code></td>
<td>
<p>logical. If <code>FALSE</code> (the default in S but
not in <span class="rlang"><b>R</b></span>) a singular fit is an error.</p>
</td></tr>
<tr><td><code id="manylm_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code>
of <code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="manylm_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em>
known component to be included in the linear predictor
during fitting.  This should be <code>NULL</code> or a numeric vector of
length either one or equal to the number of cases.
One or more <code>offset</code> terms can be included in the
formula instead or as well, and if both are specified their sum is
used.  See <code>model.offset</code>.</p>
</td></tr>
<tr><td><code id="manylm_+3A_test">test</code></td>
<td>
<p>choice of test statistic. Can be one of &quot;LR&quot; (default) = likelihood ratio statistic &quot;F&quot; = Lawley-Hotelling trace statistic <code>NULL</code> = no test
This parameter is merely stored in <code>manylm</code>, and will be used as the default value of <code>test</code> in subsequent functions for inference.</p>
</td></tr>
<tr><td><code id="manylm_+3A_cor.type">cor.type</code></td>
<td>
<p>structure imposed on the estimated correlation matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;. See anova.manylm for details of its usage. This parameter will be used as the default value of <code>cor.type</code> in subsequent functions for inference.</p>
</td></tr>
<tr><td><code id="manylm_+3A_shrink.param">shrink.param</code></td>
<td>
<p>shrinkage parameter to be used if <code>cor.type="shrink"</code>. This parameter will be used as the default value of <code>shrink.param</code> in subsequent functions for inference.</p>
</td></tr>
<tr><td><code id="manylm_+3A_tol">tol</code></td>
<td>
<p>the tolerance used in estimations.</p>
</td></tr>
<tr><td><code id="manylm_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the low level regression fitting functions (see below).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models for <code>manylm</code> are specified symbolically. For details on this 
compare the details section of <code>lm</code> and <code>formula</code>. If the formula 
includes an <code>offset</code>, this is evaluated and subtracted from the 
response.   <br />
See <code>model.matrix</code> for some further details. The terms in
the formula will be re-ordered so that main effects come first,
followed by the interactions, all second-order, all third-order and so
on: to avoid this pass a <code>terms</code> object as the formula (see
<code>aov</code> and <code>demo(glm.vr)</code> for an example). <br />
A formula has an implied intercept term.  To remove this use either
<code>y ~ x - 1</code> or <code>y ~ 0 + x</code>.  See <code>formula</code> for
more details of allowed formulae. <br />
<code>manylm</code> calls the lower level function <code><a href="#topic+manylm.fit">manylm.fit</a></code> 
or <code><a href="#topic+manylm.wfit">manylm.wfit</a></code> for the actual numerical computations. 
For programming only, you may consider doing likewise. <br />
All of <code>weights</code>, <code>subset</code> and <code>offset</code> are evaluated
in the same way as variables in <code>formula</code>, that is first in
<code>data</code> and then in the environment of <code>formula</code>.<br />
For details on arguments related to hypothesis testing (such as <code>cor.type</code>
and <code>resample</code>) see <code><a href="#topic+summary.manylm">summary.manylm</a></code> or
<code><a href="#topic+anova.manylm">anova.manylm</a></code>.
</p>


<h3>Value</h3>

<p><code>manylm</code> returns an object of <code>c("manylm", "mlm", "lm")</code> for multivariate
formula response and of of class <code>c("lm")</code> for univariate response.
</p>
<p>A <code>manylm</code> object is a list containing at least the following components:

</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>a named matrix of coefficients</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals matrix, that is response minus fitted values.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of the fitted mean values.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>the numeric rank of the fitted linear model.</p>
</td></tr>

<tr><td><code>weights</code></td>
<td>
<p>(only for weighted fits) the specified weights.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>hat.X</code></td>
<td>
<p>the hat matrix.</p>
</td></tr>
<tr><td><code>txX</code></td>
<td>
<p>the matrix <code>(t(x)%*%x)</code>.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the <code>test</code> argument supplied.</p>
</td></tr>
<tr><td><code>cor.type</code></td>
<td>
<p>the <code>cor.type</code> argument supplied.</p>
</td></tr>
<tr><td><code>resample</code></td>
<td>
<p>the <code>resample</code> argument supplied.</p>
</td></tr>
<tr><td><code>nBoot</code></td>
<td>
<p>the <code>nBoot</code> argument supplied.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code>terms</code> object used.</p>
</td></tr>

<tr><td><code>xlevels</code></td>
<td>
<p>(only where relevant) a record of the levels of the
factors used in fitting.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the model frame used.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>the offset used (missing if none were used).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>if requested, the response matrix used.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>if requested, the model matrix used.</p>
</td></tr>
</table>
<p>In addition, non-null fits will have components <code>assign</code> and 
(unless not requested) <code>qr</code> relating to the linear
fit, for use by extractor functions such as <code>summary.manylm</code>.
</p>


<h3>Author(s)</h3>

<p>Yi Wang, Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.manylm">anova.manylm</a></code>, <code><a href="#topic+summary.manylm">summary.manylm</a></code>, <code><a href="#topic+plot.manylm">plot.manylm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- log(spider$abund+1)
lm.spider &lt;- manylm(spiddat~.,data=spider$x)
lm.spider

#Then use the plot function for diagnostic plots, and use anova or summary to
#evaluate significance of different model terms.
</code></pre>

<hr>
<h2 id='manylm.fit'>workhose functions for fitting multivariate linear models</h2><span id='topic+manylm.fit'></span><span id='topic+manylm.wfit'></span>

<h3>Description</h3>

<p>These are the workhorse functions called by <code><a href="#topic+manylm">manylm</a></code> used
to fit multivariate linear models.  These should usually <em>not</em> be used
directly unless by experienced users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manylm.fit(x, y, offset = NULL, tol=1.0e-010, singular.ok = TRUE, ...)
manylm.wfit(x, y, w, offset = NULL, tol=1.0e-010, singular.ok = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="manylm.fit_+3A_x">x</code></td>
<td>
<p>design matrix of dimension <code>n * p</code>.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_y">y</code></td>
<td>
<p>matrix or an <code>mvabund</code> object of observations of dimension <code>n*q</code>.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_w">w</code></td>
<td>
<p>vector of weights (length <code>n</code>) to be used in the fitting
process for the <code>manylm.wfit</code> functions.  Weighted least squares is
used with weights <code>w</code>, i.e., <code>sum(w * e^2)</code> is minimized.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_offset">offset</code></td>
<td>
<p>numeric of length <code>n</code>).  This can be used to
specify an <em>a priori</em> known component to be included in the
linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_tol">tol</code></td>
<td>
<p>tolerance for the <code>qr</code> decomposition.  Default
is 1.0e-050.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_singular.ok">singular.ok</code></td>
<td>
<p>logical. If <code>FALSE</code>, a singular model is an
error.</p>
</td></tr>
<tr><td><code id="manylm.fit_+3A_...">...</code></td>
<td>
<p>currently disregarded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with components
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p><code>p</code> vector</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p><code>n</code> vector or matrix</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p><code>n</code> vector or matrix</p>
</td></tr>



<tr><td><code>weights</code></td>
<td>
<p><code>n</code> vector &mdash; <em>only</em> for the <code>*wfit*</code>
functions.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>integer, giving the rank</p>
</td></tr>
<tr><td><code>qr</code></td>
<td>
<p>(not null fits) the QR decomposition.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of residuals</p>
</td></tr>
<tr><td><code>hat.X</code></td>
<td>
<p>the hat matrix.</p>
</td></tr>
<tr><td><code>txX</code></td>
<td>
<p>the matrix <code>(t(x)%*%x)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code> 
</p>

<hr>
<h2 id='meanvar.plot'>
Construct Mean-Variance plots for Multivariate Abundance Data
</h2><span id='topic+meanvar.plot'></span><span id='topic+meanvar.plot.mvabund'></span><span id='topic+meanvar.plot.mvformula'></span><span id='topic+meanvar.plot+2Cmvabund-method'></span><span id='topic+meanvar.plot+2Cmvformula-method'></span><span id='topic+meanvar.plot+2Cformula-method'></span><span id='topic+meanvar.plot+2Cmatrix-method'></span><span id='topic+meanvar.plot+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>Construct mean-variance plots, separately for each column of the input
data, and separately for each level of any input factor that is 
given (via a formula). This function was specially written for high 
dimensional data where there are many correlated variables exhibiting 
a mean-variance structure, in particular, multivariate abundance 
data in ecology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanvar.plot(x, ...)

## S3 method for class 'mvabund'
meanvar.plot(
  x, n.vars=NULL, var.subset=NULL, subset=NULL, table=FALSE, ...)

## S3 method for class 'mvformula'
meanvar.plot(
  x, n.vars = NULL, var.subset=NULL, subset=NULL, table=FALSE, 
  overall.main=NULL, overlay=TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meanvar.plot_+3A_x">x</code></td>
<td>
<p>an mvabund objects or a Model Formula (can be a formula or a
mvformula) to be used.</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_n.vars">n.vars</code></td>
<td>
<p>the number of variables to include in the plot.</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_var.subset">var.subset</code></td>
<td>
<p>vector of indices indicating the variables to be included on the plot, (default: the <code>n.vars</code> most abundant variables).</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_table">table</code></td>
<td>
<p>logical, whether a table of the Means and Variances should be returned</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_overall.main">overall.main</code></td>
<td>
<p>an overall title for the window.</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_overlay">overlay</code></td>
<td>
<p>logical, whether overall means/variances for all variables are calculated and drawn on a single plot or calculated and plotted separately for different variables.</p>
</td></tr>
<tr><td><code id="meanvar.plot_+3A_...">...</code></td>
<td>
<p>arguments to be passed to or from other methods.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code>meanvar.plot</code> calculates a mean-variance plot for a dataset with many variables (e.g., Warton D. I., Wright S., and Wang, Y. (2012)).
</p>
<p>The mean values and variances are calculated across all observations, unless a 
formula is given as the first argument which specifies a factor as the dependent 
variable. In this latter case the means and variances are calculated separately within the groups defined by these factors.
</p>
<p>By default the means and variances of all variables (and all factor levels) are displayed on the same plot. If a formula is given and the explanatory variables contain factor variables, the mean values and variances for each factor level can be calculated and displayed either for all variables together or for each variable separately.
</p>
<p>For the latter, set <code>overlay</code> to <code>FALSE</code>. The mean-variances corresponding to the different factors will be drawn in different colors, that can be chosen by specifying <code>col</code>. <code>col</code> can then either be a single color value (see <code>par</code>) with the number of values being at least the maximum number of levels of the factors. The same applies to <code>pch</code>.
</p>
<p>If <code>mfrow</code> is <code>NULL</code> and <code>mfcol</code> is <code>NULL</code>, par(&quot;mfrow&quot;) is used. If <code>all.labels = FALSE</code>, only the x-axis labels at the bottom plot and the y-axis labels of plots on the right side of the window are printed if furthermore <code>main=NULL</code> only the graphics on the top contain the full title, the other ones an abreviated one.
</p>
<p>Note, that if a log-transformation is used for displaying the data, a specific mean-variance relation will not be visible in the plot, if either the calculated mean is zero and <code>log!="x"</code> or <code>log!="xy"</code> or if the calculated variance
is zero and <code>log!="y"</code> or <code>log!="xy"</code>.
</p>
<p>By default the y/x ratio of the axis, specified by <code>asp</code>, will be set to <code>1</code> if <code>log!="xy"</code>. If the mean-variance relation is not displayed on a log scale and <code>overlay</code> is <code>FALSE</code>, it is most often not advisable to specify <code>asp</code>, as there might not be one choice of <code>asp</code> that is sensible for each of the plots.
</p>


<h3>Value</h3>

<p>If <code>table</code> is <code>TRUE</code> a table of the Means and Variances is returned.
Otherwise, only the plot(s) is/are drawn.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Stephen Wright and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>
<p>Warton D.I. (2008). Raw data graphing: an informative but under-utilized tool for the analysis of multivariate abundances. <em>Austral Ecology</em> 33(3), 290-300.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mvabund">plot.mvabund</a></code>
<code><a href="#topic+plot.mvformula">plot.mvformula</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

## Load the tikus dataset:
data(tikus)
tikusdat &lt;- mvabund(tikus$abund)
year &lt;- tikus$x[,1]

## Plot mean-variance plot for a mvabund object with a log scale (default):
meanvar.plot(tikusdat) 	

## Again but without log-transformation of axes:
meanvar.plot(tikusdat,log="") 	

## A mean-variance plot, data organised by year, 
## for 1981 and 1983 only, as in Figure 7a of Warton (2008):
is81or83 &lt;- year==81 | year==83
meanvar.plot(tikusdat~year, subset=is81or83, col=c(1,10))
</code></pre>

<hr>
<h2 id='mvabund'>Multivariate Abundance Data Objects</h2><span id='topic+mvabund'></span><span id='topic+as.mvabund'></span><span id='topic+is.mvabund'></span><span id='topic+mvabund-class'></span>

<h3>Description</h3>

<p><code>mvabund</code> creates an mvabund object.<br />
<code>as.mvabund</code> attempts to turn its argument into an mvabund object.<br />
<code>is.mvabund</code> tests if the argument is an mvabund object.<br />
<code>mvabund</code> is a class of objects for which special-purpose plotting and regression functions have been written in the <code><a href="#topic+mvabund-package">mvabund-package</a></code>. The above are useful preliminary functions before analysing data using the special-purpose functions. These new functions were written specially for the analysis of multivariate abundance data in ecology, hence the title 'mvabund'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvabund( ... , row.names=NULL, check.rows=FALSE, check.names=TRUE,
  var.names=NULL, neg=FALSE, na.rm=FALSE )
  
as.mvabund(x)

is.mvabund(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvabund_+3A_...">...</code></td>
<td>
<p>these arguments are of either the form value or tag = value.
Component names are created based on 
the tag (if present) or the deparsed argument itself.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_row.names">row.names</code></td>
<td>
<p><code>NULL</code> or a single integer or character string specifying
a column to be used as row names, or a character
or integer vector giving the row names for the mvabund object.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_check.rows">check.rows</code></td>
<td>

<p>if <code>TRUE</code> then the rows are checked for consistency of length
and names.
</p>
</td></tr>
<tr><td><code id="mvabund_+3A_check.names">check.names</code></td>
<td>
<p>logical. If <code>TRUE</code> then the names of the variables are
checked to ensure that they are syntactically valid variable names
and are not duplicated. If necessary they are adjusted (by make.names) so that
they are.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_var.names">var.names</code></td>
<td>
<p><code>NULL</code> or a character vector giving the column names for
the mvabund object.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_neg">neg</code></td>
<td>
<p>character. If <code>FALSE</code> negative values will cause an error message.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, whether missing values should be removed.</p>
</td></tr>
<tr><td><code id="mvabund_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is desirable to convert abundance data to <code>mvabund</code> objects, to allow
automatic use of all methods for mvabund objects, for example the provided 
methods for plotting, linear and generalised linear model-fitting and inference.  
</p>
<p>Some more technical details:  <br />
<code>mvabund</code> objects always have two dimensions. <br />
<code>mvabund</code> converts its arguments into an mvabund object. The supplied argument can be a matrix, data frame, a list of vectors, or several vectors as separate arguments. <br />
</p>
<p>If elements of the created <code>mvabund</code> object are not numeric, a warning will be printed. <br />
</p>
<p>If <code>row.names</code> are not supplied, the row names of the <code>mvabund</code>
object will be <code>NULL</code>. If the length of row.names does not match the
number of rows or there are duplicates, an error message will result.
</p>


<h3>Value</h3>

<p><code>mvabund</code> and <code>as.mvabund</code> returns an mvabund object. <br />
<code>is.mvabund</code> returns <code>TRUE</code> if <code>x</code> is a matrix and <code>FALSE</code>
otherwise.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unabund">unabund</a></code>, <code><a href="#topic+mvformula">mvformula</a></code>, <code><a href="#topic+plot.mvabund">plot.mvabund</a></code>,
Also see the <code><a href="#topic+mvabund-package">mvabund-package</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(solberg) 

## Create an mvabund object:
solbergdat &lt;- mvabund(solberg$abund)

## Turn solberg$abund into an mvabund object and store as solbergdat:
solbergdat &lt;- as.mvabund(solberg$abund)

## Check if solbergdat  is an mvabund object:
is.mvabund(solbergdat)
</code></pre>

<hr>
<h2 id='mvabund-internal'>Internal mvabund Objects</h2><span id='topic+LLCalc'></span><span id='topic+LLSolve'></span><span id='topic++5B.mvabund'></span><span id='topic+absspp'></span><span id='topic+as.data.frame.mvabund'></span><span id='topic+as.matrix.mvabund'></span><span id='topic+betaest'></span><span id='topic+case.names.manylm'></span><span id='topic+cbind.mvabund'></span><span id='topic+covratio'></span><span id='topic+dffits'></span><span id='topic+effic.make.link'></span><span id='topic+influence.measures'></span><span id='topic+is.formulaUnimva'></span><span id='topic+manylm.multiwfit'></span><span id='topic+nbinall'></span><span id='topic+nbinall2'></span><span id='topic+nbinfit'></span><span id='topic+plot'></span><span id='topic+plotFormulafeature'></span><span id='topic+print.mvformula'></span><span id='topic+print.manyglm'></span><span id='topic+print.manylm'></span><span id='topic+print.mvabund'></span><span id='topic+rbind.mvabund'></span><span id='topic+rcalc'></span><span id='topic+transAxis'></span><span id='topic+RcppVersion'></span>

<h3>Description</h3>

<p>Internal mvabund functions.</p>


<h3>Details</h3>

<p>These are not to be called by the user.</p>

<hr>
<h2 id='mvformula'> Model Formulae for Multivariate Abundance Data </h2><span id='topic+mvformula'></span><span id='topic+as.mvformula'></span><span id='topic+is.mvformula'></span><span id='topic+mvformula-class'></span>

<h3>Description</h3>

<p><code>mvformula</code> is a method to create an object of class <code>mvformula</code> <br />
<code>as.mvformula</code> is a function to turn a formula into a <code>mvformula</code> <br />
<code>is.mvformula</code> tests if its argument is a <code>mvformula</code> object.
<code>mvformula</code> is a class of objects for which special-purpose plotting and regression functions have been written in the <code><a href="#topic+mvabund-package">mvabund-package</a></code>. The above are useful preliminary functions before analysing data using the special-purpose functions. These new functions were written specially for the analysis of multivariate abundance data in ecology, hence the title 'mvabund'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvformula(x)
as.mvformula(x)
is.mvformula(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvformula_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mvformula</code> is a method to create an object of class <code>mvformula</code>
If the response of the resulting formula is not a <code>mvabund</code> object, a warning
will be printed. 
<code>as.mvformula</code> is a function to turn a formula into a <code>mvformula</code>
if the response in x is a data.frame or an unsuitable object the conversion 
will fail.
</p>


<h3>Value</h3>

<p>a formula mvabund for <code>mvformula</code> and <code>as.mvformula</code> 
a logical value indicating whether <code>x</code> is a <code>mvformula</code> object </p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvabund">mvabund</a></code>.
<code><a href="#topic+manylm">manylm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(spider)
spiddat &lt;- mvabund(spider$abund)
X=as.matrix(spider$x)

## Create a formula for multivariate abundance data:
foo &lt;- mvformula( spiddat~X )

## Check whether foo is a mvformula:
is.mvformula(foo)

## Plot a mvformula:
plot(foo)

</code></pre>

<hr>
<h2 id='plot.manyany'>Plot Diagnostics for a manyany or glm1path Object</h2><span id='topic+plot.manyany'></span><span id='topic+plot.glm1path'></span>

<h3>Description</h3>

<p>A residual vs fits plot from a <code><a href="#topic+manyany">manyany</a></code> or <code><a href="#topic+glm1path">glm1path</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyany'
plot( x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.manyany_+3A_x">x</code></td>
<td>
 <p><code>manyany</code> object, resulting from a call to <code><a href="#topic+manyany">manyany</a></code>.</p>
</td></tr>
<tr><td><code id="plot.manyany_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting
functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.manyany</code> is used to check assumptions that are made
when fitting a model via <code><a href="#topic+manyany">manyany</a></code> or <code><a href="#topic+glm1path">glm1path</a></code>. As in Wang et al (2012), you should check
the residual vs fits plot for no pattern (hence no suggestion of failure of any linearity
and mean-variance assumptions).
It is also desirable that residuals follow a straight line of slope one on a 
normal Q-Q plot.
</p>
<p>These plots use Dunn-Smyth residuals (Dunn &amp; Smyth 1996), described at <code><a href="#topic+residuals.manyglm">residuals.manyglm</a></code>.
Note that for discrete data, these residuals involve random number generation, and
will not return identical results on replicate runs - so it is recommended that you
plot your data a few times to check if any pattern shows up consistently across replicate plots.
</p>
<p>Note also that for <code><a href="#topic+glm1path">glm1path</a></code> objects, slope coefficients have been shrunk towards zero so it is not unusual to see an increasing slope on the residual plot, with larger residuals coinciding with larger fitted values. This arises a a consequent of shrinkage, check if it goes away upon removing the penaly term (e.g. on refitting using <code><a href="#topic+manyglm">manyglm</a></code>) before ringing any alarm bells.
</p>


<h3>Author(s)</h3>

<p>David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Dunn, P.K., &amp; Smyth, G.K. (1996). Randomized quantile residuals. Journal of Computational and
Graphical Statistics 5, 236-244.
</p>
<p>Wang Y., Naumann U., Wright S.T. &amp; Warton D.I. (2012). mvabund - an R package for model-based 
analysis of multivariate abundance data. Methods in Ecology and Evolution 3, 471-474.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm1path">glm1path</a></code>, <code><a href="#topic+manyany">manyany</a></code>, <code><a href="#topic+manyglm">manyglm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(spider)
abund &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

## Plot the diagnostics for a log-linear model assuming counts are poisson:
spidPois &lt;- manyany(abund ~ X, "glm", family=poisson())
plot(spidPois,pch=19,cex=0.2)
## Fan-shape means trouble for our Poisson assumption.

## Try a negative binomial instead...
require(MASS) # this package is needed for its negative binomial family function
spidNB &lt;- manyany(abund ~ X, "manyglm", family="negative.binomial")
plot(spidNB,pch=19,cex=0.2,xlim=c(-15,6))
## That's looking a lot better...

</code></pre>

<hr>
<h2 id='plot.manylm'>Plot Diagnostics for a manylm or a manyglm Object</h2><span id='topic+plot.manylm'></span><span id='topic+plot.manyglm'></span>

<h3>Description</h3>

<p>Four plots (selectable by <code>which</code>) are currently available: a plot
of residuals against fitted values, a Normal Q-Q plot, 
a Scale-Location plot of <code class="reqn">\sqrt{| residuals |}</code> against fitted values, 
a plot of Cook's distances versus row labels.  
By default, all of them are provided. 
</p>
<p>The function is not yet available for manyglm object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
plot(
  x, res.type="pearson", which=1:4, caption=c("Residuals vs Fitted", "Normal Q-Q", 
  "Scale-Location", "Cook's distance"), overlay=TRUE, 
  n.vars=Inf, var.subset=NULL, sub.caption=NULL, studentized= TRUE, ...)

## S3 method for class 'manyglm'
plot(
  x, res.type="pit.norm", which=1, caption=c("Residuals vs Fitted", "Normal Q-Q", 
  "Scale-Location", "Cook's distance"), overlay=TRUE, 
  n.vars=Inf, var.subset=NULL, sub.caption=NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.manylm_+3A_x">x</code></td>
<td>
 <p><code>manylm</code> object or <code>manyglm</code> object, typically the 
result of a call to <code><a href="#topic+manylm">manylm</a></code> or <code>manyglm</code>.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_res.type">res.type</code></td>
<td>
<p>type of residuals to plot. By default, <code>res.type="pit-norm"</code> uses Dunn-Smyth
residuals (Dunn &amp; Smyth 2996), related to the probability integral transform, for manyglm.
These residuals are especially recommended for presence-absence data or discrete data. </p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_which">which</code></td>
<td>
<p>if a subset of the plots is required, specify a subset of
the numbers <code>1:4</code>.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_caption">caption</code></td>
<td>
<p>captions to appear above the plots</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_overlay">overlay</code></td>
<td>
<p>logical, whether or not the different variables should be
overlaid on a single plot.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_n.vars">n.vars</code></td>
<td>
<p>the number of variables to include in the plot.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_var.subset">var.subset</code></td>
<td>
<p>the variables to include in the plot.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_sub.caption">sub.caption</code></td>
<td>
<p>common title&mdash;above figures if there are multiple;
used as <code>sub</code> (s.<code>title</code>) otherwise.  If <code>NULL</code>,
as by default, a possible shortened version of
<code>deparse(x$call)</code> is used.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting
functions.</p>
</td></tr>
<tr><td><code id="plot.manylm_+3A_studentized">studentized</code></td>
<td>
<p>logical indicating whether studentized or standardized residuals should be used for plot 2 and 3.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.manylm</code> is used to check the linear model assumptions that are made
when fitting a model via <code>manylm</code>. Similarly, <code>plot.manyglm</code> checks
the generalised linear model assumptions made when using <code>manyglm</code>.
As in Wang et al (2012), you should check the residual vs fits plot for no pattern
(hence no suggestion of failure of key linearity and mean-variance assumptions).
For manylm fits of small datasets, it is desirable that residuals on the normal Q-Q plot be close
to a straight line, although in practice the most important thing is to make
sure there are no big outliers and no suggestion of strong skew in the data.
</p>
<p>The recommended <code>res.type</code> option for manyglm calls, &quot;pit-norm&quot;, uses randomised quantile or &quot;Dunn-Smyth&quot;
residuals (Dunn &amp; Smyth 1996). Note that for discrete data, these residuals
involve random number generation, and will not return identical results on replicate runs - so it is recommended
that you plot your data a few times to check if any pattern shows up consistently across replicate plots.
The other main residual option is &quot;pearson&quot;, Pearson residuals. Note that all res.type options
are equivalent for manylm.
</p>
<p>Some technical details on usage of this function:  <br />
<code>sub.caption</code> - by default the function call - is shown as
a subtitle (under the x-axis title) on each plot when plots are on
separate pages, or as a subtitle in the outer margin (if any) when
there are multiple plots per page.  
</p>
<p>The &lsquo;Scale-Location&rsquo; plot, also called &lsquo;Spread-Location&rsquo; or
&lsquo;S-L&rsquo; plot, takes the square root of the absolute residuals in
order to diminish skewness (<code class="reqn">\sqrt{| E |}</code> is much less skewed
than <code class="reqn">| E |</code> for Gaussian zero-mean <code class="reqn">E</code>).
</p>
<p>If <code>studentized=FALSE</code> the &lsquo;S-L&rsquo;, the Q-Q, and the Residual-Leverage 
plot, use <em>standardized</em> residuals which have identical variance 
(under the hypothesis) otherwise <em>studentized</em> residuals are used.  
</p>
<p>Unlike other plotting functions <code>plot.manylm</code> and <code>plot.manyglm</code> 
respectively do not have a subset argument, the subset needs to be specified 
in the <code>manylm</code> or respectively <code>manyglm</code> function.
</p>
<p>For all arguments that are formally located after the position of <code>...</code>,
positional matching does not work.
</p>
<p>For restrictions on <code>filename</code> see R's help on eps/pdf/jpeg.
Note that <code>keep.window</code> will be ignored if <code>write.plot</code> is 
not <code>show</code>.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Dunn, P.K., &amp; Smyth, G.K. (1996). Randomized quantile residuals. Journal of Computational and
Graphical Statistics 5, 236-244.
</p>
<p>Wang Y., Naumann U., Wright S.T. &amp; Warton D.I. (2012). mvabund - an R package for model-based 
analysis of multivariate abundance data. Methods in Ecology and Evolution 3, 471-474.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(spider)
spiddat &lt;- mvabund(spider$abund)

## plot the diagnostics for the linear fit of the spider data
spidlm &lt;- manylm(spiddat~., data=spider$x)
plot(spidlm,which=1:2,col.main="red",cex=3,overlay=FALSE)

plot(spidlm,which=1:4,col.main="red",cex=3,overlay=TRUE)

## plot the diagnostics for Poisson and negative binomial regression of the spider data
glmP.spid &lt;- manyglm(spiddat~., family="poisson", data=spider$x)
plot(glmP.spid, which=1) #note the marked fan-shape on the plot

glmNB.spid &lt;- manyglm(spiddat~., data=spider$x, family="negative.binomial")
plot(glmNB.spid, which=1) #no fan-shape
plot(glmNB.spid, which=1) #note the residuals change on re-plotting, but no consistent trend

</code></pre>

<hr>
<h2 id='plot.mvabund'>Plot Multivariate Abundance Data and Formulae</h2><span id='topic+plot.mvabund'></span><span id='topic+plot.mvformula'></span>

<h3>Description</h3>

<p>Produces a range of plots for visualising multivariate abundance data and 
its relationship to environmental variables, including: dot-plots and boxplots 
for different levels of a factor
stacked by response variable; comparative dot-plots and boxplots for different 
levels of a factor, stacked by response variable; scatterplots of abundances 
against a set of explanatory variables; scatterplots of pair-wise abundance 
data, e.g. from repeated measures. See details below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvabund'
plot(x, y, type="p", overall.main="", n.vars=12, 
  var.subset=NA, transformation="log", ...)

## S3 method for class 'mvformula'
plot(x,y=NA, type="p", var.subset=NA, 
  n.vars= if(any(is.na(list(var.subset)))) 12 else length(var.subset),
  xvar.select=TRUE, xvar.subset = NA, n.xvars=NA, transformation="log", ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mvabund_+3A_x">x</code></td>
<td>

<p>for the <code>mvabund</code> method, x is a <code>mvabund</code> object.<br />
For the <code>mvformula</code> method, x is a <code>mvformula</code> object,
a Model Formula to be used.
</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_y">y</code></td>
<td>
<p>in <code>plot.mvabund</code> an optional second matrix with multivariate
abundance data in <code>plot.mvformula</code> an optional matrix of the
independent variables to explain x.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_type">type</code></td>
<td>
<p>what type of plot should be drawn. Useful types are &quot;p&quot; for
scatterplot, &quot;bx&quot; for boxplot and &quot;n&quot; for no plot. Other types, see
<code>plot</code> are allowed, but usually don't give a meaningful output.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_overall.main">overall.main</code></td>
<td>
<p>a character to display as title for every window.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_var.subset">var.subset</code></td>
<td>
<p>a numeric vector of indices indicating which variables of the
mvabund.object should be included on the plot.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_n.vars">n.vars</code></td>
<td>
<p>the number of variables to include in the plot.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_xvar.select">xvar.select</code></td>
<td>
<p>whether only a subset of x variables should be plotted or all.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_n.xvars">n.xvars</code></td>
<td>
<p>the number of the most relevant x variables that should be plotted,
is not used if <code>xvar.select = FALSE</code>. If NA it will be set to at most 3.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_xvar.subset">xvar.subset</code></td>
<td>
<p>a subset of x variables that should be plotted, is not used if <code>xvar.select = FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_transformation">transformation</code></td>
<td>
<p>an optional transformation, if no formula is given,
&quot;no&quot; = untransformed, &quot;sqrt&quot;=square root transformed,
&quot;log&quot; (default)=log(Y/min+1) transformed, &quot;sqrt4&quot; =4th root transformed.<br />
Note that if <code>plot.mvabund</code> is called explicitly, and two data objects 
supplied, none of which is a <code>mvabund</code> object, then <code>plot.mvformula</code>
will be called (See Details). The argument <code>transformation</code> is then NOT 
available. </p>
</td></tr>
<tr><td><code id="plot.mvabund_+3A_...">...</code></td>
<td>
<p>arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plot.mvabund</code> produces plots for the visualisation of
multivariate abundance data and their relationships to environmental variables.
The approach taken is to separately plot the relationship between each response
variable and environmental
variables, that is, to visualise the marginal distribution, as in Warton (2008). 
Three main types of plot that can be produced:
</p>
<p>(1) Dot-plots or boxplots stacked along the y-axis by response variable. If a
factor is given, comparative dot-plots/boxplots are produced, comparing
abundances across each factor level. This type of plot is produced when one
multivariate abundance dataset is given as an input argument, either on its own,
or together with a factor, as in the examples using the solberg dataset below.
</p>
<p>(2) Scatterplots of multivariate abundances against environmental variables,
with separate plots for separate response variables. This type of plot is
produced when one multivariate abundance dataset is given as an input argument
together with an environmental variable or a set of environmental variables.
</p>
<p>(3) Scatterplots of a paired sample of multivariate abundances. This type of
plot is produced when two multivariate abundance datasets are given as input
arguments, and their size and variable names match each other. It is up to the
user to ensure that the rows match for these two datasets.
</p>
<p>There are several methods for calling <code>plot.mvabund</code>:  <br />
(a) plot.mvabund(&quot;matrix&quot;, ...) <br />
The multivariate abundances are stored
in the data matrix. Including an optional second argument determines
whether a plot of type (1) is produced (if no second argument or if it is a factor), 
or a plot of type (2) (if one or a set of environmental variables is given), or a 
plot of type (3) (if a second matching multivariate abundance dataset is given). <br />
Instead of a matrix, <code>mvabund</code> objects can be used. <br />
(b) plot(&quot;mvabund object&quot;, ...) <br />
You can define mvabund objects using the function 
<code>mvabund</code>. Then the behaviour of the plot function is the same as 
<code>plot.mvabund</code> above. <br />
(c) plot.mvformula(&quot;response&quot;~&quot;terms&quot;) <br />
The first of these two objects must be the multivariate abundances, which can be
either a matrix or a <code>mvabund</code> object. The terms determine the type of
plot produced. The terms can be either a single vector or matrix or 
a number of vectors or matrices, separated by <code>+</code>. 
Compare <code>formula</code> for further details on the specification
of the terms. <br />
(d) plot(&quot;mvformula object&quot;) <br />
You can define mvformula objects using the function <code>mvformula</code>.
Note that the response cannot be a data frame object.
</p>
<p>For plots of type (3) above, you must use method (a) or (b).
Plot methods (c) and (d) require that both the response and explanatory
variables are specified, i.e. formulas like '~x' or 'y~1' cannot be plotted.
</p>
<p>See below examples to see how each of these methods is applied.
</p>
<p>Multivariate abundance datasets typically have many variables,
more than can be visualised in a single window, so by default plot.mvabund
subsets abundance variables (and where appropriate, environmental variables).
By default the 12 most abundant variables are plotted (determined on transformed
variables if the response is transformed in the mvformula method),
although this setting can be controlled via the argument <code>n.vars</code>, and the
variables included in the subset to be plotted can be controlled via
<code>var.subset</code>. It is possible for example to plot the abundance variables
most significantly associated with an environmental variable,
as in the Solberg example below.
</p>
<p>To produce boxplots rather than dot-plots in type (1) plots, use the argument
<code>type="bx"</code>.
</p>
<p>For type (2) plots, if only one environmental variable is specified, plots for 
different abundance variables are arranged in a rectangular array (different 
abundance variables in different rows and columns). If however more than one
environmental variable is specified, different columns correspond to different
environmental variables (and different abundance variables in different rows).
If more than 3 environmental variables are specified, the 3 will be selected
that maximise average R^2 when <code>manylm</code> is applied (using the subset
selection function <code>best.r.sq</code>). To switch off this subset selection, set
<code>xvar.select=FALSE</code>, or choose your own subset of environmental variables
using <code>xvar.subset</code>.
</p>
<p>To control the appearance of points on dot-plots and scatterplots, usual
arguments apply (see <code>par</code> for details). The plotting symbols <code>pch</code>
and their <code>color</code> can be a vector, and if the plot function is called via
a mvformula object, it can also be a list, where the list elements corresponds
to the symbols / colors used in the plots for different
independent variables. 
</p>
<p>If some of the formula terms are factor variables, these will be drawn in
boxplots.
Note, that the plots produced by <code>plot.mvformula</code>
depend on whether the first independent variable is a factor or not. 
See the examples for the different possibilities of boxplots that can be
produced.
</p>
<p>If two objects are passed and only one of them is an <code>mvabund</code> object,
the resulting plots will be the same as if a formula was supplied, having the
<code>mvabund</code> object as response variable.<br />
If both objects are not <code>mvabund</code> objects, it will be tried to guess which
one of them is the response. The following logic applies:
If <code>y</code> is not a <code>data.frame</code>, it will be assumed that <code>y</code> is the
response. Note that <code>y</code> is the second object, if argument names are not
supplied.
If <code>y</code> is a <code>data.frame</code> and <code>x</code> is not a <code>data.frame</code>,
it will be assumed that <code>x</code> is the response. If both objects are
data frames an error will result, as the function is designed for <code>mvabund</code>
objects!
</p>
<p>The argument <code>shift</code> controls whether or not points are shifted on dotplots 
so that they do not overlap. This argument is ignored for boxplots and
scatterplots (type (2) or type (3) graphs).
</p>


<h3>Warning</h3>

<p>The argument <code>log</code>, that is available in lots of plotting functions can not
be used for plotting <code>mvabund</code> or <code>mvformula</code> objects. Instead use
<code>transformation</code> for the <code>mvabund</code> method and for the
<code>mvformula</code> method include any transformations in the formula.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Yi Wang, Stephen Wright and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton D.I. (2008). Raw data graphing: an informative but under-utilized tool
for the analysis of multivariate abundances. <em>Austral Ecology</em> 33(3), 290-300.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boxplot.mvabund">boxplot.mvabund</a></code>, <code><a href="#topic+meanvar.plot">meanvar.plot</a></code>, <code><a href="#topic+plot.manylm">plot.manylm</a></code>, 
<code><a href="#topic+plot.manyglm">plot.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(graphics)

############################
## Some "type (1)" plots ##
############################

data(solberg)
solbdat &lt;- solberg$abund
treatment&lt;- solberg$x

## Plot a multivariate dataset (Species vs Abundance)
plot.mvabund(solbdat)

## Alternatively, the plot command could be used directly if spiddat is 
## defined as an mvabund object:
solbmvabund &lt;- mvabund(solbdat)
plot(solbmvabund)

## Draw an mvabund object in a boxplot, but using the 20 most abundant 
## variables in the plot, using the square root transform, and adding 
## coloured axes and title:
plot.mvabund(solbdat, n.vars=20, type="bx", transformation="sqrt", 
fg="lightblue", main="Solberg abundances", col.main="red")

## Plot Species (split by treatment) vs Abundance
plot(solbmvabund,treatment)

## This can also be produced using
plot(solbmvabund~treatment)

## To use plot.mvabund to plot only the variables with P-values less than 0.1:
lm.solberg &lt;- manylm(log(solbmvabund+1)~treatment)
anova.solb &lt;- anova(lm.solberg, p.uni="unadjusted")
pj = anova.solb$uni.p

plot(solbmvabund~treatment, var.subset=pj&lt;0.1)

## Or to plot only the 12 most significant variables, according to their 
## univariate ANOVA P-values:
pj.sort = sort(pj, index.return=TRUE)
plot(solbmvabund~treatment, var.subset=pj.sort$ix[1:12])


############################
## Some "type (2)" plots ##
############################
#load and convert data
data(spider)
spiddat &lt;- mvabund(spider$abund)
spidx &lt;- mvabund(spider$x)

#create labels vectors
pch.vec &lt;- as.numeric(spidx[,3]&lt;2)
pch.vec[pch.vec==0] &lt;- 3

#Scale the soil water variable
soilWater &lt;- spidx[,1]

#Create the Table for the main titles of each plot
title &lt;- c("\n\nAlopecosa accentuata", "\n\nAlopecosa cuneata",
           "\n\nAlopecosa fabrilis", "\n\nArctosa lutetiana", 
           "\n\nArctosa perita", "\n\nAulonia albimana", 
           "\n\nPardosa lugubris", "\n\nPardosa monticola", 
           "\n\nPardosa nigriceps", "\n\nPardosa pullata",
           "\n\nTrochosa terricola", "\n\nZora spinimana")

#Plot Species Abundance vs Environmental variable
plot.mvformula(log(spiddat+1) ~ exp(soilWater), main=title, 
xlab="% Soil Moist - Log Scale  ", ylab="Abundance [log scale]", 
overall.main="Species Abundance vs %Soil Moisture", col=pch.vec, 
fg="grey", pch=pch.vec, las=1, scale.lab="ss",t.lab="o", mfrow=c(4,3),log="x")

#Add a Margin
par(xpd=NA)
legend("topright",pch=c(1,3),col=c(1,3),legend = c("few twigs", "many twigs"), 
cex = 1, inset=c(0,-0.19))


############################
## Some "type (3)" plots ##
############################

##Plot 1981 Abundance vs 1983 Abundance
data(tikus)
year &lt;- tikus$x[,1]
tikusdat &lt;- mvabund(tikus$abund)
site &lt;- tikus$x[,2]

plot(tikusdat[year==81,], tikusdat[year==83,], col.main="blue", 
xlab="1981 abundance", ylab="1983 abundance")

</code></pre>

<hr>
<h2 id='plotMvaFactor'>Draw a Mvabund Object split into groups. </h2><span id='topic+plotMvaFactor'></span>

<h3>Description</h3>

<p>Draw the <code>mvabund</code> object <code>x</code> but split the data into
groups according to the grouping variable <code>y</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMvaFactor(x, y, type="p", main="Abundance", n.vars= min(12,NCOL(x)), 
  transformation="log", legend=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMvaFactor_+3A_x">x</code></td>
<td>
<p>a <code>mvabund object</code>, a matrix with multivariate abundance data.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_y">y</code></td>
<td>
<p>a factor or a data.frame with factors, non-factor columns in a
data.frame are ignored.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_type">type</code></td>
<td>
<p>what type of plot should be drawn, allowed types are &quot;p&quot; for
scatterplot, &quot;bx&quot; for boxplot and &quot;n&quot; for no plot. Other types, as used
in <code>par</code> are NOT allowed.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_main">main</code></td>
<td>
<p>the title of the plot, see <code>plot</code>.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_n.vars">n.vars</code></td>
<td>
<p>the number of variables to include in the plot.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_transformation">transformation</code></td>
<td>
<p>an optional transformation, &quot;no&quot; = untransformed,
&quot;sqrt&quot;=square root transformed, &quot;log&quot; (default)=log(Y/min+1) transformed,
&quot;sqrt4&quot; =4th root transformed.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_legend">legend</code></td>
<td>
<p>logical, whether a legend should be added to the plot.</p>
</td></tr>
<tr><td><code id="plotMvaFactor_+3A_...">...</code></td>
<td>
<p>arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each variable in y that is a factor, a plot is drawn. When boxplots are drawn
the colors, that can be supplied by <code>col</code> are used to display different
factor levels.
For scatterplots it is also possible to use the plotting symbols, specified by
<code>pch</code> for that. <br />
</p>
<p>If the colors and for scatterplots the plotting symbols are not supplied,
they will be automatically generated. However, the plotting symbols will only
be automatically used in this way if there are up to seven different levels.
</p>
<p>If colors or the plotting symbols are supplied, but the number of factor levels
is bigger than the the number of different values, they will be replicated.
</p>
<p>Sometimes the legends might be only partially visible, especially when the width
of the graphics device is too small. To fix this, create a graphics device with
a larger width (see help(&quot;device&quot;) for on available devices and their details)
and then repeat the
<code>plotMvaFactor</code> command.
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Yi Wang, Stephen Wright and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Warton, D. I. ( )
<em>Raw data graphing: an informative but under-utilised tool 
for the analysis of multivariate abundances</em>, , .
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mvabund">plot.mvabund</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

## Plot an Environment Factor vs Abundance plot
data(spider)
spiddat &lt;- mvabund(spider$abund)

## Create a Environmental factor where TRUE=Sand, FALSE=No Sand)
X &lt;- as.factor(spider$x$bare.sand&gt;0)
plotMvaFactor(x=spiddat, y=X)
</code></pre>

<hr>
<h2 id='predict.manyglm'>Predict Method for MANYGLM Fits</h2><span id='topic+predict.manyglm'></span>

<h3>Description</h3>

  
<p>Obtains predictions and optionally estimates standard errors of those
predictions from a fitted manyglm object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyglm'
predict(object, newdata, type = c("link", "response",
    "terms"), se.fit = FALSE, dispersion = NULL, terms = NULL,
    na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.manyglm_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from <code>"manyglm"</code>.</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables with
which to predict.  If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_type">type</code></td>
<td>
<p>the type of prediction required.  The default is on the
scale of the linear predictors; the alternative <code>"response"</code>
is on the scale of the response variable.  Thus for a default
binomial model the default predictions are of log-odds (probabilities
on logit scale) and <code>type = "response"</code> gives the predicted
probabilities.  The <code>"terms"</code> option returns a matrix giving the
fitted values of each term in the model formula on the linear predictor
scale.
</p>
<p>The value of this argument can be abbreviated.
</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_se.fit">se.fit</code></td>
<td>
<p>logical switch indicating if standard errors are required.</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_dispersion">dispersion</code></td>
<td>
<p>the dispersion of the MANYGLM fit to be assumed in
computing the standard errors.  If omitted, that returned by
<code>summary</code> applied to the object is used.</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_terms">terms</code></td>
<td>
<p>with <code>type="terms"</code> by default all terms are returned.
A character vector specifies which terms are to be returned</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>. The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.manyglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>predict.manyglm refits the model using glm before making predictions.  In rare (usually pathological) cases this may lead to differences in predictions as compared to what would be expected if using the manyglm coefficients directly.
</p>
<p>If <code>newdata</code> is omitted the predictions are based on the data
used for the fit.  In that case how cases with missing values in the
original fit is determined by the <code>na.action</code> argument of that
fit.  If <code>na.action = na.omit</code> omitted cases will not appear in
the residuals, whereas if <code>na.action = na.exclude</code> they will
appear (in predictions and standard errors), with residual value
<code>NA</code>.  See also <code><a href="stats.html#topic+napredict">napredict</a></code>.
</p>


<h3>Value</h3>

<p>If <code>se = FALSE</code>, a matrix of predictions or an array of 
predictions and bounds.  
If <code>se = TRUE</code>, a list with components
</p>
<table role = "presentation">
<tr><td><code>fit</code></td>
<td>
<p>the predictions</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>estimated standard errors</p>
</td></tr>
<tr><td><code>residual.scale</code></td>
<td>
<p>a scalar giving the square root of the
dispersion used in computing the standard errors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Yi Wang and David Warton &lt;David.Warton@unsw.edu.au&gt;.</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyglm">manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
Y &lt;- spiddat[1:20,]
X &lt;- spider$x[1:20,]
glm.spid.poiss &lt;- manyglm(Y~soil.dry+bare.sand, family="poisson", data=X)
glm.spid.poiss$data = X
newdata &lt;- spider$x[21:28,]
predict(glm.spid.poiss, newdata)
pred.w.plim &lt;- predict(glm.spid.poiss, newdata, interval="prediction")
pred.w.clim &lt;- predict(glm.spid.poiss, newdata, interval="confidence")
</code></pre>

<hr>
<h2 id='predict.manylm'>Model Predictions for Multivariate Linear Models</h2><span id='topic+predict.manylm'></span>

<h3>Description</h3>

<p><code>predict.manylm</code> is a function for predictions from the
result of the model fitting function <code>manylm</code>.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
predict(object, newdata=NULL, se.fit = FALSE, 
    type = c("response", "terms"), terms = NULL, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.manylm_+3A_object">object</code></td>
<td>
<p>object of class inheriting from <code>manylm</code>.</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with which
to predict. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_se.fit">se.fit</code></td>
<td>
<p>a switch indicating if standard errors are required.</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_type">type</code></td>
<td>
<p>type of prediction (response or model term), Possible values:
&quot;response&quot;, &quot;terms&quot;.</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_terms">terms</code></td>
<td>
<p>if type=&quot;terms&quot;, which terms (default is all terms).</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing values in
newdata. The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.manylm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

 <p><code>predict.manylm</code> produces predicted values, obtained by evaluating
the regression function in the frame <code>newdata</code> (which defaults to
<code>model.frame(object)</code>.  If the logical <code>se.fit</code> is
<code>TRUE</code>, standard errors of the predictions are calculated.  If
the numeric argument <code>scale</code> is set (with optional <code>df</code>), it
is used as the residual standard deviation in the computation of the
standard errors, otherwise this is extracted from the model fit.
Setting <code>intervals</code> specifies computation of confidence or
prediction (tolerance) intervals at the specified <code>level</code>, sometimes 
referred to as narrow vs. wide intervals.
</p>
<p>If the fit is rank-deficient, some of the columns of the design matrix
will have been dropped.  Prediction from such a fit only makes sense
if <code>newdata</code> is contained in the same subspace as the original
data.  That cannot be checked accurately, so a warning is issued.
</p>
<p>If <code>newdata</code> is omitted the predictions are based on the data
used for the fit.  In that case how cases with missing values in the
original fit is determined by the <code>na.action</code> argument of that
fit.  If <code>na.action = na.omit</code> omitted cases will not appear in
the residuals, whereas if <code>na.action = na.exclude</code> they will
appear (in predictions, standard errors or interval limits),
with residual value <code>NA</code>.  See also <code><a href="stats.html#topic+napredict">napredict</a></code>.
</p>
<p>The prediction intervals are for a single observation at each case in
<code>newdata</code> (or by default, the data used for the fit) with error
variance(s) <code>pred.var</code>. This can be a multiple of <code>res.var</code>,
the estimated
value of <code class="reqn">\sigma^2</code>: the default is to assume that future
observations have the same error variance as those
used for fitting. If <code>weights</code> is supplied, the inverse of this
is used as a scale factor. For a weighted fit, if the prediction
is for the original data frame, <code>weights</code> defaults to the weights
used for the  model fit, with a warning since it might not be the
intended result. If the fit was weighted and newdata is given, the
default is to assume constant prediction variance, with a warning.
</p>


<h3>Value</h3>

<p><code>predict.manylm</code> produces a matrix of predictions or if <code>interval</code>
is set an array of predictions and bounds, where the first dimension has the names:
<code>fit</code>, <code>lwr</code>, and <code>upr</code>.
If <code>se.fit</code> is <code>TRUE</code>, a list with the following components is returned:
</p>
<table role = "presentation">
<tr><td><code>fit</code></td>
<td>
<p>vector or matrix as above</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>a matrix with the standard errors of the predicted means</p>
</td></tr>
<tr><td><code>residual.scale</code></td>
<td>
<p>vector or matrix as a vector of residual standard deviations</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>numeric, the degrees of freedom for residual</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Variables are first looked for in <code>newdata</code> and then searched for
in the usual way (which will include the environment of the formula
used in the fit).  A warning will be given if the
variables found are not of the same length as those in <code>newdata</code>
if it was supplied.
</p>
<p>Offsets specified by <code>offset</code> in the fit by <code><a href="stats.html#topic+lm">lm</a></code>
will not be included in predictions, whereas those specified by an
offset term in the formula will be.
</p>
<p>Notice that prediction variances and prediction intervals always refer
to <em>future</em> observations, possibly corresponding to the same
predictors as used for the fit. The variance of the <em>residuals</em>
will be smaller.
</p>
<p>Strictly speaking, the formula used for prediction limits assumes that
the degrees of freedom for the fit are the same as those for the
residual variance.  This may not be the case if <code>res.var</code> is
not obtained from the fit. 
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann, Yi Wang and David Warton &lt;David.Warton@unsw.edu.au&gt;.</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund[1:20, ])
dat = spider$x[1:20,]
manylm.fit &lt;- manylm(spiddat~soil.dry+bare.sand, data=dat)
predict(manylm.fit)
predict(manylm.fit, se.fit = TRUE)

new &lt;- spider$x[21:28,]
predict(manylm.fit, new, se.fit = TRUE)

</code></pre>

<hr>
<h2 id='predict.traitglm'>
Predictions from fourth corner model fits</h2><span id='topic+predict.traitglm'></span>

<h3>Description</h3>

<p>Obtains a prediction from a fitted fourth corner model object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'traitglm'
predict(object, newR=NULL, newQ=NULL, newL=NULL, type="response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.traitglm_+3A_object">object</code></td>
<td>

<p>a fitted object of class <code>traitglm</code>.
</p>
</td></tr>
<tr><td><code id="predict.traitglm_+3A_newr">newR</code></td>
<td>

<p>A new data frame of environmental variables. If omitted, the original matrix of environmental variables is used.
</p>
</td></tr>
<tr><td><code id="predict.traitglm_+3A_newq">newQ</code></td>
<td>

<p>A new data frame of traits for each response taxon. If omitted, the original matrix of traits is used.
</p>
</td></tr>
<tr><td><code id="predict.traitglm_+3A_newl">newL</code></td>
<td>

<p>A new data frame of abundances (sites in rows, taxa in columns). This is only used if seeking predicted log-likelihoods. If omitted, the original abundances are used.
</p>
</td></tr>
<tr><td><code id="predict.traitglm_+3A_type">type</code></td>
<td>

<p>The type of prediction required. The default is predictions on the scale of the response variable, alternatives are <code>"logL"</code> for predictive log-likelihood, and &quot;link&quot; for linear predictors.
</p>
</td></tr>
<tr><td><code id="predict.traitglm_+3A_...">...</code></td>
<td>

<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newR</code> and <code>newQ</code> are omitted, then as usual, predictions are based on the data used for the fit. Note that two types of predictions are possible in principle: predicting at new sites (by specifying a new set of environmental variables only, as <code>newR</code>) and predicting for new taxa (by specifying a new set of traits only, as <code>newQ</code>). Unfortunately, only predicting at new sites has been implemented at the moment! An issue with predicting to new taxa is that a main effect is included in the model for each taxon (by default), and the intercept would be unknown for a new species.
</p>
<p>If predictive log-likelihoods are desired, a new data frame of abundances <code>newL</code> would need to be specified, whose rows correspond to those of <code>newR</code> and whose columns correspond to rows of <code>newQ</code>.
</p>


<h3>Value</h3>

<p>A matrix of predictions, with sites in rows and taxa in columns. 
</p>


<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;
</p>


<h3>References</h3>

<p>Brown AM, Warton DI, Andrew NR, Binns M, Cassis G and Gibb H (2014) The fourth corner solution - using species traits to better understand how species traits interact with their environment, Methods in Ecology and Evolution 5, 344-352.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+traitglm">traitglm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(antTraits)

# fit a fourth corner model using negative binomial regression via manyglm:
ft=traitglm(antTraits$abund,antTraits$env,antTraits$traits,method="manyglm")
ft$fourth #print fourth corner terms

# predict to the first five sites
predict(ft, newR=antTraits$env[1:5,])

</code></pre>

<hr>
<h2 id='residuals.manyglm'>Residuals for MANYGLM, MANYANY, GLM1PATH Fits</h2><span id='topic+residuals.manyglm'></span><span id='topic+residuals.manyany'></span><span id='topic+residuals.glm1path'></span>

<h3>Description</h3>

  
<p>Obtains Dunn-Smyth residuals from a fitted <code>manyglm</code>, <code>manyany</code> or <code>glm1path</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyglm'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals.manyglm_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from <code>"manyglm"</code>.</p>
</td></tr>
<tr><td><code id="residuals.manyglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>residuals.manyglm</code> computes Randomised Quantile or &ldquo;Dunn-Smyth&quot; residuals (Dunn &amp; Smyth 1996) for a <code><a href="#topic+manyglm">manyglm</a></code> object. If the fitted model is correct then Dunn-Smyth residuals are standard normal in distribution.
</p>
<p>Similar functions have been written to compute Dunn-Smyth residuals from <code>manyany</code> and <code>glm1path</code> objects.
</p>
<p>Note that for discrete data, Dunn-Smyth residuals involve random number generation, and 
will not return identical results on replicate runs. Hence it is worth calling this function
multiple times to get a sense for whether your interpretation of results holds up under replication.
</p>


<h3>Value</h3>

<p>A matrix of Dunn-Smyth residuals.  
</p>


<h3>Author(s)</h3>

<p>David Warton &lt;David.Warton@unsw.edu.au&gt;.</p>


<h3>References</h3>

<p>Dunn, P.K., &amp; Smyth, G.K. (1996). Randomized quantile residuals. Journal of Computational and
Graphical Statistics 5, 236-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="#topic+manyany">manyany</a></code>, <code><a href="#topic+glm1path">glm1path</a></code>, <code><a href="#topic+plot.manyglm">plot.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

## obtain residuals for Poisson regression of the spider data, and doing a qqplot:
glmP.spid  &lt;- manyglm(spiddat~X, family="poisson")
resP       &lt;- residuals(glmP.spid)
qqnorm(resP)
qqline(resP,col="red")
#clear departure from normality.

## try again using negative binomial regression:
glmNB.spid &lt;- manyglm(spiddat~X, family="negative.binomial")
resNB      &lt;- residuals(glmNB.spid)
qqnorm(resNB)
qqline(resNB,col="red")
#that looks a lot more promising.

#note that you could construct a similar plot directly from the manyglm object using
plot(glmNB.spid, which=2)

</code></pre>

<hr>
<h2 id='ridgeParamEst'>
Estimation of the ridge parameter
</h2><span id='topic+ridgeParamEst'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the ridge parameter by cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridgeParamEst(dat, X, weights = rep(1,times=nRows), refs, 
	tol=1.0e-010, only.ridge=FALSE,  doPlot=FALSE,
	col="blue",type="l", ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ridgeParamEst_+3A_dat">dat</code></td>
<td>
<p>the data matrix.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_x">X</code></td>
<td>
<p>the design matrix.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_weights">weights</code></td>
<td>
<p>weights on the cases of the design matrix.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_refs">refs</code></td>
<td>

<p>a vector specifying validation group membership. Default is to
construct <code>refs</code> using a method that is a function of the sample size <code>N</code>: 
if <code>N&lt;=20</code>, leave-one-out is used <code>refs=1:N</code>, if <code>N&lt;=40</code>, 
10-fold Cross Validation is used where group membership is chosen randomly 
but with equal size groups, otherwise 5-fold CV with random group memberships.
</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_tol">tol</code></td>
<td>
<p>the sensitivity in calculations near zero.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_only.ridge">only.ridge</code></td>
<td>
<p>logical, whether only the ridge Parameters should be passed back or 
additionally the Cross Validation penalised likelihood.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_doplot">doPlot</code></td>
<td>
<p>logical, whether a plot of -2logL vs a candidate for the ridge parameter should be drawn.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_col">col</code></td>
<td>
<p>color of Plot symbols.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_type">type</code></td>
<td>
<p>type of Plot symbols.</p>
</td></tr>
<tr><td><code id="ridgeParamEst_+3A_...">...</code></td>
<td>
<p>further plot arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the ridge parameter when applying ridge regularization to a sample correlation matrix of residuals. The ridge parameter is estimated to maximize the normal likelihood as estimated via cross validation (Warton 2008). 
</p>


<h3>Value</h3>

<p>A list with the following component:
</p>
<table role = "presentation">
<tr><td><code>ridgeParameter</code></td>
<td>

<p>the estimated ridge parameter
</p>
</td></tr>
</table>
<p>If <code>only.ridge=FALSE</code> the returned list additionally contains the element:
</p>
<table role = "presentation">
<tr><td><code>minLL</code></td>
<td>

<p>the minimum of the negative log-likelihood</p>
</td></tr></table>
<p>.
</p>


<h3>Author(s)</h3>

<p>David Warton &lt;David.Warton@unsw.edu.au&gt; and Ulrike Naumann.
</p>


<h3>References</h3>

<p>Warton D.I. (2008). Penalized normal likelihood and ridge regularization of
correlation and covariance matrices. <em>Journal of the American
Statistical Association</em> 103, 340-349.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)
X &lt;- as.matrix(spider$x)

ridgeParamEst(dat = spiddat, X = model.matrix(spiddat~X))
</code></pre>

<hr>
<h2 id='shiftpoints'>Calculate a shift for plotting overlapping points</h2><span id='topic+shiftpoints'></span>

<h3>Description</h3>

<p>Calculate a shift to add to overlapping points in plots for better visibility</p>


<h3>Usage</h3>

<pre><code class='language-R'>shiftpoints(x, y, sh=( max(x)-min(x))/100, centered=TRUE, method=1, reg=6,
na.rm=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shiftpoints_+3A_x">x</code></td>
<td>
<p>a data matrix or numeric vector for use in a plot.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_y">y</code></td>
<td>
<p>a data matrix or numeric vector for use in a plot.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_sh">sh</code></td>
<td>
<p>the maximum total shift.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_centered">centered</code></td>
<td>
<p>logical, whether the shift is centered at 0, if <code>FALSE</code>
the shift will be positive only.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_method">method</code></td>
<td>
<p>numeric, can have the value 1 or 2, see Details.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_reg">reg</code></td>
<td>
<p>numeric, see Details.</p>
</td></tr>
<tr><td><code id="shiftpoints_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether missing values should be removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is similar to <code><a href="base.html#topic+jitter">jitter</a></code> but is defines for points in
a two-dimensional plot. In contrast to <code>jitter</code> only the points with ties
have a shift different from 0. The method to calculate the shift is therefore 
not based on random numbers. <br />
If <code>method=1</code> (default) the individual shift will be selected so that the
shift range is <code>sh</code>, without regard of the number of overlapping points <br />
<code>method=2</code> means that for up to <code>reg</code> overlapping values a fixed
shift of sh/reg is used
</p>


<h3>Value</h3>

<p>Returns an array of shift values with the same dimension
as <code>x</code>. 
</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.mvabund">plot.mvabund</a> </code>, <code><a href="#topic+plot.mvformula">plot.mvformula</a></code>,
<code><a href="base.html#topic+jitter">jitter</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>shiftpoints( x=c(1:5, 1:10), y=c(2:6, 1:10) )
</code></pre>

<hr>
<h2 id='solberg'>Solberg Data</h2><span id='topic+solberg'></span>

<h3>Description</h3>

<p>This dataset contains a list with abundance data of species and a factor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(solberg)
</code></pre>


<h3>Format</h3>

<p>A list containing the elements
</p>

<dl>
<dt>abund</dt><dd><p>a data frame containing 12 rows and has 53 variables, corresponding to the species. It has the following variables:<br />
<code>Paramesacanthion_sp.</code>, <code>Halalaimus_sp.</code>, <code>Viscosia_sp.</code>, <br />
<code>Symplocostoma_sp.</code>, <code>Bathylaimus_inermis</code>, <code>Bathylaimus_sp.</code>,<br />
<code>Rhabdodemania_sp.</code>, <code>Pandolaimus_latilaimus</code>, <code>Halanonchus_sp.</code>
,<br />
<code>Trefusia_sp.</code>, <code>Chromadora_sp.</code>, <code>Dichromadora_sp.</code>,<br />
<code>Neochromadora_sp.</code>, <code>Prochromadorella_sp.</code>, <code>Neotonchus_sp.</code>,<br />
<code>Marylynnia_complexa</code>, <code>Paracanthonchus_sp.</code>, <code>Cyatholaimidae_un
.</code>,<br />
<code>Choniolaimus_papillatus</code>, <code>Halichoanolaimus_dolichurus</code>,<br />
<code>Richtersia_inaequalis</code>, <code>Dorylaimopsis_punctatus</code>,<br />
<code>Sabatieria_longicaudata</code>, <code>Sabatieria_punctata</code>,<br />
<code>Sabatieria_sp.</code>, <code>Setosabieria_hilarula</code>,<br />
<code>Chromaspirina_sp.</code>, <code>Molgolaimus_sp.</code>, <br />
<code>Spirinia_parasitifera</code>, <code>Aponema_torosa</code>, <br />
<code>Microlaimus_sp.1</code>, <code>Microlaimus_sp.2</code>, <code>Camacolaimus_sp.</code>, <br />
<code>Leptolaimus_elegans</code>, <code>Monhystera_sp.</code>,<br />
<code>Amphimonhystera_sp.</code>, <code>Daptonema_sp.1</code>, <code>Daptonema_sp.2</code>, <br />
<code>Daptonema_sp.3</code>, <code>Theristus_aff_acer</code>, <code>Xyalidae_un.</code>,<br />
<code>Sphaerolaimus_macrocirculus</code>, <code>Sphaerolaimus_paradoxus</code>,<br />
<code>Desmolaimus_sp.</code>, <code>Eleutherolaimus_sp.</code>, <code>Eumorpholaimus_sp.</code>,<br />
<code>Terschellingia_longicaudata</code>, <code>Paralinhomoeus_conicaudatus</code>,<br />
<code>Linhomieidae_un.A</code>, <code>Linhomieidae_un.B</code>, <code>Axonolaimus_sp.</code>,<br />
<code>Odontophora_sp.</code>, <code>Unidentified</code>
</p>
</dd>
<dt>x</dt><dd><p>a factor with the levels <code>control</code>, <code>high</code>, <code>low</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The abundance of each species was measured as the count
of the number of organisms in the sample.</p>


<h3>References</h3>

<p>Gee J. M., Warwick R. M., Schaanning M., Berge J. A. and Ambrose W. G. Jr (1985) Effects of organic enrichment on meiofaunal abundance and community structure in sublittoral soft sediments. <em>Journal of Experimental Marine Biology and Ecology</em>. 91(3), 247-262.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(solberg)
solbergdat &lt;- mvabund( solberg$abund )
treatment &lt;- solberg$x

## Create a formula for multivariate abundance data:
foo.sol &lt;- mvformula( solbergdat ~ treatment )

## Fit a multivariate linear model:
lm.solberg &lt;- manylm(foo.sol)
lm.solberg
</code></pre>

<hr>
<h2 id='spider'>Spider data</h2><span id='topic+spider'></span>

<h3>Description</h3>

<p>data from spider2 directory, CANOCO FORTRAN package, with trait variables added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spider)
</code></pre>


<h3>Format</h3>

<p>A list containing the elements
</p>

<dl>
<dt>abund</dt><dd>
<p>A data frame with 28 observations of abundance of 12 hunting spider species</p>
</dd>
<dt>x</dt><dd>
<p>A matrix of six (transformed) environmental variables at each of the 28 sites.
</p>
</dd>
</dl>

<p>The data frame <code>abund</code> has the following variables
</p>

<dl>
<dt>Alopacce</dt><dd><p>(numeric) Abundance of the species Alopecosa accentuata </p>
</dd>
<dt>Alopcune</dt><dd><p>(numeric) Abundance of the species Alopecosa cuneata </p>
</dd>
<dt>Alopfabr</dt><dd><p>(numeric) Abundance of the species Alopecosa fabrilis </p>
</dd>
<dt>Arctlute</dt><dd><p>(numeric) Abundance of the species Arctosa lutetiana </p>
</dd>
<dt>Arctperi</dt><dd><p>(numeric) Abundance of the species Arctosa perita </p>
</dd>
<dt>Auloalbi</dt><dd><p>(numeric) Abundance of the species Aulonia albimana </p>
</dd>
<dt>Pardlugu</dt><dd><p>(numeric) Abundance of the species Pardosa lugubris </p>
</dd>
<dt>Pardmont</dt><dd><p>(numeric) Abundance of the species Pardosa monticola </p>
</dd>
<dt>Pardnigr</dt><dd><p>(numeric) Abundance of the species Pardosa nigriceps </p>
</dd>
<dt>Pardpull</dt><dd><p>(numeric) Abundance of the species Pardosa pullata </p>
</dd>
<dt>Trocterr</dt><dd><p>(numeric) Abundance of the species Trochosa terricola </p>
</dd>
<dt>Zoraspin</dt><dd><p>(numeric) Abundance of the species Zora spinimana </p>
</dd>
</dl>

<p>The matrix <code>x</code> has the following variables
</p>

<dl>
<dt>soil.dry</dt><dd><p>(numeric) Soil dry mass </p>
</dd>
<dt>bare.sand</dt><dd><p>(numeric) Cover bare sand </p>
</dd>
<dt>fallen.leaves</dt><dd><p>(numeric) Cover fallen leaves / twigs </p>
</dd>
<dt>moss</dt><dd><p>(numeric) Cover moss</p>
</dd>
<dt>herb.layer</dt><dd><p>(numeric) Cover herb layer</p>
</dd>
<dt>reflection</dt><dd><p>(numeric) Reflection of the soil surface with a cloudless sky</p>
</dd>
</dl>

<p>These variables have already been log(x+1)-transformed.
</p>
<p>The data frame <code>trait</code> was constructed by Googling each species and recording variables from species descriptions and images of specimens:
</p>

<dl>
<dt>length</dt><dd><p>(numeric) Length (log-transformed), averaged across typical lengths (in centimetres) for male and females</p>
</dd>
<dt>colour</dt><dd><p>(factor) Predominant colour, &quot;yellow&quot; or &quot;dark&quot;</p>
</dd>
<dt>marks</dt><dd><p>(factor) Whether the spider typically has markings on it: &quot;none&quot;, &quot;spots&quot; or &quot;stripes&quot;</p>
</dd>
</dl>



<h3>Details</h3>

<p>The abundance of each species was measured as a count of the number of organisms in the sample.</p>


<h3>Source</h3>

<p>Data attributed to van der Aart &amp; Smeenk-Enserink (1975), obtained from the spider2 directory, CANOCO FORTRAN package. Trait data largely extracted from Wikipedia entries for the species.</p>


<h3>References</h3>

<p>ter Braak, C. J. F. and Smilauer, P.  (1998)  CANOCO reference manual and user's guide to CANOCO for Windows: software for canonical community ordination (version 4). Microcomputer Power, New York, New York, USA.
</p>
<p>van der Aart, P. J. M., and Smeenk-Enserink, N. (1975) Correlations between
distributions of hunting spiders (Lycos- idae, Ctenidae) and environmental
characteristics in a dune area. <em>Netherlands Journal of Zoology</em> <b>25</b>,
1-45.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(spider)
spiddat &lt;- as.mvabund(spider$abund)

plot(spiddat)
</code></pre>

<hr>
<h2 id='summary.manyglm'>Summarizing Multivariate Generalized Linear Model Fits for Abundance Data</h2><span id='topic+summary.manyglm'></span><span id='topic+print.summary.manyglm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class &quot;manyglm&quot;. </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manyglm'
summary(object, resamp="pit.trap", test="wald", 
        p.uni="none", nBoot=999, cor.type=object$cor.type, block=NULL,
        show.cor = FALSE, show.est=FALSE, show.residuals=FALSE,
        symbolic.cor = FALSE,
        rep.seed = FALSE, 
        show.time=FALSE, show.warning=FALSE,...) 
## S3 method for class 'summary.manyglm'
print(x, ...) </code></pre>


<h3>Arguments</h3>

 <table role = "presentation">
<tr><td><code id="summary.manyglm_+3A_object">object</code></td>
<td>
<p>an 
object of class <code>manyglm</code>, typically the result of a call to 
<code><a href="#topic+manyglm">manyglm</a></code>. </p>
</td></tr> <tr><td><code id="summary.manyglm_+3A_resamp">resamp</code></td>
<td>
<p>the method of resampling used. Can be 
one of &quot;case&quot;, &quot;perm.resid&quot;, &quot;montecarlo&quot; or &quot;pit.trap&quot; (default). See 
Details.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_test">test</code></td>
<td>
<p>the test to be used. If <code>cor.type="I"</code>, this can be 
one of &quot;wald&quot; for a Wald-Test or &quot;score&quot; for a Score-Test or &quot;LR&quot; for a 
Likelihood-Ratio-Test, otherwise only &quot;wald&quot; and &quot;score&quot; is allowed. The 
default value is &quot;LR&quot;. </p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_p.uni">p.uni</code></td>
<td>
<p>whether to calculate univariate test 
statistics and their P-values, and if so, what type. This can be one of the 
following options. <br /> &quot;none&quot; = No univariate P-values (default) <br /> 
&quot;unadjusted&quot; = A test statistic and (ordinary unadjusted) P-value are 
reported for each response variable. <br /> &quot;adjusted&quot; = Univariate P-values are 
adjusted for multiple testing, using a step-down resampling procedure. </p>
</td></tr> 
<tr><td><code id="summary.manyglm_+3A_nboot">nBoot</code></td>
<td>
<p>the number of Bootstrap iterations, default is 
<code>nBoot=999</code>.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_cor.type">cor.type</code></td>
<td>
<p>structure imposed on the estimated correlation matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;. See Details.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_block">block</code></td>
<td>
<p>A factor specifying the sampling level to be resampled. Default is resampling rows.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_show.cor">show.cor</code>, <code id="summary.manyglm_+3A_show.est">show.est</code>, <code id="summary.manyglm_+3A_show.residuals">show.residuals</code></td>
<td>
<p>logical, if <code>TRUE</code>, 
the correlation matrix of the estimated parameters, or the estimated model 
parameters, or the residual summary is shown.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical. If <code>TRUE</code>, the correlation is printed in a symbolic form (see 
<code><a href="stats.html#topic+symnum">symnum</a></code> ) rather than in numerical format. </p>
</td></tr> 
<tr><td><code id="summary.manyglm_+3A_rep.seed">rep.seed</code></td>
<td>
<p>logical. Whether to fix random seed in resampling data. Useful for simulation or diagnostic purposes.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_show.time">show.time</code></td>
<td>
<p>Whether to display timing information for the resampling 
procedure: &quot;none&quot; shows none, &quot;all&quot; shows all timing information and &quot;total&quot; 
shows only the overall time taken for the tests. </p>
</td></tr> 
<tr><td><code id="summary.manyglm_+3A_show.warning">show.warning</code></td>
<td>
<p>logical. Whether to display warnings in the operation 
procedure.</p>
</td></tr>
<tr><td><code id="summary.manyglm_+3A_...">...</code></td>
<td>
<p>for <code>summary.manyglm</code> method, these are 
additional arguments including: <br /> <code>rep.seed</code> - logical. Whether to fix 
random seed in resampling data. Useful for simulation or diagnostic 
purposes.<br /> <code>bootID</code> - this matrix should be integer numbers where each 
row specifies bootstrap id's in each resampling run. When <code>bootID</code> is 
supplied, <code>nBoot</code> is set to the number of rows in <code>bootID</code>. Default 
is <code>NULL</code>.<br /> for <code>print.summary.manyglm</code> method, these are 
optional further arguments passed to or from other methods. See 
<code><a href="stats.html#topic+print.summary.glm">print.summary.glm</a></code> for more details.</p>
</td></tr> <tr><td><code id="summary.manyglm_+3A_x">x</code></td>
<td>
<p>an object of 
class &quot;summary.manyglm&quot;, usually, a result of a call to 
<code>summary.manyglm</code>.</p>
</td></tr> </table>


<h3>Details</h3>

<p> The <code>summary.manyglm</code> function returns a table summarising the 
statistical significance of each multivariate term specified in the fitted 
manyglm model (Warton 2011). For each model term, it returns a test 
statistic as determined by the argument <code>test</code>, and a P-value calculated 
by resampling rows of the data using a method determined by the argument 
<code>resamp</code>. Of the four possible resampling methods, three (case, residual 
permutation and parametric boostrap) are described in more detail in Davison 
and Hinkley (1997, chapter 6), but the default (PIT-trap) is a new method (in 
review) which bootstraps probability integral transform residuals, and which 
we have found to give the most reliable Type I error rates. All methods 
involve resampling under the alternative hypothesis. These methods ensure 
approximately valid inference even when the mean-variance relationship or the 
correlation between variables has been misspecified. Standardized pearson 
residuals (see <code><a href="#topic+manyglm">manyglm</a></code> are currently used in residual 
permutation, and where necessary, resampled response values are truncated so 
that they fall in the required range (e.g. counts cannot be negative). 
However, this can introduce bias, especially for <code>family=binomial</code>, so 
we advise extreme caution using <code>perm.resid</code> for presence/absence data. 
If <code>resamp="none"</code>, p-values cannot be calculated, however the test 
statistics are returned. 
</p>
<p>If you have a specific hypothesis of primary interest that you want to test, then you should use the <code><a href="#topic+anova.manyglm">anova.manyglm</a></code> function, which can resample rows of the data under the null hypothesis and so usually achieves a better approximation to the true significance level.
</p>
<p>For information on the different types of data that can be modelled using manyglm, see <code><a href="#topic+manyglm">manyglm</a></code>. To check model assumptions, use <code><a href="#topic+plot.manyglm">plot.manyglm</a></code>.
</p>
<p>Multivariate test statistics are constructed using one of three methods: a log-likelihood ratio statistic <code>test="LR"</code>, for example as in Warton et. al. (2012), or a Wald statistic <code>test="wald"</code> or a Score statistic <code>test="score"</code>. &quot;LR&quot; has good properties, but is only available when <code>cor.type="I"</code>.
</p>
<p>The default Wald test statistic makes use of a generalised estimating equations (GEE) approach, estimating the covariance matrix of parameter estimates using a sandwich-type estimator that assumes the mean-variance relationship in the data is correctly specified and that there is an unknown but constant correlation across all observations. Such assumptions allow the test statistic to account for correlation between variables but to do so in a more efficient way than traditional GEE sandwich estimators (Warton 2008a). The common correlation matrix is estimated from standardized Pearson residuals, and the method specified by <code>cor.type</code> is used to adjust for high dimensionality.
</p>
<p>The Wald statistic has problems for count data and presence-absence 
data when there are estimated means at zero (which usually means very large parameter estimates, check for this using <code>coef</code>). In such instances Wald statistics should not be used, Score or LR should do the job. 
</p>
<p>The <code>summary.manyglm</code> function is designed specifically for high-dimensional data (that, is when the number of variables p is not small compared to the number of observations N). In such instances a correlation matrix is computationally intensive to estimate and is numerically unstable, so by default the test statistic is calculated assuming independence of variables (<code>cor.type="I"</code>). Note however that the resampling scheme used ensures that the P-values are approximately correct even when the independence assumption is not satisfied. However if it is computationally feasible for your dataset, it is recommended that you use <code>cor.type="shrink"</code> to account for correlation between variables, or <code>cor.type="R"</code> when p is small. The <code>cor.type="R"</code> option uses the unstructured correlation matrix (only possible when N&gt;p), such that the standard classical multivariate test statistics are obtained. Note however that such statistics are typically numerically unstable and have low power when p is not small compared to N. 
</p>
<p>The <code>cor.type="shrink"</code> option applies ridge regularisation (Warton (2008b)), shrinking the sample correlation matrix towards the identity, which improves its stability when p is not small compared to N. This provides a compromise between <code>"R"</code> and <code>"I"</code>, allowing us to account for correlation between variables, while using a numerically stable test statistic that has good properties. 
</p>
<p>The shrinkage parameter is an attribute of the <code><a href="#topic+manyglm">manyglm</a></code> object. For a Wald test, the sample correlation matrix of the alternative model is used to calculate the test statistics. So <code>object$shrink.param</code> is used. For a Score test, the sample correlation matrix of the null model is used to calculate the test statistics. So <code>shrink.param</code> of the null model is used instead. If <code>cor.type=="shrink"</code> but <code>object$shrink.param</code> is not available, for example <code>object$cor.type!="shrink"</code>, then the shrinkage parameter will be estimated by cross-validation using the multivariate normal likelihood function (see <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code> and (Warton 2008b)) in the summary test.
</p>
<p>Rather than stopping after testing for multivariate effects, it is often of interest to find out which response variables express significant effects. Univariate statistics are required to answer this question, and these are reported if requested. Setting <code>p.uni="unadjusted"</code> returns resampling-based univariate P-values for all effects as well as the multivariate P-values, whereas <code>p.uni="adjusted"</code> returns adjusted P-values (that have been adjusted for multiple testing), calculated using a step-down resampling algorithm as in Westfall &amp; Young (1993, Algorithm 2.8). This method provides strong control of family-wise error rates, and makes use of resampling (using the method controlled by <code>resamp</code>) to ensure inferences take into account correlation between variables.
</p>


<h3>Value</h3>

<p>summary.manyglm returns an object of class &quot;summary.manyglm&quot;, a list with components 
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms object used.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Akaike's <em>An Information Criterion</em>, minus twice the 
maximized log-likelihood plus twice the number of coefficients 
(except for negative binomial and quasipoisson family, assuming 
that the dispersion is known).</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>devll</code></td>
<td>
<p>minus twice the maximized log-likelihood</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations that were used in
<code><a href="#topic+manyglm">manyglm</a></code> for the estimation
of the model parameters.</p>
</td></tr>
<tr><td><code>p.uni</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>nBoot</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>resample</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>the na.action used in the <code>manyglm</code> object,
if applicable</p>
</td></tr>
<tr><td><code>show.residuals</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>show.est</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>compositional</code></td>
<td>
<p>logical. Whether a test for 
compositional effects was performed.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>cor.type</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the method used in <code>manyglm</code>. Either <code>"glm.fit"</code> or
<code>"manyglm.fit"</code></p>
</td></tr>
<tr><td><code>theta.method</code></td>
<td>
<p>the method used for the estimation of the nuisance parameter
theta.</p>
</td></tr>
<tr><td><code>manyglm.args</code></td>
<td>
<p>a list of control parameters from <code>manyglm</code>.</p>
</td></tr>
<tr><td><code>rankX</code></td>
<td>
<p>the rank of the design matrix.</p>
</td></tr>
<tr><td><code>covstat</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>deviance.resid</code></td>
<td>
<p>the deviance residuals.</p>
</td></tr>
<tr><td><code>est</code></td>
<td>
<p>the estimated model coefficients</p>
</td></tr>
<tr><td><code>s.err</code></td>
<td>
<p>the Scaled Variance</p>
</td></tr>
<tr><td><code>shrink.param</code></td>
<td>

<p>the shrinkage parameter. Either the value of the argument with the same name or
if this was not supplied the estimated shrinkage parameter.
</p>
</td></tr>
<tr><td><code>n.bootsdone</code></td>
<td>
<p>the number of bootstrapping iterations that were done, i.e.
had no error.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>

<p>the matrix of coefficients, standard errors,
z-values and p-values.  Aliased coefficients are omitted.
</p>
</td></tr>
<tr><td><code>stat.iter</code></td>
<td>
<p>if the argument <code>stat.iter</code> is set to <code>TRUE</code> 
the test statistics in the resampling iterations.</p>
</td></tr>
<tr><td><code>statj.iter</code></td>
<td>
<p>if the argument <code>stat.iter</code> is set to <code>TRUE</code>
the univariate test statistics in the resampling iterations.</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>named logical vector showing if the original coefficients are aliased.</p>
</td></tr> 
<tr><td><code>dispersion</code></td>
<td>
<p>either the supplied argument or the inferred/estimated
dispersion if the latter is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>a 3-vector of the rank of the model and the number of residual degrees
of freedom, plus number of non-aliased coefficients.
</p>
</td></tr>
<tr><td><code>overall.n.bootsdone</code></td>
<td>

<p>the number of bootstrap iterations without errors that were done in the
overall test
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>a table containing test statistics, p values and degrees
of freedom for the overall test</p>
</td></tr>
<tr><td><code>overall.stat.iter</code></td>
<td>
<p>if the argument <code>stat.iter</code> is set to <code>TRUE</code>
the test statistics of the overall tests in the resampling iterations.</p>
</td></tr>
<tr><td><code>overall.statj.iter</code></td>
<td>
<p>if the argument <code>stat.iter</code> is set to <code>TRUE</code>
the univariate test statistics of the overall tests 
in the resampling iterations.</p>
</td></tr>
<tr><td><code>cov.unscaled</code></td>
<td>

<p>the unscaled (<code>dispersion = 1</code>) estimated covariance matrix of the
estimated coefficients.
</p>
</td></tr>
<tr><td><code>cov.scaled</code></td>
<td>
<p>ditto, scaled by <code>dispersion</code>.</p>
</td></tr>
<tr><td><code>correlation</code></td>
<td>

<p>(only if the argument <code>show.cor = TRUE</code>.) The estimated correlations
of the estimated coefficients.
</p>
</td></tr>
<tr><td><code>symbolic.cor</code></td>
<td>

<p>(only if <code>show.cor = TRUE</code>.) The value of the argument <code>symbolic.cor</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yi Wang, David Warton &lt;David.Warton@unsw.edu.au&gt; and Ulrike Naumann.
</p>


<h3>References</h3>

<p>Warton D.I. (2011). Regularized sandwich estimators for analysis of high dimensional data using generalized estimating equations. <em>Biometrics</em>, 67(1), 116-123.
</p>
<p>Warton D.I. (2008a). Penalized normal likelihood and ridge regularization of 
correlation and covariance matrices. <em>Journal of the American Statistical 
Association</em> 103, 340-349.
</p>
<p>Warton D.I. (2008b). Which Wald statistic?  Choosing a parameterisation of the 
Wald statistic to maximise power in <em>k</em>-sample generalised estimating 
equations. <em>Journal of Statistical Planning and Inference</em>, 138, 3269-3282.
</p>
<p>Warton D. I., Wright S., and Wang, Y. (2012). Distance-based multivariate analyses confound location and dispersion effects. <em>Methods in Ecology and Evolution</em>, 3(1), 89-101.
</p>
<p>Davison, A. C. and Hinkley, D. V. (1997) <em>Bootstrap Methods and their Application</em>,
Cambridge University Press, Cambridge.
</p>
<p>Westfall, P. H. and Young, S. S. (1993) <em>Resampling-based multiple testing.</em> 
John Wiley &amp; Sons, New York.
</p>
<p>Wu, C. F. J. (1986) Jackknife, Bootstrap and Other Resampling Methods in
Regression Analysis.
<em>The Annals of Statistics</em> 14:4, 1261-1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="#topic+anova.manyglm">anova.manyglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- mvabund(spider$abund)

## Estimate the coefficients of a multivariate glm
glm.spid &lt;- manyglm(spiddat[,1:3]~., data=spider$x, family="negative.binomial")

## Estimate the statistical significance of different multivariate terms in 
## the model, using the default settings of LR test, and 100 PIT-trap resamples
summary(glm.spid, show.time=TRUE) 

## Repeat with the parametric bootstrap and wald statistics 
summary(glm.spid, resamp="monte.carlo", test="wald", nBoot=300) 

</code></pre>

<hr>
<h2 id='summary.manylm'>Summarizing Linear Model Fits for Multivariate Abundance Data</h2><span id='topic+summary.manylm'></span><span id='topic+print.summary.manylm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class &quot;manylm&quot; - computes a table 
summarising the statistical significance of different multivariate terms 
in a linear model fitted to high-dimensional data, such as multivariate 
abundance data in ecology.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'manylm'
summary(object, nBoot=999, resamp="residual", 
   test="F", cor.type=object$cor.type, block=NULL, shrink.param=NULL, 
   p.uni="none", studentize=TRUE, R2="h", show.cor = FALSE, 
   show.est=FALSE, show.residuals=FALSE, symbolic.cor=FALSE, 
   rep.seed=FALSE, tol=1.0e-6, ... )
  
## S3 method for class 'summary.manylm'
print(
   x, digits = max(getOption("digits") - 3, 3), 
   signif.stars=getOption("show.signif.stars"), 
   dig.tst=max(1, min(5, digits - 1)), 
   eps.Pvalue=.Machine$double.eps, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.manylm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;manylm&quot;, usually, a result of a call to
<code><a href="#topic+manylm">manylm</a></code>.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_nboot">nBoot</code></td>
<td>
<p>the number of Bootstrap iterations, default is <code>nBoot=999</code>.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_resamp">resamp</code></td>
<td>
<p>the method of resampling used. Can be one of &quot;case&quot; (not yet available),&quot;residual&quot; (default), &quot;perm.resid&quot;, &quot;score&quot; or &quot;none&quot;. See Details.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_test">test</code></td>
<td>
<p> the test to be used. Possible values are: &quot;LR&quot; = likelihood ratio statistic (default) and &quot;F&quot; = Lawley-Hotelling trace statistic.<br />
Note that if all variables are assumed independent (<code>cor.shrink="I"</code>) then &quot;LR&quot; is equivalent to LR-IND and &quot;F&quot; is the sum-of-F statistics from Warton &amp; Hudson (2004).</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_cor.type">cor.type</code></td>
<td>
<p> structure imposed on the estimated correlation matrix under the fitted model. Can be &quot;I&quot;(default), &quot;shrink&quot;, or &quot;R&quot;. See Details.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_block">block</code></td>
<td>
<p>A factor specifying the sampling level to be resampled. Default is resampling rows.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_shrink.param">shrink.param</code></td>
<td>
<p>shrinkage parameter to be used if <code>cor.type="shrink"</code>. If not supplied, but needed, it will be estimated from the data by Cross
Validation using the normal likelihood as in Warton (2008).</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_p.uni">p.uni</code></td>
<td>
<p>whether to calculate univariate test statistics and their P-values, and if so, what type. <br />
&quot;none&quot; = no univariate P-values (default) <br />
&quot;unadjusted&quot; = a test statistic and (ordinary unadjusted) P-value is reported
for each response variable. <br />
&quot;adjusted&quot; = Univariate P-values are adjusted for multiple testing, using a
step-down resampling procedure.
</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_studentize">studentize</code></td>
<td>
<p>logical, whether studentized residuals or residuals should beused for simulation in the resampling steps. This option is not used in case resampling. </p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_r2">R2</code></td>
<td>

<p>the type of R^2 (correlation coefficient) that should be shown, can be one of: <br />
&quot;h&quot; = Hooper's R^2 = tr(SST^(-1)SSR)/p   <br />
&quot;v&quot; = vector R^2 = det(SSR)/det(SST)<br />
&quot;n&quot; = none
</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_show.cor">show.cor</code></td>
<td>

<p>logical, if <code>TRUE</code>, the correlation matrix of the estimated parameters is
returned and printed.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_show.est">show.est</code></td>
<td>
<p>logical. Whether to show the estimated model parameters.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_show.residuals">show.residuals</code></td>
<td>
<p>logical. Whether to show residuals/a residual summary.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical. If <code>TRUE</code>, print the correlations in a symbolic form rather than as numbers.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_rep.seed">rep.seed</code></td>
<td>
<p>logical. Whether to fix random seed in resampling data. Useful for simulation or diagnostic purposes.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_tol">tol</code></td>
<td>
<p>the tolerance used in estimations.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.manylm"</code>, usually, a result of a call to <code>summary.manylm</code>.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If <code>TRUE</code>, &lsquo;significance stars&rsquo; are printed for each coefficient.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_dig.tst">dig.tst</code></td>
<td>
<p>the number of digits to round the estimates of the model parameters.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_eps.pvalue">eps.Pvalue</code></td>
<td>
<p>a numerical tolerance for the formatting of p values.</p>
</td></tr>
<tr><td><code id="summary.manylm_+3A_...">...</code></td>
<td>
<p>for <code>summary.manyglm</code> method, these are additional arguments including: <br />
<code>bootID</code> - this matrix should be integer numbers where each row specifies bootstrap id's in each resampling run. When <code>bootID</code> is supplied, <code>nBoot</code> is set to the number of rows in <code>bootID</code>. Default is <code>NULL</code>.<br />
for <code>print.summary.manyglm</code> method, these are optional further arguments passed to or from other methods. See <code><a href="stats.html#topic+print.summary.glm">print.summary.glm</a></code> for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The <code>summary.manylm</code> function returns a table summarising the statistical 
significance of each multivariate term specified in the fitted manylm model. 
For each model term, it returns a test statistic as determined by the argument 
<code>test</code>, and a P-value calculated by resampling rows of the data using a 
method determined by the argument <code>resamp</code>. The four possible resampling methods are residual-permutation (Anderson and Robinson (2001)), score resampling (Wu (1986)), case and residual resampling (Davison and Hinkley (1997, chapter 6)), and involve resampling under the alternative hypothesis. These methods ensure approximately valid inference even when the correlation between variables has been misspecified, and for case and score resampling, even when the equal variance assumption of linear models is invalid. By default, studentized residuals (r_i/sqrt(1-h_ii)) are used in residual and score resampling, although raw residuals could be used via the argument <code>studentize=FALSE</code>. If <code>resamp="none"</code>, p-values cannot be calculated, however the test statistics are returned.
</p>
<p>If you have a specific hypothesis of primary interest that you want to test,
then you should use the <code>anova.manylm</code> function, which can resample rows
of the data under the null hypothesis and so usually achieves a better
approximation to the true significance level.
</p>
<p>To check model assumptions, use <code>plot.manylm</code>.
</p>
<p>The <code>summary.manylm</code> function is designed specifically for high-dimensional data (that, is when the number of variables p is not small compared to the number of observations N). In such instances a correlation matrix is computationally intensive to estimate and is numerically unstable, so by default the test statistic is calculated assuming independence of variables (<code>cor.type="I"</code>). Note however that the resampling scheme used ensures that the P-values are approximately correct even when the independence assumption is not satisfied. However if it is computationally feasible for your dataset, it is recommended that you use <code>cor.type="shrink"</code> to account for correlation between variables, or <code>cor.type="R"</code> when p is small. The <code>cor.type="R"</code> option uses the unstructured correlation matrix (only possible when N&gt;p), such that the standard classical multivariate test statistics are obtained. Note however that such statistics are typically numerically unstable and have low power when p is not small compared to N. The <code>cor.type="shrink"</code> option applies ridge regularisation (Warton 2008), shrinking the sample correlation matrix towards the identity, which improves its stability when p is not small compared to N. This provides a compromise between <code>"R"</code> and <code>"I"</code>, allowing us to account for correlation between variables, while using a numerically stable test statistic that has good properties. The shrinkage parameter by default is estimated by cross-validation using the multivariate normal likelihood function, although it can be specified via <code>shrink.param</code> as any value between 0 and 1 (0=&quot;I&quot; and 1=&quot;R&quot;, values closer towards 0 indicate more shrinkage towards &quot;I&quot;). The validation groups are chosen by random assignment and so you may observe some slight variation in the estimated shrinkage parameter in repeat analyses. See <code><a href="#topic+ridgeParamEst">ridgeParamEst</a></code> for more details.
</p>
<p>Rather than stopping after testing for multivariate effects, it is often of interest to find out which response variables express significant effects. Univariate statistics are required to answer this question, and these are reported if requested. Setting <code>p.uni="unadjusted"</code> returns resampling-based univariate P-values for all effects as well as the multivariate P-values, whereas  <code>p.uni="adjusted"</code> returns adjusted P-values (that have been adjusted for multiple testing), calculated using a step-down resampling algorithm as in Westfall &amp; Young (1993, Algorithm 2.8). This method provides strong control of family-wise error rates, and makes use of resampling (using the method controlled by <code>resample</code>) to ensure inferences take into account correlation between variables.
</p>
<p>A multivariate R^2 value is returned in output, but there are many ways to define a multivariate R^2. The type of R^2 used is controlled by the <code>R2</code> argument. If <code>cor.shrink="I"</code> then all variables are assumed independent, a special case in which Hooper's R^2 returns the average of all univariate R^2 values, whereas the vector R^2 returns their product. 
</p>
<p><code>print.summary.manylm</code> tries to be smart about formatting the coefficients, <code>genVar</code>, etc. and additionally gives &lsquo;significance stars&rsquo; if
<code>signif.stars</code> is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>summary.manylm returns an object of class &quot;summary.manyglm&quot;, a list with components 
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>the component from <code>object</code>.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms object used.</p>
</td></tr>
<tr><td><code>show.residuals</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>show.est</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>p.uni</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>cor.type</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>resample</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>nBoot</code></td>
<td>
<p>the supplied argument.</p>
</td></tr>
<tr><td><code>rankX</code></td>
<td>
<p>the rank of the design matrix</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the model residuals</p>
</td></tr>
<tr><td><code>genVar</code></td>
<td>
<p>the estimated generalised variance</p>
</td></tr>
<tr><td><code>est</code></td>
<td>
<p>the estimated model coefficients</p>
</td></tr>
<tr><td><code>shrink.param</code></td>
<td>

<p>the shrinkage parameter. Either the value of the argument with the same name or
if this was not supplied the estimated shrinkage parameter.
</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>named logical vector showing if the original coefficients are
aliased.</p>
</td></tr> 
<tr><td><code>df</code></td>
<td>
<p> a 3-vector of the rank of the model and the number of residual degrees of freedom, plus number of non-aliased coefficients.</p>
</td></tr>
</table>
<p>If the argument <code>test</code> is not <code>NULL</code> then the list also
included the components
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>a matrix containing the test statistics and the p-values.</p>
</td></tr>
<tr><td><code>n.iter.sing</code></td>
<td>
<p>the number of iterations that were skipped due to singularity of the design matrix caused by case resampling.</p>
</td></tr>
</table>
<p>If furthermore the Design matrix is neither empty nor consists of the Intercept only, the following adddional components are included:
</p>
<table role = "presentation">
<tr><td><code>r.squared</code></td>
<td>
<p>the calculated correlation coefficient.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>a character that describes which type of correlation coefficient was
calculated.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>a matrix containing the results of the overall test.</p>
</td></tr>
<tr><td><code>cov.unscaled</code></td>
<td>

<p>the unscaled (<code>dispersion = 1</code>) estimated covariance matrix of the
estimated coefficients.
</p>
</td></tr>
</table>
<p>If the argument <code>show.cor</code> is <code>TRUE</code> the following adddional
components are returned:
</p>
<table role = "presentation">
<tr><td><code>correlation</code></td>
<td>
<p>the (p*q) by (p*q) correlation matrix, with p being the
number of columns of the design matrix and q being the number of response
variables. Note that this matrix can be very big.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yi Wang, Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>References</h3>

<p>Anderson, M.J. and J. Robinson (2001).
Permutation tests for linear models.
<em>Australian and New Zealand Journal of Statistics</em> 43, 75-88.
</p>
<p>Davison, A. C. and Hinkley, D. V. (1997)
<em>Bootstrap Methods and their Application.</em>
Cambridge University Press, Cambridge.
</p>
<p>Warton D.I. (2008). Penalized normal likelihood and ridge regularization of 
correlation and covariance matrices. <em>Journal of the American Statistical 
Association</em> 103, 340-349.
</p>
<p>Warton D.I. and Hudson H.M. (2004). A MANOVA statistic is just as powerful as
distance-based statistics, for multivariate abundances. 
<em>Ecology</em> 85(3), 858-874.
</p>
<p>Westfall, P. H. and Young, S. S. (1993) <em>Resampling-based multiple 
testing.</em> John Wiley &amp; Sons, New York.
</p>
<p>Wu, C. F. J. (1986) Jackknife, Bootstrap and Other Resampling Methods in
Regression Analysis.
<em>The Annals of Statistics</em> 14:4, 1261-1295.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manylm">manylm</a></code>, <code><a href="#topic+anova.manylm">anova.manylm</a></code>, <code><a href="#topic+plot.manylm">plot.manylm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spider)
spiddat &lt;- log(spider$abund+1)

## Estimate the coefficients of a multivariate linear model:
fit &lt;- manylm(spiddat~., data=spider$x)

## To summarise this multivariate fit, using score resampling to
## and F Test statistic to estimate significance:
summary(fit, resamp="score", test="F")

## Instead using residual permutation with 2000 iteration, using the sum of F 
## statistics to estimate multivariate significance, but also reporting 
## univariate statistics with adjusted P-values:
summary(fit, resamp="perm.resid", nBoot=2000, test="F", p.uni="adjusted")

## Obtain a summary of test statistics using residual resampling, accounting 
## for correlation between variables but shrinking the correlation matrix to 
## improve its stability and showing univariate p-values:
summary(fit, cor.type="shrink", p.uni="adjusted")

</code></pre>

<hr>
<h2 id='Tasmania'>Tasmania Dataset</h2><span id='topic+Tasmania'></span>

<h3>Description</h3>

<p>This dataset contains a list with community abundance data of species and two factor variables, namely treatment and block. See (Warwick et.al. (1990)) for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Tasmania)
</code></pre>


<h3>Format</h3>

<p>A list containing the elements
</p>

<dl>
<dt>abund</dt><dd><p>A data frame with 16 observations of 56 Meiobenthos species exposed to a disturbance treatment in a spatially blocked design. Four blocks of four samples were collected such that each block comprised of two disturbed and undisturbed samples.</p>
</dd>
<dt>copepods</dt><dd><p>A subset of <code>abund</code> of 12 Copepod species.</p>
</dd>
<dt>nematodes</dt><dd><p>A subset of <code>abund</code> of 39 Nematode species.</p>
</dd>
<dt>treatment</dt><dd><p>A two-level factor veraible.</p>
</dd>
<dt>block</dt><dd><p>A four-level factor variable.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The count data (number of each Meiobenthos species in each sample) were collected in a spatia
lly blocked design. The labels are made to the four replicate cores within each block,
with <code>B</code> labeling for the block ID and <code>D</code> labeling for the disturbed sample ID and <code>U</code> labeling for the undisturbed sample ID. The data frame <code>abund</code> contains 12 Copepod species, 39 Nematode species and 4 undetermined ones.
</p>
<p>The 12 Copepod species are: <br />
Ameira,      Adopsyllus,  Ectinosoma,  Ectinosomat, Haloschizo,<br />
Lepta.A,     Lepta.B,     Lepta.C,     Mictyricola, Parevansula,<br />
Quin,        Rhizothrix<br />
</p>
<p>The 39 Nematode species are: <br />
Actinonema,        Axonolaimus,       Bathylaimus, <br />
Calyptronema,      Chaetonema,        Chromaspirina, <br />
Comesoma,          Daptonema,         Desmodora.A, <br />
Desmodora.B,       Enoploides,        Enoplus, <br />
Epacanthion.A,     Epacanthion.B,     Eubostrichus, <br />
Eurystomina,       Hypodontolaimus.A, Hypodontolaimus.B, <br />
Leptolaimus,       Leptonemella,      Mesacanthion, <br />
Microlaimus,       Monhystera,        Nannoluimoides.A, <br />
Nannolaimoides.B,  Neochromadora.A,   Neochromadora.B, <br />
Odontophora,       Oncholaimus,       Qnvx, <br />
Paracanthonchus,   Polysigma,         Praeacanthenchus, <br />
Promonhystera,     Pseudosteineria,   Sabatieria, <br />
Spilophorella,     Symplocostoma,     Viscosia <br />
</p>
<p>The data frame <code>copepod</code> stores the subset of 12 Copepod species, and the data frame <code>nematode</code> stores the subset of 39 Nematode species.
</p>
<p><code>treatment</code> indicates disturbed or undisturbed treatment for the 16 observations of each species in the Tasmania dataset.
</p>
<p><code>block</code> indicates the block ID for the 16 observations of each species in the Tasmania dataset.
</p>


<h3>References</h3>

<p>Warwick, R. M., Clarke, K. R. and Gee, J. M. (1990). The effect of disturbance by soldier crabs Mictyris platycheles H. Milne Edwards on meiobenthic communiy structure. <em>J. Exp. Mar. Biol. Ecol.</em>, <b>135</b>, 19-33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(Tasmania)
tasm.cop &lt;- mvabund(Tasmania$copepods)
treatment &lt;- Tasmania$treatment
block &lt;- Tasmania$block

plot(tasm.cop~block*treatment)

</code></pre>

<hr>
<h2 id='tikus'>Tikus Island Dataset</h2><span id='topic+tikus'></span>

<h3>Description</h3>

<p>This dataset contains a list with abundance data of species at different locations
in the Tikus island and explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tikus)
</code></pre>


<h3>Format</h3>

<p>A list containing the elements
</p>

<dl>
<dt>abund</dt><dd><p>A data frame with 60 observations at different locations
of abundances on 75 variables, the species. See Details.
</p>
</dd>
<dt>x</dt><dd><p>A data frame containing the id information for the Tikus island dataset.
The data frame has 60 observations on 2 variables. See Details.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The abundance of each species was measured as the length (in centimetres) of a
10 metre transect which intersected with the species.
</p>
<p><code>tikus</code> is a list containing the elements <code>abund</code> and <code>x</code>.
The data frame <code>abund</code> contains 75 variables, the species:
</p>
<p>Psammocora contigua, Psammocora digitata, Pocillopora damicornis,
Pocillopora verrucosa, Stylopora pistillata, Acropora bruegemanni,
Acropora robusta, Acropora grandis, Acropora intermedia,
Acropora formosa, Acropora splendida, Acropera aspera,
Acropora hyacinthus, Acropora palifera, Acropora cytherea,
Acropora tenuis, Acropora pulchra, Acropora nasuta,
Acropora humilis, Acropora diversa, Acropora digitifera,
Acropora divaricata, Acropora subglabra, Acropora cerealis,
Acropora valida, Acropora acuminata, Acropora elsevi,
Acropora millepora, Montipora monasteriata, Montipora tuberculosa,
Montipora hispida, Montipora digitata, Montipora foliosa,
Montipora verrucosa, Fungia fungites, Fungia paumotensis,
Fungia concina, Fungia scutaria, Halomitra limax, Pavona varians,
Pavona venosa, Pavona cactus, Coeloseris mayeri,
Galaxea fascicularis, Symphyllia radians, Lobophyllia corymbosa,
Lobophyllia hemprichii, Porites cylindrica, Porites lichen,
Porites lobata, Porites lutea, Porites nigrescens, Porites solida,
Porites stephensoni, Goniopora lobata, Favia pallida, Favia speciosa,
Favia stelligera, Favia rotumana, Favites abdita, Favites chinensis,
Goniastrea rectiformis, Goniastrea pectinata, Goniastrea sp,
Dulophyllia crispa, Platygyra daedalea, Platygyra sinensis,
Hydnopora rigida, Leptastrea purpurea, Leptastrea pruinosa,
Cyphastrea serailia, Millepora platyphylla, Millepora dichotoma,
Millepora intrincata, Heliopora coerulea
</p>
<p><code>x</code> has the following variables:
</p>

<dl>
<dt>time</dt><dd><p>(factor) the year in which the measurement was taken.</p>
</dd>
<dt>rep</dt><dd><p>(factor) the location id. </p>
</dd>
</dl>



<h3>References</h3>

<p>R.M. Warwick, K.R. Clarke and Suharsono (1990) A statistical analysis of coral
community responses to the 19823 El Nino in the Thousand Islands, Indonesia,
<em>Coral Reefs</em> <b>8</b>, 171179.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(graphics)

data(tikus)

tikusdat &lt;- as.mvabund(tikus$abund)
tikusid	&lt;- tikus$x
foo	&lt;- mvformula(tikusdat~tikusid[,1] + tikusid[,2])

plot(foo)
</code></pre>

<hr>
<h2 id='traitglm'>
Fits a fourth corner model for abundance as a function of environmental variables and species traits.
</h2><span id='topic+traitglm'></span>

<h3>Description</h3>

<p>Fits a fourth corner model - a model to study how variation in environmental response across taxa can be explained by their traits. The function to use for fitting can be (pretty well) any predictive model, default is a generalised linear model, another good option is to add a LASSO penalty via <code>glm1path</code>. Can handle overdispersed counts via  <code>family="negative.binomial"</code>, which is the default <code>family</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
traitglm(L, R, Q = NULL, family="negative.binomial", formula = NULL, method = "manyglm",
            composition = FALSE, col.intercepts = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="traitglm_+3A_l">L</code></td>
<td>

<p>A data frame (or matrix) containing the abundances for each taxon (columns) across all sites (rows).
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_r">R</code></td>
<td>

<p>A data frame (or matrix) of environmental variables (columns) across all sites (rows).
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_q">Q</code></td>
<td>

<p>A data frame (or matrix) of traits (columns) across all taxa (rows). If not specified, a different environmental response will be specified for each taxon.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_family">family</code></td>
<td>

<p>The family of the response variable, see <code><a href="stats.html#topic+family">family</a></code>. Negative binomial with unknown overdispersion and a log-link can be specified as &quot;negative.binomial&quot;, and is the default.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_formula">formula</code></td>
<td>

<p>A one-sided formula specifying exactly how to model abundance as a function of environmental and trait variables (as found in <code>R</code> and <code>Q</code> respectively).  Default is to include all terms additively, with quadratics for quantitative terms, and all environment-by-trait interactions.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_method">method</code></td>
<td>

<p>The function to use to fit the model. Default is <code><a href="#topic+manyglm">manyglm</a></code>, some other available options are <code><a href="#topic+glm1path">glm1path</a></code>, <code><a href="#topic+cv.glm1path">cv.glm1path</a></code> for LASSO-penalised fits, but in principle any model-fitting function that accepts formula input and a family argument should work.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_composition">composition</code></td>
<td>
<p>logical. TRUE includes a row effect in the model, adjusting for different sampling intensities across different samples. This can be understood as a compositional term in the sense that all other terms then model relative abundance at a site. FALSE (default) does not include a row effect, hence the model is of absolute abundance.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_col.intercepts">col.intercepts</code></td>
<td>
<p>logical. TRUE (default) includes a column effect in the model, to adjust for different levels of abundance of different response (column) variables. FALSE removes this column effect.
</p>
</td></tr>
<tr><td><code id="traitglm_+3A_...">...</code></td>
<td>

<p>Arguments passed to the function specified at <code>method</code> that will be used to fit the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a fourth corner model, that is, a model to predict abundance across several taxa (stored in <code>L</code>) as a function of environmental variables (<code>R</code>) and traits (<code>Q</code>). The environment-trait interaction can be understood as the fourth corner, giving the set of coefficients that describe how environmental response across taxa varies as traits vary. A species effect is include in the model (i.e. a different intercept term for each species), so that traits are used to explain patterns in relative abundance across taxa not patterns in absolute abundance.
</p>
<p>The actual function used to fit the model is determined by the user through the <code>method</code> argument. The default is to use <code><a href="#topic+manyglm">manyglm</a></code> to fit a GLM, although for predictive modelling, it might be better to use a LASSO penalty as in <code><a href="#topic+glm1path">glm1path</a></code> and <code><a href="#topic+cv.glm1path">cv.glm1path</a></code>. In <code><a href="#topic+glm1path">glm1path</a></code>, the penalty used for BIC calculation is <code>log(dim(L)[1])</code>, i.e. log(number of sites).
</p>
<p>The model is fitted by vectorising <code>L</code> then constructing a big matrix from repeated values of <code>R</code>, <code>Q</code>, their quadratic terms (if required) and interactions. Hence this function will hit memory issues if any of these matrices are large, and can slow down (especially if using <code><a href="#topic+cv.glm1path">cv.glm1path</a></code>). If <code>formula</code> is left unspecified, the design matrix is constructed using all environmental variables and traits specified in <code>R</code> and <code>Q</code>, and quadratic terms for any of these variables that are quantitative, and all environment-trait interactions, after standardising these variables. Specifying a one-sided <code>formula</code> as a function of the variables in <code>R</code> and <code>Q</code> would instead give the user control over the precise model that is fitted, and drops the internal standardisations. The arguments <code>composition</code> and <code>col.intercepts</code> optionally add terms to the model for row and column total abundance, irrespective of whether a <code>formula</code> has been specified.
</p>
<p>Note: when specifying a <code>formula</code>, if there are no penalties on coefficients (as for <code><a href="#topic+manyglm">manyglm</a></code>), then main effects for <code>R</code> can be excluded if including row effects (via <code>composition=TRUE</code>), and main effects for <code>Q</code> can be excluded if including column effects (via <code>col.intercepts=TRUE</code>), because those terms are redundant (trying to explain main effects for row/column when these main effects are already in the model). If using penalised likelihood (as in <code><a href="#topic+glm1path">glm1path</a></code> and <code><a href="#topic+cv.glm1path">cv.glm1path</a></code>) or a random effects model, by all means include main effects as well as row/column effects, and the penalties will sort out which terms to use.
</p>
<p>If trait matrix <code>Q</code> is not specified, default behaviour will fit a different environmental response for each taxon (and the outcome will be very similar to <code>manyglm(L~R)</code>). This can be understood as a fourth corner model where species identities are used as the species traits (i.e. no attempt is made to explain differences across species).
</p>
<p>These functions inherit default behaviour from their fitting functions. e.g. use <code>plot</code> for a Dunn-Smyth residual plot from a traits model fitted using <code><a href="#topic+manyglm">manyglm</a></code> or <code><a href="#topic+glm1path">glm1path</a></code>.
</p>


<h3>Value</h3>

<p>Returns a <code>traitglm</code> object, a list that contains at least the following components:
</p>

<dl>
<dt>...</dt><dd><p>Exactly what is included in output depends on the fitting function - by default, a <code><a href="#topic+manyglm">manyglm</a></code> object is returned, so all usual <code>manyglm</code> output is included (coefficients, residuals, deviance, etc).</p>
</dd>
<dt>family</dt><dd><p>A <code>family</code> object matching the final model.</p>
</dd>
<dt>fourth.corner</dt><dd><p>A matrix of fourth corner coefficients. If <code>formula</code> has been manually entered, this will be a vector not a matrix.</p>
</dd>
<dt>R.des</dt><dd><p>The reduced-size design matrix for environmental variables, including further arguments:
</p>

<dl>
<dt>X</dt><dd><p>Data frame of (possibly standardised) environmental variables</p>
</dd>
<dt>X.squ</dt><dd><p>A data frame containing the leading term in a quadratic expression (where appropriate) for environmental variables</p>
</dd>
<dt>var.type</dt><dd><p>A vector with the same dimension as the number of columns of X, listing the type of ecah enviromental variable (<code>"quantitative"</code>&quot; or <code>"factor"</code>&quot;)</p>
</dd>
<dt>coefs</dt><dd><p>Coefficients used in transforming variables to orthogonality. These are used later to make predictions.</p>
</dd>
</dl>

</dd>
<dt>Q.des</dt><dd><p>The reduced-size design matrix for traits, set up as for <code>R.des</code>.</p>
</dd>
<dt>spp.penalty</dt><dd><p>For LASSO fits: a vector of the same length as the final design matrix, indicating which variables had a penalty imposed on them in model fitting.</p>
</dd>
<dt>L</dt><dd><p>The data frame of abundances specified as input.</p>
</dd>
<dt>any.penalty</dt><dd><p>Logical, is any penalty applied to parameters at all (not if using a <code>manyglm</code> fit).</p>
</dd>
<dt>scaling</dt><dd><p>A list of coefficients describing the standaridsations of variables used in analyses. Stored for use later if making predictions.</p>
</dd>
<dt>call</dt><dd><p>The original call <code>traitglm</code> call.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;
</p>


<h3>References</h3>

<p>Brown AM, Warton DI, Andrew NR, Binns M, Cassis G and Gibb H (2014) The fourth corner solution - using species traits to better understand how species traits interact with their environment, Methods in Ecology and Evolution 5, 344-352.
</p>
<p>Warton DI, Shipley B &amp; Hastie T (2015) CATS regression - a model-based approach to studying trait-based community assembly, Methods in Ecology and Evolution 6, 389-398.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm1path">glm1path</a></code>, <code><a href="#topic+glm1">glm1</a></code>, <code><a href="#topic+manyglm">manyglm</a></code>, <code><a href="stats.html#topic+family">family</a></code>, <code><a href="#topic+residuals.manyglm">residuals.manyglm</a></code>, <code><a href="#topic+plot.manyany">plot.manyany</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(antTraits)

ft=traitglm(antTraits$abund,antTraits$env,antTraits$traits,method="manyglm")
ft$fourth #print fourth corner terms

# for a pretty picture of fourth corner coefficients, uncomment the following lines:
# library(lattice)
# a        = max( abs(ft$fourth.corner) )
# colort   = colorRampPalette(c("blue","white","red")) 
# plot.4th = levelplot(t(as.matrix(ft$fourth.corner)), xlab="Environmental Variables",
#   ylab="Species traits", col.regions=colort(100), at=seq(-a, a, length=100),
#   scales = list( x= list(rot = 45)))
# print(plot.4th)

plot(ft) # for a Dunn-smyth residual plot
qqnorm(residuals(ft)); abline(c(0,1),col="red") # for a normal quantile plot.

# predict to the first five sites
predict(ft,newR=antTraits$env[1:5,])

# refit using LASSO and less variables, including row effects and only two interaction terms:
ft1=traitglm(antTraits$abund,antTraits$env[,3:4],antTraits$traits[,c(1,3)],
      formula=~Shrub.cover:Femur.length+Shrub.cover:Pilosity,composition=TRUE,method="glm1path")
ft1$fourth #notice LASSO penalty has one interaction to zero

</code></pre>

<hr>
<h2 id='unabund'> Remove the mvabund Class Attribute </h2><span id='topic+unabund'></span>

<h3>Description</h3>

<p>Change an mvabund object to a non-mvabund object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unabund(x) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unabund_+3A_x">x</code></td>
<td>
<p>an mvabund object that should be transformed into a matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+unabund">unabund</a></code> doesn't convert <code>x</code> but only removes the
mvabund class attribute.
</p>


<h3>Value</h3>

<p>A matrix if <code>x</code> is an <code>mvabund</code> object otherwise <code>x</code> .</p>


<h3>Author(s)</h3>

<p>Ulrike Naumann and David Warton &lt;David.Warton@unsw.edu.au&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvabund">mvabund</a></code>.
<code><a href="#topic+as.mvabund">as.mvabund</a></code>.
<code><a href="#topic+is.mvabund">is.mvabund</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create an mvabund object:
abundances &lt;- as.mvabund(matrix(1:20,5,4))

## Restore the original object:
mat &lt;- unabund(x=abundances)
mat
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
