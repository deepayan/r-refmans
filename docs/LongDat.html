<!DOCTYPE html><html><head><title>Help for package LongDat</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LongDat}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cliff_cal'><p>Effect size (Cliff's delta) calculation in longdat_disc() pipeline</p></a></li>
<li><a href='#ConModelTest_cont'><p>Covariate model test in longdat_cont() pipeline</p></a></li>
<li><a href='#ConModelTest_disc'><p>Covariate model test in longdat_disc() pipeline</p></a></li>
<li><a href='#correlation_posthoc'><p>Post-hoc test based on correlation test for longdat_cont().</p></a></li>
<li><a href='#cuneiform_plot'><p>Create cuneiform plots of result table from longdat_disc() or</p>
longdat_cont()</a></li>
<li><a href='#data_preprocess'><p>Data preprocessing</p></a></li>
<li><a href='#factor_p_cal'><p>Calculate the p values for every factor (used for selecting factors later)</p></a></li>
<li><a href='#final_result_summarize_cont'><p>Generate result table as output in longdat_cont()</p></a></li>
<li><a href='#final_result_summarize_disc'><p>Generate result table as output in longdat_disc()</p></a></li>
<li><a href='#fix_name_fun'><p>Replace the symbols in variable and covariate names in raw input</p></a></li>
<li><a href='#longdat_cont'><p>Longitudinal analysis with time as continuous variable</p></a></li>
<li><a href='#LongDat_cont_feature_table'><p>data/LongDat_cont_feature_table.RData documentation</p></a></li>
<li><a href='#LongDat_cont_master_table'><p>data/LongDat_cont_master_table.RData documentation</p></a></li>
<li><a href='#LongDat_cont_metadata_table'><p>data/LongDat_cont_metadata_table.RData documentation</p></a></li>
<li><a href='#longdat_disc'><p>Longitudinal analysis with time as discrete variable</p></a></li>
<li><a href='#LongDat_disc_feature_table'><p>data/LongDat_disc_feature_table.RData documentation</p></a></li>
<li><a href='#LongDat_disc_master_table'><p>data/LongDat_disc_master_table.RData documentation</p></a></li>
<li><a href='#LongDat_disc_metadata_table'><p>data/LongDat_disc_metadata_table.RData documentation</p></a></li>
<li><a href='#make_master_table'><p>Create input master table from metadata and feature tables for</p>
longdat_disc() and longdat_cont()</a></li>
<li><a href='#NuModelTest_cont'><p>Null Model Test and post-hoc Test in longdat_cont() pipeline</p></a></li>
<li><a href='#NuModelTest_disc'><p>Null Model Test and post-hoc Test in longdat_disc() pipeline</p></a></li>
<li><a href='#random_neg_ctrl_cont'><p>Randomized negative control for count data in longdat_cont()</p></a></li>
<li><a href='#random_neg_ctrl_disc'><p>Randomized negative control for count data in longdat_disc()</p></a></li>
<li><a href='#rm_sparse_cont'><p>Remove the dependent variables that are below the threshold of</p>
sparsity when the data type is count data in longdat_cont()</a></li>
<li><a href='#rm_sparse_disc'><p>Remove the dependent variables that are below the threshold</p>
of sparsity when the data type is count data in longdat_disc()</a></li>
<li><a href='#theta_plot'><p>Plot theta values of negative binomial models versus non-zero count</p>
for count data</a></li>
<li><a href='#unlist_table'><p>Unlist confound (covariate) and inverse confound (covariate) tables,</p>
turn them into tables</a></li>
<li><a href='#wilcox_posthoc'><p>Wilcoxon post-hoc test</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Tool for 'Covariate'-Sensitive Longitudinal Analysis on
'omics' Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>This tool takes longitudinal dataset as input and analyzes if there is significant 
             change of the features over time (a proxy for treatments), while detects and controls 
             for 'covariates' simultaneously. 'LongDat' is able to take in several data types as input, 
             including count, proportion, binary, ordinal and continuous data. The output table contains 
              p values, effect sizes and 'covariates' of each feature, making the downstream analysis easy.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/CCY-dev/LongDat">https://github.com/CCY-dev/LongDat</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/CCY-dev/LongDat/issues">https://github.com/CCY-dev/LongDat/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lme4, reshape2, glmmTMB, emmeans, bestNormalize, MASS,
ggplot2, stringr, magrittr, tibble, dplyr, graphics, utils,
stats, rlang, car, rstatix, effsize, tidyr, patchwork</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, kableExtra</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-13 20:42:37 UTC; Jessica</td>
</tr>
<tr>
<td>Author:</td>
<td>Chia-Yu Chen <a href="https://orcid.org/0000-0003-1765-7132"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Sofia Forslund <a href="https://orcid.org/0000-0003-4285-6993"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chia-Yu Chen &lt;Chia-Yu.Chen@mdc-berlin.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-17 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cliff_cal'>Effect size (Cliff's delta) calculation in longdat_disc() pipeline</h2><span id='topic+cliff_cal'></span>

<h3>Description</h3>

<p>Effect size (Cliff's delta) calculation in longdat_disc() pipeline
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="cliff_cal_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="cliff_cal_+3A_ps_poho_fdr">Ps_poho_fdr</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="cliff_cal_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="cliff_cal_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="cliff_cal_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="cliff_cal_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='ConModelTest_cont'>Covariate model test in longdat_cont() pipeline</h2><span id='topic+ConModelTest_cont'></span>

<h3>Description</h3>

<p>Covariate model test in longdat_cont() pipeline
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConModelTest_cont_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_sel_fac">sel_fac</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_cont_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='ConModelTest_disc'>Covariate model test in longdat_disc() pipeline</h2><span id='topic+ConModelTest_disc'></span>

<h3>Description</h3>

<p>Covariate model test in longdat_disc() pipeline
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConModelTest_disc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_sel_fac">sel_fac</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="ConModelTest_disc_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='correlation_posthoc'>Post-hoc test based on correlation test for longdat_cont().</h2><span id='topic+correlation_posthoc'></span>

<h3>Description</h3>

<p>Post-hoc test based on correlation test for longdat_cont().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation_posthoc(variables, verbose, melt_data, test_var, N)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation_posthoc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="correlation_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="correlation_posthoc_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="correlation_posthoc_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="correlation_posthoc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='cuneiform_plot'>Create cuneiform plots of result table from longdat_disc() or
longdat_cont()</h2><span id='topic+cuneiform_plot'></span>

<h3>Description</h3>

<p>Create cuneiform plots of result table from longdat_disc() or
longdat_cont()
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="cuneiform_plot_+3A_result_table">result_table</code></td>
<td>
<p>The result table from longdat_disc() or
longdat_cont() output, or any data frame that has the same format.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_x_axis_order">x_axis_order</code></td>
<td>
<p>The plotting order of the x axis.
It should be a character vector
(e.g. c(&quot;Effect_1_2&quot;, &quot;Effect_2_3&quot;, &quot;Effect_1_3&quot;)).</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_covariate_panel">covariate_panel</code></td>
<td>
<p>A boolean vector indicating whether to plot
covariate status alongside the effect panel. The default is TRUE.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_pos_color">pos_color</code></td>
<td>
<p>The color for a positive effect size.
It should be a hex color code (e.g. &quot;#b3e6ff&quot;) or the colors recognized
by R. The default is &quot;red&quot;.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_neg_color">neg_color</code></td>
<td>
<p>The color for a negative effect size.
It should be a hex color code (e.g. &quot;#b3e6ff&quot;) or the colors recognized
by R. The default is &quot;blue&quot;.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_panel_width">panel_width</code></td>
<td>
<p>The width of the effect size panel on the left
relative to the covariate status panel on the right (width set to 1).
It should be a numerical vector. The default is 4.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_title">title</code></td>
<td>
<p>The name of the plot title. The default is
&quot;LongDat result cuneiform plot&quot;.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_title_size">title_size</code></td>
<td>
<p>The size of the plot title. The default is 20.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_covariate_text_size">covariate_text_size</code></td>
<td>
<p>The size of the text in the covariate status
panel. The default is 4.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_x_label_size">x_label_size</code></td>
<td>
<p>The size of the x label. The default is 10.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_y_label_size">y_label_size</code></td>
<td>
<p>The size of the y label. The default is 10.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_legend_title_size">legend_title_size</code></td>
<td>
<p>The size of the legend title. The default is 12.</p>
</td></tr>
<tr><td><code id="cuneiform_plot_+3A_legend_text_size">legend_text_size</code></td>
<td>
<p>The size of the legend text The default is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a cuneiform plot which displays the
result of longdat_disc() or longdat_cont(). It plots the effect sizes
within each time interval for each feature, and also shows the covariate
status. Only the features with non-NS signals will be included in the plot.
The output is a ggplot object in patchwork structure. For further
customization of the plot, please refer to the vignette.
</p>


<h3>Value</h3>

<p>a 'ggplot' object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_disc &lt;- longdat_disc(input = LongDat_disc_master_table,
data_type = "count", test_var = "Time_point",
variable_col = 7, fac_var = c(1:3))
test_plot &lt;- cuneiform_plot(result_table = test_disc[[1]],
x_axis_order = c("Effect_1_2", "Effect_2_3", "Effect_1_3"))
</code></pre>

<hr>
<h2 id='data_preprocess'>Data preprocessing</h2><span id='topic+data_preprocess'></span>

<h3>Description</h3>

<p>Data preprocessing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_preprocess(input, test_var, variable_col, fac_var, not_used)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data_preprocess_+3A_input">input</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="data_preprocess_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="data_preprocess_+3A_variable_col">variable_col</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="data_preprocess_+3A_fac_var">fac_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="data_preprocess_+3A_not_used">not_used</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='factor_p_cal'>Calculate the p values for every factor (used for selecting factors later)</h2><span id='topic+factor_p_cal'></span>

<h3>Description</h3>

<p>Calculate the p values for every factor (used for selecting factors later)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factor_p_cal(melt_data, variables, factor_columns, factors, data, N, verbose)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factor_p_cal_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_factor_columns">factor_columns</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_factors">factors</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="factor_p_cal_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='final_result_summarize_cont'>Generate result table as output in longdat_cont()</h2><span id='topic+final_result_summarize_cont'></span>

<h3>Description</h3>

<p>Generate result table as output in longdat_cont()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>final_result_summarize_cont(
  variable_col,
  N,
  Ps_conf_inv_model_unlist,
  variables,
  sel_fac,
  Ps_conf_model_unlist,
  model_q,
  posthoc_q,
  Ps_null_model_fdr,
  Ps_null_model,
  assoc,
  prevalence,
  mean_abundance,
  p_poho,
  not_used,
  Ps_effectsize,
  data_type,
  false_pos_count
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="final_result_summarize_cont_+3A_variable_col">variable_col</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_ps_conf_inv_model_unlist">Ps_conf_inv_model_unlist</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_sel_fac">sel_fac</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_ps_conf_model_unlist">Ps_conf_model_unlist</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_model_q">model_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_ps_null_model_fdr">Ps_null_model_fdr</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_ps_null_model">Ps_null_model</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_assoc">assoc</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_prevalence">prevalence</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_mean_abundance">mean_abundance</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_p_poho">p_poho</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_not_used">not_used</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_ps_effectsize">Ps_effectsize</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_cont_+3A_false_pos_count">false_pos_count</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='final_result_summarize_disc'>Generate result table as output in longdat_disc()</h2><span id='topic+final_result_summarize_disc'></span>

<h3>Description</h3>

<p>Generate result table as output in longdat_disc()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>final_result_summarize_disc(
  variable_col,
  N,
  Ps_conf_inv_model_unlist,
  variables,
  sel_fac,
  Ps_conf_model_unlist,
  model_q,
  posthoc_q,
  Ps_null_model_fdr,
  Ps_null_model,
  delta,
  case_pairs,
  prevalence,
  mean_abundance,
  Ps_poho_fdr,
  not_used,
  Ps_effectsize,
  case_pairs_name,
  data_type,
  false_pos_count,
  p_wilcox_final
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="final_result_summarize_disc_+3A_variable_col">variable_col</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_conf_inv_model_unlist">Ps_conf_inv_model_unlist</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_sel_fac">sel_fac</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_conf_model_unlist">Ps_conf_model_unlist</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_model_q">model_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_null_model_fdr">Ps_null_model_fdr</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_null_model">Ps_null_model</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_delta">delta</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_case_pairs">case_pairs</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_prevalence">prevalence</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_mean_abundance">mean_abundance</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_poho_fdr">Ps_poho_fdr</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_not_used">not_used</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_ps_effectsize">Ps_effectsize</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_case_pairs_name">case_pairs_name</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_false_pos_count">false_pos_count</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="final_result_summarize_disc_+3A_p_wilcox_final">p_wilcox_final</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='fix_name_fun'>Replace the symbols in variable and covariate names in raw input</h2><span id='topic+fix_name_fun'></span>

<h3>Description</h3>

<p>Replace the symbols in variable and covariate names in raw input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix_name_fun(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix_name_fun_+3A_z">z</code></td>
<td>
<p>A character vector. This is the character vector
that needs to be changed.</p>
</td></tr>
</table>

<hr>
<h2 id='longdat_cont'>Longitudinal analysis with time as continuous variable</h2><span id='topic+longdat_cont'></span>

<h3>Description</h3>

<p>longdat_cont calculates the p values, effect sizes and discover covariate
effects of time variables from longitudinal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>longdat_cont(
  input,
  data_type,
  test_var,
  variable_col,
  fac_var,
  not_used = NULL,
  adjustMethod = "fdr",
  model_q = 0.1,
  posthoc_q = 0.05,
  theta_cutoff = 2^20,
  nonzero_count_cutoff1 = 9,
  nonzero_count_cutoff2 = 5,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="longdat_cont_+3A_input">input</code></td>
<td>
<p>A data frame with the first column as &quot;Individual&quot;
and all the columns of dependent variables (features, e.g. bacteria)
at the end of the table. The time variable here should be
continuous, if time is discrete, please apply longdat_disc()
instead. Please avoid using characters that don't belong to
ASCII printable characters for potential covariates names
(covariates are any column apart from individual, test_var and
dependent variables).</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_data_type">data_type</code></td>
<td>
<p>The data type of the dependent variables (features).
Can either be &quot;proportion&quot;, &quot;measurement&quot;, &quot;count&quot;, &quot;binary&quot;, &quot;ordinal&quot; or
&quot;others&quot;. Proportion (or ratio) data range from 0 to 1. Measurement data are
continuous and can be measured at finer and finer scale (e.g. weight).
Count data consist of discrete non-negative integers resulted from
counting. Binary data are the data of sorting things into
one of two mutually exclusive categories. Ordinal data consist of
ranks. Any data that doesn't belong to the previous categories
should be classified as &quot;others&quot;.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_test_var">test_var</code></td>
<td>
<p>The name of the independent variable you are testing for,
should be a string (e.g. &quot;Time&quot;) identical to its column name
and make sure there is no space in it.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_variable_col">variable_col</code></td>
<td>
<p>The column number of the position where the dependent
variable columns (features, e.g. bacteria) start in the table.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_fac_var">fac_var</code></td>
<td>
<p>The column numbers of the position where the columns that
aren't numerical  (e.g. characters, categorical numbers, ordinal numbers).
This should be a numerical vector (e.g. c(1, 2, 5:7)).</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_not_used">not_used</code></td>
<td>
<p>The column position of the columns not are irrelevant and
can be ignored when in the analysis.
This should be a numerical vector, and the default is NULL.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_adjustmethod">adjustMethod</code></td>
<td>
<p>Multiple testing p value correction. Choices are
the ones in p.adjust(), including
'holm', 'hochberg', 'hommel', 'bonferroni', 'BH', 'BY' and 'fdr.'
The default is 'fdr'.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_model_q">model_q</code></td>
<td>
<p>The threshold for significance of model test after multiple
testing correction. The default is 0.1.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>The threshold for significance of post-hoc test after
multiple testing correction. The default is 0.05.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with theta value from negative binomial regression
larger than or equal to the cutoff will be filtered out if it
also doesn't meet the non-zero count threshold.
Users can use the function &quot;theta_plot()&quot; to help with
specifying the value for theta_cutoff. The default is 2^20.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with non-zero counts lower than or equal to this value
will be filtered out if it doesn't meet the theta threshold either.
Users can use the function &quot;theta_plot()&quot; to help with
specifying the value for nonzero_count_cutoff1. The default is 9.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with non-zero counts lower than or equal to this value
will be filtered out. Users can use the function &quot;theta_plot()&quot; to
help with specifying the value for nonzero_count_cutoff2.
The default is 5.</p>
</td></tr>
<tr><td><code id="longdat_cont_+3A_verbose">verbose</code></td>
<td>
<p>A boolean vector indicating whether to print detailed
message. The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The brief workflow of longdat_cont() is as below:
</p>
<p>When there's no potential covariates in the input data (covariates are
anything apart from individual, test_var and dependent variables):
First, the model test tests the significance of test_var on dependent
variables. Different generalized linear mixed effect models are implemented
for different types of dependent variable. Negative binomial mixed model for
&quot;count&quot;, linear mixed model (dependent variables normalized first) for
&quot;measurement&quot;, beta mixed model for &quot;proportion&quot;,
binary logistic mixed model for &quot;binary&quot;,
and proportional odds logistic mixed model for &quot;ordinal&quot;.
Then, post-hoc test (Spearman's correlation test) on the model is done.
When the data type is &quot;count&quot; mode, a control model test will be run on
randomized data (the rows are shuffled). If there are false positive
signals in this control model test, users will get a warning
at the end of the run.
</p>
<p>When there are potential covariates in the input data:
After the model test and post-hoc test described above, a covariate
model test will be added to the work flow. The potential covariates
will be added to the model one by one and test for its significance
on each dependent variable. The rest are the same as the description above.
</p>
<p>Also, when your data type is count data, please use set.seed()
before running longdat_cont() so that you can get reproducible
randomized negative check.
</p>


<h3>Value</h3>

<p>longdat_cont() returns a list which contains a &quot;Result_table&quot;,
and if there are covariates in the input data frame,
there will be another table called
&quot;Covariate_table&quot;. For count mode, if there is any false positive
in the randomized control result, then another table named
&quot;Randomized_control_table&quot; will also be
generated. The detailed description is as below.
</p>
<p>Result_table
</p>
<p>1. The first column: The dependent variables in the input data.
This can be used as row name when being imported into R.
</p>
<p>2. Prevalence_percentage: The percentage of each dependent
variable present across individuals and time points
</p>
<p>3. Mean_abundance: The mean value of each dependent variable
across individuals and time points
</p>
<p>4. Signal: The final decision of the significance of the test_var
(independent variable) on each dependent variable.
NS: This represents &quot;Non-significant&quot;,
which means that there’s no effect of time.
</p>
<p>OK_nc: This represents &quot;OK and no covariate&quot;.
There’s an effect of time and there’s no potential covariate.
</p>
<p>OK_d: This represents &quot;OK but doubtful&quot;.
There’s an effect of time and there’s no
potential covariate, however the confidence interval of the test_var
estimate in the model test covers zero, and thus it is doubtful of
this signal.
</p>
<p>OK_nrc: This represents &quot;OK and not reducible to covariate&quot;.
There are potential covariates, however
there’s an effect of time and it is independent of those of covariates.
</p>
<p>EC: This represents &quot;Entangled with covariate&quot;.
There are potential covariates, and it isn’t
possible to conclude whether the effect is resulted from time or
covariates.
</p>
<p>RC: This represents &quot;Effect reducible to covariate&quot;.
There’s an effect of time, but it can be reduced to the
covariate effects.
</p>
<p>5. Effect: This column contains the value of each dependent variable
decreases/increases/NS(non-significant) along the time.
A positive correlation between with time dependent variable value yields
&quot;increase&quot;, while a negative correlation yields &quot;decrease&quot;.
NS means no significant correlation.
</p>
<p>6. 'EffectSize': This column reports the correlation coefficient
(Spearman's rho) between each dependent variable value and time.
</p>
<p>7. Null_time_model_q: This column shows the multiple-comparison-adjusted
p values (Wald test) of the significance of test_var in the models.
</p>
<p>8. Post-hoc_q: These are the multiple-comparison-adjusted p values
from the post-hoc test (Spearman's correlation test) of the model.
</p>
<p>Covariate_table
</p>
<p>The first column contains the dependent variables in the input data.
This can be used as row name when being imported into R.
Then every 3 columns are a group. Covariate column shows the covariate's
name; Covariate column shows the covariate's
name; Covariate_type column shows how effect is affected by covariate
; Effect_size column shows the effect size of
dependent variable value between different values of
covariate. Due to the different number of covariates for each
dependent variable, there may be NAs in the table and they can
simply be ignored. If the covariate table is totally empty,
this means that there are no covariates detected.
</p>
<p>Randomized_control_table (for user's reference)
</p>
<p>We assume that there shouldn't be positive results in the randomized
control test, because all the rows in the original dataset are
shuffled randomly. Therefore, any signal that showed significance here
will be regarded as false positive. And if there's false
positive in this randomized control result, longdat_disc will warn the
user at the end of the run. This Randomized_control table is only
generated when there is false positive in the randomized control test.
It is intended to be a reference for users to see the effect size of
false positive features.
</p>
<p>1. The first column &quot;Model_q&quot; shows the multiple-comparison-adjusted
p values (Wald test) of the significance of test_var in the negative-
binomial models in the randomized
dataset. Only the features with Model_q lower than the defined model_q
(default = 0.1) will be listed in this table.
</p>
<p>2. Signal: This column describes if test_var is significant on each
dependent variable based on the post-hoc test p values
(Spearman's correlation test).
&quot;False positive&quot; indicates that test_var is significant, while
&quot;Negative&quot; indicates non-significance.
</p>
<p>3. 'Posthoc_q': This column describes the multiple-comparison-adjusted
p values from the post-hoc test (Spearman's correlation test) of the
model in the randomized control dataset.
</p>
<p>4. Effect_size: This column describes the correlation coefficient
(Spearman's rho) of each dependent variable between each dependent
variable value and time.
</p>
<p>Normalize_method (for user's reference)
</p>
<p>When data_type is either &quot;measurement&quot; or &quot;others&quot;, this table shows the
normalization method used for each feature. Please refer to &quot;Using the
bestNormalize Package&quot; on the Internet for the details of each method.
&quot;NA&quot; indicates that there are too few data points to interpolate, and
thus no normalization was done.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_cont &lt;- suppressWarnings(longdat_cont(input = LongDat_cont_master_table,
data_type = "count", test_var = "Day",
variable_col = 7, fac_var = c(1, 3)))
</code></pre>

<hr>
<h2 id='LongDat_cont_feature_table'>data/LongDat_cont_feature_table.RData documentation</h2><span id='topic+LongDat_cont_feature_table'></span>

<h3>Description</h3>

<p>Example feature data frame for longdat_cont(). This is a dummy data
which contains features (dependent variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_cont_feature_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 20 rows and 4 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_cont_feature_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='LongDat_cont_master_table'>data/LongDat_cont_master_table.RData documentation</h2><span id='topic+LongDat_cont_master_table'></span>

<h3>Description</h3>

<p>Example master data frame for longdat_cont(). This is a dummy data
which contains metadata and features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_cont_master_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 20 rows and 9 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_cont_master_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='LongDat_cont_metadata_table'>data/LongDat_cont_metadata_table.RData documentation</h2><span id='topic+LongDat_cont_metadata_table'></span>

<h3>Description</h3>

<p>Example metadata data frame for longdat_cont(). This is a dummy data
which contains metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_cont_metadata_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 20 rows and 7 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_cont_metadata_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='longdat_disc'>Longitudinal analysis with time as discrete variable</h2><span id='topic+longdat_disc'></span>

<h3>Description</h3>

<p>longdat_disc calculates the p values, effect sizes and discover covariate
effects of time variables from longitudinal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>longdat_disc(
  input,
  data_type,
  test_var,
  variable_col,
  fac_var,
  not_used = NULL,
  adjustMethod = "fdr",
  model_q = 0.1,
  posthoc_q = 0.05,
  theta_cutoff = 2^20,
  nonzero_count_cutoff1 = 9,
  nonzero_count_cutoff2 = 5,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="longdat_disc_+3A_input">input</code></td>
<td>
<p>A data frame with the first column as &quot;Individual&quot;
and all the columns of dependent variables (features, e.g. bacteria)
at the end of the table. The time variable here should be
discrete, if time is continuous, please apply longdat_cont()
instead. Please avoid using characters that don't belong to
ASCII printable characters for potential covariates names
(covariates are any column apart from individual, test_var and
dependent variables).</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_data_type">data_type</code></td>
<td>
<p>The data type of the dependent variables (features).
Can either be &quot;proportion&quot;, &quot;measurement&quot;, &quot;count&quot;, &quot;binary&quot;, &quot;ordinal&quot; or
&quot;others&quot;. Proportion (or ratio) data range from 0 to 1. Measurement data are
continuous and can be measured at finer and finer scale (e.g. weight).
Count data consist of discrete non-negative integers resulted from
counting. Binary data are the data of sorting things into
one of two mutually exclusive categories. Ordinal data consist of
ranks. Any data that doesn't belong to the previous categories
should be classified as &quot;others&quot;.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_test_var">test_var</code></td>
<td>
<p>The name of the independent variable you are testing for,
should be a string (e.g. &quot;Time&quot;)
identical to its column name and make sure there is no space in it.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_variable_col">variable_col</code></td>
<td>
<p>The column number of the position where the dependent
variable columns (features, e.g. bacteria) start in the table.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_fac_var">fac_var</code></td>
<td>
<p>The column numbers of the position where the columns that
aren't numerical  (e.g. characters, categorical numbers, ordinal numbers).
This should be a numerical vector (e.g. c(1, 2, 5:7)).</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_not_used">not_used</code></td>
<td>
<p>The column position of the columns not are irrelevant and
can be ignored when in the analysis. This should be a numerical vector, and
the default is NULL.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_adjustmethod">adjustMethod</code></td>
<td>
<p>Multiple testing p value correction. Choices are the
ones in p.adjust(), including 'holm', 'hochberg', 'hommel', 'bonferroni',
'BH', 'BY' and 'fdr'. The default is 'fdr'.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_model_q">model_q</code></td>
<td>
<p>The threshold for significance of model test after multiple
testing correction. The default is 0.1.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>The threshold for significance of post-hoc test of the
model after multiple testing correction. The default is 0.05.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with theta value from negative binomial regression
larger than or equal to the cutoff will be filtered out if it
also doesn't meet the non-zero count threshold.
Users can use the function &quot;theta_plot()&quot; to help with
specifying the value for theta_cutoff. The default is 2^20.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with non-zero counts lower than or equal to this value
will be filtered out if it doesn't meet the theta threshold either.
Users can use the function &quot;theta_plot()&quot; to help with
specifying the value for nonzero_count_cutoff1. The default is 9.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Required when the data type is set as &quot;count&quot;.
Variable with non-zero counts lower than or equal to this value
will be filtered out. Users can use the function &quot;theta_plot()&quot; to
help with specifying the value for nonzero_count_cutoff2.
The default is 5.</p>
</td></tr>
<tr><td><code id="longdat_disc_+3A_verbose">verbose</code></td>
<td>
<p>A boolean vector indicating whether to print detailed
message. The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The brief workflow of longdat_disc() is as below:
</p>
<p>When there's no potential covariates in the input data
(covariates are anything apart from individual, test_var and
dependent variables):
First, the model test tests the significance of test_var on dependent
variables. Different generalized linear mixed effect models are implemented
for different types of dependent variable. Negative binomial mixed model for
&quot;count&quot;, linear mixed model (dependent variables normalized first) for
&quot;measurement&quot;,
beta mixed model for &quot;proportion&quot;, binary logistic mixed model for
&quot;binary&quot;, and proportional odds logistic mixed model for &quot;ordinal&quot;.
Then, post-hoc test ('emmeans') on
the model is done. When the data type is &quot;count&quot; mode, a control model
test will be run on randomized data (the rows are shuffled). If there
are false positive signals in this control model
test, then additional Wilcoxon post-hoc test will be done because it
is more conservative.
</p>
<p>When there are potential covariates in the input data:
After the model test and post-hoc test described above, a covariate
model test will be added to the work flow. The potential covariates will
be added to the model
one by one and test for its significance on each dependent variable. The
rest are the same as the description above.
</p>
<p>Also, when your data type is count data, please use set.seed() before
running longdat_disc() so that you can get reproducible randomized
negative check.
</p>


<h3>Value</h3>

<p>longdat_disc() returns a list which contains a &quot;Result_table&quot;,
and if there are covariates in the input data frame,
there will be another table called &quot;Covariate_table&quot;. For count mode,
if there is any false positive
in the randomized control result, then another table named
&quot;Randomized_control_table&quot; will also be
generated. The detailed description is as below.
</p>
<p>Result_table
</p>
<p>1. The first column: The dependent variables in the input data.
This can be used as row name when being imported into R.
</p>
<p>2. Prevalence_percentage: The percentage of each dependent variable
present across individuals and time points.
</p>
<p>3. Mean_abundance: The mean value of each dependent variable across
individuals and time points.
</p>
<p>4. Signal: The final decision of the significance of the test_var
(independent variable) on each dependent variable.
NS: This represents &quot;Non-significant&quot;,
which means that there’s no effect of time.
</p>
<p>OK_nc: This represents &quot;OK and no covariate&quot;.
There’s an effect of time and there’s no potential covariate.
</p>
<p>OK_d: This represents &quot;OK but doubtful&quot;.
There’s an effect of time and there’s no
potential covariate, however the confidence interval of the test_var
estimate in the model test covers zero, and thus it is doubtful of
this signal.
</p>
<p>OK_nrc: This represents &quot;OK and not reducible to covariate&quot;.
There are potential covariates, however
there’s an effect of time and it is independent of those of covariates.
</p>
<p>EC: This represents &quot;Entangled with covariate&quot;.
There are potential covariates, and it isn’t
possible to conclude whether the effect is resulted from time or
covariates.
</p>
<p>RC: This represents &quot;Effect reducible to covariate&quot;.
There’s an effect of time, but it can be reduced to the
covariate effects.
</p>
<p>5. 'Effect_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns describe the value of each dependent
variable decreases/increases/NS(non-significant) at time
point b comparing with time point a. The number of
Effect columns depends on how many combinations of
time points in the input data.
</p>
<p>6. 'EffectSize_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns describe the effect size (Cliff's delta) of each dependent
variable between time point b and a. The number of
'EffectSize' columns depends on how many combinations of
time points in the input data.
</p>
<p>7. 'Null_time_model_q': This column shows the multiple-comparison-adjusted
p values (Wald test) of the significance of test_var in the models.
</p>
<p>8. 'Post-hoc_q_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These are the multiple-comparison-adjusted p values from the post-hoc
test of the model. The number of Post-hoc_q columns
depends on how many combinations of time points
in the input data.
</p>
<p>9. 'Wilcox_p_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns only appear when data type is &quot;count&quot; and there exist
false positives in the model test on randomized data. Wilcoxon test
are more conservative than the default post-hoc test ('emmeans'),
and thus it is a good reference for getting a more conservative result
of the significant outcomes.
</p>
<p>Covariate_table
</p>
<p>The first column contains the dependent variables in the input data.
This can be used as row name when being imported into R.
Then every 3 columns are a group. Covariate column shows the covariate's
name; Covariate_type column shows how effect is affected by covariate;
Effect_size column shows the effect
size of dependent variable value between different values of
covariate. Due to the different number of covariates for each dependent
variable, there may be NAs in the table and they can
simply be ignored. If the covariate table is totally empty, this means
that there are no covariates detected.
</p>
<p>Randomized_control_table (for user's reference)
</p>
<p>We assume that there shouldn't be positive results in the randomized control
test, because all the rows in the original dataset are
shuffled randomly. Therefore, any signal that showed significance here will
be regarded as false positive. And if there's false
positive in this randomized control result, longdat_disc() will warn the user
at the end of the run. This Randomized_control table is only
generated when there is false positive in the randomized control test.
It is intended to be a reference for users to see the effect size of
false positive features.
</p>
<p>1. &quot;Model_q&quot;: It shows the multiple-comparison-adjusted p values
(Wald test)of the significance of test_var in the negative-binomial
models in the randomized dataset. Only the features with Model_q lower
than the defined model_q (default = 0.1) will be listed in this table.
</p>
<p>2. Final_signal: It show the overall signal being either false positive
or negative. &quot;False positive&quot; indicates that test_var is significant,
while &quot;Negative&quot; indicates non-significance.
</p>
<p>3. 'Signal_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns describe if test_var is significant on each dependent
variable between each time point based on the post-hoc test p values
(listed right to Signal_a_b). &quot;False positive&quot; indicates that test_var
is significant, while &quot;Negative&quot; indicates non-significance. The number
of Signal_a_b columns depends on how many combinations of time points
in the input data.
</p>
<p>4. 'Posthoc_q_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns describe the multiple-comparison-adjusted p values from the
post-hoc test of the model between time point b and a in the randomized
control dataset. The number of 'Posthoc_q_a_b' columns depends on how
many combinations of time points in the input data.
</p>
<p>5. 'Effect_size_a_b': The &quot;a&quot; and &quot;b&quot; here are the names of the time points.
These columns describe the effect size (Cliff's delta) of each dependent
variable between time point b and a in the randomized control dataset.
The number of Effect_size_a_b columns depends on how many combinations
of time points in the input data.
</p>
<p>Normalize_method (for user's reference)
</p>
<p>When data_type is either &quot;measurement&quot; or &quot;others&quot;, this table shows the
normalization method used for each feature. Please refer to &quot;Using the
bestNormalize Package&quot; on the Internet for the details of each method.
&quot;NA&quot; indicates that there are too few data points to interpolate, and
thus no normalization was done.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_disc &lt;- longdat_disc(input = LongDat_disc_master_table,
data_type = "count", test_var = "Time_point",
variable_col = 7, fac_var = c(1:3))
</code></pre>

<hr>
<h2 id='LongDat_disc_feature_table'>data/LongDat_disc_feature_table.RData documentation</h2><span id='topic+LongDat_disc_feature_table'></span>

<h3>Description</h3>

<p>Example feature data frame for longdat_disc(). This is a dummy data
which contains features (dependent variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_disc_feature_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 30 rows and 4 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_disc_feature_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='LongDat_disc_master_table'>data/LongDat_disc_master_table.RData documentation</h2><span id='topic+LongDat_disc_master_table'></span>

<h3>Description</h3>

<p>Example master data frame for longdat_disc(). This is a dummy data
which contains metadata and features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_disc_master_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 30 rows and 9 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_disc_master_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='LongDat_disc_metadata_table'>data/LongDat_disc_metadata_table.RData documentation</h2><span id='topic+LongDat_disc_metadata_table'></span>

<h3>Description</h3>

<p>Example metadata data frame for longdat_disc(). This is a dummy data
which contains metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LongDat_disc_metadata_table)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 30 rows and 7 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(LongDat_disc_metadata_table)

## End(Not run)
</code></pre>

<hr>
<h2 id='make_master_table'>Create input master table from metadata and feature tables for
longdat_disc() and longdat_cont()</h2><span id='topic+make_master_table'></span>

<h3>Description</h3>

<p>Create input master table from metadata and feature tables for
longdat_disc() and longdat_cont()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_master_table(
  metadata_table,
  feature_table,
  sample_ID,
  individual,
  keep_id = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_master_table_+3A_metadata_table">metadata_table</code></td>
<td>
<p>A data frame whose columns consist of
sample identifiers (sample_ID), individual, time point and other meta data.
Each row corresponds to one sample_ID. Metadata table should have the same
number of rows as feature table does. Please avoid using characters that
don't belong to ASCII printable characters for the column names.</p>
</td></tr>
<tr><td><code id="make_master_table_+3A_feature_table">feature_table</code></td>
<td>
<p>A data frame whose columns only consist of
sample identifiers (sample_ID) and features
(dependent variables, e.g. microbiome). Each row corresponds to
one sample_ID. Please do not include any columns other than
sample_ID and features. Please avoid using characters that
don't belong to ASCII printable characters for the column names.
Also, feature table should have the same number
of rows as metadata table does.</p>
</td></tr>
<tr><td><code id="make_master_table_+3A_sample_id">sample_ID</code></td>
<td>
<p>The name of the column which stores sample identifiers.
Please make sure that sample_IDs are unique for each sample, and that
metadata and feature tables have the same sample_IDs. If sample_IDs don't
match between the two tables, it will fail to join them together. This
should be a string, e.g. &quot;Sample_ID&quot;</p>
</td></tr>
<tr><td><code id="make_master_table_+3A_individual">individual</code></td>
<td>
<p>The name of the column which stores individual information
in the metadata table. This should be a string, e.g. &quot;Individual&quot;</p>
</td></tr>
<tr><td><code id="make_master_table_+3A_keep_id">keep_id</code></td>
<td>
<p>A boolean vector indicating whether keep sample_ID
column in the output master table. The default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function joins metadata and feature tables by the sample_ID
column. Users can create master tables compatible with the format of
longdat_disc() and longdat_cont() input easily.This function outputs a
master table with individual as the first column, followed by time point
and other metadata, and then by feature columns.
</p>


<h3>Value</h3>

<p>a data frame which complies with the required format of an input
data frame for longdat_disc() and longdat_cont().
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_master &lt;- make_master_table(
metadata_table = LongDat_disc_metadata_table,
feature_table = LongDat_disc_feature_table,
sample_ID = "Sample_ID",
individual = "Individual")
</code></pre>

<hr>
<h2 id='NuModelTest_cont'>Null Model Test and post-hoc Test in longdat_cont() pipeline</h2><span id='topic+NuModelTest_cont'></span>

<h3>Description</h3>

<p>Null Model Test and post-hoc Test in longdat_cont() pipeline
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="NuModelTest_cont_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_cont_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_cont_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_cont_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_cont_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_cont_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='NuModelTest_disc'>Null Model Test and post-hoc Test in longdat_disc() pipeline</h2><span id='topic+NuModelTest_disc'></span>

<h3>Description</h3>

<p>Null Model Test and post-hoc Test in longdat_disc() pipeline
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="NuModelTest_disc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_disc_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_disc_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_disc_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_disc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="NuModelTest_disc_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='random_neg_ctrl_cont'>Randomized negative control for count data in longdat_cont()</h2><span id='topic+random_neg_ctrl_cont'></span>

<h3>Description</h3>

<p>Randomized negative control for count data in longdat_cont()
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_neg_ctrl_cont_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_variable_col">variable_col</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_fac_var">fac_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_not_used">not_used</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_factors">factors</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_adjustmethod">adjustMethod</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_model_q">model_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_cont_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='random_neg_ctrl_disc'>Randomized negative control for count data in longdat_disc()</h2><span id='topic+random_neg_ctrl_disc'></span>

<h3>Description</h3>

<p>Randomized negative control for count data in longdat_disc()
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_neg_ctrl_disc_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_variable_col">variable_col</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_fac_var">fac_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_not_used">not_used</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_factors">factors</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_data_type">data_type</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_case_pairs">case_pairs</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_adjustmethod">adjustMethod</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_model_q">model_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_posthoc_q">posthoc_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="random_neg_ctrl_disc_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='rm_sparse_cont'>Remove the dependent variables that are below the threshold of
sparsity when the data type is count data in longdat_cont()</h2><span id='topic+rm_sparse_cont'></span>

<h3>Description</h3>

<p>Remove the dependent variables that are below the threshold of
sparsity when the data type is count data in longdat_cont()
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm_sparse_cont_+3A_values">values</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_ps_null_model">Ps_null_model</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_prevalence">prevalence</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_absolute_sparsity">absolute_sparsity</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_mean_abundance">mean_abundance</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_p_poho">p_poho</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_cont_+3A_assoc">assoc</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='rm_sparse_disc'>Remove the dependent variables that are below the threshold
of sparsity when the data type is count data in longdat_disc()</h2><span id='topic+rm_sparse_disc'></span>

<h3>Description</h3>

<p>Remove the dependent variables that are below the threshold
of sparsity when the data type is count data in longdat_disc()
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="rm_sparse_disc_+3A_values">values</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_nonzero_count_cutoff1">nonzero_count_cutoff1</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_nonzero_count_cutoff2">nonzero_count_cutoff2</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_theta_cutoff">theta_cutoff</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_ps_null_model">Ps_null_model</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_prevalence">prevalence</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_absolute_sparsity">absolute_sparsity</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_mean_abundance">mean_abundance</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_ps_poho_fdr">Ps_poho_fdr</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="rm_sparse_disc_+3A_delta">delta</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='theta_plot'>Plot theta values of negative binomial models versus non-zero count
for count data</h2><span id='topic+theta_plot'></span>

<h3>Description</h3>

<p>Plot theta values of negative binomial models versus non-zero count
for count data
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="theta_plot_+3A_input">input</code></td>
<td>
<p>A data frame with the first column as &quot;Individual&quot;
and all the columns of dependent variables (features, e.g. bacteria)
at the end of the table.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_test_var">test_var</code></td>
<td>
<p>The name of the independent variable you are testing for,
should be a character vector (e.g. c(&quot;Time&quot;))
identical to its column name and make sure there is no space in it.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_variable_col">variable_col</code></td>
<td>
<p>The column number of the position where the dependent
variable columns (e.g. bacteria) start in the table</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_fac_var">fac_var</code></td>
<td>
<p>The column numbers of the position where the columns
that aren't numerical  (e.g. characters, categorical numbers,
ordinal numbers), should be a numerical vector (e.g. c(1, 2, 5:7))</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_not_used">not_used</code></td>
<td>
<p>The column position of the columns not are irrelevant and
can be ignored when in the analysis.
This should be a number vector, and the default is NULL.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_point_size">point_size</code></td>
<td>
<p>The point size for plotting in 'ggplot2'. The default is 1.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_x_interval_value">x_interval_value</code></td>
<td>
<p>The interval value for tick marks on x-axis.
The default is 5.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_y_interval_value">y_interval_value</code></td>
<td>
<p>The interval value for tick marks on y-axis.
The default is 5.</p>
</td></tr>
<tr><td><code id="theta_plot_+3A_verbose">verbose</code></td>
<td>
<p>A boolean vector indicating whether to print detailed
message.
The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function outputs a plot that facilitates the setting of theta_cutoff
in longdat_disc() and longdat_cont(). This only applies when the dependent
variables are count data. longdat_disc() and longdat_cont() implements
negative binomial (NB) model for count data,
and if the theta (dispersion parameter) of
NB model gets too high, then the p value of it will be extremely low
regardless of whether there is real significance
or not. Therefore, the highest threshold of theta value is set and any
variable beyond the threshold will be excluded
from the test. The default value of theta_cutoff is set to 2^20 from the
observation that 2^20 is a clear cutoff line
for several datasets. Users can change theta_cutoff value to fit
their own data.
</p>


<h3>Value</h3>

<p>a 'ggplot' object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_theta_plot &lt;- theta_plot(input = LongDat_disc_master_table,
 test_var = "Time_point", variable_col = 7, fac_var = c(1:3))
</code></pre>

<hr>
<h2 id='unlist_table'>Unlist confound (covariate) and inverse confound (covariate) tables,
turn them into tables</h2><span id='topic+unlist_table'></span>

<h3>Description</h3>

<p>Unlist confound (covariate) and inverse confound (covariate) tables,
turn them into tables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unlist_table(x, N, variables)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unlist_table_+3A_x">x</code></td>
<td>
<p>The list to be unlisted and turned into table</p>
</td></tr>
<tr><td><code id="unlist_table_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="unlist_table_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

<hr>
<h2 id='wilcox_posthoc'>Wilcoxon post-hoc test</h2><span id='topic+wilcox_posthoc'></span>

<h3>Description</h3>

<p>Wilcoxon post-hoc test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wilcox_posthoc(
  result_neg_ctrl,
  model_q,
  melt_data,
  test_var,
  variables,
  data,
  N,
  verbose
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wilcox_posthoc_+3A_result_neg_ctrl">result_neg_ctrl</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_model_q">model_q</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_melt_data">melt_data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_test_var">test_var</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_variables">variables</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_data">data</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_n">N</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
<tr><td><code id="wilcox_posthoc_+3A_verbose">verbose</code></td>
<td>
<p>Internal function argument.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
