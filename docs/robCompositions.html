<!DOCTYPE html><html><head><title>Help for package robCompositions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {robCompositions}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#robCompositions-package'><p>Robust Estimation for Compositional Data.</p></a></li>
<li><a href='#addLR'><p>Additive logratio coordinates</p></a></li>
<li><a href='#addLRinv'><p>Inverse additive logratio mapping</p></a></li>
<li><a href='#aDist'><p>Aitchison distance</p></a></li>
<li><a href='#adjust'><p>Adjusting for original scale</p></a></li>
<li><a href='#adtest'><p>Anderson-Darling Normality Tests</p></a></li>
<li><a href='#adtestWrapper'><p>Wrapper for Anderson-Darling tests</p></a></li>
<li><a href='#ageCatWorld'><p>child, middle and eldery population</p></a></li>
<li><a href='#alcohol'><p>alcohol consumptions by country and type of alcohol</p></a></li>
<li><a href='#alcoholreg'><p>regional alcohol per capita (15+) consumption by WHO region</p></a></li>
<li><a href='#arcticLake'><p>arctic lake sediment data</p></a></li>
<li><a href='#balances'><p>Balance calculation</p></a></li>
<li><a href='#biomarker'><p>biomarker</p></a></li>
<li><a href='#biplot.factanal'><p>Biplot method</p></a></li>
<li><a href='#biplot.pcaCoDa'><p>Biplot method</p></a></li>
<li><a href='#bootnComp'><p>Bootstrap to find optimal number of components</p></a></li>
<li><a href='#bpc'><p>Backwards pivot coordinates and their inverse</p></a></li>
<li><a href='#bpcPca'><p>Principal component analysis based on backwards pivot coordinates</p></a></li>
<li><a href='#bpcPcaTab'><p>Principal component analysis of compositional tables based on backwards pivot coordinates</p></a></li>
<li><a href='#bpcReg'><p>Classical and robust regression based on backwards pivot coordinates</p></a></li>
<li><a href='#bpcRegTab'><p>Classical and robust regression based on backwards pivot coordinates</p></a></li>
<li><a href='#bpcTab'><p>Backwards pivot coordinates and their inverse</p></a></li>
<li><a href='#bpcTabWrapper'><p>Backwards pivot coordinates and their inverse</p></a></li>
<li><a href='#cancer'><p>hospital discharges on cancer and distribution of age</p></a></li>
<li><a href='#cancerMN'><p>malignant neoplasms cancer</p></a></li>
<li><a href='#ced'><p>Compositional error deviation</p></a></li>
<li><a href='#cenLR'><p>Centred logratio coefficients</p></a></li>
<li><a href='#cenLRinv'><p>Inverse centred logratio mapping</p></a></li>
<li><a href='#chorizonDL'><p>C-horizon of the Kola data with rounded zeros</p></a></li>
<li><a href='#clustCoDa'><p>Cluster analysis for compositional data</p></a></li>
<li><a href='#clustCoDa_qmode'><p>Q-mode cluster analysis for compositional parts</p></a></li>
<li><a href='#coffee'><p>coffee data set</p></a></li>
<li><a href='#compareMahal'><p>Compares Mahalanobis distances from two approaches</p></a></li>
<li><a href='#compositionalSpline'><p>Compositional spline</p></a></li>
<li><a href='#constSum'><p>Constant sum</p></a></li>
<li><a href='#coord'><p>Coordinate representation of compositional tables</p></a></li>
<li><a href='#corCoDa'><p>Correlations for compositional data</p></a></li>
<li><a href='#cubeCoord'><p>Coordinate representation of a compositional cube and of a sample of compositional cubes</p></a></li>
<li><a href='#daCoDa'><p>Linear and quadratic discriminant analysis for compositional data.</p></a></li>
<li><a href='#daFisher'><p>Discriminant analysis by Fisher Rule.</p></a></li>
<li><a href='#economy'><p>economic indicators</p></a></li>
<li><a href='#educFM'><p>education level of father (F) and mother (M)</p></a></li>
<li><a href='#efsa'><p>efsa nutrition consumption</p></a></li>
<li><a href='#election'><p>election data</p></a></li>
<li><a href='#electionATbp'><p>Austrian presidential election data</p></a></li>
<li><a href='#employment'><p>employment in different countries by gender and status.</p></a></li>
<li><a href='#employment_df'><p>Employment in different countries by gender and status.</p></a></li>
<li><a href='#employment2'><p>Employment in different countries by Sex, Age, Contract, Value</p></a></li>
<li><a href='#expenditures'><p>synthetic household expenditures toy data set</p></a></li>
<li><a href='#expendituresEU'><p>mean consumption expenditures data.</p></a></li>
<li><a href='#fcenLR'><p>fcenLR transformation (functional)</p></a></li>
<li><a href='#fcenLRinv'><p>Inverse of fcenLR transformations (functional)</p></a></li>
<li><a href='#fcenLRp'><p>fcenLRp transformation (functional)</p></a></li>
<li><a href='#fcenLRu'><p>fcenLRu transformation (functional)</p></a></li>
<li><a href='#foodbalance'><p>country food balances</p></a></li>
<li><a href='#GDPsatis'><p>GDP satisfaction</p></a></li>
<li><a href='#gemas'><p>GEMAS geochemical data set</p></a></li>
<li><a href='#gjovik'><p>gjovik</p></a></li>
<li><a href='#gm'><p>gmean</p></a></li>
<li><a href='#gmean_sum'><p>Geometric mean</p></a></li>
<li><a href='#govexp'><p>government spending</p></a></li>
<li><a href='#haplogroups'><p>haplogroups data.</p></a></li>
<li><a href='#honey'><p>honey compositions</p></a></li>
<li><a href='#ilr.2x2'><p>ilr coordinates in 2x2 compositional tables</p></a></li>
<li><a href='#impAll'><p>Replacement of rounded zeros and missing values.</p></a></li>
<li><a href='#impCoda'><p>Imputation of missing values in compositional data</p></a></li>
<li><a href='#impKNNa'><p>Imputation of missing values in compositional data using knn methods</p></a></li>
<li><a href='#impRZalr'><p>alr EM-based imputation of rounded zeros</p></a></li>
<li><a href='#impRZilr'><p>EM-based replacement of rounded zeros in compositional data</p></a></li>
<li><a href='#imputeBDLs'><p>EM-based replacement of rounded zeros in compositional data</p></a></li>
<li><a href='#imputeUDLs'><p>Imputation of values above an upper detection limit in compositional data</p></a></li>
<li><a href='#ind2x2'><p>Independence 2x2 compositional table</p></a></li>
<li><a href='#indTab'><p>Independence table</p></a></li>
<li><a href='#instw'><p>value added, output and input for different ISIC codes and countries.</p></a></li>
<li><a href='#int2x2'><p>Interaction 2x2 table</p></a></li>
<li><a href='#intArray'><p>Interaction array</p></a></li>
<li><a href='#intTab'><p>Interaction table</p></a></li>
<li><a href='#is.equivalent'><p>equivalence class</p></a></li>
<li><a href='#isic32'><p>ISIC codes by name</p></a></li>
<li><a href='#laborForce'><p>labour force by status in employment</p></a></li>
<li><a href='#landcover'><p>European land cover</p></a></li>
<li><a href='#lifeExpGdp'><p>life expectancy and GDP (2008) for EU-countries</p></a></li>
<li><a href='#lmCoDaX'><p>Classical and robust regression of non-compositional (real) response on</p>
compositional and non-compositional predictors</a></li>
<li><a href='#machineOperators'><p>machine operators</p></a></li>
<li><a href='#manu_abs'><p>Distribution of manufacturing output</p></a></li>
<li><a href='#mcad'><p>metabolomics mcad data set</p></a></li>
<li><a href='#missPatterns'><p>missing or zero pattern structure.</p></a></li>
<li><a href='#mortality'><p>mortality and life expectancy in the EU</p></a></li>
<li><a href='#mortality_tab'><p>mortality table</p></a></li>
<li><a href='#norm1'><p>Normalize a vector to length 1</p></a></li>
<li><a href='#nutrients'><p>nutrient contents</p></a></li>
<li><a href='#nutrients_branded'><p>nutrient contents (branded)</p></a></li>
<li><a href='#orthbasis'><p>Orthonormal basis</p></a></li>
<li><a href='#outCoDa'><p>Outlier detection for compositional data</p></a></li>
<li><a href='#payments'><p>special payments</p></a></li>
<li><a href='#pcaCoDa'><p>Robust principal component analysis for compositional data</p></a></li>
<li><a href='#perturbation'><p>Perturbation and powering</p></a></li>
<li><a href='#pfa'><p>Factor analysis for compositional data</p></a></li>
<li><a href='#phd'><p>PhD students in the EU</p></a></li>
<li><a href='#phd_totals'><p>PhD students in the EU (totals)</p></a></li>
<li><a href='#pivotCoord'><p>Pivot coordinates and their inverse</p></a></li>
<li><a href='#plot.imp'><p>Plot method for objects of class imp</p></a></li>
<li><a href='#plot.pcaCoDa'><p>Plot method</p></a></li>
<li><a href='#plot.smoothSpl'><p>plot smoothSpl</p></a></li>
<li><a href='#precipitation'><p>24-hour precipitation</p></a></li>
<li><a href='#print.imp'><p>Print method for objects of class imp</p></a></li>
<li><a href='#production'><p>production splitted by nationality on enterprise level</p></a></li>
<li><a href='#pTab'><p>Propability table</p></a></li>
<li><a href='#rcodes'><p>codes for UNIDO tables</p></a></li>
<li><a href='#rdcm'><p>relative difference between covariance matrices</p></a></li>
<li><a href='#rSDev'><p>Relative simplicial deviance</p></a></li>
<li><a href='#rSDev.test'><p>Relative simplicial deviance tests</p></a></li>
<li><a href='#saffron'><p>saffron compositions</p></a></li>
<li><a href='#SDev'><p>Simplicial deviance</p></a></li>
<li><a href='#skyeLavas'><p>aphyric skye lavas data</p></a></li>
<li><a href='#smoothSplines'><p>Estimate density from histogram</p></a></li>
<li><a href='#smoothSplinesVal'><p>Estimate density from histogram - for different <code>alpha</code></p></a></li>
<li><a href='#socExp'><p>social expenditures</p></a></li>
<li><a href='#stats'><p>Classical estimates for tables</p></a></li>
<li><a href='#summary.imp'><p>Summary method for objects of class imp</p></a></li>
<li><a href='#tabCoord'><p>Coordinate representation of compositional tables and a sample of compositional tables</p></a></li>
<li><a href='#teachingStuff'><p>teaching stuff</p></a></li>
<li><a href='#ternaryDiag'><p>Ternary diagram</p></a></li>
<li><a href='#ternaryDiagAbline'><p>Adds a line to a ternary diagram.</p></a></li>
<li><a href='#ternaryDiagEllipse'><p>Adds tolerance ellipses to a ternary diagram.</p></a></li>
<li><a href='#ternaryDiagPoints'><p>Add points or lines to a given ternary diagram.</p></a></li>
<li><a href='#trapzc'><p>Trapezoidal formula for numerical integration</p></a></li>
<li><a href='#trondelagC'><p>regional geochemical survey of soil C in Norway</p></a></li>
<li><a href='#trondelagO'><p>regional geochemical survey of soil O in Norway</p></a></li>
<li><a href='#unemployed'><p>unemployed of young people</p></a></li>
<li><a href='#variation'><p>Robust and classical variation matrix</p></a></li>
<li><a href='#weightedPivotCoord'><p>Weighted pivot coordinates</p></a></li>
<li><a href='#ZBsplineBasis'><p>ZB-spline basis</p></a></li>
<li><a href='#zeroOut'><p>Detection of outliers of zero-inflated data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Compositional Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-21</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), ggplot2, pls, data.table</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Imports:</td>
<td>cvTools, e1071, fda, rrcov, cluster, dplyr, magrittr, fpc,
GGally, ggfortify, kernlab, MASS, mclust, tidyr, robustbase,
robustHD, splines, VIM, zCompositions, reshape2, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthias Templ &lt;matthias.templ@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for analysis of compositional data including robust
    methods  (&lt;<a href="https://doi.org/10.1007%2F978-3-319-96422-5">doi:10.1007/978-3-319-96422-5</a>&gt;), imputation of missing values (&lt;<a href="https://doi.org/10.1016%2Fj.csda.2009.11.023">doi:10.1016/j.csda.2009.11.023</a>&gt;), methods to replace 
    rounded zeros (&lt;<a href="https://doi.org/10.1080%2F02664763.2017.1410524">doi:10.1080/02664763.2017.1410524</a>&gt;, &lt;<a href="https://doi.org/10.1016%2Fj.chemolab.2016.04.011">doi:10.1016/j.chemolab.2016.04.011</a>&gt;, &lt;<a href="https://doi.org/10.1016%2Fj.csda.2012.02.012">doi:10.1016/j.csda.2012.02.012</a>&gt;), 
    count zeros (&lt;<a href="https://doi.org/10.1177%2F1471082X14535524">doi:10.1177/1471082X14535524</a>&gt;), 
    methods to deal with essential zeros (&lt;<a href="https://doi.org/10.1080%2F02664763.2016.1182135">doi:10.1080/02664763.2016.1182135</a>&gt;), (robust) outlier
    detection for compositional data, (robust) principal component analysis for
    compositional data, (robust) factor analysis for compositional data, (robust)
    discriminant analysis for compositional data (Fisher rule), robust regression
    with compositional predictors, functional data analysis (&lt;<a href="https://doi.org/10.1016%2Fj.csda.2015.07.007">doi:10.1016/j.csda.2015.07.007</a>&gt;) and p-splines (&lt;<a href="https://doi.org/10.1016%2Fj.csda.2015.07.007">doi:10.1016/j.csda.2015.07.007</a>&gt;), 
    contingency (&lt;<a href="https://doi.org/10.1080%2F03610926.2013.824980">doi:10.1080/03610926.2013.824980</a>&gt;) 
    and compositional tables (&lt;<a href="https://doi.org/10.1111%2Fsjos.12326">doi:10.1111/sjos.12326</a>&gt;, &lt;<a href="https://doi.org/10.1111%2Fsjos.12223">doi:10.1111/sjos.12223</a>&gt;, &lt;<a href="https://doi.org/10.1080%2F02664763.2013.856871">doi:10.1080/02664763.2013.856871</a>&gt;) 
    and (robust) Anderson-Darling normality tests for
    compositional data as well as popular log-ratio transformations (addLR, cenLR,
    isomLR, and their inverse transformations). In addition, visualisation and
    diagnostic tools are implemented as well as high and low-level plot functions
    for the ternary diagram.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-25 15:02:41 UTC; matthias</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthias Templ <a href="https://orcid.org/0000-0002-8638-5276"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Karel Hron <a href="https://orcid.org/0000-0002-1847-6598"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Peter Filzmoser <a href="https://orcid.org/0000-0002-8014-4682"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Kamila Facevicova [ctb],
  Petra Kynclova [ctb],
  Jan Walach [ctb],
  Veronika Pintar [ctb],
  Jiajia Chen [ctb],
  Dominika Miksova [ctb],
  Bernhard Meindl [ctb],
  Alessandra Menafoglio
    <a href="https://orcid.org/0000-0003-0682-6412"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Alessia Di Blasi [ctb],
  Federico Pavone [ctb],
  Nikola Stefelova [ctb],
  Gianluca Zeni [ctb],
  Roman Wiederkehr [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-25 15:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='robCompositions-package'>Robust Estimation for Compositional Data.</h2><span id='topic+robCompositions-package'></span><span id='topic+robCompositions'></span>

<h3>Description</h3>

<p>The package contains methods for imputation of compositional data including
robust methods, (robust) outlier detection for compositional data, (robust)
principal component analysis for compositional data, (robust) factor
analysis for compositional data, (robust) discriminant analysis (Fisher
rule) and (robust) Anderson-Darling normality tests for compositional data
as well as popular log-ratio transformations (alr, clr, ilr, and their
inverse transformations).
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Peter Filzmoser, Karel Hron,
</p>
<p>Maintainer: Matthias Templ &lt;templ@tuwien.ac.at&gt;
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p. 
</p>
<p>Filzmoser, P., and Hron, K. (2008) Outlier detection for compositional data
using robust methods. <em>Math. Geosciences</em>, <b>40</b> 233-248.
</p>
<p>Filzmoser, P., Hron, K., Reimann, C. (2009) Principal Component Analysis for
Compositional Data with Outliers. <em>Environmetrics</em>, <b>20</b> (6),
621&ndash;632.
</p>
<p>P. Filzmoser, K. Hron, C. Reimann, R. Garrett (2009): Robust Factor Analysis
for Compositional Data.  <em>Computers and Geosciences</em>, <b>35</b> (9),
1854&ndash;1861.
</p>
<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of missing values
for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, <b>54</b> (12),
3095&ndash;3107.
</p>
<p>C. Reimann, P. Filzmoser, R.G. Garrett, and R. Dutter (2008): Statistical
Data Analysis Explained.  <em>Applied Environmental Statistics with R</em>.
John Wiley and Sons, Chichester, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## k nearest neighbor imputation
data(expenditures)
expenditures[1,3]
expenditures[1,3] &lt;- NA
impKNNa(expenditures)$xImp[1,3]

## iterative model based imputation
data(expenditures)
x &lt;- expenditures
x[1,3]
x[1,3] &lt;- NA
xi &lt;- impCoda(x)$xImp
xi[1,3]
s1 &lt;- sum(x[1,-3])
impS &lt;- sum(xi[1,-3])
xi[,3] * s1/impS

xi &lt;- impKNNa(expenditures)
xi
summary(xi)
## Not run: plot(xi, which=1)
plot(xi, which=2)
plot(xi, which=3)

## pca
data(expenditures)
p1 &lt;- pcaCoDa(expenditures)
p1
plot(p1)

## outlier detection
data(expenditures)
oD &lt;- outCoDa(expenditures)
oD
plot(oD)

## transformations
data(arcticLake)
x &lt;- arcticLake
x.alr &lt;- addLR(x, 2)
y &lt;- addLRinv(x.alr)
addLRinv(addLR(x, 3))
data(expenditures)
x &lt;- expenditures
y &lt;- addLRinv(addLR(x, 5))
head(x)
head(y)
addLRinv(x.alr, ivar=2, useClassInfo=FALSE)

data(expenditures)
eclr &lt;- cenLR(expenditures)
inveclr &lt;- cenLRinv(eclr)
head(expenditures)
head(inveclr)
head(cenLRinv(eclr$x.clr))

require(MASS)
Sigma &lt;- matrix(c(5.05,4.95,4.95,5.05), ncol=2, byrow=TRUE)
z &lt;- pivotCoordInv(mvrnorm(100, mu=c(0,2), Sigma=Sigma))

</code></pre>

<hr>
<h2 id='addLR'>Additive logratio coordinates</h2><span id='topic+addLR'></span>

<h3>Description</h3>

<p>The additive logratio coordinates map D-part compositional data from
the simplex into a (D-1)-dimensional real space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addLR(x, ivar = ncol(x), base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addLR_+3A_x">x</code></td>
<td>
<p>D-part compositional data</p>
</td></tr>
<tr><td><code id="addLR_+3A_ivar">ivar</code></td>
<td>
<p>Rationing part</p>
</td></tr>
<tr><td><code id="addLR_+3A_base">base</code></td>
<td>
<p>a positive or complex number: 
the base with respect to which logarithms are computed. Defaults to <code>exp(1)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional parts are divided by the rationing part before the
logarithm is taken.
</p>


<h3>Value</h3>

<p>A list of class &ldquo;alr&rdquo; which includes the following content:
</p>
<table>
<tr><td><code>x.alr</code></td>
<td>
<p>the resulting coordinates</p>
</td></tr> <tr><td><code>varx</code></td>
<td>
<p>the rationing variable</p>
</td></tr>
<tr><td><code>ivar</code></td>
<td>
<p>the index of the rationing variable, indicating the column
number of the rationing variable in the data matrix <em>x</em></p>
</td></tr>
<tr><td><code>cnames</code></td>
<td>
<p>the column names of <em>x</em></p>
</td></tr></table>
<p> The additional information such
as <em>cnames</em> or <em>ivar</em> is useful when an inverse mapping is
applied on the &lsquo;same&rsquo; data set.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addLRinv">addLRinv</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
x &lt;- arcticLake
x.alr &lt;- addLR(x, 2)
y &lt;- addLRinv(x.alr)
## This exactly fulfills:
addLRinv(addLR(x, 3))
data(expenditures)
x &lt;- expenditures
y &lt;- addLRinv(addLR(x, 5))
head(x)
head(y)
## --&gt; absolute values are preserved as well.

## preserve only the ratios:
addLRinv(x.alr, ivar=2, useClassInfo=FALSE)


</code></pre>

<hr>
<h2 id='addLRinv'>Inverse additive logratio mapping</h2><span id='topic+addLRinv'></span>

<h3>Description</h3>

<p>Inverse additive logratio mapping, often called additive logistic
transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addLRinv(x, cnames = NULL, ivar = NULL, useClassInfo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addLRinv_+3A_x">x</code></td>
<td>
<p>data set, object of class &ldquo;alr&rdquo;, &ldquo;matrix&rdquo; or
&ldquo;data.frame&rdquo;</p>
</td></tr>
<tr><td><code id="addLRinv_+3A_cnames">cnames</code></td>
<td>
<p>column names. If the object is of class &ldquo;alr&rdquo; the
column names are chosen from therein.</p>
</td></tr>
<tr><td><code id="addLRinv_+3A_ivar">ivar</code></td>
<td>
<p>index of the rationing part. If the object is of class
&ldquo;alr&rdquo; the column names are chosen from therein. If not and ivar is
not provided by the user, it is assumed that the rationing part was the last
column of the data in the simplex.</p>
</td></tr>
<tr><td><code id="addLRinv_+3A_useclassinfo">useClassInfo</code></td>
<td>
<p>if FALSE, the class information of object <code>x</code> is
not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function allows also to preserve absolute values when class info is
provided. Otherwise only the relative information is preserved.
</p>


<h3>Value</h3>

<p>the resulting compositional data matrix
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pivotCoordInv">pivotCoordInv</a></code>, <code><a href="#topic+cenLRinv">cenLRinv</a></code>,
<code><a href="#topic+cenLR">cenLR</a></code>, <code><a href="#topic+addLR">addLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
x &lt;- arcticLake
x.alr &lt;- addLR(x, 2)
y &lt;- addLRinv(x.alr)
## This exactly fulfills:
addLRinv(addLR(x, 3))
data(expenditures)
x &lt;- expenditures
y &lt;- addLRinv(addLR(x, 5, 2))
head(x)
head(y)
## --&gt; absolute values are preserved as well.

## preserve only the ratios:
addLRinv(x.alr, ivar=2, useClassInfo=FALSE)

</code></pre>

<hr>
<h2 id='aDist'>Aitchison distance</h2><span id='topic+aDist'></span><span id='topic+iprod'></span>

<h3>Description</h3>

<p>Computes the Aitchison distance between two observations, between two data
sets or within observations of one data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aDist(x, y = NULL)

iprod(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aDist_+3A_x">x</code></td>
<td>
<p>a vector, matrix or data.frame</p>
</td></tr>
<tr><td><code id="aDist_+3A_y">y</code></td>
<td>
<p>a vector, matrix or data.frame with equal dimension as <code>x</code> or NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distance measure accounts for the relative scale property of
compositional data. It measures the distance between two compositions if
<code>x</code> and <code>y</code> are vectors. It evaluates the sum of the distances between
<code>x</code> and <code>y</code> for each row of <code>x</code> and <code>y</code> if <code>x</code> and
<code>y</code> are matrices or data frames. It computes a n times n distance matrix (with n
the number of observations/compositions) if only <code>x</code> is provided.
</p>
<p>The underlying code is partly written in C and allows a fast computation also for
large data sets whenever <code>y</code> is supplied.
</p>


<h3>Value</h3>

<p>The Aitchison distance between two compositions or between two data
sets, or a distance matrix in case codey is not supplied.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Bernhard Meindl
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>
<p>Aitchison, J. and Barcelo-Vidal, C. and Martin-Fernandez, J.A. and
Pawlowsky-Glahn, V. (2000) Logratio analysis and compositional distance.
<em>Mathematical Geology</em>, <b>32</b>, 271-275.
</p>
<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of missing values
for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, vol 54 (12), pages
3095-3107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
x &lt;- xOrig &lt;- expenditures
## Aitchison distance between two 2 observations:
aDist(x[1, ], x[2, ])

## Aitchison distance of x:
aDist(x)

## Example of distances between matrices:
## set some missing values:
x[1,3] &lt;- x[3,5] &lt;- x[2,4] &lt;- x[5,3] &lt;- x[8,3] &lt;- NA

## impute the missing values:
xImp &lt;- impCoda(x, method="ltsReg")$xImp

## calculate the relative Aitchsion distance between xOrig and xImp:
aDist(xOrig, xImp)

data("expenditures") 
aDist(expenditures)  
x &lt;- expenditures[, 1]
y &lt;- expenditures[, 2]
aDist(x, y)
aDist(expenditures, expenditures)
</code></pre>

<hr>
<h2 id='adjust'>Adjusting for original scale</h2><span id='topic+adjust'></span>

<h3>Description</h3>

<p>Results from the model based iterative methods provides the results in
another scale (but the ratios are still the same). This function rescale the
output to the original scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_+3A_x">x</code></td>
<td>
<p>object from class &lsquo;imp&rsquo;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is self-explaining if you try the examples.
</p>


<h3>Value</h3>

<p>The object of class &lsquo;imp&rsquo; but with the adjusted imputed data.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of
missing values for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, In Press, Corrected
Proof, ISSN: 0167-9473, DOI:10.1016/j.csda.2009.11.023
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
x &lt;- expenditures
x[1,3] &lt;- x[2,4] &lt;- x[3,3] &lt;- x[3,4] &lt;- NA
xi &lt;- impCoda(x)
x
xi$xImp
adjust(xi)$xImp

</code></pre>

<hr>
<h2 id='adtest'>Anderson-Darling Normality Tests</h2><span id='topic+adtest'></span>

<h3>Description</h3>

<p>This function provides three kinds of Anderson-Darling Normality Tests
(Anderson and Darling, 1952).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adtest(x, R = 1000, locscatt = "standard")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adtest_+3A_x">x</code></td>
<td>
<p>either a numeric vector, or a data.frame, or a matrix</p>
</td></tr>
<tr><td><code id="adtest_+3A_r">R</code></td>
<td>
<p>Number of Monte Carlo simulations to obtain p-values</p>
</td></tr>
<tr><td><code id="adtest_+3A_locscatt">locscatt</code></td>
<td>
<p>standard for classical estimates of mean and (co)variance.
robust for robust estimates using &lsquo;covMcd()&rsquo; from package robustbase</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three version of the test are implemented (univariate, angle and radius
test) and it depends on the data which test is chosen.
</p>
<p>If the data is univariate the univariate Anderson-Darling test for normality
is applied.
</p>
<p>If the data is bivariate the angle Anderson-Darling test for normality is
performed out.
</p>
<p>If the data is multivariate the radius Anderson-Darling test for normality
is used.
</p>
<p>If &lsquo;locscatt&rsquo; is equal to &ldquo;robust&rdquo; then within the procedure,
robust estimates of mean and covariance are provided using &lsquo;covMcd()&rsquo;
from package robustbase.
</p>
<p>To provide estimates for the corresponding p-values, i.e. to compute the
probability of obtaining a result at least as extreme as the one that was
actually observed under the null hypothesis, we use Monte Carlo techniques
where we check how often the statistic of the underlying data is more
extreme than statistics obtained from simulated normal distributed data with
the same (column-wise-) mean(s) and (co)variance.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>The result of the corresponding test statistic</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The chosen method (univariate, angle or radius)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value</p>
</td></tr>
</table>


<h3>Note</h3>

<p>These functions are use by <code><a href="#topic+adtestWrapper">adtestWrapper</a></code>.
</p>


<h3>Author(s)</h3>

<p>Karel Hron, Matthias Templ
</p>


<h3>References</h3>

<p>Anderson, T.W. and Darling, D.A. (1952) Asymptotic theory of
certain goodness-of-fit criteria based on stochastic processes. <em>Annals
of Mathematical Statistics</em>, <b>23</b> 193-212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adtestWrapper">adtestWrapper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
adtest(rnorm(100))
data(machineOperators)
x &lt;- machineOperators
adtest(pivotCoord(x[,1:2]))
adtest(pivotCoord(x[,1:3]))
adtest(pivotCoord(x))
adtest(pivotCoord(x[,1:2]), locscatt="robust")

</code></pre>

<hr>
<h2 id='adtestWrapper'>Wrapper for Anderson-Darling tests</h2><span id='topic+adtestWrapper'></span><span id='topic+print.adtestWrapper'></span><span id='topic+summary.adtestWrapper'></span>

<h3>Description</h3>

<p>A set of Anderson-Darling tests (Anderson and Darling, 1952) are applied as
proposed by Aitchison (Aichison, 1986).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adtestWrapper(x, alpha = 0.05, R = 1000, robustEst = FALSE)

## S3 method for class 'adtestWrapper'
print(x, ...)

## S3 method for class 'adtestWrapper'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adtestWrapper_+3A_x">x</code></td>
<td>
<p>compositional data of class data.frame or matrix</p>
</td></tr>
<tr><td><code id="adtestWrapper_+3A_alpha">alpha</code></td>
<td>
<p>significance level</p>
</td></tr>
<tr><td><code id="adtestWrapper_+3A_r">R</code></td>
<td>
<p>Number of Monte Carlo simulations in order to provide p-values.</p>
</td></tr>
<tr><td><code id="adtestWrapper_+3A_robustest">robustEst</code></td>
<td>
<p>logical</p>
</td></tr>
<tr><td><code id="adtestWrapper_+3A_...">...</code></td>
<td>
<p>additional parameters for print and summary passed through</p>
</td></tr>
<tr><td><code id="adtestWrapper_+3A_object">object</code></td>
<td>
<p>an object of class adtestWrapper for the summary method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, the data is transformed using the &lsquo;ilr&rsquo;-transformation.  After
applying this transformation
</p>
<p>- all (D-1)-dimensional marginal, univariate distributions are tested using
the univariate Anderson-Darling test for normality.
</p>
<p>- all 0.5 (D-1)(D-2)-dimensional bivariate angle distributions are tested
using the Anderson-Darling angle test for normality.
</p>
<p>- the (D-1)-dimensional radius distribution is tested using the
Anderson-Darling radius test for normality.
</p>
<p>A print and a summary method are implemented. The latter one provides a similar output is proposed by (Pawlowsky-Glahn, et al. (2008). In addition
to that, p-values are provided.
</p>


<h3>Value</h3>

<table>
<tr><td><code>res</code></td>
<td>
<p> a list including each test result </p>
</td></tr> <tr><td><code>check</code></td>
<td>

<p>information about the rejection of the null hypothesis</p>
</td></tr> <tr><td><code>alpha</code></td>
<td>
<p> the
underlying significance level </p>
</td></tr> <tr><td><code>info</code></td>
<td>
<p> further information which is
used by the print and summary method. </p>
</td></tr> <tr><td><code>est</code></td>
<td>
 <p>&ldquo;standard&rdquo; for
standard estimation and &ldquo;robust&rdquo; for robust estimation </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ and Karel Hron
</p>


<h3>References</h3>

<p>Anderson, T.W. and Darling, D.A. (1952) <em>Asymptotic theory
of certain goodness-of-fit criteria based on stochastic processes</em> Annals of
Mathematical Statistics, <b>23</b> 193-212.
</p>
<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional Data</em>
Monographs on Statistics and Applied Probability. Chapman and Hall Ltd.,
London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adtest">adtest</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(machineOperators)
a &lt;- adtestWrapper(machineOperators, R=50) # choose higher value of R
a
summary(a)

</code></pre>

<hr>
<h2 id='ageCatWorld'>child, middle and eldery population</h2><span id='topic+ageCatWorld'></span>

<h3>Description</h3>

<p>Percentages of childs, middle generation and eldery population in 195 countries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ageCatWorld)
</code></pre>


<h3>Format</h3>

<p>A data frame with 195 rows and 4 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>&lt;15 </code>Percentage of people with age below 15
</p>
</li>
<li><p><code>15-60 </code>Percentage of people with age between 15 and 60
</p>
</li>
<li><p><code>60+ </code>Percentage of people with age above 60
</p>
</li>
<li><p><code>country </code>country of origin
</p>
</li></ul>

<p>The rows sum up to 100.
</p>


<h3>Author(s)</h3>

<p>extracted by Karel Hron and Eva Fiserova, implemented by Matthias Templ
</p>


<h3>References</h3>

<p>Fiserova, E. and Hron, K. (2012). Statistical Inference in Orthogonal Regression for Three-Part Compositional Data Using a Linear Model with Type-II Constraints. <em>Communications in Statistics - Theory and Methods</em>, 41 (13-14), 2367-2385.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ageCatWorld)
str(ageCatWorld)
summary(ageCatWorld)
rowSums(ageCatWorld[, 1:3])
ternaryDiag(ageCatWorld[, 1:3])
plot(pivotCoord(ageCatWorld[, 1:3]))
</code></pre>

<hr>
<h2 id='alcohol'>alcohol consumptions by country and type of alcohol</h2><span id='topic+alcohol'></span>

<h3>Description</h3>


<ul>
<li><p><code>country </code>Country
</p>
</li>
<li><p><code>year </code>Year
</p>
</li>
<li><p><code>beer </code>Consumption of pure alcohol on beer (in percentages)
</p>
</li>
<li><p><code>wine </code>Consumption of pure alcohol on wine (in percentages)
</p>
</li>
<li><p><code>spirits </code>Consumption of pure alcohol on spirits (in percentages)
</p>
</li>
<li><p><code>other </code>Consumption of pure alcohol on other beverages (in percentages)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(alcohol)
</code></pre>


<h3>Format</h3>

<p>A data frame with 193 rows and 6 variables
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>Transfered from the World Health Organisation website.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("alcohol")
str(alcohol)
summary(alcohol)
</code></pre>

<hr>
<h2 id='alcoholreg'>regional alcohol per capita (15+) consumption by WHO region</h2><span id='topic+alcoholreg'></span>

<h3>Description</h3>


<ul>
<li><p><code>country </code>Country
</p>
</li>
<li><p><code>year </code>Year
</p>
</li>
<li><p><code>recorded </code>Recorded alcohol consumption
</p>
</li>
<li><p><code>unrecorded </code>Unrecorded alcohol consumption
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(alcoholreg)
</code></pre>


<h3>Format</h3>

<p>A data frame with 6 rows and 4 variables
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>Transfered from the World Health Organisation website.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("alcoholreg")
alcoholreg
</code></pre>

<hr>
<h2 id='arcticLake'>arctic lake sediment data</h2><span id='topic+arcticLake'></span>

<h3>Description</h3>

<p>Sand, silt, clay compositions of 39 sediment samples at different water depths in an Arctic lake.
This data set can be found on page 359 of the Aitchison book (see reference).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(arcticLake)
</code></pre>


<h3>Format</h3>

<p>A data frame with 39 rows and 3 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>sand </code>numeric vector of percentages of sand
</p>
</li>
<li><p><code>silt </code>numeric vector of percentages of silt
</p>
</li>
<li><p><code>clay </code>numeric vector of percentages of clay
</p>
</li></ul>

<p>The rows sum up to 100, except for rounding errors.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Aitchison, J. (1986). <em>The Statistical Analysis of Compositional Data</em>. Monographs on Statistics and Applied Probability. Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
str(arcticLake)
summary(arcticLake)
rowSums(arcticLake)
ternaryDiag(arcticLake)
plot(pivotCoord(arcticLake))
</code></pre>

<hr>
<h2 id='balances'>Balance calculation</h2><span id='topic+balances'></span>

<h3>Description</h3>

<p>Given a D-dimensional compositional data set and a sequential binary partition,
the function bal calculates the balances in order to express the given data
in the (D-1)-dimensional real space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balances(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="balances_+3A_x">x</code></td>
<td>
<p>data frame or matrix, typically compositional data</p>
</td></tr>
<tr><td><code id="balances_+3A_y">y</code></td>
<td>
<p>binary partition</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequential binary partition constructs an orthonormal basis in the (D-1)-dimensional hyperplane
in real space, resulting in orthonormal coordinates with respect to the Aitchison geometry of compositional data.
</p>


<h3>Value</h3>

<table>
<tr><td><code>balances</code></td>
<td>
<p>The balances represent orthonormal coordinates which allow an interpretation in sense of groups of compositional parts.
Output is a matrix, the D-1 colums contain balance coordinates of the observations in the rows.</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>A Dx(D-1) contrast matrix associated with the orthonormal basis, corresponding to the sequential binary partition (in clr coefficients).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Veronika Pintar, Karel Hron, Matthias Templ
</p>


<h3>References</h3>

<p>(Egozcue, J.J., Pawlowsky-Glahn, V. (2005) Groups of parts and their balances in compositional data analysis. Mathematical Geology, 37 (7), 795???828.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures, package = "robCompositions")
y1 &lt;- data.frame(c(1,1,1,-1,-1),c(1,-1,-1,0,0),
                 c(0,+1,-1,0,0),c(0,0,0,+1,-1))
y2 &lt;- data.frame(c(1,-1,1,-1,-1),c(1,0,-1,0,0),
                 c(1,-1,1,-1,1),c(0,-1,0,1,0))
y3 &lt;- data.frame(c(1,1,1,1,-1),c(-1,-1,-1,+1,0),
                 c(-1,-1,+1,0,0),c(-1,1,0,0,0))
y4 &lt;- data.frame(c(1,1,1,-1,-1),c(0,0,0,-1,1),
                 c(-1,-1,+1,0,0),c(-1,1,0,0,0))
y5 &lt;- data.frame(c(1,1,1,-1,-1),c(-1,-1,+1,0,0),
                 c(0,0,0,-1,1),c(-1,1,0,0,0))
b1 &lt;- balances(expenditures, y1)
b2 &lt;- balances(expenditures, y5)
b1$balances
b2$balances

data(machineOperators)
sbp &lt;- data.frame(c(1,1,-1,-1),c(-1,+1,0,0),
                 c(0,0,+1,-1))
balances(machineOperators, sbp)

</code></pre>

<hr>
<h2 id='biomarker'>biomarker</h2><span id='topic+biomarker'></span><span id='topic+print.biomarker'></span><span id='topic+summary.biomarker'></span><span id='topic+plot.biomarker'></span>

<h3>Description</h3>

<p>The function for identification of biomakers and 
outlier diagnostics as described in paper &quot;Robust biomarker 
identification in a two-class problem based on pairwise log-ratios&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biomarker(
  x,
  cut = qnorm(0.975, 0, 1),
  g1,
  g2,
  type = "tau",
  diag = TRUE,
  plot = FALSE,
  diag.plot = FALSE
)

## S3 method for class 'biomarker'
plot(x, cut = qnorm(0.975, 0, 1), type = "Vstar", ...)

## S3 method for class 'biomarker'
print(x, ...)

## S3 method for class 'biomarker'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biomarker_+3A_x">x</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="biomarker_+3A_cut">cut</code></td>
<td>
<p>cut-off value, initialy set as 0.975 quantile of standard normal distribution</p>
</td></tr>
<tr><td><code id="biomarker_+3A_g1">g1</code></td>
<td>
<p>vector with locations of observations of group 1</p>
</td></tr>
<tr><td><code id="biomarker_+3A_g2">g2</code></td>
<td>
<p>vector with locations of observations of group 2</p>
</td></tr>
<tr><td><code id="biomarker_+3A_type">type</code></td>
<td>
<p>type of estimation of the variation matrix. Possible values are <code>"sd"</code>,  <code>"mad"</code> and <code>"tau"</code>, representing Standard deviation, Median absolute deviation and Tau estimator of scale</p>
</td></tr>
<tr><td><code id="biomarker_+3A_diag">diag</code></td>
<td>
<p>logical, indicating wheter outlier diagnostic should be computed</p>
</td></tr>
<tr><td><code id="biomarker_+3A_plot">plot</code></td>
<td>
<p>logical, indicating wheter Vstar values should be plotted</p>
</td></tr>
<tr><td><code id="biomarker_+3A_diag.plot">diag.plot</code></td>
<td>
<p>logical, indicating wheter outlier diagnostic plot should be made</p>
</td></tr>
<tr><td><code id="biomarker_+3A_...">...</code></td>
<td>
<p>further arguments can be passed through</p>
</td></tr>
<tr><td><code id="biomarker_+3A_object">object</code></td>
<td>
<p>object of class biomarker</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Robust biomarker identification and outlier diagnostics
</p>
<p>The method computes variation matrices separately with 
observations from both groups and also together with all observations. 
Then, <em>V</em> statistics is then computed and normalized. 
The variables, for which according <em>V*</em> values are bigger that the 
cut-off value are considered as biomarkers.
</p>


<h3>Value</h3>

<p>The function returns object of type &quot;biomarker&quot;.
Functions <code>print</code>, <code>plot</code> and <code>summary</code> are available.
</p>
<table>
<tr><td><code>biom.ident</code></td>
<td>
<p>List of <code>V, Vstar, biomarkers</code></p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Values of <em>V</em> statistics</p>
</td></tr>
<tr><td><code>Vstar</code></td>
<td>
<p>Normalizes values of <em>V</em> statistics (V^* values))</p>
</td></tr>
<tr><td><code>biomarkers</code></td>
<td>
<p>Logical value, indicating if certain variable was identified as biomarker</p>
</td></tr>
<tr><td><code>diag</code></td>
<td>
<p>Outlier diagnostics (returned only if <code>diag=TRUE</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jan Walach
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.biomarker">plot.biomarker</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(4523)
n &lt;- 40; p &lt;- 50
r &lt;- runif(p, min = 1, max = 10)
conc &lt;- runif(p, min = 0, max = 1)*5+matrix(1,p,1)*5
a &lt;- conc*r
S &lt;- rnorm(n,0,0.3) %*% t(rep(1,p))
B &lt;- matrix(rnorm(n*p,0,0.8),n,p)
R &lt;- rep(1,n) %*% t(r)
M &lt;- matrix(rnorm(n*p,0,0.021),n,p)
# Fifth observation is an outlier
M[5,] &lt;- M[5,]*3 + sample(c(0.5,-0.5),replace=TRUE,p)
C &lt;- rep(1,n) %*% t(conc)
C[1:20,c(2,15,28,40)] &lt;- C[1:20,c(2,15,28,40)]+matrix(1,20,4)*1.8
X &lt;- (1-S)*(C*R+B)*exp(M)
# Biomarker identification
b &lt;- biomarker(X, g1 = 1:20, g2 = 21:40, type = "tau")
</code></pre>

<hr>
<h2 id='biplot.factanal'>Biplot method</h2><span id='topic+biplot.factanal'></span>

<h3>Description</h3>

<p>Provides robust compositional biplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factanal'
biplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplot.factanal_+3A_x">x</code></td>
<td>
<p>object of class &lsquo;factanal&rsquo;</p>
</td></tr>
<tr><td><code id="biplot.factanal_+3A_...">...</code></td>
<td>
<p>...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The robust compositional biplot according to Aitchison and Greenacre (2002),
computed from resulting (robust) loadings and scores, is performed.
</p>


<h3>Value</h3>

<p>The robust compositional biplot.
</p>


<h3>Author(s)</h3>

<p>M. Templ, K. Hron
</p>


<h3>References</h3>

<p>Aitchison, J. and Greenacre, M. (2002). Biplots of compositional
data. <em>Applied Statistics</em>, <b>51</b>, 375-392. \
</p>
<p>Filzmoser, P., Hron, K., Reimann, C. (2009) Principal component analysis for
compositional data with outliers. <em>Environmetrics</em>, <b>20</b> (6),
621&ndash;632.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfa">pfa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
res.rob &lt;- pfa(expenditures, factors=2, scores = "regression")
biplot(res.rob)
</code></pre>

<hr>
<h2 id='biplot.pcaCoDa'>Biplot method</h2><span id='topic+biplot.pcaCoDa'></span>

<h3>Description</h3>

<p>Provides robust compositional biplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcaCoDa'
biplot(x, y, ..., choices = 1:2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplot.pcaCoDa_+3A_x">x</code></td>
<td>
<p>object of class &lsquo;pcaCoDa&rsquo;</p>
</td></tr>
<tr><td><code id="biplot.pcaCoDa_+3A_y">y</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="biplot.pcaCoDa_+3A_...">...</code></td>
<td>
<p>arguments passed to plot methods</p>
</td></tr>
<tr><td><code id="biplot.pcaCoDa_+3A_choices">choices</code></td>
<td>
<p>selection of two principal components by number. Default: c(1,2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The robust compositional biplot according to Aitchison and Greenacre (2002),
computed from (robust) loadings and scores resulting from <code><a href="#topic+pcaCoDa">pcaCoDa</a></code>, is performed.
</p>


<h3>Value</h3>

<p>The robust compositional biplot.
</p>


<h3>Author(s)</h3>

<p>M. Templ, K. Hron
</p>


<h3>References</h3>

<p>Aitchison, J. and Greenacre, M. (2002). Biplots of compositional
data. <em>Applied Statistics</em>, <b>51</b>, 375-392. \
</p>
<p>Filzmoser, P., Hron, K., Reimann, C. (2009) Principal component analysis for
compositional data with outliers. <em>Environmetrics</em>, <b>20</b> (6),
621&ndash;632.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcaCoDa">pcaCoDa</a></code>, <code><a href="#topic+plot.pcaCoDa">plot.pcaCoDa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
p1 &lt;- pcaCoDa(coffee[,-1])
p1
plot(p1, which = 2, choices = 1:2)

# exemplarly, showing the first and third PC
a &lt;- p1$princompOutputClr
biplot(a, choices = c(1,3))


## with labels for the scores:
data(arcticLake)
rownames(arcticLake) &lt;- paste(sample(letters[1:26], nrow(arcticLake), replace=TRUE), 
                              1:nrow(arcticLake), sep="")
pc &lt;- pcaCoDa(arcticLake, method="classical")
plot(pc, xlabs=rownames(arcticLake), which = 2)
plot(pc, xlabs=rownames(arcticLake), which = 3)

</code></pre>

<hr>
<h2 id='bootnComp'>Bootstrap to find optimal number of components</h2><span id='topic+bootnComp'></span>

<h3>Description</h3>

<p>Combined bootstrap and cross validation procedure to find optimal number of
PLS components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootnComp(X, y, R = 99, plotting = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootnComp_+3A_x">X</code></td>
<td>
<p>predictors as a matrix</p>
</td></tr>
<tr><td><code id="bootnComp_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id="bootnComp_+3A_r">R</code></td>
<td>
<p>number of bootstrap replicates</p>
</td></tr>
<tr><td><code id="bootnComp_+3A_plotting">plotting</code></td>
<td>
<p>if TRUE, a diagnostic plot is drawn for each bootstrap
replicate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Heavily used internally in function impRZilr.
</p>


<h3>Value</h3>

<p>Including other information in a list, the optimal number of
components
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impRZilr">impRZilr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## we refer to impRZilr()

</code></pre>

<hr>
<h2 id='bpc'>Backwards pivot coordinates and their inverse</h2><span id='topic+bpc'></span>

<h3>Description</h3>

<p>Backwards pivot coordinate representation of a set of compositional ventors as a special case of isometric logratio coordinates and their inverse mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpc(X, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpc_+3A_x">X</code></td>
<td>
<p>object of class data.frame. Positive values only.</p>
</td></tr>
<tr><td><code id="bpc_+3A_base">base</code></td>
<td>
<p>a positive number: the base with respect to which logarithms are computed. Defaults to exp(1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpc
</p>
<p>Backwards pivot coordinates map D-part compositional data from the simplex into a (D-1)-dimensional real space isometrically. The first coordinate has form of pairwise logratio log(x2/x1) and serves as an alternative to additive logratio transformation with part x1 being the rationing element. The remaining coordinates are structured as detailed in Nesrstova et al. (2023). 
Consequently, when a specific pairwise logratio is of the main interest, the respective columns have to be placed at the first (the compositional part in denominator of the logratio, the rationing element) and the second position (the compositional part in numerator) in the data matrix X.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Coordinates</code></td>
<td>
<p>array of orthonormal coordinates.</p>
</td></tr> 
<tr><td><code>Coordinates.ortg</code></td>
<td>
<p>array of orthogonal coordinates (without the normalising constant sqrt(i/i+1).</p>
</td></tr> 
<tr><td><code>Contrast.matrix</code></td>
<td>
<p>contrast matrix corresponding to the orthonormal coordinates.</p>
</td></tr>
<tr><td><code>Base</code></td>
<td>
<p>the base with respect to which logarithms are computed.</p>
</td></tr>
<tr><td><code>Levels</code></td>
<td>
<p>the order of compositional parts.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Hron, K., Coenders, G., Filzmoser, P., Palarea-Albaladejo, J., Famera, M., Matys Grygar, M. (2022). Analysing pairwise logratios revisited. Mathematical Geosciences 53, 1643 - 1666.
</p>
<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpcTab">bpcTab</a></code> 
<code><a href="#topic+bpcTabWrapper">bpcTabWrapper</a></code> 
<code><a href="#topic+bpcPca">bpcPca</a></code>
<code><a href="#topic+bpcReg">bpcReg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)

# default setting with ln()
bpc(expenditures)

# logarithm of base 2
bpc(expenditures, base = 2)
</code></pre>

<hr>
<h2 id='bpcPca'>Principal component analysis based on backwards pivot coordinates</h2><span id='topic+bpcPca'></span>

<h3>Description</h3>

<p>Performs classical or robust principal component analysis on system of backwards pivot coordinates and returns the result related to pairwise logratios as well as the clr representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcPca(X, robust = FALSE, norm.cat = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcPca_+3A_x">X</code></td>
<td>
<p>object of class data.frame. Positive values only.</p>
</td></tr>
<tr><td><code id="bpcPca_+3A_robust">robust</code></td>
<td>
<p>if TRUE, the MCD estimate is used. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="bpcPca_+3A_norm.cat">norm.cat</code></td>
<td>
<p>the rationing category placed at the first position in the composition. If not defined, all pairwise logratios are considered. Given in quotation marks.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcPca
</p>
<p>The compositional data set is repeatedly expressed in a set of backwards logratio coordinates, when each set highlights one pairwise logratio (or one pairwise logratio with the selected rationing category). 
For each set, robust or classical principal component analysis is performed and loadings respective to the first backwards pivot coordinate are stored. 
The procedure results in matrix of scores (invariant to the specific coordinate system), clr loading matrix and matrix with loadings respective to pairwise logratios.
</p>


<h3>Value</h3>

<table>
<tr><td><code>scores</code></td>
<td>
<p>array of scores.</p>
</td></tr> 
<tr><td><code>loadings</code></td>
<td>
<p>loadings related to the pairwise logratios. The names of the rows indicate the type of the respective coordinate 
(bpc.1 - the first backwards pivot coordinate) and the logratio quantified thereby. 
E.g. bpc.1_C2.to.C1 would therefore correspond to the logratio between compositional parts C1 and C2, schematically written log(C2/C1). See Nesrstova et al. (2023) for details.</p>
</td></tr> 
<tr><td><code>loadings.clr</code></td>
<td>
<p>loadings in the clr space.</p>
</td></tr> 
<tr><td><code>sdev</code></td>
<td>
<p>standard deviations of the principal components.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>means of the pairwise logratios.</p>
</td></tr>
<tr><td><code>center.clr</code></td>
<td>
<p>means of the clr coordinates.</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Hron, K., Coenders, G., Filzmoser, P., Palarea-Albaladejo, J., Famera, M., Matys Grygar, M. (2022). Analysing pairwise logratios revisited. Mathematical Geosciences 53, 1643 - 1666.
</p>
<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpc">bpc</a></code> 
<code><a href="#topic+bpcPcaTab">bpcPcaTab</a></code>
<code><a href="#topic+bpcReg">bpcReg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(arcticLake)

# classical estimation with all pairwise logratios:
res.cla &lt;- bpcPca(arcticLake)
summary(res.cla)
biplot(res.cla)
head(res.cla$scores)
res.cla$loadings
res.cla$loadings.clr

# similar output as from pca CoDa
res.cla2 &lt;- pcaCoDa(arcticLake, method="classical", solve = "eigen")
biplot(res.cla2)
head(res.cla2$scores)
res.cla2$loadings

# classical estimation focusing on pairwise logratios with clay:
res.cla.clay &lt;- bpcPca(arcticLake, norm.cat = "clay")
biplot(res.cla.clay)

# robust estimation with all pairwise logratios:
res.rob &lt;- bpcPca(arcticLake, robust = TRUE)
biplot(res.rob)

</code></pre>

<hr>
<h2 id='bpcPcaTab'>Principal component analysis of compositional tables based on backwards pivot coordinates</h2><span id='topic+bpcPcaTab'></span>

<h3>Description</h3>

<p>Performs classical or robust principal component analysis on a set of compositional tables, based on backwards pivot coordinates. Returns the result related to pairwise row and column balances and four-part log odds-ratios. The loadings in the clr space are available as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcPcaTab(
  X,
  obs.ID = NULL,
  row.factor = NULL,
  col.factor = NULL,
  value = NULL,
  robust = FALSE,
  norm.cat.row = NULL,
  norm.cat.col = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcPcaTab_+3A_x">X</code></td>
<td>
<p>object of class data.frame with columns corresponding to row and column factors of the respective compositional table, a variable with the values of the composition (positive values only) and a factor with observation IDs.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_obs.id">obs.ID</code></td>
<td>
<p>name of the factor variable distinguishing the observations. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_robust">robust</code></td>
<td>
<p>if TRUE, the MCD estimate is used. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_norm.cat.row">norm.cat.row</code></td>
<td>
<p>the rationing category of the row factor. If not defined, all pairs are considered. Given in quotation marks.</p>
</td></tr>
<tr><td><code id="bpcPcaTab_+3A_norm.cat.col">norm.cat.col</code></td>
<td>
<p>the rationing category of the column factor. If not defined, all pairs are considered. Given in quotation marks.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcPcaTab
</p>
<p>The set of compositional tables is repeatedly expressed in a set of backwards logratio coordinates, 
when each set highlights different combination of pairs of row and column factor categories, as detailed in Nesrstova et al. (2023). 
For each set, robust or classical principal component analysis is performed and loadings respective to the first row, column and odds-ratio backwards pivot coordinates are stored. 
The procedure results in matrix of scores (invariant to the specific coordinate system), clr loading matrix and matrix with loadings related to the selected backwards coordinates.
</p>


<h3>Value</h3>

<table>
<tr><td><code>scores</code></td>
<td>
<p>array of scores.</p>
</td></tr> 
<tr><td><code>loadings</code></td>
<td>
<p>loadings related to the selected backwards coordinates. The names of the rows indicate the type of the respective coordinate 
(rbpb.1 - the first row backwards pivot balance, cbpb.1 - the first column backwards pivot balance and tbpc.1.1 - the first table backwards pivot coordinate) and the logratio or log odds-ratio quantified thereby. 
E.g. cbpb.1_C2.to.C1 would therefore correspond to the logratio between column categories C1 and C2, schematically written log(C2/C1), and tbpc.1.1_R2.to.R1.&amp;.C2.to.C1 would correspond to the log odds-ratio computed from a 2x2 table, 
which is formed by row categories R1 and R2 and columns C1 and C2. See Nesrstova et al. (2023) for details.</p>
</td></tr> 
<tr><td><code>loadings.clr</code></td>
<td>
<p>loadings in the clr space. The names of the rows indicate the position of respective part in the clr representation of the compositional table, labeled as row.category_column.category.</p>
</td></tr> 
<tr><td><code>sdev</code></td>
<td>
<p>standard deviations of the principal components.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>means of the selected backwards coordinates.</p>
</td></tr>
<tr><td><code>center.clr</code></td>
<td>
<p>means of the clr coordinates.</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpcTabWrapper">bpcTabWrapper</a></code> 
<code><a href="#topic+bpcPca">bpcPca</a></code>
<code><a href="#topic+bpcRegTab">bpcRegTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(manu_abs)
manu_abs$output &lt;- as.factor(manu_abs$output)
manu_abs$isic &lt;- as.factor(manu_abs$isic)

# classical estimation with all pairwise balances and four-part ORs:
res.cla &lt;- bpcPcaTab(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value")
summary(res.cla)
biplot(res.cla)
head(res.cla$scores)
res.cla$loadings
res.cla$loadings.clr

# classical estimation with LAB anf 155 as rationing categories
res.cla.select &lt;- bpcPcaTab(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value", norm.cat.row = "LAB", norm.cat.col = "155")
summary(res.cla.select)
biplot(res.cla.select)
head(res.cla.select$scores)
res.cla.select$loadings
res.cla.select$loadings.clr

# robust estimation with all pairwise balances and four-part ORs:
res.rob &lt;- bpcPcaTab(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value", robust = TRUE)
summary(res.rob)
biplot(res.rob)
head(res.rob$scores)
res.rob$loadings
res.rob$loadings.clr
</code></pre>

<hr>
<h2 id='bpcReg'>Classical and robust regression based on backwards pivot coordinates</h2><span id='topic+bpcReg'></span>

<h3>Description</h3>

<p>Performs classical or robust regression analysis of real response on compositional predictors, represented in backwards pivot coordinates. Also non-compositional covariates can be included (additively).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcReg(
  X,
  y,
  external = NULL,
  norm.cat = NULL,
  robust = FALSE,
  base = exp(1),
  norm.const = F,
  seed = 8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcReg_+3A_x">X</code></td>
<td>
<p>object of class data.frame with compositional (positive values only) and non-compositional predictors. The response y can be also included.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_y">y</code></td>
<td>
<p>character with the name of response (if included in X) or an array with values of the response.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_external">external</code></td>
<td>
<p>array with names of non-compositional predictors.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_norm.cat">norm.cat</code></td>
<td>
<p>the rationing category placed at the first position in the composition. If not defined, all pairwise logratios are considered. Given in quotation marks.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_robust">robust</code></td>
<td>
<p>if TRUE, the MM-type estimator is used. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_base">base</code></td>
<td>
<p>a positive number: the base with respect to which logarithms are computed. Defaults to exp(1).</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_norm.const">norm.const</code></td>
<td>
<p>if TRUE, the regression coefficients corresponding to orthonormal coordinates are given a s result. Defaults to FALSE, the normalising constant is omitted.</p>
</td></tr>
<tr><td><code id="bpcReg_+3A_seed">seed</code></td>
<td>
<p>a single value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcReg
</p>
<p>The compositional part of the data set is repeatedly expressed in a set of backwards logratio coordinates, when each set highlights one pairwise logratio (or one pairwise logratio with the selected rationing category). 
For each set (supplemented by non-compositonal predictors), robust MM or classical least squares estimate of regression coefficients is performed and information respective to the first backwards pivot coordinate is stored. 
The summary therefore collects results from several regression models, each leading to the same overall model characteristics, like the F statistics or R^2.
The coordinates are structured as detailed in Nesrstova et al. (2023).
In order to maintain consistency of the iterative results collected in the output, a seed is set before robust estimation of each of the models considered. Its specific value can be set via parameter seed.
</p>


<h3>Value</h3>

<p>A list containing:</p>

<dl>
<dt>Summary</dt><dd><p>the summary object which collects results from all coordinate systems. The names of the coefficients indicate the type of the respective coordinate 
(bpc.1 - the first backwards pivot coordinate) and the logratio quantified thereby. 
E.g. bpc.1_C2.to.C1 would therefore correspond to the logratio between compositional parts C1 and C2, schematically written log(C2/C1). See Nesrstova et al. (2023) for details.</p>
</dd> 
<dt>Base</dt><dd><p>the base with respect to which logarithms are computed</p>
</dd> 
<dt>Norm.const</dt><dd><p>the values of normalising constants (when results for orthonormal coordinates are reported).</p>
</dd>
<dt>Robust</dt><dd><p>TRUE if the MM estimator was applied.</p>
</dd>
<dt>lm</dt><dd><p>the lm object resulting from the first iteration.</p>
</dd>
<dt>Levels</dt><dd><p>the order of compositional parts cosidered in the first iteration.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Hron, K., Coenders, G., Filzmoser, P., Palarea-Albaladejo, J., Famera, M., Matys Grygar, M. (2022). Analysing pairwise logratios revisited. Mathematical Geosciences 53, 1643 - 1666.
</p>
<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpc">bpc</a></code> 
<code><a href="#topic+bpcPca">bpcPca</a></code>
<code><a href="#topic+bpcRegTab">bpcRegTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## How the total household expenditures in EU Member
## States depend on relative contributions of 
## single household expenditures:
data(expendituresEU)
y &lt;- as.numeric(apply(expendituresEU,1,sum))

# classical regression summarizing the effect of all pairwise logratios 
lm.cla &lt;- bpcReg(expendituresEU, y)
lm.cla

# gives the same model characteristics as lmCoDaX:
lm &lt;- lmCoDaX(y, expendituresEU, method="classical")
lm$ilr

# robust regression, with Food as the rationing category and logarithm of base 2
# response is part of the data matrix X
expendituresEU.y &lt;- data.frame(expendituresEU, total = y)
lm.rob &lt;- bpcReg(expendituresEU.y, "total", norm.cat = "Food", robust = TRUE, base = 2)
lm.rob

## Illustrative example with exports and imports (categorized) as non-compositional covariates
data(economy)
X.ext &lt;- economy[!economy$country2 %in% c("HR", "NO", "CH"), c("exports", "imports")]
X.ext$imports.cat &lt;- cut(X.ext$imports, quantile(X.ext$imports, c(0, 1/3, 2/3, 1)), 
labels = c("A", "B", "C"), include.lowest = TRUE)

X.y.ext &lt;- data.frame(expendituresEU.y, X.ext[, c("exports", "imports.cat")])

lm.ext &lt;- bpcReg(X.y.ext, y = "total", external = c("exports", "imports.cat"))
lm.ext
</code></pre>

<hr>
<h2 id='bpcRegTab'>Classical and robust regression based on backwards pivot coordinates</h2><span id='topic+bpcRegTab'></span>

<h3>Description</h3>

<p>Performs classical or robust regression analysis of real response on a compositional table, which is represented in backwards pivot coordinates.  Also non-compositional covariates can be included (additively).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcRegTab(
  X,
  y,
  obs.ID = NULL,
  row.factor = NULL,
  col.factor = NULL,
  value = NULL,
  external = NULL,
  norm.cat.row = NULL,
  norm.cat.col = NULL,
  robust = FALSE,
  base = exp(1),
  norm.const = F,
  seed = 8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcRegTab_+3A_x">X</code></td>
<td>
<p>object of class data.frame with columns corresponding to row and column factors of the respective compositional table, a variable with the values of the composition (positive values only) and a factor with observation IDs. The response y and non-compositional predictors can be also included.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_y">y</code></td>
<td>
<p>character with the name of response (if included in X), data frame with row names corresponding to observation IDs or a named array with values of the response.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_obs.id">obs.ID</code></td>
<td>
<p>name of the factor variable distinguishing the observations. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_external">external</code></td>
<td>
<p>array with names of non-compositional predictors.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_norm.cat.row">norm.cat.row</code></td>
<td>
<p>the rationing category of the row factor. If not defined, all pairs are considered. Given in quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_norm.cat.col">norm.cat.col</code></td>
<td>
<p>the rationing category of the column factor. If not defined, all pairs are considered. Given in quotation marks.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_robust">robust</code></td>
<td>
<p>if TRUE, the MM-type estimator is used. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_base">base</code></td>
<td>
<p>a positive number: the base with respect to which logarithms are computed. Defaults to exp(1).</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_norm.const">norm.const</code></td>
<td>
<p>if TRUE, the regression coefficients corresponding to orthonormal coordinates are given a s result. Defaults to FALSE, the normalising constant is omitted.</p>
</td></tr>
<tr><td><code id="bpcRegTab_+3A_seed">seed</code></td>
<td>
<p>a single value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcRegTab
</p>
<p>The set of compositional tables is repeatedly expressed in a set of backwards logratio coordinates, 
when each set highlights different combination of pairs of row and column factor categories, as detailed in Nesrstova et al. (2023).
For each coordinates system (supplemented by non-compositonal predictors), robust MM or classical least squares estimate of regression coefficients is performed and information respective to the first row, column and table backwards pivot coordinate is stored. 
The summary therefore collects results from several regression models, each leading to the same overall model characteristics, like the F statistics or R^2. 
In order to maintain consistency of the iterative results collected in the output, a seed is set before robust estimation of each of the models considered. Its specific value can be set via parameter seed.
</p>


<h3>Value</h3>

<p>A list containing:</p>

<dl>
<dt>Summary</dt><dd><p>the summary object which collects results from all coordinate systems. The names of the coefficients indicate the type of the respective coordinate 
(rbpb.1 - the first row backwards pivot balance, cbpb.1 - the first column backwards pivot balance and tbpc.1.1 - the first table backwards pivot coordinate) and the logratio or log odds-ratio quantified thereby. 
E.g. cbpb.1_C2.to.C1 would therefore correspond to the logratio between column categories C1 and C2, schematically written log(C2/C1), and tbpc.1.1_R2.to.R1.&amp;.C2.to.C1 would correspond to the log odds-ratio computed from a 2x2 table, 
which is formed by row categories R1 and R2 and columns C1 and C2. See Nesrstova et al. (2023) for details.</p>
</dd> 
<dt>Base</dt><dd><p>the base with respect to which logarithms are computed</p>
</dd> 
<dt>Norm.const</dt><dd><p>the values of normalising constants (when results for orthonormal coordinates are reported).</p>
</dd>
<dt>Robust</dt><dd><p>TRUE if the MM estimator was applied.</p>
</dd>
<dt>lm</dt><dd><p>the lm object resulting from the first iteration.</p>
</dd>
<dt>Row.levels</dt><dd><p>the order of the row factor levels cosidered in the first iteration.</p>
</dd>
<dt>Col.levels</dt><dd><p>the order of the column factor levels cosidered in the first iteration.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpcTabWrapper">bpcTabWrapper</a></code> 
<code><a href="#topic+bpcPcaTab">bpcPcaTab</a></code>
<code><a href="#topic+bpcReg">bpcReg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># let's prepare some data
data(employment2)
data(unemployed)

table_data &lt;- employment2[employment2$Contract == "FT", ]
y &lt;- unemployed[unemployed$age == "20_24" &amp; unemployed$year == 2015,]
countries &lt;- intersect(levels(droplevels(y$country)), levels(table_data$Country))

table_data &lt;- table_data[table_data$Country %in% countries, ]
y &lt;- y[y$country %in% countries, c("country", "value")]
colnames(y) &lt;- c("Country", "unemployed")

# response as part of X
table_data.y &lt;- merge(table_data, y, by = "Country")
reg.cla &lt;- bpcRegTab(table_data.y, y = "unemployed", obs.ID = "Country", 
row.factor = "Sex", col.factor = "Age", value = "Value")
reg.cla

# response as named array
resp &lt;- y$unemployed
names(resp) &lt;- y$Country
reg.cla2 &lt;- bpcRegTab(table_data.y, y = resp, obs.ID = "Country", 
row.factor = "Sex", col.factor = "Age", value = "Value")
reg.cla2

# response as data.frame, robust estimator, 55plus as the rationing category, logarithm of base 2
resp.df &lt;- as.data.frame(y$unemployed)
rownames(resp.df) &lt;- y$Country
reg.rob &lt;- bpcRegTab(table_data.y, y = resp.df, obs.ID = "Country", 
row.factor = "Sex", col.factor = "Age", value = "Value",
norm.cat.col = "55plus", robust = TRUE, base = 2)
reg.rob

# Illustrative example with non-compositional predictors and response as part of X
x.ext &lt;- unemployed[unemployed$age == "15_19" &amp; unemployed$year == 2015,]
x.ext &lt;- x.ext[x.ext$country %in% countries, c("country", "value")]
colnames(x.ext) &lt;- c("Country", "15_19")

table_data.y.ext &lt;- merge(table_data.y, x.ext, by = "Country")
reg.cla.ext &lt;- bpcRegTab(table_data.y.ext, y = "unemployed", obs.ID = "Country", 
row.factor = "Sex", col.factor = "Age", value = "Value", external = "15_19")
reg.cla.ext
</code></pre>

<hr>
<h2 id='bpcTab'>Backwards pivot coordinates and their inverse</h2><span id='topic+bpcTab'></span>

<h3>Description</h3>

<p>Backwards pivot coordinate representation of a compositional table as a special case of isometric logratio coordinates and their inverse mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcTab(x, row.factor = NULL, col.factor = NULL, value = NULL, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcTab_+3A_x">x</code></td>
<td>
<p>object of class data.frame with columns corresponding to row and column factors of the respective compositional table and a variable with the values of the composition (positive values only).</p>
</td></tr>
<tr><td><code id="bpcTab_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTab_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTab_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTab_+3A_base">base</code></td>
<td>
<p>a positive number: the base with respect to which logarithms are computed. Defaults to exp(1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcTab
</p>
<p>Backwards pivot coordinates map IxJ-part compositional table from the simplex into a (IJ-1)-dimensional real space isometrically. 
Particularly the first coordinate from each group (rbpb.1, cbpb.1, tbpc.1) preserves the elemental information on the two-factorial structure. 
The first row and column backwards pivot balances rbpb.1 and cbpb.1 represent two-factorial counterparts to the pairwise logratios. 
More specifically, the first two levels of the considered factor are compared in the ratio, while the first level plays the role of the rationing category (denominator of the ratio) and the second level is treated as the normalized category (numerator of the ratio). All categories of the complementary factor are aggregated with the geometric mean.
The first table backwards pivot coordinate, has form of a four-part log odds-ratio (again related to the first two levels of the row and column factors) and quantifies the relations between factors.
All coordinates are structured as detailed in Nesrstova et al. (2023).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Coordinates</code></td>
<td>
<p>array of orthonormal coordinates.</p>
</td></tr> 
<tr><td><code>Coordinates.ortg</code></td>
<td>
<p>array of orthogonal coordinates.</p>
</td></tr> 
<tr><td><code>Contrast.matrix</code></td>
<td>
<p>contrast matrix corresponding to the orthonormal coordinates.</p>
</td></tr>
<tr><td><code>Base</code></td>
<td>
<p>the base with respect to which logarithms are computed.</p>
</td></tr>
<tr><td><code>Row.levels</code></td>
<td>
<p>order of the row factor levels.</p>
</td></tr>
<tr><td><code>Col.levels</code></td>
<td>
<p>order of the column factor levels.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpc">bpc</a></code> 
<code><a href="#topic+bpcTabWrapper">bpcTabWrapper</a></code> 
<code><a href="#topic+bpcPcaTab">bpcPcaTab</a></code>
<code><a href="#topic+bpcRegTab">bpcRegTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(manu_abs)
manu_USA &lt;- manu_abs[which(manu_abs$country=='USA'),]
manu_USA$output &lt;- as.factor(manu_USA$output)
manu_USA$isic &lt;- as.factor(manu_USA$isic)

# default setting with ln()
bpcTab(manu_USA, row.factor = "output", col.factor = "isic", value = "value")

# logarithm of base 2
bpcTab(manu_USA, row.factor = "output", col.factor = "isic", value = "value",
base = 2)

# for base exp(1) is the result similar to tabCoord():
r &lt;- rbind(c(-1,1,0), c(-1,-1,1))
c &lt;- rbind(c(-1,1,0,0,0), c(-1,-1,1,0,0), c(-1,-1,-1,1,0), c(-1,-1,-1,-1,1))
tabCoord(manu_USA, row.factor = "output", col.factor = "isic", value = "value",
SBPr = r, SBPc = c)
</code></pre>

<hr>
<h2 id='bpcTabWrapper'>Backwards pivot coordinates and their inverse</h2><span id='topic+bpcTabWrapper'></span>

<h3>Description</h3>

<p>For each compositional table in the sample a system of backwards pivot coordinates is computed as a special case of isometric logratio coordinates. 
For their inverse mapping, the contrast matrix is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpcTabWrapper(
  X,
  obs.ID = NULL,
  row.factor = NULL,
  col.factor = NULL,
  value = NULL,
  base = exp(1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpcTabWrapper_+3A_x">X</code></td>
<td>
<p>object of class data.frame with columns corresponding to row and column factors of the respective compositional table, a variable with the values of the composition (positive values only) and a factor with observation IDs.</p>
</td></tr>
<tr><td><code id="bpcTabWrapper_+3A_obs.id">obs.ID</code></td>
<td>
<p>name of the factor variable distinguishing the observations. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTabWrapper_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTabWrapper_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTabWrapper_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be given with the quotation marks.</p>
</td></tr>
<tr><td><code id="bpcTabWrapper_+3A_base">base</code></td>
<td>
<p>a positive number: the base with respect to which logarithms are computed. Defaults to exp(1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bpcTabWrapper
</p>
<p>Backwards pivot coordinates map IxJ-part compositional table from the simplex into a (IJ-1)-dimensional real space isometrically. 
Particularly the first coordinate from each group (rbpb.1, cbpb.1, tbpc.1) preserves the elemental information on the two-factorial structure. 
The first row and column backwards pivot balances rbpb.1 and cbpb.1 represent two-factorial counterparts to the pairwise logratios. 
More specifically, the first two levels of the considered factor are compared in the ratio, while the first level plays the role of the rationing category (denominator of the ratio) and the second level is treated as the normalized category (numerator of the ratio). All categories of the complementary factor are aggregated with the geometric mean.
The first table backwards pivot coordinate, has form of a four-part log odds-ratio (again related to the first two levels of the row and column factors) and quantifies the relations between factors.
All coordinates are structured as detailed in Nesrstova et al. (2023).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Coordinates</code></td>
<td>
<p>array of orthonormal coordinates.</p>
</td></tr> 
<tr><td><code>Coordinates.ortg</code></td>
<td>
<p>array of orthogonal coordinates.</p>
</td></tr> 
<tr><td><code>Contrast.matrix</code></td>
<td>
<p>contrast matrix corresponding to the orthonormal coordinates.</p>
</td></tr>
<tr><td><code>Base</code></td>
<td>
<p>the base with respect to which logarithms are computed.</p>
</td></tr>
<tr><td><code>Row.levels</code></td>
<td>
<p>order of the row factor levels.</p>
</td></tr>
<tr><td><code>Col.levels</code></td>
<td>
<p>order of the column factor levels.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Nesrstova, V., Jaskova, P., Pavlu, I., Hron, K., Palarea-Albaladejo, J., Gaba, A., Pelclova, J., Facevicova, K. (2023). Simple enough, but not simpler: Reconsidering additive logratio coordinates in compositional analysis. Submitted
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpc">bpc</a></code> 
<code><a href="#topic+bpcPcaTab">bpcPcaTab</a></code>
<code><a href="#topic+bpcRegTab">bpcRegTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(manu_abs)
manu_abs$output &lt;- as.factor(manu_abs$output)
manu_abs$isic &lt;- as.factor(manu_abs$isic)

# default setting with ln()
bpcTabWrapper(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value")

# logarithm of base 2
bpcTabWrapper(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value", base = 2)

# for base exp(1) is the result similar to tabCoordWrapper():
r &lt;- rbind(c(-1,1,0), c(-1,-1,1))
c &lt;- rbind(c(-1,1,0,0,0), c(-1,-1,1,0,0), c(-1,-1,-1,1,0), c(-1,-1,-1,-1,1))
tabCoordWrapper(manu_abs, obs.ID = "country", row.factor = "output", 
col.factor = "isic", value = "value", SBPr = r, SBPc = c)
</code></pre>

<hr>
<h2 id='cancer'>hospital discharges on cancer and distribution of age</h2><span id='topic+cancer'></span>

<h3>Description</h3>

<p>Hospital discharges of in-patients on neoplasms (cancer) per 100.000 inhabitants (year 2007) and population age structure.
</p>


<h3>Format</h3>

<p>A data set on 24 compositions on 6 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>country                            
</p>
</li>
<li><p><code>year </code>year                                      
</p>
</li>
<li><p><code>p1 </code>percentage of population with age below 15                       
</p>
</li>
<li><p><code>p2 </code>percentage of population with age between 15 and 60
</p>
</li>
<li><p><code>p3 </code>percentage of population with age above 60                    
</p>
</li>
<li><p><code>discharges </code>hospital discharges of in-patients on neoplasms (cancer) per 100.000 inhabitants
</p>
</li></ul>

<p>The response (discharges) is provided for the European Union countries (except Greece, Hungary and Malta) by Eurostat. As explanatory variables we use the age structure of the population in the same countries (year 2008). The age structure consists of three parts, age smaller than 15, age between 15 and 60 and age above 60 years, and they are expressed as percentages on the overall population in the countries. The data are provided by the United Nations Statistics Division.
</p>


<h3>Author(s)</h3>

<p>conversion to R by Karel Hron and Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p><a href="https://www.ec.europa.eu/eurostat">https://www.ec.europa.eu/eurostat</a> and <a href="https://unstats.un.org/home/">https://unstats.un.org/home/</a>
</p>


<h3>References</h3>

<p>K. Hron, P. Filzmoser, K. Thompson (2012). Linear regression with compositional explanatory variables. <em>Journal of Applied Statistics</em>, Volume 39, Issue 5, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(cancer)
str(cancer)
</code></pre>

<hr>
<h2 id='cancerMN'>malignant neoplasms cancer</h2><span id='topic+cancerMN'></span>

<h3>Description</h3>

<p>Two main types of malignant neoplasms cancer affecting colon and lung, respectively, in male and female populations. 
For this purpose population data (2012) from 35 OECD countries were collected.
</p>


<h3>Format</h3>

<p>A data set on 35 compositional tables on 4 parts (row-wise sorted cells) and 5 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>country                                  
</p>
</li>
<li><p><code>females-colon </code>number of colon cancer cases in female population                       
</p>
</li>
<li><p><code>females-lung </code>number of lung cancer cases in female population                    
</p>
</li>
<li><p><code>males-colon </code>number of colon cancer cases in male population
</p>
</li>
<li><p><code>males-lung </code>number of lung cancer cases in male population
</p>
</li></ul>

<p>The data are obtained from the OECD website.
</p>


<h3>Author(s)</h3>

<p>conversion to R by Karel Hron and intergration by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>From OECD website
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(cancerMN)
head(cancerMN)
rowSums(cancerMN[, 2:5])
</code></pre>

<hr>
<h2 id='ced'>Compositional error deviation</h2><span id='topic+ced'></span>

<h3>Description</h3>

<p>Normalized Aitchison distance between two data sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ced(x, y, ni)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ced_+3A_x">x</code></td>
<td>
<p>matrix or data frame</p>
</td></tr>
<tr><td><code id="ced_+3A_y">y</code></td>
<td>
<p>matrix or data frame of the same size as x</p>
</td></tr>
<tr><td><code id="ced_+3A_ni">ni</code></td>
<td>
<p>normalization parameter. See details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has been mainly written for procudures 
that evaluate imputation or replacement of rounded zeros. The ni parameter can thus, e.g. be
used for expressing the number of rounded zeros.
</p>


<h3>Value</h3>

<p>the compositinal error distance
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Hron, K., Templ, M., Filzmoser, P. (2010) Imputation of
missing values for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, 54 (12),
3095-3107.
</p>
<p>Templ, M., Hron, K., Filzmoser, P., Gardlo, A. (2016). 
Imputation of rounded zeros for high-dimensional compositional data. 
<em>Chemometrics and Intelligent Laboratory Systems</em>, 155, 183-190.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdcm">rdcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
x &lt;- expenditures
x[1,3] &lt;- NA
xi &lt;- impKNNa(x)$xImp
ced(expenditures, xi, ni = sum(is.na(x)))
</code></pre>

<hr>
<h2 id='cenLR'>Centred logratio coefficients</h2><span id='topic+cenLR'></span>

<h3>Description</h3>

<p>The centred logratio (clr) coefficients map D-part compositional data from the simplex
into a D-dimensional real space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cenLR(x, base = exp(1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cenLR_+3A_x">x</code></td>
<td>
<p>multivariate data, ideally of class data.frame or matrix</p>
</td></tr>
<tr><td><code id="cenLR_+3A_base">base</code></td>
<td>
<p>a positive or complex number: 
the base with respect to which logarithms are computed. Defaults to <code>exp(1)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each composition is divided by the geometric mean of its parts before the
logarithm is taken.
</p>


<h3>Value</h3>

<p>the resulting clr coefficients, including </p>
<table>
<tr><td><code>x.clr</code></td>
<td>
<p>clr coefficients</p>
</td></tr>
<tr><td><code>gm</code></td>
<td>
<p>the geometric means of the original compositional data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The resulting data set is singular by definition.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cenLRinv">cenLRinv</a></code>, <code><a href="#topic+addLR">addLR</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>,
<code><a href="#topic+addLRinv">addLRinv</a></code>, <code><a href="#topic+pivotCoordInv">pivotCoordInv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
eclr &lt;- cenLR(expenditures)
inveclr &lt;- cenLRinv(eclr)
head(expenditures)
head(inveclr)
head(pivotCoordInv(eclr$x.clr))

</code></pre>

<hr>
<h2 id='cenLRinv'>Inverse centred logratio mapping</h2><span id='topic+cenLRinv'></span>

<h3>Description</h3>

<p>Applies the inverse centred logratio mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cenLRinv(x, useClassInfo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cenLRinv_+3A_x">x</code></td>
<td>
<p>an object of class &ldquo;clr&rdquo;, &ldquo;data.frame&rdquo; or
&ldquo;matrix&rdquo;</p>
</td></tr>
<tr><td><code id="cenLRinv_+3A_useclassinfo">useClassInfo</code></td>
<td>
<p>if the object is of class &ldquo;clr&rdquo;, the useClassInfo
is used to determine if the class information should be used. If yes, also
absolute values may be preserved.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the resulting compositional data set.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cenLR">cenLR</a></code>, <code><a href="#topic+addLR">addLR</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>,
<code><a href="#topic+addLRinv">addLRinv</a></code>, <code><a href="#topic+pivotCoordInv">pivotCoordInv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
eclr &lt;- cenLR(expenditures, 2)
inveclr &lt;- cenLRinv(eclr)
head(expenditures)
head(inveclr)
head(cenLRinv(eclr$x.clr))

</code></pre>

<hr>
<h2 id='chorizonDL'>C-horizon of the Kola data with rounded zeros</h2><span id='topic+chorizonDL'></span>

<h3>Description</h3>

<p>This data set is almost the same as the 'chorizon' data set
in package <code>mvoutlier</code> and <code><a href="VIM.html#topic+chorizonDL">chorizonDL</a></code>, except that values below the detection limit
are coded as zeros, and detection limits provided as attributes to the data set and
less variables are included.
</p>


<h3>Format</h3>

<p>A data frame with 606 observations on the following 62 variables.
</p>
 
<dl>
<dt>*ID </dt><dd><p>a numeric vector</p>
</dd> 
<dt>XCOO </dt><dd><p>a numeric vector</p>
</dd> 
<dt>YCOO </dt><dd><p>a numeric vector</p>
</dd> 
<dt>Ag </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Al </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Al_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>As </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ba </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ba_INAA </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Be </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Bi </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Ca </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ca_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Cd </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ce_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Co </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Co_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Cr </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Cr_INAA </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Cu </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Eu_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Fe </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Fe_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Hf_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>K </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>K_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>La </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>La_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Li </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Lu_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Mg </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Mg_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Mn </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Mn_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Na </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Na_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Nd_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ni </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>P </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>P_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Pb </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>S </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Sc </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Sc_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Si </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Si_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>Sm_INAA </dt><dd><p>concentration in mg/kg</p>
</dd>
<dt>Sr </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Th_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ti </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Ti_XRF </dt><dd><p>concentration in wt. percentage</p>
</dd> 
<dt>V </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Y </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Yb_INAA </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>Zn </dt><dd><p>concentration in mg/kg</p>
</dd> 
<dt>LOI </dt><dd><p>concentration in wt. percentage</p>
</dd>
<dt>pH </dt><dd><p>ph value</p>
</dd>
<dt>ELEV </dt><dd><p>elevation</p>
</dd>
<dt>*COUN </dt><dd><p>country</p>
</dd>
<dt>*ASP </dt><dd><p>a numeric vector</p>
</dd> 
<dt>TOPC </dt><dd><p>a numeric vector</p>
</dd>
<dt>LITO </dt><dd><p>information on lithography</p>
</dd> 
</dl>



<h3>Note</h3>

<p>For a more detailed description of this data set, see
'chorizon' in package <code>mvoutlier</code>.
</p>


<h3>Source</h3>

<p>Kola Project (1993-1998)
</p>


<h3>References</h3>

<p>Reimann, C., Filzmoser, P., Garrett, R.G. and Dutter, R. (2008)
<em>Statistical Data Analysis Explained: Applied Environmental Statistics
with R</em>. Wiley.
</p>


<h3>See Also</h3>

<p>'chorizon', <code><a href="VIM.html#topic+chorizonDL">chorizonDL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(chorizonDL, package = "robCompositions")
dim(chorizonDL)
colnames(chorizonDL)
zeroPatterns(chorizonDL)
</code></pre>

<hr>
<h2 id='clustCoDa'>Cluster analysis for compositional data</h2><span id='topic+clustCoDa'></span><span id='topic+plot.clustCoDa'></span>

<h3>Description</h3>

<p>Clustering in orthonormal coordinates or by using the Aitchison distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustCoDa(
  x,
  k = NULL,
  method = "Mclust",
  scale = "robust",
  transformation = "pivotCoord",
  distMethod = NULL,
  iter.max = 100,
  vals = TRUE,
  alt = NULL,
  bic = NULL,
  verbose = TRUE
)

## S3 method for class 'clustCoDa'
plot(
  x,
  y,
  ...,
  normalized = FALSE,
  which.plot = "clusterMeans",
  measure = "silwidths"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clustCoDa_+3A_x">x</code></td>
<td>
<p>compositional data represented as a data.frame</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_k">k</code></td>
<td>
<p>number of clusters</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_method">method</code></td>
<td>
<p>clustering method. One of Mclust, cmeans, kmeansHartigan,
cmeansUfcl, pam, clara, fanny, ward.D2, single, hclustComplete, 
average, mcquitty, median, centroid</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_scale">scale</code></td>
<td>
<p>if orthonormal coordinates should be normalized.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_transformation">transformation</code></td>
<td>
<p>default are the isometric logratio coordinates. Can only used when distMethod 
is not Aitchison.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_distmethod">distMethod</code></td>
<td>
<p>Distance measure to be used. If &ldquo;Aitchison&rdquo;, then transformation should be &ldquo;identity&rdquo;.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_iter.max">iter.max</code></td>
<td>
<p>parameter if kmeans is chosen. The maximum number of iterations allowed</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_vals">vals</code></td>
<td>
<p>if cluster validity measures should be calculated</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_alt">alt</code></td>
<td>
<p>a known partitioning can be provided (for special cluster validity measures)</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_bic">bic</code></td>
<td>
<p>if TRUE then the BIC criteria is evaluated for each single cluster as validity measure</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE additional print output is provided</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_y">y</code></td>
<td>
<p>the y coordinates of points in the plot, optional if x is an appropriate structure.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_...">...</code></td>
<td>
<p>additional parameters for print method passed through</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_normalized">normalized</code></td>
<td>
<p>results gets normalized before plotting. Normalization is done by z-transformation 
applied on each variable.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_which.plot">which.plot</code></td>
<td>
<p>currently the only plot. Plot of cluster centers.</p>
</td></tr>
<tr><td><code id="clustCoDa_+3A_measure">measure</code></td>
<td>
<p>cluster validity measure to be considered for which.plot equals &ldquo;partMeans&rdquo;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional data set is either internally represented by orthonormal coordiantes
before a cluster algorithm is applied, or - depending on the 
choice of parameters -  the Aitchison distance is used.
</p>


<h3>Value</h3>

<p>all relevant information such as cluster centers, cluster memberships, and
cluster statistics.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ (accessing the basic features of hclust, Mclust, kmeans, etc. that 
are all written by others)
</p>


<h3>References</h3>

<p>M. Templ, P. Filzmoser, C. Reimann.
Cluster analysis applied to regional geochemical data: Problems and possibilities. 
<em>Applied Geochemistry</em>, <strong>23</strong> (8), 2198&ndash;2213, 2008
</p>
<p>Templ, M., Filzmoser, P., Reimann, C. (2008) 
<em>Cluster analysis applied to regional geochemical data: Problems and possibilities</em>, 
Applied Geochemistry, 23 (2008), pages 2198 - 2213.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
x &lt;- expenditures
rr &lt;- clustCoDa(x, k=6, scale = "robust", transformation = "pivotCoord")
rr2 &lt;- clustCoDa(x, k=6, distMethod = "Aitchison", scale = "none", 
                 transformation = "identity")
rr3 &lt;- clustCoDa(x, k=6, distMethod = "Aitchison", method = "single",
                 transformation = "identity", scale = "none")
                 
## Not run: 
require(reshape2)
plot(rr)
plot(rr, normalized = TRUE)
plot(rr, normalized = TRUE, which.plot = "partMeans")

## End(Not run)
</code></pre>

<hr>
<h2 id='clustCoDa_qmode'>Q-mode cluster analysis for compositional parts</h2><span id='topic+clustCoDa_qmode'></span><span id='topic+plot.clustCoDa_qmode'></span>

<h3>Description</h3>

<p>Clustering using the variation matrix of compositional parts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustCoDa_qmode(x, method = "ward.D2")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clustCoDa_qmode_+3A_x">x</code></td>
<td>
<p>compositional data represented as a data.frame</p>
</td></tr>
<tr><td><code id="clustCoDa_qmode_+3A_method">method</code></td>
<td>
<p>hclust method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a hclust object
</p>


<h3>Author(s)</h3>

<p>Matthias Templ (accessing the basic features of hclust that 
are all written by other authors)
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K. Templ, M. (2018)
<em>Applied Compositional Data Analysis</em>, 
Springer, Cham.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures) 
x &lt;- expenditures
cl &lt;- clustCoDa_qmode(x)
## Not run: 
require(reshape2)
plot(cl)
cl2 &lt;- clustCoDa_qmode(x, method = "single")
plot(cl2)

## End(Not run)
</code></pre>

<hr>
<h2 id='coffee'>coffee data set</h2><span id='topic+coffee'></span>

<h3>Description</h3>

<p>30 commercially available coffee samples of different origins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coffee)
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations and 7 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>sort </code>sort of coffee
</p>
</li>
<li><p><code>acit </code>acetic acid 
</p>
</li>
<li><p><code>metpyr </code>methylpyrazine
</p>
</li>
<li><p><code>furfu </code>furfural
</p>
</li>
<li><p><code>furfualc </code>furfuryl alcohol
</p>
</li>
<li><p><code>dimeth </code>2,6 dimethylpyrazine
</p>
</li>
<li><p><code>met5 </code>5-methylfurfural
</p>
</li></ul>

<p>In the original data set, 15 volatile compounds (descriptors of coffee aroma) were selected for a statistical analysis. We selected six compounds (compositional parts) on three sorts of coffee.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>, Karel Hron
</p>


<h3>References</h3>

<p>M. Korhonov\'a, K. Hron, D. Klimc\'ikov\'a, L. Muller, P. Bedn\'ar, and P. Bart\'ak (2009). Coffee aroma - statistical analysis of compositional data. <em>Talanta</em>, 80(2): 710&ndash;715.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
str(coffee)
summary(coffee)
</code></pre>

<hr>
<h2 id='compareMahal'>Compares Mahalanobis distances from two approaches</h2><span id='topic+compareMahal'></span><span id='topic+getEstimates'></span><span id='topic+print.estimates'></span><span id='topic+plot.estimates'></span><span id='topic+plot.mahal'></span>

<h3>Description</h3>

<p>Mahalanobis distances are calculated for each zero pattern.
Two approaches are used. The first one estimates Mahalanobis distance for observations belonging to one each zero pattern each.
The second method uses a more sophisticated approach described below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareMahal(x, imp = "KNNa")

## S3 method for class 'mahal'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compareMahal_+3A_x">x</code></td>
<td>
<p>data frame or matrix</p>
</td></tr>
<tr><td><code id="compareMahal_+3A_imp">imp</code></td>
<td>
<p>imputation method</p>
</td></tr>
<tr><td><code id="compareMahal_+3A_y">y</code></td>
<td>
<p>unused second argument for the plot method</p>
</td></tr>
<tr><td><code id="compareMahal_+3A_...">...</code></td>
<td>
<p>additional arguments for plotting passed through</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>df</code></td>
<td>
<p>a data.frame containing the Mahalanobis distances from the estimation in subgroups, the Mahalanobis distances from the imputation and covariance approach, an indicator specifiying outliers and an indicator specifying the zero pattern</p>
</td></tr> <tr><td><code>df2</code></td>
<td>
<p>a groupwise statistics.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ, Karel Hron
</p>


<h3>References</h3>

<p>Templ, M., Hron, K., Filzmoser, P. (2017) 
Exploratory tools for outlier detection in compositional data with structural zeros&quot;.
<em>Journal of Applied Statistics</em>, <strong>44</strong> (4), 734&ndash;752
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impKNNa">impKNNa</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
# generate some zeros
arcticLake[1:10, 1] &lt;- 0
arcticLake[11:20, 2] &lt;- 0
m &lt;- compareMahal(arcticLake)
plot(m)
</code></pre>

<hr>
<h2 id='compositionalSpline'>Compositional spline</h2><span id='topic+compositionalSpline'></span>

<h3>Description</h3>

<p>This code implements the compositional smoothing splines grounded on the theory of 
Bayes spaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compositionalSpline(
  t,
  clrf,
  knots,
  w,
  order,
  der,
  alpha,
  spline.plot = FALSE,
  basis.plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compositionalSpline_+3A_t">t</code></td>
<td>
<p>class midpoints</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_clrf">clrf</code></td>
<td>
<p>clr transformed values at class midpoints, i.e., fcenLR(f(t))</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_knots">knots</code></td>
<td>
<p>sequence of knots</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_w">w</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_order">order</code></td>
<td>
<p>order of the spline (i.e., degree + 1)</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_der">der</code></td>
<td>
<p>lth derivation</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_alpha">alpha</code></td>
<td>
<p>smoothing parameter</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_spline.plot">spline.plot</code></td>
<td>
<p>if TRUE, the resulting spline is plotted</p>
</td></tr>
<tr><td><code id="compositionalSpline_+3A_basis.plot">basis.plot</code></td>
<td>
<p>if TRUE, the ZB-spline basis system is plotted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional splines enable to construct a spline basis in the centred logratio (clr) space of density 
functions (ZB-spline basis) and consequently also in the original space of densities (CB-spline basis).The resulting 
compositional splines in the clr space as well as the ZB-spline basis satisfy the zero integral constraint. 
This enables to work with compositional splines consistently in the framework of the Bayes space methodology.
</p>
<p>Augmented knot sequence is obtained from the original knots by adding #(order-1) multiple endpoints.
</p>


<h3>Value</h3>

<table>
<tr><td><code>J</code></td>
<td>
<p>value of the functional J</p>
</td></tr>
<tr><td><code>ZB_coef</code></td>
<td>
<p>ZB-spline basis coeffcients</p>
</td></tr>
<tr><td><code>CV</code></td>
<td>
<p>score of cross-validation</p>
</td></tr>
<tr><td><code>GCV</code></td>
<td>
<p>score of generalized cross-validation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Machalova <a href="mailto:jitka.machalova@upol.cz">jitka.machalova@upol.cz</a>, R. Talska <a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>
</p>


<h3>References</h3>

<p>Machalova, J., Talska, R., Hron, K. Gaba, A. Compositional splines for representation of density functions. <em>Comput Stat</em> (2020). https://doi.org/10.1007/s00180-020-01042-7
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example (Iris data):
SepalLengthCm &lt;- iris$Sepal.Length
Species &lt;- iris$Species
iris1 &lt;- SepalLengthCm[iris$Species==levels(iris$Species)[1]]
h1 &lt;- hist(iris1, plot = FALSE)
midx1 &lt;- h1$mids
midy1 &lt;- matrix(h1$density, nrow=1, ncol = length(h1$density), byrow=TRUE)
clrf  &lt;- cenLR(rbind(midy1,midy1))$x.clr[1,]
knots &lt;- seq(min(h1$breaks),max(h1$breaks),l=5)
order &lt;- 4
der &lt;- 2
alpha &lt;- 0.99

sol1 &lt;- compositionalSpline(t = midx1, clrf = clrf, knots = knots, 
  w = rep(1,length(midx1)), order = order, der = der, 
  alpha = alpha, spline.plot = TRUE)
sol1$GCV
ZB_coef &lt;- sol1$ZB_coef
t &lt;- seq(min(knots),max(knots),l=500)
t_step &lt;- diff(t[1:2])
ZB_base &lt;- ZBsplineBasis(t=t,knots,order)$ZBsplineBasis
sol1.t &lt;- ZB_base%*%ZB_coef
sol2.t &lt;- fcenLRinv(t,t_step,sol1.t)
h2 = hist(iris1,prob=TRUE,las=1)
points(midx1,midy1,pch=16)
lines(t,sol2.t,col="darkred",lwd=2)
# Example (normal distrubution):
# generate n values from normal distribution
set.seed(1)
n = 1000; mean = 0; sd = 1.5
raw_data = rnorm(n,mean,sd)
  
# number of classes according to Sturges rule
n.class = round(1+1.43*log(n),0)
  
# Interval midpoints
parnition = seq(-5,5,length=(n.class+1))
t.mid = c(); for (i in 1:n.class){t.mid[i]=(parnition[i+1]+parnition[i])/2}
  
counts = table(cut(raw_data,parnition))
prob = counts/sum(counts)                # probabilities
dens.raw = prob/diff(parnition)          # raw density data
clrf =  cenLR(rbind(dens.raw,dens.raw))$x.clr[1,]  # raw clr density data
  
# set the input parameters for smoothing 
knots = seq(min(parnition),max(parnition),l=5)
w = rep(1,length(clrf))
order = 4
der = 2
alpha = 0.5
spline = compositionalSpline(t = t.mid, clrf = clrf, knots = knots, 
  w = w, order = order, der = der, alpha = alpha, 
  spline.plot=TRUE, basis.plot=FALSE)
  
# ZB-spline coefficients
ZB_coef = spline$ZB_coef
  
# ZB-spline basis evaluated on the grid "t.fine"
t.fine = seq(min(knots),max(knots),l=1000)
ZB_base = ZBsplineBasis(t=t.fine,knots,order)$ZBsplineBasis
  
# Compositional spline in the clr space (evaluated on the grid t.fine)
comp.spline.clr = ZB_base%*%ZB_coef
  
# Compositional spline in the Bayes space (evaluated on the grid t.fine)
comp.spline = fcenLRinv(t.fine,diff(t.fine)[1:2],comp.spline.clr)
  
# Unit-integral representation of truncated true normal density function 
dens.true = dnorm(t.fine, mean, sd)/trapzc(diff(t.fine)[1:2],dnorm(t.fine, mean, sd))
  
# Plot of compositional spline together with raw density data
matplot(t.fine,comp.spline,type="l",
    lty=1, las=1, col="darkblue", xlab="t", 
    ylab="density",lwd=2,cex.axis=1.2,cex.lab=1.2,ylim=c(0,0.28))
matpoints(t.mid,dens.raw,pch = 8, col="darkblue", cex=1.3)
  
# Add true normal density function
matlines(t.fine,dens.true,col="darkred",lwd=2)

</code></pre>

<hr>
<h2 id='constSum'>Constant sum</h2><span id='topic+constSum'></span>

<h3>Description</h3>

<p>Closes compositions to sum up to a given constant (default 1), by dividing
each part of a composition by its row sum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constSum(x, const = 1, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constSum_+3A_x">x</code></td>
<td>
<p>multivariate data ideally of class data.frame or matrix</p>
</td></tr>
<tr><td><code id="constSum_+3A_const">const</code></td>
<td>
<p>constant, the default equals 1.</p>
</td></tr>
<tr><td><code id="constSum_+3A_na.rm">na.rm</code></td>
<td>
<p>removing missing values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data for which the row sums are equal to <code>const</code>.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
constSum(expenditures)
constSum(expenditures, 100)

</code></pre>

<hr>
<h2 id='coord'>Coordinate representation of compositional tables</h2><span id='topic+coord'></span><span id='topic+print.coord'></span>

<h3>Description</h3>

<p>General approach to orthonormal coordinates for compositional tables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coord(x, SBPr, SBPc)

## S3 method for class 'coord'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coord_+3A_x">x</code></td>
<td>
<p>an object of class &ldquo;table&rdquo;, &ldquo;data.frame&rdquo; or &ldquo;matrix&rdquo;</p>
</td></tr>
<tr><td><code id="coord_+3A_sbpr">SBPr</code></td>
<td>
<p>sequential binary partition for rows</p>
</td></tr>
<tr><td><code id="coord_+3A_sbpc">SBPc</code></td>
<td>
<p>sequential binary partition for columns</p>
</td></tr>
<tr><td><code id="coord_+3A_...">...</code></td>
<td>
<p>further arguments passed to the print function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A contingency or propability table can be considered as a two-factor composition, we refer to compositional tables. 
This function constructs orthonomal coordinates for compositional tables using
the balances approach for given sequential binary partitions on rows and columns of the compositional table.
</p>


<h3>Value</h3>

<p>Row and column balances and odds ratios as coordinate representations of the independence and interaction tables, respectively.
</p>
<table>
<tr><td><code>row_balances</code></td>
<td>
<p>row balances</p>
</td></tr>
<tr><td><code>row_bin</code></td>
<td>
<p>binary partition for rows</p>
</td></tr>
<tr><td><code>col_balances</code></td>
<td>
<p>column balances</p>
</td></tr>
<tr><td><code>col_bin</code></td>
<td>
<p>binary parition for columns</p>
</td></tr>
<tr><td><code>odds_ratios_coord</code></td>
<td>
<p>odds ratio coordinates</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova, and minor adaption by Matthias Templ
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V., Templ, M. (2018)
General approach to coordinate representation of compositional tables. 
<em>Scandinavian Journal of Statistics</em>, 45(4), 879-899.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbind(c(1,5,3,6,8,4),c(6,4,9,5,8,12),c(15,2,68,42,11,6),
           c(20,15,4,6,23,8),c(11,20,35,26,44,8))
x
SBPc &lt;- rbind(c(1,1,1,1,-1,-1),c(1,-1,-1,-1,0,0),c(0,1,1,-1,0,0),
              c(0,1,-1,0,0,0),c(0,0,0,0,1,-1))
SBPc
SBPr &lt;- rbind(c(1,1,1,-1,-1),c(1,1,-1,0,0),c(1,-1,0,0,0),c(0,0,0,1,-1))
SBPr
result &lt;- coord(x, SBPr,SBPc)
result
data(socExp)

</code></pre>

<hr>
<h2 id='corCoDa'>Correlations for compositional data</h2><span id='topic+corCoDa'></span>

<h3>Description</h3>

<p>This function computes correlation coefficients between compositional parts based
on symmetric pivot coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corCoDa(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corCoDa_+3A_x">x</code></td>
<td>
<p>a matrix or data frame with compositional data</p>
</td></tr>
<tr><td><code id="corCoDa_+3A_...">...</code></td>
<td>
<p>additional arguments for the function <code><a href="stats.html#topic+cor">cor</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A compositional correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Petra Kynclova
</p>


<h3>References</h3>

<p>Kynclova, P., Hron, K., Filzmoser, P. (2017)
Correlation between compositional parts based on symmetric balances.
<em>Mathematical Geosciences</em>, 49(6), 777-796.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
corCoDa(expenditures)
x &lt;- arcticLake 
corCoDa(x)

</code></pre>

<hr>
<h2 id='cubeCoord'>Coordinate representation of a compositional cube and of a sample of compositional cubes</h2><span id='topic+cubeCoord'></span><span id='topic+cubeCoordWrapper'></span>

<h3>Description</h3>

<p>cubeCoord computes a system of orthonormal coordinates of a compositional cube. 
Computation of either pivot coordinates or a coordinate system based on the given SBP is possible.
</p>
<p>Wrapper (cubeCoordWrapper): For each compositional cube in the sample cubeCoordWrapper computes 
a system of orthonormal coordinates and provide a simple descriptive analysis. 
Computation of either pivot coordinates or a coordinate system based on the 
given SBP is possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cubeCoord(
  x,
  row.factor = NULL,
  col.factor = NULL,
  slice.factor = NULL,
  value = NULL,
  SBPr = NULL,
  SBPc = NULL,
  SBPs = NULL,
  pivot = FALSE,
  print.res = FALSE
)

cubeCoordWrapper(
  X,
  obs.ID = NULL,
  row.factor = NULL,
  col.factor = NULL,
  slice.factor = NULL,
  value = NULL,
  SBPr = NULL,
  SBPc = NULL,
  SBPs = NULL,
  pivot = FALSE,
  test = FALSE,
  n.boot = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cubeCoord_+3A_x">x</code></td>
<td>
<p>a data frame containing variables representing row, column and slice factors of the respective compositional cube and variable with the values of the composition.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_slice.factor">slice.factor</code></td>
<td>
<p>name of the variable representing the slice factor. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_sbpr">SBPr</code></td>
<td>
<p>an <code class="reqn">I-1\times I</code> array defining the sequential binary partition of the values of the row factor, where I is the number of the row factor levels. The values assigned in the given step to the + group are marked by 1, values from  the - group by -1 and the rest by 0. If it is not provided, the pivot version of coordinates is constructed automatically.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_sbpc">SBPc</code></td>
<td>
<p>an <code class="reqn">J-1\times J</code> array defining the sequential binary partition of the values of the column factor, where J is the number of the column factor levels. The values assigned in the given step to the + group are marked by 1, values from  the - group by -1 and the rest by 0. If it is not provided, the pivot version of coordinates is constructed automatically.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_sbps">SBPs</code></td>
<td>
<p>an <code class="reqn">K-1\times K</code> array defining the sequential binary partition of the values of the slice factor, where K is the number of the slice factor levels. The values assigned in the given step to the + group are marked by 1, values from  the - group by -1 and the rest by 0. If it is not provided, the pivot version of coordinates is constructed automatically.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_pivot">pivot</code></td>
<td>
<p>logical, default is FALSE. If TRUE, or one of the SBPs is not defined, its pivot version is used.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_print.res">print.res</code></td>
<td>
<p>logical, default is FALSE. If TRUE, the output is displayed in the Console.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_x">X</code></td>
<td>
<p>a data frame containing variables representing row, column and slice factors 
of the respective compositional cubes, variable with the values 
of the composition and variable distinguishing the observations.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_obs.id">obs.ID</code></td>
<td>
<p>name of the variable distinguishing the observations. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_test">test</code></td>
<td>
<p>logical, default is FALSE. If TRUE, the bootstrap analysis of coordinates is provided.</p>
</td></tr>
<tr><td><code id="cubeCoord_+3A_n.boot">n.boot</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>cubeCoord
</p>
<p>This transformation moves the IJK-part compositional cubes from the simplex into a (IJK-1)-dimensional real space isometrically with respect to its three-factorial nature.
</p>
<p>Wrapper (cubeCoordWrapper): Each of n IJK-part compositional cubes from the sample is 
with respect to its three-factorial nature isometrically transformed 
from the simplex into a (IJK-1)-dimensional real space. 
Sample mean values and standard deviations are computed and using 
bootstrap an estimate of 95 % confidence interval is given.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Coordinates</code></td>
<td>
<p>an array of orthonormal coordinates.</p>
</td></tr> 
<tr><td><code>Grap.rep</code></td>
<td>
<p>graphical representation of the coordinates. 
Parts denoted by + form the groups in the numerator of the respective computational formula, 
parts - form the denominator and parts . are not involved in the given coordinate.</p>
</td></tr> 
<tr><td><code>Row.balances</code></td>
<td>
<p>an array of row balances.</p>
</td></tr>
<tr><td><code>Column.balances</code></td>
<td>
<p>an array of column balances.</p>
</td></tr>
<tr><td><code>Slice.balances</code></td>
<td>
<p>an array of slice balances.</p>
</td></tr>
<tr><td><code>Row.column.OR</code></td>
<td>
<p>an array of row-column OR coordinates.</p>
</td></tr>
<tr><td><code>Row.slice.OR</code></td>
<td>
<p>an array of row-slice OR coordinates.</p>
</td></tr>
<tr><td><code>Column.slice.OR</code></td>
<td>
<p>an array of column-slice OR coordinates.</p>
</td></tr>
<tr><td><code>Row.col.slice.OR</code></td>
<td>
<p>an array of coordinates describing the mutual interaction between all three factors.</p>
</td></tr>
<tr><td><code>Contrast.matrix</code></td>
<td>
<p>contrast matrix.</p>
</td></tr>
<tr><td><code>Log.ratios</code></td>
<td>
<p>an array of pure log-ratios between groups of parts without the normalizing constant.</p>
</td></tr>
<tr><td><code>Coda.cube</code></td>
<td>
<p>cube form of the given composition.</p>
</td></tr>
<tr><td><code>Bootstrap</code></td>
<td>
<p>array of sample means, standard deviations and bootstrap confidence intervals.</p>
</td></tr>
<tr><td><code>Cubes</code></td>
<td>
<p>Cube form of the given compositions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Facevicova, K., Filzmoser, P. and K. Hron (2019) Compositional Cubes: Three-factorial Compositional Data. Under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tabCoord">tabCoord</a></code> 
<code><a href="#topic+tabCoordWrapper">tabCoordWrapper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################
### Coordinate representation of a CoDa Cube
## Not run: 
### example from Fa\v cevicov\'a (2019)
data(employment2)
CZE &lt;- employment2[which(employment2$Country == 'CZE'), ]

# pivot coordinates
cubeCoord(CZE, "Sex", 'Contract', "Age", 'Value')

# coordinates with given SBP

r &lt;- t(c(1,-1))
c &lt;- t(c(1,-1))
s &lt;- rbind(c(1,-1,-1), c(0,1,-1))

cubeCoord(CZE, "Sex", 'Contract', "Age", 'Value', r,c,s)

## End(Not run)

###################
### Analysis of a sample of CoDa Cubes
## Not run: 
### example from Fa\v cevicov\'a (2019)
data(employment2)
### Compositional tables approach,
### analysis of the relative structure.
### An example from Facevi\v cov\'a (2019)

# pivot coordinates
cubeCoordWrapper(employment2, 'Country', 'Sex', 'Contract', 'Age', 'Value',  
test=TRUE)

# coordinates with given SBP (defined in the paper)

r &lt;- t(c(1,-1))
c &lt;- t(c(1,-1))
s &lt;- rbind(c(1,-1,-1), c(0,1,-1))

res &lt;- cubeCoordWrapper(employment2, 'Country', 'Sex', 'Contract', 
"Age", 'Value', r,c,s, test=TRUE)

### Classical approach,
### generalized linear mixed effect model.

library(lme4)
employment2$y &lt;- round(employment2$Value*1000)
glmer(y~Sex*Age*Contract+(1|Country),data=employment2,family=poisson)

### other relations within cube (in the log-ratio form)
### e.g. ratio between women and man in the group FT, 15to24
### and ratio between age groups 15to24 and 55plus

# transformation matrix
T &lt;- rbind(c(1,rep(0,5), -1, rep(0,5)), c(rep(c(1/4,0,-1/4), 4)))
T %*% t(res$Contrast.matrix) %*%res$Bootstrap[,1]

## End(Not run)
</code></pre>

<hr>
<h2 id='daCoDa'>Linear and quadratic discriminant analysis for compositional data.</h2><span id='topic+daCoDa'></span>

<h3>Description</h3>

<p>Linear and quadratic discriminant analysis for compositional data using either robust or 
classical estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>daCoDa(x, grp, coda = TRUE, method = "classical", rule = "linear", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="daCoDa_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing the explanatory variables</p>
</td></tr>
<tr><td><code id="daCoDa_+3A_grp">grp</code></td>
<td>
<p>grouping variable: a factor specifying the class for each
observation.</p>
</td></tr>
<tr><td><code id="daCoDa_+3A_coda">coda</code></td>
<td>
<p>TRUE, when the underlying data are compositions.</p>
</td></tr>
<tr><td><code id="daCoDa_+3A_method">method</code></td>
<td>
<p>&ldquo;classical&rdquo; or &ldquo;robust&rdquo;</p>
</td></tr>
<tr><td><code id="daCoDa_+3A_rule">rule</code></td>
<td>
<p>a character, either &ldquo;linear&rdquo; (the default) or &ldquo;quadratic&rdquo;.</p>
</td></tr>
<tr><td><code id="daCoDa_+3A_...">...</code></td>
<td>
<p>additional arguments for the functions passed through</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compositional data are expressed in orthonormal (ilr) coordinates (if <code>coda==TRUE</code>). For linear 
discriminant analysis the functions LdaClassic (classical) and Linda (robust) from the 
package rrcov are used. Similarly, quadratic discriminant analysis 
uses the functions QdaClassic and QdaCov (robust) from the same package.
</p>
<p>The classical linear and quadratic discriminant rules are invariant to ilr coordinates and clr
coefficients. The robust rules are invariant to ilr transformations if
affine equivariant robust estimators of location and covariance are taken.
</p>


<h3>Value</h3>

<p>An S4 object of class LdaClassic, Linda, QdaClassic or QdaCov. See package 
rrcov for details.
</p>


<h3>Author(s)</h3>

<p>Jutta Gamper
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K., Templ, M. (2012) 
Discriminant analysis for compositional data and robust parameter estimation. 
<em>Computational Statistics</em>, 27(4), 585-604.
</p>


<h3>See Also</h3>

<p><code><a href="rrcov.html#topic+LdaClassic">LdaClassic</a></code>, <code><a href="rrcov.html#topic+Linda">Linda</a></code>, 
<code><a href="rrcov.html#topic+QdaClassic">QdaClassic</a></code>, <code><a href="rrcov.html#topic+QdaCov">QdaCov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## toy data (non-compositional)
require(MASS)
x1 &lt;- mvrnorm(20,c(0,0,0),diag(3))
x2 &lt;- mvrnorm(30,c(3,0,0),diag(3))
x3 &lt;- mvrnorm(40,c(0,3,0),diag(3))
X &lt;- rbind(x1,x2,x3)
grp=c(rep(1,20),rep(2,30),rep(3,40))

clas1 &lt;- daCoDa(X, grp, coda=FALSE, method = "classical", rule="linear")
summary(clas1)
## predict runs only with newest verison of rrcov
## Not run: 
predict(clas1)

## End(Not run)
# specify different prior probabilities
clas2 &lt;- daCoDa(X, grp, coda=FALSE, prior=c(1/3, 1/3, 1/3))
summary(clas2)

## compositional data
data(coffee)
x &lt;- coffee[coffee$sort!="robusta",2:7]
group &lt;- droplevels(coffee$sort[coffee$sort!="robusta"])
cof.cla &lt;- daCoDa(x, group, method="classical", rule="quadratic")
cof.rob &lt;- daCoDa(x, group, method="robust", rule="quadratic")
## predict runs only with newest verison of rrcov
## Not run: 
predict(cof.cla)@ct
predict(cof.rob)@ct

## End(Not run)
</code></pre>

<hr>
<h2 id='daFisher'>Discriminant analysis by Fisher Rule.</h2><span id='topic+daFisher'></span><span id='topic+print.daFisher'></span><span id='topic+predict.daFisher'></span><span id='topic+summary.daFisher'></span>

<h3>Description</h3>

<p>Discriminant analysis by Fishers rule using the logratio approach to compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>daFisher(x, grp, coda = TRUE, method = "classical", plotScore = FALSE, ...)

## S3 method for class 'daFisher'
print(x, ...)

## S3 method for class 'daFisher'
predict(object, ..., newdata)

## S3 method for class 'daFisher'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="daFisher_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing the explanatory variables
(training set)</p>
</td></tr>
<tr><td><code id="daFisher_+3A_grp">grp</code></td>
<td>
<p>grouping variable: a factor specifying the class for each
observation.</p>
</td></tr>
<tr><td><code id="daFisher_+3A_coda">coda</code></td>
<td>
<p>TRUE, when the underlying data are compositions.</p>
</td></tr>
<tr><td><code id="daFisher_+3A_method">method</code></td>
<td>
<p>&ldquo;classical&rdquo; or &ldquo;robust&rdquo; estimation.</p>
</td></tr>
<tr><td><code id="daFisher_+3A_plotscore">plotScore</code></td>
<td>
<p>TRUE, if the scores should be plotted automatically.</p>
</td></tr>
<tr><td><code id="daFisher_+3A_...">...</code></td>
<td>
<p>additional arguments for the print method passed through</p>
</td></tr>
<tr><td><code id="daFisher_+3A_object">object</code></td>
<td>
<p>object of class &ldquo;daFisher&rdquo;</p>
</td></tr>
<tr><td><code id="daFisher_+3A_newdata">newdata</code></td>
<td>
<p>new data in the appropriate form (CoDa, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Fisher rule leads only to linear boundaries. However, this method allows
for dimension reduction and thus for a better visualization of the
separation boundaries. For the Fisher discriminant rule (Fisher, 1938; Rao,
1948) the assumption of normal distribution of the groups is not explicitly
required, although the method looses its optimality in case of deviations
from normality.
</p>
<p>The classical Fisher discriminant rule is invariant to ilr coordinates and clr
coefficients. The robust rule is invariant to ilr transformations if
affine equivariant robust estimators of location and covariance are taken.
</p>
<p>Robustification is done (method &ldquo;robust&rdquo;) by estimating the
columnwise means and the covariance by the Minimum Covariance Estimator.
</p>


<h3>Value</h3>

<p>an object of class &ldquo;daFisher&rdquo; including the following
elements 
</p>
<table>
<tr><td><code>B</code></td>
<td>
<p>Between variance of the groups</p>
</td></tr> 
<tr><td><code>W</code></td>
<td>
<p>Within variance
of the groups</p>
</td></tr> 
<tr><td><code>loadings</code></td>
<td>
<p>loadings</p>
</td></tr> 
<tr><td><code>scores</code></td>
<td>
<p>fisher scores</p>
</td></tr> 
<tr><td><code>mc</code></td>
<td>
<p>table indicating misclassifications</p>
</td></tr> 
<tr><td><code>mcrate</code></td>
<td>
<p>misclassification rate</p>
</td></tr>  
<tr><td><code>coda</code></td>
<td>
<p>coda</p>
</td></tr>
<tr><td><code>grp</code></td>
<td>
<p>grouping</p>
</td></tr>
<tr><td><code>grppred</code></td>
<td>
<p>predicted groups</p>
</td></tr>
<tr><td><code>xc</code></td>
<td>
<p>xc</p>
</td></tr>
<tr><td><code>meanj</code></td>
<td>
<p>meanj</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>cv</p>
</td></tr>
<tr><td><code>pj</code></td>
<td>
<p>pj</p>
</td></tr>
<tr><td><code>meanov</code></td>
<td>
<p>meanov</p>
</td></tr>
<tr><td><code>fdiscr</code></td>
<td>
<p>fdiscr</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ.
</p>


<h3>References</h3>

<p>Filzmoser, P. and Hron, K. and Templ, M. (2012) 
Discriminant analysis for compositional data and robust parameter estimation. 
<em>Computational Statistics</em>, 27(4), 585-604.
</p>
<p>Fisher, R. A. (1938) The statistical utiliziation of multiple measurements.
<em>Annals of Eugenics</em>, 8, 376-386.
</p>
<p>Rao, C.R. (1948) The utilization of multiple measurements in problems of
biological classification. <em>Journal of the Royal Statistical Society</em>,
Series B, 10, 159-203.
</p>


<h3>See Also</h3>

<p><code><a href="rrcov.html#topic+Linda">Linda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## toy data (non-compositional)
require(MASS)
x1 &lt;- mvrnorm(20,c(0,0,0),diag(3))
x2 &lt;- mvrnorm(30,c(3,0,0),diag(3))
x3 &lt;- mvrnorm(40,c(0,3,0),diag(3))
X &lt;- rbind(x1,x2,x3)
grp=c(rep(1,20),rep(2,30),rep(3,40))

#par(mfrow=c(1,2))
d1 &lt;- daFisher(X,grp=grp,method="classical",coda=FALSE)
d2 &lt;- daFisher(X,grp=grp,method="robust",coda=FALSE)
d2
summary(d2)
predict(d2, newdata = X)

## example with olive data:
## Not run: 
data(olive, package = "RnavGraph")
# exclude zeros (alternatively impute them if 
# the detection limit is known using impRZilr())
ind &lt;- which(olive == 0, arr.ind = TRUE)[,1]
olives &lt;- olive[-ind, ]
x &lt;- olives[, 4:10]
grp &lt;- olives$Region # 3 groups
res &lt;- daFisher(x,grp)
res
summary(res)
res &lt;- daFisher(x, grp, plotScore = TRUE)
res &lt;- daFisher(x, grp, method = "robust")
res
summary(res)
predict(res, newdata = x)
res &lt;- daFisher(x,grp, plotScore = TRUE, method = "robust")

# 9 regions
grp &lt;- olives$Area
res &lt;- daFisher(x, grp, plotScore = TRUE)
res
summary(res)
predict(res, newdata = x)

## End(Not run)
</code></pre>

<hr>
<h2 id='economy'>economic indicators</h2><span id='topic+economy'></span>

<h3>Description</h3>

<p>Household and government consumptions, gross captial formation and import and exports of goods 
and services.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(economy)
</code></pre>


<h3>Format</h3>

<p>A data frame with 30 observations and 7 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>country name
</p>
</li>
<li><p><code>country2 </code>country name, short version
</p>
</li>
<li><p><code>HHconsumption </code>Household and NPISH final consumption expenditure
</p>
</li>
<li><p><code>GOVconsumption </code>Final consumption expenditure of general government
</p>
</li>
<li><p><code>capital </code>Gross capital formation
</p>
</li>
<li><p><code>exports </code>Exports of goods and services
</p>
</li>
<li><p><code>imports </code>Imports of goods and services
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Eurostat, <a href="https://ec.europa.eu/eurostat/data">https://ec.europa.eu/eurostat/data</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(economy)
str(economy)
</code></pre>

<hr>
<h2 id='educFM'>education level of father (F) and mother (M)</h2><span id='topic+educFM'></span>

<h3>Description</h3>

<p>Education level of father (F) and mother (M) in percentages of low
(l), medium (m), and high (h) of 31 countries in Europe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(educFM)
</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations and 8 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>community code
</p>
</li>
<li><p><code>F.l </code>percentage of females with low edcuation level
</p>
</li>
<li><p><code>F.m </code>percentage of females with medium edcuation level
</p>
</li>
<li><p><code>F.h </code>percentage of females with high edcuation level
</p>
</li>
<li><p><code>F.l </code>percentage of males with low edcuation level
</p>
</li>
<li><p><code>F.m </code>percentage of males with medium edcuation level
</p>
</li>
<li><p><code>F.h </code>percentage of males with high edcuation level
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ
</p>


<h3>Source</h3>

<p>from Eurostat,<a href="https://ec.europa.eu/eurostat/">https://ec.europa.eu/eurostat/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(educFM)
str(educFM)
</code></pre>

<hr>
<h2 id='efsa'>efsa nutrition consumption</h2><span id='topic+efsa'></span>

<h3>Description</h3>

<p>Comprehensive European Food Consumption Database
</p>


<h3>Format</h3>

<p>A data frame with 87 observations on the following 22 variables.
</p>
 
<ul>
<li><p><code>Country </code>country name
</p>
</li>
<li><p><code>Pop.Class </code>population class
</p>
</li>
<li><p><code>grains </code>Grains and grain-based products
</p>
</li>
<li><p><code>vegetables </code>Vegetables and vegetable products (including fungi)
</p>
</li>
<li><p><code>roots </code>Starchy roots and tubers
</p>
</li>
<li><p><code>nuts </code>Legumes, nuts and oilseeds
</p>
</li>
<li><p><code>fruit </code>Fruit and fruit products
</p>
</li>
<li><p><code>meat </code>Meat and meat products (including edible offal) 
</p>
</li>
<li><p><code>fish </code>Fish and other seafood (including amphibians, rept) 
</p>
</li>
<li><p><code>milk </code>Milk and dairy products
</p>
</li>
<li><p><code>eggs </code>Eggs and egg products
</p>
</li>
<li><p><code>sugar </code>Sugar and confectionary 
</p>
</li>
<li><p><code>fat </code>Animal and vegetable fats and oils 
</p>
</li>
<li><p><code>juices </code>Fruit and vegetable juice 
</p>
</li>
<li><p><code>nonalcoholic </code>Non-alcoholic beverages (excepting milk based beverages) 
</p>
</li>
<li><p><code>alcoholic </code>Alcoholic beverages 
</p>
</li>
<li><p><code>water </code>Drinking water (water without any additives) 
</p>
</li>
<li><p><code>herbs </code>Herbs, spices and condiments 
</p>
</li>
<li><p><code>small_children_food </code>Food for infants and small children 
</p>
</li>
<li><p><code>special </code>Products for special nutritional use 
</p>
</li>
<li><p><code>composite </code>Composite food (including frozen products) 
</p>
</li>
<li><p><code>snacks </code>Snacks, desserts, and other foods 
</p>
</li></ul>



<h3>Details</h3>

<p>The Comprehensive Food Consumption Database is a source of information on 
food consumption across the European Union (EU). 
The food consumption are reported in grams per day (g/day).
</p>


<h3>Source</h3>

<p>efsa
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(efsa)

</code></pre>

<hr>
<h2 id='election'>election data</h2><span id='topic+election'></span>

<h3>Description</h3>

<p>Results of a election in Germany 2013 in different
federal states
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(election)
</code></pre>


<h3>Format</h3>

<p>A data frame with 16 observations and 8 variables
</p>


<h3>Details</h3>

<p>Votes for the political parties
in the elections (compositional variables), and their relation to the unemployment rate
and the average monthly income (external non-compositional variables). Votes are for the Christian Democratic Union and Christian Social Union of Bavaria, also
called The Union (CDU/CSU), Social Democratic Party (SDP), The Left (DIE LINKE),
Alliance '90/The Greens (GRUNE), Free Democratic Party (FDP) and the rest of the
parties participated in the elections (other parties). The votes are examined in absolute
values (number of valid votes). The unemployment in the federal states is reported in
percentages, and the average monthly income in Euros.
</p>

<ul>
<li><p><code>CDU_CSU </code>Christian Democratic Union and Christian Social Union of Bavaria, also
called The Union
</p>
</li>
<li><p><code>SDP </code>Social Democratic Party
</p>
</li>
<li><p><code>GRUENE </code>Alliance '90/The Greens
</p>
</li>
<li><p><code>FDP </code>Free Democratic Party
</p>
</li>
<li><p><code>DIE_LINKE </code>The Left
</p>
</li>
<li><p><code>other_parties </code>Votes for the rest of the
parties participated in the elections
</p>
</li>
<li><p><code>unemployment </code>Unemployment in the federal states in percentages
</p>
</li>
<li><p><code>income </code>Average monthly income in Euros
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Petra Klynclova, Matthias Templ
</p>


<h3>Source</h3>

<p>German Federal Statistical Office
</p>


<h3>References</h3>

<p>Eurostat, <a href="https://ec.europa.eu/eurostat/data">https://ec.europa.eu/eurostat/data</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(election)
str(election)
</code></pre>

<hr>
<h2 id='electionATbp'>Austrian presidential election data</h2><span id='topic+electionATbp'></span>

<h3>Description</h3>

<p>Results the Austrian presidential election in October 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(electionATbp)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2202 observations and 10 variables
</p>


<h3>Details</h3>

<p>Votes for the candidates Hofer and Van der Bellen.
</p>

<ul>
<li><p><code>GKZ </code>Community code
</p>
</li>
<li><p><code>Name </code>Name of the community
</p>
</li>
<li><p><code>Eligible </code>eligible votes
</p>
</li>
<li><p><code>Votes_total </code>total votes
</p>
</li>
<li><p><code>Votes_invalid </code>invalid votes
</p>
</li>
<li><p><code>Votes_valid </code>valid votes
</p>
</li>
<li><p><code>Hofer_total </code>votes for Hofer
</p>
</li>
<li><p><code>Hofer_perc </code>votes for Hofer in percentages
</p>
</li>
<li><p><code>VanderBellen_total </code>votes for Van der Bellen
</p>
</li>
<li><p><code>VanderBellen_perc </code>votes for Van der Bellen in percentages
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Filzmoser
</p>


<h3>Source</h3>

<p>OpenData Austria, <a href="https://www.data.gv.at/">https://www.data.gv.at/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(electionATbp)
str(electionATbp)
</code></pre>

<hr>
<h2 id='employment'>employment in different countries by gender and status.</h2><span id='topic+employment'></span>

<h3>Description</h3>

<p>employment in different countries by gender and status.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(employment)
</code></pre>


<h3>Format</h3>

<p>A three-dimensional table
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment)
str(employment)
employment
</code></pre>

<hr>
<h2 id='employment_df'>Employment in different countries by gender and status.</h2><span id='topic+employment_df'></span>

<h3>Description</h3>


<ul>
<li><p><code>gender</code>factor
</p>
</li>
<li><p><code>status</code>factor, defining if part or full time work
</p>
</li>
<li><p><code>country</code>country
</p>
</li>
<li><p><code>value</code>employment
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(employment_df)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 132 rows and 4 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment_df)
head(employment_df)
</code></pre>

<hr>
<h2 id='employment2'>Employment in different countries by Sex, Age, Contract, Value</h2><span id='topic+employment2'></span>

<h3>Description</h3>

<p>Estimated number of employees in 42 countries in 2015, 
distributed according to gender (Women/Men), 
age (15-24, 25-54, 55+) and type of contract (Full- and part-time).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(employment2)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 504 rows and 5 columns.
</p>


<h3>Details</h3>

<p>For each country in the sample, an estimated number of
employees in the year 2015 was available, divided according to gender and age of
employees and the type of the contract. 
The data form a sample of 42 cubes with two rows (gender), two columns (type)                                                                                                                                          of contract) and three slices (age), which allow for a deeper analysis of the overall
employment structure, not just from the perspective of each factor separately, but
also from the perspective of the relations/interactions between them. 
Thorough analysis of the sample is described in Facevicova (2019).
</p>

<ul>
<li><p><code>Country</code>Country
</p>
</li>
<li><p><code>Sex</code>gender, males (M) and females (F)
</p>
</li>
<li><p><code>Age</code>age class, young (category 15 - 24), middle-aged (25 - 54) and older
(55+) employees
</p>
</li>
<li><p><code>Contract</code>factor, defining the type of contract, full-time (FT) and part-time (PT) contracts
</p>
</li>
<li><p><code>Value</code>Number of employees in the given category (in thousands)
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>Source</h3>

<p>https://stats.oecd.org
</p>


<h3>References</h3>

<p>Facevicova, K., Filzmoser, P. and K. Hron (2019) 
Compositional Cubes: Three-factorial Compositional Data. Under review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment2)
head(employment2)
</code></pre>

<hr>
<h2 id='expenditures'>synthetic household expenditures toy data set</h2><span id='topic+expenditures'></span>

<h3>Description</h3>

<p>This data set from Aitchison (1986), p. 395, describes household expenditures (in former Hong Kong dollars) on five commundity groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(expenditures)
</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 5 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>housing </code>housing (including fuel and light)
</p>
</li>
<li><p><code>foodstuffs </code>foodstuffs
</p>
</li>
<li><p><code>alcohol </code>alcohol and tobacco
</p>
</li>
<li><p><code>other </code>other goods (including clothing, footwear and durable goods)
</p>
</li>
<li><p><code>services </code>services (including transport and vehicles)
</p>
</li></ul>

<p>This data set contains household expenditures on five commodity groups of 20 single men. The variables represent housing (including fuel and light), foodstuff, alcohol and tobacco, other goods (including clothing, footwear and durable goods) and services (including transport and vehicles). Thus they represent the ratios of the men's income spent on the mentioned expenditures.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>, Karel Hron
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional Data</em> Monographs on Statistics and Applied Probability. Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
## imputing a missing value in the data set using k-nearest neighbor imputation:
expenditures[1,3]
expenditures[1,3] &lt;- NA
impKNNa(expenditures)$xImp[1,3]
</code></pre>

<hr>
<h2 id='expendituresEU'>mean consumption expenditures data.</h2><span id='topic+expendituresEU'></span>

<h3>Description</h3>

<p>Mean consumption expenditure of households at EU-level.  The final
consumption expenditure of households encompasses all domestic costs (by
residents and non-residents) for individual needs.
</p>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 12 variables.
</p>
 
<ul>
<li><p><code>Food</code>a numeric vector 
</p>
</li>
<li><p><code>Alcohol</code>a numeric vector 
</p>
</li>
<li><p><code>Clothing</code>a numeric vector
</p>
</li>
<li><p><code>Housing</code>a numeric vector 
</p>
</li>
<li><p><code>Furnishings</code>a numeric vector 
</p>
</li>
<li><p><code>Health</code>a numeric vector
</p>
</li>
<li><p><code>Transport</code>a numeric vector 
</p>
</li>
<li><p><code>Communications</code>a numeric vector 
</p>
</li>
<li><p><code>Recreation</code>a numeric vector
</p>
</li>
<li><p><code>Education</code>a numeric vector 
</p>
</li>
<li><p><code>Restaurants</code>a numeric vector 
</p>
</li>
<li><p><code>Other</code>a numeric vector 
</p>
</li></ul>



<h3>Source</h3>

<p>Eurostat
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expendituresEU)

</code></pre>

<hr>
<h2 id='fcenLR'>fcenLR transformation (functional)</h2><span id='topic+fcenLR'></span>

<h3>Description</h3>

<p>fcenLR[lambda] transformation: mapping from B^2(lambda) into L^2(lambda)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fcenLR(z, z_step, density)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fcenLR_+3A_z">z</code></td>
<td>
<p>grid of points defining the abscissa</p>
</td></tr>
<tr><td><code id="fcenLR_+3A_z_step">z_step</code></td>
<td>
<p>step of the grid of the abscissa</p>
</td></tr>
<tr><td><code id="fcenLR_+3A_density">density</code></td>
<td>
<p>grid evaluation of the lambda-density</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>out</code></td>
<td>
<p>grid evaluation of the lambda-density in L^2(lambda)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Talska<a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>, A. Menafoglio, K. Hron<a href="mailto:karel.hron@upol.cz">karel.hron@upol.cz</a>, J. J. Egozcue, J. Palarea-Albaladejo
</p>


<h3>References</h3>

<p>Talska, R., Menafoglio, A., Hron, K., Egozcue, J. J., Palarea-Albaladejo, J. (2020). Weighting the domain of probability densities in functional data analysis.<em>Stat</em>(2020). https://doi.org/10.1002/sta4.283
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example (normal density)
t = seq(-4.7,4.7, length = 1000)
t_step = diff(t[1:2])

mean = 0; sd = 1.5
f = dnorm(t, mean, sd)
f1 = f/trapzc(t_step,f)

f.fcenLR = fcenLR(t,t_step,f) 
f.fcenLRinv = fcenLRinv(t.fine,t_step,f.fcenLR)

plot(t,f.fcenLR, type="l",las=1, ylab="fcenLR(density)", 
  cex.lab=1.2,cex.axis=1.2, col="darkblue",lwd=2)
abline(h=0, col="red")

plot(t,f.fcenLRinv, type="l",las=1, 
  ylab="density",cex.lab=1.2,cex.axis=1.2, col="darkblue",lwd=2,lty=1)
lines(t,f1,lty=2,lwd=2,col="gold")   
</code></pre>

<hr>
<h2 id='fcenLRinv'>Inverse of fcenLR transformations (functional)</h2><span id='topic+fcenLRinv'></span>

<h3>Description</h3>

<p>Inverse of fcenLR transformations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fcenLRinv(z, z_step, fcenLR, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fcenLRinv_+3A_z">z</code></td>
<td>
<p>grid of points defining the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRinv_+3A_z_step">z_step</code></td>
<td>
<p>step of the grid of the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRinv_+3A_fcenlr">fcenLR</code></td>
<td>
<p>grid evaluation of (i) fcenLR[lambda] transformed lambda-density,
(ii) fcenLR[u] transformed P-density, (iii) fcenLR[P] transformed P-density</p>
</td></tr>
<tr><td><code id="fcenLRinv_+3A_k">k</code></td>
<td>
<p>value of the integral of density; if k=1 it returns a unit-integral representation of density</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, it returns a unit-integral representation of density.
</p>


<h3>Value</h3>

<p><code>out</code> ... grid evaluation of (i) lambda-density in B2(lambda), 
(ii) P-density in unweighted B2(lambda), (iii) P-density in B2(P)
</p>


<h3>Author(s)</h3>

<p>R. Talska<a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>, A. Menafoglio, K. Hron<a href="mailto:karel.hron@upol.cz">karel.hron@upol.cz</a>, J. J. Egozcue, J. Palarea-Albaladejo
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example (normal density)
t = seq(-4.7,4.7, length = 1000)
t_step = diff(t[1:2])

mean = 0; sd = 1.5
f = dnorm(t, mean, sd)
f1 = f/trapzc(t_step,f)

f.fcenLR = fcenLR(t,t_step,f) 
f.fcenLRinv = fcenLRinv(t.fine,t_step,f.fcenLR)

plot(t,f.fcenLR, type="l",las=1, ylab="fcenLR(density)", 
  cex.lab=1.2,cex.axis=1.2, col="darkblue",lwd=2)
abline(h=0, col="red")

plot(t,f.fcenLRinv, type="l",las=1, 
  ylab="density",cex.lab=1.2,cex.axis=1.2, col="darkblue",lwd=2,lty=1)
lines(t,f1,lty=2,lwd=2,col="gold")  
</code></pre>

<hr>
<h2 id='fcenLRp'>fcenLRp transformation (functional)</h2><span id='topic+fcenLRp'></span>

<h3>Description</h3>

<p>fcenLR[P] transformation: mapping from B2(P) into L2(P)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fcenLRp(z, z_step, density, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fcenLRp_+3A_z">z</code></td>
<td>
<p>grid of points defining the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRp_+3A_z_step">z_step</code></td>
<td>
<p>step of the grid of the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRp_+3A_density">density</code></td>
<td>
<p>grid evaluation of the P-density</p>
</td></tr>
<tr><td><code id="fcenLRp_+3A_p">p</code></td>
<td>
<p>density of the reference measure P</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>out</code></td>
<td>
<p>grid evaluation of the P-density in L2(P)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Talska<a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>, A. Menafoglio, K. Hron<a href="mailto:karel.hron@upol.cz">karel.hron@upol.cz</a>, J.J. Egozcue, J. Palarea-Albaladejo
</p>


<h3>References</h3>

<p>Talska, R., Menafoglio, A., Hron, K., Egozcue, J. J., Palarea-Albaladejo, J. (2020). Weighting the domain of probability densities in functional data analysis.<em>Stat</em>(2020). https://doi.org/10.1002/sta4.283
</p>

<hr>
<h2 id='fcenLRu'>fcenLRu transformation (functional)</h2><span id='topic+fcenLRu'></span>

<h3>Description</h3>

<p>fcenLR[u] transformation: mapping from B2(P) into unweigted L2(lambda)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fcenLRu(z, z_step, density, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fcenLRu_+3A_z">z</code></td>
<td>
<p>grid of points defining the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRu_+3A_z_step">z_step</code></td>
<td>
<p>step of the grid of the abscissa</p>
</td></tr>
<tr><td><code id="fcenLRu_+3A_density">density</code></td>
<td>
<p>grid evaluation of the P-density</p>
</td></tr>
<tr><td><code id="fcenLRu_+3A_p">p</code></td>
<td>
<p>density of the reference measure P</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>out</code></td>
<td>
<p>grid evaluation of the P-density in unweighted L2(lambda)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Talska<a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>, A. Menafoglio, K. Hron<a href="mailto:karel.hron@upol.cz">karel.hron@upol.cz</a>, J. J. Egozcue, J. Palarea-Albaladejo
</p>


<h3>References</h3>

<p>Talska, R., Menafoglio, A., Hron, K., Egozcue, J. J., Palarea-Albaladejo, J. (2020). Weighting the domain of probability densities in functional data analysis.<em>Stat</em>(2020). https://doi.org/10.1002/sta4.283
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Common example for all transformations - fcenLR, fcenLRp, fcenLRu 
# Example (log normal distribution under the reference P) 
t = seq(1,10, length = 1000)
t_step = diff(t[1:2])

# Log normal density w.r.t. Lebesgue reference measure in B2(lambda)
f = dlnorm(t, meanlog = 1.5, sdlog = 0.5)

# Log normal density w.r.t. Lebesgue reference measure in L2(lambda)
f.fcenLR = fcenLR(t,t_step,f) 

# New reference given by exponential density
p = dexp(t,0.25)/trapzc(t_step,dexp(t,0.25))

# Plot of log normal density w.r.t. Lebesgue reference measure 
# in B2(lambda) together with the new reference density p
matplot(t,f,type="l",las=1, ylab="density",cex.lab=1.2,cex.axis=1.2, 
  col="black",lwd=2,ylim=c(0,0.3),xlab="t")
matlines(t,p,col="blue")
text(2,0.25,"p",col="blue")
text(4,0.22,"f",col="black")

# Log-normal density w.r.t. exponential distribution in B2(P) 
# (unit-integral representation)
fp = (f/p)/trapzc(t_step,f/p)

# Log-normal density w.r.t. exponential distribution in L2(P)
fp.fcenLRp = fcenLRp(t,t_step,fp,p)

# Log-normal density w.r.t. exponential distribution in L2(lambda)
fp.fcenLRu = fcenLRu(t,t_step,fp,p)

# Log-normal density w.r.t. exponential distribution in B2(lambda)
fp.u = fcenLRinv(t,t_step,fp.fcenLRu)

# Plot
layout(rbind(c(1,2,3,4),c(7,8,5,6)))
par(cex=1.1)

plot(t, f.fcenLR, type='l', ylab=expression(fcenLR[lambda](f)), 
  xlab='t',las=1,ylim=c(-3,3),
  main=expression(bold(atop(paste('(a) Representation of f in ', L^2, (lambda)),'[not weighted]'))))
abline(h=0,col="red")

plot(t, f, type='l', ylab=expression(f[lambda]), 
  xlab='t',las=1,ylim=c(0,0.4),
  main=expression(bold(atop(paste('(b) Density f in ', B^2, (lambda)),'[not weighted]'))))

plot(t, fp, type='l', ylab=expression(f[P]), xlab='t',
  las=1,ylim=c(0,0.4),
  main=expression(bold(atop(paste('(c) Density f in ', B^2, (P)),'[weighted with P]'))))

plot(t, fp.fcenLRp, type='l', ylab=expression(fcenLR[P](f[P])), 
  xlab='t',las=1,ylim=c(-3,3), 
  main=expression(bold(atop(paste('(d) Representation of f in ', L^2, (P)),'[weighted with P]'))))
abline(h=0,col="red")

plot(t, fp.u, type='l', ylab=expression(paste(omega^(-1),(f[P]))), 
  xlab='t',las=1,ylim=c(0,0.4), 
  main=expression(bold(atop(paste('(e) Representation of f in ', B^2, (lambda)),'[unweighted]'))))

plot(t, fp.fcenLRu, type='l', ylab=expression(paste(fcenLR[u](f[P]))), 
  xlab='t',las=1,ylim=c(-3,3),
  main=expression(bold(atop(paste('(f) Representation of f in ', L^2, (lambda)),'[unweighted]'))))
abline(h=0,col="red")
</code></pre>

<hr>
<h2 id='foodbalance'>country food balances</h2><span id='topic+foodbalance'></span>

<h3>Description</h3>

<p>Food balance in each country (2018)
</p>


<h3>Format</h3>

<p>A data frame with 115 observations on the following 116 variables.
</p>
 
<ul>
<li><p><code>country</code>country 
</p>
</li>
<li><p><code>Cereals - Excluding Beer</code>Food balance on cereals 
</p>
</li>
<li><p><code>...</code>...
#' </p>
</li>
<li><p><code>Alcohol - Non-Food</code>Food balance on alcohol
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://www.fao.org/home/en/">https://www.fao.org/home/en/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(foodbalance)

</code></pre>

<hr>
<h2 id='GDPsatis'>GDP satisfaction</h2><span id='topic+GDPsatis'></span>

<h3>Description</h3>

<p>Satisfaction of GDP in 31 countries. The GDP is measured per capita from the year 2012.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GDPsatis)
</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations and 8 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>community code
</p>
</li>
<li><p><code>gdp </code>GDP per capita in 2012
</p>
</li>
<li><p><code>very.bad </code>satisfaction very bad
</p>
</li>
<li><p><code>bad </code>satisfaction bad
</p>
</li>
<li><p><code>moderately.bad </code>satisfaction moderately bad
</p>
</li>
<li><p><code>moderately.good </code>satisfaction moderately good
</p>
</li>
<li><p><code>good </code>satisfaction good
</p>
</li>
<li><p><code>very.good </code>satisfaction very good
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ
</p>


<h3>Source</h3>

<p>from Eurostat,<a href="https://ec.europa.eu/eurostat/">https://ec.europa.eu/eurostat/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(GDPsatis)
str(GDPsatis)
</code></pre>

<hr>
<h2 id='gemas'>GEMAS geochemical data set</h2><span id='topic+gemas'></span>

<h3>Description</h3>

<p>Geochemical data set on agricultural and grazing land soil
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gemas)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2108 observations and 30 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>COUNTRY </code>country name
</p>
</li>
<li><p><code>longitude </code>longitude in WGS84
</p>
</li>
<li><p><code>latitude </code>latitude in WGS84
</p>
</li>
<li><p><code>Xcoord </code>UTM zone east
</p>
</li>
<li><p><code>Ycoord </code>UTM zone north
</p>
</li>
<li><p><code>MeanTemp</code>Annual mean temperature
</p>
</li>
<li><p><code>AnnPrec </code>Annual mean precipitation
</p>
</li>
<li><p><code>soilclass </code>soil class
</p>
</li>
<li><p><code>sand </code>sand
</p>
</li>
<li><p><code>silt </code>silt
</p>
</li>
<li><p><code>clay </code>clay
</p>
</li>
<li><p><code>Al </code>Concentration of aluminum (in mg/kg)
</p>
</li>
<li><p><code>Ba </code>Concentration of barium (in mg/kg)
</p>
</li>
<li><p><code>Ca </code>Concentration of calzium (in mg/kg)\
</p>
</li>
<li><p><code>Cr </code>Concentration of chromium (in mg/kg)
</p>
</li>
<li><p><code>Fe </code>Concentration of iron (in mg/kg)
</p>
</li>
<li><p><code>K </code>Concentration of pottasium (in mg/kg)
</p>
</li>
<li><p><code>Mg </code>Concentration of magnesium (in mg/kg)
</p>
</li>
<li><p><code>Mn </code>Concentration of manganese (in mg/kg)
</p>
</li>
<li><p><code>Na </code>Concentration of sodium (in mg/kg)
</p>
</li>
<li><p><code>Nb </code>Concentration of niobium (in mg/kg)
</p>
</li>
<li><p><code>Ni </code>Concentration of nickel (in mg/kg)
</p>
</li>
<li><p><code>P </code>Concentration of phosphorus (in mg/kg)
</p>
</li>
<li><p><code>Si </code>Concentration of silicium (in mg/kg)
</p>
</li>
<li><p><code>Sr </code>Concentration of strontium (in mg/kg)
</p>
</li>
<li><p><code>Ti </code>Concentration of titanium (in mg/kg)
</p>
</li>
<li><p><code>V </code>Concentration of vanadium (in mg/kg)\
</p>
</li>
<li><p><code>Y </code>Concentration of yttrium (in mg/kg)
</p>
</li>
<li><p><code>Zn </code>Concentration of zinc (in mg/kg)
</p>
</li>
<li><p><code>Zr </code>Concentration of zirconium (in mg/kg)
</p>
</li>
<li><p><code>LOI </code>Loss on ignition (in wt-percent)
</p>
</li></ul>

<p>The sampling, at a density of 1 site/2500 sq. km, was completed at the beginning of 2009 by collecting 2211 samples of agricultural soil (Ap-horizon, 0-20 cm, regularly ploughed fields), and 2118 samples from land under permanent grass cover (grazing land soil, 0-10 cm), according to an agreed field protocol.
All GEMAS project samples were shipped to Slovakia for sample preparation, where they were air dried, sieved to &lt;2 mm using a nylon screen, homogenised and split to subsamples for analysis. They were analysed for a large number of chemical elements. In this sample, the main elements by X-ray fluorescence are included as well as the composition on sand, silt, clay.
</p>


<h3>Author(s)</h3>

<p>GEMAS is a cooperation project between the EuroGeoSurveys Geochemistry Expert Group and Eurometaux. Integration in R, Peter Filzmoser and Matthias Templ.
</p>


<h3>References</h3>

<p>Reimann, C., Birke, M., Demetriades, A., Filzmoser, P. and O'Connor, P. (Editors), 2014. Chemistry of Europe's agricultural soils - Part A: Methodology and interpretation of the GEMAS data set. Geologisches Jahrbuch (Reihe B 102), Schweizerbarth, Hannover, 528 pp. + DVD 
Reimann, C., Birke, M., Demetriades, A., Filzmoser, P. &amp; O'Connor, P. (Editors), 2014. Chemistry of Europe's agricultural soils - Part B: General background information and further analysis of the GEMAS data set. Geologisches Jahrbuch (Reihe B 103), Schweizerbarth, Hannover, 352 pp.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(gemas)
str(gemas)
## sample sites
## Not run: 
require(ggmap)
map &lt;- get_map("europe", source = "stamen", maptype = "watercolor", zoom=4)
ggmap(map) + geom_point(aes(x=longitude, y=latitude), data=gemas)
map &lt;- get_map("europe", zoom=4)
ggmap(map) + geom_point(aes(x=longitude, y=latitude), data=gemas, size=0.8)

## End(Not run)
</code></pre>

<hr>
<h2 id='gjovik'>gjovik</h2><span id='topic+gjovik'></span>

<h3>Description</h3>

<p>Gjovik geochemical data set
</p>


<h3>Format</h3>

<p>A data frame with 615 observations and 63 variables.
</p>

<ul>
<li><p><code>ID </code>a numeric vector
</p>
</li>
<li><p><code>MAT </code>type of material
</p>
</li>
<li><p><code>mE32wgs </code>longitude 
</p>
</li>
<li><p><code>mN32wgs </code>latitude 
</p>
</li>
<li><p><code>XCOO </code>X coordinates
</p>
</li>
<li><p><code>YCOO </code>Y coordinates
</p>
</li>
<li><p><code>ALT </code>altitute
</p>
</li>
<li><p><code>kmNS </code>some distance north-south
</p>
</li>
<li><p><code>kmSN </code>some distance south-north
</p>
</li>
<li><p><code>LITHO </code>lithologies
</p>
</li>
<li><p><code>Ag </code>a numeric vector
</p>
</li>
<li><p><code>Al </code>a numeric vector
</p>
</li>
<li><p><code>As </code>a numeric vector
</p>
</li>
<li><p><code>Au </code>a numeric vector
</p>
</li>
<li><p><code>B </code>a numeric vector
</p>
</li>
<li><p><code>Ba </code>a numeric vector
</p>
</li>
<li><p><code>Be </code>a numeric vector
</p>
</li>
<li><p><code>Bi </code>a numeric vector
</p>
</li>
<li><p><code>Ca </code>a numeric vector
</p>
</li>
<li><p><code>Cd </code>a numeric vector
</p>
</li>
<li><p><code>Ce </code>a numeric vector
</p>
</li>
<li><p><code>Co </code>a numeric vector
</p>
</li>
<li><p><code>Cr </code>a numeric vector
</p>
</li>
<li><p><code>Cs </code>a numeric vector
</p>
</li>
<li><p><code>Cu </code>a numeric vector
</p>
</li>
<li><p><code>Fe </code>a numeric vector
</p>
</li>
<li><p><code>Ga </code>a numeric vector
</p>
</li>
<li><p><code>Ge </code>a numeric vector
</p>
</li>
<li><p><code>Hf </code>a numeric vector
</p>
</li>
<li><p><code>Hg </code>a numeric vector
</p>
</li>
<li><p><code>In </code>a numeric vector
</p>
</li>
<li><p><code>K </code>a numeric vector
</p>
</li>
<li><p><code>La </code>a numeric vector
</p>
</li>
<li><p><code>Li </code>a numeric vector
</p>
</li>
<li><p><code>Mg </code>a numeric vector
</p>
</li>
<li><p><code>Mn </code>a numeric vector
</p>
</li>
<li><p><code>Mo </code>a numeric vector
</p>
</li>
<li><p><code>Na </code>a numeric vector
</p>
</li>
<li><p><code>Nb </code>a numeric vector
</p>
</li>
<li><p><code>Ni </code>a numeric vector
</p>
</li>
<li><p><code>P </code>a numeric vector
</p>
</li>
<li><p><code>Pb </code>a numeric vector
</p>
</li>
<li><p><code>Pd </code>a numeric vector
</p>
</li>
<li><p><code>Pt </code>a numeric vector
</p>
</li>
<li><p><code>Rb </code>a numeric vector
</p>
</li>
<li><p><code>Re </code>a numeric vector
</p>
</li>
<li><p><code>S </code>a numeric vector
</p>
</li>
<li><p><code>Sb </code>a numeric vector
</p>
</li>
<li><p><code>Sc </code>a numeric vector
</p>
</li>
<li><p><code>Se </code>a numeric vector
</p>
</li>
<li><p><code>Sn </code>a numeric vector
</p>
</li>
<li><p><code>Sr </code>a numeric vector
</p>
</li>
<li><p><code>Ta </code>a numeric vector
</p>
</li>
<li><p><code>Te </code>a numeric vector
</p>
</li>
<li><p><code>Th </code>a numeric vector
</p>
</li>
<li><p><code>Ti </code>a numeric vector
</p>
</li>
<li><p><code>Tl </code>a numeric vector
</p>
</li>
<li><p><code>U </code>a numeric vector
</p>
</li>
<li><p><code>V </code>a numeric vector
</p>
</li>
<li><p><code>W </code>a numeric vector
</p>
</li>
<li><p><code>Y </code>a numeric vector
</p>
</li>
<li><p><code>Zn </code>a numeric vector
</p>
</li>
<li><p><code>Zr </code>a numeric vector
</p>
</li></ul>



<h3>Details</h3>

<p>Geochemical data set. 41 sample sites have been investigated. At each site, 15 different sample 
materials have been collected and analyzed for the concentration of more than 40 chemical elements. 
Soil: CHO - C horizon, OHO - O horizon. Mushroom: LAC - milkcap. Plant: BIL - birch leaves, 
BLE - blueberry leaves, BLU - blueberry twigs, BTW - birch twigs, CLE - cowberry leaves, 
COW - cowberry twigs, EQU - horsetail, FER - fern, HYL - terrestrial moss, PIB - pine bark, 
SNE - spruce needles, SPR - spruce twigs.
</p>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Dominika Miksova
</p>


<h3>References</h3>

<p>C. Reimann, P. Englmaier, B. Flem, O.A. Eggen, T.E. Finne, M. Andersson &amp; P. Filzmoser (2018). 
The response of 12 different plant materials and one mushroom to Mo and Pb mineralization along 
a 100-km transect in southern central Norway. 
Geochemistry: Exploration, Environment, Analysis, 18(3), 204-215.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(gjovik)
str(gjovik)
</code></pre>

<hr>
<h2 id='gm'>gmean</h2><span id='topic+gm'></span>

<h3>Description</h3>

<p>This function calculates the geometric mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gm(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gm_+3A_x">x</code></td>
<td>
<p>a vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gm</code> calculates the geometric mean for all positive entries of a vector. 
Please note that there is a faster version available implemented with Rcpp
but it currently do not pass CRAN checks cause of use of Rcpp11 features. This C++ version
accounts for over- and underflows. It is placed in inst/doc
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gm(c(3,5,3,6,7))
</code></pre>

<hr>
<h2 id='gmean_sum'>Geometric mean</h2><span id='topic+gmean_sum'></span><span id='topic+gmean'></span>

<h3>Description</h3>

<p>Computes the geometric mean(s) of a numeric vector, matrix or data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmean_sum(x, margin = NULL)

gmean(x, margin = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmean_sum_+3A_x">x</code></td>
<td>
<p>matrix or data.frame with numeric entries</p>
</td></tr>
<tr><td><code id="gmean_sum_+3A_margin">margin</code></td>
<td>
<p>a vector giving the subscripts which the function will be applied over, 
1 indicates rows, 2 indicates columns, 3 indicates all values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gmean_sum</code> calculates the totals based on geometric means while <code>gmean</code>
calculates geometric means on rows (margin = 1), on columns (margin = 2), or on all values (margin = 3)
</p>


<h3>Value</h3>

<p>geometric means (if <code>gmean</code> is used) or totals (if <code>gmean_sum</code> is used)
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("precipitation")
gmean_sum(precipitation)
gmean_sum(precipitation, margin = 2)
gmean_sum(precipitation, margin = 1)
gmean_sum(precipitation, margin = 3)
addmargins(precipitation)
addmargins(precipitation, FUN = gmean_sum)
addmargins(precipitation, FUN = mean)
addmargins(precipitation, FUN = gmean)

data("arcticLake", package = "robCompositions")
gmean(arcticLake$sand)
gmean(as.numeric(arcticLake[1, ]))
gmean(arcticLake)
gmean(arcticLake, margin = 1)
gmean(arcticLake, margin = 2)
gmean(arcticLake, margin = 3)
</code></pre>

<hr>
<h2 id='govexp'>government spending</h2><span id='topic+govexp'></span>

<h3>Description</h3>

<p>Government expenditures based on COFOG categories
</p>


<h3>Format</h3>

<p>A (tidy) data frame with 5140 observations on the following 4 variables.
</p>
 
<ul>
<li><p><code>country </code>Country of origin
</p>
</li>
<li><p><code>category </code>The COFOG expenditures are divided into 
in the following ten categories: general public services; 
defence; public order and safety; economic affairs; 
environmental protection; housing and community amenities; 
health; recreation, culture and religion; education; and 
social protection.  
</p>
</li>
<li><p><code>year </code>Year 
</p>
</li>
<li><p><code>value </code>COFOG spendings/expenditures
</p>
</li></ul>



<h3>Details</h3>

<p>The general government sector consists of central, 
state and local governments, and the social security funds controlled 
by these units. The data are based on the system of national accounts, 
a set of internationally agreed concepts, definitions, classifications 
and rules for national accounting. The classification of functions of government 
(COFOG) is used as classification system. 
The central government spending by category is measured as a percentage 
of total expenditures.
</p>


<h3>Author(s)</h3>

<p>translated from <a href="https://data.oecd.org/">https://data.oecd.org/</a> and restructured by Matthias Templ
</p>


<h3>Source</h3>

<p>OECD:
<a href="https://data.oecd.org/">https://data.oecd.org/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(govexp)
str(govexp)
</code></pre>

<hr>
<h2 id='haplogroups'>haplogroups data.</h2><span id='topic+haplogroups'></span>

<h3>Description</h3>

<p>Distribution of European Y-chromosome DNA (Y-DNA) haplogroups by region in
percentage.
</p>


<h3>Format</h3>

<p>A data frame with 38 observations on the following 12 variables.
</p>
 
<ul>
<li><p><code>I1 </code>pre-Germanic (Nordic)
</p>
</li>
<li><p><code>I2b </code>pre-Celto-Germanic 
</p>
</li>
<li><p><code>I2a1 </code>Sardinian, Basque 
</p>
</li>
<li><p><code>I2a2 </code>Dinaric, Danubian
</p>
</li>
<li><p><code>N1c1 </code>Uralo-Finnic, Baltic, Siberian
</p>
</li>
<li><p><code>R1a </code>Balto-Slavic, Mycenaean Greek, Macedonia
</p>
</li>
<li><p><code>R1b </code>Italic, Celtic, Germanic; Hitite, Armenian
</p>
</li>
<li><p><code>G2a </code>Caucasian, Greco-Anatolien 
</p>
</li>
<li><p><code>E1b1b </code>North and Eastern Afrika, Near Eastern, Balkanic 
</p>
</li>
<li><p><code>J2 </code>Mesopotamian, Minoan Greek, Phoenician 
</p>
</li>
<li><p><code>J1 </code>Semitic (Arabic, Jewish)
</p>
</li>
<li><p><code>T </code>Near-Eastern, Egyptian, Ethiopian, Arabic 
</p>
</li></ul>



<h3>Details</h3>

<p>Human Y-chromosome DNA can be divided in genealogical groups sharing a
common ancestor, called haplogroups.
</p>


<h3>Source</h3>

<p>Eupedia:
<a href="https://www.eupedia.com/europe/european_y-dna_haplogroups.shtml">https://www.eupedia.com/europe/european_y-dna_haplogroups.shtml</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(haplogroups)

</code></pre>

<hr>
<h2 id='honey'>honey compositions</h2><span id='topic+honey'></span>

<h3>Description</h3>

<p>The contents of honey, syrup, and adulteration mineral elements.
</p>


<h3>Format</h3>

<p>A data frame with 429 observations on the following 17 variables.
</p>
 
<ul>
<li><p><code>class </code>adulterated honey, Honey or Syrup
</p>
</li>
<li><p><code>group </code>group information
</p>
</li>
<li><p><code>group3 </code>detailed group information
</p>
</li>
<li><p><code>group1 </code>less detailed group information
</p>
</li>
<li><p><code>region </code>region
</p>
</li>
<li><p><code>Al </code>chemical element
</p>
</li>
<li><p><code>B </code>chemical element
</p>
</li>
<li><p><code>Ba </code>chemical element 
</p>
</li>
<li><p><code>Ca </code>chemical element 
</p>
</li>
<li><p><code>Fe </code>chemical element
</p>
</li>
<li><p><code>K </code>chemical element
</p>
</li>
<li><p><code>Mg </code>chemical element 
</p>
</li>
<li><p><code>Mn</code>chemical element 
</p>
</li>
<li><p><code>Na </code>chemical element 
</p>
</li>
<li><p><code>P </code>chemical element 
</p>
</li>
<li><p><code>Sr </code>chemical element 
</p>
</li>
<li><p><code>Zn </code>chemical element 
</p>
</li></ul>



<h3>Details</h3>

<p>Discrimination of honey and adulteration by elemental chemometrics profiling.
</p>


<h3>Note</h3>

<p>In the original paper, sparse PLS-DA were applied optimize the classify model 
and test effectiveness. Classify accuracy were exceed 87.7 percent.
</p>


<h3>Source</h3>

<p>Mendeley Data, contributed by Liping Luo and translated to R by Matthias Templ
</p>


<h3>References</h3>

<p>Tao Liu, Kang Ming, Wei Wang, Ning Qiao, Shengrong Qiu, Shengxiang Yi, Xueyong Huang, Liping Luo,
Discrimination of honey and syrup-based adulteration by mineral element chemometrics profiling,'
Food Chemistry, Volume 343, 2021, <a href="https://doi.org/10.1016/j.foodchem.2020.128455">doi:10.1016/j.foodchem.2020.128455</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(honey)

</code></pre>

<hr>
<h2 id='ilr.2x2'>ilr coordinates in 2x2 compositional tables</h2><span id='topic+ilr.2x2'></span>

<h3>Description</h3>

<p>ilr coordinates of original, independent and interaction compositional table using SBP1 and SBP2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ilr.2x2(x, margin = 1, type = "independence", version = "book")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ilr.2x2_+3A_x">x</code></td>
<td>
<p>a 2x2 table</p>
</td></tr>
<tr><td><code id="ilr.2x2_+3A_margin">margin</code></td>
<td>
<p>for 2x2 tables available for a whole set of another dimension.
For example, if 2x2 tables are available for every country.</p>
</td></tr>
<tr><td><code id="ilr.2x2_+3A_type">type</code></td>
<td>
<p>choose between &ldquo;independence&rdquo; or &ldquo;interaction&rdquo; table</p>
</td></tr>
<tr><td><code id="ilr.2x2_+3A_version">version</code></td>
<td>
<p>the version used in the &ldquo;paper&rdquo; below or the version of
the &ldquo;book&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ilr coordinates
</p>


<h3>Author(s)</h3>

<p>Kamila Facevicova, Matthias Templ
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V., Guo, D., Templ, M. (2014).
Logratio approach to statistical analysis of 2x2 compositional tables.
<em>Journal of Applied Statistics</em>, 41 (5), 944&ndash;958.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment) 
ilr.2x2(employment[,,"AUT"])
ilr.2x2(employment[,,"AUT"], version = "paper")
ilr.2x2(employment, margin = 3, version = "paper")
ilr.2x2(employment[,,"AUT"], type = "interaction")
</code></pre>

<hr>
<h2 id='impAll'>Replacement of rounded zeros and missing values.</h2><span id='topic+impAll'></span>

<h3>Description</h3>

<p>Parametric replacement of rounded zeros and missing values for compositional
data using classical and robust methods based on ilr coordinates with
special choice of balances. Values under detection limit should be saved
with the negative value of the detection limit (per variable). Missing
values should be coded as NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impAll(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impAll_+3A_x">x</code></td>
<td>
<p>data frame</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper function that calls <em>impRZilr()</em> for the replacement
of zeros and <em>impCoda</em> for the imputation of missing values
sequentially. The detection limit is automatically derived form negative
numbers in the data set.
</p>


<h3>Value</h3>

<p>The imputed data set.
</p>


<h3>Note</h3>

<p>This function is mainly used by the compositionsGUI.
</p>


<h3>References</h3>

<p>Hron, K., Templ, M., Filzmoser, P. (2010) Imputation of
missing values for compositional data using classical and robust methods,
<em>Computational Statistics and Data Analysis</em>, 54 (12),
3095-3107.
</p>
<p>Martin-Fernandez, J.A., Hron, K., Templ, M., Filzmoser, P.,
Palarea-Albaladejo, J. (2012) Model-based replacement of rounded zeros in
compositional data: Classical and robust approaches, <em>Computational
Statistics</em>, 56 (2012), 2688 - 2704.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>, <code><a href="#topic+impRZilr">impRZilr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## see the compositionsGUI

</code></pre>

<hr>
<h2 id='impCoda'>Imputation of missing values in compositional data</h2><span id='topic+impCoda'></span>

<h3>Description</h3>

<p>This function offers different methods for the imputation of missing values
in compositional data. Missing values are initialized with proper values.
Then iterative algorithms try to find better estimations for the former
missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impCoda(
  x,
  maxit = 10,
  eps = 0.5,
  method = "ltsReg",
  closed = FALSE,
  init = "KNN",
  k = 5,
  dl = rep(0.05, ncol(x)),
  noise = 0.1,
  bruteforce = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impCoda_+3A_x">x</code></td>
<td>
<p>data frame or matrix</p>
</td></tr>
<tr><td><code id="impCoda_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="impCoda_+3A_eps">eps</code></td>
<td>
<p>convergence criteria</p>
</td></tr>
<tr><td><code id="impCoda_+3A_method">method</code></td>
<td>
<p>imputation method</p>
</td></tr>
<tr><td><code id="impCoda_+3A_closed">closed</code></td>
<td>
<p>imputation of transformed data (using ilr transformation) or
in the original space (<code>closed</code> equals TRUE)</p>
</td></tr>
<tr><td><code id="impCoda_+3A_init">init</code></td>
<td>
<p>method for initializing missing values</p>
</td></tr>
<tr><td><code id="impCoda_+3A_k">k</code></td>
<td>
<p>number of nearest neighbors (if init $==$ &ldquo;KNN&rdquo;)</p>
</td></tr>
<tr><td><code id="impCoda_+3A_dl">dl</code></td>
<td>
<p>detection limit(s), only important for the imputation of rounded
zeros</p>
</td></tr>
<tr><td><code id="impCoda_+3A_noise">noise</code></td>
<td>
<p>amount of adding random noise to predictors after convergency</p>
</td></tr>
<tr><td><code id="impCoda_+3A_bruteforce">bruteforce</code></td>
<td>
<p>if TRUE, imputations over dl are set to dl. If FALSE,
truncated (Tobit) regression is applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>eps: The algorithm is finished as soon as the imputed values stabilize, i.e.
until the sum of Aitchison distances from the present and previous iteration
changes only marginally (eps).\
</p>
<p>method: Several different methods can be chosen, such as &lsquo;ltsReg&rsquo;:
least trimmed squares regression is used within the iterative procedure.
&lsquo;lm&rsquo;: least squares regression is used within the iterative
procedure.  &lsquo;classical&rsquo;: principal component analysis is used within
the iterative procedure.  &lsquo;ltsReg2&rsquo;: least trimmed squares regression
is used within the iterative procedure.  The imputated values are perturbed
in the direction of the predictor by values drawn form a normal distribution
with mean and standard deviation related to the corresponding residuals and
multiplied by <code>noise</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>xOrig</code></td>
<td>
<p>Original data frame or matrix</p>
</td></tr> <tr><td><code>xImp</code></td>
<td>
<p>Imputed
data</p>
</td></tr> <tr><td><code>criteria</code></td>
<td>
<p>Sum of the Aitchison distances from the present and
previous iteration</p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>Number of iterations</p>
</td></tr> <tr><td><code>maxit</code></td>
<td>
<p>Maximum
number of iterations </p>
</td></tr> <tr><td><code>w</code></td>
<td>
<p>Amount of imputed values</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>Index of the missing values in the data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ, Karel Hron
</p>


<h3>References</h3>

<p>Hron, K., Templ, M., Filzmoser, P. (2010) Imputation of
missing values for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, 54 (12),
3095-3107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impKNNa">impKNNa</a></code>, <code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
x &lt;- expenditures
x[1,3]
x[1,3] &lt;- NA
xi &lt;- impCoda(x)$xImp
xi[1,3]
s1 &lt;- sum(x[1,-3])
impS &lt;- sum(xi[1,-3])
xi[,3] * s1/impS

# other methods
impCoda(x, method = "lm")
impCoda(x, method = "ltsReg")

</code></pre>

<hr>
<h2 id='impKNNa'>Imputation of missing values in compositional data using knn methods</h2><span id='topic+impKNNa'></span>

<h3>Description</h3>

<p>This function offers several k-nearest neighbor methods for the imputation
of missing values in compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impKNNa(
  x,
  method = "knn",
  k = 3,
  metric = "Aitchison",
  agg = "median",
  primitive = FALSE,
  normknn = TRUE,
  das = FALSE,
  adj = "median"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impKNNa_+3A_x">x</code></td>
<td>
<p>data frame or matrix</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_method">method</code></td>
<td>
<p>method (at the moment, only &ldquo;knn&rdquo; can be used)</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_k">k</code></td>
<td>
<p>number of nearest neighbors chosen for imputation</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_metric">metric</code></td>
<td>
<p>&ldquo;Aichison&rdquo; or &ldquo;Euclidean&rdquo;</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_agg">agg</code></td>
<td>
<p>&ldquo;median&rdquo; or &ldquo;mean&rdquo;, for the aggregation of the
nearest neighbors</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_primitive">primitive</code></td>
<td>
<p>if TRUE, a more enhanced search for the $k$-nearest
neighbors is obtained (see details)</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_normknn">normknn</code></td>
<td>
<p>An adjustment of the imputed values is performed if TRUE</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_das">das</code></td>
<td>
<p>depricated. if TRUE, the definition of the Aitchison distance,
based on simple logratios of the compositional part, is used (Aitchison,
2000) to calculate distances between observations.  if FALSE, a version
using the clr transformation is used.</p>
</td></tr>
<tr><td><code id="impKNNa_+3A_adj">adj</code></td>
<td>
<p>either &lsquo;median&rsquo; (default) or &lsquo;sum&rsquo; can be chosen
for the adjustment of the nearest neighbors, see Hron et al., 2010.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Aitchison <code>metric</code> should be chosen when dealing with compositional
data, the Euclidean <code>metric</code> otherwise.
</p>
<p>If <code>primitive</code> <code class="reqn">==</code> FALSE, a sequential search for the
<code class="reqn">k</code>-nearest neighbors is applied for every missing value where all
information corresponding to the non-missing cells plus the information in
the variable to be imputed plus some additional information is available. If
<code>primitive</code> <code class="reqn">==</code> TRUE, a search of the <code class="reqn">k</code>-nearest neighbors
among observations is applied where in addition to the variable to be
imputed any further cells are non-missing.
</p>
<p>If <code>normknn</code> is TRUE (prefered option) the imputed cells from a nearest
neighbor method are adjusted with special adjustment factors (more details
can be found online (see the references)).
</p>


<h3>Value</h3>

<table>
<tr><td><code>xOrig</code></td>
<td>
<p>Original data frame or matrix</p>
</td></tr> <tr><td><code>xImp</code></td>
<td>
<p>Imputed
data</p>
</td></tr> <tr><td><code>w</code></td>
<td>
<p>Amount of imputed values</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>Index of the missing
values in the data</p>
</td></tr> <tr><td><code>metric</code></td>
<td>
<p>Metric used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J., Barcelo-Vidal, C., Martin-Fernandez, J.A.,
Pawlowsky-Glahn, V. (2000) Logratio analysis and compositional distance,
<em>Mathematical Geology</em>, 32(3), 271-275.
</p>
<p>Hron, K., Templ, M., Filzmoser, P. (2010) Imputation of missing values
for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, 54 (12),
3095-3107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
x &lt;- expenditures
x[1,3]
x[1,3] &lt;- NA
xi &lt;- impKNNa(x)$xImp
xi[1,3]

</code></pre>

<hr>
<h2 id='impRZalr'>alr EM-based imputation of rounded zeros</h2><span id='topic+impRZalr'></span>

<h3>Description</h3>

<p>A modified EM alr-algorithm for replacing rounded zeros in compositional
data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impRZalr(
  x,
  pos = ncol(x),
  dl = rep(0.05, ncol(x) - 1),
  eps = 1e-04,
  maxit = 50,
  bruteforce = FALSE,
  method = "lm",
  step = FALSE,
  nComp = "boot",
  R = 10,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impRZalr_+3A_x">x</code></td>
<td>
<p>compositional data</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_pos">pos</code></td>
<td>
<p>position of the rationing variable for alr transformation</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_dl">dl</code></td>
<td>
<p>detection limit for each part</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_eps">eps</code></td>
<td>
<p>convergence criteria</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_bruteforce">bruteforce</code></td>
<td>
<p>if TRUE, imputations over dl are set to dl. If FALSE,
truncated (Tobit) regression is applied.</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_method">method</code></td>
<td>
<p>either &ldquo;lm&rdquo; (default) or &ldquo;MM&rdquo;</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_step">step</code></td>
<td>
<p>if TRUE, a stepwise (AIC) procedure is applied when fitting
models</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_ncomp">nComp</code></td>
<td>
<p>if determined, it fixes the number of pls components. If
&ldquo;boot&rdquo;, the number of pls components are estimated using a
bootstraped cross validation approach.</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_r">R</code></td>
<td>
<p>number of bootstrap samples for the determination of pls
components. Only important for method &ldquo;pls&rdquo;.</p>
</td></tr>
<tr><td><code id="impRZalr_+3A_verbose">verbose</code></td>
<td>
<p>additional print output during calculations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Statistical analysis of compositional data including zeros runs into
problems, because log-ratios cannot be applied.  Usually, rounded zeros are
considerer as missing not at random missing values. The algorithm first
applies an additive log-ratio transformation to the compositions. Then the
rounded zeros are imputed using a modified EM algorithm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>xOrig</code></td>
<td>
<p>Original data frame or matrix</p>
</td></tr> <tr><td><code>xImp</code></td>
<td>
<p>Imputed
data</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>Index of the missing values in the data</p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>Number of iterations</p>
</td></tr> <tr><td><code>eps</code></td>
<td>
<p>eps</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ and Karel Hron
</p>


<h3>References</h3>

<p>Palarea-Albaladejo, J., Martin-Fernandez, J.A. Gomez-Garcia, J. (2007) 
A parametric approach for dealing with compositional rounded zeros. 
<em>Mathematical Geology</em>, 39(7), 625-645.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impRZilr">impRZilr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
x &lt;- arcticLake
## generate rounded zeros artificially:
x[x[,1] &lt; 5, 1] &lt;- 0
x[x[,2] &lt; 47, 2] &lt;- 0
xia &lt;- impRZalr(x, pos=3, dl=c(5,47), eps=0.05)
xia$xImp

</code></pre>

<hr>
<h2 id='impRZilr'>EM-based replacement of rounded zeros in compositional data</h2><span id='topic+impRZilr'></span>

<h3>Description</h3>

<p>Parametric replacement of rounded zeros for compositional data using
classical and robust methods based on ilr coordinates with a special
choice of balances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impRZilr(
  x,
  maxit = 10,
  eps = 0.1,
  method = "pls",
  dl = rep(0.05, ncol(x)),
  variation = FALSE,
  nComp = "boot",
  bruteforce = FALSE,
  noisemethod = "residuals",
  noise = FALSE,
  R = 10,
  correction = "normal",
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impRZilr_+3A_x">x</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_eps">eps</code></td>
<td>
<p>convergency criteria</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_method">method</code></td>
<td>
<p>either &ldquo;lm&rdquo;, &ldquo;MM&rdquo; or &ldquo;pls&rdquo;</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_dl">dl</code></td>
<td>
<p>Detection limit for each variable. zero for variables with
variables that have no detection limit problems.</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_variation">variation</code></td>
<td>
<p>matrix is used to first select number of parts</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_ncomp">nComp</code></td>
<td>
<p>if determined, it fixes the number of pls components. If
&ldquo;boot&rdquo;, the number of pls components are estimated using a
bootstraped cross validation approach.</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_bruteforce">bruteforce</code></td>
<td>
<p>sets imputed values above the detection limit to the
detection limit. Replacement above the detection limit only exceptionally
occur due to numerical instabilities. The default is FALSE!</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_noisemethod">noisemethod</code></td>
<td>
<p>adding noise to imputed values. Experimental</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_noise">noise</code></td>
<td>
<p>TRUE to activate noise (experimental)</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_r">R</code></td>
<td>
<p>number of bootstrap samples for the determination of pls
components. Only important for method &ldquo;pls&rdquo;.</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_correction">correction</code></td>
<td>
<p>normal or density</p>
</td></tr>
<tr><td><code id="impRZilr_+3A_verbose">verbose</code></td>
<td>
<p>additional print output during calculations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Statistical analysis of compositional data including zeros runs into
problems, because log-ratios cannot be applied. Usually, rounded zeros are
considered as missing not at random missing values.
</p>
<p>The algorithm iteratively imputes parts with rounded zeros whereas in each
step (1) compositional data are expressed in pivot coordinates (2) tobit regression is
applied (3) the rounded zeros are replaced by the expected values (4) the
corresponding inverse ilr mapping is applied. After all parts are
imputed, the algorithm starts again until the imputations do not change.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>imputed data</p>
</td></tr> <tr><td><code>criteria</code></td>
<td>
<p>change between last and
second last iteration</p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr> <tr><td><code>maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>index of zeros</p>
</td></tr>
<tr><td><code>nComp</code></td>
<td>
<p>number of components for method pls</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>chosen
method</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ and Peter Filzmoser
</p>


<h3>References</h3>

<p>Martin-Fernandez, J.A., Hron, K., Templ, M., Filzmoser, P., Palarea-Albaladejo, J. (2012)
Model-based replacement of rounded zeros in compositional data: Classical and robust approaches. 
<em>Computational Statistics and Data Analysis</em>, 56 (9), 2688-2704.
</p>
<p>Templ, M., Hron, K., Filzmoser, P., Gardlo, A. (2016) Imputation of rounded zeros
for high-dimensional compositional data. <em>Chemometrics and Intelligent
Laboratory Systems</em>, 155, 183-190.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impRZalr">impRZalr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
x &lt;- arcticLake
## generate rounded zeros artificially:
#x[x[,1] &lt; 5, 1] &lt;- 0
x[x[,2] &lt; 44, 2] &lt;- 0
xia &lt;- impRZilr(x, dl=c(5,44,0), eps=0.01, method="lm")
xia$x

</code></pre>

<hr>
<h2 id='imputeBDLs'>EM-based replacement of rounded zeros in compositional data</h2><span id='topic+imputeBDLs'></span><span id='topic+print.replaced'></span><span id='topic+checkData'></span><span id='topic+adjustImputed'></span>

<h3>Description</h3>

<p>Parametric replacement of rounded zeros for compositional data using
classical and robust methods based on ilr coordinates with a special
choice of balances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeBDLs(
  x,
  maxit = 10,
  eps = 0.1,
  method = "subPLS",
  dl = rep(0.05, ncol(x)),
  variation = TRUE,
  nPred = NULL,
  nComp = "boot",
  bruteforce = FALSE,
  noisemethod = "residuals",
  noise = FALSE,
  R = 10,
  correction = "normal",
  verbose = FALSE,
  test = FALSE
)

adjustImputed(xImp, xOrig, wind)

checkData(x, dl)

## S3 method for class 'replaced'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputeBDLs_+3A_x">x</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_eps">eps</code></td>
<td>
<p>convergency criteria</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_method">method</code></td>
<td>
<p>either &quot;lm&quot;, &quot;lmrob&quot; or &quot;pls&quot;</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_dl">dl</code></td>
<td>
<p>Detection limit for each variable. zero for variables with
variables that have no detection limit problems.</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_variation">variation</code></td>
<td>
<p>if TRUE those predictors are chosen in each step, who's variation is lowest to the predictor.</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_npred">nPred</code></td>
<td>
<p>if determined and variation equals TRUE, it fixes the number of predictors</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_ncomp">nComp</code></td>
<td>
<p>if determined, it fixes the number of pls components. If
&ldquo;boot&rdquo;, the number of pls components are estimated using a
bootstraped cross validation approach.</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_bruteforce">bruteforce</code></td>
<td>
<p>sets imputed values above the detection limit to the
detection limit. Replacement above the detection limit are only exeptionally
occur due to numerical instabilities. The default is FALSE!</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_noisemethod">noisemethod</code></td>
<td>
<p>adding noise to imputed values. Experimental</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_noise">noise</code></td>
<td>
<p>TRUE to activate noise (experimental)</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_r">R</code></td>
<td>
<p>number of bootstrap samples for the determination of pls
components. Only important for method &ldquo;pls&rdquo;.</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_correction">correction</code></td>
<td>
<p>normal or density</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_verbose">verbose</code></td>
<td>
<p>additional print output during calculations.</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_test">test</code></td>
<td>
<p>an internal test situation (this parameter will be deleted soon)</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_ximp">xImp</code></td>
<td>
<p>imputed data set</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_xorig">xOrig</code></td>
<td>
<p>original data set</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_wind">wind</code></td>
<td>
<p>index matrix of rounded zeros</p>
</td></tr>
<tr><td><code id="imputeBDLs_+3A_...">...</code></td>
<td>
<p>further arguments passed through the print function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Statistical analysis of compositional data including zeros runs into
problems, because log-ratios cannot be applied.  Usually, rounded zeros are
considerer as missing not at random missing values.
</p>
<p>The algorithm iteratively imputes parts with rounded zeros whereas in each
step (1) compositional data are expressed in pivot coordinates (2) tobit regression is
applied (3) the rounded zeros are replaced by the expected values (4) the
corresponding inverse ilr mapping is applied. After all parts are
imputed, the algorithm starts again until the imputations do not change.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>imputed data</p>
</td></tr> <tr><td><code>criteria</code></td>
<td>
<p>change between last and
second last iteration</p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr> <tr><td><code>maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>index of zeros</p>
</td></tr>
<tr><td><code>nComp</code></td>
<td>
<p>number of components for method pls</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>chosen
method</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ, method subPLS from Jiajia Chen
</p>


<h3>References</h3>

<p>Templ, M., Hron, K., Filzmoser, P., Gardlo, A. (2016). 
Imputation of rounded zeros for high-dimensional compositional data. 
<em>Chemometrics and Intelligent Laboratory Systems</em>, 155, 183-190.
</p>
<p>Chen, J., Zhang, X., Hron, K., Templ, M., Li, S. (2018). 
Regression imputation with Q-mode clustering for rounded zero replacement in high-dimensional compositional data. 
<em>Journal of Applied Statistics</em>, 45 (11), 2067-2080.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imputeBDLs">imputeBDLs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
p &lt;- 10
n &lt;- 50
k &lt;- 2
T &lt;- matrix(rnorm(n*k), ncol=k)
B &lt;- matrix(runif(p*k,-1,1),ncol=k)
X &lt;- T %*% t(B)
E &lt;-  matrix(rnorm(n*p, 0,0.1), ncol=p)
XE &lt;- X + E
data &lt;- data.frame(pivotCoordInv(XE))
col &lt;- ncol(data)
row &lt;- nrow(data)
DL &lt;- matrix(rep(0),ncol=col,nrow=1)
for(j in seq(1,col,2))
{DL[j] &lt;- quantile(data[,j],probs=0.06,na.rm=FALSE)}

for(j in 1:col){        
  data[data[,j]&lt;DL[j],j] &lt;- 0
}
## Not run: 
# under dontrun because of long exectution time
imp &lt;- imputeBDLs(data,dl=DL,maxit=10,eps=0.1,R=10,method="subPLS")
imp
imp &lt;- imputeBDLs(data,dl=DL,maxit=10,eps=0.1,R=10,method="pls", variation = FALSE)
imp
imp &lt;- imputeBDLs(data,dl=DL,maxit=10,eps=0.1,R=10,method="lm")
imp
imp &lt;- imputeBDLs(data,dl=DL,maxit=10,eps=0.1,R=10,method="lmrob")
imp

data(mcad)
## generate rounded zeros artificially:
x &lt;- mcad
x &lt;- x[1:25, 2:ncol(x)]
dl &lt;- apply(x, 2, quantile, 0.1)
for(i in seq(1, ncol(x), 2)){
  x[x[,i] &lt; dl[i], i] &lt;- 0
} 
ni &lt;- sum(x==0, na.rm=TRUE) 
ni/(ncol(x)*nrow(x)) * 100
dl[seq(2, ncol(x), 2)] &lt;- 0
replaced_lm &lt;- imputeBDLs(x, dl=dl, eps=1, method="lm",  
  verbose=FALSE, R=50, variation=TRUE)$x
replaced_lmrob &lt;- imputeBDLs(x, dl=dl, eps=1, method="lmrob",  
  verbose=FALSE, R=50, variation=TRUE)$x
replaced_plsfull &lt;- imputeBDLs(x, dl=dl, eps=1, 
  method="pls", verbose=FALSE, R=50, 
  variation=FALSE)$x 

## End(Not run)



</code></pre>

<hr>
<h2 id='imputeUDLs'>Imputation of values above an upper detection limit in compositional data</h2><span id='topic+imputeUDLs'></span>

<h3>Description</h3>

<p>Parametric replacement of values above upper detection limit for compositional data using
classical and robust methods (possibly also the pls method) based on ilr-transformations with special
choice of balances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeUDLs(
  x,
  maxit = 10,
  eps = 0.1,
  method = "lm",
  dl = NULL,
  variation = TRUE,
  nPred = NULL,
  nComp = "boot",
  bruteforce = FALSE,
  noisemethod = "residuals",
  noise = FALSE,
  R = 10,
  correction = "normal",
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputeUDLs_+3A_x">x</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_eps">eps</code></td>
<td>
<p>convergency criteria</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_method">method</code></td>
<td>
<p>either &quot;lm&quot;, &quot;lmrob&quot; or &quot;pls&quot;</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_dl">dl</code></td>
<td>
<p>Detection limit for each variable. zero for variables with
variables that have no detection limit problems.</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_variation">variation</code></td>
<td>
<p>if TRUE those predictors are chosen in each step, who's variation is lowest to the predictor.</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_npred">nPred</code></td>
<td>
<p>if determined and variation equals TRUE, it fixes the number of predictors</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_ncomp">nComp</code></td>
<td>
<p>if determined, it fixes the number of pls components. If
&ldquo;boot&rdquo;, the number of pls components are estimated using a
bootstraped cross validation approach.</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_bruteforce">bruteforce</code></td>
<td>
<p>sets imputed values above the detection limit to the
detection limit. Replacement above the detection limit are only exeptionally
occur due to numerical instabilities. The default is FALSE!</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_noisemethod">noisemethod</code></td>
<td>
<p>adding noise to imputed values. Experimental</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_noise">noise</code></td>
<td>
<p>TRUE to activate noise (experimental)</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_r">R</code></td>
<td>
<p>number of bootstrap samples for the determination of pls
components. Only important for method &ldquo;pls&rdquo;.</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_correction">correction</code></td>
<td>
<p>normal or density</p>
</td></tr>
<tr><td><code id="imputeUDLs_+3A_verbose">verbose</code></td>
<td>
<p>additional print output during calculations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>imputeUDLs
</p>
<p>An imputation method for right-censored compositional data. 
Statistical analysis is not possible with values reported in data, 
for example as &quot;&gt;10000&quot;. These values are replaced using tobit regression.
</p>
<p>The algorithm iteratively imputes parts with values above upper detection limit
whereas in each step (1) compositional data are expressed in pivot coordinates (2) tobit regression is
applied (3) the values above upper detection limit are replaced by the expected values (4) the
corresponding inverse ilr mapping is applied. After all parts are
imputed, the algorithm starts again until the imputations only change marginally.
</p>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>imputed data</p>
</td></tr> <tr><td><code>criteria</code></td>
<td>
<p>change between last and
second last iteration</p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr> <tr><td><code>maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr> <tr><td><code>wind</code></td>
<td>
<p>index of values above upper detection limit</p>
</td></tr>
<tr><td><code>nComp</code></td>
<td>
<p>number of components for method pls</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>chosen
method</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Dominika Miksova based on function imputeBDLs code from Matthias Templ
</p>


<h3>References</h3>

<p>Martin-Fernandez, J.A.,  Hron K.,  Templ, M., Filzmoser, P.  and Palarea-Albaladejo, J. (2012).
Model-based replacement of rounded zeros in compositional data:  Classical and robust approaches.
<em>Computational Statistics and Data Analysis</em>, 56, 2688-2704.
</p>
<p>Templ, M. and Hron, K. and Filzmoser and Gardlo, A. (2016). 
Imputation of rounded zeros for high-dimensional compositional data. 
<em>Chemometrics and Intelligent Laboratory Systems</em>, 155, 183-190.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imputeBDLs">imputeBDLs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gemas)  # read data
dat &lt;- gemas[gemas$COUNTRY=="HEL",c(12:29)]
UDL &lt;- apply(dat,2,max)
names(UDL) &lt;- names(dat)
UDL["Mn"] &lt;- quantile(dat[,"Mn"], probs = 0.8)  # UDL present only in one variable
whichudl &lt;- dat[,"Mn"] &gt; UDL["Mn"] 
# classical method
imp.lm &lt;- dat
imp.lm[whichudl,"Mn"] &lt;- Inf
res.lm &lt;- imputeUDLs(imp.lm, dl=UDL, method="lm", variation=TRUE)
imp.lm &lt;- res.lm$x


</code></pre>

<hr>
<h2 id='ind2x2'>Independence 2x2 compositional table</h2><span id='topic+ind2x2'></span>

<h3>Description</h3>

<p>Estimates the expected frequencies from an 2x2 table under the 
null hypotheses of independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ind2x2(x, margin = 3, pTabMethod = c("dirichlet", "half", "classical"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ind2x2_+3A_x">x</code></td>
<td>
<p>a 2x2 table</p>
</td></tr>
<tr><td><code id="ind2x2_+3A_margin">margin</code></td>
<td>
<p>if multidimensional table (larger than 2-dimensional), 
then the margin determines on which dimension the independene tables should be estimated.</p>
</td></tr>
<tr><td><code id="ind2x2_+3A_ptabmethod">pTabMethod</code></td>
<td>
<p>&lsquo;classical&rsquo; that is function <code>prop.table()</code> from package base or method &ldquo;half&rdquo; that add 1/2 to each cell
to avoid zero problems.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The independence table(s) with either relative or absolute frequencies.
</p>


<h3>Author(s)</h3>

<p>Kamila Facevicova, Matthias Templ
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V., Guo, D., Templ, M. (2014).
Logratio approach to statistical analysis of 2x2 compositional tables.
<em>Journal of Applied Statistics</em>, 41 (5), 944&ndash;958.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment) 
ind2x2(employment)
</code></pre>

<hr>
<h2 id='indTab'>Independence table</h2><span id='topic+indTab'></span>

<h3>Description</h3>

<p>Estimates the expected frequencies from an m-way table under the 
null hypotheses of independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indTab(
  x,
  margin = c("gmean_sum", "sum"),
  frequency = c("relative", "absolute"),
  pTabMethod = c("dirichlet", "half", "classical")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indTab_+3A_x">x</code></td>
<td>
<p>an object of class table</p>
</td></tr>
<tr><td><code id="indTab_+3A_margin">margin</code></td>
<td>
<p>determines how the margins of the table should be estimated (default via geometric mean margins)</p>
</td></tr>
<tr><td><code id="indTab_+3A_frequency">frequency</code></td>
<td>
<p>indicates whether absolute or relative frequencies should be computed.</p>
</td></tr>
<tr><td><code id="indTab_+3A_ptabmethod">pTabMethod</code></td>
<td>
<p>to estimate the propability table. Default is &lsquo;dirichlet&rsquo;. Other available methods: 
&lsquo;classical&rsquo; that is function <code>prop.table()</code> from package base or method &ldquo;half&rdquo; that add 1/2 to each cell
to avoid zero problems.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because of the compositional nature of probability tables, the independence tables should 
be estimated using geometric marginals.
</p>


<h3>Value</h3>

<p>The independence table(s) with either relative or absolute frequencies.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
tab1 &lt;- indTab(precipitation)
tab1
sum(tab1)

## Not run: 
data("PreSex", package = "vcd")
indTab(PreSex)

## End(Not run)
</code></pre>

<hr>
<h2 id='instw'>value added, output and input for different ISIC codes and countries.</h2><span id='topic+instw'></span>

<h3>Description</h3>


<ul>
<li><p><code>ct</code>ct
</p>
</li>
<li><p><code>isic</code>ISIC classification, Rev 3.2
</p>
</li>
<li><p><code>VA</code>value added
</p>
</li>
<li><p><code>OUT</code>output
</p>
</li>
<li><p><code>INP</code>input
</p>
</li>
<li><p><code>IS03</code>country code
</p>
</li>
<li><p><code>mht</code>mht
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(instw)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 1555 rows and 7 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(instw)
head(instw)
</code></pre>

<hr>
<h2 id='int2x2'>Interaction 2x2 table</h2><span id='topic+int2x2'></span>

<h3>Description</h3>

<p>Estimates the interactions from an 2x2 table under the 
null hypotheses of independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>int2x2(x, margin = 3, pTabMethod = c("dirichlet", "half", "classical"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="int2x2_+3A_x">x</code></td>
<td>
<p>a 2x2 table</p>
</td></tr>
<tr><td><code id="int2x2_+3A_margin">margin</code></td>
<td>
<p>if multidimensional table (larger than 2-dimensional), 
then the margin determines on which dimension the independene tables should be estimated.</p>
</td></tr>
<tr><td><code id="int2x2_+3A_ptabmethod">pTabMethod</code></td>
<td>
<p>to estimate the propability table. Default is &lsquo;dirichlet&rsquo;. Other available methods: 
&lsquo;classical&rsquo; that is function <code>prop.table()</code> from package base or method &ldquo;half&rdquo; that add 1/2 to each cell
to avoid zero problems.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The independence table(s) with either relative or absolute frequencies.
</p>


<h3>Author(s)</h3>

<p>Kamila Facevicova, Matthias Templ
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V., Guo, D., Templ, M. (2014).
Logratio approach to statistical analysis of 2x2 compositional tables.
<em>Journal of Applied Statistics</em>, 41 (5), 944&ndash;958.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(employment) 
int2x2(employment)
</code></pre>

<hr>
<h2 id='intArray'>Interaction array</h2><span id='topic+intArray'></span>

<h3>Description</h3>

<p>Estimates the interaction compositional table 
with normalization for further analysis according to Egozcue et al. (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intArray(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intArray_+3A_x">x</code></td>
<td>
<p>an object of class &ldquo;intTab&rdquo;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates the interaction table using its ilr coordinates.
</p>


<h3>Value</h3>

<p>The interaction array
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+intTab">intTab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
tab1prob &lt;- prop.table(precipitation)
tab1 &lt;- indTab(precipitation)
tabINT &lt;- intTab(tab1prob, tab1)
intArray(tabINT)
</code></pre>

<hr>
<h2 id='intTab'>Interaction table</h2><span id='topic+intTab'></span>

<h3>Description</h3>

<p>Estimates the interaction table based on clr and inverse clr coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intTab(x, y, frequencies = c("relative", "absolute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intTab_+3A_x">x</code></td>
<td>
<p>an object of class table</p>
</td></tr>
<tr><td><code id="intTab_+3A_y">y</code></td>
<td>
<p>the corresponding independence table which is of class &ldquo;intTab&rdquo;.</p>
</td></tr>
<tr><td><code id="intTab_+3A_frequencies">frequencies</code></td>
<td>
<p>indicates whether absolute or relative frequencies should be computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because of the compositional nature of probability tables, the independence tables should 
be estimated using geometric marginals.
</p>


<h3>Value</h3>


<ul>
<li><p>intTabThe interaction table(s) with either relative or absolute frequencies.
</p>
</li>
<li><p>signsThe sign illustrates if there is an excess of probability (plus), or a 
deficit (minus) regarding to the estimated probability table and the independece table in the clr space.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation)
tab1prob &lt;- prop.table(precipitation)
tab1 &lt;- indTab(precipitation)
intTab(tab1prob, tab1)
</code></pre>

<hr>
<h2 id='is.equivalent'>equivalence class</h2><span id='topic+is.equivalent'></span>

<h3>Description</h3>

<p>Checks if two vectors or two data frames are from the same equivalence class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.equivalent(x, y, tollerance = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.equivalent_+3A_x">x</code></td>
<td>
<p>either a numeric vector, or a data.frame containing such vectors.</p>
</td></tr>
<tr><td><code id="is.equivalent_+3A_y">y</code></td>
<td>
<p>either a numeric vector, or a data.frame containing such vectors.</p>
</td></tr>
<tr><td><code id="is.equivalent_+3A_tollerance">tollerance</code></td>
<td>
<p>numeric &gt;= 0. Differences smaller than tolerance are not considered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical TRUE if the two vectors are from the same equivalence class.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K., Templ, M. (2018) <em>Applied Compositional Data Analysis</em>.
Springer, Cham.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+all.equal">all.equal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
is.equivalent(1:10, 1:10*2)
is.equivalent(1:10, 1:10+1)
data(expenditures)
x &lt;- expenditures
is.equivalent(x, constSum(x))
y &lt;- x
y[1,1] &lt;- x[1,1]+1
is.equivalent(y, constSum(x))

</code></pre>

<hr>
<h2 id='isic32'>ISIC codes by name</h2><span id='topic+isic32'></span>

<h3>Description</h3>


<ul>
<li><p><code>code</code>ISIC code, Rev 3.2
</p>
</li>
<li><p><code>description</code>Description of ISIC codes
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(isic32)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 24 rows and 2 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(instw)
instw
</code></pre>

<hr>
<h2 id='laborForce'>labour force by status in employment</h2><span id='topic+laborForce'></span>

<h3>Description</h3>

<p>Labour force by status in employment for 124 countries, latest update: December 2009
</p>


<h3>Format</h3>

<p>A data set on 124 compositions on 9 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>country                            
</p>
</li>
<li><p><code>year </code>year                                      
</p>
</li>
<li><p><code>employeesW </code>percentage female employees                             
</p>
</li>
<li><p><code>employeesM </code>percentage male employees
</p>
</li>
<li><p><code>employersW </code>percentage female employers                    
</p>
</li>
<li><p><code>employersM </code>percentage male employers
</p>
</li>
<li><p><code>ownW </code>percentage female own-account workers and contributing family workers               
</p>
</li>
<li><p><code>ownM </code>percentage male own-account workers and contributing family workers 
</p>
</li>
<li><p><code>source </code>HS: household or labour force survey. OE: official estimates. PC: population census 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>conversion to R by Karel Hron and Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>from UNSTATS website
</p>


<h3>References</h3>

<p>K. Hron, P. Filzmoser, K. Thompson (2012). Linear regression with compositional explanatory variables. <em>Journal of Applied Statistics</em>, Volume 39, Issue 5, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(laborForce)
str(laborForce)

</code></pre>

<hr>
<h2 id='landcover'>European land cover</h2><span id='topic+landcover'></span>

<h3>Description</h3>

<p>Land cover data from Eurostat (2015) extended with (log) population and (log) pollution
</p>


<h3>Format</h3>

<p>A data set on 28 compositions on 7 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>Woodland </code>Coverage in km2                            
</p>
</li>
<li><p><code>Cropland </code>Coverage in km2                                      
</p>
</li>
<li><p><code>Grassland </code>Coverage in km2                             
</p>
</li>
<li><p><code>Water </code>Coverage in km2
</p>
</li>
<li><p><code>Artificial </code>Coverage in km2                    
</p>
</li>
<li><p><code>Pollution </code>log(Pollution) values per country
</p>
</li>
<li><p><code>PopDensity </code>log(PopDensity) values per country               
</p>
</li></ul>



<h3>Author(s)</h3>

<p>conversion to R by Karel Hron
</p>


<h3>Source</h3>

<p>Lucas land cover
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(landcover)
str(landcover)

</code></pre>

<hr>
<h2 id='lifeExpGdp'>life expectancy and GDP (2008) for EU-countries</h2><span id='topic+lifeExpGdp'></span>

<h3>Description</h3>

<p>Social-economic data for compositional regression.
</p>


<h3>Format</h3>

<p>A data set on 27 compositions on 9 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>country                                   
</p>
</li>
<li><p><code>agriculture </code>GDP on agriculture, hunting, forestry, fishing (ISIC A-B, x1)               
</p>
</li>
<li><p><code>manufacture </code>GDP on mining, manufacturing, utilities (ISIC C-E, x2)
</p>
</li>
<li><p><code>construction </code>GDP on construction (ISIC F, x3)              
</p>
</li>
<li><p><code>wholesales </code>GDP on wholesale, retail trade, restaurants and hotels (ISIC G-H, x4)
</p>
</li>
<li><p><code>transport </code>GDP on transport, storage and communication (ISIC I, x5)
</p>
</li>
<li><p><code>other </code>GDP on other activities (ISIC J-P, x6)
</p>
</li>
<li><p><code>lifeExpMen </code>life expectancy for men and women
</p>
</li>
<li><p><code>lifeExpWomen </code>life expectancy for men and women
</p>
</li></ul>



<h3>Author(s)</h3>

<p>conversion to R by Karel Hron and Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p><a href="https://www.ec.europa.eu/eurostat">https://www.ec.europa.eu/eurostat</a> and <a href="https://unstats.un.org/home/">https://unstats.un.org/home/</a>
</p>


<h3>References</h3>

<p>K. Hron, P. Filzmoser, K. Thompson (2012). Linear regression with compositional explanatory variables. <em>Journal of Applied Statistics</em>, Volume 39, Issue 5, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(lifeExpGdp)
str(lifeExpGdp)
</code></pre>

<hr>
<h2 id='lmCoDaX'>Classical and robust regression of non-compositional (real) response on
compositional and non-compositional predictors</h2><span id='topic+lmCoDaX'></span><span id='topic+ilrregression'></span><span id='topic+robilrregression'></span>

<h3>Description</h3>

<p>Delivers appropriate inference for regression of y on a compositional matrix
X or and compositional and non-compositional combined predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmCoDaX(
  y,
  X,
  external = NULL,
  method = "robust",
  pivot_norm = "orthonormal",
  max_refinement_steps = 200
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmCoDaX_+3A_y">y</code></td>
<td>
<p>The response which should be non-compositional</p>
</td></tr>
<tr><td><code id="lmCoDaX_+3A_x">X</code></td>
<td>
<p>The compositional and/or non-compositional predictors as a matrix, data.frame or numeric
vector</p>
</td></tr>
<tr><td><code id="lmCoDaX_+3A_external">external</code></td>
<td>
<p>Specify the columns name of the external variables. The name has to be introduced as follows:
external = c(&quot;variable_name&quot;). Multiple selection is supported for the external variable. Factor variables are
automatically detected.</p>
</td></tr>
<tr><td><code id="lmCoDaX_+3A_method">method</code></td>
<td>
<p>If robust, LTS-regression is applied, while with method equals
&ldquo;classical&rdquo;, the conventional least squares regression is applied.</p>
</td></tr>
<tr><td><code id="lmCoDaX_+3A_pivot_norm">pivot_norm</code></td>
<td>
<p>if FALSE then the normalizing constant is not used, if TRUE sqrt((D-i)/(D-i+1))
is used (default). The user can also specify a self-defined constant.</p>
</td></tr>
<tr><td><code id="lmCoDaX_+3A_max_refinement_steps">max_refinement_steps</code></td>
<td>
<p>(for the fast-S algorithm): maximal number of refinement
steps for the fully iterated best candidates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compositional explanatory variables should not be directly used in a linear
regression model because any inference statistic can become misleading.
While various approaches for this problem were proposed, here an approach
based on the pivot coordinates is used. Further these compositional explanatory 
variables can be supplemented with external non-compositional data
and factor variables.
</p>


<h3>Value</h3>

<p>An object of class &lsquo;lts&rsquo; or &lsquo;lm&rsquo; and two summary
objects.
</p>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Roman Wiedemeier, Matthias Templ
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K., Thompsonc, K. (2012) Linear regression
with compositional explanatory variables. <em>Journal of Applied
Statistics</em>, 39, 1115-1128.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## How the total household expenditures in EU Member
## States depend on relative contributions of 
## single household expenditures:
data(expendituresEU)
y &lt;- as.numeric(apply(expendituresEU,1,sum))
lmCoDaX(y, expendituresEU, method="classical")

## How the relative content of sand of the agricultural
## and grazing land soils in Germany depend on
## relative contributions of the main chemical trace elements,
## their different soil types and the Annual mean temperature:
data("gemas")
gemas$COUNTRY &lt;- as.factor(gemas$COUNTRY)
gemas_GER &lt;- dplyr::filter(gemas, gemas$COUNTRY == 'POL')
ssc &lt;- cenLR(gemas_GER[, c("sand", "silt", "clay")])$x.clr
y &lt;- ssc$sand
X &lt;- dplyr::select(gemas_GER, c(MeanTemp, soilclass, Al:Zr))
X$soilclass &lt;- factor(X$soilclass)
lmCoDaX(y, X, external = c('MeanTemp', 'soilclass'),
method='classical', pivot_norm = 'orthonormal')
lmCoDaX(y, X, external = c('MeanTemp', 'soilclass'),
method='robust', pivot_norm = 'orthonormal')
</code></pre>

<hr>
<h2 id='machineOperators'>machine operators</h2><span id='topic+machineOperators'></span>

<h3>Description</h3>

<p>Compositions of eight-hour shifts of 27 machine operators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(machineOperators)
</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 4 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>hqproduction </code>high-quality production
</p>
</li>
<li><p><code>lqproduction </code>low-quality production
</p>
</li>
<li><p><code>setting </code>machine settings
</p>
</li>
<li><p><code>repair </code>machine repair
</p>
</li></ul>

<p>The data set from Aitchison (1986), p. 382, contains compositions of eight-hour shifts of 27 machine operators. The parts represent proportions of shifts in each activity:  high-quality production, low-quality production, machine setting and machine repair.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional Data</em> Monographs on Statistics and Applied Probability. Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(machineOperators)
str(machineOperators)
summary(machineOperators)
rowSums(machineOperators)
</code></pre>

<hr>
<h2 id='manu_abs'>Distribution of manufacturing output</h2><span id='topic+manu_abs'></span>

<h3>Description</h3>

<p>The data consists of values of the manufacturing output in 42 countries in 2009. 
The output, given in national currencies, is structured according to the 
3-digit ISIC category and its components. 
Thorough analysis of the sample is described in Facevicova (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(manu_abs)
</code></pre>


<h3>Format</h3>

<p>A data frame with 630 observations of 4 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>Country
</p>
</li>
<li><p><code>isic </code>3-digit ISIC category. The categories are 
151 processed meat, fish, fruit, vegetables, fats; 
152 Dairy products; 
153 Grain mill products, starches, animal feeds; 
154 Other food products and 
155 Beverages. 
</p>
</li>
<li><p><code>output </code>The output components are Labour, Surplus and Input.
</p>
</li>
<li><p><code>value</code>Value of manufacturing output in the national currency
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>Source</h3>

<p>Elaboration based on the INDSTAT 4 database (UNIDO 2012a), see also UNIDO, 2012b.
UNIDO (2012a), INDSTAT 4 Industrial Statistics Database at 3- and 4-digit level of 
ISIC Revision 3 and 4. Vienna. Available from https://stat.unido.org. 
UNIDO (2012b) International Yearbook of Industrial Statistics, Edward Elgar Publishing Ltd, UK.
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V. and M. Templ (2018) 
General approach to coordinate representation of compositional tables. 
Scandinavian Journal of Statistics, 45(4).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(manu_abs)

### Compositional tables approach
### analysis of the relative structure

result &lt;- tabCoordWrapper(manu_abs, obs.ID='country',row.factor = 'output', 
col.factor = 'isic', value='value', test = TRUE)

result$Bootstrap

### Classical approach
### generalized linear mixed effect model
## Not run: 
library(lme4)
m &lt;- glmer(value~output*as.factor(isic)+(1|country),
data=manu_abs,family=poisson)
summary(m)

## End(Not run)
</code></pre>

<hr>
<h2 id='mcad'>metabolomics mcad data set</h2><span id='topic+mcad'></span>

<h3>Description</h3>

<p>The aim of the experiment was to ascertain novel biomarkers of 
MCAD (Medium chain acyl-CoA dehydrogenase) deficiency. 
The data consists of 25 patients and 25 controls and the analysis was done by LC-MS.
Rows represent patients and controls and columns represent chemical 
entities with their quantity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mcad)
</code></pre>


<h3>Format</h3>

<p>A data frame with 50 observations and 279 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>group </code>patient group
</p>
</li>
<li><p><code>... </code>the remaining variables columns are represented by m/z which are chemical characterizations of individual chemical components on exact mass measurements..
</p>
</li></ul>



<h3>References</h3>

<p>Najdekr L., Gardlo A., Madrova L., Friedeckyy D., Janeckova H., Correa E.S., Goodacre R., Adam T., Oxidized phosphatidylcholines suggest oxidative stress in patients with medium-chain acyl-CoA dehydrogenase deficiency, <em>Talanta</em> 139, 2015, 62-66.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mcad)
str(mcad)
</code></pre>

<hr>
<h2 id='missPatterns'>missing or zero pattern structure.</h2><span id='topic+missPatterns'></span><span id='topic+zeroPatterns'></span>

<h3>Description</h3>

<p>Analysis of the missing or the zero patterns structure of a data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missPatterns(x)

zeroPatterns(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missPatterns_+3A_x">x</code></td>
<td>
<p>a data frame or matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here, one pattern defines those observations that have the same structure
regarding their missingness or zeros. For all patterns a summary is
calculated.
</p>


<h3>Value</h3>

<table>
<tr><td><code>groups</code></td>
<td>
<p>List of the different patterns and the observation
numbers for each pattern</p>
</td></tr> <tr><td><code>cn</code></td>
<td>
<p>the names of the patterns coded as
vectors of 0-1's</p>
</td></tr> <tr><td><code>tabcomb</code></td>
<td>
<p>the pattern structure - all combinations of
zeros or missings in the variables</p>
</td></tr> <tr><td><code>tabcombPlus</code></td>
<td>
<p>the pattern structure
- all combinations of zeros or missings in the variables including the size
of those combinations/patterns, i.e. the number of observations that belongs
to each pattern.</p>
</td></tr> <tr><td><code>rsum</code></td>
<td>
<p>the number of zeros or missing values in each
row of the data set.</p>
</td></tr> <tr><td><code>rindex</code></td>
<td>
<p>the index of zeros or missing values in each
row of the data set</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ. The code is based on a previous version from Andreas
Alfons and Matthias Templ from package VIM
</p>


<h3>See Also</h3>

<p><code><a href="VIM.html#topic+aggr">aggr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
## set NA's artificial:
expenditures[expenditures &lt; 300] &lt;- NA
## detect the NA structure:
missPatterns(expenditures)

</code></pre>

<hr>
<h2 id='mortality'>mortality and life expectancy in the EU</h2><span id='topic+mortality'></span>

<h3>Description</h3>


<ul>
<li><p><code>country </code>country name
</p>
</li>
<li><p><code>country2 </code>country name, short version
</p>
</li>
<li><p><code>sex </code>gender
</p>
</li>
<li><p><code>lifeExpectancy </code>life expectancy
</p>
</li>
<li><p><code>infectious </code>certain infectious and parasitic diseases (A00-B99)
</p>
</li>
<li><p><code>neoplasms </code>malignant neoplasms (C00-C97)
</p>
</li>
<li><p><code>endocrine </code>endocrine nutritional and metabolic diseases (E00-E90)
</p>
</li>
<li><p><code>mental </code>mental and behavioural disorders (F00-F99)
</p>
</li>
<li><p><code>nervous </code>diseases of the nervous system and the sense organs (G00-H95)
</p>
</li>
<li><p><code>circulatory </code>diseases of the circulatory system (I00-I99)
</p>
</li>
<li><p><code>respiratory </code>diseases of the respiratory system (J00-J99)
</p>
</li>
<li><p><code>digestive </code>diseases of the digestive system (K00-K93)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(mortality)
</code></pre>


<h3>Format</h3>

<p>A data frame with 60 observations and 12 variables
</p>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Eurostat, <a href="https://ec.europa.eu/eurostat/data">https://ec.europa.eu/eurostat/data</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mortality)
str(mortality)
## totals (mortality)
aggregate(mortality[,5:ncol(mortality)], 
          list(mortality$country2), sum)
</code></pre>

<hr>
<h2 id='mortality_tab'>mortality table</h2><span id='topic+mortality_tab'></span>

<h3>Description</h3>

<p>Mortality data by gender, unknown year
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mortality_tab)
</code></pre>


<h3>Format</h3>

<p>A table
</p>


<h3>Details</h3>


<ul>
<li><p><code>female</code>mortality rates for females by age groups
</p>
</li>
<li><p><code>male</code>mortality rates for males by age groups
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mortality_tab)
mortality_tab
</code></pre>

<hr>
<h2 id='norm1'>Normalize a vector to length 1</h2><span id='topic+norm1'></span>

<h3>Description</h3>

<p>Scales a vector to a unit vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm1(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm1_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
i &lt;- 1
D &lt;- 6
vec &lt;- c(rep(-1/i, i), 1, rep(0, (D-i-1)))

norm1(vec)

</code></pre>

<hr>
<h2 id='nutrients'>nutrient contents</h2><span id='topic+nutrients'></span>

<h3>Description</h3>

<p>Nutrients on more than 40 components and 965 generic food products
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nutrients)
</code></pre>


<h3>Format</h3>

<p>A data frame with 965 observations on the following 50 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>ID </code>ID, for internal use
</p>
</li>
<li><p><code>ID_V4 </code>ID V4, for internal use
</p>
</li>
<li><p><code>ID_SwissFIR </code>ID, for internal use
</p>
</li>
<li><p><code>name_D </code>Name in German
</p>
</li>
<li><p><code>name_F </code>Name in French
</p>
</li>
<li><p><code>name_I </code>Name in Italian
</p>
</li>
<li><p><code>name_E </code>Name in Spanish
</p>
</li>
<li><p><code>category_D </code>Category name in German
</p>
</li>
<li><p><code>category_F </code>Category name in French
</p>
</li>
<li><p><code>category_I </code>Category name in Italy
</p>
</li>
<li><p><code>category_E </code>Category name in Spanish
</p>
</li>
<li><p><code>gravity </code>specific gravity
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;energy_kJ &#8288;</span>&rsquo;energy in kJ per 100g edible portion
</p>
</li>
<li><p><code>energy_kcal </code>energy in kcal per 100g edible portion
</p>
</li>
<li><p><code>protein </code>protein in gram per 100g edible portion
</p>
</li>
<li><p><code>alcohol </code>alcohol in gram per 100g edible portion
</p>
</li>
<li><p><code>water </code>water in gram per 100g edible portion
</p>
</li>
<li><p><code>carbohydrates</code>crbohydrates in gram per 100g edible portion
</p>
</li>
<li><p><code>starch </code>starch in gram per 100g edible portion
</p>
</li>
<li><p><code>sugars </code>sugars in gram per 100g edible portion
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;dietar_ fibres &#8288;</span>&rsquo;dietar fibres in gram per 100g edible portion
</p>
</li>
<li><p><code>fat </code>fat in gram per 100g edible portion
</p>
</li>
<li><p><code>cholesterol </code>cholesterolin milligram per 100g edible portion
</p>
</li>
<li><p><code>fattyacids_monounsaturated </code>fatty acids monounsatrurated in gram per 100g edible portion
</p>
</li>
<li><p><code>fattyacids_saturated </code>fatty acids saturated in gram per 100g edible portion
</p>
</li>
<li><p><code>fatty_acids_polyunsaturated </code>fatty acids polyunsaturated in gram per 100g edible portion
</p>
</li>
<li><p><code>vitaminA </code>vitamin A in retinol equivalent per 100g edible portion
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;all-trans_retinol_equivalents &#8288;</span>&rsquo;all trans-retinol equivalents in gram per 100g edible portion
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;beta-carotene-activity &#8288;</span>&rsquo;beta-carotene activity in beta-carotene equivalent per 100g edible portion
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;beta-carotene &#8288;</span>&rsquo;beta-carotene in micogram per 100g edible portion
</p>
</li>
<li><p><code>vitaminB1 </code>vitamin B1 in milligram per 100g edible portion
</p>
</li>
<li><p><code>vitaminB2 </code>vitamin B2 in milligram per 100g edible portion
</p>
</li>
<li><p><code>vitaminB6 </code>vitamin B6 in milligram per 100g edible portion
</p>
</li>
<li><p><code>vitaminB12 </code>vitamin B12 in micogram per 100g edible portion
</p>
</li>
<li><p><code>niacin </code>niacin in milligram per 100g edible portion
</p>
</li>
<li><p><code>folate </code>folate in micogram per 100g edible portion
</p>
</li>
<li><p><code>pantothenic_acid </code>pantothenic acid in milligram per 100g edible portion
</p>
</li>
<li><p><code>vitaminC </code>vitamin C in milligram per 100g edible portion
</p>
</li>
<li><p><code>vitaminD </code>vitamin D in micogram per 100g edible portion
</p>
</li>
<li><p><code>vitaminE </code>vitamin E in alpha-tocopherol equivalent per 100g edible portion
</p>
</li>
<li><p><code>Na </code>Sodium in milligram per 100g edible portion
</p>
</li>
<li><p><code>K </code>Potassium in milligram per 100g edible portion
</p>
</li>
<li><p><code>Cl </code>Chloride
</p>
</li>
<li><p><code>Ca </code>Calcium
</p>
</li>
<li><p><code>Mg </code>Magnesium
</p>
</li>
<li><p><code>P </code>Phosphorus
</p>
</li>
<li><p><code>Fe </code>Iron
</p>
</li>
<li><p><code>I </code>Iodide in milligram per 100g edible portion
</p>
</li>
<li><p><code>Zn </code>Zink
</p>
</li>
<li><p><code>unit </code>a factor with levels <code>per 100g edible portion</code> <code>per 100ml food volume</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Translated from the Swiss nutrion data base by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>From the Swiss nutrition data base 2015 (second edition)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(nutrients)
str(nutrients)
head(nutrients[, 41:49])
</code></pre>

<hr>
<h2 id='nutrients_branded'>nutrient contents (branded)</h2><span id='topic+nutrients_branded'></span>

<h3>Description</h3>

<p>Nutrients on more than 10 components and 9618 branded food products
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nutrients_branded)
</code></pre>


<h3>Format</h3>

<p>A data frame with 9618 observations on the following 18 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>name_D </code>name (in German)
</p>
</li>
<li><p><code>category_D </code>factor specifying the category names
</p>
</li>
<li><p><code>category_F </code>factor specifying the category names
</p>
</li>
<li><p><code>category_I </code>factor specifying the category names
</p>
</li>
<li><p><code>category_E </code>factor specifying the category names
</p>
</li>
<li><p><code>gravity </code>specific gravity
</p>
</li>
<li><p><code>energy_kJ </code>energy in kJ
</p>
</li>
<li><p>&lsquo;<span class="samp">&#8288;energy_kcal &#8288;</span>&rsquo;energy in kcal
</p>
</li>
<li><p><code>protein </code>protein in gram
</p>
</li>
<li><p><code>alcohol </code>alcohol in gram
</p>
</li>
<li><p><code>water </code>water in gram
</p>
</li>
<li><p><code>carbohydrates_available </code>available carbohydrates in gram
</p>
</li>
<li><p><code>sugars </code>sugars in gram
</p>
</li>
<li><p><code>dietary_fibres </code>dietary fibres in gram
</p>
</li>
<li><p><code>fat_total </code>total fat in gram
</p>
</li>
<li><p><code>fatty_acids_saturated </code>saturated acids fat in gram
</p>
</li>
<li><p><code>Na </code>Sodium in gram
</p>
</li>
<li><p><code>unit </code>a factor with levels <code>per 100g edible portion</code> <code>per 100ml food volume</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Translated from the Swiss nutrion data base by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>From the Swiss nutrition data base 2015 (second edition)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(nutrients_branded)
str(nutrients_branded)
</code></pre>

<hr>
<h2 id='orthbasis'>Orthonormal basis</h2><span id='topic+orthbasis'></span>

<h3>Description</h3>

<p>Orthonormal basis from cenLR transformed data to pivotCoord transformated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orthbasis(D)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orthbasis_+3A_d">D</code></td>
<td>
<p>number of parts (variables)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the chosen balances for &ldquo;pivotCoord&rdquo;, this is the orthonormal basis
that transfers the data from centered logratio to isometric logratio.
</p>


<h3>Value</h3>

<p>the orthonormal basis.
</p>


<h3>Author(s)</h3>

<p>Karel Hron, Matthias Templ. Some code lines of this function are a copy 
from function gsi.buildilr from
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pivotCoord">pivotCoord</a></code>, <code><a href="#topic+cenLR">cenLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
V &lt;- orthbasis(ncol(expenditures))
xcen &lt;- cenLR(expenditures)$x.clr
xi &lt;- as.matrix(xcen) %*% V$V
xi
xi2 &lt;- pivotCoord(expenditures)
xi2
</code></pre>

<hr>
<h2 id='outCoDa'>Outlier detection for compositional data</h2><span id='topic+outCoDa'></span><span id='topic+print.outCoDa'></span><span id='topic+plot.outCoDa'></span>

<h3>Description</h3>

<p>Outlier detection for compositional data using standard and robust
statistical methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outCoDa(x, quantile = 0.975, method = "robust", alpha = 0.5, coda = TRUE)

## S3 method for class 'outCoDa'
print(x, ...)

## S3 method for class 'outCoDa'
plot(x, y, ..., which = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outCoDa_+3A_x">x</code></td>
<td>
<p>compositional data</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_quantile">quantile</code></td>
<td>
<p>quantile, corresponding to a significance level, is used as
a cut-off value for outlier identification: observations with larger
(squared) robust Mahalanobis distance are considered as potential outliers.</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_method">method</code></td>
<td>
<p>either &ldquo;robust&rdquo; (default) or &ldquo;standard&rdquo;</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_alpha">alpha</code></td>
<td>
<p>the size of the subsets for the robust covariance estimation
according the MCD-estimator for which the determinant is minimized, see <code><a href="robustbase.html#topic+covMcd">covMcd</a></code>.</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_coda">coda</code></td>
<td>
<p>if TRUE, data transformed to coordinate representation before outlier detection.</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_...">...</code></td>
<td>
<p>additional parameters for print and plot method passed through</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_y">y</code></td>
<td>
<p>unused second plot argument for the plot method</p>
</td></tr>
<tr><td><code id="outCoDa_+3A_which">which</code></td>
<td>
<p>1 ... MD against index
2 ... distance-distance plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The outlier detection procedure is based on (robust) Mahalanobis distances
in isometric logratio coordinates.  Observations with
squared Mahalanobis distance greater equal a certain quantile of the
chi-squared distribution are marked as outliers.
</p>
<p>If method &ldquo;robust&rdquo; is chosen, the outlier detection is based on the
homogeneous majority of the compositional data set. If method
&ldquo;standard&rdquo; is used, standard measures of location and scatter are
applied during the outlier detection procedure. Method &ldquo;robust&rdquo;
can be used if the number of variables is greater than the number
of observations. Here the OGK estimator is chosen. 
</p>
<p>plot method: the Mahalanobis distance are plotted against the index.
The dashed line indicates the (1 - alpha) quantile of the chi-squared
distribution. Observations with Mahalanobis distance greater than this
quantile could be considered as compositional outliers.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mahalDist</code></td>
<td>
<p>resulting Mahalanobis distance</p>
</td></tr> <tr><td><code>limit</code></td>
<td>
<p>quantile of the Chi-squared distribution</p>
</td></tr> <tr><td><code>outlierIndex</code></td>
<td>
<p>logical
vector indicating outliers and non-outliers</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>method used</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It is highly recommended to use the robust version of the procedure.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Karel Hron
</p>


<h3>References</h3>

<p>Egozcue J.J., Pawlowsky-Glahn, V., Mateu-Figueras, G.,
Barcelo-Vidal, C. (2003) Isometric logratio transformations for compositional
data analysis. <em>Mathematical Geology</em>, 35 (3) 279-300. 
</p>
<p>Filzmoser, P., and Hron, K. (2008) Outlier detection for compositional data
using robust methods. <em>Math. Geosciences</em>, 40, 233-248.
</p>
<p>Rousseeuw, P.J., Van Driessen, K. (1999) A fast algorithm for the minimum
covariance determinant estimator.  <em>Technometrics</em>, 41, 212-223.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
oD &lt;- outCoDa(expenditures)
oD
## providing a function:
oD &lt;- outCoDa(expenditures, coda = log)
## for high-dimensional data:
oD &lt;- outCoDa(expenditures, method = "robustHD")
</code></pre>

<hr>
<h2 id='payments'>special payments</h2><span id='topic+payments'></span>

<h3>Description</h3>

<p>Payments splitted by different NACE categories and kind of employment in Austria 2004
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(payments)
</code></pre>


<h3>Format</h3>

<p>A data frame with 535 rows and 11 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>nace </code>NACE classification, 2 digits
</p>
</li>
<li><p><code>oenace_2008 </code>Corresponding Austrian NACE classification (in German)
</p>
</li>
<li><p><code>year </code>year
</p>
</li>
<li><p><code>month </code>month
</p>
</li>
<li><p><code>localunit </code>local unit ID
</p>
</li>
<li><p><code>spay </code>special payments (total)
</p>
</li>
<li><p><code>spay_wc </code>special payments for white colar workers
</p>
</li>
<li><p><code>spay_bc </code>special payments for blue colar workers
</p>
</li>
<li><p><code>spay_traintrade </code>special payments for trainees in trade businness
</p>
</li>
<li><p><code>spay_home </code>special payments for home workers
</p>
</li>
<li><p><code>spay_traincomm </code>special payments for trainees in commercial businness
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>statCube data base at the website of Statistics Austria. The product and all 
material contained therein are protected by copyright with all rights 
reserved by the Bundesanstalt Statistik Oesterreich (STATISTICS AUSTRIA). 
It is permitted to reproduce, distribute, make publicly available 
and process the content for non-commercial purposes. Prior to any use for 
commercial purposes a written consent of STATISTICS AUSTRIA must be obtained. 
Any use of the contained material must 
be correctly reproduced and clearly cite the source STATISTICS AUSTRIA. 
If tables published by STATISTICS AUSTRIA are partially used, displayed or 
otherwise changed, a note must be added at an adequate position to 
show data was extracted or adapted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(payments)
str(payments)
summary(payments)
</code></pre>

<hr>
<h2 id='pcaCoDa'>Robust principal component analysis for compositional data</h2><span id='topic+pcaCoDa'></span><span id='topic+print.pcaCoDa'></span><span id='topic+summary.pcaCoDa'></span>

<h3>Description</h3>

<p>This function applies robust principal component analysis for compositional
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcaCoDa(
  x,
  method = "robust",
  mult_comp = NULL,
  external = NULL,
  solve = "eigen"
)

## S3 method for class 'pcaCoDa'
print(x, ...)

## S3 method for class 'pcaCoDa'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcaCoDa_+3A_x">x</code></td>
<td>
<p>compositional data</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_method">method</code></td>
<td>
<p>must be either &ldquo;robust&rdquo; (default) or &ldquo;classical&rdquo;</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_mult_comp">mult_comp</code></td>
<td>
<p>a list of numeric vectors holding the indices of linked
compositions</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_external">external</code></td>
<td>
<p>external non-compositional variables</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_solve">solve</code></td>
<td>
<p>eigen (as princomp does, i.e. eigenvalues of the covariance matrix) or svd (as prcomp does with single value decomposition instead of eigen). Only for method classical.</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_...">...</code></td>
<td>
<p>additional parameters for print method passed through</p>
</td></tr>
<tr><td><code id="pcaCoDa_+3A_object">object</code></td>
<td>
<p>object of class pcaCoDa</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional data set is expressed in isometric logratio coordinates.
Afterwards, robust principal component analysis is performed.  Resulting
loadings and scores are back-transformed to the clr space where the
compositional biplot can be shown.
</p>
<p><code>mult_comp</code> is used when there are more than one group of compositional
parts in the data. To give an illustrative example, lets assume that one
variable group measures angles of the inner ear-bones of animals which sum
up to 100 and another one having percentages of a whole on the thickness of
the inner ear-bones included. Then two groups of variables exists which are
both compositional parts. The isometric logratio coordinates are then internally applied
to each group independently whenever the <code>mult_comp</code> is set correctly.
</p>


<h3>Value</h3>

<table>
<tr><td><code>scores</code></td>
<td>
<p>scores in clr space</p>
</td></tr> <tr><td><code>loadings</code></td>
<td>
<p>loadings in clr
space</p>
</td></tr> <tr><td><code>eigenvalues</code></td>
<td>
<p>eigenvalues of the clr covariance matrix</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>method</p>
</td></tr> <tr><td><code>princompOutputClr</code></td>
<td>
<p>output of <code>princomp</code>
needed in <code>plot.pcaCoDa</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Karel Hron, Peter Filzmoser, Matthias Templ and a contribution for dimnames in external variables by Amelia Landre.
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K., Reimann, C. (2009) Principal component
analysis for compositional data with outliers. <em>Environmetrics</em>,
<b>20</b>, 621-632.
</p>
<p>Kynclova, P., Filzmoser, P., Hron, K. (2016) Compositional biplots including external non-compositional variables. 
<em>Statistics: A Journal of Theoretical and Applied Statistics</em>,
<b>50</b>, 1132-1148.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.pcaCoDa">print.pcaCoDa</a></code>, <code><a href="#topic+summary.pcaCoDa">summary.pcaCoDa</a></code>, <code><a href="#topic+biplot.pcaCoDa">biplot.pcaCoDa</a></code>, <code><a href="#topic+plot.pcaCoDa">plot.pcaCoDa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)

## robust estimation (default):
res.rob &lt;- pcaCoDa(arcticLake)
res.rob
summary(res.rob)
plot(res.rob)

## classical estimation:
res.cla &lt;- pcaCoDa(arcticLake, method="classical", solve = "eigen")
biplot(res.cla)

## just for illustration how to set the mult_comp argument:
data(expenditures)
p1 &lt;- pcaCoDa(expenditures, mult_comp=list(c(1,2,3),c(4,5)))
p1

## example with external variables:
data(election)
# transform external variables
election$unemployment &lt;- log((election$unemployment/100)/(1-election$unemployment/100))
election$income &lt;- scale(election$income)

res &lt;- pcaCoDa(election[,1:6], method="classical", external=election[,7:8])
res
biplot(res, scale=0)
</code></pre>

<hr>
<h2 id='perturbation'>Perturbation and powering</h2><span id='topic+perturbation'></span><span id='topic+powering'></span>

<h3>Description</h3>

<p>Perturbation and powering for two compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturbation(x, y)

powering(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perturbation_+3A_x">x</code></td>
<td>
<p>(compositional) vector containing positive values</p>
</td></tr>
<tr><td><code id="perturbation_+3A_y">y</code></td>
<td>
<p>(compositional) vector containing positive values or NULL for powering</p>
</td></tr>
<tr><td><code id="perturbation_+3A_a">a</code></td>
<td>
<p>constant, numeric vector of length 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Result of perturbation or powering
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
x &lt;- expenditures[1 ,]
y &lt;- expenditures[2, ]
perturbation(x, y)
powering(x, 2)
</code></pre>

<hr>
<h2 id='pfa'>Factor analysis for compositional data</h2><span id='topic+pfa'></span>

<h3>Description</h3>

<p>Computes the principal factor analysis of the input data which are
transformed and centered first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pfa(
  x,
  factors,
  robust = TRUE,
  data = NULL,
  covmat = NULL,
  n.obs = NA,
  subset,
  na.action,
  start = NULL,
  scores = c("none", "regression", "Bartlett"),
  rotation = "varimax",
  maxiter = 5,
  control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pfa_+3A_x">x</code></td>
<td>
<p>(robustly) scaled input data</p>
</td></tr>
<tr><td><code id="pfa_+3A_factors">factors</code></td>
<td>
<p>number of factors</p>
</td></tr>
<tr><td><code id="pfa_+3A_robust">robust</code></td>
<td>
<p>default value is TRUE</p>
</td></tr>
<tr><td><code id="pfa_+3A_data">data</code></td>
<td>
<p>default value is NULL</p>
</td></tr>
<tr><td><code id="pfa_+3A_covmat">covmat</code></td>
<td>
<p>(robustly) computed covariance or correlation matrix</p>
</td></tr>
<tr><td><code id="pfa_+3A_n.obs">n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="pfa_+3A_subset">subset</code></td>
<td>
<p>if a subset is used</p>
</td></tr>
<tr><td><code id="pfa_+3A_na.action">na.action</code></td>
<td>
<p>what to do with NA values</p>
</td></tr>
<tr><td><code id="pfa_+3A_start">start</code></td>
<td>
<p>starting values</p>
</td></tr>
<tr><td><code id="pfa_+3A_scores">scores</code></td>
<td>
<p>which method should be used to calculate the scores</p>
</td></tr>
<tr><td><code id="pfa_+3A_rotation">rotation</code></td>
<td>
<p>if a rotation should be made</p>
</td></tr>
<tr><td><code id="pfa_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="pfa_+3A_control">control</code></td>
<td>
<p>default value is NULL</p>
</td></tr>
<tr><td><code id="pfa_+3A_...">...</code></td>
<td>
<p>arguments for creating a list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main difference to usual implementations is that uniquenesses are nor
longer of diagonal form. This kind of factor analysis is designed for
centered log-ratio transformed compositional data. However, if the
covariance is not specified, the covariance is estimated from isometric
log-ratio transformed data internally, but the data used for factor analysis
are backtransformed to the clr space (see Filzmoser et al., 2009).
</p>


<h3>Value</h3>

<table>
<tr><td><code>loadings</code></td>
<td>
<p>A matrix of loadings, one column for each factor.
The factors are ordered in decreasing order of sums of squares of loadings.</p>
</td></tr>
<tr><td><code>uniqueness</code></td>
<td>
<p>uniqueness</p>
</td></tr> <tr><td><code>correlation</code></td>
<td>
<p>correlation matrix</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>The results of the optimization: the value of the negativ
log-likelihood and information of the iterations used.</p>
</td></tr> <tr><td><code>factors</code></td>
<td>
<p>the
factors </p>
</td></tr> <tr><td><code>dof</code></td>
<td>
<p>degrees of freedom</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>&ldquo;principal&rdquo;</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations if available, or NA</p>
</td></tr> <tr><td><code>call</code></td>
<td>
<p>The
matched call.</p>
</td></tr> <tr><td><code>STATISTIC</code>, <code>PVAL</code></td>
<td>
<p>The significance-test statistic and
p-value, if they can be computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Karel Hron, Matthias Templ
</p>


<h3>References</h3>

<p>C. Reimann, P. Filzmoser, R.G. Garrett, and R. Dutter (2008):
Statistical Data Analysis Explained.  <em>Applied Environmental Statistics
with R</em>.  John Wiley and Sons, Chichester, 2008.
</p>
<p>P. Filzmoser, K. Hron, C. Reimann, R. Garrett (2009): Robust Factor Analysis
for Compositional Data.  <em>Computers and Geosciences</em>, <b>35</b> (9),
1854&ndash;1861.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
x &lt;- expenditures
res.rob &lt;- pfa(x, factors=1)
res.cla &lt;- pfa(x, factors=1, robust=FALSE)


## the following produce always the same result:
res1 &lt;- pfa(x, factors=1, covmat="covMcd")
res2 &lt;- pfa(x, factors=1, covmat=robustbase::covMcd(pivotCoord(x))$cov)
res3 &lt;- pfa(x, factors=1, covmat=robustbase::covMcd(pivotCoord(x)))

</code></pre>

<hr>
<h2 id='phd'>PhD students in the EU</h2><span id='topic+phd'></span>

<h3>Description</h3>

<p>PhD students in Europe based on the standard classification system splitted
by different kind of studies (given as percentages).
</p>


<h3>Format</h3>

<p>A data set on 32 compositions and 11 variables.
</p>


<h3>Details</h3>

<p>Due to unknown reasons the rowSums of the percentages is not always 100.
</p>

<ul>
<li><p><code>country </code>country of origin (German)  
</p>
</li>
<li><p><code>countryEN </code>country of origin (English)    
</p>
</li>
<li><p><code>country2 </code>country of origin, 2-digits   
</p>
</li>
<li><p><code>total </code>total phd students (in 1.000)              
</p>
</li>
<li><p><code>male </code>male phd students (in 1.000)                   
</p>
</li>
<li><p><code>female </code>total phd students (in 1.000)               
</p>
</li>
<li><p><code>technical </code>phd students in natural and technical sciences
</p>
</li>
<li><p><code>socio-economic-low </code>phd students in social sciences, economic sciences and law sciences                    
</p>
</li>
<li><p><code>human </code>phd students in human sciences including teaching
</p>
</li>
<li><p><code>health </code>phd students in health and life sciences               
</p>
</li>
<li><p><code>agriculture </code>phd students in agriculture 
</p>
</li></ul>



<h3>Source</h3>

<p>Eurostat
</p>


<h3>References</h3>

<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of missing values for compositional data using classical and robust methods. <em>Computational Statistics and Data Analysis</em>, vol 54 (12), pages 3095-3107.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(phd)
str(phd)

</code></pre>

<hr>
<h2 id='phd_totals'>PhD students in the EU (totals)</h2><span id='topic+phd_totals'></span>

<h3>Description</h3>

<p>PhD students in Europe by different kind of studies.
</p>


<h3>Format</h3>

<p>A data set on 29 compositions and 5 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>technical </code>phd students in natural and technical sciences
</p>
</li>
<li><p><code>socio-economic-low </code>phd students in social sciences, economic sciences and law sciences                    
</p>
</li>
<li><p><code>human </code>phd students in human sciences including teaching
</p>
</li>
<li><p><code>health </code>phd students in health and life sciences               
</p>
</li>
<li><p><code>agriculture </code>phd students in agriculture 
</p>
</li></ul>



<h3>Source</h3>

<p>Eurostat
</p>


<h3>References</h3>

<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of missing values for compositional data using classical and robust methods. <em>Computational Statistics and Data Analysis</em>, vol 54 (12), pages 3095-3107.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("phd_totals")
str(phd_totals)

</code></pre>

<hr>
<h2 id='pivotCoord'>Pivot coordinates and their inverse</h2><span id='topic+pivotCoord'></span><span id='topic+isomLR'></span><span id='topic+isomLRinv'></span><span id='topic+isomLRp'></span><span id='topic+isomLRinvp'></span><span id='topic+pivotCoordInv'></span>

<h3>Description</h3>

<p>Pivot coordinates as a special case of isometric logratio coordinates and their inverse mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pivotCoord(
  x,
  pivotvar = 1,
  fast = FALSE,
  method = "pivot",
  base = exp(1),
  norm = "orthonormal"
)

isomLR(x, fast = FALSE, base = exp(1), norm = "sqrt((D-i)/(D-i+1))")

isomLRinv(x)

pivotCoordInv(x, norm = "orthonormal")

isomLRp(x, fast = FALSE, base = exp(1), norm = "sqrt((D-i)/(D-i+1))")

isomLRinvp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pivotCoord_+3A_x">x</code></td>
<td>
<p>object of class data.frame or matrix. Positive values only.</p>
</td></tr>
<tr><td><code id="pivotCoord_+3A_pivotvar">pivotvar</code></td>
<td>
<p>pivotal variable. If any other number than 1, the data are resorted in 
that sense that the pivotvar is shifted to the first part.</p>
</td></tr>
<tr><td><code id="pivotCoord_+3A_fast">fast</code></td>
<td>
<p>if TRUE, it is approx. 10 times faster but numerical problems in case of 
high-dimensional data may occur. Only available for method &ldquo;pivot&rdquo;.</p>
</td></tr>
<tr><td><code id="pivotCoord_+3A_method">method</code></td>
<td>
<p>pivot takes the method described in the description. Method &quot;symm&quot; 
uses symmetric pivot coordinates (parameters pivotvar and norm have then no effect)</p>
</td></tr>
<tr><td><code id="pivotCoord_+3A_base">base</code></td>
<td>
<p>a positive or complex number: 
the base with respect to which logarithms are computed. Defaults to <code>exp(1)</code>.</p>
</td></tr>
<tr><td><code id="pivotCoord_+3A_norm">norm</code></td>
<td>
<p>if FALSE then the normalizing constant is not used, if TRUE <code>sqrt((D-i)/(D-i+1))</code> is 
used (default). The user can also specify a self-defined constant.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pivot coordinates map D-part compositional data from the simplex
into a (D-1)-dimensional real space isometrically. From our choice of pivot
coordinates, all the relative information about one of parts (or about two parts) is aggregated in the first coordinate
(or in the first two coordinates in case of symmetric pivot coordinates, respectively).
</p>


<h3>Value</h3>

<p>The data represented in pivot coordinates
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Karel Hron, Peter Filzmoser
</p>


<h3>References</h3>

<p>Egozcue J.J., Pawlowsky-Glahn, V., Mateu-Figueras, G.,
Barcel'o-Vidal, C. (2003) Isometric logratio transformations for compositional
data analysis. <em>Mathematical Geology</em>, <b>35</b>(3) 279-300. 
</p>
<p>Filzmoser, P., Hron, K., Templ, M. (2018) <em>Applied Compositional Data Analysis</em>.
Springer, Cham.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(MASS)
Sigma &lt;- matrix(c(5.05,4.95,4.95,5.05), ncol=2, byrow=TRUE)
z &lt;- pivotCoordInv(mvrnorm(100, mu=c(0,2), Sigma=Sigma))

data(expenditures)
## first variable as pivot variable
pivotCoord(expenditures)
## third variable as pivot variable
pivotCoord(expenditures, 3) 

x &lt;- exp(mvrnorm(2000, mu=rep(1,10), diag(10)))
system.time(pivotCoord(x))
system.time(pivotCoord(x, fast=TRUE))

## without normalizing constant
pivotCoord(expenditures, norm = "orthogonal") # or:
pivotCoord(expenditures, norm = "1")
## other normalization
pivotCoord(expenditures, norm = "-sqrt((D-i)/(D-i+1))")

# symmetric balances (results in 2-dim symmetric pivot coordinates)
pivotCoord(expenditures, method = "symm")
</code></pre>

<hr>
<h2 id='plot.imp'>Plot method for objects of class imp</h2><span id='topic+plot.imp'></span>

<h3>Description</h3>

<p>This function provides several diagnostic plots for the imputed data set in
order to see how the imputated values are distributed in comparison with the
original data values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imp'
plot(
  x,
  ...,
  which = 1,
  ord = 1:ncol(x),
  colcomb = "missnonmiss",
  plotvars = NULL,
  col = c("skyblue", "red"),
  alpha = NULL,
  lty = par("lty"),
  xaxt = "s",
  xaxlabels = NULL,
  las = 3,
  interactive = TRUE,
  pch = c(1, 3),
  ask = prod(par("mfcol")) &lt; length(which) &amp;&amp; dev.interactive(),
  center = FALSE,
  scale = FALSE,
  id = FALSE,
  seg.l = 0.02,
  seg1 = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.imp_+3A_x">x</code></td>
<td>
<p>object of class &lsquo;imp&rsquo;</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_which">which</code></td>
<td>
<p>if a subset of the plots is required, specify a subset of the
numbers 1:3.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_ord">ord</code></td>
<td>
<p>determines the ordering of the variables</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_colcomb">colcomb</code></td>
<td>
<p>if colcomb<code class="reqn">=</code>&ldquo;missnonmiss&rdquo;, observations with
missings in any variable are highlighted. Otherwise, observations with
missings in any of the variables specified by colcomb are highlighted in the
parallel coordinate plot.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_plotvars">plotvars</code></td>
<td>
<p>Parameter for the parallel coordinate plot. A vector giving
the variables to be plotted.  If NULL (the default), all variables are
plotted.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_col">col</code></td>
<td>
<p>a vector of length two giving the colors to be used in the plot.
The second color will be used for highlighting.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value between 0 and 1 giving the level of
transparency of the colors, or NULL. This can be used to prevent
overplotting.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_lty">lty</code></td>
<td>
<p>a vector of length two giving the line types.  The second line
type will be used for the highlighted observations.  If a single value is
supplied, it will be used for both non-highlighted and highlighted
observations.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_xaxt">xaxt</code></td>
<td>
<p>the x-axis type (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_xaxlabels">xaxlabels</code></td>
<td>
<p>a character vector containing the labels for the x-axis.
If NULL, the column names of x will be used.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_las">las</code></td>
<td>
<p>the style of axis labels (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_interactive">interactive</code></td>
<td>
<p>a logical indicating whether the variables to be used for
highlighting can be selected interactively (see &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_pch">pch</code></td>
<td>
<p>a vector of length two giving the symbol of the plotting points.
The symbol will be used for the highlighted observations.  If a single value
is supplied, it will be used for both non-highlighted and highlighted
observations.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_ask">ask</code></td>
<td>
<p>logical; if TRUE, the user is asked before each plot, see
<code><a href="graphics.html#topic+par">par</a></code>(ask=.).</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_center">center</code></td>
<td>
<p>logical, indicates if the data should be centered prior
plotting the ternary plot.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_scale">scale</code></td>
<td>
<p>logical, indicates if the data should be centered prior
plotting the ternary plot.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_id">id</code></td>
<td>
<p>reads the position of the graphics pointer when the (first) mouse
button is pressed and returns the corresponding index of the observation.
(only used by the ternary plot)</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_seg.l">seg.l</code></td>
<td>
<p>length of the plotting symbol (spikes) for the ternary plot.</p>
</td></tr>
<tr><td><code id="plot.imp_+3A_seg1">seg1</code></td>
<td>
<p>if TRUE, the spikes of the plotting symbol are justified.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first plot (which <code class="reqn">== 1</code>) is a multiple scatterplot where for the
imputed values another plot symbol and color is used in order to highlight
them. Currently, the ggpairs functions from the GGally package is used.
</p>
<p>Plot 2 is a parallel coordinate plot in which imputed values in certain
variables are highlighted.  In parallel coordinate plots, the variables are
represented by parallel axes.  Each observation of the scaled data is shown
as a line.  If interactive is TRUE, the variables to be used for
highlighting can be selected interactively. Observations which includes
imputed values in any of the selected variables will be highlighted.  A
variable can be added to the selection by clicking on a coordinate axis.  If
a variable is already selected, clicking on its coordinate axis will remove
it from the selection. Clicking anywhere outside the plot region quits the
interactive session.
</p>
<p>Plot 3 shows a ternary diagram in which imputed values are highlighted, i.e.
those spikes of the chosen plotting symbol are colored in red for which of
the values are missing in the unimputed data set.
</p>


<h3>Value</h3>

<p>None (invisible NULL).
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>
<p>Wegman, E. J. (1990) <em>Hyperdimensional data analysis using parallel
coordinates</em> Journal of the American Statistical Association 85, 664&ndash;675.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>, <code><a href="#topic+impKNNa">impKNNa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
expenditures[1,3]
expenditures[1,3] &lt;- NA
xi &lt;- impKNNa(expenditures)
xi
summary(xi)
## Not run: plot(xi, which=1)
plot(xi, which=2)
plot(xi, which=3)
plot(xi, which=3, seg1=FALSE)

</code></pre>

<hr>
<h2 id='plot.pcaCoDa'>Plot method</h2><span id='topic+plot.pcaCoDa'></span>

<h3>Description</h3>

<p>Provides a screeplot and biplot for (robust) compositional principal components analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcaCoDa'
plot(x, y, ..., which = 1, choices = 1:2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pcaCoDa_+3A_x">x</code></td>
<td>
<p>object of class &lsquo;pcaCoDa&rsquo;</p>
</td></tr>
<tr><td><code id="plot.pcaCoDa_+3A_y">y</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="plot.pcaCoDa_+3A_...">...</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="plot.pcaCoDa_+3A_which">which</code></td>
<td>
<p>an integer between 1 and 3. Produces a screeplot (1), or a biplot using stats biplot.prcomp function (2), or a biplot using ggfortify's autoplot function (3).</p>
</td></tr>
<tr><td><code id="plot.pcaCoDa_+3A_choices">choices</code></td>
<td>
<p>principal components to plot by number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The robust compositional screeplot.
</p>


<h3>Author(s)</h3>

<p>M. Templ, K. Hron
</p>


<h3>References</h3>

<p>Filzmoser, P., Hron, K., Reimann, C. (2009) Principal Component Analysis for
Compositional Data with Outliers. <em>Environmetrics</em>, <b>20</b> (6),
621&ndash;632.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcaCoDa">pcaCoDa</a></code>, <code><a href="#topic+biplot.pcaCoDa">biplot.pcaCoDa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
## Not run: 
p1 &lt;- pcaCoDa(coffee[,-1])
plot(p1)
plot(p1, type="lines")
plot(p1, which = 2)
plot(p1, which = 3)

## End(Not run)


</code></pre>

<hr>
<h2 id='plot.smoothSpl'>plot smoothSpl</h2><span id='topic+plot.smoothSpl'></span>

<h3>Description</h3>

<p>plot densities of objects of class smoothSpl
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smoothSpl'
plot(x, y, ..., by = 1, n = 10, index = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.smoothSpl_+3A_x">x</code></td>
<td>
<p>class smoothSpl object</p>
</td></tr>
<tr><td><code id="plot.smoothSpl_+3A_y">y</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="plot.smoothSpl_+3A_...">...</code></td>
<td>
<p>further arguments passed by</p>
</td></tr>
<tr><td><code id="plot.smoothSpl_+3A_by">by</code></td>
<td>
<p>stepsize</p>
</td></tr>
<tr><td><code id="plot.smoothSpl_+3A_n">n</code></td>
<td>
<p>length of sequence to plot</p>
</td></tr>
<tr><td><code id="plot.smoothSpl_+3A_index">index</code></td>
<td>
<p>optinally the sequence instead of by and n</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alessia Di Blasi, Federico Pavone, Gianluca Zeni
</p>

<hr>
<h2 id='precipitation'>24-hour precipitation</h2><span id='topic+precipitation'></span>

<h3>Description</h3>

<p>table containing counts for 24-hour precipitation for season at the rain-gouge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(precipitation)
</code></pre>


<h3>Format</h3>

<p>A table with 4 rows and 6 columns
</p>


<h3>Details</h3>


<ul>
<li><p><code>spring</code>numeric vector on counts for different level of precipitation
</p>
</li>
<li><p><code>summer</code>numeric vector on counts for different level of precipitation
</p>
</li>
<li><p><code>autumn</code>numeric vector on counts for different level of precipitation
</p>
</li>
<li><p><code>winter</code>numeric vector on counts for different level of precipitation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Romero R, Guijarro J A, Ramis C, Alonso S (1998). A 30-years (196493) daily rainfall
data base for the Spanish Mediterranean regions: first exploratory study. 
<em>International Journal of Climatology</em> 18, 541560.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation)
precipitation
str(precipitation)
</code></pre>

<hr>
<h2 id='print.imp'>Print method for objects of class imp</h2><span id='topic+print.imp'></span>

<h3>Description</h3>

<p>The function returns a few information about how many missing values are
imputed and possible other information about the amount of iterations, for
example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imp'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.imp_+3A_x">x</code></td>
<td>
<p>an object of class &lsquo;imp&rsquo;</p>
</td></tr>
<tr><td><code id="print.imp_+3A_...">...</code></td>
<td>
<p>additional arguments passed trough</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None (invisible NULL).
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>, <code><a href="#topic+impKNNa">impKNNa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
expenditures[1,3]
expenditures[1,3] &lt;- NA
## Not run: 
xi &lt;- impCoda(expenditures)
xi
summary(xi)
plot(xi, which=1:2)

## End(Not run)

</code></pre>

<hr>
<h2 id='production'>production splitted by nationality on enterprise level</h2><span id='topic+production'></span>

<h3>Description</h3>


<ul>
<li><p><code>nace </code>NACE classification, 2 digits
</p>
</li>
<li><p><code>oenace_2008 </code>Corresponding Austrian NACE classification (in German)
</p>
</li>
<li><p><code>year </code>year
</p>
</li>
<li><p><code>month </code>month
</p>
</li>
<li><p><code>enterprise </code>enterprise ID
</p>
</li>
<li><p><code>total </code>total ...
</p>
</li>
<li><p><code>home </code>home ...
</p>
</li>
<li><p><code>EU </code>EU ...
</p>
</li>
<li><p><code>non-EU </code>non-EU ...
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(production)
</code></pre>


<h3>Format</h3>

<p>A data frame with 535 rows and 9 variables
</p>


<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>Source</h3>

<p>statCube data base at the website of Statistics Austria. The product and all 
material contained therein are protected by copyright with all rights 
reserved by the Bundesanstalt Statistik Oesterreich (STATISTICS AUSTRIA). 
It is permitted to reproduce, distribute, make publicly available 
and process the content for non-commercial purposes. Prior to any use for 
commercial purposes a written consent of STATISTICS AUSTRIA must be obtained. 
Any use of the contained material must 
be correctly reproduced and clearly cite the source STATISTICS AUSTRIA. 
If tables published by STATISTICS AUSTRIA are partially used, displayed or 
otherwise changed, a note must be added at an adequate position to 
show data was extracted or adapted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(production)
str(production)
summary(production)
</code></pre>

<hr>
<h2 id='pTab'>Propability table</h2><span id='topic+pTab'></span>

<h3>Description</h3>

<p>Calculates the propability table using different methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pTab(x, method = "dirichlet", alpha = 1/length(as.numeric(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pTab_+3A_x">x</code></td>
<td>
<p>an object of class table</p>
</td></tr>
<tr><td><code id="pTab_+3A_method">method</code></td>
<td>
<p>default is &lsquo;dirichlet&rsquo;. Other available methods: 
&lsquo;classical&rsquo; that is function <code>prop.table()</code> from package base or method &ldquo;half&rdquo; that add 1/2 to each cell
to avoid zero problems.</p>
</td></tr>
<tr><td><code id="pTab_+3A_alpha">alpha</code></td>
<td>
<p>constant used for method &lsquo;dirichlet&rsquo;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The probablity table
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
pTab(precipitation)
pTab(precipitation, method = "dirichlet")
</code></pre>

<hr>
<h2 id='rcodes'>codes for UNIDO tables</h2><span id='topic+rcodes'></span>

<h3>Description</h3>


<ul>
<li><p><code>ISOCN</code>ISOCN codes
</p>
</li>
<li><p><code>OPERATOR</code>Operator
</p>
</li>
<li><p><code>ADESC</code>Country
</p>
</li>
<li><p><code>CCODE</code>Country code
</p>
</li>
<li><p><code>CDESC</code>Country destination
</p>
</li>
<li><p><code>ACODE</code>Country destination code
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(rcodes)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 2717 rows and 6 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(rcodes)
str(rcodes)
</code></pre>

<hr>
<h2 id='rdcm'>relative difference between covariance matrices</h2><span id='topic+rdcm'></span>

<h3>Description</h3>

<p>The sample covariance matrices are computed from compositions expressed in the same isometric logratio coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdcm(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdcm_+3A_x">x</code></td>
<td>
<p>matrix or data frame</p>
</td></tr>
<tr><td><code id="rdcm_+3A_y">y</code></td>
<td>
<p>matrix or data frame of the same size as x.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The difference in covariance structure is based on the Euclidean distance between both covariance estimations.
</p>


<h3>Value</h3>

<p>the error measures value
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Hron, K. and Templ, M. and Filzmoser, P. (2010) Imputation of
missing values for compositional data using classical and robust methods
<em>Computational Statistics and Data Analysis</em>, 54 (12),
3095-3107.
</p>
<p>Templ, M. and Hron, K. and Filzmoser and Gardlo, A. (2016). 
Imputation of rounded zeros for high-dimensional compositional data. 
<em>Chemometrics and Intelligent Laboratory Systems</em>, 155, 183-190.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdcm">rdcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(expenditures)
x &lt;- expenditures
x[1,3] &lt;- NA
xi &lt;- impKNNa(x)$xImp
rdcm(expenditures, xi)
</code></pre>

<hr>
<h2 id='rSDev'>Relative simplicial deviance</h2><span id='topic+rSDev'></span>

<h3>Description</h3>

<p>Relative simplicial deviance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rSDev(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rSDev_+3A_x">x</code></td>
<td>
<p>a propability table</p>
</td></tr>
<tr><td><code id="rSDev_+3A_y">y</code></td>
<td>
<p>an interaction table</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The relative simplicial deviance
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
tabprob &lt;- prop.table(precipitation)
tabind &lt;- indTab(precipitation)
tabint &lt;- intTab(tabprob, tabind)
rSDev(tabprob, tabint$intTab)
</code></pre>

<hr>
<h2 id='rSDev.test'>Relative simplicial deviance tests</h2><span id='topic+rSDev.test'></span>

<h3>Description</h3>

<p>Monte Carlo based contingency table tests considering the compositional approach to contingency tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rSDev.test(x, R = 999, method = "multinom")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rSDev.test_+3A_x">x</code></td>
<td>
<p>matrix, data.frame or table</p>
</td></tr>
<tr><td><code id="rSDev.test_+3A_r">R</code></td>
<td>
<p>an integer specifying the number of replicates used in the Monte Carlo test.</p>
</td></tr>
<tr><td><code id="rSDev.test_+3A_method">method</code></td>
<td>
<p>either &ldquo;rmultinom&rdquo; (default) or &ldquo;permutation&rdquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method &ldquo;rmultinom&rdquo; generate multinomially distributed samples  
from the independent probability table, which is estimated from <code>x</code> using geometric mean marginals. 
The relative simplicial deviance of the original data are then compared to the generated ones.
</p>
<p>Method &ldquo;permutation&rdquo; permutes the entries of <code>x</code> and compares the relative simplicial deviance estimated from
the original data to the ones of the permuted data (the independence table is unchanged and originates on <code>x</code>). 
</p>
<p>Method &ldquo;rmultinom&rdquo; should be preferred, while method &ldquo;permutation&rdquo; can be used for comparisons.
</p>


<h3>Value</h3>

<p>A list with class  &ldquo;htest&rdquo; containing the following components:
</p>

<ul>
<li><p>statisticthe value of the relative simplicial deviance (test statistic).
</p>
</li>
<li><p>methoda character string indicating what type of rSDev.test was performed.
</p>
</li>
<li><p>p.valuethe p-value for the test.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ, Karel Hron
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rSDev">rSDev</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation)
rSDev.test(precipitation)
</code></pre>

<hr>
<h2 id='saffron'>saffron compositions</h2><span id='topic+saffron'></span>

<h3>Description</h3>

<p>Stable isotope ratio  and trace metal cncentration data for saffron samples.
</p>


<h3>Format</h3>

<p>A data frame with 53 observations on the following 36 variables.
</p>
 
<ul>
<li><p><code>Sample </code>adulterated honey, Honey or Syrup
</p>
</li>
<li><p><code>Country </code>group information
</p>
</li>
<li><p><code>Batch </code>detailed group information
</p>
</li>
<li><p><code>Region </code>less detailed group information
</p>
</li>
<li><p><code>d2H </code>region
</p>
</li>
<li><p><code>d13C </code>chemical element
</p>
</li>
<li><p><code>d15N </code>chemical element
</p>
</li>
<li><p><code>Li </code>chemical element 
</p>
</li>
<li><p><code>B </code>chemical element 
</p>
</li>
<li><p><code>Na </code>chemical element
</p>
</li>
<li><p><code>Mg </code>chemical element
</p>
</li>
<li><p><code>Al </code>chemical element 
</p>
</li>
<li><p><code>K</code>chemical element 
</p>
</li>
<li><p><code>Ca </code>chemical element 
</p>
</li>
<li><p><code>V </code>chemical element 
</p>
</li>
<li><p><code>Mn </code>chemical element 
</p>
</li>
<li><p><code>Fe </code>chemical element 
</p>
</li>
<li><p><code>Co </code>chemical element 
</p>
</li>
<li><p><code>Ni </code>chemical element 
</p>
</li>
<li><p><code>Cu </code>chemical element 
</p>
</li>
<li><p><code>Zn </code>chemical element 
</p>
</li>
<li><p><code>Ga </code>chemical element 
</p>
</li>
<li><p><code>As </code>chemical element 
</p>
</li>
<li><p><code>Rb </code>chemical element 
</p>
</li>
<li><p><code>Sr </code>chemical element 
</p>
</li>
<li><p><code>Y </code>chemical element 
</p>
</li>
<li><p><code>Mo </code>chemical element 
</p>
</li>
<li><p><code>Cd </code>chemical element 
</p>
</li>
<li><p><code>Cs </code>chemical element 
</p>
</li>
<li><p><code>Ba </code>chemical element 
</p>
</li>
<li><p><code>Ce </code>chemical element 
</p>
</li>
<li><p><code>Pr </code>chemical element 
</p>
</li>
<li><p><code>Nd </code>chemical element 
</p>
</li>
<li><p><code>Sm </code>chemical element 
</p>
</li>
<li><p><code>Gd </code>chemical element 
</p>
</li>
<li><p><code>Pb </code>chemical element 
</p>
</li></ul>



<h3>Note</h3>

<p>In the original paper, the authors applied lda for classifying the observations.
</p>


<h3>Source</h3>

<p>Mendeley Data, contributed by Russell Frew and translated to R by Matthias Templ
</p>


<h3>References</h3>

<p>Frew, Russell (2019), Data for: 
CHEMICAL PROFILING OF SAFFRON FOR AUTHENTICATION OF ORIGIN, Mendeley Data, V1, 
<a href="https://doi.org/10.17632/5544tn9v6c.1">doi:10.17632/5544tn9v6c.1</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(saffron)

</code></pre>

<hr>
<h2 id='SDev'>Simplicial deviance</h2><span id='topic+SDev'></span>

<h3>Description</h3>

<p>Simplicial deviance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SDev(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SDev_+3A_x">x</code></td>
<td>
<p>a propability table</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The simplicial deviance
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Juan Jose Egozcuea, Vera Pawlowsky-Glahn, Matthias Templ, Karel Hron (2015)
Independence in Contingency Tables Using Simplicial Geometry. 
<em>Communications in Statistics - Theory and Methods</em>, Vol. 44 (18), 3978&ndash;3996.
DOI:10.1080/03610926.2013.824980
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
tab1prob &lt;- prop.table(precipitation)
SDev(tab1prob)
</code></pre>

<hr>
<h2 id='skyeLavas'>aphyric skye lavas data</h2><span id='topic+skyeLavas'></span>

<h3>Description</h3>

<p>AFM compositions of 23 aphyric Skye lavas. This data set can be found on page 360 of the Aitchison book (see reference).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(skyeLavas)
</code></pre>


<h3>Format</h3>

<p>A data frame with 23 observations on the following 3 variables.
</p>


<h3>Details</h3>


<ul>
<li><p><code>sodium-potassium </code>a numeric vector of percentages of Na2O<code class="reqn">+</code>K2O
</p>
</li>
<li><p><code>iron </code>a numeric vector of percentages of Fe2O3
</p>
</li>
<li><p><code>magnesium </code>a numeric vector of percentages of MgO
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional Data</em> Monographs on Statistics and Applied Probability. Chapman and Hall Ltd., London (UK). 416p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(skyeLavas)
str(skyeLavas)
summary(skyeLavas)
rowSums(skyeLavas)
</code></pre>

<hr>
<h2 id='smoothSplines'>Estimate density from histogram</h2><span id='topic+smoothSplines'></span>

<h3>Description</h3>

<p>Given raw (discretized) distributional observations, <code>smoothSplines</code> computes the density
function that 'best' fits data, in a trade-off between smooth and least squares approximation, using B-spline basis functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothSplines(
  k,
  l,
  alpha,
  data,
  xcp,
  knots,
  weights = matrix(1, dim(data)[1], dim(data)[2]),
  num_points = 100,
  prior = "default",
  cores = 1,
  fast = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothSplines_+3A_k">k</code></td>
<td>
<p>smoothing splines degree</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_l">l</code></td>
<td>
<p>order of derivative in the penalization term</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_alpha">alpha</code></td>
<td>
<p>weight for penalization</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_data">data</code></td>
<td>
<p>an object of class &quot;matrix&quot; containing data to be smoothed, row by row</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_xcp">xcp</code></td>
<td>
<p>vector of control points</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_knots">knots</code></td>
<td>
<p>either vector of knots for the splines or a integer for the number of equispaced knots</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_weights">weights</code></td>
<td>
<p>matrix of weights. If not given, all data points will be weighted the same.</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_num_points">num_points</code></td>
<td>
<p>number of points of the grid where to evaluate the density estimated</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_prior">prior</code></td>
<td>
<p>prior used for zero-replacements. This must be one of &quot;perks&quot;, &quot;jeffreys&quot;, &quot;bayes_laplace&quot;, &quot;sq&quot; or &quot;default&quot;</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel execution, if the option was enabled before installing the package</p>
</td></tr>
<tr><td><code id="smoothSplines_+3A_fast">fast</code></td>
<td>
<p>1 if maximal performance is required (print statements suppressed), 0 otherwise</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original discretized densities are not directly smoothed, but instead the centred logratio transformation is
first applied, to deal with the unit integral constraint related to density functions. <br />
Then the constrained variational problem is set. This minimization problem for the optimal
density is a compromise between staying close to the given data, at the corresponding <code>xcp</code>,
and obtaining a smooth function.
The non-smoothness measure takes into account the <code>l</code>th derivative, while the fidelity term is weigthed by <code>alpha</code>. <br />
The solution is a natural spline. The vector of its coefficients is obtained by the minimum norm solution of a linear system.
The resulting splines can be either back-transformed to the original Bayes space of density
functions (in order to provide their smoothed counterparts for vizualization and interpretation
purposes), or retained for further statistical analysis in the clr space.
</p>


<h3>Value</h3>

<p>An object of class <code>smoothSpl</code>, containing among the other the following variables:
</p>
<table>
<tr><td><code>bspline</code></td>
<td>
<p>each row is the vector of B-spline coefficients</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the values of the smoothed curve, for the grid given</p>
</td></tr>
<tr><td><code>Y_clr</code></td>
<td>
<p>the values of the smoothed curve, in the clr setting, for the grid given</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alessia Di Blasi, Federico Pavone, Gianluca Zeni, Matthias Templ
</p>


<h3>References</h3>

<p>J. Machalova, K. Hron &amp; G.S. Monti (2016):
Preprocessing of centred logratio transformed density functions
using smoothing splines. Journal of Applied Statistics, 43:8, 1419-1435.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SepalLengthCm &lt;- iris$Sepal.Length
Species &lt;- iris$Species

iris1 &lt;- SepalLengthCm[iris$Species==levels(iris$Species)[1]]
h1 &lt;- hist(iris1, nclass = 12, plot = FALSE)

midx1 &lt;- h1$mids
midy1 &lt;- matrix(h1$density, nrow=1, ncol = length(h1$density), byrow=TRUE)
knots &lt;- 7
## Not run: 
sol1 &lt;- smoothSplines(k=3,l=2,alpha=1000,midy1,midx1,knots)
plot(sol1)

h1 &lt;- hist(iris1, freq = FALSE, nclass = 12, xlab = "Sepal Length     [cm]", main = "Iris setosa")
# black line: kernel method; red line: smoothSplines result
lines(density(iris1), col = "black", lwd = 1.5)
xx1 &lt;- seq(sol1$Xcp[1],tail(sol1$Xcp,n=1),length.out = sol1$NumPoints)
lines(xx1,sol1$Y[1,], col = 'red', lwd = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='smoothSplinesVal'>Estimate density from histogram - for different <code>alpha</code></h2><span id='topic+smoothSplinesVal'></span>

<h3>Description</h3>

<p>As <code><a href="#topic+smoothSplines">smoothSplines</a></code>, <code>smoothSplinesVal</code> computes the density function that 'best' fits
discretized distributional data, using B-spline basis functions, for different <code>alpha</code>. <br />
Comparing and choosing an appropriate <code>alpha</code> is the ultimate goal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothSplinesVal(
  k,
  l,
  alpha,
  data,
  xcp,
  knots,
  weights = matrix(1, dim(data)[1], dim(data)[2]),
  prior = "default",
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothSplinesVal_+3A_k">k</code></td>
<td>
<p>smoothing splines degree</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_l">l</code></td>
<td>
<p>order of derivative in the penalization term</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_alpha">alpha</code></td>
<td>
<p>vector of weights for penalization</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_data">data</code></td>
<td>
<p>an object of class &quot;matrix&quot; containing data to be smoothed, row by row</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_xcp">xcp</code></td>
<td>
<p>vector of control points</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_knots">knots</code></td>
<td>
<p>either vector of knots for the splines or a integer for the number of equispaced knots</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_weights">weights</code></td>
<td>
<p>matrix of weights. If not gives, all data points will be weighted the same.</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_prior">prior</code></td>
<td>
<p>prior used for zero-replacements. This must be one of &quot;perks&quot;, &quot;jeffreys&quot;, &quot;bayes_laplace&quot;, &quot;sq&quot; or &quot;default&quot;</p>
</td></tr>
<tr><td><code id="smoothSplinesVal_+3A_cores">cores</code></td>
<td>
<p>number of cores for parallel execution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+smoothSplines">smoothSplines</a></code> for the description of the algorithm.
</p>


<h3>Value</h3>

<p>A list of three objects:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>the values of <code>alpha</code></p>
</td></tr>
<tr><td><code>J</code></td>
<td>
<p>the values of the functional evaluated in the minimizing</p>
</td></tr>
<tr><td><code>CV-error</code></td>
<td>
<p>the values of the leave-one-out CV-error</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alessia Di Blasi, Federico Pavone, Gianluca Zeni, Matthias Templ
</p>


<h3>References</h3>

<p>J. Machalova, K. Hron &amp; G.S. Monti (2016):
Preprocessing of centred logratio transformed density functions
using smoothing splines. Journal of Applied Statistics, 43:8, 1419-1435.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SepalLengthCm &lt;- iris$Sepal.Length
Species &lt;- iris$Species

iris1 &lt;- SepalLengthCm[iris$Species==levels(iris$Species)[1]]
h1 &lt;- hist(iris1, nclass = 12, plot = FALSE)

## Not run: 
midx1 &lt;- h1$mids
midy1 &lt;- matrix(h1$density, nrow=1, ncol = length(h1$density), byrow=TRUE)
knots &lt;- 7
sol1 &lt;- smoothSplinesVal(k=3,l=2,alpha=10^seq(-4,4,by=1),midy1,midx1,knots,cores=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='socExp'>social expenditures</h2><span id='topic+socExp'></span>

<h3>Description</h3>

<p>Social expenditures according to source (public or private) 
and three important branches (health, old age, incapacity related) in 
selected OECD countries in 2010. Expenditures are always provided 
in the respective currency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(socExp)
</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 8 variables (country + currency + row-wise sorted cells of 2x3 compositional table).
</p>


<h3>Details</h3>


<ul>
<li><p><code>country </code>Country of origin
</p>
</li>
<li><p><code>currency </code>Currency unit (in Million)
</p>
</li>
<li><p><code>health-public </code>Health from the public
</p>
</li>
<li><p><code>old-public </code>Old age expenditures from the public
</p>
</li>
<li><p><code>incap-public </code>Incapacity related expenditures from the public
</p>
</li>
<li><p><code>health-private </code>Health from private sources
</p>
</li>
<li><p><code>old-private </code>Old age expenditures from private sources
</p>
</li>
<li><p><code>incap-private </code>Incapacity related expenditures from private sources
</p>
</li></ul>



<h3>Author(s)</h3>

<p>conversion to R by Karel Hron Karel Hron and modifications by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>OECD
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(socExp)
str(socExp)
rowSums(socExp[, 3:ncol(socExp)])
</code></pre>

<hr>
<h2 id='stats'>Classical estimates for tables</h2><span id='topic+stats'></span>

<h3>Description</h3>

<p>Some standard/classical (non-compositional) statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stats(
  x,
  margins = NULL,
  statistics = c("phi", "cramer", "chisq", "yates"),
  maggr = mean
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stats_+3A_x">x</code></td>
<td>
<p>a data.frame, matrix or table</p>
</td></tr>
<tr><td><code id="stats_+3A_margins">margins</code></td>
<td>
<p>margins</p>
</td></tr>
<tr><td><code id="stats_+3A_statistics">statistics</code></td>
<td>
<p>statistics of interest</p>
</td></tr>
<tr><td><code id="stats_+3A_maggr">maggr</code></td>
<td>
<p>a function for calculating the mean margins of a table, default is the arithmetic mean</p>
</td></tr>
</table>


<h3>Details</h3>

<p>statistics &lsquo;phi&rsquo; is the values of the table divided by the product of margins. &lsquo;cramer&rsquo; normalize these values according to the dimension of the table. &lsquo;chisq&rsquo; are the expected values according to Pearson while &lsquo;yates&rsquo; according to Yates.
</p>
<p>For the <code>maggr</code> function argument, arithmetic means (<code>mean</code>) should be chosen to obtain the classical results. Any other user-provided functions should be take with care since the classical estimations relies on the arithmetic mean.
</p>


<h3>Value</h3>

<p>List containing all statistics
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Egozcue, J.J., Pawlowsky-Glahn, V., Templ, M., Hron, K. (2015)
Independence in contingency tables using simplicial geometry. 
<em>Communications in Statistics - Theory and Methods</em>, 44 (18), 3978&ndash;3996.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(precipitation) 
tab1 &lt;- indTab(precipitation)
stats(precipitation)
stats(precipitation, statistics = "cramer")
stats(precipitation, statistics = "chisq")
stats(precipitation, statistics = "yates")

## take with care 
## (the provided statistics are not designed for that case):
stats(precipitation, statistics = "chisq", maggr = gmean)
</code></pre>

<hr>
<h2 id='summary.imp'>Summary method for objects of class imp</h2><span id='topic+summary.imp'></span>

<h3>Description</h3>

<p>A short comparison of the original data and the imputed data is given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imp'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.imp_+3A_object">object</code></td>
<td>
<p>an object of class &lsquo;imp&rsquo;</p>
</td></tr>
<tr><td><code id="summary.imp_+3A_...">...</code></td>
<td>
<p>additional arguments passed trough</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function will be enhanced with more sophisticated methods in
future versions of the package.  It is very rudimental in its present form.
</p>


<h3>Value</h3>

<p>None (invisible NULL).
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+impCoda">impCoda</a></code>, <code><a href="#topic+impKNNa">impKNNa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
expenditures[1,3]
expenditures[1,3] &lt;- NA
xi &lt;- impKNNa(expenditures)
xi
summary(xi)
# plot(xi, which=1:2)

</code></pre>

<hr>
<h2 id='tabCoord'>Coordinate representation of compositional tables and a sample of compositional tables</h2><span id='topic+tabCoord'></span><span id='topic+tabCoordWrapper'></span>

<h3>Description</h3>

<p>tabCoord computes a system of orthonormal coordinates of a compositional table. 
Computation of either pivot coordinates or a coordinate system based on the given SBP is possible.
</p>
<p>tabCoordWrapper: For each compositional table in the sample <code>tabCoordWrapper</code> 
computes a system of orthonormal coordinates and provide a simple descriptive analysis. 
Computation of either pivot coordinates or a coordinate system based on the given SBP is possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tabCoord(
  x = NULL,
  row.factor = NULL,
  col.factor = NULL,
  value = NULL,
  SBPr = NULL,
  SBPc = NULL,
  pivot = FALSE,
  print.res = FALSE
)

tabCoordWrapper(
  X,
  obs.ID = NULL,
  row.factor = NULL,
  col.factor = NULL,
  value = NULL,
  SBPr = NULL,
  SBPc = NULL,
  pivot = FALSE,
  test = FALSE,
  n.boot = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tabCoord_+3A_x">x</code></td>
<td>
<p>a data frame containing variables representing row and column factors of the respective compositional table and variable with the values of the composition.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_row.factor">row.factor</code></td>
<td>
<p>name of the variable representing the row factor. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_col.factor">col.factor</code></td>
<td>
<p>name of the variable representing the column factor. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_value">value</code></td>
<td>
<p>name of the variable representing the values of the composition. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_sbpr">SBPr</code></td>
<td>
<p>an <code class="reqn">I-1\times I</code> array defining the sequential binary partition of the values of the row factor, where I is the number of the row factor levels. The values assigned in the given step to the + group are marked by 1, values from  the - group by -1 and the rest by 0. If it is not provided, the pivot version of coordinates is constructed automatically.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_sbpc">SBPc</code></td>
<td>
<p>an <code class="reqn">J-1\times J</code> array defining the sequential binary partition of the values of the column factor, where J is the number of the column factor levels. The values assigned in the given step to the + group are marked by 1, values from  the - group by -1 and the rest by 0. If it is not provided, the pivot version of coordinates is constructed automatically.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_pivot">pivot</code></td>
<td>
<p>logical, default is FALSE. If TRUE, or one of the SBPs is not defined, its pivot version is used.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_print.res">print.res</code></td>
<td>
<p>logical, default is FALSE. If TRUE, the output is displayed in the Console.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_x">X</code></td>
<td>
<p>a data frame containing variables representing row and column factors of the respective compositional tables, variable with the values 
of the composition and variable distinguishing the observations.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_obs.id">obs.ID</code></td>
<td>
<p>name of the variable distinguishing the observations. Needs to be stated with the quotation marks.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_test">test</code></td>
<td>
<p>logical, default is <code>FALSE</code>. If <code>TRUE</code>, the bootstrap analysis of coordinates is provided.</p>
</td></tr>
<tr><td><code id="tabCoord_+3A_n.boot">n.boot</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>tabCoord
</p>
<p>This transformation moves the IJ-part compositional tables 
from the simplex into a (IJ-1)-dimensional real space isometrically 
with respect to its two-factorial nature. 
The coordinate system is formed by two types of coordinates - balances and log odds-ratios.
</p>
<p>tabCoordWrapper: Each of n IJ-part compositional tables from the sample is with 
respect to its two-factorial nature isometrically transformed from the simplex 
into a (IJ-1)-dimensional real space. Sample mean values and standard deviations are 
computed and using bootstrap an estimate of 95 % confidence interval is given.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Coordinates</code></td>
<td>
<p>an array of orthonormal coordinates.</p>
</td></tr>
<tr><td><code>Grap.rep</code></td>
<td>
<p>graphical representation of the coordinates. Parts denoted by <code style="white-space: pre;">&#8288;+&#8288;</code> form the groups in the numerator of the respective computational formula, parts <code style="white-space: pre;">&#8288;-&#8288;</code> form the denominator and parts <code style="white-space: pre;">&#8288;.&#8288;</code> are not involved in the given coordinate.</p>
</td></tr>
<tr><td><code>Ind.coord</code></td>
<td>
<p>an array of row and column balances. Coordinate representation of the independent part of the table.</p>
</td></tr>
<tr><td><code>Int.coord</code></td>
<td>
<p>an array of OR coordinates. Coordinate representation of the interactive part of the table.</p>
</td></tr>
<tr><td><code>Contrast.matrix</code></td>
<td>
<p>contrast matrix.</p>
</td></tr>
<tr><td><code>Log.ratios</code></td>
<td>
<p>an array of pure log-ratios between groups of parts without the normalizing constant.</p>
</td></tr>
<tr><td><code>Coda.table</code></td>
<td>
<p>table form of the given composition.</p>
</td></tr>
<tr><td><code>Bootstrap</code></td>
<td>
<p>array of sample means, standard deviations and bootstrap confidence intervals.</p>
</td></tr>
<tr><td><code>Tables</code></td>
<td>
<p>Table form of the given compositions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kamila Facevicova
</p>


<h3>References</h3>

<p>Facevicova, K., Hron, K., Todorov, V. and M. Templ (2018) 
General approach to coordinate representation of compositional tables. 
Scandinavian Journal of Statistics, 45(4), 879&ndash;899.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cubeCoord">cubeCoord</a></code> 
<code><a href="#topic+cubeCoordWrapper">cubeCoordWrapper</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################
### Coordinate representation of a CoDa Table

# example from Fa\v cevicov\'a (2018):
data(manu_abs)
manu_USA &lt;- manu_abs[which(manu_abs$country=='USA'),]
manu_USA$output &lt;- factor(manu_USA$output, levels=c('LAB', 'SUR', 'INP'))

# pivot coordinates
tabCoord(manu_USA, row.factor = 'output', col.factor = 'isic', value='value')

# SBPs defined in paper
r &lt;- rbind(c(-1,-1,1), c(-1,1,0))
c &lt;- rbind(c(-1,-1,-1,-1,1), c(-1,-1,-1,1,0), c(-1,-1,1,0,0), c(-1,1,0,0,0))
tabCoord(manu_USA, row.factor = 'output', col.factor = 'isic', value='value', SBPr=r, SBPc=c)

###################
### Analysis of a sample of CoDa Tables

# example from Fa\v cevicov\'a (2018):
data(manu_abs)

### Compositional tables approach,
### analysis of the relative structure.
### An example from Facevi\v cov\'a (2018)

manu_abs$output &lt;- factor(manu_abs$output, levels=c('LAB', 'SUR', 'INP'))

# pivot coordinates
tabCoordWrapper(manu_abs, obs.ID='country',
row.factor = 'output', col.factor = 'isic', value='value')

# SBPs defined in paper
r &lt;- rbind(c(-1,-1,1), c(-1,1,0))
c &lt;- rbind(c(-1,-1,-1,-1,1), c(-1,-1,-1,1,0), 
c(-1,-1,1,0,0), c(-1,1,0,0,0))
tabCoordWrapper(manu_abs, obs.ID='country',row.factor = 'output', 
col.factor = 'isic', value='value', SBPr=r, SBPc=c, test=TRUE)

### Classical approach,
### generalized linear mixed effect model.

## Not run: 
library(lme4)
glmer(value~output*as.factor(isic)+(1|country),data=manu_abs,family=poisson)

## End(Not run)
</code></pre>

<hr>
<h2 id='teachingStuff'>teaching stuff</h2><span id='topic+teachingStuff'></span>

<h3>Description</h3>

<p>Teaching stuff in selected countries
</p>


<h3>Format</h3>

<p>A (tidy) data frame with 1216 observations on the following 4 variables.
</p>
 
<ul>
<li><p><code>country </code>Country of origin
</p>
</li>
<li><p><code>subject </code>school type: primary, lower secondary, higher secondary and tertiary  
</p>
</li>
<li><p><code>year </code>Year 
</p>
</li>
<li><p><code>value </code>Number of stuff
</p>
</li></ul>



<h3>Details</h3>

<p>Teaching staff include professional personnel directly 
involved in teaching students, including classroom 
teachers, special education teachers and other 
teachers who work with students as a whole class, 
in small groups, or in one-to-one teaching. 
Teaching staff also include department chairs 
of whose duties include some teaching, but 
it does not include non-professional personnel 
who support teachers in providing instruction 
to students, such as teachers' aides and other 
paraprofessional personnel. Academic staff include 
personnel whose primary assignment is instruction, 
research or public service, holding an academic 
rank with such titles as professor, associate 
professor, assistant professor, instructor, 
lecturer, or the equivalent of any of these 
academic ranks. The category includes personnel 
with other titles (e.g. dean, director, associate 
dean, assistant dean, chair or head of department), 
if their principal activity is instruction or research.
</p>


<h3>Author(s)</h3>

<p>translated from <a href="https://data.oecd.org/">https://data.oecd.org/</a> and restructured by Matthias Templ
</p>


<h3>Source</h3>

<p>OECD:
<a href="https://data.oecd.org/">https://data.oecd.org/</a>
</p>


<h3>References</h3>

<p>OECD (2017), Teaching staff (indicator). doi: 10.1787/6a32426b-en (Accessed on 27 March 2017)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(teachingStuff)
str(teachingStuff)
</code></pre>

<hr>
<h2 id='ternaryDiag'>Ternary diagram</h2><span id='topic+ternaryDiag'></span>

<h3>Description</h3>

<p>This plot shows the relative proportions of three variables (compositional
parts) in one diagramm. Before plotting, the data are scaled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternaryDiag(
  x,
  name = colnames(x),
  text = NULL,
  grid = TRUE,
  gridCol = grey(0.6),
  mcex = 1.2,
  line = "none",
  robust = TRUE,
  group = NULL,
  tol = 0.975,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ternaryDiag_+3A_x">x</code></td>
<td>
<p>matrix or data.frame with 3 columns</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_name">name</code></td>
<td>
<p>names of the variables</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_text">text</code></td>
<td>
<p>default NULL, text for each point can be provided</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_grid">grid</code></td>
<td>
<p>if TRUE a grid is plotted additionally in the ternary diagram</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_gridcol">gridCol</code></td>
<td>
<p>color for the grid lines</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_mcex">mcex</code></td>
<td>
<p>label size</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_line">line</code></td>
<td>
<p>may be set to &ldquo;none&rdquo;, &ldquo;pca&rdquo;, &ldquo;regression&rdquo;,
&ldquo;regressionconf&rdquo;, &ldquo;regressionpred&rdquo;, &ldquo;ellipse&rdquo;,
&ldquo;lda&rdquo;</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_robust">robust</code></td>
<td>
<p>if line equals TRUE, it dedicates if a robust estimation is
applied or not.</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_group">group</code></td>
<td>
<p>if line equals &ldquo;da&rdquo;, it determines the grouping variable</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_tol">tol</code></td>
<td>
<p>if line equals &ldquo;ellipse&rdquo;, it determines the parameter for
the tolerance ellipse</p>
</td></tr>
<tr><td><code id="ternaryDiag_+3A_...">...</code></td>
<td>
<p>further parameters, see, e.g., <code>par()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative proportions of each variable are plotted.
</p>


<h3>Author(s)</h3>

<p>Peter Filzmoser &lt;<a href="mailto:P.Filzmoser@tuwien.ac.at">P.Filzmoser@tuwien.ac.at</a>&gt;, Matthias Templ &lt;<a href="mailto:matthias.templ@fhnw.ch">matthias.templ@fhnw.ch</a>&gt;
</p>


<h3>References</h3>

<p>Reimann, C., Filzmoser, P., Garrett, R.G., Dutter, R. (2008)
<em>Statistical Data Analysis Explained. Applied Environmental Statistics with
R</em>. John Wiley and Sons, Chichester.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(arcticLake)
ternaryDiag(arcticLake)

data(coffee)
x &lt;- coffee[,2:4]
grp &lt;- as.integer(coffee[,1])
ternaryDiag(x, col=grp, pch=grp)
ternaryDiag(x, grid=FALSE, col=grp, pch=grp)
legend("topright", legend=unique(coffee[,4]), pch=1:2, col=1:2)

ternaryDiag(x, grid=FALSE, col=grp, pch=grp, line="ellipse", tol=c(0.975,0.9), lty=2)
ternaryDiag(x, grid=FALSE, line="pca")
ternaryDiag(x, grid=FALSE, col=grp, pch=grp, line="pca", lty=2, lwd=2)

</code></pre>

<hr>
<h2 id='ternaryDiagAbline'>Adds a line to a ternary diagram.</h2><span id='topic+ternaryDiagAbline'></span>

<h3>Description</h3>

<p>A low-level plot function which adds a line to a high-level ternary diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternaryDiagAbline(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ternaryDiagAbline_+3A_x">x</code></td>
<td>
<p>Two-dimensional data set in isometric log-ratio transformed space.</p>
</td></tr>
<tr><td><code id="ternaryDiagAbline_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a small utility function which helps to add a line in a ternary plot
from two given points in an isometric transformed space.
</p>


<h3>Value</h3>

<p>no values are returned.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ternaryDiag">ternaryDiag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
x &lt;- coffee[,2:4]
ternaryDiag(x, grid=FALSE)
ternaryDiagAbline(data.frame(z1=c(0.01,0.5), z2=c(0.4,0.8)), col="red")

</code></pre>

<hr>
<h2 id='ternaryDiagEllipse'>Adds tolerance ellipses to a ternary diagram.</h2><span id='topic+ternaryDiagEllipse'></span>

<h3>Description</h3>

<p>Low-level plot function which add tolerance ellipses to a high-level plot of
a ternary diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternaryDiagEllipse(x, tolerance = c(0.9, 0.95, 0.975), locscatt = "MCD", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ternaryDiagEllipse_+3A_x">x</code></td>
<td>
<p>Three-part composition. Object of class &ldquo;matrix&rdquo; or
&ldquo;data.frame&rdquo;.</p>
</td></tr>
<tr><td><code id="ternaryDiagEllipse_+3A_tolerance">tolerance</code></td>
<td>
<p>Determines the amount of observations with Mahalanobis
distance larger than the drawn ellipse, scaled to one.</p>
</td></tr>
<tr><td><code id="ternaryDiagEllipse_+3A_locscatt">locscatt</code></td>
<td>
<p>Method for estimating the mean and covariance.</p>
</td></tr>
<tr><td><code id="ternaryDiagEllipse_+3A_...">...</code></td>
<td>
<p>Additional arguments passed trough.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no values are returned.
</p>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ternaryDiag">ternaryDiag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
x &lt;- coffee[,2:4]
ternaryDiag(x, grid=FALSE)
ternaryDiagEllipse(x)
## or directly:
ternaryDiag(x, grid=FALSE, line="ellipse")

</code></pre>

<hr>
<h2 id='ternaryDiagPoints'>Add points or lines to a given ternary diagram.</h2><span id='topic+ternaryDiagPoints'></span><span id='topic+ternaryDiagLines'></span>

<h3>Description</h3>

<p>Low-level plot function to add points or lines to a ternary high-level plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternaryDiagPoints(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ternaryDiagPoints_+3A_x">x</code></td>
<td>
<p>Three-dimensional composition given as an object of class
&ldquo;matrix&rdquo; or &ldquo;data.frame&rdquo;.</p>
</td></tr>
<tr><td><code id="ternaryDiagPoints_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no values are returned.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>C. Reimann, P. Filzmoser, R.G. Garrett, and R. Dutter:
Statistical Data Analysis Explained. Applied Environmental Statistics with
R. John Wiley and Sons, Chichester, 2008.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ternaryDiag">ternaryDiag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(coffee)
x &lt;- coffee[,2:4]
ternaryDiag(x, grid=FALSE)
ternaryDiagPoints(x+1, col="red", pch=2)

</code></pre>

<hr>
<h2 id='trapzc'>Trapezoidal formula for numerical integration</h2><span id='topic+trapzc'></span>

<h3>Description</h3>

<p>Numerical integration via trapezoidal formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trapzc(step, f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trapzc_+3A_step">step</code></td>
<td>
<p>step of the grid</p>
</td></tr>
<tr><td><code id="trapzc_+3A_f">f</code></td>
<td>
<p>grid evaluation of density</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>int</code></td>
<td>
<p>The value of integral computed numerically by trapezoidal formula.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Talska<a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>, K. Hron<a href="mailto:karel.hron@upol.cz">karel.hron@upol.cz</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example (zero-integral of fcenLR density)
t = seq(-4.7,4.7, length = 1000)
t_step = diff(t[1:2])
mean = 0; sd = 1.5
f = dnorm(t, mean, sd)
f.fcenLR = fcenLR(t,t_step,f)
trapzc(t_step,f.fcenLR)
</code></pre>

<hr>
<h2 id='trondelagC'>regional geochemical survey of soil C in Norway</h2><span id='topic+trondelagC'></span>

<h3>Description</h3>

<p>A regional-scale geochemical survey of C horizon samples in Nord-Trondelag, Central Norway
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(trondelagC)
</code></pre>


<h3>Format</h3>

<p>A data frame with 754 observations and 70 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>X.S_ID </code>ID
</p>
</li>
<li><p><code>X.Loc_ID </code>ID
</p>
</li>
<li><p><code>longitude </code>longitude in WGS84
</p>
</li>
<li><p><code>latitude </code>latitude in WGS84
</p>
</li>
<li><p><code>E32wgs </code>UTM zone east
</p>
</li>
<li><p><code>N32wgs </code>UTM zone north
</p>
</li>
<li><p><code>X.Medium </code>
</p>
</li>
<li><p><code>Ag </code>Concentration of silver (in mg/kg)
</p>
</li>
<li><p><code>Al </code>Concentration of aluminum (in mg/kg)
</p>
</li>
<li><p><code>As </code>Concentration of arsenic (in mg/kg)
</p>
</li>
<li><p><code>Au </code>Concentration of gold (in mg/kg)
</p>
</li>
<li><p><code>B </code>Concentration of boron (in mg/kg)
</p>
</li>
<li><p><code>Ba </code>Concentration of barium (in mg/kg)
</p>
</li>
<li><p><code>Be </code>Concentration of beryllium (in mg/kg)
</p>
</li>
<li><p><code>Bi </code>Concentration of bismuth (in mg/kg)
</p>
</li>
<li><p><code>Ca </code>Concentration of calzium (in mg/kg)
</p>
</li>
<li><p><code>Cd </code>Concentration of cadmium (in mg/kg)
</p>
</li>
<li><p><code>Ce </code>Concentration of cerium (in mg/kg)
</p>
</li>
<li><p><code>Co </code>Concentration of cobalt (in mg/kg)
</p>
</li>
<li><p><code>Cr </code>Concentration of chromium (in mg/kg)
</p>
</li>
<li><p><code>Cs </code>Concentration of cesium (in mg/kg)
</p>
</li>
<li><p><code>Cu </code>Concentration of copper (in mg/kg)
</p>
</li>
<li><p><code>Fe </code>Concentration of iron (in mg/kg)
</p>
</li>
<li><p><code>Ga </code>Concentration of gallium (in mg/kg)
</p>
</li>
<li><p><code>Ge </code>Concentration of germanium (in mg/kg)
</p>
</li>
<li><p><code>Hf </code>Concentration of hafnium (in mg/kg)
</p>
</li>
<li><p><code>Hg </code>Concentration of mercury (in mg/kg)
</p>
</li>
<li><p><code>In </code>Concentration of indium (in mg/kg)
</p>
</li>
<li><p><code>K </code>Concentration of pottasium (in mg/kg)
</p>
</li>
<li><p><code>La </code>Concentration of lanthanum (in mg/kg)
</p>
</li>
<li><p><code>Li </code>Concentration of lithium (in mg/kg)
</p>
</li>
<li><p><code>Mg </code>Concentration of magnesium (in mg/kg)
</p>
</li>
<li><p><code>Mn </code>Concentration of manganese (in mg/kg)
</p>
</li>
<li><p><code>Mo </code>Concentration of molybdenum (in mg/kg)
</p>
</li>
<li><p><code>Na </code>Concentration of sodium (in mg/kg)
</p>
</li>
<li><p><code>Nb </code>Concentration of niobium (in mg/kg)
</p>
</li>
<li><p><code>Ni </code>Concentration of nickel (in mg/kg)
</p>
</li>
<li><p><code>P </code>Concentration of phosphorus (in mg/kg)
</p>
</li>
<li><p><code>Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>Pb204 </code>Concentration of lead, 204 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb206 </code>Concentration of lead, 206 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb207 </code>Concentration of lead, 207 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb208 </code>Concentration of lead, 208 neutrons (in mg/kg)
</p>
</li>
<li><p><code>X6_7Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X7_8Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X6_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X7_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X8_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>Pd </code>Concentration of palladium (in mg/kg)
</p>
</li>
<li><p><code>Pt </code>Concentration of platium (in mg/kg)
</p>
</li>
<li><p><code>Rb </code>Concentration of rubidium (in mg/kg)
</p>
</li>
<li><p><code>Re </code>Concentration of rhenium (in mg/kg)
</p>
</li>
<li><p><code>S </code>Concentration of sulfur (in mg/kg)
</p>
</li>
<li><p><code>Sb </code>Concentration of antimony (in mg/kg)
</p>
</li>
<li><p><code>Sc </code>Concentration of scandium (in mg/kg)
</p>
</li>
<li><p><code>Se </code>Concentration of selenium (in mg/kg)
</p>
</li>
<li><p><code>Sn </code>Concentration of tin (in mg/kg)
</p>
</li>
<li><p><code>Sr </code>Concentration of strontium (in mg/kg)
</p>
</li>
<li><p><code>Ta </code>Concentration of tantalum (in mg/kg)
</p>
</li>
<li><p><code>Te </code>Concentration of tellurium (in mg/kg)
</p>
</li>
<li><p><code>Th </code>Concentration of thorium (in mg/kg)
</p>
</li>
<li><p><code>Ti </code>Concentration of titanium (in mg/kg)
</p>
</li>
<li><p><code>Tl </code>Concentration of thalium (in mg/kg)
</p>
</li>
<li><p><code>U </code>Concentration of uranium (in mg/kg)
</p>
</li>
<li><p><code>V </code>Concentration of vanadium (in mg/kg)
</p>
</li>
<li><p><code>W </code>Concentration of tungsten (in mg/kg)
</p>
</li>
<li><p><code>Y </code>Concentration of yttrium (in mg/kg)
</p>
</li>
<li><p><code>Zn </code>Concentration of zinc (in mg/kg)
</p>
</li>
<li><p><code>Zr </code>Concentration of zirconium (in mg/kg)
</p>
</li></ul>

<p>The samples were analysed using aqua regia extraction. 
Sampling was based on a 6.6km grid, i.e. 1 sample site/36 km2.
</p>


<h3>Author(s)</h3>

<p>NGU, <a href="https://www.ngu.no">https://www.ngu.no</a>, transfered to R by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>C.Reimann, J.Schilling, D.Roberts, K.Fabian. A regional-scale geochemical survey of soil C horizon samples in Nord-Trondelag, Central Norway. Geology and mineral potential, <em>Applied Geochemistry</em> 61 (2015) 192-205.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(trondelagC)
str(trondelagC)
</code></pre>

<hr>
<h2 id='trondelagO'>regional geochemical survey of soil O in Norway</h2><span id='topic+trondelagO'></span>

<h3>Description</h3>

<p>A regional-scale geochemical survey of O horizon samples in Nord-Trondelag, Central Norway
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(trondelagO)
</code></pre>


<h3>Format</h3>

<p>A data frame with 754 observations and 70 variables
</p>


<h3>Details</h3>


<ul>
<li><p><code>X.Loc_ID </code>ID
</p>
</li>
<li><p><code>LITHO </code>Rock type
</p>
</li>
<li><p><code>longitude </code>langitude in WGS84
</p>
</li>
<li><p><code>latitude </code>latitude in WGS84
</p>
</li>
<li><p><code>E32wgs </code>UTM zone east
</p>
</li>
<li><p><code>N32wgs </code>UTM zone north
</p>
</li>
<li><p><code>X.Medium </code>a numeric vector
</p>
</li>
<li><p><code>Alt_masl </code>a numeric vector
</p>
</li>
<li><p><code>LOI_480 </code>Loss on ignition
</p>
</li>
<li><p><code>pH </code>Numeric scale used to specify the acidity or alkalinity of an aqueous solution
</p>
</li>
<li><p><code>Ag </code>Concentration of silver (in mg/kg)
</p>
</li>
<li><p><code>Al </code>Concentration of aluminum (in mg/kg)
</p>
</li>
<li><p><code>As </code>Concentration of arsenic (in mg/kg)
</p>
</li>
<li><p><code>Au </code>Concentration of gold (in mg/kg)
</p>
</li>
<li><p><code>B </code>Concentration of boron (in mg/kg)
</p>
</li>
<li><p><code>Ba </code>Concentration of barium (in mg/kg)
</p>
</li>
<li><p><code>Be </code>Concentration of beryllium (in mg/kg)
</p>
</li>
<li><p><code>Bi </code>Concentration of bismuth (in mg/kg)
</p>
</li>
<li><p><code>Ca </code>Concentration of calzium (in mg/kg)
</p>
</li>
<li><p><code>Cd </code>Concentration of cadmium (in mg/kg)
</p>
</li>
<li><p><code>Ce </code>Concentration of cerium (in mg/kg)
</p>
</li>
<li><p><code>Co </code>Concentration of cobalt (in mg/kg)
</p>
</li>
<li><p><code>Cr </code>Concentration of chromium (in mg/kg)
</p>
</li>
<li><p><code>Cs </code>Concentration of cesium (in mg/kg)
</p>
</li>
<li><p><code>Cu </code>Concentration of copper (in mg/kg)
</p>
</li>
<li><p><code>Fe </code>Concentration of iron (in mg/kg)
</p>
</li>
<li><p><code>Ga </code>Concentration of gallium (in mg/kg)
</p>
</li>
<li><p><code>Ge </code>Concentration of germanium (in mg/kg)
</p>
</li>
<li><p><code>Hf </code>Concentration of hafnium (in mg/kg)
</p>
</li>
<li><p><code>Hg </code>Concentration of mercury (in mg/kg)
</p>
</li>
<li><p><code>In </code>Concentration of indium (in mg/kg)
</p>
</li>
<li><p><code>K </code>Concentration of pottasium (in mg/kg)
</p>
</li>
<li><p><code>La </code>Concentration of lanthanum (in mg/kg)
</p>
</li>
<li><p><code>Li </code>Concentration of lithium (in mg/kg)
</p>
</li>
<li><p><code>Mg </code>Concentration of magnesium (in mg/kg)
</p>
</li>
<li><p><code>Mn </code>Concentration of manganese (in mg/kg)
</p>
</li>
<li><p><code>Mo </code>Concentration of molybdenum (in mg/kg)
</p>
</li>
<li><p><code>Na </code>Concentration of sodium (in mg/kg)
</p>
</li>
<li><p><code>Nb </code>Concentration of niobium (in mg/kg)
</p>
</li>
<li><p><code>Ni </code>Concentration of nickel (in mg/kg)
</p>
</li>
<li><p><code>P </code>Concentration of phosphorus (in mg/kg)
</p>
</li>
<li><p><code>Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>Pb204 </code>Concentration of lead, 204 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb206 </code>Concentration of lead, 206 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb207 </code>Concentration of lead, 207 neutrons (in mg/kg)
</p>
</li>
<li><p><code>Pb208 </code>Concentration of lead, 208 neutrons (in mg/kg)
</p>
</li>
<li><p><code>X6_7Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X7_8Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X6_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X7_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>X8_4Pb </code>Concentration of lead (in mg/kg)
</p>
</li>
<li><p><code>Pd </code>Concentration of palladium (in mg/kg)
</p>
</li>
<li><p><code>Pt </code>Concentration of platium (in mg/kg)
</p>
</li>
<li><p><code>Rb </code>Concentration of rubidium (in mg/kg)
</p>
</li>
<li><p><code>Re </code>Concentration of rhenium (in mg/kg)
</p>
</li>
<li><p><code>S </code>Concentration of sulfur (in mg/kg)
</p>
</li>
<li><p><code>Sb </code>Concentration of antimony (in mg/kg)
</p>
</li>
<li><p><code>Sc </code>Concentration of scandium (in mg/kg)
</p>
</li>
<li><p><code>Se </code>Concentration of selenium (in mg/kg)
</p>
</li>
<li><p><code>Sn </code>Concentration of tin (in mg/kg)
</p>
</li>
<li><p><code>Sr </code>Concentration of strontium (in mg/kg)
</p>
</li>
<li><p><code>Ta </code>Concentration of tantalum (in mg/kg)
</p>
</li>
<li><p><code>Te </code>Concentration of tellurium (in mg/kg)
</p>
</li>
<li><p><code>Th </code>Concentration of thorium (in mg/kg)
</p>
</li>
<li><p><code>Ti </code>Concentration of titanium (in mg/kg)
</p>
</li>
<li><p><code>Tl </code>Concentration of thalium (in mg/kg)
</p>
</li>
<li><p><code>U </code>Concentration of uranium (in mg/kg)
</p>
</li>
<li><p><code>V </code>Concentration of vanadium (in mg/kg)
</p>
</li>
<li><p><code>W </code>Concentration of tungsten (in mg/kg)
</p>
</li>
<li><p><code>Y </code>Concentration of yttrium (in mg/kg)
</p>
</li>
<li><p><code>Zn </code>Concentration of zinc (in mg/kg)
</p>
</li>
<li><p><code>Zr </code>Concentration of zirconium (in mg/kg)
</p>
</li></ul>

<p>The samples were analysed using aqua regia extraction. 
Sampling was based on a 6.6km grid, i.e. 1 sample site/36 km2.
</p>


<h3>Author(s)</h3>

<p>NGU, <a href="https://www.ngu.no">https://www.ngu.no</a>, transfered to R by Matthias Templ <a href="mailto:matthias.templ@tuwien.ac.at">matthias.templ@tuwien.ac.at</a>
</p>


<h3>References</h3>

<p>C.Reimann, J.Schilling, D.Roberts, K.Fabian. A regional-scale geochemical survey of soil C horizon samples in Nord-Trondelag, Central Norway. Geology and mineral potential, <em>Applied Geochemistry</em> 61 (2015) 192-205.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(trondelagO)
str(trondelagO)
</code></pre>

<hr>
<h2 id='unemployed'>unemployed of young people</h2><span id='topic+unemployed'></span>

<h3>Description</h3>

<p>Youth not in employment, education or training (NEET) in 43 countries from 1997 till 2015
</p>


<h3>Format</h3>

<p>A (tidy) data frame with 1216 observations on the following 4 variables.
</p>
 
<ul>
<li><p><code>country </code>Country of origin
</p>
</li>
<li><p><code>age </code>age group  
</p>
</li>
<li><p><code>year </code>Year 
</p>
</li>
<li><p><code>value </code>percentage of unemployed
</p>
</li></ul>



<h3>Details</h3>

<p>This indicator presents the share of young people who are 
not in employment, education or training (NEET), as 
a percentage of the total number of young people 
in the corresponding age group, by gender. 
Young people in education include those attending 
part-time or full-time education, but exclude those 
in non-formal education and in educational activities 
of very short duration. Employment is defined according 
to the OECD/ILO Guidelines and covers all those who 
have been in paid work for at least one hour in the 
reference week of the survey or were temporarily 
absent from such work. Therefore NEET youth can be 
either unemployed or inactive and not involved in 
education or training. Young people who are neither 
in employment nor in education or training are at 
risk of becoming socially excluded - individuals 
with income below the poverty-line and lacking the 
skills to improve their economic situation.
</p>


<h3>Author(s)</h3>

<p>translated from <a href="https://data.oecd.org/">https://data.oecd.org/</a> and restructured by Matthias Templ
</p>


<h3>Source</h3>

<p>OECD:
<a href="https://data.oecd.org/">https://data.oecd.org/</a>
</p>


<h3>References</h3>

<p>OECD (2017), Youth not in employment, education or training (NEET) (indicator). doi: 10.1787/72d1033a-en (Accessed on 27 March 2017)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(unemployed)
str(unemployed)
</code></pre>

<hr>
<h2 id='variation'>Robust and classical variation matrix</h2><span id='topic+variation'></span>

<h3>Description</h3>

<p>Estimates the variation matrix with robust methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variation(x, method = "robustPivot", algorithm = "MCD")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variation_+3A_x">x</code></td>
<td>
<p>data frame or matrix with positive entries</p>
</td></tr>
<tr><td><code id="variation_+3A_method">method</code></td>
<td>
<p>method used for estimating covariances. See details.</p>
</td></tr>
<tr><td><code id="variation_+3A_algorithm">algorithm</code></td>
<td>
<p>kind of robust estimator (MCD or MM)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variation matrix is estimated for a given compositional data set.
Instead of using the classical standard deviations the miniminm covariance estimator
is used (<code><a href="robustbase.html#topic+covMcd">covMcd</a></code>) is used when parameter robust is set to TRUE.
</p>
<p>For method <code>robustPivot</code> forumala 5.8. of the book (see second reference) is used. Here 
robust (mcd-based) covariance estimation is done on pivot coordinates. 
Method <code>robustPairwise</code> uses a mcd covariance estimation on pairwise log-ratios.
Methods <code>Pivot</code> (see second reference) and <code>Pairwise</code> (see first reference) 
are the non-robust counterparts. 
Naturally, <code>Pivot</code> and <code>Pairwise</code> gives the same results, but 
the computational time is much less for method <code>Pairwise</code>.
</p>


<h3>Value</h3>

<p>The (robust) variation matrix.
</p>


<h3>Author(s)</h3>

<p>Karel Hron, Matthias Templ
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of
Compositional Data</em> Monographs on Statistics and Applied Probability.
Chapman and Hall Ltd., London (UK). 416p.
</p>
<p>#' Filzmoser, P., Hron, K., Templ, M. (2018) <em>Applied Compositional Data Analysis</em>.
Springer, Cham.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(expenditures)
variation(expenditures) # default is method "robustPivot"
variation(expenditures, method = "Pivot")
variation(expenditures, method = "robustPairwise")
variation(expenditures, method = "Pairwise") # same results as Pivot

</code></pre>

<hr>
<h2 id='weightedPivotCoord'>Weighted pivot coordinates</h2><span id='topic+weightedPivotCoord'></span>

<h3>Description</h3>

<p>Weighted pivot coordinates as a special case of isometric logratio coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedPivotCoord(
  x,
  pivotvar = 1,
  option = "var",
  method = "classical",
  pow = 1,
  yvar = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedPivotCoord_+3A_x">x</code></td>
<td>
<p>object of class 'data.frame' or 'matrix'; positive values only</p>
</td></tr>
<tr><td><code id="weightedPivotCoord_+3A_pivotvar">pivotvar</code></td>
<td>
<p>pivotal variable; if any other number than 1, the data are resorted in that sense that 
pivotvar is shifted to the first part</p>
</td></tr>
<tr><td><code id="weightedPivotCoord_+3A_option">option</code></td>
<td>
<p>option for the choice of weights. If 'option = &quot;var&quot;' (default), weights are based on variation matrix elements: 
'(1/t_1j)^pow', if 'option = &quot;cor&quot;', weights are based on correlations between variable specified in yvar and logratios and its distribution:
'|integral_0^r_j f(x) dx|', 'f(x)...' Kernel density estimator for 's_j; s_j=0 if |r_j|&lt;cut' otherwise 's_j=r_j',
'cut = min(#r_j=&gt;0/#r_j, #r_j&lt;0/#r_j', with Gaussian Kernel function and bandwidth 'h=0.05'.</p>
</td></tr>
<tr><td><code id="weightedPivotCoord_+3A_method">method</code></td>
<td>
<p>method for estimation of variation/correlation,
if 'option = &quot;classical&quot;' (default), classical estimation is applied,
if 'option = &quot;robust&quot;', robust estimation is applied;</p>
</td></tr>
<tr><td><code id="weightedPivotCoord_+3A_pow">pow</code></td>
<td>
<p>if 'option = &quot;var&quot;', power 'pow' is applied on unnormalized weights; default is 1;</p>
</td></tr>
<tr><td><code id="weightedPivotCoord_+3A_yvar">yvar</code></td>
<td>
<p>if 'option = &quot;cor&quot;', weights are based on correlation between logratios and variable specified in 'yvar';</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Weighted pivot coordinates map D-part compositional data from the simplex into a (D-1)-dimensional real space isometrically.
The relevant relative information about one of parts is contained in the first coordinate.
Unlike in the (ordinary) pivot coordinates, the pairwise logratios aggregated into the first coordinate are weighted according to their relevance for the purpose of the analysis.
</p>


<h3>Value</h3>

<table>
<tr><td><code>WPC</code></td>
<td>
<p>weighted pivot coordinates (matrix with n rows and (D-1) columns)</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>logcontrasts (matrix with D rows and (D-1) columns)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Nikola Stefelova
</p>


<h3>References</h3>

<p>Hron K, Filzmoser P, de Caritat P, Fiserova E, Gardlo A (2017) 
Weighted 'pivot coordinates for compositional data and their application to geochemical mapping.
Mathematical Geosciences 49(6):797-814.
</p>
<p>Stefelova N, Palarea-Albaladejo J, and Hron K (2021)
Weighted pivot coordinates for PLS-based marker discovery in high-throughput compositional data.
Statistical Analysis and Data Mining: The ASA Data Science Journal 14(4):315-330.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pivotCoord">pivotCoord</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################
data(phd)
x &lt;- phd[, 7:ncol(phd)]
x[x == 0] &lt;- 0.1 # better: impute with one 
                 # of the zero imputation methods 
                 # from robCompositions

# first variable as pivotal, weights based on variation matrix
wpc_var &lt;- weightedPivotCoord(x)
coordinates &lt;- wpc_var$WPC
logcontrasts &lt;- wpc_var$w

# third variable as pivotal, weights based on variation matrix, 
# robust estimation of variance, effect of weighting enhanced
wpc_var &lt;- weightedPivotCoord(x, pivotvar = 3, method = "robust", pow = 2)
coordinates = wpc_var$WPC
logcontrasts = wpc_var$w

# first variable as pivotal, weights based on correlation between pairwise logratios and y
wpc_cor &lt;- weightedPivotCoord(x, option = "cor", yvar = phd$female)
coordinates &lt;- wpc_cor$WPC
logcontrasts &lt;- wpc_cor$w

# fifth variable as pivotal, weights based on correlation between pairwise logratios 
# and y, robust estimation of correlation
wpc_cor &lt;- weightedPivotCoord(x, pivotvar = 5, option = "cor", method = "robust", yvar = phd$female)
coordinates &lt;- wpc_cor$WPC
logcontrasts &lt;- wpc_cor$w

</code></pre>

<hr>
<h2 id='ZBsplineBasis'>ZB-spline basis</h2><span id='topic+ZBsplineBasis'></span>

<h3>Description</h3>

<p>Spline basis system having zero-integral on I=[a,b] of the L^2_0 space (called ZB-splines) has been
proposed for an basis representation of fcenLR transformed probability density functions. The ZB-spline basis functions can be back
transformed to Bayes spaces using inverse of fcenLR transformation, resulting in compositional B-splines (CB-splines), 
and forming a basis system of the Bayes spaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ZBsplineBasis(t, knots, order, basis.plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ZBsplineBasis_+3A_t">t</code></td>
<td>
<p>a vector of argument values at which the ZB-spline basis functions are to be evaluated</p>
</td></tr>
<tr><td><code id="ZBsplineBasis_+3A_knots">knots</code></td>
<td>
<p>sequence of knots</p>
</td></tr>
<tr><td><code id="ZBsplineBasis_+3A_order">order</code></td>
<td>
<p>order of the ZB-splines (i.e., degree + 1)</p>
</td></tr>
<tr><td><code id="ZBsplineBasis_+3A_basis.plot">basis.plot</code></td>
<td>
<p>if TRUE, the ZB-spline basis system is plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ZBsplineBasis</code></td>
<td>
<p>matrix of ZB-spline basis functions evaluated at a vector of argument values t</p>
</td></tr>
<tr><td><code>nbasis</code></td>
<td>
<p>number of ZB-spline basis functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Machalova <a href="mailto:jitka.machalova@upol.cz">jitka.machalova@upol.cz</a>, R. Talska <a href="mailto:talskarenata@seznam.cz">talskarenata@seznam.cz</a>
</p>


<h3>References</h3>

<p>Machalova, J., Talska, R., Hron, K. Gaba, A. Compositional splines 
for representation of density functions. <em>Comput Stat</em> (2020). 
https://doi.org/10.1007/s00180-020-01042-7
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: ZB-spline basis functions evaluated at a vector of argument values t
t = seq(0,20,l=500)
knots = c(0,2,5,9,14,20)
order = 4

ZBsplineBasis.out = ZBsplineBasis(t,knots,order, basis.plot=TRUE)

# Back-transformation of ZB-spline basis functions from L^2_0 to Bayes space -&gt; 
# CB-spline basis functions
CBsplineBasis=NULL
for (i in 1:ZBsplineBasis.out$nbasis)
{
 CB_spline = fcenLRinv(t,diff(t)[1:2],ZBsplineBasis.out$ZBsplineBasis[,i])
 CBsplineBasis = cbind(CBsplineBasis,CB_spline)
}

matplot(t,CBsplineBasis, type="l",lty=1, las=1, 
  col=rainbow(ZBsplineBasis.out$nbasis), xlab="t", 
  ylab="CB-spline basis",
cex.lab=1.2,cex.axis=1.2)
abline(v=knots, col="gray", lty=2)
</code></pre>

<hr>
<h2 id='zeroOut'>Detection of outliers of zero-inflated data</h2><span id='topic+zeroOut'></span>

<h3>Description</h3>

<p>detects outliers in compositional zero-inflated data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeroOut(x, impute = "knn")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zeroOut_+3A_x">x</code></td>
<td>
<p>a data frame</p>
</td></tr>
<tr><td><code id="zeroOut_+3A_impute">impute</code></td>
<td>
<p>imputation method internally used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>XXX
</p>


<h3>Value</h3>

<p>XXX
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Installing and loading required packages
data(expenditures)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
