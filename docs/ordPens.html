<!DOCTYPE html><html><head><title>Help for package ordPens</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ordPens}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ICFCoreSetCWP'><p>ICF core set for chronic widespread pain</p></a></li>
<li><a href='#ordAOV'><p>ANOVA for factors with ordered levels</p></a></li>
<li><a href='#ordCV'><p>Cross-validation for penalized regression with ordinal predictors.</p></a></li>
<li><a href='#ordFusion'><p>Fusion and selection of dummy coefficients of ordinal predictors</p></a></li>
<li><a href='#ordGene'><p>Testing for differentially expressed genes</p></a></li>
<li><a href='#ordPCA'><p>Penalized nonlinear PCA for ordinal variables</p>
</p></a></li>
<li><a href='#ordPens-internal'><p>Internal ordPens functions</p></a></li>
<li><a href='#ordPens-package'>
<p>Selection and/or Smoothing and Principal Components Analysis for Ordinal Variables</p></a></li>
<li><a href='#ordSelect'><p>Selection and smoothing of dummy coefficients of ordinal predictors</p></a></li>
<li><a href='#ordSmooth'><p>Smoothing dummy coefficients of ordinal predictors</p></a></li>
<li><a href='#plot.ordPen'><p>Plot method for ordPen objects</p></a></li>
<li><a href='#predict.ordPen'><p>Predict method for ordPen objects</p></a></li>
<li><a href='#Stability.cumu'><p>Stability selection for ordinal-on-ordinal regression.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Selection, Fusion, Smoothing and Principal Components Analysis
for Ordinal Variables</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Aisouda Hoshiyar &lt;aisouda.hoshiyar@hsu-hh.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Selection, fusion, and/or smoothing of ordinally scaled independent variables using a group lasso, fused lasso or generalized ridge penalty, as well as non-linear principal components analysis for ordinal variables using a second-order difference/smoothing penalty.</td>
</tr>
<tr>
<td>Depends:</td>
<td>grplasso, mgcv, RLRsim, quadprog, glmpath</td>
</tr>
<tr>
<td>Imports:</td>
<td>ordinalNet</td>
</tr>
<tr>
<td>Suggests:</td>
<td>utils, psy, knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-10 09:45:40 UTC; aisoudahoshiyar</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan Gertheiss [aut],
  Aisouda Hoshiyar [aut, cre],
  Fabian Scheipl [ctb]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-10 10:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='ICFCoreSetCWP'>ICF core set for chronic widespread pain</h2><span id='topic+ICFCoreSetCWP'></span>

<h3>Description</h3>

<p>The data set contains observed levels of ICF categories from
the (comprehensive) ICF Core Set for chronic widespread pain (CWP) and a
physical health component summary measure for n = 420 patients.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ICFCoreSetCWP)
</code></pre>


<h3>Format</h3>

<p>The data frame has 420 rows and 68 columns. The first 67 columns
contain observed levels of ICF categories from the (comprehensive) ICF Core Set
for chronic widespread pain (CWP). In the last column, the physical health
component summary measure is given. Each row corresponds to one patient
with CWP. ICF categories have discrete ordinal values between 0 and 4
(columns 1 - 50 and 67), or between -4 and 4 (columns 51 - 66). See the given
references for details.
</p>


<h3>Details</h3>

<p>The original data set contained some missing values, which have been imputed 
using R package <code>Amelia</code>.
</p>
<p>The data were collected within the study <em>Validation of ICF Core Sets for
chronic conditions</em>, which was a collaboration effort between the ICF Research 
Branch of the collaborating centers for the Family of International
Classifications in German, the Classification, Terminology and standards Team
from the World Health Organization and the International Society for Physical
and Rehabilitation Medicine.
</p>
<p>Special thanks go to the following participating study centers:
Ankara University, Turkey; Azienda Ospedaliera di Sciacca, Italy; Donauspital,
Vienna, Austria; Drei-Burgen-Klinik, Bad Muenster, Germany; Edertal Klinik,
Bad Wildungen, Germany; Fachklinik Bad Bentheim, Germany; Hospital das
Clinicas, School of Medicine, University of Sao Paulo, Brazil; Hospital San
Juan Bautista, Catamarca, Argentina; Istituto Scientifico di Montescano, Italy;
Istituto Scientifico di Veruno, Italy; Kaiser-Franz-Josef-Spital, Vienna,
Austria; Klinik am Regenbogen, Nittenau, Germany; Klinik Bavaria Kreischa,
Germany; Klinik Hoher Meissner, Bad Sooden-Allendorf, Germany; Klinikum
Berchtesgadener Land, Schoenau, Germany; Kuwait Physical Medicine and
Rehabilitation Society, Safat, Kuwait; National Institute for Medical
Rehabilitation, Budapest, Hungary; Neuro-Orthopaedisches Krankenhaus und
Zentrum fuer Rehabilitative Medizin Soltau, Germany; Praxis fuer Physikalische
Medizin und Rehabilitation, Goettingen, Germany; Rehabilitationsklinik Seehof
der Bundesversicherungsanstalt fuer Angestellte, Teltow, Germany; Rehaklinik
Rheinfelden, Switzerland; Spanish Society of Rheumatology, Madrid, Spain;
University Hospital Zurich, Switzerland; University of Santo Tomas, Quelonchy,
Philippines.
</p>
<p>Most special thanks go to all the patients participating in the study.
</p>
<p>If you use the data, please cite the following two references.
</p>


<h3>References</h3>

<p>Cieza, A., G. Stucki, M. Weigl, L. Kullmann, T. Stoll, L. Kamen, N. Kostanjsek,
and N. Walsh (2004). <em>ICF Core Sets for chronic widespread pain</em>. Journal
of Rehabilitation Medicine, Suppl. 44, 63-68.
</p>
<p>Gertheiss, J., S. Hogger, C. Oberhauser and G. Tutz (2011). <em>Selection
of ordinally scaled independent variables with applications to international
classification of functioning core sets</em>. Journal of the Royal Statistical 
Society C (Applied Statistics), 60, 377-395.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the data
data(ICFCoreSetCWP)

# available variables
names(ICFCoreSetCWP)

# adequate coding of x matrix (using levels 1,2,...)
p &lt;- ncol(ICFCoreSetCWP) - 1
n &lt;- nrow(ICFCoreSetCWP)
add &lt;- c(rep(1,50),rep(5,16),1)
add &lt;- matrix(add,n,p,byrow=TRUE)
x &lt;- ICFCoreSetCWP[,1:p] + add

# make sure that also a coefficient is fitted for levels
# that are not observed in the data
addrow &lt;- c(rep(5,50),rep(9,16),5)
x &lt;- rbind(x,addrow)
y &lt;- c(ICFCoreSetCWP$phcs,NA)

# some lambda values
lambda &lt;- c(600,500,400,300,200,100)

# smoothing and selection
modelICF &lt;- ordSelect(x = x, y = y, lambda = lambda)

# results
plot(modelICF)

# plot a selected ICF category (e.g. e1101 'drugs')
# with adequate class labels
plot(modelICF, whx = 51, xaxt = "n")
axis(side = 1, at = 1:9, labels = -4:4)
</code></pre>

<hr>
<h2 id='ordAOV'>ANOVA for factors with ordered levels</h2><span id='topic+ordAOV'></span>

<h3>Description</h3>

<p>This function performs analysis of variance when the
factor(s) of interest has/have ordinal scale level. For testing, values from
the null distribution are simulated.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordAOV(x, y, type = c("RLRT", "LRT"), nsim = 10000,
null.sample = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordAOV_+3A_x">x</code></td>
<td>
<p>a vector or matrix of integers 1,2,... giving the observed levels
of the ordinal factor(s). If <code>x</code> is a matrix, it is assumed that
each column corresponds to one ordinal factor.</p>
</td></tr>
<tr><td><code id="ordAOV_+3A_y">y</code></td>
<td>
<p>the vector of response values.</p>
</td></tr>
<tr><td><code id="ordAOV_+3A_type">type</code></td>
<td>
<p>the type of test to carry out: likelihood ratio (&quot;LRT&quot;) or
restricted likelihood ratio (&quot;RLRT&quot;).</p>
</td></tr>
<tr><td><code id="ordAOV_+3A_nsim">nsim</code></td>
<td>
<p>number of values to simulate from the null distribution.</p>
</td></tr>
<tr><td><code id="ordAOV_+3A_null.sample">null.sample</code></td>
<td>
<p>a vector, or a list of vectors (in case of multi-factorial
ANOVA) containing values already simulated from the null distribution
(overrides <code>nsim</code>)</p>
</td></tr>
<tr><td><code id="ordAOV_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>LRTSim</code> and
<code>RLRTSim</code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that ordinal factor levels (contained in vector/columns of
matrix <code>x</code>) take values 1,2,...,max, where max denotes the highest level
of the respective factor observed in the data. Every level between 1 and max has
to be observed at least once.
</p>
<p>The method uses a mixed effects formulation of the usual one- or multi-factorial
ANOVA model (with main effects only) while penalizing (squared) differences of
adjacent means. Testing for equal means across factor levels is done by
(restricted) likelihood ratio testing for a zero variance component in a linear
mixed model. For simulating values from the finite sample null
distribution of the (restricted) likelihood ratio statistic, the
algorithms implemented in Package <code>RLRsim</code> are used. See
<code>LRTSim</code> and <code>RLRTSim</code> for further information.
</p>
<p>If <code>x</code> is a vector (or one-column matrix), one-factorial ANOVA is applied,
and it is simulated from the exact finite sample null distribution as derived by
Crainiceanu &amp; Ruppert (2004). If <code>x</code> is a matrix, multi-factorial ANOVA
(with main effects only) is done, and the approximation of the finite sample null
distribution proposed by Greven et al. (2008) is used. Simulation
studies by Gertheiss (2014) suggest that for ANOVA with ordinal factors RLRT
should rather be used than LRT.
</p>


<h3>Value</h3>

<p>In case of one-factorial ANOVA, a list of class <code>htest</code> containing the
following components (see also <code>exactLRT</code> and <code>exactRLRT</code>):
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the observed (restricted) likelihood ratio.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p-value for the observed test statistic.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was performed
and how many values were simulated to determine the critical value.</p>
</td></tr>
<tr><td><code>sample</code></td>
<td>
<p>the samples from the null distribution returned by
<code>LRTSim</code> and <code>RLRTSim, respectively.</code></p>
</td></tr>
</table>
<p>In case of multi-factorial ANOVA, a list (of lists) with the jth component
giving the results above when testing the main effect of factor j.
</p>


<h3>Author(s)</h3>

<p>Jan Gertheiss</p>


<h3>References</h3>

<p>Crainiceanu, C. and D. Ruppert (2004). <em>Likelihood ratio tests in linear
mixed models with one variance component</em>, Journal of the Royal Statistical
Society B, 66, 165-185.
</p>
<p>Gertheiss, J. (2014). <em>ANOVA for factors with ordered levels</em>, Journal of
Agricultural, Biological and Environmental Statistics, 19, 258-277.
</p>
<p>Gertheiss, J. and F. Oehrlein (2011). <em>Testing relevance and linearity of
ordinal predictors</em>, Electronic Journal of Statistics, 5, 1935-1959.
</p>
<p>Greven, S., C. Crainiceanu, H. Kuechenhoff, and A. Peters (2008). <em>Restricted
likelihood ratio testing for zero variance components in linear mixed models</em>,
Journal of Computational and Graphical Statistics, 17, 870-891.
</p>
<p>Scheipl, F., S. Greven, and H. Kuechenhoff (2008). <em>Size and power of tests
for a zero random effect variance or polynomial regression in additive and linear
mixed models</em>, Computational Statistics &amp; Data Analysis, 52, 3283-3299.
</p>


<h3>See Also</h3>

<p><code>LRTSim</code>, <code>RLRTSim</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># load some data
data(ICFCoreSetCWP)

# the pysical health component summary
y &lt;- ICFCoreSetCWP$phcs

# consider the first ordinal factor
x &lt;- ICFCoreSetCWP[,1]

# adequate coding
x &lt;- as.integer(x - min(x) + 1)

# ANOVA
ordAOV(x, y, type = "RLRT", nsim=1000000)
</code></pre>

<hr>
<h2 id='ordCV'>Cross-validation for penalized regression with ordinal predictors.</h2><span id='topic+ordCV'></span>

<h3>Description</h3>

<p>Performs k-fold cross-validation in order to evaluate the performance and/or select an optimal smoothing parameter of a penalized regression model with ordinal predictors.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordCV(x, y, u = NULL, z = NULL, k=5, lambda, offset = rep(0,length(y)), 
  model = c("linear", "logit", "poisson", "cumulative"), 
  type=c("selection", "fusion"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordCV_+3A_x">x</code></td>
<td>
<p>matrix of integers 1,2,... giving the observed levels
of the ordinal factor(s).</p>
</td></tr>
<tr><td><code id="ordCV_+3A_y">y</code></td>
<td>
<p>the vector of response values.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_u">u</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional categorical (nominal) 
predictors, with each column corresponding to one (additional) predictor and
containing numeric values from {1,2,...}; corresponding dummy coefficients
will not be penalized, and for each covariate category 1 is taken as reference category. Currently not supported if <code>model="cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_z">z</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional metric predictors, with 
each column corresponding to one (additional) predictor; corresponding
coefficients will not be penalized. Currently not supported if <code>model="cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_k">k</code></td>
<td>
<p>number of folds.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_lambda">lambda</code></td>
<td>
<p>vector of penalty parameters (in decreasing order).</p>
</td></tr>
<tr><td><code id="ordCV_+3A_offset">offset</code></td>
<td>
<p>vector of offset values.</p>
</td></tr> 
<tr><td><code id="ordCV_+3A_model">model</code></td>
<td>
<p>the model which is to be fitted. Possible choices are &quot;linear&quot;
(default), &quot;logit&quot;, &quot;poisson&quot; or &quot;cumulative&quot;. See details below.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_type">type</code></td>
<td>
<p>penalty to be applied. If &quot;selection&quot;, group lasso penalty for smoothing and selection is used. If &quot;fusion&quot;, a fused lasso penalty for fusion and selection is used.</p>
</td></tr>
<tr><td><code id="ordCV_+3A_...">...</code></td>
<td>
<p>additional arguments to <code><a href="#topic+ordFusion">ordFusion</a></code> and
<code><a href="#topic+ordSelect">ordSelect</a></code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that categorical covariates (contained in <code>x</code> and 
<code>u</code>) take values 1,2,...,max, where max denotes the (columnwise) highest 
level observed in the data. If any level between 1 and max is not observed for an ordinal predictor, 
a corresponding (dummy) coefficient is fitted anyway. If any level &gt; max is 
not observed but possible in principle, and a corresponding coefficient is to 
be fitted, the easiest way is to add a corresponding row to <code>x</code> (and 
<code>u</code>,<code>z</code>) with corresponding <code>y</code> value being <code>NA</code>.
</p>
<p>If a linear regression model is fitted, response vector <code>y</code> may contain 
any numeric values; if a logit model is fitted, <code>y</code> has to be 0/1 coded;
if a poisson model is fitted, <code>y</code> has to contain count data. If a cumulative   logit model is fitted, <code>y</code> takes values 1,2,...,max. 
</p>
<p>For the cumulative model, the measure of performance used by the function is the brier score, being the sum of squared differences between (indicator) outcome and predicted probabilities  <code class="reqn">P(Y_i=r)=P(y_{ir})=\pi_{ir}</code>, with observations <code class="reqn">i=1,...,n</code> and classes <code class="reqn">r=1,...,c</code>. Otherwise, the deviance is used.
</p>


<h3>Value</h3>

<p>Returns a list containing the following components:
</p>
<table>
<tr><td><code>Train</code></td>
<td>
<p>matrix of size (<code>k</code> <code class="reqn">x</code> <code>length(lambda)</code>) containing brier/deviance scores on the training data. </p>
</td></tr>
<tr><td><code>Test</code></td>
<td>
<p>Brier/deviance score matrix when looking at the test data set.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and     Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordSelect">ordSelect</a></code>, <code><a href="#topic+ordFusion">ordFusion</a></code></p>

<hr>
<h2 id='ordFusion'>Fusion and selection of dummy coefficients of ordinal predictors</h2><span id='topic+ordFusion'></span>

<h3>Description</h3>

<p>Fits dummy coefficients of ordinally scaled independent variables
with a fused lasso penalty on differences of adjacent dummy coefficients. Using the <code>ordinalNet</code> algorithm if cumulative logit model is fitted, otherwise <code>glmpath</code> algorithm is used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordFusion(x, y, u = NULL, z = NULL, offset = rep(0,length(y)), lambda,  
  model = c("linear", "logit", "poisson", "cumulative"), 
  restriction = c("refcat", "effect"), scalex = TRUE, nonpenx = NULL, 
  frac.arclength = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordFusion_+3A_x">x</code></td>
<td>
<p>the matrix of ordinal predictors, with each column corresponding to
one predictor and containing numeric values from {1,2,...}; for each 
covariate, category 1 is taken as reference category with zero dummy 
coefficient.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_y">y</code></td>
<td>
<p>the response vector.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_u">u</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional categorical (nominal) 
predictors, with each column corresponding to one (additional) predictor and
containing numeric values from {1,2,...}; corresponding dummy coefficients
will not be penalized, and for each covariate category 1 is taken as reference category. Curretnly not supported if <code>model == "cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_z">z</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional metric predictors, with 
each column corresponding to one (additional) predictor; corresponding
coefficients will not be penalized. Curretnly not supported if <code>model == "cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_offset">offset</code></td>
<td>
<p>vector of offset values.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_lambda">lambda</code></td>
<td>
<p>vector of penalty parameters, i.e., lambda values.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_model">model</code></td>
<td>
<p>the model which is to be fitted. Possible choices are &quot;linear&quot;
(default), &quot;logit&quot;, &quot;poisson&quot; or &quot;cumulative&quot;. See details below.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_restriction">restriction</code></td>
<td>
<p>identifiability restriction for dummy coding. &quot;reference&quot; takes category 1 is as reference category (default), while with &quot;effect&quot; dummy coefficients sum up to 0 (known as effect coding).</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_scalex">scalex</code></td>
<td>
<p>logical. Should (split-coded) design matrix corresponding to
<code>x</code> be scaled to have unit variance over columns before fitting? See details below.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_nonpenx">nonpenx</code></td>
<td>
<p>vectors of indices indicating columns of
<code>x</code> whose regression coefficients are not penalized. Curretnly not supported if <code>model == "cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordFusion_+3A_frac.arclength">frac.arclength</code></td>
<td>
<p>just in case the corresponding <code>glmpath</code> argument is to be modified; default is <code>1</code> for <code>model == "linear"</code>, and <code>0.1</code> otherwise.</p>
</td></tr>  
<tr><td><code id="ordFusion_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>ordinalNet</code> (if <code>model == "cumulative"</code>) or <code>glmpath</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that categorical covariates (contained in <code>x</code> and 
<code>u</code>) take values 1,2,...,max, where max denotes the (columnwise) highest 
level observed in the data. If any level between 1 and max is not observed for an ordinal predictor, 
a corresponding (dummy) coefficient is fitted anyway (by linear interpolation, due to some additional but small quadratic penalty, see <code>glmpath</code> for details). If any level &gt; max is 
not observed but possible in principle, and a corresponding coefficient is to 
be fitted, the easiest way is to add a corresponding row to <code>x</code> (and 
<code>u</code>,<code>z</code>) with corresponding <code>y</code> value being <code>NA</code>.
</p>
<p>If a linear regression model is fitted, response vector <code>y</code> may contain 
any numeric values; if a logit model is fitted, <code>y</code> has to be 0/1 coded;
if a poisson model is fitted, <code>y</code> has to contain count data. If a cumulative   logit model is fitted, <code>y</code> takes values 1,2,...,max.
</p>
<p>If <code>scalex</code> is <code>TRUE</code>, (split-coded) design matrix constructed from <code>x</code> is scaled to have 
unit variance over columns (see <code>standardize</code> argument of <code>glmpath</code> or/and <code>ordinalNet</code>).
</p>


<h3>Value</h3>

<p>An <code>ordPen</code> object, which is a list containing:
</p>
<table>
<tr><td><code>fitted</code></td>
<td>
<p>the matrix of fitted response values of the training data.
Columns correspond to different <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the matrix of fitted coefficients with respect to 
dummy-coded (ordinal or nominal) categorical input variables (including the 
reference category) as well as metric predictors. Columns correspond to 
different lambda values.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the type of the fitted model: &quot;linear&quot;, &quot;logit&quot;, &quot;poisson&quot;, or &quot;cumulative&quot;.</p>
</td></tr>
<tr><td><code>restriction</code></td>
<td>
<p>the type of restriction used for identifiability.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the used lambda values.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>a vector giving the number of levels of the ordinal predictors.</p>
</td></tr>
<tr><td><code>ulevels</code></td>
<td>
<p>a vector giving the number of levels of the nominal predictors (if any).</p>
</td></tr>
<tr><td><code>zcovars</code></td>
<td>
<p>the number of metric covariates (if any).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jan Gertheiss, Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Gertheiss, J. and G. Tutz (2010). <em>Sparse modeling of categorial explanatory
variables</em>. The Annals of Applied Statistics, 4, 2150-2180.
</p>
<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and    Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em>  Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Park, M.Y. and T. Hastie (2007). <em>L1 regularization path algorithm for 
generalized linear models</em>. Journal of the Royal Statistical Society B, 69, 659-677.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors &ndash; the old
question of scale level and some answers</em>. Psychometrica, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical
data</em>. Statistical Modelling, 16, 161-200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.ordPen">plot.ordPen</a></code>, <code><a href="#topic+predict.ordPen">predict.ordPen</a></code>, 
<code><a href="#topic+ICFCoreSetCWP">ICFCoreSetCWP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># fusion and selection of ordinal covariates on a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(80,70,60,50,40,30,20,10,5,1) 

# fusion and selection
ofu &lt;- ordFusion(x = x, y = y, lambda = lambda)

# results
round(ofu$coef,digits=3)
plot(ofu)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(ofu, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))
</code></pre>

<hr>
<h2 id='ordGene'>Testing for differentially expressed genes</h2><span id='topic+ordGene'></span>

<h3>Description</h3>

<p>This function can be used to test for genes that are differentially
expressed between levels of an ordinal factor, such as dose levels or ordinal
phenotypes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordGene(xpr, lvs, type = c("RLRT", "LRT"), nsim = 1e6,
null.sample=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordGene_+3A_xpr">xpr</code></td>
<td>
<p>a matrix or data frame of gene expression data with Probe IDs as
row names.</p>
</td></tr>
<tr><td><code id="ordGene_+3A_lvs">lvs</code></td>
<td>
<p>a numeric vector containing the factor levels (e.g., dose levels)
corresponding to the columns of <code>xpr</code>.</p>
</td></tr>
<tr><td><code id="ordGene_+3A_type">type</code></td>
<td>
<p>the type of test to carry out: likelihood ratio (&quot;LRT&quot;) or
restricted likelihood ratio (&quot;RLRT&quot;).</p>
</td></tr>
<tr><td><code id="ordGene_+3A_nsim">nsim</code></td>
<td>
<p>number of values to simulate from the null distribution.</p>
</td></tr>
<tr><td><code id="ordGene_+3A_null.sample">null.sample</code></td>
<td>
<p>a vector containing values already simulated from the null 
distribution (overrides <code>nsim</code>)</p>
</td></tr>
<tr><td><code id="ordGene_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>LRTSim</code> and
<code>RLRTSim</code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each gene in the dataset, <code><a href="#topic+ordAOV">ordAOV</a></code> is applied to test for
differences between levels given in <code>lvs</code>. See <code><a href="#topic+ordAOV">ordAOV</a></code> for
further information on the testing procedure. Simulation studies by Gertheiss (2014)
suggest that a restricted likelihood test (RLRT) should rather be used than
a likelihood ratio test (LRT).
</p>
<p>In addition to (R)LRT, results of usual one-way ANOVA (not taking the factor's
ordinal scale level into account) and a t-test assuming a linear trend across
factor levels are reported. Note that the t-test does not assume linearity in the
doses (such as 0, 0.5, 2.0, 5.0, ...), if given, but in the levels, i.e., 1, 2, 3, etc.
</p>


<h3>Value</h3>

<p>A matrix containing the raw p-values for each gene (rows) when using (R)LRT,
ANOVA or a t-test (columns).
</p>


<h3>Author(s)</h3>

<p>Jan Gertheiss</p>


<h3>References</h3>

<p>Crainiceanu, C. and D. Ruppert (2004). <em>Likelihood ratio tests in linear
mixed models with one variance component</em>, Journal of the Royal Statistical
Society B, 66, 165-185.
</p>
<p>Gertheiss, J. (2014). <em>ANOVA for factors with ordered levels</em>, Journal of
Agricultural, Biological and Environmental Statistics, 19, 258-277.
</p>
<p>Gertheiss, J. and F. Oehrlein (2011). <em>Testing relevance and linearity of
ordinal predictors</em>, Electronic Journal of Statistics, 5, 1935-1959.
</p>
<p>Sweeney, E., C. Crainiceanu, and J. Gertheiss (2015). <em>Testing
differentially expressed genes in dose-response studies and with ordinal
phenotypes</em>, Statistical Applications in Genetics and Molecular Biology, 15, 213-235.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordAOV">ordAOV</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# generate toy gene expression data
set.seed(321) 
ni &lt;- 5
n &lt;- sum(5*ni)
xpr &lt;- matrix(NA, ncol = n, nrow = 100)
mu_lin &lt;- 3:7  
mu_sq2 &lt;- (-2:2)^2 * 0.5 + 3   
a &lt;- seq(0.75, 1.25, length.out = 10)

for(i in 1:10){ 
  xpr[i,] &lt;- a[i] * rep(mu_lin, each = ni) + rnorm(n)
  xpr[i+10,] &lt;- a[i] * rep(mu_sq2, each = ni) + rnorm(n) 
} 
for(i in 21:100) xpr[i,] &lt;- 3 + rnorm(n)

dose &lt;- rep(c(0,0.01,0.05,0.2,1.5), each = ni)

# continuous representation
oldpar &lt;- par(mfrow = c(2,2))
plot(dose, xpr[4,], col = as.factor(dose), lwd = 2, ylab = "expression", main = "gene 4") 
lines(sort(unique(dose)), mu_lin * a[4], lty = 1, col = 1) 
plot(dose, xpr[14,], col = as.factor(dose), lwd = 2, ylab = "expression", main = "gene 14") 
lines(sort(unique(dose)), mu_sq2 * a[4], lty = 1, col = 1) 

# dose on ordinal scale
plot(1:length(sort(unique(dose))), ylim = range(xpr[4,]), pch = "", ylab = "expression", 
     xlab = "levels", xaxt="n")
axis(1, at = 1:length(sort(unique(dose))) ) 
points(as.factor(dose), xpr[4,], col=as.factor(dose), lwd = 2) 
lines(1:length(sort(unique(dose))), mu_lin * a[4], lty = 1)
plot(1:length(sort(unique(dose))), ylim = range(xpr[14,]), pch = "", ylab = "expression", 
     xlab = "levels", xaxt="n")
axis(1, at = 1:length(sort(unique(dose))) ) 
points(as.factor(dose), xpr[14,], col=as.factor(dose), lwd = 2) 
lines(1:length(sort(unique(dose))), mu_sq2 * a[4], lty = 1)
par(oldpar)

# calculate p-values
library(ordPens)
pvals &lt;- ordGene(xpr = xpr, lvs = dose, nsim = 1e6)

# compare distribution of (small) p-values
plot(ecdf(pvals[,1]), xlim = c(0,0.05), ylim = c(0, 0.25),
     main = "", xlab = "p-value", ylab = "F(p-value)")
plot(ecdf(pvals[,2]), xlim = c(0, 0.05), add = TRUE, col = 2)
plot(ecdf(pvals[,3]), xlim = c(0, 0.05), add = TRUE, col = 3)
legend('topleft', colnames(pvals), col = 1:3, lwd = 2, lty = 1) 

## End(Not run)
</code></pre>

<hr>
<h2 id='ordPCA'>Penalized nonlinear PCA for ordinal variables
</h2><span id='topic+ordPCA'></span>

<h3>Description</h3>

<p>This function performs nonlinear principal components analysis when the variables of interest have ordinal level scale using a second-order difference penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordPCA(H, p, lambda = c(1), maxit = 100, crit = 1e-7, qstart = NULL, 
       Ks = apply(H,2,max), constr = rep(FALSE, ncol(H)), trace = FALSE,
       CV = FALSE, k = 5, CVfit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordPCA_+3A_h">H</code></td>
<td>
<p>a matrix or data frame of of integers 1,2,... giving the observed levels
of the ordinal variables; provides the data for the principal components analysis.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_p">p</code></td>
<td>
<p>the number of principal components to be extracted.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_lambda">lambda</code></td>
<td>
<p>a numeric value or a vector (in decreasing order) defining the amount of shrinkage; defaults to 1.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_maxit">maxit</code></td>
<td>
<p>the maximum number of iterations; defaults to 100.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_crit">crit</code></td>
<td>
<p>convergence tolerance; defaults to 1e-7.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_qstart">qstart</code></td>
<td>
<p>optional list of quantifications for the initial linear PCA.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_ks">Ks</code></td>
<td>
<p>a vector containing the highest level of each variable.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_constr">constr</code></td>
<td>
<p>a logical vector specifying whether monotonicity constraints should be applied to the variables.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_trace">trace</code></td>
<td>
<p>logical; if <code>TRUE</code>, tracing information on the progress of the optimization is produced in terms of VAF in each iteration.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_cv">CV</code></td>
<td>
<p>a logical value indicating whether k-fold cross-validation should be performed in order to evaluate the
performance and/or select an optimal smoothing parameter.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_k">k</code></td>
<td>
<p>the number of folds to be specified; only if <code>CV</code> is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ordPCA_+3A_cvfit">CVfit</code></td>
<td>
<p>logical; to be specified only if <code>CV = TRUE</code>. If <code>CVfit = TRUE</code> and <code>lambda</code> is a vector of length &gt; 5, additional yes/no dialog appears;
if <code>FALSE</code>, only VAF values are provided (recommended); else, also lists of matrices of PCA results are produced and stored.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>In order to respect the ordinal scale of the data, principal components analysis is not applied to data matrix <code>H</code> itself, but to newly constructed variables by assigning numerical values &ndash; the quantifications &ndash; to the categories via penalized, optimal scaling/scoring. 
The calculation is done by alternately cycling through data scoring and PCA until convergence. 
</p>
<p>The penalty parameter controls the amount of shrinkage: For <code>lambda = 0</code>, purely nonlinear PCA via standard, optimal scaling is obtained. As <code>lambda</code> becomes very large, the quantifications are shrunken towars linearity, i.e., usual PCA is applied to levels 1,2,... ignoring the ordinal scale level of the variables. 
</p>
<p>Note that optimization starts with the first component of <code>lambda</code>. Thus, if <code>lambda</code> is not in decreasing order, the vector will be sorted internally and so will be corresponding results.
</p>
<p>In case of cross-validation, for each <code>lambda</code> the proportion of variance accounted for (VAF) is given for both the training and test data (see below).
</p>


<h3>Value</h3>

<p>A List with components:
</p>
<table>
<tr><td><code>qs</code></td>
<td>
<p>a list of quantifications, if <code>lambda</code> is specified as a single value. Otherwise, a list of matrices,
each column corresponding to a certain <code>lambda</code> value.</p>
</td></tr>
<tr><td><code>Q</code></td>
<td>
<p>data matrix after scaling, if <code>lambda</code> is scalar. Otherwise, a list of matrices with each list entry corresponding to a certain <code>lambda</code> value.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>matrix of factor values resulting from <code><a href="stats.html#topic+prcomp">prcomp</a></code>, if <code>lambda</code> is scalar. Otherwise, list of matrices.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>loadings matrix as a result from <code><a href="stats.html#topic+prcomp">prcomp</a></code>, if <code>lambda</code> is scalar. 
Otherwise, list of matrices.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations used.</p>
</td></tr>
<tr><td><code>pca</code></td>
<td>
<p>object of class <code>"prcomp"</code> returned by <code><a href="stats.html#topic+prcomp">prcomp</a></code>.</p>
</td></tr>
<tr><td><code>trace</code></td>
<td>
<p>vector of VAF values in each iteration, if <code>lambda</code> is specified as a single value. Otherwise, a list of vectors, each entry corresponding to a certain <code>lambda</code> value.</p>
</td></tr>
<tr><td><code>VAFtrain</code></td>
<td>
<p>matrix with columns corresponding to <code>lambda</code> and rows corresponding to the folds <code>k</code>.
Contains corresponding proportions of variance accounted for (VAF) on the training data within cross-validation. VAF here is defined in terms of the proportion of variance explained by the first <code>p</code> PCs.</p>
</td></tr>
<tr><td><code>VAFtest</code></td>
<td>
<p>VAF matrix for the test data within cross-validation.</p>
</td></tr> 
</table>
<p>If cross-validation is desired, the pca results are stored in a list called <code>fit</code> with each list entry corresponding to a certain fold. Within such a list entry, all sub entries can be accessed as described above. 
However, VAF values are stored in <code>VAFtrain</code> or <code>VAFtest</code> and can be accessed directly. 
</p>


<h3>Author(s)</h3>

<p>Aisouda Hoshiyar, Jan Gertheiss</p>


<h3>References</h3>

<p>Hoshiyar, A. (2020). <em>Analyzing Likert-type data using penalized non-linear principal components analysis</em>, in: Proceedings of the 35th International Workshop on Statistical Modelling, Vol. I, 337-340.
</p>
<p>Hoshiyar, A., H.A.L. Kiers, and J. Gertheiss (2021). <em>Penalized non-linear principal components analysis for ordinal variables with an application to international classification of functioning core sets</em>, British Journal of Mathematical and Statistical Psychology, 76, 353-371.
</p>
<p>Linting, M., J.J. Meulmann, A.J. von der Kooji, and P.J.F. Groenen (2007). 
<em>Nonlinear principal components analysis: Introduction and application</em>, 
Psychological Methods, 12, 336-358.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+prcomp">prcomp</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## load ICF data 
data(ICFCoreSetCWP)

# adequate coding to get levels 1,..., max 
H &lt;- ICFCoreSetCWP[, 1:67] + matrix(c(rep(1, 50), rep(5, 16), 1),
                                    nrow(ICFCoreSetCWP), 67,
                                    byrow = TRUE)
xnames &lt;- colnames(H)                                    
                                    
# nonlinear PCA
icf_pca1 &lt;- ordPCA(H, p = 2, lambda = c(5, 0.5, 0.0001), maxit = 1000, 
                   Ks = c(rep(5, 50), rep(9, 16), 5), 
                   constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE))

# estimated quantifications 
icf_pca1$qs[[55]]

plot(1:9, icf_pca1$qs[[55]][,1], type="b", 
xlab="category", ylab="quantification", col=1, main=xnames[55], 
ylim=range(c(icf_pca1$qs[[55]][,1],icf_pca1$qs[[55]][,2],icf_pca1$qs[[55]][,3])))
lines(icf_pca1$qs[[55]][,2], type = "b", col = 2, lty = 2, pch = 2, lwd=2)
lines(icf_pca1$qs[[55]][,3], type = "b", col = 3, lty = 3, pch = 3, lwd=2)

# compare VAF 
icf_pca2 &lt;- ordPCA(H, p = 2, lambda = c(5, 0.5, 0.0001), maxit = 1000, 
                   Ks = c(rep(5, 50), rep(9, 16), 5), 
                   constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE),
                   CV = TRUE, k = 5)
icf_pca2$VAFtest

## load ehd data 
require(psy)
data(ehd)

# recoding to get levels 1,..., max 
H &lt;- ehd + 1

# nonlinear PCA
ehd1 &lt;- ordPCA(H, p = 5, lambda = 0.5, maxit = 100,
               constr = rep(TRUE,ncol(H)),
               CV = FALSE)

# resulting PCA on the scaled variables
summary(ehd1$pca)

# plot quantifications
oldpar &lt;- par(mfrow = c(4,5))
for(j in 1:length(ehd1$qs))
  plot(1:5, ehd1$qs[[j]], type = "b", xlab = "level", ylab = "quantification",
  main = colnames(H)[j])
par(oldpar)

# include cross-validation
lambda &lt;- 10^seq(4,-4, by = -0.1)
set.seed(456)
cvResult &lt;- ordPCA(H, p = 5, lambda = lambda, maxit = 100,
                    constr = rep(TRUE,ncol(H)),
                    CV = TRUE, k = 5, CVfit = FALSE)
# optimal lambda                    
lambda[which.max(apply(cvResult$VAFtest,2,mean))]

## End(Not run)
</code></pre>

<hr>
<h2 id='ordPens-internal'>Internal ordPens functions</h2><span id='topic+cd'></span><span id='topic+coding'></span><span id='topic+genRidge'></span><span id='topic+ordAOV1'></span><span id='topic+ordAOV2'></span><span id='topic+crO'></span><span id='topic+penALS'></span><span id='topic+ord.glasso'></span><span id='topic+ordglasso_control'></span><span id='topic+invlink'></span><span id='topic+nloglik'></span><span id='topic+nscore'></span><span id='topic+nhessian'></span><span id='topic+smooth.construct.ordinal.smooth.spec'></span><span id='topic+Predict.matrix.ordinal.smooth'></span><span id='topic+plot.ordinal.smooth'></span>

<h3>Description</h3>

<p>Internal ordPens functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>cd(x)
coding(x, constant=TRUE, splitcod=TRUE)
genRidge(x, y, offset, omega, lambda, model, delta=1e-6, maxit=25)
ordAOV1(x, y, type, nsim, null.sample, ...)
ordAOV2(x, y, type, nsim, null.sample, ...)
crO(k, d=2)
penALS(H, p, lambda, qstart, crit, maxit, Ks, constr)
ord.glasso(x, y, lambda, weights = rep(1, length(y)), penscale = sqrt, 
              standardize = TRUE, restriction = c("refcat", "effect"), 
              nonpenx = NULL, control=ordglasso_control())
ordglasso_control(control = list())
invlink(eta)


## S3 method for class 'ordinal.smooth.spec'
smooth.construct(object, data, knots)
## S3 method for class 'ordinal.smooth'
Predict.matrix(object, data)
## S3 method for class 'ordinal.smooth'
plot(x, P=NULL, data=NULL, label="", se1.mult=1, se2.mult=2,
partial.resids=FALSE, rug=TRUE, se=TRUE, scale=-1, n=100, n2=40, n3=3,
pers=FALSE, theta=30, phi=30, jit=FALSE, xlab=NULL, ylab=NULL, main=NULL,
ylim=NULL, xlim=NULL, too.far=0.1, shade=FALSE, shade.col="gray80",
shift=0, trans=I, by.resids=FALSE, scheme=0, ...)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the user.
</p>


<h3>Author(s)</h3>

<p>Jan Gertheiss, Fabian Scheipl, Aisouda Hoshiyar</p>

<hr>
<h2 id='ordPens-package'>
Selection and/or Smoothing and Principal Components Analysis for Ordinal Variables
</h2><span id='topic+ordPens-package'></span><span id='topic+ordPens'></span>

<h3>Description</h3>

<p>Selection, and/or smoothing/fusing of ordinally scaled independent variables using 
a group lasso or generalized ridge penalty. Nonlinear principal components analysis for ordinal variables using a second-order difference penalty. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ordPens</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-07-10</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> grplasso, mgcv, RLRsim, quadprog, glmpath</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> ordinalNet</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> psy</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Smoothing and selection of ordinal predictors is done by the function 
<code><a href="#topic+ordSelect">ordSelect</a></code>; smoothing only, by <code><a href="#topic+ordSmooth">ordSmooth</a></code>; fusion and selection of ordinal predictors by <code><a href="#topic+ordFusion">ordFusion</a></code>. For
ANOVA with ordinal factors, use <code><a href="#topic+ordAOV">ordAOV</a></code>. Nonlinear PCA, performance evaluation and selection of an optimal 
penalty parameter can be done using <code><a href="#topic+ordPCA">ordPCA</a></code>.
</p>


<h3>Author(s)</h3>

<p><em>Authors:</em>
Jan Gertheiss <a href="mailto:jan.gertheiss@hsu-hh.de">jan.gertheiss@hsu-hh.de</a>,
Aisouda Hoshiyar <a href="mailto:aisouda.hoshiyar@hsu-hh.de">aisouda.hoshiyar@hsu-hh.de</a>.
</p>
<p><em>Contributors:</em>
Fabian Scheipl
</p>
<p><em>Maintainer:</em> Aisouda Hoshiyar <a href="mailto:aisouda.hoshiyar@hsu-hh.de">aisouda.hoshiyar@hsu-hh.de</a>
</p>


<h3>References</h3>

<p>Gertheiss, J. (2014). <em>ANOVA for factors with ordered levels</em>, Journal of
Agricultural, Biological and Environmental Statistics, 19, 258-277.
</p>
<p>Gertheiss, J., S. Hogger, C. Oberhauser and G. Tutz (2011). <em>Selection
of ordinally scaled independent variables with applications to international
classification of functioning core sets</em>.
Journal of the Royal Statistical Society C (Applied Statistics), 60, 377-395.
</p>
<p>Gertheiss, J. and F. Oehrlein (2011). <em>Testing relevance and linearity of
ordinal predictors</em>, Electronic Journal of Statistics, 5, 1935-1959.
</p>
<p>Gertheiss, J., F. Scheipl, T. Lauer, and H. Ehrhardt (2022). <em>Statistical 
inference for ordinal predictors in generalized linear and additive models with
application to bronchopulmonary dysplasia</em>. BMC research notes, 15, 112.
</p>
<p>Gertheiss, J. and G. Tutz (2009). <em>Penalized regression with ordinal 
predictors</em>. International Statistical Review, 77, 345-365.
</p>
<p>Gertheiss, J. and G. Tutz (2010). <em>Sparse modeling of categorial explanatory
variables</em>. The Annals of Applied Statistics, 4, 2150-2180.
</p>
<p>Hoshiyar, A., H.A.L. Kiers, and J. Gertheiss (2021). <em>Penalized non-linear principal components analysis for ordinal variables with an application to international classification of functioning core sets</em>,  British Journal of Mathematical and Statistical Psychology, 76, 353-371.
</p>
<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and    Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors &ndash; the old
question of scale level and some answers</em>. Psychometrica, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical
data</em>. Statistical Modelling, 16, 161-200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordSelect">ordSelect</a></code>, <code><a href="#topic+ordSmooth">ordSmooth</a></code>, 
<code><a href="#topic+ordFusion">ordFusion</a></code>, <code><a href="#topic+ordAOV">ordAOV</a></code>, <code><a href="#topic+ordPCA">ordPCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
### smooth modeling of a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# smooth modeling
o1 &lt;- ordSmooth(x = x, y = y, lambda = lambda)

# results
round(o1$coef,digits=3)
plot(o1)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(o1, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))


### nonlinear PCA on chronic widespread pain data 
# load example data 
data(ICFCoreSetCWP)

# adequate coding to get levels 1,..., max 
H &lt;- ICFCoreSetCWP[, 1:67] + matrix(c(rep(1, 50), rep(5, 16), 1),
                                    nrow(ICFCoreSetCWP), 67, 
                                    byrow = TRUE)

# nonlinear PCA
ordPCA(H, p = 2, lambda = 0.5, maxit = 1000,
       Ks = c(rep(5, 50), rep(9, 16), 5), 
       constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE))


# k-fold cross-validation
set.seed(1234)
lambda &lt;- 10^seq(4,-4, by = -0.1) 
cvResult1 &lt;- ordPCA(H, p = 2, lambda = lambda, maxit = 100,
       Ks = c(rep(5, 50), rep(9, 16), 5), 
       constr = c(rep(TRUE, 50), rep(FALSE, 16), TRUE),
       CV = TRUE, k = 5)
            
# optimal lambda                    
lambda[which.max(apply(cvResult1$VAFtest,2,mean))]                      

## End(Not run)
</code></pre>

<hr>
<h2 id='ordSelect'>Selection and smoothing of dummy coefficients of ordinal predictors</h2><span id='topic+ordSelect'></span>

<h3>Description</h3>

<p>Fits dummy coefficients of ordinally scaled independent variables
with a group lasso penalty on differences of adjacent dummy coefficients.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordSelect(x, y, u = NULL, z = NULL, offset = rep(0,length(y)), lambda,  
  model = c("linear", "logit", "poisson", "cumulative"), 
  restriction = c("refcat", "effect"), penscale = sqrt, scalex = TRUE, 
  nonpenx = NULL, control = NULL, eps = 1e-3, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordSelect_+3A_x">x</code></td>
<td>
<p>the matrix of ordinal predictors, with each column corresponding to
one predictor and containing numeric values from {1,2,...}; for each 
covariate, category 1 is taken as reference category with zero dummy 
coefficient.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_y">y</code></td>
<td>
<p>the response vector.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_u">u</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional categorical (nominal) 
predictors, with each column corresponding to one (additional) predictor and
containing numeric values from {1,2,...}; corresponding dummy coefficients
will not be penalized, and for each covariate category 1 is taken as reference category. Currently not supported if <code>model="cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_z">z</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional metric predictors, with 
each column corresponding to one (additional) predictor; corresponding
coefficients will not be penalized. Currently not supported if <code>model="cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_offset">offset</code></td>
<td>
<p>vector of offset values.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_lambda">lambda</code></td>
<td>
<p>vector of penalty parameters (in decreasing order).
Optimization starts with the first component. See details below.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_model">model</code></td>
<td>
<p>the model which is to be fitted. Possible choices are &quot;linear&quot;
(default), &quot;logit&quot;, &quot;poisson&quot; or &quot;cumulative&quot;. See details below.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_restriction">restriction</code></td>
<td>
<p>identifiability restriction for dummy coding. &quot;reference&quot; takes category 1 is as reference category (default), while with &quot;effect&quot; dummy coefficients sum up to 0 (known as effect coding).</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_penscale">penscale</code></td>
<td>
<p>rescaling function to adjust the value of the penalty
parameter to the degrees of freedom of the parameter group. See the
references below.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_scalex">scalex</code></td>
<td>
<p>logical. Should (split-coded) design matrix corresponding to
<code>x</code> be scaled to have unit variance over columns before fitting? See details below.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_nonpenx">nonpenx</code></td>
<td>
<p>vectors of indices indicating columns of
<code>x</code> whose regression coefficients are not penalized.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_control">control</code></td>
<td>
<p>a list of control parameters only if <code>model=="cumulative"</code>.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_eps">eps</code></td>
<td>
<p>a (small) constant to be added to the columnwise standard
deviations when scaling the design matrix, to control the effect of very small
stds. See details below.</p>
</td></tr>
<tr><td><code id="ordSelect_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that categorical covariates (contained in <code>x</code> and 
<code>u</code>) take values 1,2,...,max, where max denotes the (columnwise) highest 
level observed in the data. If any level between 1 and max is not observed for an ordinal predictor, 
a corresponding (dummy) coefficient is fitted anyway. If any level &gt; max is 
not observed but possible in principle, and a corresponding coefficient is to 
be fitted, the easiest way is to add a corresponding row to <code>x</code> (and 
<code>u</code>,<code>z</code>) with corresponding <code>y</code> value being <code>NA</code>.
</p>
<p>If a linear regression model is fitted, response vector <code>y</code> may contain 
any numeric values; if a logit model is fitted, <code>y</code> has to be 0/1 coded;
if a poisson model is fitted, <code>y</code> has to contain count data. If a cumulative   logit model is fitted, <code>y</code> takes values 1,2,...,max. 
</p>
<p>If <code>scalex</code> is <code>TRUE</code>, (split-coded) design matrix constructed from <code>x</code> is scaled to have 
unit variance over columns. If a certain <code>x</code>-category, 
however, is observed only a few times, variances may become very small and
scaling has enormous effects on the result and may cause numerical problems.
Hence a small constant <code>eps</code> can be added to each standard deviation 
when used for scaling.
</p>


<h3>Value</h3>

<p>An <code>ordPen</code> object, which is a list containing:
</p>
<table>
<tr><td><code>fitted</code></td>
<td>
<p>the matrix of fitted response values of the training data.
Columns correspond to different <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the matrix of fitted coefficients with respect to 
dummy-coded (ordinal or nominal) categorical input variables (including the 
reference category) as well as metric predictors. Columns correspond to 
different lambda values.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the type of the fitted model: &quot;linear&quot;, &quot;logit&quot;, &quot;poisson&quot;, or &quot;cumulative&quot;.</p>
</td></tr>
<tr><td><code>restriction</code></td>
<td>
<p>the type of restriction used for identifiability.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the used lambda values.</p>
</td></tr>
<tr><td><code>fraction</code></td>
<td>
<p>the used fraction values (<code>NULL</code> in case of <code>ordSelect</code>).</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>a vector giving the number of levels of the ordinal predictors.</p>
</td></tr>
<tr><td><code>ulevels</code></td>
<td>
<p>a vector giving the number of levels of the nominal predictors (if any).</p>
</td></tr>
<tr><td><code>zcovars</code></td>
<td>
<p>the number of metric covariates (if any).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jan Gertheiss, Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Gertheiss, J., S. Hogger, C. Oberhauser and G. Tutz (2011). <em>Selection
of ordinally scaled independent variables with applications to international
classification of functioning core sets</em>.
Journal of the Royal Statistical Society C (Applied Statistics), 60, 377-395.
</p>
<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and    Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Meier, L., S. van de Geer and P. Buehlmann (2008). <em>The
group lasso for logistic regression</em>. Journal of the Royal
Statistical Society B, 70, 53-71.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors &ndash; the old
question of scale level and some answers</em>. Psychometrika, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical
data</em>. Statistical Modelling, 16, 161-200.
</p>
<p>Yuan, M. and Y. Lin (2006). <em>Model selection and estimation in regression
with grouped variables</em>. Journal of the Royal Statistical Society B, 68, 49-67.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.ordPen">plot.ordPen</a></code>, <code><a href="#topic+predict.ordPen">predict.ordPen</a></code>, 
<code><a href="#topic+ICFCoreSetCWP">ICFCoreSetCWP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># smoothing and selection of ordinal covariates on a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# smoothing and selection
osl &lt;- ordSelect(x = x, y = y, lambda = lambda)

# results
round(osl$coef,digits=3)
plot(osl)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(osl, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))
</code></pre>

<hr>
<h2 id='ordSmooth'>Smoothing dummy coefficients of ordinal predictors</h2><span id='topic+ordSmooth'></span>

<h3>Description</h3>

<p>Fits dummy coefficients of ordinally scaled independent variables
with the sum of squared differences of adjacent dummy coefficients being penalized.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordSmooth(x, y, u = NULL, z = NULL, offset = rep(0,length(y)), lambda, 
  model = c("linear", "logit", "poisson"), restriction = c("refcat", "effect"),
  penscale = identity, scalex = TRUE, nonpenx = NULL, eps = 1e-3, delta = 1e-6, 
  maxit = 25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordSmooth_+3A_x">x</code></td>
<td>
<p>the matrix (or <code>data.frame</code>) of ordinal predictors, with each 
column corresponding to one predictor and containing numeric values from 
{1,2,...}; for each covariate, category 1 is taken as reference category 
with zero dummy coefficient.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_y">y</code></td>
<td>
<p>the response vector.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_u">u</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional categorical (nominal) 
predictors, with each column corresponding to one (additional) predictor 
and containing numeric values {1,2,...}; corresponding dummy coefficients
will not be penalized, and for each covariate category 1 is taken as reference category.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_z">z</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of additional metric predictors, with 
each column corresponding to one (additional) predictor; corresponding
coefficients will not be penalized.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_offset">offset</code></td>
<td>
<p>vector of offset values.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_lambda">lambda</code></td>
<td>
<p>vector of penalty parameters (in decreasing order).
Optimization starts with the first component. See details below.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_model">model</code></td>
<td>
<p>the model which is to be fitted. Possible choices are &quot;linear&quot;
(default), &quot;logit&quot; or &quot;poisson&quot;. See details below.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_restriction">restriction</code></td>
<td>
<p>identifiability restriction for dummy coding. &quot;reference&quot; takes category 1 is as reference category (default), while with &quot;effect&quot; dummy coefficients sum up to 0 (known as effect coding).</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_penscale">penscale</code></td>
<td>
<p>rescaling function to adjust the value of the penalty
parameter to the degrees of freedom of the parameter group.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_scalex">scalex</code></td>
<td>
<p>logical. Should (split-coded) design matrix corresponding to <code>x</code> be scaled to have unit variance over columns before fitting? See details below.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_nonpenx">nonpenx</code></td>
<td>
<p>vector of indices indicating columns of
<code>x</code> whose regression coefficients are not penalized.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_eps">eps</code></td>
<td>
<p>a (small) constant to be added to the columnwise standard
deviations when scaling the design matrix, to control the effect of very small
stds. See details below.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_delta">delta</code></td>
<td>
<p>a small positive convergence tolerance which is used as stopping
criterion for the penalized Fisher scoring when a logit or poisson model
is fitted. See details below.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_maxit">maxit</code></td>
<td>
<p>integer given the maximal number of (penalized) Fisher scoring
iterations.</p>
</td></tr>
<tr><td><code id="ordSmooth_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that categorical covariates (contained in <code>x</code> and 
<code>u</code>) take values 1,2,...,max, where max denotes the (columnwise) highest 
level observed in the data. If any level between 1 and max is not observed for an ordinal predictor, 
a corresponding (dummy) coefficient is fitted anyway. If any level &gt; max is 
not observed but possible, and a corresponding coefficient is to 
be fitted, the easiest way is to add a corresponding row to <code>x</code> (and 
<code>u</code>,<code>z</code>) with corresponding <code>y</code> value being <code>NA</code>.
</p>
<p>If a linear regression model is fitted, response vector <code>y</code> may contain 
any numeric values; if a logit model is fitted, <code>y</code> has to be 0/1 coded;
if a poisson model is fitted, <code>y</code> has to contain count data. 
</p>
<p>If <code>scalex</code> is <code>TRUE</code>, (split-coded) design matrix constructed from <code>x</code> is scaled to have 
unit variance over columns. If a certain <code>x</code>-category, 
however, is observed only a few times, variances may become very small and
scaling has enormous effects on the result and may cause numerical problems.
Hence a small constant <code>eps</code> can be added to each standard deviation 
when used for scaling. 
</p>
<p>A logit or poisson model is fitted by penalized Fisher scoring. For stopping 
the iterations the criterion <code>sqrt(sum((b.new-b.old)^2)/sum(b.old^2)) &lt; delta</code>
is used. 
</p>
<p>Please note, <code>ordSmooth</code> is intended for use with high-dimensional ordinal predictors; more precisely, if the number of ordinal predictors is large. Package <code>ordPens</code>, however, also includes auxiliary functions such that <code><a href="mgcv.html#topic+gam">gam</a></code> from <code><a href="mgcv.html#topic+mgcv">mgcv</a></code> can be used for fitting generalized linear and additive models with first- and second-order ordinal smoothing penalty as well as built-in smoothing parameter selection. In addition, <code><a href="mgcv.html#topic+mgcv">mgcv</a></code> tools for further statistical inference can be used. Note, however, significance of smooth (ordinal) terms is only reliable in case of the second-order penalty. Also note, if using <code><a href="mgcv.html#topic+gam">gam</a></code>, dummy coefficients/fitted functions are centered over the data observed. For details, please see Gertheiss et al. (2021) and examples below.
</p>


<h3>Value</h3>

<p>An <code>ordPen</code> object, which is a list containing:
</p>
<table>
<tr><td><code>fitted</code></td>
<td>
<p>the matrix of fitted response values of the training data. 
Columns correspond to different <code>lambda</code> values.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the matrix of fitted coefficients with respect to 
dummy-coded (ordinal or nominal) categorical input variables (including the
reference category) as well as metric predictors. Columns correspond to 
different lambda values.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the type of the fitted model: &quot;linear&quot;, &quot;logit&quot;, or &quot;poisson&quot;.</p>
</td></tr>
<tr><td><code>restriction</code></td>
<td>
<p>the type of restriction used for identifiability.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the used lambda values.</p>
</td></tr>
<tr><td><code>fraction</code></td>
<td>
<p>the used fraction values (<code>NULL</code> in case of <code>ordSmooth</code>).</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>a vector giving the number of levels of the ordinal predictors.</p>
</td></tr>
<tr><td><code>ulevels</code></td>
<td>
<p>a vector giving the number of levels of the nominal predictors (if any).</p>
</td></tr>
<tr><td><code>zcovars</code></td>
<td>
<p>the number of metric covariates (if any).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jan Gertheiss, Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Gertheiss, J., F. Scheipl, T. Lauer, and H. Ehrhardt (2022). <em>Statistical 
inference for ordinal predictors in generalized linear and additive models with
application to bronchopulmonary dysplasia</em>. BMC research notes, 15, 112.
</p>
<p>Gertheiss, J. and G. Tutz (2009). <em>Penalized regression with ordinal 
predictors</em>. International Statistical Review, 77, 345-365.
</p>
<p>Tutz, G. and J. Gertheiss (2014). <em>Rating scales as predictors &ndash; the old
question of scale level and some answers</em>. Psychometrica, 79, 357-376.
</p>
<p>Tutz, G. and J. Gertheiss (2016). <em>Regularized regression for categorical data</em>. Statistical Modelling, 16, 161-200. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.ordPen">plot.ordPen</a></code>, <code><a href="#topic+predict.ordPen">predict.ordPen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># smooth modeling of a simulated dataset
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# smooth modeling
osm1 &lt;- ordSmooth(x = x, y = y, lambda = lambda)

# results
round(osm1$coef,digits=3)
plot(osm1)

# If for a certain plot the x-axis should be annotated in a different way,
# this can (for example) be done as follows:
plot(osm1, whx = 1, xlim = c(0,9), xaxt = "n")
axis(side = 1, at = c(1,8), labels = c("no agreement","total agreement"))

# add a nominal covariate to control for
u1 &lt;- sample(1:8,100,replace=TRUE)
u &lt;- cbind(u1)
osm2 &lt;- ordSmooth(x = x, y = y, u = u, lambda = lambda)
round(osm2$coef,digits=3)


## Use gam() from mgcv for model fitting:
# ordinal predictors need to be ordered factors
x1 &lt;- as.ordered(x1)
x2 &lt;- as.ordered(x2)
x3 &lt;- as.ordered(x3)

# model fitting with first-order penalty and smoothing parameter selection by REML
gom1 &lt;- gam(y ~ s(x1, bs = "ordinal", m = 1) + s(x2, bs = "ordinal", m = 1) + 
s(x3, bs = "ordinal", m = 1) + factor(u1), method = "REML")

# plot with confidence intervals
plot(gom1)

# use second-order penalty instead
gom2 &lt;- gam(y ~ s(x1, bs = "ordinal", m = 2) + s(x2, bs = "ordinal", m = 2) + 
s(x3, bs = "ordinal", m = 2) + factor(u1), method = "REML")

# summary including significance of smooth terms
# please note, the latter is only reliable for m = 2
summary(gom2)

# plotting
plot(gom2)
</code></pre>

<hr>
<h2 id='plot.ordPen'>Plot method for ordPen objects</h2><span id='topic+plot.ordPen'></span>

<h3>Description</h3>

<p>Takes a fitted <code>ordPen</code> object and plots estimated dummy coefficients
of ordinal predictors for different <code>lambda</code> values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ordPen'
plot(x, whl = NULL, whx = NULL, 
  type = NULL, xlab = NULL, ylab = NULL, main = NULL, 
  xlim = NULL, ylim = NULL, col = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ordPen_+3A_x">x</code></td>
<td>
<p>an <code>ordPen</code> object.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_whl">whl</code></td>
<td>
<p>a vector of indices of <code>lambda</code> values corresponding
to <code>object$lambda</code> for which plotting is done; if <code>NULL</code>, all
values from <code>object$lambda</code> are considered.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_whx">whx</code></td>
<td>
<p>a vector of indices indicating the ordinal predictors whose
dummy coefficients are plotted; e.g., set <code>whx=2</code>, if you just want 
the plot for the second smooth term.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_type">type</code></td>
<td>
<p>1-character string giving the type of plot desired, see
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_xlab">xlab</code></td>
<td>
<p>a label for the x axis; if supplied then this will be used as the
x label for all plots.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_ylab">ylab</code></td>
<td>
<p>a label for the y axis; if supplied then this will be used as the
y label for all plots.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_main">main</code></td>
<td>
<p>a main title for the plot(s); if supplied then this will be used
as the title for all plots.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_xlim">xlim</code></td>
<td>
<p>the x limits; if supplied then this pair of numbers are used
as the x limits for each plot.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_ylim">ylim</code></td>
<td>
<p>the y limits; if supplied then this pair of numbers are used
as the y limits for each plot.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_col">col</code></td>
<td>
<p>the plotting color; can be a vector of the same length as
<code>whl</code> specifying different colors for different <code>lambda</code> values. Default is shades of gray: the higher <code>lambda</code> the darker.</p>
</td></tr>
<tr><td><code id="plot.ordPen_+3A_...">...</code></td>
<td>
<p>additional graphical parameters (see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>,
or  <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function simply generates plots.
</p>


<h3>Author(s)</h3>

<p>Jan Gertheiss</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordFusion">ordFusion</a></code>, <code><a href="#topic+ordSelect">ordSelect</a></code>, <code><a href="#topic+ordSmooth">ordSmooth</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># see for example
help(ordSelect)
</code></pre>

<hr>
<h2 id='predict.ordPen'>Predict method for ordPen objects</h2><span id='topic+predict.ordPen'></span>

<h3>Description</h3>

<p>Obtains predictions from an <code>ordPen</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ordPen'
predict(object, newx, newu = NULL, newz = NULL,
  offset = rep(0,nrow(as.matrix(newx))), 
  type = c("link", "response", "class"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ordPen_+3A_object">object</code></td>
<td>
<p>an <code>ordPen</code> object.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_newx">newx</code></td>
<td>
<p>the matrix (or <code>data.frame</code>) of new observations of the
considered ordinal predictors, with each column corresponding to
one predictor and containing numeric values from {1,2,...}.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_newu">newu</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of new observations of the
additional categorical (nominal) predictors, with each column corresponding
to one (additional) predictor and containing numeric values {1,2,...}.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_newz">newz</code></td>
<td>
<p>a matrix (or <code>data.frame</code>) of new observations of the
additional metric predictors, with each column corresponding to one
(additional) predictor.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_offset">offset</code></td>
<td>
<p>potential offset values.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_type">type</code></td>
<td>
<p>the type of prediction; <code>type = "link"</code> is on the
scale of linear predictors, whereas <code>type = "response"</code> is on
the scale of the response variable, i.e., <code>type = "response"</code>
applies the inverse link function to the linear predictors. <code>type = "class"</code> is only available for cumulative logit models and returns the class number with the highest fitted probability.</p>
</td></tr>
<tr><td><code id="predict.ordPen_+3A_...">...</code></td>
<td>
<p>additional arguments (not supported at this time).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions whose columns correspond to the different values of
the penalty parameter <code>lambda</code> of the <code>ordPen</code> object.
</p>


<h3>Author(s)</h3>

<p>Jan Gertheiss, Aisouda Hoshiyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordSelect">ordSelect</a></code>, <code><a href="#topic+ordSmooth">ordSmooth</a></code>, <code><a href="#topic+ordFusion">ordFusion</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># the training data
set.seed(123)

# generate (ordinal) predictors
x1 &lt;- sample(1:8,100,replace=TRUE)
x2 &lt;- sample(1:6,100,replace=TRUE)
x3 &lt;- sample(1:7,100,replace=TRUE)

# the response
y &lt;- -1 + log(x1) + sin(3*(x2-1)/pi) + rnorm(100)

# x matrix
x &lt;- cbind(x1,x2,x3)

# lambda values
lambda &lt;- c(1000,500,200,100,50,30,20,10,1)

# selecting and/or smoothing/fusing
o1 &lt;- ordSmooth(x = x, y = y, lambda = lambda)
o2 &lt;- ordSelect(x = x, y = y, lambda = lambda)
o3 &lt;- ordFusion(x = x, y = y, lambda = lambda)

# new data
x1 &lt;- sample(1:8,10,replace=TRUE)
x2 &lt;- sample(1:6,10,replace=TRUE)
x3 &lt;- sample(1:7,10,replace=TRUE)
newx &lt;- cbind(x1,x2,x3)

# prediction
round(predict(o1, newx), digits=3)
round(predict(o2, newx), digits=3)
round(predict(o3, newx), digits=3)
</code></pre>

<hr>
<h2 id='Stability.cumu'>Stability selection for ordinal-on-ordinal regression.</h2><span id='topic+Stability.cumu'></span>

<h3>Description</h3>

<p>This function performs stability selection for the cumulative logit model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stability.cumu(x, y, lambda, n_iter=100, type=c("selection", "fusion"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stability.cumu_+3A_x">x</code></td>
<td>
<p>a vector or matrix of integers 1,2,... giving the observed levels
of the ordinal factor(s). If <code>x</code> is a matrix, it is assumed that
each column corresponds to one ordinal factor.</p>
</td></tr>
<tr><td><code id="Stability.cumu_+3A_y">y</code></td>
<td>
<p>the vector of response values.</p>
</td></tr>
<tr><td><code id="Stability.cumu_+3A_lambda">lambda</code></td>
<td>
<p>vector of penalty parameters (in decreasing order).</p>
</td></tr>
<tr><td><code id="Stability.cumu_+3A_n_iter">n_iter</code></td>
<td>
<p>number of subsamples. Details below.</p>
</td></tr>
<tr><td><code id="Stability.cumu_+3A_type">type</code></td>
<td>
<p>penalty to be applied. If &quot;selection&quot;, group lasso penalty for smoothing and selection is used. If &quot;fusion&quot;, a fused lasso penalty for fusiona dn selection is used.</p>
</td></tr>
<tr><td><code id="Stability.cumu_+3A_...">...</code></td>
<td>
<p>additional arguments to <code><a href="#topic+ordFusion">ordFusion</a></code> and
<code><a href="#topic+ordSelect">ordSelect</a></code>, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes that ordinal factor levels (contained in vector/columns of
matrix <code>x</code>) take values 1,2,...,max, where max denotes the highest level
of the respective factor observed in the data. Every level between 1 and max has
to be observed at least once.
</p>
<p>Instead of selecting/fitting one model, the data are pertubed/subsampled <code>iter</code> times and we choose those variables that occur in a large fraction (<code class="reqn">pi</code>) of runs.
The stability path then shows the order of relevance of the predictors according to stability selection.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Pi</code></td>
<td>
<p>the matrix of estimated selection probabilities. Columns correspond to 
different lambda values, rows correspond to covariates.</p>
</td></tr>
<tr><td><code>mSize</code></td>
<td>
<p>matrix of size <code>n_iter</code> <code class="reqn">x</code> length(<code>lambda</code>) containing the corresponding model size.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Aisouda Hoshiyar</p>


<h3>References</h3>

<p>Hoshiyar, A., Gertheiss, L.H., and Gertheiss, J. (2023). <em>Regularization and Model Selection for Item-on-Items Regression with Applications to Food Products' Survey Data.</em> Preprint, available from https://arxiv.org/abs/2309.16373.
</p>
<p>Meinshausen, N. and Buehlmann, P. (2010). <em>Stability selection</em>, Journal of the Royal Statistical Society B (Statistical Methodology), 72, 417-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ordSelect">ordSelect</a></code>, <code><a href="#topic+ordFusion">ordFusion</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
