<!DOCTYPE html><html><head><title>Help for package BBSSL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BBSSL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BB_SSL'><p>BB-SSL</p></a></li>
<li><a href='#Generate_data'><p>Generate_data</p></a></li>
<li><a href='#Gibbs'><p>Gibbs</p></a></li>
<li><a href='#Gibbs2'><p>Gibbs2</p></a></li>
<li><a href='#plot.SSLASSO'><p>Plot coefficients from a &quot;SSLASSO&quot; object</p></a></li>
<li><a href='#SSLASSO_2'><p>The Spike-and-Slab LASSO (for BB-SSL).</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Bayesian Bootstrap Spike-and-Slab LASSO</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Posterior sampling for Spike-and-Slab LASSO prior in linear models from Nie and Rockova &lt;<a href="https://arxiv.org/abs/2011.14279">arXiv:2011.14279</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>svMisc (&ge; 1.1.0), mvnfast (&ge; 0.2.5), rmutil (&ge; 1.1.3),
greybox (&ge; 0.5.1), statmod (&ge; 1.4.30), Matrix (&ge; 1.2-17),
glmnet (&ge; 2.0-16), truncnorm (&ge; 1.0-8), methods</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-26 17:10:00 UTC; lizhennie</td>
</tr>
<tr>
<td>Author:</td>
<td>Lizhen Nie [aut, cre],
  Veronika Rockova [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lizhen Nie &lt;lizhen@uchicago.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-27 08:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='BB_SSL'>BB-SSL</h2><span id='topic+BB_SSL'></span>

<h3>Description</h3>

<p>This function runs BB-SSL, WBB with fixed prior weight, and WBB with random prior weight.
It solves the optimization by calling function SSLASSO_2, a variant of the function SSLASSO in CRAN package 'SSLASSO': in the version used,
we do NOT standardize the design matrix and allow inputting initial values of beta's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BB_SSL(y, X, method = 3, lambda, NSample, a, b, maxiter=500, eps = 1e-3, burn.in = FALSE,
length.out = 50, discard = FALSE, alpha = 3, sigma = 1, initial.beta,
penalty = "adaptive", theta=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BB_SSL_+3A_y">y</code></td>
<td>
<p>A vector of continuous responses (n x 1).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_x">X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_method">method</code></td>
<td>
<p>A number between c(1,2,3) to specify which method to run, method = 1 is fixed WBB, method = 2 is random WBB, method = 3 is BB-SSL.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_lambda">lambda</code></td>
<td>
<p>A two-dim vector = c(lambda0, lambda1).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_nsample">NSample</code></td>
<td>
<p>An integer which specifies the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_a">a</code>, <code id="BB_SSL_+3A_b">b</code></td>
<td>
<p>Parameters of the prior.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer which specifies the maximum number of iterations for SSLASSO_2 (default maxiter= 500).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_eps">eps</code></td>
<td>
<p>Convergence criterion when running SSLASSO_2: converged when difference in regression coefficients is less than eps (default eps = 0.001).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_burn.in">burn.in</code></td>
<td>
<p>A boolean to specify whether to use annealing on a sequence of lambda0's (default burn.in = FALSE).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_length.out">length.out</code></td>
<td>
<p>An integer to specify the length of sequence of lambda0's used in annealing. This value is not used when burn.in = FALSE. Default is 50.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_discard">discard</code></td>
<td>
<p>A boolean to specify whether to discard unconverged sample points.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_alpha">alpha</code></td>
<td>
<p>The parameter for generating weights in BB-SSL, which follows n x Dirichlet(alpha,...,alpha). Default is 3.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_sigma">sigma</code></td>
<td>
<p>Noise standard deviation.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_initial.beta">initial.beta</code></td>
<td>
<p>A vector of initial values of beta to used when solving SSLASSO_2 (n x 1).</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_penalty">penalty</code></td>
<td>
<p>The penalty (prior) to be applied to the model. Either &quot;separable&quot; (with a fixed theta) or &quot;adaptive&quot; (with a random theta, where theta ~ B(a,p)). The default is &quot;adaptive&quot;.</p>
</td></tr>
<tr><td><code id="BB_SSL_+3A_theta">theta</code></td>
<td>
<p>Prior mixing proportion. For &quot;separable&quot; penalty, this value is fixed. For &quot;adaptive&quot; penalty, this value is used as a starting value. Default is 0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of matrices, including matrix beta (NSample x p) and matrix gamma (NSample x p).
</p>


<h3>Author(s)</h3>

<p>Lizhen Nie <a href="mailto:lizhen@statistics.uchicago.edu">lizhen@statistics.uchicago.edu</a>, Veronika Rockova <a href="mailto:Veronika.Rockova@chicagobooth.edu">Veronika.Rockova@chicagobooth.edu</a>
</p>


<h3>References</h3>

<p>Nie, L., &amp; Ročková, V. (2020). Bayesian Bootstrap Spike-and-Slab LASSO. arXiv:2011.14279.
</p>
<p>Newton, M. A., Polson, N. G., and Xu, J. (2020). Weighted Bayesian bootstrap for scalable
posterior distributions. Canadian Journal of Statistics (In Press).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># -------------- Generate Data --------------
n = 50; p = 12;
truth.beta = c(1.3, 1.3, 1.3, 1.3);
truth.sigma = 1
data = Generate_data(truth.beta, p, n, truth.sigma = 1, rho = 0.6,"block",4)
y = data$y; X = data$X; beta = data$beta

# --------------- set parameters -----------------
lambda0 = 7; lambda1 = 0.15; lambda = c(lambda0, lambda1)
a = 1; b = p #beta prior for theta



#--------------- BB-SSL -------------
# this is for demonstration of usage only
# in practice, you may want to use more iterations!
BB.SSL.result = BB_SSL(y, X, method = 3, lambda = c(lambda0, lambda1), NSample = 100, a, b,
maxiter = 500, length.out = 50, burn.in = FALSE, discard = TRUE, alpha=1,
initial.beta = rep(0,p))

# Alternatively, you can use SSLASSO_2 solution to get an initial value of beta's
result = SSLASSO_2(X, y, penalty = "adaptive", variance = "fixed", sigma = truth.sigma,
                   lambda1 = lambda1, lambda0 = seq(lambda1, lambda0, length.out = 50),
                   a = a, b = b,
                   max.iter = 500, initial.beta = rep(0,p))

fixed.WBB.result = BB_SSL(y, X, method = 1, lambda = c(lambda0, lambda1), NSample = 100,
                          a, b, maxiter = 500, length.out = 50, burn.in = FALSE,
                          discard = TRUE, initial.beta = result$beta[,50])

random.WBB.result = BB_SSL(y, X, method = 2, lambda = c(lambda0, lambda1), NSample = 100,
                           a, b, maxiter = 500, length.out = 50, burn.in = FALSE,
                           discard = TRUE, initial.beta = result$beta[,50])

BB.SSL.result = BB_SSL(y, X, method = 3, lambda = c(lambda0, lambda1), NSample = 100, a,
                       b, maxiter = 500, length.out = 50, burn.in = FALSE, discard = TRUE,
                       alpha=1, initial.beta = result$beta[,50])

</code></pre>

<hr>
<h2 id='Generate_data'>Generate_data</h2><span id='topic+Generate_data'></span>

<h3>Description</h3>

<p>This function generates data (X,y) with specified correlation and noise standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Generate_data(truth.beta, p, n, truth.sigma, rho, correlation = c("block", "all"),
NumOfBlock)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Generate_data_+3A_truth.beta">truth.beta</code></td>
<td>
<p>A vector of active beta's (s x 1, with s being the number of active coordinates).</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_p">p</code></td>
<td>
<p>The number of covariates.</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_truth.sigma">truth.sigma</code></td>
<td>
<p>Noise standard deviation.</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_rho">rho</code></td>
<td>
<p>Correlation Coefficient.</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_correlation">correlation</code></td>
<td>
<p>Correlation structure. Correlation = &quot;block&quot; means predictors are grouped into equi-size blocks where each block contains one active predictor, and the within-block correlation coefficient is rho; predictors in different blocks are mutually independent. Correlation = &quot;all&quot; means all predictors are equi-correlated with coefficient rho.</p>
</td></tr>
<tr><td><code id="Generate_data_+3A_numofblock">NumOfBlock</code></td>
<td>
<p>Number of blocks, used only when correlation = 'block'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, including vector 'y' (n x 1), matrix 'X' (n x p), vector 'beta' (p x 1).
</p>

<hr>
<h2 id='Gibbs'>Gibbs</h2><span id='topic+Gibbs'></span>

<h3>Description</h3>

<p>This function runs SSVS for linear regression with Spike-and-Slab LASSO prior.
By default, this function uses the speed-up trick in Bhattacharya et al. (2016) when p &gt; n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gibbs(y, X, a, b, lambda, maxiter, burn.in, initial.beta = NULL, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gibbs_+3A_y">y</code></td>
<td>
<p>A vector of continuous responses (n x 1).</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_x">X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_a">a</code>, <code id="Gibbs_+3A_b">b</code></td>
<td>
<p>Parameters of the prior.</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_lambda">lambda</code></td>
<td>
<p>A two-dim vector = c(lambda0, lambda1).</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer which specifies the maximum number of iterations for MCMC.</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_burn.in">burn.in</code></td>
<td>
<p>An integer which specifies the maximum number of burn-in iterations for MCMC.</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_initial.beta">initial.beta</code></td>
<td>
<p>A vector of initial values of beta to used. If set to NULL, the LASSO solution with 10-fold cross validation is used. Default is NULL.</p>
</td></tr>
<tr><td><code id="Gibbs_+3A_sigma">sigma</code></td>
<td>
<p>Noise standard deviation. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, including matrix 'beta' ((maxiter-burn.in) x p), matrix 'tau2' ((maxiter-burn.in) x p),
matrix 'gamma' ((maxiter-burn.in) x p), vector 'theta' ((maxiter-burn.in) x 1).
</p>


<h3>Author(s)</h3>

<p>Lizhen Nie <a href="mailto:lizhen@statistics.uchicago.edu">lizhen@statistics.uchicago.edu</a>, Veronika Rockova <a href="mailto:Veronika.Rockova@chicagobooth.edu">Veronika.Rockova@chicagobooth.edu</a>
</p>


<h3>References</h3>

<p>Nie, L., &amp; Ročková, V. (2020). Bayesian Bootstrap Spike-and-Slab LASSO. arXiv:2011.14279.
</p>
<p>Bhattacharya, A., Chakraborty, A., &amp; Mallick, B. K. (2016). Fast sampling with Gaussian scale mixture priors in high-dimensional regression. Biometrika, 103(4):985.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50; p = 12;
truth.beta = c(1.3, 1.3, 1.3, 1.3);
truth.sigma = 1
data = Generate_data(truth.beta, p, n, truth.sigma = 1, rho = 0.6,"block",4)
y = data$y; X = data$X; beta = data$beta

# --------------- set parameters -----------------
lambda0 = 7; lambda1 = 0.15; lambda = c(lambda0, lambda1)
a = 1; b = p #beta prior for theta

# this is for demonstration of usage only
# in practice, you may want to use more iterations!
MCchain1 = Gibbs(y, X, a, b, lambda, maxiter = 1000, burn.in = 100)
</code></pre>

<hr>
<h2 id='Gibbs2'>Gibbs2</h2><span id='topic+Gibbs2'></span>

<h3>Description</h3>

<p>This function runs one-site Gibbs sampler for linear regression with Spike-and-Slab LASSO prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gibbs2(y, X, a, b, lambda, maxiter, burn.in, initial.beta = NULL, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gibbs2_+3A_y">y</code></td>
<td>
<p>A vector of continuous responses (n x 1).</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_x">X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_a">a</code>, <code id="Gibbs2_+3A_b">b</code></td>
<td>
<p>Parameters of the prior.</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_lambda">lambda</code></td>
<td>
<p>A two-dim vector = c(lambda0, lambda1).</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_maxiter">maxiter</code></td>
<td>
<p>An integer which specifies the maximum number of iterations for MCMC.</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_burn.in">burn.in</code></td>
<td>
<p>An integer which specifies the number of burn-in iterations for MCMC.</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_initial.beta">initial.beta</code></td>
<td>
<p>A vector of initial values of beta to used. If set to NULL, the LASSO solution with 10-fold cross validation is used. Default is NULL.</p>
</td></tr>
<tr><td><code id="Gibbs2_+3A_sigma">sigma</code></td>
<td>
<p>Noise standard deviation. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, including matrix beta ((maxiter-burn.in) x p) and matrix gamma (maxiter-burn.in) x p, vector theta ((maxiter-burn.in) x 1)
</p>


<h3>Author(s)</h3>

<p>Lizhen Nie <a href="mailto:lizhen@statistics.uchicago.edu">lizhen@statistics.uchicago.edu</a>, Veronika Rockova <a href="mailto:Veronika.Rockova@chicagobooth.edu">Veronika.Rockova@chicagobooth.edu</a>
</p>


<h3>References</h3>

<p>Nie, L., &amp; Ročková, V. (2020). Bayesian Bootstrap Spike-and-Slab LASSO. arXiv:2011.14279.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50; p = 12;
truth.beta = c(1.3, 1.3, 1.3, 1.3);
truth.sigma = 1
data = Generate_data(truth.beta, p, n, truth.sigma = 1, rho = 0.6,"block",4)
y = data$y; X = data$X; beta = data$beta

# --------------- set parameters -----------------
lambda0 = 7; lambda1 = 0.15; lambda = c(lambda0, lambda1)
a = 1; b = p #beta prior for theta

# this is for demonstration of usage only
# in practice, you may want to use more iterations!
MCchain2 = Gibbs2(y, X, a, b, lambda, maxiter = 1000, burn.in = 100)
</code></pre>

<hr>
<h2 id='plot.SSLASSO'>Plot coefficients from a &quot;SSLASSO&quot; object</h2><span id='topic+plot.SSLASSO'></span>

<h3>Description</h3>

<p>Produces a plot of the coefficient paths for a fitted
<code>"SSLASSO"</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SSLASSO'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SSLASSO_+3A_x">x</code></td>
<td>
<p>Fitted <code>"SSLASSO"</code> model.</p>
</td></tr>
<tr><td><code id="plot.SSLASSO_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the coefficient paths for a fitted &quot;SSLASSO&quot; object.</p>


<h3>References</h3>

<p>Rockova, V. and George, E.I. (2018) The Spike-and-Slab LASSO. Journal of the American Statistical Association.</p>


<h3>See Also</h3>

<p><code><a href="#topic+SSLASSO_2">SSLASSO_2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Linear regression, where p&gt;n

n = 100; p = 1000;
truth.beta = c(2, 3, -3, 4); # high-dimensional case
truth.sigma = 1
data = Generate_data(truth.beta, p, n, truth.sigma = 1, rho = 0.6,"all", 4)
y = data$y; X = data$X; beta = data$beta

# --------------- set parameters -----------------
lambda0 = 50; lambda1 = 0.05; lambda = c(lambda0, lambda1)
a = 1; b = p #beta prior for theta


# Separable penalty with fixed theta

result&lt;-SSLASSO_2(X, y,penalty="separable", variance = "fixed",
lambda1 = lambda1, lambda0 = seq(from=lambda1,to=lambda0,length.out=50),
theta = 4/p,initial.beta = rep(0,p))

plot(result)

</code></pre>

<hr>
<h2 id='SSLASSO_2'>The Spike-and-Slab LASSO (for BB-SSL).</h2><span id='topic+SSLASSO_2'></span>

<h3>Description</h3>

<p>Spike-and-Slab LASSO is a spike-and-slab refinement of the LASSO procedure, using a mixture of Laplace priors indexed by  <code>lambda0</code> (spike) and <code>lambda1</code> (slab).
</p>
<p>The <code>SSLASSO</code> procedure fits coefficients paths for Spike-and-Slab LASSO-penalized
linear regression models over a grid of values for the regularization
parameter <code>lambda0</code>. The code has been adapted from the <code>SSLASSO</code> package (Rockova, V. and Moran, G. (2019). Package ‘SSLASSO’.) such that now it does NOT normalize each column and allows specifying initialization value). </p>


<h3>Usage</h3>

<pre><code class='language-R'>SSLASSO_2(X, y, initial.beta, penalty = c("adaptive", "separable"),
variance = c("fixed", "unknown"), lambda1, lambda0, nlambda = 100,
theta = 0.5, sigma = 1, a = 1, b, eps = 0.001, max.iter = 500,
counter = 10, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSLASSO_2_+3A_x">X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.  <code>SSLASSO</code>
standardizes the data by default.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_y">y</code></td>
<td>
<p>Vector of continuous responses (n x 1). The responses will be centered by default.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_initial.beta">initial.beta</code></td>
<td>
<p>Initial value for beta when searching for the solution.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  Either &quot;separable&quot;
(with a fixed <code>theta</code>) or &quot;adaptive&quot; (with a random <code>theta</code>, where <code>theta ~ B(a,p)</code>). The default is <code>"adaptive"</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_variance">variance</code></td>
<td>
<p>Whether the error variance is also estimated. Either &quot;fixed&quot; (with a fixed <code>sigma</code>) or &quot;unknown&quot; (with a random <code>sigma</code>, where <code>p(sigma) ~ 1/sigma</code>). The default is <code>"fixed"</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_lambda1">lambda1</code></td>
<td>
<p>Slab variance parameter. Needs to be less than <code>lambda0</code>. The default is <code>lambda0 = 1</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_lambda0">lambda0</code></td>
<td>
<p>Spike penalty parameters (L x 1). Either a numeric value for a single run (L=1) or a sequence of increasing values for dynamic posterior exploration. The default is <code>lambda0 = seq(1, nrow(X), length.out = 100)</code>.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda0</code> values. Default is 100.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_theta">theta</code></td>
<td>
<p>Prior mixing proportion. For &quot;separable&quot; penalty, this value is fixed. For &quot;adaptive&quot; penalty, this value is used as a starting value.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_sigma">sigma</code></td>
<td>
<p>Error variance. For &quot;fixed&quot; variance, this value is fixed. For &quot;unknown&quot; variance, this value is used as a starting value.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_a">a</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>a = 1</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_b">b</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>b = ncol(X)</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_eps">eps</code></td>
<td>
<p>Convergence criterion: converged when difference in regression coefficients is less than <code>eps</code> (default <code>eps = 0.001</code>).</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations.  Default is 500.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_counter">counter</code></td>
<td>
<p>Applicable only for the adaptive penalty. Determines how often the parameter <code>theta</code> is updated throughout the cycles of coordinate ascent. Default is 10.</p>
</td></tr>
<tr><td><code id="SSLASSO_2_+3A_warn">warn</code></td>
<td>
<p>TRUE if warnings should be printed; FALSE by default</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter
<code>lambda0</code> is fitted using a coordinate descent algorithm. The algorithm uses
screening rules for discarding irrelevant predictors along the lines of Breheny (2011).
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"SSLASSO"</code> containing:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients (p x L).  The number of rows is
equal to the number of coefficients <code>p</code>, and the number of columns is
equal to <code>L</code> (the length of <code>lambda0</code>).</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>A vector of length <code>L</code> containing the intercept for each value of <code>lambda0</code>. The intercept is <code>intercept = mean(y) - crossprod(XX, beta)</code>, where <code>XX</code> is the centered design matrix.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>L</code> containing the number
of iterations until convergence at each value of <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>lambda0</code></td>
<td>
<p>The sequence of regularization parameter values in the
path.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>thetas</code></td>
<td>
<p>A vector of length <code>L</code> containing the hyper-parameter values <code>theta</code> (the same as <code>theta</code> for &quot;separable&quot; penalty).</p>
</td></tr>
<tr><td><code>sigmas</code></td>
<td>
<p>A vector of length <code>L</code> containing the values <code>sigma</code> (the same as the initial <code>sigma</code> for &quot;known&quot; variance).</p>
</td></tr>
<tr><td><code>select</code></td>
<td>
<p>A (p x L) binary matrix indicating which variables were selected along the solution path.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>A single model chosen after the stabilization of the regularization path.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rockova, V. and George, E.I. (2018) The Spike-and-Slab LASSO. Journal of the American Statistical Association.
</p>
<p>Moran, G., Rockova, V. and George, E.I. (2018) On variance estimation for Bayesian variable selection. &lt;https://arxiv.org/abs/1801.03019&gt;.
</p>
<p>Nie, L., &amp; Ročková, V. (2020). Bayesian Bootstrap Spike-and-Slab LASSO. arXiv:2011.14279.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Linear regression, where p &gt; n

p &lt;- 1000
n &lt;- 100

X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)
beta &lt;- c(1, 2, 3, rep(0, p-3))
y = X[,1] * beta[1] + X[,2] * beta[2] + X[,3] * beta[3] + rnorm(n)

# Oracle SSLASSO with known variance

result1 &lt;- SSLASSO_2(X, y, penalty = "separable", theta = 3/p, initial.beta = rep(0,p))
plot(result1)

# Adaptive SSLASSO with known variance

result2 &lt;- SSLASSO_2(X, y, initial.beta = rep(0,p))
plot(result2)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
