<!DOCTYPE html><html><head><title>Help for package tfaddons</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfaddons}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#activation_gelu'><p>Gelu</p></a></li>
<li><a href='#activation_hardshrink'><p>Hardshrink</p></a></li>
<li><a href='#activation_lisht'><p>Lisht</p></a></li>
<li><a href='#activation_mish'><p>Mish</p></a></li>
<li><a href='#activation_rrelu'><p>Rrelu</p></a></li>
<li><a href='#activation_softshrink'><p>Softshrink</p></a></li>
<li><a href='#activation_sparsemax'><p>Sparsemax</p></a></li>
<li><a href='#activation_tanhshrink'><p>Tanhshrink</p></a></li>
<li><a href='#attention_bahdanau'><p>Bahdanau Attention</p></a></li>
<li><a href='#attention_bahdanau_monotonic'><p>Bahdanau Monotonic Attention</p></a></li>
<li><a href='#attention_luong'><p>Implements Luong-style (multiplicative) attention scoring.</p></a></li>
<li><a href='#attention_luong_monotonic'><p>Monotonic attention mechanism with Luong-style energy function.</p></a></li>
<li><a href='#attention_monotonic'><p>Monotonic attention</p></a></li>
<li><a href='#attention_wrapper'><p>Attention Wrapper</p></a></li>
<li><a href='#attention_wrapper_state'><p>Attention Wrapper State</p></a></li>
<li><a href='#callback_average_model_checkpoint'><p>Average Model Checkpoint</p></a></li>
<li><a href='#callback_time_stopping'><p>Time Stopping</p></a></li>
<li><a href='#callback_tqdm_progress_bar'><p>TQDM Progress Bar</p></a></li>
<li><a href='#crf_binary_score'><p>CRF binary score</p></a></li>
<li><a href='#crf_decode'><p>CRF decode</p></a></li>
<li><a href='#crf_decode_backward'><p>CRF decode backward</p></a></li>
<li><a href='#crf_decode_forward'><p>CRF decode forward</p></a></li>
<li><a href='#crf_forward'><p>CRF forward</p></a></li>
<li><a href='#crf_log_likelihood'><p>CRF log likelihood</p></a></li>
<li><a href='#crf_log_norm'><p>CRF log norm</p></a></li>
<li><a href='#crf_multitag_sequence_score'><p>CRF multitag sequence score</p></a></li>
<li><a href='#crf_sequence_score'><p>CRF sequence score</p></a></li>
<li><a href='#crf_unary_score'><p>CRF unary score</p></a></li>
<li><a href='#decode_dynamic'><p>Dynamic decode</p></a></li>
<li><a href='#decoder'><p>An RNN Decoder abstract interface object.</p></a></li>
<li><a href='#decoder_base'><p>Base Decoder</p></a></li>
<li><a href='#decoder_basic'><p>Basic Decoder</p></a></li>
<li><a href='#decoder_basic_output'><p>Basic decoder output</p></a></li>
<li><a href='#decoder_beam_search'><p>BeamSearch sampling decoder</p></a></li>
<li><a href='#decoder_beam_search_output'><p>Beam Search Decoder Output</p></a></li>
<li><a href='#decoder_beam_search_state'><p>Beam Search Decoder State</p></a></li>
<li><a href='#decoder_final_beam_search_output'><p>Final Beam Search Decoder Output</p></a></li>
<li><a href='#extend_with_decoupled_weight_decay'><p>Factory function returning an optimizer class with decoupled weight decay</p></a></li>
<li><a href='#gather_tree'><p>Gather tree</p></a></li>
<li><a href='#gather_tree_from_array'><p>Gather tree from array</p></a></li>
<li><a href='#hardmax'><p>Hardmax</p></a></li>
<li><a href='#img_adjust_hsv_in_yiq'><p>Adjust hsv in yiq</p></a></li>
<li><a href='#img_angles_to_projective_transforms'><p>Angles to projective transforms</p></a></li>
<li><a href='#img_blend'><p>Blend</p></a></li>
<li><a href='#img_compose_transforms'><p>Compose transforms</p></a></li>
<li><a href='#img_connected_components'><p>Connected components</p></a></li>
<li><a href='#img_cutout'><p>Cutout</p></a></li>
<li><a href='#img_dense_image_warp'><p>Dense image warp</p></a></li>
<li><a href='#img_equalize'><p>Equalize</p></a></li>
<li><a href='#img_euclidean_dist_transform'><p>Euclidean dist transform</p></a></li>
<li><a href='#img_flat_transforms_to_matrices'><p>Flat transforms to matrices</p></a></li>
<li><a href='#img_from_4D'><p>From 4D image</p></a></li>
<li><a href='#img_get_ndims'><p>Get ndims</p></a></li>
<li><a href='#img_interpolate_bilinear'><p>Interpolate bilinear</p></a></li>
<li><a href='#img_interpolate_spline'><p>Interpolate spline</p></a></li>
<li><a href='#img_matrices_to_flat_transforms'><p>Matrices to flat transforms</p></a></li>
<li><a href='#img_mean_filter2d'><p>Mean filter2d</p></a></li>
<li><a href='#img_median_filter2d'><p>Median filter2d</p></a></li>
<li><a href='#img_random_cutout'><p>Random cutout</p></a></li>
<li><a href='#img_random_hsv_in_yiq'><p>Random hsv in yiq</p></a></li>
<li><a href='#img_resampler'><p>Resampler</p></a></li>
<li><a href='#img_rotate'><p>Rotate</p></a></li>
<li><a href='#img_sharpness'><p>Sharpness</p></a></li>
<li><a href='#img_shear_x'><p>Shear x-axis</p></a></li>
<li><a href='#img_shear_y'><p>Shear y-axis</p></a></li>
<li><a href='#img_sparse_image_warp'><p>Sparse image warp</p></a></li>
<li><a href='#img_to_4D'><p>To 4D image</p></a></li>
<li><a href='#img_transform'><p>Transform</p></a></li>
<li><a href='#img_translate'><p>Translate</p></a></li>
<li><a href='#img_translate_xy'><p>Translate xy dims</p></a></li>
<li><a href='#img_translations_to_projective_transforms'><p>Translations to projective transforms</p></a></li>
<li><a href='#img_unwrap'><p>Uwrap</p></a></li>
<li><a href='#img_wrap'><p>Wrap</p></a></li>
<li><a href='#install_tfaddons'><p>Install TensorFlow SIG Addons</p></a></li>
<li><a href='#layer_activation_gelu'><p>Gaussian Error Linear Unit</p></a></li>
<li><a href='#layer_correlation_cost'><p>Correlation Cost Layer.</p></a></li>
<li><a href='#layer_filter_response_normalization'><p>FilterResponseNormalization</p></a></li>
<li><a href='#layer_group_normalization'><p>Group normalization layer</p></a></li>
<li><a href='#layer_instance_normalization'><p>Instance normalization layer</p></a></li>
<li><a href='#layer_maxout'><p>Maxout layer</p></a></li>
<li><a href='#layer_multi_head_attention'><p>Keras-based multi head attention layer</p></a></li>
<li><a href='#layer_nas_cell'><p>Neural Architecture Search (NAS) recurrent network cell.</p></a></li>
<li><a href='#layer_norm_lstm_cell'><p>LSTM cell with layer normalization and recurrent dropout.</p></a></li>
<li><a href='#layer_poincare_normalize'><p>Project into the Poincare ball with norm &lt;= 1.0 - epsilon</p></a></li>
<li><a href='#layer_sparsemax'><p>Sparsemax activation function</p></a></li>
<li><a href='#layer_weight_normalization'><p>Weight Normalization layer</p></a></li>
<li><a href='#lookahead_mechanism'><p>Lookahead mechanism</p></a></li>
<li><a href='#loss_contrastive'><p>Contrastive loss</p></a></li>
<li><a href='#loss_giou'><p>Implements the GIoU loss function.</p></a></li>
<li><a href='#loss_hamming'><p>Hamming loss</p></a></li>
<li><a href='#loss_lifted_struct'><p>Lifted structured loss</p></a></li>
<li><a href='#loss_npairs'><p>Npairs loss</p></a></li>
<li><a href='#loss_npairs_multilabel'><p>Npairs multilabel loss</p></a></li>
<li><a href='#loss_pinball'><p>Pinball loss</p></a></li>
<li><a href='#loss_sequence'><p>Weighted cross-entropy loss for a sequence of logits.</p></a></li>
<li><a href='#loss_sigmoid_focal_crossentropy'><p>Sigmoid focal crossentropy loss</p></a></li>
<li><a href='#loss_sparsemax'><p>Sparsemax loss</p></a></li>
<li><a href='#loss_triplet_hard'><p>Triplet hard loss</p></a></li>
<li><a href='#loss_triplet_semihard'><p>Triplet semihard loss</p></a></li>
<li><a href='#metric_cohen_kappa'><p>Computes Kappa score between two raters</p></a></li>
<li><a href='#metric_fbetascore'><p>FBetaScore</p></a></li>
<li><a href='#metric_hamming_distance'><p>Hamming distance</p></a></li>
<li><a href='#metric_mcc'><p>MatthewsCorrelationCoefficient</p></a></li>
<li><a href='#metric_multilabel_confusion_matrix'><p>MultiLabelConfusionMatrix</p></a></li>
<li><a href='#metric_rsquare'><p>RSquare</p>
</p>
<p>This is also called as coefficient of determination. It tells how close</p>
are data to the fitted regression line. Highest score can be 1.0 and it
indicates that the predictors perfectly accounts for variation in the target.
Score 0.0 indicates that the predictors do not account for variation in the
target. It can also be negative if the model is worse.</a></li>
<li><a href='#metrics_f1score'><p>F1Score</p></a></li>
<li><a href='#optimizer_conditional_gradient'><p>Conditional Gradient</p></a></li>
<li><a href='#optimizer_decay_adamw'><p>Optimizer that implements the Adam algorithm with weight decay</p></a></li>
<li><a href='#optimizer_decay_sgdw'><p>Optimizer that implements the Momentum algorithm with weight_decay</p></a></li>
<li><a href='#optimizer_lamb'><p>Layer-wise Adaptive Moments</p></a></li>
<li><a href='#optimizer_lazy_adam'><p>Lazy Adam</p></a></li>
<li><a href='#optimizer_moving_average'><p>Moving Average</p></a></li>
<li><a href='#optimizer_novograd'><p>NovoGrad</p></a></li>
<li><a href='#optimizer_radam'><p>Rectified Adam (a.k.a. RAdam)</p></a></li>
<li><a href='#optimizer_swa'><p>Stochastic Weight Averaging</p></a></li>
<li><a href='#optimizer_yogi'><p>Yogi</p></a></li>
<li><a href='#parse_time'><p>Parse time</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#register_all'><p>Register all</p></a></li>
<li><a href='#register_custom_kernels'><p>Register custom kernels</p></a></li>
<li><a href='#register_keras_objects'><p>Register keras objects</p></a></li>
<li><a href='#safe_cumprod'><p>Safe cumprod</p></a></li>
<li><a href='#sample_bernoulli'><p>Bernoulli sample</p></a></li>
<li><a href='#sample_categorical'><p>Categorical sample</p></a></li>
<li><a href='#sampler'><p>Sampler</p></a></li>
<li><a href='#sampler_custom'><p>Base abstract class that allows the user to customize sampling.</p></a></li>
<li><a href='#sampler_greedy_embedding'><p>Greedy Embedding Sampler</p></a></li>
<li><a href='#sampler_inference'><p>Inference Sampler</p></a></li>
<li><a href='#sampler_sample_embedding'><p>Sample Embedding Sampler</p></a></li>
<li><a href='#sampler_scheduled_embedding_training'><p>A training sampler that adds scheduled sampling</p></a></li>
<li><a href='#sampler_scheduled_output_training'><p>Scheduled Output Training Sampler</p></a></li>
<li><a href='#sampler_training'><p>A Sampler for use during training.</p></a></li>
<li><a href='#skip_gram_sample'><p>Skip gram sample</p></a></li>
<li><a href='#skip_gram_sample_with_text_vocab'><p>Skip gram sample with text vocab</p></a></li>
<li><a href='#tfaddons_version'><p>Version of TensorFlow SIG Addons</p></a></li>
<li><a href='#tile_batch'><p>Tile batch</p></a></li>
<li><a href='#viterbi_decode'><p>Viterbi decode</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interface to 'TensorFlow SIG Addons'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.10.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Turgut Abdullayev &lt;turqut.a.314@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>'TensorFlow SIG Addons' <a href="https://www.tensorflow.org/addons">https://www.tensorflow.org/addons</a> is a repository 
             of community contributions that conform to well-established API patterns, 
             but implement new functionality not available in core 'TensorFlow'. 
             'TensorFlow' natively supports a large number of operators, layers, metrics, 
             losses, optimizers, and more. However, in a fast moving field like Machine Learning, 
             there are many interesting new developments that cannot be integrated into 
             core 'TensorFlow' (because their broad applicability is not yet clear, or 
             it is mostly used by a smaller subset of the community).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/henry090/tfaddons">https://github.com/henry090/tfaddons</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/henry090/tfaddons/issues">https://github.com/henry090/tfaddons/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>TensorFlow &gt;= 2.0 (https://www.tensorflow.org/)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate, tensorflow, rstudioapi, keras, purrr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, dplyr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-25 15:30:15 UTC; turgutabdullayev</td>
</tr>
<tr>
<td>Author:</td>
<td>Turgut Abdullayev [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-02 08:50:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='activation_gelu'>Gelu</h2><span id='topic+activation_gelu'></span>

<h3>Description</h3>

<p>Gaussian Error Linear Unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_gelu(x, approximate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_gelu_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
<tr><td><code id="activation_gelu_+3A_approximate">approximate</code></td>
<td>
<p>bool, whether to enable approximation. Returns: A 'Tensor'. Has the same type as 'x'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes gaussian error linear:
'0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3)))' or
'x * P(X &lt;= x) = 0.5 * x * (1 + erf(x / sqrt(2)))', where P(X) ~ N(0, 1),
depending on whether approximation is enabled.
See [Gaussian Error Linear Units (GELUs)](https://arxiv.org/abs/1606.08415)
and [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805).
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>


<h3>Computes gaussian error linear</h3>

<p>'0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3)))' or 'x * P(X &lt;= x) = 0.5 * x * (1 + erf(x / sqrt(2)))',
where P(X) ~ N(0, 1), depending on whether approximation is enabled.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(keras)
library(tfaddons)
model = keras_model_sequential() %&gt;%
layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
              activation = activation_gelu)

## End(Not run)


</code></pre>

<hr>
<h2 id='activation_hardshrink'>Hardshrink</h2><span id='topic+activation_hardshrink'></span>

<h3>Description</h3>

<p>Hard shrink function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_hardshrink(x, lower = -0.5, upper = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_hardshrink_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
<tr><td><code id="activation_hardshrink_+3A_lower">lower</code></td>
<td>
<p>'float', lower bound for setting values to zeros.</p>
</td></tr>
<tr><td><code id="activation_hardshrink_+3A_upper">upper</code></td>
<td>
<p>'float', upper bound for setting values to zeros. Returns: A 'Tensor'. Has the same type as 'x'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes hard shrink function:
'x if x &lt; lower or x &gt; upper else 0'.
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>


<h3>Computes hard shrink function</h3>

<p>'x if x &lt; lower or x &gt; upper else 0'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(keras)
library(tfaddons)
model = keras_model_sequential() %&gt;%
layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
              activation = activation_hardshrink)

## End(Not run)

</code></pre>

<hr>
<h2 id='activation_lisht'>Lisht</h2><span id='topic+activation_lisht'></span>

<h3>Description</h3>

<p>LiSHT: Non-Parameteric Linearly Scaled Hyperbolic Tangent Activation Function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_lisht(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_lisht_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes linearly scaled hyperbolic tangent (LiSHT): 'x * tanh(x)'
See [LiSHT: Non-Parameteric Linearly Scaled Hyperbolic Tangent Activation Function for Neural Networks](https://arxiv.org/abs/1901.05894).
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(keras)
library(tfaddons)
model = keras_model_sequential() %&gt;%
layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
              activation = activation_lisht)

## End(Not run)

</code></pre>

<hr>
<h2 id='activation_mish'>Mish</h2><span id='topic+activation_mish'></span>

<h3>Description</h3>

<p>Mish: A Self Regularized Non-Monotonic Neural Activation Function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_mish(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_mish_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.
Returns: A 'Tensor'. Has the same type as 'x'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes mish activation: x * tanh(softplus(x))
See [Mish: A Self Regularized Non-Monotonic Neural Activation Function](https://arxiv.org/abs/1908.08681).
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>

<hr>
<h2 id='activation_rrelu'>Rrelu</h2><span id='topic+activation_rrelu'></span>

<h3>Description</h3>

<p>rrelu function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_rrelu(
  x,
  lower = 0.125,
  upper = 0.333333333333333,
  training = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_rrelu_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
<tr><td><code id="activation_rrelu_+3A_lower">lower</code></td>
<td>
<p>'float', lower bound for random alpha.</p>
</td></tr>
<tr><td><code id="activation_rrelu_+3A_upper">upper</code></td>
<td>
<p>'float', upper bound for random alpha.</p>
</td></tr>
<tr><td><code id="activation_rrelu_+3A_training">training</code></td>
<td>
<p>'bool', indicating whether the 'call' is meant for training or inference.</p>
</td></tr>
<tr><td><code id="activation_rrelu_+3A_seed">seed</code></td>
<td>
<p>'int', this sets the operation-level seed. Returns:</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes rrelu function:
'x if x &gt; 0 else random(lower, upper) * x' or
'x if x &gt; 0 else x * (lower + upper) / 2'
depending on whether training is enabled.
See [Empirical Evaluation of Rectified Activations in Convolutional Network](https://arxiv.org/abs/1505.00853).
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>


<h3>Computes rrelu function</h3>

<p>'x if x &gt; 0 else random(lower, upper) * x' or 'x if x &gt; 0 else x * (lower + upper) / 2' depending on
whether training is enabled.
</p>

<hr>
<h2 id='activation_softshrink'>Softshrink</h2><span id='topic+activation_softshrink'></span>

<h3>Description</h3>

<p>Soft shrink function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_softshrink(x, lower = -0.5, upper = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_softshrink_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
<tr><td><code id="activation_softshrink_+3A_lower">lower</code></td>
<td>
<p>'float', lower bound for setting values to zeros.</p>
</td></tr>
<tr><td><code id="activation_softshrink_+3A_upper">upper</code></td>
<td>
<p>'float', upper bound for setting values to zeros. Returns: A 'Tensor'. Has the same type as 'x'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes soft shrink function:
'x - lower if x &lt; lower, x - upper if x &gt; upper else 0'.
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'x'.
</p>


<h3>Computes soft shrink function</h3>

<p>'x - lower if x &lt; lower, x - upper if x &gt; upper else 0'.
</p>

<hr>
<h2 id='activation_sparsemax'>Sparsemax</h2><span id='topic+activation_sparsemax'></span>

<h3>Description</h3>

<p>Sparsemax activation function [1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_sparsemax(logits, axis = -1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_sparsemax_+3A_logits">logits</code></td>
<td>
<p>Input tensor.</p>
</td></tr>
<tr><td><code id="activation_sparsemax_+3A_axis">axis</code></td>
<td>
<p>Integer, axis along which the sparsemax operation is applied.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each batch 'i' and class 'j' we have $$sparsemax[i, j] =
max(logits[i, j] - tau(logits[i, :]), 0)$$ [1]: https://arxiv.org/abs/1602.02068
</p>


<h3>Value</h3>

<p>Tensor, output of sparsemax transformation. Has the same type and shape as
'logits'. Raises: ValueError: In case 'dim(logits) == 1'.
</p>


<h3>Raises</h3>

<p>ValueError: In case 'dim(logits) == 1'.
</p>

<hr>
<h2 id='activation_tanhshrink'>Tanhshrink</h2><span id='topic+activation_tanhshrink'></span>

<h3>Description</h3>

<p>Applies the element-wise function: x - tanh(x)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>activation_tanhshrink(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="activation_tanhshrink_+3A_x">x</code></td>
<td>
<p>A 'Tensor'. Must be one of the following types: 'float16', 'float32', 'float64'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'features'.
</p>

<hr>
<h2 id='attention_bahdanau'>Bahdanau Attention</h2><span id='topic+attention_bahdanau'></span>

<h3>Description</h3>

<p>Implements Bahdanau-style (additive) attention
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_bahdanau(
  object,
  units,
  memory = NULL,
  memory_sequence_length = NULL,
  normalize = FALSE,
  probability_fn = "softmax",
  kernel_initializer = "glorot_uniform",
  dtype = NULL,
  name = "BahdanauAttention",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_bahdanau_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_units">units</code></td>
<td>
<p>The depth of the query mechanism.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_memory">memory</code></td>
<td>
<p>The memory to query; usually the output of an RNN encoder. This tensor
should be shaped [batch_size, max_time, ...].</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_memory_sequence_length">memory_sequence_length</code></td>
<td>
<p>(optional): Sequence lengths for the batch entries in
memory. If provided, the memory tensor rows are masked with zeros for values past the
respective sequence lengths.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_normalize">normalize</code></td>
<td>
<p>boolean. Whether to normalize the energy term.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_probability_fn">probability_fn</code></td>
<td>
<p>(optional) string, the name of function to convert the attention
score to probabilities. The default is softmax which is tf.nn.softmax. Other options is hardmax,
which is hardmax() within this module. Any other value will result into validation
error. Default to use softmax.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>(optional), the name of the initializer for the attention kernel.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_dtype">dtype</code></td>
<td>
<p>The data type for the query and memory layers of the attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_+3A_...">...</code></td>
<td>
<p>A list that contains other common arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This attention has two forms. The first is Bahdanau attention, as described in:
Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. &quot;Neural Machine Translation by Jointly
Learning to Align and Translate.&quot; ICLR 2015. https://arxiv.org/abs/1409.0473 The second
is the normalized form. This form is inspired by the weight normalization article:
Tim Salimans, Diederik P. Kingma. &quot;Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks.&quot; https://arxiv.org/abs/1602.07868
To enable the second form, construct the object with parameter 'normalize=TRUE'.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='attention_bahdanau_monotonic'>Bahdanau Monotonic Attention</h2><span id='topic+attention_bahdanau_monotonic'></span>

<h3>Description</h3>

<p>Monotonic attention mechanism with Bahadanau-style energy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_bahdanau_monotonic(
  object,
  units,
  memory = NULL,
  memory_sequence_length = NULL,
  normalize = FALSE,
  sigmoid_noise = 0,
  sigmoid_noise_seed = NULL,
  score_bias_init = 0,
  mode = "parallel",
  kernel_initializer = "glorot_uniform",
  dtype = NULL,
  name = "BahdanauMonotonicAttention",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_bahdanau_monotonic_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_units">units</code></td>
<td>
<p>The depth of the query mechanism.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_memory">memory</code></td>
<td>
<p>The memory to query; usually the output of an RNN encoder. This tensor
should be shaped [batch_size, max_time, ...].</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_memory_sequence_length">memory_sequence_length</code></td>
<td>
<p>(optional): Sequence lengths for the batch entries in memory.
If provided, the memory tensor rows are masked with zeros for values past the respective
sequence lengths.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_normalize">normalize</code></td>
<td>
<p>Python boolean. Whether to normalize the energy term.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_sigmoid_noise">sigmoid_noise</code></td>
<td>
<p>Standard deviation of pre-sigmoid noise. See the docstring for
'_monotonic_probability_fn' for more information.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_sigmoid_noise_seed">sigmoid_noise_seed</code></td>
<td>
<p>(optional) Random seed for pre-sigmoid noise.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_score_bias_init">score_bias_init</code></td>
<td>
<p>Initial value for score bias scalar. It's recommended to initialize
this to a negative value when the length of the memory is large.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_mode">mode</code></td>
<td>
<p>How to compute the attention distribution. Must be one of 'recursive',
'parallel', or 'hard'. See the docstring for tfa.seq2seq.monotonic_attention for more information.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>(optional), the name of the initializer for the attention kernel.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_dtype">dtype</code></td>
<td>
<p>The data type for the query and memory layers of the attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
<tr><td><code id="attention_bahdanau_monotonic_+3A_...">...</code></td>
<td>
<p>A list that contains other common arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This type of attention enforces a monotonic constraint on the attention
distributions; that is once the model attends to a given point in the memory it
can't attend to any prior points at subsequence output timesteps. It achieves this
by using the _monotonic_probability_fn instead of softmax to construct its attention
distributions. Since the attention scores are passed through a sigmoid, a learnable
scalar bias parameter is applied after the score function and before the sigmoid.
Otherwise, it is equivalent to BahdanauAttention. This approach is proposed in
</p>
<p>Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
&quot;Online and Linear-Time Attention by Enforcing Monotonic Alignments.&quot;
ICML 2017. https://arxiv.org/abs/1704.00784
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='attention_luong'>Implements Luong-style (multiplicative) attention scoring.</h2><span id='topic+attention_luong'></span>

<h3>Description</h3>

<p>Implements Luong-style (multiplicative) attention scoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_luong(
  object,
  units,
  memory = NULL,
  memory_sequence_length = NULL,
  scale = FALSE,
  probability_fn = "softmax",
  dtype = NULL,
  name = "LuongAttention",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_luong_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_units">units</code></td>
<td>
<p>The depth of the attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_memory">memory</code></td>
<td>
<p>The memory to query; usually the output of an RNN encoder. This tensor should be shaped [batch_size, max_time, ...].</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_memory_sequence_length">memory_sequence_length</code></td>
<td>
<p>(optional): Sequence lengths for the batch entries in memory. If provided, the memory tensor rows are masked with zeros for values past the respective sequence lengths.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_scale">scale</code></td>
<td>
<p>boolean. Whether to scale the energy term.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_probability_fn">probability_fn</code></td>
<td>
<p>(optional) string, the name of function to convert the attention score to probabilities. The default is softmax which is tf.nn.softmax. Other options is hardmax, which is hardmax() within this module. Any other value will result intovalidation error. Default to use softmax.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_dtype">dtype</code></td>
<td>
<p>The data type for the memory layer of the attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
<tr><td><code id="attention_luong_+3A_...">...</code></td>
<td>
<p>A list that contains other common arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This attention has two forms. The first is standard Luong attention,
as described in:
Minh-Thang Luong, Hieu Pham, Christopher D. Manning. Effective Approaches to
Attention-based Neural Machine Translation. EMNLP 2015.
The second is the scaled form inspired partly by the normalized form of Bahdanau
attention.
To enable the second form, construct the object with parameter 'scale=TRUE'.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='attention_luong_monotonic'>Monotonic attention mechanism with Luong-style energy function.</h2><span id='topic+attention_luong_monotonic'></span>

<h3>Description</h3>

<p>Monotonic attention mechanism with Luong-style energy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_luong_monotonic(
  object,
  units,
  memory = NULL,
  memory_sequence_length = NULL,
  scale = FALSE,
  sigmoid_noise = 0,
  sigmoid_noise_seed = NULL,
  score_bias_init = 0,
  mode = "parallel",
  dtype = NULL,
  name = "LuongMonotonicAttention",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_luong_monotonic_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_units">units</code></td>
<td>
<p>The depth of the query mechanism.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_memory">memory</code></td>
<td>
<p>The memory to query; usually the output of an RNN encoder. This
tensor should be shaped [batch_size, max_time, ...].</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_memory_sequence_length">memory_sequence_length</code></td>
<td>
<p>(optional): Sequence lengths for the batch entries
in memory. If provided, the memory tensor rows are masked with zeros for values
past the respective sequence lengths.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_scale">scale</code></td>
<td>
<p>boolean. Whether to scale the energy term.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_sigmoid_noise">sigmoid_noise</code></td>
<td>
<p>Standard deviation of pre-sigmoid noise. See the docstring
for '_monotonic_probability_fn' for more information.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_sigmoid_noise_seed">sigmoid_noise_seed</code></td>
<td>
<p>(optional) Random seed for pre-sigmoid noise.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_score_bias_init">score_bias_init</code></td>
<td>
<p>Initial value for score bias scalar. It's recommended to
initialize this to a negative value when the length of the memory is large.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_mode">mode</code></td>
<td>
<p>How to compute the attention distribution. Must be one of 'recursive',
'parallel', or 'hard'. See the docstring for tfa.seq2seq.monotonic_attention for
more information.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_dtype">dtype</code></td>
<td>
<p>The data type for the query and memory layers of the attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
<tr><td><code id="attention_luong_monotonic_+3A_...">...</code></td>
<td>
<p>A list that contains other common arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This type of attention enforces a monotonic constraint on the attention
distributions; that is once the model attends to a given point in the memory it
can't attend to any prior points at subsequence output timesteps. It achieves
this by using the _monotonic_probability_fn instead of softmax to construct its
attention distributions. Otherwise, it is equivalent to LuongAttention.
This approach is proposed in
[Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck, &quot;Online and
Linear-Time Attention by Enforcing Monotonic Alignments.&quot; ICML 2017.](https://arxiv.org/abs/1704.00784)
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='attention_monotonic'>Monotonic attention</h2><span id='topic+attention_monotonic'></span>

<h3>Description</h3>

<p>Compute monotonic attention distribution from choosing probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_monotonic(p_choose_i, previous_attention, mode)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_monotonic_+3A_p_choose_i">p_choose_i</code></td>
<td>
<p>Probability of choosing input sequence/memory element i.
Should be of shape (batch_size, input_sequence_length), and should all be
in the range [0, 1].</p>
</td></tr>
<tr><td><code id="attention_monotonic_+3A_previous_attention">previous_attention</code></td>
<td>
<p>The attention distribution from the previous output
timestep. Should be of shape (batch_size, input_sequence_length). For the first
output timestep, preevious_attention[n] should be [1, 0, 0, ..., 0] for all n
in [0, ... batch_size - 1].</p>
</td></tr>
<tr><td><code id="attention_monotonic_+3A_mode">mode</code></td>
<td>
<p>How to compute the attention distribution. Must be one of 'recursive',
'parallel', or 'hard'.  'recursive' uses tf$scan to recursively compute the
distribution. This is slowest but is exact, general, and does not suffer from
numerical instabilities.  'parallel' uses parallelized cumulative-sum and
cumulative-product operations to compute a closed-form solution to the recurrence
relation defining the attention distribution. This makes it more efficient than
'recursive', but it requires numerical checks which make the distribution non-exact.
This can be a problem in particular when input_sequence_length is long and/or p_choose_i
has entries very close to 0 or 1. * 'hard' requires that the probabilities in p_choose_i
are all either 0 or 1, and subsequently uses a more efficient and exact solution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Monotonic attention implies that the input sequence is processed in an
explicitly left-to-right manner when generating the output sequence. In
addition, once an input sequence element is attended to at a given output
timestep, elements occurring before it cannot be attended to at subsequent
output timesteps. This function generates attention distributions
according to these assumptions. For more information, see 'Online and
Linear-Time Attention by Enforcing Monotonic Alignments'.
</p>


<h3>Value</h3>

<p>A tensor of shape (batch_size, input_sequence_length) representing
the attention distributions for each sequence in the batch.
</p>


<h3>Raises</h3>

<p>ValueError: mode is not one of 'recursive', 'parallel', 'hard'.
</p>

<hr>
<h2 id='attention_wrapper'>Attention Wrapper</h2><span id='topic+attention_wrapper'></span>

<h3>Description</h3>

<p>Attention Wrapper
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_wrapper(
  object,
  cell,
  attention_mechanism,
  attention_layer_size = NULL,
  alignment_history = FALSE,
  cell_input_fn = NULL,
  output_attention = TRUE,
  initial_cell_state = NULL,
  name = NULL,
  attention_layer = NULL,
  attention_fn = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_wrapper_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_cell">cell</code></td>
<td>
<p>An instance of RNNCell.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_attention_mechanism">attention_mechanism</code></td>
<td>
<p>A list of AttentionMechanism instances or a single instance.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_attention_layer_size">attention_layer_size</code></td>
<td>
<p>A list of Python integers or a single Python integer, the
depth of the attention (output) layer(s). If 'NULL' (default), use the context as attention
at each time step. Otherwise, feed the context and cell output into the attention layer
to generate attention at each time step. If attention_mechanism is a list,
attention_layer_size must be a list of the same length. If attention_layer is set, this
must be 'NULL'. If attention_fn is set, it must guaranteed that the outputs of 'attention_fn'
also meet the above requirements.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_alignment_history">alignment_history</code></td>
<td>
<p>Python boolean, whether to store alignment history from all time
steps in the final output state (currently stored as a time major TensorArray on which you
must call stack()).</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_cell_input_fn">cell_input_fn</code></td>
<td>
<p>(optional) A callable.
The default is: lambda inputs, attention: tf$concat(list(inputs, attention), -1).</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_output_attention">output_attention</code></td>
<td>
<p>Python bool. If True (default), the output at each time step is the
attention value. This is the behavior of Luong-style attention mechanisms. If FALSE, the output
at each time step is the output of cell. This is the behavior of Bhadanau-style attention
mechanisms. In both cases, the attention tensor is propagated to the next time step via the
state and is used there. This flag only controls whether the attention mechanism is propagated
up to the next cell in an RNN stack or to the top RNN output.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_initial_cell_state">initial_cell_state</code></td>
<td>
<p>The initial state value to use for the cell when the user calls
get_initial_state(). Note that if this value is provided now, and the user uses a batch_size
argument of get_initial_state which does not match the batch size of initial_cell_state,
proper behavior is not guaranteed.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_attention_layer">attention_layer</code></td>
<td>
<p>A list of tf$keras$layers$Layer instances or a single tf$keras$layers$Layer
instance taking the context and cell output as inputs to generate attention at each time step.
If 'NULL' (default), use the context as attention at each time step. If attention_mechanism is a list,
attention_layer must be a list of the same length. If attention_layers_size is set, this must be 'NULL'.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_attention_fn">attention_fn</code></td>
<td>
<p>An optional callable function that allows users to provide their own customized
attention function, which takes input (attention_mechanism, cell_output, attention_state, attention_layer)
and outputs (attention, alignments, next_attention_state). If provided, the attention_layer_size should
be the size of the outputs of attention_fn.</p>
</td></tr>
<tr><td><code id="attention_wrapper_+3A_...">...</code></td>
<td>
<p>Other keyword arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Note</h3>

<p>If you are using the 'decoder_beam_search' with a cell wrapped in 'AttentionWrapper', then
you must ensure that:
- The encoder output has been tiled to 'beam_width' via 'tile_batch' (NOT 'tf$tile').
- The 'batch_size' argument passed to the 'get_initial_state' method of this wrapper
is equal to 'true_batch_size * beam_width'.
- The initial state created with 'get_initial_state' above contains a 'cell_state' value
containing properly tiled final state from the encoder.
</p>

<hr>
<h2 id='attention_wrapper_state'>Attention Wrapper State</h2><span id='topic+attention_wrapper_state'></span>

<h3>Description</h3>

<p>'namedlist' storing the state of a 'attention_wrapper'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attention_wrapper_state(
  object,
  cell_state,
  attention,
  alignments,
  alignment_history,
  attention_state
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attention_wrapper_state_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="attention_wrapper_state_+3A_cell_state">cell_state</code></td>
<td>
<p>The state of the wrapped RNNCell at the previous time step.</p>
</td></tr>
<tr><td><code id="attention_wrapper_state_+3A_attention">attention</code></td>
<td>
<p>The attention emitted at the previous time step.</p>
</td></tr>
<tr><td><code id="attention_wrapper_state_+3A_alignments">alignments</code></td>
<td>
<p>A single or tuple of Tensor(s) containing the alignments
emitted at the previous time step for each attention mechanism.</p>
</td></tr>
<tr><td><code id="attention_wrapper_state_+3A_alignment_history">alignment_history</code></td>
<td>
<p>(if enabled) a single or tuple of TensorArray(s)
containing alignment matrices from all time steps for each attention mechanism.
Call stack() on each to convert to a Tensor.</p>
</td></tr>
<tr><td><code id="attention_wrapper_state_+3A_attention_state">attention_state</code></td>
<td>
<p>A single or tuple of nested objects containing attention
mechanism state for each attention mechanism. The objects may contain Tensors or
TensorArrays.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='callback_average_model_checkpoint'>Average Model Checkpoint</h2><span id='topic+callback_average_model_checkpoint'></span>

<h3>Description</h3>

<p>Save the model after every epoch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_average_model_checkpoint(
  filepath,
  update_weights,
  monitor = "val_loss",
  verbose = 0,
  save_best_only = FALSE,
  save_weights_only = FALSE,
  mode = "auto",
  save_freq = "epoch",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_average_model_checkpoint_+3A_filepath">filepath</code></td>
<td>
<p>string, path to save the model file.</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_update_weights">update_weights</code></td>
<td>
<p>bool, wheteher to update weights or not</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_monitor">monitor</code></td>
<td>
<p>quantity to monitor.</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_verbose">verbose</code></td>
<td>
<p>verbosity mode, 0 or 1.</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_save_best_only">save_best_only</code></td>
<td>
<p>if 'save_best_only=TRUE', the latest best model according
to the quantity monitored will not be overwritten. If &lsquo;filepath' doesn&rsquo;t contain
formatting options like 'epoch' then 'filepath' will be overwritten by each new
better model.</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_save_weights_only">save_weights_only</code></td>
<td>
<p>if TRUE, then only the model's weights will be saved
('model$save_weights(filepath)'), else the full model is saved ('model$save(filepath)').</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_mode">mode</code></td>
<td>
<p>one of auto, min, max. If 'save_best_only=TRUE', the decision to
overwrite the current save file is made based on either the maximization or the
minimization of the monitored quantity. For 'val_acc', this should be 'max', for
'val_loss' this should be 'min', etc. In 'auto' mode, the direction is automatically
inferred from the name of the monitored quantity.</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_save_freq">save_freq</code></td>
<td>
<p>''epoch'&lsquo; or integer. When using '&rsquo;epoch'', the callback saves the
model after each epoch. When using integer, the callback saves the model at end of a
batch at which this many samples have been seen since last saving. Note that if the
saving isn't aligned to epochs, the monitored metric may potentially be less reliable
(it could reflect as little as 1 batch, since the metrics get reset every epoch).
Defaults to ''epoch''</p>
</td></tr>
<tr><td><code id="callback_average_model_checkpoint_+3A_...">...</code></td>
<td>
<p>Additional arguments for backwards compatibility. Possible key is 'period'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The callback that should be used with optimizers that extend
AverageWrapper, i.e., MovingAverage and StochasticAverage optimizers.
It saves and, optionally, assigns the averaged weights.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>For example</h3>

<p>if 'filepath' is 'weights.epoch:02d-val_loss:.2f.hdf5',:
then the model checkpoints will be saved with the epoch number and the validation loss in the filename.
</p>

<hr>
<h2 id='callback_time_stopping'>Time Stopping</h2><span id='topic+callback_time_stopping'></span>

<h3>Description</h3>

<p>Time Stopping
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_time_stopping(seconds = 86400, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_time_stopping_+3A_seconds">seconds</code></td>
<td>
<p>maximum amount of time before stopping. Defaults to 86400 (1 day).</p>
</td></tr>
<tr><td><code id="callback_time_stopping_+3A_verbose">verbose</code></td>
<td>
<p>verbosity mode. Defaults to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stop training when a specified amount of time has passed.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model %&gt;% fit(
x_train, y_train,
batch_size = 128,
epochs = 4,
validation_split = 0.2,
verbose = 0,
callbacks = callback_time_stopping(seconds = 6, verbose = 1)
)

## End(Not run)



</code></pre>

<hr>
<h2 id='callback_tqdm_progress_bar'>TQDM Progress Bar</h2><span id='topic+callback_tqdm_progress_bar'></span>

<h3>Description</h3>

<p>TQDM Progress Bar
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_tqdm_progress_bar(
  metrics_separator = " - ",
  overall_bar_format = NULL,
  epoch_bar_format = "{n_fmt}/{total_fmt}{bar} ETA: {remaining}s - {desc}",
  update_per_second = 10,
  leave_epoch_progress = TRUE,
  leave_overall_progress = TRUE,
  show_epoch_progress = TRUE,
  show_overall_progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_tqdm_progress_bar_+3A_metrics_separator">metrics_separator</code></td>
<td>
<p>(string) Custom separator between metrics. Defaults to ' - '</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_overall_bar_format">overall_bar_format</code></td>
<td>
<p>(string format) Custom bar format for overall (outer) progress
bar, see https://github.com/tqdm/tqdm#parameters for more detail.
By default: 'l_barbar n_fmt/total_fmt ETA: remainings,  rate_fmtpostfix'</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_epoch_bar_format">epoch_bar_format</code></td>
<td>
<p>(string format) Custom bar format for epoch (inner) progress bar,
see https://github.com/tqdm/tqdm#parameters for more detail.</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_update_per_second">update_per_second</code></td>
<td>
<p>(int) Maximum number of updates in the epochs bar per second, this
is to prevent small batches from slowing down training. Defaults to 10.</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_leave_epoch_progress">leave_epoch_progress</code></td>
<td>
<p>(bool) TRUE to leave epoch progress bars</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_leave_overall_progress">leave_overall_progress</code></td>
<td>
<p>(bool) TRUE to leave overall progress bar</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_show_epoch_progress">show_epoch_progress</code></td>
<td>
<p>(bool) FALSE to hide epoch progress bars</p>
</td></tr>
<tr><td><code id="callback_tqdm_progress_bar_+3A_show_overall_progress">show_overall_progress</code></td>
<td>
<p>(bool) FALSE to hide overall progress bar</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TQDM Progress Bar for Tensorflow Keras.
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model %&gt;% fit(
x_train, y_train,
batch_size = 128,
epochs = 4,
validation_split = 0.2,
verbose = 0,
callbacks = callback_tqdm_progress_bar()
)

## End(Not run)



</code></pre>

<hr>
<h2 id='crf_binary_score'>CRF binary score</h2><span id='topic+crf_binary_score'></span>

<h3>Description</h3>

<p>Computes the binary scores of tag sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_binary_score(tag_indices, sequence_lengths, transition_params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_binary_score_+3A_tag_indices">tag_indices</code></td>
<td>
<p>A [batch_size, max_seq_len] matrix of tag indices.</p>
</td></tr>
<tr><td><code id="crf_binary_score_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_binary_score_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] matrix of binary potentials.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>binary_scores: A [batch_size] vector of binary scores.
</p>

<hr>
<h2 id='crf_decode'>CRF decode</h2><span id='topic+crf_decode'></span>

<h3>Description</h3>

<p>Decode the highest scoring sequence of tags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_decode(potentials, transition_params, sequence_length)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_decode_+3A_potentials">potentials</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials.</p>
</td></tr>
<tr><td><code id="crf_decode_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] matrix of binary potentials.</p>
</td></tr>
<tr><td><code id="crf_decode_+3A_sequence_length">sequence_length</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>decode_tags: A [batch_size, max_seq_len] matrix, with dtype 'tf.int32'.
Contains the highest scoring tag indices. best_score: A [batch_size] vector,
containing the score of 'decode_tags'.
</p>

<hr>
<h2 id='crf_decode_backward'>CRF decode backward</h2><span id='topic+crf_decode_backward'></span>

<h3>Description</h3>

<p>Computes backward decoding in a linear-chain CRF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_decode_backward(inputs, state)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_decode_backward_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, num_tags] matrix of backpointer of next step (in time order).</p>
</td></tr>
<tr><td><code id="crf_decode_backward_+3A_state">state</code></td>
<td>
<p>A [batch_size, 1] matrix of tag index of next step.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>new_tags: A [batch_size, num_tags] tensor containing the new tag indices.
</p>

<hr>
<h2 id='crf_decode_forward'>CRF decode forward</h2><span id='topic+crf_decode_forward'></span>

<h3>Description</h3>

<p>Computes forward decoding in a linear-chain CRF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_decode_forward(inputs, state, transition_params, sequence_lengths)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_decode_forward_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, num_tags] matrix of unary potentials.</p>
</td></tr>
<tr><td><code id="crf_decode_forward_+3A_state">state</code></td>
<td>
<p>A [batch_size, num_tags] matrix containing the previous step's score values.</p>
</td></tr>
<tr><td><code id="crf_decode_forward_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] matrix of binary potentials.</p>
</td></tr>
<tr><td><code id="crf_decode_forward_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>backpointers: A [batch_size, num_tags] matrix of backpointers.
new_state: A [batch_size, num_tags] matrix of new score values.
</p>

<hr>
<h2 id='crf_forward'>CRF forward</h2><span id='topic+crf_forward'></span>

<h3>Description</h3>

<p>Computes the alpha values in a linear-chain CRF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_forward(inputs, state, transition_params, sequence_lengths)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_forward_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, num_tags] matrix of unary potentials.</p>
</td></tr>
<tr><td><code id="crf_forward_+3A_state">state</code></td>
<td>
<p>A [batch_size, num_tags] matrix containing the previous alpha values.</p>
</td></tr>
<tr><td><code id="crf_forward_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] matrix of binary potentials. This
matrix is expanded into a [1, num_tags, num_tags] in preparation for the broadcast
summation occurring within the cell.</p>
</td></tr>
<tr><td><code id="crf_forward_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See http://www.cs.columbia.edu/~mcollins/fb.pdf for reference.
</p>


<h3>Value</h3>

<p>new_alphas: A [batch_size, num_tags] matrix containing the new alpha values.
</p>

<hr>
<h2 id='crf_log_likelihood'>CRF log likelihood</h2><span id='topic+crf_log_likelihood'></span>

<h3>Description</h3>

<p>Computes the log-likelihood of tag sequences in a CRF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_log_likelihood(
  inputs,
  tag_indices,
  sequence_lengths,
  transition_params = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_log_likelihood_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials to use
as input to the CRF layer.</p>
</td></tr>
<tr><td><code id="crf_log_likelihood_+3A_tag_indices">tag_indices</code></td>
<td>
<p>A [batch_size, max_seq_len] matrix of tag indices for which we
compute the log-likelihood.</p>
</td></tr>
<tr><td><code id="crf_log_likelihood_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_log_likelihood_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] transition matrix, if available.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log_likelihood: A [batch_size] Tensor containing the log-likelihood of each example,
given the sequence of tag indices. transition_params: A [num_tags, num_tags] transition matrix.
This is either provided by the caller or created in this function.
</p>

<hr>
<h2 id='crf_log_norm'>CRF log norm</h2><span id='topic+crf_log_norm'></span>

<h3>Description</h3>

<p>Computes the normalization for a CRF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_log_norm(inputs, sequence_lengths, transition_params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_log_norm_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials
to use as input to the CRF layer.</p>
</td></tr>
<tr><td><code id="crf_log_norm_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_log_norm_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] transition matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log_norm: A [batch_size] vector of normalizers for a CRF.
</p>

<hr>
<h2 id='crf_multitag_sequence_score'>CRF multitag sequence score</h2><span id='topic+crf_multitag_sequence_score'></span>

<h3>Description</h3>

<p>Computes the unnormalized score of all tag sequences matching
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_multitag_sequence_score(
  inputs,
  tag_bitmap,
  sequence_lengths,
  transition_params
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_multitag_sequence_score_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials
to use as input to the CRF layer.</p>
</td></tr>
<tr><td><code id="crf_multitag_sequence_score_+3A_tag_bitmap">tag_bitmap</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] boolean tensor representing
all active tags at each index for which to calculate the unnormalized score.</p>
</td></tr>
<tr><td><code id="crf_multitag_sequence_score_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_multitag_sequence_score_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] transition matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>tag_bitmap. tag_bitmap enables more than one tag to be considered
correct at each time
step. This is useful when an observed output at a given time step is
consistent with more than one tag, and thus the log likelihood of that
observation must take into account all possible consistent tags. Using
one-hot vectors in tag_bitmap gives results identical to
crf_sequence_score.
</p>


<h3>Value</h3>

<p>sequence_scores: A [batch_size] vector of unnormalized sequence scores.
</p>

<hr>
<h2 id='crf_sequence_score'>CRF sequence score</h2><span id='topic+crf_sequence_score'></span>

<h3>Description</h3>

<p>Computes the unnormalized score for a tag sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_sequence_score(inputs, tag_indices, sequence_lengths, transition_params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_sequence_score_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials
to use as input to the CRF layer.</p>
</td></tr>
<tr><td><code id="crf_sequence_score_+3A_tag_indices">tag_indices</code></td>
<td>
<p>A [batch_size, max_seq_len] matrix of tag indices for which
we compute the unnormalized score.</p>
</td></tr>
<tr><td><code id="crf_sequence_score_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_sequence_score_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] transition matrix. Returns:</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sequence_scores: A [batch_size] vector of unnormalized sequence scores.
</p>

<hr>
<h2 id='crf_unary_score'>CRF unary score</h2><span id='topic+crf_unary_score'></span>

<h3>Description</h3>

<p>Computes the unary scores of tag sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crf_unary_score(tag_indices, sequence_lengths, inputs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crf_unary_score_+3A_tag_indices">tag_indices</code></td>
<td>
<p>A [batch_size, max_seq_len] matrix of tag indices.</p>
</td></tr>
<tr><td><code id="crf_unary_score_+3A_sequence_lengths">sequence_lengths</code></td>
<td>
<p>A [batch_size] vector of true sequence lengths.</p>
</td></tr>
<tr><td><code id="crf_unary_score_+3A_inputs">inputs</code></td>
<td>
<p>A [batch_size, max_seq_len, num_tags] tensor of unary potentials.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>unary_scores: A [batch_size] vector of unary scores.
</p>

<hr>
<h2 id='decode_dynamic'>Dynamic decode</h2><span id='topic+decode_dynamic'></span>

<h3>Description</h3>

<p>Perform dynamic decoding with 'decoder'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decode_dynamic(
  decoder,
  output_time_major = FALSE,
  impute_finished = FALSE,
  maximum_iterations = NULL,
  parallel_iterations = 32L,
  swap_memory = FALSE,
  training = NULL,
  scope = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decode_dynamic_+3A_decoder">decoder</code></td>
<td>
<p>A 'Decoder' instance.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_output_time_major">output_time_major</code></td>
<td>
<p>boolean. Default: 'FALSE' (batch major). If 'TRUE', outputs
are returned as time major tensors (this mode is faster). Otherwise, outputs are returned
as batch major tensors (this adds extra time to the computation).</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_impute_finished">impute_finished</code></td>
<td>
<p>boolean. If 'TRUE', then states for batch entries which are
marked as finished get copied through and the corresponding outputs get zeroed out. This
causes some slowdown at each time step, but ensures that the final state and outputs have
the correct values and that backprop ignores time steps that were marked as finished.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_maximum_iterations">maximum_iterations</code></td>
<td>
<p>'int32' scalar, maximum allowed number of decoding steps. Default
is 'NULL' (decode until the decoder is fully done).</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_parallel_iterations">parallel_iterations</code></td>
<td>
<p>Argument passed to 'tf$while_loop'.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_swap_memory">swap_memory</code></td>
<td>
<p>Argument passed to 'tf$while_loop'.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_training">training</code></td>
<td>
<p>boolean. Indicates whether the layer should behave in training mode or
in inference mode. Only relevant when 'dropout' or 'recurrent_dropout' is used.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_scope">scope</code></td>
<td>
<p>Optional variable scope to use.</p>
</td></tr>
<tr><td><code id="decode_dynamic_+3A_...">...</code></td>
<td>
<p>A list, other keyword arguments for
dynamic_decode. It might contain arguments for 'BaseDecoder' to initialize, which takes
all tensor inputs during 'call()'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls 'initialize()' once and 'step()' repeatedly on the Decoder object.
</p>


<h3>Value</h3>

<p>'(final_outputs, final_state, final_sequence_lengths)'.
</p>


<h3>Raises</h3>

<p>TypeError: if 'decoder' is not an instance of 'Decoder'. ValueError: if 'maximum_iterations'
is provided but is not a scalar.
</p>

<hr>
<h2 id='decoder'>An RNN Decoder abstract interface object.</h2><span id='topic+decoder'></span>

<h3>Description</h3>

<p>An RNN Decoder abstract interface object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_+3A_...">...</code></td>
<td>
<p>arguments to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>- inputs: (structure of) tensors and TensorArrays that is passed as input to the RNNCell
composing the decoder, at each time step.
- state: (structure of) tensors and TensorArrays that is passed to the RNNCell instance as the state.
- finished: boolean tensor telling whether each sequence in the batch is finished.
- training: boolean whether it should behave in training mode or in inference mode.
- outputs: Instance of BasicDecoderOutput. Result of the decoding, at each time step.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_base'>Base Decoder</h2><span id='topic+decoder_base'></span>

<h3>Description</h3>

<p>An RNN Decoder that is based on a Keras layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_base(object, cell, sampler, output_layer = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_base_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="decoder_base_+3A_cell">cell</code></td>
<td>
<p>An RNNCell instance.</p>
</td></tr>
<tr><td><code id="decoder_base_+3A_sampler">sampler</code></td>
<td>
<p>A Sampler instance.</p>
</td></tr>
<tr><td><code id="decoder_base_+3A_output_layer">output_layer</code></td>
<td>
<p>(Optional) An instance of tf$layers$Layer, i.e., tf$layers$Dense.
Optional layer to apply to the RNN output prior to storing the result or sampling.</p>
</td></tr>
<tr><td><code id="decoder_base_+3A_...">...</code></td>
<td>
<p>Other keyword arguments for layer creation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_basic'>Basic Decoder</h2><span id='topic+decoder_basic'></span>

<h3>Description</h3>

<p>Basic Decoder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_basic(object, cell, sampler, output_layer = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_basic_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="decoder_basic_+3A_cell">cell</code></td>
<td>
<p>An RNNCell instance.</p>
</td></tr>
<tr><td><code id="decoder_basic_+3A_sampler">sampler</code></td>
<td>
<p>A Sampler instance.</p>
</td></tr>
<tr><td><code id="decoder_basic_+3A_output_layer">output_layer</code></td>
<td>
<p>(Optional) An instance of tf$layers$Layer,
i.e., tf$layers$Dense. Optional layer to apply to the RNN output
prior to storing the result or sampling.</p>
</td></tr>
<tr><td><code id="decoder_basic_+3A_...">...</code></td>
<td>
<p>Other keyword arguments for layer creation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_basic_output'>Basic decoder output</h2><span id='topic+decoder_basic_output'></span>

<h3>Description</h3>

<p>Basic decoder output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_basic_output(rnn_output, sample_id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_basic_output_+3A_rnn_output">rnn_output</code></td>
<td>
<p>the output of RNN cell</p>
</td></tr>
<tr><td><code id="decoder_basic_output_+3A_sample_id">sample_id</code></td>
<td>
<p>the 'id' of the sample</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_beam_search'>BeamSearch sampling decoder</h2><span id='topic+decoder_beam_search'></span>

<h3>Description</h3>

<p>BeamSearch sampling decoder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_beam_search(
  object,
  cell,
  beam_width,
  embedding_fn = NULL,
  output_layer = NULL,
  length_penalty_weight = 0,
  coverage_penalty_weight = 0,
  reorder_tensor_arrays = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_beam_search_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_cell">cell</code></td>
<td>
<p>An RNNCell instance.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_beam_width">beam_width</code></td>
<td>
<p>integer, the number of beams.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_embedding_fn">embedding_fn</code></td>
<td>
<p>A callable that takes a vector tensor of ids (argmax ids).</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_output_layer">output_layer</code></td>
<td>
<p>(Optional) An instance of tf.keras.layers.Layer,
i.e., tf$keras$layers$Dense. Optional layer to apply to the RNN output prior
to storing the result or sampling.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_length_penalty_weight">length_penalty_weight</code></td>
<td>
<p>Float weight to penalize length. Disabled with 0.0.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_coverage_penalty_weight">coverage_penalty_weight</code></td>
<td>
<p>Float weight to penalize the coverage of source
sentence. Disabled with 0.0.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_reorder_tensor_arrays">reorder_tensor_arrays</code></td>
<td>
<p>If &lsquo;TRUE', TensorArrays&rsquo; elements within the cell
state will be reordered according to the beam search path. If the TensorArray
can be reordered, the stacked form will be returned. Otherwise, the TensorArray
will be returned as is. Set this flag to False if the cell state contains
TensorArrays that are not amenable to reordering.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_+3A_...">...</code></td>
<td>
<p>A list, other keyword arguments for initialization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Note</h3>

<p>If you are using the 'BeamSearchDecoder' with a cell wrapped in
'AttentionWrapper', then you must ensure that:
- The encoder output has been tiled to 'beam_width' via
'tile_batch()' (NOT 'tf$tile').
- The 'batch_size' argument passed to the 'get_initial_state' method of
this wrapper is equal to 'true_batch_size * beam_width'.
- The initial state created with 'get_initial_state' above contains a
'cell_state' value containing properly tiled final state from the encoder.
</p>

<hr>
<h2 id='decoder_beam_search_output'>Beam Search Decoder Output</h2><span id='topic+decoder_beam_search_output'></span>

<h3>Description</h3>

<p>Beam Search Decoder Output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_beam_search_output(scores, predicted_ids, parent_ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_beam_search_output_+3A_scores">scores</code></td>
<td>
<p>calculate the scores for each beam</p>
</td></tr>
<tr><td><code id="decoder_beam_search_output_+3A_predicted_ids">predicted_ids</code></td>
<td>
<p>The final prediction. A tensor of shape
'[batch_size, T, beam_width]' (or '[T, batch_size, beam_width]' if 'output_time_major'
is 'TRUE'). Beams are ordered from best to worst.</p>
</td></tr>
<tr><td><code id="decoder_beam_search_output_+3A_parent_ids">parent_ids</code></td>
<td>
<p>The parent ids of shape '[max_time, batch_size, beam_width]'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_beam_search_state'>Beam Search Decoder State</h2><span id='topic+decoder_beam_search_state'></span>

<h3>Description</h3>

<p>Beam Search Decoder State
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_beam_search_state(
  cell_state,
  log_probs,
  finished,
  lengths,
  accumulated_attention_probs
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_beam_search_state_+3A_cell_state">cell_state</code></td>
<td>
<p>cell_state</p>
</td></tr>
<tr><td><code id="decoder_beam_search_state_+3A_log_probs">log_probs</code></td>
<td>
<p>log_probs</p>
</td></tr>
<tr><td><code id="decoder_beam_search_state_+3A_finished">finished</code></td>
<td>
<p>finished</p>
</td></tr>
<tr><td><code id="decoder_beam_search_state_+3A_lengths">lengths</code></td>
<td>
<p>lengths</p>
</td></tr>
<tr><td><code id="decoder_beam_search_state_+3A_accumulated_attention_probs">accumulated_attention_probs</code></td>
<td>
<p>accumulated_attention_probs</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='decoder_final_beam_search_output'>Final Beam Search Decoder Output</h2><span id='topic+decoder_final_beam_search_output'></span>

<h3>Description</h3>

<p>Final outputs returned by the beam search after all decoding is finished.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decoder_final_beam_search_output(predicted_ids, beam_search_decoder_output)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decoder_final_beam_search_output_+3A_predicted_ids">predicted_ids</code></td>
<td>
<p>The final prediction. A tensor of shape '[batch_size, T, beam_width]'
(or '[T, batch_size, beam_width]' if 'output_time_major' is TRUE). Beams are ordered from
best to worst.</p>
</td></tr>
<tr><td><code id="decoder_final_beam_search_output_+3A_beam_search_decoder_output">beam_search_decoder_output</code></td>
<td>
<p>An instance of 'BeamSearchDecoderOutput' that describes
the state of the beam search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='extend_with_decoupled_weight_decay'>Factory function returning an optimizer class with decoupled weight decay</h2><span id='topic+extend_with_decoupled_weight_decay'></span>

<h3>Description</h3>

<p>Factory function returning an optimizer class with decoupled weight decay
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extend_with_decoupled_weight_decay(base_optimizer)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extend_with_decoupled_weight_decay_+3A_base_optimizer">base_optimizer</code></td>
<td>
<p>An optimizer class that inherits from tf$optimizers$Optimizer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The API of the new optimizer class slightly differs from the API of the base optimizer:
</p>
<p>- The first argument to the constructor is the weight decay rate.
- minimize and apply_gradients accept the optional keyword argument decay_var_list,
which specifies the variables that should be decayed. If NULLs, all variables that are optimized are decayed.
</p>


<h3>Value</h3>

<p>A new optimizer class that inherits from DecoupledWeightDecayExtension and base_optimizer.
</p>


<h3>Note</h3>

<p>Note: this extension decays weights BEFORE applying the update based
on the gradient, i.e. this extension only has the desired behaviour for
optimizers which do not depend on the value of 'var' in the update step!
Note: when applying a decay to the learning rate, be sure to manually apply
the decay to the 'weight_decay' as well.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

### MyAdamW is a new class
MyAdamW = extend_with_decoupled_weight_decay(tf$keras$optimizers$Adam)
### Create a MyAdamW object
optimizer = MyAdamW(weight_decay = 0.001, learning_rate = 0.001)
#### update var1, var2 but only decay var1
optimizer$minimize(loss, var_list = list(var1, var2), decay_variables = list(var1))


## End(Not run)

</code></pre>

<hr>
<h2 id='gather_tree'>Gather tree</h2><span id='topic+gather_tree'></span>

<h3>Description</h3>

<p>Gather tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gather_tree(step_ids, parent_ids, max_sequence_lengths, end_token)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gather_tree_+3A_step_ids">step_ids</code></td>
<td>
<p>requires the step id</p>
</td></tr>
<tr><td><code id="gather_tree_+3A_parent_ids">parent_ids</code></td>
<td>
<p>The parent ids of shape '[max_time, batch_size, beam_width]'.</p>
</td></tr>
<tr><td><code id="gather_tree_+3A_max_sequence_lengths">max_sequence_lengths</code></td>
<td>
<p>get max_sequence_length across all beams for each batch.</p>
</td></tr>
<tr><td><code id="gather_tree_+3A_end_token">end_token</code></td>
<td>
<p>'int32' scalar, the token that marks end of decoding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='gather_tree_from_array'>Gather tree from array</h2><span id='topic+gather_tree_from_array'></span>

<h3>Description</h3>

<p>Calculates the full beams for 'TensorArray's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gather_tree_from_array(t, parent_ids, sequence_length)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gather_tree_from_array_+3A_t">t</code></td>
<td>
<p>A stacked 'TensorArray' of size 'max_time' that contains 'Tensor's of
shape '[batch_size, beam_width, s]' or '[batch_size * beam_width, s]' where 's'
is the depth shape.</p>
</td></tr>
<tr><td><code id="gather_tree_from_array_+3A_parent_ids">parent_ids</code></td>
<td>
<p>The parent ids of shape '[max_time, batch_size, beam_width]'.</p>
</td></tr>
<tr><td><code id="gather_tree_from_array_+3A_sequence_length">sequence_length</code></td>
<td>
<p>The sequence length of shape '[batch_size, beam_width]'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 'Tensor' which is a stacked 'TensorArray' of the same size and type as
't' and where beams are sorted in each 'Tensor' according to 'parent_ids'.
</p>

<hr>
<h2 id='hardmax'>Hardmax</h2><span id='topic+hardmax'></span>

<h3>Description</h3>

<p>Returns batched one-hot vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hardmax(logits, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hardmax_+3A_logits">logits</code></td>
<td>
<p>A batch tensor of logit values.</p>
</td></tr>
<tr><td><code id="hardmax_+3A_name">name</code></td>
<td>
<p>Name to use when creating ops.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The depth index containing the '1' is that of the maximum logit value.
</p>


<h3>Value</h3>

<p>A batched one-hot tensor.
</p>

<hr>
<h2 id='img_adjust_hsv_in_yiq'>Adjust hsv in yiq</h2><span id='topic+img_adjust_hsv_in_yiq'></span>

<h3>Description</h3>

<p>Adjust hue, saturation, value of an RGB image in YIQ color space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_adjust_hsv_in_yiq(
  image,
  delta_hue = 0,
  scale_saturation = 1,
  scale_value = 1,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_adjust_hsv_in_yiq_+3A_image">image</code></td>
<td>
<p>RGB image or images. Size of the last dimension must be 3.</p>
</td></tr>
<tr><td><code id="img_adjust_hsv_in_yiq_+3A_delta_hue">delta_hue</code></td>
<td>
<p>float, the hue rotation amount, in radians.</p>
</td></tr>
<tr><td><code id="img_adjust_hsv_in_yiq_+3A_scale_saturation">scale_saturation</code></td>
<td>
<p>float, factor to multiply the saturation by.</p>
</td></tr>
<tr><td><code id="img_adjust_hsv_in_yiq_+3A_scale_value">scale_value</code></td>
<td>
<p>float, factor to multiply the value by.</p>
</td></tr>
<tr><td><code id="img_adjust_hsv_in_yiq_+3A_name">name</code></td>
<td>
<p>A name for this operation (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a convenience method that converts an RGB image to float
representation, converts it to YIQ, rotates the color around the
Y channel by delta_hue in radians, scales the chrominance channels
(I, Q) by scale_saturation, scales all channels (Y, I, Q) by scale_value,
converts back to RGB, and then back to the original data type. 'image' is an RGB image.
The image hue is adjusted by converting the
image to YIQ, rotating around the luminance channel (Y) by
'delta_hue' in radians, multiplying the chrominance channels (I, Q) by
'scale_saturation', and multiplying all channels (Y, I, Q) by
'scale_value'. The image is then converted back to RGB.
</p>


<h3>Value</h3>

<p>Adjusted image(s), same shape and dtype as 'image'.
</p>

<hr>
<h2 id='img_angles_to_projective_transforms'>Angles to projective transforms</h2><span id='topic+img_angles_to_projective_transforms'></span>

<h3>Description</h3>

<p>Returns projective transform(s) for the given angle(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_angles_to_projective_transforms(
  angles,
  image_height,
  image_width,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_angles_to_projective_transforms_+3A_angles">angles</code></td>
<td>
<p>A scalar angle to rotate all images by, or (for batches of images)
a vector with an angle to rotate each image in the batch. The rank must be statically
known (the shape is not 'TensorShape(NULL)'.</p>
</td></tr>
<tr><td><code id="img_angles_to_projective_transforms_+3A_image_height">image_height</code></td>
<td>
<p>Height of the image(s) to be transformed.</p>
</td></tr>
<tr><td><code id="img_angles_to_projective_transforms_+3A_image_width">image_width</code></td>
<td>
<p>Width of the image(s) to be transformed.</p>
</td></tr>
<tr><td><code id="img_angles_to_projective_transforms_+3A_name">name</code></td>
<td>
<p>name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of shape (num_images, 8). Projective transforms which can be given to 'transform' op.
</p>

<hr>
<h2 id='img_blend'>Blend</h2><span id='topic+img_blend'></span>

<h3>Description</h3>

<p>Blend image1 and image2 using 'factor'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_blend(image1, image2, factor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_blend_+3A_image1">image1</code></td>
<td>
<p>An image Tensor of shape (num_rows, num_columns, num_channels) (HWC),
or (num_rows, num_columns) (HW), or (num_channels, num_rows, num_columns).</p>
</td></tr>
<tr><td><code id="img_blend_+3A_image2">image2</code></td>
<td>
<p>An image Tensor of shape (num_rows, num_columns, num_channels) (HWC),
or (num_rows, num_columns) (HW), or (num_channels, num_rows, num_columns).</p>
</td></tr>
<tr><td><code id="img_blend_+3A_factor">factor</code></td>
<td>
<p>A floating point value or Tensor of type tf.float32 above 0.0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Factor can be above 0.0. A value of 0.0 means only image1 is used.
A value of 1.0 means only image2 is used. A value between 0.0 and
1.0 means we linearly interpolate the pixel values between the two
images. A value greater than 1.0 &quot;extrapolates&quot; the difference
between the two pixel values, and we clip the results to values
between 0 and 255.
</p>


<h3>Value</h3>

<p>A blended image Tensor of tf$float32.
</p>

<hr>
<h2 id='img_compose_transforms'>Compose transforms</h2><span id='topic+img_compose_transforms'></span>

<h3>Description</h3>

<p>Composes the transforms tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_compose_transforms(transforms, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_compose_transforms_+3A_transforms">transforms</code></td>
<td>
<p>List of image projective transforms to be composed.
Each transform is length 8 (single transform) or shape (N, 8) (batched transforms).
The shapes of all inputs must be equal, and at least one input must be given.</p>
</td></tr>
<tr><td><code id="img_compose_transforms_+3A_name">name</code></td>
<td>
<p>The name for the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A composed transform tensor. When passed to 'transform' op, equivalent to
applying each of the given transforms to the image in order.
</p>

<hr>
<h2 id='img_connected_components'>Connected components</h2><span id='topic+img_connected_components'></span>

<h3>Description</h3>

<p>Labels the connected components in a batch of images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_connected_components(images, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_connected_components_+3A_images">images</code></td>
<td>
<p>A 2D (H, W) or 3D (N, H, W) Tensor of image (integer,
floating point and boolean types are supported).</p>
</td></tr>
<tr><td><code id="img_connected_components_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A component is a set of pixels in a single input image, which are
all adjacent and all have the same non-zero value. The components
using a squared connectivity of one (all equal entries are joined with
their neighbors above,below, left, and right). Components across all
images have consecutive ids 1 through n.
Components are labeled according to the first pixel of the
component appearing in row-major order (lexicographic order by
image_index_in_batch, row, col).
Zero entries all have an output id of 0.
This op is equivalent with 'scipy.ndimage.measurements.label'
on a 2D array with the default structuring element
(which is the connectivity used here).
</p>


<h3>Value</h3>

<p>Components with the same shape as 'images'. entries that evaluate to
FALSE (e.g. 0/0.0f, FALSE) in 'images' have value 0, and all other entries
map to a component id &gt; 0.
</p>


<h3>Raises</h3>

<p>TypeError: if 'images' is not 2D or 3D.
</p>

<hr>
<h2 id='img_cutout'>Cutout</h2><span id='topic+img_cutout'></span>

<h3>Description</h3>

<p>Apply cutout (https://arxiv.org/abs/1708.04552) to images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_cutout(
  images,
  mask_size,
  offset = list(0, 0),
  constant_values = 0,
  data_format = "channels_last"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_cutout_+3A_images">images</code></td>
<td>
<p>A tensor of shape (batch_size, height, width, channels) (NHWC),
(batch_size, channels, height, width)(NCHW).</p>
</td></tr>
<tr><td><code id="img_cutout_+3A_mask_size">mask_size</code></td>
<td>
<p>Specifies how big the zero mask that will be generated is that
is applied to the images. The mask will be of size (mask_height x mask_width).
Note: mask_size should be divisible by 2.</p>
</td></tr>
<tr><td><code id="img_cutout_+3A_offset">offset</code></td>
<td>
<p>A list of (height, width) or (batch_size, 2)</p>
</td></tr>
<tr><td><code id="img_cutout_+3A_constant_values">constant_values</code></td>
<td>
<p>What pixel value to fill in the images in the area that
has the cutout mask applied to it.</p>
</td></tr>
<tr><td><code id="img_cutout_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of 'channels_last' (default) or 'channels_first'.
The ordering of the dimensions in the inputs. 'channels_last' corresponds to
inputs with shape '(batch_size, ..., channels)' while 'channels_first' corresponds
to inputs with shape '(batch_size, channels, ...)'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This operation applies a (mask_height x mask_width) mask of zeros to
a location within 'img' specified by the offset. The pixel values filled in will be of the
value 'replace'. The located where the mask will be applied is randomly
chosen uniformly over the whole images.
</p>


<h3>Value</h3>

<p>An image Tensor.
</p>


<h3>Raises</h3>

<p>InvalidArgumentError: if mask_size can't be divisible by 2.
</p>

<hr>
<h2 id='img_dense_image_warp'>Dense image warp</h2><span id='topic+img_dense_image_warp'></span>

<h3>Description</h3>

<p>Image warping using per-pixel flow vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_dense_image_warp(image, flow, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_dense_image_warp_+3A_image">image</code></td>
<td>
<p>4-D float Tensor with shape [batch, height, width, channels].</p>
</td></tr>
<tr><td><code id="img_dense_image_warp_+3A_flow">flow</code></td>
<td>
<p>A 4-D float Tensor with shape [batch, height, width, 2].</p>
</td></tr>
<tr><td><code id="img_dense_image_warp_+3A_name">name</code></td>
<td>
<p>A name for the operation (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Apply a non-linear warp to the image, where the warp is specified by a
dense flow field of offset vectors that define the correspondences of
pixel values in the output image back to locations in the source image.
Specifically, the pixel value at output[b, j, i, c] is
images[b, j - flow[b, j, i, 0], i - flow[b, j, i, 1], c]. The locations specified by
this formula do not necessarily map to an int
index. Therefore, the pixel value is obtained by bilinear
interpolation of the 4 nearest pixels around
(b, j - flow[b, j, i, 0], i - flow[b, j, i, 1]). For locations outside
of the image, we use the nearest pixel values at the image boundary.
</p>


<h3>Value</h3>

<p>A 4-D float 'Tensor' with shape'[batch, height, width, channels]' and same type as input image.
</p>


<h3>Raises</h3>

<p>ValueError: if height &lt; 2 or width &lt; 2 or the inputs have the wrong number of dimensions.
</p>


<h3>Note</h3>

<p>Note that image and flow can be of type tf$half, tf$float32, or tf$float64, and
do not necessarily have to be the same type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
flow_shape = list(1L, as.integer(input_img$shape[[2]]), as.integer(input_img$shape[[3]]), 2L)
init_flows = tf$random$normal(flow_shape) * 2.0
dense_img_warp = img_dense_image_warp(input_img, init_flows)
dense_img_warp = tf$squeeze(dense_img_warp, 0)

## End(Not run)


</code></pre>

<hr>
<h2 id='img_equalize'>Equalize</h2><span id='topic+img_equalize'></span>

<h3>Description</h3>

<p>Equalize image(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_equalize(image, data_format = "channels_last", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_equalize_+3A_image">image</code></td>
<td>
<p>A tensor of shape (num_images, num_rows, num_columns, num_channels) (NHWC),
or (num_images, num_channels, num_rows, num_columns) (NCHW), or
(num_rows, num_columns, num_channels) (HWC), or (num_channels, num_rows, num_columns) (CHW),
or (num_rows, num_columns) (HW). The rank must be statically known (the shape is
not TensorShape(None)).</p>
</td></tr>
<tr><td><code id="img_equalize_+3A_data_format">data_format</code></td>
<td>
<p>Either 'channels_first' or 'channels_last'</p>
</td></tr>
<tr><td><code id="img_equalize_+3A_name">name</code></td>
<td>
<p>The name of the op. Returns: Image(s) with the same type and
shape as 'images', equalized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the same type and shape as 'images', equalized.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
img_equalize(img)

## End(Not run)

</code></pre>

<hr>
<h2 id='img_euclidean_dist_transform'>Euclidean dist transform</h2><span id='topic+img_euclidean_dist_transform'></span>

<h3>Description</h3>

<p>Applies euclidean distance transform(s) to the image(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_euclidean_dist_transform(images, dtype = tf$float32, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_euclidean_dist_transform_+3A_images">images</code></td>
<td>
<p>A tensor of shape (num_images, num_rows, num_columns, 1) (NHWC),
or (num_rows, num_columns, 1) (HWC) or (num_rows, num_columns) (HW).</p>
</td></tr>
<tr><td><code id="img_euclidean_dist_transform_+3A_dtype">dtype</code></td>
<td>
<p>DType of the output tensor.</p>
</td></tr>
<tr><td><code id="img_euclidean_dist_transform_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the type 'dtype' and same shape as 'images', with the
transform applied. If a tensor of all ones is given as input, the output tensor
will be filled with the max value of the 'dtype'.
</p>


<h3>Raises</h3>

<p>TypeError: If 'image' is not tf.uint8, or 'dtype' is not floating point.
ValueError: If 'image' more than one channel, or 'image' is not of rank between 2 and 4.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
img_path = tf$keras$utils$get_file('tensorflow.png','https://tensorflow.org/images/tf_logo.png')
img_raw = tf$io$read_file(img_path)
img = tf$io$decode_png(img_raw)
img = tf$image$convert_image_dtype(img, tf$float32)
img = tf$image$resize(img, c(500L,500L))
bw_img = 1.0 - tf$image$rgb_to_grayscale(img)
gray = tf$image$convert_image_dtype(bw_img,tf$uint8)
gray = tf$expand_dims(gray, 0L)
eucid = img_euclidean_dist_transform(gray)
eucid = tf$squeeze(eucid, c(0,-1))

## End(Not run)


</code></pre>

<hr>
<h2 id='img_flat_transforms_to_matrices'>Flat transforms to matrices</h2><span id='topic+img_flat_transforms_to_matrices'></span>

<h3>Description</h3>

<p>Converts projective transforms to affine matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_flat_transforms_to_matrices(transforms, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_flat_transforms_to_matrices_+3A_transforms">transforms</code></td>
<td>
<p>Vector of length 8, or batches of transforms with shape '(N, 8)'.</p>
</td></tr>
<tr><td><code id="img_flat_transforms_to_matrices_+3A_name">name</code></td>
<td>
<p>The name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the output matrices map output coordinates to input coordinates.
For the forward transformation matrix, call 'tf$linalg$inv' on the result.
</p>


<h3>Value</h3>

<p>3D tensor of matrices with shape '(N, 3, 3)'. The output matrices
map the *output coordinates* (in homogeneous coordinates) of each transform
to the corresponding *input coordinates*.
</p>


<h3>Raises</h3>

<p>ValueError: If 'transforms' have an invalid shape.
</p>

<hr>
<h2 id='img_from_4D'>From 4D image</h2><span id='topic+img_from_4D'></span>

<h3>Description</h3>

<p>Convert back to an image with 'ndims' rank.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_from_4D(image, ndims)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_from_4D_+3A_image">image</code></td>
<td>
<p>4D tensor.</p>
</td></tr>
<tr><td><code id="img_from_4D_+3A_ndims">ndims</code></td>
<td>
<p>The original rank of the image.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>'ndims'-D tensor with the same type.
</p>

<hr>
<h2 id='img_get_ndims'>Get ndims</h2><span id='topic+img_get_ndims'></span>

<h3>Description</h3>

<p>Print dimensions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_get_ndims(image)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_get_ndims_+3A_image">image</code></td>
<td>
<p>image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dimensions of the image
</p>

<hr>
<h2 id='img_interpolate_bilinear'>Interpolate bilinear</h2><span id='topic+img_interpolate_bilinear'></span>

<h3>Description</h3>

<p>Similar to Matlab's interp2 function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_interpolate_bilinear(grid, query_points, indexing = "ij", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_interpolate_bilinear_+3A_grid">grid</code></td>
<td>
<p>a 4-D float Tensor of shape [batch, height, width, channels].</p>
</td></tr>
<tr><td><code id="img_interpolate_bilinear_+3A_query_points">query_points</code></td>
<td>
<p>a 3-D float Tensor of N points with shape [batch, N, 2].</p>
</td></tr>
<tr><td><code id="img_interpolate_bilinear_+3A_indexing">indexing</code></td>
<td>
<p>whether the query points are specified as row and column (ij),
or Cartesian coordinates (xy).</p>
</td></tr>
<tr><td><code id="img_interpolate_bilinear_+3A_name">name</code></td>
<td>
<p>a name for the operation (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds values for query points on a grid using bilinear interpolation.
</p>


<h3>Value</h3>

<p>values: a 3-D 'Tensor' with shape '[batch, N, channels]'
</p>


<h3>Raises</h3>

<p>ValueError: if the indexing mode is invalid, or if the shape of the inputs invalid.
</p>

<hr>
<h2 id='img_interpolate_spline'>Interpolate spline</h2><span id='topic+img_interpolate_spline'></span>

<h3>Description</h3>

<p>Interpolate signal using polyharmonic interpolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_interpolate_spline(
  train_points,
  train_values,
  query_points,
  order,
  regularization_weight = 0,
  name = "interpolate_spline"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_interpolate_spline_+3A_train_points">train_points</code></td>
<td>
<p>'[batch_size, n, d]' float 'Tensor' of n d-dimensional
locations. These do not need to be regularly-spaced.</p>
</td></tr>
<tr><td><code id="img_interpolate_spline_+3A_train_values">train_values</code></td>
<td>
<p>'[batch_size, n, k]' float 'Tensor' of n c-dimensional
values evaluated at train_points.</p>
</td></tr>
<tr><td><code id="img_interpolate_spline_+3A_query_points">query_points</code></td>
<td>
<p>'[batch_size, m, d]' 'Tensor' of m d-dimensional locations
where we will output the interpolant's values.</p>
</td></tr>
<tr><td><code id="img_interpolate_spline_+3A_order">order</code></td>
<td>
<p>order of the interpolation. Common values are 1
for '\(\phi(r) = r\), 2 for \(\phi(r) = r^2 * log(r)\) (thin-plate spline), or 3 for \(\phi(r) = r^3\)'.</p>
</td></tr>
<tr><td><code id="img_interpolate_spline_+3A_regularization_weight">regularization_weight</code></td>
<td>
<p>weight placed on the regularization term. This will
depend substantially on the problem, and it should always be tuned. For many problems,
it is reasonable to use no regularization. If using a non-zero value, we recommend
a small value like 0.001.</p>
</td></tr>
<tr><td><code id="img_interpolate_spline_+3A_name">name</code></td>
<td>
<p>name prefix for ops created by this function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interpolant has the form
f(x) = '\sum_i = 1^n w_i \phi(||x - c_i||) + v^T x + b'. This is a sum of two terms:
(1) a weighted sum of radial basis function
(RBF) terms, with the centers \(c_1, ... c_n\), and (2) a linear term
with a bias. The \(c_i\) vectors are 'training' points.
In the code, b is absorbed into v
by appending 1 as a final dimension to x. The coefficients w and v are
estimated such that the interpolant exactly fits the value of the function
at the \(c_i\) points, the vector w is orthogonal to each \(c_i\),
and the vector w sums to 0. With these constraints, the coefficients
can be obtained by solving a linear system. '\(\phi\)' is an RBF, parametrized by
an interpolation
order. Using order=2 produces the well-known thin-plate spline. We also provide the
option to perform regularized interpolation. Here, the
interpolant is selected to trade off between the squared loss on the
training data and a certain measure of its curvature
([details](https://en.wikipedia.org/wiki/Polyharmonic_spline)).
Using a regularization weight greater than zero has the effect that the
interpolant will no longer exactly fit the training data. However, it may
be less vulnerable to overfitting, particularly for high-order
interpolation. Note the interpolation procedure is differentiable with respect to all
inputs besides the order parameter. We support dynamically-shaped inputs,
where batch_size, n, and m are NULL
at graph construction time. However, d and k must be known.
</p>


<h3>Value</h3>

<p>'[b, m, k]' float 'Tensor' of query values. We use train_points and train_values
to perform polyharmonic interpolation. The query values are the values of the interpolant
evaluated at the locations specified in query_points.
</p>


<h3>This is a sum of two terms</h3>

<p>(1) a weighted sum of radial basis function:
(RBF) terms, with the centers \(c_1, ... c_n\), and (2) a linear term with a bias.
The \(c_i\) vectors are 'training' points. In the code, b is absorbed into v by
appending 1 as a final dimension to x. The coefficients w and v are estimated such
that the interpolant exactly fits the value of the function at the \(c_i\) points,
the vector w is orthogonal to each \(c_i\), and the vector w sums to 0. With these
constraints, the coefficients can be obtained by solving a linear system.
</p>

<hr>
<h2 id='img_matrices_to_flat_transforms'>Matrices to flat transforms</h2><span id='topic+img_matrices_to_flat_transforms'></span>

<h3>Description</h3>

<p>Converts affine matrices to projective transforms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_matrices_to_flat_transforms(transform_matrices, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_matrices_to_flat_transforms_+3A_transform_matrices">transform_matrices</code></td>
<td>
<p>One or more affine transformation matrices, for the
reverse transformation in homogeneous coordinates. Shape 'c(3, 3)' or 'c(N, 3, 3)'.</p>
</td></tr>
<tr><td><code id="img_matrices_to_flat_transforms_+3A_name">name</code></td>
<td>
<p>The name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that we expect matrices that map output coordinates to input
coordinates. To convert forward transformation matrices,
call 'tf$linalg$inv' on the matrices and use the result here.
</p>


<h3>Value</h3>

<p>2D tensor of flat transforms with shape '(N, 8)', which may be passed into 'transform' op.
</p>


<h3>Raises</h3>

<p>ValueError: If 'transform_matrices' have an invalid shape.
</p>

<hr>
<h2 id='img_mean_filter2d'>Mean filter2d</h2><span id='topic+img_mean_filter2d'></span>

<h3>Description</h3>

<p>Perform mean filtering on image(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_mean_filter2d(
  image,
  filter_shape = list(3, 3),
  padding = "REFLECT",
  constant_values = 0,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_mean_filter2d_+3A_image">image</code></td>
<td>
<p>Either a 2-D Tensor of shape [height, width], a 3-D Tensor of
shape [height, width, channels], or a 4-D Tensor of
shape [batch_size, height, width, channels].</p>
</td></tr>
<tr><td><code id="img_mean_filter2d_+3A_filter_shape">filter_shape</code></td>
<td>
<p>An integer or tuple/list of 2 integers, specifying the height
and width of the 2-D mean filter. Can be a single integer to specify the same
value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="img_mean_filter2d_+3A_padding">padding</code></td>
<td>
<p>A string, one of &quot;REFLECT&quot;, &quot;CONSTANT&quot;, or &quot;SYMMETRIC&quot;. The type
of padding algorithm to use, which is compatible with mode argument in tf.pad.
For more details, please refer to https://www.tensorflow.org/api_docs/python/tf/pad.</p>
</td></tr>
<tr><td><code id="img_mean_filter2d_+3A_constant_values">constant_values</code></td>
<td>
<p>A scalar, the pad value to use in &quot;CONSTANT&quot; padding mode.</p>
</td></tr>
<tr><td><code id="img_mean_filter2d_+3A_name">name</code></td>
<td>
<p>A name for this operation (optional).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>3-D or 4-D 'Tensor' of the same dtype as input.
</p>


<h3>Raises</h3>

<p>ValueError: If 'image' is not 2, 3 or 4-dimensional, if 'padding' is other
than &quot;REFLECT&quot;, &quot;CONSTANT&quot; or &quot;SYMMETRIC&quot;, or if 'filter_shape' is invalid.
</p>

<hr>
<h2 id='img_median_filter2d'>Median filter2d</h2><span id='topic+img_median_filter2d'></span>

<h3>Description</h3>

<p>Perform median filtering on image(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_median_filter2d(
  image,
  filter_shape = list(3, 3),
  padding = "REFLECT",
  constant_values = 0,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_median_filter2d_+3A_image">image</code></td>
<td>
<p>Either a 2-D Tensor of shape [height, width], a 3-D Tensor of
shape [height, width, channels], or a 4-D Tensor of
shape [batch_size, height, width, channels].</p>
</td></tr>
<tr><td><code id="img_median_filter2d_+3A_filter_shape">filter_shape</code></td>
<td>
<p>An integer or tuple/list of 2 integers, specifying the height
and width of the 2-D median filter. Can be a single integer to specify the same
value for all spatial dimensions.</p>
</td></tr>
<tr><td><code id="img_median_filter2d_+3A_padding">padding</code></td>
<td>
<p>A string, one of &quot;REFLECT&quot;, &quot;CONSTANT&quot;, or &quot;SYMMETRIC&quot;. The type
of padding algorithm to use, which is compatible with mode argument in tf.pad. For
more details, please refer to https://www.tensorflow.org/api_docs/python/tf/pad.</p>
</td></tr>
<tr><td><code id="img_median_filter2d_+3A_constant_values">constant_values</code></td>
<td>
<p>A scalar, the pad value to use in &quot;CONSTANT&quot; padding mode.</p>
</td></tr>
<tr><td><code id="img_median_filter2d_+3A_name">name</code></td>
<td>
<p>A name for this operation (optional)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>3-D or 4-D 'Tensor' of the same dtype as input.
</p>


<h3>Raises</h3>

<p>ValueError: If 'image' is not 2, 3 or 4-dimensional, if 'padding' is other
than &quot;REFLECT&quot;, &quot;CONSTANT&quot; or &quot;SYMMETRIC&quot;, or if 'filter_shape' is invalid.
</p>

<hr>
<h2 id='img_random_cutout'>Random cutout</h2><span id='topic+img_random_cutout'></span>

<h3>Description</h3>

<p>Apply cutout (https://arxiv.org/abs/1708.04552) to images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_random_cutout(
  images,
  mask_size,
  constant_values = 0,
  seed = NULL,
  data_format = "channels_last"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_random_cutout_+3A_images">images</code></td>
<td>
<p>A tensor of shape (batch_size, height, width, channels) (NHWC),
(batch_size, channels, height, width)(NCHW).</p>
</td></tr>
<tr><td><code id="img_random_cutout_+3A_mask_size">mask_size</code></td>
<td>
<p>Specifies how big the zero mask that will be generated is that
is applied to the images. The mask will be of size (mask_height x mask_width).
Note: mask_size should be divisible by 2.</p>
</td></tr>
<tr><td><code id="img_random_cutout_+3A_constant_values">constant_values</code></td>
<td>
<p>What pixel value to fill in the images in the area that
has the cutout mask applied to it.</p>
</td></tr>
<tr><td><code id="img_random_cutout_+3A_seed">seed</code></td>
<td>
<p>An integer. Used in combination with 'tf$random$set_seed' to
create a reproducible sequence of tensors across multiple calls.</p>
</td></tr>
<tr><td><code id="img_random_cutout_+3A_data_format">data_format</code></td>
<td>
<p>A string, one of 'channels_last' (default) or 'channels_first'.
The ordering of the dimensions in the inputs. 'channels_last' corresponds to inputs
with shape '(batch_size, ..., channels)' while 'channels_first' corresponds to inputs
with shape '(batch_size, channels, ...)'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This operation applies a (mask_height x mask_width) mask of zeros to
a random location within 'img'. The pixel values filled in will be of the
value 'replace'. The located where the mask will be applied is randomly
chosen uniformly over the whole images.
</p>


<h3>Value</h3>

<p>An image Tensor.
</p>


<h3>Raises</h3>

<p>InvalidArgumentError: if mask_size can't be divisible by 2.
</p>

<hr>
<h2 id='img_random_hsv_in_yiq'>Random hsv in yiq</h2><span id='topic+img_random_hsv_in_yiq'></span>

<h3>Description</h3>

<p>Adjust hue, saturation, value of an RGB image randomly in YIQ color
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_random_hsv_in_yiq(
  image,
  max_delta_hue = 0,
  lower_saturation = 1,
  upper_saturation = 1,
  lower_value = 1,
  upper_value = 1,
  seed = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_random_hsv_in_yiq_+3A_image">image</code></td>
<td>
<p>RGB image or images. Size of the last dimension must be 3.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_max_delta_hue">max_delta_hue</code></td>
<td>
<p>float. Maximum value for the random delta_hue.
Passing 0 disables adjusting hue.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_lower_saturation">lower_saturation</code></td>
<td>
<p>float. Lower bound for the random scale_saturation.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_upper_saturation">upper_saturation</code></td>
<td>
<p>float. Upper bound for the random scale_saturation.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_lower_value">lower_value</code></td>
<td>
<p>float. Lower bound for the random scale_value.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_upper_value">upper_value</code></td>
<td>
<p>float. Upper bound for the random scale_value.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_seed">seed</code></td>
<td>
<p>An operation-specific seed. It will be used in conjunction with
the graph-level seed to determine the real seeds that will be used in this
operation. Please see the documentation of set_random_seed for its interaction
with the graph-level random seed.</p>
</td></tr>
<tr><td><code id="img_random_hsv_in_yiq_+3A_name">name</code></td>
<td>
<p>A name for this operation (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>space. Equivalent to 'adjust_yiq_hsv()' but uses a 'delta_h' randomly
picked in the interval '[-max_delta_hue, max_delta_hue]', a
'scale_saturation' randomly picked in the interval
'[lower_saturation, upper_saturation]', and a 'scale_value'
randomly picked in the interval '[lower_saturation, upper_saturation]'.
</p>


<h3>Value</h3>

<p>3-D float tensor of shape '[height, width, channels]'.
</p>


<h3>Raises</h3>

<p>ValueError: if 'max_delta', 'lower_saturation', 'upper_saturation',
'lower_value', or 'upper_value' is invalid.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
delta = 0.5
lower_saturation = 0.1
upper_saturation = 0.9
lower_value = 0.2
upper_value = 0.8
rand_hsvinyiq = img_random_hsv_in_yiq(img, delta,
lower_saturation, upper_saturation,
lower_value, upper_value)
)

## End(Not run)


</code></pre>

<hr>
<h2 id='img_resampler'>Resampler</h2><span id='topic+img_resampler'></span>

<h3>Description</h3>

<p>Resamples input data at user defined coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_resampler(data, warp, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_resampler_+3A_data">data</code></td>
<td>
<p>Tensor of shape [batch_size, data_height, data_width, data_num_channels]
containing 2D data that will be resampled.</p>
</td></tr>
<tr><td><code id="img_resampler_+3A_warp">warp</code></td>
<td>
<p>Tensor of minimum rank 2 containing the coordinates at which resampling
will be performed. Since only bilinear interpolation is currently supported, the last
dimension of the warp tensor must be 2, representing the (x, y) coordinate where x is
the index for width and y is the index for height.</p>
</td></tr>
<tr><td><code id="img_resampler_+3A_name">name</code></td>
<td>
<p>Optional name of the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resampler currently only supports bilinear interpolation of 2D data.
</p>


<h3>Value</h3>

<p>Tensor of resampled values from 'data'. The output tensor shape is determined
by the shape of the warp tensor. For example, if 'data' is of shape
'[batch_size, data_height, data_width, data_num_channels]' and warp of
shape '[batch_size, dim_0, ... , dim_n, 2]' the output will be of
shape '[batch_size, dim_0, ... , dim_n, data_num_channels]'.
</p>


<h3>Raises</h3>

<p>ImportError: if the wrapper generated during compilation is not present when the function is called.
</p>

<hr>
<h2 id='img_rotate'>Rotate</h2><span id='topic+img_rotate'></span>

<h3>Description</h3>

<p>Rotate image(s) counterclockwise by the passed angle(s) in radians.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_rotate(images, angles, interpolation = "NEAREST", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_rotate_+3A_images">images</code></td>
<td>
<p>A tensor of shape (num_images, num_rows, num_columns, num_channels) (NHWC),
(num_rows, num_columns, num_channels) (HWC), or (num_rows, num_columns) (HW).</p>
</td></tr>
<tr><td><code id="img_rotate_+3A_angles">angles</code></td>
<td>
<p>A scalar angle to rotate all images by, or (if images has rank 4) a vector
of length num_images, with an angle for each image in the batch.</p>
</td></tr>
<tr><td><code id="img_rotate_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: &quot;NEAREST&quot;, &quot;BILINEAR&quot;.</p>
</td></tr>
<tr><td><code id="img_rotate_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the same type and shape as 'images', rotated by the given angle(s).
Empty space due to the rotation will be filled with zeros.
</p>


<h3>Raises</h3>

<p>TypeError: If 'image' is an invalid type.
</p>

<hr>
<h2 id='img_sharpness'>Sharpness</h2><span id='topic+img_sharpness'></span>

<h3>Description</h3>

<p>Change sharpness of image(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_sharpness(image, factor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_sharpness_+3A_image">image</code></td>
<td>
<p>an image</p>
</td></tr>
<tr><td><code id="img_sharpness_+3A_factor">factor</code></td>
<td>
<p>A floating point value or Tensor above 0.0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the same type and shape as 'images', sharper.
</p>

<hr>
<h2 id='img_shear_x'>Shear x-axis</h2><span id='topic+img_shear_x'></span>

<h3>Description</h3>

<p>Perform shear operation on an image (x-axis)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_shear_x(image, level, replace)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_shear_x_+3A_image">image</code></td>
<td>
<p>A 3D image Tensor.</p>
</td></tr>
<tr><td><code id="img_shear_x_+3A_level">level</code></td>
<td>
<p>A float denoting shear element along y-axis</p>
</td></tr>
<tr><td><code id="img_shear_x_+3A_replace">replace</code></td>
<td>
<p>A one or three value 1D tensor to fill empty pixels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed image along X or Y axis, with space outside image filled with replace.
</p>

<hr>
<h2 id='img_shear_y'>Shear y-axis</h2><span id='topic+img_shear_y'></span>

<h3>Description</h3>

<p>Perform shear operation on an image (y-axis)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_shear_y(image, level, replace)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_shear_y_+3A_image">image</code></td>
<td>
<p>A 3D image Tensor.</p>
</td></tr>
<tr><td><code id="img_shear_y_+3A_level">level</code></td>
<td>
<p>A float denoting shear element along x-axis</p>
</td></tr>
<tr><td><code id="img_shear_y_+3A_replace">replace</code></td>
<td>
<p>A one or three value 1D tensor to fill empty pixels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Transformed image along X or Y axis, with space outside image filled with replace.
</p>

<hr>
<h2 id='img_sparse_image_warp'>Sparse image warp</h2><span id='topic+img_sparse_image_warp'></span>

<h3>Description</h3>

<p>Image warping using correspondences between sparse control points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_sparse_image_warp(
  image,
  source_control_point_locations,
  dest_control_point_locations,
  interpolation_order = 2,
  regularization_weight = 0,
  num_boundary_points = 0,
  name = "sparse_image_warp"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_sparse_image_warp_+3A_image">image</code></td>
<td>
<p>'[batch, height, width, channels]' float 'Tensor'</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_source_control_point_locations">source_control_point_locations</code></td>
<td>
<p>'[batch, num_control_points, 2]' float 'Tensor'</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_dest_control_point_locations">dest_control_point_locations</code></td>
<td>
<p>'[batch, num_control_points, 2]' float 'Tensor'</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_interpolation_order">interpolation_order</code></td>
<td>
<p>polynomial order used by the spline interpolation</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_regularization_weight">regularization_weight</code></td>
<td>
<p>weight on smoothness regularizer in interpolation</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_num_boundary_points">num_boundary_points</code></td>
<td>
<p>How many zero-flow boundary points to include at each image edge.
Usage:
num_boundary_points=0: don't add zero-flow points
num_boundary_points=1: 4 corners of the image
num_boundary_points=2: 4 corners and one in the middle of each edge (8 points total)
num_boundary_points=n: 4 corners and n-1 along each edge</p>
</td></tr>
<tr><td><code id="img_sparse_image_warp_+3A_name">name</code></td>
<td>
<p>A name for the operation (optional).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Apply a non-linear warp to the image, where the warp is specified by
the source and destination locations of a (potentially small) number of
control points. First, we use a polyharmonic spline
('tf$contrib$image$interpolate_spline') to interpolate the displacements
between the corresponding control points to a dense flow field.
Then, we warp the image using this dense flow field
('tf$contrib$image$dense_image_warp'). Let t index our control points.
For regularization_weight=0, we have:
warped_image[b, dest_control_point_locations[b, t, 0],
dest_control_point_locations[b, t, 1], :] =
image[b, source_control_point_locations[b, t, 0],
source_control_point_locations[b, t, 1], :]. For regularization_weight &gt; 0,
this condition is met approximately, since
regularized interpolation trades off smoothness of the interpolant vs.
reconstruction of the interpolant at the control points.
See 'tf$contrib$image$interpolate_spline' for further documentation of the
interpolation_order and regularization_weight arguments.
</p>


<h3>Value</h3>

<p>warped_image: '[batch, height, width, channels]' float 'Tensor' with
same type as input image. flow_field: '[batch, height, width, 2]'
float 'Tensor' containing the dense flow field produced by the interpolation.
</p>

<hr>
<h2 id='img_to_4D'>To 4D image</h2><span id='topic+img_to_4D'></span>

<h3>Description</h3>

<p>Convert 2/3/4D image to 4D image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_to_4D(image)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_to_4D_+3A_image">image</code></td>
<td>
<p>2/3/4D tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>4D tensor with the same type.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
img_to_4D(img)

## End(Not run)

</code></pre>

<hr>
<h2 id='img_transform'>Transform</h2><span id='topic+img_transform'></span>

<h3>Description</h3>

<p>Applies the given transform(s) to the image(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_transform(
  images,
  transforms,
  interpolation = "NEAREST",
  output_shape = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_transform_+3A_images">images</code></td>
<td>
<p>A tensor of shape (num_images, num_rows, num_columns, num_channels)
(NHWC), (num_rows, num_columns, num_channels) (HWC), or (num_rows, num_columns) (HW).</p>
</td></tr>
<tr><td><code id="img_transform_+3A_transforms">transforms</code></td>
<td>
<p>Projective transform matrix/matrices. A vector of length 8 or tensor
of size N x 8. If one row of transforms is [a0, a1, a2, b0, b1, b2, c0, c1], then it
maps the output point (x, y) to a transformed input point
(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k), where k = c0 x + c1 y + 1.
The transforms are inverted compared to the transform mapping input points to output points.
Note that gradients are not backpropagated into transformation parameters.</p>
</td></tr>
<tr><td><code id="img_transform_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: &quot;NEAREST&quot;, &quot;BILINEAR&quot;.</p>
</td></tr>
<tr><td><code id="img_transform_+3A_output_shape">output_shape</code></td>
<td>
<p>Output dimesion after the transform, [height, width]. If NULL,
output is the same size as input image.</p>
</td></tr>
<tr><td><code id="img_transform_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the same type and shape as 'images', with
the given transform(s) applied. Transformed coordinates outside of the
input image will be filled with zeros.
</p>


<h3>Raises</h3>

<p>TypeError: If 'image' is an invalid type. ValueError: If output shape is not 1-D int32 Tensor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
transform = img_transform(img, c(1.0, 1.0, -250, 0.0, 1.0, 0.0, 0.0, 0.0))

## End(Not run)



</code></pre>

<hr>
<h2 id='img_translate'>Translate</h2><span id='topic+img_translate'></span>

<h3>Description</h3>

<p>Translate image(s) by the passed vectors(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_translate(images, translations, interpolation = "NEAREST", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_translate_+3A_images">images</code></td>
<td>
<p>A tensor of shape (num_images, num_rows, num_columns, num_channels) (NHWC),
(num_rows, num_columns, num_channels) (HWC), or (num_rows, num_columns) (HW). The rank must
be statically known (the shape is not TensorShape(None)).</p>
</td></tr>
<tr><td><code id="img_translate_+3A_translations">translations</code></td>
<td>
<p>A vector representing [dx, dy] or (if images has rank 4) a matrix of
length num_images, with a [dx, dy] vector for each image in the batch.</p>
</td></tr>
<tr><td><code id="img_translate_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: &quot;NEAREST&quot;, &quot;BILINEAR&quot;.</p>
</td></tr>
<tr><td><code id="img_translate_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image(s) with the same type and shape as 'images', translated by the
given vector(s). Empty space due to the translation will be filled with zeros.
</p>


<h3>Raises</h3>

<p>TypeError: If 'images' is an invalid type.
</p>

<hr>
<h2 id='img_translate_xy'>Translate xy dims</h2><span id='topic+img_translate_xy'></span>

<h3>Description</h3>

<p>Translates image in X or Y dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_translate_xy(image, translate_to, replace)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_translate_xy_+3A_image">image</code></td>
<td>
<p>A 3D image Tensor.</p>
</td></tr>
<tr><td><code id="img_translate_xy_+3A_translate_to">translate_to</code></td>
<td>
<p>A 1D tensor to translate [x, y]</p>
</td></tr>
<tr><td><code id="img_translate_xy_+3A_replace">replace</code></td>
<td>
<p>A one or three value 1D tensor to fill empty pixels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Translated image along X or Y axis, with space outside image
filled with replace. Raises: ValueError: if axis is neither 0 nor 1.
</p>


<h3>Raises</h3>

<p>ValueError: if axis is neither 0 nor 1.
</p>

<hr>
<h2 id='img_translations_to_projective_transforms'>Translations to projective transforms</h2><span id='topic+img_translations_to_projective_transforms'></span>

<h3>Description</h3>

<p>Returns projective transform(s) for the given translation(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_translations_to_projective_transforms(translations, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_translations_to_projective_transforms_+3A_translations">translations</code></td>
<td>
<p>A 2-element list representing [dx, dy] or a matrix of 2-element
lists representing [dx, dy] to translate for each image (for a batch of images). The
rank must be statically known (the shape is not 'TensorShape(NULL)').</p>
</td></tr>
<tr><td><code id="img_translations_to_projective_transforms_+3A_name">name</code></td>
<td>
<p>The name of the op.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of shape c(num_images, 8) projective transforms which can be given to 'img_transform'.
</p>

<hr>
<h2 id='img_unwrap'>Uwrap</h2><span id='topic+img_unwrap'></span>

<h3>Description</h3>

<p>Unwraps an image produced by wrap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_unwrap(image, replace)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_unwrap_+3A_image">image</code></td>
<td>
<p>image</p>
</td></tr>
<tr><td><code id="img_unwrap_+3A_replace">replace</code></td>
<td>
<p>a one or three value 1D tensor to fill empty pixels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Where there is a 0 in the last channel for every spatial position,
the rest of the three channels in that spatial dimension are grayed (set to 128).
Operations like translate and shear on a wrapped Tensor will leave 0s in empty
locations. Some transformations look at the intensity of values to do preprocessing,
and we want these empty pixels to assume the 'average' value, rather than pure black.
</p>


<h3>Value</h3>

<p>a 3D image Tensor with 3 channels.
</p>

<hr>
<h2 id='img_wrap'>Wrap</h2><span id='topic+img_wrap'></span>

<h3>Description</h3>

<p>wrap an image array
</p>


<h3>Usage</h3>

<pre><code class='language-R'>img_wrap(image)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="img_wrap_+3A_image">image</code></td>
<td>
<p>a 3D Image Tensor with 4 channels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>'image' with an extra channel set to all 1s.
</p>

<hr>
<h2 id='install_tfaddons'>Install TensorFlow SIG Addons</h2><span id='topic+install_tfaddons'></span>

<h3>Description</h3>

<p>This function is used to install the 'TensorFlow SIG Addons' python module
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_tfaddons(version = NULL, ..., restart_session = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_tfaddons_+3A_version">version</code></td>
<td>
<p>for specific version of 'TensorFlow SIG Addons', e.g. &quot;0.10.0&quot;</p>
</td></tr>
<tr><td><code id="install_tfaddons_+3A_...">...</code></td>
<td>
<p>other arguments passed to [reticulate::py_install()].</p>
</td></tr>
<tr><td><code id="install_tfaddons_+3A_restart_session">restart_session</code></td>
<td>
<p>Restart R session after installing (note this will only occur within RStudio).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a python module 'tensorflow_addons'
</p>

<hr>
<h2 id='layer_activation_gelu'>Gaussian Error Linear Unit</h2><span id='topic+layer_activation_gelu'></span>

<h3>Description</h3>

<p>Gaussian Error Linear Unit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_activation_gelu(object, approximate = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_activation_gelu_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_activation_gelu_+3A_approximate">approximate</code></td>
<td>
<p>(bool) Whether to apply approximation</p>
</td></tr>
<tr><td><code id="layer_activation_gelu_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A smoother version of ReLU generally used in the BERT or BERT architecture based
models. Original paper: https://arxiv.org/abs/1606.08415
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Note</h3>

<p>Input shape: Arbitrary. Use the keyword argument 'input_shape' (tuple of integers, d
oes not include the samples axis) when using this layer as the first layer in a model.
</p>
<p>Output shape: Same shape as the input.
</p>

<hr>
<h2 id='layer_correlation_cost'>Correlation Cost Layer.</h2><span id='topic+layer_correlation_cost'></span>

<h3>Description</h3>

<p>Correlation Cost Layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_correlation_cost(
  object,
  kernel_size,
  max_displacement,
  stride_1,
  stride_2,
  pad,
  data_format,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_correlation_cost_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_kernel_size">kernel_size</code></td>
<td>
<p>An integer specifying the height and width of the
patch used to compute the per-patch costs.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_max_displacement">max_displacement</code></td>
<td>
<p>An integer specifying the maximum search radius
for each position.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_stride_1">stride_1</code></td>
<td>
<p>An integer specifying the stride length in the input.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_stride_2">stride_2</code></td>
<td>
<p>An integer specifying the stride length in the patch.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_pad">pad</code></td>
<td>
<p>An integer specifying the paddings in height and width.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_data_format">data_format</code></td>
<td>
<p>Specifies the data format. Possible values are:
&quot;channels_last&quot; float [batch, height, width, channels] &quot;channels_first&quot;
float [batch, channels, height, width] Defaults to &quot;channels_last&quot;.</p>
</td></tr>
<tr><td><code id="layer_correlation_cost_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This layer implements the correlation operation from FlowNet
Learning Optical Flow with Convolutional Networks (Fischer et al.):
https://arxiv.org/abs/1504.06
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_filter_response_normalization'>FilterResponseNormalization</h2><span id='topic+layer_filter_response_normalization'></span>

<h3>Description</h3>

<p>Filter response normalization layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_filter_response_normalization(
  object,
  epsilon = 1e-06,
  axis = c(1, 2),
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  learned_epsilon = FALSE,
  learned_epsilon_constraint = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_filter_response_normalization_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Small positive float value added to variance to avoid dividing by zero.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_axis">axis</code></td>
<td>
<p>List of axes that should be normalized. This should represent the spatial dimensions.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_beta_initializer">beta_initializer</code></td>
<td>
<p>Initializer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_gamma_initializer">gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_beta_regularizer">beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_gamma_regularizer">gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_beta_constraint">beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_gamma_constraint">gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_learned_epsilon">learned_epsilon</code></td>
<td>
<p>(bool) Whether to add another learnable epsilon parameter or not.</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_learned_epsilon_constraint">learned_epsilon_constraint</code></td>
<td>
<p>learned_epsilon_constraint</p>
</td></tr>
<tr><td><code id="layer_filter_response_normalization_+3A_name">name</code></td>
<td>
<p>Optional name for the layer</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Filter Response Normalization (FRN), a normalization
method that enables models trained with per-channel
normalization to achieve high accuracy. It performs better than
all other normalization techniques for small batches and is par
with Batch Normalization for bigger batch sizes.
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Note</h3>

<p>Input shape Arbitrary. Use the keyword argument 'input_shape' (list of integers,
does not include the samples axis) when using this layer as the first layer in a model.
This layer, as of now, works on a 4-D tensor where the tensor should have the
shape [N X H X W X C] TODO: Add support for NCHW data format and FC layers. Output shape
Same shape as input. References - [Filter Response Normalization Layer: Eliminating Batch
Dependence in the training of Deep Neural Networks] (https://arxiv.org/abs/1911.09737)
</p>

<hr>
<h2 id='layer_group_normalization'>Group normalization layer</h2><span id='topic+layer_group_normalization'></span>

<h3>Description</h3>

<p>Group normalization layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_group_normalization(
  object,
  groups = 2,
  axis = -1,
  epsilon = 0.001,
  center = TRUE,
  scale = TRUE,
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_group_normalization_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_groups">groups</code></td>
<td>
<p>Integer, the number of groups for Group Normalization. Can be in the range [1, N]
where N is the input dimension. The input dimension must be divisible by the number of groups.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer, the axis that should be normalized.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Small float added to variance to avoid dividing by zero.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_center">center</code></td>
<td>
<p>If TRUE, add offset of beta to normalized tensor. If False, beta is ignored.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_scale">scale</code></td>
<td>
<p>If TRUE, multiply by gamma. If False, gamma is not used.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_beta_initializer">beta_initializer</code></td>
<td>
<p>Initializer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_gamma_initializer">gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_beta_regularizer">beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_gamma_regularizer">gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_beta_constraint">beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_gamma_constraint">gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_group_normalization_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Group Normalization divides the channels into groups and computes within each group
the mean and variance for normalization. Empirically, its accuracy is more stable than batch
norm in a wide range of small batch sizes, if learning rate is adjusted linearly with batch
sizes. Relation to Layer Normalization: If the number of groups is set to 1, then this operation
becomes identical to Layer Normalization. Relation to Instance Normalization: If the number of
groups is set to the input dimension (number of groups is equal to number of channels), then this
operation becomes identical to Instance Normalization.
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_instance_normalization'>Instance normalization layer</h2><span id='topic+layer_instance_normalization'></span>

<h3>Description</h3>

<p>Instance normalization layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_instance_normalization(
  object,
  groups = 2,
  axis = -1,
  epsilon = 0.001,
  center = TRUE,
  scale = TRUE,
  beta_initializer = "zeros",
  gamma_initializer = "ones",
  beta_regularizer = NULL,
  gamma_regularizer = NULL,
  beta_constraint = NULL,
  gamma_constraint = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_instance_normalization_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_groups">groups</code></td>
<td>
<p>Integer, the number of groups for Group Normalization. Can be in the
range [1, N] where N is the input dimension. The input dimension must be divisible
by the number of groups.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_axis">axis</code></td>
<td>
<p>Integer, the axis that should be normalized.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_epsilon">epsilon</code></td>
<td>
<p>Small float added to variance to avoid dividing by zero.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_center">center</code></td>
<td>
<p>If TRUE, add offset of 'beta' to normalized tensor. If FALSE, 'beta' is ignored.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_scale">scale</code></td>
<td>
<p>If TRUE, multiply by 'gamma'. If FALSE, 'gamma' is not used.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_beta_initializer">beta_initializer</code></td>
<td>
<p>Initializer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_gamma_initializer">gamma_initializer</code></td>
<td>
<p>Initializer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_beta_regularizer">beta_regularizer</code></td>
<td>
<p>Optional regularizer for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_gamma_regularizer">gamma_regularizer</code></td>
<td>
<p>Optional regularizer for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_beta_constraint">beta_constraint</code></td>
<td>
<p>Optional constraint for the beta weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_gamma_constraint">gamma_constraint</code></td>
<td>
<p>Optional constraint for the gamma weight.</p>
</td></tr>
<tr><td><code id="layer_instance_normalization_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instance Normalization is an specific case of &ldquo;'GroupNormalizationsince&ldquo;'
it normalizes all features of one channel. The Groupsize is equal to the channel
size. Empirically, its accuracy is more stable than batch norm in a wide range of
small batch sizes, if learning rate is adjusted linearly with batch sizes.
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>References</h3>

<p>[Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022)
</p>

<hr>
<h2 id='layer_maxout'>Maxout layer</h2><span id='topic+layer_maxout'></span>

<h3>Description</h3>

<p>Maxout layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_maxout(object, num_units, axis = -1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_maxout_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_maxout_+3A_num_units">num_units</code></td>
<td>
<p>Specifies how many features will remain after maxout in the axis dimension
(usually channel). This must be a factor of number of features.</p>
</td></tr>
<tr><td><code id="layer_maxout_+3A_axis">axis</code></td>
<td>
<p>The dimension where max pooling will be performed. Default is the last dimension.</p>
</td></tr>
<tr><td><code id="layer_maxout_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&quot;Maxout Networks&quot; Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza,
Aaron Courville, Yoshua Bengio. https://arxiv.org/abs/1302.4389 Usually the operation
is performed in the filter/channel dimension. This can also be used after Dense layers
to reduce number of features.
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_multi_head_attention'>Keras-based multi head attention layer</h2><span id='topic+layer_multi_head_attention'></span>

<h3>Description</h3>

<p>MultiHead Attention layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_multi_head_attention(
  object,
  head_size,
  num_heads,
  output_size = NULL,
  dropout = 0,
  use_projection_bias = TRUE,
  return_attn_coef = FALSE,
  kernel_initializer = "glorot_uniform",
  kernel_regularizer = NULL,
  kernel_constraint = NULL,
  bias_initializer = "zeros",
  bias_regularizer = NULL,
  bias_constraint = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_multi_head_attention_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_head_size">head_size</code></td>
<td>
<p>int, dimensionality of the 'query', 'key' and 'value' tensors after the linear transformation.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_num_heads">num_heads</code></td>
<td>
<p>int, number of attention heads.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_output_size">output_size</code></td>
<td>
<p>int, dimensionality of the output space, if 'NULL' then the input dimension of 'value' or 'key' will be used, default 'NULL'.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_dropout">dropout</code></td>
<td>
<p>float, 'rate' parameter for the dropout layer that is applied to attention after softmax, default '0'.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_use_projection_bias">use_projection_bias</code></td>
<td>
<p>bool, whether to use a bias term after the linear output projection.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_return_attn_coef">return_attn_coef</code></td>
<td>
<p>bool, if 'TRUE', return the attention coefficients as an additional output argument.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>initializer, initializer for the kernel weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>regularizer, regularizer for the kernel weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>constraint, constraint for the kernel weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>initializer, initializer for the bias weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>regularizer, regularizer for the bias weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>constraint, constraint for the bias weights.</p>
</td></tr>
<tr><td><code id="layer_multi_head_attention_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Defines the MultiHead Attention operation as defined in
[Attention Is All You Need](https://arxiv.org/abs/1706.03762) which takes
in a 'query', 'key' and 'value' tensors returns the dot-product attention
between them.
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

mha = layer_multi_head_attention(head_size=128, num_heads=128)
query = tf$random$uniform(list(32L, 20L, 200L)) # (batch_size, query_elements, query_depth)
key = tf$random$uniform(list(32L, 15L, 300L)) # (batch_size, key_elements, key_depth)
value = tf$random$uniform(list(32L, 15L, 400L)) # (batch_size, key_elements, value_depth)
attention = mha(list(query, key, value)) # (batch_size, query_elements, value_depth)

# If `value` is not given then internally `value = key` will be used:
mha = layer_multi_head_attention(head_size=128, num_heads=128)
query = tf$random$uniform(list(32L, 20L, 200L)) # (batch_size, query_elements, query_depth)
key = tf$random$uniform(list(32L, 15L, 300L)) # (batch_size, key_elements, key_depth)
attention = mha(list(query, key)) # (batch_size, query_elements, value_depth)


## End(Not run)

</code></pre>

<hr>
<h2 id='layer_nas_cell'>Neural Architecture Search (NAS) recurrent network cell.</h2><span id='topic+layer_nas_cell'></span>

<h3>Description</h3>

<p>Neural Architecture Search (NAS) recurrent network cell.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_nas_cell(
  object,
  units,
  projection = NULL,
  use_bias = FALSE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "glorot_uniform",
  projection_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_nas_cell_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_units">units</code></td>
<td>
<p>int, The number of units in the NAS cell.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_projection">projection</code></td>
<td>
<p>(optional) int, The output dimensionality for the projection matrices.
If None, no projection is performed.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_use_bias">use_bias</code></td>
<td>
<p>(optional) bool, If 'TRUE' then use biases within the cell.
This is 'FALSE' by default.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for kernel weight.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for recurrent kernel weight.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_projection_initializer">projection_initializer</code></td>
<td>
<p>Initializer for projection weight, used when projection
is not 'NULL'.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for bias, used when 'use_bias' is 'TRUE'.</p>
</td></tr>
<tr><td><code id="layer_nas_cell_+3A_...">...</code></td>
<td>
<p>Additional keyword arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implements the recurrent cell from the paper: https://arxiv.org/abs/1611.01578
Barret Zoph and Quoc V. Le. &quot;Neural Architecture Search with Reinforcement Learning&quot;
Proc. ICLR 2017. The class uses an optional projection layer.
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_norm_lstm_cell'>LSTM cell with layer normalization and recurrent dropout.</h2><span id='topic+layer_norm_lstm_cell'></span>

<h3>Description</h3>

<p>LSTM cell with layer normalization and recurrent dropout.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_norm_lstm_cell(
  object,
  units,
  activation = "tanh",
  recurrent_activation = "sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  dropout = 0,
  recurrent_dropout = 0,
  norm_gamma_initializer = "ones",
  norm_beta_initializer = "zeros",
  norm_epsilon = 0.001,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_norm_lstm_cell_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_units">units</code></td>
<td>
<p>Positive integer, dimensionality of the output space.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_activation">activation</code></td>
<td>
<p>Activation function to use. Default: hyperbolic tangent ('tanh'). If
you pass 'NULL', no activation is applied (ie. &quot;linear&quot; activation: 'a(x) = x').</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_recurrent_activation">recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.
Default: sigmoid ('sigmoid'). If you pass 'NULL', no activation is applied
(ie. &quot;linear&quot; activation: 'a(x) = x').</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_use_bias">use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_kernel_initializer">kernel_initializer</code></td>
<td>
<p>Initializer for the 'kernel' weights matrix, used for the
linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_recurrent_initializer">recurrent_initializer</code></td>
<td>
<p>Initializer for the 'recurrent_kernel' weights matrix,
used for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_bias_initializer">bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_unit_forget_bias">unit_forget_bias</code></td>
<td>
<p>Boolean. If True, add 1 to the bias of the forget gate at initialization.
Setting it to true will also force 'bias_initializer=&quot;zeros&quot;'. This is
recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_kernel_regularizer">kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the 'kernel' weights matrix.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_recurrent_regularizer">recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the 'recurrent_kernel' weights matrix.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_bias_regularizer">bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_kernel_constraint">kernel_constraint</code></td>
<td>
<p>Constraint function applied to the 'kernel' weights matrix.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_recurrent_constraint">recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the 'recurrent_kernel' weights matrix.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_bias_constraint">bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_dropout">dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_recurrent_dropout">recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_norm_gamma_initializer">norm_gamma_initializer</code></td>
<td>
<p>Initializer for the layer normalization gain initial value.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_norm_beta_initializer">norm_beta_initializer</code></td>
<td>
<p>Initializer for the layer normalization shift initial value.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_norm_epsilon">norm_epsilon</code></td>
<td>
<p>Float, the epsilon value for normalization layers.</p>
</td></tr>
<tr><td><code id="layer_norm_lstm_cell_+3A_...">...</code></td>
<td>
<p>List, the other keyword arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This class adds layer normalization and recurrent dropout to a LSTM unit. Layer
normalization implementation is based on: https://arxiv.org/abs/1607.06450.
&quot;Layer Normalization&quot; Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton and is
applied before the internal nonlinearities.
Recurrent dropout is based on: https://arxiv.org/abs/1603.05118
&quot;Recurrent Dropout without Memory Loss&quot; Stanislau Semeniuta, Aliaksei Severyn, Erhardt Barth.
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_poincare_normalize'>Project into the Poincare ball with norm &lt;= 1.0 - epsilon</h2><span id='topic+layer_poincare_normalize'></span>

<h3>Description</h3>

<p>Project into the Poincare ball with norm &lt;= 1.0 - epsilon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_poincare_normalize(object, axis = 1, epsilon = 1e-05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_poincare_normalize_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_poincare_normalize_+3A_axis">axis</code></td>
<td>
<p>Axis along which to normalize.  A scalar or a vector of integers.</p>
</td></tr>
<tr><td><code id="layer_poincare_normalize_+3A_epsilon">epsilon</code></td>
<td>
<p>A small deviation from the edge of the unit sphere for numerical stability.</p>
</td></tr>
<tr><td><code id="layer_poincare_normalize_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>https://en.wikipedia.org/wiki/Poincare_ball_model Used in Poincare Embeddings
for Learning Hierarchical Representations Maximilian Nickel, Douwe Kiela
https://arxiv.org/pdf/1705.08039.pdf For a 1-D tensor with axis = 0, computes
</p>


<h3>Value</h3>

<p>A tensor
</p>

<hr>
<h2 id='layer_sparsemax'>Sparsemax activation function</h2><span id='topic+layer_sparsemax'></span>

<h3>Description</h3>

<p>Sparsemax activation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_sparsemax(object, axis = -1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_sparsemax_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_sparsemax_+3A_axis">axis</code></td>
<td>
<p>Integer, axis along which the sparsemax normalization is applied.</p>
</td></tr>
<tr><td><code id="layer_sparsemax_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output shape is the same as the input shape. https://arxiv.org/abs/1602.02068
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
                activation = activation_gelu) %&gt;%
  layer_sparsemax()

## End(Not run)


</code></pre>

<hr>
<h2 id='layer_weight_normalization'>Weight Normalization layer</h2><span id='topic+layer_weight_normalization'></span>

<h3>Description</h3>

<p>Weight Normalization layer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>layer_weight_normalization(object, layer, data_init = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="layer_weight_normalization_+3A_object">object</code></td>
<td>
<p>Model or layer object</p>
</td></tr>
<tr><td><code id="layer_weight_normalization_+3A_layer">layer</code></td>
<td>
<p>a layer instance.</p>
</td></tr>
<tr><td><code id="layer_weight_normalization_+3A_data_init">data_init</code></td>
<td>
<p>If 'TRUE' use data dependent variable initialization</p>
</td></tr>
<tr><td><code id="layer_weight_normalization_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This wrapper reparameterizes a layer by decoupling the weight's magnitude and
direction.
This speeds up convergence by improving the conditioning of the optimization problem.
Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural
Networks: https://arxiv.org/abs/1602.07868 Tim Salimans, Diederik P. Kingma (2016)
WeightNormalization wrapper works for keras and tf layers.
</p>


<h3>Value</h3>

<p>A tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

model= keras_model_sequential() %&gt;%
layer_weight_normalization(
layer_conv_2d(filters = 2, kernel_size = 2, activation = 'relu'),
input_shape = c(32L, 32L, 3L))
model



## End(Not run)

</code></pre>

<hr>
<h2 id='lookahead_mechanism'>Lookahead mechanism</h2><span id='topic+lookahead_mechanism'></span>

<h3>Description</h3>

<p>Lookahead mechanism
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lookahead_mechanism(
  optimizer,
  sync_period = 6,
  slow_step_size = 0.5,
  name = "Lookahead",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lookahead_mechanism_+3A_optimizer">optimizer</code></td>
<td>
<p>The original optimizer that will be used to compute and apply the gradients.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_sync_period">sync_period</code></td>
<td>
<p>An integer. The synchronization period of lookahead. Enable lookahead mechanism
by setting it with a positive value.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_slow_step_size">slow_step_size</code></td>
<td>
<p>A floating point value. The ratio for updating the slow weights.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;Lookahead&quot;.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="lookahead_mechanism_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mechanism is proposed by Michael R. Zhang et.al in the paper
[Lookahead Optimizer: k steps forward, 1 step back](https://arxiv.org/abs/1907.08610v1).
The optimizer iteratively updates two sets of weights: the search directions for weights
are chosen by the inner optimizer, while the &quot;slow weights&quot; are updated each k steps based
on the directions of the &quot;fast weights&quot; and the two sets of weights are synchronized.
This method improves the learning stability and lowers the variance of its inner optimizer.
</p>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

opt = tf$keras$optimizers$SGD(learning_rate)
opt = lookahead_mechanism(opt)


## End(Not run)
</code></pre>

<hr>
<h2 id='loss_contrastive'>Contrastive loss</h2><span id='topic+loss_contrastive'></span>

<h3>Description</h3>

<p>Computes the contrastive loss between 'y_true' and 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_contrastive(
  margin = 1,
  reduction = tf$keras$losses$Reduction$SUM_OVER_BATCH_SIZE,
  name = "contrasitve_loss"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_contrastive_+3A_margin">margin</code></td>
<td>
<p>Float, margin term in the loss definition. Default value is 1.0.</p>
</td></tr>
<tr><td><code id="loss_contrastive_+3A_reduction">reduction</code></td>
<td>
<p>(Optional) Type of tf$keras$losses$Reduction to apply.
Default value is SUM_OVER_BATCH_SIZE.</p>
</td></tr>
<tr><td><code id="loss_contrastive_+3A_name">name</code></td>
<td>
<p>(Optional) name for the loss.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This loss encourages the embedding to be close to each other for
the samples of the same label and the embedding to be far apart at least
by the margin constant for the samples of different labels.
The euclidean distances 'y_pred' between two embedding matrices
'a' and 'b' with shape [batch_size, hidden_size] can be computed
as follows: &ldquo;'python
# y_pred = '\sqrt' ('\sum_i' (a[:, i] - b[:, i])^2)
y_pred = tf$linalg.norm(a - b, axis=1)
&ldquo;' See: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
</p>


<h3>Value</h3>

<p>contrastive_loss: 1-D float 'Tensor' with shape [batch_size].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(4, input_shape = c(784)) %&gt;%
  compile(
    optimizer = 'sgd',
    loss=loss_contrastive(),
    metrics='accuracy'
  )

## End(Not run)

</code></pre>

<hr>
<h2 id='loss_giou'>Implements the GIoU loss function.</h2><span id='topic+loss_giou'></span>

<h3>Description</h3>

<p>GIoU loss was first introduced in the [Generalized Intersection over Union:
A Metric and A Loss for Bounding Box Regression](https://giou.stanford.edu/GIoU.pdf).
GIoU is an enhancement for models which use IoU in object detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_giou(
  mode = "giou",
  reduction = tf$keras$losses$Reduction$AUTO,
  name = "giou_loss"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_giou_+3A_mode">mode</code></td>
<td>
<p>one of ['giou', 'iou'], decided to calculate GIoU or IoU loss.</p>
</td></tr>
<tr><td><code id="loss_giou_+3A_reduction">reduction</code></td>
<td>
<p>(Optional) Type of tf$keras$losses$Reduction to apply.
Default value is SUM_OVER_BATCH_SIZE.</p>
</td></tr>
<tr><td><code id="loss_giou_+3A_name">name</code></td>
<td>
<p>A name for the operation (optional).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>GIoU loss float 'Tensor'.
</p>

<hr>
<h2 id='loss_hamming'>Hamming loss</h2><span id='topic+loss_hamming'></span>

<h3>Description</h3>

<p>Computes hamming loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_hamming(
  mode,
  name = "hamming_loss",
  threshold = NULL,
  dtype = tf$float32,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_hamming_+3A_mode">mode</code></td>
<td>
<p>multi-class or multi-label</p>
</td></tr>
<tr><td><code id="loss_hamming_+3A_name">name</code></td>
<td>
<p>(optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="loss_hamming_+3A_threshold">threshold</code></td>
<td>
<p>Elements of 'y_pred' greater than threshold are converted to be 1,
and the rest 0. If threshold is None, the argmax is converted to 1, and the rest 0.</p>
</td></tr>
<tr><td><code id="loss_hamming_+3A_dtype">dtype</code></td>
<td>
<p>(optional) Data type of the metric result. Defaults to 'tf$float32'.</p>
</td></tr>
<tr><td><code id="loss_hamming_+3A_...">...</code></td>
<td>
<p>additional arguments that are passed on to function 'fn'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hamming loss is the fraction of wrong labels to the total number of labels.
In multi-class classification, hamming loss is calculated as the hamming distance
between 'actual' and 'predictions'. In multi-label classification, hamming loss
penalizes only the individual labels.
</p>


<h3>Value</h3>

<p>hamming loss: float
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# multi-class hamming loss
hl = loss_hamming(mode='multiclass', threshold=0.6)
actuals = tf$constant(list(as.integer(c(1, 0, 0, 0)),as.integer(c(0, 0, 1, 0)),
                       as.integer(c(0, 0, 0, 1)),as.integer(c(0, 1, 0, 0))),
                      dtype=tf$float32)
predictions = tf$constant(list(c(0.8, 0.1, 0.1, 0),
                           c(0.2, 0, 0.8, 0),
                           c(0.05, 0.05, 0.1, 0.8),
                           c(1, 0, 0, 0)),
                          dtype=tf$float32)
hl$update_state(actuals, predictions)
paste('Hamming loss: ', hl$result()$numpy()) # 0.25
# multi-label hamming loss
hl = loss_hamming(mode='multilabel', threshold=0.8)
actuals = tf$constant(list(as.integer(c(1, 0, 1, 0)),as.integer(c(0, 1, 0, 1)),
                       as.integer(c(0, 0, 0,1))), dtype=tf$int32)
predictions = tf$constant(list(c(0.82, 0.5, 0.90, 0),
                           c(0, 1, 0.4, 0.98),
                           c(0.89, 0.79, 0, 0.3)),
                          dtype=tf$float32)
hl$update_state(actuals, predictions)
paste('Hamming loss: ', hl$result()$numpy()) # 0.16666667


## End(Not run)

</code></pre>

<hr>
<h2 id='loss_lifted_struct'>Lifted structured loss</h2><span id='topic+loss_lifted_struct'></span>

<h3>Description</h3>

<p>Computes the lifted structured loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_lifted_struct(margin = 1, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_lifted_struct_+3A_margin">margin</code></td>
<td>
<p>Float, margin term in the loss definition.</p>
</td></tr>
<tr><td><code id="loss_lifted_struct_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
<tr><td><code id="loss_lifted_struct_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The loss encourages the positive distances (between a pair of embeddings
with the same labels) to be smaller than any negative distances (between a pair of
embeddings with different labels) in the mini-batch in a way that is differentiable
with respect to the embedding vectors. See: https://arxiv.org/abs/1511.06452
</p>


<h3>Value</h3>

<p>lifted_loss: tf$float32 scalar.
</p>

<hr>
<h2 id='loss_npairs'>Npairs loss</h2><span id='topic+loss_npairs'></span>

<h3>Description</h3>

<p>Computes the npairs loss between 'y_true' and 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_npairs(name = "npairs_loss")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_npairs_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Npairs loss expects paired data where a pair is composed of samples from
the same labels and each pairs in the minibatch have different labels.
The loss takes each row of the pair-wise similarity matrix, 'y_pred',
as logits and the remapped multi-class labels, 'y_true', as labels. The
similarity matrix 'y_pred' between two embedding matrices 'a' and 'b'
with shape '[batch_size, hidden_size]' can be computed as follows:
&ldquo;'
# y_pred = a * b^T
y_pred = tf$matmul(a, b, transpose_a=FALSE, transpose_b=TRUE)
&ldquo;'
See: http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf
</p>


<h3>Value</h3>

<p>npairs_loss: float scalar.
</p>

<hr>
<h2 id='loss_npairs_multilabel'>Npairs multilabel loss</h2><span id='topic+loss_npairs_multilabel'></span>

<h3>Description</h3>

<p>Computes the npairs loss between multilabel data 'y_true' and 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_npairs_multilabel(name = "npairs_multilabel_loss")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_npairs_multilabel_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Npairs loss expects paired data where a pair is composed of samples from
the same labels and each pairs in the minibatch have different labels.
The loss takes each row of the pair-wise similarity matrix, 'y_pred',
as logits and the remapped multi-class labels, 'y_true', as labels. To deal with
multilabel inputs, the count of label intersection
is computed as follows:
&ldquo;'
L_i,j = | set_of_labels_for(i) '\cap' set_of_labels_for(j) |
&ldquo;'
Each row of the count based label matrix is further normalized so that
each row sums to one. 'y_true' should be a binary indicator for classes.
That is, if 'y_true[i, j] = 1', then 'i'th sample is in 'j'th class;
if 'y_true[i, j] = 0', then 'i'th sample is not in 'j'th class. The similarity matrix
'y_pred' between two embedding matrices 'a' and 'b'
with shape '[batch_size, hidden_size]' can be computed as follows:
&ldquo;'
# y_pred = a * b^T
y_pred = tf.matmul(a, b, transpose_a=FALSE, transpose_b=TRUE)
&ldquo;'
</p>


<h3>Value</h3>

<p>npairs_multilabel_loss: float scalar.
</p>


<h3>See</h3>

<p>http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf
</p>

<hr>
<h2 id='loss_pinball'>Pinball loss</h2><span id='topic+loss_pinball'></span>

<h3>Description</h3>

<p>Computes the pinball loss between 'y_true' and 'y_pred'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_pinball(
  tau = 0.5,
  reduction = tf$keras$losses$Reduction$AUTO,
  name = "pinball_loss"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_pinball_+3A_tau">tau</code></td>
<td>
<p>(Optional) Float in [0, 1] or a tensor taking values in [0, 1] and
shape = [d0,..., dn]. It defines the slope of the pinball loss. In the context
of quantile regression, the value of tau determines the conditional quantile
level. When tau = 0.5, this amounts to l1 regression, an estimator of the
conditional median (0.5 quantile).</p>
</td></tr>
<tr><td><code id="loss_pinball_+3A_reduction">reduction</code></td>
<td>
<p>(Optional) Type of tf.keras.losses.Reduction to apply to loss.
Default value is AUTO. AUTO indicates that the reduction option will be determined
by the usage context. For almost all cases this defaults to SUM_OVER_BATCH_SIZE.
When used with tf.distribute.Strategy, outside of built-in training loops such as
tf$keras compile and fit, using AUTO or SUM_OVER_BATCH_SIZE will raise an error.
Please see https://www.tensorflow.org/alpha/tutorials/distribute/training_loops
for more details on this.</p>
</td></tr>
<tr><td><code id="loss_pinball_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>'loss = maximum(tau * (y_true - y_pred), (tau - 1) * (y_true - y_pred))' In the context of regression this, loss yields an estimator of the tau
conditional quantile. See: https://en.wikipedia.org/wiki/Quantile_regression Usage:
&ldquo;'python
loss = pinball_loss([0., 0., 1., 1.], [1., 1., 1., 0.], tau=.1) # loss = max(0.1 * (y_true - y_pred), (0.1 - 1) * (y_true - y_pred))
# = (0.9 + 0.9 + 0 + 0.1) / 4 print('Loss: ', loss$numpy()) # Loss: 0.475
&ldquo;'
</p>


<h3>Value</h3>

<p>pinball_loss: 1-D float 'Tensor' with shape [batch_size].
</p>
<p>pinball_loss: 1-D float 'Tensor' with shape [batch_size].
</p>


<h3>Usage</h3>

<p>&ldquo;'python_loss = pinball_loss([0., 0., 1., 1.], [1., 1., 1., 0.], tau=.1) &ldquo;&ldquo;
</p>


<h3>References</h3>

<p>- https://en.wikipedia.org/wiki/Quantile_regression - https://projecteuclid.org/download/pdfview_1/euclid.bj/1297173840
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(4, input_shape = c(784)) %&gt;%
  compile(
    optimizer = 'sgd',
    loss=loss_pinball(),
    metrics='accuracy'
  )

## End(Not run)


</code></pre>

<hr>
<h2 id='loss_sequence'>Weighted cross-entropy loss for a sequence of logits.</h2><span id='topic+loss_sequence'></span>

<h3>Description</h3>

<p>Weighted cross-entropy loss for a sequence of logits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_sequence(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_sequence_+3A_...">...</code></td>
<td>
<p>A list of parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='loss_sigmoid_focal_crossentropy'>Sigmoid focal crossentropy loss</h2><span id='topic+loss_sigmoid_focal_crossentropy'></span>

<h3>Description</h3>

<p>Sigmoid focal crossentropy loss
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_sigmoid_focal_crossentropy(
  from_logits = FALSE,
  alpha = 0.25,
  gamma = 2,
  reduction = tf$keras$losses$Reduction$NONE,
  name = "sigmoid_focal_crossentropy"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_sigmoid_focal_crossentropy_+3A_from_logits">from_logits</code></td>
<td>
<p>If logits are provided then convert the predictions into probabilities</p>
</td></tr>
<tr><td><code id="loss_sigmoid_focal_crossentropy_+3A_alpha">alpha</code></td>
<td>
<p>balancing factor.</p>
</td></tr>
<tr><td><code id="loss_sigmoid_focal_crossentropy_+3A_gamma">gamma</code></td>
<td>
<p>modulating factor.</p>
</td></tr>
<tr><td><code id="loss_sigmoid_focal_crossentropy_+3A_reduction">reduction</code></td>
<td>
<p>(Optional) Type of tf$keras$losses$Reduction to apply.
Default value is SUM_OVER_BATCH_SIZE.</p>
</td></tr>
<tr><td><code id="loss_sigmoid_focal_crossentropy_+3A_name">name</code></td>
<td>
<p>(Optional) name for the loss.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Weighted loss float 'Tensor'. If 'reduction' is 'NONE',this has the same shape as 'y_true';
otherwise, it is scalar.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(4, input_shape = c(784)) %&gt;%
  compile(
    optimizer = 'sgd',
    loss=loss_sigmoid_focal_crossentropy(),
    metrics='accuracy'
  )

## End(Not run)


</code></pre>

<hr>
<h2 id='loss_sparsemax'>Sparsemax loss</h2><span id='topic+loss_sparsemax'></span>

<h3>Description</h3>

<p>Sparsemax loss function [1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_sparsemax(
  from_logits = TRUE,
  reduction = tf$keras$losses$Reduction$SUM_OVER_BATCH_SIZE,
  name = "sparsemax_loss"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_sparsemax_+3A_from_logits">from_logits</code></td>
<td>
<p>Whether y_pred is expected to be a logits tensor.
Default is True, meaning y_pred is the logits.</p>
</td></tr>
<tr><td><code id="loss_sparsemax_+3A_reduction">reduction</code></td>
<td>
<p>(Optional) Type of tf$keras$losses$Reduction to apply
to loss. Default value is SUM_OVER_BATCH_SIZE.</p>
</td></tr>
<tr><td><code id="loss_sparsemax_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the generalized multi-label classification loss for the sparsemax
function. The implementation is a reformulation of the original loss
function such that it uses the sparsemax properbility output instead of the
internal au variable. However, the output is identical to the original
loss function. [1]: https://arxiv.org/abs/1602.02068
</p>


<h3>Value</h3>

<p>A 'Tensor'. Has the same type as 'logits'.
</p>

<hr>
<h2 id='loss_triplet_hard'>Triplet hard loss</h2><span id='topic+loss_triplet_hard'></span>

<h3>Description</h3>

<p>Computes the triplet loss with hard negative and hard positive mining.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_triplet_hard(margin = 1, soft = FALSE, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_triplet_hard_+3A_margin">margin</code></td>
<td>
<p>Float, margin term in the loss definition. Default value is 1.0.</p>
</td></tr>
<tr><td><code id="loss_triplet_hard_+3A_soft">soft</code></td>
<td>
<p>Boolean, if set, use the soft margin version. Default value is False.</p>
</td></tr>
<tr><td><code id="loss_triplet_hard_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
<tr><td><code id="loss_triplet_hard_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>triplet_loss: float scalar with dtype of y_pred.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_conv_2d(filters = 64, kernel_size = 2, padding='same', input_shape=c(28,28,1)) %&gt;%
  layer_max_pooling_2d(pool_size=2) %&gt;%
  layer_flatten() %&gt;%
  layer_dense(256, activation= NULL) %&gt;%
  layer_lambda(f = function(x) tf$math$l2_normalize(x, axis = 1L))

model %&gt;% compile(
  optimizer = optimizer_lazy_adam(),
  # apply triplet semihard loss
  loss = loss_triplet_hard())

## End(Not run)

</code></pre>

<hr>
<h2 id='loss_triplet_semihard'>Triplet semihard loss</h2><span id='topic+loss_triplet_semihard'></span>

<h3>Description</h3>

<p>Computes the triplet loss with semi-hard negative mining.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss_triplet_semihard(margin = 1, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loss_triplet_semihard_+3A_margin">margin</code></td>
<td>
<p>Float, margin term in the loss definition. Default value is 1.0.</p>
</td></tr>
<tr><td><code id="loss_triplet_semihard_+3A_name">name</code></td>
<td>
<p>Optional name for the op.</p>
</td></tr>
<tr><td><code id="loss_triplet_semihard_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>triplet_loss: float scalar with dtype of y_pred.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_conv_2d(filters = 64, kernel_size = 2, padding='same', input_shape=c(28,28,1)) %&gt;%
  layer_max_pooling_2d(pool_size=2) %&gt;%
  layer_flatten() %&gt;%
  layer_dense(256, activation= NULL) %&gt;%
  layer_lambda(f = function(x) tf$math$l2_normalize(x, axis = 1L))

model %&gt;% compile(
  optimizer = optimizer_lazy_adam(),
  # apply triplet semihard loss
  loss = loss_triplet_semihard())

## End(Not run)


</code></pre>

<hr>
<h2 id='metric_cohen_kappa'>Computes Kappa score between two raters</h2><span id='topic+metric_cohen_kappa'></span>

<h3>Description</h3>

<p>Computes Kappa score between two raters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_cohen_kappa(
  num_classes,
  name = "cohen_kappa",
  weightage = NULL,
  sparse_labels = FALSE,
  regression = FALSE,
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_cohen_kappa_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of unique classes in your dataset.</p>
</td></tr>
<tr><td><code id="metric_cohen_kappa_+3A_name">name</code></td>
<td>
<p>(optional) String name of the metric instance</p>
</td></tr>
<tr><td><code id="metric_cohen_kappa_+3A_weightage">weightage</code></td>
<td>
<p>(optional) Weighting to be considered for calculating kappa statistics.
A valid value is one of [None, 'linear', 'quadratic']. Defaults to 'NULL'</p>
</td></tr>
<tr><td><code id="metric_cohen_kappa_+3A_sparse_labels">sparse_labels</code></td>
<td>
<p>(bool) Valid only for multi-class scenario. If True, ground truth
labels are expected tp be integers and not one-hot encoded</p>
</td></tr>
<tr><td><code id="metric_cohen_kappa_+3A_regression">regression</code></td>
<td>
<p>(bool) If set, that means the problem is being treated as a regression
problem where you are regressing the predictions. **Note:** If you are regressing for the
values, the the output layer should contain a single unit.</p>
</td></tr>
<tr><td><code id="metric_cohen_kappa_+3A_dtype">dtype</code></td>
<td>
<p>(optional) Data type of the metric result. Defaults to 'NULL'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The score lies in the range [-1, 1]. A score of -1 represents complete
disagreement between two raters whereas a score of 1 represents complete agreement
between the two raters. A score of 0 means agreement by chance.
</p>


<h3>Value</h3>

<p>Input tensor or list of input tensors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_dense(units = 10, input_shape = ncol(iris) - 1,activation = activation_lisht) %&gt;%
  layer_dense(units = 3)

model %&gt;% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_radam(),
                  metrics = metric_cohen_kappa(3))

## End(Not run)



</code></pre>

<hr>
<h2 id='metric_fbetascore'>FBetaScore</h2><span id='topic+metric_fbetascore'></span>

<h3>Description</h3>

<p>Computes F-Beta score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_fbetascore(
  num_classes,
  average = NULL,
  beta = 1,
  threshold = NULL,
  name = "fbeta_score",
  dtype = tf$float32,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_fbetascore_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of unique classes in the dataset.</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_average">average</code></td>
<td>
<p>Type of averaging to be performed on data. Acceptable
values are None, micro, macro and weighted. Default value is NULL.
micro, macro and weighted. Default value is NULL.
- None: Scores for each class are returned
- micro: True positivies, false positives and false negatives are computed globally.
- macro: True positivies, false positives and
- false negatives are computed for each class and their unweighted mean is returned.
- weighted: Metrics are computed for each class and returns the mean weighted by the number of
true instances in each class.-</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_beta">beta</code></td>
<td>
<p>Determines the weight of precision and recall in harmonic mean.
Determines the weight given to the precision and recall. Default value is 1.</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_threshold">threshold</code></td>
<td>
<p>Elements of y_pred greater than threshold are converted to be 1,
and the rest 0. If threshold is None, the argmax is converted to 1, and the rest 0.</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_name">name</code></td>
<td>
<p>(optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_dtype">dtype</code></td>
<td>
<p>(optional) Data type of the metric result. Defaults to 'tf$float32'.</p>
</td></tr>
<tr><td><code id="metric_fbetascore_+3A_...">...</code></td>
<td>
<p>additional parameters to pass</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is the weighted harmonic mean of precision
and recall. Output range is [0, 1]. Works for
both multi-class and multi-label classification.
F-Beta = (1 + beta^2) * (prec * recall) / ((beta^2 * prec) + recall)
</p>


<h3>Value</h3>

<p>F-Beta Score: float
</p>


<h3>Raises</h3>

<p>ValueError: If the 'average' has values other than [NULL, micro, macro, weighted].
</p>

<hr>
<h2 id='metric_hamming_distance'>Hamming distance</h2><span id='topic+metric_hamming_distance'></span>

<h3>Description</h3>

<p>Computes hamming distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_hamming_distance(actuals, predictions)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_hamming_distance_+3A_actuals">actuals</code></td>
<td>
<p>actual value</p>
</td></tr>
<tr><td><code id="metric_hamming_distance_+3A_predictions">predictions</code></td>
<td>
<p>predicted value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hamming distance is for comparing two binary strings.
It is the number of bit positions in which two bits
are different.
</p>


<h3>Value</h3>

<p>hamming distance: float
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

actuals = tf$constant(as.integer(c(1, 1, 0, 0, 1, 0, 1, 0, 0, 1)), dtype=tf$int32)
predictions = tf$constant(as.integer(c(1, 0, 0, 0, 1, 0, 0, 1, 0, 1)),dtype=tf$int32)
result = metric_hamming_distance(actuals, predictions)
paste('Hamming distance: ', result$numpy())


## End(Not run)

</code></pre>

<hr>
<h2 id='metric_mcc'>MatthewsCorrelationCoefficient</h2><span id='topic+metric_mcc'></span>

<h3>Description</h3>

<p>Computes the Matthews Correlation Coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_mcc(
  num_classes = NULL,
  name = "MatthewsCorrelationCoefficient",
  dtype = tf$float32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_mcc_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of unique classes in the dataset.</p>
</td></tr>
<tr><td><code id="metric_mcc_+3A_name">name</code></td>
<td>
<p>(Optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_mcc_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) Data type of the metric result. Defaults to 'tf$float32'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The statistic is also known as the phi coefficient.
The Matthews correlation coefficient (MCC) is used in
machine learning as a measure of the quality of binary
and multiclass classifications. It takes into account
true and false positives and negatives and is generally
regarded as a balanced measure which can be used even
if the classes are of very different sizes. The correlation
coefficient value of MCC is between -1 and +1. A
coefficient of +1 represents a perfect prediction,
0 an average random prediction and -1 an inverse
prediction. The statistic is also known as
the phi coefficient. MCC = (TP * TN) - (FP * FN) / ((TP + FP) * (TP + FN) * (TN + FP ) * (TN + FN))^(1/2) Usage:
</p>


<h3>Value</h3>

<p>Matthews correlation coefficient: float
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

actuals = tf$constant(list(1, 1, 1, 0), dtype=tf$float32)
preds = tf$constant(list(1,0,1,1), dtype=tf$float32)
# Matthews correlation coefficient
mcc = metric_mcc(num_classes=1)
mcc$update_state(actuals, preds)
paste('Matthews correlation coefficient is:', mcc$result()$numpy())
# Matthews correlation coefficient is : -0.33333334


## End(Not run)


</code></pre>

<hr>
<h2 id='metric_multilabel_confusion_matrix'>MultiLabelConfusionMatrix</h2><span id='topic+metric_multilabel_confusion_matrix'></span>

<h3>Description</h3>

<p>Computes Multi-label confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_multilabel_confusion_matrix(
  num_classes,
  name = "Multilabel_confusion_matrix",
  dtype = tf$int32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_multilabel_confusion_matrix_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of unique classes in the dataset.</p>
</td></tr>
<tr><td><code id="metric_multilabel_confusion_matrix_+3A_name">name</code></td>
<td>
<p>(Optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_multilabel_confusion_matrix_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) Data type of the metric result. Defaults to 'tf$int32'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Class-wise confusion matrix is computed for the
evaluation of classification. If multi-class input is provided, it will be treated
as multilabel data. Consider classification problem with two classes
(i.e num_classes=2). Resultant matrix 'M' will be in the shape of (num_classes, 2, 2).
Every class 'i' has a dedicated 2*2 matrix that contains: - true negatives for class i in M(0,0)
- false positives for class i in M(0,1)
- false negatives for class i in M(1,0)
- true positives for class i in M(1,1) &ldquo;'python
# multilabel confusion matrix
y_true = tf$constant(list(as.integer(c(1, 0, 1)), as.integer(c(0, 1, 0))), dtype=tf$int32)
y_pred = tf$constant(list(as.integer(c(1, 0, 0)), as.integer(c(0, 1, 1))), dtype=tf$int32)
output = metric_multilabel_confusion_matrix(num_classes=3)
output$update_state(y_true, y_pred)
paste('Confusion matrix:', output$result())
# Confusion matrix: [[[1 0] [0 1]] [[1 0] [0 1]] [[0 1] [1 0]]] # if multiclass input is provided
y_true = tf$constant(list(as.integer(c(1, 0, 0)), as.integer(c(0, 1, 0))), dtype=tf$int32)
y_pred = tf$constant(list(as.integer(c(1, 0, 0)), as.integer(c(0, 0, 1))), dtype=tf$int32)
output = metric_multilabel_confusion_matrix(num_classes=3)
output$update_state(y_true, y_pred)
paste('Confusion matrix:', output$result())
# Confusion matrix: [[[1 0] [0 1]] [[1 0] [1 0]] [[1 1] [0 0]]]
&ldquo;'
</p>


<h3>Value</h3>

<p>MultiLabelConfusionMatrix: float
</p>

<hr>
<h2 id='metric_rsquare'>RSquare
This is also called as coefficient of determination. It tells how close
are data to the fitted regression line. Highest score can be 1.0 and it
indicates that the predictors perfectly accounts for variation in the target.
Score 0.0 indicates that the predictors do not account for variation in the
target. It can also be negative if the model is worse.</h2><span id='topic+metric_rsquare'></span>

<h3>Description</h3>

<p>RSquare
</p>
<p>This is also called as coefficient of determination. It tells how close
are data to the fitted regression line. Highest score can be 1.0 and it
indicates that the predictors perfectly accounts for variation in the target.
Score 0.0 indicates that the predictors do not account for variation in the
target. It can also be negative if the model is worse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_rsquare(
  name = "r_square",
  dtype = tf$float32,
  ...,
  multioutput = "uniform_average"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_rsquare_+3A_name">name</code></td>
<td>
<p>(Optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="metric_rsquare_+3A_dtype">dtype</code></td>
<td>
<p>(Optional) Data type of the metric result. Defaults to 'tf$float32'.</p>
</td></tr>
<tr><td><code id="metric_rsquare_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
<tr><td><code id="metric_rsquare_+3A_multioutput">multioutput</code></td>
<td>
<p>one of the following: &quot;raw_values&quot;, &quot;uniform_average&quot;, &quot;variance_weighted&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>r squared score: float
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

actuals = tf$constant(c(1, 4, 3), dtype=tf$float32)
preds = tf$constant(c(2, 4, 4), dtype=tf$float32)
result = metric_rsquare()
result$update_state(actuals, preds)
paste('R^2 score is: ', r1$result()$numpy()) # 0.57142866


## End(Not run)
</code></pre>

<hr>
<h2 id='metrics_f1score'>F1Score</h2><span id='topic+metrics_f1score'></span>

<h3>Description</h3>

<p>Computes F-1 Score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metrics_f1score(
  num_classes,
  average = NULL,
  threshold = NULL,
  name = "f1_score",
  dtype = tf$float32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metrics_f1score_+3A_num_classes">num_classes</code></td>
<td>
<p>Number of unique classes in the dataset.</p>
</td></tr>
<tr><td><code id="metrics_f1score_+3A_average">average</code></td>
<td>
<p>Type of averaging to be performed on data. Acceptable values are NULL,
micro, macro and weighted. Default value is NULL.
- None: Scores for each class are returned
- micro: True positivies, false positives and false negatives are computed globally.
- macro: True positivies, false positives and
- false negatives are computed for each class and their unweighted mean is returned.
- weighted: Metrics are computed for each class and returns the mean weighted by the number of
true instances in each class.</p>
</td></tr>
<tr><td><code id="metrics_f1score_+3A_threshold">threshold</code></td>
<td>
<p>Elements of y_pred above threshold are considered to be 1, and the rest 0.
If threshold is NULL, the argmax is converted to 1, and the rest 0.</p>
</td></tr>
<tr><td><code id="metrics_f1score_+3A_name">name</code></td>
<td>
<p>(optional) String name of the metric instance.</p>
</td></tr>
<tr><td><code id="metrics_f1score_+3A_dtype">dtype</code></td>
<td>
<p>(optional) Data type of the metric result. Defaults to 'tf$float32'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is the harmonic mean of precision and recall.
Output range is [0, 1]. Works for both multi-class
and multi-label classification. F-1 = 2 * (precision * recall) / (precision + recall)
</p>


<h3>Value</h3>

<p>F-1 Score: float
</p>


<h3>Raises</h3>

<p>ValueError: If the 'average' has values other than [NULL, micro, macro, weighted].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
model = keras_model_sequential() %&gt;%
  layer_dense(units = 10, input_shape = ncol(iris) - 1,activation = activation_lisht) %&gt;%
  layer_dense(units = 3)

model %&gt;% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_radam(),
                  metrics = metrics_f1score(3))

## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_conditional_gradient'>Conditional Gradient</h2><span id='topic+optimizer_conditional_gradient'></span>

<h3>Description</h3>

<p>Conditional Gradient
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_conditional_gradient(
  learning_rate,
  lambda_,
  epsilon = 1e-07,
  use_locking = FALSE,
  name = "ConditionalGradient",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_conditional_gradient_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A Tensor or a floating point value, or a schedule that is a tf$keras$optimizers$schedules$LearningRateSchedule The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_lambda_">lambda_</code></td>
<td>
<p>A Tensor or a floating point value. The constraint.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_epsilon">epsilon</code></td>
<td>
<p>A Tensor or a floating point value. A small constant for numerical stability when handling the case of norm of gradient to be zero.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_use_locking">use_locking</code></td>
<td>
<p>If True, use locks for update operations.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_name">name</code></td>
<td>
<p>Optional name prefix for the operations created when applying gradients. Defaults to 'ConditionalGradient'.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_conditional_gradient_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>

<hr>
<h2 id='optimizer_decay_adamw'>Optimizer that implements the Adam algorithm with weight decay</h2><span id='topic+optimizer_decay_adamw'></span>

<h3>Description</h3>

<p>This is an implementation of the AdamW optimizer described in &quot;Decoupled Weight Decay Regularization&quot;
by Loshchilov &amp; Hutter (https://arxiv.org/abs/1711.05101) ([pdf])(https://arxiv.org/pdf/1711.05101.pdf). It computes
the update step of tf.keras.optimizers.Adam and additionally decays the variable. Note that this is different
from adding L2 regularization on the variables to the loss: it regularizes variables with large gradients more than
L2 regularization would, which was shown to yield better training loss and generalization error in the paper above.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_decay_adamw(
  weight_decay,
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  amsgrad = FALSE,
  name = "AdamW",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_decay_adamw_+3A_weight_decay">weight_decay</code></td>
<td>
<p>A Tensor or a floating point value. The weight decay.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A Tensor or a floating point value. The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability. This epsilon is &quot;epsilon hat&quot; in
the Kingma and Ba paper (in the formula just before Section 2.1),
not the epsilon in Algorithm 1 of the paper.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_amsgrad">amsgrad</code></td>
<td>
<p>boolean. Whether to apply AMSGrad variant of this algorithm from the paper
&quot;On the Convergence of Adam and beyond&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_decay_adamw_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

step = tf$Variable(0L, trainable = FALSE)
schedule = tf$optimizers$schedules$PiecewiseConstantDecay(list(c(10000, 15000)),
list(c(1e-0, 1e-1, 1e-2)))
lr = 1e-1 * schedule(step)
wd = lambda: 1e-4 * schedule(step)


## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_decay_sgdw'>Optimizer that implements the Momentum algorithm with weight_decay</h2><span id='topic+optimizer_decay_sgdw'></span>

<h3>Description</h3>

<p>This is an implementation of the SGDW optimizer described in &quot;Decoupled Weight Decay Regularization&quot;
by Loshchilov &amp; Hutter (https://arxiv.org/abs/1711.05101) ([pdf])(https://arxiv.org/pdf/1711.05101.pdf).
It computes the update step of tf.keras.optimizers.SGD and additionally decays the variable. Note that this
is different from adding L2 regularization on the variables to the loss. Decoupling the weight decay from other
hyperparameters (in particular the learning rate) simplifies hyperparameter search. For further information see
the documentation of the SGD Optimizer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_decay_sgdw(
  weight_decay,
  learning_rate = 0.001,
  momentum = 0,
  nesterov = FALSE,
  name = "SGDW",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_decay_sgdw_+3A_weight_decay">weight_decay</code></td>
<td>
<p>weight decay rate.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_learning_rate">learning_rate</code></td>
<td>
<p>float hyperparameter &gt;= 0. Learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_momentum">momentum</code></td>
<td>
<p>float hyperparameter &gt;= 0 that accelerates SGD in the relevant direction and dampens oscillations.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_nesterov">nesterov</code></td>
<td>
<p>boolean. Whether to apply Nesterov momentum.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_name">name</code></td>
<td>
<p>Optional name prefix for the operations created when applying gradients. Defaults to 'SGD'.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_decay_sgdw_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

step = tf$Variable(0L, trainable = FALSE)
schedule = tf$optimizers$schedules$PiecewiseConstantDecay(list(c(10000, 15000)),
list(c(1e-0, 1e-1, 1e-2)))
lr = 1e-1 * schedule(step)
wd = lambda: 1e-4 * schedule(step)


## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_lamb'>Layer-wise Adaptive Moments</h2><span id='topic+optimizer_lamb'></span>

<h3>Description</h3>

<p>Layer-wise Adaptive Moments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_lamb(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-06,
  weight_decay_rate = 0,
  exclude_from_weight_decay = NULL,
  exclude_from_layer_adaptation = NULL,
  name = "LAMB",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_lamb_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A 'Tensor' or a floating point value. or a schedule that is a 'tf$keras$optimizers$schedules$LearningRateSchedule' The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_beta_1">beta_1</code></td>
<td>
<p>A 'float' value or a constant 'float' tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_beta_2">beta_2</code></td>
<td>
<p>A 'float' value or a constant 'float' tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_weight_decay_rate">weight_decay_rate</code></td>
<td>
<p>weight decay rate.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_exclude_from_weight_decay">exclude_from_weight_decay</code></td>
<td>
<p>List of regex patterns of variables excluded from weight decay. Variables whose name contain a substring matching the pattern will be excluded.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_exclude_from_layer_adaptation">exclude_from_layer_adaptation</code></td>
<td>
<p>List of regex patterns of variables excluded from layer adaptation. Variables whose name contain a substring matching the pattern will be excluded.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;LAMB&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_lamb_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(32, input_shape = c(784)) %&gt;%
  compile(
    optimizer = optimizer_lamb(),
    loss='binary_crossentropy',
    metrics='accuracy'
  )

## End(Not run)


</code></pre>

<hr>
<h2 id='optimizer_lazy_adam'>Lazy Adam</h2><span id='topic+optimizer_lazy_adam'></span>

<h3>Description</h3>

<p>Lazy Adam
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_lazy_adam(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  amsgrad = FALSE,
  name = "LazyAdam",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_lazy_adam_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A Tensor or a floating point value. or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability. This epsilon is &quot;epsilon hat&quot; in Adam: A Method for Stochastic Optimization. Kingma et al., 2014 (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_amsgrad">amsgrad</code></td>
<td>
<p>boolean. Whether to apply AMSGrad variant of this algorithm from the paper &quot;On the Convergence of Adam and beyond&quot;. Note that this argument is currently not supported and the argument can only be False.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;LazyAdam&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm;</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value,</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_lazy_adam_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(32, input_shape = c(784)) %&gt;%
  compile(
    optimizer = optimizer_lazy_adam(),
    loss='binary_crossentropy',
    metrics='accuracy'
  )

## End(Not run)


</code></pre>

<hr>
<h2 id='optimizer_moving_average'>Moving Average</h2><span id='topic+optimizer_moving_average'></span>

<h3>Description</h3>

<p>Moving Average
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_moving_average(
  optimizer,
  sequential_update = TRUE,
  average_decay = 0.99,
  num_updates = NULL,
  name = "MovingAverage",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_moving_average_+3A_optimizer">optimizer</code></td>
<td>
<p>str or tf$keras$optimizers$Optimizer that will be used to compute
and apply gradients.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_sequential_update">sequential_update</code></td>
<td>
<p>Bool. If False, will compute the moving average at the same
time as the model is updated, potentially doing benign data races. If True, will update
the moving average after gradient updates.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_average_decay">average_decay</code></td>
<td>
<p>float. Decay to use to maintain the moving averages of trained variables.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_num_updates">num_updates</code></td>
<td>
<p>Optional count of the number of updates applied to variables.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients.
Defaults to &quot;MovingAverage&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_moving_average_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optimizer that computes a moving average of the variables.
Empirically it has been found that using the moving average of the
trained parameters of a deep network is better than using its trained
parameters directly. This optimizer allows you to compute this moving
average and swap the variables at save time so that any code outside
of the training loop will use by default the average values
instead of the original ones.
</p>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

opt = tf$keras$optimizers$SGD(learning_rate)
opt = moving_average(opt)


## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_novograd'>NovoGrad</h2><span id='topic+optimizer_novograd'></span>

<h3>Description</h3>

<p>NovoGrad
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_novograd(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  weight_decay = 0,
  grad_averaging = FALSE,
  amsgrad = FALSE,
  name = "NovoGrad",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_novograd_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A 'Tensor' or a floating point value. or a schedule that is a 'tf$keras$optimizers$schedules$LearningRateSchedule' The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_weight_decay">weight_decay</code></td>
<td>
<p>A floating point value. Weight decay for each param.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_grad_averaging">grad_averaging</code></td>
<td>
<p>determines whether to use Adam style exponential moving averaging for the first order moments.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_amsgrad">amsgrad</code></td>
<td>
<p>boolean. Whether to apply AMSGrad variant of this algorithm from the paper &quot;On the Convergence of Adam and beyond&quot;</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;NovoGrad&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_novograd_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
keras_model_sequential() %&gt;%
  layer_dense(32, input_shape = c(784)) %&gt;%
  compile(
    optimizer = optimizer_novograd(),
    loss='binary_crossentropy',
    metrics='accuracy'
  )

## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_radam'>Rectified Adam (a.k.a. RAdam)</h2><span id='topic+optimizer_radam'></span>

<h3>Description</h3>

<p>Rectified Adam (a.k.a. RAdam)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_radam(
  learning_rate = 0.001,
  beta_1 = 0.9,
  beta_2 = 0.999,
  epsilon = 1e-07,
  weight_decay = 0,
  amsgrad = FALSE,
  sma_threshold = 5,
  total_steps = 0,
  warmup_proportion = 0.1,
  min_lr = 0,
  name = "RectifiedAdam",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_radam_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A 'Tensor' or a floating point value. or a schedule that is
a 'tf$keras$optimizers$schedules$LearningRateSchedule' The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_beta_1">beta_1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_beta_2">beta_2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_epsilon">epsilon</code></td>
<td>
<p>A small constant for numerical stability.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_weight_decay">weight_decay</code></td>
<td>
<p>A floating point value. Weight decay for each param.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_amsgrad">amsgrad</code></td>
<td>
<p>boolean. Whether to apply AMSGrad variant of this algorithm from the paper
&quot;On the Convergence of Adam and beyond&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_sma_threshold">sma_threshold</code></td>
<td>
<p>A float value. The threshold for simple mean average.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_total_steps">total_steps</code></td>
<td>
<p>An integer. Total number of training steps. Enable warmup by setting a positive value.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_warmup_proportion">warmup_proportion</code></td>
<td>
<p>A floating point value. The proportion of increasing steps.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_min_lr">min_lr</code></td>
<td>
<p>A floating point value. Minimum learning rate after warmup.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;RectifiedAdam&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_radam_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>

<hr>
<h2 id='optimizer_swa'>Stochastic Weight Averaging</h2><span id='topic+optimizer_swa'></span>

<h3>Description</h3>

<p>Stochastic Weight Averaging
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_swa(
  optimizer,
  start_averaging = 0,
  average_period = 10,
  name = "SWA",
  sequential_update = TRUE,
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_swa_+3A_optimizer">optimizer</code></td>
<td>
<p>The original optimizer that will be used to compute and apply the gradients.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_start_averaging">start_averaging</code></td>
<td>
<p>An integer. Threshold to start averaging using SWA. Averaging only occurs
at start_averaging iters, must be &gt;= 0. If start_averaging = m, the first snapshot will be taken
after the mth application of gradients (where the first iteration is iteration 0).</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_average_period">average_period</code></td>
<td>
<p>An integer. The synchronization period of SWA. The averaging occurs every
average_period steps. Averaging period needs to be &gt;= 1.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to 'SWA'.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_sequential_update">sequential_update</code></td>
<td>
<p>Bool. If FALSE, will compute the moving average at the same time as the
model is updated, potentially doing benign data races. If True, will update the moving average
after gradient updates</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_swa_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Stochastic Weight Averaging mechanism was proposed by Pavel Izmailov et. al
in the paper [Averaging Weights Leads to Wider Optima and Better Generalization](https://arxiv.org/abs/1803.05407). The
optimizer implements averaging of multiple points along the trajectory of SGD. The optimizer
expects an inner optimizer which will be used to apply the gradients to the variables and
itself computes a running average of the variables every k steps (which generally corresponds
to the end of a cycle when a cyclic learning rate is employed). We also allow the specification
of the number of steps averaging should first happen after. Let's say, we want averaging
to happen every k steps after the first m steps. After step m we'd take a snapshot of
the variables and then average the weights appropriately at step m + k, m + 2k and so on.
The assign_average_vars function can be called at the end of training to obtain the
averaged_weights from the optimizer.
</p>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
opt = tf$keras$optimizers$SGD(learning_rate)
opt = optimizer_swa(opt, start_averaging=m, average_period=k)

## End(Not run)

</code></pre>

<hr>
<h2 id='optimizer_yogi'>Yogi</h2><span id='topic+optimizer_yogi'></span>

<h3>Description</h3>

<p>Yogi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizer_yogi(
  learning_rate = 0.01,
  beta1 = 0.9,
  beta2 = 0.999,
  epsilon = 0.001,
  l1_regularization_strength = 0,
  l2_regularization_strength = 0,
  initial_accumulator_value = 1e-06,
  activation = "sign",
  name = "Yogi",
  clipnorm = NULL,
  clipvalue = NULL,
  decay = NULL,
  lr = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizer_yogi_+3A_learning_rate">learning_rate</code></td>
<td>
<p>A Tensor or a floating point value. The learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_beta1">beta1</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_beta2">beta2</code></td>
<td>
<p>A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_epsilon">epsilon</code></td>
<td>
<p>A constant trading off adaptivity and noise.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_l1_regularization_strength">l1_regularization_strength</code></td>
<td>
<p>A float value, must be greater than or equal to zero.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_l2_regularization_strength">l2_regularization_strength</code></td>
<td>
<p>A float value, must be greater than or equal to zero.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_initial_accumulator_value">initial_accumulator_value</code></td>
<td>
<p>The starting value for accumulators. Only positive values are allowed.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_activation">activation</code></td>
<td>
<p>Use hard sign or soft tanh to determin sign.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_name">name</code></td>
<td>
<p>Optional name for the operations created when applying gradients. Defaults to &quot;Yogi&quot;.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_clipnorm">clipnorm</code></td>
<td>
<p>is clip gradients by norm.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_clipvalue">clipvalue</code></td>
<td>
<p>is clip gradients by value.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_decay">decay</code></td>
<td>
<p>is included for backward compatibility to allow time inverse decay of learning rate.</p>
</td></tr>
<tr><td><code id="optimizer_yogi_+3A_lr">lr</code></td>
<td>
<p>is included for backward compatibility, recommended to use learning_rate instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Optimizer for use with 'keras::compile()'
</p>

<hr>
<h2 id='parse_time'>Parse time</h2><span id='topic+parse_time'></span>

<h3>Description</h3>

<p>Parse an input string according to the provided format string into a
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_time(time_string, time_format, output_unit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_time_+3A_time_string">time_string</code></td>
<td>
<p>The input time string to be parsed.</p>
</td></tr>
<tr><td><code id="parse_time_+3A_time_format">time_format</code></td>
<td>
<p>The time format.</p>
</td></tr>
<tr><td><code id="parse_time_+3A_output_unit">output_unit</code></td>
<td>
<p>The output unit of the parsed unix time. Can only be SECOND, MILLISECOND, MICROSECOND, NANOSECOND.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unix time. Parse an input string according to the provided format string
into a Unix
time, the number of seconds / milliseconds / microseconds / nanoseconds
elapsed since January 1, 1970 UTC. Uses strftime()-like formatting options, with
the same extensions as
FormatTime(), but with the exceptions that 
characters as it can, so the matching
data should always be terminated with a non-numeric. 
consumes exactly four characters, including any sign. Unspecified fields are taken
from the default date and time of ... &quot;1970-01-01 00:00:00.0 +0000&quot; For example,
parsing a string of &quot;15:45&quot; (
Unix time that represents &quot;1970-01-01 15:45:00.0 +0000&quot;. Note that ParseTime only
heeds the fields year, month, day, hour,
minute, (fractional) second, and UTC offset. Other fields, like
weekday (
ignored in the conversion. Date and time fields that are out-of-range will be treated as
errors rather than normalizing them like 'absl::CivilSecond' does.
For example, it is an error to parse the date &quot;Oct 32, 2013&quot;
because 32 is out of range. A leap second of &quot;:60&quot; is normalized to &quot;:00&quot; of the following
minute with fractional seconds discarded. The following table
shows how the given seconds and subseconds will be parsed: &quot;59.x&quot; -&gt; 59.x // exact &quot;60.x&quot; -&gt; 00.0 // normalized &quot;00.x&quot; -&gt; 00.x // exact
</p>


<h3>Value</h3>

<p>the number of seconds / milliseconds / microseconds / nanoseconds elapsed since January 1, 1970 UTC.
</p>


<h3>Raises</h3>

<p>ValueError: If 'output_unit' is not a valid value, if parsing 'time_string' according to 'time_format' failed.
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+tf'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+tf">tf</a></code></p>
</dd>
</dl>


<h3>Value</h3>

<p>a alias for tensorflow::tf
</p>

<hr>
<h2 id='register_all'>Register all</h2><span id='topic+register_all'></span>

<h3>Description</h3>

<p>Register TensorFlow Addons' objects in TensorFlow global dictionaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>register_all(keras_objects = TRUE, custom_kernels = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="register_all_+3A_keras_objects">keras_objects</code></td>
<td>
<p>boolean, 'TRUE' by default. If 'TRUE', register all Keras
objects with 'tf$keras$utils$register_keras_serializable(package=&quot;Addons&quot;)' If
set to FALSE, doesn't register any Keras objects of Addons in TensorFlow.</p>
</td></tr>
<tr><td><code id="register_all_+3A_custom_kernels">custom_kernels</code></td>
<td>
<p>boolean, 'TRUE' by default. If 'TRUE', loads all custom
kernels of TensorFlow Addons with 'tf.load_op_library(&quot;path/to/so/file.so&quot;)'.
Loading the SO files register them automatically. If &lsquo;FALSE' doesn&rsquo;t load and
register the shared objects files. Not that it might be useful to turn it off
if your installation of Addons doesn't work well with custom ops.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When loading a Keras model that has a TF Addons' function, it is needed
for this function to be known by the Keras deserialization process. There are two ways
to do this, either do
&ldquo;'
tf$keras$models$load_model( &quot;my_model.tf&quot;, custom_objects=list(&quot;LAMB&quot;: tfaddons::optimizer_lamb)
)
&ldquo;'
or you can do:
&ldquo;'python
register_all()
tf$keras$models$load_model(&quot;my_model.tf&quot;)
&ldquo;' If the model contains custom ops (compiled ops) of TensorFlow Addons,
and the graph is loaded with 'tf$saved_model$load', then custom ops need
to be registered before to avoid an error of the type:
&ldquo;'
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered
'...' in binary running on ... Make sure the Op and Kernel are
registered in the binary running in this process.
&ldquo;'
In this case, the only way to make sure that the ops are registered is to call
this function:
&ldquo;'
register_all()
tf$saved_model$load(&quot;my_model.tf&quot;)
&ldquo;'
Note that you can call this function multiple times in the same process,
it only has an effect the first time. Afterward, it's just a no-op.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='register_custom_kernels'>Register custom kernels</h2><span id='topic+register_custom_kernels'></span>

<h3>Description</h3>

<p>Register custom kernels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>register_custom_kernels(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="register_custom_kernels_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='register_keras_objects'>Register keras objects</h2><span id='topic+register_keras_objects'></span>

<h3>Description</h3>

<p>Register keras objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>register_keras_objects(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="register_keras_objects_+3A_...">...</code></td>
<td>
<p>parameters to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='safe_cumprod'>Safe cumprod</h2><span id='topic+safe_cumprod'></span>

<h3>Description</h3>

<p>Computes cumprod of x in logspace using cumsum to avoid underflow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>safe_cumprod(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="safe_cumprod_+3A_x">x</code></td>
<td>
<p>Tensor to take the cumulative product of.</p>
</td></tr>
<tr><td><code id="safe_cumprod_+3A_...">...</code></td>
<td>
<p>Passed on to cumsum; these are identical to those in cumprod</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumprod function and its gradient can result in numerical instabilities
when its argument has very small and/or zero values. As long as the
argument is all positive, we can instead compute the cumulative product as
exp(cumsum(log(x))). This function can be called identically to
tf$cumprod.
</p>


<h3>Value</h3>

<p>Cumulative product of x.
</p>

<hr>
<h2 id='sample_bernoulli'>Bernoulli sample</h2><span id='topic+sample_bernoulli'></span>

<h3>Description</h3>

<p>Samples from Bernoulli distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_bernoulli(
  probs = NULL,
  logits = NULL,
  dtype = tf$int32,
  sample_shape = list(),
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_bernoulli_+3A_probs">probs</code></td>
<td>
<p>probabilities</p>
</td></tr>
<tr><td><code id="sample_bernoulli_+3A_logits">logits</code></td>
<td>
<p>logits</p>
</td></tr>
<tr><td><code id="sample_bernoulli_+3A_dtype">dtype</code></td>
<td>
<p>the data type</p>
</td></tr>
<tr><td><code id="sample_bernoulli_+3A_sample_shape">sample_shape</code></td>
<td>
<p>a list/vector of integers</p>
</td></tr>
<tr><td><code id="sample_bernoulli_+3A_seed">seed</code></td>
<td>
<p>integer, random seed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Tensor
</p>

<hr>
<h2 id='sample_categorical'>Categorical sample</h2><span id='topic+sample_categorical'></span>

<h3>Description</h3>

<p>Samples from categorical distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_categorical(
  logits,
  dtype = tf$int32,
  sample_shape = list(),
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_categorical_+3A_logits">logits</code></td>
<td>
<p>logits</p>
</td></tr>
<tr><td><code id="sample_categorical_+3A_dtype">dtype</code></td>
<td>
<p>dtype</p>
</td></tr>
<tr><td><code id="sample_categorical_+3A_sample_shape">sample_shape</code></td>
<td>
<p>the shape of sample</p>
</td></tr>
<tr><td><code id="sample_categorical_+3A_seed">seed</code></td>
<td>
<p>random seed: integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Tensor
</p>

<hr>
<h2 id='sampler'>Sampler</h2><span id='topic+sampler'></span>

<h3>Description</h3>

<p>Interface for implementing sampling in seq2seq decoders.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_+3A_...">...</code></td>
<td>
<p>parametr to pass batch_size, initialize, next_inputs, sample, sample_ids_dtype, sample_ids_shape</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sampler_custom'>Base abstract class that allows the user to customize sampling.</h2><span id='topic+sampler_custom'></span>

<h3>Description</h3>

<p>Base abstract class that allows the user to customize sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_custom(
  initialize_fn,
  sample_fn,
  next_inputs_fn,
  sample_ids_shape = NULL,
  sample_ids_dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_custom_+3A_initialize_fn">initialize_fn</code></td>
<td>
<p>callable that returns (finished, next_inputs) for the first iteration.</p>
</td></tr>
<tr><td><code id="sampler_custom_+3A_sample_fn">sample_fn</code></td>
<td>
<p>callable that takes (time, outputs, state) and emits tensor sample_ids.</p>
</td></tr>
<tr><td><code id="sampler_custom_+3A_next_inputs_fn">next_inputs_fn</code></td>
<td>
<p>callable that takes (time, outputs, state, sample_ids) and emits
(finished, next_inputs, next_state).</p>
</td></tr>
<tr><td><code id="sampler_custom_+3A_sample_ids_shape">sample_ids_shape</code></td>
<td>
<p>Either a list of integers, or a 1-D Tensor of type int32, the
shape of each value in the sample_ids batch. Defaults to a scalar.</p>
</td></tr>
<tr><td><code id="sampler_custom_+3A_sample_ids_dtype">sample_ids_dtype</code></td>
<td>
<p>The dtype of the sample_ids tensor. Defaults to int32.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sampler_greedy_embedding'>Greedy Embedding Sampler</h2><span id='topic+sampler_greedy_embedding'></span>

<h3>Description</h3>

<p>A sampler for use during inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_greedy_embedding(embedding_fn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_greedy_embedding_+3A_embedding_fn">embedding_fn</code></td>
<td>
<p>A optional callable that takes a vector tensor of ids (argmax ids),
or the params argument for embedding_lookup. The returned tensor will be passed to the
decoder input. Default to use tf$nn$embedding_lookup.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the argmax of the output (treated as logits) and passes the result through
an embedding layer to get the next input.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sampler_inference'>Inference Sampler</h2><span id='topic+sampler_inference'></span>

<h3>Description</h3>

<p>Inference Sampler
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_inference(
  sample_fn,
  sample_shape,
  sample_dtype = tf$int32,
  end_fn,
  next_inputs_fn = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_inference_+3A_sample_fn">sample_fn</code></td>
<td>
<p>A callable that takes outputs and emits tensor sample_ids.</p>
</td></tr>
<tr><td><code id="sampler_inference_+3A_sample_shape">sample_shape</code></td>
<td>
<p>Either a list of integers, or a 1-D Tensor of type int32,
the shape of the each sample in the batch returned by sample_fn.</p>
</td></tr>
<tr><td><code id="sampler_inference_+3A_sample_dtype">sample_dtype</code></td>
<td>
<p>the dtype of the sample returned by sample_fn.</p>
</td></tr>
<tr><td><code id="sampler_inference_+3A_end_fn">end_fn</code></td>
<td>
<p>A callable that takes sample_ids and emits a bool vector shaped
[batch_size] indicating whether each sample is an end token.</p>
</td></tr>
<tr><td><code id="sampler_inference_+3A_next_inputs_fn">next_inputs_fn</code></td>
<td>
<p>(Optional) A callable that takes sample_ids and returns
the next batch of inputs. If not provided, sample_ids is used as the next batch of inputs.</p>
</td></tr>
<tr><td><code id="sampler_inference_+3A_...">...</code></td>
<td>
<p>A list that contains other common arguments for layer creation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A helper to use during inference with a custom sampling function.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sampler_sample_embedding'>Sample Embedding Sampler</h2><span id='topic+sampler_sample_embedding'></span>

<h3>Description</h3>

<p>A sampler for use during inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_sample_embedding(
  embedding_fn = NULL,
  softmax_temperature = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_sample_embedding_+3A_embedding_fn">embedding_fn</code></td>
<td>
<p>(Optional) A callable that takes a vector tensor of ids (argmax ids),
or the params argument for embedding_lookup. The returned tensor will be passed to the
decoder input.</p>
</td></tr>
<tr><td><code id="sampler_sample_embedding_+3A_softmax_temperature">softmax_temperature</code></td>
<td>
<p>(Optional) float32 scalar, value to divide the logits by
before computing the softmax. Larger values (above 1.0) result in more random samples,
while smaller values push the sampling distribution towards the argmax. Must be strictly
greater than 0. Defaults to 1.0.</p>
</td></tr>
<tr><td><code id="sampler_sample_embedding_+3A_seed">seed</code></td>
<td>
<p>(Optional) The sampling seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses sampling (from a distribution) instead of argmax and passes
the result through an embedding layer to get the next input.
</p>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='sampler_scheduled_embedding_training'>A training sampler that adds scheduled sampling</h2><span id='topic+sampler_scheduled_embedding_training'></span>

<h3>Description</h3>

<p>A training sampler that adds scheduled sampling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_scheduled_embedding_training(
  sampling_probability,
  embedding_fn = NULL,
  time_major = FALSE,
  seed = NULL,
  scheduling_seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_scheduled_embedding_training_+3A_sampling_probability">sampling_probability</code></td>
<td>
<p>A float32 0-D or 1-D tensor: the probability of sampling
categorically from the output ids instead of reading directly from the inputs.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_embedding_training_+3A_embedding_fn">embedding_fn</code></td>
<td>
<p>A callable that takes a vector tensor of ids (argmax ids), or the
params argument for embedding_lookup.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_embedding_training_+3A_time_major">time_major</code></td>
<td>
<p>bool. Whether the tensors in inputs are time major. If 'FALSE'
(default), they are assumed to be batch major.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_embedding_training_+3A_seed">seed</code></td>
<td>
<p>The sampling seed.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_embedding_training_+3A_scheduling_seed">scheduling_seed</code></td>
<td>
<p>The schedule decision rule sampling seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns -1s for sample_ids where no sampling took place; valid sample id values elsewhere.
</p>

<hr>
<h2 id='sampler_scheduled_output_training'>Scheduled Output Training Sampler</h2><span id='topic+sampler_scheduled_output_training'></span>

<h3>Description</h3>

<p>A training sampler that adds scheduled sampling directly to outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_scheduled_output_training(
  sampling_probability,
  time_major = FALSE,
  seed = NULL,
  next_inputs_fn = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_scheduled_output_training_+3A_sampling_probability">sampling_probability</code></td>
<td>
<p>A float32 scalar tensor: the probability of sampling
from the outputs instead of reading directly from the inputs.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_output_training_+3A_time_major">time_major</code></td>
<td>
<p>bool. Whether the tensors in inputs are time major. If False (default),
they are assumed to be batch major.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_output_training_+3A_seed">seed</code></td>
<td>
<p>The sampling seed.</p>
</td></tr>
<tr><td><code id="sampler_scheduled_output_training_+3A_next_inputs_fn">next_inputs_fn</code></td>
<td>
<p>(Optional) callable to apply to the RNN outputs to create the next
input when sampling. If None (default), the RNN outputs will be used as the next inputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>FALSE for sample_ids where no sampling took place; TRUE elsewhere.
</p>

<hr>
<h2 id='sampler_training'>A Sampler for use during training.</h2><span id='topic+sampler_training'></span>

<h3>Description</h3>

<p>Only reads inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_training(time_major = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampler_training_+3A_time_major">time_major</code></td>
<td>
<p>bool. Whether the tensors in inputs are time major.
If 'FALSE' (default), they are assumed to be batch major.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>

<hr>
<h2 id='skip_gram_sample'>Skip gram sample</h2><span id='topic+skip_gram_sample'></span>

<h3>Description</h3>

<p>Generates skip-gram token and label paired Tensors from the input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skip_gram_sample(
  input_tensor,
  min_skips = 1,
  max_skips = 5,
  start = 0,
  limit = -1,
  emit_self_as_target = FALSE,
  vocab_freq_table = NULL,
  vocab_min_count = NULL,
  vocab_subsampling = NULL,
  corpus_size = NULL,
  batch_size = NULL,
  batch_capacity = NULL,
  seed = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skip_gram_sample_+3A_input_tensor">input_tensor</code></td>
<td>
<p>A rank-1 'Tensor' from which to generate skip-gram candidates.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_min_skips">min_skips</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the minimum window size to
randomly use for each token. Must be &gt;= 0 and &lt;= 'max_skips'. If 'min_skips' and
'max_skips' are both 0, the only label outputted will be the token itself when
'emit_self_as_target = TRUE' - or no output otherwise.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_max_skips">max_skips</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the maximum window size to
randomly use for each token. Must be &gt;= 0.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_start">start</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the position in 'input_tensor'
from which to start generating skip-gram candidates.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_limit">limit</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the maximum number of elements
in 'input_tensor' to use in generating skip-gram candidates. -1 means to use the
rest of the 'Tensor' after 'start'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_emit_self_as_target">emit_self_as_target</code></td>
<td>
<p>'bool' or scalar 'Tensor' specifying whether to emit
each token as a label for itself.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_vocab_freq_table">vocab_freq_table</code></td>
<td>
<p>(Optional) A lookup table (subclass of
'lookup.InitializableLookupTableBase') that maps tokens to their raw frequency counts.
If specified, any token in 'input_tensor' that is not found in 'vocab_freq_table' will
be filtered out before generating skip-gram candidates. While this will typically map
to integer raw frequency counts, it could also map to float frequency proportions.
'vocab_min_count' and 'corpus_size' should be in the same units as this.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_vocab_min_count">vocab_min_count</code></td>
<td>
<p>(Optional) 'int', 'float', or scalar 'Tensor' specifying minimum
frequency threshold (from 'vocab_freq_table') for a token to be kept in 'input_tensor'.
If this is specified, 'vocab_freq_table' must also be specified - and they should both
be in the same units.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_vocab_subsampling">vocab_subsampling</code></td>
<td>
<p>(Optional) 'float' specifying frequency proportion threshold
for tokens from 'input_tensor'. Tokens that occur more frequently (based on the ratio
of the token's 'vocab_freq_table' value to the 'corpus_size') will be randomly down-sampled.
Reasonable starting values may be around 1e-3 or 1e-5. If this is specified, both
'vocab_freq_table' and 'corpus_size' must also be specified.
See Eq. 5 in http://arxiv.org/abs/1310.4546 for more details.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_corpus_size">corpus_size</code></td>
<td>
<p>(Optional) 'int', 'float', or scalar 'Tensor' specifying the total
number of tokens in the corpus (e.g., sum of all the frequency counts of 'vocab_freq_table').
Used with 'vocab_subsampling' for down-sampling frequently occurring tokens. If this
is specified, 'vocab_freq_table' and 'vocab_subsampling' must also be specified.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_batch_size">batch_size</code></td>
<td>
<p>(Optional) 'int' specifying batch size of returned 'Tensors'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_batch_capacity">batch_capacity</code></td>
<td>
<p>(Optional) 'int' specifying batch capacity for the queue used for
batching returned 'Tensors'. Only has an effect if 'batch_size' &gt; 0.
Defaults to 100 * 'batch_size' if not specified.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_seed">seed</code></td>
<td>
<p>(Optional) 'int' used to create a random seed for window size and subsampling.
See 'set_random_seed' docs for behavior.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_+3A_name">name</code></td>
<td>
<p>(Optional) A 'string' name or a name scope for the operations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>tensor. Generates skip-gram '(&quot;token&quot;, &quot;label&quot;)' pairs using each
element in the
rank-1 'input_tensor' as a token. The window size used for each token will
be randomly selected from the range specified by '[min_skips, max_skips]',
inclusive. See https://arxiv.org/abs/1301.3781 for more details about
skip-gram. For example, given 'input_tensor = [&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;,
&quot;jumps&quot;]', 'min_skips = 1', 'max_skips = 2', 'emit_self_as_target = FALSE',
the output '(tokens, labels)' pairs for the token &quot;quick&quot; will be randomly
selected from either '(tokens=[&quot;quick&quot;, &quot;quick&quot;], labels=[&quot;the&quot;, &quot;brown&quot;])'
for 1 skip, or '(tokens=[&quot;quick&quot;, &quot;quick&quot;, &quot;quick&quot;],
labels=[&quot;the&quot;, &quot;brown&quot;, &quot;fox&quot;])' for 2 skips. If 'emit_self_as_target = TRUE',
each token will also be emitted as a label
for itself. From the previous example, the output will be either
'(tokens=[&quot;quick&quot;, &quot;quick&quot;, &quot;quick&quot;], labels=[&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;])'
for 1 skip, or '(tokens=[&quot;quick&quot;, &quot;quick&quot;, &quot;quick&quot;, &quot;quick&quot;],
labels=[&quot;the&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;])' for 2 skips.
The same process is repeated for each element of 'input_tensor' and
concatenated together into the two output rank-1 'Tensors' (one for all the
tokens, another for all the labels). If 'vocab_freq_table' is specified,
tokens in 'input_tensor' that are not
present in the vocabulary are discarded. Tokens whose frequency counts are
below 'vocab_min_count' are also discarded. Tokens whose frequency
proportions in the corpus exceed 'vocab_subsampling' may be randomly
down-sampled. See Eq. 5 in http://arxiv.org/abs/1310.4546 for more details
about subsampling. Due to the random window sizes used for each token, the lengths of the
outputs are non-deterministic, unless 'batch_size' is specified to batch
the outputs to always return 'Tensors' of length 'batch_size'.
</p>


<h3>Value</h3>

<p>A 'list' containing (token, label) 'Tensors'. Each output 'Tensor' is of rank-1 and
has the same type as 'input_tensor'. The 'Tensors' will be of length 'batch_size';
if 'batch_size' is not specified, they will be of random length, though they will be
in sync with each other as long as they are evaluated together.
</p>


<h3>Raises</h3>

<p>ValueError: If 'vocab_freq_table' is not provided, but 'vocab_min_count',
'vocab_subsampling', or 'corpus_size' is specified. If 'vocab_subsampling' and
'corpus_size' are not both present or both absent.
</p>

<hr>
<h2 id='skip_gram_sample_with_text_vocab'>Skip gram sample with text vocab</h2><span id='topic+skip_gram_sample_with_text_vocab'></span>

<h3>Description</h3>

<p>Skip-gram sampling with a text vocabulary file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skip_gram_sample_with_text_vocab(
  input_tensor,
  vocab_freq_file,
  vocab_token_index = 0,
  vocab_token_dtype = tf$string,
  vocab_freq_index = 1,
  vocab_freq_dtype = tf$float64,
  vocab_delimiter = ",",
  vocab_min_count = NULL,
  vocab_subsampling = NULL,
  corpus_size = NULL,
  min_skips = 1,
  max_skips = 5,
  start = 0,
  limit = -1,
  emit_self_as_target = FALSE,
  batch_size = NULL,
  batch_capacity = NULL,
  seed = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_input_tensor">input_tensor</code></td>
<td>
<p>A rank-1 'Tensor' from which to generate skip-gram candidates.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_freq_file">vocab_freq_file</code></td>
<td>
<p>'string' specifying full file path to the text vocab file.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_token_index">vocab_token_index</code></td>
<td>
<p>'int' specifying which column in the text vocab file contains the
tokens.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_token_dtype">vocab_token_dtype</code></td>
<td>
<p>'DType' specifying the format of the tokens in the text vocab file.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_freq_index">vocab_freq_index</code></td>
<td>
<p>'int' specifying which column in the text vocab file contains the
frequency counts of the tokens.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_freq_dtype">vocab_freq_dtype</code></td>
<td>
<p>'DType' specifying the format of the frequency counts in the text
vocab file.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_delimiter">vocab_delimiter</code></td>
<td>
<p>'string' specifying the delimiter used in the text vocab file.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_min_count">vocab_min_count</code></td>
<td>
<p>'int', 'float', or scalar 'Tensor' specifying minimum frequency
threshold (from 'vocab_freq_file') for a token to be kept in 'input_tensor'. This should
correspond with 'vocab_freq_dtype'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_vocab_subsampling">vocab_subsampling</code></td>
<td>
<p>(Optional) 'float' specifying frequency proportion threshold for
tokens from 'input_tensor'. Tokens that occur more frequently will be randomly down-sampled.
Reasonable starting values may be around 1e-3 or 1e-5. See Eq. 5
in http://arxiv.org/abs/1310.4546 for more details.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_corpus_size">corpus_size</code></td>
<td>
<p>(Optional) 'int', 'float', or scalar 'Tensor' specifying the total number
of tokens in the corpus (e.g., sum of all the frequency counts of 'vocab_freq_file'). Used with
'vocab_subsampling' for down-sampling frequently occurring tokens. If this is specified,
'vocab_freq_file' and 'vocab_subsampling' must also be specified. If 'corpus_size' is needed
but not supplied, then it will be calculated from 'vocab_freq_file'. You might want to supply
your own value if you have already eliminated infrequent tokens from your vocabulary files
(where frequency &lt; vocab_min_count) to save memory in the internal token lookup table. Otherwise,
the unused tokens' variables will waste memory. The user-supplied 'corpus_size' value must be
greater than or equal to the sum of all the frequency counts of 'vocab_freq_file'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_min_skips">min_skips</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the minimum window size to randomly use for
each token. Must be &gt;= 0 and &lt;= 'max_skips'. If 'min_skips' and 'max_skips' are both 0, the only
label outputted will be the token itself.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_max_skips">max_skips</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the maximum window size to randomly use for
each token. Must be &gt;= 0.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_start">start</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the position in 'input_tensor' from which to start
generating skip-gram candidates.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_limit">limit</code></td>
<td>
<p>'int' or scalar 'Tensor' specifying the maximum number of elements in 'input_tensor'
to use in generating skip-gram candidates. -1 means to use the rest of the 'Tensor' after 'start'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_emit_self_as_target">emit_self_as_target</code></td>
<td>
<p>'bool' or scalar 'Tensor' specifying whether to emit each token as a
label for itself.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_batch_size">batch_size</code></td>
<td>
<p>(Optional) 'int' specifying batch size of returned 'Tensors'.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_batch_capacity">batch_capacity</code></td>
<td>
<p>(Optional) 'int' specifying batch capacity for the queue used for
batching returned 'Tensors'. Only has an effect if 'batch_size' &gt; 0.
Defaults to 100 * 'batch_size' if not specified.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_seed">seed</code></td>
<td>
<p>(Optional) 'int' used to create a random seed for window size and subsampling.
See ['set_random_seed'](../../g3doc/python/constant_op.md#set_random_seed) for behavior.</p>
</td></tr>
<tr><td><code id="skip_gram_sample_with_text_vocab_+3A_name">name</code></td>
<td>
<p>(Optional) A 'string' name or a name scope for the operations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wrapper around 'skip_gram_sample()' for use with a text vocabulary file.
The vocabulary file is expected to be a plain-text file, with lines of
'vocab_delimiter'-separated columns. The 'vocab_token_index' column should
contain the vocabulary term, while the 'vocab_freq_index' column should
contain the number of times that term occurs in the corpus. For example,
with a text vocabulary file of:
&ldquo;' bonjour,fr,42 hello,en,777 hola,es,99 &ldquo;'
You should set 'vocab_delimiter=&quot;,&quot;', 'vocab_token_index=0', and
'vocab_freq_index=2'. See 'skip_gram_sample()' documentation for more details
about the skip-gram
sampling process.
</p>


<h3>Value</h3>

<p>A 'list' containing (token, label) 'Tensors'. Each output 'Tensor' is of rank-1 and
has the same type as 'input_tensor'. The 'Tensors' will be of length 'batch_size';
if 'batch_size' is not specified, they will be of random length, though they will be
in sync with each other as long as they are evaluated together.
</p>


<h3>Raises</h3>

<p>ValueError: If 'vocab_token_index' or 'vocab_freq_index' is less than 0 or exceeds the
number of columns in 'vocab_freq_file'. If 'vocab_token_index' and 'vocab_freq_index'
are both set to the same column. If any token in 'vocab_freq_file' has a negative frequency.
</p>

<hr>
<h2 id='tfaddons_version'>Version of TensorFlow SIG Addons</h2><span id='topic+tfaddons_version'></span>

<h3>Description</h3>

<p>Get the current version of TensorFlow SIG Addons
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tfaddons_version()
</code></pre>


<h3>Value</h3>

<p>prints the version.
</p>

<hr>
<h2 id='tile_batch'>Tile batch</h2><span id='topic+tile_batch'></span>

<h3>Description</h3>

<p>Tile the batch dimension of a (possibly nested structure of) tensor(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tile_batch(t, multiplier, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tile_batch_+3A_t">t</code></td>
<td>
<p>'Tensor' shaped '[batch_size, ...]'.</p>
</td></tr>
<tr><td><code id="tile_batch_+3A_multiplier">multiplier</code></td>
<td>
<p>Python int.</p>
</td></tr>
<tr><td><code id="tile_batch_+3A_name">name</code></td>
<td>
<p>Name scope for any created operations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>t. For each tensor t in a (possibly nested structure) of tensors,
this function takes a tensor t shaped '[batch_size, s0, s1, ...]' composed
of minibatch entries 't[0], ..., t[batch_size - 1]' and tiles it to have a
shape '[batch_size * multiplier, s0, s1, ...]' composed of minibatch
entries 't[0], t[0], ..., t[1], t[1], ...' where each minibatch entry is
repeated 'multiplier' times.
</p>


<h3>Value</h3>

<p>A (possibly nested structure of) 'Tensor' shaped '[batch_size * multiplier, ...]'.
</p>


<h3>Raises</h3>

<p>ValueError: if tensor(s) 't' do not have a statically known rank or the rank is &lt; 1.
</p>

<hr>
<h2 id='viterbi_decode'>Viterbi decode</h2><span id='topic+viterbi_decode'></span>

<h3>Description</h3>

<p>Decode the highest scoring sequence of tags outside of TensorFlow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>viterbi_decode(score, transition_params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="viterbi_decode_+3A_score">score</code></td>
<td>
<p>A [seq_len, num_tags] matrix of unary potentials.</p>
</td></tr>
<tr><td><code id="viterbi_decode_+3A_transition_params">transition_params</code></td>
<td>
<p>A [num_tags, num_tags] matrix of binary potentials.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This should only be used at test time.
</p>


<h3>Value</h3>

<p>viterbi: A [seq_len] list of integers containing the highest scoring tag indices.
viterbi_score: A float containing the score for the Viterbi sequence.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
