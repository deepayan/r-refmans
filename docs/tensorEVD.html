<!DOCTYPE html><html><head><title>Help for package tensorEVD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tensorEVD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Hadamard+20product'><p>Hadamard product</p></a></li>
<li><a href='#Kronecker+20product'><p>Kronecker product</p></a></li>
<li><a href='#Multivariate+20variance+20matrix'><p>Multivariate variance matrix penalization</p></a></li>
<li><a href='#Tensor+20EVD'><p>Tensor EVD</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Fast Algorithm to Factorize High-Dimensional Tensor Product
Matrices</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-28</td>
</tr>
<tr>
<td>Description:</td>
<td>Here we provide tools for the computation and factorization of high-dimensional
	     tensor products that are formed by smaller matrices. The methods are based on
	     properties of Kronecker products (Searle 1982, p. 265, ISBN-10: 0470009616).
	     We evaluated this methodology by benchmark testing and illustrated its use in
	     Gaussian Linear Models ('Lopez-Cruz et al., 2024') &lt;<a href="https://doi.org/10.1093%2Fg3journal%2Fjkae001">doi:10.1093/g3journal/jkae001</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/MarcooLopez/tensorEVD">https://github.com/MarcooLopez/tensorEVD</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, ggplot2, ggnewscale, reshape2,
RColorBrewer, pryr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-29 02:05:39 UTC; marco</td>
</tr>
<tr>
<td>Author:</td>
<td>Marco Lopez-Cruz [aut, cre],
  Gustavo de los Campos [aut],
  Paulino Perez-Rodriguez [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marco Lopez-Cruz &lt;maraloc@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-30 07:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Hadamard+20product'>Hadamard product</h2><span id='topic+Hadamard'></span>

<h3>Description</h3>

<p>Computes the Hadamard product between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hadamard(A, B, IDrowA, IDrowB,
         IDcolA = NULL, IDcolB = NULL,
         make.dimnames = FALSE,
         drop = TRUE, inplace = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hadamard+2B20product_+3A_a">A</code></td>
<td>
<p>(numeric) Left numeric matrix</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_b">B</code></td>
<td>
<p>(numeric) Right numeric matrix</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_idrowa">IDrowA</code></td>
<td>
<p>(integer/character) Vector of length <i>m</i> with either indices or row names mapping from rows of <code>A</code> into the resulting hadamard product. If 'missing', it is assumed to be equal to <code>1,...,nrow(A)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_idrowb">IDrowB</code></td>
<td>
<p>(integer/character) Vector of length <i>m</i> with either indices or row names mapping from rows of <code>B</code> into the resulting hadamard product. If 'missing', it is assumed to be equal to <code>1,...,nrow(B)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_idcola">IDcolA</code></td>
<td>
<p>(integer/character) (Optional) Similar to <code>IDrowA</code>, vector of length <i>n</i> for columns. If <code>NULL</code>, it is assumed to be equal to <code>IDrowA</code> if 
<i>m=n</i></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_idcolb">IDcolB</code></td>
<td>
<p>(integer/character) (Optional) Similar to <code>IDrowB</code>, vector of length <i>n</i> for columns. If <code>NULL</code>, it is assumed to be equal to <code>IDrowB</code> if
<i>m=n</i></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_drop">drop</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_inplace">inplace</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether operate directly on one input matrix (<code>A</code> or <code>B</code>) when this is used as is (i.e., is not indexed; therefore, needs to be of appropiate dimensions) in the Hadamard. When <code>TRUE</code> the output will be overwritten on the same address occupied by the non-indexed matrix. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the <i>m</i> &times; <i>n</i> Hadamard product (aka element-wise or entry-wise product) matrix between matrices 
<b>A</b> and <b>B</b>,
</p>
<p style='text-align:center'>(<b>R</b><sub>1</sub> <b>A</b> <b>C'</b><sub>1</sub>) &odot; (<b>R</b><sub>2</sub> <b>B</b> <b>C'</b><sub>2</sub>)</p>
<p>where
<b>R</b><sub>1</sub> and
<b>R</b><sub>2</sub> are incidence matrices mapping from rows of the resulting Hadamard to rows of <b>A</b> and <b>B</b>, respectively; and 
<b>C</b><sub>1</sub> and
<b>C</b><sub>2</sub> are incidence matrices mapping from columns of the resulting Hadamard to columns of <b>A</b> and <b>B</b>, respectively.
</p>
<p>Matrix <b>R</b><sub>1</sub> <b>A</b> <b>C'</b><sub>1</sub>
can be obtained by matrix indexing as <code>A[IDrowA,IDcolA]</code>, where <code>IDrowA</code> and <code>IDcolA</code> are integer vectors whose entries are, respectively, the row and column number of 
<b>A</b> that are mapped at each row of 
<b>R</b><sub>1</sub> and 
<b>C</b><sub>1</sub>, respectively.
Likewise, matrix 
<b>R</b><sub>2</sub> <b>B</b> <b>C'</b><sub>2</sub>
can be obtained as <code>B[IDrowB,IDcolB]</code>, where <code>IDrowB</code> and <code>IDcolB</code> are integer vectors whose entries are, respectively, the row and column number of 
<b>B</b> that are mapped at each row of 
<b>R</b><sub>2</sub> and 
<b>C</b><sub>2</sub>, respectively. Therefore, the Hadamard product can be obtained directly as
</p>
<p style='text-align:center;font-family:courier'>A[IDrowA,IDcolA]*B[IDrowB,IDcolB]</p>
<p>The function computes the Hadamard product directly from <b>A</b> and <b>B</b> without forming <b>R</b><sub>1</sub> <b>A</b> <b>C'</b><sub>1</sub> or 
<b>R</b><sub>2</sub> <b>B</b> <b>C'</b><sub>2</sub>
matrices.
</p>


<h3>Value</h3>

<p>Returns a matrix containing the Hadamard product.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # (a) Example 1. Indexing using row/column names
  # Generate rectangular matrices A (nrowA x ncolA) and B (nrowB x ncolB)
  nA = c(10,15)
  nB = c(12,8)
  A = matrix(rnorm(nA[1]*nA[2]), nrow=nA[1])
  B = matrix(rnorm(nB[1]*nB[2]), nrow=nB[1])
  dimnames(A) = list(paste0("row",seq(nA[1])), paste0("col",seq(nA[2])))
  dimnames(B) = list(paste0("row",seq(nB[1])), paste0("col",seq(nB[2])))
  
  # Define IDs for a Hadamard of size n1 x n2
  n = c(1000,500)
  IDrowA = sample(rownames(A), n[1], replace=TRUE)
  IDrowB = sample(rownames(B), n[1], replace=TRUE)
  IDcolA = sample(colnames(A), n[2], replace=TRUE)
  IDcolB = sample(colnames(B), n[2], replace=TRUE)
  
  K1 = Hadamard(A, B, IDrowA, IDrowB, IDcolA, IDcolB, make.dimnames=TRUE)
  
  # (it must equal to:)
  K2 = A[IDrowA,IDcolA]*B[IDrowB,IDcolB]
  dimnames(K2) = list(paste0(IDrowA,":",IDrowB), paste0(IDcolA,":",IDcolB))
  all.equal(K1,K2)
  
  # (b) Example 2. Indexing using integers
  # Generate squared symmetric matrices A and B 
  nA = 20
  nB = 15
  A = tcrossprod(matrix(rnorm(nA*nA), nrow=nA))
  B = tcrossprod(matrix(rnorm(nB*nB), nrow=nB))
  
  # Define IDs for a Hadamard of size n x n
  n = 1000
  IDA = sample(seq(nA), n, replace=TRUE)
  IDB = sample(seq(nB), n, replace=TRUE)
  
  K1 = Hadamard(A, B, IDA, IDB)
  
  # (it must equal to:)
  K2 = A[IDA,IDA]*B[IDB,IDB]
  all.equal(K1,K2)
  
  # (c) Inplace calculation
  # overwrite the output at the same address as the input:
  IDB = sample(seq(nB), nA, replace=TRUE)
  
  K1 = A[]                     # copy of A to be used as input
  add  = pryr::address(K1)     # address of K on entry
  K1 = Hadamard(K1, B, IDrowB=IDB)
  pryr::address(K1) == add     # on exit, K was moved to a different address
  
  K2 = A[]   
  add  = pryr::address(K2)
  K2 = Hadamard(K2, B, IDrowB=IDB, inplace=TRUE)
  pryr::address(K2) == add     # on exit, K remains at the same address
  all.equal(K1,K2)
</code></pre>

<hr>
<h2 id='Kronecker+20product'>Kronecker product</h2><span id='topic+Kronecker'></span>

<h3>Description</h3>

<p>Computes the direct Kronecker product between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kronecker(A, B, rows = NULL, cols = NULL, 
          make.dimnames = FALSE, drop = TRUE,
          inplace = FALSE) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kronecker+2B20product_+3A_a">A</code></td>
<td>
<p>(numeric) Left numeric matrix</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_b">B</code></td>
<td>
<p>(numeric) Right numeric matrix</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_rows">rows</code></td>
<td>
<p>(integer) Index which rows of the Kronecker are to be returned. They must range from 1 to <code>nrow(A)*nrow(B)</code>. Default <code>rows=NULL</code> will return all the rows</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_cols">cols</code></td>
<td>
<p>(integer) Index which columns of the Kronecker are to be returned. They must range from 1 to <code>ncol(A)*ncol(B)</code>. Default <code>cols=NULL</code> return all the columns</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_drop">drop</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_inplace">inplace</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether operate directly on one input matrix (<code>A</code> or <code>B</code>) when the other one is a scalar. This is possible only when <code>rows=NULL</code> and <code>cols=NULL</code>. When <code>TRUE</code> the output will be overwritten on the same address occupied by the input that is not scalar. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For any two matrices
<b>A</b>={a<sub>ij</sub>} of dimensions 
<i>m</i> &times; <i>n</i> and
<b>B</b>={b<sub>ij</sub>} of dimensions
<i>p</i> &times; <i>q</i>, 
the direct Kronecker product between them is a matrix defined as the block matrix
</p>
<p style='text-align:center'><b>A</b>&otimes;<b>B</b> = {a<sub>ij</sub><b>B</b>}</p>
<p>which is of dimensions <i>mp</i> &times; <i>nq</i>.
</p>
<p>A sub-matrix formed by selecting specific rows and columns from the Kronecker can be obtained by pre- and post- multiplication with incidence matrices
</p>
<p style='text-align:center'><b>R</b> (<b>A</b>&otimes;<b>B</b>) <b>C'</b></p>
<p>where
<b>R</b> is an incidence matrix mapping from rows of the resulting sub-matrix to rows of the Kronecker product, and 
<b>C</b> is an incidence matrix mapping from columns of the resulting sub-matrix to columns of the Kronecker product.
This sub-matrix of the Kronecker can be obtained by matrix indexing as
</p>
<p style='text-align:center;font-family:courier'>Kronecker(A,B)[rows,cols]</p>
<p>where <code>rows</code> and <code>cols</code> are integer vectors whose entries are, respectively, the row and column number of the Kronecker that are mapped at each row of <b>R</b> and <b>C</b>.
</p>
<p>The function computes this sub-matrix of the Kronecker product directly from <b>A</b> and <b>B</b> without forming the whole Kronecker product. This is very useful if a relatively small number of row/columns are to be selected. 
</p>


<h3>Value</h3>

<p>Returns the Kronecker product matrix. It can be a sub-matrix of it as per the <code>rows</code> and <code>cols</code> arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # (a) Kronecker product of 2 vectors
  A = rnorm(3)
  B = rnorm(2) 
  (K1 = Kronecker(A, B))
  # it must equal when using from the R-base package:
  (K2 = kronecker(A, B))
  
  # (b) Kronecker product of 2 matrices
  A = matrix(rnorm(12), ncol=3)
  B = matrix(rnorm(4), ncol=2)
  K1 = Kronecker(A, B)
  # (it must equal (but faster) to:)
  K2 = kronecker(A, B)
  all.equal(K1,K2)
  
  # (c) Subsetting rows/columns from the Kronecker
  A = matrix(rnorm(100*150), ncol=150)
  B = matrix(rnorm(100*120), ncol=120)
  rows = c(1,3,5,7)
  cols = c(10,20,30,50)
  K1 = Kronecker(A, B, rows=rows, cols=cols)
  # (it must equal (but faster) to:)
  K2 = Kronecker(A, B)[rows,cols]
  all.equal(K1,K2)
  
  # (d) Inplace calculation
  # overwrite the output at the same address as the input:
  K1 = A[]                     # copy of A to be used as input
  add  = pryr::address(K1)     # address of K on entry
  K1 = Kronecker(K1, B=0.5)
  pryr::address(K1) == add     # on exit, K was moved to a different address
  
  K2 = A[]   
  add  = pryr::address(K2)
  K2 = Kronecker(K2, B=0.5, inplace=TRUE)
  pryr::address(K2) == add     # on exit, K remains at the same address
  all.equal(K1,K2)
  
</code></pre>

<hr>
<h2 id='Multivariate+20variance+20matrix'>Multivariate variance matrix penalization</h2><span id='topic+Kronecker_cov'></span><span id='topic+Hadamard_cov'></span>

<h3>Description</h3>

<p>Ridge penalization of a multi-variate (co)variance matrix taking the form of either a Kronecker or Hadamard product
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kronecker_cov(Sigma = 1, K, Theta, swap = FALSE,
              rows = NULL, cols = NULL, 
              drop = TRUE, inplace = FALSE)
              
Hadamard_cov(Sigma = 1, K, Theta, IDS, IDK, 
             drop = TRUE, inplace = FALSE) 
              
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_sigma">Sigma</code></td>
<td>
<p>(numeric) A variance matrix among features. If is scalar, a scaled identity matrix with the same dimension as <code>Theta</code> is used</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_k">K</code></td>
<td>
<p>(numeric) Variance matrix among subjects</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_theta">Theta</code></td>
<td>
<p>(numeric) A diagonal-shifting parameter, value to be added to the diagonals of the resulting (co)variance matrix. It should be a (symmetric) matrix with the same dimension as <code>Sigma</code></p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_rows">rows</code></td>
<td>
<p>(integer) Index which rows of the (Kronecker product) (co)variance matrix are to be returned. Default <code>rows=NULL</code> will return all the rows</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_cols">cols</code></td>
<td>
<p>(integer) Index which columns of the (Kronecker product) (co)variance are to be returned. Default <code>cols=NULL</code> return all the columns</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_ids">IDS</code></td>
<td>
<p>(integer/character) Vector with either indices or row names mapping from rows/columns of <code>Sigma</code> and <code>Theta</code> into the resulting (Hadamard product) (co)variance matrix</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_idk">IDK</code></td>
<td>
<p>(integer/character) Vector with either indices or row names mapping from rows/columns of <code>K</code> into the resulting (Hadamard product) (co)variance matrix</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_swap">swap</code></td>
<td>
<p>(logical) Either <code>TRUE</code> or <code>FALSE</code> (default) to whether swap the order of the matrices in the resulting (Kronecker product) (co)variance matrix</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_drop">drop</code></td>
<td>
<p>(logical) Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Multivariate+2B20variance+2B20matrix_+3A_inplace">inplace</code></td>
<td>
<p>(logical) Either <code>TRUE</code> or <code>FALSE</code> to whether operate directly on matrix <code>K</code> when <code>Sigma</code> and <code>Theta</code> are scalars. This is possible only when <code>rows=NULL</code> and <code>cols=NULL</code>. When <code>TRUE</code> the output will be overwritten on the same address occupied by <code>K</code>. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume that a multi-variate random matrix <b>X</b> with 
<i>n</i> subjects in rows and <i>p</i> features in columns follows a matrix Gaussian distribution with certain matrix of means 
<b>M</b> and variance matrix
<b>K</b> of dimension 
<i>n</i> &times; <i>n</i> between subjects, and 
<b>&Sigma;</b> of dimension 
<i>p</i> &times; <i>p</i> between features.
</p>
<b>Kronecker product form.</b>
<p>The random variable 
<b>x</b> = vec(<b>X</b>), formed by stacking columns of
<b>X</b>, is a vector of length 
<i>n</i><i>p</i>
that also follow a Gaussian distribution with mean 
vec(<b>M</b>) and (co)variance covariance matrix taking the Kronecker form
</p>
<p style='text-align:center'><b>&Sigma;</b>&otimes;<b>K</b></p>
<p>In the uni-variate case, the problem of near-singularity can be alleviated by penalizing the variance matrix
<b>K</b> by adding positive elements 
&theta; to its diagonal, i.e., 
<b>K</b> + &theta;<b>I</b>, where 
<b>I</b> is an identity matrix. The same can be applied to the multi-variate case where the Kronecker product (co)variance matrix is penalized with 
<b>&Theta;</b>={&theta;<sub>ij</sub>} of dimensions <i>p</i> &times; <i>p</i>, where diagonal entries will penalize within feature
<i>i</i> and off-diagonals will penalize between features <i>i</i>
and <i>j</i>. This is,
</p>
<p style='text-align:center'><b>&Sigma;</b>&otimes;<b>K</b> + <b>&Theta;</b>&otimes;<b>I</b></p>
<p>The second Kronecker summand 
<b>&Theta;</b>&otimes;<b>I</b>
is a sparse matrix consisting of non-zero diagonal and sub-diagonals. The <code>Kronecker_cov</code> function derives the penalized Kronecker (co)variance matrix by computing densely only the first Kronecker summand
<b>&Sigma;</b>&otimes;<b>K</b>,
and then calculating and adding accordingly only the non-zero entries of 
<b>&Theta;</b>&otimes;<b>I</b>.
</p>
<p><em>Note</em>: Swapping the order of the matrices in the above Kronecker operations will yield a different result. In this case the penalized matrix 
</p>
<p style='text-align:center'><b>K</b>&otimes;<b>&Sigma;</b> + <b>I</b>&otimes;<b>&Theta;</b></p>
<p>corresponds to the penalized multi-variate (co)variance matrix of the transposed of the above multi-variate random matrix 
<b>X</b>, now with features in rows and subjects in columns. This can be achieved by setting <code>swap=TRUE</code> in the <code>Kronecker_cov</code> function.
</p>
<b>Hadamard product form.</b>
<p>Assume the random variable <b>x</b><sub>0</sub> is a subset of <b>x</b> containing entries corresponding to specific combinations of subjects and features, then the (co)variance matrix of the vector <b>x</b><sub>0</sub> will be a Hadamard product formed by the entry-wise product of only the elements of 
<b>&Sigma;</b> and
<b>K</b> involved in the combinations contained in
<b>x</b><sub>0</sub>; this is
</p>
<p style='text-align:center'>(<b>Z</b><sub>1</sub> <b>&Sigma;</b> <b>Z'</b><sub>1</sub>) &odot; (<b>Z</b><sub>2</sub> <b>K</b> <b>Z'</b><sub>2</sub>)</p>
<p>where
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub> are incidence matrices mapping from entries of the random variable <b>x</b><sub>0</sub> to rows (and columns) of <b>&Sigma;</b> and <b>K</b>, respectively. This (co)variance matrix can be obtained using matrix indexing (see <code>help(Hadamard)</code>), as 
</p>
<p style='text-align:center;font-family:courier'>Sigma[IDS,IDS]*K[IDK,IDK]</p>
<p>where <code>IDS</code> and <code>IDK</code> are integer vectors whose entries are the row (and column) number of 
<b>&Sigma;</b> and <b>K</b>, respectively, that are mapped at each row of
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub>, respectively.
</p>
<p>The penalized version of this Hadamard product (co)variance matrix will be
</p>
<p style='text-align:center'>(<b>Z</b><sub>1</sub> <b>&Sigma;</b> <b>Z'</b><sub>1</sub>) &odot; (<b>Z</b><sub>2</sub> <b>K</b> <b>Z'</b><sub>2</sub>) + (<b>Z</b><sub>1</sub> <b>&Theta;</b> <b>Z'</b><sub>1</sub>) &odot; (<b>Z</b><sub>2</sub> <b>I</b> <b>Z'</b><sub>2</sub>)</p>
<p>The <code>Hadamard_cov</code> function derives this penalized (co)variance matrix using matrix indexing, as 
</p>
<p style='text-align:center;font-family:courier'>Sigma[IDS,IDS]*K[IDK,IDK] + Theta[IDS,IDS]*I[IDK,IDK]</p>
<p>Likewise, this function computes densely only the first Hadamard summand
and then calculates and adds accordingly only the non-zero entries of the second summand.
</p>


<h3>Value</h3>

<p>Returns the penalized (co)variance matrix formed either as a Kronecker or Hadamard product. For the Kronecker product case, it can be a sub-matrix of the Kronecker product as per the <code>rows</code> and <code>cols</code> arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # Generate rectangular some covariance matrices 
  n = 30;  p = 10
  
  K = crossprod(matrix(rnorm(n*p), ncol=n))      # n x n matrix 
  Sigma = crossprod(matrix(rnorm(n*p), ncol=p))  # p x p matrix  
  Theta = crossprod(matrix(rnorm(n*p), ncol=p))  # p x p matrix
  
  # ==============================================
  # Kronecker covariance
  # ==============================================
  G1 = Kronecker_cov(Sigma, K, Theta = Theta)

  # it must equal to:
  D = diag(n)    # diagonal matrix of dimension n
  G2 = Kronecker(Sigma, K) + Kronecker(Theta, D)
  all.equal(G1,G2)
  
  # (b) Swapping the order of the matrices
  G1 = Kronecker_cov(Sigma, K, Theta, swap = TRUE)

  # in this case the kronecker is swapped:
  G2 = Kronecker(K, Sigma) + Kronecker(D, Theta)
  all.equal(G1,G2)
  
  # (c) Selecting specific entries of the output
  # We want only some rows and columns
  rows = c(1,3,5)
  cols = c(10,30,50)
  G1 = Kronecker_cov(Sigma, K, Theta, rows=rows, cols=cols)

  # this can be preferable instead of:
  G2 = (Kronecker(Sigma, K) + Kronecker(Theta, D))[rows,cols]
  all.equal(G1,G2)
  
  # (d) Inplace calculation
  # overwrite the output at the same address as the input:
  G1 = K[]                     # copy of K to be used as input
  add  = pryr::address(G1)     # address of G on entry
  G1 = Kronecker_cov(Sigma=0.5, G1, Theta=1.5)
  pryr::address(G1) == add     # on exit, G was moved to a different address
  
  G2 = K[]   
  add  = pryr::address(G2) 
  G2 = Kronecker_cov(Sigma=0.5, G2, Theta=1.5, inplace=TRUE)
  pryr::address(G2) == add     # on exit, G remains at the same address
  all.equal(G1,G2)
  
  # ==============================================
  # Hadamard covariance
  # ==============================================
  # Define IDs for a Hadamard of size m x m
  m = 1000
  IDS = sample(1:p, m, replace=TRUE)
  IDK = sample(1:n, m, replace=TRUE)
  
  G1 = Hadamard_cov(Sigma, K, Theta, IDS=IDS, IDK=IDK)
  
  # it must equal to:
  G2 = Sigma[IDS,IDS]*K[IDK,IDK] + Theta[IDS,IDS]*D[IDK,IDK]
  all.equal(G1,G2)
  
  # (b) Inplace calculation
  # overwrite the output at the same address as the input:
  G1 = K[]                     # copy of K to be used as input
  add  = pryr::address(G1)     # address of G on entry
  G1 = Hadamard_cov(Sigma=0.5, G1, Theta=1.5, IDS=rep(1,n))
  pryr::address(G1) == add     # on exit, G was moved to a different address
  
  G2 = K[]   
  add  = pryr::address(G2)
  G2 = Hadamard_cov(Sigma=0.5, G2, Theta=1.5, IDS=rep(1,n), inplace=TRUE)
  pryr::address(G2) == add     # on exit, G remains at the same address
  all.equal(G1,G2)
  
</code></pre>

<hr>
<h2 id='Tensor+20EVD'>Tensor EVD</h2><span id='topic+tensorEVD'></span>

<h3>Description</h3>

<p>Fast eigen value decomposition (EVD) of the Hadamard product of two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensorEVD(K1, K2, ID1, ID2, alpha = 1.0,
          EVD1 = NULL, EVD2 = NULL,
          d.min = .Machine$double.eps, 
          make.dimnames = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tensor+2B20EVD_+3A_k1">K1</code>, <code id="Tensor+2B20EVD_+3A_k2">K2</code></td>
<td>
<p>(numeric) Covariance structure matrices</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_id1">ID1</code></td>
<td>
<p>(character/integer) Vector of length <i>n</i> with either names or indices mapping from rows/columns of <code>K1</code> into the resulting tensor product</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_id2">ID2</code></td>
<td>
<p>(character/integer) Vector of length <i>n</i> with either names or indices mapping from rows/columns of <code>K2</code> into the resulting tensor product</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Proportion of variance of the tensor product to be explained by the tensor eigenvectors</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_evd1">EVD1</code></td>
<td>
<p>(list) (Optional) Eigenvectors and eigenvalues of <code>K1</code> as produced by the <code>eigen</code> function</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_evd2">EVD2</code></td>
<td>
<p>(list) (Optional) Eigenvectors and eigenvalues of <code>K2</code> as produced by the <code>eigen</code> function</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_d.min">d.min</code></td>
<td>
<p>(numeric) Tensor eigenvalue threshold. Default is a numeric zero. Only eigenvectors with eigenvalue passing this threshold are returned</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether show progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the <i>n</i> &times; <i>n</i> matrix <b>K</b> to be the Hadamard product (aka element-wise or entry-wise product) involving two smaller matrices 
<b>K</b><sub>1</sub> and
<b>K</b><sub>2</sub> of dimensions 
<i>n</i><sub>1</sub> and <i>n</i><sub>2</sub>, respectively,
</p>
<p style='text-align:center'><b>K</b> = (<b>Z</b><sub>1</sub> <b>K</b><sub>1</sub> <b>Z'</b><sub>1</sub>) &odot; (<b>Z</b><sub>2</sub> <b>K</b><sub>2</sub> <b>Z'</b><sub>2</sub>)</p>
<p>where
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub> are incidence matrices mapping from rows (and columns) of the resulting Hadamard to rows (and columns) of <b>K</b><sub>1</sub> and
<b>K</b><sub>2</sub>, respectively. 
</p>
<p>Let the eigenvalue decomposition (EVD) of <b>K</b><sub>1</sub> and
<b>K</b><sub>2</sub> to be
<b>K</b><sub>1</sub> = <b>V</b><sub>1</sub> <b>D</b><sub>1</sub> <b>V'</b><sub>1</sub> and 
<b>K</b><sub>2</sub> = <b>V</b><sub>2</sub> <b>D</b><sub>2</sub> <b>V'</b><sub>2</sub>. 
Using properties of the Hadamard and Kronecker products, an EVD of the Hadamard product
<b>K</b> can be approximated using the EVD of 
<b>K</b><sub>1</sub> and 
<b>K</b><sub>2</sub> as
</p>
<p style='text-align:center'><b>K = V D V'</b></p>
<p>where <b>D</b> = <b>D</b><sub>1</sub>&otimes;<b>D</b><sub>2</sub> is a diagonal matrix containing
<i>N</i> = <i>n</i><sub>1</sub> &times; <i>n</i><sub>2</sub> tensor eigenvalues 
d<sub>1</sub> &ge; ... &ge; d<sub>N</sub> &ge; 0 and
<b>V</b> = (<b>Z</b><sub>1</sub>&Star;<b>Z</b><sub>2</sub>)(<b>V</b><sub>1</sub>&otimes;<b>V</b><sub>2</sub>) = [<b>v</b><sub>1</sub>,...,<b>v</b><sub>N</sub>] is matrix containing <i>N</i> tensor eigenvectors
<b>v</b><sub>k</sub>; here the term 
<b>Z</b><sub>1</sub>&Star;<b>Z</b><sub>2</sub> is the 
&quot;face-splitting product&quot; (aka &quot;transposed Khatriâ€“Rao product&quot;) of matrices 
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub>.
</p>
<p>Each tensor eigenvector <i>k</i> is derived separately as a Hadamard product using the corresponding 
<i>i(k)</i> and <i>j(k)</i> eigenvectors 
<b>v</b><sub>1i(k)</sub> and
<b>v</b><sub>2j(k)</sub> from 
<b>V</b><sub>1</sub> and 
<b>V</b><sub>2</sub>, respectively, this is
</p>
<p style='text-align:center'><b>v</b><sub>k</sub> = (<b>Z</b><sub>1</sub><b>v</b><sub>1i(k)</sub>)&odot;(<b>Z</b><sub>2</sub><b>v</b><sub>2j(k)</sub>)</p>
<p>The <code>tensorEVD</code> function derives each of these eigenvectors <b>v</b><sub>k</sub> by matrix indexing using integer vectors <code>ID1</code> and <code>ID2</code>. The entries of these vectors are the row (and column) number of 
<b>K</b><sub>1</sub> and 
<b>K</b><sub>2</sub> that are mapped at each row of <b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub>, respectively.
</p>


<h3>Value</h3>

<p>Returns a list object that contains the elements:
</p>

<ul>
<li> <p><code>values</code>: (vector) resulting tensor eigenvalues.
</p>
</li>
<li> <p><code>vectors</code>: (matrix) resulting tensor eigenvectors.
</p>
</li>
<li> <p><code>totalVar</code>: (numeric) total variance of the tensor matrix product.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  set.seed(195021)
  
  # Generate matrices K1 and K2 of dimensions n1 and n2
  n1 = 10; n2 = 15
  K1 = crossprod(matrix(rnorm(n1*(n1+10)), ncol=n1))
  K2 = crossprod(matrix(rnorm(n2*(n2+10)), ncol=n2))

  # (a) Example 1. Full design (Kronecker product)
  ID1 = rep(seq(n1), each=n2)
  ID2 = rep(seq(n2), times=n1)

  # Direct EVD of the Hadamard product
  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)

  # Tensor EVD using K1 and K2
  EVD = tensorEVD(K1, K2, ID1, ID2)

  # Eigenvectors and eigenvalues are numerically equal
  all.equal(EVD0$values, EVD$values)
  all.equal(abs(EVD0$vectors), abs(EVD$vectors)) 

  # (b) If a proportion of variance explained is specified, 
  # only the eigenvectors needed to explain such proportion are derived
  alpha = 0.95
  EVD = tensorEVD(K1, K2, ID1, ID2, alpha=alpha)
  dim(EVD$vectors)

  # For the direct EVD
  varexp = cumsum(EVD0$values/sum(EVD0$values))
  index = 1:which.min(abs(varexp-alpha))
  dim(EVD0$vectors[,index])

  # (c) Example 2. Incomplete design (Hadamard product)
  # Eigenvectors and eigenvalues are no longer equivalent
  n = n1*n2   # Sample size n
  ID1 = sample(seq(n1), n, replace=TRUE) # Randomly sample of ID1
  ID2 = sample(seq(n2), n, replace=TRUE) # Randomly sample of ID2

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  all.equal(EVD0$values, EVD$values)
  all.equal(abs(EVD0$vectors), abs(EVD$vectors)) 
  
  # However, the sum of the eigenvalues is equal to the trace(K)
  c(sum(EVD0$values), sum(EVD$values), sum(diag(K)))

  # And provide the same approximation for K
  K01 = EVD0$vectors%*%diag(EVD0$values)%*%t(EVD0$vectors)
  K02 = EVD$vectors%*%diag(EVD$values)%*%t(EVD$vectors)
  c(all.equal(K,K01), all.equal(K,K02))

  # When n is different from N=n1xn2, both methods provide different 
  # number or eigenvectors/eigenvalues. The eigen function provides 
  # a number of eigenvectors equal to the minimum between n and N
  # for the tensorEVD, this number is always N

  # (d) Sample size n being half of n1 x n2
  n = n1*n2/2
  ID1 = sample(seq(n1), n, replace=TRUE)
  ID2 = sample(seq(n2), n, replace=TRUE)

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  c(eigen=sum(EVD0$values&gt;1E-10), tensorEVD=sum(EVD$values&gt;1E-10))

  # (e) Sample size n being twice n1 x n2
  n = n1*n2*2
  ID1 = sample(seq(n1), n, replace=TRUE)
  ID2 = sample(seq(n2), n, replace=TRUE)

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  c(eigen=sum(EVD0$values&gt;1E-10), tensorEVD=sum(EVD$values&gt;1E-10))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
