<!DOCTYPE html><html><head><title>Help for package tensorEVD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tensorEVD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Hadamard product'><p>Hadamard product</p></a></li>
<li><a href='#Kronecker covariance'><p>Kronecker variance matrix penalization</p></a></li>
<li><a href='#Kronecker product'><p>Kronecker product</p></a></li>
<li><a href='#Tensor EVD'><p>Tensor EVD</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Fast Algorithm to Factorize High-Dimensional Tensor Product
Matrices</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-07</td>
</tr>
<tr>
<td>Description:</td>
<td>Here we provide tools for the computation and factorization of high-dimensional
	     tensor products that are formed by smaller matrices. The methods are based on
	     properties of Kronecker products (Searle 1982, p. 265, ISBN-10: 0470009616). 
	     We evaluated this methodology by benchmark testing and illustrated its use in 
	     Gaussian Linear Models ('Lopez-Cruz et al., 2024') &lt;<a href="https://doi.org/10.1093%2Fg3journal%2Fjkae001">doi:10.1093/g3journal/jkae001</a>&gt;.</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, ggplot2, ggnewscale, reshape2,
RColorBrewer, pryr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-08 21:39:45 UTC; marco</td>
</tr>
<tr>
<td>Author:</td>
<td>Marco Lopez-Cruz [aut, cre],
  Gustavo de los Campos [aut],
  Paulino Perez-Rodriguez [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marco Lopez-Cruz &lt;lopezcru@msu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-08 22:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Hadamard+20product'>Hadamard product</h2><span id='topic+Hadamard'></span>

<h3>Description</h3>

<p>Computes the Hadamard product between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hadamard(A, B, rowsA, rowsB,
         colsA = NULL, colsB = NULL,
         make.dimnames = FALSE,
         drop = TRUE, inplace = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hadamard+2B20product_+3A_a">A</code></td>
<td>
<p>(numeric) Left numeric matrix</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_b">B</code></td>
<td>
<p>(numeric) Right numeric matrix</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_rowsa">rowsA</code></td>
<td>
<p>(integer/character) Vector of length <i>m</i> with either indices or row names mapping from rows of <code>A</code> into the resulting hadamard product. If 'missing', it is assumed to be equal to <code>1,...,nrow(A)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_rowsb">rowsB</code></td>
<td>
<p>(integer/character) Vector of length <i>m</i> with either indices or row names mapping from rows of <code>B</code> into the resulting hadamard product. If 'missing', it is assumed to be equal to <code>1,...,nrow(B)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_colsa">colsA</code></td>
<td>
<p>(integer/character) (Optional) Similar to <code>rowsA</code>, vector of length <i>n</i> for columns. If <code>NULL</code>, it is assumed to be equal to <code>1,...,ncol(A)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_colsb">colsB</code></td>
<td>
<p>(integer/character) (Optional) Similar to <code>rowsB</code>, vector of length <i>n</i> for columns. If <code>NULL</code>, it is assumed to be equal to <code>1,...,ncol(B)</code></p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_drop">drop</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Hadamard+2B20product_+3A_inplace">inplace</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether operate directly on one input matrix (<code>A</code> or <code>B</code>) when this is used as is (i.e., is not indexed; therefore, needs to be of appropiate dimensions) in the Hadamard. When <code>TRUE</code> the output will be overwritten on the same address occupied by the non-indexed matrix. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the <i>m</i> &times; <i>n</i> Hadamard product (aka element-wise or entry-wise product) matrix between matrices 
<b>A</b><sub>0</sub> = <b>R</b><sub>1</sub> <b>A</b> <b>C'</b><sub>1</sub> and
<b>B</b><sub>0</sub> = <b>R</b><sub>2</sub> <b>B</b> <b>C'</b><sub>2</sub>,
</p>
<p style='text-align:center'>(<b>R</b><sub>1</sub> <b>A</b> <b>C'</b><sub>1</sub>) &odot; (<b>R</b><sub>2</sub> <b>B</b> <b>C'</b><sub>2</sub>)</p>
<p>where
<b>R</b><sub>1</sub> and
<b>R</b><sub>2</sub> are incidence matrices for rows that can be formed by integer vectors
<code>rowsA</code> and <code>rowsB</code> of length <i>m</i>, respectively, and 
<b>C</b><sub>1</sub> and
<b>C</b><sub>2</sub> are incidence matrices for columns that can be formed by integer vectors
<code>colsA</code> and <code>colsB</code> of length <i>n</i>, respectively.
</p>
<p>Matrices <b>A</b><sub>0</sub> and 
<b>B</b><sub>0</sub> can be obtained by matrix indexing as <code>A[rowsA,colsA]</code> and <code>B[rowsB,colsB]</code>, respectively. Therefore, the Hadamard product can be obtained directly as
</p>
<p style='text-align:center;font-family:courier'>A[rowsA,colsA]*B[rowsB,colsB]</p>
<p>The function computes the Hadamard product directly from <b>A</b> and <b>B</b> without forming <b>A</b><sub>0</sub> or <b>B</b><sub>0</sub> matrices.
</p>


<h3>Value</h3>

<p>Returns a matrix containing the Hadamard product.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # ==============================================
  # Example 1. Indexing using integers
  # ==============================================
  # Generate rectangular matrices A (nrowA x ncolA) and B (nrowB x ncolB)
  nA = c(10,15)
  nB = c(12,8)
  A = matrix(rnorm(nA[1]*nA[2]), nrow=nA[1])
  B = matrix(rnorm(nB[1]*nB[2]), nrow=nB[1])
  
  # Define size of the Hadamard n1 x n2
  n1 = 1000
  n2 = 500
  rowsA = sample(seq(nA[1]), n1, replace=TRUE)
  rowsB = sample(seq(nB[1]), n1, replace=TRUE)
  colsA = sample(seq(nA[2]), n2, replace=TRUE)
  colsB = sample(seq(nB[2]), n2, replace=TRUE)
  
  # Direct hadamard product
  K1 = A[rowsA,colsA]*B[rowsB,colsB]
  
  # Using 'Hadamard' function
  K2 = Hadamard(A, B, rowsA, rowsB, colsA, colsB)
  
  all.equal(K1,K2)  # They should be equal
  
  # ==============================================
  # Example 2. Indexing using row/column names
  # ==============================================
  # Generate squared symmetric matrices A and B 
  nA = 20
  nB = 15
  A = tcrossprod(matrix(rnorm(nA*nA), nrow=nA, dimnames=list(paste0("id",seq(nA)))))
  B = tcrossprod(matrix(rnorm(nB*nB), nrow=nB, dimnames=list(paste0("id",seq(nB)))))
  
  # Define size of the Hadamard n x n
  n = 1000
  IDA = sample(rownames(A), n, replace=TRUE)
  IDB = sample(rownames(B), n, replace=TRUE)
  
  # Direct hadamard product
  K1 = A[IDA,IDA]*B[IDB,IDB]
  dimnames(K1) = list(paste0(IDA,":",IDB), paste0(IDA,":",IDB))
  
  # Using 'Hadamard' function
  K2 = Hadamard(A, B, IDA, IDB, make.dimnames=TRUE)
  
  all.equal(K1,K2)  # They should be equal

</code></pre>

<hr>
<h2 id='Kronecker+20covariance'>Kronecker variance matrix penalization</h2><span id='topic+Kronecker_cov'></span>

<h3>Description</h3>

<p>Ridge penalization of a Kronecker covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kronecker_cov(K, Sigma = 1, Theta, byrow = FALSE,
              rows = NULL, cols = NULL, drop = TRUE,
              inplace = FALSE)
              
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kronecker+2B20covariance_+3A_k">K</code></td>
<td>
<p>(numeric) Variance matrix among subjects</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_sigma">Sigma</code></td>
<td>
<p>(numeric) A variance matrix among features. Default <code>Sigma=NULL</code> will consider an identity matrix with the same dimension as <code>Theta</code></p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_theta">Theta</code></td>
<td>
<p>(numeric) A diagonal-shifting parameter, value to be added to the diagonals of the Kronecker variance matrix. It can be a (symmetric) matrix with the same dimension as <code>Sigma</code> for within (diagonal) and between (off-diagonal) features shifting</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_byrow">byrow</code></td>
<td>
<p>(logical) If <code>FALSE</code> (default) the output Kronecker covariance matrix corresponds to a vectorized random matrix stacked by columns, otherwise, it is assumed to be stacked by rows</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_rows">rows</code></td>
<td>
<p>(integer) Index which rows of the Kronecker variance are to be returned. Default <code>rows=NULL</code> will return all the rows</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_cols">cols</code></td>
<td>
<p>(integer) Index which columns of the Kronecker variance are to be returned. Default <code>cols=NULL</code> return all the columns</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_drop">drop</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Kronecker+2B20covariance_+3A_inplace">inplace</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether operate directly on matrix <code>K</code> when <code>Sigma</code> and <code>Theta</code> are scalars. This is possible only when <code>rows=NULL</code> and <code>cols=NULL</code>. When <code>TRUE</code> the output will be overwritten on the same address occupied by <code>K</code>. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume that a multi-variate random matrix <b>X</b> with 
<i>n</i> subjects in rows and <i>p</i> features in columns follows a matrix Gaussian distribution with certain matrix of means 
<b>M</b> and variance-covariance matrix
<b>K</b> of dimension 
<i>n</i> &times; <i>n</i> between subjects, and 
<b>&Sigma;</b> of dimension 
<i>p</i> &times; <i>p</i> between features, then its vectorized form 
vec(<b>X</b>)
will also follow a Gaussian distribution with mean 
vec(<b>M</b>) and variance covariance matrix equal to the Kronecker
</p>
<p style='text-align:center'><b>&Sigma;</b>&otimes;<b>K</b></p>
<p>if the random matrix is vectorized column-wise or 
</p>
<p style='text-align:center'><b>K</b>&otimes;<b>&Sigma;</b></p>
<p>if the random matrix is vectorized row-wise.
</p>
<p>In the uni-variate case, the problem of near-singularity can be alleviated by penalizing the variance matrix
<b>K</b> by adding positive elements 
&theta; to its diagonal, i.e., 
<b>K</b> + &theta;<b>I</b>, where 
<b>I</b> is an identity matrix. The same can be applied to the multi-variate case where the Kronecker variance matrix is penalized with 
<b>&Theta;</b>={&theta;<sub>ij</sub>} of dimensions <i>p</i> &times; <i>p</i>, where diagonal entries will penalize within feature
<i>i</i> and off-diagonals will penalize between features <i>i</i>
and <i>j</i>. This is, 
</p>
<p style='text-align:center'><b>&Sigma;</b>&otimes;<b>K</b> + <b>&Theta;</b>&otimes;<b>I</b></p>
<p>if the random matrix is vectorized column-wise or 
</p>
<p style='text-align:center'><b>K</b>&otimes;<b>&Sigma;</b> + <b>I</b>&otimes;<b>&Theta;</b></p>
<p>if the random matrix is vectorized row-wise.
</p>
<p>Specific rows and columns from this Kronecker can be obtained as per the <code>rows</code> and <code>cols</code> arguments without forming the whole Kronecker product (see <code>help(Kronecker)</code>).
</p>


<h3>Value</h3>

<p>Returns the penalized Kronecker covariance matrix. It can be a sub-matrix of it as per the <code>rows</code> and <code>cols</code> arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # Random matrix witn n subjects in rows and p features in columns
  n = 20
  p = 5
  X = matrix(rnorm(n*p), ncol=p)
  
  # Variance matrix among rows/columns
  K = tcrossprod(X)      # for rows
  Sigma = crossprod(X)   # for columns
  dim(K)      # n x n matrix
  dim(Sigma)  # p x p matrix
  
  # Several examples of penalizing the Kronecker variance
  # ==============================================
  # Example 1. Add unique value 
  # ==============================================
  theta = 10.0
  G = Kronecker_cov(K, Sigma, Theta = theta)

  # it must equal to:
  I0 = diag(n)    # diagonal matrix of dimension n
  Theta0 = matrix(theta, nrow=p, ncol=p)
  G0 = kronecker(Sigma, K) + kronecker(Theta0, I0)
  all.equal(G,G0)
  
  # ==============================================
  # Example 2. Add feature-specific value 
  # ==============================================
  theta = rnorm(p)^2    # One value for each feature
  G = Kronecker_cov(K, Sigma, Theta = theta)

  # it must equal to:
  Theta0 = diag(theta)
  G0 = kronecker(Sigma, K) + kronecker(Theta0, I0)
  all.equal(G,G0)
  
  # ==============================================
  # Example 3. Add specific values within same feature
  #            and between different features 
  # ==============================================
  Theta = crossprod(matrix(rnorm(p*p), ncol=p))
  G = Kronecker_cov(K, Sigma, Theta = Theta)

  # it must equal to:
  G0 = kronecker(Sigma, K) + kronecker(Theta, I0)
  all.equal(G,G0)
  
  # Assume that random matrix X is stacked row-wise
  G = Kronecker_cov(K, Sigma, Theta = Theta, byrow = TRUE)

  # in this case the kronecker is inverted:
  G0 = kronecker(K, Sigma) + kronecker(I0, Theta)
  all.equal(G,G0)
  
  # ==============================================
  # Extra: Selecting specific entries of the output
  # ==============================================
  n = 150
  p = 120
  X = matrix(rnorm(n*p), ncol=p)
  K = tcrossprod(X)      
  Sigma = crossprod(X)   
  Theta = crossprod(matrix(rnorm(p*p), ncol=p))
  
  # We want only some rows and columns
  rows = c(1,3,5)
  cols = c(10,30,50)
  G = Kronecker_cov(K, Sigma, Theta = Theta, rows=rows, cols=cols)

  # this is preferable instead of:
  # I0 = diag(n)
  # G0 = (kronecker(Sigma, K) + kronecker(Theta, I0))[rows,cols]
  # all.equal(G,G0)
  

</code></pre>

<hr>
<h2 id='Kronecker+20product'>Kronecker product</h2><span id='topic+Kronecker'></span>

<h3>Description</h3>

<p>Computes the direct Kronecker product between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kronecker(A, B, rows = NULL, cols = NULL, 
          make.dimnames = FALSE, drop = TRUE,
          inplace = FALSE) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kronecker+2B20product_+3A_a">A</code></td>
<td>
<p>(numeric) Left numeric matrix</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_b">B</code></td>
<td>
<p>(numeric) Right numeric matrix</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_rows">rows</code></td>
<td>
<p>(integer) Index which rows of the Kronecker are to be returned. They must range from 1 to <code>nrow(A)*nrow(B)</code>. Default <code>rows=NULL</code> will return all the rows</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_cols">cols</code></td>
<td>
<p>(integer) Index which columns of the Kronecker are to be returned. They must range from 1 to <code>ncol(A)*ncol(B)</code>. Default <code>cols=NULL</code> return all the columns</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_drop">drop</code></td>
<td>
<p>Either <code>TRUE</code> or <code>FALSE</code> to whether return a uni-dimensional vector when output is a matrix with either 1 row or 1 column as per the <code>rows</code> and <code>cols</code> arguments</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Kronecker+2B20product_+3A_inplace">inplace</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether operate directly on one input matrix (<code>A</code> or <code>B</code>) when the other one is a scalar. This is possible only when <code>rows=NULL</code> and <code>cols=NULL</code>. When <code>TRUE</code> the output will be overwritten on the same address occupied by the input that is not scalar. Default <code>inplace=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For any two matrices
<b>A</b>={a<sub>ij</sub>} of dimensions 
<i>m</i> &times; <i>n</i> and
<b>B</b>={b<sub>ij</sub>} of dimensions
<i>p</i> &times; <i>q</i>, 
the direct Kronecker product between them is a matrix defined as the block matrix
</p>
<p style='text-align:center'><b>A</b>&otimes;<b>B</b> = {a<sub>ij</sub><b>B</b>}</p>
<p>which is of dimensions <i>mp</i> &times; <i>nq</i>.
</p>
<p>Selecting specific rows and columns from the Kronecker can be done by pre- and post- multiplication with incidence matrices
</p>
<p style='text-align:center'><b>R</b> (<b>A</b>&otimes;<b>B</b>) <b>C'</b></p>
<p>where
<b>R</b> is an incidence matrix for rows that can be formed by an integer vector <code>rows</code>, and 
<b>C</b> is an incidence matrix for columns that can be formed by an
integer vector <code>cols</code>.
This sub-matrix of the Kronecker can be obtained by matrix indexing using <code>rows</code> and <code>cols</code> as
</p>
<p style='text-align:center;font-family:courier'>Kronecker(A,B)[rows,cols]</p>
<p>The function computes this sub-matrix of the Kronecker product directly from <b>A</b> and <b>B</b> without forming the whole Kronecker product. This is very useful if a relatively small number of row/columns are to be selected. 
</p>


<h3>Value</h3>

<p>Returns the Kronecker product matrix. It can be a sub-matrix of it as per the <code>rows</code> and <code>cols</code> arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  
  # Kronecker product of 2 vectors
  A = rnorm(3)
  B = rnorm(2) 
  (K = Kronecker(A, B))
  # it must equal when using from the R-base package:
  (K0 = kronecker(A, B))
  
  # Kronecker product of 2 matrices
  A = matrix(rnorm(12), ncol=3)
  B = matrix(rnorm(4), ncol=2)
  K = Kronecker(A, B)
  # (it must equal (but faster) to:)
  K0 = kronecker(A, B)
  all.equal(K,K0)
  
  # Subsetting rows/columns from the Kronecker
  A = matrix(rnorm(100*150), ncol=150)
  B = matrix(rnorm(100*120), ncol=120)
  rows = c(1,3,5,7)
  cols = c(10,20,30,50)
  K = Kronecker(A, B, rows=rows, cols=cols)
  # (it must equal (but much faster) to:)
  K0 = kronecker(A, B)[rows,cols]
  all.equal(K,K0)
  

</code></pre>

<hr>
<h2 id='Tensor+20EVD'>Tensor EVD</h2><span id='topic+tensorEVD'></span>

<h3>Description</h3>

<p>Fast eigen value decomposition (EVD) of the Hadamard product of two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensorEVD(K1, K2, ID1, ID2, alpha = 1.0,
          EVD1 = NULL, EVD2 = NULL,
          d.min = .Machine$double.eps, 
          make.dimnames = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tensor+2B20EVD_+3A_k1">K1</code>, <code id="Tensor+2B20EVD_+3A_k2">K2</code></td>
<td>
<p>(numeric) Covariance structure matrices</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_id1">ID1</code></td>
<td>
<p>(character/integer) Vector of length <i>n</i> with either names or indices mapping from rows/columns of <code>K1</code> into the resulting tensor product</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_id2">ID2</code></td>
<td>
<p>(character/integer) Vector of length <i>n</i> with either names or indices mapping from rows/columns of <code>K2</code> into the resulting tensor product</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Proportion of variance of the tensor product to be explained by the tensor eigenvectors</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_evd1">EVD1</code></td>
<td>
<p>(list) (Optional) Eigenvectors and eigenvalues of <code>K1</code> as produced by the <code>eigen</code> function</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_evd2">EVD2</code></td>
<td>
<p>(list) (Optional) Eigenvectors and eigenvalues of <code>K2</code> as produced by the <code>eigen</code> function</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_d.min">d.min</code></td>
<td>
<p>(numeric) Tensor eigenvalue threshold. Default is a numeric zero. Only eigenvectors with eigenvalue passing this threshold are returned</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_make.dimnames">make.dimnames</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether add <code>rownames</code> and <code>colnames</code> attributes to the output</p>
</td></tr>
<tr><td><code id="Tensor+2B20EVD_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> to whether show progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the <i>n</i> &times; <i>n</i> matrix <b>K</b> to be the Hadamard product (aka element-wise or entry-wise product) involving two smaller matrices 
<b>K</b><sub>1</sub> and
<b>K</b><sub>2</sub> of dimensions 
<i>n</i><sub>1</sub> and <i>n</i><sub>2</sub>, respectively,
</p>
<p style='text-align:center'><b>K</b> = (<b>Z</b><sub>1</sub> <b>K</b><sub>1</sub> <b>Z'</b><sub>1</sub>) &odot; (<b>Z</b><sub>2</sub> <b>K</b><sub>2</sub> <b>Z'</b><sub>2</sub>)</p>
<p>where
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub> are incidence matrices that can be formed by integer vectors
<code>ID1</code> and <code>ID2</code> of length <i>n</i>, respectively.
</p>
<p>Let the eigenvalue decomposition (EVD) of <b>K</b><sub>1</sub> and
<b>K</b><sub>2</sub> to be
<b>K</b><sub>1</sub> = <b>V</b><sub>1</sub> <b>D</b><sub>1</sub> <b>V'</b><sub>1</sub> and 
<b>K</b><sub>2</sub> = <b>V</b><sub>2</sub> <b>D</b><sub>2</sub> <b>V'</b><sub>2</sub>. 
Using properties of the Hadamard and Kronecker products, an EVD of the Hadamard product
<b>K</b> can be approximated using the EVD of 
<b>K</b><sub>1</sub> and 
<b>K</b><sub>2</sub> as
</p>
<p style='text-align:center'><b>K = V D V'</b></p>
<p>where <b>D</b> = <b>D</b><sub>1</sub>&otimes;<b>D</b><sub>2</sub> is a diagonal matrix containing
<i>N</i> = <i>n</i><sub>1</sub> &times; <i>n</i><sub>2</sub> tensor eigenvalues 
d<sub>1</sub> &ge; ... &ge; d<sub>N</sub> &ge; 0 and
<b>V</b> = (<b>Z</b><sub>1</sub>&Star;<b>Z</b><sub>2</sub>)(<b>V</b><sub>1</sub>&otimes;<b>V</b><sub>2</sub>) = [<b>v</b><sub>1</sub>,...,<b>v</b><sub>N</sub>] is matrix containing <i>N</i> tensor eigenvectors
<b>v</b><sub>k</sub>; here the term 
<b>Z</b><sub>1</sub>&Star;<b>Z</b><sub>2</sub> is the 
&quot;face-splitting product&quot; (aka &quot;transposed Khatriâ€“Rao product&quot;) of matrices 
<b>Z</b><sub>1</sub> and
<b>Z</b><sub>2</sub>.
</p>
<p>Each tensor eigenvector <i>k</i> is derived separately as a Hadamard product using the corresponding 
<i>i(k)</i> and <i>j(k)</i> eigenvectors 
<b>v</b><sub>1i(k)</sub> and
<b>v</b><sub>2j(k)</sub> from 
<b>V</b><sub>1</sub> and 
<b>V</b><sub>2</sub>, respectively, this is
</p>
<p style='text-align:center'><b>v</b><sub>k</sub> = (<b>Z</b><sub>1</sub><b>v</b><sub>1i(k)</sub>)&odot;(<b>Z</b><sub>2</sub><b>v</b><sub>2j(k)</sub>)</p>


<h3>Value</h3>

<p>Returns a list object that contains the elements:
</p>

<ul>
<li> <p><code>values</code>: (vector) resulting tensor eigenvalues.
</p>
</li>
<li> <p><code>vectors</code>: (matrix) resulting tensor eigenvectors.
</p>
</li>
<li> <p><code>totalVar</code>: (numeric) total variance of the tensor matrix product.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>  require(tensorEVD)
  set.seed(195021)
  
  # Generate matrices K1 and K2 of dimensions n1 and n2
  n1 = 10; n2 = 15
  K1 = crossprod(matrix(rnorm(n1*(n1+10)), ncol=n1))
  K2 = crossprod(matrix(rnorm(n2*(n2+10)), ncol=n2))

  # ==============================================
  # Example 1. Full design (Kronecker product)
  # ==============================================
  ID1 = rep(seq(n1), each=n2)
  ID2 = rep(seq(n2), times=n1)

  # Direct EVD of the Hadamard product
  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)

  # Tensor EVD using K1 and K2
  EVD = tensorEVD(K1, K2, ID1, ID2)

  # Eigenvectors and eigenvalues are numerically equal
  all.equal(EVD0$values, EVD$values)
  all.equal(abs(EVD0$vectors), abs(EVD$vectors)) 

  # If a proportion of variance explained is specified, 
  # only the eigenvectors needed to explain such proportion are derived
  alpha = 0.95
  EVD = tensorEVD(K1, K2, ID1, ID2, alpha=alpha)
  dim(EVD$vectors)

  # For the direct EVD
  varexp = cumsum(EVD0$values/sum(EVD0$values))
  index = 1:which.min(abs(varexp-alpha))
  dim(EVD0$vectors[,index])

  # ==============================================
  # Example 2. Incomplete design (Hadamard product)
  # ==============================================
  # Eigenvectors and eigenvalues are no longer equivalent
  n = n1*n2   # Sample size n
  ID1 = sample(seq(n1), n, replace=TRUE) # Randomly sample of ID1
  ID2 = sample(seq(n2), n, replace=TRUE) # Randomly sample of ID2

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  all.equal(EVD0$values, EVD$values)
  all.equal(abs(EVD0$vectors), abs(EVD$vectors)) 
  
  # However, the sum of the eigenvalues is equal to the trace(K)
  c(sum(EVD0$values), sum(EVD$values), sum(diag(K)))

  # And provide the same approximation for K
  K01 = EVD0$vectors%*%diag(EVD0$values)%*%t(EVD0$vectors)
  K02 = EVD$vectors%*%diag(EVD$values)%*%t(EVD$vectors)
  c(all.equal(K,K01), all.equal(K,K02))

  # When n is different from N=n1xn2, both methods provide different 
  # number or eigenvectors/eigenvalues. The eigen function provides 
  # a number of eigenvectors equal to the minimum between n and N
  # for the tensorEVD, this number is always N

  # Sample size n being half of n1 x n2
  n = n1*n2/2
  ID1 = sample(seq(n1), n, replace=TRUE)
  ID2 = sample(seq(n2), n, replace=TRUE)

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  c(eigen=sum(EVD0$values&gt;1E-10), tensorEVD=sum(EVD$values&gt;1E-10))

  # Sample size n being twice n1 x n2
  n = n1*n2*2
  ID1 = sample(seq(n1), n, replace=TRUE)
  ID2 = sample(seq(n2), n, replace=TRUE)

  K = K1[ID1,ID1]*K2[ID2,ID2]
  EVD0 = eigen(K)
  EVD = tensorEVD(K1, K2, ID1, ID2)

  c(eigen=sum(EVD0$values&gt;1E-10), tensorEVD=sum(EVD$values&gt;1E-10))
  
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
