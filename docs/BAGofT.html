<!DOCTYPE html><html lang="en"><head><title>Help for package BAGofT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BAGofT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BAGofT'><p>A Binary Regression Adaptive Goodness-of-fit Test (BAGofT)</p></a></li>
<li><a href='#parRF'><p>Adaptive partition based on random forests</p></a></li>
<li><a href='#testGlmBi'><p>Testing binomial regressions</p></a></li>
<li><a href='#testGlmnet'><p>Testing penalized logistic regressions</p></a></li>
<li><a href='#testRF'><p>Testing random forests</p></a></li>
<li><a href='#testXGboost'><p>Testing XGboosts</p></a></li>
<li><a href='#VarImp'><p>Variable Importance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Binary Regression Adaptive Goodness-of-Fit Test (BAGofT)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>The BAGofT assesses the goodness-of-fit of binary classifiers. Details can be found in Zhang, Ding and Yang (2021) &lt;<a href="https://doi.org/10.48550/arXiv.1911.03063">doi:10.48550/arXiv.1911.03063</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>randomForest (&ge; 4.6.14), dcov (&ge; 0.1.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>glmnet (&ge; 2.0.18), xgboost (&ge; 1.2.0.1)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-14 20:05:13 UTC; mikezhang</td>
</tr>
<tr>
<td>Author:</td>
<td>Jiawei Zhang [aut, cre],
  Jie Ding [aut],
  Yuhong Yang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jiawei Zhang &lt;zhan4362@umn.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-14 20:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='BAGofT'>A Binary Regression Adaptive Goodness-of-fit Test (BAGofT)
</h2><span id='topic+BAGofT'></span>

<h3>Description</h3>

<p><code>BAGofT</code> is used to test the goodness-of-fit of binary classifiers.
The test statistic is constructed based on the results from multiple splittings.
In each split, the test first
splits the data into a training set and a validation set. Then,
it adaptively obtains a partition based on the training set and performs a goodness-of-fit test on the validation set. Details can be found in Zhang, Ding and Yang (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BAGofT(testModel, parFun = parRF(), data, nsplits = 100,
ne = floor(5*nrow(data)^(1/2)), nsim = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BAGofT_+3A_testmodel">testModel</code></td>
<td>
<p> a function that generates predicted results from the classifier to test. Details can be found in <code>"<a href="#topic+testGlmBi">testGlmBi</a>"</code> for binomial regression, <code>"<a href="#topic+testGlmnet">testGlmnet</a>"</code> for penalized logistic regression, <code>"<a href="#topic+testRF">testRF</a>"</code> for random forest, and <code>"<a href="#topic+testXGboost">testXGboost</a>"</code> for XGboost.
</p>
</td></tr>
<tr><td><code id="BAGofT_+3A_parfun">parFun</code></td>
<td>
<p> a function that generates the adaptive partition. The default is &lsquo;parRF()&rsquo; that generates a partition by random forest. More information can be found in <code>"<a href="#topic+parRF">parRF</a>"</code>.
</p>
</td></tr>
<tr><td><code id="BAGofT_+3A_data">data</code></td>
<td>
<p>a data frame containing  the response and covariates used in the model together with the other covariates not in the model but considered used to generate the partition.
</p>
</td></tr>
<tr><td><code id="BAGofT_+3A_nsplits">nsplits</code></td>
<td>
<p>number of splits. The default is 100.
</p>
</td></tr>
<tr><td><code id="BAGofT_+3A_ne">ne</code></td>
<td>
<p>the size of the validation set. The default is floor(5*nrow(data)^(1/2)).
</p>
</td></tr>
<tr><td><code id="BAGofT_+3A_nsim">nsim</code></td>
<td>
<p>the number of simulated datasets to calculate the bootstrap <code class="reqn">p</code>-value.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p.value</code></td>
<td>
<p>the bootstrap <code class="reqn">p</code>-value of the BAGofT test statistic (which combines the results from multiple splitting by taking the average).
</p>
</td></tr>
<tr><td><code>p.value2</code></td>
<td>
<p>the bootstrap <code class="reqn">p</code>-value from an alternative version of the BAGofT test statistic (which combines the results from multiple splitting by taking the sample median).
</p>
</td></tr>
<tr><td><code>p.value3</code></td>
<td>
<p>the bootstrap <code class="reqn">p</code>-value from an alternative version of the BAGofT test statistic (which combines the results from multiple splitting by taking the minimum).
</p>
</td></tr>
<tr><td><code>pmean</code></td>
<td>
<p>the BAGofT test statistic (which combines the results from multiple splitting by taking the average).
</p>
</td></tr>
<tr><td><code>pmedian</code></td>
<td>
<p>an alternative BAGofT test statistic (which combines the results from multiple splitting by taking the sample median).
</p>
</td></tr>
<tr><td><code>pmin</code></td>
<td>
<p>an alternative BAGofT test statistic (which combines the results from multiple splitting by taking the minimum).
</p>
</td></tr>
<tr><td><code>simRes</code></td>
<td>
<p>a list that contains the simulated test statitics used to generate the bootstrap <code class="reqn">p</code>-values. &lsquo;simRes$pmeanSim&rsquo;, &lsquo;simRes$pmediansim&rsquo;, &lsquo;simRes$pmeanSim&rsquo; corresepond to the three kinds of BAGofT statistics, respectively.
</p>
</td></tr>
<tr><td><code>singleSplit.results</code></td>
<td>
<p>a list that contains the results from each splitting. Its elements are as follows.
</p>
<p>&lsquo;singleSplit.results[[k]]$chisq&rsquo;: The chi-squared statistic of the BAGofT test from the <code class="reqn">k</code>th splitting.
</p>
<p>&lsquo;singleSplit.results[[k]]$p.value&rsquo;: The <code class="reqn">p</code>-value calculated from the chi-squared statistic.
</p>
<p>&lsquo;singleSplit.results[[k]]$ngp&rsquo;: The number of groups chosen by the adaptive partition.
</p>
<p>&lsquo;singleSplit.results[[k]]$contri&rsquo;: The weighted sum of squares from each group.
</p>
<p>&lsquo;singleSplit.results[[k]]$parRes&rsquo;: Variable importance (or other results from custom partition functions) from the adaptive partition.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200

# generate covariates data
x1dat &lt;- runif(n, -3, 3)
x2dat &lt;- rnorm(n, 0, 1)
x3dat &lt;- rchisq(n, 4)

# set coefficients
beta1 &lt;- 1
beta2 &lt;- 1
beta3 &lt;- 1

# calculate the linear predictor data
lindat &lt;- x1dat * beta1 + x2dat * beta2 + x3dat * beta3
# calculate the probabilities by inverse logit link
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, x1 = x1dat, x2 = x2dat,
                    x3 = x3dat)

###################################################
# Obtain the testing result
###################################################
# Test a logistic regression that misses 'x3'. The partition
# variables are 'x1', 'x2', and 'x3'.
testRes &lt;- BAGofT(testModel =testGlmBi(formula = y ~ x1 + x2 , link = "logit"),
       parFun = parRF(parVar = c("x1", "x2", "x3")),
       data = dat)

# the bootstrap p-value is 0. Therefore, the test is rejected
print(testRes$p.value)

# the variable importance from the adaptive partition shows that x3 is likely
# to be the reason for the overfitting (,which is correct since the formula
# fm misses the x3).
print(VarImp(testRes))

## End(Not run)
</code></pre>

<hr>
<h2 id='parRF'>Adaptive partition based on random forests
</h2><span id='topic+parRF'></span>

<h3>Description</h3>

<p><code>parRF</code> generates an adaptive partition based on the training set data and training set predictions. It controls the group sizes by the covariates data from the validation set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parRF(parVar = ".", Kmax = NULL, nmin = NULL, ntree = 60, mtry = NULL, maxnodes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parRF_+3A_parvar">parVar</code></td>
<td>
<p> a character vector that contains the names of the  covariates to generate the adaptive partition. The default is taking all the variables except the response from the &lsquo;data&rsquo;.
</p>
</td></tr>
<tr><td><code id="parRF_+3A_kmax">Kmax</code></td>
<td>
<p> the maximum number of groups. The default is floor(nrow(Test.data)/nmin).
</p>
</td></tr>
<tr><td><code id="parRF_+3A_nmin">nmin</code></td>
<td>
<p> a numerical vector of the training set Pearson residuals from the classifier to test. The default is ceiling(sqrt(nrow(Validation.data))).
</p>
</td></tr>
<tr><td><code id="parRF_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. The default is 60.
</p>
</td></tr>
<tr><td><code id="parRF_+3A_mtry">mtry</code></td>
<td>
<p>number of variables randomly sampled as candidates at each split. The default value is floor( length(parVarNew)/3) where parVarNew is the number of covariates after the preselection.
</p>
</td></tr>
<tr><td><code id="parRF_+3A_maxnodes">maxnodes</code></td>
<td>
<p>maximum number of terminal nodes trees in the forest can have.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>gup</code></td>
<td>
<p> a factor that contains the grouping result of the validation set data.
</p>
</td></tr>
<tr><td><code>parRes</code></td>
<td>
<p> a list that contains the variable importance from the random forest.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200

# generate covariates data
x1dat &lt;- runif(n, -3, 3)
x2dat &lt;- rnorm(n, 0, 1)
x3dat &lt;- rchisq(n, 4)

# set coefficients
beta1 &lt;- 1
beta2 &lt;- 1
beta3 &lt;- 1

# calculate the linear predictor data
lindat &lt;- x1dat * beta1 + x2dat * beta2 + x3dat * beta3
# calculate the probabilities by inverse logit link
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, x1 = x1dat, x2 = x2dat,
                  x3 = x3dat)

###################################################
# Apply parRF to generate an adaptive partition
###################################################
# number of rows in the dataset
nr &lt;- nrow(dat)
# size of the validation set
ne &lt;- floor(5*nrow(dat)^(1/2))
# obtain the training set size
nt &lt;- nr - ne
# the indices for training set observations
trainIn &lt;- sample(c(1 : nr), nt)

#split the data
datT &lt;- dat[trainIn, ]
datE &lt;- dat[-trainIn, ]
# fit a logistic regression model to test by training data
testModel &lt;- testGlmBi(formula = y ~ x1 + x2 , link = "logit")
# output training set predictions and pearson residuals
testMod &lt;- testModel(Train.data = datT, Validation.data = datE)

# obtain adaptive partition result from parFun
parFun &lt;- parRF(parVar = c("x1", "x2", "x3"))
par &lt;- parFun(Rsp = testMod$Rsp, predT = testMod$predT, res = testMod$res,
              Train.data = datT, Validation.data = datE)

# print the grouping result of the validataion set data
print(par$gup)

# print variable importance from the random forest
print(par$parRes)
</code></pre>

<hr>
<h2 id='testGlmBi'>Testing binomial regressions
</h2><span id='topic+testGlmBi'></span>

<h3>Description</h3>

<p><code>testGlmBi</code> specifies a binomial regression as the classifier to test. It returns a function that can be taken as the input of &lsquo;testModel&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testGlmBi(formula, link)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testGlmBi_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to test.
</p>
</td></tr>
<tr><td><code id="testGlmBi_+3A_link">link</code></td>
<td>
<p>a specification for the model link function. Can be one of &quot;logit&quot;, &quot;probit&quot;, &quot;cloglog&quot;.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200

# generate covariates data
x1dat &lt;- runif(n, -3, 3)
x2dat &lt;- rnorm(n, 0, 1)
x3dat &lt;- rchisq(n, 4)

# set coefficients
beta1 &lt;- 1
beta2 &lt;- 1
beta3 &lt;- 1

# calculate the linear predictor data
lindat &lt;- x1dat * beta1 + x2dat * beta2 + x3dat * beta3
# calculate the probabilities by inverse logit link
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, x1 = x1dat, x2 = x2dat,
                    x3 = x3dat)

###################################################
# Obtain the testing result
###################################################
# Test a logistic regression that misses 'x3'. The partition
# variables are 'x1', 'x2', and 'x3'.
testRes &lt;- BAGofT(testModel =testGlmBi(formula = y ~ x1 + x2 , link = "logit"),
       parFun = parRF(parVar = c("x1", "x2", "x3")),
       data = dat)

# the bootstrap p-value is 0. Therefore, the test is rejected
print(testRes$p.value)

# the variable importance from the adaptive partion shows that x3 is likely
# to be the reason for the overfitting (,which is correct since the formula
# fm misses the x3).
print(VarImp(testRes))

## End(Not run)
</code></pre>

<hr>
<h2 id='testGlmnet'>Testing penalized logistic regressions
</h2><span id='topic+testGlmnet'></span>

<h3>Description</h3>

<p><code>testGlmnet</code> specifies a penalized logistic regression as the classifier to test. It returns a function that can be taken as the input of &lsquo;testModel&rsquo;. R package &lsquo;glmnet&rsquo; is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testGlmnet(formula, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testGlmnet_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to test.
</p>
</td></tr>
<tr><td><code id="testGlmnet_+3A_alpha">alpha</code></td>
<td>
<p>the elasticnet mixing parameter, with <code class="reqn">0\le\alpha\le 1</code>.
The penalty is defined as
</p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.</code>
</p>
 <p><code>alpha=1</code> is the
lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200
# set the number of covariates
p &lt;- 20

# generate covariates data
Xdat &lt;- matrix(runif((n*p), -5,5), nrow = n, ncol = p)
colnames(Xdat) &lt;- paste("x", c(1:p), sep = "")

# generate random coefficients
betaVec &lt;- rnorm(6)
# calculate the linear predictor data
lindat &lt;-  3 * (Xdat[,1] &lt; 2 &amp; Xdat[,1] &gt; -2) + -3 * (Xdat[,1] &gt; 2 | Xdat[,1] &lt; -2) +
  0.5 * (Xdat[,2] + Xdat[, 3] + Xdat[,4] + Xdat[, 5])
# calculate the probabilities
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, Xdat)

###################################################
# Obtain the testing result
###################################################

# 50 percent training set
testRes1 &lt;- BAGofT(testModel = testGlmnet(formula = y~., alpha = 1),
                  data = dat,
                  ne = n*0.5,
                  nsplits = 20,
                  nsim = 40)
# 75 percent training set
testRes2 &lt;- BAGofT(testModel = testGlmnet(formula = y~., alpha = 1),
                   data = dat,
                   ne = n*0.75,
                   nsplits = 20,
                   nsim = 40)
# 90 percent training set
testRes3 &lt;- BAGofT(testModel = testGlmnet(formula = y~., alpha = 1),
                   data = dat,
                   ne = n*0.9,
                   nsplits = 20,
                   nsim = 40)

# print the testing result.
print(c(testRes1$p.value, testRes2$p.value, testRes3$p.value))

## End(Not run)
</code></pre>

<hr>
<h2 id='testRF'>Testing random forests
</h2><span id='topic+testRF'></span>

<h3>Description</h3>

<p><code>testRF</code> specifies a random forest as the classifier to test. It returns a function that can be taken as the input of &lsquo;testModel&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testRF(formula, ntree = 500, mtry = NULL, maxnodes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testRF_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to test.
</p>
</td></tr>
<tr><td><code id="testRF_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. The default is 500.
</p>
</td></tr>
<tr><td><code id="testRF_+3A_mtry">mtry</code></td>
<td>
<p>number of variables randomly sampled as candidates at each split. The default value is sqrt(p) where p is the number of covariates.
</p>
</td></tr>
<tr><td><code id="testRF_+3A_maxnodes">maxnodes</code></td>
<td>
<p>maximum number of terminal nodes trees in the forest can have.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200
# set the number of covariates
p &lt;- 20

# generate covariates data
Xdat &lt;- matrix(runif((n*p), -5,5), nrow = n, ncol = p)
colnames(Xdat) &lt;- paste("x", c(1:p), sep = "")

# generate random coefficients
betaVec &lt;- rnorm(6)
# calculate the linear predictor data
lindat &lt;-  3 * (Xdat[,1] &lt; 2 &amp; Xdat[,1] &gt; -2) + -3 * (Xdat[,1] &gt; 2 | Xdat[,1] &lt; -2) +
  0.5 * (Xdat[,2] + Xdat[, 3] + Xdat[,4] + Xdat[, 5])
# calculate the probabilities
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, Xdat)

###################################################
# Obtain the testing result
###################################################

# 50 percent training set
testRes1 &lt;- BAGofT(testModel = testRF(formula = y ~.),
                  data = dat,
                  ne = n*0.5,
                  nsplits = 20,
                  nsim = 40)
# 75 percent training set
testRes2 &lt;- BAGofT(testModel = testRF(formula = y ~.),
                   data = dat,
                   ne = n*0.75,
                   nsplits = 20,
                   nsim = 40)
# 90 percent training set
testRes3 &lt;- BAGofT(testModel = testRF(formula = y ~.),
                   data = dat,
                   ne = n*0.9,
                   nsplits = 20,
                   nsim = 40)

# print the testing result.
print(c(testRes1$p.value, testRes2$p.value, testRes3$p.value))

## End(Not run)
</code></pre>

<hr>
<h2 id='testXGboost'>Testing XGboosts
</h2><span id='topic+testXGboost'></span>

<h3>Description</h3>

<p><code>testXGboost</code> specifies an XGboost as the classifier to test. It returns a function that can be taken as the input of &lsquo;testModel&rsquo;. R package &lsquo;xgboost&rsquo; is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testXGboost(formula, params = list(), nrounds = 25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="testXGboost_+3A_formula">formula</code></td>
<td>

<p>an object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to test.
</p>
</td></tr>
<tr><td><code id="testXGboost_+3A_params">params</code></td>
<td>
<p>the list of parameters. The complete list of parameters is
available in the <a href="http://xgboost.readthedocs.io/en/latest/parameter.html">online documentation</a>.
</p>
</td></tr>
<tr><td><code id="testXGboost_+3A_nrounds">nrounds</code></td>
<td>
<p>max number of boosting iterations.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200
# set the number of covariates
p &lt;- 20

# generate covariates data
Xdat &lt;- matrix(runif((n*p), -5,5), nrow = n, ncol = p)
colnames(Xdat) &lt;- paste("x", c(1:p), sep = "")

# generate random coefficients
betaVec &lt;- rnorm(6)
# calculate the linear predictor data
lindat &lt;-  3 * (Xdat[,1] &lt; 2 &amp; Xdat[,1] &gt; -2) + -3 * (Xdat[,1] &gt; 2 | Xdat[,1] &lt; -2) +
  0.5 * (Xdat[,2] + Xdat[, 3] + Xdat[,4] + Xdat[, 5])
# calculate the probabilities
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, Xdat)

###################################################
# Obtain the testing result
###################################################

# 50 percent training set
testRes1 &lt;- BAGofT(testModel = testXGboost(formula = y ~.),
                  data = dat,
                  ne = n*0.5,
                  nsplits = 20,
                  nsim = 40)
# 75 percent training set
testRes2 &lt;- BAGofT(testModel = testXGboost(formula = y ~.),
                   data = dat,
                   ne = n*0.75,
                   nsplits = 20,
                   nsim = 40)
# 90 percent training set
testRes3 &lt;- BAGofT(testModel = testXGboost(formula = y ~.),
                   data = dat,
                   ne = n*0.9,
                   nsplits = 20,
                   nsim = 40)

# print the testing result.
print(c(testRes1$p.value, testRes2$p.value, testRes3$p.value))

## End(Not run)
</code></pre>

<hr>
<h2 id='VarImp'>Variable Importance
</h2><span id='topic+VarImp'></span>

<h3>Description</h3>

<p><code>VarImp</code> averages the variable importance generated by <code>"<a href="#topic+parRF">parRF</a>"</code> from different splittings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarImp(TestRes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VarImp_+3A_testres">TestRes</code></td>
<td>
<p> an output from <code>"<a href="#topic+BAGofT">BAGofT</a>"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Var.imp</code></td>
<td>
<p> the averaged variable importance from multiple splittings. A high variable importance indicates that the corresponding covariate is likely to be related to the possible underfitting. When the number of partition covariates is larger than 5, output the result of 5 covariates with the largest averaged variable importance.
</p>
</td></tr>
<tr><td><code>preVar.imp</code></td>
<td>
<p> the averaged variable importance for all of the variables. Output only when the number of partition covariates is larger than 5.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhang, Ding and Yang (2021) &quot;Is a Classification Procedure Good Enough?-A Goodness-of-Fit Assessment Tool for Classification Learning&quot; arXiv preprint 	arXiv:1911.03063v2 (2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
###################################################
# Generate a sample dataset.
###################################################
# set the random seed
set.seed(20)
# set the number of observations
n &lt;- 200

# generate covariates data
x1dat &lt;- runif(n, -3, 3)
x2dat &lt;- rnorm(n, 0, 1)
x3dat &lt;- rchisq(n, 4)

# set coefficients
beta1 &lt;- 1
beta2 &lt;- 1
beta3 &lt;- 1

# calculate the linear predictor data
lindat &lt;- x1dat * beta1 + x2dat * beta2 + x3dat * beta3
# calculate the probabilities by inverse logit link
pdat &lt;- 1/(1 + exp(-lindat))

# generate the response data
ydat &lt;- sapply(pdat, function(x) stats :: rbinom(1, 1, x))

# generate the dataset
dat &lt;- data.frame(y = ydat, x1 = x1dat, x2 = x2dat,
                    x3 = x3dat)

###################################################
# Obtain the testing result
###################################################
# Test a logistic regression that misses 'x3'. The partition
# variables are 'x1', 'x2', and 'x3'.
testRes &lt;- BAGofT(testModel =testGlmBi(formula = y ~ x1 + x2 , link = "logit"),
       parFun = parRF(parVar = c("x1", "x2", "x3")),
       data = dat)

# the bootstrap p-value is 0. Therefore, the test is rejected
print(testRes$p.value)

# the variable importance from the adaptive partion shows that x3 is likely
# to be the reason for the overfitting (,which is correct since the formula
# fm misses the x3).
print(VarImp(testRes))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
