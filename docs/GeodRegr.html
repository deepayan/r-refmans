<!DOCTYPE html><html lang="en"><head><title>Help for package GeodRegr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GeodRegr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#are'><p>Approximate ARE of an M-type estimator to the least-squares estimator</p></a></li>
<li><a href='#are_nr'><p>Newton-Raphson method for the <code>are</code> function</p></a></li>
<li><a href='#calvaria'><p>Data on calvaria growth in rat skulls</p></a></li>
<li><a href='#exp_map'><p>Exponential map</p></a></li>
<li><a href='#geo_dist'><p>Geodesic distance between two points on a manifold</p></a></li>
<li><a href='#geo_reg'><p>Gradient descent for (robust) geodesic regression</p></a></li>
<li><a href='#intrinsic_location'><p>Gradient descent for location based on M-type estimators</p></a></li>
<li><a href='#log_map'><p>Logarithm map</p></a></li>
<li><a href='#loss'><p>Loss</p></a></li>
<li><a href='#onmanifold'><p>Manifold check and projection</p></a></li>
<li><a href='#par_trans'><p>Parallel transport</p></a></li>
<li><a href='#rnormtangents'><p>Random generation of tangent vectors from the Riemannian normal distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Geodesic Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a gradient descent algorithm to find a geodesic relationship between real-valued independent variables and a manifold-valued dependent variable (i.e. geodesic regression). Available manifolds are Euclidean space, the sphere, hyperbolic space, and Kendall's 2-dimensional shape space. Besides the standard least-squares loss, the least absolute deviations, Huber, and Tukey biweight loss functions can also be used to perform robust geodesic regression. Functions to help choose appropriate cutoff parameters to maintain high efficiency for the Huber and Tukey biweight estimators are included, as are functions for generating random tangent vectors from the Riemannian normal distributions on the sphere and hyperbolic space. The n-sphere is a n-dimensional manifold: we represent it as a sphere of radius 1 and center 0 embedded in (n+1)-dimensional space. Using the hyperboloid model of hyperbolic space, n-dimensional hyperbolic space is embedded in (n+1)-dimensional Minkowski space as the upper sheet of a hyperboloid of two sheets. Kendall's 2D shape space with K landmarks is of real dimension 2K-4; preshapes are represented as complex K-vectors with mean 0 and magnitude 1. Details are described in Shin, H.-Y. and Oh, H.-S. (2020) &lt;<a href="https://doi.org/10.48550/arXiv.2007.04518">doi:10.48550/arXiv.2007.04518</a>&gt;. Also see Fletcher, P. T. (2013) &lt;<a href="https://doi.org/10.1007%2Fs11263-012-0591-y">doi:10.1007/s11263-012-0591-y</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS (&ge; 7.3.51.6), zipfR (&ge; 0.6.66), stats (&ge; 4.0.1)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/hayoungshin1/GeodRegr">https://github.com/hayoungshin1/GeodRegr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/hayoungshin1/GeodRegr/issues">https://github.com/hayoungshin1/GeodRegr/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-03 02:30:56 UTC; multiscale59</td>
</tr>
<tr>
<td>Author:</td>
<td>Ha-Young Shin [aut, cre],
  Hee-Seok Oh [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ha-Young Shin &lt;hayoung.shin@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-03 08:00:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='are'>Approximate ARE of an M-type estimator to the least-squares estimator</h2><span id='topic+are'></span>

<h3>Description</h3>

<p>Approximate asymptotic relative efficiency (ARE) of an M-type estimator to
the least-squares estimator given Gaussian errors, calculated using a tangent
space approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are(estimator, n, c = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="are_+3A_estimator">estimator</code></td>
<td>
<p>M-type estimator (<code>'l2'</code>, <code>'l1'</code>, <code>'huber'</code>,
or <code>'tukey'</code>).</p>
</td></tr>
<tr><td><code id="are_+3A_n">n</code></td>
<td>
<p>Dimension of the manifold.</p>
</td></tr>
<tr><td><code id="are_+3A_c">c</code></td>
<td>
<p>A positive multiplier, or a vector of them, of <code class="reqn">\sigma</code>, the
square root of the variance, used in the cutoff parameter for the
<code>'huber'</code> and <code>'tukey'</code> estimators; should be <code>NULL</code> for the
<code>'l2'</code> or <code>'l1'</code> estimators.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Approximate ARE
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression.
&lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+are_nr">are_nr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>are('l1', 10)

</code></pre>

<hr>
<h2 id='are_nr'>Newton-Raphson method for the <code>are</code> function</h2><span id='topic+are_nr'></span>

<h3>Description</h3>

<p>Finds the positive multiplier of <code class="reqn">\sigma</code>, the square root of the
variance, used in the cutoff parameter that will give the desired
(approximate) level of efficiency for the provided M-type estimator. Does so
by using <code>are</code> and its partial derivative with respect to <code>c</code> in
the Newton-Raphson method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are_nr(estimator, n, startingpoint, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="are_nr_+3A_estimator">estimator</code></td>
<td>
<p>M-type estimator (<code>'huber'</code> or <code>'tukey'</code>).</p>
</td></tr>
<tr><td><code id="are_nr_+3A_n">n</code></td>
<td>
<p>Dimension of the manifold.</p>
</td></tr>
<tr><td><code id="are_nr_+3A_startingpoint">startingpoint</code></td>
<td>
<p>Initial estimate for the Newton-Raphson method. May be
determined after looking at a graph of the <code>are</code> function.</p>
</td></tr>
<tr><td><code id="are_nr_+3A_level">level</code></td>
<td>
<p>The desired ARE to the <code>'l2'</code> estimator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As is often the case with the Newton-Raphson method, the starting point must
be chosen carefully in order to ensure convergence. The use of the graph of
the <code>are</code> function to find a starting point close to the root is
recommended.
</p>


<h3>Value</h3>

<p>Positive multiplier of <code class="reqn">\sigma</code>, the square root of the variance,
used in the cutoff parameter, to give the desired level of efficiency.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression. &lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+are">are</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dimension &lt;- 4
x &lt;- 1:10000 / 1000
# use a graph of the are function to pick a good starting point
plot(x, are('huber', dimension, x) - 0.95)
are_nr('huber', dimension, 2)

</code></pre>

<hr>
<h2 id='calvaria'>Data on calvaria growth in rat skulls</h2><span id='topic+calvaria'></span>

<h3>Description</h3>

<p>Vilmann data for growth in rat calvariae, that is, upper skulls, for 21 rats.
For each rat, the shape of the calavaria was measured at 8 different ages (7,
14, 21, 30, 40, 60, 90, and 150 days), for a total of 168 data points. The
boundaries of the midsagittal sections of the rats' calvariae are each marked
with 8 landmarks. The data points have been translated and scaled in order to
make them preshapes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(calvaria)
</code></pre>


<h3>Format</h3>

<p>A named list containing <code>x</code> a vector containing the ages
<code>y</code> a matrix where each column is a preshape. The 23rd, 101st,
104th, and 160th entries are corrupted)
</p>


<h3>Details</h3>

<p>There are 4 corrupted data points: those corresponding to day 90 for the 3rd
rat, day 40 and 150 for the 13th rat, and day 150 for the 20th rat (the 23rd,
101st, 104th, and 160th entries); one of the landmarks for each of these
measurements has been entered as (9999, 9999) (before translation/scaling).
</p>


<h3>Source</h3>

<p>Vilmann's rat data set from pp. 408-414 of Bookstein. Original data
available at
<a href="https://www.sbmorphometrics.org/data/Book-VilmannRat.txt">https://www.sbmorphometrics.org/data/Book-VilmannRat.txt</a>.
</p>


<h3>References</h3>

<p>Bookstein, F. L. (1991). Morphometric Tools for Landmark Data:
Geometry and Biology. Cambridge Univ, 408-414.
</p>
<p>Hinkle, J., Muralidharan, P., Fletcher, P. T., Joshi, S. (2012). Polynomial
Regression on Riemannian Manifolds. European Conference on Computer Vision,
1-14.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># we will test the robustness of each estimator by comparing their
# performance on the original (corrupted) data set to that of the L_2
# estimator on the uncorrupted data set (with the 4 problematic data points
# removed).

data(calvaria)

manifold &lt;- 'kendall'

contam_x_data &lt;- calvaria$x
contam_mean_x &lt;- mean(contam_x_data)
contam_x_data &lt;- contam_x_data - contam_mean_x # center x data
uncontam_x_data &lt;- calvaria$x[ -c(23, 101, 104, 160)]
uncontam_mean_x &lt;- mean(uncontam_x_data)
uncontam_x_data &lt;- uncontam_x_data - uncontam_mean_x # center x data

contam_y_data &lt;- calvaria$y
uncontam_y_data &lt;- calvaria$y[, -c(23, 101, 104, 160)] # remove corrupted
    # columns

landmarks &lt;- dim(contam_y_data)[1]
dimension &lt;- 2 * landmarks - 4

# we ignore Huber's estimator as the L_1 estimator already has an
# (approximate) efficiency above 95% in 12 dimensions; see documentation for
# the are and are_nr functions

tol &lt;- 1e-5
uncontam_l2 &lt;- geo_reg(manifold, uncontam_x_data, uncontam_y_data,
    'l2', p_tol = tol, V_tol = tol)
contam_l2 &lt;- geo_reg(manifold, contam_x_data, contam_y_data,
    'l2', p_tol = tol, V_tol = tol)
contam_l1 &lt;- geo_reg(manifold, contam_x_data, contam_y_data,
    'l1', p_tol = tol, V_tol = tol)
contam_tukey &lt;- geo_reg(manifold, contam_x_data, contam_y_data,
    'tukey', are_nr('tukey', dimension, 10, 0.99), p_tol = tol, V_tol = tol)

geodesics &lt;- vector('list')
geodesics[[1]] &lt;- uncontam_l2
geodesics[[2]] &lt;- contam_l2
geodesics[[3]] &lt;- contam_l1
geodesics[[4]] &lt;- contam_tukey

loss(manifold, geodesics[[1]]$p, geodesics[[1]]$V, uncontam_x_data,
    uncontam_y_data, 'l2')
loss(manifold, geodesics[[2]]$p, geodesics[[2]]$V, contam_x_data,
    contam_y_data, 'l2')
loss(manifold, geodesics[[3]]$p, geodesics[[3]]$V, contam_x_data,
    contam_y_data, 'l1')
loss(manifold, geodesics[[4]]$p, geodesics[[4]]$V, contam_x_data,
    contam_y_data, 'tukey', are_nr('tukey', dimension, 10, 0.99))

# visualization of each geodesic

oldpar &lt;- par(mfrow = c(1, 4))

days &lt;- c(7, 14, 21, 30, 40, 60, 90, 150)
pal &lt;- colorRampPalette(c("blue", "red"))(length(days))

# each predicted geodesic will be represented as a sequence of the predicted
# shapes at each of the above ages, the blue contour will show the predicted
# shape on day 7 and the red contour the predicted shape on day 150

contour &lt;- vector('list')

for (i in 1:length(days)) {
  contour[[i]] &lt;- exp_map(manifold, geodesics[[1]]$p, (days[i] -
      uncontam_mean_x) * geodesics[[1]]$V)
  contour[[i]] &lt;- c(contour[[i]], contour[[i]][1])
}
plot(Re(contour[[length(days)]]), Im(contour[[length(days)]]), type = 'n',
    xaxt = 'n', yaxt = 'n', ann = FALSE, asp = 1)
 for (i in 1:length(days)) {
   lines(Re(contour[[i]]), Im(contour[[i]]), col = pal[i])
}
for (j in 2:4) {
  for (i in 1:length(days)) {
    contour[[i]] &lt;- exp_map(manifold, geodesics[[j]]$p, (days[i] -
        contam_mean_x) * geodesics[[j]]$V)
    contour[[i]] &lt;- c(contour[[i]], contour[[i]][1])
  }
  plot(Re(contour[[length(days)]]), Im(contour[[length(days)]]), type = 'n',
      xaxt = 'n', yaxt = 'n', ann = FALSE, asp = 1)
  for (i in 1:length(days)) {
    lines(Re(contour[[i]]), Im(contour[[i]]), col = pal[i])
  }
}
# even with a mere 4 corrupted landmarks out of a total of 8 * 168 = 1344, we
# can clearly see that contam_l2, the second image, looks slightly
# different from all the others, especially near the top of the image.

par(oldpar)

</code></pre>

<hr>
<h2 id='exp_map'>Exponential map</h2><span id='topic+exp_map'></span>

<h3>Description</h3>

<p>Performs the exponential map <code class="reqn">\textrm{Exp}_p(v)</code> on the given manifold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp_map(manifold, p, v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="exp_map_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="exp_map_+3A_p">p</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
<tr><td><code id="exp_map_+3A_v">v</code></td>
<td>
<p>A vector (or column matrix) tangent to <code>p</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector representing a point on the manifold.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Cornea, E., Zhu, H., Kim, P. and Ibrahim, J. G. (2017). Regression models
on Riemannian symmetric spaces. Journal of the Royal Statistical Society:
Series B, 79, 463-482.
</p>
<p>Calinon, S. (2020). Gaussians on Riemannian manifolds: Applications for
robot learning and adaptive control. IEEE Robotics &amp; Automation Magazine,
27, 33-45.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression. &lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+log_map">log_map</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>exp_map('hyperbolic', c(1, 0, 0, 0, 0), c(0, 0, pi / 4, 0, 0))

</code></pre>

<hr>
<h2 id='geo_dist'>Geodesic distance between two points on a manifold</h2><span id='topic+geo_dist'></span>

<h3>Description</h3>

<p>Finds the Riemannian distance
<code class="reqn">d(p_1,p_2)=||\textrm{Log}_{p_1}(p_2)||</code> between two points on
the given manifold, provided <code class="reqn">p_2</code> is in the domain of
<code class="reqn">\textrm{Log}_{p_1}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geo_dist(manifold, p1, p2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="geo_dist_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="geo_dist_+3A_p1">p1</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
<tr><td><code id="geo_dist_+3A_p2">p2</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>On the sphere, <code class="reqn">-p_1</code> is not in the domain of <code class="reqn">\textrm{Log}_{p_1}</code>.
</p>


<h3>Value</h3>

<p>Riemannian distance between <code>p1</code> and <code>p2</code>.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>See Also</h3>

<p><code><a href="#topic+log_map">log_map</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p1 &lt;- matrix(rnorm(10), ncol = 2)
p1 &lt;- p1[, 1] + (1i) * p1[, 2]
p1 &lt;- (p1 - mean(p1)) / norm(p1 - mean(p1), type = '2')
p2 &lt;- matrix(rnorm(10), ncol = 2)
p2 &lt;- p2[, 1] + (1i) * p2[, 2]
p2 &lt;- (p2 - mean(p2)) / norm(p2 - mean(p2), type = '2')
geo_dist('kendall', p1, p2)

</code></pre>

<hr>
<h2 id='geo_reg'>Gradient descent for (robust) geodesic regression</h2><span id='topic+geo_reg'></span>

<h3>Description</h3>

<p>Finds <code class="reqn">\mathrm{argmin}_{(p,V)\in M\times (T_pM) ^ n}\sum_{i=1} ^ {N}
\rho(d(\mathrm{Exp}(p,Vx_i),y_i))</code> through a gradient descent algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geo_reg(
  manifold,
  x,
  y,
  estimator,
  c = NULL,
  p_tol = 1e-05,
  V_tol = 1e-05,
  max_iter = 1e+05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="geo_reg_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_x">x</code></td>
<td>
<p>A vector, matrix, or data frame of independent variables; for
matrices and data frames, the rows and columns represent the subjects and
independent variables, respectively.</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_y">y</code></td>
<td>
<p>A matrix or data frame whose columns represent points on the
manifold.</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_estimator">estimator</code></td>
<td>
<p>M-type estimator (<code>'l2'</code>, <code>'l1'</code>, <code>'huber'</code>,
or <code>'tukey'</code>).</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_c">c</code></td>
<td>
<p>Multiplier of <code class="reqn">\sigma</code>, the square root of the variance, used in
the cutoff parameter for the <code>'huber'</code> and <code>'tukey'</code> estimators;
should be <code>NULL</code> for the <code>'l2'</code> or <code>'l1'</code> estimators.</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_p_tol">p_tol</code></td>
<td>
<p>Termination condition for the distance between consecutive
updates of <code>p</code>.</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_v_tol">V_tol</code></td>
<td>
<p>Termination condition for the distance between columns of
consecutive updates of <code>V</code>, parallel transported to be in the same
tangent space. Can be a vector of positive real numbers for each
independent variable or a single positive number.</p>
</td></tr>
<tr><td><code id="geo_reg_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of gradient descent steps before ending the
algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each column of <code>x</code> should be centered to have an average of 0 for the
quickest and most accurate results. If all of the elements of a column of
<code>x</code> are equal, the resulting vector will consist of <code>NA</code>s. In the
case of the <code>'sphere'</code>, an error will be raised if all points are on a
pair of antipodes.
</p>


<h3>Value</h3>

<p>A named list containing </p>
<table role = "presentation">
<tr><td><code>p</code></td>
<td>
<p>a vector representing the estimate
of the initial point on the manifold</p>
</td></tr> <tr><td><code>V</code></td>
<td>
<p>a matrix representing the
estimate of the initial velocities for each independent variable; the
columns represent the independent variables.</p>
</td></tr> <tr><td><code>iteration</code></td>
<td>
<p>number of
gradient descent steps taken.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Kim, H. J., Adluru, N., Collins, M. D., Chung, M. K., Bendin, B. B.,
Johnson, S. C., Davidson, R. J. and Singh, V. (2014). Multivariate general
linear models (MGLM) on Riemannian manifolds with applications to
statistical analysis of diffusion weighted images. 2014 IEEE Conference on
Computer Vision and Pattern Recognition, 2705-2712.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression.
&lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+intrinsic_location">intrinsic_location</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># an example of multiple regression with two independent variables, with 64
# data points

x &lt;- matrix(runif(2 * 64), ncol = 2)
x &lt;- t(t(x) - colMeans(x))
y &lt;- matrix(0L, nrow = 4, ncol = 64)
for (i in 1:64) {
  y[, i] &lt;- exp_map('sphere', c(1, 0, 0, 0), c(0, runif(1), runif(1),
      runif(1)))
}
geo_reg('sphere', x, y, 'tukey', c = are_nr('tukey', 2, 6))

</code></pre>

<hr>
<h2 id='intrinsic_location'>Gradient descent for location based on M-type estimators</h2><span id='topic+intrinsic_location'></span>

<h3>Description</h3>

<p>Finds <code class="reqn">\mathrm{argmin}_{p\in M}\sum_{i=1} ^ {N} \rho(d(p,y_i))</code> through a
gradient descent algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intrinsic_location(
  manifold,
  y,
  estimator,
  c = NULL,
  p_tol = 1e-05,
  V_tol = 1e-05,
  max_iter = 1e+05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intrinsic_location_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_y">y</code></td>
<td>
<p>A matrix or data frame whose columns represent points on the
manifold.</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_estimator">estimator</code></td>
<td>
<p>M-type estimator (<code>'l2'</code>, <code>'l1'</code>, <code>'huber'</code>,
or <code>'tukey'</code>).</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_c">c</code></td>
<td>
<p>Multiplier of <code class="reqn">\sigma</code>, the square root of the variance, used in
the cutoff parameter for the <code>'huber'</code> and <code>'tukey'</code> estimators;
should be <code>NULL</code> for the <code>'l2'</code> or <code>'l1'</code> estimators.</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_p_tol">p_tol</code></td>
<td>
<p>Termination condition for the distance between consecutive
updates of <code>p</code>.</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_v_tol">V_tol</code></td>
<td>
<p>Termination condition for the distance between columns of
consecutive updates of <code>V</code>, parallel transported to be in the same
tangent space. Can be a vector of positive real numbers for each
independent variable or a single positive number.</p>
</td></tr>
<tr><td><code id="intrinsic_location_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of gradient descent steps before ending the
algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of the <code>'sphere'</code>, an error will be raised if all points are
on a pair of antipodes.
</p>


<h3>Value</h3>

<p>A vector representing the location estimate
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Kim, H. J., Adluru, N., Collins, M. D., Chung, M. K., Bendin, B. B.,
Johnson, S. C., Davidson, R. J. and Singh, V. (2014). Multivariate general
linear models (MGLM) on Riemannian manifolds with applications to
statistical analysis of diffusion weighted images. 2014 IEEE Conference on
Computer Vision and Pattern Recognition, 2705-2712.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression.
&lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+geo_reg">geo_reg</a></code>, <code><a href="RiemBase.html#topic+rbase.mean">rbase.mean</a></code>,
<code><a href="RiemBase.html#topic+rbase.median">rbase.median</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrix(runif(100, 1000, 2000), nrow = 10)
intrinsic_location('euclidean', y, 'l2')

</code></pre>

<hr>
<h2 id='log_map'>Logarithm map</h2><span id='topic+log_map'></span>

<h3>Description</h3>

<p>Performs the logarithm map <code class="reqn">\textrm{Log}_{p_1}(p_2)</code> on the given
manifold, provided <code class="reqn">p_2</code> is in the domain of <code class="reqn">\textrm{Log}_{p_1}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_map(manifold, p1, p2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_map_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="log_map_+3A_p1">p1</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
<tr><td><code id="log_map_+3A_p2">p2</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>On the sphere, <code class="reqn">-p_1</code> is not in the domain of <code class="reqn">\textrm{Log}_{p_1}</code>.
</p>


<h3>Value</h3>

<p>A vector tangent to <code>p1</code>.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Cornea, E., Zhu, H., Kim, P. and Ibrahim, J. G. (2017). Regression models
on Riemannian symmetric spaces. Journal of the Royal Statistical Society:
Series B, 79, 463-482.
</p>
<p>Calinon, S. (2020). Gaussians on Riemannian manifolds: Applications for
robot learning and adaptive control. IEEE Robotics &amp; Automation Magazine,
27, 33-45.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression.
&lt;arXiv:2007.04518&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exp_map">exp_map</a></code>, <code><a href="#topic+geo_dist">geo_dist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>log_map('sphere', c(0, 1, 0, 0), c(0, 0, 1, 0))

</code></pre>

<hr>
<h2 id='loss'>Loss</h2><span id='topic+loss'></span>

<h3>Description</h3>

<p>Loss for a given <code>p</code> and <code>V</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loss(manifold, p, V, x, y, estimator, cutoff = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loss_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="loss_+3A_p">p</code></td>
<td>
<p>A vector (or column matrix) on the manifold.</p>
</td></tr>
<tr><td><code id="loss_+3A_v">V</code></td>
<td>
<p>A matrix (or vector) where each column is a vector in the tangent
space at <code>p</code>.</p>
</td></tr>
<tr><td><code id="loss_+3A_x">x</code></td>
<td>
<p>A matrix or data frame of independent variables; for matrices and
data frames, the rows and columns represent the subjects and independent
variables, respectively.</p>
</td></tr>
<tr><td><code id="loss_+3A_y">y</code></td>
<td>
<p>A matrix or data frame (or vector) whose columns represent points on
the manifold.</p>
</td></tr>
<tr><td><code id="loss_+3A_estimator">estimator</code></td>
<td>
<p>M-type estimator (<code>'l2'</code>, <code>'l1'</code>, <code>'huber'</code>,
or <code>'tukey'</code>).</p>
</td></tr>
<tr><td><code id="loss_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff parameter for the <code>'huber'</code> and <code>'tukey'</code>
estimators; should be <code>NULL</code> for the <code>'l2'</code> or <code>'l1'</code>
estimators.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrix(0L, nrow = 3, ncol = 64)
for (i in 1:64) {
  y[, i] &lt;- exp_map('hyperbolic', c(1, 0, 0), c(0, runif(1), runif(1)))
}
intrinsic_mean &lt;- intrinsic_location('hyperbolic', y, 'l2')
loss('hyperbolic', intrinsic_mean, numeric(3), numeric(64), y, 'l2')

</code></pre>

<hr>
<h2 id='onmanifold'>Manifold check and projection</h2><span id='topic+onmanifold'></span>

<h3>Description</h3>

<p>Checks whether each data point in <code class="reqn">y</code> is on the given manifold, and if
not, provides a modified version of <code class="reqn">y</code> where each column has been
projected onto the manifold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onmanifold(manifold, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="onmanifold_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="onmanifold_+3A_y">y</code></td>
<td>
<p>A vector, matrix, or data frame whose columns should represent
points on the manifold.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing </p>
<table role = "presentation">
<tr><td><code>on</code></td>
<td>
<p>a logical vector describing whether
or not each column of <code>y</code> is on the manifold.</p>
</td></tr> <tr><td><code>data</code></td>
<td>
<p>a matrix of
data frame of the same dimensions as <code>y</code>; each column of <code>y</code> has
been projected onto the manifold.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y1 &lt;- matrix(rnorm(10), ncol = 2)
y1 &lt;- y1[, 1] + (1i) * y1[, 2]
y2 &lt;- matrix(rnorm(10), ncol = 2)
y2 &lt;- y2[, 1] + (1i) * y2[, 2]
y3 &lt;- matrix(rnorm(10), ncol = 2)
y3 &lt;- y3[, 1] + (1i) * y3[, 2]
y3 &lt;- (y3 - mean(y3)) / norm(y3 - mean(y3), type = '2') # project onto preshape space
y &lt;- matrix(c(y1, y2, y3), ncol = 3)
onmanifold('kendall', y)

</code></pre>

<hr>
<h2 id='par_trans'>Parallel transport</h2><span id='topic+par_trans'></span>

<h3>Description</h3>

<p>Performs <code class="reqn">\Gamma_{p_1 \rightarrow p_2}(v)</code>, parallel transport along the
unique minimizing geodesic connecting <code class="reqn">p_1</code> and <code class="reqn">p_2</code>, if it exists,
on the given manifold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par_trans(manifold, p1, p2, v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="par_trans_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'euclidean'</code>, <code>'sphere'</code>,
<code>'hyperbolic'</code>, or <code>'kendall'</code>).</p>
</td></tr>
<tr><td><code id="par_trans_+3A_p1">p1</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
<tr><td><code id="par_trans_+3A_p2">p2</code></td>
<td>
<p>A vector (or column matrix) representing a point on the manifold.</p>
</td></tr>
<tr><td><code id="par_trans_+3A_v">v</code></td>
<td>
<p>A vector (or column matrix) tangent to <code>p1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>On the sphere, there is no unique minimizing geodesic connecting <code class="reqn">p_1</code>
and <code class="reqn">-p_1</code>.
</p>


<h3>Value</h3>

<p>A vector tangent to <code>p2</code>.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Cornea, E., Zhu, H., Kim, P. and Ibrahim, J. G. (2017). Regression models
on Riemannian symmetric spaces. Journal of the Royal Statistical Society:
Series B, 79, 463-482.
</p>
<p>Calinon, S. (2020). Gaussians on Riemannian manifolds: Applications for
robot learning and adaptive control. IEEE Robotics &amp; Automation Magazine,
27, 33-45.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression. &lt;arXiv:2007.04518&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p1 &lt;- matrix(rnorm(10), ncol = 2)
p1 &lt;- p1[, 1] + (1i) * p1[, 2]
p1 &lt;- (p1 - mean(p1)) / norm(p1 - mean(p1), type = '2') # project onto pre-shape space
p2 &lt;- matrix(rnorm(10), ncol = 2)
p2 &lt;- p2[, 1] + (1i) * p2[, 2]
p2 &lt;- (p2 - mean(p2)) / norm(p2 - mean(p2), type = '2') # project onto pre-shape space
p3 &lt;- matrix(rnorm(10), ncol = 2)
p3 &lt;- p3[, 1] + (1i) * p3[, 2]
p3 &lt;- (p3 - mean(p3)) / norm(p3 - mean(p3), type = '2') # project onto pre-shape space
v &lt;- log_map('kendall', p1, p3)
par_trans('kendall', p1, p2, v)

</code></pre>

<hr>
<h2 id='rnormtangents'>Random generation of tangent vectors from the Riemannian normal distribution</h2><span id='topic+rnormtangents'></span>

<h3>Description</h3>

<p>Random generation of tangent vectors from the Riemannian normal distribution
on the <code>n</code>-dimensional sphere or hyperbolic space at mean <code>(1, 0,
..., 0)</code>, a vector of length <code>n+1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnormtangents(manifold, N, n, sigma_sq)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rnormtangents_+3A_manifold">manifold</code></td>
<td>
<p>Type of manifold (<code>'sphere'</code> or <code>'hyperbolic'</code>).</p>
</td></tr>
<tr><td><code id="rnormtangents_+3A_n">N</code></td>
<td>
<p>Number of points to generate.</p>
</td></tr>
<tr><td><code id="rnormtangents_+3A_n">n</code></td>
<td>
<p>Dimension of the manifold.</p>
</td></tr>
<tr><td><code id="rnormtangents_+3A_sigma_sq">sigma_sq</code></td>
<td>
<p>A scale parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tangent vectors are of the form <code class="reqn">\mathrm{Log}(\mu, y)</code> in the tangent
space at the Fr\'echet mean <code class="reqn">\mu</code> = <code>(1, 0, ..., 0)</code>, which is
isomorphic to <code>n</code>-dimensional Euclidean space, where <code class="reqn">y</code> has a
Riemannian normal distribution. The first element of these vectors
will always be 0 at this <code class="reqn">\mu</code>. These vectors can be
transported to any other <code class="reqn">\mu</code> on the manifold.
</p>


<h3>Value</h3>

<p>An <code>(n+1)</code>-by-<code>N</code> matrix where each column represents a random
tangent vector at <code>(1, 0, ..., 0)</code>.
</p>


<h3>Author(s)</h3>

<p>Ha-Young Shin
</p>


<h3>References</h3>

<p>Fletcher, P. T. (2013). Geodesic regression and the theory of
least squares on Riemannian manifolds. International Journal of Computer
Vision, 105, 171-185.
</p>
<p>Fletcher, T. (2020). Statistics on manifolds. In <em>Riemannian Geometric
Statistics in Medical Image Analysis</em>. 39&ndash;74. Academic Press.
</p>
<p>Shin, H.-Y. and Oh H.-S. (2020). Robust Geodesic Regression.
&lt;arXiv:2007.04518&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sims &lt;- rnormtangents('hyperbolic', N = 4, n = 2, sigma_sq = 1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
