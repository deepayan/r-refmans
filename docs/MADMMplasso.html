<!DOCTYPE html><html lang="en-GB"><head><title>Help for package MADMMplasso</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MADMMplasso}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MADMMplasso'><p>MADMMplasso: Multi Variate Multi Response ADMM with Interaction Effects</p></a></li>
<li><a href='#admm_MADMMplasso'><p>Fit the ADMM part of  model for the given lambda values</p></a></li>
<li><a href='#admm_MADMMplasso_cpp'><p>Fit the ADMM part of  model for a given lambda vale</p></a></li>
<li><a href='#compute_pliable'><p>Compute the interaction part of the model.</p></a></li>
<li><a href='#cv_MADMMplasso'><p>Carries out cross-validation for a MADMMplasso model over a path of regularization values</p></a></li>
<li><a href='#generate_my_w'><p>Generate the matrix W as seen in equation 8  for use in the function.</p></a></li>
<li><a href='#predict.MADMMplasso'><p>Compute predicted values from a fitted MADMMplasso  object.</p>
Make predictions from a fitted MADMMplasso model</a></li>
<li><a href='#sim2'><p>Simulate data for the model. This is the second simulation data used in the paper</p></a></li>
<li><a href='#tree_parms'><p>Fit the hierarchical tree structure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Multi Variate Multi Response ADMM with Interaction Effects</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>This system allows one to model a multi-variate, multi-response
    problem with interaction effects. It combines the usual squared error loss
    for the multi-response problem with some penalty terms to encourage
    responses that correlate to form groups and also allow for modeling main and
    interaction effects that exit within the covariates.
    The optimization method employed is the Alternating Direction Method of
    Multipliers (ADMM). The implementation is based on the methodology
    presented on Quachie Asenso, T., &amp; Zucknick, M. (2023)
    &lt;<a href="https://doi.org/10.48550%2FarXiv.2303.11155">doi:10.48550/arXiv.2303.11155</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, MASS, Rcpp, RcppArmadillo, foreach, doParallel, class,
graphics, parallel, stats, spatstat.sparse, methods</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), lintr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-08</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-08 11:56:39 UTC; waldir</td>
</tr>
<tr>
<td>Author:</td>
<td>Theophilus Quachie Asenso [aut],
  Manuela Zucknick [aut],
  Waldir Leoncio <a href="https://orcid.org/0000-0002-6719-6162"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Chi Zhang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Waldir Leoncio &lt;w.l.netto@medisin.uio.no&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-08 16:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='MADMMplasso'>MADMMplasso: Multi Variate Multi Response ADMM with Interaction Effects</h2><span id='topic+MADMMplasso-package'></span><span id='topic+MADMMplasso'></span>

<h3>Description</h3>

<p>This system allows one to model a multi-variate, multi-response problem with interaction effects. It combines the usual squared error loss for the multi-response problem with some penalty terms to encourage responses that correlate to form groups and also allow for modeling main and interaction effects that exit within the covariates. The optimization method employed is the Alternating Direction Method of Multipliers (ADMM). The implementation is based on the methodology presented on Quachie Asenso, T., &amp; Zucknick, M. (2023) <a href="https://doi.org/10.48550/arXiv.2303.11155">doi:10.48550/arXiv.2303.11155</a>.
</p>
<p>This function fits a multi-response pliable lasso model over a path of regularization values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MADMMplasso(
  X,
  Z,
  y,
  alpha,
  my_lambda = NULL,
  lambda_min = 0.001,
  max_it = 50000,
  e.abs = 0.001,
  e.rel = 0.001,
  maxgrid,
  nlambda,
  rho = 5,
  my_print = FALSE,
  alph = 1.8,
  tree,
  pal = cl == 1L,
  gg = NULL,
  tol = 1e-04,
  cl = 1L,
  legacy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MADMMplasso_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_z">Z</code></td>
<td>
<p>N by K matrix of modifying variables. The elements of Z  may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_y">y</code></td>
<td>
<p>N by D matrix  of responses. The X and Z variables are centered in the function. We recommend that X and Z also be standardized before the call</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_alpha">alpha</code></td>
<td>
<p>mixing parameter. When the goal is to include more interactions, alpha should be very small and vice versa.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_my_lambda">my_lambda</code></td>
<td>
<p>user specified lambda_3 values</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_lambda_min">lambda_min</code></td>
<td>
<p>the smallest value for lambda_3 , as a fraction of max(lambda_3), the (data derived (lammax)) entry value (i.e. the smallest value for which all coefficients are zero)</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_max_it">max_it</code></td>
<td>
<p>maximum number of iterations in loop for one lambda during the ADMM optimization</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_e.abs">e.abs</code></td>
<td>
<p>absolute error for the ADMM</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_e.rel">e.rel</code></td>
<td>
<p>relative error for the ADMM</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_maxgrid">maxgrid</code></td>
<td>
<p>number of lambda_3 values desired</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_nlambda">nlambda</code></td>
<td>
<p>number of lambda_3 values desired. Similar to maxgrid but can have a value less than or equal to maxgrid.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_rho">rho</code></td>
<td>
<p>the Lagrange variable for the ADMM. This value is updated during the ADMM call based on a certain condition.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_my_print">my_print</code></td>
<td>
<p>Should information form each ADMM iteration be printed along the way? This prints the dual and primal residuals</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_alph">alph</code></td>
<td>
<p>an overrelaxation parameter in [1, 1.8]. The implementation is borrowed from Stephen Boyd's <a href="https://stanford.edu/~boyd/papers/admm/lasso/lasso.html">MATLAB code</a></p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_tree">tree</code></td>
<td>
<p>The results from the hierarchical clustering of the response matrix. The easy way to obtain this is by using the function (tree_parms) which gives a default clustering. However, user decide on a specific structure and then input a tree that follows such structure.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_pal">pal</code></td>
<td>
<p>Should the lapply function be applied for an alternative to parallelization.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_gg">gg</code></td>
<td>
<p>penalty term for the tree structure. This is a 2×2 matrix values in the first row representing the maximum to the minimum values for lambda_1 and the second row representing the maximum to the minimum values for lambda_2. In the current setting, we set both maximum and the minimum to be same because cross validation is not carried across the lambda_1 and lambda_2. However, setting different values will work during the model fit.</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_tol">tol</code></td>
<td>
<p>threshold for the non-zero coefficients</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_cl">cl</code></td>
<td>
<p>The number of CPUs to be used for parallel processing</p>
</td></tr>
<tr><td><code id="MADMMplasso_+3A_legacy">legacy</code></td>
<td>
<p>If <code>TRUE</code>, use the R version of the algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted values for the MADMMplasso object with the following components:
path: a table containing the summary of the model for each lambda_3.
</p>
<p>beta0: a list (length=nlambda) of estimated beta_0 coefficients each having a size of 1 by ncol(y)
</p>
<p>beta: a list (length=nlambda) of estimated beta coefficients each having a matrix   ncol(X) by ncol(y)
</p>
<p>BETA_hat: a list (length=nlambda) of estimated beta and theta coefficients each having a matrix   (ncol(X)+ncol(X) by ncol(Z)) by ncol(y)
</p>
<p>theta0: a list (length=nlambda) of estimated theta_0 coefficients each having a matrix   ncol(Z) by ncol(y)
</p>
<p>theta: a list (length=nlambda) of estimated theta coefficients each having a an array   ncol(X) by ncol(Z) by ncol(y)
</p>
<p>Lambdas: values of lambda_3 used
</p>
<p>non_zero: number of nonzero betas for each model in path
</p>
<p>LOSS: sum of squared of the error for each model in path
</p>
<p>Y_HAT: a list (length=nlambda) of predicted response nrow(X) by ncol(y)
</p>
<p>gg: penalty term for the tree structure (lambda_1 and lambda_2) for each lambda_3 nlambda by 2
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Waldir Leoncio <a href="mailto:w.l.netto@medisin.uio.no">w.l.netto@medisin.uio.no</a> (<a href="https://orcid.org/0000-0002-6719-6162">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Theophilus Quachie Asenso <a href="mailto:t.q.asenso@medisin.uio.no">t.q.asenso@medisin.uio.no</a>
</p>
</li>
<li><p> Manuela Zucknick <a href="mailto:Manuela.zucknick@medisin.uio.no">Manuela.zucknick@medisin.uio.no</a>
</p>
</li>
<li><p> Chi Zhang <a href="mailto:andreachizhang@yahoo.com">andreachizhang@yahoo.com</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Train the model
# generate some data
set.seed(1235)
N &lt;- 100
p &lt;- 50
nz &lt;- 4
K &lt;- nz
X &lt;- matrix(rnorm(n = N * p), nrow = N, ncol = p)
mx &lt;- colMeans(X)
sx &lt;- sqrt(apply(X, 2, var))
X &lt;- scale(X, mx, sx)
X &lt;- matrix(as.numeric(X), N, p)
Z &lt;- matrix(rnorm(N * nz), N, nz)
mz &lt;- colMeans(Z)
sz &lt;- sqrt(apply(Z, 2, var))
Z &lt;- scale(Z, mz, sz)
beta_1 &lt;- rep(x = 0, times = p)
beta_2 &lt;- rep(x = 0, times = p)
beta_3 &lt;- rep(x = 0, times = p)
beta_4 &lt;- rep(x = 0, times = p)
beta_5 &lt;- rep(x = 0, times = p)
beta_6 &lt;- rep(x = 0, times = p)

beta_1[1:5] &lt;- c(2, 2, 2, 2, 2)
beta_2[1:5] &lt;- c(2, 2, 2, 2, 2)
beta_3[6:10] &lt;- c(2, 2, 2, -2, -2)
beta_4[6:10] &lt;- c(2, 2, 2, -2, -2)
beta_5[11:15] &lt;- c(-2, -2, -2, -2, -2)
beta_6[11:15] &lt;- c(-2, -2, -2, -2, -2)

Beta &lt;- cbind(beta_1, beta_2, beta_3, beta_4, beta_5, beta_6)
colnames(Beta) &lt;- 1:6

theta &lt;- array(0, c(p, K, 6))
theta[1, 1, 1] &lt;- 2
theta[3, 2, 1] &lt;- 2
theta[4, 3, 1] &lt;- -2
theta[5, 4, 1] &lt;- -2
theta[1, 1, 2] &lt;- 2
theta[3, 2, 2] &lt;- 2
theta[4, 3, 2] &lt;- -2
theta[5, 4, 2] &lt;- -2
theta[6, 1, 3] &lt;- 2
theta[8, 2, 3] &lt;- 2
theta[9, 3, 3] &lt;- -2
theta[10, 4, 3] &lt;- -2
theta[6, 1, 4] &lt;- 2
theta[8, 2, 4] &lt;- 2
theta[9, 3, 4] &lt;- -2
theta[10, 4, 4] &lt;- -2
theta[11, 1, 5] &lt;- 2
theta[13, 2, 5] &lt;- 2
theta[14, 3, 5] &lt;- -2
theta[15, 4, 5] &lt;- -2
theta[11, 1, 6] &lt;- 2
theta[13, 2, 6] &lt;- 2
theta[14, 3, 6] &lt;- -2
theta[15, 4, 6] &lt;- -2

pliable &lt;- matrix(0, N, 6)
for (e in 1:6) {
  pliable[, e] &lt;- compute_pliable(X, Z, theta[, , e])
}

esd &lt;- diag(6)
e &lt;- MASS::mvrnorm(N, mu = rep(0, 6), Sigma = esd)
y_train &lt;- X %*% Beta + pliable + e
y &lt;- y_train

colnames(y) &lt;- c(paste0("y", seq_len(ncol(y))))
TT &lt;- tree_parms(y)
plot(TT$h_clust)
gg1 &lt;- matrix(0, 2, 2)
gg1[1, ] &lt;- c(0.02, 0.02)
gg1[2, ] &lt;- c(0.02, 0.02)

nlambda &lt;- 1
e.abs &lt;- 1E-4
e.rel &lt;- 1E-2
alpha &lt;- 0.2
tol &lt;- 1E-3
fit &lt;- MADMMplasso(
  X, Z, y,
  alpha = alpha, my_lambda = matrix(rep(0.2, ncol(y)), 1),
  lambda_min = 0.001, max_it = 1000, e.abs = e.abs, e.rel = e.rel,
  maxgrid = nlambda, nlambda = nlambda, rho = 5, tree = TT, my_print = FALSE,
  alph = TRUE, gg = gg1, tol = tol, cl = 2L
)
</code></pre>

<hr>
<h2 id='admm_MADMMplasso'>Fit the ADMM part of  model for the given lambda values</h2><span id='topic+admm_MADMMplasso'></span>

<h3>Description</h3>

<p>This function fits a multi-response pliable lasso model over a path of regularization values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>admm_MADMMplasso(
  beta0,
  theta0,
  beta,
  beta_hat,
  theta,
  rho1,
  X,
  Z,
  max_it,
  W_hat,
  XtY,
  y,
  N,
  e.abs,
  e.rel,
  alpha,
  lambda,
  alph,
  svd.w,
  tree,
  my_print,
  invmat,
  gg = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="admm_MADMMplasso_+3A_beta0">beta0</code></td>
<td>
<p>a vector of length ncol(y) of estimated beta_0 coefficients</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_theta0">theta0</code></td>
<td>
<p>matrix of the initial theta_0 coefficients  ncol(Z) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_beta">beta</code></td>
<td>
<p>a matrix of the initial beta coefficients    ncol(X) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_beta_hat">beta_hat</code></td>
<td>
<p>a matrix of the initial beta and theta coefficients    (ncol(X)+ncol(X) by ncol(Z)) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_theta">theta</code></td>
<td>
<p>an array of initial theta coefficients    ncol(X) by ncol(Z) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_rho1">rho1</code></td>
<td>
<p>the Lagrange variable for the ADMM which is usually included as rho in the MADMMplasso call.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_z">Z</code></td>
<td>
<p>N by K matrix of modifying variables. The elements of Z  may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_max_it">max_it</code></td>
<td>
<p>maximum number of iterations in loop for one lambda during the ADMM optimization</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_w_hat">W_hat</code></td>
<td>
<p>N by (p+(p by nz)) of the main and interaction predictors. This generated internally  when MADMMplasso is called or by using the function generate_my_w.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_xty">XtY</code></td>
<td>
<p>a matrix formed by multiplying the transpose of X by y.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_y">y</code></td>
<td>
<p>N by D matrix  of responses. The X and Z variables are centered in the function. We recommend that X and Z also be standardized before the call</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_n">N</code></td>
<td>
<p>nrow(X)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_e.abs">e.abs</code></td>
<td>
<p>absolute error for the ADMM</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_e.rel">e.rel</code></td>
<td>
<p>relative error for the ADMM</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_alpha">alpha</code></td>
<td>
<p>mixing parameter. When the goal is to include more interactions, alpha should be very small and vice versa.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_lambda">lambda</code></td>
<td>
<p>user specified lambda_3 values.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_alph">alph</code></td>
<td>
<p>an overrelaxation parameter in [1, 1.8]. The implementation is borrowed from Stephen Boyd's <a href="https://stanford.edu/~boyd/papers/admm/lasso/lasso.html">MATLAB code</a></p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_svd.w">svd.w</code></td>
<td>
<p>singular value decomposition of W</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_tree">tree</code></td>
<td>
<p>The results from the hierarchical clustering of the response matrix. The easy way to obtain this is by using the function (tree_parms) which gives a default clustering. However, user decide on a specific structure and then input a tree that follows such structure.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_my_print">my_print</code></td>
<td>
<p>Should information form each ADMM iteration be printed along the way? This prints the dual and primal residuals</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_invmat">invmat</code></td>
<td>
<p>A list of length ncol(y), each containing the C_d part of equation 32 in the paper</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_+3A_gg">gg</code></td>
<td>
<p>penalty terms for the tree structure for lambda_1 and  lambda_2 for the ADMM call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted values for the ADMM part
beta0:  estimated beta_0 coefficients  having a size of 1 by ncol(y)
</p>
<p>beta: estimated beta coefficients  having a matrix   ncol(X) by ncol(y)
</p>
<p>BETA_hat:  estimated beta and theta coefficients  having a matrix   (ncol(X)+ncol(X) by ncol(Z)) by ncol(y)
</p>
<p>theta0:  estimated theta_0 coefficients  having a matrix   ncol(Z) by ncol(y)
</p>
<p>theta:  estimated theta coefficients  having a an array   ncol(X) by ncol(Z) by ncol(y)
converge: did the algorithm converge?
</p>
<p>Y_HAT:  predicted response nrow(X) by ncol(y)
</p>

<hr>
<h2 id='admm_MADMMplasso_cpp'>Fit the ADMM part of  model for a given lambda vale</h2><span id='topic+admm_MADMMplasso_cpp'></span>

<h3>Description</h3>

<p>This function fits a multi-response pliable lasso model over a path of regularization values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>admm_MADMMplasso_cpp(
  beta0,
  theta0,
  beta,
  beta_hat,
  theta,
  rho1,
  X,
  Z,
  max_it,
  W_hat,
  XtY,
  y,
  N,
  e_abs,
  e_rel,
  alpha,
  lambda,
  alph,
  svd_w_tu,
  svd_w_tv,
  svd_w_d,
  C,
  CW,
  gg,
  my_print = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="admm_MADMMplasso_cpp_+3A_beta0">beta0</code></td>
<td>
<p>a vector of length ncol(y) of estimated beta_0 coefficients</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_theta0">theta0</code></td>
<td>
<p>matrix of the initial theta_0 coefficients  ncol(Z) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_beta">beta</code></td>
<td>
<p>a matrix of the initial beta coefficients    ncol(X) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_beta_hat">beta_hat</code></td>
<td>
<p>a matrix of the initial beta and theta coefficients    (ncol(X)+ncol(X) by ncol(Z)) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_theta">theta</code></td>
<td>
<p>an array of initial theta coefficients    ncol(X) by ncol(Z) by ncol(y)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_rho1">rho1</code></td>
<td>
<p>the Lagrange variable for the ADMM which is usually included as rho in the MADMMplasso call.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_x">X</code></td>
<td>
<p>n by p matrix of predictors</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_z">Z</code></td>
<td>
<p>n by nz matrix of modifying variables. The elements of z
may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level
variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_max_it">max_it</code></td>
<td>
<p>maximum number of iterations in loop for one lambda during the ADMM optimization. This is usually included  in the MADMMplasso call</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_w_hat">W_hat</code></td>
<td>
<p>N by (p+(p by nz)) of the main and interaction predictors. This generated internally  when MADMMplasso is called or by using the function generate_my_w.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_xty">XtY</code></td>
<td>
<p>a matrix formed by multiplying the transpose of X by y.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_y">y</code></td>
<td>
<p>N by D matrix  of responses. The X and Z variables are centered in the function. We recommend that X and Z also be standardized before the call</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_n">N</code></td>
<td>
<p>nrow(X)</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_e_abs">e_abs</code></td>
<td>
<p>absolute error for the ADMM. This is included int the call of MADMMplasso.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_e_rel">e_rel</code></td>
<td>
<p>relative error for the ADMM. This is included int the call of MADMMplasso.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_alpha">alpha</code></td>
<td>
<p>mixing parameter, usually obtained from the MADMMplasso call. When the goal is to include more interactions, alpha should be very small and vice versa.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_lambda">lambda</code></td>
<td>
<p>a vector  lambda_3 values for the ADMM call with length ncol(y). This is usually calculated in the MADMMplasso call.   In our current setting, we use the same the lambda_3 value for all responses.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_alph">alph</code></td>
<td>
<p>an overrelaxation parameter in [1, 1.8], usually obtained from the MADMMplasso call.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_svd_w_tu">svd_w_tu</code></td>
<td>
<p>the transpose of the U matrix from the SVD of W_hat</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_svd_w_tv">svd_w_tv</code></td>
<td>
<p>the transpose of the V matrix from the SVD of W_hat</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_svd_w_d">svd_w_d</code></td>
<td>
<p>the D matrix from the SVD of W_hat</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_c">C</code></td>
<td>
<p>the trained tree</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_cw">CW</code></td>
<td>
<p>weights for the trained tree
The easy way to obtain this is by using the function (tree_parms) which gives a default clustering.
However, user decide on a specific structure and then input a tree that follows such structure.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_gg">gg</code></td>
<td>
<p>penalty terms for the tree structure for lambda_1 and  lambda_2 for the ADMM call.</p>
</td></tr>
<tr><td><code id="admm_MADMMplasso_cpp_+3A_my_print">my_print</code></td>
<td>
<p>Should information form each ADMM iteration be printed along the way? Default TRUE. This prints  the dual and primal residuals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted values for the ADMM part
</p>

<hr>
<h2 id='compute_pliable'>Compute the interaction part of the model.</h2><span id='topic+compute_pliable'></span>

<h3>Description</h3>

<p>Compute the interaction part of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_pliable(X, Z, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_pliable_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="compute_pliable_+3A_z">Z</code></td>
<td>
<p>N by K matrix of modifying variables. The elements of Z  may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
<tr><td><code id="compute_pliable_+3A_theta">theta</code></td>
<td>
<p>theta coefficients for a single response ncol(X) by ncol(Z)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of length N of the calculated interaction term for a single response
</p>

<hr>
<h2 id='cv_MADMMplasso'>Carries out cross-validation for a MADMMplasso model over a path of regularization values</h2><span id='topic+cv_MADMMplasso'></span>

<h3>Description</h3>

<p>Carries out cross-validation for a MADMMplasso model over a path of regularization values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_MADMMplasso(
  fit,
  nfolds,
  X,
  Z,
  y,
  alpha = 0.5,
  lambda = fit$Lambdas,
  max_it = 50000,
  e.abs = 0.001,
  e.rel = 0.001,
  nlambda,
  rho = 5,
  my_print = FALSE,
  alph = 1,
  foldid = NULL,
  pal = cl == 1L,
  gg = c(7, 0.5),
  TT,
  tol = 1e-04,
  cl = 1L,
  legacy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv_MADMMplasso_+3A_fit">fit</code></td>
<td>
<p>object returned by the MADMMplasso function</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_nfolds">nfolds</code></td>
<td>
<p>number of cross-validation folds</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_z">Z</code></td>
<td>
<p>N by K matrix of modifying variables. The elements of Z  may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_y">y</code></td>
<td>
<p>N by D matrix  of responses. The X and Z variables are centered in the function. We recommend that X and Z also be standardized before the call</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_alpha">alpha</code></td>
<td>
<p>mixing parameter. When the goal is to include more interactions, alpha should be very small and vice versa.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_lambda">lambda</code></td>
<td>
<p>user specified lambda_3 values.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_max_it">max_it</code></td>
<td>
<p>maximum number of iterations in loop for one lambda during the ADMM optimization</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_e.abs">e.abs</code></td>
<td>
<p>absolute error for the ADMM</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_e.rel">e.rel</code></td>
<td>
<p>relative error for the ADMM</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_nlambda">nlambda</code></td>
<td>
<p>number of lambda_3 values desired. Similar to maxgrid but can have a value less than or equal to maxgrid.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_rho">rho</code></td>
<td>
<p>the Lagrange variable for the ADMM. This value is updated during the ADMM call based on a certain condition.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_my_print">my_print</code></td>
<td>
<p>Should information form each ADMM iteration be printed along the way? This prints the dual and primal residuals</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_alph">alph</code></td>
<td>
<p>an overrelaxation parameter in [1, 1.8]. The implementation is borrowed from Stephen Boyd's <a href="https://stanford.edu/~boyd/papers/admm/lasso/lasso.html">MATLAB code</a></p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_foldid">foldid</code></td>
<td>
<p>vector with values in 1:K, indicating folds for K-fold CV. Default NULL</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_pal">pal</code></td>
<td>
<p>Should the lapply function be applied for an alternative to parallelization.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_gg">gg</code></td>
<td>
<p>penalty term for the tree structure. This is a 2×2 matrix values in the first row representing the maximum to the minimum values for lambda_1 and the second row representing the maximum to the minimum values for lambda_2. In the current setting, we set both maximum and the minimum to be same because cross validation is not carried across the lambda_1 and lambda_2. However, setting different values will work during the model fit.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_tt">TT</code></td>
<td>
<p>The results from the hierarchical clustering of the response matrix.
This should same as the parameter tree used during the MADMMplasso call.</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_tol">tol</code></td>
<td>
<p>threshold for the non-zero coefficients</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_cl">cl</code></td>
<td>
<p>The number of CPUs to be used for parallel processing</p>
</td></tr>
<tr><td><code id="cv_MADMMplasso_+3A_legacy">legacy</code></td>
<td>
<p>If <code>TRUE</code>, use the R version of the algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>results containing the CV values
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train the model
# generate some data
set.seed(1235)
N &lt;- 100
p &lt;- 50
nz &lt;- 4
K &lt;- nz
X &lt;- matrix(rnorm(n = N * p), nrow = N, ncol = p)
mx &lt;- colMeans(X)
sx &lt;- sqrt(apply(X, 2, var))
X &lt;- scale(X, mx, sx)
X &lt;- matrix(as.numeric(X), N, p)
Z &lt;- matrix(rnorm(N * nz), N, nz)
mz &lt;- colMeans(Z)
sz &lt;- sqrt(apply(Z, 2, var))
Z &lt;- scale(Z, mz, sz)
beta_1 &lt;- rep(x = 0, times = p)
beta_2 &lt;- rep(x = 0, times = p)
beta_3 &lt;- rep(x = 0, times = p)
beta_4 &lt;- rep(x = 0, times = p)
beta_5 &lt;- rep(x = 0, times = p)
beta_6 &lt;- rep(x = 0, times = p)

beta_1[1:5] &lt;- c(2, 2, 2, 2, 2)
beta_2[1:5] &lt;- c(2, 2, 2, 2, 2)
beta_3[6:10] &lt;- c(2, 2, 2, -2, -2)
beta_4[6:10] &lt;- c(2, 2, 2, -2, -2)
beta_5[11:15] &lt;- c(-2, -2, -2, -2, -2)
beta_6[11:15] &lt;- c(-2, -2, -2, -2, -2)

Beta &lt;- cbind(beta_1, beta_2, beta_3, beta_4, beta_5, beta_6)
colnames(Beta) &lt;- c(1:6)

theta &lt;- array(0, c(p, K, 6))
theta[1, 1, 1] &lt;- 2
theta[3, 2, 1] &lt;- 2
theta[4, 3, 1] &lt;- -2
theta[5, 4, 1] &lt;- -2
theta[1, 1, 2] &lt;- 2
theta[3, 2, 2] &lt;- 2
theta[4, 3, 2] &lt;- -2
theta[5, 4, 2] &lt;- -2
theta[6, 1, 3] &lt;- 2
theta[8, 2, 3] &lt;- 2
theta[9, 3, 3] &lt;- -2
theta[10, 4, 3] &lt;- -2
theta[6, 1, 4] &lt;- 2
theta[8, 2, 4] &lt;- 2
theta[9, 3, 4] &lt;- -2
theta[10, 4, 4] &lt;- -2
theta[11, 1, 5] &lt;- 2
theta[13, 2, 5] &lt;- 2
theta[14, 3, 5] &lt;- -2
theta[15, 4, 5] &lt;- -2
theta[11, 1, 6] &lt;- 2
theta[13, 2, 6] &lt;- 2
theta[14, 3, 6] &lt;- -2
theta[15, 4, 6] &lt;- -2

pliable &lt;- matrix(0, N, 6)
for (e in 1:6) {
  pliable[, e] &lt;- compute_pliable(X, Z, theta[, , e])
}

esd &lt;- diag(6)
e &lt;- MASS::mvrnorm(N, mu = rep(0, 6), Sigma = esd)
y_train &lt;- X %*% Beta + pliable + e
y &lt;- y_train

colnames(y) &lt;- c(paste("y", 1:(ncol(y)), sep = ""))
TT &lt;- tree_parms(y)
plot(TT$h_clust)
gg1 &lt;- matrix(0, 2, 2)
gg1[1, ] &lt;- c(0.02, 0.02)
gg1[2, ] &lt;- c(0.02, 0.02)
nlambda &lt;- 3
e.abs &lt;- 1E-3
e.rel &lt;- 1E-1
alpha &lt;- .2
tol &lt;- 1E-2
fit &lt;- MADMMplasso(
  X, Z, y, alpha = alpha, my_lambda = NULL, lambda_min = 0.001, max_it = 100,
  e.abs = e.abs, e.rel = e.rel, maxgrid = nlambda, nlambda = nlambda, rho = 5,
  tree = TT, my_print = FALSE, alph = 1, gg = gg1, tol = tol, cl = 2L
)
cv_admp &lt;- cv_MADMMplasso(
  fit, nfolds = 5, X, Z, y, alpha = alpha, lambda = fit$Lambdas, max_it = 100,
  e.abs = e.abs, e.rel = e.rel, nlambda, rho = 5, my_print = FALSE, alph = 1,
  foldid = NULL, gg = fit$gg, TT = TT, tol = tol
)
plot(cv_admp)
</code></pre>

<hr>
<h2 id='generate_my_w'>Generate the matrix W as seen in equation 8  for use in the function.</h2><span id='topic+generate_my_w'></span>

<h3>Description</h3>

<p>Generate the matrix W as seen in equation 8  for use in the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_my_w(X = matrix(), Z = matrix())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_my_w_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="generate_my_w_+3A_z">Z</code></td>
<td>
<p>N by nz matrix of modifying variables. The elements of z
may represent quantitative or categorical variables, or a mixture of the two.
Categorical variables should be coded by 0-1 dummy variables: for a k-level
variable, one can use either k or k-1  dummy variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generated W matrix nrow(X) by (ncol(X)+ncol(X) by ncol(Z))
</p>

<hr>
<h2 id='predict.MADMMplasso'>Compute predicted values from a fitted MADMMplasso  object.
Make predictions from a fitted MADMMplasso model</h2><span id='topic+predict.MADMMplasso'></span>

<h3>Description</h3>

<p>Compute predicted values from a MADMMplasso  object.
Make predictions from a fitted MADMMplasso model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MADMMplasso'
predict(object, X, Z, y, lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.MADMMplasso_+3A_object">object</code></td>
<td>
<p>object returned from a call to MADMMplasso</p>
</td></tr>
<tr><td><code id="predict.MADMMplasso_+3A_x">X</code></td>
<td>
<p>N by p matrix of predictors</p>
</td></tr>
<tr><td><code id="predict.MADMMplasso_+3A_z">Z</code></td>
<td>
<p>N by nz matrix of modifying variables. These may be observed or
the predictions from a supervised learning algorithm that predicts z from
test features x  and possibly other features.</p>
</td></tr>
<tr><td><code id="predict.MADMMplasso_+3A_y">y</code></td>
<td>
<p>N by D matrix  of responses.</p>
</td></tr>
<tr><td><code id="predict.MADMMplasso_+3A_lambda">lambda</code></td>
<td>
<p>values of lambda at which predictions are desired. If NULL (default), the path of lambda values from the fitted model. are used. If lambda is not NULL, the predictions are made at the closest values to lambda in the lambda path from the fitted model</p>
</td></tr>
<tr><td><code id="predict.MADMMplasso_+3A_...">...</code></td>
<td>
<p>additional arguments to the generic <code>predict()</code> method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted values
</p>

<hr>
<h2 id='sim2'>Simulate data for the model. This is the second simulation data used in the paper</h2><span id='topic+sim2'></span>

<h3>Description</h3>

<p>Simulate data for the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim2(p = 500, n = 100, m = 24, nz = 4, rho = 0.4, B.elem = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim2_+3A_p">p</code></td>
<td>
<p>column for X which is the main effect</p>
</td></tr>
<tr><td><code id="sim2_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="sim2_+3A_m">m</code></td>
<td>
<p>number of responses</p>
</td></tr>
<tr><td><code id="sim2_+3A_nz">nz</code></td>
<td>
<p>number of modifiers</p>
</td></tr>
<tr><td><code id="sim2_+3A_rho">rho</code></td>
<td>
<p>values to be used in the covariance matrix when generating  X</p>
</td></tr>
<tr><td><code id="sim2_+3A_b.elem">B.elem</code></td>
<td>
<p>the value of the non-zero elements in beta?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The simulated data with the following components:
Beta: matrix of actual beta coefficients  p by m
Theta: a m by p by K array of actual theta coefficients
Y: a N by m matrix of response variables
X: a N by p matrix of covariates
Z: a N by K matrix of modifiers
</p>

<hr>
<h2 id='tree_parms'>Fit the hierarchical tree structure</h2><span id='topic+tree_parms'></span>

<h3>Description</h3>

<p>Fit the hierarchical tree structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tree_parms(y = y, h = 0.7)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tree_parms_+3A_y">y</code></td>
<td>
<p>N by D matrix of response variables</p>
</td></tr>
<tr><td><code id="tree_parms_+3A_h">h</code></td>
<td>
<p>is the tree cut off</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A trained  tree with the following components:
Tree: the tree matrix stored in 1s and 0s
Tw: tree weights associated with the tree matrix. Each weight corresponds to a row in the tree matrix.
h_clust: Summary of the hclust call
y.colnames: names of the response
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
