<!DOCTYPE html><html><head><title>Help for package recosystem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {recosystem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data_source'><p>Specifying Data Source</p></a></li>
<li><a href='#output'><p>Exporting Factorization Matrices</p></a></li>
<li><a href='#output_format'><p>Specifying Output Format</p></a></li>
<li><a href='#predict'><p>Recommender Model Predictions</p></a></li>
<li><a href='#Reco'><p>Constructing a Recommender System Object</p></a></li>
<li><a href='#train'><p>Training a Recommender Model</p></a></li>
<li><a href='#tune'><p>Tuning Model Parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Recommender System using Matrix Factorization</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Yixuan Qiu, David Cortes, Chih-Jen Lin, Yu-Chin Juan, Wei-Sheng Chin,
    Yong Zhuang, Bo-Wen Yuan, Meng-Yuan Yang, and other
    contributors. See file AUTHORS for details.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yixuan Qiu &lt;yixuan.qiu@cos.name&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>R wrapper of the 'libmf' library
    <a href="https://www.csie.ntu.edu.tw/~cjlin/libmf/">https://www.csie.ntu.edu.tw/~cjlin/libmf/</a> for recommender
    system using matrix factorization. It is typically used to
    approximate an incomplete matrix using the product of two
    matrices in a latent space. Other common names for this task
    include "collaborative filtering", "matrix completion",
    "matrix recovery", etc. High performance multi-core parallel
    computing is supported in this package.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Copyright:</td>
<td>see file COPYRIGHTS</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/yixuan/recosystem">https://github.com/yixuan/recosystem</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/yixuan/recosystem/issues">https://github.com/yixuan/recosystem/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.0), float</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, prettydoc, Matrix</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppProgress</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-05 08:56:55 UTC; qyx</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-05 10:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data_source'>Specifying Data Source</h2><span id='topic+data_source'></span><span id='topic+data_file'></span><span id='topic+data_memory'></span><span id='topic+data_matrix'></span>

<h3>Description</h3>

<p>Functions in this page are used to specify the source of data in the recommender system.
They are intended to provide the input argument of functions such as
<code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+train">train</a>()</code>, and <code>$<a href="#topic+predict">predict</a>()</code>.
Currently three data formats are supported: data file (via function <code>data_file()</code>),
data in memory as R objects (via function <code>data_memory()</code>), and data stored as a
sparse matrix (via function <code>data_matrix()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_file(path, index1 = FALSE, ...)

data_memory(user_index, item_index, rating = NULL, index1 = FALSE, ...)

data_matrix(mat, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data_source_+3A_path">path</code></td>
<td>
<p>Path to the data file.</p>
</td></tr>
<tr><td><code id="data_source_+3A_index1">index1</code></td>
<td>
<p>Whether the user indices and item indices start with 1
(<code>index1 = TRUE</code>) or 0 (<code>index1 = FALSE</code>).</p>
</td></tr>
<tr><td><code id="data_source_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="data_source_+3A_user_index">user_index</code></td>
<td>
<p>An integer vector giving the user indices of rating scores.</p>
</td></tr>
<tr><td><code id="data_source_+3A_item_index">item_index</code></td>
<td>
<p>An integer vector giving the item indices of rating scores.</p>
</td></tr>
<tr><td><code id="data_source_+3A_rating">rating</code></td>
<td>
<p>A numeric vector of the observed entries in the rating matrix.
Can be specified as <code>NULL</code> for testing data, in which case
it is ignored.</p>
</td></tr>
<tr><td><code id="data_source_+3A_mat">mat</code></td>
<td>
<p>A <code>dgTMatrix</code> (if it has ratings/values) or <code>ngTMatrix</code>
(if it is binary) sparse matrix, with users corresponding to rows
and items corresponding to columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <code>$<a href="#topic+tune">tune</a>()</code> and <code>$<a href="#topic+train">train</a>()</code>, functions in this page
are used to specify the source of training data.
</p>
<p><code>data_file()</code> expects a text file that describes a sparse matrix
in triplet form, i.e., each line in the file contains three numbers
</p>
<pre>row col value</pre>
<p>representing a number in the rating matrix
with its location. In real applications, it typically looks like
</p>
<pre>user_index item_index rating</pre>
<p>The &lsquo;<span class="file">smalltrain.txt</span>&rsquo; file in the &lsquo;<span class="file">dat</span>&rsquo; directory of this package
shows an example of training data file.
</p>
<p>If the sparse matrix is given as a <code>dgTMatrix</code> or <code>ngTMatrix</code> object
(triplets/COO format defined in the <span class="pkg">Matrix</span> package), then the function
<code>data_matrix()</code> can be used to specify the data source.
</p>
<p>If user index, item index, and ratings are stored as R vectors in memory,
they can be passed to <code>data_memory()</code> to form the training data source.
</p>
<p>By default the user index and item index start with zeros, and the option
<code>index1 = TRUE</code> can be set if they start with ones.
</p>
<p>From version 0.4 <span class="pkg">recosystem</span> supports two special types of matrix
factorization: the binary matrix factorization (BMF), and the one-class
matrix factorization (OCMF). BMF requires ratings to take value from
<code class="reqn">{-1, 1}</code>, and OCMF requires all the ratings to be positive.
</p>
<p>In <code>$<a href="#topic+predict">predict</a>()</code>, functions in this page provide the source of
testing data. The testing data have the same format as training data, except
that the value (rating) column is not required, and will be ignored if it is
provided. The &lsquo;<span class="file">smalltest.txt</span>&rsquo; file in the &lsquo;<span class="file">dat</span>&rsquo; directory of this
package shows an example of testing data file.
</p>


<h3>Value</h3>

<p>An object of class &quot;DataSource&quot; as required by
<code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+train">train</a>()</code>, and <code>$<a href="#topic+predict">predict</a>()</code>.
</p>


<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+train">train</a>()</code>, <code>$<a href="#topic+predict">predict</a>()</code>
</p>

<hr>
<h2 id='output'>Exporting Factorization Matrices</h2><span id='topic+output'></span>

<h3>Description</h3>

<p>This method is a member function of class &quot;<code>RecoSys</code>&quot;
that exports the user score matrix <code class="reqn">P</code> and the item score matrix <code class="reqn">Q</code>.
</p>
<p>Prior to calling this method, model needs to be trained using member function
<code>$<a href="#topic+train">train</a>()</code>.
</p>
<p>The common usage of this method is
</p>
<pre>r = Reco()
r$train(...)
r$output(out_P = out_file("mat_P.txt"), out_Q = out_file("mat_Q.txt"))</pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="output_+3A_r">r</code></td>
<td>
<p>Object returned by <code><a href="#topic+Reco">Reco</a>()</code>.</p>
</td></tr>
<tr><td><code id="output_+3A_out_p">out_P</code></td>
<td>
<p>An object of class <code>Output</code> that specifies the
output format of the user matrix, typically returned by function
<code><a href="#topic+out_file">out_file</a>()</code>, <code><a href="#topic+out_memory">out_memory</a>()</code> or
<code><a href="#topic+out_nothing">out_nothing</a>()</code>.
<code><a href="#topic+out_file">out_file</a>()</code> writes the matrix into a file, with
each row representing a user and each column representing a
latent factor.
<code><a href="#topic+out_memory">out_memory</a>()</code> exports the matrix
into the return value of <code>$output()</code>.
<code><a href="#topic+out_nothing">out_nothing</a>()</code> means the matrix will not be exported.</p>
</td></tr>
<tr><td><code id="output_+3A_out_q">out_Q</code></td>
<td>
<p>Ditto, but for the item matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components <code>P</code> and <code>Q</code>. They will be filled
with user or item matrix if <code><a href="#topic+out_memory">out_memory</a>()</code> is used
in the function argument, otherwise <code>NULL</code> will be returned.
</p>


<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>References</h3>

<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems.
ACM TIST, 2015.
</p>
<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Learning-rate Schedule for Stochastic Gradient Methods to Matrix Factorization.
PAKDD, 2015.
</p>
<p>W.-S. Chin, B.-W. Yuan, M.-Y. Yang, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.
Technical report, 2015.
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+train">train</a>()</code>, <code>$<a href="#topic+predict">predict</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train_set = system.file("dat", "smalltrain.txt", package = "recosystem")
r = Reco()
set.seed(123) # This is a randomized algorithm
r$train(data_file(train_set), out_model = file.path(tempdir(), "model.txt"),
        opts = list(dim = 10, nmf = TRUE))

## Write P and Q matrices to files
P_file = out_file(tempfile())
Q_file = out_file(tempfile())
r$output(P_file, Q_file)
head(read.table(P_file@dest, header = FALSE, sep = " "))
head(read.table(Q_file@dest, header = FALSE, sep = " "))

## Skip P and only export Q
r$output(out_nothing(), Q_file)

## Return P and Q in memory
res = r$output(out_memory(), out_memory())
head(res$P)
head(res$Q)

</code></pre>

<hr>
<h2 id='output_format'>Specifying Output Format</h2><span id='topic+output_format'></span><span id='topic+out_file'></span><span id='topic+out_memory'></span><span id='topic+out_nothing'></span>

<h3>Description</h3>

<p>Functions in this page are used to specify the format of output results.
They are intended to provide the argument of functions such as
<code>$<a href="#topic+output">output</a>()</code> and <code>$<a href="#topic+predict">predict</a>()</code>.
Currently there are three types of output: <code>out_file()</code> indicates
that the result should be written into a file, <code>out_memory()</code> makes
the result to be returned as R objects, and <code>out_nothing()</code> means
the result is not needed and will not be returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>out_file(path, ...)

out_memory(...)

out_nothing(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="output_format_+3A_path">path</code></td>
<td>
<p>Path to the output file.</p>
</td></tr>
<tr><td><code id="output_format_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;Output&quot; as required by
<code>$<a href="#topic+output">output</a>()</code> and <code>$<a href="#topic+predict">predict</a>()</code>.
</p>


<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+output">output</a>()</code>, <code>$<a href="#topic+predict">predict</a>()</code>
</p>

<hr>
<h2 id='predict'>Recommender Model Predictions</h2><span id='topic+predict'></span>

<h3>Description</h3>

<p>This method is a member function of class &quot;<code>RecoSys</code>&quot;
that predicts unknown entries in the rating matrix.
</p>
<p>Prior to calling this method, model needs to be trained using member function
<code>$<a href="#topic+train">train</a>()</code>.
</p>
<p>The common usage of this method is
</p>
<pre>r = Reco()
r$train(...)
r$predict(test_data, out_pred = out_file("predict.txt")</pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_r">r</code></td>
<td>
<p>Object returned by <code><a href="#topic+Reco">Reco</a>()</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_test_data">test_data</code></td>
<td>
<p>An object of class &quot;DataSource&quot; that describes the source
of testing data, typically returned by function
<code><a href="#topic+data_file">data_file</a>()</code>, <code><a href="#topic+data_memory">data_memory</a>()</code>,
or <code><a href="#topic+data_matrix">data_matrix</a>()</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_out_pred">out_pred</code></td>
<td>
<p>An object of class <code>Output</code> that specifies the
output format of prediction, typically returned by function
<code><a href="#topic+out_file">out_file</a>()</code>, <code><a href="#topic+out_memory">out_memory</a>()</code> or
<code><a href="#topic+out_nothing">out_nothing</a>()</code>.
<code><a href="#topic+out_file">out_file</a>()</code> writes the result into a
file, <code><a href="#topic+out_memory">out_memory</a>()</code> exports the vector of
predicted values into the return value of <code>$predict()</code>,
and <code><a href="#topic+out_nothing">out_nothing</a>()</code> means the result will be
neither returned nor written into a file (but computation will
still be conducted).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>References</h3>

<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems.
ACM TIST, 2015.
</p>
<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Learning-rate Schedule for Stochastic Gradient Methods to Matrix Factorization.
PAKDD, 2015.
</p>
<p>W.-S. Chin, B.-W. Yuan, M.-Y. Yang, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.
Technical report, 2015.
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+train">train</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
train_file = data_file(system.file("dat", "smalltrain.txt", package = "recosystem"))
test_file = data_file(system.file("dat", "smalltest.txt", package = "recosystem"))
r = Reco()
set.seed(123) # This is a randomized algorithm
opts_tune = r$tune(train_file)$min
r$train(train_file, out_model = NULL, opts = opts_tune)

## Write predicted values into file
out_pred = out_file(tempfile())
r$predict(test_file, out_pred)

## Return predicted values in memory
pred = r$predict(test_file, out_memory())

## If testing data are stored in memory
test_df = read.table(test_file@source, sep = " ", header = FALSE)
test_data = data_memory(test_df[, 1], test_df[, 2])
pred2 = r$predict(test_data, out_memory())

## Compare results
print(scan(out_pred@dest, n = 10))
head(pred, 10)
head(pred2, 10)

## If testing data are stored as a sparse matrix
if(require(Matrix))
{
    mat = Matrix::sparseMatrix(i = test_df[, 1], j = test_df[, 2], x = -1,
                               repr = "T", index1 = FALSE)
    test_data = data_matrix(mat)
    pred3 = r$predict(test_data, out_memory())
    print(head(pred3, 10))
}

## End(Not run)

</code></pre>

<hr>
<h2 id='Reco'>Constructing a Recommender System Object</h2><span id='topic+Reco'></span>

<h3>Description</h3>

<p>This function simply returns an object of class &quot;<code>RecoSys</code>&quot;
that can be used to construct recommender model and conduct prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Reco()
</code></pre>


<h3>Value</h3>

<p><code>Reco()</code> returns an object of class &quot;<code>RecoSys</code>&quot;
equipped with methods
<code>$<a href="#topic+train">train</a>()</code>, <code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+output">output</a>()</code>
and <code>$<a href="#topic+predict">predict</a>()</code>, which describe the typical process of
building and tuning model, exporting factorization matrices, and
predicting results. See their help documents for details.
</p>


<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>References</h3>

<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems.
ACM TIST, 2015.
</p>
<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Learning-rate Schedule for Stochastic Gradient Methods to Matrix Factorization.
PAKDD, 2015.
</p>
<p>W.-S. Chin, B.-W. Yuan, M.-Y. Yang, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.
Technical report, 2015.
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+train">train</a>()</code>, <code>$<a href="#topic+output">output</a>()</code>,
<code>$<a href="#topic+predict">predict</a>()</code>
</p>

<hr>
<h2 id='train'>Training a Recommender Model</h2><span id='topic+train'></span>

<h3>Description</h3>

<p>This method is a member function of class &quot;<code>RecoSys</code>&quot;
that trains a recommender model. It will read from a training data source and
create a model file at the specified location. The model file contains
necessary information for prediction.
</p>
<p>The common usage of this method is
</p>
<pre>r = Reco()
r$train(train_data, out_model = file.path(tempdir(), "model.txt"),
        opts = list())</pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_+3A_r">r</code></td>
<td>
<p>Object returned by <code><a href="#topic+Reco">Reco</a></code>().</p>
</td></tr>
<tr><td><code id="train_+3A_train_data">train_data</code></td>
<td>
<p>An object of class &quot;DataSource&quot; that describes the source
of training data, typically returned by function
<code><a href="#topic+data_file">data_file</a>()</code>, <code><a href="#topic+data_memory">data_memory</a>()</code>,
or <code><a href="#topic+data_matrix">data_matrix</a>()</code>.</p>
</td></tr>
<tr><td><code id="train_+3A_out_model">out_model</code></td>
<td>
<p>Path to the model file that will be created.
If passing <code>NULL</code>, the model will be stored in-memory, and
model matrices can then be accessed under <code>r$model$matrices</code>.</p>
</td></tr>
<tr><td><code id="train_+3A_opts">opts</code></td>
<td>
<p>A number of parameters and options for the model training.
See section <strong>Parameters and Options</strong> for details.</p>
</td></tr>
</table>


<h3>Parameters and Options</h3>

<p>The <code>opts</code> argument is a list that can supply any of the following parameters:
</p>

<dl>
<dt><code>loss</code></dt><dd><p>Character string, the loss function. Default is &quot;l2&quot;, see below for details.</p>
</dd>
<dt><code>dim</code></dt><dd><p>Integer, the number of latent factors. Default is 10.</p>
</dd>
<dt><code>costp_l1</code></dt><dd><p>Numeric, L1 regularization parameter for user factors. Default is 0.</p>
</dd>
<dt><code>costp_l2</code></dt><dd><p>Numeric, L2 regularization parameter for user factors. Default is 0.1.</p>
</dd>
<dt><code>costq_l1</code></dt><dd><p>Numeric, L1 regularization parameter for item factors. Default is 0.</p>
</dd>
<dt><code>costq_l2</code></dt><dd><p>Numeric, L2 regularization parameter for item factors. Default is 0.1.</p>
</dd>
<dt><code>lrate</code></dt><dd><p>Numeric, the learning rate, which can be thought
of as the step size in gradient descent. Default is 0.1.</p>
</dd>
<dt><code>niter</code></dt><dd><p>Integer, the number of iterations. Default is 20.</p>
</dd>
<dt><code>nthread</code></dt><dd><p>Integer, the number of threads for parallel
computing. Default is 1.</p>
</dd>
<dt><code>nbin</code></dt><dd><p>Integer, the number of bins. Must be greater than <code>nthread</code>.
Default is 20.</p>
</dd>
<dt><code>nmf</code></dt><dd><p>Logical, whether to perform non-negative matrix factorization.
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical, whether to show detailed information. Default is
<code>TRUE</code>.</p>
</dd>
</dl>

<p>The <code>loss</code> option may take the following values:
</p>
<p>For real-valued matrix factorization,
</p>

<dl>
<dt><code>"l2"</code></dt><dd><p>Squared error (L2-norm)</p>
</dd>
<dt><code>"l1"</code></dt><dd><p>Absolute error (L1-norm)</p>
</dd>
<dt><code>"kl"</code></dt><dd><p>Generalized KL-divergence</p>
</dd>
</dl>

<p>For binary matrix factorization,
</p>

<dl>
<dt><code>"log"</code></dt><dd><p>Logarithmic error</p>
</dd>
<dt><code>"squared_hinge"</code></dt><dd><p>Squared hinge loss</p>
</dd>
<dt><code>"hinge"</code></dt><dd><p>Hinge loss</p>
</dd>
</dl>

<p>For one-class matrix factorization,
</p>

<dl>
<dt><code>"row_log"</code></dt><dd><p>Row-oriented pair-wise logarithmic loss</p>
</dd>
<dt><code>"col_log"</code></dt><dd><p>Column-oriented pair-wise logarithmic loss</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>References</h3>

<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems.
ACM TIST, 2015.
</p>
<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Learning-rate Schedule for Stochastic Gradient Methods to Matrix Factorization.
PAKDD, 2015.
</p>
<p>W.-S. Chin, B.-W. Yuan, M.-Y. Yang, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.
Technical report, 2015.
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+tune">tune</a>()</code>, <code>$<a href="#topic+output">output</a>()</code>, <code>$<a href="#topic+predict">predict</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Training model from a data file
train_set = system.file("dat", "smalltrain.txt", package = "recosystem")
train_data = data_file(train_set)
r = Reco()
set.seed(123) # This is a randomized algorithm
# The model will be saved to a file
r$train(train_data, out_model = file.path(tempdir(), "model.txt"),
        opts = list(dim = 20, costp_l2 = 0.01, costq_l2 = 0.01, nthread = 1)
)

## Training model from data in memory
train_df = read.table(train_set, sep = " ", header = FALSE)
train_data = data_memory(train_df[, 1], train_df[, 2], rating = train_df[, 3])
set.seed(123)
# The model will be stored in memory
r$train(train_data, out_model = NULL,
        opts = list(dim = 20, costp_l2 = 0.01, costq_l2 = 0.01, nthread = 1)
)

## Training model from data in a sparse matrix
if(require(Matrix))
{
    mat = Matrix::sparseMatrix(i = train_df[, 1], j = train_df[, 2], x = train_df[, 3],
                               repr = "T", index1 = FALSE)
    train_data = data_matrix(mat)
    r$train(train_data, out_model = NULL,
            opts = list(dim = 20, costp_l2 = 0.01, costq_l2 = 0.01, nthread = 1))
}

</code></pre>

<hr>
<h2 id='tune'>Tuning Model Parameters</h2><span id='topic+tune'></span>

<h3>Description</h3>

<p>This method is a member function of class &quot;<code>RecoSys</code>&quot;
that uses cross validation to tune the model parameters.
</p>
<p>The common usage of this method is
</p>
<pre>r = Reco()
r$tune(train_data, opts = list(dim      = c(10L, 20L),
                               costp_l1 = c(0, 0.1),
                               costp_l2 = c(0.01, 0.1),
                               costq_l1 = c(0, 0.1),
                               costq_l2 = c(0.01, 0.1),
                               lrate    = c(0.01, 0.1))
)</pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tune_+3A_r">r</code></td>
<td>
<p>Object returned by <code><a href="#topic+Reco">Reco</a></code>().</p>
</td></tr>
<tr><td><code id="tune_+3A_train_data">train_data</code></td>
<td>
<p>An object of class &quot;DataSource&quot; that describes the source
of training data, typically returned by function
<code><a href="#topic+data_file">data_file</a>()</code>, <code><a href="#topic+data_memory">data_memory</a>()</code>,
or <code><a href="#topic+data_matrix">data_matrix</a>()</code>.</p>
</td></tr>
<tr><td><code id="tune_+3A_opts">opts</code></td>
<td>
<p>A number of candidate tuning parameter values and extra options in the
model tuning procedure. See section <strong>Parameters and Options</strong>
for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components:
</p>

<dl>
<dt><code>min</code></dt><dd><p>Parameter values with minimum cross validated loss.
This is a list that can be passed to the
<code>opts</code> argument in <code>$<a href="#topic+train">train</a>()</code>.</p>
</dd>
<dt><code>res</code></dt><dd><p>A data frame giving the supplied candidate
values of tuning parameters, and one column showing the
loss function value associated with each combination.</p>
</dd>
</dl>



<h3>Parameters and Options</h3>

<p>The <code>opts</code> argument should be a list that provides the candidate values
of tuning parameters and some other options. For tuning parameters (<code>dim</code>,
<code>costp_l1</code>, <code>costp_l2</code>, <code>costq_l1</code>, <code>costq_l2</code>,
and <code>lrate</code>), users can provide a numeric vector for each one, so that
the model will be evaluated on each combination of the candidate values.
For other non-tuning options, users should give a single value. If a parameter
or option is not set by the user, the program will use a default one.
</p>
<p>See below for the list of available parameters and options:
</p>

<dl>
<dt><code>dim</code></dt><dd><p>Tuning parameter, the number of latent factors.
Can be specified as an integer vector, with default value
<code>c(10L, 20L)</code>.</p>
</dd>
<dt><code>costp_l1</code></dt><dd><p>Tuning parameter, the L1 regularization cost for user factors.
Can be specified as a numeric vector, with default value
<code>c(0, 0.1)</code>.</p>
</dd>
<dt><code>costp_l2</code></dt><dd><p>Tuning parameter, the L2 regularization cost for user factors.
Can be specified as a numeric vector, with default value
<code>c(0.01, 0.1)</code>.</p>
</dd>
<dt><code>costq_l1</code></dt><dd><p>Tuning parameter, the L1 regularization cost for item factors.
Can be specified as a numeric vector, with default value
<code>c(0, 0.1)</code>.</p>
</dd>
<dt><code>costq_l2</code></dt><dd><p>Tuning parameter, the L2 regularization cost for item factors.
Can be specified as a numeric vector, with default value
<code>c(0.01, 0.1)</code>.</p>
</dd>
<dt><code>lrate</code></dt><dd><p>Tuning parameter, the learning rate, which can be thought
of as the step size in gradient descent.
Can be specified as a numeric vector, with default value
<code>c(0.01, 0.1)</code>.</p>
</dd>
<dt><code>loss</code></dt><dd><p>Character string, the loss function. Default is &quot;l2&quot;, see
section <strong>Parameters and Options</strong> in <code>$<a href="#topic+train">train</a>()</code>
for details.</p>
</dd>
<dt><code>nfold</code></dt><dd><p>Integer, the number of folds in cross validation. Default is 5.</p>
</dd>
<dt><code>niter</code></dt><dd><p>Integer, the number of iterations. Default is 20.</p>
</dd>
<dt><code>nthread</code></dt><dd><p>Integer, the number of threads for parallel
computing. Default is 1.</p>
</dd>
<dt><code>nbin</code></dt><dd><p>Integer, the number of bins. Must be greater than <code>nthread</code>.
Default is 20.</p>
</dd>
<dt><code>nmf</code></dt><dd><p>Logical, whether to perform non-negative matrix factorization.
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical, whether to show detailed information. Default is
<code>FALSE</code>.</p>
</dd>
<dt><code>progress</code></dt><dd><p>Logical, whether to show a progress bar. Default is <code>TRUE</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yixuan Qiu &lt;<a href="https://statr.me">https://statr.me</a>&gt;
</p>


<h3>References</h3>

<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems.
ACM TIST, 2015.
</p>
<p>W.-S. Chin, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
A Learning-rate Schedule for Stochastic Gradient Methods to Matrix Factorization.
PAKDD, 2015.
</p>
<p>W.-S. Chin, B.-W. Yuan, M.-Y. Yang, Y. Zhuang, Y.-C. Juan, and C.-J. Lin.
LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.
Technical report, 2015.
</p>


<h3>See Also</h3>

<p><code>$<a href="#topic+train">train</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
train_set = system.file("dat", "smalltrain.txt", package = "recosystem")
train_src = data_file(train_set)
r = Reco()
set.seed(123) # This is a randomized algorithm
res = r$tune(
    train_src,
    opts = list(dim = c(10, 20, 30),
                costp_l1 = 0, costq_l1 = 0,
                lrate = c(0.05, 0.1, 0.2), nthread = 2)
)
r$train(train_src, opts = res$min)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
