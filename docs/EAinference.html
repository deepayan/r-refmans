<!DOCTYPE html><html><head><title>Help for package EAinference</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EAinference}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.lasso'><p>Compute K-fold cross-validated mean squared error for lasso</p></a></li>
<li><a href='#hdIS'><p>Compute importance weights for  lasso, group lasso, scaled lasso or</p>
scaled group lasso estimator under high-dimensional setting</a></li>
<li><a href='#lassoFit'><p>Compute lasso estimator</p></a></li>
<li><a href='#MHLS'><p>Metropolis-Hastings lasso sampler under a fixed active set.</p></a></li>
<li><a href='#PB.CI'><p>Provide <code>(1-alpha)%</code> confidence interval of each coefficients</p></a></li>
<li><a href='#PBsampler'><p>Parametric bootstrap sampler for lasso, group lasso, scaled lasso or scaled group lasso estimator</p></a></li>
<li><a href='#plot.MHLS'><p>Plot Metropolis-Hastings sampler outputs</p></a></li>
<li><a href='#postInference.MHLS'><p>Post-inference with lasso estimator</p></a></li>
<li><a href='#print.MHLS'><p>Print Metropolis-Hastings sampler outputs</p></a></li>
<li><a href='#summary.MHLS'><p>Summarizing Metropolis-Hastings sampler outputs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimator Augmentation and Simulation-Based Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Seunghyun Min &lt;seunghyun@ucla.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimator augmentation methods for statistical inference on high-dimensional data, 
    as described in Zhou, Q. (2014) &lt;<a href="https://doi.org/10.48550/arXiv.1401.4425">doi:10.48550/arXiv.1401.4425</a>&gt;
    and Zhou, Q. and Min, S. (2017) &lt;<a href="https://doi.org/10.1214%2F17-EJS1309">doi:10.1214/17-EJS1309</a>&gt;.
    It provides several simulation-based inference methods: (a) Gaussian and 
    wild multiplier bootstrap for lasso, group lasso, scaled lasso, scaled group
    lasso and their de-biased estimators, (b) importance sampler for approximating
    p-values in these methods, (c) Markov chain Monte Carlo lasso sampler with 
    applications in post-selection inference.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, msm, mvtnorm, parallel, limSolve, MASS, hdi,
Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-12-01 23:11:51 UTC; seunghyunmin</td>
</tr>
<tr>
<td>Author:</td>
<td>Seunghyun Min [aut, cre],
  Qing Zhou [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-12-02 00:01:31 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.lasso'>Compute K-fold cross-validated mean squared error for lasso</h2><span id='topic+cv.lasso'></span>

<h3>Description</h3>

<p>Computes K-fold cross-validated mean squared error
to propose a lambda value for lasso, group lasso, scaled lasso or scaled
group lasso.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lasso(X, Y, group = 1:ncol(X), weights = rep(1, max(group)), type,
  K = 10L, minlbd, maxlbd, num.lbdseq = 100L, parallel = FALSE,
  ncores = 2L, plot.it = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.lasso_+3A_x">X</code></td>
<td>
<p>predictor matrix.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_y">Y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_group">group</code></td>
<td>
<p><code>p</code> x <code>1</code> vector of consecutive integers describing the group structure.
The number of groups should be the same as max(group). Default is <code>group = 1:p</code>
, where <code>p</code> is number of covariates. See examples for a guideline.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_weights">weights</code></td>
<td>
<p>weight vector with length equal to the number of groups. Default is
<code>rep(1, max(group))</code>.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_type">type</code></td>
<td>
<p>type of penalty. Must be specified to be one of the following:
<code>"lasso", "grlasso", "slasso"</code> or <code>"sgrlasso"</code>, which correspond to
lasso, group lasso, scaled lasso or scaled group lasso.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_k">K</code></td>
<td>
<p>integer. Number of folds</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_minlbd">minlbd</code></td>
<td>
<p>numeric. Minimum value of the lambda sequence.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_maxlbd">maxlbd</code></td>
<td>
<p>numeric. Maximum value of the lambda sequence.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_num.lbdseq">num.lbdseq</code></td>
<td>
<p>integer. Length of the lambda sequence.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_parallel">parallel</code></td>
<td>
<p>logical. If <code>parallel = TRUE</code>, uses parallelization.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_ncores">ncores</code></td>
<td>
<p>integer. The number of cores to use for parallelization.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_plot.it">plot.it</code></td>
<td>
<p>logical. If true, plots the squared error curve.</p>
</td></tr>
<tr><td><code id="cv.lasso_+3A_verbose">verbose</code></td>
<td>
<p>logical.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>lbd.min</code></td>
<td>
<p>a value of lambda which gives a minimum squared error.</p>
</td></tr>
<tr><td><code>lbd.1se</code></td>
<td>
<p>a largest lambda within 1 standard error from <code>lbd.min</code>.</p>
</td></tr>
<tr><td><code>lbd.seq</code></td>
<td>
<p>lambda sequence.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>mean squared error at each lambda value.</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>the standard deviation of cv.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 30
p &lt;- 50
group &lt;- rep(1:(p/10),each=10)
weights &lt;- rep(1, max(group))
X &lt;- matrix(rnorm(n*p),n)
truebeta &lt;- c(rep(1,5),rep(0,p-5))
Y &lt;- X%*%truebeta + rnorm(n)

# To accelerate the computational time, we set K=2 and num.lbdseq=2.
# However, in practice, Allowing K=10 and num.lbdseq &gt; 100 is recommended.
cv.lasso(X = X, Y = Y, group = group, weights = weights, K = 2,
type = "grlasso", num.lbdseq = 2, plot.it = FALSE)
cv.lasso(X = X, Y = Y, group = group, weights = weights, K = 2,
type = "sgrlasso", num.lbdseq = 2, plot.it = FALSE)
</code></pre>

<hr>
<h2 id='hdIS'>Compute importance weights for  lasso, group lasso, scaled lasso or
scaled group lasso estimator under high-dimensional setting</h2><span id='topic+hdIS'></span>

<h3>Description</h3>

<p><code>hdIS</code> computes importance weights using samples
drawn by <code><a href="#topic+PBsampler">PBsampler</a></code>. See the examples
below for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdIS(PBsample, PETarget, sig2Target, lbdTarget, TsA.method = "default",
  log = TRUE, parallel = FALSE, ncores = 2L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdIS_+3A_pbsample">PBsample</code></td>
<td>
<p>bootstrap samples of class <code>PB</code> from <code><a href="#topic+PBsampler">PBsampler</a></code>.</p>
</td></tr>
<tr><td><code id="hdIS_+3A_petarget">PETarget</code>, <code id="hdIS_+3A_sig2target">sig2Target</code>, <code id="hdIS_+3A_lbdtarget">lbdTarget</code></td>
<td>
<p>parameters of target distribution.
(point estimate of beta or <code>E(y)</code>, estimated variance of error and lambda)</p>
</td></tr>
<tr><td><code id="hdIS_+3A_tsa.method">TsA.method</code></td>
<td>
<p>method to construct <code>T(eta(s),A)</code> matrix. See Zhou and Min(2017)
for details.</p>
</td></tr>
<tr><td><code id="hdIS_+3A_log">log</code></td>
<td>
<p>logical. If <code>log = TRUE</code>, importance weight is computed in log scale.</p>
</td></tr>
<tr><td><code id="hdIS_+3A_parallel">parallel</code></td>
<td>
<p>logical. If <code>parallel = TRUE</code>, uses parallelization.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="hdIS_+3A_ncores">ncores</code></td>
<td>
<p>integer. The number of cores to use for parallelization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>computes importance weights which is defined as (target density)/(proposal density),
when the samples are drawn from the proposal
distribution with the function <code><a href="#topic+PBsampler">PBsampler</a></code> while the parameters of
the target distribution are (PETarget, sig2Target, lbdTarget). <br />
Say that we are interested in computing the expectation of a function of a random variable, <code>h(X)</code>.
Let <code>f(x)</code> be the true or target distribution and <code>g(x)</code> be the proposal distribution.
We can approximate the expectation, <code>E[h(X)]</code>, by a weighted average of samples, <code>x_i</code>, drawn from
the proposal distribution as follows, <code>E[h(X)] = mean( h(x_i) * f(x_i)/h(x_i) )</code>.
</p>


<h3>Value</h3>

<p>importance weights of the proposed samples.
</p>


<h3>References</h3>

<p>Zhou, Q. (2014), &quot;Monte Carlo simulation for Lasso-type problems by estimator augmentation,&quot;
Journal of the American Statistical Association, 109, 1495-1516.
</p>
<p>Zhou, Q. and Min, S. (2017), &quot;Estimator augmentation with applications in
high-dimensional group inference,&quot; Electronic Journal of Statistics, 11(2), 3039-3080.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
n &lt;- 10
p &lt;- 30
Niter &lt;-  10
Group &lt;- rep(1:(p/10), each = 10)
Weights &lt;- rep(1, p/10)
x &lt;- matrix(rnorm(n*p), n)

# Target distribution parameter
PETarget &lt;- rep(0, p)
sig2Target &lt;- .5
lbdTarget &lt;- .37

#
# Using non-mixture distribution
# ------------------------------
## Proposal distribution parameter
PEProp1 &lt;- rep(1, p)
sig2Prop1 &lt;- .5
lbdProp1 &lt;- 1
PB &lt;- PBsampler(X = x, PE_1 = PEProp1, sig2_1 = sig2Prop1,
 lbd_1 = lbdProp1, weights = Weights, group = Group, niter = Niter,
 type="grlasso", PEtype = "coeff")

hdIS(PB, PETarget = PETarget, sig2Target = sig2Target, lbdTarget = lbdTarget,
 log = TRUE)

#
# Using mixture distribution
# ------------------------------
# Target distribution parameters (coeff, sig2, lbd) = (rep(0,p), .5, .37)
# Proposal distribution parameters
#  (coeff, sig2, lbd) = (rep(0,p), .5, .37) &amp; (rep(1,p), 1, .5)
#
#
PEProp1 &lt;- rep(0,p); PEProp2 &lt;- rep(1,p)
sig2Prop1 &lt;- .5; sig2Prop2 &lt;- 1
lbdProp1 &lt;- .37; lbdProp2 &lt;- .5

PBMixture &lt;- PBsampler(X = x, PE_1 = PEProp1,
 sig2_1 = sig2Prop1, lbd_1 = lbdProp1, PE_2 = PEProp2,
 sig2_2 = sig2Prop2, lbd_2 = lbdProp2, weights = Weights, group = Group,
 niter = Niter, type = "grlasso", PEtype = "coeff")
hdIS(PBMixture, PETarget = PETarget, sig2Target = sig2Target, lbdTarget = lbdTarget,
 log = TRUE)
</code></pre>

<hr>
<h2 id='lassoFit'>Compute lasso estimator</h2><span id='topic+lassoFit'></span>

<h3>Description</h3>

<p>Computes lasso, group lasso, scaled lasso, or scaled group lasso solution.
The outputs are coefficient-estimate and subgradient. If <code>type = "slasso"</code>
or <code>type = "sgrlasso"</code>, the output will include estimated standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lassoFit(X, Y, type, lbd, group = 1:ncol(X), weights = rep(1, max(group)),
  verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lassoFit_+3A_x">X</code></td>
<td>
<p>predictor matrix.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_y">Y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_type">type</code></td>
<td>
<p>type of penalty. Must be specified to be one of the following:
<code>"lasso", "grlasso", "slasso"</code> or <code>"sgrlasso"</code>, which correspond to
lasso, group lasso, scaled lasso or scaled group lasso.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_lbd">lbd</code></td>
<td>
<p>penalty term of lasso. By letting this argument be <code>"cv.1se"</code> or
<code>"cv.min"</code>, users can have the cross-validated lambda that gives either minimum
squared error or that is within 1 std error bound.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_group">group</code></td>
<td>
<p><code>p</code> x <code>1</code> vector of consecutive integers describing the group structure.
The number of groups should be the same as max(group). Default is <code>group = 1:p</code>
, where <code>p</code> is number of covariates.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_weights">weights</code></td>
<td>
<p>weight vector with length equal to the number of groups. Default is
<code>weights = rep(1, max(group))</code>.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_verbose">verbose</code></td>
<td>
<p>logical. Only available for <code>type = "slasso"</code> or <code>type = "sgrlasso"</code>.</p>
</td></tr>
<tr><td><code id="lassoFit_+3A_...">...</code></td>
<td>
<p>auxiliary arguments for <code>lbd = "cv.min", lbd = "cv.1se"</code>.
See <code><a href="#topic+cv.lasso">cv.lasso</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes lasso, group lasso, scaled lasso, or scaled group lasso solution.
Users can specify the value of lbd or choose to run cross-validation to get
optimal lambda in term of mean squared error. Coordinate decent algorithm is used
to fit scaled lasso and scaled group lasso models.
</p>


<h3>Value</h3>

<table>
<tr><td><code>B0</code></td>
<td>
<p>coefficient estimator.</p>
</td></tr>
<tr><td><code>S0</code></td>
<td>
<p>subgradient.</p>
</td></tr>
<tr><td><code>sigmaHat</code></td>
<td>
<p>estimated standard deviation.</p>
</td></tr>
<tr><td><code>lbd</code>, <code>weights</code>, <code>group</code></td>
<td>
<p>same as input arguments.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mitra, R. and Zhang, C. H. (2016), &quot;The benefit of group sparsity in group inference with
de-biased scaled group lasso,&quot; Electronic Journal of Statistics, 10, 1829-1873.
</p>
<p>Yang, Y. and Zou, H. (2015), “A Fast Unified Algorithm for Computing
Group-Lasso Penalized Learning Problems,” Statistics and Computing, 25(6), 1129-1141.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 50
p &lt;- 10
X &lt;- matrix(rnorm(n*p), n)
Y &lt;- X %*% c(1, 1, rep(0, p-2)) + rnorm(n)
#
# lasso
#
lassoFit(X = X, Y = Y, type = "lasso", lbd = .5)
#
# group lasso
#
lassoFit(X = X, Y = Y, type = "grlasso", lbd = .5, weights = rep(1,2),
           group = rep(1:2, each=5))
#
# scaled lasso
#
lassoFit(X = X, Y = Y, type = "slasso", lbd = .5)
#
# scaled group lasso
#
lassoFit(X = X, Y = Y, type = "sgrlasso", lbd = .5, weights = rep(1,2),
           group = rep(1:2, each=5))
</code></pre>

<hr>
<h2 id='MHLS'>Metropolis-Hastings lasso sampler under a fixed active set.</h2><span id='topic+MHLS'></span>

<h3>Description</h3>

<p>Metropolis-Hastings sampler to simulate from the sampling
distribution of lasso given a fixed active set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MHLS(X, PE, sig2, lbd, weights = rep(1, ncol(X)), B0, S0, A = which(B0 !=
  0), tau = rep(1, ncol(X)), niter = 2000, burnin = 0, PEtype = "coeff",
  updateS.itv = 1, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MHLS_+3A_x">X</code></td>
<td>
<p>predictor matrix.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_pe">PE</code>, <code id="MHLS_+3A_sig2">sig2</code>, <code id="MHLS_+3A_lbd">lbd</code></td>
<td>
<p>parameters of target distribution.
(point estimate of beta or <code>E(y)</code> depends on <code>PEtype</code>, variance estimate of error and lambda).</p>
</td></tr>
<tr><td><code id="MHLS_+3A_weights">weights</code></td>
<td>
<p>weight vector with length <code>p</code>(the number of covariates).
Default is <code>weights = rep(1, p)</code>.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_b0">B0</code></td>
<td>
<p>numeric vector with length <code>p</code>.
Initial value of lasso estimator.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_s0">S0</code></td>
<td>
<p>numeric vector with length <code>p</code>.
Initial value of subgradients.
If not given, this will be generated in a default way.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_a">A</code></td>
<td>
<p>numeric vector. Active coefficient index.
Every active coefficient index in <code>B0</code> must be included.
Default is <code>A = which(B0 != 0)</code>.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_tau">tau</code></td>
<td>
<p>numeric vector with length <code>p</code>.
Standard deviation of proposal distribution for each coefficient.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_niter">niter</code></td>
<td>
<p>integer. The number of iterations. Default is <code>niter = 2000</code></p>
</td></tr>
<tr><td><code id="MHLS_+3A_burnin">burnin</code></td>
<td>
<p>integer. The length of burin-in periods. Default is <code>burnin = 0</code></p>
</td></tr>
<tr><td><code id="MHLS_+3A_petype">PEtype</code></td>
<td>
<p>Type of <code>PE</code> which is needed to characterize the target distribution.
Users can choose either <code>"coeff"</code> or <code>"mu"</code>.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_updates.itv">updateS.itv</code></td>
<td>
<p>integer. Update subgradients every <code>updateS.itv</code> iterations.
Set this value larger than <code>niter</code> if one wants to skip updating subgradients.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_verbose">verbose</code></td>
<td>
<p>logical. If true, print out the progress step.</p>
</td></tr>
<tr><td><code id="MHLS_+3A_...">...</code></td>
<td>
<p>complementary arguments.
</p>

<ul>
<li><p><code>FlipSA :</code> optional parameter.
This has to be a subset of active set, A. If the index is not listed in FlipSA,
the sign of coefficients which correspond to the listed index will remain fixed.
The default is <code>FlipSA=A</code>
</p>
</li>
<li><p><code>SFindex :</code> optional parameter. subgradient index for the free coordinate.
</p>
</li>
<li><p><code>randomSFindex :</code> logical. If <code>true</code>, resample <code>SFindex</code> every
<code>updateSF.itv</code> iterations.
</p>
</li>
<li><p><code>updateSF.itv :</code> integer. In every <code>updateSF.itv</code> iterations,
randomize <code>SFindex</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Given appropriate initial value, provides Metropolis-Hastings samples
under the fixed active set. <br />
From the initial values, <code>B0</code> and S0, <code><a href="#topic+MHLS">MHLS</a></code> draws <code>beta</code> and <code>subgrad</code> samples.
In every iteration, given <code>t</code>-th iteration values, <code>t</code>-th <code>beta</code> and <code>t</code>-th <code>subgrad</code>,
a new set of proposed beta and subgradient is sampled. We either accept the proposed sample
and use that as <code>(t+1)</code>-th iteration values or reuse <code>t</code>-th iteration values. <br />
See Zhou(2014) for more details.
</p>


<h3>Value</h3>

<p><code><a href="#topic+MHLS">MHLS</a></code> returns an object of class <code>"MHLS"</code>.
The functions <code><a href="#topic+summary.MHLS">summary.MHLS</a></code> and <code><a href="#topic+plot.MHLS">plot.MHLS</a></code>
provide a brief summary and generate plots.
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>lasso samples.</p>
</td></tr>
<tr><td><code>subgrad</code></td>
<td>
<p>subgradient samples.</p>
</td></tr>
<tr><td><code>acceptHistory</code></td>
<td>
<p>numbers of acceptance and proposal.</p>
</td></tr>
<tr><td><code>niter</code>, <code>burnin</code>, <code>PE</code>, <code>type</code></td>
<td>
<p>same as function arguments.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhou, Q. (2014), &quot;Monte Carlo simulation for Lasso-type problems by estimator augmentation,&quot;
Journal of the American Statistical Association, 109, 1495-1516.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------
# Low dim
#-------------------------
set.seed(123)
n &lt;- 10
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n)
Y &lt;- X %*% rep(1, p) + rnorm(n)
sigma2 &lt;- 1
lbd &lt;- .37
weights &lt;- rep(1, p)
LassoResult &lt;- lassoFit(X = X, Y = Y, lbd = lbd, type = "lasso", weights = weights)
B0 &lt;- LassoResult$B0
S0 &lt;- LassoResult$S0
MHLS(X = X, PE = rep(0, p), sig2 = 1, lbd = 1,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     PEtype = "coeff")
MHLS(X = X, PE = rep(0, n), sig2 = 1, lbd = 1,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     PEtype = "mu")

#-------------------------
# High dim
#-------------------------
set.seed(123)
n &lt;- 5
p &lt;- 10
X &lt;- matrix(rnorm(n*p),n)
Y &lt;- X %*% rep(1,p) + rnorm(n)
weights &lt;- rep(1,p)
LassoResult &lt;- lassoFit(X = X,Y = Y,lbd = lbd, type = "lasso", weights = weights)
B0 &lt;- LassoResult$B0
S0 &lt;- LassoResult$S0
MHLS(X = X, PE = rep(0, p), sig2 = 1, lbd = 1,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     PEtype = "coeff")
MHLS(X = X, PE = rep(0, n), sig2 = 1, lbd = 1,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     PEtype = "mu")
</code></pre>

<hr>
<h2 id='PB.CI'>Provide <code>(1-alpha)%</code> confidence interval of each coefficients</h2><span id='topic+PB.CI'></span>

<h3>Description</h3>

<p>Using samples drawn by <code><a href="#topic+PBsampler">PBsampler</a></code>, computes
<code>(1-alpha)%</code> confidence interval of each coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PB.CI(object, alpha = 0.05, method = "debias", parallel = FALSE,
  ncores = 2L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PB.CI_+3A_object">object</code></td>
<td>
<p>bootstrap samples of class <code>PB</code> from <code><a href="#topic+PBsampler">PBsampler</a></code></p>
</td></tr>
<tr><td><code id="PB.CI_+3A_alpha">alpha</code></td>
<td>
<p>significance level.</p>
</td></tr>
<tr><td><code id="PB.CI_+3A_method">method</code></td>
<td>
<p>bias-correction method. Either to be &quot;none&quot; or &quot;debias&quot;.</p>
</td></tr>
<tr><td><code id="PB.CI_+3A_parallel">parallel</code></td>
<td>
<p>logical. If <code>TRUE</code>, use parallelization. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="PB.CI_+3A_ncores">ncores</code></td>
<td>
<p>integer. The number of cores to use for parallelization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "none"</code>, <code><a href="#topic+PB.CI">PB.CI</a></code> simply compute
the two-sided <code>(1-alpha)</code> quantile of the sampled coefficients.
If <code>method = "debias"</code>, we use
debiased estimator to compute confidence interval.
</p>


<h3>Value</h3>

<p><code>(1-alpha)%</code> confidence interval of each coefficients
</p>


<h3>References</h3>

<p>Zhang, C., Zhang, S. (2014), &quot;Confidence intervals for low dimensional
parameters in high dimensional linear models,&quot; Journal of the Royal
Statistical Society: Series B, 76, 217–242.
</p>
<p>Dezeure, R., Buhlmann, P., Meier, L. and Meinshausen, N. (2015),
&quot;High-Dimensional Inference: Confidence Intervals, p-values and R-Software hdi,&quot;
Statistical Science, 30(4), 533-558
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
n &lt;- 40
p &lt;- 50
Niter &lt;-  10
X &lt;- matrix(rnorm(n*p), n)
object &lt;- PBsampler(X = X, PE_1 = c(1,1,rep(0,p-2)), sig2_1 = 1, lbd_1 = .5,
niter = 100, type = "lasso")
parallel &lt;- (.Platform$OS.type != "windows")
PB.CI(object = object, alpha = .05, method = "none")

</code></pre>

<hr>
<h2 id='PBsampler'>Parametric bootstrap sampler for lasso, group lasso, scaled lasso or scaled group lasso estimator</h2><span id='topic+PBsampler'></span>

<h3>Description</h3>

<p>Draw gaussian bootstrap or wild multiplier bootstrap samples for
lasso, group lasso, scaled lasso and scaled group lasso estimators along with their subgradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PBsampler(X, PE_1, sig2_1, lbd_1, PE_2, sig2_2, lbd_2, weights = rep(1,
  max(group)), group = 1:ncol(X), niter = 2000, type, PEtype = "coeff",
  Btype = "gaussian", Y = NULL, parallel = FALSE, ncores = 2L,
  verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PBsampler_+3A_x">X</code></td>
<td>
<p>predictor matrix.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_pe_1">PE_1</code>, <code id="PBsampler_+3A_sig2_1">sig2_1</code>, <code id="PBsampler_+3A_lbd_1">lbd_1</code></td>
<td>
<p>parameters of target distribution.
(point estimate of beta or <code>E(y)</code> depends on <code>PEtype</code>, variance estimate of error and lambda)
sig2_1 is only needed when <code>Btype = "wild"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_pe_2">PE_2</code>, <code id="PBsampler_+3A_sig2_2">sig2_2</code>, <code id="PBsampler_+3A_lbd_2">lbd_2</code></td>
<td>
<p>additional parameters of target distribution. This is required
only if mixture distribution is used. sig2_2 is only needed when <code>Btype = "wild"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_weights">weights</code></td>
<td>
<p>weight vector with length equal to the number of groups. Default is
<code>rep(1, max(group))</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_group">group</code></td>
<td>
<p><code>p</code> x <code>1</code> vector of consecutive integers describing the group structure.
The number of groups should be the same as max(group). Default is <code>group = 1:p</code>
, where <code>p</code> is number of covariates. See examples for a guideline.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_niter">niter</code></td>
<td>
<p>integer. The number of iterations. Default is <code>niter = 2000</code></p>
</td></tr>
<tr><td><code id="PBsampler_+3A_type">type</code></td>
<td>
<p>type of penalty. Must be specified to be one of the following:
<code>"lasso", "grlasso", "slasso"</code> or <code>"sgrlasso"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_petype">PEtype</code></td>
<td>
<p>Type of <code>PE</code> which is needed to characterize the target distribution.
Users can choose either <code>"coeff"</code> or <code>"mu"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_btype">Btype</code></td>
<td>
<p>Type of bootstrap method. Users can choose either <code>"gaussian"</code>
for gaussian bootstrap or <code>"wild"</code> for wild multiplier bootstrap. Default
is <code>"gaussian"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_y">Y</code></td>
<td>
<p>response vector. This is only required when <code>Btype = "wild"</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_parallel">parallel</code></td>
<td>
<p>logical. If <code>parallel = TRUE</code>, uses parallelization.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_ncores">ncores</code></td>
<td>
<p>integer. The number of cores to use for parallelization.</p>
</td></tr>
<tr><td><code id="PBsampler_+3A_verbose">verbose</code></td>
<td>
<p>logical. This works only when
<code>parallel = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides bootstrap samples for lasso, group lasso,
scaled lasso or scaled group lasso estimator
and its subgradient. <br />
The sampling distribution is characterized by <code>(PE, sig2, lbd)</code>.
If <code>Btype = "gaussian"</code>, <code>error_new</code> is generated from <code>N(0, sig2)</code>.
If <code>Btype = "wild"</code>, we first generate <code>error_new</code> from <code>N(0, 1)</code>
and multiply with the residuals.
Then, if <code>PEtype = "coeff"</code>, <code>y_new</code> is generated by <code>X * PE + error_new</code>
and if <code>PEtype = "mu"</code>, <code>y_new</code> is generated by <code>PE + error_new</code>. <br />
By providing <code>(PE_2, sig2_2, lbd_2)</code>, this function simulates from a mixture distribution.
With 1/2 probability, samples will be drawn from the distribution with parameters
(PE_1, sig2_1, lbd_1) and with another 1/2 probability, they will be drawn from
the distribution with parameters (PE_2, sig2_2, lbd_2).
Four distinct penalties can be used; <code>"lasso"</code> for lasso, <code>"grlasso"</code> for group lasso,
<code>"slasso"</code> for scaled lasso and <code>"sgrlasso"</code> for scaled group lasso.
See Zhou(2014) and Zhou and Min(2017) for details.
</p>


<h3>Value</h3>

<table>
<tr><td><code>beta</code></td>
<td>
<p>coefficient estimate.</p>
</td></tr>
<tr><td><code>subgrad</code></td>
<td>
<p>subgradient.</p>
</td></tr>
<tr><td><code>hsigma</code></td>
<td>
<p>standard deviation estimator, for type=&quot;slasso&quot; or type=&quot;sgrlasso&quot; only.</p>
</td></tr>
<tr><td><code>X</code>, <code>PE</code>, <code>sig2</code>, <code>weights</code>, <code>group</code>, <code>type</code>, <code>PEtype</code>, <code>Btype</code>, <code>Y</code>, <code>mixture</code></td>
<td>
<p>model parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhou, Q. (2014), &quot;Monte Carlo simulation for Lasso-type problems by estimator augmentation,&quot;
Journal of the American Statistical Association, 109, 1495-1516.
</p>
<p>Zhou, Q. and Min, S. (2017), &quot;Estimator augmentation with applications in
high-dimensional group inference,&quot; Electronic Journal of Statistics, 11(2), 3039-3080.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
n &lt;- 10
p &lt;- 30
Niter &lt;-  10
Group &lt;- rep(1:(p/10), each = 10)
Weights &lt;- rep(1, p/10)
x &lt;- matrix(rnorm(n*p), n)
#
# Using non-mixture distribution
#
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, type = "grlasso", niter = Niter, parallel = FALSE)
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, type = "grlasso", niter = Niter, parallel = TRUE)
#
# Using mixture distribution
#
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 PE_2 = rep(1, p), sig2_2 = 2, lbd_2 = .3, weights = Weights,
 group = Group, type = "grlasso", niter = Niter, parallel = TRUE)
</code></pre>

<hr>
<h2 id='plot.MHLS'>Plot Metropolis-Hastings sampler outputs</h2><span id='topic+plot.MHLS'></span>

<h3>Description</h3>

<p>Provides six plots for each covariate index;
histogram, path plot and acf plot for beta and for its subgradient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MHLS'
plot(x, index = 1:ncol(x$beta), skipS = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.MHLS_+3A_x">x</code></td>
<td>
<p>an object of class &quot;MHLS&quot;, which is an output of <code><a href="#topic+MHLS">MHLS</a></code>.</p>
</td></tr>
<tr><td><code id="plot.MHLS_+3A_index">index</code></td>
<td>
<p>an index of covariates to plot.</p>
</td></tr>
<tr><td><code id="plot.MHLS_+3A_skips">skipS</code></td>
<td>
<p>logical. If <code>skipS = TRUE</code>, plots beta only.</p>
</td></tr>
<tr><td><code id="plot.MHLS_+3A_...">...</code></td>
<td>
<p>additional arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+plot.MHLS">plot.MHLS</a></code> provides summary plots of beta and subgradient.
The first column provides histogram of beta and subgradient, while the second
and the third columns provide path and acf plots, respectively.
If <code>skipS = TRUE</code>, this function provides summary plots for beta only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' set.seed(123)
n &lt;- 10
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n)
Y &lt;- X %*% rep(1, p) + rnorm(n)
sigma2 &lt;- 1
lbd &lt;- .37
weights &lt;- rep(1, p)
LassoResult &lt;- lassoFit(X = X, Y = Y, lbd = lbd, type="lasso", weights = weights)
B0 &lt;- LassoResult$B0
S0 &lt;- LassoResult$S0
plot(MHLS(X = X, PE = rep(0, p), sig2 = 1, lbd = 1, group = 1:p,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     type = "coeff"))
</code></pre>

<hr>
<h2 id='postInference.MHLS'>Post-inference with lasso estimator</h2><span id='topic+postInference.MHLS'></span>

<h3>Description</h3>

<p>Provides confidence intervals for the set of active coefficients
of lasso using Metropolis-Hastings sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postInference.MHLS(X, Y, lbd, weights = rep(1, ncol(X)), tau = rep(1,
  ncol(X)), sig2.hat, alpha = 0.05, nChain = 10, method,
  niterPerChain = 500, parallel = FALSE, ncores = 2L,
  returnSamples = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postInference.MHLS_+3A_x">X</code></td>
<td>
<p>predictor matrix.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_y">Y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_lbd">lbd</code></td>
<td>
<p>penalty term of lasso. By letting this argument be <code>"cv.1se"</code> or
<code>"cv.min"</code>, users can have the cross-validated lambda that gives either minimum
squared error or that is within 1 std error bound.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_weights">weights</code></td>
<td>
<p>weight vector with length equal to the number of coefficients.
Default is <code>rep(1, ncol(X))</code>.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_tau">tau</code></td>
<td>
<p>numeric vector. Standard deviation of proposal distribution
for each beta. Adjust the value to get relevant level of acceptance rate.
Default is <code>rep(1, ncol(X))</code>.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_sig2.hat">sig2.hat</code></td>
<td>
<p>variance of error term.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_alpha">alpha</code></td>
<td>
<p>confidence level for confidence interval.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_nchain">nChain</code></td>
<td>
<p>the number of chains. For each chain, different plug-in beta will be generated
from its confidence region.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_method">method</code></td>
<td>
<p>Type of robust method. Users can choose either <code>"coeff"</code> or <code>"mu"</code>.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_niterperchain">niterPerChain</code></td>
<td>
<p>the number of iterations per chain.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_parallel">parallel</code></td>
<td>
<p>logical. If <code>parallel = TRUE</code>, uses parallelization.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_ncores">ncores</code></td>
<td>
<p>integer. The number of cores to use for parallelization.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_returnsamples">returnSamples</code></td>
<td>
<p>logical. If <code>returnSamples = TRUE</code>, print Metropolis-Hastings samples.</p>
</td></tr>
<tr><td><code id="postInference.MHLS_+3A_...">...</code></td>
<td>
<p>auxiliary <code><a href="#topic+MHLS">MHLS</a></code> arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides post-selection inference for the active coefficients selected by lasso.
Uses Metropolis-Hastings sampler with multiple chains to draw from the
distribution under a fixed active set and generates <code>(1-alpha)</code>
confidence interval for each active coefficients.
Set <code>returnSamples = TRUE</code> to check the Metropolis-Hastings samples.
Check the acceptance rate and adjust <code>tau</code> accordingly.
We recommend to set <code>nChain &gt;= 10</code> and <code>niterPerChain &gt;= 500</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>MHsamples</code></td>
<td>
<p>a list of class MHLS.</p>
</td></tr>
<tr><td><code>confidenceInterval</code></td>
<td>
<p>(1-alpha) confidence interval
for each active coefficient.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 6
p &lt;- 10
X &lt;- matrix(rnorm(n*p),n)
Y &lt;- X %*% rep(1,p) + rnorm(n)
sig2 &lt;- 1
lbd &lt;- .37
weights &lt;- rep(1,p)
parallel &lt;- (.Platform$OS.type != "windows")
postInference.MHLS(X = X, Y = Y, lbd = lbd, sig2.hat = 1, alpha = .05,
nChain = 3, niterPerChain = 20, method = "coeff", parallel = parallel)
postInference.MHLS(X = X, Y = Y, lbd = lbd, sig2.hat = 1, alpha = .05,
nChain = 3, niterPerChain = 20, method = "coeff", parallel = parallel, returnSamples = TRUE)
postInference.MHLS(X = X, Y = Y, lbd = lbd, sig2.hat = 1, alpha = .05,
nChain = 3, niterPerChain = 20, method = "mu", parallel = parallel)
postInference.MHLS(X = X, Y = Y, lbd = lbd, sig2.hat = 1, alpha = .05,
nChain = 3, niterPerChain = 20, method = "mu", parallel = parallel, returnSamples = TRUE)
</code></pre>

<hr>
<h2 id='print.MHLS'>Print Metropolis-Hastings sampler outputs</h2><span id='topic+print.MHLS'></span>

<h3>Description</h3>

<p>Print a brief summary of the MH sampler outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MHLS'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.MHLS_+3A_x">x</code></td>
<td>
<p>an object of class &quot;MHLS&quot;, which is a result of <code><a href="#topic+MHLS">MHLS</a></code>.</p>
</td></tr>
<tr><td><code id="print.MHLS_+3A_...">...</code></td>
<td>
<p>additional print arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+print.MHLS">print.MHLS</a></code> prints out last 10 iterations and a brief summary
of the simulation; number of iterations, number of burn-in periods, PE, PEtype and
acceptance rate.
</p>


<h3>Value</h3>

<p>Above results are silently returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 10
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n)
Y &lt;- X %*% rep(1, p) + rnorm(n)
sigma2 &lt;- 1
lbd &lt;- .37
weights &lt;- rep(1, p)
LassoResult &lt;- lassoFit(X = X, Y = Y, lbd = lbd, type="lasso", weights = weights)
B0 &lt;- LassoResult$B0
S0 &lt;- LassoResult$S0
Result &lt;- MHLS(X = X, PE = rep(0, p), sig2 = sigma2, lbd = lbd, group = 1:p,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     type = "coeff")
print(Result)
</code></pre>

<hr>
<h2 id='summary.MHLS'>Summarizing Metropolis-Hastings sampler outputs</h2><span id='topic+summary.MHLS'></span>

<h3>Description</h3>

<p>Summary method for class &quot;MHLS&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MHLS'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.MHLS_+3A_object">object</code></td>
<td>
<p>an object of class &quot;MHLS&quot;, which is a result of <code><a href="#topic+MHLS">MHLS</a></code>.</p>
</td></tr>
<tr><td><code id="summary.MHLS_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides a summary of each sampled beta and subgradient.
</p>


<h3>Value</h3>

<p>mean, median, standard deviation, 2.5% quantile and 97.5% quantile
for each beta and its subgradient.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' set.seed(123)
n &lt;- 10
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n)
Y &lt;- X %*% rep(1, p) + rnorm(n)
sigma2 &lt;- 1
lbd &lt;- .37
weights &lt;- rep(1, p)
LassoResult &lt;- lassoFit(X = X, Y = Y, lbd = lbd, type = "lasso", weights = weights)
B0 &lt;- LassoResult$B0
S0 &lt;- LassoResult$S0
summary(MHLS(X = X, PE = rep(0, p), sig2 = sigma2, lbd = lbd,
     weights = weights, B0 = B0, S0 = S0, niter = 50, burnin = 0,
     type = "coeff"))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
